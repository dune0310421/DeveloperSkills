[
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 8,
        "title": "Fix bug of sparse attn on hdim 128.",
        "body": "Fix bug of sparse attn on hdim 128.",
        "issue_number": "8",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2023-06-05T08:20:24+00:00",
        "closed_at": "2024-07-04T12:12:37+00:00",
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "commits": [
            "98625ce9fd8023d36986635a0d4bad097177f141"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 2,
        "title": "fix zero bug; fix num_splits",
        "body": "fix zero bug; fix num_splits",
        "issue_number": "2",
        "state": "closed",
        "merged": true,
        "user": "kuizhiqing",
        "merged_by": "sneaxiy",
        "created_at": "2023-02-12T14:21:58+00:00",
        "closed_at": "2023-02-13T02:23:47+00:00",
        "additions": 10,
        "deletions": 7,
        "changed_files": 2,
        "commits": [
            "72306ab90a9adc0fa6152400eca5959af98330ff"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 3,
        "title": "For AlphaFold2 model",
        "body": "- RT",
        "issue_number": "3",
        "state": "closed",
        "merged": false,
        "user": "JamesLim-sy",
        "merged_by": null,
        "created_at": "2023-04-06T03:27:24+00:00",
        "closed_at": "2023-04-06T12:01:07+00:00",
        "additions": 601,
        "deletions": 514,
        "changed_files": 10,
        "commits": [
            "05ee6949ca3596dc83ab78ce4c60971a96b54602"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 6,
        "title": "Try to crop the library's size.",
        "body": "#4 支持了带bias、mask计算的Flash-Attention，但是模板应用太多，导致包大小从50+M增加到了240+M。\r\n\r\n- #4 合入之前包大小：\r\n![280af400950645c5c10374b5ad75ca47](https://github.com/PaddlePaddle/flash-attention/assets/12538138/79f3ae34-3e6d-4739-bc68-779bac6c82df)\r\n\r\n- #4 合入之后包大小：\r\n![dc42f9999982fb0a6cec2cbccb836b49](https://github.com/PaddlePaddle/flash-attention/assets/12538138/124c5e0e-fdcd-471c-ab02-7274287f14ec)\r\n\r\n- 本PR主要通过移除模板、裁剪部分功能来减少动态库的大小，具体包括：\r\n  - cmake中移除fmha_api计算相关的两个cu\r\n  - 裁剪bias_mask分支`head_dim=16`的实现\r\n  - 将has_attn_bias、has_attn_mask从模板传入改成从输入参数传入\r\n  - 因库调用传入的`return_softmax`和`is_causal`始终为`false`，故裁剪掉`return_softmax=true`和`is_causal=true`的分支\r\n![bc5f36a54fcf79c95fefbdfcefbbc8e6](https://github.com/PaddlePaddle/flash-attention/assets/12538138/4357aeb9-a4f3-4b10-a5f2-39b4b5f2a373)\r\n\r\nhttps://github.com/PaddlePaddle/Paddle/pull/52731 CI中已通过除需要Approval、覆盖率之外的全部测试。",
        "issue_number": "6",
        "state": "closed",
        "merged": true,
        "user": "Xreki",
        "merged_by": "sneaxiy",
        "created_at": "2023-05-11T12:01:59+00:00",
        "closed_at": "2023-05-18T09:41:02+00:00",
        "additions": 443,
        "deletions": 636,
        "changed_files": 20,
        "commits": [
            "93f6d23ae30902f3dc68f4889362296e93541934",
            "97361a5fedae8b7c590a08240a381c618baf30dc",
            "4fd0f2a620d3e80fb8ce448f9af63dca25a7886e",
            "7f7d6753a37c0c918391d9334fb7630f61e3617e",
            "4023c807b287c9260cac54874bf76d33906dae30",
            "85cb2f03c8770ace12f85b5e0e00134cf2bb4b7b",
            "818ee7627964e1080aa85fbeecdb01317e8a4663",
            "5819aff6404bc04855e8d452b896c05d9a043db5",
            "4035d9452681d800f483d32c09f08bc8ba14b95f",
            "afee922453d76934c86c2b036f7a5a81fd39055b"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 5,
        "title": "add loop condition when num_split!=0",
        "body": "If `num_splits` can be different from 0, add loop condition to allocate mem.",
        "issue_number": "5",
        "state": "closed",
        "merged": true,
        "user": "kuizhiqing",
        "merged_by": "sneaxiy",
        "created_at": "2023-04-12T06:22:44+00:00",
        "closed_at": "2023-04-12T07:33:08+00:00",
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "commits": [
            "958ac1185120156b5f257704ed68a8180db632fe"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 7,
        "title": "add block sparse api",
        "body": "Add API\r\n\r\n* flash_attn_fwd_block\r\n* flash_attn_bwd_block\r\n\r\nSupport bf16.",
        "issue_number": "7",
        "state": "open",
        "merged": false,
        "user": "kuizhiqing",
        "merged_by": null,
        "created_at": "2023-05-27T10:17:23+00:00",
        "closed_at": null,
        "additions": 469,
        "deletions": 141,
        "changed_files": 11,
        "commits": [
            "48d9be3fddf8b11393d0a9211899d370fe176124",
            "be5cade50b0f93fa5c19c75fadec38db8270a9c7",
            "c51e94408e0832c4982d6e233657ba770748c696",
            "dc557473ec08c0f8d918bb7ebf8de27bab9dec92",
            "ff74bc0c2032f92b97b13aa34ffcdb34eea3692e",
            "98625ce9fd8023d36986635a0d4bad097177f141",
            "5a82ddc3cf3e5849fb3222e0aa71bf8a7c2fe75f"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 9,
        "title": "[WIP]Sparse seqparallel",
        "body": null,
        "issue_number": "9",
        "state": "open",
        "merged": false,
        "user": "zkh2016",
        "merged_by": null,
        "created_at": "2023-06-08T06:06:40+00:00",
        "closed_at": null,
        "additions": 675,
        "deletions": 159,
        "changed_files": 11,
        "commits": [
            "48d9be3fddf8b11393d0a9211899d370fe176124",
            "be5cade50b0f93fa5c19c75fadec38db8270a9c7",
            "c51e94408e0832c4982d6e233657ba770748c696",
            "dc557473ec08c0f8d918bb7ebf8de27bab9dec92",
            "ff74bc0c2032f92b97b13aa34ffcdb34eea3692e",
            "98625ce9fd8023d36986635a0d4bad097177f141",
            "5a82ddc3cf3e5849fb3222e0aa71bf8a7c2fe75f",
            "dd68e2c60edb6ca55ecc3d42161ed2566ba1df34"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 1,
        "title": "CAPI for paddle",
        "body": "Introduce capi for paddle integration.",
        "issue_number": "1",
        "state": "closed",
        "merged": true,
        "user": "kuizhiqing",
        "merged_by": "sneaxiy",
        "created_at": "2023-02-03T05:45:05+00:00",
        "closed_at": "2023-02-06T05:13:26+00:00",
        "additions": 836,
        "deletions": 20,
        "changed_files": 16,
        "commits": [
            "b9dbb1752848c6e6a1c4bde190fe4d4191eba171",
            "1f583e4130708dcb68806c187edba8c5f043a6d9",
            "971d22b5ad4e92dc498e840102c528152763225c",
            "9f756ae41f2feec99e0241ccd18e7ffec967956a",
            "085c77411670cbc2fe056ecdfe9897e1e30f5500"
        ],
        "comment_by": [],
        "review_by": [
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 4,
        "title": "Opitmization for AlphaFold2 model",
        "body": "- Feature: Addition of bias and mask into flash_attention computation. \r\n\r\n- Performance: The last optimization for AlphaFold models, which increasing the performance of AlphaFold2 model from 2.99s/iter to 2.79s/iter.\r\n\r\n- Precision: Have past precision tested on AF2.\r\n\r\n- Citation: https://github.com/dptech-corp/flash-attention",
        "issue_number": "4",
        "state": "closed",
        "merged": true,
        "user": "JamesLim-sy",
        "merged_by": "sneaxiy",
        "created_at": "2023-04-06T12:01:29+00:00",
        "closed_at": "2023-05-08T03:20:18+00:00",
        "additions": 3033,
        "deletions": 13,
        "changed_files": 27,
        "commits": [
            "33bcb9f4c14fe15b790be8acf879bccf22c95309",
            "3043fa4450b93daf78f51290c41cac831316270b",
            "1f1063785c0f48d4973517a638d35a57e2ceee0d",
            "e3dcc69aeaa02537d459532feeb473c3b3a5ee96",
            "327e33fdb74dd3ff3da05cbfbf670f7ea8f018b3",
            "4093cc76b66f989d96f8385ed3577f06d042785e",
            "737f6f9b1ed8e32142f3e7266e245a078da81f2c",
            "05ecd140356cffe46444cd364944f6ec5067e724",
            "17ae436155ac7c7f2945ce10b8574e08bfab90b1",
            "76ee2b2a4855b9a1f14fc61820b89aa838d67e0f",
            "12590d415b1b22fc3e24ff6267255f014ce969b2",
            "fd199a439db69d0e91a869480716e5a5e79336aa",
            "edeaea701e0c0e712f1a43a8970b5d59f5256e3b",
            "4f4862eb9c3d868d4080c9933f42705fb62701ea",
            "eb28018fbbe8e4fd855301a822eda906d463819b",
            "a0c2edf58f2bfad3938c54794789afaa367f176a",
            "b38835146895c6482503a91d81fdadd3aa008e49",
            "e4463b342c59f4771ae081c14e7daf42832b8f56",
            "5886b2a651e20d4f204455575e1d858ac3338728",
            "3730bd92346f2df53e01a530d9af094449c2c445",
            "782a98a1fc02fb36d07129a97750430e4fdf2022",
            "0f93eaa62364a5c9ac9695c75c10878079bfd22f",
            "9e112ed1d4820704ded42437920d7e0255bb2649",
            "b7c6c9ac3c561c46258c8d12d890f7f0191defe4",
            "c90517720f6aabe239d26850aaa5be60396f8f57",
            "8fce2d3965957e54fa934f3b1e8b97cfdbe3746b",
            "7ebe8129d8d7d63bc1d2fa2392c032ef3213bd41",
            "dfafa69b10d16ad94f55e1f1ca2b8ab0f7058ec0",
            "7dc781ed665dc6ca7a674a050db821eb1b0c111a",
            "8571fcd3716e9dc5eef8828d810d77f8af4afa36",
            "bedc55b0ebc26776909b2b989401fabf87c9bfa3",
            "93486d94943605436bb4cb636d9ac4a109d3fcaf"
        ],
        "comment_by": [
            "JamesLim-sy"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 16,
        "title": "Pass RNG state to kernel launch params",
        "body": "fa v2.0.4在前向kernel内部将```seed```和```offset```写入```rng_state```，反向直接读取前向记录的```seed```和```offset```。在paddle框架中，已经实现了前向记录```seed```, ```offset```及反向复用的功能。capi需做对应修改以兼容kernel变化。修改如下：\r\n1. 前向反向的capi都传入```rng_state```。\r\n2. ```seed```和```offset```的类型是```uint64_t```，paddle框架中缺乏对```uint64_t```的支持，因此在paddle框架中以```int64_t```类型申请同样大小的```rng_state```。在反向capi中使用```cudaMemcpyAsync```对```rng_state```写入前向记录的```seed```和```offset```。",
        "issue_number": "16",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "Xreki",
        "created_at": "2023-08-06T06:03:02+00:00",
        "closed_at": "2023-08-06T09:31:27+00:00",
        "additions": 26,
        "deletions": 6,
        "changed_files": 2,
        "commits": [
            "71a43c21b865560a1e5dc12b5fe95d861bc33dbe",
            "653e3ddc4ae4fc18e3b684aeb29d0dc205e0a0c3"
        ],
        "comment_by": [],
        "review_by": [
            "Xreki",
            "Xreki",
            "umiswing"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 15,
        "title": "Update the latest flash-attention repo",
        "body": "rt",
        "issue_number": "15",
        "state": "closed",
        "merged": true,
        "user": "Xreki",
        "merged_by": "Xreki",
        "created_at": "2023-08-04T12:57:51+00:00",
        "closed_at": "2023-08-04T13:23:29+00:00",
        "additions": 785,
        "deletions": 280,
        "changed_files": 20,
        "commits": [
            "8e9820a55bc7d610d942cf5453838197869393e2",
            "56ccaff12678868c773cb9d4af7b309763173a7b",
            "8ee62efca3809894df380aa302516de483a14335",
            "4c98d0b41f38ee638a979064856ae06fc1aec8b6",
            "a03f6f8e9ea6692568d98411b464034c22304afd",
            "32a953f4860511bd1dbf6ef3b92939869c8c7b3f",
            "60499abcfda1fabd48e1b97341f4f888c66991a3",
            "840f7925a0a82aff7e981ee1a28f660623e94a93",
            "184b992dcb2a0890adaa19eb9b541c3e4f9d2a08",
            "a4f148b6abe077cd387e69e5caae45d63a76bb24",
            "8f4cd4c16bc3143b6a2aa3cecbcc8dc8d89dff9e",
            "a4e5d1edddd67f9299fba510732b3c67dcab7219",
            "1c41d2b0e5021907374e9509250ad7a22e5693bd",
            "d30f2e1cd50185c98ed88c0684b4a603f15bee37",
            "cba96bd67fec9e7805e2681204162a0c2a4ddc4c"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 20,
        "title": "[For Debugging] Revert \"Additional mask support on FA2\"",
        "body": "Reverts PaddlePaddle/flash-attention#19\r\n\r\n",
        "issue_number": "20",
        "state": "closed",
        "merged": false,
        "user": "Xreki",
        "merged_by": null,
        "created_at": "2023-10-27T09:14:19+00:00",
        "closed_at": "2023-10-30T06:25:21+00:00",
        "additions": 135,
        "deletions": 314,
        "changed_files": 9,
        "commits": [
            "51e9863a7ca3f2deaf66963869264029f741aec8"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 12,
        "title": "Bump to fa2",
        "body": "Bump to flash-attention-2, keep flash-attention-1 for flash_attn_with_bias_mask",
        "issue_number": "12",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "Xreki",
        "created_at": "2023-08-02T06:54:09+00:00",
        "closed_at": "2023-08-02T12:25:32+00:00",
        "additions": 12855,
        "deletions": 2049,
        "changed_files": 191,
        "commits": [
            "c9a649805bccc4adb6df4f22f1c12562501070f0",
            "2dc2a195890d323f6f9e1b74e4667099e6144f79",
            "57ee618170e1adecbf787365cdf330c63768abd2",
            "f28d61cb2a3969d7ad1c77c5995f613d67ab3d63",
            "e45a46a5b767d76e14c76e4bfac408b7cf94d896",
            "31653980749654c80c561bff5bb697c176da3b46",
            "318e2f1b9b2cdbfae36e3a6b2d5c51d4f096d012",
            "1b18f1b7a133c20904c096b8b222a0916e1b3d37",
            "dc08ea1c33afca500a3d4ada907608f7815a11d9",
            "5d079fdd7a20bbd354080a80b20b5c36c93898d4",
            "4360cfc6a850ee2431cc7b21fdba4fdc6bec4d0f",
            "4d87e4d875077ad9efd25030efa4ab0ba92c19e1",
            "f5d0fbd46805155a4406d36e8fb9f9d0324030c4",
            "993d12448e2af5fe73bad1c8f93a3cb524aade33",
            "009a3e71ece11b2ec20629883f7d66212db52c7d",
            "b6aa059bbfee365db7f991db88af99d3d0bf82da",
            "393882bc089aff64863c260a8633b8390c90aa78",
            "d6fc86057305cc15d91f21221acc78a6bc1d672d",
            "c5be8d3aabef5d282dc095268185c6688ee81dcd",
            "d478eeec8f16c7939c54e4617dbd36f59b8eeed7",
            "dec4f2e9101f88f8beffabc9d0f0379323748973",
            "74af0233166583e58b38c50241831c6114dfea0b",
            "853ff72963e73456c2a318bde1ebfa292ce935e9",
            "31018c5fa0349384d3b90ad66f12d560182020e7",
            "8c424156641ceadc9cd1f5de71c8ae144b4db113",
            "5cee071431b94ec84c2354861da019231e7a16b4",
            "315fd31f0c317b1d0127af71da922fd2a846eef3",
            "7d25a4ec4f4ecef5df1a208ec74ca34455dcb439",
            "6f6e9a9aaf42b2894055495dc3ae4b11be054f3f",
            "1c9ef9b39967f0eab77e3a4ea17690833ec931d6",
            "081c2b012a08ef90346d6adf7e54f55a58b58e9f",
            "72629ac9ba3cedb2ae5333cac3be64b66bc71811",
            "dceb2687c5b0aa40ee0bbb9f0068acc0143499fc",
            "605655bc66bc0fb11ac10dad2e656a97f3729b5b",
            "221a39fd3a6aa12809d05c1cb4fffcac73f6b9ed",
            "a0997bc77c89710878ea6ee9d100bb0f808e0b21",
            "45567a25a2f74cabe17f9d59f88169ad06d4c874",
            "635f159ee32c78319d7ab41b160be998bc4b91b0",
            "df1344f8668829d6e46b32d79d9089d19888da9f",
            "ac3b684cdb2d3262a0dff2b7952ee1519ffcdc9c",
            "b630aef53fb263520a10f86fe08cd5cfb0360702",
            "96d10f654527cc82c81022e16f77a8d9564f7eba",
            "311d6606bf82cece56b600f7f500b4c41d88e27d",
            "3da42d24b1678b3ed930ab86e801b4ee851af1d2",
            "ba2fe7f378c938263e8b5eeeac0fb2766c754551",
            "fcab93b43add5324d97147cd56b245a99424b4c7",
            "67ef5d28df71d395bc16787b31e08ea1afbe4178",
            "fbbb10784881c5b8b2183cb9e4727c397a131aa7",
            "ad113948a6c3864fbe48156a9857e97a38ce758c",
            "d63cfc35518a84ed038426d10ac882029d482091",
            "a9a4b4e4f260ae4d96386ae38a38a3c7638fefc9",
            "3889ba168b2fc0149fb77de1ffdadb478da15e1a",
            "69f5f7d0a23db4debd6888d2b21c5a6a898f8432",
            "5bf7f57d477ff318bb4b650c198fe8b4bc9c8360",
            "36d0a19f1eb5dc5922bbcad6b04749c6d49b6a66",
            "eff9fe6b8076df59d64d7a3f464696738a3c7c24",
            "40a25c8ee7465cf547b929cfa2937034e37bfce9",
            "31f78a9814951374af5238af969338bce45394e4",
            "3cad2ab35d516b014d95d41f6b986f94e3703555",
            "f0c40b7ddb188bccee800628af45214cdced0ad5",
            "c1d117c2d070bbdd0c94be67213bd16ed9717618",
            "852bc40b8c9a5ea0dbe203a3b1bb5b9b1ed07d6b",
            "6d45d0bd6c9f833204d8a6438c4b2d5438729026",
            "cf4f0a39f3ce94a6c19c7a465efad02205bf892d",
            "ce68305c8475b6265ac3493109f3a2189e233bbb",
            "dd9c3a1fc25d415688da65729ecdf7b46341fae1",
            "7c766b1bbc65d341f5f7fcead82946319c9657d0",
            "48bc6eacd61b4b57bbd250057655d52f7068ba2f",
            "27f8f890dff58986391b606bc7c181c3b9f5148a",
            "85b51d61eea5ed85c93168262048005c1a9131c0",
            "8e44c0eefbaf526874406488fcbac3ca70bdefa2",
            "9818f85fee29ac6b60c9214bce841f8109a18b1b",
            "62e981446609156b0c5d2c2a54eb628cce83e66d",
            "a5d8714c2699c5755b201f717577c7fb31389e06",
            "9610114ce8fc16923b09515d2c2f8c1ac7459f0a",
            "e8a0b4acddeff1a85d7d0ad7273ea0f2aeab6143",
            "3a9bfd076f98746c73362328958dbc68d145fbec",
            "d2f4324f4c56e017fbf22dc421943793a8ca6c3b",
            "2800efc71fbd56436829eafad90c795a4fe6a73f",
            "70ab266a5659b3024d88bc1ea58386bc2448779b",
            "72ad03eaa661f6bf3a14c855316c27fbab4f8f4c",
            "6ababeb7dba9277ce6a4819e97da28715daee274",
            "905c13a2d9a845e9ac8bd597e30a19270b058382",
            "4dbcaa144378c1461f0e64420c59fcdd1cd43409",
            "01c40dacc45c91f80b74d4a29f91a44eddd64011",
            "6d48e14a6c2f551db96f0badc658a6279a929df3",
            "4f285b354796fb17df8636485b9a04df3ebbb7dc",
            "b4cc152e97cec3fb608288abdc5fe48daaed32e2",
            "d1a3b52f17b914c93bf740654387b566a7330687",
            "538d570c96cc88030cfc68d538f0fc57be8c72a7",
            "31ae2488e62bbe7b2470c3899c06841da75c63fc",
            "dfc60f6b7d9a2bd94ffa95ae3f0f7d3c4fb4efcb",
            "b8020d73c9e068665586989883083a4a5429a443",
            "30fd8c17d8253310ff3a69636e5c9ce8982e3cf5",
            "2dd87d060958a9de8d86f4437254cb22b073aff1",
            "9ee0ff1d9b6a99630e2a6868b9291dfa32d35abd",
            "6fc1e07da22a344b6f0927b9e21e0eafb31fda99",
            "b3177dfaf696ee522a495bcb48b88d32167aa17f",
            "75e334d407029be25a4665a49c64d59acd45448f",
            "a157cc8c9bf4460da70243bc100a363b5daad9ba",
            "ec9f74ab9ac9f2110d747f0e7c5e01e257c41d78",
            "425dbcb6c6f570346a927ed49fb260bb155adcef",
            "cbf982afa5e3ac03d49e6738e356cbac1c9edf41",
            "684196b8c55d0cf04d1f657dc3d96e8982f7747b",
            "d38357dd2fb4ed92bd8e4156f6c0cff8ddc487e4",
            "767b71ccf0664ea382135f039212f087afc4c682",
            "2a2a3c4bfdaa9d078c8421b516ae7536e6275312",
            "b252072409e69c25f2b9d473cc534e49b24decd2",
            "e700b350dbf886d3354da1c5c16c8f61cc68f49f",
            "b6b03f793bc10c2ac861f6cfaf62c6ed6c6aefb5",
            "e63698ce2c0e0be02f162efd1926cac57e071149",
            "5d7dbbae3646a4829027dd7f3c957fe59714218c"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 21,
        "title": "Revert num_splits in flash_bwd_kernel.h for large model",
        "body": "Revert num_splits in flash_bwd_kernel.h for large model",
        "issue_number": "21",
        "state": "closed",
        "merged": true,
        "user": "AnnaTrainingG",
        "merged_by": "sneaxiy",
        "created_at": "2023-10-27T14:51:24+00:00",
        "closed_at": "2023-10-27T14:53:21+00:00",
        "additions": 9,
        "deletions": 9,
        "changed_files": 1,
        "commits": [
            "10fb072f514f6014e17d349a21cea414cec8bca8"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 10,
        "title": "[WIP] FA2 CAPI for paddle",
        "body": "Introduce capi for paddle fa2 integration.",
        "issue_number": "10",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2023-07-27T13:02:10+00:00",
        "closed_at": "2023-07-31T02:54:47+00:00",
        "additions": 13609,
        "deletions": 11291,
        "changed_files": 179,
        "commits": [
            "c9a649805bccc4adb6df4f22f1c12562501070f0",
            "2dc2a195890d323f6f9e1b74e4667099e6144f79",
            "57ee618170e1adecbf787365cdf330c63768abd2",
            "f28d61cb2a3969d7ad1c77c5995f613d67ab3d63",
            "e45a46a5b767d76e14c76e4bfac408b7cf94d896",
            "31653980749654c80c561bff5bb697c176da3b46",
            "318e2f1b9b2cdbfae36e3a6b2d5c51d4f096d012",
            "1b18f1b7a133c20904c096b8b222a0916e1b3d37",
            "dc08ea1c33afca500a3d4ada907608f7815a11d9",
            "5d079fdd7a20bbd354080a80b20b5c36c93898d4",
            "4360cfc6a850ee2431cc7b21fdba4fdc6bec4d0f",
            "4d87e4d875077ad9efd25030efa4ab0ba92c19e1",
            "f5d0fbd46805155a4406d36e8fb9f9d0324030c4",
            "993d12448e2af5fe73bad1c8f93a3cb524aade33",
            "009a3e71ece11b2ec20629883f7d66212db52c7d",
            "b6aa059bbfee365db7f991db88af99d3d0bf82da",
            "393882bc089aff64863c260a8633b8390c90aa78",
            "d6fc86057305cc15d91f21221acc78a6bc1d672d",
            "c5be8d3aabef5d282dc095268185c6688ee81dcd",
            "d478eeec8f16c7939c54e4617dbd36f59b8eeed7",
            "dec4f2e9101f88f8beffabc9d0f0379323748973",
            "74af0233166583e58b38c50241831c6114dfea0b",
            "853ff72963e73456c2a318bde1ebfa292ce935e9",
            "31018c5fa0349384d3b90ad66f12d560182020e7",
            "8c424156641ceadc9cd1f5de71c8ae144b4db113",
            "5cee071431b94ec84c2354861da019231e7a16b4",
            "315fd31f0c317b1d0127af71da922fd2a846eef3",
            "7d25a4ec4f4ecef5df1a208ec74ca34455dcb439",
            "6f6e9a9aaf42b2894055495dc3ae4b11be054f3f",
            "1c9ef9b39967f0eab77e3a4ea17690833ec931d6",
            "081c2b012a08ef90346d6adf7e54f55a58b58e9f",
            "72629ac9ba3cedb2ae5333cac3be64b66bc71811",
            "dceb2687c5b0aa40ee0bbb9f0068acc0143499fc",
            "605655bc66bc0fb11ac10dad2e656a97f3729b5b",
            "221a39fd3a6aa12809d05c1cb4fffcac73f6b9ed",
            "a0997bc77c89710878ea6ee9d100bb0f808e0b21",
            "45567a25a2f74cabe17f9d59f88169ad06d4c874",
            "635f159ee32c78319d7ab41b160be998bc4b91b0",
            "df1344f8668829d6e46b32d79d9089d19888da9f",
            "ac3b684cdb2d3262a0dff2b7952ee1519ffcdc9c",
            "b630aef53fb263520a10f86fe08cd5cfb0360702",
            "96d10f654527cc82c81022e16f77a8d9564f7eba",
            "311d6606bf82cece56b600f7f500b4c41d88e27d",
            "3da42d24b1678b3ed930ab86e801b4ee851af1d2",
            "ba2fe7f378c938263e8b5eeeac0fb2766c754551",
            "fcab93b43add5324d97147cd56b245a99424b4c7",
            "67ef5d28df71d395bc16787b31e08ea1afbe4178",
            "fbbb10784881c5b8b2183cb9e4727c397a131aa7",
            "ad113948a6c3864fbe48156a9857e97a38ce758c",
            "d63cfc35518a84ed038426d10ac882029d482091",
            "a9a4b4e4f260ae4d96386ae38a38a3c7638fefc9",
            "3889ba168b2fc0149fb77de1ffdadb478da15e1a",
            "69f5f7d0a23db4debd6888d2b21c5a6a898f8432",
            "5bf7f57d477ff318bb4b650c198fe8b4bc9c8360",
            "36d0a19f1eb5dc5922bbcad6b04749c6d49b6a66",
            "eff9fe6b8076df59d64d7a3f464696738a3c7c24",
            "40a25c8ee7465cf547b929cfa2937034e37bfce9",
            "31f78a9814951374af5238af969338bce45394e4",
            "3cad2ab35d516b014d95d41f6b986f94e3703555",
            "f0c40b7ddb188bccee800628af45214cdced0ad5",
            "c1d117c2d070bbdd0c94be67213bd16ed9717618",
            "852bc40b8c9a5ea0dbe203a3b1bb5b9b1ed07d6b",
            "6d45d0bd6c9f833204d8a6438c4b2d5438729026",
            "cf4f0a39f3ce94a6c19c7a465efad02205bf892d",
            "ce68305c8475b6265ac3493109f3a2189e233bbb",
            "dd9c3a1fc25d415688da65729ecdf7b46341fae1",
            "7c766b1bbc65d341f5f7fcead82946319c9657d0",
            "48bc6eacd61b4b57bbd250057655d52f7068ba2f",
            "27f8f890dff58986391b606bc7c181c3b9f5148a",
            "85b51d61eea5ed85c93168262048005c1a9131c0",
            "8e44c0eefbaf526874406488fcbac3ca70bdefa2",
            "9818f85fee29ac6b60c9214bce841f8109a18b1b",
            "62e981446609156b0c5d2c2a54eb628cce83e66d",
            "a5d8714c2699c5755b201f717577c7fb31389e06",
            "9610114ce8fc16923b09515d2c2f8c1ac7459f0a",
            "e8a0b4acddeff1a85d7d0ad7273ea0f2aeab6143",
            "3a9bfd076f98746c73362328958dbc68d145fbec",
            "d2f4324f4c56e017fbf22dc421943793a8ca6c3b",
            "2800efc71fbd56436829eafad90c795a4fe6a73f",
            "70ab266a5659b3024d88bc1ea58386bc2448779b",
            "72ad03eaa661f6bf3a14c855316c27fbab4f8f4c",
            "6ababeb7dba9277ce6a4819e97da28715daee274",
            "905c13a2d9a845e9ac8bd597e30a19270b058382",
            "4dbcaa144378c1461f0e64420c59fcdd1cd43409",
            "01c40dacc45c91f80b74d4a29f91a44eddd64011",
            "6d48e14a6c2f551db96f0badc658a6279a929df3",
            "4f285b354796fb17df8636485b9a04df3ebbb7dc",
            "b4cc152e97cec3fb608288abdc5fe48daaed32e2",
            "d1a3b52f17b914c93bf740654387b566a7330687",
            "538d570c96cc88030cfc68d538f0fc57be8c72a7",
            "31ae2488e62bbe7b2470c3899c06841da75c63fc",
            "dfc60f6b7d9a2bd94ffa95ae3f0f7d3c4fb4efcb",
            "b8020d73c9e068665586989883083a4a5429a443",
            "30fd8c17d8253310ff3a69636e5c9ce8982e3cf5",
            "2dd87d060958a9de8d86f4437254cb22b073aff1",
            "9ee0ff1d9b6a99630e2a6868b9291dfa32d35abd",
            "6fc1e07da22a344b6f0927b9e21e0eafb31fda99",
            "b3177dfaf696ee522a495bcb48b88d32167aa17f",
            "75e334d407029be25a4665a49c64d59acd45448f",
            "a157cc8c9bf4460da70243bc100a363b5daad9ba",
            "ec9f74ab9ac9f2110d747f0e7c5e01e257c41d78",
            "425dbcb6c6f570346a927ed49fb260bb155adcef",
            "cbf982afa5e3ac03d49e6738e356cbac1c9edf41",
            "684196b8c55d0cf04d1f657dc3d96e8982f7747b",
            "d38357dd2fb4ed92bd8e4156f6c0cff8ddc487e4",
            "767b71ccf0664ea382135f039212f087afc4c682",
            "2a2a3c4bfdaa9d078c8421b516ae7536e6275312",
            "b252072409e69c25f2b9d473cc534e49b24decd2",
            "9fe487d0bcca3b9d405968e00afe6b865bfef457",
            "58d08be94d2a03c7cb72d6ed6777da272851869a",
            "23c2e4e8bc7d046759b2c537bd0827332dfae4c1",
            "d601ca776152e798fa984d10a8a3e9c6733c81b5",
            "81760bf164d90be984ad9af0e573e7b0ffb0d5a8",
            "bcdef71809d25d6fedc72a92968cf01e7524283c",
            "d27cb4e9dee7a901a65311ae1133396831ae139d",
            "91dcebfc6bf6946b23aed5ea318c6279fa56b2d3",
            "0df25de34ee010b2eff627de63daa6e89c38c1a6",
            "fba0c9c7a41a0b9537937ff9774acba5e36c5368",
            "984ed4815d5eb98a1dd803eb91d035f0fe7a9fe0"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 14,
        "title": "FA2 CAPI for paddle",
        "body": "Introduce capi for paddle fa2 integration.",
        "issue_number": "14",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "Xreki",
        "created_at": "2023-08-02T12:31:05+00:00",
        "closed_at": "2023-08-04T12:18:27+00:00",
        "additions": 1204,
        "deletions": 138,
        "changed_files": 14,
        "commits": [
            "26e3ee3467525bcaa7b29db3f676b90cfa7efc79",
            "939aa2b46f7b4106bc384ea8e2664b80029172cf",
            "be05deb32db7ac213806066e00eb4e9de68a904c",
            "4ee110ae58feb49258f1156aa96f7cb247475494",
            "a8759bcb22b4dae322652d7d510f60d9d0693864",
            "173eaecd6a8c20232bf0a9005c4100be56ffcfa3",
            "386822c0ca8782eff27abd9e093dd645768e2943",
            "0ae2afea1bdc9e4ae1be9e46ca41c2fe741e55b1",
            "3f02d991a7bef8e0310f3f460ea61adc3c2f0c7e",
            "4f33bf40d86f2ffacf623c7b32ee362cd12569ad",
            "4390226b320a502bba4782c2f96721d8756ea589",
            "e8bc323f9cdc6215247e8478b5296784bd8ba6ef",
            "caba237b67a88aa85e971b25ae23cdbd76ca66a2",
            "f6f492d107e167ef98359777d41b50ccc8ab8999",
            "87ba30035e6093e5bdb2207b4aa8a24605afed4b",
            "9feeb8ba790eed2d793b4f0405b343621189f477",
            "a3d2d19279a862ac73d488f8f6ddcf42ee61034b",
            "87e727516489764e1e1d12a9076e90d481e8b84a",
            "8b82f4dd8a9c53e597364deea7a2b36cdab78751",
            "235f0c3bb6b77e79f66dcd1a04c8d98eb08b3861",
            "9835ba103b77e1e73ce1878b1090a7f7e7bfd3a5",
            "17c37cee9d84717007d42b516832d26bcfeda2bc",
            "3a2a8486ed6997b7f78ddde251633ae686e42cf8",
            "951e79a51bf331d439f99fe7b3d1f177e7b5b0fd",
            "4e54844d7858fbbdfa2ec45b145bc6c6daa62135",
            "4090fc0ca8a9e26e6fcb9a1607830226658d8a4c",
            "b6f02d219a2286fc92e430703fa4c64f45f70ecc"
        ],
        "comment_by": [],
        "review_by": [
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "umiswing",
            "umiswing",
            "umiswing",
            "Xreki",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "Xreki"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 17,
        "title": "Add num_splits in flash attn backward api",
        "body": null,
        "issue_number": "17",
        "state": "closed",
        "merged": true,
        "user": "AnnaTrainingG",
        "merged_by": "Xreki",
        "created_at": "2023-08-15T03:47:03+00:00",
        "closed_at": "2023-08-30T06:19:22+00:00",
        "additions": 35,
        "deletions": 14,
        "changed_files": 5,
        "commits": [
            "b76836c0b43feef7b83b5688fab65ca6a5fe9268"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": [
            "umiswing",
            "AnnaTrainingG",
            "umiswing",
            "AnnaTrainingG"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 18,
        "title": "Update to v2.0.8",
        "body": null,
        "issue_number": "18",
        "state": "closed",
        "merged": true,
        "user": "Xreki",
        "merged_by": "Xreki",
        "created_at": "2023-09-13T08:13:47+00:00",
        "closed_at": "2023-09-13T08:53:01+00:00",
        "additions": 845,
        "deletions": 529,
        "changed_files": 22,
        "commits": [
            "add4f0bc42e7d85c23ed20a64453f918f232039d",
            "e1faefce9de958fa64747edef823a0779392b027",
            "0e7769c813fcd2b04882a9cd7e13945002a903d3",
            "dab99053e46c32f394fee40c6d8627f302566b9f",
            "5e4699782a8734f871bee1f628b55d25c05a46a5",
            "9fc9820a5bf0eb851b79388908f43a70affbe296",
            "ea2ed8862341767d1bb7d82bff3cbd27c9740784",
            "cd0c169eeef47eba8d67c0717bec19f6484739b0",
            "a682252be78e09f55925e36775ff5818a26b5172",
            "2dadfdbbcab2edc6a56b068a8cedc73c8324aacc",
            "061470ae58220a189272e72995a4a206f7447d39",
            "18e100d312b9fe04079d993aebb2b68dd145daa3",
            "a372e2be1bd970956bd9b2b8e84f23b7e86e2a4a",
            "ac543b0e8d0d5f30e6ce02411f860995127ca013",
            "84009fcc66fe7a9d777f3b3ec49277ae704656b8",
            "1848d0004f4bf698b908db871db0a22666d2e311",
            "8d60c373e4ed0075baa4c597891ffd9fb576752c",
            "494b2aa48657edb55eb9f5907d5e980014d9dbdc",
            "6c730dc8c669ffd140ed90366cd96aa031a08594",
            "eb812c205b4a4327230f5e75407d06e75917417b",
            "9af165c38920bd18fc066e193383903e6ecff451",
            "364a5b4a71203b9977def9829a5c1a6af45468c8",
            "565615c603bc83ff0215cf62bc4d907b27041215",
            "bc6d4992f2de570969bfbc956799c67fd81c31d0",
            "ecc6535443c73efca91007b1a300c4b049c6c0ff",
            "6ef3bd800e8b8104537ffa0ba4ea10306da40f42",
            "3524e13c11c7866511973a39ebfd60ff6d74f8ce",
            "c5e87b11e95fbebd6d79bb3f05b1f8dce4fe5f7f",
            "dbd79237822c851de3594db08bfb40a3ff992954",
            "3c458cff771c2c22ee5b3296f557194b62ccff53",
            "d8ec6a2f1352c3fdccf8e993c52d75c7da39a4ce",
            "2ddeaa406c9b1408dcbc0051d4d02a9dc1689ebc",
            "67ae6fd74b4bc99c36b2ce524cf139c35663793c",
            "9c531bdc0a3404369ead182af6f8558b3e860162",
            "f8dccfc90a115ce797fed7d5eaf8b066f2753d34",
            "aab603af4f65cd392fc2841067c27dcc78529844",
            "c60851a8253257eb970e06a022c82517a8033e8c",
            "0f7853c6a166d137b2a88ff39d868e5470a27216",
            "c65b5106ac8098c05351d6852561b5c1eb3bc875",
            "2286d7cea7ca8264165c16b2442b6436c43140de",
            "67032ff8eed442eee525f2c8529cb20d165ca05b"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 11,
        "title": "[WIP] FA2 CAPI for paddle",
        "body": "Introduce capi for paddle fa2 integration.",
        "issue_number": "11",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2023-07-31T02:55:25+00:00",
        "closed_at": "2023-08-02T08:48:38+00:00",
        "additions": 14039,
        "deletions": 2181,
        "changed_files": 196,
        "commits": [
            "c9a649805bccc4adb6df4f22f1c12562501070f0",
            "2dc2a195890d323f6f9e1b74e4667099e6144f79",
            "57ee618170e1adecbf787365cdf330c63768abd2",
            "f28d61cb2a3969d7ad1c77c5995f613d67ab3d63",
            "e45a46a5b767d76e14c76e4bfac408b7cf94d896",
            "31653980749654c80c561bff5bb697c176da3b46",
            "318e2f1b9b2cdbfae36e3a6b2d5c51d4f096d012",
            "1b18f1b7a133c20904c096b8b222a0916e1b3d37",
            "dc08ea1c33afca500a3d4ada907608f7815a11d9",
            "5d079fdd7a20bbd354080a80b20b5c36c93898d4",
            "4360cfc6a850ee2431cc7b21fdba4fdc6bec4d0f",
            "4d87e4d875077ad9efd25030efa4ab0ba92c19e1",
            "f5d0fbd46805155a4406d36e8fb9f9d0324030c4",
            "993d12448e2af5fe73bad1c8f93a3cb524aade33",
            "009a3e71ece11b2ec20629883f7d66212db52c7d",
            "b6aa059bbfee365db7f991db88af99d3d0bf82da",
            "393882bc089aff64863c260a8633b8390c90aa78",
            "d6fc86057305cc15d91f21221acc78a6bc1d672d",
            "c5be8d3aabef5d282dc095268185c6688ee81dcd",
            "d478eeec8f16c7939c54e4617dbd36f59b8eeed7",
            "dec4f2e9101f88f8beffabc9d0f0379323748973",
            "74af0233166583e58b38c50241831c6114dfea0b",
            "853ff72963e73456c2a318bde1ebfa292ce935e9",
            "31018c5fa0349384d3b90ad66f12d560182020e7",
            "8c424156641ceadc9cd1f5de71c8ae144b4db113",
            "5cee071431b94ec84c2354861da019231e7a16b4",
            "315fd31f0c317b1d0127af71da922fd2a846eef3",
            "7d25a4ec4f4ecef5df1a208ec74ca34455dcb439",
            "6f6e9a9aaf42b2894055495dc3ae4b11be054f3f",
            "1c9ef9b39967f0eab77e3a4ea17690833ec931d6",
            "081c2b012a08ef90346d6adf7e54f55a58b58e9f",
            "72629ac9ba3cedb2ae5333cac3be64b66bc71811",
            "dceb2687c5b0aa40ee0bbb9f0068acc0143499fc",
            "605655bc66bc0fb11ac10dad2e656a97f3729b5b",
            "221a39fd3a6aa12809d05c1cb4fffcac73f6b9ed",
            "a0997bc77c89710878ea6ee9d100bb0f808e0b21",
            "45567a25a2f74cabe17f9d59f88169ad06d4c874",
            "635f159ee32c78319d7ab41b160be998bc4b91b0",
            "df1344f8668829d6e46b32d79d9089d19888da9f",
            "ac3b684cdb2d3262a0dff2b7952ee1519ffcdc9c",
            "b630aef53fb263520a10f86fe08cd5cfb0360702",
            "96d10f654527cc82c81022e16f77a8d9564f7eba",
            "311d6606bf82cece56b600f7f500b4c41d88e27d",
            "3da42d24b1678b3ed930ab86e801b4ee851af1d2",
            "ba2fe7f378c938263e8b5eeeac0fb2766c754551",
            "fcab93b43add5324d97147cd56b245a99424b4c7",
            "67ef5d28df71d395bc16787b31e08ea1afbe4178",
            "fbbb10784881c5b8b2183cb9e4727c397a131aa7",
            "ad113948a6c3864fbe48156a9857e97a38ce758c",
            "d63cfc35518a84ed038426d10ac882029d482091",
            "a9a4b4e4f260ae4d96386ae38a38a3c7638fefc9",
            "3889ba168b2fc0149fb77de1ffdadb478da15e1a",
            "69f5f7d0a23db4debd6888d2b21c5a6a898f8432",
            "5bf7f57d477ff318bb4b650c198fe8b4bc9c8360",
            "36d0a19f1eb5dc5922bbcad6b04749c6d49b6a66",
            "eff9fe6b8076df59d64d7a3f464696738a3c7c24",
            "40a25c8ee7465cf547b929cfa2937034e37bfce9",
            "31f78a9814951374af5238af969338bce45394e4",
            "3cad2ab35d516b014d95d41f6b986f94e3703555",
            "f0c40b7ddb188bccee800628af45214cdced0ad5",
            "c1d117c2d070bbdd0c94be67213bd16ed9717618",
            "852bc40b8c9a5ea0dbe203a3b1bb5b9b1ed07d6b",
            "6d45d0bd6c9f833204d8a6438c4b2d5438729026",
            "cf4f0a39f3ce94a6c19c7a465efad02205bf892d",
            "ce68305c8475b6265ac3493109f3a2189e233bbb",
            "dd9c3a1fc25d415688da65729ecdf7b46341fae1",
            "7c766b1bbc65d341f5f7fcead82946319c9657d0",
            "48bc6eacd61b4b57bbd250057655d52f7068ba2f",
            "27f8f890dff58986391b606bc7c181c3b9f5148a",
            "85b51d61eea5ed85c93168262048005c1a9131c0",
            "8e44c0eefbaf526874406488fcbac3ca70bdefa2",
            "9818f85fee29ac6b60c9214bce841f8109a18b1b",
            "62e981446609156b0c5d2c2a54eb628cce83e66d",
            "a5d8714c2699c5755b201f717577c7fb31389e06",
            "9610114ce8fc16923b09515d2c2f8c1ac7459f0a",
            "e8a0b4acddeff1a85d7d0ad7273ea0f2aeab6143",
            "3a9bfd076f98746c73362328958dbc68d145fbec",
            "d2f4324f4c56e017fbf22dc421943793a8ca6c3b",
            "2800efc71fbd56436829eafad90c795a4fe6a73f",
            "70ab266a5659b3024d88bc1ea58386bc2448779b",
            "72ad03eaa661f6bf3a14c855316c27fbab4f8f4c",
            "6ababeb7dba9277ce6a4819e97da28715daee274",
            "905c13a2d9a845e9ac8bd597e30a19270b058382",
            "4dbcaa144378c1461f0e64420c59fcdd1cd43409",
            "01c40dacc45c91f80b74d4a29f91a44eddd64011",
            "6d48e14a6c2f551db96f0badc658a6279a929df3",
            "4f285b354796fb17df8636485b9a04df3ebbb7dc",
            "b4cc152e97cec3fb608288abdc5fe48daaed32e2",
            "d1a3b52f17b914c93bf740654387b566a7330687",
            "538d570c96cc88030cfc68d538f0fc57be8c72a7",
            "31ae2488e62bbe7b2470c3899c06841da75c63fc",
            "dfc60f6b7d9a2bd94ffa95ae3f0f7d3c4fb4efcb",
            "b8020d73c9e068665586989883083a4a5429a443",
            "30fd8c17d8253310ff3a69636e5c9ce8982e3cf5",
            "2dd87d060958a9de8d86f4437254cb22b073aff1",
            "9ee0ff1d9b6a99630e2a6868b9291dfa32d35abd",
            "6fc1e07da22a344b6f0927b9e21e0eafb31fda99",
            "b3177dfaf696ee522a495bcb48b88d32167aa17f",
            "75e334d407029be25a4665a49c64d59acd45448f",
            "a157cc8c9bf4460da70243bc100a363b5daad9ba",
            "ec9f74ab9ac9f2110d747f0e7c5e01e257c41d78",
            "425dbcb6c6f570346a927ed49fb260bb155adcef",
            "cbf982afa5e3ac03d49e6738e356cbac1c9edf41",
            "684196b8c55d0cf04d1f657dc3d96e8982f7747b",
            "d38357dd2fb4ed92bd8e4156f6c0cff8ddc487e4",
            "767b71ccf0664ea382135f039212f087afc4c682",
            "2a2a3c4bfdaa9d078c8421b516ae7536e6275312",
            "b252072409e69c25f2b9d473cc534e49b24decd2",
            "9fe487d0bcca3b9d405968e00afe6b865bfef457",
            "58d08be94d2a03c7cb72d6ed6777da272851869a",
            "23c2e4e8bc7d046759b2c537bd0827332dfae4c1",
            "d601ca776152e798fa984d10a8a3e9c6733c81b5",
            "81760bf164d90be984ad9af0e573e7b0ffb0d5a8",
            "bcdef71809d25d6fedc72a92968cf01e7524283c",
            "d27cb4e9dee7a901a65311ae1133396831ae139d",
            "91dcebfc6bf6946b23aed5ea318c6279fa56b2d3",
            "0df25de34ee010b2eff627de63daa6e89c38c1a6",
            "fba0c9c7a41a0b9537937ff9774acba5e36c5368",
            "984ed4815d5eb98a1dd803eb91d035f0fe7a9fe0",
            "fc195488c63add1a4af7bf445b1e47d212433a50",
            "010871a54221351b5996ab760e7089b468ec7d88",
            "9c405b202ade4afce194e9d5e8a64b3507bc9780",
            "8af16e628cb7474d4fcc8ee690a028fdbb05f361",
            "7415d55f369560b231a632e635de5919b401d608",
            "6f14ba8de12dad3d80482d98ce387f06f63c9e6a",
            "fec33e6ae26752942db2fe12d7f07c1343f75905",
            "20d33d3fcad33aa413ad1d51fafe0948e9f3b5aa",
            "41e36a04229b00cb95e915e8e7f57c805bfa0d6b",
            "97200f4cf07f295e7def044561f34e468c083da1",
            "fee8b3d8d9a8931ad2086657408730321cea8e49"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 19,
        "title": "Additional mask support on FA2",
        "body": "Support additional mask on fa2.\r\n\r\nso size: 66M -> 96M\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "issue_number": "19",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "Xreki",
        "created_at": "2023-09-13T08:44:50+00:00",
        "closed_at": "2023-09-22T10:44:44+00:00",
        "additions": 314,
        "deletions": 135,
        "changed_files": 9,
        "commits": [
            "471f95f767c0f121c5faccd0b763f593cb4dde9c",
            "4c162e894841dc1d7d585a5755d1d1d9142a52a8",
            "c2383fd094988d920e9e0eb71c1e485343337bcd",
            "479ce211faab640de81ee16ef991422020287f48",
            "29f691d8bcc9e3a02b68eb72587e36de5ffec000",
            "d7ad81973b1673ec411bca0faeb16723ac346aff",
            "e1564d5dabc09c047d0966efffe5d977a5607ce3",
            "447c093c41cbee0b72425105f4f62477dc9d3100",
            "c718d53b65beb026738bdc8a3a579c1a062979ee",
            "d85752b7c7ca30033ef9e0cab00a2518920d0bb9",
            "49d2a232e9acf730d26fb4760817f666968d32c6",
            "854c4df972375b32bbad636108600a533d7ef2f3",
            "a3a1c27bdd2a1528a0a28e580e2cc768781e135f",
            "ec8bf4fcd00960d4718c21f75bc0a930c898e75f",
            "f939e9c301976d788173c50786120505f1ce66fe",
            "28676577ac99068eb49cd50759278dc3b11606ce",
            "8454bbbd447f82df89d2e9b821fbd2c94ee89b53",
            "1f8dbad952af5d19b122fcd7ea6f04f446b5e3a3",
            "957a73c2afc166d78dcc58c6d7eab1f5f7330869",
            "9ebf2af4ad53533a48da58f9ded1627cfa39ccc6"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": [
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "umiswing",
            "umiswing",
            "umiswing",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "umiswing"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 22,
        "title": "Add template when seqlen_q equal to seqlen_k with casual mask",
        "body": null,
        "issue_number": "22",
        "state": "closed",
        "merged": false,
        "user": "AnnaTrainingG",
        "merged_by": null,
        "created_at": "2023-10-30T08:34:34+00:00",
        "closed_at": "2023-11-06T12:54:02+00:00",
        "additions": 35,
        "deletions": 29,
        "changed_files": 3,
        "commits": [
            "10fb072f514f6014e17d349a21cea414cec8bca8",
            "69349f4a389bd57b68d1208b20e04d0cacc6cd18",
            "897adbf79db80f242ff56fae537a15398c141f45",
            "7afc0838deb5881e65efa78a24ffb523f2cfc5a6",
            "b2e01c0cf2718735da514aa80e821142f36fe140",
            "685f420ebe66c03bd39fc9036d9e484a8cf09159",
            "2991bd1e4c16e600935eeb234faf89a6b1f65678",
            "17dbb1b8da58da1b2db006f4aae941e387694043"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 23,
        "title": "Add template when seqlen_q equal to seqlen_k with casual mask",
        "body": "rebase ",
        "issue_number": "23",
        "state": "closed",
        "merged": true,
        "user": "AnnaTrainingG",
        "merged_by": "sneaxiy",
        "created_at": "2023-10-31T01:58:01+00:00",
        "closed_at": "2023-11-01T10:57:08+00:00",
        "additions": 26,
        "deletions": 20,
        "changed_files": 2,
        "commits": [
            "3bc47d7fbecd994f8df0475e840650fe5bdc2c68"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 27,
        "title": "fix compile error on SM80 & SM90",
        "body": null,
        "issue_number": "27",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-05T06:31:54+00:00",
        "closed_at": "2023-12-05T06:32:52+00:00",
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "00e44837844d5b7ebc9c6738a67ccca05800f4cf",
            "ed3cc7f44dac4fa295bc95df80b493ac7121dac1",
            "1a998830637547ea1501a8095203ea50218b2b8e"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 24,
        "title": "Add SM90 compile options on DFA",
        "body": null,
        "issue_number": "24",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-01T09:07:24+00:00",
        "closed_at": "2023-12-01T09:08:41+00:00",
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "f67e2d660f6a95a9c4b6c2933c2a48ef2e979cbc"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 25,
        "title": "Add SM90 compile options on EFA",
        "body": null,
        "issue_number": "25",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-01T09:09:04+00:00",
        "closed_at": "2023-12-01T09:09:11+00:00",
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "2aad3037a2b2329ecd725148bf5a412ec4e2e82e"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 28,
        "title": "Fix SM90 compilation error",
        "body": null,
        "issue_number": "28",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-06T06:54:59+00:00",
        "closed_at": "2023-12-08T01:38:12+00:00",
        "additions": 19,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "9a5d5072c10df76a8f0ef88dfd5944512f004be8"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 26,
        "title": "fix compile error on SM80 & SM90",
        "body": null,
        "issue_number": "26",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-05T06:28:39+00:00",
        "closed_at": "2023-12-05T06:29:38+00:00",
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "2aad3037a2b2329ecd725148bf5a412ec4e2e82e",
            "5e00bf068b4d0b38a18ecc73d0c49caae85ee70e",
            "0726f3bf5700c98a9ae8f803ebd662407ac67ea6"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 13,
        "title": "FA2 CAPI for paddle",
        "body": "Introduce capi for paddle fa2 integration.",
        "issue_number": "13",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2023-08-02T09:21:11+00:00",
        "closed_at": "2023-08-02T12:29:49+00:00",
        "additions": 14025,
        "deletions": 2181,
        "changed_files": 196,
        "commits": [
            "c9a649805bccc4adb6df4f22f1c12562501070f0",
            "2dc2a195890d323f6f9e1b74e4667099e6144f79",
            "57ee618170e1adecbf787365cdf330c63768abd2",
            "f28d61cb2a3969d7ad1c77c5995f613d67ab3d63",
            "e45a46a5b767d76e14c76e4bfac408b7cf94d896",
            "31653980749654c80c561bff5bb697c176da3b46",
            "318e2f1b9b2cdbfae36e3a6b2d5c51d4f096d012",
            "1b18f1b7a133c20904c096b8b222a0916e1b3d37",
            "dc08ea1c33afca500a3d4ada907608f7815a11d9",
            "5d079fdd7a20bbd354080a80b20b5c36c93898d4",
            "4360cfc6a850ee2431cc7b21fdba4fdc6bec4d0f",
            "4d87e4d875077ad9efd25030efa4ab0ba92c19e1",
            "f5d0fbd46805155a4406d36e8fb9f9d0324030c4",
            "993d12448e2af5fe73bad1c8f93a3cb524aade33",
            "009a3e71ece11b2ec20629883f7d66212db52c7d",
            "b6aa059bbfee365db7f991db88af99d3d0bf82da",
            "393882bc089aff64863c260a8633b8390c90aa78",
            "d6fc86057305cc15d91f21221acc78a6bc1d672d",
            "c5be8d3aabef5d282dc095268185c6688ee81dcd",
            "d478eeec8f16c7939c54e4617dbd36f59b8eeed7",
            "dec4f2e9101f88f8beffabc9d0f0379323748973",
            "74af0233166583e58b38c50241831c6114dfea0b",
            "853ff72963e73456c2a318bde1ebfa292ce935e9",
            "31018c5fa0349384d3b90ad66f12d560182020e7",
            "8c424156641ceadc9cd1f5de71c8ae144b4db113",
            "5cee071431b94ec84c2354861da019231e7a16b4",
            "315fd31f0c317b1d0127af71da922fd2a846eef3",
            "7d25a4ec4f4ecef5df1a208ec74ca34455dcb439",
            "6f6e9a9aaf42b2894055495dc3ae4b11be054f3f",
            "1c9ef9b39967f0eab77e3a4ea17690833ec931d6",
            "081c2b012a08ef90346d6adf7e54f55a58b58e9f",
            "72629ac9ba3cedb2ae5333cac3be64b66bc71811",
            "dceb2687c5b0aa40ee0bbb9f0068acc0143499fc",
            "605655bc66bc0fb11ac10dad2e656a97f3729b5b",
            "221a39fd3a6aa12809d05c1cb4fffcac73f6b9ed",
            "a0997bc77c89710878ea6ee9d100bb0f808e0b21",
            "45567a25a2f74cabe17f9d59f88169ad06d4c874",
            "635f159ee32c78319d7ab41b160be998bc4b91b0",
            "df1344f8668829d6e46b32d79d9089d19888da9f",
            "ac3b684cdb2d3262a0dff2b7952ee1519ffcdc9c",
            "b630aef53fb263520a10f86fe08cd5cfb0360702",
            "96d10f654527cc82c81022e16f77a8d9564f7eba",
            "311d6606bf82cece56b600f7f500b4c41d88e27d",
            "3da42d24b1678b3ed930ab86e801b4ee851af1d2",
            "ba2fe7f378c938263e8b5eeeac0fb2766c754551",
            "fcab93b43add5324d97147cd56b245a99424b4c7",
            "67ef5d28df71d395bc16787b31e08ea1afbe4178",
            "fbbb10784881c5b8b2183cb9e4727c397a131aa7",
            "ad113948a6c3864fbe48156a9857e97a38ce758c",
            "d63cfc35518a84ed038426d10ac882029d482091",
            "a9a4b4e4f260ae4d96386ae38a38a3c7638fefc9",
            "3889ba168b2fc0149fb77de1ffdadb478da15e1a",
            "69f5f7d0a23db4debd6888d2b21c5a6a898f8432",
            "5bf7f57d477ff318bb4b650c198fe8b4bc9c8360",
            "36d0a19f1eb5dc5922bbcad6b04749c6d49b6a66",
            "eff9fe6b8076df59d64d7a3f464696738a3c7c24",
            "40a25c8ee7465cf547b929cfa2937034e37bfce9",
            "31f78a9814951374af5238af969338bce45394e4",
            "3cad2ab35d516b014d95d41f6b986f94e3703555",
            "f0c40b7ddb188bccee800628af45214cdced0ad5",
            "c1d117c2d070bbdd0c94be67213bd16ed9717618",
            "852bc40b8c9a5ea0dbe203a3b1bb5b9b1ed07d6b",
            "6d45d0bd6c9f833204d8a6438c4b2d5438729026",
            "cf4f0a39f3ce94a6c19c7a465efad02205bf892d",
            "ce68305c8475b6265ac3493109f3a2189e233bbb",
            "dd9c3a1fc25d415688da65729ecdf7b46341fae1",
            "7c766b1bbc65d341f5f7fcead82946319c9657d0",
            "48bc6eacd61b4b57bbd250057655d52f7068ba2f",
            "27f8f890dff58986391b606bc7c181c3b9f5148a",
            "85b51d61eea5ed85c93168262048005c1a9131c0",
            "8e44c0eefbaf526874406488fcbac3ca70bdefa2",
            "9818f85fee29ac6b60c9214bce841f8109a18b1b",
            "62e981446609156b0c5d2c2a54eb628cce83e66d",
            "a5d8714c2699c5755b201f717577c7fb31389e06",
            "9610114ce8fc16923b09515d2c2f8c1ac7459f0a",
            "e8a0b4acddeff1a85d7d0ad7273ea0f2aeab6143",
            "3a9bfd076f98746c73362328958dbc68d145fbec",
            "d2f4324f4c56e017fbf22dc421943793a8ca6c3b",
            "2800efc71fbd56436829eafad90c795a4fe6a73f",
            "70ab266a5659b3024d88bc1ea58386bc2448779b",
            "72ad03eaa661f6bf3a14c855316c27fbab4f8f4c",
            "6ababeb7dba9277ce6a4819e97da28715daee274",
            "905c13a2d9a845e9ac8bd597e30a19270b058382",
            "4dbcaa144378c1461f0e64420c59fcdd1cd43409",
            "01c40dacc45c91f80b74d4a29f91a44eddd64011",
            "6d48e14a6c2f551db96f0badc658a6279a929df3",
            "4f285b354796fb17df8636485b9a04df3ebbb7dc",
            "b4cc152e97cec3fb608288abdc5fe48daaed32e2",
            "d1a3b52f17b914c93bf740654387b566a7330687",
            "538d570c96cc88030cfc68d538f0fc57be8c72a7",
            "31ae2488e62bbe7b2470c3899c06841da75c63fc",
            "dfc60f6b7d9a2bd94ffa95ae3f0f7d3c4fb4efcb",
            "b8020d73c9e068665586989883083a4a5429a443",
            "30fd8c17d8253310ff3a69636e5c9ce8982e3cf5",
            "2dd87d060958a9de8d86f4437254cb22b073aff1",
            "9ee0ff1d9b6a99630e2a6868b9291dfa32d35abd",
            "6fc1e07da22a344b6f0927b9e21e0eafb31fda99",
            "b3177dfaf696ee522a495bcb48b88d32167aa17f",
            "75e334d407029be25a4665a49c64d59acd45448f",
            "a157cc8c9bf4460da70243bc100a363b5daad9ba",
            "ec9f74ab9ac9f2110d747f0e7c5e01e257c41d78",
            "425dbcb6c6f570346a927ed49fb260bb155adcef",
            "cbf982afa5e3ac03d49e6738e356cbac1c9edf41",
            "684196b8c55d0cf04d1f657dc3d96e8982f7747b",
            "d38357dd2fb4ed92bd8e4156f6c0cff8ddc487e4",
            "767b71ccf0664ea382135f039212f087afc4c682",
            "2a2a3c4bfdaa9d078c8421b516ae7536e6275312",
            "b252072409e69c25f2b9d473cc534e49b24decd2",
            "e700b350dbf886d3354da1c5c16c8f61cc68f49f",
            "b6b03f793bc10c2ac861f6cfaf62c6ed6c6aefb5",
            "e63698ce2c0e0be02f162efd1926cac57e071149",
            "5d7dbbae3646a4829027dd7f3c957fe59714218c",
            "26e3ee3467525bcaa7b29db3f676b90cfa7efc79",
            "939aa2b46f7b4106bc384ea8e2664b80029172cf",
            "be05deb32db7ac213806066e00eb4e9de68a904c",
            "4ee110ae58feb49258f1156aa96f7cb247475494",
            "a8759bcb22b4dae322652d7d510f60d9d0693864",
            "173eaecd6a8c20232bf0a9005c4100be56ffcfa3",
            "386822c0ca8782eff27abd9e093dd645768e2943",
            "0ae2afea1bdc9e4ae1be9e46ca41c2fe741e55b1",
            "3f02d991a7bef8e0310f3f460ea61adc3c2f0c7e",
            "4f33bf40d86f2ffacf623c7b32ee362cd12569ad",
            "4390226b320a502bba4782c2f96721d8756ea589",
            "e8bc323f9cdc6215247e8478b5296784bd8ba6ef",
            "caba237b67a88aa85e971b25ae23cdbd76ca66a2",
            "f6f492d107e167ef98359777d41b50ccc8ab8999",
            "87ba30035e6093e5bdb2207b4aa8a24605afed4b",
            "9feeb8ba790eed2d793b4f0405b343621189f477",
            "a3d2d19279a862ac73d488f8f6ddcf42ee61034b",
            "87e727516489764e1e1d12a9076e90d481e8b84a",
            "8b82f4dd8a9c53e597364deea7a2b36cdab78751"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 30,
        "title": "Add FA deterministic mode",
        "body": null,
        "issue_number": "30",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2023-12-08T02:03:25+00:00",
        "closed_at": "2023-12-08T02:07:17+00:00",
        "additions": 23,
        "deletions": 20,
        "changed_files": 2,
        "commits": [
            "8d974d420dc458943f49eab197766bbaea46f589"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 32,
        "title": "Support GQA and MQA",
        "body": null,
        "issue_number": "32",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2024-01-03T05:53:33+00:00",
        "closed_at": "2024-01-03T16:18:43+00:00",
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "commits": [
            "b060571370d17935d0db2a1700125d6cb1b6e2d9"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 33,
        "title": "build flash-attn whl",
        "body": "背景：flash-attn的基础功能随Paddle发布。高级功能如：attn_mask功能， 反向确定算法（用于逐位对齐精度调试）需要用户手动安装paddle_flash_attn的whl包。该whl包实际为完成版本的flash-attn，即包含了基础+高级功能。\r\n\r\n介绍：\r\n- 使用方式：paddle_flash_attn的whl包只包含了libflashattn_advanced.so，需要随Paddle一起安装\r\n- 优先级：使用Paddle时，会自动查找paddle_flash_attn package，并设置Paddle的flash-attn动态链接库。因此如果用户安装了paddle_flash_attn，则会设置为libflashattn_advanced.so，否则则依然会使用Paddle whl包中本身包含的libflashattn.so。\r\n-  区别：\r\n    - libflashattn_advanced.so包含基础功能+高级功能，libflashattn.so仅包含基础功能\r\n    - 用户使用Paddle的flash_attention和scaled_dot_product_attention接口时，如果涉及到高级功能，Paddle会自动检查高级功能是否可用，如不可用，则报错提示用户安装paddle_flash_attn的whl包。\r\n\r\n编译方式：进入flash-attention/csrc 创建build文件夹\r\n1. 执行 cmake .. # 此处有2个选项可以设置\r\n```\r\n-DNVCC_ARCH_BIN=80-90 表示编译80 和 90 架构，默认值编译 80\r\n-DWITH_ADVANCED=ON 表示是否使用paddle flash_attention的高级功能，默认为OFF\r\n# 示例\r\n cmake .. -DNVCC_ARCH_BIN=80-90, -DWITH_ADVANCED=ON\r\n```\r\n\r\n2. 编译产物\r\n    - 如果设置-DWITH_ADVANCED=ON ，flash-attention/csrc/build/paddle_flash_attn 下会产生libflashattn_advanced.so；flash-attention/csrc/build/dist 下会生成如 paddle_flash_attn-2.0.8+cu12.0-py3-none-linux_x86_64.whl。\r\n    - 如果设置-DWITH_ADVANCED=OFF， flash-attention/csrc/build 下会产生 libflashattn.so 不会对.so进行打包【用于paddle内部源码编译】\r\n\r\n\r\nPaddle PR：https://github.com/PaddlePaddle/Paddle/pull/61813",
        "issue_number": "33",
        "state": "closed",
        "merged": true,
        "user": "zhangting2020",
        "merged_by": "sneaxiy",
        "created_at": "2024-01-10T06:59:29+00:00",
        "closed_at": "2024-02-26T14:46:18+00:00",
        "additions": 215,
        "deletions": 10,
        "changed_files": 6,
        "commits": [
            "e14a2fa2a0b92302a9cd7a6059f44255d414aaa3",
            "9765de4a05ee8a805d797fe5b27e1b6c3f705bfb",
            "36aec08bb33150258ed8548ad3e258e5704627e7",
            "5be3f0dc18d4db8e4e9423b6d56ac696428ef022",
            "d68eaa76acc647bb56fa36edcabea398d869796b"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 34,
        "title": "Fix Is_equal_qk error in FA fwd kernel",
        "body": "When `cu_seqlens_q` or `cu_seqlens_k` is not `nullptr`, the sequence lengths of `Q`, `K` and `V` are dynamic. In this way, `Is_equal_qk` should be false.",
        "issue_number": "34",
        "state": "closed",
        "merged": true,
        "user": "sneaxiy",
        "merged_by": "sneaxiy",
        "created_at": "2024-01-11T12:37:00+00:00",
        "closed_at": "2024-01-11T12:48:04+00:00",
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "commits": [
            "e09f90bb0d874ab5894a1e90847c59df23dc7cc8"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 39,
        "title": "Revert \"build flash-attn whl\"",
        "body": "Reverts PaddlePaddle/flash-attention#33",
        "issue_number": "39",
        "state": "closed",
        "merged": true,
        "user": "kircle888",
        "merged_by": "sneaxiy",
        "created_at": "2024-04-18T10:17:55+00:00",
        "closed_at": "2024-04-19T12:18:14+00:00",
        "additions": 10,
        "deletions": 215,
        "changed_files": 6,
        "commits": [
            "8f3f4bf4c99506984683e7a83356d96c21ba1cde"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 35,
        "title": "Support FlashAttentionWithSparseMask",
        "body": null,
        "issue_number": "35",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-01-31T08:08:16+00:00",
        "closed_at": "2024-02-21T04:10:51+00:00",
        "additions": 149,
        "deletions": 18,
        "changed_files": 9,
        "commits": [
            "fbe8aa3b8a7cb47ca2bb902da336d9ec529edc80",
            "b4cc779c51cdc7118979d72fdfe997b4959316eb",
            "d42c8cadbea1af86f3b6ee450a502cf657b8317f",
            "ccd103069b85a70b0af20bbc76fa6df452dcb21b",
            "f0974dd39a105662fc2a9a95bd8807c6b23c4a4b"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 40,
        "title": "Revert \"[Cherry-pick] Support flash attention 2 with causal masking when KV's seq length is longer than Q's seq length.\"",
        "body": "Reverts PaddlePaddle/flash-attention#36",
        "issue_number": "40",
        "state": "closed",
        "merged": true,
        "user": "kircle888",
        "merged_by": "sneaxiy",
        "created_at": "2024-04-22T12:43:12+00:00",
        "closed_at": "2024-04-23T09:30:52+00:00",
        "additions": 11,
        "deletions": 14,
        "changed_files": 3,
        "commits": [
            "4f676ce52ce56233063bb1d8ab34fd4a0fc9d1a1"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 31,
        "title": "Fa cmake extends op",
        "body": null,
        "issue_number": "31",
        "state": "open",
        "merged": false,
        "user": "AnnaTrainingG",
        "merged_by": null,
        "created_at": "2023-12-14T07:01:29+00:00",
        "closed_at": null,
        "additions": 773,
        "deletions": 7,
        "changed_files": 5,
        "commits": [
            "b5b20b814f60f6435b73b75653c1a8a7244acefa",
            "199b9d68ad1d89e724987bbd9de16a92a7c6cf38",
            "a582b3a9e571bea2f65284c0626756ad7ff589a3",
            "78080ddb5dfdec3a0154698ea81ccc3a45826c39",
            "0d6766ef6c134f8a550db884409238c949c32ef8",
            "17b89c9047017af7cb127bf5c1eec349e9045b5a",
            "1355060bb29ad6c703f003d8022fb786cc158a52",
            "d536119e240ac62eb6b8b71c872115a49200c11e",
            "66fc8a754ceee446a05964bbf99746536fd82c3f",
            "41ebd074fb8942a2cefe7f1f318945ab8176475a",
            "ad614e0dfcaa8862eedb59506d65b2ed8f6a5a39",
            "c8d003ab709aec89ada749677d2c3e4c014d860b",
            "559a47952de47cfd5aeecb66cdc306208757dec8",
            "bd670ae650df79b3b60b98d4de6be8fd69f00d41",
            "e4b500675954bf1a9f48189e512e1c00b73c902a",
            "4f7f1f0dfa0793fc24fe495bf55a0efa75986442",
            "8c12f7266657a1627f4331053de776b843e610ba",
            "7b257e8ad308b30a5a98bd861b7d14e1f3a30a74",
            "4fd33eaf567f5a837f63bd5b1d2e7383c006d76e",
            "f03a1dffd0f3661c80c7d4098f5769a04b3febae",
            "d8101084517132fa4f43cd657edd5fc3e28d792f",
            "48eb6479fd7163bd20164f0e36ad9a3b5f7ec510",
            "7bb6f314f0995d2a1bc67aa95e2a0edd573dd906",
            "58563ba8c8172dad5439041fc396d61dc120d449",
            "e856a057707bb1d101e1e49bf2558646fb11cfd4",
            "256a3c6b8a9b13923cb1c7f4e9cae6dd2a726361",
            "af386bf4e232948e1c713339e72eb2b05943272b",
            "3aca223f32b4117dc44177c9932eb44712fcae34",
            "06edc27972b0a8a08a62b42ea410058679fc25bb",
            "45fcc53e73b3ea9b69098ccfe9878fd26467427d",
            "940a8ae76bdc72fe79d38f9d083c7d629531c6c0",
            "6b6c7a88e490056fd47698b83402fb4c471ab109",
            "18ae75621289868c096ea63477271bd227ab5805",
            "d926c09ca157063b1a8ed673d24fcb358c9a11d4",
            "a2714ebebc2113548bd5d47d6f44fde0b4cc4872",
            "a61e35b2bb4195f98811ed90c06ddabf2390c75e",
            "600d748a16ebe044054c4cb695978476006baede"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 38,
        "title": "Fix unpadding input with padding mask compute error",
        "body": "Fix unpadding input with padding mask compute error",
        "issue_number": "38",
        "state": "open",
        "merged": false,
        "user": "wwbitejotunn",
        "merged_by": null,
        "created_at": "2024-04-15T04:10:46+00:00",
        "closed_at": null,
        "additions": 6,
        "deletions": 12,
        "changed_files": 1,
        "commits": [
            "3450d89830017e7b5f20b3bb28553736137923e6",
            "c450e752a72fcf0677c2f0f0ac00bf78dc53daea"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 37,
        "title": "flashattn support stride and padded varlen",
        "body": "q/k/v/o/dq/dk/dv的batch/row/head stride属性将作为参数传入并被正确设置\r\n当varlen_padded_input被设置时，kernel将认为输入输出是padded，但是会根据cu_seq_len跳过padding部分的计算",
        "issue_number": "37",
        "state": "closed",
        "merged": true,
        "user": "kircle888",
        "merged_by": "sneaxiy",
        "created_at": "2024-04-07T11:29:49+00:00",
        "closed_at": "2024-04-10T07:05:09+00:00",
        "additions": 478,
        "deletions": 18,
        "changed_files": 4,
        "commits": [
            "2521ed0f49750e45cb0a9769aaf445e28d776809"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 36,
        "title": "[Cherry-pick] Support flash attention 2 with causal masking when KV's seq length is longer than Q's seq length.",
        "body": "cherry pick from https://github.com/Dao-AILab/flash-attention/commit/e07aa036db0e6cd251b17d9ee2d1720023da2def\r\n\r\nthe detail of PR: https://github.com/Dao-AILab/flash-attention/pull/436\r\n",
        "issue_number": "36",
        "state": "closed",
        "merged": true,
        "user": "Wanglongzhi2001",
        "merged_by": "sneaxiy",
        "created_at": "2024-03-25T02:24:38+00:00",
        "closed_at": "2024-04-08T03:14:51+00:00",
        "additions": 14,
        "deletions": 11,
        "changed_files": 3,
        "commits": [
            "cc2a9da6be4f0a77af58e0db49aa03ef27a06204"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 29,
        "title": "Fa cmake",
        "body": "PR描述：\r\n1. 将csrc/build编译产生的结果编译成whl 或者 .so\r\n\r\n2. 使用方法：\r\n    1. 进入flash-attention/csrc 创建build文件夹\r\n    2. 执行 cmake ..   # 此处有2个选项可以设置\r\n        1.   -DNVCC_ARCH_BIN=80-90 表示编译80 和 90 架构，默认值编译 80\r\n        2.  -DWITH_ADVANCED=ON 表示是否使用paddle flash_attention的高级功能\r\n             + 高级功能包含：\r\n                       1. attn_mask功能支持， \r\n                       2. fa反向确定算法支持，用于逐位对齐精度调试）\r\n    3. make -j128\r\n    5. 示例：  cmake .. -DNVCC_ARCH_BIN=80-90，-DWITH_ADVANCED=ON\r\n    6. 编译结束后在：\r\n        1. 如果设置-DWITH_ADVANCED=ON ：\r\n                    1.    flash-attention/csrc/build 下会产生 libflashattn_advanced.so\r\n                    2.   flash-attention/csrc/build/dist  下会生成 paddle_flash_attn-2.0.8-cp37-none-any.whl 【注意这个打包只打包了libflashattn_advanced.so】\r\n                    3.   2.0.8表示当前paddle flash_attention的版本， cp37表示python版本为3.7， any 表示任意平台均可\r\n        2. 如果不设置则\r\n                    1. flash-attention/csrc/build 下会产生 libflashattn.so  不会对.so进行打包【用于paddle内部源码编译】\r\n\r\npaddle_flash_attn-2.0.8-cp37-none-any.whl  使用方法：\r\n            直接pip install 即可\r\n\r\n说明：安装后后在/usr/local/lib/python3.7/dist-packages/paddle/libs/下新增  libflashattn_advanced.so。\r\n触发条件： 当使用additional_mask功能 |  设置确定算法环境变量  | 设置 FLAGS_flash_attention_with_advanced 环境变量时 会调用  libflashattn_advanced.so 中的实现，如果未安装libflashattn_advanced.so 则会直接报错。\r\n<img width=\"506\" alt=\"image\" src=\"https://github.com/PaddlePaddle/flash-attention/assets/51102941/6e6a8f36-1431-4c70-879e-9eaf1ec5c387\">\r\n<img width=\"529\" alt=\"image\" src=\"https://github.com/PaddlePaddle/flash-attention/assets/51102941/f5ad34c4-edf0-4871-956a-49c529abe1cd\">\r\n\r\n\r\n本PR修改后.so大小：\r\n<img width=\"1009\" alt=\"image\" src=\"https://github.com/PaddlePaddle/flash-attention/assets/51102941/cb5eb7eb-f2bd-440a-9e1d-0080272fd352\">\r\n\r\n\r\n",
        "issue_number": "29",
        "state": "open",
        "merged": false,
        "user": "AnnaTrainingG",
        "merged_by": null,
        "created_at": "2023-12-06T10:52:43+00:00",
        "closed_at": null,
        "additions": 296,
        "deletions": 7,
        "changed_files": 4,
        "commits": [
            "b5b20b814f60f6435b73b75653c1a8a7244acefa",
            "199b9d68ad1d89e724987bbd9de16a92a7c6cf38",
            "a582b3a9e571bea2f65284c0626756ad7ff589a3",
            "78080ddb5dfdec3a0154698ea81ccc3a45826c39",
            "0d6766ef6c134f8a550db884409238c949c32ef8",
            "17b89c9047017af7cb127bf5c1eec349e9045b5a",
            "1355060bb29ad6c703f003d8022fb786cc158a52",
            "d536119e240ac62eb6b8b71c872115a49200c11e",
            "66fc8a754ceee446a05964bbf99746536fd82c3f",
            "41ebd074fb8942a2cefe7f1f318945ab8176475a",
            "ad614e0dfcaa8862eedb59506d65b2ed8f6a5a39",
            "c8d003ab709aec89ada749677d2c3e4c014d860b",
            "559a47952de47cfd5aeecb66cdc306208757dec8",
            "bd670ae650df79b3b60b98d4de6be8fd69f00d41",
            "e4b500675954bf1a9f48189e512e1c00b73c902a",
            "4f7f1f0dfa0793fc24fe495bf55a0efa75986442",
            "8c12f7266657a1627f4331053de776b843e610ba",
            "7b257e8ad308b30a5a98bd861b7d14e1f3a30a74",
            "4fd33eaf567f5a837f63bd5b1d2e7383c006d76e",
            "f03a1dffd0f3661c80c7d4098f5769a04b3febae",
            "d8101084517132fa4f43cd657edd5fc3e28d792f",
            "48eb6479fd7163bd20164f0e36ad9a3b5f7ec510",
            "7bb6f314f0995d2a1bc67aa95e2a0edd573dd906",
            "58563ba8c8172dad5439041fc396d61dc120d449",
            "e856a057707bb1d101e1e49bf2558646fb11cfd4",
            "256a3c6b8a9b13923cb1c7f4e9cae6dd2a726361",
            "af386bf4e232948e1c713339e72eb2b05943272b",
            "3aca223f32b4117dc44177c9932eb44712fcae34",
            "06edc27972b0a8a08a62b42ea410058679fc25bb",
            "45fcc53e73b3ea9b69098ccfe9878fd26467427d",
            "940a8ae76bdc72fe79d38f9d083c7d629531c6c0",
            "6b6c7a88e490056fd47698b83402fb4c471ab109",
            "18ae75621289868c096ea63477271bd227ab5805",
            "d926c09ca157063b1a8ed673d24fcb358c9a11d4",
            "a2714ebebc2113548bd5d47d6f44fde0b4cc4872",
            "a61e35b2bb4195f98811ed90c06ddabf2390c75e"
        ],
        "comment_by": [
            "Xreki",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "CLAassistant"
        ],
        "review_by": [
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "Xreki",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "Xreki",
            "Xreki",
            "Xreki",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "AnnaTrainingG",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "sneaxiy",
            "AnnaTrainingG"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 42,
        "title": "Flashmask",
        "body": "sparsemask相关内容将被重命名为flashmask\r\n当使用Flashmask时，支持避免计算完全masked的block以减少计算量\r\n支持双向的flashmask",
        "issue_number": "42",
        "state": "closed",
        "merged": false,
        "user": "kircle888",
        "merged_by": null,
        "created_at": "2024-04-26T09:18:10+00:00",
        "closed_at": "2024-07-09T01:40:38+00:00",
        "additions": 505,
        "deletions": 98,
        "changed_files": 10,
        "commits": [
            "d7eced81abe2257531de62d75a6d26f9105b673c",
            "2be69c9c1ffe90807be49d264ee5f58c2b5344d0",
            "0cc2c95bcf5bdc07d8f9c25fe82813377fd322d9",
            "32846115ace21582092027f840870cd20bc8d5ae",
            "e0157592b51395f6a71598a9448d26d7ed54ff26",
            "fad8447ae73d82158f74526472cc615cc6ca8d13",
            "94b772547bd500cdb2b6b12f25559cbfcc4c442b",
            "68f8ab92e444d8c57a3f5c328b00ea83cba5bbef",
            "d6d1e659e0d0726fe6160d95aa65abbe1d90527f",
            "07791f41be29c1669dcc45bcb68047c0ea65c54f",
            "c3212be631fc97957339f024f80b4485fe7348b9",
            "12d37525ce5bf3b39badf3f3080f5ce00d9b9b8b",
            "43c517dc87549a7045ae5f3db48a2ce0f6a5b9b8",
            "e9f25be009eb8fa3e1c937d5d0725c5643d47d04",
            "1e82ffc6527fe187ca914f50597f554cc94e356e",
            "8bd7e4734a137aad1640690685f5aab5fca3bf83",
            "63130e57327e7512296fd3537f24ace2bb7c3d3a",
            "b15f2e57b5e42c2088d52c292a4404908914c45d",
            "13d73df40c590993ef7c663943023034d9b1f753",
            "f20f94d331b292dbd79ee4eccae39d82b432c397",
            "0d17840a101d579ceb228e48e65c43559a10087a",
            "aaf36624bd403533223015fd3361c466ca4bdbdf",
            "dec79ae95d3d7515c20e055ee08fdce190ddf196",
            "7b64a27f4f758dcc1ddf29fb464aaed141422254",
            "2863eb80ccc942e211752181105978560365ac64",
            "64bc18726058bc0f810c8b5cd07c9ccf2936d13e",
            "2fb731d1fa4fefda9fbfc3a81cb107b6dbccdca8",
            "eafb9849c7a65ac586625811d6723ada2871d845"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 43,
        "title": "Support reduce attention scores.",
        "body": "Add a new kernel: `calc_reduced_attn_scores`, which returns reduce sum of attention scores over dim `seqlen_q`.\r\n\r\nso size: 312M -> 320M\r\n\r\nPaddle PR: https://github.com/PaddlePaddle/Paddle/pull/64823",
        "issue_number": "43",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "sneaxiy",
        "created_at": "2024-06-05T03:31:19+00:00",
        "closed_at": "2024-07-05T08:05:08+00:00",
        "additions": 794,
        "deletions": 0,
        "changed_files": 22,
        "commits": [
            "edebe353a87c2df09e8e8b004e477b6fd60f3d31",
            "12c768e35f18e9634b13b92a04fc0c33776f45be",
            "da5f718ebad8e083353c6e1a7c15da25d5e19dd3",
            "dd775232ec49909e7974562da60ecbc45e057c7b",
            "865c470e118d34cf69a7e8515ee8713678e036b2",
            "bb4dd6a371bf19622480059f74824f988ea4979f",
            "dd016835c5efec44dce41c0abd23208d30840f2a",
            "2c057e8ad068fe27ec6ff27a7204a5b89c299d52",
            "ef8a4a40c1708fe081ddc0a43d91cd4ddf3ecf3a",
            "89d8eada9799b1bf2eab302cea536c6b55151814",
            "33053de518ab953bff8e080fd8b73573b90a00df",
            "396be2967d3a1c3acf9bc2b83b0548baa3aa9d59",
            "63a730e1ac3ee54204b1d6be48f81b0acdb4dc16"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 41,
        "title": "[BugFix] fix_mask error using unpadding api",
        "body": "fix mask add error when using unpadding api",
        "issue_number": "41",
        "state": "open",
        "merged": false,
        "user": "wwbitejotunn",
        "merged_by": null,
        "created_at": "2024-04-23T13:42:17+00:00",
        "closed_at": null,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "commits": [
            "e84b9a535aa254c342ce7fa74dfcbfd56f586b09"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 46,
        "title": "Flashmask  support upend",
        "body": "完善Flashmask双向带结束行功能",
        "issue_number": "46",
        "state": "closed",
        "merged": true,
        "user": "kircle888",
        "merged_by": "sneaxiy",
        "created_at": "2024-07-30T07:41:22+00:00",
        "closed_at": "2024-08-09T02:28:25+00:00",
        "additions": 150,
        "deletions": 36,
        "changed_files": 3,
        "commits": [
            "8d522b088b76157322b093a9215ede5cb61764da",
            "9ed9316fa038db041f23b1e7554c1e052b374045"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 45,
        "title": "Flashmask",
        "body": "sparsemask相关内容将被重命名为flashmask\r\n当使用Flashmask时，支持避免计算完全masked的block以减少计算量\r\n支持双向的flashmask，支持单向带结束行的flashmask",
        "issue_number": "45",
        "state": "closed",
        "merged": true,
        "user": "kircle888",
        "merged_by": "sneaxiy",
        "created_at": "2024-07-09T01:40:26+00:00",
        "closed_at": "2024-07-23T12:01:35+00:00",
        "additions": 632,
        "deletions": 105,
        "changed_files": 9,
        "commits": [
            "d7eced81abe2257531de62d75a6d26f9105b673c",
            "2be69c9c1ffe90807be49d264ee5f58c2b5344d0",
            "0cc2c95bcf5bdc07d8f9c25fe82813377fd322d9",
            "32846115ace21582092027f840870cd20bc8d5ae",
            "e0157592b51395f6a71598a9448d26d7ed54ff26",
            "fad8447ae73d82158f74526472cc615cc6ca8d13",
            "94b772547bd500cdb2b6b12f25559cbfcc4c442b",
            "68f8ab92e444d8c57a3f5c328b00ea83cba5bbef",
            "d6d1e659e0d0726fe6160d95aa65abbe1d90527f",
            "07791f41be29c1669dcc45bcb68047c0ea65c54f",
            "c3212be631fc97957339f024f80b4485fe7348b9",
            "12d37525ce5bf3b39badf3f3080f5ce00d9b9b8b",
            "43c517dc87549a7045ae5f3db48a2ce0f6a5b9b8",
            "e9f25be009eb8fa3e1c937d5d0725c5643d47d04",
            "1e82ffc6527fe187ca914f50597f554cc94e356e",
            "8bd7e4734a137aad1640690685f5aab5fca3bf83",
            "63130e57327e7512296fd3537f24ace2bb7c3d3a",
            "b15f2e57b5e42c2088d52c292a4404908914c45d",
            "13d73df40c590993ef7c663943023034d9b1f753",
            "f20f94d331b292dbd79ee4eccae39d82b432c397",
            "0d17840a101d579ceb228e48e65c43559a10087a",
            "803a1af8f2557c30c2d6e51979042e1fb8d2e5a0",
            "751105a9f871f99b87713593f2d5ad9aec3d2eff",
            "d8034ed593970caa1e341d5622682a724a9af518"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 48,
        "title": "Fix bug in apply_sparse_mask at diagonal",
        "body": "Fix bug in `apply_sparse_mask_causal` and `apply_sparse_mask_causal_withend`.",
        "issue_number": "48",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "sneaxiy",
        "created_at": "2024-08-28T14:43:50+00:00",
        "closed_at": "2024-08-28T14:44:47+00:00",
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "commits": [
            "6e6748955daf8e7cf669fb5d3687898a3e130598"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 49,
        "title": "optimize skip block calculate in bwd",
        "body": "Optimize FlashMask by skipping the computation of masked-out blocks during the backward pass, thereby improving backward performance.",
        "issue_number": "49",
        "state": "open",
        "merged": false,
        "user": "GuoxiaWang",
        "merged_by": null,
        "created_at": "2024-08-28T15:03:21+00:00",
        "closed_at": null,
        "additions": 62,
        "deletions": 30,
        "changed_files": 2,
        "commits": [
            "598f152cb033be01574cafeb8ad48e33b705b978"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 44,
        "title": "flash attention v2 for paddle-dcu",
        "body": "flash attention v2 for paddle-dcu",
        "issue_number": "44",
        "state": "closed",
        "merged": true,
        "user": "yuguo-Jack",
        "merged_by": "sneaxiy",
        "created_at": "2024-06-25T02:06:33+00:00",
        "closed_at": "2024-06-25T12:30:22+00:00",
        "additions": 325304,
        "deletions": 55108,
        "changed_files": 2114,
        "commits": [
            "2ae2ad0696d4f9dfe5014985a0783cc903164630",
            "f99425ebe7a1b7ed184c4eb5b2abe3fc282ea1d0",
            "b03e6daa13d25c7b1bf37f761d69f6e667b31a8e"
        ],
        "comment_by": [],
        "review_by": [
            "SylarTiaNII",
            "SylarTiaNII"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 50,
        "title": "Revert \"Flashmask  support upend (#46)\"",
        "body": "This reverts commit 666d5c56bba917f9f5197cb4a2fdee123f0f6c38.",
        "issue_number": "50",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-08-29T11:16:41+00:00",
        "closed_at": "2024-08-29T11:20:25+00:00",
        "additions": 36,
        "deletions": 150,
        "changed_files": 3,
        "commits": [
            "c6e60149d93508c718ede12147bc714d5a9afc82"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 47,
        "title": "[WIP] skip gemm in bwd.",
        "body": null,
        "issue_number": "47",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2024-08-25T06:32:08+00:00",
        "closed_at": "2024-10-16T06:02:13+00:00",
        "additions": 77,
        "deletions": 16,
        "changed_files": 3,
        "commits": [
            "df0a579cfc9b7f5203539d35ffcbccfeead3c4e0",
            "0198ececefe738964098f51790d976285ddf9311"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 53,
        "title": "opt bwk skip load",
        "body": null,
        "issue_number": "53",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-09-22T10:54:01+00:00",
        "closed_at": "2024-09-23T01:25:10+00:00",
        "additions": 32,
        "deletions": 10,
        "changed_files": 1,
        "commits": [
            "b240ff89b1cb15bf5ea06b55d3258bee4a2d04ea",
            "36aedf87f02c23f0dd898cb4fad008c83a51e04a"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 54,
        "title": "remove enable_mask_bypass limit",
        "body": null,
        "issue_number": "54",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-09-23T07:16:02+00:00",
        "closed_at": "2024-09-23T07:36:24+00:00",
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "commits": [
            "8c092ce6abb2efbf2e951b58ad88173b96bb9cea"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 51,
        "title": "Supports FlashMask bidirectional attention has start row",
        "body": "Supports FlashMask bidirectional attention with both start and end row functionality, and optimizes performance by skipping masked blocks during backward computation.",
        "issue_number": "51",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-08-31T12:53:34+00:00",
        "closed_at": "2024-09-11T07:05:31+00:00",
        "additions": 3115,
        "deletions": 1087,
        "changed_files": 44,
        "commits": [
            "e72d842ff55d666d4ca7668e03652d141181f3ed",
            "761104a8998e4911e1e3ee37b5847d6e37a4d721",
            "2ddb61a7626c51f2c966a5cc57757d9bf7bd11e9",
            "1b81033268e82eb9b44abeba040d2776ff363876",
            "2f5db281ea710ef35c2c968f72d05270cf71d6ba",
            "338eadb0777b3ae00d8c9d3e1f43d076f8ddf90c",
            "49e5a51b55d594001fc99c1692a7f780b29297fb"
        ],
        "comment_by": [],
        "review_by": [
            "sneaxiy"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 55,
        "title": "scan from right to left and skip masked block for each row at kernel begin",
        "body": null,
        "issue_number": "55",
        "state": "open",
        "merged": false,
        "user": "GuoxiaWang",
        "merged_by": null,
        "created_at": "2024-09-23T08:28:08+00:00",
        "closed_at": null,
        "additions": 80,
        "deletions": 37,
        "changed_files": 1,
        "commits": [
            "c0380cea20132e88d2364208f46088e5566269b8"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 52,
        "title": "optimize skip calculation logic to improve performance",
        "body": null,
        "issue_number": "52",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-09-13T08:28:24+00:00",
        "closed_at": "2024-09-13T11:17:03+00:00",
        "additions": 224,
        "deletions": 254,
        "changed_files": 3,
        "commits": [
            "ba54ddfcf98e8f4c6510d20f6f72f051455d15e8",
            "1bb68cd9df715f2fc4594c19ae9b05a12cad0dfc"
        ],
        "comment_by": [],
        "review_by": [
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing",
            "umiswing"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 58,
        "title": "add fa3",
        "body": null,
        "issue_number": "58",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-10-25T16:41:34+00:00",
        "closed_at": "2024-10-26T01:30:07+00:00",
        "additions": 9220,
        "deletions": 14,
        "changed_files": 30,
        "commits": [
            "9c239a8adad3802e5efcc8ae98efcc8a3da16c0e"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 59,
        "title": "add flag to skip compile",
        "body": null,
        "issue_number": "59",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-12-04T13:14:37+00:00",
        "closed_at": "2024-12-04T13:16:06+00:00",
        "additions": 165,
        "deletions": 155,
        "changed_files": 1,
        "commits": [
            "4abcef4da826b66f025741fa495673c4f09ad6db"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 56,
        "title": "[NVIDIA] bugfix, add missing header, cstdio",
        "body": "The macro C10_CUDA_CHECK calls fprintf, so it should includes cstdio but it doesn't.",
        "issue_number": "56",
        "state": "closed",
        "merged": true,
        "user": "jeng1220",
        "merged_by": "Xreki",
        "created_at": "2024-10-01T13:45:54+00:00",
        "closed_at": "2025-03-17T12:41:11+00:00",
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "commits": [
            "df2457ada040cb4d7c06f5b55275c497c48ab542"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 61,
        "title": "【dcu】support cutlass fa",
        "body": "support cutlass fa 内部已测试通过",
        "issue_number": "61",
        "state": "closed",
        "merged": true,
        "user": "lifulll",
        "merged_by": "sneaxiy",
        "created_at": "2025-02-28T02:38:44+00:00",
        "closed_at": "2025-03-01T13:21:37+00:00",
        "additions": 183,
        "deletions": 7,
        "changed_files": 2,
        "commits": [
            "edbc437a1dd291ee0f3202ed8eb4454e1caad490"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 57,
        "title": "Support densemask with causal.",
        "body": null,
        "issue_number": "57",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "sneaxiy",
        "created_at": "2024-10-14T12:52:43+00:00",
        "closed_at": "2024-10-14T13:02:20+00:00",
        "additions": 2,
        "deletions": 4,
        "changed_files": 3,
        "commits": [
            "64fa82383f1fa2988bcbce18aaec685085cf3d7e",
            "011363ed9047f26e733d69d8e7196c285e06c36e"
        ],
        "comment_by": [
            "CLAassistant"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 60,
        "title": "fix bug of FA2 densemask when casual=True",
        "body": null,
        "issue_number": "60",
        "state": "closed",
        "merged": true,
        "user": "GuoxiaWang",
        "merged_by": "sneaxiy",
        "created_at": "2024-12-06T08:52:41+00:00",
        "closed_at": "2024-12-06T09:02:41+00:00",
        "additions": 11,
        "deletions": 9,
        "changed_files": 2,
        "commits": [
            "f45b93ec45c453f169287f3a78393282f2fdbdd1"
        ],
        "comment_by": [
            "umiswing"
        ],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 63,
        "title": "support unpadded_lse",
        "body": null,
        "issue_number": "63",
        "state": "open",
        "merged": false,
        "user": "GuoxiaWang",
        "merged_by": null,
        "created_at": "2025-03-24T09:59:18+00:00",
        "closed_at": null,
        "additions": 63,
        "deletions": 31,
        "changed_files": 5,
        "commits": [
            "b0e8a12110c4aa95385670a0187fb962a5cd271d"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 64,
        "title": "Support hdimQK != hdimV backward",
        "body": "将torch flashattn库 pr1604进行迁移，来支持  headdim != headdim_v 的情况。\r\n\r\n# 精度压测\r\n1. 1600组测试中前向逐位对齐\r\n    1. 前向out是诸位对齐的\r\n    2. softmax_lse 的相对最大误差分别是：0, 0\r\n\r\n2. 保证反向paddle相较于torch 误差小于torch2次误差\r\n    1. q.grad 从对齐角度，存在不一致率，但对比两次torch的不一致率，只增加了一两个数量级，可以接受\r\n    2. q.grad 的误差基本和两次torch的误差齐平如图2,3\r\n    3. k.grad, v.grad  都没有误差（相比于torch）\r\n    \r\n<img width=\"771\" alt=\"image\" src=\"https://github.com/user-attachments/assets/37e4f549-fd62-4ffd-bb3b-a69c72be3df2\" />\r\n\r\n图1 \r\n\r\n<img width=\"785\" alt=\"image\" src=\"https://github.com/user-attachments/assets/60b52a87-4cd7-4436-9392-594f24efe504\" />\r\n\r\n图2\r\n\r\n<img width=\"798\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80345031-3bc4-4d4c-9607-86aa4ef01308\" />\r\n\r\n图3\r\n\r\n\r\n3. 不同shape组间误差接近\r\n    基本如是，见图2,3\r\n\r\n\r\n# 性能测试（经典shape）\r\n\r\n进行端到端性能测试新版paddle相比于torch基本持平\r\n\r\n   <meta charset=\"UTF-8\"><div class=\"mp-paragraph-wrapper hxj\" data-morpho-type=\"paragraph\" style=\"padding-left:0px;--indent-pixels:0px\" data-slate-node=\"element\" data-morpho-padding=\"0\"><span data-morpho-text=\"%E7%9B%B8%E6%AF%94%E4%BA%8E%E6%97%A7%E7%89%88paddle%20%E7%9C%81%E5%8E%BB%E4%BA%86%E4%B8%80%E6%AC%A1\">相比于旧版paddle 省去了一次</span><span data-morpho-text=\"ConcatTensorWithDifferentShape%20%20%E5%92%8C%20EigenMetaKernel\"><span data-raw-font-value=\"#1C1D1F\" style=\"color:#1C1D1F\"><span>ConcatTensorWithDifferentShape  和 EigenMetaKernel</span></span></span><div class=\"mp-paragraph-block-selection\"></div></div><div class=\"mp-table-align\"><div class=\"mp-table-wrapper\"><div data-slate-node=\"element\" style=\"padding-left:0px\" class=\"mp-table-container\">\r\n  | fw(us) | speedup(vs padding version) | bwd(us) | speedup(vs padding version) | 一次前反向的设备时间（us） | speedup (vs padding version)\r\n-- | -- | -- | -- | -- | -- | --\r\npaddle(new) | 958 | 1 x | 5039 | 1.1 x | 5997 | 1.09 x\r\npaddle | 954 | - | 5605 | - | 6559 | -\r\ntorch | 958 | - | 4997 | - | 5955 | -\r\n\r\n</div><div class=\"mp-table-serialize-flag\"><br/></div></div></div><span data-morpho-doc-data='{\"token\":\"eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIiwiYXBwSWQiOjEsInVpZCI6IjBYbGdTY1hrVmIiLCJkb2NJZCI6IlpvZGJaRHpEVVNKOTY5In0..trcVJWZdid1-EZ-Z.nnhDUTUlTJVbGzZSX1fHqhlWH_5OkxCMR0RXCHTqzl00OtShvDrNa1BCFBII2BkgGCN-UZQ60Yw8LhSYGWHB04aSlNgwC7oLgvBC26qv1zGdfR8zQWcl67nZPcd3pFYwmsxJDUgPVPRRmFktYc3mPaZFGjszZCb9TltRvwlrUWZWckqGUmCzZHCUkYQHBzro9Gz0uqve4tmV4rxE1YiR5zOvUw.EZL6q8dw-R10f_6_tghs1Q\",\"appId\":\"1\"}' class='mp-morpho-clipboard-doc-data'></span>",
        "issue_number": "64",
        "state": "closed",
        "merged": true,
        "user": "hxzd5568",
        "merged_by": "sneaxiy",
        "created_at": "2025-06-04T02:12:11+00:00",
        "closed_at": "2025-06-04T03:25:23+00:00",
        "additions": 85,
        "deletions": 51,
        "changed_files": 6,
        "commits": [
            "02fd280d49a2729d81555d78bb837b95ecda36b4"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 65,
        "title": "[WIP] fa3 varlen fix int32 overflow",
        "body": null,
        "issue_number": "65",
        "state": "open",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2025-06-19T12:15:03+00:00",
        "closed_at": null,
        "additions": 22,
        "deletions": 21,
        "changed_files": 5,
        "commits": [
            "3cd7c25ee18322e257fae26627b04bea8b73247f",
            "e74f69e8b61857bcbde84f6a8abcddbb9a52c591",
            "1ac962eb1d58744d1948a960c7ca2c8ea5675fae",
            "3a830f65c475d8c57a8d3eeb59db32134705c117",
            "37e944becc70ba29eec8786a504fe2722934e92f"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 62,
        "title": "Update flash attention 3",
        "body": "update flash attention 3 to https://github.com/Dao-AILab/flash-attention/commit/27f501dbe011f4371bff938fe7e09311ab3002fa",
        "issue_number": "62",
        "state": "closed",
        "merged": true,
        "user": "umiswing",
        "merged_by": "sneaxiy",
        "created_at": "2025-03-21T11:13:06+00:00",
        "closed_at": "2025-03-31T06:07:51+00:00",
        "additions": 11109,
        "deletions": 6972,
        "changed_files": 50,
        "commits": [
            "8cac698c417afd89172cfe53cc6617c998029071",
            "03f2a4a98d2843096f0a7f8d81478d9cb3abdb3d",
            "98732dde7ddef76d1780bbc0dae617029ca6bba0",
            "915e0683788e18658e014ad1d8ebc3265ccd0098",
            "ab286b2a2d9c472aaba39c8ff4853f0ef43fd20b",
            "ae60268568397965a89e1fe28a46933798505925",
            "472c7107cc28b70d8f128254516ce8003d1006d8"
        ],
        "comment_by": [],
        "review_by": [
            "umiswing",
            "umiswing"
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 66,
        "title": "[WIP] Fa3 varlen fix int32 overflow merge",
        "body": null,
        "issue_number": "66",
        "state": "closed",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2025-06-19T12:46:37+00:00",
        "closed_at": "2025-06-19T13:17:44+00:00",
        "additions": 22,
        "deletions": 21,
        "changed_files": 5,
        "commits": [
            "3cd7c25ee18322e257fae26627b04bea8b73247f",
            "e74f69e8b61857bcbde84f6a8abcddbb9a52c591",
            "1ac962eb1d58744d1948a960c7ca2c8ea5675fae",
            "3a830f65c475d8c57a8d3eeb59db32134705c117",
            "37e944becc70ba29eec8786a504fe2722934e92f"
        ],
        "comment_by": [],
        "review_by": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "number": 67,
        "title": "fix fa2 flashmask oob read",
        "body": null,
        "issue_number": "67",
        "state": "open",
        "merged": false,
        "user": "umiswing",
        "merged_by": null,
        "created_at": "2025-06-26T02:31:13+00:00",
        "closed_at": null,
        "additions": 6,
        "deletions": 5,
        "changed_files": 2,
        "commits": [
            "1a6af5188dae9e20e0bc1ec150fb3e7ea653d016"
        ],
        "comment_by": [],
        "review_by": []
    }
]