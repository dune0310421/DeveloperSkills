[
    {
        "repo": "PaddlePaddle/models",
        "number": 6,
        "title": "example configuration for nce_cost.",
        "body": "- In this example, we would like to show how to use NCE in PaddlePaddle, which is useful when training language model with a large vocabulary.\r\n\r\n- The example must include a training and a predicting process.\r\n\r\n- Please consider to use the following data for training and add these datasets into `paddle.dataset` package.\r\n    1. [1billionword-training](https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark), [1 billionword-test](https://github.com/tensorflow/models/tree/master/lm_1b) \r\n    2. [ptb](https://github.com/facebook/SCRNNs) \r\n\r\n- Note that the dataset is also used in [this task](https://github.com/PaddlePaddle/models/issues/3), please consider to share the data processing work.\r\n\r\n- Please pull your codes and docs into the [nce_cost](https://github.com/PaddlePaddle/models/tree/develop/nce_cost) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T10:04:42+00:00",
        "updated_at": "2017-06-08T11:29:49+00:00",
        "closed_at": "2017-06-08T11:29:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4,
        "title": "example configuration for LTR task.",
        "body": "In this example, we would like to show how to do LTR task in PaddlePaddle. Usually, there are three ways:\r\n1. pointwise (a simple regression/classification task, so we do not consider this situation in this example)\r\n2. pairwise, please refer to [this](https://github.com/lcy-seso/paddle_confs_v1/blob/master/ltr/pairwise_ltr.conf) configuration file written in old PaddlePaddleAPI.\r\n3. listwise, please refer to [this](https://github.com/lcy-seso/paddle_confs_v1/blob/master/ltr/listwise_ltr.conf) configuration file written in old PaddlePaddleAPI.\r\n\r\nThe example also must include *how to predict*. Note that in LTR task, training and testing network is different.\r\n\r\nI suggest to use [movielens](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/dataset/movielens.py) dataset.\r\n\r\nPlease pull your codes and docs into the [ltr](https://github.com/PaddlePaddle/models/tree/develop/ltr)  directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T09:51:51+00:00",
        "updated_at": "2017-05-24T10:36:38+00:00",
        "closed_at": "2017-05-24T10:36:38+00:00",
        "comments_count": [
            "dzhwinter"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3,
        "title": "example configuration for language model.",
        "body": "- In this example, we would like to show how to **train**:\r\n    1. a n-gram language model (please refer to [this](https://github.com/lcy-seso/paddle_confs_v1/blob/master/language_model/ngram_language_model.conf) configuration file written in old PaddlePaddle API）\r\n    2. a rnn/lstm language model  (please refer to [this](https://github.com/lcy-seso/paddle_confs_v1/blob/master/language_model/rnn_language_model.conf) configuration file written in old PaddlePaddle API)\r\n\r\n- Besides, we would like to show how to **generate sequence** from:\r\n    1. a N-gram language\r\n    2. a rnn language model\r\n\r\n- In the generation process, please consider the following two situations:\r\n    1. generate a sequence by using [paddle.infer](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/inference.py#L73) API, in which you need to implement one-way search or beam search (beam search is more complicated, I suggest to implement one-way search first.)\r\n    2. generate a sequence by using recurrent_layer_group\r\n\r\n- Please consider to use the following data for training and add these datasets into `paddle.dataset` package.\r\n    1. [1billionword-training](https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark), [1 billionword-test](https://github.com/tensorflow/models/tree/master/lm_1b) \r\n    2. [ptb](https://github.com/facebook/SCRNNs)\r\n\r\n- Please pull your codes and docs into the [language_model](https://github.com/PaddlePaddle/models/tree/develop/language_model) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T09:28:57+00:00",
        "updated_at": "2018-08-15T09:59:45+00:00",
        "closed_at": "2018-08-15T09:59:45+00:00",
        "comments_count": [
            "lcy-seso",
            "chengxiaohua1105",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 11,
        "title": "example configuration for scheduled_sampling.",
        "body": "- In this example, we would like to show how to use [scheduled sampling](https://arxiv.org/abs/1506.03099) for seq2seq task.\r\n\r\n- Please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/blob/master/scheduled_sampling/seq2seq_with_scheduled_sampling.conf) file written in old PaddlePaddle API.\r\n\r\n- The example must include the training and the generating process.\r\n\r\n- Please pull your codes and docs into the [scheduled_sampling](https://github.com/PaddlePaddle/models/tree/develop/scheduled_sampling) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T11:10:00+00:00",
        "updated_at": "2017-06-19T02:49:18+00:00",
        "closed_at": "2017-06-19T02:49:18+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 10,
        "title": "example configuration for regression.",
        "body": "- In this example, we would like to show how the do regression task in PaddlePaddle.\r\n\r\n- Please refer to [this configuration file](https://github.com/lcy-seso/paddle_confs_v1/blob/master/regression/regression.conf) written in old PaddlePaddle API.\r\n\r\n- Note that, currently PaddlePaddle provides two regression costs: mse and [huber loss](http://www.paddlepaddle.org/develop/doc/api/v2/config/layer.html#huber-cost). Please consider adding an example for huber loss.\r\n\r\n- Please pull your codes and docs into the [regressoin](https://github.com/PaddlePaddle/models/tree/develop/regression) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T11:05:24+00:00",
        "updated_at": "2018-08-15T09:59:32+00:00",
        "closed_at": "2018-08-15T09:59:32+00:00",
        "comments_count": [
            "chrisxu2016",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 9,
        "title": "example configuration for ntm_addressing_mechanism.",
        "body": "- In this example, we would like to show how the three addressing mechanism in [NTM](https://arxiv.org/abs/1410.5401).\r\n\r\n- Please refer to this configuration file written in old PaddlePaddle API.\r\n\r\n- The example must include the training and the generating process.\r\n\r\n- Please pull your codes and docs into the [ntm_addressing_mechanism](https://github.com/PaddlePaddle/models/tree/develop/ntm_addressing_mechanism) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T10:47:49+00:00",
        "updated_at": "2018-08-15T09:59:35+00:00",
        "closed_at": "2018-08-15T09:59:35+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5,
        "title": "example configuration for neural machine translation with external memory.",
        "body": "- the idea of external memory originates from [NTM](https://arxiv.org/abs/1410.5401).\r\n\r\n- In this example, we would like to show how to add external memory to a NMT model. Please refer to [this](https://github.com/lcy-seso/paddle_confs_v1/tree/master/mt_with_external_memory) configuration file written in old PaddlePaddle API.\r\n\r\n- The example must include the training and generating process.\r\n- Please directly use the [wmt14 dataset](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/dataset/wmt14.py).\r\n- Please pull your codes and doc to the [mt_with_external_memory](https://github.com/PaddlePaddle/models/tree/develop/mt_with_external_memory) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T09:59:03+00:00",
        "updated_at": "2017-09-13T08:48:18+00:00",
        "closed_at": "2017-09-13T08:48:18+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 7,
        "title": "example configuration for nested sequence.",
        "body": "- In this example, we would like to show how to use nested sequence, which is one of the most amazing things in PaddlePaddle.\r\n\r\n- We would like to show how to use the nested sequence in the following task:\r\n    1. text classification, please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/blob/master/nested_sequence/nested_cnn_text_classification.conf) written in old PaddlePaddle API.\r\n    2. text generation, please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/blob/master/nested_sequence/nested_seq_for_text_generateion.conf) written in old PaddlePaddle API. The example must include the training and the generating process.\r\n\r\n- About dataset:\r\n    1. for the text classification task, please directly use the **[imdb](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/dataset/imdb.py)** dataset.\r\n    2. for the text generation task, you have to give some example training dataset.\r\n\r\n- Please pull your codes and docs into the nested_sequence directory.\r\n\r\n",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T10:13:10+00:00",
        "updated_at": "2018-08-15T09:59:40+00:00",
        "closed_at": "2018-08-15T09:59:40+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "luotao1",
            "wanghaoshuang",
            "luotao1",
            "wanghaoshuang",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1,
        "title": "Basic Requirements on examples added into this repo.",
        "body": "# Goals\r\nGoals of example configuration files are twofold:\r\n1. Example configuration file is a kind of documentations to some extent, which shows how to use layers/pre-defined small networks in PaddlePaddle through examples. It is expected to be more lightweight than PaddleBook.\r\n  \r\n2. Backup of configuration files for newly developed layers/modules. Every time, if anyone adds a new layer into PaddlePaddle, or add a new pre-defined network into the paddle python package, he must have written a test configuration file. This test configuration file is also a good example to show how to use his new layer/network for other users.\r\n\r\n# Basic Requirements\r\n\r\n1. Each example has its own directory, and (optional) some complicated examples may have sub-directory.\r\n2.  Each example should have at least two files\r\n    - the model configuration, which includes the definition of the network topology, the optimization algorithm, the PaddlePaddle trainer, and how to read the data.\r\n    - a README doc.\r\n3. Each example should be tested without bugs.\r\n\r\n# About training/testing data\r\n-  always consider using dataset in paddle.dataset package first.\r\n-  If there is no appropriate dataset in paddle.dataset package, give a description of the format of the input data\r\n\r\n# Requirements on the README doc\r\n- The REAMDE doc should have at least the following two sections:\r\n    1. **Brief introduction**. The introduction should include:\r\n           - what task does the configuration file for?\r\n           - If the example does not provide data for training, it should provide descriptions about the format of the training data, and give an example to at least one training data.\r\n    2. **Explanation about the model architecture**.  A picture to show the model architecture, or refer to a certain reference. Chose a convenient way to make some explanations about the model architecture to let other know about why do you write the example and what the example wants to explain. \r\n    3. [**optional**] How to run, but try to provide such an explanation as much as possible.   ",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T02:52:04+00:00",
        "updated_at": "2018-08-15T09:59:52+00:00",
        "closed_at": "2018-08-15T09:59:52+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 12,
        "title": "example configuration for seq2seq.",
        "body": "- In this example, we would like to show some different configuration for seq2seq task.\r\n- Please refer to the following two configuration files:\r\n    1. [grid lstm](https://github.com/lcy-seso/paddle_confs_v1/blob/master/seq2seq/grid_lstm.conf) written in old PaddlePaddle API.\r\n    2. [encoder-decoder without attention](https://github.com/lcy-seso/paddle_confs_v1/blob/master/seq2seq/nmt_without_attention.conf) written in old PaddlePaddle API.\r\n- The example **must** include the training and the generating process.\r\n- Please pull your codes and docs into the [seq2seq](https://github.com/PaddlePaddle/models/tree/develop/seq2seq) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-04-21T11:17:45+00:00",
        "updated_at": "2018-08-15T09:59:27+00:00",
        "closed_at": "2018-08-15T09:59:27+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 14,
        "title": "example configuration for text classification.",
        "body": "- In this example, we would like to show how to do text classification task in PaddlePaddle.\r\n- We provide a DNN network and a CNN network for texe classification\r\n    1. for DNN network, please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/blob/master/text_classification/dnn_text_classification.conf) file written in old PaddlePaddle API.\r\n    2. for CNN network, please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/blob/master/text_classification/cnn_text_classification.conf) file written in old PaddlePaddle API.\r\n- The example **must** include the training and the predicting process.\r\n- Please pull your codes and docs into the [text_classification](https://github.com/PaddlePaddle/models/tree/develop/text_classification) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "luotao1",
        "created_at": "2017-04-21T11:29:01+00:00",
        "updated_at": "2017-05-17T05:02:09+00:00",
        "closed_at": "2017-05-17T05:02:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 13,
        "title": "example configuration for NER.",
        "body": "- In this example, we would like to show how to do sequence tagging task in PaddlePaddle. We take NER as an example.\r\n- Please refer to [this configuration](https://github.com/lcy-seso/paddle_confs_v1/tree/master/sequence_tagging_for_ner) file written in old PaddlePaddle API.\r\n- The example **must** include the training and the decoding process.\r\n- Please pull your codes and docs into the [sequence_tagging_for_ner](https://github.com/lcy-seso/paddle_confs_v1/blob/master/sequence_tagging_for_ner/ner.conf) directory.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T11:24:03+00:00",
        "updated_at": "2017-05-24T11:39:52+00:00",
        "closed_at": "2017-05-24T11:39:52+00:00",
        "comments_count": [
            "guoshengCS",
            "lcy-seso",
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 21,
        "title": "Add example nmt_without_attention for seq2seq demo",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "lcy-seso",
        "created_at": "2017-05-03T06:35:09+00:00",
        "updated_at": "2017-05-24T08:00:13+00:00",
        "closed_at": "2017-05-24T08:00:13+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 15,
        "title": "example configuration for word embedding.",
        "body": "- In this example, we would like to show how to use **hsigmoid** to training word embedding for large vocabulary.\r\n- Please refer to this [example](https://gist.github.com/reyoung/21ecaa4c7bca9943352a40d0ce59f9bc) provided by @reyoung. Note that this example is not for word embedding training exactly. You‘d better learn and then modify it.\r\n- The example must include the training and the predicting process.\r\n- Please pull your codes and docs into the [word_embedding](https://github.com/PaddlePaddle/models/tree/develop/word_embedding) directory.\r\n\r\n- In future, we may add more configuration for models with a large vocabulary.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-04-21T11:35:29+00:00",
        "updated_at": "2017-05-25T01:45:44+00:00",
        "closed_at": "2017-05-25T01:45:44+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 18,
        "title": "Add basic network configuration and training script for word embedding task",
        "body": "@lcy-seso \r\nDon't understand how to add prediction logic in the task.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "luotao1",
        "created_at": "2017-05-02T13:52:26+00:00",
        "updated_at": "2017-05-11T14:08:25+00:00",
        "closed_at": "2017-05-11T14:08:25+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 26,
        "title": "Need new tutorial， about how to use the models",
        "body": "Maybe\r\n- how to setup paddle\r\n- how to clone models\r\n- how to input data\r\n- how to train model（k8s & mpi）\r\n- how to select a model\r\n- how to forecast this model use API (C API & Python API & more)",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-05-05T12:05:00+00:00",
        "updated_at": "2018-08-15T10:11:53+00:00",
        "closed_at": "2018-08-15T10:11:53+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 25,
        "title": "Inferece error occurs in language model.",
        "body": "A part of model code:\r\n\r\n```\r\n\r\nfirstword = paddle.layer.data(\r\n    name=\"firstw\", type=paddle.data_type.integer_value(dict_size))\r\nsecondword = paddle.layer.data(\r\n    name=\"secondw\", type=paddle.data_type.integer_value(dict_size))\r\nthirdword = paddle.layer.data(\r\n    name=\"thirdw\", type=paddle.data_type.integer_value(dict_size))\r\nfourthword = paddle.layer.data(\r\n    name=\"fourthw\", type=paddle.data_type.integer_value(dict_size))\r\nnextword = paddle.layer.data(\r\n    name=\"fifthw\", type=paddle.data_type.integer_value(dict_size))\r\n\r\nEfirst = wordemb(firstword)\r\nEsecond = wordemb(secondword)\r\nEthird = wordemb(thirdword)\r\nEfourth = wordemb(fourthword)\r\n\r\n\r\ncontextemb = paddle.layer.concat(input=[Efirst, Esecond, Ethird, Efourth])\r\n\r\nhidden1 = paddle.layer.fc(input=contextemb,\r\n                          size=hiddensize,\r\n                          act=paddle.activation.Sigmoid(),\r\n                          layer_attr=paddle.attr.Extra(drop_rate=0.5),\r\n                          bias_attr=paddle.attr.Param(learning_rate=1),\r\n                          param_attr=paddle.attr.Param(\r\n                                initial_std=1. / math.sqrt(embsize * 8),\r\n                                learning_rate=1))\r\n\r\n\r\npredictword = paddle.layer.fc(input=hidden1,\r\n                              size=dict_size,\r\n                              bias_attr=paddle.attr.Param(learning_rate=1),\r\n                              act=paddle.activation.Softmax())\r\n\r\n\r\n```\r\n\r\nThe part of inference code:\r\n\r\n```\r\nembsize = 32 \r\nhiddensize = 256 \r\nN = 5\r\n\r\ndef main():\r\n    paddle.init(use_gpu=False, trainer_count=3) \r\n    word_dict = paddle.dataset.imikolov.build_dict()\r\n    dict_size = len(word_dict)\r\n\r\n    _, prediction, _= nnlm(hiddensize, embsize, dict_size)\r\n\r\n    #with gzip.open(\"model_params.tar.gz\", 'r') as f:\r\n    #   parameters.from_tar(f)\r\n    parameters = paddle.parameters.Parameters.from_tar(gzip.open(\"model_params.tar.gz\", 'r'))\r\n\r\n    infer_data = []\r\n    infer_label_data = []\r\n    cnt = 0\r\n    for item in paddle.dataset.imikolov.test(word_dict, N)():\r\n        infer_data.append((item[:4]))\r\n        infer_label_data.append(item[4])\r\n        cnt += 1\r\n        if cnt == 100:\r\n            break\r\n\r\n    predictions = paddle.infer(\r\n        output_layer = prediction,\r\n        parameters = parameters,\r\n        input = infer_data\r\n    )\r\n\r\n    for i, prob in enumerate(predictions):\r\n        print prob, infer_label_data[i]\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n    \r\n```\r\n\r\n10 elements ahead of item[:4]:\r\n\r\n```\r\n[(2, 1063, 95, 353), (1063, 95, 353, 5), (95, 353, 5, 335), (353, 5, 335, 51), (5, 335, 51, 2072), (335, 51, 2072, 6), (51, 2072, 6, 319), (2072, 6, 319, 2072), (6, 319, 20, 5), (319, 2072, 5, 0)]\r\n```\r\n\r\n",
        "state": "closed",
        "user": "pakchoi",
        "closed_by": "pakchoi",
        "created_at": "2017-05-04T08:50:17+00:00",
        "updated_at": "2017-05-10T09:48:00+00:00",
        "closed_at": "2017-05-10T09:47:59+00:00",
        "comments_count": [
            "pakchoi",
            "lcy-seso",
            "pakchoi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 27,
        "title": "Provide a general tool for converting Caffe models.",
        "body": "- 1. A general tool `caffe2paddle.py` which can be used to convert most of Caffe's model.\r\n- 2. Verification method to verify that the accuracy of converted model is correct. \r\n- 3. Usage document.\r\n- 4. Provide a ResNet model based on ImageNet.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "guoshengCS",
        "created_at": "2017-05-08T06:41:29+00:00",
        "updated_at": "2017-06-12T07:05:06+00:00",
        "closed_at": "2017-06-12T07:05:06+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 47,
        "title": "Add a CTR example",
        "body": "We are now working on a CTR model trained by PaddlePaddle.\r\n\r\nThe model structure mainly follows the paper [Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792).",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "Superjomn",
        "created_at": "2017-05-23T02:05:43+00:00",
        "updated_at": "2017-06-02T07:56:39+00:00",
        "closed_at": "2017-06-02T07:56:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 28,
        "title": "Example configuration for image classification.",
        "body": "In this example, we would like to show how to do image classification task in PaddlePaddle. We need to provide several classic configuration, AlexNet, VGG, GoogleNet, ResNet. It's betther to provide GoogleNet-v3/v4, [identity-mapping-ResNet](https://arxiv.org/abs/1603.05027), but it doesn't matter if they are not provided in the first version.\r\n\r\nReference configuration:\r\n\r\n- v1 of AlexNet: https://github.com/PaddlePaddle/Paddle/blob/develop/benchmark/paddle/image/alexnet.py\r\n- VGG: https://github.com/PaddlePaddle/book/blob/develop/03.image_classification/vgg.py\r\n- v1 of GoogleNet: https://github.com/PaddlePaddle/Paddle/blob/develop/benchmark/paddle/image/googlenet.py\r\n- ResNet: https://github.com/PaddlePaddle/book/blob/develop/03.image_classification/resnet.py\r\n\r\nDataSet:\r\n- ImageNet\r\n- Oxford-flowers: http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "lcy-seso",
        "created_at": "2017-05-08T07:08:28+00:00",
        "updated_at": "2017-06-15T08:14:13+00:00",
        "closed_at": "2017-06-15T08:14:13+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 33,
        "title": "Summary of Bugs of V2 APIs",
        "body": "- [x] Nested sequence is problematic in V2 https://github.com/PaddlePaddle/Paddle/issues/2065\r\n- [x] Incorrect topological parsing with memory-layer https://github.com/PaddlePaddle/Paddle/issues/2061\r\n- [ ] No check for static parameters. https://github.com/PaddlePaddle/Paddle/issues/2069\r\n- [x] Some global parameters crucial for learning performance are not properly set https://github.com/PaddlePaddle/Paddle/issues/2042\r\n- [x] Clipping can not work that makes training RNN model unstable https://github.com/PaddlePaddle/Paddle/issues/1894 https://github.com/PaddlePaddle/Paddle/issues/1961\r\n- [x] Inference in V2 is slower than the old API https://github.com/PaddlePaddle/Paddle/issues/1961\r\n- [ ] size and num_filters cannot be obtained in V2 APIs. https://github.com/PaddlePaddle/Paddle/issues/1811\r\n\r\nNot supported\r\n- [x] Multiplex Layer for scheduled sampling is not supported in v2. \r\n- [ ] Subsequence Layer https://github.com/PaddlePaddle/Paddle/issues/2026\r\n- [x] Some element-wise computation https://github.com/PaddlePaddle/Paddle/issues/1790\r\n- [ ] C-API not ready for V2 https://github.com/PaddlePaddle/Paddle/issues/1949",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-05-09T03:39:03+00:00",
        "updated_at": "2018-08-15T10:11:50+00:00",
        "closed_at": "2018-08-15T10:11:50+00:00",
        "comments_count": [
            "QiJune",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 35,
        "title": "huber_cost  is running incorrectly, connect to  issue #10",
        "body": "@lcy-seso huber_cost is used error ,connect to issue[ #10 ](https://github.com/PaddlePaddle/models/issues/10)\r\n\r\n##example\r\n>\r\nimport paddle.v2 as paddle\r\nimport paddle.v2.dataset.uci_housing as uci_housing\r\n\r\ndef main():\r\n    # init\r\n    paddle.init(use_gpu=False, trainer_count=1)\r\n\r\n    # network config\r\n    x = paddle.layer.data(\r\n        name='x',\r\n        type=paddle.data_type.dense_vector(13))\r\n\r\n    y_predict = paddle.layer.fc(\r\n        input=x,\r\n        size=1,\r\n        act=paddle.activation.Linear())\r\n\r\n    y = paddle.layer.data(\r\n        name='y',\r\n        type=paddle.data_type.dense_vector(1))\r\n    \r\n    cost = paddle.layer.huber_cost(input=y_predict, label=y)\r\n\r\n    # create parameters\r\n    parameters = paddle.parameters.create(cost)\r\n\r\n    # create optimizer\r\n    optimizer = paddle.optimizer.Momentum(momentum=0)\r\n\r\n    trainer = paddle.trainer.SGD(\r\n        cost=cost, parameters=parameters, update_equation=optimizer)\r\n\r\n    feeding = {'x': 0, 'y': 1}\r\n\r\n    # event_handler to print training and testing info\r\n    def event_handler(event):\r\n        if isinstance(event, paddle.event.EndIteration):\r\n            if event.batch_id % 100 == 0:\r\n                print \"Pass %d, Batch %d, Cost %f\" % (\r\n                    event.pass_id, event.batch_id, event.cost)\r\n\r\n        if isinstance(event, paddle.event.EndPass):\r\n            result = trainer.test(\r\n                reader=paddle.batch(uci_housing.test(), batch_size=2),\r\n                feeding=feeding)\r\n            print \"Test %d, Cost %f\" % (event.pass_id, result.cost)\r\n\r\n    # training\r\n    trainer.train(\r\n        reader=paddle.batch(\r\n            paddle.reader.shuffle(uci_housing.train(), buf_size=500),\r\n            batch_size=2),\r\n        feeding=feeding,\r\n        event_handler=event_handler,\r\n        num_passes=30)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n\r\n## Failuer infomation\r\n![image](https://cloud.githubusercontent.com/assets/18379485/25836012/e6224c64-34b5-11e7-8a94-b0f3b0fbc49b.png)\r\n\r\n",
        "state": "closed",
        "user": "chrisxu2016",
        "closed_by": "shanyi15",
        "created_at": "2017-05-09T04:49:36+00:00",
        "updated_at": "2018-08-15T10:11:46+00:00",
        "closed_at": "2018-08-15T10:11:46+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 44,
        "title": "Deep Speech 2 on PaddlePaddle: Plan & Task Breakdown",
        "body": "We are planning to build Deep Speech 2 (DS2) \\[[1](#references)\\], a powerful Automatic Speech Recognition (ASR) engine,  on PaddlePaddle. For the first-stage plan, we have the following short-term goals:\r\n\r\n- Release a basic distributed implementation of DS2 on PaddlePaddle.\r\n- Contribute a chapter of Deep Speech to PaddlePaddle Book.\r\n\r\nIntensive system optimization and low-latency inference library (details in \\[[1](#references)\\]) are not yet covered in this first-stage plan.\r\n\r\n\r\n## Tasks\r\n\r\nWe roughly break down the project into 14 tasks:\r\n\r\n1. Develop an **audio data provider**:\r\n    - Json filelist generator\r\n    - Audio file format transformer.\r\n    - Spectrogram feature extraction, power normalization etc.\r\n    - Batch data reader with SortaGrad.\r\n    - Data augmentation (optional).\r\n    - Prepare (one or more) public English data sets & baseline.\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2226\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2227\r\n2. Create a **simplified DS2 model configuration**:\r\n    - With only fixed-length (by padding) audio sequences (otherwise need *Task 3*).\r\n    - With only bidirectional-GRU (otherwise need *Task 4*).\r\n    - With only greedy decoder (otherwise need *Task 5, 6*).\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2231\r\n3. Develop to support **variable-shaped** dense-vector (image) batches of input data.\r\n    - Update `DenseScanner` in `dataprovider_converter.py`, etc.\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2198\r\n4. Develop a new **lookahead-row-convolution layer** (See \\[[1](#references)\\] for details):\r\n    - Lookahead convolution windows.\r\n    - Within-row convolution, without kernels shared across rows.\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2228\r\n5. Build KenLM n-gram **language model** for beam search decoding:\r\n    - Use KenLM toolkit, Kneser-Ney smoothed, 5-gram, with pruning etc.\r\n    - Prepare the corpus & train the model.\r\n    - Create infererence interfaces plugable to CTC beam search (for Task 6).\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2229\r\n6. Develop a **beam search decoder** with CTC + LM + WORDCOUNT:\r\n    - Beam search with CTC.\r\n    - Beam search with external custom scorer (e.g. LM).\r\n    - Try to design a more general beam search interface.\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2230\r\n7. Develop a **Word Error Rate evaluator**:\r\n    - update `ctc_error_evaluator`(CER) to support WER.\r\n8. Prepare internal dataset for Mandarin (optional):\r\n    - Dataset, baseline, evaluation details.\r\n    - Particular data preprocessing for Mandarin.\r\n    - Might need cooperating with the Department of Speech.\r\n    - https://github.com/PaddlePaddle/Paddle/issues/2232\r\n9. Create **standard DS2 model configuration**:\r\n    - With variable-length audio sequences (need *Task 3*).\r\n\t- With unidirectional-GRU + row-convolution (need *Task 4*).\r\n\t- With CTC-LM beam search decoder (need *Task 5, 6*).\r\n10. Make it run perfectly on **clusters**.\r\n11. Experiments and **benchmarking** (for accuracy, not efficiency):\r\n    - With public English dataset.\r\n    - With internal (Baidu) Mandarin dataset (optional).\r\n12. Time **profiling** and optimization.\r\n13. Prepare **docs**.\r\n14. Prepare PaddlePaddle **Book** chapter with a simplified version.\r\n\r\n\r\n\r\n## Task Dependency\r\n\r\nTasks parallelizable within phases:\r\n\r\nRoadmap  | Description | Parallelizable Tasks\r\n------------- | :------------- | :------\r\nPhase I\t    | Basic model & components | *Task 1* ~ *Task 8*\r\nPhase II  | Standard model & benchmarking & profiling | *Task 9* ~ *Task 12*\r\nPhase III | Documentations | *Task13* ~ *Task14*\r\n\r\n\r\nIssue for each task will be created later. Contributions, discussions and comments are all highly appreciated and welcomed!\r\n\r\n## Possible Future Work\r\n\r\n- Efficiency Improvement\r\n- Accuracy Improvement\r\n- Low-latency Inference Library\r\n- Large-scale benchmarking\r\n\r\n\r\n## References\r\n\r\n1. Dario Amodei, etc., [Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin](http://proceedings.mlr.press/v48/amodei16.pdf). ICML 2016.\r\n\r\n",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "shanyi15",
        "created_at": "2017-05-17T16:32:22+00:00",
        "updated_at": "2018-08-15T10:11:42+00:00",
        "closed_at": "2018-08-15T10:11:42+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 51,
        "title": "how to run the model?",
        "body": "how to \r\n- install PaddlePaddle\r\n- run the model\r\n- custom data\r\n- run the model in PaddlePaddle Cloud",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-05-24T09:23:54+00:00",
        "updated_at": "2018-08-15T10:16:48+00:00",
        "closed_at": "2018-08-15T10:16:48+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 64,
        "title": "Please fix this typo",
        "body": "I don't have permission to revise it.\r\n\r\n<img width=\"972\" alt=\"2eeb7a4593b97ba8d414270b456d8d7a\" src=\"https://cloud.githubusercontent.com/assets/3071933/26715083/d7738bca-47a6-11e7-97f9-b8515dae66c3.png\">\r\n",
        "state": "closed",
        "user": "gangliao",
        "closed_by": "lcy-seso",
        "created_at": "2017-06-02T07:19:44+00:00",
        "updated_at": "2017-06-02T08:42:36+00:00",
        "closed_at": "2017-06-02T08:42:36+00:00",
        "comments_count": [
            "JiayiFeng",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 65,
        "title": "Add a  GAN example.",
        "body": "GAN is one of some of the old examples that haven't merged into PaddlePaddle yet. Here is the original pull request: https://github.com/PaddlePaddle/book/pull/30. We are going to merge it into PaddlePaddle first.\r\n\r\nGAN will be a good example to enhance PaddlePaddle's control flow of sub-graphs in the entire network during training.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-06-02T07:28:17+00:00",
        "updated_at": "2018-08-15T10:16:45+00:00",
        "closed_at": "2018-08-15T10:16:45+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 73,
        "title": "train lm_rnn, Check failed: numUpdates_ > prevNumUpdate_(0 vs.0)",
        "body": "F0606  AverageOptimizer.h:76    Check failed: numUpdates_ > prevNumUpdate_(0 vs.0)\r\nFYI image\r\n<img width=\"883\" alt=\"4fef683c51092f4507011031c\" src=\"https://cloud.githubusercontent.com/assets/1908992/26829410/1a6e1158-4af8-11e7-9623-90d89417884e.png\">\r\n\r\n\r\nfix:\r\nadd parameter `max_average_window=10000`\r\n\r\n> model_average=paddle.optimizer.ModelAverage(average_window=0.5, max_ average_window=10000)",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-06-06T12:42:42+00:00",
        "updated_at": "2017-06-28T04:54:22+00:00",
        "closed_at": "2017-06-06T12:43:24+00:00",
        "comments_count": [
            "llxxxll"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 77,
        "title": "Refine librispeech.py for DeepSpeech2",
        "body": "1. Add manifest line check.\r\n2. Avoid re-unpacking if unpacked data already exists.\r\n3. Add full_download (download all 7 sub-datasets of LibriSpeech).",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-07T09:39:47+00:00",
        "updated_at": "2017-06-09T03:52:11+00:00",
        "closed_at": "2017-06-09T03:52:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 87,
        "title": "Add unittest for ci",
        "body": "There are several new python modules added in deep speech project. These modules should be tested before merging. Since some scripts need PaddlePaddle running environment, so I expand the ```.travis.yml``` to support docker. There are several rules when writing unit test scripts.\r\n1. all unit test scripts should be placed into **tests** directory.\r\n2. all unit test scripts should be named like ```test*.py```.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "gangliao",
        "created_at": "2017-06-13T10:29:40+00:00",
        "updated_at": "2017-06-14T06:37:19+00:00",
        "closed_at": "2017-06-14T06:37:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 75,
        "title": "Support variable input batch and SortaGrad for deep speech2.",
        "body": "",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-07T08:50:34+00:00",
        "updated_at": "2017-06-12T12:31:38+00:00",
        "closed_at": "2017-06-12T12:31:38+00:00",
        "comments_count": [
            "qingqing01",
            "xinghai-sun",
            "qingqing01",
            "xinghai-sun",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 79,
        "title": "Add loading model function for train.py",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-07T10:53:57+00:00",
        "updated_at": "2017-06-08T06:08:26+00:00",
        "closed_at": "2017-06-08T06:08:26+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 81,
        "title": "Add WER and CER evaluation script.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-06-08T06:05:12+00:00",
        "updated_at": "2017-06-19T03:38:38+00:00",
        "closed_at": "2017-06-19T03:38:38+00:00",
        "comments_count": [
            "pkuyym",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 92,
        "title": "Add post processing for decoder",
        "body": "If training texts are end of white space, sentences generated by decoder should be end of white space too. In such situation, we need a post processing logic to re-calculate a LM score after replacing white space by end token.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-06-14T08:02:02+00:00",
        "updated_at": "2017-07-06T04:54:17+00:00",
        "closed_at": "2017-07-06T04:54:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 90,
        "title": "Refactor the whole data preprocessor part for DeepSpeech2.",
        "body": "  Refactor the whole data preprocessor for DeepSpeech2 (e.g. re-design classes, re-organize dir, add augmentation interfaces etc.):\r\n\r\n- [x] Refactor the data preprocessor with newly added classes, e.g. `AudioSegment`, `SpeechSegment`, `TextFeaturizer`, `AudioFeaturizer`, `SpeechFeaturizer` etc. \r\n- [x] Add data augmentation interfaces and classes e.g. `AugmentorBase`, `AugmentationPipeline`, `VolumePerturbAugmentor` etc., to make it easier to add more data augmentation models.\r\n- [x] Separate normalizer's mean-std computing from `DataGenerator`. Add `FeatureNormalizer`. -\r\n- [x] Add an independent tool `compute_mean_std.py` for users to create mean_std file before training.\r\n- [x] Re-organize `data` directory into `datasets` and `data_utils`.\r\n- [x] Test for convergence.\r\n- [x] Add module, class, function docs.\r\n- [x] Update README.md.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-13T15:48:17+00:00",
        "updated_at": "2017-06-14T06:49:10+00:00",
        "closed_at": "2017-06-14T06:49:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 89,
        "title": "models code &document Cannot find in PaddlePaddle Documents",
        "body": "models code &document Cannot find in PaddlePaddle Documents",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-06-13T13:21:37+00:00",
        "updated_at": "2018-08-15T10:16:40+00:00",
        "closed_at": "2018-08-15T10:16:40+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 95,
        "title": "The numerical stability in ctc beam search decoder",
        "body": "The computation of probabilities in CTC beam search involves the addition and multiplication of very small numbers. To make sure the numerical stability, many other implementations first convert the  probabilities into log format, then execute the operation. \r\n\r\nIn the Deep Speech 2 project, we implement two versions of beam search decoder, computing probability in the original and log form respectively. Currently, we use the the former for which is found to have a bit benefit in efficiency. But we also care about the numerical stability, so we have an [independent test](https://github.com/kuke/ctc_beam_search_decoder_num_test) to compare the two decoders with the ctc beam search decoder in TensorFlow.\r\n\r\nRun ```test_ctc_beam_search_decoder.py```, the outputs look like\r\n<img width=\"1025\" alt=\"2017-06-15 9 37 50\" src=\"https://user-images.githubusercontent.com/3064195/27163465-29084e04-51ba-11e7-946a-9ed65c666eb7.png\">\r\n\r\nWhen the length of input probability list is limited to several hundreds, the two decoders get almost the same scores and decoding results. Hence we believe that the numerical stability may be not a problem in the decoder right now, but we will be careful about it all the way.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2017-06-14T16:49:37+00:00",
        "updated_at": "2018-08-15T10:16:37+00:00",
        "closed_at": "2018-08-15T10:16:37+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 96,
        "title": "add data argumentation part for DeepSpeech2",
        "body": "add data augmentation part for DeepSpeech2(inclued noise_speech, impuls_response eg)\r\n- [x] add data augmentation class ,inclued `noise_speech`, `impuls_response`, `resampler`, `speed_perturb`, `online_bayesias_normalization`.\r\n- [x] add function to audio.py, eg. `convolve`， `add_noise`, `normalizer` \r\n- [ ] add noise data preprocess script",
        "state": "closed",
        "user": "chrisxu2016",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-14T18:51:56+00:00",
        "updated_at": "2017-06-19T07:30:05+00:00",
        "closed_at": "2017-06-19T07:30:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 105,
        "title": "Fix ci",
        "body": "Currently, dependencies installation is always failed in CI, since some complex requirements is lack of well tested installing process. I try to settle this problem by following the below solutions:\r\n1.  Unify the dependency installation process in setup.sh.\r\n2. Change the version of package scipy from 0.13.0b1 to 0.13.1 ",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-06-19T15:23:52+00:00",
        "updated_at": "2017-06-20T02:09:04+00:00",
        "closed_at": "2017-06-20T02:09:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 107,
        "title": "add data augmentor class",
        "body": "1.add data augmentor class  for DeepSpeech2(inclued speed_change, resample, online bayesias_noline)\r\n\r\n2.NosieAugmentor and ImpulseResaponseAugmentor will be added later",
        "state": "closed",
        "user": "chrisxu2016",
        "closed_by": "chrisxu2016",
        "created_at": "2017-06-20T08:28:35+00:00",
        "updated_at": "2017-06-27T12:15:37+00:00",
        "closed_at": "2017-06-27T12:15:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 110,
        "title": "Add multi-threading support for DS2 data generator.",
        "body": "Add multi-threading support for DS2 data generator, to accelerate the training.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-20T09:09:39+00:00",
        "updated_at": "2017-06-20T10:19:22+00:00",
        "closed_at": "2017-06-20T10:19:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 113,
        "title": "Improve audio featurizer and add shift augmentor for DS2.",
        "body": " Improve audio featurizer by adding e.g. resampling, db_normalization, and random shift, as suggested in speech_dl codes.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-06-21T12:58:57+00:00",
        "updated_at": "2017-06-26T06:24:04+00:00",
        "closed_at": "2017-06-26T06:24:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 100,
        "title": "Abnormal learning curve bumping at early batches of each epoch during DS2 training.",
        "body": "After merging PR #74, we have seen such abnormal learning curve:\r\n\r\n<img width=\"500\" alt=\"7eb432e75966334978e6adb2b\" src=\"https://user-images.githubusercontent.com/7038341/27165435-7dcfe1a2-51c6-11e7-8b18-5660da44183a.png\">\r\n\r\nThe figure plots the training cost. Notice that in the tails of the curve, there are many spikes, exactly locating at the first batch of each epoch. \r\n\r\nBesides, it is not easy to reproduce the phenomenon in a small dataset.\r\n\r\n",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "shanyi15",
        "created_at": "2017-06-15T04:39:49+00:00",
        "updated_at": "2018-08-15T10:16:30+00:00",
        "closed_at": "2018-08-15T10:16:30+00:00",
        "comments_count": [
            "xinghai-sun",
            "qingqing01",
            "xinghai-sun",
            "xinghai-sun",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 109,
        "title": "train language model Segmentation fault",
        "body": "```\r\npython train.py \r\nprepare vocab...\r\nSegmentation fault\r\n```\r\ntrain.txt 1.8GB - chinese UTF-8 Unicode text\r\n\r\ncat /proc/meminfo |grep MemTotal\r\nMemTotal:        4048124 kB",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-06-20T09:08:09+00:00",
        "updated_at": "2017-06-21T07:21:09+00:00",
        "closed_at": "2017-06-21T07:21:09+00:00",
        "comments_count": [
            "llxxxll",
            "wanghaoshuang",
            "llxxxll",
            "wanghaoshuang",
            "llxxxll",
            "llxxxll"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 115,
        "title": "Pruning speedups beam search",
        "body": "The ctc beam search in DS2, or [prefix beam search](https://arxiv.org/abs/1408.2873) consists of appending candidate characters to prefixes and repeatedly looking up the n-gram language model. Both the two processes are time-consuming, and bring difficulty in parameters tuning and deployment. \r\n\r\nA proven effective way is to prune the beam search. Specifically, in extending prefix only the fewest number of characters whose cumulative probability is at least **p** need to be considered, instead of all the characters in the vocabulary. When **p** is taken 0.99 as recommended by the [DS2 paper](https://arxiv.org/abs/1512.02595), about **20x** speedup is yielded in English transcription than that without pruning, with very little loss in accuracy. And for the Mandarin, the speedup ratio is reported to be up to **150x**.\r\n\r\nDue to pruning,  the tuning of parameters gets more efficiently. There are two important parameters ```alpha``` and ```beta``` in beam search, associated with language model and word insertion respectively. With a more acceptable speed,  ```alpha``` and ```beta``` can be searched elaborately. And the relation between WER and the two parameters turns out to be:\r\n![figure_1](https://user-images.githubusercontent.com/3064195/27387097-5661acdc-56ca-11e7-9d24-05ab2d79e2ff.png)\r\n  \r\nWith the optimal parameters ```alpha=0.26``` and ```beta=0.1``` as shown in above figure, currently the beam search decoder has decreased WER to **13%** from the best path decoding accuracy **22%**.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2017-06-21T13:43:26+00:00",
        "updated_at": "2018-08-15T10:16:26+00:00",
        "closed_at": "2018-08-15T10:16:26+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 124,
        "title": "Modify inference script",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "lcy-seso",
        "created_at": "2017-06-26T03:44:07+00:00",
        "updated_at": "2017-06-26T04:30:02+00:00",
        "closed_at": "2017-06-26T04:30:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 116,
        "title": "Add a public mandarin dataset",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2017-06-21T15:34:41+00:00",
        "updated_at": "2018-08-15T10:16:23+00:00",
        "closed_at": "2018-08-15T10:16:23+00:00",
        "comments_count": [
            "pkuyym",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 119,
        "title": "Add DSSM",
        "body": "Add Deep Structured Semantic Model(DSSM)\r\n学习两个句子之间的相关性",
        "state": "closed",
        "user": "fty8788",
        "closed_by": "Superjomn",
        "created_at": "2017-06-22T08:26:05+00:00",
        "updated_at": "2017-07-17T02:23:52+00:00",
        "closed_at": "2017-07-17T02:23:52+00:00",
        "comments_count": [
            "Superjomn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 126,
        "title": "Refine SoundFile installation process.",
        "body": "1. First install libsndfile.\r\n2. Install SoundFile using pip.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "chrisxu2016",
        "created_at": "2017-06-26T05:07:24+00:00",
        "updated_at": "2017-06-27T09:25:18+00:00",
        "closed_at": "2017-06-27T09:25:18+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 133,
        "title": "Train ds2 on THCHS30 (WIP)",
        "body": "I am trying to train ds2 on THCHS30 which is a mandarin dataset. A phenomenon is that we encounter error explosion easily when ```batch_size``` is big liking 64, 128 or 256. I try to clip the error to 1000 when ```inf``` appears. The clipping operation is very tricky, I catch ```inf``` and clip in ```paddle/v2/trainer.py``` as following:\r\n```python\r\ncost_sum = out_args.sum()\r\nimport math\r\nif (math.isinf(cost_sum)): cost_sum = 1000.0\r\ncost = cost_sum / len(data_batch)\r\n```\r\nWe can train ds2 normally after adding the clipping operation. I have tried to train the model using ```batch_shuffle_clipped``` provider and ```instance_shuffle``` provider. The learning curves are as following:\r\n![shuffle_compare](https://user-images.githubusercontent.com/5782283/27638338-79556474-5c45-11e7-93ce-5a8726651d50.png)\r\nAs we can see, ```instance_shuffle``` converges badly and I abandon this configuration after training several iterations. The ```batch_shuffle_clipped``` configuration looks like converging very slowly when the training cost goes down to 170~. The key settings of above experiments are:\r\n\r\nsetting | value\r\n---- | ----\r\nbatch_size | 64\r\ntrainer_count | 4\r\nnum_conv_layers | 2\r\nadam_learning_rate | 0.0005\r\n\r\nI also product another experiment on a tiny dataset which only contains 128 samples (first 128). Training data and validation data both use the tiny dataset. Training settings are same with above. Following are the learning curves:\r\n\r\n![small_data](https://user-images.githubusercontent.com/5782283/27641947-f594e3b6-5c4f-11e7-94c3-68528dbf27db.png)\r\n\r\nFrom the figure above we can learn that the convergence is very unstable and slow. There exists a unreasonable gap between training curve and validation curve. Since the training data and validation data are same, the difference of two curves should be minor. Will figure out the reason of the anomalies. ",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2017-06-28T10:56:41+00:00",
        "updated_at": "2018-08-15T10:16:20+00:00",
        "closed_at": "2018-08-15T10:16:20+00:00",
        "comments_count": [
            "pkuyym",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 143,
        "title": "Make ds2 run on paddle cloud",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "xinghai-sun",
        "created_at": "2017-07-03T07:19:22+00:00",
        "updated_at": "2017-08-14T07:34:38+00:00",
        "closed_at": "2017-08-14T07:34:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 142,
        "title": "paddlepaddle第一章新手入门时，存在描述不清问题",
        "body": "经查证是因缺少一部分内容，后续希望作者尽快merge",
        "state": "closed",
        "user": "jinbiaomao",
        "closed_by": "llxxxll",
        "created_at": "2017-07-03T03:22:11+00:00",
        "updated_at": "2017-07-12T13:20:18+00:00",
        "closed_at": "2017-07-12T13:20:18+00:00",
        "comments_count": [
            "llxxxll"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 136,
        "title": "Add demo for SSD model (WIP)",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "qingqing01",
        "created_at": "2017-06-28T14:43:06+00:00",
        "updated_at": "2017-08-11T05:00:54+00:00",
        "closed_at": "2017-08-11T05:00:54+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 149,
        "title": "Some questions ofThe vectors generated by embedding_laye",
        "body": "Q1：If two words' vectors are very close to each other,  are they really similar words? Or just because their IDs are close to each other ?\r\nQ2:  If I apply embedding_layer into my network, will these vectors change during iteration？",
        "state": "closed",
        "user": "xhzhang1212",
        "closed_by": "xhzhang1212",
        "created_at": "2017-07-07T07:24:03+00:00",
        "updated_at": "2017-07-07T07:39:01+00:00",
        "closed_at": "2017-07-07T07:39:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 147,
        "title": "image_classification vgg13 Check failed: (size_t)lbl[i] < dim (102 vs. 102)",
        "body": "```\r\n➜  image_classification git:(develop) ✗ python train.py vgg13\r\n/home/lizhao/.jumbo/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:28: UserWarning: This platform l\r\nacks a functioning sem_open implementation, therefore, the required synchronization primitives needed will not function, see issue 37\r\n70..  joblib will operate in serial mode\r\n  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\r\nI0705 14:23:52.511775  6784 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\n[INFO 2017-07-05 14:23:52,518 layers.py:2412] output for __conv_0__: c = 64, h = 224, w = 224, size = 3211264\r\n[INFO 2017-07-05 14:23:52,519 layers.py:2412] output for __conv_1__: c = 64, h = 224, w = 224, size = 3211264\r\n[INFO 2017-07-05 14:23:52,520 layers.py:2537] output for __pool_0__: c = 64, h = 112, w = 112, size = 802816\r\n[INFO 2017-07-05 14:23:52,521 layers.py:2412] output for __conv_2__: c = 128, h = 112, w = 112, size = 1605632\r\n[INFO 2017-07-05 14:23:52,522 layers.py:2412] output for __conv_3__: c = 128, h = 112, w = 112, size = 1605632\r\n[INFO 2017-07-05 14:23:52,523 layers.py:2537] output for __pool_1__: c = 128, h = 56, w = 56, size = 401408\r\n[INFO 2017-07-05 14:23:52,524 layers.py:2412] output for __conv_4__: c = 256, h = 56, w = 56, size = 802816\r\n[INFO 2017-07-05 14:23:52,525 layers.py:2412] output for __conv_5__: c = 256, h = 56, w = 56, size = 802816\r\n[INFO 2017-07-05 14:23:52,526 layers.py:2537] output for __pool_2__: c = 256, h = 28, w = 28, size = 200704\r\n[INFO 2017-07-05 14:23:52,527 layers.py:2412] output for __conv_6__: c = 512, h = 28, w = 28, size = 401408\r\n[INFO 2017-07-05 14:23:52,528 layers.py:2412] output for __conv_7__: c = 512, h = 28, w = 28, size = 401408\r\n[INFO 2017-07-05 14:23:52,529 layers.py:2537] output for __pool_3__: c = 512, h = 14, w = 14, size = 100352\r\n[INFO 2017-07-05 14:23:52,530 layers.py:2412] output for __conv_8__: c = 512, h = 14, w = 14, size = 100352\r\n[INFO 2017-07-05 14:23:52,531 layers.py:2412] output for __conv_9__: c = 512, h = 14, w = 14, size = 100352\r\n[INFO 2017-07-05 14:23:52,532 layers.py:2537] output for __pool_4__: c = 512, h = 7, w = 7, size = 25088\r\nI0705 14:23:55.889189  6784 GradientMachine.cpp:85] Initing parameters..\r\nI0705 14:24:04.664135  6784 GradientMachine.cpp:92] Init parameters done.\r\nF0705 14:28:51.952270  6784 Matrix.cpp:3286] Check failed: (size_t)lbl[i] < dim (102 vs. 102)\r\n*** Check failure stack trace: ***\r\n    @     0x7f01d1fa231d  google::LogMessage::Fail()\r\n    @     0x7f01d1fa5dcc  google::LogMessage::SendToLog()\r\n    @     0x7f01d1fa1e43  google::LogMessage::Flush()\r\n    @     0x7f01d1fa72de  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f01d1dfe6b0  paddle::CpuMatrix::oneHotCrossEntropy()\r\n    @     0x7f01d1d288e5  paddle::CostLayer::forward()\r\n    @     0x7f01d1d996f0  paddle::NeuralNetwork::forward()\r\n    @     0x7f01d1d75433  paddle::GradientMachine::forwardBackward()\r\n    @     0x7f01d1f7db7b  GradientMachine::forwardBackward()\r\n    @     0x7f01d1bf87ce  _wrap_GradientMachine_forwardBackward\r\n    @     0x7f01dab763a3  PyEval_EvalFrameEx\r\n    @     0x7f01dab78130  PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1  PyEval_EvalFrameEx\r\n    @     0x7f01dab78130  PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1  PyEval_EvalFrameEx\r\n    @     0x7f01dab78130  PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1  PyEval_EvalFrameEx\r\n    @     0x7f01dab78130  PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1  PyEval_EvalFrameEx\r\n    @     0x7f01dab78130  PyEval_EvalCodeEx\r\n    @     0x7f01dab78242  PyEval_EvalCode\r\n    @     0x7f01dab9262c  run_mod\r\n    @     0x7f01dab92700  PyRun_FileExFlags\r\n    @     0x7f01dab93c0c  PyRun_SimpleFileExFlags\r\n    @     0x7f01daba54cc  Py_Main\r\n    @       0x318ae1ecdd  (unknown)\r\nThread [139645940217600] Forwarding __cost_0__,\r\n*** Aborted at 1499236132 (unix time) try \"date -d @1499236132\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x20900001a80) received by PID 6784 (TID 0x7f01daa93700) from PID 6784; stack trace: ***\r\n    @       0x318b20f500 (unknown)\r\n    @       0x318ae328a5 (unknown)\r\n    @       0x318ae34085 (unknown)\r\n    @     0x7f01d1fac85b google::FindSymbol()\r\n    @     0x7f01d1fad21a google::GetSymbolFromObjectFile()\r\n    @     0x7f01d1fad8e2 google::SymbolizeAndDemangle()\r\n    @     0x7f01d1fab0e8 google::DumpStackTrace()\r\n    @     0x7f01d1fab1a6 google::DumpStackTraceAndExit()\r\n    @     0x7f01d1fa231d google::LogMessage::Fail()\r\n    @     0x7f01d1fa5dcc google::LogMessage::SendToLog()\r\n    @     0x7f01d1fa1e43 google::LogMessage::Flush()\r\n    @     0x7f01d1fa72de google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f01d1dfe6b0 paddle::CpuMatrix::oneHotCrossEntropy()\r\n    @     0x7f01d1d288e5 paddle::CostLayer::forward()\r\n    @     0x7f01d1d996f0 paddle::NeuralNetwork::forward()\r\n    @     0x7f01d1d75433 paddle::GradientMachine::forwardBackward()\r\n    @     0x7f01d1f7db7b GradientMachine::forwardBackward()\r\n    @     0x7f01d1bf87ce _wrap_GradientMachine_forwardBackward\r\n    @     0x7f01dab763a3 PyEval_EvalFrameEx\r\n    @     0x7f01dab78130 PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1 PyEval_EvalFrameEx\r\n    @     0x7f01dab78130 PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1 PyEval_EvalFrameEx\r\n    @     0x7f01dab78130 PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1 PyEval_EvalFrameEx\r\n    @     0x7f01dab78130 PyEval_EvalCodeEx\r\n    @     0x7f01dab764a1 PyEval_EvalFrameEx\r\n    @     0x7f01dab78130 PyEval_EvalCodeEx\r\n    @     0x7f01dab78242 PyEval_EvalCode\r\n    @     0x7f01dab9262c run_mod\r\n    @     0x7f01dab92700 PyRun_FileExFlags\r\n    @     0x7f01dab93c0c PyRun_SimpleFileExFlags\r\n[1]    6784 abort (core dumped)  python train.py vgg13\r\n```",
        "state": "closed",
        "user": "livc",
        "closed_by": "shanyi15",
        "created_at": "2017-07-05T06:39:46+00:00",
        "updated_at": "2018-08-15T10:08:39+00:00",
        "closed_at": "2018-08-15T10:08:39+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 145,
        "title": "模型使用有些疑惑",
        "body": "当我进行定义线性回归训练时，发现了一个问题\r\n> 读取一个文件\r\n`# define training dataset reader\r\ndef train_reader():\r\n    train_x = [];\r\n    train_y = [];\r\n    for line in open(\"test2.txt\"):\r\n        line  = line.split('|')\r\n        x = [int(line[2])]\r\n        y = [int(line[3])]\r\n        train_x.append(x)\r\n        train_y.append(y)\r\n    train_y = np.array(train_y)\r\n    train_x = np.array(train_x)\r\n    def reader():\r\n        for i in xrange(train_y.shape[0]):\r\n            yield train_x[i], train_y[i]\r\n    return reader`\r\n文件内容为下方展示\r\n2017/3/3|地图|1|1000|\r\n2017/3/5|地图|2|900|\r\n2017/3/23|地图|3|800|\r\n2017/3/25|地图|4|700|\r\n2017/3/28|地图|5|600|\r\n2017/4/1|地图|6|500|\r\n2017/4/2|地图|7|400|\r\n2017/4/3|地图|8|300|\r\n2017/4/4|地图|9|200|\r\n2017/4/4|地图|10|100|\r\n_当我进行完成模型处理时，得到的结果为下_\r\n`[ 164.00054932]\r\n[ 190.17622375]\r\n[ 216.35189819]\r\n[ 242.52755737]\r\n[ 268.70324707]`\r\n此处测试为下方\r\n`#test\r\ntest_data = [[1],[2],[3],[4],[5]];\r\n`inference\r\nprobs = paddle.infer(\r\n    output_layer=y_predict, parameters=parameters, input=test_data)\r\n\r\nfor data in probs:\r\n    print data``\r\n-----------------此处模型配置如下-------------------------\r\n`# network config\r\nx = paddle.layer.data(name='x', type=paddle.data_type.dense_vector(1))\r\ny_predict = paddle.layer.fc(input=x, size=1, act=paddle.activation.Linear())\r\ny = paddle.layer.data(name='y', type=paddle.data_type.dense_vector(1))\r\ncost = paddle.layer.mse_cost(input=y_predict, label=y)\r\n\r\n# create parameters\r\nparameters = paddle.parameters.create(cost)\r\n# create optimizer\r\noptimizer = paddle.optimizer.Momentum(momentum=0)\r\n# create trainer\r\ntrainer = paddle.trainer.SGD(cost=cost,\r\n                             parameters=parameters,\r\n                             update_equation=optimizer)`\r\n关于这个问题尚且不是十分清楚，希望得到解答",
        "state": "closed",
        "user": "jinbiaomao",
        "closed_by": "jacquesqiao",
        "created_at": "2017-07-03T07:50:39+00:00",
        "updated_at": "2017-07-06T02:27:47+00:00",
        "closed_at": "2017-07-06T02:27:47+00:00",
        "comments_count": [
            "jinbiaomao",
            "jacquesqiao",
            "jinbiaomao",
            "jacquesqiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 150,
        "title": "models.paddlepaddle.org fix and todo",
        "body": "Some bugs here:\r\n\r\n- [ ] http://models.paddlepaddle.org/2017/04/21/sequence-tagging-for-ner-README.html 第二张图\r\n\r\nSome TODOs here:\r\n- [ ] 教程添加代码链接\r\n- [ ] 自动部署工具\r\n- [ ] LOGO",
        "state": "closed",
        "user": "Superjomn",
        "closed_by": "shanyi15",
        "created_at": "2017-07-07T07:46:21+00:00",
        "updated_at": "2018-08-15T10:08:36+00:00",
        "closed_at": "2018-08-15T10:08:36+00:00",
        "comments_count": [
            "llxxxll",
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 153,
        "title": "CTR model例子，id字段不适合选作特征吧？",
        "body": "CTR model这个例子中：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/ctr/dataset.md\r\n选用了id这个字段。\r\n经过统计，dataset大小是40428967， id的不同取值个数是40428967个。也就是说每一个样本都有一个不同的id。\r\n那么还用这个id作为特征，不合适吧？",
        "state": "closed",
        "user": "superzhangmch",
        "closed_by": "shanyi15",
        "created_at": "2017-07-10T10:00:36+00:00",
        "updated_at": "2018-08-15T10:08:31+00:00",
        "closed_at": "2018-08-15T10:08:31+00:00",
        "comments_count": [
            "Superjomn",
            "superzhangmch",
            "Superjomn",
            "Superjomn",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 155,
        "title": "fork的models-1/ctr branch:ctr2 infer时有异常",
        "body": "```text\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 80, in <module>\r\n    ctr_inferer = CTRInferer(args.model_gz_path)\r\n  File \"infer.py\", line 54, in __init__\r\n    is_infer=True)\r\n  File \"/home/zhangjunmin/mycore/model/paddle/models-1-ctr2/ctr/network_conf.py\", line 44, in __init__\r\n    if self.model_type.is_classification():\r\nAttributeError: 'int' object has no attribute 'is_classification'\r\n\r\n修改self.model_type = ModelType.create_classification()后，另有如下出错\r\n\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 80, in <module>\r\n    ctr_inferer = CTRInferer(args.model_gz_path)\r\n  File \"infer.py\", line 54, in __init__\r\n    is_infer=True)\r\n  File \"/home/zhangjunmin/mycore/model/paddle/models-1-ctr2/ctr/network_conf.py\", line 45, in __init__\r\n    self.model = self._build_classification_model(self.dnn, self.lr)\r\n  File \"/home/zhangjunmin/mycore/model/paddle/models-1-ctr2/ctr/network_conf.py\", line 99, in _build_classification_model\r\n    input=self.output, label=self.click)\r\nAttributeError: 'CTRmodel' object has no attribute 'click'\r\n```",
        "state": "closed",
        "user": "awper361",
        "closed_by": "Superjomn",
        "created_at": "2017-07-12T09:04:59+00:00",
        "updated_at": "2017-07-17T02:18:28+00:00",
        "closed_at": "2017-07-17T02:18:28+00:00",
        "comments_count": [
            "awper361",
            "Superjomn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 158,
        "title": "provide examples on how to use CAPI to predict",
        "body": "In some situation, by the deployment considerations, users hope to use CAPI to predict, instead of Python infer interface. We should provide examples to tell users how to do so. This also helps to test the CAPI.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-07-13T06:17:30+00:00",
        "updated_at": "2018-08-15T09:59:20+00:00",
        "closed_at": "2018-08-15T09:59:20+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 159,
        "title": "LTR例子中直接运行python ranknet.py出现错误",
        "body": "$ python ranknet.py \r\nI0713 17:47:23.595508 19546 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=4 \r\nI0713 17:47:23.610213 19546 GradientMachine.cpp:85] Initing parameters..\r\nI0713 17:47:23.610375 19546 GradientMachine.cpp:92] Init parameters done.\r\nTraceback (most recent call last):\r\n  File \"ranknet.py\", line 134, in <module>\r\n    train_ranknet(pass_num)\r\n  File \"ranknet.py\", line 94, in train_ranknet\r\n    num_passes=num_passes)\r\n  File \"/home/users/lutaojian/work/paddle/paddle-binary/python27/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 153, in train\r\n    in_args = feeder(data_batch)\r\n  File \"/home/users/lutaojian/work/paddle/paddle-binary/python27/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 278, in __call__\r\n    return self.convert(dat, argument)\r\n  File \"/home/users/lutaojian/work/paddle/paddle-binary/python27/lib/python2.7/site-packages/paddle/v2/data_feeder.py\", line 134, in convert\r\n    return DataProviderConverter.convert(self, reorder_data(dat), argument)\r\n  File \"/home/users/lutaojian/work/paddle/paddle-binary/python27/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 263, in convert\r\n    scanner.pre_scan(each_step)\r\n  File \"/home/users/lutaojian/work/paddle/paddle-binary/python27/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 112, in pre_scan\r\n    self.__dim__ = reduce(lambda x, y: x * y, self.__shape__)",
        "state": "closed",
        "user": "lutaojian",
        "closed_by": "dzhwinter",
        "created_at": "2017-07-13T09:50:19+00:00",
        "updated_at": "2017-08-24T05:15:36+00:00",
        "closed_at": "2017-08-24T05:15:36+00:00",
        "comments_count": [
            "dzhwinter",
            "dzhwinter"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 160,
        "title": "DSSM please add a infer.py",
        "body": "DSSM可以提供一个infer.py脚本么，输入测试集，输出预测结果，以及评估结果（如AUC、准/召）",
        "state": "closed",
        "user": "fty8788",
        "closed_by": "shanyi15",
        "created_at": "2017-07-13T13:21:30+00:00",
        "updated_at": "2018-08-15T09:59:17+00:00",
        "closed_at": "2018-08-15T09:59:16+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 163,
        "title": "写模型到本地目录的时候崩溃",
        "body": "第一轮训练完成之后，写入文件，崩溃，代码是：\r\n```python\r\nwith gzip.open(\"dssm_%s_pass_%05d.tar.gz\" %\r\n(model_save_name_prefix, event.pass_id), \"w\") as f:\r\nparameters.to_tar(f)\r\n```\r\n错误日志是：\r\n```text\r\n[INFO 2017-07-13 15:26:48,320 train.py:199] Pass 0, Batch 4000, Cost 0.530298, {'auc_evaluator_0': 0.7309514880180359, 'classification_error_evaluator': 0.2705000042915344}\r\n\r\n(paddle_box) (paddle_box) tail log.bigram\r\nnum_passes=num_passes)\r\nFile \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 175, in train\r\nevent_handler(v2_event.EndPass(pass_id, evaluator=pass_evaluator))\r\nFile \"train.py\", line 211, in _event_handler\r\nparameters.to_tar(f)\r\nFile \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 274, in to_tar\r\nself.serialize(nm, buf)\r\nFile \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 256, in serialize\r\nf.write(param.tostring())\r\nOverflowError: length too large\r\n```\r\n\r\n用的DSSM模型，字典维度200w",
        "state": "closed",
        "user": "fty8788",
        "closed_by": "shanyi15",
        "created_at": "2017-07-16T01:33:43+00:00",
        "updated_at": "2018-08-15T09:59:13+00:00",
        "closed_at": "2018-08-15T09:59:13+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 165,
        "title": "ctr（wide&deep）模型的dense部分是否可以通过特征slot号进行embedding",
        "body": "@Superjom ",
        "state": "closed",
        "user": "awper361",
        "closed_by": "shanyi15",
        "created_at": "2017-07-17T02:27:22+00:00",
        "updated_at": "2018-08-15T09:59:10+00:00",
        "closed_at": "2018-08-15T09:59:10+00:00",
        "comments_count": [
            "Superjomn",
            "awper361",
            "Superjomn",
            "awper361",
            "Superjomn",
            "shanyi15"
        ],
        "labels": [
            "question"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 166,
        "title": "ctr模型使用自己数据训练，仍需加载meta",
        "body": "https://github.com/Superjom/models-1/tree/ctr2/ctr\r\n\r\nmodels-1-ctr2/ctr/train.py:58\r\n\r\ndnn_input_dim, lr_input_dim = reader.load_data_meta(args.data_meta_file)\r\n@Superjom",
        "state": "closed",
        "user": "awper361",
        "closed_by": "Superjomn",
        "created_at": "2017-07-17T02:35:57+00:00",
        "updated_at": "2017-08-11T03:14:31+00:00",
        "closed_at": "2017-08-11T03:14:31+00:00",
        "comments_count": [
            "Superjomn"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 174,
        "title": "各个模型的目录结构、文件名称、运行方式需要统一",
        "body": "现在模型的运行方式有：\r\n`python train.py`\r\n`python xxx.py`\r\n`python xxx.py -y 0 --model_arch 0`\r\n`./run.sh`\r\n这里最好统一一下，此外模型的train和infer最好都分开，并都命名为相同的名字（train.py, infer.py），总之，models中各个模型的目录结构、文件名称、运行方式需要统一。",
        "state": "closed",
        "user": "livc",
        "closed_by": "shanyi15",
        "created_at": "2017-07-20T10:05:38+00:00",
        "updated_at": "2018-08-15T09:59:06+00:00",
        "closed_at": "2018-08-15T09:59:06+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 176,
        "title": "Task List for DS2 on Paddle",
        "body": "For tracking progress of key tasks:\r\n\r\n- [x] Warp-CTC‘s numerical instability problem and INF bug.\r\n- [ ] Bad convergence for THCHS-30.\r\n- [x] Performance drop for latest paddle version.\r\n- [x] Inconsistent results between trainer.test and inference.infer ([issue](https://github.com/PaddlePaddle/models/issues/178)).\r\n- [x] Prefix-beam-search decoder's difference with speech_dl codes.\r\n- [ ] Double check for the reliability of Paddle-v2 (by comparing V1 and V2).\r\n- [x] Experimenting with MFCC.\r\n- [x] Kubernetes running and profiling.\r\n- [ ] Performance profiling.\r\n- [x] Make autoset for cudnn-conv and cudnn-batch-norm.\r\n- [x] Speed difference for gpu-00 and gpu-01 machines.\r\n- [x] Debug for incorrect inferencing with multiple GPUs ([issue](https://github.com/PaddlePaddle/Paddle/issues/3073)).\r\n- [x] Unicom-3k data preprocessing.\r\n- [ ] Remove padding steps from ctc loss computation.\r\n- [x] Fix CUDNN_STATUS_NOT_SUPPORTED error ([Issue](https://github.com/PaddlePaddle/Paddle/issues/929)).\r\n- [x] Make setup.sh more robust. #177 #182 \r\n- [x] Add a real-time ASR demo (server + client) ([PR](https://github.com/PaddlePaddle/models/pull/186)).\r\n\r\nhttps://github.com/PaddlePaddle/Paddle/projects/17",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "shanyi15",
        "created_at": "2017-07-25T12:07:54+00:00",
        "updated_at": "2018-08-15T09:59:03+00:00",
        "closed_at": "2018-08-15T09:59:03+00:00",
        "comments_count": [
            "lcy-seso",
            "xinghai-sun",
            "xinghai-sun",
            "xinghai-sun",
            "pkuyym",
            "kuke",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 179,
        "title": "Profiling of DS2 on paddle cloud ",
        "body": "# DeepSpeech2 on PaddleCloud\r\n\r\n## Paddle Cloud GPU\r\nTesla P40\r\n\r\n## Experiments\r\n\r\n### cudnn\r\n\r\n|id | parallelism|GPU |batch_size| time(sec) | reader threads|\r\n|---|---|---|---|---|---|\r\n| 1| 1| 1| 256 |OOM error|8|\r\n| 2| 1| 1| 256 |39524|16|\r\n| 3| 1| 4| 256 |9770 |8|\r\n| 4| 1| 4| 256 | 12481|16|\r\n| 5| 2| 4| 256 |5217 |8|\r\n| 6| 2| 4| 128 | 6003|8|\r\n| 7| 2| 4| 128 | 6978|16|\r\n\r\n- **id:** experiment id\r\n- **parallelism:** number of machines(k8s ins?) using for trainning \r\n- **GPU:** number GPU using in one k8s instance\r\n- **batch_size:** batch size in each k8s instance\r\n- **time:** time per pass \r\n- **reader threads:** thread num of reading and processing data in xmap\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2017-07-26T15:26:18+00:00",
        "updated_at": "2018-04-12T05:20:53+00:00",
        "closed_at": "2018-04-12T05:20:53+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Yancey0623"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 178,
        "title": "Inconsistent results with trainer.test and Inference.infer under different batch sizes.",
        "body": "1) Inconsistent inference results with Inference.infer under different batch sizes.\r\n2) Small inference difference between trainer.test and Inference.infer.\r\n\r\nExperiments are run with DeepSpeech2 on Paddle.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-07-26T10:55:40+00:00",
        "updated_at": "2017-07-26T16:47:18+00:00",
        "closed_at": "2017-07-26T11:03:20+00:00",
        "comments_count": [
            "xinghai-sun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 180,
        "title": "在实际数据上运行ner的训练demo，训练时precision,recall,f1都为0是否正常",
        "body": "![f8056b82ec924d17b6337dab466af441](https://user-images.githubusercontent.com/22500910/28709566-6ee42608-73b3-11e7-99d4-bbcb30d13f6d.png)\r\n我在实际数据集上运行了一下ner的demo，训练时截图如上图，怎么感觉有问题，有问题的话会出在哪呢？麻烦您看一下，谢谢啦~~\r\n主要代码和数据：\r\n[music.zip](https://github.com/PaddlePaddle/models/files/1182507/music.zip)\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "hitwangshuai",
        "closed_by": "Yancey0623",
        "created_at": "2017-07-28T08:47:53+00:00",
        "updated_at": "2017-09-20T16:04:37+00:00",
        "closed_at": "2017-09-20T16:04:37+00:00",
        "comments_count": [
            "lcy-seso",
            "Yancey0623"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 181,
        "title": "在mq2007数据集上训练LR模型，train cost没有呈现下降。",
        "body": "常使用paddle实验LR模型，在mq2007数据集上做point wise模型，具体网络实现如下。训练过程中train cost没有呈现下降趋势，但test cost反馈出下降，无法确定是否已经收敛。\r\n\r\n有两个问题求大神解答：\r\n1）下文的网络实验是否与LR模型等价；\r\n2）训练过程train cost不下降是否正常。\r\n![d9e0c3f8e0caf8a1db6cd77511e6d994](https://user-images.githubusercontent.com/30145175/28770856-492180a2-7613-11e7-9905-c274e41ec836.png)\r\n\r\ndef sigmoid(input_dim):\r\n    # data layer\r\n    data = paddle.layer.data(\"data\", paddle.data_type.dense_vector(input_dim))\r\n\r\n    # sigmoid\r\n    output = paddle.layer.fc(\r\n        input=data,\r\n        size=1,\r\n        act=paddle.activation.Sigmoid(),\r\n        param_attr=paddle.attr.Param(initial_std=0.01, name=\"output\"))\r\n\r\n    return output\r\n\r\n\r\ndef lr(input_dim):\r\n    # label layer\r\n    label = paddle.layer.data(\"label\", paddle.data_type.dense_vector(1))\r\n\r\n    # output layer\r\n    output = sigmoid(input_dim)\r\n\r\n    # cost layer\r\n    cost = paddle.layer.multi_binary_label_cross_entropy_cost(input=output, label=label)\r\n    \r\n    return cost\r\n\r\n\r\ndef train_lr(num_passes):\r\n    fill_default_train = functools.partial(paddle.dataset.mq2007.train, format=\"pointwise\")\r\n    fill_default_test = functools.partial(paddle.dataset.mq2007.test, format=\"pointwise\")\r\n    train_reader = paddle.batch(paddle.reader.shuffle(fill_default_train, buf_size=100), batch_size=100)\r\n    test_reader = paddle.batch(fill_default_test, batch_size=100)\r\n\r\n    # mq2007 feature_dim = 46, dense format\r\n    feature_dim = 46\r\n    cost = lr(feature_dim)\r\n    parameters = paddle.parameters.create(cost)\r\n\r\n    trainer = paddle.trainer.SGD(\r\n        cost=cost,\r\n        parameters=parameters,\r\n        update_equation=paddle.optimizer.Adam(learning_rate=2e-4))\r\n\r\n    # Define the input data order\r\n    feeding = {\"label\": 0, \"data\": 1}\r\n\r\n    #  Define end batch and end pass event handler\r\n    def event_handler(event):\r\n        if isinstance(event, paddle.event.EndIteration):\r\n            if event.batch_id % 100 == 0:\r\n                print \"Train with Pass %d Batch %d Cost %.9f\" % (\r\n                    event.pass_id, event.batch_id, event.cost)\r\n            else:\r\n                sys.stdout.write(\".\")\r\n                sys.stdout.flush()\r\n        if isinstance(event, paddle.event.EndPass):\r\n            result = trainer.test(reader=test_reader, feeding=feeding)\r\n            print \"\\nTest with Pass %d Cost %.9f\\n\" % (event.pass_id, result.cost)\r\n            with gzip.open(\"lr_params_%d.tar.gz\" % (event.pass_id), \"w\") as f:\r\n                parameters.to_tar(f)\r\n\r\n    trainer.train(\r\n        reader=train_reader,\r\n        event_handler=event_handler,\r\n        feeding=feeding,\r\n        num_passes=num_passes)",
        "state": "closed",
        "user": "lutaojian",
        "closed_by": "shanyi15",
        "created_at": "2017-07-31T09:11:29+00:00",
        "updated_at": "2018-08-15T09:58:59+00:00",
        "closed_at": "2018-08-15T09:58:59+00:00",
        "comments_count": [
            "dzhwinter",
            "shanyi15"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 198,
        "title": "DS2 reader: Move local data variable from global into class DataGenerator.",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2017-08-14T11:36:25+00:00",
        "updated_at": "2017-08-14T11:46:09+00:00",
        "closed_at": "2017-08-14T11:46:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 187,
        "title": "Does beam_search support convolutional decoder?",
        "body": "As used in https://arxiv.org/abs/1705.03122?\r\nThe key difference may be the rnn decoder depends on only one previous state, while conv decoder depends on many previous states?",
        "state": "closed",
        "user": "byzhang",
        "closed_by": "shanyi15",
        "created_at": "2017-08-05T04:05:54+00:00",
        "updated_at": "2018-08-15T09:58:52+00:00",
        "closed_at": "2018-08-15T09:58:52+00:00",
        "comments_count": [
            "lcy-seso",
            "byzhang",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 197,
        "title": "generate_sequence_by_rnn_lm文本预测总是生成太短的句子",
        "body": "最近在研究paddlepaddle的代码——generate_sequence_by_rnn_lm，用于文本预测的。\r\n但是我实际使用下来，不论是原始代码中的例子还是我自己的语料，最后测试的时候，生成的几个文本，要么就是直接<e>结束，要么就是一个词加<e>结束。和我预想的能预测出一句话的与其不太符合呀？问一下知道是什么原因，应该从什么地方去调节么？\r\n附原始模型的预测结果：\r\n0\t我们 不会 伤害 你 的 。 他们 也 这么 说 。\r\n-3.5803\t<e>\r\n-7.1343\t。 <e>\r\n-7.2209\t合法 <e>\r\n-7.2261\t这么 <e>\r\n-7.2467\t伤害 <e>\r\n\r\n1\t你 拥有 你 父亲 皇室 的 血统 。 是 合法 的 继承人 。\r\n-3.5302\t<e>\r\n-7.0220\t。 <e>\r\n-7.2087\t合法 <e>\r\n-7.2363\t的 <e>\r\n-7.2734\t谁 <e>\r\n\r\n2\t叫 什么 你 可以 告诉 我 。\r\n-3.5723\t<e>\r\n-7.0548\t完成 <e>\r\n-7.0734\t的 <e>\r\n-7.1087\t合法 <e>\r\n-7.1976\t血统 <e>\r\n\r\n3\t你 并 没有 留言 说 要 去 哪里 。 是 的 , 因为 我 必须 要 去 完成 这件 事 。\r\n-3.4887\t<e>\r\n-7.0560\t。 <e>\r\n-7.1366\t住 <e>\r\n-7.1659\t事 <e>\r\n-7.1768\t在 <e>\r\n\r\n4\t你 查出 是 谁 住 在 隔壁 房间 吗 ?\r\n-3.6060\t<e>\r\n-7.1809\t。 <e>\r\n-7.2621\t在 <e>\r\n-7.3472\t并 <e>\r\n-10.7716\t在 。 <e>\r\n\r\n",
        "state": "closed",
        "user": "sky-lc",
        "closed_by": "sky-lc",
        "created_at": "2017-08-14T02:09:29+00:00",
        "updated_at": "2017-08-14T16:23:55+00:00",
        "closed_at": "2017-08-14T16:23:55+00:00",
        "comments_count": [
            "lcy-seso",
            "sky-lc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 200,
        "title": "Bug fix and refine cloud training for DS2.",
        "body": "1. Add missing is_local argument (when set False, use pserver).\r\n2. Add exception thrown if cloud cp failed.\r\n3. Add cloud mkdir if cloud path for uploading does not exist.\r\n4. Fix a bug using common path ./local_manifest for all nodes. (convert to /local_manifest)\r\n5. Refine coding style.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-08-14T11:59:11+00:00",
        "updated_at": "2017-08-14T14:01:54+00:00",
        "closed_at": "2017-08-14T14:01:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 203,
        "title": "Rename self.local_data to self._local_data in class DataGenerator.",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "lcy-seso",
        "created_at": "2017-08-14T12:46:13+00:00",
        "updated_at": "2017-09-02T08:17:05+00:00",
        "closed_at": "2017-09-02T08:17:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 210,
        "title": "Encounter exception when running tools/compute_mean_std.py",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"tools/compute_mean_std.py\", line 64, in <module>\r\n    main()\r\n  File \"tools/compute_mean_std.py\", line 59, in main\r\n    num_samples=args.num_samples)\r\n  File \"/home/disk1/yangyaming/workspace/paddle/ds2/mandarin_unicom/default_conf/tools/../data_utils/normalizer.py\", line 46, in __init__\r\n    self._compute_mean_std(manifest_path, featurize_func, num_samples)\r\n  File \"/home/disk1/yangyaming/workspace/paddle/ds2/mandarin_unicom/default_conf/tools/../data_utils/normalizer.py\", line 84, in _compute_mean_std\r\n    AudioSegment.from_file(instance[\"audio_filepath\"])))\r\n  File \"tools/compute_mean_std.py\", line 53, in augment_and_featurize\r\n    return audio_featurizer.featurize(audio_segment)\r\n  File \"/home/disk1/yangyaming/workspace/paddle/ds2/mandarin_unicom/default_conf/tools/../data_utils/featurizer/audio_featurizer.py\", line 79, in featurize\r\n    allow_upsampling)):\r\nNameError: global name 'allow_upsampling' is not defined\r\n```\r\nLook like a typo problem.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "xinghai-sun",
        "created_at": "2017-08-17T03:08:23+00:00",
        "updated_at": "2017-08-21T14:10:39+00:00",
        "closed_at": "2017-08-21T14:10:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 204,
        "title": " Separate data uploading from job submission for DS2 cloud training and add support for multiple shards uploading.",
        "body": "- Separate data uploading from training job submission for DS2 cloud training.\r\n- Add supports for multiple shards packing and uploading.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "shanyi15",
        "created_at": "2017-08-15T10:16:17+00:00",
        "updated_at": "2018-08-15T09:58:49+00:00",
        "closed_at": "2018-08-15T09:58:49+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 206,
        "title": "generate_sequence_by_rnn_lm - Cuda Error: out of memory",
        "body": "Trying to use the generate_sequence_by_rnn_lm model for sequence prediction. But I have large vocabulary size about half million (non word). The GPU card has 12GB ram. I got memory error even with small batch size 32. Can this model handle large dictionary size - max_word_num = 500000?\r\n\r\n```text\r\nINFO 2017-08-15 12:57:05,733 train.py:95] dictionay size = 461546\r\nI0815 12:57:05.739673  4302 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1\r\nI0815 12:57:07.165385  4302 GradientMachine.cpp:85] Initing parameters..\r\nI0815 12:57:25.333416  4302 GradientMachine.cpp:92] Init parameters done.\r\n[INFO 2017-08-15 12:57:25,333 train.py:78] start training...\r\n[INFO 2017-08-15 12:57:28,632 train.py:58] Pass 0, Batch 0, Cost 257.150330, {'classification_error_evaluator': 1.0}\r\nF0815 12:57:49.568514  4302 hl_cuda_device.cc:273] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory\r\n*** Check failure stack trace: ***\r\n    @     0x7f96cf30c8bd  google::LogMessage::Fail()\r\n    @     0x7f96cf310415  google::LogMessage::SendToLog()\r\n    @     0x7f96cf30c3b3  google::LogMessage::Flush()\r\n    @     0x7f96cf31192e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f96cf2ce79c  hl_malloc_device()\r\n    @     0x7f96cf18fd06  paddle::GpuAllocator::alloc()\r\n    @     0x7f96cf260666  paddle::PoolAllocator::alloc()\r\n    @     0x7f96cf163614  paddle::GpuMemoryHandle::GpuMemoryHandle()\r\n    @     0x7f96cf16d094  paddle::GpuMatrix::resize()\r\n    @     0x7f96cf17db22  paddle::Matrix::resizeOrCreate()\r\n    @     0x7f96cf09a1ad  paddle::Layer::resetSpecifyOutput()\r\n    @     0x7f96cf09a311  paddle::Layer::reserveOutput()\r\n    @     0x7f96cf00e63f  paddle::FullyConnectedLayer::forward()\r\n    @     0x7f96cefdba10  paddle::NeuralNetwork::forward()\r\n    @     0x7f96cefc9033  paddle::GradientMachine::forwardBackward()\r\n    @     0x7f96cf2e7caa  GradientMachine::forwardBackward()\r\n    @     0x7f96cef609ee  _wrap_GradientMachine_forwardBackward\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x5247ea  PyEval_EvalFrameEx\r\n    @           0x567d14  (unknown)\r\n    @           0x465bf4  PyRun_FileExFlags\r\n    @           0x46612d  PyRun_SimpleFileExFlags\r\n    @           0x466d92  Py_Main\r\n    @     0x7f96d0ceaf45  __libc_start_main\r\nAborted (core dumped)\r\n```",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "shanyi15",
        "created_at": "2017-08-15T17:50:50+00:00",
        "updated_at": "2018-08-15T09:58:46+00:00",
        "closed_at": "2018-08-15T09:58:46+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 207,
        "title": "lambda_cost NCG_DIFF 计算公式为什么和论文中公式不一样",
        "body": "Paddle/paddle/gserver/layers/CostLayer.cpp 中 lambda_cost NCG_DIFF 计算：\r\n        dcgDif = (std::pow(2, score_i) - std::pow(2, score_j)) /  (std::log(i + 2) - std::log(j + 2));\r\nlambdarank paper 中\r\n       dcgDif = (2^score_i - 2^score_j) * (1/log(i+2) - 1/ log(j+2))\r\n为什么有这种差异？\r\n（自己实现lambda cost玩发现效果还不如rank net。看到如上差异，难道原因在此？）",
        "state": "closed",
        "user": "superzhangmch",
        "closed_by": "shanyi15",
        "created_at": "2017-08-16T03:45:29+00:00",
        "updated_at": "2018-08-15T09:58:40+00:00",
        "closed_at": "2018-08-15T09:58:40+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 213,
        "title": "Add GRU option (instead of only simple RNN) for DS2 model.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "lcy-seso",
        "created_at": "2017-08-21T14:05:41+00:00",
        "updated_at": "2017-09-04T05:31:43+00:00",
        "closed_at": "2017-09-04T05:31:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 209,
        "title": "Some notes on experiment with MFCC",
        "body": "[MFCCs](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) (Mel Frequency Cepstral Coefficents) are a widely used representation of audio data in ASR (automic speech recognition), which are thought as a better approximation of the human auditory system's response than the linearly-spaced frequency spectrum. And many ASR systems achieved state-of-the-art performance by taking advantage of MFCCs. Considering Deep Speech 2 only taking the power spectrum as its input feature, it is worth evaluating the performance of MFCCs on the same network.  \r\n\r\n**The experimental results will be continuously updated in this issue.**\r\n \r\n The MFCC feature used here is a 39-dimension vector, consisting of the 13 basic cepstral coefficents and the first and second order derivatives, with the first component replaced by the energy of the frame. At the first attempt, the training process follows the default setting totally in ```train.py``` except adjusting the kernel and padding size in conv layers to adapt the new feature dimension. But the convergence gets a little bit slow. Then inspired by [Wav2letter](https://arxiv.org/pdf/1609.03193.pdf), retrain the model with no striding in the feature dimension. And a relative better convergence appears, as shown in the figure below. \r\n \r\n![mfcc_traing_result](https://user-images.githubusercontent.com/3064195/29394324-3094b122-833c-11e7-839d-e716056d3306.png)\r\n\r\n\r\nThe validation cost doesn't decay significantly at the end, and the training is in progress with smaller learning rate after pass 25. The rest part of learning curves will be appended later.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2017-08-17T03:03:07+00:00",
        "updated_at": "2020-06-23T17:28:15+00:00",
        "closed_at": "2018-08-15T09:58:36+00:00",
        "comments_count": [
            "shanyi15",
            "pbansal5"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 217,
        "title": "when using rankloss, learning performance of DSSM model is terrible.",
        "body": "- DSSM 模型命令行指定 `model_type=rank` 时，训练结果非常糟糕，我觉得可能存在以下问题：\r\n----\r\n1. DSSM 指定 `model_type=rank` 时，实际上就是经典的Pairwise RankNet。\r\n2. 在RankNet中，神经网络对一个输入的”对“进行打分，学习一个标量分值作为输出。\r\n3. 以下是 RankLoss 计算的部分公式：\r\n$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$\r\n$$o_{ij} = o_i - o_j$$\r\n\r\n4. 在上面的公式中，网络对左右一对输入进行打分，分值相减得到 $o_{ij}$，$o_{ij}$ 通过指数公式转化为概率，最终的损失函数为基于概率的交叉熵。\r\n5. ranknet的优化目标是希望推开左右两部分网络的得分，使他们之间差异尽可能大以提高泛化能力，一般不对$o_{i,j}$做值域的限制；一些含有指数项的激活函数，也可能会影响梯度的回传；\r\n6. 目前 Paddle 的dssm 模型使用 fc + cosine 的方式得到一维得分 $o_{i,j}$ ，cosine 的值域受限，落在 [-1,1]之内，于是会出现下图的情况，下图是[-1, 1] 区间上，$o_{ij}$ 和 $P_{ij}$ 变化曲线：\r\n\r\n![image](https://user-images.githubusercontent.com/5842774/29695058-e5618134-8972-11e7-800c-cbbe95d75bf2.png)\r\n\r\n可以看出来，即使落在了$P_{ij}$的两个极端，对相关和不相关的区分力也是非常弱的。\r\n\r\n我认为DSSM模型使用rankloss时，目前配置部分有问题，不应该使用cosine 得到一维分值，而是使用全连接映射到一维，并且不使用任何非线性激活。\r\n\r\nltr 目录下的 ranknet，配置更为合理：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/ltr/ranknet.py#L32",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-08-25T00:57:06+00:00",
        "updated_at": "2017-12-10T08:33:11+00:00",
        "closed_at": "2017-10-31T09:24:52+00:00",
        "comments_count": [
            "lcy-seso",
            "fanfannothing"
        ],
        "labels": [
            "enhancement",
            "user",
            "need be discussed"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 218,
        "title": "Retune parameters for CTC beam search decoder",
        "body": "The beam search decoder for deployment in [PR#139](https://github.com/PaddlePaddle/models/pull/139) takes advantage of trie tree as the data structure for prefix search and finite-state transducers for spelling correction, which speedup the decoding process and lower the WER. With a larger (compared with the model in [#115](https://github.com/PaddlePaddle/models/issues/115) ) well-trained acoustic model, parameters ```alpha``` and ```beta``` for the decoder are retuned on the development dataset of LibriSpeech, as shown in the figure below.  \r\n\r\n![tune on larger model](https://user-images.githubusercontent.com/3064195/29906109-676990be-8e45-11e7-9cab-5a1d758dce19.png)\r\n\r\n\r\n- ```alpha```: language model weight\r\n- ```beta```: word insertion weight\r\n- ```WER```: word error rate \r\n\r\nAs usual, the WER is mainly affected by the variation of parameter ```alpha```. And the optimal parameters pair appears at ```(alpha,beta) = (2.15, 0.35)```, which produces a minimum WER **7.87%** on the test dataset of LibriSpeech, and attenuates the WER by **0.8%** compared to the prototype decoder in Python. ",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2017-08-31T04:10:59+00:00",
        "updated_at": "2018-08-15T09:58:28+00:00",
        "closed_at": "2018-08-15T09:58:28+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 226,
        "title": "Reduce the config parsing codes for DS2 and make it looks cleaner.",
        "body": "Shorten the code:\r\n```\r\nparser.add_argument(\r\n    \"--num_passes\",\r\n    default=200,\r\n    type=int,\r\n    help=\"Training pass number. (default: %(default)s)\")\r\n```\r\nto\r\n```\r\nadd_arg('num_passes',       int,    200,    \"# of training epochs.\")\r\n```\r\n\r\nAnd align the columns to make it looks cleaner.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-04T16:25:44+00:00",
        "updated_at": "2017-09-05T08:42:16+00:00",
        "closed_at": "2017-09-05T08:42:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 216,
        "title": "\"gen_chinese_poetry\" load model slow",
        "body": "branch https://github.com/lcy-seso/models/tree/gen_chinese_poetry\r\nrun `generate.py`\r\n- model size 193MB\r\n- load time 12s\r\n\r\nSlow code\r\n```python\r\n    with gzip.open(model_path, \"r\") as f:\r\n        parameters = paddle.parameters.Parameters.from_tar(f)\r\n```",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-08-23T14:51:23+00:00",
        "updated_at": "2018-08-15T09:58:33+00:00",
        "closed_at": "2018-08-15T09:58:33+00:00",
        "comments_count": [
            "llxxxll",
            "lcy-seso",
            "reyoung",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "enhancement",
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 232,
        "title": " Re-organize folder structure and hierarchy for DS2.",
        "body": "整理DeepSpeech2 目录结构，使之更合理和整洁。",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-06T06:44:10+00:00",
        "updated_at": "2017-09-06T12:32:21+00:00",
        "closed_at": "2017-09-06T12:32:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 229,
        "title": "每个 Pass 的 Test 中，各个 node 的 cost 不一致。",
        "body": "日志\r\n```\r\nTue Sep  5 15:16:57 2017[1,37]<stdout>:Test with Pass 2, Cost 4.149080, {}\r\nTue Sep  5 15:17:00 2017[1,34]<stdout>:Test with Pass 2, Cost 4.421460, {}\r\nTue Sep  5 15:17:02 2017[1,46]<stdout>:Test with Pass 2, Cost 4.200185, {}\r\nTue Sep  5 15:17:08 2017[1,39]<stdout>:Test with Pass 2, Cost 4.398165, {}\r\nTue Sep  5 15:17:09 2017[1,17]<stdout>:Test with Pass 2, Cost 4.678599, {}\r\n```\r\n网络配置\r\n```Python\r\ndef fc_net(dict_dim, class_dim=2):\r\n    \"\"\"\r\n    dnn network definition\r\n\r\n    :param dict_dim: size of word dictionary\r\n    :type input_dim: int\r\n    :params class_dim: number of instance class\r\n    :type class_dim: int\r\n    \"\"\"\r\n\r\n    # input layers\r\n    data = paddle.layer.data(\"word\", paddle.data_type.sparse_binary_vector(dict_dim))\r\n    label = paddle.layer.data(\"label\", paddle.data_type.dense_vector(1))\r\n\r\n    # hidden\r\n    h_size = 128\r\n    h = paddle.layer.fc(\r\n        input=data,\r\n        size=h_size,\r\n        act=paddle.activation.Tanh())\r\n\r\n    # output layer\r\n    output = paddle.layer.fc(\r\n        input=h,\r\n        size=1,\r\n        act=paddle.activation.Linear())\r\n\r\n    cost = paddle.layer.smooth_l1_cost(input=output, label=label)\r\n\r\n    return cost, output, label\r\n```\r\n训练参数\r\n```Python\r\n    parameters = paddle.parameters.create(cost)\r\n    # create optimizer\r\n    adagrad_optimizer = paddle.optimizer.DecayedAdaGrad(\r\n        learning_rate=0.01,\r\n        regularization=paddle.optimizer.L2Regularization(rate=0.01),\r\n        rho=0.95,\r\n        epsilon=1e-6,\r\n     )\r\n\r\n    # create trainer\r\n    trainer = paddle.trainer.SGD(\r\n        cost=cost,\r\n        parameters=parameters,\r\n        update_equation=adagrad_optimizer\r\n    )\r\n```",
        "state": "closed",
        "user": "FrankRouter",
        "closed_by": "FrankRouter",
        "created_at": "2017-09-05T08:20:57+00:00",
        "updated_at": "2017-09-05T09:23:41+00:00",
        "closed_at": "2017-09-05T09:23:41+00:00",
        "comments_count": [
            "FrankRouter"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 230,
        "title": "Paddle/DeepSpeech2 数据读入上的一些问题",
        "body": "# 问题描述\r\n在这个 repo 的 DeepSpeech2 代码中，应用层的 _padding_batch 函数，框架层的\r\n feeder 和 gradient_machine.forwardBackward 是在一个线程顺序做的。这种方案在速度上，不是最优的。因为前两者耗时较大(都是需要0.3s量级的事情)，而且本来可以 pipeline 地并行做掉。\r\n\r\n# 我的方案\r\n## 方案概述\r\nStep 1: 把 DataFeeder 拆成两部分，第一部分是 list of ndarrays to one big ndarray，第二部分是 the final ndarray to paddle.argument\r\nStep 2: 把 instance 的 reading 和 processing, batch 的 padding, 和刚才拆出来的 DataFeeder 第一部分(list of ndarrays to one big ndarray)放在第一个**进程**中，把生成的 ndarray 训练数据通过 pipe 传递到第二个进程，第二个进程从 pipe 读数据，然后做训练。\r\n## 设计原因\r\n我的方案几个设计上的考虑：\r\n1. 分进程的原因：担心 GIL\r\n2. 拆 Feeder 的原因：ndarray 可以从 pipe 用 pickle 传递，但是 paddle.argument 不能跨进程传递\r\n\r\n## 操作方式\r\n把框架层的代码(trainer.py, data_feeder.py, dataprovider_converter.py)拷贝到应用层，然后做了很多修改。\r\n## 实验结果 \r\n我测试我的这份加速代码的结果：单batch平均(第10个到第20个)从2.5s下降到1.8s(很接近forwardbackward时间了)，其中 reader + feeder 时间 从 0.65s 降低到 0.15s。端到端加速1/3，效果明显。\r\n# 汇总观点\r\n1. 现在 Paddle DataFeeder 的设计可能是有问题的，在框架层面限制一块挺大的计算量必须在 forward/backward 前完成，对速度影响较大。\r\n2. 现在 DS2 batch_reader 里面的 padding 也是在 forward/backward 线程做的，这个倒是可以在应用层而不是框架层直接改掉。\r\n\r\n可以一起讨论一下观点～",
        "state": "closed",
        "user": "lispc",
        "closed_by": "shanyi15",
        "created_at": "2017-09-05T13:30:02+00:00",
        "updated_at": "2018-08-15T09:58:21+00:00",
        "closed_at": "2018-08-15T09:58:21+00:00",
        "comments_count": [
            "xinghai-sun",
            "xinghai-sun",
            "shanyi15"
        ],
        "labels": [
            "help wanted",
            "need be discussed"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 234,
        "title": "Memory leaking of deepspeech2",
        "body": "Here is my command:\r\n`python train.py --use_gpu=False --num_passes=1 --trainer_count=1 --batch_size=512 --num_iter_print=1 --num_proc_data=4`\r\n\r\nI did not train with GPU, and only give 1`trainer_count` and 4 `num_proc_data`, which should makes the thing easy.\r\n\r\nTotal available memory of my system is 62.6G.\r\n\r\nWhen stat to train,  I found the memory percent from ~50% increasing to 99%, then killed by system.\r\n\r\nIs this possible that some memory leaking ?\r\n\r\n> \r\n> Pass: 0, Batch: 1, TrainCost: 221.743195\r\n> I0907 17:58:52.262146 50789 Thread.h:271] SyncThreadPool worker thread 0\r\n> \r\n> Pass: 0, Batch: 2, TrainCost: 745.176697\r\n> \r\n> Pass: 0, Batch: 3, TrainCost: 217.676758\r\n> Killed\r\n\r\nPaddlePaddle version:\r\n\r\n> commit a072ab9e74227361421e6b1fdc167b6709fcdf87\r\nDate:   Thu Sep 7 11:10:47 2017 +0800\r\n\r\nDeepSpeech2 version:\r\n\r\n> commit acea40b6d1a23cb4923dc82ad7c0428a832406e2\r\nDate:   Wed Sep 6 20:32:20 2017 +0800\r\n",
        "state": "closed",
        "user": "tensor-tang",
        "closed_by": "shanyi15",
        "created_at": "2017-09-07T10:43:54+00:00",
        "updated_at": "2018-08-15T09:58:18+00:00",
        "closed_at": "2018-08-15T09:58:18+00:00",
        "comments_count": [
            "tensor-tang",
            "xinghai-sun",
            "pkuyym",
            "tensor-tang",
            "shanyi15"
        ],
        "labels": [
            "need be discussed"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 235,
        "title": "Preparing Data in deep_speech2 README error",
        "body": "In https://github.com/PaddlePaddle/models/tree/develop/deep_speech_2#preparing-data\r\n```\r\ncd datasets\r\nsh run_all.sh\r\ncd ..\r\n```\r\nBut there is no `datasets` directory currently, how do we prepare the data?",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2017-09-07T11:47:39+00:00",
        "updated_at": "2018-08-15T09:58:14+00:00",
        "closed_at": "2018-08-15T09:58:14+00:00",
        "comments_count": [
            "xinghai-sun",
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 244,
        "title": "Add a new mandarin dataset aishell",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-12T04:04:21+00:00",
        "updated_at": "2017-09-19T05:13:03+00:00",
        "closed_at": "2017-09-19T05:13:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 237,
        "title": "prepare_data.sh error",
        "body": "```\r\ncd models/deep_speech_2/examples/librispeech\r\nsh prepare_data.sh\r\n\r\n~/models/deep_speech_2 ~/models/deep_speech_2/examples/librispeech\r\nDownloading http://www.openslr.org/resources/12/test-clean.tar.gz ...\r\n--2017-09-07 20:11:30--  http://www.openslr.org/resources/12/test-clean.tar.gz\r\nResolving www.openslr.org... 35.184.122.207\r\nConnecting to www.openslr.org|35.184.122.207|:80... connected.\r\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\r\n\r\n    The file is already fully retrieved; nothing to do.\r\n\r\n\r\nMD5 Chesksum ~/.cache/paddle/dataset/speech/Libri/test-clean/test-clean.tar.gz ...\r\nTraceback (most recent call last):\r\n  File \"data/librispeech/librispeech.py\", line 177, in <module>\r\n    main()\r\n  File \"data/librispeech/librispeech.py\", line 142, in main\r\n    manifest_path=args.manifest_prefix + \".test-clean\")\r\n  File \"data/librispeech/librispeech.py\", line 127, in prepare_dataset\r\n    filepath = download(url, md5sum, target_dir)\r\n  File \"data/librispeech/librispeech.py\", line 72, in download\r\n    if not md5file(filepath) == md5sum:\r\n  File \"/home/luotao02/.jumbo/lib/python2.7/site-packages/paddle/v2/dataset/common.py\", line 55, in md5file\r\n    f = open(fname, \"rb\")\r\nIOError: [Errno 2] No such file or directory: '~/.cache/paddle/dataset/speech/Libri/test-clean/test-clean.tar.gz'\r\nPrepare LibriSpeech failed. Terminated.\r\n```\r\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-07T12:47:50+00:00",
        "updated_at": "2017-09-07T14:07:06+00:00",
        "closed_at": "2017-09-07T14:07:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 245,
        "title": "Completely rewrite README.md for DS2.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-12T06:51:45+00:00",
        "updated_at": "2017-09-13T09:40:56+00:00",
        "closed_at": "2017-09-13T09:40:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 243,
        "title": "[new feature request]half-precision support",
        "body": "As the DS2 paper mentioned:\r\n\r\n> Our deployment system evaluates RNNs in half-precision\r\n> arithmetic, which has no measurable accuracy impact, but\r\n> significantly improves efficiency. We wrote our own 16-bit\r\n> matrix-matrix multiply routines for this task, substantially\r\n> improving throughput for our relatively small batches.\r\n\r\nSo have you implemented this half-precision arithmetic?\r\nDoes it take the advantages of CUDA's half-precision ability \r\n(https://devblogs.nvidia.com/parallelforall/new-features-cuda-7-5/\r\nhttps://devblogs.nvidia.com/parallelforall/mixed-precision-programming-cuda-8/)?",
        "state": "closed",
        "user": "chenjiasheng",
        "closed_by": "chenjiasheng",
        "created_at": "2017-09-11T03:51:13+00:00",
        "updated_at": "2017-09-11T05:45:44+00:00",
        "closed_at": "2017-09-11T05:45:44+00:00",
        "comments_count": [
            "wangkuiyi",
            "chenjiasheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 255,
        "title": "Release librispeech model url for DS2.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-15T11:16:14+00:00",
        "updated_at": "2017-09-15T11:21:32+00:00",
        "closed_at": "2017-09-15T11:21:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 257,
        "title": "Publish urls for Aishell model and Chinese language model.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-15T11:52:33+00:00",
        "updated_at": "2017-09-15T11:59:10+00:00",
        "closed_at": "2017-09-15T11:59:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 254,
        "title": "vocabulary should contain blank to make the decoder API easy to use.",
        "body": "https://github.com/PaddlePaddle/models/blob/8b5c739a847b03ae8e7daa10f5311ef8cd12290b/deep_speech_2/model_utils/decoder.py#L87\r\n\r\nIf vocabulary dosen't contain blank, we have:\r\n```\r\nvocabulary=['a', 'b', ..., 'z', ' ', '.']\r\nlen(vocabulary) = 28\r\nlen(prob_list) = 29\r\n```\r\n\r\nThen at line 135,\r\n```\r\nnew_char = vocabulary[c]\r\n```\r\nhere `c` ranges from 0 to `len(prob_list)`, but `vocabulary[28]` causes index out of range.\r\n\r\n\r\nTo use this decoder, one have to make the vocabulary a **dict** indexed from 1 instead of a **list** indexed from 0, in spite of that the doc suggests `vocabulary` to be a list.\r\n```\r\n    :param vocabulary: Vocabulary list.\r\n    :type vocabulary: list\r\n```\r\n\r\nThis is really confusing.\r\n\r\n@xinghai-sun \r\n@kuke \r\n",
        "state": "closed",
        "user": "chenjiasheng",
        "closed_by": "chenjiasheng",
        "created_at": "2017-09-15T03:12:17+00:00",
        "updated_at": "2017-09-18T02:20:01+00:00",
        "closed_at": "2017-09-18T02:20:01+00:00",
        "comments_count": [
            "kuke",
            "chenjiasheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 259,
        "title": "In DS2, examples/run_infer_golden.sh continues to run if model download fails",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "kuke",
        "created_at": "2017-09-15T15:19:07+00:00",
        "updated_at": "2017-09-15T15:42:44+00:00",
        "closed_at": "2017-09-15T15:42:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 260,
        "title": "Add \"Experiment\" section and \"Models Released\" section to README.md doc of DS2.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "wangkuiyi",
        "created_at": "2017-09-15T15:20:36+00:00",
        "updated_at": "2017-09-16T22:09:28+00:00",
        "closed_at": "2017-09-16T22:09:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 275,
        "title": "Add profile.sh script for multi-gpu profiling for DS2.",
        "body": "Provide a script doing experiments in https://github.com/PaddlePaddle/Paddle/issues/3137#issuecomment-320996396",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-18T10:06:27+00:00",
        "updated_at": "2017-09-18T13:21:44+00:00",
        "closed_at": "2017-09-18T13:21:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 277,
        "title": "Add optimized decoder for the deployment of DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-18T12:14:10+00:00",
        "updated_at": "2017-09-18T17:27:56+00:00",
        "closed_at": "2017-09-18T17:27:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 268,
        "title": "Deep Speech Model will core dump when using nvidia-docker",
        "body": "The log as below. It seems that the same memory is operated by C++ and Python.\r\n\r\n\r\n```text\r\nroot@53ac34831359:/ds2/examples/librispeech# bash run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 64\r\ndev_manifest: data/librispeech/manifest.dev\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/librispeech/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 12\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/libri\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntrain_manifest: data/librispeech/manifest.train\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/librispeech/vocab.txt\r\n------------------------------------------------\r\nI0917 06:55:44.676560  8826 Util.cpp:166] commandline:  --use_gpu=1 --trainer_count=1\r\n[INFO 2017-09-17 06:55:53,917 layers.py:2539] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-09-17 06:55:53,918 layers.py:3062] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-09-17 06:55:53,919 layers.py:2539] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-09-17 06:55:53,920 layers.py:3062] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n/ds2/checkpoints/libri\r\nI0917 06:55:53.998572  8826 GradientMachine.cpp:85] Initing parameters..\r\nI0917 06:55:55.796345  8826 GradientMachine.cpp:92] Init parameters done.\r\n...........*** Aborted at 1505631395 (unix time) try \"date -d @1505631395\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x50) received by PID 8826 (TID 0x7f646527a700) from PID 80; stack trace: ***\r\n    @     0x7f656ec1f390 (unknown)\r\n    @     0x7f656ee3773c (unknown)\r\n    @     0x7f656ee40851 (unknown)\r\n    @     0x7f656ee3b564 (unknown)\r\n    @     0x7f656ee3fda9 (unknown)\r\n    @     0x7f656e98756d (unknown)\r\n    @     0x7f656ee3b564 (unknown)\r\n    @     0x7f656e987624 __libc_dlopen_mode\r\n    @     0x7f656e959a45 (unknown)\r\n    @     0x7f656ec1ca99 __pthread_once_slow\r\n    @     0x7f656e959b64 backtrace\r\n    @     0x7f656c945ec3 check_callers.part.0\r\n    @     0x7f656c946546 can_elide_temp_unary\r\n    @     0x7f656c930f33 array_power\r\n    @           0x55372c PyNumber_Power\r\n    @           0x4c6050 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4de8b8 (unknown)\r\n```",
        "state": "closed",
        "user": "reyoung",
        "closed_by": "kuke",
        "created_at": "2017-09-17T06:58:55+00:00",
        "updated_at": "2017-09-30T08:03:22+00:00",
        "closed_at": "2017-09-30T08:03:22+00:00",
        "comments_count": [
            "xinghai-sun",
            "reyoung",
            "kuke"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 283,
        "title": "Enrich the tuning section of README in DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-19T04:20:27+00:00",
        "updated_at": "2017-09-19T05:12:38+00:00",
        "closed_at": "2017-09-19T05:12:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 273,
        "title": "Add Dockerfile to build ds2 Docker Image",
        "body": "",
        "state": "closed",
        "user": "Yancey0623",
        "closed_by": "shanyi15",
        "created_at": "2017-09-18T07:31:54+00:00",
        "updated_at": "2018-08-15T09:58:11+00:00",
        "closed_at": "2018-08-15T09:58:11+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 278,
        "title": "Add multi-gpu profiling results to REAME doc for DS2.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-18T13:22:55+00:00",
        "updated_at": "2017-09-18T15:59:29+00:00",
        "closed_at": "2017-09-18T15:59:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 285,
        "title": "Update LibriSpeech experimental results for DS2.",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-09-19T04:46:59+00:00",
        "updated_at": "2017-09-19T05:02:36+00:00",
        "closed_at": "2017-09-19T05:02:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 288,
        "title": "Add training scripts for Aishell",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-19T05:07:38+00:00",
        "updated_at": "2017-09-19T06:49:01+00:00",
        "closed_at": "2017-09-19T06:49:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 290,
        "title": "Add test scripts for Aishell",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-19T05:08:14+00:00",
        "updated_at": "2017-09-19T07:36:32+00:00",
        "closed_at": "2017-09-19T07:36:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 289,
        "title": "Add infer scripts for Aishell",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-19T05:07:56+00:00",
        "updated_at": "2017-09-19T08:49:02+00:00",
        "closed_at": "2017-09-19T08:49:02+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 300,
        "title": "Enable to output figure of error surface after tuning",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-20T04:01:45+00:00",
        "updated_at": "2017-09-27T18:04:47+00:00",
        "closed_at": "2017-09-27T18:04:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 297,
        "title": "Add doc for mandarin LM",
        "body": "#### Mandarin LM\r\n\r\nDifferent from word-based language model, mandarin language model is character-based where each token is a chinese character. We use an internal corpus to train the released mandarin language model. This corpus contains billions of tokens. The preprocessing has small difference from english language model and all steps are:\r\n\r\n  * The beginning and trailing whitespace characters are removed.\r\n  * English punctuations and chinese punctuations are removed.\r\n  * Insert a whitespace character between two tokens.\r\n\t\r\nPlease notice that the released language model only contains chinese simplified characters. When preprocessing done we can begin to train the language model. The key training parameters are '-o 5 --prune 0 1 2 4 4'. Please refer above section for the meaning of each parameter. We also convert the arpa file to binary file using default settings.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-19T13:02:24+00:00",
        "updated_at": "2017-09-21T03:00:15+00:00",
        "closed_at": "2017-09-21T03:00:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 299,
        "title": "Improve params tuning strategy for CTC beam search decoder",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-20T04:00:54+00:00",
        "updated_at": "2017-09-25T11:30:21+00:00",
        "closed_at": "2017-09-25T11:30:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 294,
        "title": "Add doc for english LM training",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-19T08:40:33+00:00",
        "updated_at": "2017-09-19T12:30:15+00:00",
        "closed_at": "2017-09-19T12:30:15+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 296,
        "title": "编写DNN模型进行Regression训练，不收敛，求助排查原因。",
        "body": "基于CTR模型的Demo修改建立DNN网络进行Regression预测，训练结果不收敛，infer的结果也不正确。帮忙排查原因。\r\n\r\n训练输出如下：\r\n```text\r\nWARNING:paddle:Pass 0, Samples 0, Cost 11620.388000, {}\r\nWARNING:paddle:Test 0-0, Cost 5308.589006, {}\r\nWARNING:paddle:Pass 1, Samples 0, Cost 12167.511000, {}\r\nWARNING:paddle:Test 1-0, Cost 5269.448265, {}\r\nWARNING:paddle:Pass 2, Samples 0, Cost 12159.679000, {}\r\nWARNING:paddle:Test 2-0, Cost 5264.473139, {}\r\nWARNING:paddle:Pass 3, Samples 0, Cost 12154.542000, {}\r\nWARNING:paddle:Test 3-0, Cost 5261.147334, {}\r\nWARNING:paddle:Pass 4, Samples 0, Cost 12151.005000, {}\r\nWARNING:paddle:Test 4-0, Cost 5258.846167, {}\r\nWARNING:paddle:Pass 5, Samples 0, Cost 12148.595000, {}\r\nWARNING:paddle:Test 5-0, Cost 5257.272729, {}\r\nWARNING:paddle:Pass 6, Samples 0, Cost 12146.910000, {}\r\nWARNING:paddle:Test 6-0, Cost 5256.165883, {}\r\nWARNING:paddle:Pass 7, Samples 0, Cost 12145.686000, {}\r\nWARNING:paddle:Test 7-0, Cost 5255.357524, {}\r\nWARNING:paddle:Pass 8, Samples 0, Cost 12144.765000, {}\r\nWARNING:paddle:Test 8-0, Cost 5254.747666, {}\r\nWARNING:paddle:Pass 9, Samples 0, Cost 12144.054000, {}\r\nWARNING:paddle:Test 9-0, Cost 5254.274953, {}\r\n```\r\n\r\n模型相关代码：\r\n```python\r\n# 模型定义\r\nclass DNNmodel(object):\r\n    def __init__(self,\r\n                 dnn_layer_dims,\r\n                 dnn_input_dim,\r\n                 is_infer=False):\r\n        self.dnn_layer_dims = dnn_layer_dims\r\n        self.dnn_input_dim = dnn_input_dim\r\n        self.is_infer = is_infer\r\n\r\n        self._declare_input_layers()\r\n        self.dnn = self._build_dnn_submodel_(self.dnn_layer_dims)\r\n        self.model = self._build_regression_model(self.dnn)\r\n\r\n    def _declare_input_layers(self):\r\n        self.dnn_merged_input = layer.data(\r\n            name='dnn_input',\r\n            type=dtype.sparse_vector(self.dnn_input_dim))\r\n\r\n        if not self.is_infer:\r\n            self.target = paddle.layer.data(\r\n                name='target', type=dtype.dense_vector(1))\r\n\r\n    def _build_dnn_submodel_(self, dnn_layer_dims):\r\n        dnn_embedding = layer.fc(\r\n            input=self.dnn_merged_input, size=dnn_layer_dims[0])\r\n        _input_layer = dnn_embedding\r\n        for i, dim in enumerate(dnn_layer_dims[1:]):\r\n            fc = layer.fc(\r\n                input=_input_layer,\r\n                size=dim,\r\n                act=paddle.activation.Relu(),\r\n                name='dnn-fc-%d' % i)\r\n            _input_layer = fc\r\n        return _input_layer\r\n\r\n    def _build_regression_model(self, dnn):\r\n        self.output = layer.fc(\r\n            input=dnn, size=1, act=paddle.activation.Sigmoid())\r\n        if not self.is_infer:\r\n            self.train_cost = paddle.layer.square_error_cost(\r\n                input=self.output, label=self.target)\r\n        return self.output\r\n```\r\n# 模型训练\r\n```python\r\ndnn_layer_dims = [128, 64, 32, 1]\r\ndef train():\r\n    args = parse_args()\r\n    paddle.init(use_gpu=False, trainer_count=1)\r\n    dnn_input_dim = reader.load_data_meta(args.data_meta_file)\r\n\r\n    # create ctr model.\r\n    model = DNNmodel(\r\n        dnn_layer_dims,\r\n        dnn_input_dim,\r\n        is_infer=False)\r\n\r\n    params = paddle.parameters.create(model.train_cost)\r\n    optimizer = paddle.optimizer.AdaGrad()\r\n\r\n    trainer = paddle.trainer.SGD(\r\n        cost=model.train_cost, parameters=params, update_equation=optimizer)\r\n\r\n    dataset = reader.Dataset()\r\n\r\n    def __event_handler__(event):\r\n        if isinstance(event, paddle.event.EndIteration):\r\n            num_samples = event.batch_id * args.batch_size\r\n            if event.batch_id % 100 == 0:\r\n                logger.warning(\"Pass %d, Samples %d, Cost %f, %s\" % (\r\n                    event.pass_id, num_samples, event.cost, event.metrics))\r\n\r\n            if event.batch_id % 1000 == 0:\r\n                if args.test_data_path:\r\n                    result = trainer.test(\r\n                        reader=paddle.batch(\r\n                            dataset.test(args.test_data_path),\r\n                            batch_size=args.batch_size),\r\n                        feeding=reader.feeding_index)\r\n                    logger.warning(\"Test %d-%d, Cost %f, %s\" %\r\n                                   (event.pass_id, event.batch_id, result.cost,\r\n                                    result.metrics))\r\n\r\n                path = \"{}-pass-{}-batch-{}-test-{}.tar.gz\".format(\r\n                    args.model_output_prefix, event.pass_id, event.batch_id,\r\n                    result.cost)\r\n                with gzip.open(path, 'w') as f:\r\n                    params.to_tar(f)\r\n\r\n    trainer.train(\r\n        reader=paddle.batch(\r\n            paddle.reader.shuffle(\r\n                dataset.train(args.train_data_path), buf_size=500),\r\n            batch_size=args.batch_size),\r\n        feeding=reader.feeding_index,\r\n        event_handler=__event_handler__,\r\n        num_passes=args.num_passes)\r\n```",
        "state": "closed",
        "user": "Fangkey",
        "closed_by": "shanyi15",
        "created_at": "2017-09-19T09:38:38+00:00",
        "updated_at": "2018-08-15T10:08:28+00:00",
        "closed_at": "2018-08-15T10:08:28+00:00",
        "comments_count": [
            "Fangkey",
            "wanghaoshuang",
            "Fangkey",
            "wanghaoshuang",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 301,
        "title": "Failed to download the Chinese LM ",
        "body": "The DeepSpeech2 LM cannot be downloaded. I tried `download_lm_ch.sh` or `wget -c 'http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e' -O ./zh_giga.no_cna_cmn.prune01244.klm` directly more than five times yesterday and today from baiduyun server and my own server, every downloading task will fail after exact 60s. Is there any downloading related limit on the download server side?   \r\nThe error msg is like below:\r\n```bash\r\nbash -x download_lm_ch.sh\r\n+ source ../../utils/utility.sh\r\n+ URL='http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e'\r\n+ MD5=29e02312deb2e59b3c8686c7966d4fe3\r\n+ TARGET=./zh_giga.no_cna_cmn.prune01244.klm\r\n+ echo 'Download language model ...'\r\nDownload language model ...\r\n+ download 'http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e' 29e02312deb2e59b3c8686c7966d4fe3 ./zh_giga.no_cna_cmn.prune01244.klm\r\n+ URL='http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e'\r\n+ MD5=29e02312deb2e59b3c8686c7966d4fe3\r\n+ TARGET=./zh_giga.no_cna_cmn.prune01244.klm\r\n+ '[' -e ./zh_giga.no_cna_cmn.prune01244.klm ']'\r\n++ awk '-F[ ]' '{print $1}'\r\n++ md5sum ./zh_giga.no_cna_cmn.prune01244.klm\r\n+ md5_result=f9daaa02705421bd5450fdfece0ea819\r\n+ '[' 29e02312deb2e59b3c8686c7966d4fe3 == f9daaa02705421bd5450fdfece0ea819 ']'\r\n+ wget -c 'http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e' -O ./zh_giga.no_cna_cmn.prune01244.klm\r\n--2017-09-20 12:21:10--  http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 202.108.23.203\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|202.108.23.203|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\nLength: unspecified [application/force-download]\r\nSaving to: ‘./zh_giga.no_cna_cmn.prune01244.klm’\r\n\r\n./zh_giga.no_cna_cmn.prune01244.klm           [                                                                 <=>                  ] 453.00M  8.66MB/s    in 60s     \r\n\r\n2017-09-20 12:22:27 (7.54 MB/s) - ‘./zh_giga.no_cna_cmn.prune01244.klm’ saved [475003342]\r\n\r\n+ '[' 0 -ne 0 ']'\r\n++ awk '-F[ ]' '{print $1}'\r\n++ md5sum ./zh_giga.no_cna_cmn.prune01244.klm\r\n+ md5_result=36e444b6aefa4f2286e40923dbe9e432\r\n+ '[' '!' 29e02312deb2e59b3c8686c7966d4fe3 == 36e444b6aefa4f2286e40923dbe9e432 ']'\r\n+ return 1\r\n+ '[' 1 -ne 0 ']'\r\n+ echo 'Fail to download the language model!'\r\nFail to download the language model!\r\n+ exit 1\r\n```",
        "state": "closed",
        "user": "lispc",
        "closed_by": "typhoonzero",
        "created_at": "2017-09-20T04:35:26+00:00",
        "updated_at": "2017-09-21T06:43:39+00:00",
        "closed_at": "2017-09-21T06:43:39+00:00",
        "comments_count": [
            "llxxxll",
            "Yancey0623",
            "pkuyym",
            "typhoonzero",
            "typhoonzero",
            "lispc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 302,
        "title": "图像分类的例子如何单机多卡进行训练",
        "body": "请问在如下目录下，执行修改train.py的如下行：\r\n```python\r\npaddle.init(use_gpu=True, trainer_count=1)为\r\npaddle.init(use_gpu=True, trainer_count=4)\r\n```\r\n是否可以在四个卡上数据并行训练？\r\n若可以，我设置的batch_size=1024，是四个卡总的batch_size,还是单卡的batch_size呢？\r\n在这个目录下我仅仅修改了如下注释行(训练和测试部分)：\r\n```python\r\nflowers.train()\r\n```\r\n为\r\n```python\r\n reader.train_reader('train.list')\r\n```\r\n和num_classes实现了在imagenet数据集上的训练，是否可行？\r\n期待您的回复。",
        "state": "closed",
        "user": "Sampson1107",
        "closed_by": "shanyi15",
        "created_at": "2017-09-20T09:01:44+00:00",
        "updated_at": "2018-08-15T10:08:24+00:00",
        "closed_at": "2018-08-15T10:08:24+00:00",
        "comments_count": [
            "Sampson1107",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 306,
        "title": "Speed bug in DeepSpeech2 data module",
        "body": "[This line](https://github.com/PaddlePaddle/models/blob/88edc4c9f7d232a8a574783dc3b01afc697d8f06/deep_speech_2/data_utils/data.py#L330)\r\n```\r\nbatch_manifest = list(sum(batch_manifest, ()))\r\n```  \r\nis O(N^2) complexity. It took **very very** significant time during training.\r\nI gave a small demo [gist](https://gist.github.com/lispc/682910e2c445b5fb33f59dd59f11dfb4) code for verifying this.\r\nAnd the [stackoverflow link](https://stackoverflow.com/questions/716477/join-list-of-lists-in-python#comment8701078_716489) also discussed this.   \r\n\r\nI will make a pull request to fix it.",
        "state": "closed",
        "user": "lispc",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-21T07:58:27+00:00",
        "updated_at": "2017-09-21T08:36:28+00:00",
        "closed_at": "2017-09-21T08:36:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 303,
        "title": "paddle.layer.mse_cost core dump:Segmentation fault",
        "body": "使用：\r\n```python\r\nlbl = paddle.layer.data(\"label\", paddle.data_type.integer_value(1))\r\nprob = paddle.layer.cos_sim(a=conv_1, b=fc, size=1)\r\ncost = paddle.layer.mse_cost(input=prob,label=lbl)\r\n```\r\n\r\n报错：\r\n```bash\r\nI0920 12:31:37.379825    38 GradientMachine.cpp:85] Initing parameters..\r\nI0920 12:32:03.477682    38 GradientMachine.cpp:92] Init parameters done.\r\nThread [140488122263296] Forwarding __mse_cost_0__,\r\n Aborted at 1505910723 (unix time) try \"date -d @1505910723\" if you are using GNU date \r\nPC: @                0x0 (unknown)\r\n SIGSEGV (@0x8) received by PID 38 (TID 0x7fc5f09f6700) from PID 8; stack trace: \r\n    @     0x7fc5f03d1390 (unknown)\r\n    @     0x7fc596951ed8 paddle::GpuMatrix::sumOfSquares()\r\n    @     0x7fc5967cd3e8 paddle::CostLayer::forward()\r\n    @     0x7fc596837e21 paddle::NeuralNetwork::forward()\r\n    @     0x7fc596b56940 GradientMachine::forwardBackward()\r\n    @     0x7fc59667ea34 _wrap_GradientMachine_forwardBackward\r\n    @           0x4cb45e PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c9d8f PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4c2509 PyEval_EvalCode\r\n    @           0x4f1def (unknown)\r\n    @           0x4ec652 PyRun_FileExFlags\r\n    @           0x4eae31 PyRun_SimpleFileExFlags\r\n    @           0x49e14a Py_Main\r\n    @     0x7fc5f0016830 __libc_start_main\r\n    @           0x49d9d9 _start\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\njob returned 139...setting pod return message...\r\n===============================\r\ntermination log wroted...\r\n==========================dtpcosv3-trainer-nd7kg==========================\r\nFailed trainer count beyond the threadhold: 0\r\n```",
        "state": "closed",
        "user": "xhzhang1212",
        "closed_by": "luotao1",
        "created_at": "2017-09-20T12:53:23+00:00",
        "updated_at": "2017-09-21T07:18:07+00:00",
        "closed_at": "2017-09-21T07:18:07+00:00",
        "comments_count": [
            "lcy-seso",
            "xhzhang1212"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 310,
        "title": "resnet模型配置的问题",
        "body": "目前resnet的配置有一些问题，可见 https://github.com/PaddlePaddle/models/issues/308#issuecomment-331384031",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-22T09:53:22+00:00",
        "updated_at": "2017-09-22T13:09:41+00:00",
        "closed_at": "2017-09-22T13:09:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 305,
        "title": "CTR Demo Bug",
        "body": "In train.py line 89, dataset.test(args.test_data_path) will set the data file path to test data. For in line 105, train function use the same dataset object, after one call for `__event_handler__` `if event.batch_id % 1000 == 0`, the dataset will change to test data permanently and the following training iteration will use test data. That is not what we expect, check please.",
        "state": "closed",
        "user": "Fangkey",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-21T03:48:18+00:00",
        "updated_at": "2017-09-26T12:31:31+00:00",
        "closed_at": "2017-09-26T12:31:31+00:00",
        "comments_count": [
            "lcy-seso",
            "ranqiu92"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 308,
        "title": "希望获取一份训练好的CNN模型",
        "body": "目前GPU还没有到货，训练CNN模型的时间成本比较大，希望能获取一份训练好的CNN模型用于图片特征提取； alexnet或者Resnet均可",
        "state": "closed",
        "user": "zhaodongwei",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-22T04:04:40+00:00",
        "updated_at": "2017-09-22T15:55:14+00:00",
        "closed_at": "2017-09-22T15:55:14+00:00",
        "comments_count": [
            "guoshengCS",
            "zhaodongwei",
            "zhaodongwei",
            "guoshengCS",
            "guoshengCS",
            "zhaodongwei",
            "lcy-seso"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 314,
        "title": "VoxForge dataset evaluation",
        "body": "Libri Model\r\n\r\n| Accent | Duration (hour) | WER |\r\n| --- | --- | -- |\r\n| American-Canadian |  69.9 | 0.133341 |\r\n| CommonWealth | 17.8 | 0.221014 |\r\n| Indian |  4.05 | 0.587939 |\r\n| European | 12.59 | 0.322141 |",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2017-09-25T07:18:04+00:00",
        "updated_at": "2018-08-15T10:08:21+00:00",
        "closed_at": "2018-08-15T10:08:21+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 315,
        "title": "failed to install swig_decoders",
        "body": "hi!\r\nwhen i run 'models/deep_speech_2/setup.sh'\r\nit always says ''module' object has no attribute 'ccompiler'' and failed to install swig_decoders\r\n![image](https://user-images.githubusercontent.com/6188797/30797554-101ed616-a209-11e7-9992-0297e9d812e4.png)\r\n\r\nmy env:\r\n centos:7.3\r\n python:2.7.5\r\n gcc: 4.8.5\r\n\r\nalso: when i run 'python setup.py install --num_processes 4' in 'models/deep_speech_2/decoders/swig'\r\nthe following error comes:\r\n![image](https://user-images.githubusercontent.com/6188797/30799129-63ead984-a20e-11e7-917e-38576e02390d.png)\r\n\r\nanyone can help me!\r\nvery thanks!",
        "state": "closed",
        "user": "zhaifly",
        "closed_by": "zhaifly",
        "created_at": "2017-09-25T07:49:18+00:00",
        "updated_at": "2018-05-17T06:43:51+00:00",
        "closed_at": "2017-09-26T06:25:18+00:00",
        "comments_count": [
            "pkuyym",
            "zhaifly",
            "kuke",
            "pkuyym",
            "zhaifly",
            "pkuyym",
            "zhaifly",
            "pkuyym",
            "zhaifly",
            "kuke",
            "zhaifly",
            "zhaifly",
            "zhaifly",
            "rituraj17",
            "dancinghui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 316,
        "title": "Aishell dataset evaluation.",
        "body": "First we compare the impact for larger language model under default golden settings.\r\n\r\n| Language Model | CER |\r\n| -- | -- |\r\n| Released | 0.094452 |\r\n| Larger | 0.088407 |",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2017-09-25T08:25:38+00:00",
        "updated_at": "2018-08-15T10:08:18+00:00",
        "closed_at": "2018-08-15T10:08:18+00:00",
        "comments_count": [
            "pkuyym",
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 323,
        "title": "README of models repo should be updated.",
        "body": "We haven't updated the README of models repo since we added many new models, including deep speech, SSD, GNR, and so on.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-26T12:29:32+00:00",
        "updated_at": "2017-11-07T05:21:13+00:00",
        "closed_at": "2017-11-07T05:21:13+00:00",
        "comments_count": [],
        "labels": [
            "enhancement",
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 317,
        "title": "We should unify the coding for target and inference result",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-25T08:28:38+00:00",
        "updated_at": "2017-10-25T08:04:37+00:00",
        "closed_at": "2017-10-25T08:04:37+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 319,
        "title": "add dense sequence example",
        "body": "Add dense sequence in how_to_use_capi for PaddlePaddle.",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2017-09-26T03:22:17+00:00",
        "updated_at": "2018-08-15T10:08:14+00:00",
        "closed_at": "2018-08-15T10:08:14+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 325,
        "title": "Should avoid repeated infer for the same batch in the tuning of DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-27T04:03:19+00:00",
        "updated_at": "2017-09-27T07:51:34+00:00",
        "closed_at": "2017-09-27T07:51:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 321,
        "title": "implementation of weighted cost",
        "body": "Say I have a prediction sequence $\\hat{Y} = [\\hat{y_1}, ... , \\hat{y_T}]$ which comes from paddle.v2.layer.lstmemory, a target sequence $Y = [y_1, ..., y_T]$ comes from \r\n```python\r\npaddle.layer.data( name='target', type=paddle.data_type.integer_value_sequence(label_dict_len))\r\n```\r\n, and a weight sequence $W=[w_1, ..., w_T]$. Is there a way to calculate cost as \r\n$\\sum_t w_t*cross_entropy(\\hat{y_t}, y_t)$ ?\r\n\r\nThanks",
        "state": "closed",
        "user": "jmliu88",
        "closed_by": "shanyi15",
        "created_at": "2017-09-26T07:21:54+00:00",
        "updated_at": "2018-08-15T10:08:11+00:00",
        "closed_at": "2018-08-15T10:08:11+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 322,
        "title": "models网站序列标注示例的Web页面图片显示问题",
        "body": "models网站序列标注示例页面中图片没有显示出来 http://models.paddlepaddle.org/2017/04/21/sequence-tagging-for-ner-README.html\r\n\r\n![image](https://user-images.githubusercontent.com/14105589/30852042-0f7592fc-a2dd-11e7-93c0-d064e6014ae0.png)\r\n",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "Superjomn",
        "created_at": "2017-09-26T09:09:07+00:00",
        "updated_at": "2017-09-27T16:00:16+00:00",
        "closed_at": "2017-09-27T16:00:16+00:00",
        "comments_count": [
            "lcy-seso",
            "Superjomn",
            "Superjomn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 328,
        "title": "add scene_text_recognition",
        "body": "add scene_text_recognition demo",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-27T09:09:01+00:00",
        "updated_at": "2017-10-29T03:05:14+00:00",
        "closed_at": "2017-10-29T03:05:14+00:00",
        "comments_count": [],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 327,
        "title": "图像分类的例子如何在多机多卡上训练？",
        "body": "老师，\r\n你好！\r\n我之前在https://github.com/PaddlePaddle/models/tree/develop/image_classification这个模型下实现了单机多卡的训练，但是在多机多卡上训练总是遇到一些问题。\r\n我按照分布式的相关操作设置了conf.py如下\r\nHOSTS = [\r\n    \"root@192.168.100.67\",\r\n    \"root@192.168.100.68\",\r\n]\r\n'''\r\nworkspace configuration\r\n'''\r\n#root dir for workspace, can be set as any director with real user account\r\nROOT_DIR = \"/home/users/AI/paddle/paddle/scripts/cluster_train\"\r\n'''\r\nnetwork configuration\r\n'''\r\n#pserver nics\r\nPADDLE_NIC = \"eno1\"\r\n#pserver port\r\nPADDLE_PORT = 22222\r\n#pserver ports num\r\nPADDLE_PORTS_NUM = 2\r\n#pserver sparse ports num\r\nPADDLE_PORTS_NUM_FOR_SPARSE = 2\r\n\r\n#environments setting for all processes in cluster job\r\nLD_LIBRARY_PATH = \"/usr/local/cuda/lib64:/usr/lib64:/home/users/cudnn/cudnn6.0/lib64:/home/users/openmpi/lib\"\r\n使用例子中的：paddle/paddle/scripts/cluster_train 下的脚本\r\nrun.sh如下：\r\npython paddle2.py \\\r\n  --job_dispatch_package=\"/home/users/AI/paddle/paddle/scripts/cluster_train\" \\\r\n  --dot_period=10 \\\r\n  --ports_num_for_sparse=2 \\\r\n  --log_period=50 \\\r\n  --num_passes=10 \\\r\n  --trainer_count=4 \\\r\n  --saving_period=1 \\\r\n  --local=0 \\\r\n  --config=/home/users/AI/paddle/paddle/scripts/cluster_train/train.py \\\r\n  --save_dir=./output \\\r\n  --use_gpu=1\r\n运行的时候总是出现如下错误：\r\nPython Error: <class 'google.protobuf.message.EncodeError'> : Message paddle.TrainerConfig is missing required fields: opt_config.batch_size\r\n是否是这个例子不能作为分布式的脚本来用呢？\r\n\r\n\r\n全部错误提示如下：\r\n[INFO 2017-09-27 10:42:59,648 (unknown file):0] model_config {\r\n  type: \"nn\"\r\n  sub_models {\r\n    name: \"root\"\r\n    is_recurrent_layer_group: false\r\n  }\r\n}\r\nopt_config {\r\n  algorithm: \"async_sgd\"\r\n  learning_rate: 1.0\r\n  learning_rate_decay_a: 0.0\r\n  learning_rate_decay_b: 0.0\r\n  l1weight: 0.1\r\n  l2weight: 0.0\r\n  c1: 0.0001\r\n  backoff: 0.5\r\n  owlqn_steps: 10\r\n  max_backoff: 5\r\n  l2weight_zero_iter: 0\r\n  average_window: 0\r\n  learning_method: \"momentum\"\r\n  ada_epsilon: 1e-06\r\n  do_average_in_cpu: false\r\n  ada_rou: 0.95\r\n  learning_rate_schedule: \"poly\"\r\n  delta_add_rate: 1.0\r\n  shrink_parameter_value: 0\r\n  adam_beta1: 0.9\r\n  adam_beta2: 0.999\r\n  adam_epsilon: 1e-08\r\n  learning_rate_args: \"\"\r\n  async_lagged_grad_discard_ratio: 1.5\r\n}\r\nsave_dir: \"./output/model\"\r\nstart_pass: 0\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/paddle/trainer/config_parser.py\", line 4230, in parse_config_and_serialize\r\n    return config.SerializeToString()\r\n  File \"/usr/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1059, in SerializeToString\r\n    self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\r\nEncodeError: Message paddle.TrainerConfig is missing required fields: opt_config.batch_size\r\nF0927 10:42:59.650485 40923 PythonUtil.cpp:131] Check failed: (ret) != nullptr Current PYTHONPATH: ['/usr/local/bin', '/usr/lib/python2.7/site-packages/pip-9.0.1-py2.7.egg', '/usr/lib/python2.7/site-packages/pybind11-1.9.dev0-py2.7.egg', '/home/users/AI/paddle/paddle/scripts/cluster_train/JOB20170927104210', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages']\r\nPython Error: <class 'google.protobuf.message.EncodeError'> : Message paddle.TrainerConfig is missing required fields: opt_config.batch_size\r\nPython Callstack:\r\n            /us/usr/local/bin/paddle: line 96: 40536 Aborted                 ${DEBUGGER} $PADDLE_BIN_PATH/paddle_trainer ${@:2}\r\n/google/protobuf/internal/python_message.py : 1059\r\nCall Object failed.\r\n*** Check failure stack trace: ***\r\n    @           0x61061d  google::LogMessage::Fail()\r\n    @           0x61249f  google::LogMessage::SendToLog()\r\n    @           0x610193  google::LogMessage::Flush()\r\n    @           0x612dbe  google::LogMessageFatal::~LogMessageFatal()\r\n    @           0x97d6aa  paddle::callPythonFuncRetPyObj()\r\n    @           0x97d88c  paddle::callPythonFunc()\r\n",
        "state": "closed",
        "user": "Sampson1107",
        "closed_by": "shanyi15",
        "created_at": "2017-09-27T06:34:34+00:00",
        "updated_at": "2018-08-15T10:08:07+00:00",
        "closed_at": "2018-08-15T10:08:07+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 332,
        "title": "Need to make sh scripts more robust in DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-27T09:55:29+00:00",
        "updated_at": "2017-09-27T09:58:14+00:00",
        "closed_at": "2017-09-27T09:58:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 333,
        "title": "add data preprocess scripts for GNR model",
        "body": "GNR example hasn't totally finished yet.\r\n- It lacks a data pre-process script.\r\n- It lacks an evaluation script.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-27T10:09:45+00:00",
        "updated_at": "2017-10-09T03:56:45+00:00",
        "closed_at": "2017-10-09T03:56:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 334,
        "title": "add data preprocess and trained model scripts for generating Chinese poetry.",
        "body": "- Please use data from this project https://github.com/lcy-seso/chinese-poetry and add a reference to this projection.\r\n- Add the trained model.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-09-27T10:12:58+00:00",
        "updated_at": "2017-11-20T02:41:41+00:00",
        "closed_at": "2017-11-20T02:41:41+00:00",
        "comments_count": [],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 330,
        "title": "unify the way how demos runs in models repo and codes organization.",
        "body": "- Currently, how each demos run in models repo varies from demo to demo. Except for some very complicated demo, for example, DS2, it is better to unify the organization of the code.\r\n- At least the following work is required:\r\n    - create command line interfaces for each example.\r\n    - add docstring for each important function, and unify the style of docstring.  Keep the style be consistent with PaddlePaddle main repo.\r\n",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-09-27T09:14:18+00:00",
        "updated_at": "2018-08-15T10:08:04+00:00",
        "closed_at": "2018-08-15T10:08:04+00:00",
        "comments_count": [
            "will-am",
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 336,
        "title": "Fix bugs in preparing data scripts",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-27T10:46:56+00:00",
        "updated_at": "2017-09-27T10:51:36+00:00",
        "closed_at": "2017-09-27T10:51:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 340,
        "title": "Fix bugs for demo_server.py",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-28T02:55:15+00:00",
        "updated_at": "2017-09-28T04:17:57+00:00",
        "closed_at": "2017-09-28T04:17:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 342,
        "title": "Fix some efficiency problem for data_utils/data.py ",
        "body": "Already fixed:\r\n```batch_manifest = [item for batch in batch_manifest for item in batch]```",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-28T11:42:16+00:00",
        "updated_at": "2017-09-28T11:44:51+00:00",
        "closed_at": "2017-09-28T11:44:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 339,
        "title": "Add the script to parse tuning log for DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2017-09-27T18:04:06+00:00",
        "updated_at": "2018-08-15T10:07:59+00:00",
        "closed_at": "2018-08-15T10:07:59+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 343,
        "title": "Fix bugs for model_utils/model.py",
        "body": "Always print 0 for ValidataionCost",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-09-29T03:49:40+00:00",
        "updated_at": "2017-09-29T07:03:06+00:00",
        "closed_at": "2017-09-29T07:03:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 348,
        "title": "Convert decoding results to unicode in DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-29T12:17:08+00:00",
        "updated_at": "2017-09-29T12:21:57+00:00",
        "closed_at": "2017-09-29T12:21:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 349,
        "title": "Enable the log of gradient clipping in training",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-09-29T12:17:50+00:00",
        "updated_at": "2017-09-29T12:21:57+00:00",
        "closed_at": "2017-09-29T12:21:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 354,
        "title": "[Deep Speech 2] Slow training with internal English dataset",
        "body": "Currently, training with our internal English dataset (.seqbin) is unexpectedly slow. Only 15% GPU utilization. The normal speed should be larger than 70% GPU utilization.\r\n\r\nBy profiling, we found the reason is:\r\n\r\nSome audio data in this dataset requires a resampling (from 8000 to 16000 sample-rates) before spectrogram feature extraction. Such a resampling is CPU intensive. However, `paddle.reader.xmap_readers` is multi-threading, which can in fact use only single CPU core due to GIL (refer to [Link](https://stackoverflow.com/questions/8774989/python-multithreading-too-slow-multiprocess)).\r\n\r\nFor LibriSpeech dataset, this problem was not revealed since no CPU intensive resampling is needed for LibriSpeech data.\r\n\r\nIn a word, we need a multiprocessing version of `xmap_reader`.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-07T13:11:44+00:00",
        "updated_at": "2017-10-09T14:35:38+00:00",
        "closed_at": "2017-10-09T14:35:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 345,
        "title": "add nest sequence example for capi",
        "body": "add nest sequence data type demo for capi  inference",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2017-09-29T06:32:28+00:00",
        "updated_at": "2018-08-15T10:07:54+00:00",
        "closed_at": "2018-08-15T10:07:54+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 357,
        "title": "Bug in librispeech/run_train.sh",
        "body": "After running ```examples/librispeech/run_data.sh```, we can get ```data/librispeech/mainfest.dev-clean``` and ```data/librispeech/manifest.dev-other```. However, current ```examples/librispeech/run_train.sh``` use ```data/librispeech/manifest.dev``` as test data. For detail, please refer https://github.com/PaddlePaddle/models/blob/develop/deep_speech_2/examples/librispeech/run_train.sh#L27\r\n\r\nWe can just change ```data/librispeech/manifest.dev``` to ```data/librispeech/manifest.dev-clean``` to avoid training failure.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-10-11T13:37:04+00:00",
        "updated_at": "2017-10-11T14:49:36+00:00",
        "closed_at": "2017-10-11T14:49:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 358,
        "title": "Turn on FLAG_rnn_use_batch for DS2 for accelartion.",
        "body": "By setting `FLAG_rnn_use_batch` to `True`, simple rnn layer might get more than 2X speedup.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-11T13:54:23+00:00",
        "updated_at": "2017-10-11T14:15:12+00:00",
        "closed_at": "2017-10-11T14:15:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 351,
        "title": "Dependency should be installed before compilation of `libsndfile`",
        "body": "Libsndfile dependents `libflac-dev` `libogg-dev` `libvorbis-dev`.\r\nSo maybe use command like `apt-get install -y libflac-dev libogg-dev libvorbis-dev` to install them.",
        "state": "closed",
        "user": "gongweibao",
        "closed_by": "shanyi15",
        "created_at": "2017-09-30T09:26:31+00:00",
        "updated_at": "2018-08-15T10:07:51+00:00",
        "closed_at": "2018-08-15T10:07:51+00:00",
        "comments_count": [
            "kuke",
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 352,
        "title": "Scipy's version is old.",
        "body": "In PaddlePaddle, we use version 0.19.x.\r\nDo we need to use the new one?",
        "state": "closed",
        "user": "gongweibao",
        "closed_by": "shanyi15",
        "created_at": "2017-09-30T09:27:38+00:00",
        "updated_at": "2018-08-15T10:07:44+00:00",
        "closed_at": "2018-08-15T10:07:44+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 361,
        "title": "Document about Aishell demo.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-10-11T14:21:34+00:00",
        "updated_at": "2017-11-03T14:55:01+00:00",
        "closed_at": "2017-11-03T14:55:01+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 362,
        "title": "Invalid url in `librispeech/download_model.sh`",
        "body": "The url in `librispeech/download_model.sh` is not available now.",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-11T14:44:44+00:00",
        "updated_at": "2017-10-11T14:55:59+00:00",
        "closed_at": "2017-10-11T14:55:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 366,
        "title": "add text classification demo for nested sequence data ",
        "body": "text classification with nested sequence data in paddle.v2",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2017-10-12T02:28:30+00:00",
        "updated_at": "2017-10-15T13:20:51+00:00",
        "closed_at": "2017-10-15T13:20:51+00:00",
        "comments_count": [],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 365,
        "title": "Complete document for LMs",
        "body": "Due to the problem of paddle cloud, will update the url of large LM later.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-11T14:54:14+00:00",
        "updated_at": "2017-11-03T08:27:02+00:00",
        "closed_at": "2017-11-03T08:27:02+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 369,
        "title": "Add three trained image classification models on ImageNet.",
        "body": "Add three trained models for image classification. Update the documentation to add three trained models on ImageNet:\r\n\r\nResNet50: http://cloud.dlnel.org/filepub/?uuid=f63f237a-698e-4a22-9782-baf5bb183019\r\nResNet101: http://cloud.dlnel.org/filepub/?uuid=3d5fb996-83d0-4745-8adc-13ee960fc55c\r\nVgg16：http://cloud.dlnel.org/filepub/?uuid=aa0e397e-474a-4cc1-bd8f-65a214039c2e",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-10-12T08:28:17+00:00",
        "updated_at": "2018-07-20T14:06:12+00:00",
        "closed_at": "2017-10-13T07:27:20+00:00",
        "comments_count": [
            "zgplvyou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 371,
        "title": "Need a documentation on \"How to fine tune an existing model.\"",
        "body": "Need a documentation and an example on \"How to fine tune an existing model.\"",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-10-13T06:15:35+00:00",
        "updated_at": "2018-08-15T10:07:40+00:00",
        "closed_at": "2018-08-15T10:07:40+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "enhancement",
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 372,
        "title": "Update the documentation of \"How to use CAPI\" in PaddleModel repo.",
        "body": "- 我们计划在 models repo 的 [`how_to_use_capi`](https://github.com/PaddlePaddle/models/tree/develop/how_to_use_capi) 目录下增加更加丰富的，与CAPI使用相关的文档和例子，保证能够覆盖到 PaddlePaddle 所有输入数据类型。\r\n- 在这个issue 中，先提出我们能够想到的，需要包含的最小信息。请大家不吝提出更好的建议，帮助我们做好“CAPI使用”相关的文档和例子。\r\n- `how_to_use_capi` 会含有二级目录，对应不同的可以完整运行的示例代码；\r\n- 一级目录下的 README 需要介绍与CAPI使用相关的通用信息。\r\n- 以下是关于一级目录下 README 的一个基础提纲：\r\n---\r\n\r\n### 1. 编译paddle lib\r\n\r\n### 2. CAPI 使用流程指南\r\n1.  序列化模型配置；\r\n2. 组织数据数据；\r\n3. 初始化/加载模型；\r\n4. 前向计算；\r\n5. 清理；\r\n\r\n### 3. 从python 用户接口的输入数据类型，到 C++ 端输入数据类型对应\r\n\r\n- 首先，需要一个`[ 12 x 2]` 的表格，第一列是用户在 python 端看到的，PaddlePaddle 支持的所有 12 种输入数据类型；第二列对应了 12 种输入数据在 C++ 代码中如何组织的tips。\r\n- 关键代码片段和一定的解释说明；\r\n\r\n### 4. 多线程预测\r\n\r\n### 5. F&Q",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-10-13T08:23:31+00:00",
        "updated_at": "2018-08-15T10:11:36+00:00",
        "closed_at": "2018-08-15T10:11:36+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 374,
        "title": "Need a guide/standard for adding new models into the model repo.",
        "body": "After a period of trying and practice, we found that a standard or a guide for adding a new model into the Paddle Models repo is required.\r\n\r\nWe have already had some practices that are better to be followed, which should be added as a document. The document is also expected to be a guide for anyone who hopes to contribute.\r\n\r\nThe guide/standard should include (but not limited to) :\r\n\r\n- The code structures and naming conventions.\r\n- How to organize README;\r\n    - A suggested outlines.\r\n    - The least things should be explained in the README.\r\n",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-10-14T02:25:12+00:00",
        "updated_at": "2018-08-15T10:11:31+00:00",
        "closed_at": "2018-08-15T10:11:31+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 375,
        "title": "Add the trained model for NER task.",
        "body": "We have a well trained NER model based on CoNLL dataset. It can be added to the [NER](https://github.com/PaddlePaddle/models/tree/develop/sequence_tagging_for_ner) task for all the users to evaluate or used as a baseline.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-10-14T03:06:48+00:00",
        "updated_at": "2018-08-15T10:11:27+00:00",
        "closed_at": "2018-08-15T10:11:27+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 377,
        "title": "DS2's tools/compute_mean_std.py failed with seqbin data",
        "body": "",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-15T10:43:21+00:00",
        "updated_at": "2017-10-16T05:01:59+00:00",
        "closed_at": "2017-10-16T05:01:59+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 376,
        "title": "ctc_decoder的一些问题",
        "body": "在编译使用中遇到了一些问题。\r\n在swig目录中执行`sh setup.sh` ，报了一个错\r\n```text\r\nInstall decoders ...\r\ndecoder_utils.h:55: Error: Syntax error in input(1).\r\nrunning install\r\n```\r\n最终安装成功了\r\n```text\r\nProcessing dependencies for swig-decoders==0.1\r\nFinished processing dependencies for swig-decoders==0.1\r\n```\r\n\r\n但是执行`python -c \"import swig_decoders\"`还是报以下错误：\r\n\r\n```text\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in \r\nImportError: No module named swig_decoders\r\n```\r\n\r\n@kuke 给了解决方案：\r\n```text\r\ndecoder_utils.h:55: Error: Syntax error in input(1)\r\nThis error results from that the version of swig is too low. Please upgrade swig first then reinstall the decoders.\r\n```\r\n升级到3.0.12后问题解决。\r\n\r\n---\r\n但目前仍有两个问题：\r\n\r\n1.  在mac上执行会报这个问题：\r\n\r\n```text\r\nopenfst-1.6.3/src/include/fst/types.h:19:10: fatal error: 'cstdint' file not found\r\n```\r\n\r\n2.  还有一个使用的问题：在中文的处理中，`ctc_beam_search_decoder.cpp` 第122行，`c == space_id` 中文是没有空格的，怎么把语言模型的转移概率加进去呢？\r\n\r\n@kuke @lcy-seso ",
        "state": "closed",
        "user": "fanlu",
        "closed_by": "shanyi15",
        "created_at": "2017-10-14T07:16:39+00:00",
        "updated_at": "2018-08-15T10:11:22+00:00",
        "closed_at": "2018-08-15T10:11:22+00:00",
        "comments_count": [
            "kuke",
            "fanlu",
            "kuke",
            "fanlu",
            "pkuyym",
            "kuke",
            "fanlu",
            "fanlu",
            "kuke",
            "fanlu",
            "ghost",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 379,
        "title": "Fix doc style in models.",
        "body": "Fix doc style in nested_sequence, image_classification and scheduled_sampling.",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2017-10-16T02:58:39+00:00",
        "updated_at": "2017-10-16T03:08:31+00:00",
        "closed_at": "2017-10-16T03:08:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 381,
        "title": "Refine readme.md in nested_sequence.",
        "body": "Add introduction for nested_sequence.",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2017-10-16T05:37:15+00:00",
        "updated_at": "2017-10-17T07:57:11+00:00",
        "closed_at": "2017-10-17T07:57:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 384,
        "title": "Parameter cutoff_top_n is missing in some scripts of DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-10-16T11:16:02+00:00",
        "updated_at": "2017-11-02T02:58:35+00:00",
        "closed_at": "2017-11-02T02:58:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 393,
        "title": "[DS2] Should give option to disable converting from transcription text to ids",
        "body": "There is no need to convert transcription text to id sequence when doing evaluation and inference.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "xinghai-sun",
        "created_at": "2017-10-23T03:40:53+00:00",
        "updated_at": "2017-11-03T08:25:33+00:00",
        "closed_at": "2017-11-03T08:25:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 386,
        "title": "ImportError: No module named soundfile in latest docker",
        "body": "docker 使用latest，运行test.py ，提示：\r\nImportError: No module named soundfile\r\n\r\n",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "lezasantaizi",
        "created_at": "2017-10-18T02:31:16+00:00",
        "updated_at": "2017-10-18T05:46:51+00:00",
        "closed_at": "2017-10-18T05:46:51+00:00",
        "comments_count": [
            "lezasantaizi",
            "lezasantaizi",
            "kuke",
            "lezasantaizi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 388,
        "title": "deep_speech_2 中test.py 遇到的问题",
        "body": "下载了paddlepaddle/models:deep-speech-2 ,直接运行了test.py,找不到以下这个文件，我需要如何获取这个数据？\r\nIOError: [Errno 2] No such file or directory: 'data/librispeech/mean_std.npz'\r\n",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "kuke",
        "created_at": "2017-10-18T06:02:20+00:00",
        "updated_at": "2018-12-11T21:56:12+00:00",
        "closed_at": "2018-03-15T05:27:13+00:00",
        "comments_count": [
            "luotao1",
            "xinghai-sun",
            "lezasantaizi",
            "lezasantaizi",
            "lezasantaizi",
            "sivagururaman",
            "seethagithub"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 389,
        "title": "tiny文件夹中 run_train.sh 运行错误",
        "body": "![image](https://user-images.githubusercontent.com/7878465/31706255-ef0bb0d2-b3ad-11e7-9031-2eaed2fb920e.png)\r\n",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "shanyi15",
        "created_at": "2017-10-18T07:42:40+00:00",
        "updated_at": "2018-08-15T10:11:19+00:00",
        "closed_at": "2018-08-15T10:11:19+00:00",
        "comments_count": [
            "kuke",
            "lezasantaizi",
            "lezasantaizi",
            "kuke",
            "lezasantaizi",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 391,
        "title": "Models 中 CTR 例子网页显示格式异常",
        "body": "CTR 例子网页显示格式异常：\r\nhttp://models.paddlepaddle.org/2017/05/24/ctr-README.html",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-10-19T12:57:37+00:00",
        "updated_at": "2018-08-15T09:58:05+00:00",
        "closed_at": "2018-08-15T09:58:05+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 394,
        "title": "Evaluate internel mandarin dataset (~12k hours)",
        "body": "Regular Dev (Randomly select 2000 examples)\r\n\r\n| Model | Decode Type | CER |\r\n| -- | -- | -- |\r\n| Pass-4 | Greedy | 0.170827\r\n| Pass-5-8000 | Greedy | 0.181563\r\n| Continue-Pass-1 (About Pass-6) | Greedy | 0.167423\r\n| Continue-Pass-3 (About Pass-8) | Greedy | 0.168330\r\n| Continue-Pass-2 (About Pass-7) | Greedy | 0.161796\r\n| Continue-8x-Pass-4-2000 (About Pass-9) | Greedy | 0.167176\r\n\r\nAishell Test (Randomly select 2000 examples)\r\n\r\n| Model | Decode Type | CER |\r\n| -- | -- | -- |\r\n| Pass-4 | Beam Search (default) | 0.301863\r\n| Pass-5-8000 | Beam Search (default) | 0.312483\r\n| Continue-Pass-1 | Beam Search (default) | 0.295325\r\n| Continue-Pass-1 | Greedy | 0.410359 ",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2017-10-23T04:25:35+00:00",
        "updated_at": "2018-08-15T09:58:01+00:00",
        "closed_at": "2018-08-15T09:58:01+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 398,
        "title": "使用 generate_sequence_by_rnn_lm 进行train的时候报错",
        "body": "在 generate_sequence_by_rnn_lm 这个模型下运行 train.py 的时候，当测试文件的路径不存在的时候会报错。错误的原因是把conf写成了config。错误行数是train.py 的112行",
        "state": "closed",
        "user": "rongshunlin",
        "closed_by": "ranqiu92",
        "created_at": "2017-10-24T05:42:14+00:00",
        "updated_at": "2017-10-24T11:27:37+00:00",
        "closed_at": "2017-10-24T11:27:37+00:00",
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 397,
        "title": "训练ssd demo内存占用随着pass增加而增加",
        "body": "如题，每次跑到20左右pass的时候就因为内存不足被kill掉，pass0 pass2之类的占用还是5%左右，到了pass7就到了30%了，越到后面，内存占用不停地变多\r\n\r\n             total       used       free     shared    buffers     cached\r\nMem:      24519888   24356632     163256          0      49744   15330580\r\n-/+ buffers/cache:    8976308   15543580\r\nSwap:            0          0          0",
        "state": "closed",
        "user": "bushidonggua",
        "closed_by": "bushidonggua",
        "created_at": "2017-10-23T13:54:59+00:00",
        "updated_at": "2017-10-25T02:02:18+00:00",
        "closed_at": "2017-10-25T02:00:33+00:00",
        "comments_count": [
            "pkuyym",
            "bushidonggua",
            "pkuyym",
            "bushidonggua",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 402,
        "title": "experiment results on ConvS2S",
        "body": "网络配置：\r\nencoder: 5层 (256, 3)卷积\r\ndecoder: 3层 (256, 3)卷积\r\n\r\n实验条件：\r\n训练集：iwslt2014 英-德里的153326条数据\r\n验证集：6969条数据\r\nbatch_size = 32\r\np40 两卡训练\r\n\r\n实验结果：\r\n速度：24min/pass\r\nBLEU： 25.44（验证集，greedy search）",
        "state": "closed",
        "user": "ranqiu92",
        "closed_by": "ranqiu92",
        "created_at": "2017-10-26T08:20:37+00:00",
        "updated_at": "2017-12-29T08:39:19+00:00",
        "closed_at": "2017-12-29T08:39:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 400,
        "title": "CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 6) Cudnn Error",
        "body": "```------------------------------------------------\r\nI1024 12:30:02.643218    58 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=8 \r\nF1024 12:30:02.761147    58 hl_cuda_cudnn.cc:186] Check failed: CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 6) Cudnn Error: CUDNN_STATUS_ARCH_MISMATCH\r\n*** Check failure stack trace: ***\r\n    @     0x7f1b059dc12d  google::LogMessage::Fail()\r\n    @     0x7f1b059de478  google::LogMessage::SendToLog()\r\n    @     0x7f1b059dbc1b  google::LogMessage::Flush()\r\n    @     0x7f1b059df34e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f1b0597cb65  hl_cudnn_init()\r\n    @     0x7f1b05987b2f  hl_create_global_resources()\r\n    @     0x7f1b05988494  hl_specify_devices_start()\r\n    @     0x7f1b0598876d  hl_start()\r\n    @     0x7f1b0590c6fe  paddle::initMain()\r\n    @     0x7f1b059c2691  initPaddle()\r\n    @     0x7f1b054845b7  _wrap_initPaddle\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4de6fe  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4c6ad1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7f1b21c88830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\nrun_test.sh: line 38:    58 Aborted                 (core dumped) CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u test.py --batch_size=16 --trainer_count=8 --beam_size=500 --num_proc_bsearch=8 --num_proc_data=8 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --alpha=2.15 --beta=0.35 --cutoff_prob=1.0 --use_gru=False --use_gpu=True --share_rnn_weights=True --test_manifest='data/tiny/manifest.tiny' --mean_std_path='data/tiny/mean_std.npz' --vocab_path='data/tiny/vocab.txt' --model_path='checkpoints/params.pass-19.tar.gz' --lang_model_path='models/lm/common_crawl_00.prune01111.trie.klm' --decoding_method='ctc_beam_search' --error_rate_type='wer' --specgram_type='linear'\r\nFailed in evaluation!\r\n```",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "shanyi15",
        "created_at": "2017-10-24T12:32:55+00:00",
        "updated_at": "2018-08-15T09:57:52+00:00",
        "closed_at": "2018-08-15T09:57:52+00:00",
        "comments_count": [
            "lezasantaizi",
            "pkuyym",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 404,
        "title": "运行lambdarank demo infer阶段代码报错",
        "body": "执行ltr中的lambdarank的infer出现错误，数据为demo中mq2007中的数据。\r\nhttps://github.com/PaddlePaddle/models/tree/develop/ltr\r\n在lambda_rank.py中infer_data是array，但是到dataprovider_converter.py中dat为一个float型，错误如下，\r\n```\r\nTraceback (most recent call last): File \"lambda_rank.py\", line 137, in <module> lambda_rank_infer(pass_id=args.num_passes - 1) File \"lambda_rank.py\", line 120, in lambda_rank_infer output_layer=output, parameters=parameters, input=infer_data) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/inference.py\", line 158, in infer return inferer.infer(field=field, input=input, feeding=feeding) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/inference.py\", line 93, in infer for result in self.iter_infer_field(field=field, **kwargs): File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/inference.py\", line 80, in iter_infer_field for result in self.iter_infer(**kwargs): File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/inference.py\", line 73, in iter_infer yield self.__gradient_machine__.forwardTest(feeder(data_batch)) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 284, in __call__ return self.convert(dat, argument) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/data_feeder.py\", line 133, in convert return DataProviderConverter.convert(self, reorder_data(dat), argument) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 269, in convert scanner.pre_scan(each_step) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 227, in pre_scan self.__inner_scanner__.pre_scan(each) File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 116, in pre_scan \"The input should be a vector, please check your input data.\" ValueError: The input should be a vector, please check your input data.\r\n```",
        "state": "closed",
        "user": "MiraiJ",
        "closed_by": "lcy-seso",
        "created_at": "2017-10-31T06:32:07+00:00",
        "updated_at": "2017-11-02T03:34:05+00:00",
        "closed_at": "2017-11-02T03:34:05+00:00",
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 401,
        "title": "Add pointer to models in paddle book",
        "body": "Models such as NMT with attention is not included in this repo but present in paddle book. I think it will be convenient for the users if we add some links to these models in this repo. Otherwise, some users may feel confused why such useful models are absent in this repo.",
        "state": "closed",
        "user": "pengli09",
        "closed_by": "shanyi15",
        "created_at": "2017-10-25T07:44:14+00:00",
        "updated_at": "2018-08-15T09:57:48+00:00",
        "closed_at": "2018-08-15T09:57:48+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 406,
        "title": "paddle convolution filter dimension order is opposite to caffe or tensorflow",
        "body": "In paddle, filter_x is for horizontal direction, filter_y is for vertical direction, which is different in other platforms.",
        "state": "closed",
        "user": "PES2g",
        "closed_by": "PES2g",
        "created_at": "2017-10-31T09:34:25+00:00",
        "updated_at": "2017-10-31T10:09:32+00:00",
        "closed_at": "2017-10-31T10:01:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 405,
        "title": "如何添加新的layer",
        "body": "请教下如何在paddle添加新的layer，例如想自己修改已有的loss函数，应该如何实现呢？",
        "state": "closed",
        "user": "utopiar",
        "closed_by": "utopiar",
        "created_at": "2017-10-31T08:53:43+00:00",
        "updated_at": "2017-10-31T08:54:17+00:00",
        "closed_at": "2017-10-31T08:54:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 410,
        "title": "sequence_tagging_for_ner 模型疑问",
        "body": "感觉sequence_tagging_for_ner中network_conf.py中的网络配置与教程的的网络结构图不符，求教是否是我理解有误？\r\n教程中的网络结构图如下：\r\n<img width=\"369\" alt=\"ner_network\" src=\"https://user-images.githubusercontent.com/5753928/32260310-fc5d03d0-bf01-11e7-9963-02f4047f53e3.png\">\r\n示意图中的网络结构是左右两个双向rnn，而代码中\r\n```python\r\n    for direction in [\"fwd\", \"bwd\"]:\r\n        for i in range(stack_num):\r\n            if i:\r\n                hidden = paddle.layer.fc(\r\n                    name=\"__hidden%02d_%s__\" % (i, direction),\r\n                    size=hidden_dim,\r\n                    act=paddle.activation.STanh(),\r\n                    bias_attr=paddle.attr.Param(initial_std=1.),\r\n                    input=[hidden, rnn],\r\n                    param_attr=[hidden_para_attr, rnn_para_attr])\r\n\r\n            rnn = paddle.layer.recurrent(\r\n                name=\"__rnn%02d_%s__\" % (i, direction),\r\n                input=hidden,\r\n                act=paddle.activation.Relu(),\r\n                bias_attr=paddle.attr.Param(initial_std=1.),\r\n                reverse=i % 2 if direction == \"fwd\" else not i % 2,\r\n                param_attr=rnn_para_attr)\r\n        fea += [hidden, rnn]\r\n```\r\n按照我的理解好像只有示意图的右半部分",
        "state": "closed",
        "user": "utopiar",
        "closed_by": "utopiar",
        "created_at": "2017-11-01T04:41:46+00:00",
        "updated_at": "2017-11-01T08:08:13+00:00",
        "closed_at": "2017-11-01T08:08:13+00:00",
        "comments_count": [
            "peterzhang2029",
            "utopiar"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 411,
        "title": "sequence_tagging_for_ner训练过程F1为什么一直是0？",
        "body": "```\r\n[INFO 2017-11-01 18:49:00,898 train.py:83] Pass 0, Batch 0, Cost 15.435392, {'ner_chunk.precision': 0.02575107291340828, 'ner_chunk.F1-score': 0.03539822995662689, 'ner_chunk.recall': 0.056603774428367615, 'error': 0.8953229188919067}\r\n[INFO 2017-11-01 18:49:05,185 train.py:87]\r\nTest with Pass 0, Batch 0, {'ner_chunk.precision': 0.019510731101036072, 'ner_chunk.F1-score': 0.029499361291527748, 'ner_chunk.recall': 0.06044403091073036, 'error': 0.9291946291923523}\r\n[INFO 2017-11-01 18:49:05,246 train.py:83] Pass 0, Batch 1, Cost 11.822507, {'ner_chunk.precision': 0.0, 'ner_chunk.F1-score': 0.0, 'ner_chunk.recall': 0.0, 'error': 0.24517905712127686}\r\n[INFO 2017-11-01 18:49:09,545 train.py:87]\r\nTest with Pass 0, Batch 1, {'ner_chunk.precision': 0.0, 'ner_chunk.F1-score': 0.0, 'ner_chunk.recall': 0.0, 'error': 0.16679592430591583}\r\n[INFO 2017-11-01 18:49:09,601 train.py:83] Pass 0, Batch 2, Cost 10.640020, {'ner_chunk.precision': 0.0, 'ner_chunk.F1-score': 0.0, 'ner_chunk.recall': 0.0, 'error': 0.29411765933036804}\r\n[INFO 2017-11-01 18:49:13,849 train.py:87]\r\nTest with Pass 0, Batch 2, {'ner_chunk.precision': 0.0, 'ner_chunk.F1-score': 0.0, 'ner_chunk.recall': 0.0, 'error': 0.16679592430591583}\r\n```\r\n除了第一个Batch的F1不是0，以后一直是0，请教这是什么问题呢？",
        "state": "closed",
        "user": "utopiar",
        "closed_by": "shanyi15",
        "created_at": "2017-11-01T10:53:01+00:00",
        "updated_at": "2018-08-15T09:57:45+00:00",
        "closed_at": "2018-08-15T09:57:45+00:00",
        "comments_count": [
            "guoshengCS",
            "utopiar",
            "JenningsL",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 414,
        "title": "For ds2, we should not involve padding data when computing loss and gradient",
        "body": "To solve the problem, two things should be done.\r\n- [x] Expose SubSequenceLayer (including bug fixes) https://github.com/PaddlePaddle/Paddle/issues/5335\r\n- [x] Add a ScaleSubRegionLayer (support set value for given indices) https://github.com/PaddlePaddle/Paddle/issues/5416\r\n- [x] Modify the network configuration. https://github.com/PaddlePaddle/models/pull/444\r\n- [x] Adapt tune.py https://github.com/PaddlePaddle/models/pull/447",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-02T02:25:16+00:00",
        "updated_at": "2017-11-10T08:54:36+00:00",
        "closed_at": "2017-11-10T08:54:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 419,
        "title": "Add the document about docker running for DS2",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "xinghai-sun",
        "created_at": "2017-11-03T09:43:41+00:00",
        "updated_at": "2017-11-03T13:54:43+00:00",
        "closed_at": "2017-11-03T13:54:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 416,
        "title": "ssd demo预测分类异常",
        "body": "infer.py源码：\r\n```python\r\ndef _infer(inferer, infer_data, threshold):\r\n    ret = []\r\n    infer_res = inferer.infer(input=infer_data)\r\n    keep_inds = np.where(infer_res[:, 2] >= threshold)[0]\r\n    for idx in keep_inds:\r\n        ret.append([\r\n            infer_res[idx][0], infer_res[idx][1] - 1, infer_res[idx][2],\r\n            infer_res[idx][3], infer_res[idx][4], infer_res[idx][5],\r\n            infer_res[idx][6]\r\n        ])\r\n    return ret\r\n```\r\n其中，label标签为何要-1？，标签id从0开始，这个导致预测出来的所有的标签都要+1才是正确的结果。\r\n",
        "state": "closed",
        "user": "bushidonggua",
        "closed_by": "shanyi15",
        "created_at": "2017-11-02T11:19:02+00:00",
        "updated_at": "2018-08-15T09:57:33+00:00",
        "closed_at": "2018-08-15T09:57:33+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 420,
        "title": "Got \"ValueError: The input should be a vector, please check your input data.\" problem",
        "body": "I met the following errors when I tried to run my DSSM model,\r\n```text\r\n> [INFO 2017-11-06 11:53:25,772 reader.py:66] [reader] load trainset from /home/work/zhaoyijin/video-recsys-model/dssm/train_data_dir/train/train\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 247, in <module>\r\n    use_gpu=args.use_gpu)\r\n  File \"train.py\", line 229, in train\r\n    num_passes=num_passes)\r\n  File \"/home/work/zhaoyijin/paddle_new/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 169, in train\r\n    in_args = feeder(data_batch)\r\n  File \"/home/work/zhaoyijin/paddle_new/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 282, in __call__\r\n    return self.convert(dat, argument)\r\n  File \"/home/work/zhaoyijin/paddle_new/python27-gcc482/lib/python2.7/site-packages/paddle/v2/data_feeder.py\", line 133, in convert\r\n    return DataProviderConverter.convert(self, reorder_data(dat), argument)\r\n  File \"/home/work/zhaoyijin/paddle_new/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 267, in convert\r\n    scanner.pre_scan(each_step)\r\n  File \"/home/work/zhaoyijin/paddle_new/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 114, in pre_scan\r\n    \"The input should be a vector, please check your input data.\"\r\nValueError: The input should be a vector, please check your input data.\r\n```\r\nHere is my code related to data input, in reader.py\r\n```python\r\ndef train(self):\r\n        logger.info(\"[reader] load trainset from %s\" % self.train_path)\r\n        with open(self.train_path) as f:\r\n            for line_id, line in enumerate(f):\r\n                yield self.record_reader(line)\r\n\r\ndef _read_classification_record(self, line):\r\n        fs = line.strip().split('\\t')\r\n        label = int(fs[0])\r\n        user_id = self.feature_dic['baidu_id'].get(fs[1], UNK)\r\n        video_id = self.feature_dic['item_id'].get(fs[3], UNK)\r\n        cluster_id = self.feature_dic['cluster_no'].get(fs[10], UNK)\r\n        title_len = len(fs[5])\r\n        if not self.is_infer:\r\n            out_list = [video_id, cluster_id, title_len, user_id, label, ]\r\n            return tuple(out_list)\r\n        out_list = [video_id, cluster_id, title_len, user_id]\r\n        return tuple(out_list)\r\n```\r\ntrain.py:\r\n```python\r\ndef train(train_data_path=None,\r\n          test_data_path=None,\r\n          dic_path=None,\r\n          model_type=ModelType.create_classification(),\r\n          batch_size=10,\r\n          num_passes=10,\r\n          share_semantic_generator=False,\r\n          share_embed=False,\r\n          class_num=None,\r\n          num_workers=1,\r\n          use_gpu=False):\r\n    '''\r\n    Train the DSSM.\r\n    '''\r\n    if not train_data_path or not test_data_path:\r\n        logger.error(\"No input data\")\r\n        exit(1)\r\n\r\n    dataset = reader.Dataset(\r\n        train_path=train_data_path,\r\n        test_path=test_data_path,\r\n        dic_path=dic_path,\r\n        model_type=model_type, )\r\n\r\n    train_reader = paddle.batch(\r\n        paddle.reader.shuffle(dataset.train, buf_size=1000),\r\n        batch_size=batch_size)\r\n\r\n    test_reader = paddle.batch(\r\n        paddle.reader.shuffle(dataset.test, buf_size=1000),\r\n        batch_size=batch_size)\r\n\r\n    paddle.init(use_gpu=use_gpu, trainer_count=num_workers)\r\n\r\n    cost, prediction, label = DSSM(\r\n        dnn_dims=layer_dims,\r\n        feature_size_dict=dataset.load_feature_size_dic(dic_path),\r\n        model_type=model_type,\r\n        share_semantic_generator=share_semantic_generator,\r\n        class_num=class_num,\r\n        share_embed=share_embed)()\r\n\r\n    parameters = paddle.parameters.create(cost)\r\n\r\n    adam_optimizer = paddle.optimizer.Adam(\r\n        learning_rate=1e-3,\r\n        regularization=paddle.optimizer.L2Regularization(rate=1e-3),\r\n        model_average=paddle.optimizer.ModelAverage(average_window=0.5))\r\n\r\n    trainer = paddle.trainer.SGD(\r\n        cost=cost,\r\n        extra_layers=paddle.evaluator.auc(input=prediction, label=label)\r\n        if not model_type.is_rank() else None,\r\n        parameters=parameters,\r\n        update_equation=adam_optimizer)\r\n\r\n    feeding = {'video_id': 0, 'cluster_id': 1, 'title_len': 2, 'user_id':3, 'label_input':4}\r\n\r\n    def _event_handler(event):\r\n        '''\r\n        Define batch handler\r\n        '''\r\n        if isinstance(event, paddle.event.EndIteration):\r\n            # output train log\r\n            if event.batch_id % args.num_batches_to_log == 0:\r\n                logger.info(\"Pass %d, Batch %d, Cost %f, %s\" % (\r\n                    event.pass_id, event.batch_id, event.cost, event.metrics))\r\n\r\n            # test model\r\n            if event.batch_id > 0 and \\\r\n                    event.batch_id % args.num_batches_to_test == 0:\r\n                if test_reader is not None:\r\n                    if model_type.is_classification():\r\n                        result = trainer.test(\r\n                            reader=test_reader, feeding=feeding)\r\n                        logger.info(\"Test at Pass %d, %s\" % (event.pass_id,\r\n                                                             result.metrics))\r\n                    else:\r\n                        result = None\r\n            # save model\r\n            if event.batch_id > 0 and \\\r\n                    event.batch_id % args.num_batches_to_save_model == 0:\r\n                model_desc = \"{type}_{arch}\".format(\r\n                    type=str(args.model_type), arch=str(args.model_arch))\r\n                with open(\"%sdssm_%s_pass_%05d.tar\" %\r\n                          (args.model_output_prefix, model_desc,\r\n                           event.pass_id), \"w\") as f:\r\n                    trainer.save_parameter_to_tar(f)\r\n\r\n    trainer.train(\r\n        reader=train_reader,\r\n        event_handler=_event_handler,\r\n        feeding=feeding,\r\n        num_passes=num_passes)\r\n\r\n    logger.info(\"Training has finished.\")\r\n```",
        "state": "closed",
        "user": "Bella-Zhao",
        "closed_by": "Bella-Zhao",
        "created_at": "2017-11-06T04:04:18+00:00",
        "updated_at": "2017-11-06T05:13:15+00:00",
        "closed_at": "2017-11-06T05:13:15+00:00",
        "comments_count": [
            "luotao1",
            "Bella-Zhao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 428,
        "title": "Add the scoring of last word/char of prefixes in CTC beam search decoder",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-06T15:32:31+00:00",
        "updated_at": "2017-11-07T09:19:05+00:00",
        "closed_at": "2017-11-07T09:19:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 429,
        "title": "Update benchmark results for BaiduEN8K model due to #427",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-06T15:47:46+00:00",
        "updated_at": "2017-11-08T04:46:25+00:00",
        "closed_at": "2017-11-06T16:06:55+00:00",
        "comments_count": [
            "PES2g"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 437,
        "title": "Update benchmark results for LibriSpeech model due to #427",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-08T06:47:53+00:00",
        "updated_at": "2017-11-08T07:04:05+00:00",
        "closed_at": "2017-11-08T07:04:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 438,
        "title": "Calculation discrepency exists in gru_unit_op and gru_op",
        "body": "The calculations for final output are different between gru_unit_op and gru_op:\r\n\r\n- gru_op\r\n\r\n```\r\n h_t = dot((1 - u_t), h_{t-1}) + dot(u_t, {h}_t)\r\n```\r\n\r\n- gru_unit_op\r\n\r\n```\r\n h_t = dot((1 - u_t), {h}_t) + dot(u_t, h_{t-1})\r\n```",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "guoshengCS",
        "created_at": "2017-11-08T12:52:28+00:00",
        "updated_at": "2017-11-08T12:54:18+00:00",
        "closed_at": "2017-11-08T12:54:17+00:00",
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 442,
        "title": "Need adjust ds2 to support padding removing",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-09T09:06:53+00:00",
        "updated_at": "2017-11-10T06:52:28+00:00",
        "closed_at": "2017-11-10T06:52:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 445,
        "title": "In ds2, subprocesses quit abnormally when main process quits.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-09T14:50:48+00:00",
        "updated_at": "2017-11-10T06:00:48+00:00",
        "closed_at": "2017-11-10T06:00:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 450,
        "title": "Need to set the version of CTC decoders formally",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-10T08:50:18+00:00",
        "updated_at": "2017-11-10T09:00:53+00:00",
        "closed_at": "2017-11-10T09:00:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 451,
        "title": "deep_speech_2/examples/tiny run_data.sh报错，无法继续",
        "body": "RuntimeError: Error opening '/root/.cache/paddle/dataset/speech/libri/test-clean/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac': File contains data in an unimplemented format\r\n\r\n另外docker里没有libsndfile-1.0.28,setup.sh也下载不下来，手动安装的，这些应该在docker中打包好的吧？",
        "state": "closed",
        "user": "harold-yh",
        "closed_by": "harold-yh",
        "created_at": "2017-11-11T03:42:52+00:00",
        "updated_at": "2017-12-13T02:05:14+00:00",
        "closed_at": "2017-12-13T02:05:14+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 454,
        "title": "How to use the SSD framework in paddle 0.10.0 released version?",
        "body": "I want to use the object detection framework in models/ssd, but I got those errors:\r\nroot@c1b28bac8e39:/home/workspace/models/ssd# python train.py  --use_gpu=True --trainer_count=1\r\nI1113 07:04:48.332365   319 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=4\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 84, in <module>\r\n    init_model_path='./vgg/vgg_model.tar.gz')\r\n  File \"train.py\", line 20, in train\r\n    cost, detect_out = vgg_ssd_net.net_conf('train')\r\n  File \"/home/workspace/models/ssd/vgg_ssd_net.py\", line 242, in net_conf\r\n    detection_out = paddle.layer.detection_output(\r\nAttributeError: 'module' object has no attribute 'detection_output'\r\nroot@c1b28bac8e39:/home/workspace/models/ssd#\r\nWhat should I do?\r\n",
        "state": "closed",
        "user": "TheodoreG",
        "closed_by": "luotao1",
        "created_at": "2017-11-13T07:10:54+00:00",
        "updated_at": "2018-01-29T07:07:26+00:00",
        "closed_at": "2018-01-29T07:07:26+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 455,
        "title": "普通话模型下载不了",
        "body": "```\r\nSaving to: './zh_giga.no_cna_cmn.prune01244.klm'\r\n\r\n./zh_giga.no_cna_cmn.prune012     [               <=>                             ] 631.80M  10.3MB/s    in 60s     \r\n\r\n2017-11-13 09:39:12 (10.5 MB/s) - Read error at byte 704826965 (Success).Retrying.\r\n\r\n```",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "lezasantaizi",
        "created_at": "2017-11-13T09:52:02+00:00",
        "updated_at": "2017-11-14T02:24:56+00:00",
        "closed_at": "2017-11-14T02:24:56+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": [
            "bug",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 457,
        "title": "sh run_infer_golden.sh  运行最后出现的错误",
        "body": "```\r\nCurrent error rate [wer] = 0.000000\r\n[INFO 2017-11-13 10:31:24,045 infer.py:115] finish inference\r\nProcess Process-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/paddle/code/models/deep_speech_2/data_utils/utility.py\", line 121, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/paddle/code/models/deep_speech_2/data_utils/utility.py\", line 134, in flush_worker\r\n    sample = in_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nroot@8095f1eb2e9a:/paddle/code/models/deep_speech_2/examples/tiny# sh run_infer_golden.sh \r\n\r\n```",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "lezasantaizi",
        "created_at": "2017-11-13T10:33:10+00:00",
        "updated_at": "2017-11-14T02:22:11+00:00",
        "closed_at": "2017-11-14T02:22:11+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 458,
        "title": "优化目录名称",
        "body": "![image](https://user-images.githubusercontent.com/6836917/32759242-4e46444c-c923-11e7-8b1e-b1546aca24ad.png)\r\n目录存在两个问题：\r\n- 2/6/10/14 目录名称太长，导致右侧导航栏显示不全。\r\n- CopyRight不应该出现在目录中。\r\n\r\n准备修改：\r\n- 2/6/10/14 目录分别改成：RNN语言模型，结构化语义模型，自动问答，语音识别\r\n- 在目录中去掉CopyRight",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-14T02:10:23+00:00",
        "updated_at": "2017-11-14T03:42:54+00:00",
        "closed_at": "2017-11-14T03:42:54+00:00",
        "comments_count": [
            "luotao1",
            "lcy-seso",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 412,
        "title": "sequence_tagging_for_ner 测试集上的 F1-score 一直没有变化",
        "body": "我在 sequence_tagging_for_ner 示例代码的基础上增加了几列特征，但是没有改变模型结构。在训练时，训练集上的 Cost, error, 以及其他指标都有变化，但是测试集上的F1-score 等指标从第一个batch开始就是一个非零值，并且没有任何变化。\r\n`\r\n[INFO 2017-11-01 19:25:05,183 train.py:103] Pass 9, Batch 0, Cost 11.496690, {'ner_chunk.precision': 0.7249544858932495, 'ner_chunk.F1-score': 0.8158245086669922, 'ner_chunk.recall': 0.9327396154403687, 'error': 0.22525805234909058}\r\n[INFO 2017-11-01 19:25:08,022 train.py:107]\r\nTest with Pass 9, Batch 0, {'ner_chunk.precision': 0.7743763327598572, 'ner_chunk.F1-score': 0.8488954901695251, 'ner_chunk.recall': 0.9392839074134827, 'error': 0.177949458360672}\r\n[INFO 2017-11-01 19:25:36,543 train.py:103] Pass 9, Batch 10, Cost 10.829126, {'ner_chunk.precision': 0.7487720847129822, 'ner_chunk.F1-score': 0.8320754766464233, 'ner_chunk.recall': 0.936234712600708, 'error': 0.20192831754684448}\r\n[INFO 2017-11-01 19:25:39,371 train.py:107]\r\nTest with Pass 9, Batch 10, {'ner_chunk.precision': 0.7743763327598572, 'ner_chunk.F1-score': 0.8488954901695251, 'ner_chunk.recall': 0.9392839074134827, 'error': 0.177949458360672}\r\n[INFO 2017-11-01 19:26:08,431 train.py:103] Pass 9, Batch 20, Cost 9.446608, {'ner_chunk.precision': 0.7925390601158142, 'ner_chunk.F1-score': 0.8627714514732361, 'ner_chunk.recall': 0.9466617703437805, 'error': 0.16465938091278076}\r\n[INFO 2017-11-01 19:26:11,258 train.py:107]\r\nTest with Pass 9, Batch 20, {'ner_chunk.precision': 0.7743763327598572, 'ner_chunk.F1-score': 0.8488954901695251, 'ner_chunk.recall': 0.9392839074134827, 'error': 0.177949458360672}\r\n[INFO 2017-11-01 19:26:33,026 train.py:117]\r\nTest with Pass 9, {'ner_chunk.precision': 0.7743763327598572, 'ner_chunk.F1-score': 0.8488954901695251, 'ner_chunk.recall': 0.9392839074134827, 'error': 0.177949458360672}\r\n`\r\n在调用 infer.py 进行预测时，发现所有标签都预测为 O。",
        "state": "closed",
        "user": "JenningsL",
        "closed_by": "shanyi15",
        "created_at": "2017-11-01T11:53:10+00:00",
        "updated_at": "2018-08-15T09:57:36+00:00",
        "closed_at": "2018-08-15T09:57:36+00:00",
        "comments_count": [
            "guoshengCS",
            "JenningsL",
            "guoshengCS",
            "JenningsL",
            "guoshengCS",
            "guoshengCS",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 452,
        "title": "The dev dataset should be involved to build vocabulary in the aishell example",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-12T08:53:02+00:00",
        "updated_at": "2017-11-12T08:58:15+00:00",
        "closed_at": "2017-11-12T08:58:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 448,
        "title": "Adapt tuning script to padding removing #444",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-10T08:36:31+00:00",
        "updated_at": "2017-11-10T08:40:20+00:00",
        "closed_at": "2017-11-10T08:40:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 424,
        "title": "Update benchmark results for LibriSpeech model",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-06T07:50:19+00:00",
        "updated_at": "2017-11-06T07:55:54+00:00",
        "closed_at": "2017-11-06T07:55:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 417,
        "title": "机器翻译模型自定义Beam_search情景下，如何避免重复计算",
        "body": "生成模式下走训练流程，从源，开始生成第一个词w1， w1 | 源 作为新的输入，生成 w2，w1, w2 | 源，作为新的输入生成 w3 ，以此类推。已生成的前缀在预测的前向网络中重复计算，但是时间上较慢。如何解决？",
        "state": "closed",
        "user": "dpwu1994",
        "closed_by": "shanyi15",
        "created_at": "2017-11-02T14:47:11+00:00",
        "updated_at": "2018-08-15T09:57:30+00:00",
        "closed_at": "2018-08-15T09:57:30+00:00",
        "comments_count": [
            "lcy-seso",
            "dpwu1994",
            "lcy-seso",
            "dpwu1994",
            "lcy-seso",
            "dpwu1994",
            "dpwu1994",
            "lcy-seso",
            "dpwu1994",
            "gongweibao",
            "dpwu1994",
            "Superjomn",
            "guoshengCS",
            "shanyi15"
        ],
        "labels": [
            "user",
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 434,
        "title": "DeepSpeech2 implementation detail not consistent with paper",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/deep_speech_2/decoders/scorer_deprecated.py#L67\r\n```\r\nscore = self._alpha * np.log(lm) + self._beta * np.log(word_cnt)\r\n```\r\nWhile in the original paper, there is no `log` with word_cnt.\r\n",
        "state": "closed",
        "user": "lispc",
        "closed_by": "luotao1",
        "created_at": "2017-11-08T05:48:46+00:00",
        "updated_at": "2018-01-29T07:06:43+00:00",
        "closed_at": "2018-01-29T07:06:43+00:00",
        "comments_count": [
            "kuke",
            "lispc",
            "kuke",
            "lispc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 456,
        "title": "图像分类使用vgg模型如何优化参数，降低测试集上分类错误率。",
        "body": "按照官网提供的图像分类代码，使用其中的vgg模型进行训练，训练步骤200pass，训练数据10类共7000张，测试数据10类共2000张。\r\n```text\r\nPass 136, Batch 0, Cost 0.024843, {'classification_error_evaluator': 0.015625}\r\n......................................................................\r\nTest with Pass 136, {'classification_error_evaluator': 0.1459999978542328}\r\nPass 137, Batch 0, Cost 0.015981, {'classification_error_evaluator': 0.0078125}\r\n......................................................................\r\nTest with Pass 137, {'classification_error_evaluator': 0.13449999690055847}\r\n```\r\n从第75pass开始测试集上分类错误率一直保持在0.12~0.14，请问如何优化参数才能降低测试集上分类错误率。\r\n修改过的参数：\r\n```python\r\nmomentum_optimizer = paddle.optimizer.Momentum(\r\n    momentum=0.9,\r\n    regularization=paddle.optimizer.L2Regularization(rate=0.0002 * 128),\r\n    learning_rate=0.1 / 128.0,\r\n    learning_rate_decay_a=0.1,\r\n    learning_rate_decay_b=7000 * 100, #这个7000按照我的训练集的总数设置过，其他的没有再设置过\r\n    learning_rate_schedule='discexp')\r\n```",
        "state": "closed",
        "user": "Ihuzb",
        "closed_by": "shanyi15",
        "created_at": "2017-11-13T09:59:11+00:00",
        "updated_at": "2018-08-15T09:57:21+00:00",
        "closed_at": "2018-08-15T09:57:21+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 459,
        "title": "has no attribute 'scale_sub_region'",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 126, in <module>\r\n    main()\r\n  File \"infer.py\", line 122, in main\r\n    infer()\r\n  File \"infer.py\", line 89, in infer\r\n    share_rnn_weights=args.share_rnn_weights)\r\n  File \"/paddle/code/models/deep_speech_2/model_utils/model.py\", line 46, in __init__\r\n    rnn_layer_size, use_gru, share_rnn_weights)\r\n  File \"/paddle/code/models/deep_speech_2/model_utils/model.py\", line 307, in _create_network\r\n    share_rnn_weights=share_rnn_weights)\r\n  File \"/paddle/code/models/deep_speech_2/model_utils/network.py\", line 263, in deep_speech_v2_network\r\n    index_range_datas=index_range_datas)\r\n  File \"/paddle/code/models/deep_speech_2/model_utils/network.py\", line 165, in conv_group\r\n    index_range_data=index_range_datas[0])\r\n  File \"/paddle/code/models/deep_speech_2/model_utils/network.py\", line 43, in conv_bn_layer\r\n    scale_sub_region = paddle.layer.scale_sub_region(\r\nAttributeError: 'module' object has no attribute 'scale_sub_region'\r\n\r\n```",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "luotao1",
        "created_at": "2017-11-14T02:38:10+00:00",
        "updated_at": "2018-01-29T07:06:02+00:00",
        "closed_at": "2018-01-29T07:06:02+00:00",
        "comments_count": [
            "lezasantaizi",
            "kuke",
            "lezasantaizi",
            "lezasantaizi",
            "kuke",
            "lezasantaizi",
            "yangliu2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 440,
        "title": "商户流失预警可使用什么算法建模？",
        "body": "",
        "state": "closed",
        "user": "azhua",
        "closed_by": "shanyi15",
        "created_at": "2017-11-09T06:27:04+00:00",
        "updated_at": "2018-08-15T09:57:25+00:00",
        "closed_at": "2018-08-15T09:57:25+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 462,
        "title": "英文首页缺最新状态",
        "body": "在中文首页中，有文档的最新状态和许可证\r\n![image](https://user-images.githubusercontent.com/6836917/32765274-a06d4d44-c944-11e7-91d1-5ab31df7c84d.png)\r\n但英文首页缺少这一部分。\r\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2017-11-14T06:04:39+00:00",
        "updated_at": "2017-11-14T06:19:32+00:00",
        "closed_at": "2017-11-14T06:19:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 468,
        "title": "Add link to new DeepSpeech repo",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-14T14:16:14+00:00",
        "updated_at": "2017-11-14T14:59:18+00:00",
        "closed_at": "2017-11-14T14:59:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 460,
        "title": "URL='To-be-added'",
        "body": "```\r\nURL='To-be-added'\r\nMD5=a19d40cb3b558eb696c44d883f32cfda\r\nTARGET=./baidu_en8k_model.tar.gz\r\n\r\n\r\necho \"Download BaiduEn8k model ...\"\r\ndownload $URL $MD5 $TARGET\r\nif [ $? -ne 0 ]; then\r\n    echo \"Fail to download BaiduEn8k model!\"\r\n    exit 1\r\nfi\r\ntar -zxvf $TARGET\r\n\r\n```",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "luotao1",
        "created_at": "2017-11-14T02:50:29+00:00",
        "updated_at": "2018-01-29T07:04:51+00:00",
        "closed_at": "2018-01-29T07:04:51+00:00",
        "comments_count": [
            "pkuyym",
            "lezasantaizi",
            "lispc",
            "pkuyym",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 464,
        "title": "增加文本/图像/语音等更高一级的目录",
        "body": "能否增加文本/图像/语音等更高一级的目录，使得中英文右侧导航栏展示效果如下：\r\n- models简介\r\n- 文本\r\n 1. 词向量\r\n 2. RNN语言模型\r\n   ……\r\n- 图像\r\n  11. 图像分类\r\n  12. 目标检测\r\n  13. 场景文字识别\r\n- 语音\r\n  14. 语音识别",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2017-11-14T06:26:54+00:00",
        "updated_at": "2018-08-15T09:57:18+00:00",
        "closed_at": "2018-08-15T09:57:18+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 474,
        "title": "NER 中crf的状态特征错误的加上了非线性激活",
        "body": "- 在NER的例子中，调用 crf 层之前依赖于首先通过 fc 层计算状态特征。\r\n- CRF 层在内部会计算状态特征和转移特征的exponetials，并进行全局归一化。因此，fc 层在计算状态特征时不应该使用任何非线性激活。\r\n- `paddle.layer.fc`默认激活函数是 `tanh`，让crf的状态特征计算“意外”地加上了非线性激活。",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-16T02:29:55+00:00",
        "updated_at": "2017-11-16T02:32:24+00:00",
        "closed_at": "2017-11-16T02:32:24+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 471,
        "title": "Bugs in ctr model.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "Superjomn",
        "created_at": "2017-11-15T10:08:21+00:00",
        "updated_at": "2017-11-15T10:30:35+00:00",
        "closed_at": "2017-11-15T10:30:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 480,
        "title": "Currently ci doesn't work properly ",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-17T08:12:57+00:00",
        "updated_at": "2017-11-17T09:12:07+00:00",
        "closed_at": "2017-11-17T09:12:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 476,
        "title": "text_classification reader error",
        "body": "Get follow error log while running  `train.py`  of text_classification model:\r\n```\r\n[INFO 2017-11-16 17:19:51,458 train.py:44] please wait to build the word dictionary ...\r\n[INFO 2017-11-16 17:20:07,138 train.py:101] length of word dictionary is : 5147.\r\nI1116 17:20:07.168130 24638 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nI1116 17:20:07.176143 24638 GradientMachine.cpp:94] Initing parameters..\r\nI1116 17:20:07.186369 24638 GradientMachine.cpp:101] Init parameters done.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 178, in <module>\r\n    main(args)\r\n  File \"train.py\", line 169, in main\r\n    model_save_dir=args.model_save_dir)\r\n  File \"train.py\", line 150, in train\r\n    num_passes=num_passes)\r\n  File \"/home/work/wanghaoshuang/paddle/python/install/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 162, in train\r\n    for batch_id, data_batch in enumerate(reader()):\r\n  File \"/home/work/wanghaoshuang/paddle/python/install/lib/python2.7/site-packages/paddle/v2/minibatch.py\", line 33, in batch_reader\r\n    for instance in r:\r\n  File \"/home/work/wanghaoshuang/paddle/python/install/lib/python2.7/site-packages/paddle/v2/reader/decorator.py\", line 67, in data_reader\r\n    for e in reader():\r\nTypeError: 'function' object is not iterable\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-16T09:31:28+00:00",
        "updated_at": "2017-11-16T10:06:21+00:00",
        "closed_at": "2017-11-16T10:06:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 475,
        "title": "ZeroDivisionError: float division by zero",
        "body": "训练过程中出错：\r\n```text\r\n[INFO 2017-11-16 10:52:46,895 train.py:225] Pass 0, Batch 1000, Cost 0.514772, {'__auc_evaluator_0__': 0.7693212628364563, 'classification_error_evaluator': 0.27489998936653137}\r\nmodel type:  classification\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 270, in <module>\r\n  File \"train.py\", line 270, in <module>\r\n    use_gpu=args.use_gpu)\r\n  File \"train.py\", line 250, in train\r\n    num_passes=num_passes)\r\n  File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 178, in train\r\n  File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 178, in train\r\n    gm=self.__gradient_machine__))\r\n  File \"train.py\", line 232, in _event_handler\r\n    reader=test_reader, feeding=feeding)\r\n  File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 220, in test\r\n  File \"/home/yitengfei/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 220, in test\r\n    evaluator=evaluator, cost=total_cost / num_samples)\r\nZeroDivisionError: float division by zero\r\n```\r\n网络结构是DSSM-classification模型：\r\n```python\r\nclass DSSM(object):\r\n    def __init__(self,\r\n                 dnn_dims=[],\r\n                 vocab_sizes=[],\r\n                 model_type=ModelType.create_classification(),\r\n                 model_arch=ModelArch.create_cnn(),\r\n                 share_semantic_generator=False,\r\n                 class_num=None,\r\n                 share_embed=False,\r\n                 is_infer=False):\r\n        '''\r\n        @dnn_dims: list of int\r\n            dimentions of each layer in semantic vector generator.\r\n        @vocab_sizes: 2-d tuple\r\n            size of both left and right items.\r\n        @model_type: int\r\n            type of task, should be 'rank: 0', 'regression: 1' or 'classification: 2'\r\n        @model_arch: int\r\n            model architecture\r\n        @share_semantic_generator: bool\r\n            whether to share the semantic vector generator for both left and right.\r\n        @share_embed: bool\r\n            whether to share the embeddings between left and right.\r\n        @class_num: int\r\n            number of categories.\r\n        '''\r\n        assert len(\r\n            vocab_sizes\r\n        ) == 2, \"vocab_sizes specify the sizes left and right inputs, and dim should be 2.\"\r\n        assert len(dnn_dims) > 1, \"more than two layers is needed.\"\r\n\r\n        self.dnn_dims = dnn_dims\r\n        self.vocab_sizes = vocab_sizes\r\n        self.share_semantic_generator = share_semantic_generator\r\n        self.share_embed = share_embed\r\n        self.model_type = ModelType(model_type)\r\n        self.model_arch = ModelArch(model_arch)\r\n        self.class_num = class_num\r\n        self.is_infer = is_infer\r\n        logger.warning(\"build DSSM model with config of %s, %s\" %\r\n                       (self.model_type, self.model_arch))\r\n        logger.info(\"vocabulary sizes: %s\" % str(self.vocab_sizes))\r\n\r\n        # bind model architecture\r\n        _model_arch = {\r\n            'cnn': self.create_cnn,\r\n            'fc': self.create_fc,\r\n            'rnn': self.create_rnn,\r\n        }\r\n\r\n        def _model_arch_creater(emb, prefix=''):\r\n            sent_vec = _model_arch.get(str(model_arch))(emb, prefix)\r\n            dnn = self.create_dnn(sent_vec, prefix)\r\n            return dnn\r\n\r\n        self.model_arch_creater = _model_arch_creater\r\n\r\n        # build model type\r\n        _model_type = {\r\n            'classification': self._build_classification_model,\r\n            'rank': self._build_rank_model,\r\n            'regression': self._build_regression_model,\r\n        }\r\n        print 'model type: ', str(self.model_type)\r\n        self.model_type_creater = _model_type[str(self.model_type)]\r\n\r\n    def __call__(self):\r\n        return self.model_type_creater()\r\n\r\n    def create_embedding(self, input, prefix=''):\r\n        '''\r\n        Create an embedding table whose name has a `prefix`.\r\n        '''\r\n        logger.info(\"create embedding table [%s] which dimention is %d\" %\r\n                    (prefix, self.dnn_dims[0]))\r\n        emb = paddle.layer.embedding(\r\n            input=input,\r\n            size=self.dnn_dims[0],\r\n            param_attr=ParamAttr(name='%s_emb.w' % prefix))\r\n        return emb\r\n\r\n    def create_fc(self, emb, prefix=''):\r\n        '''\r\n        A multi-layer fully connected neural networks.\r\n\r\n        @emb: paddle.layer\r\n            output of the embedding layer\r\n        @prefix: str\r\n            prefix of layers' names, used to share parameters between more than one `fc` parts.\r\n        '''\r\n        _input_layer = paddle.layer.pooling(\r\n            input=emb, pooling_type=paddle.pooling.Max())\r\n        fc = paddle.layer.fc(input=_input_layer, size=self.dnn_dims[1])\r\n        return fc\r\n\r\n    def create_rnn(self, emb, prefix=''):\r\n        '''\r\n        A GRU sentence vector learner.\r\n        '''\r\n        gru = paddle.layer.gru_memory(\r\n            input=emb, )\r\n        sent_vec = paddle.layer.last_seq(gru)\r\n        return sent_vec\r\n\r\n    def create_cnn(self, emb, prefix=''):\r\n        '''\r\n        A multi-layer CNN.\r\n\r\n        @emb: paddle.layer\r\n            output of the embedding layer\r\n        @prefix: str\r\n            prefix of layers' names, used to share parameters between more than one `cnn` parts.\r\n        '''\r\n\r\n        def create_conv(context_len, hidden_size, prefix):\r\n            key = \"%s_%d_%d\" % (prefix, context_len, hidden_size)\r\n            conv = paddle.networks.sequence_conv_pool(\r\n                input=emb,\r\n                context_len=context_len,\r\n                hidden_size=hidden_size,\r\n                # set parameter attr for parameter sharing\r\n                context_proj_param_attr=ParamAttr(name=key + 'contex_proj.w'),\r\n                fc_param_attr=ParamAttr(name=key + '_fc.w'),\r\n                fc_bias_attr=ParamAttr(name=key + '_fc.b'),\r\n                pool_bias_attr=ParamAttr(name=key + '_pool.b'))\r\n            return conv\r\n\r\n        logger.info('create a sequence_conv_pool which context width is 3')\r\n        conv_3 = create_conv(3, self.dnn_dims[1], \"cnn\")\r\n        logger.info('create a sequence_conv_pool which context width is 4')\r\n        conv_4 = create_conv(4, self.dnn_dims[1], \"cnn\")\r\n\r\n        return conv_3, conv_4\r\n\r\n    def create_dnn(self, sent_vec, prefix):\r\n        # if more than three layers, than a fc layer will be added.\r\n        if len(self.dnn_dims) > 1:\r\n            _input_layer = sent_vec\r\n            for id, dim in enumerate(self.dnn_dims[1:]):\r\n                name = \"%s_fc_%d_%d\" % (prefix, id, dim)\r\n                logger.info(\"create fc layer [%s] which dimention is %d\" %\r\n                            (name, dim))\r\n                fc = paddle.layer.fc(\r\n                    name=name,\r\n                    input=_input_layer,\r\n                    size=dim,\r\n                    act=paddle.activation.Tanh(),\r\n                    param_attr=ParamAttr(name='%s.w' % name),\r\n                    bias_attr=ParamAttr(name='%s.b' % name))\r\n                _input_layer = fc\r\n        return _input_layer\r\n\r\n    def _build_classification_model(self):\r\n        logger.info(\"build classification model\")\r\n        assert self.model_type.is_classification()\r\n        return self._build_classification_or_regression_model(\r\n            is_classification=True)\r\n\r\n    def _build_regression_model(self):\r\n        logger.info(\"build regression model\")\r\n        assert self.model_type.is_regression()\r\n        return self._build_classification_or_regression_model(\r\n            is_classification=False)\r\n\r\n    def _build_rank_model(self):\r\n        '''\r\n        Build a pairwise rank model, and the cost is returned.\r\n\r\n        A pairwise rank model has 3 inputs:\r\n          - source sentence\r\n          - left_target sentence\r\n          - right_target sentence\r\n          - label, 1 if left_target should be sorted in front of right_target, otherwise 0.\r\n        '''\r\n        logger.info(\"build rank model\")\r\n        assert self.model_type.is_rank()\r\n        source = paddle.layer.data(\r\n            name='source_input',\r\n            type=paddle.data_type.integer_value_sequence(self.vocab_sizes[0]))\r\n        left_target = paddle.layer.data(\r\n            name='left_target_input',\r\n            type=paddle.data_type.integer_value_sequence(self.vocab_sizes[1]))\r\n        right_target = paddle.layer.data(\r\n            name='right_target_input',\r\n            type=paddle.data_type.integer_value_sequence(self.vocab_sizes[1]))\r\n        if not self.is_infer:\r\n            label = paddle.layer.data(\r\n                name='label_input', type=paddle.data_type.integer_value(1))\r\n\r\n        prefixs = '_ _ _'.split(\r\n        ) if self.share_semantic_generator else 'source left right'.split()\r\n        embed_prefixs = '_ _'.split(\r\n        ) if self.share_embed else 'source target target'.split()\r\n\r\n        word_vecs = []\r\n        for id, input in enumerate([source, left_target, right_target]):\r\n            x = self.create_embedding(input, prefix=embed_prefixs[id])\r\n            word_vecs.append(x)\r\n\r\n        semantics = []\r\n        for id, input in enumerate(word_vecs):\r\n            x = self.model_arch_creater(input, prefix=prefixs[id])\r\n            semantics.append(x)\r\n\r\n        # cossim score of source and left_target\r\n        left_score = paddle.layer.cos_sim(semantics[0], semantics[1])\r\n        # cossim score of source and right target\r\n        right_score = paddle.layer.cos_sim(semantics[0], semantics[2])\r\n\r\n        if not self.is_infer:\r\n            # rank cost\r\n            cost = paddle.layer.rank_cost(left_score, right_score, label=label)\r\n            # prediction = left_score - right_score\r\n            # but this operator is not supported currently.\r\n            # so AUC will not used.\r\n            return cost, None, label\r\n        return None, [left_score, right_score], label\r\n\r\n    def _build_classification_or_regression_model(self, is_classification):\r\n        '''\r\n        Build a classification/regression model, and the cost is returned.\r\n\r\n        A Classification has 3 inputs:\r\n          - source sentence\r\n          - target sentence\r\n          - classification label\r\n\r\n        '''\r\n        if is_classification:\r\n            # prepare inputs.\r\n            assert self.class_num\r\n\r\n        source = paddle.layer.data(\r\n            name='source_input',\r\n            type=paddle.data_type.integer_value_sequence(self.vocab_sizes[0]))\r\n        target = paddle.layer.data(\r\n            name='target_input',\r\n            type=paddle.data_type.integer_value_sequence(self.vocab_sizes[1]))\r\n        label = paddle.layer.data(\r\n            name='label_input',\r\n            type=paddle.data_type.integer_value(self.class_num)\r\n            if is_classification else paddle.data_type.dense_vector(1))\r\n\r\n        prefixs = '_ _'.split(\r\n        ) if self.share_semantic_generator else 'left right'.split()\r\n        embed_prefixs = '_ _'.split(\r\n        ) if self.share_embed else 'left right'.split()\r\n\r\n        word_vecs = []\r\n        for id, input in enumerate([source, target]):\r\n            x = self.create_embedding(input, prefix=embed_prefixs[id])\r\n            word_vecs.append(x)\r\n\r\n        semantics = []\r\n        for id, input in enumerate(word_vecs):\r\n            x = self.model_arch_creater(input, prefix=prefixs[id])\r\n            semantics.append(x)\r\n\r\n        if is_classification:\r\n            concated_vector = paddle.layer.concat(semantics)\r\n            name = \"final\"\r\n            logger.info(\"create fc layer [%s] which dimention is %d\" %\r\n                            (name, 32))\r\n            final = paddle.layer.fc(\r\n                    name=name,\r\n                    input=concated_vector,\r\n                    size=32,\r\n                    act=paddle.activation.Tanh(),\r\n                    param_attr=ParamAttr(name='%s.w' % name),\r\n                    bias_attr=ParamAttr(name='%s.b' % name))\r\n            name = \"final2\"\r\n            logger.info(\"create fc layer [%s] which dimention is %d\" %\r\n                            (name, 16))\r\n            final2 = paddle.layer.fc(\r\n                    name=name,\r\n                    input=final,\r\n                    size=16,\r\n                    act=paddle.activation.Tanh(),\r\n                    param_attr=ParamAttr(name='%s.w' % name),\r\n                    bias_attr=ParamAttr(name='%s.b' % name))\r\n            prediction = paddle.layer.fc(\r\n                input=final2,\r\n                size=self.class_num,\r\n                act=paddle.activation.Softmax())\r\n            cost = paddle.layer.classification_cost(\r\n                input=prediction, label=label)\r\n        else:\r\n            prediction = paddle.layer.cos_sim(*semantics)\r\n            cost = paddle.layer.mse_cost(prediction, label)\r\n\r\n        if not self.is_infer:\r\n            return cost, prediction, label, semantics\r\n        return None, prediction, label\r\n```",
        "state": "closed",
        "user": "fty8788",
        "closed_by": "fty8788",
        "created_at": "2017-11-16T04:13:19+00:00",
        "updated_at": "2017-11-16T07:04:46+00:00",
        "closed_at": "2017-11-16T07:04:46+00:00",
        "comments_count": [
            "wanghaoshuang",
            "fty8788"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 482,
        "title": "How to use a model from TF",
        "body": "How to use a model from TF",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-22T09:46:44+00:00",
        "updated_at": "2017-12-04T08:05:01+00:00",
        "closed_at": "2017-12-04T08:05:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 487,
        "title": "The AUC evaluator throws an error in LTR example.",
        "body": "```text\r\nI1123 14:33:30.425339 11920 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=4 \r\nI1123 14:33:30.439476 11920 GradientMachine.cpp:94] Initing parameters..\r\nI1123 14:33:30.439570 11920 GradientMachine.cpp:101] Init parameters done.\r\nPass 0 Batch 0 Cost 0.693153992\r\n...................................................................................................Pass 0 Batch 100 Cost 0.667165222\r\n...................................................................................................Pass 0 Batch 200 Cost 0.615809021\r\n...................................................................................................Pass 0 Batch 300 Cost 0.554315910\r\n...................................................................................................Pass 0 Batch 400 Cost 0.500374222\r\n...................................................................................................Pass 0 Batch 500 Cost 0.452697983\r\n...................................................................................................Pass 0 Batch 600 Cost 0.331662292\r\n.........................F1123 14:34:10.959939 11920 Evaluator.cpp:460] Check failed: binIdx <= kBinNum_ bin index [16908496] out of range, predict value[1.00783]\r\n*** Check failure stack trace: ***\r\n    @     0x7f7f1e92cf4d  google::LogMessage::Fail()\r\n    @     0x7f7f1e9309fc  google::LogMessage::SendToLog()\r\n    @     0x7f7f1e92ca73  google::LogMessage::Flush()\r\n    @     0x7f7f1e931f0e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7f1e51e50d  paddle::AucEvaluator::evalImp()\r\n    @     0x7f7f1e51d621  paddle::Evaluator::eval()\r\n    @     0x7f7f1e4f1c8a  paddle::CombinedEvaluator::eval()\r\n    @     0x7f7f1e4efb84  paddle::NeuralNetwork::eval()\r\n    @     0x7f7f1e504d54  paddle::MultiGradientMachine::eval()\r\n    @     0x7f7f1e9012f4  GradientMachine::eval()\r\n    @     0x7f7f1e3692a2  _wrap_GradientMachine_eval\r\n    @     0x7f7f5698c3a3  PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130  PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1  PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130  PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1  PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130  PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1  PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130  PyEval_EvalCodeEx\r\n    @     0x7f7f5698e242  PyEval_EvalCode\r\n    @     0x7f7f569a862c  run_mod\r\n    @     0x7f7f569a8700  PyRun_FileExFlags\r\n    @     0x7f7f569a9c0c  PyRun_SimpleFileExFlags\r\n    @     0x7f7f569bb4cc  Py_Main\r\n    @       0x318ae1ecdd  (unknown)\r\n*** Aborted at 1511418850 (unix time) try \"date -d @1511418850\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1fb00002e90) received by PID 11920 (TID 0x7f7f56896700) from PID 11920; stack trace: ***\r\n    @       0x318b20f500 (unknown)\r\n    @       0x318ae328a5 (unknown)\r\n    @       0x318ae34085 (unknown)\r\n    @     0x7f7f1e93758b google::FindSymbol()\r\n    @     0x7f7f1e937f4a google::GetSymbolFromObjectFile()\r\n    @     0x7f7f1e938612 google::SymbolizeAndDemangle()\r\n    @     0x7f7f1e935e18 google::DumpStackTrace()\r\n    @     0x7f7f1e935ed6 google::DumpStackTraceAndExit()\r\n    @     0x7f7f1e92cf4d google::LogMessage::Fail()\r\n    @     0x7f7f1e9309fc google::LogMessage::SendToLog()\r\n    @     0x7f7f1e92ca73 google::LogMessage::Flush()\r\n    @     0x7f7f1e931f0e google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7f1e51e50d paddle::AucEvaluator::evalImp()\r\n    @     0x7f7f1e51d621 paddle::Evaluator::eval()\r\n    @     0x7f7f1e4f1c8a paddle::CombinedEvaluator::eval()\r\n    @     0x7f7f1e4efb84 paddle::NeuralNetwork::eval()\r\n    @     0x7f7f1e504d54 paddle::MultiGradientMachine::eval()\r\n    @     0x7f7f1e9012f4 GradientMachine::eval()\r\n    @     0x7f7f1e3692a2 _wrap_GradientMachine_eval\r\n    @     0x7f7f5698c3a3 PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130 PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1 PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130 PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1 PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130 PyEval_EvalCodeEx\r\n    @     0x7f7f5698c4a1 PyEval_EvalFrameEx\r\n    @     0x7f7f5698e130 PyEval_EvalCodeEx\r\n    @     0x7f7f5698e242 PyEval_EvalCode\r\n    @     0x7f7f569a862c run_mod\r\n    @     0x7f7f569a8700 PyRun_FileExFlags\r\n    @     0x7f7f569a9c0c PyRun_SimpleFileExFlags\r\n    @     0x7f7f569bb4cc Py_Main\r\n\r\n```",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-23T06:36:31+00:00",
        "updated_at": "2017-11-23T07:29:50+00:00",
        "closed_at": "2017-11-23T07:29:50+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 486,
        "title": "models/ctr跑完auc只有0.52左右",
        "body": "代码用的models/ctr，数据集用的是代码中推荐的：Kaggle上CTR任务的数据集，使用avazu_data_processer.py处理后保留500w左右的数据用于train，infer数据集使用默认的100条左右，auc使用sklearn.metrics.roc_auc_score计算，但是auc只有0.52左右，是哪里出错了吗，还是只能达到这个效果？",
        "state": "closed",
        "user": "buptwds",
        "closed_by": "Superjomn",
        "created_at": "2017-11-23T05:39:19+00:00",
        "updated_at": "2019-12-04T08:05:46+00:00",
        "closed_at": "2018-03-11T02:25:16+00:00",
        "comments_count": [
            "QiJune",
            "QiJune",
            "Superjomn",
            "buptwds",
            "Superjomn",
            "buptwds",
            "Superjomn",
            "buptwds",
            "buptwds",
            "Superjomn",
            "buptwds",
            "Superjomn",
            "shuDaoNan9"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 490,
        "title": "Need make class count configurable for ssd",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-24T10:21:56+00:00",
        "updated_at": "2017-11-24T12:13:51+00:00",
        "closed_at": "2017-11-24T12:13:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 497,
        "title": "models/conv_seq2seq 运行时会输出 initial_smart 相关信息",
        "body": "在运行该model时，在使用BN时，会输出如下日志：\r\n```\r\n[INFO 2017-10-30 20:54:45,684 layers.py:3080] Use initial_smart, but dims not set. Initial_smart may not be used in this layer\r\n```\r\n但不影响训练，不知道是怎么回事",
        "state": "closed",
        "user": "ranqiu92",
        "closed_by": "ranqiu92",
        "created_at": "2017-11-28T12:12:34+00:00",
        "updated_at": "2018-03-15T06:42:02+00:00",
        "closed_at": "2018-03-15T06:42:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 489,
        "title": "model/text_classification 使用内置语料集训练模型后，预测时出错，具体如下",
        "body": "```text\r\nI1123 09:23:54.320137    84 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 91, in <module>\r\n    batch_size=10)\r\n  File \"infer.py\", line 58, in infer\r\n    for idx, item in enumerate(test_reader):\r\nTypeError: 'function' object is not iterable\r\n```\r\npaddle镜像用的是https://hub.docker.com/r/paddlepaddle/paddle/tags/ latest的，model下载的最新的",
        "state": "closed",
        "user": "yatouxingren",
        "closed_by": "QiJune",
        "created_at": "2017-11-23T09:36:48+00:00",
        "updated_at": "2017-11-27T08:03:25+00:00",
        "closed_at": "2017-11-27T08:03:25+00:00",
        "comments_count": [
            "QiJune",
            "QiJune"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 488,
        "title": "How to train a pascal voc based SSD model from the very beginning without pretrained model?",
        "body": "I did not use the pretrained model and want to train a new model from initialized parameters but I got the Floating point exception (core dumped) error. What should I do.\r\n![image](https://user-images.githubusercontent.com/13977118/33161379-3f365afe-d05e-11e7-9b74-4690804f4f74.png)\r\n",
        "state": "closed",
        "user": "TheodoreG",
        "closed_by": "wangkuiyi",
        "created_at": "2017-11-23T06:55:43+00:00",
        "updated_at": "2018-03-10T18:17:41+00:00",
        "closed_at": "2018-03-10T18:17:41+00:00",
        "comments_count": [
            "QiJune",
            "pkuyym",
            "wangkuiyi"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 499,
        "title": "Update images for examples",
        "body": "Some images in the Paddle Models repo should be redrawn (There are directly from the Internet (we add the reference, however, this may not be enough.)) :\r\n1.  https://github.com/PaddlePaddle/models/blob/develop/ctr/images/wide_deep.png\r\n2. https://github.com/PaddlePaddle/models/blob/develop/mt_with_external_memory/image/lstm_c_state.png\r\n3.  https://github.com/PaddlePaddle/models/blob/develop/mt_with_external_memory/image/turing_machine_cartoon.gif\r\n4. images in this directory: https://github.com/PaddlePaddle/models/tree/develop/dssm/images\r\n5. https://github.com/PaddlePaddle/models/blob/develop/scene_text_recognition/images/ctc.png\r\n6. https://github.com/PaddlePaddle/models/blob/develop/scene_text_recognition/images/feature_vector.png\r\n7. https://github.com/PaddlePaddle/models/blob/develop/scene_text_recognition/images/transcription.png",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-11-29T02:50:49+00:00",
        "updated_at": "2018-08-15T09:57:15+00:00",
        "closed_at": "2018-08-15T09:57:15+00:00",
        "comments_count": [
            "luotao1",
            "lcy-seso",
            "luotao1",
            "lcy-seso",
            "jetfuel",
            "lcy-seso",
            "varunarora",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 501,
        "title": "语言模型中如何通过classification_cost来计算Perplexity?",
        "body": "在语言模型任务中，困惑度(Perplexity)是常用的一个评价指标，可以通过交叉熵的幂运算直接得到，在paddle中如何计算呢？",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "peterzhang2029",
        "created_at": "2017-11-29T05:48:10+00:00",
        "updated_at": "2017-11-29T08:10:36+00:00",
        "closed_at": "2017-11-29T08:10:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 500,
        "title": "for logistic regreetion, got \"ValueError: The input should be a vector, please check your input data.\"",
        "body": "```python\r\n1. def reader():\r\n2.          UNK_ID = word_dict[\"<UNK>\"]\r\n3.          word_col = 1\r\n4.          teacher_label_col = 0\r\n5.          for file_name in os.listdir(data_dir):\r\n6.              with open(os.path.join(data_dir, file_name), \"r\") as f:\r\n7.                       for line in f:\r\n8.                      line_split = line.strip().split(\"\\t\")\r\n9.                      word_ids = [\r\n10.                          word_dict.get(w, UNK_ID)\r\n11.                         for w in line_split[word_col].split() ]\r\n12.                      y_value = float(line_split[teacher_label_col])\r\n13.                     yield word_ids, y_value\r\n14.      return reader\r\n```\r\nthis is my reader code, y_value is float type, x value is writed as words_ids like [12, 34, 55]. when run got \"ValueError:The input should be a vector, please check your input data.\" when I try to replace the line 12 to \"y_value = [float(line_split[teacher_label_col])]\" , got a core bug..",
        "state": "closed",
        "user": "690609237",
        "closed_by": "shanyi15",
        "created_at": "2017-11-29T03:11:36+00:00",
        "updated_at": "2018-08-15T09:57:10+00:00",
        "closed_at": "2018-08-15T09:57:10+00:00",
        "comments_count": [
            "wangkuiyi",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 503,
        "title": "conv_seq2seq调参优化",
        "body": "  训练 models/conv_seq2seq时，使用说明中的训练脚本，默认网络配置中embedding的initial_std设置为0.05 。\r\n  预测时，beam_size=3, 在第16个pass（从1开始计数）取得 dev集（6969条）上最高BLUE 28.51，此时test集（6750条）上为26.05。\r\n  整个训练过程中的网络参数绝对值 及 相应梯度绝对值的统计信息如下(横轴为pass数):\r\n![___fc_layer_0__ w0](https://user-images.githubusercontent.com/31875089/33362939-4b325da2-d519-11e7-9657-28332934e47e.jpg)\r\n![___fc_layer_0__ wbias](https://user-images.githubusercontent.com/31875089/33362941-4b619c02-d519-11e7-8731-8e28c960186b.jpg)\r\n![___fc_layer_1__ w0](https://user-images.githubusercontent.com/31875089/33362942-4b925afe-d519-11e7-8beb-6aa41c57ff45.jpg)\r\n![___fc_layer_2__ w0](https://user-images.githubusercontent.com/31875089/33362943-4bbf8038-d519-11e7-9aa9-8fd5dcc02a51.jpg)\r\n![___fc_layer_3__ w0](https://user-images.githubusercontent.com/31875089/33362944-4bed9cb6-d519-11e7-8125-c5166e629369.jpg)\r\n![___fc_layer_4__ w0](https://user-images.githubusercontent.com/31875089/33362945-4c1e9122-d519-11e7-941d-a05253325995.jpg)\r\n![___fc_layer_5__ w0](https://user-images.githubusercontent.com/31875089/33362947-4c4e7b26-d519-11e7-96e6-fd54f6dad9dd.jpg)\r\n![___fc_layer_6__ w0](https://user-images.githubusercontent.com/31875089/33362948-4c7e01fc-d519-11e7-9d64-e8aee2f777a0.jpg)\r\n![___fc_layer_6__ wbias](https://user-images.githubusercontent.com/31875089/33362949-4cabf7a6-d519-11e7-8eeb-d86e6210c187.jpg)\r\n![___fc_layer_7__ w0](https://user-images.githubusercontent.com/31875089/33362950-4cdb7a44-d519-11e7-8185-fa590952f357.jpg)\r\n![___fc_layer_7__ wbias](https://user-images.githubusercontent.com/31875089/33362951-4d2088a0-d519-11e7-8ea4-3e848f6f029c.jpg)\r\n![___fc_layer_8__ w0](https://user-images.githubusercontent.com/31875089/33362952-4d4f3fc4-d519-11e7-9736-da68744bb2af.jpg)\r\n![___fc_layer_9__ __recurrent_group_0__ w0](https://user-images.githubusercontent.com/31875089/33362953-4d808b42-d519-11e7-98b7-b9d863c357c0.jpg)\r\n![___fc_layer_10__ __recurrent_group_0__ w0](https://user-images.githubusercontent.com/31875089/33362954-4daf517a-d519-11e7-85dc-6dcc8597979a.jpg)\r\n![___fc_layer_10__ __recurrent_group_0__ wbias](https://user-images.githubusercontent.com/31875089/33362955-4ddd56ba-d519-11e7-86b1-4da83c86e72c.jpg)\r\n![___fc_layer_11__ w0](https://user-images.githubusercontent.com/31875089/33362956-4e0a994a-d519-11e7-8024-0ebe7fb7ecc5.jpg)\r\n![___fc_layer_12__ __recurrent_group_1__ w0](https://user-images.githubusercontent.com/31875089/33362957-4e3f278c-d519-11e7-99c0-250a127b2091.jpg)\r\n![___fc_layer_13__ __recurrent_group_1__ w0](https://user-images.githubusercontent.com/31875089/33362958-4e6fda08-d519-11e7-92f6-322908628070.jpg)\r\n![___fc_layer_13__ __recurrent_group_1__ wbias](https://user-images.githubusercontent.com/31875089/33362959-4e9f193a-d519-11e7-9c46-88a935827443.jpg)\r\n![___fc_layer_14__ w0](https://user-images.githubusercontent.com/31875089/33362960-4ed1c218-d519-11e7-9d44-69e00c3c3d2b.jpg)\r\n![___fc_layer_15__ __recurrent_group_2__ w0](https://user-images.githubusercontent.com/31875089/33362961-4f002c34-d519-11e7-8bc4-816af6c7f809.jpg)\r\n![___fc_layer_16__ __recurrent_group_2__ w0](https://user-images.githubusercontent.com/31875089/33362962-4f2e555a-d519-11e7-8a3c-4718aeca27a8.jpg)\r\n![___fc_layer_16__ __recurrent_group_2__ wbias](https://user-images.githubusercontent.com/31875089/33362963-4f5c8bc8-d519-11e7-8c04-9c2292c34206.jpg)\r\n![___fc_layer_17__ w0](https://user-images.githubusercontent.com/31875089/33362964-4f8bebde-d519-11e7-8e59-689f36d7858f.jpg)\r\n![___fc_layer_17__ wbias](https://user-images.githubusercontent.com/31875089/33362965-4fbccaa6-d519-11e7-9345-b45eeed20143.jpg)\r\n![___fc_layer_18__ w0](https://user-images.githubusercontent.com/31875089/33362966-5001b300-d519-11e7-9d4f-f0d5fd1d8d2d.jpg)\r\n![___fc_layer_18__ wbias](https://user-images.githubusercontent.com/31875089/33362967-503553ea-d519-11e7-95b6-149d06f6ac9f.jpg)\r\n![___mixed_0__ w0](https://user-images.githubusercontent.com/31875089/33362968-50645456-d519-11e7-9fab-154cb13a7800.jpg)\r\n![___mixed_5__ w0](https://user-images.githubusercontent.com/31875089/33362969-50931034-d519-11e7-8e00-dcb73efeb8a3.jpg)\r\n![___mixed_10__ w0](https://user-images.githubusercontent.com/31875089/33362970-50c181d0-d519-11e7-8c95-869074582306.jpg)\r\n![___mixed_15__ w0](https://user-images.githubusercontent.com/31875089/33362971-50faa56e-d519-11e7-9ad2-1a6dc8508707.jpg)\r\n![___mixed_20__ w0](https://user-images.githubusercontent.com/31875089/33362973-513be29a-d519-11e7-8438-1168c3599d10.jpg)\r\n![___mixed_25__ w0](https://user-images.githubusercontent.com/31875089/33362974-5174b26e-d519-11e7-9558-0fb2f41fbaa8.jpg)\r\n![___mixed_29__ __recurrent_group_0__ w0](https://user-images.githubusercontent.com/31875089/33362975-51a30934-d519-11e7-9d88-f223cceb6a08.jpg)\r\n![___mixed_29__ __recurrent_group_0__ wbias](https://user-images.githubusercontent.com/31875089/33362976-51d1a8e8-d519-11e7-8c12-5a765d102a73.jpg)\r\n![___mixed_30__ w0](https://user-images.githubusercontent.com/31875089/33362977-51fff6bc-d519-11e7-86c6-41f03cf65520.jpg)\r\n![___mixed_34__ __recurrent_group_1__ w0](https://user-images.githubusercontent.com/31875089/33362978-52324e32-d519-11e7-9956-0320488178c3.jpg)\r\n![___mixed_34__ __recurrent_group_1__ wbias](https://user-images.githubusercontent.com/31875089/33362979-5261fb8c-d519-11e7-8d71-0982187f8928.jpg)\r\n![___mixed_35__ w0](https://user-images.githubusercontent.com/31875089/33362980-5291dadc-d519-11e7-9d50-7589b94bca07.jpg)\r\n![___mixed_39__ __recurrent_group_2__ w0](https://user-images.githubusercontent.com/31875089/33362982-52c3f832-d519-11e7-80b8-0b19b7b6fae7.jpg)\r\n![___mixed_39__ __recurrent_group_2__ wbias](https://user-images.githubusercontent.com/31875089/33362983-52f3cc6a-d519-11e7-97fe-4e34127b97cb.jpg)\r\n![_src_pos_emb w0](https://user-images.githubusercontent.com/31875089/33362985-5336441e-d519-11e7-8363-dc5988c5879e.jpg)\r\n![_src_word_emb w0](https://user-images.githubusercontent.com/31875089/33362986-53723afa-d519-11e7-8cad-b07ec96785d6.jpg)\r\n![_trg_pos_emb w0](https://user-images.githubusercontent.com/31875089/33362987-53a102b8-d519-11e7-8070-2a6748059af9.jpg)\r\n![_trg_word_emb w0](https://user-images.githubusercontent.com/31875089/33362988-53cfa51e-d519-11e7-9e0b-9e5fc91d8317.jpg)\r\n",
        "state": "closed",
        "user": "ranqiu92",
        "closed_by": "ranqiu92",
        "created_at": "2017-11-29T07:27:10+00:00",
        "updated_at": "2018-02-03T10:38:29+00:00",
        "closed_at": "2018-02-03T10:38:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 506,
        "title": "Implement Policy Gradients demo with refactored API",
        "body": "## 1. 任务描述\r\n假设有一个阶梯，连接A、B点，player从A点出发，每一步只能向前走一步或向后走一步，到达B点即为完成任务。我们希望训练一个聪明的player，它知道怎么最快的从A点到达B点。\r\n我们在命令行以下边的形式模拟任务：\r\n```\r\nA - O - - - - - B\r\n```\r\n一个‘-'代表一个阶梯，A点在行头，B点在行末，O代表player当前在的位置。\r\n\r\n## 2. Policy Gradient\r\n### 2.1 模型\r\n#### inputyer\r\n模型的输入是player观察到的当前阶梯的状态$S$, 要包含阶梯的长度和player当前的位置信息。\r\n在命令行模拟的情况下，player的位置和阶梯长度连个变量足以表示当前的状态，但是我们为了便于将这个demo推广到更复杂的任务场景，我们这里用一个向量来表示游戏状态$S$.\r\n向量$S$的长度为阶梯的长度，每一维代表一个阶梯，player所在的位置为1，其它位置为0.\r\n下边是一个例子：\r\n```\r\nS = [0, 1, 0, 0]  // 阶梯长度为4，player在第二个阶梯上。\r\n```\r\n#### hidden layer\r\n隐藏层采用两个全连接layer `FC_1`和`FC_2`, 其中`FC_1` 的size为10， `FC_2`的size为2. \r\n\r\n#### output layer\r\n我们使用softmax将`FC_2`的output映射为所有可能的动作（前进或后退）的概率分布（Probability of taking the action）,即为一个二维向量`act_probs`, 其中，`act_probs[0]` 为后退的概率，`act_probs[1]`为前进的概率。\r\n\r\n#### 模型表示\r\n我将我们的player模型(actor)形式化表示如下：\r\n$$a = \\pi_\\theta(s)$$\r\n其中$\\theta$表示模型的参数，$s$是输入状态。",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-30T12:58:19+00:00",
        "updated_at": "2018-01-19T09:43:39+00:00",
        "closed_at": "2018-01-19T09:43:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 509,
        "title": "How to implement the Inception-ResNet-v2 model",
        "body": "How to implement the Inception-ResNet-v2 model in PaddlePaddle",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-30T15:52:54+00:00",
        "updated_at": "2017-12-20T12:15:19+00:00",
        "closed_at": "2017-12-20T12:15:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 511,
        "title": "调整ltr代码结构",
        "body": "调整ltr代码结构以与其他模型代码结构一致",
        "state": "closed",
        "user": "will-am",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-01T03:26:44+00:00",
        "updated_at": "2017-12-04T06:16:23+00:00",
        "closed_at": "2017-12-04T06:16:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 507,
        "title": "Add a tutorial for policy gradient",
        "body": "[A rendered version tutorial](https://wanghaoshuang.github.io/2017/12/Policy-Gradient-RL-by-PaddlePaddle/)\r\n 内容为:\r\n - 任务描述\r\n -  模型\r\n -  策略（目标函数）\r\n -  算法（Gradient ascent）\r\n -  PaddlePaddle实现\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "lcy-seso",
        "created_at": "2017-11-30T12:59:57+00:00",
        "updated_at": "2018-01-19T09:43:39+00:00",
        "closed_at": "2018-01-19T09:43:39+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 512,
        "title": "运行nested_sequence目录下的文本分类的例子出错",
        "body": "执行`python train.py` 后报错：\r\n```\r\n[CRITICAL 2017-12-01 16:59:20,940 layers.py:1058] When the name field of param_attr is manually specified and the input is a list, the param_attr should also be a list with each item being the param_attr for each input item. If only one named param_attr is provided, all the input items would share this parameter.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 195, in <module>\r\n    train()\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/click/core.py\", line 722, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/click/core.py\", line 697, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/click/core.py\", line 895, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/click/core.py\", line 535, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"train.py\", line 150, in train\r\n    cost, prob, label = nested_net(dict_dim, class_num, is_infer=False)\r\n  File \"/home/zhangchao/code/models/models/nested_sequence/text_classification/network_conf.py\", line 47, in nested_net\r\n    step=cnn_cov_group)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py\", line 4068, in recurrent_group\r\n    layer_outs = step(*in_args)\r\n  File \"/home/zhangchao/code/models/models/nested_sequence/text_classification/network_conf.py\", line 25, in cnn_cov_group\r\n    act=paddle.activation.Linear())\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py\", line 410, in wrapper\r\n    return method(*args, **kwargs)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py\", line 1058, in fc_layer\r\n    \"When the name field of param_attr is manually specified \"\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/trainer/config_parser.py\", line 4228, in my_fatal\r\n    raise Exception()\r\nException\r\n```\r\n\r\n主要是由于fc_layer的更新，使得不能默认的共享参数，导致报错。",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "peterzhang2029",
        "created_at": "2017-12-01T09:02:26+00:00",
        "updated_at": "2017-12-01T09:31:26+00:00",
        "closed_at": "2017-12-01T09:31:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 514,
        "title": "自带的flowers下载脚本重复下载数据",
        "body": "用自带的分类脚本对flowers数据集分类时，图像压缩包总是重复下载\r\ndownload后对图像进行md5校验，程序中给出的DATA_MD5和实际下载压缩包的DATA_MD5不同",
        "state": "closed",
        "user": "bit1002lst",
        "closed_by": "luotao1",
        "created_at": "2017-12-01T12:12:16+00:00",
        "updated_at": "2017-12-28T10:18:48+00:00",
        "closed_at": "2017-12-28T10:18:48+00:00",
        "comments_count": [
            "will-am",
            "wft8108",
            "wft8108"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 516,
        "title": "NER模型中执行默认的预测程序出错",
        "body": "error log: \r\n```\r\nI1204 19:16:10.800665 20558 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 62, in <module>\r\n    target_file=\"data/target.txt\")\r\n  File \"infer.py\", line 33, in infer\r\n    gzip.open(model_path, \"r\"))\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/gzip.py\", line 34, in open\r\n    return GzipFile(filename, mode, compresslevel)\r\n  File \"/home/zhangchao/.jumbo/lib/python2.7/gzip.py\", line 89, in __init__\r\n    fileobj = self.myfileobj = __builtin__.open(filename, mode or 'rb')\r\nIOError: [Errno 2] No such file or directory: 'models/params_pass_0.tar.gz'\r\n```\r\n应该是训练配置中默认的文件夹设置有误",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-04T11:20:33+00:00",
        "updated_at": "2017-12-04T11:52:49+00:00",
        "closed_at": "2017-12-04T11:52:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 519,
        "title": "CTR中文文档误删",
        "body": "#266在增加CTR英文README的时候，把中文READEME给误删了，需要恢复。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2017-12-05T13:45:14+00:00",
        "updated_at": "2017-12-11T03:12:36+00:00",
        "closed_at": "2017-12-11T03:12:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 518,
        "title": "分本分类的demo无法正常运行",
        "body": "地址：http://paddlepaddle.org/docs/develop/models/text_classification/README.html\r\n\r\n错误提示\r\npython27-gcc482/lib/python2.7/site-packages/paddle/v2/reader/decorator.py\", line 67, in data_reader\r\n    for e in reader():\r\nTypeError: 'function' object is not iterable",
        "state": "closed",
        "user": "daichengchao",
        "closed_by": "daichengchao",
        "created_at": "2017-12-05T12:03:36+00:00",
        "updated_at": "2017-12-12T08:46:43+00:00",
        "closed_at": "2017-12-12T08:46:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 520,
        "title": "Download of librispeech model does not work",
        "body": "Is it only me or anyone else faced an issue with downloading the librispeech model from http://cloud.dlnel.org/filepub/?uuid=17404caf-cf19-492f-9707-1fad07c19aae?\r\n\r\nIt always stops before completion with network error message.",
        "state": "closed",
        "user": "rsbhat78",
        "closed_by": "shanyi15",
        "created_at": "2017-12-06T06:10:16+00:00",
        "updated_at": "2018-08-15T09:57:06+00:00",
        "closed_at": "2018-08-15T09:57:06+00:00",
        "comments_count": [
            "kuke",
            "jayiind",
            "kuke",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 521,
        "title": "models 效果和精度持续测试机制及框架",
        "body": "paddle/models 最早定位是作为 Paddle 对外输出模型，便于用户直接修改使用，同时在模型的粒度上验证 paddle 可用性。\r\n\r\n目前，models已经积累了相当数量的比较有应用价值的模型，但由于缺少精度和效果的测试机制，难以保证模型的效果，历史上也成出现过版本间效果差异较大的情况。\r\n\r\n最新的 fluid 框架完善后，models 需要逐步迁移到 fluid 上，在这之前，我们可以尝试建立 models 的自动测试机制和框架，以实现\r\n\r\n- 模型级别的效果验证\r\n- 性能测试\r\n- 宏观上的大功能验证\r\n\r\n以长久保证 models 以及 Paddle 的实用性。",
        "state": "closed",
        "user": "Superjomn",
        "closed_by": "shanyi15",
        "created_at": "2017-12-06T07:51:46+00:00",
        "updated_at": "2018-08-15T09:57:02+00:00",
        "closed_at": "2018-08-15T09:57:02+00:00",
        "comments_count": [
            "wangkuiyi",
            "Superjomn",
            "Superjomn",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 524,
        "title": "The ResNet config for cifar10 in image_classification/resnet.py is not right.",
        "body": "https://github.com/PaddlePaddle/models/blob/3a6d980dae529d74e1dd76be26f633b383969e92/image_classification/resnet.py#L88-L90\r\n\r\nIt should be as follows, remove the input channel number. Since the `layer_warp` interface has changed. \r\n\r\n```python\r\n    res1 = layer_warp(basicblock, conv1, 16, n, 1)\r\n    res2 = layer_warp(basicblock, res1, 32, n, 2)\r\n    res3 = layer_warp(basicblock, res2, 64, n, 2)\r\n```",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "peterzhang2029",
        "created_at": "2017-12-07T08:07:29+00:00",
        "updated_at": "2017-12-11T08:04:06+00:00",
        "closed_at": "2017-12-11T08:04:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 523,
        "title": "examples/librispeech/run_infer.sh core dump",
        "body": "sh run_infer.sh as well as run_infer_golden.sh are not successfully executed. Ressults in core_Dump with teh following error\r\nF1207 08:41:56.133008  8493 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: mkldnn_conv\r\n*** Check failure stack trace: ***\r\n    @     0x7f565498c9ad  google::LogMessage::Fail()\r\n    @     0x7f565499045c  google::LogMessage::SendToLog()\r\n    @     0x7f565498c4d3  google::LogMessage::Flush()\r\n    @     0x7f565499196e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f56546b683b  paddle::Layer::create()\r\n    @     0x7f5654740408  _ZZN6paddle13NeuralNetwork4initERKNS_11ModelConfigESt8functionIFviPNS_9ParameterEEERKSt6vectorINS_19enumeration_wrapper13ParameterTypeESaISB_EEbENKUlRKNS_11LayerConfigEE_clESI_\r\n    @     0x7f56547418bf  paddle::NeuralNetwork::init()\r\n    @     0x7f565476a29f  paddle::GradientMachine::create()\r\n    @     0x7f5654969425  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7f565496960f  GradientMachine::createByConfigProtoStr()\r\n    @     0x7f56545f8de7  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4cb755  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca088  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4de858  (unknown)\r\n    @           0x4b0c93  PyObject_Call\r\n    @           0x4f452e  (unknown)\r\n    @           0x4b0c93  PyObject_Call\r\n    @           0x4f42a7  (unknown)\r\n    @           0x4b669c  (unknown)\r\n    @           0x4b0c93  PyObject_Call\r\n    @           0x4c9f9f  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\nAborted (core dumped)\r\n\r\n\r\nAny help here would be appreciated",
        "state": "closed",
        "user": "jayiind",
        "closed_by": "shanyi15",
        "created_at": "2017-12-07T03:19:24+00:00",
        "updated_at": "2018-08-15T09:56:53+00:00",
        "closed_at": "2018-08-15T09:56:53+00:00",
        "comments_count": [
            "pkuyym",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 522,
        "title": "deep_speech_2/examples/tiny run_data.sh 运行时报错",
        "body": "root@3328a2284d27:/DeepSpeech/examples/tiny# sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 8\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI1206 11:44:56.762332    47 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=8 \r\nF1206 11:44:57.226635    47 hl_cuda_cublas.cc:137] Check failed: CUBLAS_STATUS_SUCCESS == g_cublasStat (0 vs. 1) Cublas Error: [cublas status]: not initialized [cublas init] Cublas create handle faild!\r\n*** Check failure stack trace: ***\r\n    @     0x7f7b10b7f04d  google::LogMessage::Fail()\r\n    @     0x7f7b10b81398  google::LogMessage::SendToLog()\r\n    @     0x7f7b10b7eb5b  google::LogMessage::Flush()\r\n    @     0x7f7b10b8226e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7b10b1d7a1  hl_cublas_init()\r\n    @     0x7f7b10b2a6e4  hl_create_global_resources()\r\n    @     0x7f7b10b2b1a4  hl_specify_devices_start()\r\n    @     0x7f7b10b2b47d  hl_start()\r\n    @     0x7f7b10aace7e  paddle::initMain()\r\n    @     0x7f7b10b65621  initPaddle()\r\n    @     0x7f7b10601347  _wrap_initPaddle\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4de6fe  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4c6ad1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7f7b35555830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\nFail in training!\r\n",
        "state": "closed",
        "user": "JoeBlack220",
        "closed_by": "shanyi15",
        "created_at": "2017-12-06T11:48:05+00:00",
        "updated_at": "2018-08-15T09:56:56+00:00",
        "closed_at": "2018-08-15T09:56:56+00:00",
        "comments_count": [
            "kuke",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 525,
        "title": "Anyone who has questions about Deep Speech 2 please notice ",
        "body": "The Deep Speech 2 project under this repo has been deprecated and moved to [an independent repo](https://github.com/PaddlePaddle/DeepSpeech). Hence,  \r\n\r\n- Please DON’T pull and test the remaining code due to the stopped maintenance,  including the Docker image;\r\n- Please go to [the new repo](https://github.com/PaddlePaddle/DeepSpeech) to follow our work or raise any questions.\r\n\r\nWe appreciate your attention to this project and the suggestive feedback from you is  always welcome.\r\n\r\nThanks!",
        "state": "closed",
        "user": "kuke",
        "closed_by": "luotao1",
        "created_at": "2017-12-07T10:27:07+00:00",
        "updated_at": "2018-01-29T02:07:36+00:00",
        "closed_at": "2018-01-29T02:07:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 529,
        "title": "The Chinese version of models",
        "body": "Related to https://github.com/PaddlePaddle/PaddlePaddle.org/issues/354, we should update the root README.cn.md in Models, and point to the README file with specific language.\r\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2017-12-11T03:14:10+00:00",
        "updated_at": "2017-12-11T04:55:14+00:00",
        "closed_at": "2017-12-11T04:55:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 531,
        "title": "hinge loss 这类max margin损失函数的开发计划？ ",
        "body": "在实现dssm的过程中，使用cosim会导致rank效果特别差。分析发现，需要用max margin的损失函数替代。\r\nhinge loss 这类max margin损失函数具体的开发计划？ ",
        "state": "closed",
        "user": "fanfannothing",
        "closed_by": "shanyi15",
        "created_at": "2017-12-11T06:14:05+00:00",
        "updated_at": "2018-08-15T09:56:48+00:00",
        "closed_at": "2018-08-15T09:56:48+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 526,
        "title": "bug in cnn-rank-dssm",
        "body": "in line 154 of models/dssm/network_conf.py:\r\nreturn paddle.layer.concat(input=[conv_3, conv_4])   \r\nrather than:\r\nreturn conv_3, conv_4",
        "state": "closed",
        "user": "neopro12",
        "closed_by": "peterzhang2029",
        "created_at": "2017-12-07T11:50:29+00:00",
        "updated_at": "2017-12-12T01:57:15+00:00",
        "closed_at": "2017-12-12T01:57:15+00:00",
        "comments_count": [
            "peterzhang2029"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 535,
        "title": "Fix URLs in nmt_without_attention's doc",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-11T13:33:05+00:00",
        "updated_at": "2017-12-11T13:41:16+00:00",
        "closed_at": "2017-12-11T13:41:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 532,
        "title": "Some candidates  for Paddle Models  repository.",
        "body": "We are going to find more partners to help us add more popular models into the Paddle Models repository. Here are some candidates. If anyone has any suggestion please comment this issue. Thank you. \r\n\r\n--- \r\n\r\n### Understanding / Generalization / Transfer\r\n- Distilling the knowledge in a neural network (2015), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1503.02531)\r\n\r\n### Optimization / Training Techniques\r\n- Training very deep networks (2015), R. Srivastava et al. [[pdf]](http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf)\r\n\r\n### Convolutional Neural Network Models\r\n- Identity Mappings in Deep Residual Networks (2016), K. He et al. [[pdf]](https://arxiv.org/pdf/1603.05027v2.pdf)\r\n\r\n### Segmentation\r\n- Fully convolutional networks for semantic segmentation (2015), J. Long et al. [pdf](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)\r\n\r\n### Image / Video\r\n- Show, attend and tell: Neural image caption generation with visual attention (2015), K. Xu et al. [[pdf]](http://arxiv.org/pdf/1502.03044)\r\n- Show and tell: A neural image caption generator (2015), O. Vinyals et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)\r\n\r\n### Natural Language Processing / RNNs\r\n- Teaching machines to read and comprehend (2015), K. Hermann et al. [[pdf]](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\r\n- A convolutional neural network for modeling sentences (2014), N. Kalchbrenner et al. [[pdf]](http://arxiv.org/pdf/1404.2188v1)\r\n- Distributed representations of words and phrases and their compositionality (2013), T. Mikolov et al. [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\r\n\r\n### Mobile\r\n- SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size (2016), F. Iandola et al. [[pdf]](http://arxiv.org/pdf/1602.07360)\r\n\r\n### Classic Paper\r\n- Natural language processing (almost) from scratch (2011), R. Collobert et al. [[pdf]](http://arxiv.org/pdf/1103.0398)\r\n- Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&rep=rep1&type=pdf)",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-12-11T06:40:34+00:00",
        "updated_at": "2018-08-15T09:56:42+00:00",
        "closed_at": "2018-08-15T09:56:42+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 538,
        "title": "Implement Inception-v4 network for image classification",
        "body": "https://arxiv.org/pdf/1602.07261.pdf",
        "state": "closed",
        "user": "will-am",
        "closed_by": "will-am",
        "created_at": "2017-12-12T07:13:18+00:00",
        "updated_at": "2017-12-27T08:44:56+00:00",
        "closed_at": "2017-12-27T08:44:56+00:00",
        "comments_count": [],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 544,
        "title": "DSSM model input format documentation is incorrect , dssm model文档里输入格式的说明有问题",
        "body": "文档里说输入的格式是word ids:\r\n```\r\n# 3 fields each line:\r\n#   - source's word ids\r\n#   - target's word ids\r\n#   - target\r\n<ids> \\t <ids> \\t <label>\r\n```\r\n实际上程序里面读了输入之后又做了个word2id的mapping，所以输入应该是\r\n```\r\ni like apple\\ti love apple !\\t1\r\n```\r\n",
        "state": "closed",
        "user": "rulai-huiyingl",
        "closed_by": "peterzhang2029",
        "created_at": "2017-12-15T05:17:04+00:00",
        "updated_at": "2017-12-19T09:34:52+00:00",
        "closed_at": "2017-12-19T09:34:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 537,
        "title": "使用MPI无法正常训练文本分类",
        "body": "1.脚本：\r\n\r\n2.日志：\r\n",
        "state": "closed",
        "user": "daichengchao",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-12T03:45:10+00:00",
        "updated_at": "2017-12-16T07:07:04+00:00",
        "closed_at": "2017-12-16T07:07:04+00:00",
        "comments_count": [
            "sweetsky0901"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 542,
        "title": "Implement Xception",
        "body": "Xception is a popular model for image classification and object detection.\r\n\r\nhttps://arxiv.org/pdf/1610.02357.pdf",
        "state": "closed",
        "user": "will-am",
        "closed_by": "will-am",
        "created_at": "2017-12-14T12:29:05+00:00",
        "updated_at": "2018-01-16T04:48:41+00:00",
        "closed_at": "2018-01-16T04:48:41+00:00",
        "comments_count": [],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 540,
        "title": "修改CNN的网络结构",
        "body": "参考文本分类的示例，修改了网络结构；\r\nhttp://paddlepaddle.org/docs/develop/models/text_classification/README.html\r\n在原始text_cnn的最后一层中添加一些特征add_fea。\r\n![image](https://user-images.githubusercontent.com/34272448/33876758-6559bde0-df61-11e7-8730-a73ebad2ef73.png)\r\n\r\n修改后网络结构为：\r\n```python\r\n # input layers\r\n 81     data = paddle.layer.data(\"word\",\r\n 82                              paddle.data_type.integer_value_sequence(dict_dim))\r\n 83     lbl = paddle.layer.data(\"label\", paddle.data_type.integer_value(class_dim))\r\n 84     add_feature = paddle.layer.data(\"znd_fea\",paddle.data_type.dense_vector(5))\r\n 85     print add_feature,lbl\r\n 86     logger.info(\"add_feature is : %s.\" % (add_feature))\r\n 87     # embedding layer\r\n 88     emb = paddle.layer.embedding(input=data, size=emb_dim)\r\n 89 \r\n 90     # convolution layers with max pooling\r\n 91     conv_3 = paddle.networks.sequence_conv_pool(\r\n 92         input=emb, context_len=3, hidden_size=hid_dim)\r\n 93     conv_4 = paddle.networks.sequence_conv_pool(\r\n 94         input=emb, context_len=4, hidden_size=hid_dim)\r\n 95 \r\n 96     # fc and output layer\r\n 97     prob = paddle.layer.fc(\r\n 98         input=[conv_3, conv_4, add_feature], size=class_dim, act=paddle.activation.Softmax())\r\n 99     #    input=[conv_3, conv_4,], size=class_dim, act=paddle.activation.Softmax())\r\n```\r\n添加了84行add_feature，修改了98行。请问代码中定义的网络结构是否反应上图中的结构？\r\n\r\n在模型预估时，\r\n```python\r\n 57     test_batch = []\r\n 58     for idx, item in enumerate(test_reader):\r\n 59         test_batch.append([item[0]])\r\n 60         if len(test_batch) == batch_size:\r\n 61             _infer_a_batch(inferer, test_batch, word_reverse_dict,\r\n 62                            label_reverse_dict)\r\n 63             test_batch = []\r\n```\r\n问题2：需要把label和添加的特征都加到test_batch吗？我测试了一下，仅仅需要添加 test_batch.append([item[0],item[2]]),item[2]标示add_feature，请问这样预估时正确的吗？",
        "state": "closed",
        "user": "daichengchao",
        "closed_by": "luotao1",
        "created_at": "2017-12-12T08:52:13+00:00",
        "updated_at": "2018-01-29T02:08:14+00:00",
        "closed_at": "2018-01-29T02:08:14+00:00",
        "comments_count": [
            "lcy-seso",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 545,
        "title": "Questions in README of NCE Demo",
        "body": "The text indicates that use `act=paddle.activation.Softmax()` when inferring while followed by the code using `act=paddle.activation.Sigmoid()`\r\n\r\n```python\r\n    return paddle.layer.mixed(\r\n          size=dict_size,\r\n          input=paddle.layer.trans_full_matrix_projection(\r\n              hidden_layer, param_attr=paddle.attr.Param(name=\"nce_w\")),\r\n          act=paddle.activation.Sigmoid(),\r\n          bias_attr=paddle.attr.Param(name=\"nce_b\"))\r\n```",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-15T13:19:50+00:00",
        "updated_at": "2017-12-18T03:00:30+00:00",
        "closed_at": "2017-12-18T03:00:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 548,
        "title": "CI failed because of the unmatched clang-format version",
        "body": "CI failed because of the unmatched clang-format version. The errors are as followed:\r\n\r\n```\r\nyapf.....................................................................Passed\r\nCheck for merge conflicts................................................Passed\r\nCheck for broken symlinks................................................Passed\r\nDetect Private Key.......................................................Passed\r\nFix End of Files.........................................................Passed\r\nTrim Trailing Whitespace.................................................Passed\r\nCRLF end-lines checker...................................................Passed\r\nCRLF end-lines remover...................................................Passed\r\nNo-tabs checker..........................................................Passed\r\nTabs remover.............................................................Passed\r\nclang-format.............................................................Failed\r\nhookid: clang-format\r\nclang-format version check failed.\r\na version contains '3.9' is needed, but get 'clang-format version 5.0.0 (tags/RELEASE_500/final)'\r\nyou can install the right version, and make an soft-link to '$PATH' env\r\n```",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-16T04:58:54+00:00",
        "updated_at": "2017-12-16T07:25:41+00:00",
        "closed_at": "2017-12-16T07:25:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 551,
        "title": "how_to_use_capi 文件夹不再需要",
        "body": "CAPI 相关的文档和示例会merge到PaddlePaddle repo下面，models下的 how_to_use_capi 文件夹不再需要。",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2017-12-19T02:22:58+00:00",
        "updated_at": "2017-12-19T02:38:51+00:00",
        "closed_at": "2017-12-19T02:38:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 549,
        "title": "CNN attention",
        "body": "paddle可否支持cnn attention？",
        "state": "closed",
        "user": "OleNet",
        "closed_by": "OleNet",
        "created_at": "2017-12-16T07:14:39+00:00",
        "updated_at": "2017-12-27T05:44:53+00:00",
        "closed_at": "2017-12-27T05:44:53+00:00",
        "comments_count": [
            "lcy-seso",
            "OleNet",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 553,
        "title": "models 下 clang-format 版本与Paddle repo不一致",
        "body": "models 下 clang-format 版本与Paddle repo不一致，如果同时向 models 和 Paddle 提交PR，比较麻烦（pre-sumbit 检测clang-format 版本不满足退出）。",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "luotao1",
        "created_at": "2017-12-19T02:37:57+00:00",
        "updated_at": "2017-12-19T02:54:55+00:00",
        "closed_at": "2017-12-19T02:54:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 556,
        "title": "dssm train core",
        "body": "cd dssm\r\npython train.py -y 0 --model_arch 0 --class_num 2\r\nthen, core file appear and training process abort\r\nmore pitful, i don't know how find where is the error\r\n\r\nplease help me, thx",
        "state": "closed",
        "user": "syllenz",
        "closed_by": "shanyi15",
        "created_at": "2017-12-23T17:38:42+00:00",
        "updated_at": "2018-08-15T09:56:39+00:00",
        "closed_at": "2018-08-15T09:56:39+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 558,
        "title": "Implement ResNeXt",
        "body": "https://arxiv.org/pdf/1611.05431.pdf",
        "state": "closed",
        "user": "will-am",
        "closed_by": "shanyi15",
        "created_at": "2017-12-27T06:47:49+00:00",
        "updated_at": "2018-08-15T10:11:15+00:00",
        "closed_at": "2018-08-15T10:11:15+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "model in process"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 564,
        "title": "在使用reader.py测试自定义数据集时出错",
        "body": "* 我使用自己的自定义数据集时,在运行这行代码测试时报错[https://github.com/PaddlePaddle/models/blob/develop/image_classification/reader.py#L51](https://github.com/PaddlePaddle/models/blob/develop/image_classification/reader.py#L51)\r\n```\r\nif __name__ == '__main__':\r\n    for im in train_reader('train.list'):\r\n        print len(im[0])\r\n    for im in train_reader('test.list'):\r\n        print len(im[0])\r\n```\r\n* 报错如下\r\n```\r\nE\r\nError\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\r\n    testMethod()\r\n  File \"/usr/local/lib/python2.7/dist-packages/nose/case.py\", line 197, in runTest\r\n    self.test(*self.arg)\r\nTypeError: test_mapper() takes exactly 1 argument (0 given)\r\n\r\nE\r\n======================================================================\r\nERROR: map image path to type needed by model input layer for the test set\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/nose/case.py\", line 197, in runTest\r\n    self.test(*self.arg)\r\nTypeError: test_mapper() takes exactly 1 argument (0 given)\r\n\r\n======================================================================\r\nERROR: imageclassify.reader.test_reader\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/nose/case.py\", line 197, in runTest\r\n    self.test(*self.arg)\r\nTypeError: test_reader() takes at least 1 argument (0 given)\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.004s\r\n\r\nFAILED (errors=2)\r\n\r\nError\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\r\n    testMethod()\r\n  File \"/usr/local/lib/python2.7/dist-packages/nose/case.py\", line 197, in runTest\r\n    self.test(*self.arg)\r\nTypeError: test_reader() takes at least 1 argument (0 given)\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-01-03T15:44:58+00:00",
        "updated_at": "2018-01-15T02:57:52+00:00",
        "closed_at": "2018-01-15T02:57:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 560,
        "title": "遇到一个问题，Evaluator.cpp:460] Check failed: binIdx <= kBinNum_ bin index [4288776562] out of range, predict value[-0.368997]",
        "body": "`F1228 13:33:18.571247  7082 Evaluator.cpp:460] Check failed: binIdx <= kBinNum_ bin index [4288776562] out of range, predict value[-0.368997]\r\n*** Check failure stack trace: ***\r\n    @     0x7fc2943d426d  google::LogMessage::Fail()\r\n    @     0x7fc2943d60df  google::LogMessage::SendToLog()\r\n    @     0x7fc2943d3e13  google::LogMessage::Flush()\r\n    @     0x7fc2943d69fe  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc2941d486b  paddle::AucEvaluator::evalImp()\r\n    @     0x7fc2941d409b  paddle::Evaluator::eval()\r\n    @     0x7fc2941c0c08  paddle::CombinedEvaluator::eval()\r\n    @     0x7fc29403042e  _wrap_GradientMachine_eval\r\n    @     0x7fc2bc044bb0  PyEval_EvalFrameEx\r\n    @     0x7fc2bc04457d  PyEval_EvalFrameEx\r\n    @     0x7fc2bc046efd  PyEval_EvalCodeEx\r\n    @     0x7fc2bc0443fc  PyEval_EvalFrameEx\r\n    @     0x7fc2bc046efd  PyEval_EvalCodeEx\r\n    @     0x7fc2bc0443fc  PyEval_EvalFrameEx\r\n    @     0x7fc2bc046efd  PyEval_EvalCodeEx\r\n    @     0x7fc2bc047002  PyEval_EvalCode\r\n    @     0x7fc2bc06043f  (unknown)\r\n    @     0x7fc2bc0615fe  PyRun_FileExFlags\r\n    @     0x7fc2bc062889  PyRun_SimpleFileExFlags\r\n    @     0x7fc2bc073a3f  Py_Main\r\n    @     0x7fc2bb299c05  __libc_start_main\r\n    @           0x40071e  (unknown)\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n`",
        "state": "closed",
        "user": "immaster",
        "closed_by": "immaster",
        "created_at": "2017-12-28T06:11:46+00:00",
        "updated_at": "2017-12-29T23:32:39+00:00",
        "closed_at": "2017-12-28T07:54:27+00:00",
        "comments_count": [
            "immaster",
            "kangshantong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 561,
        "title": "deepfm运行demo，出现Segmentation fault (core dumped)",
        "body": "我从头开始，部署了下modles里面的deepfm示例，发现有段错误。（在一台新机器上装最新paddle，并且部署models下的deepfm）。batchsize=1的时候，不会有问题，但是当batchsize增大的时候，会有段错误。\r\n另外，示例里面有这个代码，我不是很明白\r\n```\r\nbuf_size=args.batch_size * 10000\r\n```\r\n当batch_size较大，比如示例里面默认是1000，会导致初始化加载10几G的缓存，会初始化很久，并且这么大的缓存也不是必要的吧\r\n\r\n下面是我两次运行，只是改了下batch_size大小。代码就是原来的，除了我把buf_size固定成了2000，另外测试和验证数据，我取了原来测试和验证数据的各自top 100\r\n```\r\n[work@XXX deep_fm]$ python train.py --train_data_path data/train2.txt --test_data_path data/valid2.txt --batch_size 1\r\nI0101 21:55:06.438161 13166 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\nI0101 21:55:06.519804 13166 GradientMachine.cpp:94] Initing parameters..\r\nI0101 21:55:06.632671 13166 GradientMachine.cpp:101] Init parameters done.\r\n[WARNING 2018-01-01 21:55:07,184 train.py:77] Pass 0, Batch 0, Samples 0, Cost 0.640660, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:55:07,719 train.py:88] Test 0-0, Cost 0.904218, {'auc': 0.5116550326347351, 'classification_error': 0.6600000262260437}\r\n[WARNING 2018-01-01 21:55:18,102 train.py:77] Pass 1, Batch 0, Samples 0, Cost 0.392937, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:55:18,632 train.py:88] Test 1-0, Cost 0.663319, {'auc': 0.5314685106277466, 'classification_error': 0.25999999046325684}\r\n[WARNING 2018-01-01 21:55:29,005 train.py:77] Pass 2, Batch 0, Samples 0, Cost 0.153824, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:55:29,538 train.py:88] Test 2-0, Cost 0.647524, {'auc': 0.5536130666732788, 'classification_error': 0.2199999988079071}\r\n[WARNING 2018-01-01 21:55:39,917 train.py:77] Pass 3, Batch 0, Samples 0, Cost 0.287967, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:55:40,449 train.py:88] Test 3-0, Cost 0.646834, {'auc': 0.5879953503608704, 'classification_error': 0.2199999988079071}\r\n[WARNING 2018-01-01 21:55:50,842 train.py:77] Pass 4, Batch 0, Samples 0, Cost 1.319486, {'auc': 0.0, 'classification_error': 1.0}\r\n[WARNING 2018-01-01 21:55:51,374 train.py:88] Test 4-0, Cost 0.653498, {'auc': 0.5979021191596985, 'classification_error': 0.20999999344348907}\r\n[WARNING 2018-01-01 21:56:01,749 train.py:77] Pass 5, Batch 0, Samples 0, Cost 1.486811, {'auc': 0.0, 'classification_error': 1.0}\r\n[WARNING 2018-01-01 21:56:02,286 train.py:88] Test 5-0, Cost 0.643287, {'auc': 0.6095570921897888, 'classification_error': 0.20999999344348907}\r\n[WARNING 2018-01-01 21:56:12,657 train.py:77] Pass 6, Batch 0, Samples 0, Cost 0.131564, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:56:13,220 train.py:88] Test 6-0, Cost 0.712368, {'auc': 0.6118881106376648, 'classification_error': 0.20000000298023224}\r\n[WARNING 2018-01-01 21:56:23,595 train.py:77] Pass 7, Batch 0, Samples 0, Cost 0.007719, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:56:24,129 train.py:88] Test 7-0, Cost 0.728682, {'auc': 0.6130536198616028, 'classification_error': 0.20999999344348907}\r\n[WARNING 2018-01-01 21:56:34,510 train.py:77] Pass 8, Batch 0, Samples 0, Cost 0.003461, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:56:35,045 train.py:88] Test 8-0, Cost 0.763806, {'auc': 0.6212121248245239, 'classification_error': 0.20000000298023224}\r\n[WARNING 2018-01-01 21:56:45,418 train.py:77] Pass 9, Batch 0, Samples 0, Cost 0.011033, {'auc': 0.0, 'classification_error': 0.0}\r\n[WARNING 2018-01-01 21:56:45,948 train.py:88] Test 9-0, Cost 0.753952, {'auc': 0.6340326070785522, 'classification_error': 0.23000000417232513}\r\n\r\n\r\n[work@XXX deep_fm]$ python train.py --train_data_path data/train2.txt --test_data_path data/valid2.txt --batch_size 10\r\nI0101 22:12:07.115480 26987 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\nI0101 22:12:07.198402 26987 GradientMachine.cpp:94] Initing parameters..\r\nI0101 22:12:07.312139 26987 GradientMachine.cpp:101] Init parameters done.\r\n\r\n*** Aborted at 1514815927 (unix time) try \"date -d @1514815927\" if you are using GNU date ***\r\n\r\nPC: @                0x0 (unknown)\r\n\r\n*** SIGSEGV (@0x7fe68ac1400c) received by PID 26987 (TID 0x7fe69801c700) from PID 18446744071742504972; stack trace: ***\r\n\r\n    @       0x318b20f500 (unknown)\r\n\r\n    @     0x7fe69b9125e0 sgemm_itcopy_SANDYBRIDGE\r\n\r\n    @     0x7fe69a4cedf0 inner_thread\r\n\r\n    @     0x7fe69a4d752f blas_thread_server\r\n\r\n    @       0x318b207851 (unknown)\r\n\r\n    @       0x318aee767d (unknown)\r\n\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\n```\r\n  ",
        "state": "closed",
        "user": "windy444",
        "closed_by": "luotao1",
        "created_at": "2018-01-03T03:15:30+00:00",
        "updated_at": "2018-01-29T02:03:09+00:00",
        "closed_at": "2018-01-29T02:03:09+00:00",
        "comments_count": [
            "will-am",
            "QiJune",
            "will-am",
            "windy444",
            "will-am",
            "windy444",
            "QiJune",
            "will-am",
            "xlhlhlx",
            "will-am",
            "windy444",
            "will-am",
            "luotao1",
            "windy444",
            "luotao1",
            "fingthinking",
            "will-am",
            "fingthinking",
            "will-am",
            "windy444",
            "luotao1"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 565,
        "title": "利用paddle的hsigmoid训练词向量，出现IVector_create错误",
        "body": "**【背景】**\r\n利用paddle的hsigmoid训练词向量的时候，reader输出结果符合要求。但是出现如下错误。\r\n在issue里面搜索过，没有找到对应的答案。麻烦看看。\r\n\r\n**【错误日志】**\r\nRuntimeError: module compiled against API version 0xb but this version of numpy is 0xa\r\n[INFO 2018-01-04 13:35:08,759 reader.py:29] load dict success\r\nI0104 13:35:08.760479 26773 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\n[INFO 2018-01-04 13:35:08,762 network_conf.py:13] input data layer name __word00__\r\n[INFO 2018-01-04 13:35:08,763 network_conf.py:13] input data layer name __word01__\r\n[INFO 2018-01-04 13:35:08,764 network_conf.py:13] input data layer name __word02__\r\n[INFO 2018-01-04 13:35:08,765 network_conf.py:13] input data layer name __word03__\r\n[INFO 2018-01-04 13:35:08,766 network_conf.py:21] output data layer name __target_word__\r\nI0104 13:35:15.055646 26773 GradientMachine.cpp:85] Initing parameters..\r\nI0104 13:36:06.293507 26773 GradientMachine.cpp:92] Init parameters done.\r\n[INFO 2018-01-04 13:36:06,294 reader.py:40] [reader] load trainset from ./part-00\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 125, in <module>\r\n    is_cloud=args.cloud)\r\n  File \"train.py\", line 105, in train\r\n    num_passes=30, event_handler=event_handler, feeding=feeding)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 153, in train\r\n    in_args = feeder(data_batch)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 282, in __call__\r\n    return self.convert(dat, argument)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/paddle/v2/data_feeder.py\", line 134, in convert\r\n    return DataProviderConverter.convert(self, reorder_data(dat), argument)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 277, in convert\r\n    scanner.finish_scan(argument)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py\", line 211, in finish_scan\r\n    ids = swig_paddle.IVector.create(self.__ids__, self.data_in_gpu)\r\n  File \"/home/disk1/fengzhifan/python27-gcc482/lib/python2.7/site-packages/py_paddle/swig_paddle.py\", line 881, in create\r\n    return _swig_paddle.IVector_create(*args)\r\nNotImplementedError: Wrong number or type of arguments for overloaded function 'IVector_create'.\r\n  Possible C/C++ prototypes are:\r\n    IVector::create(std::vector< int,std::allocator< int > > const &,bool)\r\n    IVector::create(std::vector< int,std::allocator< int > > const &)\r\n\r\n**【网络结构】**\r\n```\r\n  8 def ngram_lm(hidden_size, embed_size, dict_size, gram_num=4, is_train=True):\r\n  9     emb_layers = []\r\n 10     embed_param_attr = paddle.attr.Param(\r\n 11         name=\"_proj\", initial_std=0.001, learning_rate=1, l2_rate=0)\r\n 12\r\n 13     for i in range(gram_num):\r\n 14         logger.info('input data layer name __word%02d__' % (i))\r\n 15         word = paddle.layer.data(\r\n 16             name=\"__word%02d__\" % (i),\r\n 17             type=paddle.data_type.integer_value(dict_size))\r\n 18         emb_layers.append(paddle.layer.embedding(\r\n 19             input=word, size=embed_size, param_attr=embed_param_attr))\r\n 20\r\n 21     logger.info('output data layer name __target_word__')\r\n 22     target_word = paddle.layer.data(\r\n 23         name=\"__target_word__\", type=paddle.data_type.integer_value(dict_size))\r\n 24\r\n 25     embed_context = paddle.layer.concat(input=emb_layers)\r\n 26\r\n 27     hidden_layer = paddle.layer.fc(\r\n 28         input=embed_context,\r\n 29         size=hidden_size,\r\n 30         act=paddle.activation.Sigmoid(),\r\n 31         layer_attr=paddle.attr.Extra(drop_rate=0.5),\r\n 32         bias_attr=paddle.attr.Param(learning_rate=2),\r\n 33         param_attr=paddle.attr.Param(\r\n 34             initial_std=1. / math.sqrt(embed_size * 8), learning_rate=1))\r\n 35\r\n 36     if is_train == True:\r\n 37         return paddle.layer.hsigmoid(\r\n 38             input=hidden_layer,\r\n 39             label=target_word,\r\n 40             num_classes=dict_size,\r\n 41             param_attr=paddle.attr.Param(name=\"sigmoid_w\"),\r\n 42             bias_attr=paddle.attr.Param(name=\"sigmoid_b\"))\r\n 43     else:\r\n 44         return paddle.layer.mixed(\r\n 45             size=dict_size - 1,\r\n 46             input=paddle.layer.trans_full_matrix_projection(\r\n 47                 hidden_layer, param_attr=paddle.attr.Param(name=\"sigmoid_w\")),\r\n 48             act=paddle.activation.Sigmoid(),\r\n 49             bias_attr=paddle.attr.Param(name=\"sigmoid_b\"))\r\n```\r\n  \r\n**【reader输出数据】**\r\n[INFO 2018-01-04 14:57:47,452 reader.py:49] 0 1667662 660821 1154603 1325816\r\n[INFO 2018-01-04 14:57:47,452 reader.py:49] 1667662 660821 1154603 1325816 1376644\r\n[INFO 2018-01-04 14:57:47,452 reader.py:49] 660821 1154603 1325816 1376644 1457480\r\n[INFO 2018-01-04 14:57:47,452 reader.py:49] 1154603 1325816 1376644 1457480 852167\r\n[INFO 2018-01-04 14:57:47,452 reader.py:49] 1325816 1376644 1457480 852167 1",
        "state": "closed",
        "user": "fanfannothing",
        "closed_by": "wanghaox",
        "created_at": "2018-01-04T06:55:04+00:00",
        "updated_at": "2018-01-04T11:57:30+00:00",
        "closed_at": "2018-01-04T11:57:30+00:00",
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 562,
        "title": "用alexnet训练图片模型后，如何让模型判断非训练类别的图片",
        "body": "目前想到的方案是，看模型给该图片在每个类上打的分值，设定一个阈值，低于这个值时，认为是其他分类图片。但这种方案效果不好，希望有更好的方案！",
        "state": "closed",
        "user": "Datian1993",
        "closed_by": "will-am",
        "created_at": "2018-01-03T07:59:43+00:00",
        "updated_at": "2018-01-16T04:50:54+00:00",
        "closed_at": "2018-01-16T04:50:54+00:00",
        "comments_count": [
            "sweetsky0901",
            "Datian1993"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 566,
        "title": "PaddlePaddle新年大礼！周边产品送不停！",
        "body": "各位亲爱的PaddlePaddle用户：\r\n\r\n2017年已经过去，感谢你们一直陪伴PaddlePaddle在深度学习领域共同成长，无论是应用、贡献、还是review、纠错；每一个人的付出对于PaddlePaddle都是至关重要的。**值此新年，PaddlePaddle准备了一批周边小礼物赠送给各位，与各位一同迎接更好的2018！PaddlePaddle，一起加油！**\r\n\r\n**周边礼物领取方式如下：**\r\n请各位使用者、贡献者将**如下信息**发到PaddlePaddle-TechWriter@baidu.com\r\n**【“姓名“+“github账号名” +“周边礼物快递邮寄地址”+”快递联系电话“+”定制卫衣号码（S：160，M：165，L：170，XL：175，xxL：180）“】** →发到PaddlePaddle-TechWriter@baidu.com\r\n我们会根据邮件中的地址为您送上PaddlePaddle周边礼物一份。\r\n您也可以同时回复此issue-”你对PaddlePaddle的祝福和嘱咐“或“PaddlePaddle，一起加油！”来提醒我们查收您的邮件。\r\n\r\n# 礼物内容如下：\r\n每位发送邮件的用户都能获得PaddlePaddle**礼袋一个，内置“LOGO卫衣+贴纸+纪念小徽章“**\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556980-9ed91f42-f173-11e7-974c-e0db65314868.png)\r\n\r\n\r\n# 重要贡献用户随机加发下列周边产品之一：\r\n## PaddlePaddle定制款-膳魔师保温水杯\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556983-a3bcbed8-f173-11e7-9c0c-7fe35348b0c7.png)\r\n\r\n## PaddlePaddle定制款-机械键盘\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556989-a9dc7c4a-f173-11e7-80d0-5af5ec9f2a20.png)\r\n\r\n\r\n## PaddlePaddle定制款-树莓派\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34557019-d4f113e6-f173-11e7-9489-265ac6ba207b.png)\r\n\r\n# 如有其他疑问，可以直接回复本issue~~感谢大家的支持！",
        "state": "closed",
        "user": "angelashane",
        "closed_by": "shanyi15",
        "created_at": "2018-01-04T09:24:12+00:00",
        "updated_at": "2018-08-15T10:11:12+00:00",
        "closed_at": "2018-08-15T10:11:12+00:00",
        "comments_count": [
            "qzhongwood",
            "ji04xiaogang",
            "skrcoder",
            "donote",
            "shibing624",
            "utopiar",
            "5idaidai",
            "fywu85",
            "hujq1002",
            "westu",
            "zhuqunyan",
            "zhongqiuwood",
            "oakatplatform",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 567,
        "title": "sequence_tagging_for_ner的download.sh的bug",
        "body": "按照说明：\r\n为运行本例，请首先在data目录下运行download.sh脚本下载输入文本的词典和预训练的词向量。 完成后会将这两个文件一并放入data目录下，输入文本的词典和预训练的词向量分别对应：data/vocab.txt和data/wordVectors.txt这两个文件。\r\n但是在data下执行download.sh后data里的文件是这样的\r\ndata  download.sh  target.txt  test  train  vocab.txt。没有wordVectors.txt\r\n在执行\r\n+ cp assignment2_release/data/ner/wordVectors.txt ./data\r\n+ cp assignment2_release/data/ner/vocab.txt ./data的时候，会后一个覆盖掉前一个。\r\n这里不确定是拷贝到原本的data里，还是还要在里面再新建一个data\r\n",
        "state": "closed",
        "user": "sweetsky0901",
        "closed_by": "shanyi15",
        "created_at": "2018-01-05T08:32:53+00:00",
        "updated_at": "2018-08-15T10:11:09+00:00",
        "closed_at": "2018-08-15T10:11:09+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 573,
        "title": "Wrong link to book chapters",
        "body": "In the model page of English paddle [website](http://www.paddlepaddle.org/docs/develop/models/README.html), \r\n\r\nThere are several links that need to be fixed.\r\n\r\n1. `please refer to PaddleBook Sentiment Analysis` under `4. Text classification`:\r\n\r\nThe `Sentiment Analysis` links to the [Chinese version](https://github.com/PaddlePaddle/book/blob/develop/06.understand_sentiment/README.cn.md) of document. \r\n\r\nShould be fixed to point to the [English version](https://github.com/PaddlePaddle/book/blob/develop/06.understand_sentiment/README.md)\r\n\r\n2. Similar issue for `please refer to Recommended System` under `5. Learning to rank`",
        "state": "closed",
        "user": "kexinzhao",
        "closed_by": "luotao1",
        "created_at": "2018-01-12T03:53:46+00:00",
        "updated_at": "2018-01-12T05:46:12+00:00",
        "closed_at": "2018-01-12T05:46:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 581,
        "title": "use the same version yapf with Paddle main repo.",
        "body": "Currently, the Paddle/models repository uses a different version yapf with Paddle main repository. It is quite inconvenient if one contributes codes to both repositories in pre-commit hook.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "luotao1",
        "created_at": "2018-01-19T07:16:31+00:00",
        "updated_at": "2018-01-19T07:34:12+00:00",
        "closed_at": "2018-01-19T07:34:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 568,
        "title": "dssm模型训练过程中退出",
        "body": "单机运行dssm目录下的train.py\r\n//model_type = 2 for regresison\r\n//model_arch ==1 for cnn\r\npython train.py --train_data_path ./data/regression/train.txt --test_data_path ./data/regression/test.txt -s ./data/vocab.txt  --model_type 2  --num_workers 8 --model_arch  1\r\n其余参数使用默认。\r\n\r\n[INFO 2018-01-08 23:06:47,145 utils.py:125] The arguments passed by command line is :\r\n[INFO 2018-01-08 23:06:47,145 utils.py:127] batch_size:\t32\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] class_num:\t0\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] dnn_dims:\t256,128,64,32\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] model_arch:\tcnn\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] model_output_prefix:\t./\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] model_type:\tregression\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] num_batches_to_log:\t100\r\n[INFO 2018-01-08 23:06:47,146 utils.py:127] num_batches_to_save_model:\t400\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] num_batches_to_test:\t200\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] num_passes:\t10\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] num_workers:\t8\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] share_embed:\tFalse\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] share_network_between_source_target:\tFalse\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] source_dic_path:\t./data/vocab.txt\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] target_dic_path:\t./data/vocab.txt\r\n[INFO 2018-01-08 23:06:47,147 utils.py:127] test_data_path:\t./data/regression/test.txt\r\n[INFO 2018-01-08 23:06:47,148 utils.py:127] train_data_path:\t./data/regression/train.txt\r\n[INFO 2018-01-08 23:06:47,148 utils.py:127] use_gpu:\tFalse\r\nI0108 23:06:47.283903 18257 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=8 \r\n[WARNING 2018-01-08 23:06:47,365 network_conf.py:53] Build DSSM model with config of regression, cnn\r\n[INFO 2018-01-08 23:06:47,366 network_conf.py:54] The vocabulary size is : [57919, 57919]\r\n[INFO 2018-01-08 23:06:47,366 network_conf.py:180] build regression model\r\n[INFO 2018-01-08 23:06:47,368 network_conf.py:87] Create embedding table [source] whose dimention is 256. \r\n[INFO 2018-01-08 23:06:47,371 network_conf.py:87] Create embedding table [target] whose dimention is 256. \r\n[INFO 2018-01-08 23:06:47,372 network_conf.py:149] create a sequence_conv_pool whose context width is 3.\r\n[INFO 2018-01-08 23:06:47,375 network_conf.py:151] create a sequence_conv_pool whose context width is 4.\r\n[INFO 2018-01-08 23:06:47,378 network_conf.py:163] create fc layer [source_fc_0_128] which dimention is 128\r\n[INFO 2018-01-08 23:06:47,379 network_conf.py:163] create fc layer [source_fc_1_64] which dimention is 64\r\n[INFO 2018-01-08 23:06:47,380 network_conf.py:163] create fc layer [source_fc_2_32] which dimention is 32\r\n[INFO 2018-01-08 23:06:47,381 network_conf.py:149] create a sequence_conv_pool whose context width is 3.\r\n[INFO 2018-01-08 23:06:47,383 network_conf.py:151] create a sequence_conv_pool whose context width is 4.\r\n[INFO 2018-01-08 23:06:47,386 network_conf.py:163] create fc layer [target_fc_0_128] which dimention is 128\r\n[INFO 2018-01-08 23:06:47,387 network_conf.py:163] create fc layer [target_fc_1_64] which dimention is 64\r\n[INFO 2018-01-08 23:06:47,388 network_conf.py:163] create fc layer [target_fc_2_32] which dimention is 32\r\nI0108 23:06:47.985695 18257 GradientMachine.cpp:94] Initing parameters..\r\nI0108 23:06:53.009483 18257 GradientMachine.cpp:101] Init parameters done.\r\n[INFO 2018-01-08 23:06:53,422 reader.py:31] [reader] load trainset from ./data/regression/train.txt\r\n[INFO 2018-01-08 23:06:54,772 train.py:229] Pass 0, Batch 0, Cost 0.306331, {'__auc_evaluator_0__': 0.6302083134651184}\r\n[INFO 2018-01-08 23:08:39,500 train.py:229] Pass 0, Batch 100, Cost 0.153258, {'__auc_evaluator_0__': 0.9294871687889099}\r\n[INFO 2018-01-08 23:10:28,211 train.py:229] Pass 0, Batch 200, Cost 0.088812, {'__auc_evaluator_0__': 0.7851851582527161}\r\n[INFO 2018-01-08 23:12:18,108 train.py:229] Pass 0, Batch 300, Cost 0.083488, {'__auc_evaluator_0__': 0.7239583134651184}\r\n[INFO 2018-01-08 23:14:13,401 train.py:229] Pass 0, Batch 400, Cost 0.084395, {'__auc_evaluator_0__': 0.7816091775894165}\r\nF0108 23:15:27.318744 18257 Evaluator.cpp:460] Check failed: binIdx <= kBinNum_ bin index [4293613805] out of range, predict value[-0.0806744]\r\n*** Check failure stack trace: ***\r\n    @     0x7ff5af39c9ad  google::LogMessage::Fail()\r\n    @     0x7ff5af3a045c  google::LogMessage::SendToLog()\r\n    @     0x7ff5af39c4d3  google::LogMessage::Flush()\r\n    @     0x7ff5af3a196e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7ff5af17e81d  paddle::AucEvaluator::evalImp()\r\n    @     0x7ff5af17e018  paddle::Evaluator::eval()\r\n    @     0x7ff5af152ce8  paddle::CombinedEvaluator::eval()\r\n    @     0x7ff5af16faaa  paddle::MultiGradientMachine::eval()\r\n    @     0x7ff5aeff7886  _wrap_GradientMachine_eval\r\n    @           0x4cb45e  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7ff5dc6a4830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\n('model type: ', 'regression')\r\nAborted (core dumped)\r\n\r\n训练主程序入口[train.py](https://github.com/PaddlePaddle/models/blob/develop/dssm/train.py)\r\n",
        "state": "closed",
        "user": "wangbin11",
        "closed_by": "will-am",
        "created_at": "2018-01-09T05:30:37+00:00",
        "updated_at": "2018-01-16T04:50:32+00:00",
        "closed_at": "2018-01-16T04:50:32+00:00",
        "comments_count": [
            "jacquesqiao",
            "wangbin11",
            "will-am"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 578,
        "title": "文本分类model的问题",
        "body": "我按照下面的说明，修改run.sh\r\n```\r\n#!/bin/sh\r\n\r\npython train.py \\\r\n--nn_type=\"dnn\" \\\r\n--batch_size=64 \\\r\n--train_data_dir=\"/root/桌面/baidu/model/text_classification/traindata/\" \\\r\n--word_dict=\"/root/桌面/baidu/model/text_classification/worddict/\" \\\r\n--lable_dict=\"/root/桌面/baidu/model/text_classification/labledict/\" \\\r\n--num_passes=10 \\\r\n2>&1 | tee train.log\r\n~                      \r\n```\r\n但是执行的时候报错\r\nusage: train.py [-h] [--nn_type NN_TYPE] [--train_data_dir TRAIN_DATA_DIR]\r\n                [--test_data_dir TEST_DATA_DIR] [--word_dict WORD_DICT]\r\n                [--label_dict LABEL_DICT] [--batch_size BATCH_SIZE]\r\n                [--num_passes NUM_PASSES] [--model_save_dir MODEL_SAVE_DIR]\r\ntrain.py: error: unrecognized arguments:  \r\nrun2.sh:行7: --train_data_dir=/root/桌面/baidu/model/text_classification/traindata/: 没有那个文件或目录\r\n\r\n这个路径实际是存在的\r\n[root@localhost text_classification]# ls /root/桌面/baidu/model/text_classification/traindata/\r\ntrain.data\r\n",
        "state": "closed",
        "user": "sweetsky0901",
        "closed_by": "luotao1",
        "created_at": "2018-01-17T05:47:54+00:00",
        "updated_at": "2018-01-29T01:58:16+00:00",
        "closed_at": "2018-01-29T01:58:16+00:00",
        "comments_count": [
            "JiayiFeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 569,
        "title": "models/deep_fm使用时报错",
        "body": "我用的是另外一个广告数据集[kaggle avazu](https://www.kaggle.com/c/avazu-ctr-prediction/data)。因为只用了类别特征，去掉了连续值特征对应的输入，运行几分钟后报错。谢谢大家的建议~\r\n\r\n(paddle) ➜  deep_fm CUDA_VISIBLE_DEVICES=2 python train.py \\\r\n        --train_data_path data/train.txt \\\r\n        --test_data_path data/valid.txt\r\nI0109 11:21:08.664938 31376 Util.cpp:166] commandline:  --use_gpu=1 --trainer_count=1\r\nI0109 11:21:14.895238 31376 GradientMachine.cpp:94] Initing parameters..\r\nI0109 11:21:14.985219 31376 GradientMachine.cpp:101] Init parameters done.\r\nF0109 11:28:41.559394 31376 Matrix.cpp:653] Not supported\r\n*** Check failure stack trace: ***\r\n    @     0x7fd3475852fd  google::LogMessage::Fail()\r\n    @     0x7fd347588dac  google::LogMessage::SendToLog()\r\n    @     0x7fd347584e23  google::LogMessage::Flush()\r\n    @     0x7fd34758a2be  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fd3473a6246  paddle::GpuMatrix::mul()\r\n    @     0x7fd34720e8ef  paddle::FullyConnectedLayer::forward()\r\n    @     0x7fd34728af8d  paddle::NeuralNetwork::forward()\r\n    @     0x7fd34728bca3  paddle::GradientMachine::forwardBackward()\r\n    @     0x7fd347561004  GradientMachine::forwardBackward()\r\n    @     0x7fd3470fbad9  _wrap_GradientMachine_forwardBackward\r\n    @     0x7fd3a543cbad  PyEval_EvalFrameEx\r\n    @     0x7fd3a543dc3e  PyEval_EvalCodeEx\r\n    @     0x7fd3a543d1f7  PyEval_EvalFrameEx\r\n    @     0x7fd3a543dc3e  PyEval_EvalCodeEx\r\n    @     0x7fd3a543d1f7  PyEval_EvalFrameEx\r\n    @     0x7fd3a543dc3e  PyEval_EvalCodeEx\r\n    @     0x7fd3a543d1f7  PyEval_EvalFrameEx\r\n    @     0x7fd3a543dc3e  PyEval_EvalCodeEx\r\n    @     0x7fd3a543d1f7  PyEval_EvalFrameEx\r\n    @     0x7fd3a543dc3e  PyEval_EvalCodeEx\r\n    @     0x7fd3a543dd52  PyEval_EvalCode\r\n    @     0x7fd3a545e450  PyRun_FileExFlags\r\n    @     0x7fd3a545e62f  PyRun_SimpleFileExFlags\r\n    @     0x7fd3a5473fd4  Py_Main\r\n    @     0x7fd3a466cf45  __libc_start_main\r\n    @           0x400729  (unknown)\r\n[1]    31376 abort (core dumped)  CUDA_VISIBLE_DEVICES=2 python train.py --train_data_path data/train.txt",
        "state": "closed",
        "user": "yufengwhy",
        "closed_by": "yufengwhy",
        "created_at": "2018-01-09T07:58:15+00:00",
        "updated_at": "2018-01-09T09:37:58+00:00",
        "closed_at": "2018-01-09T09:26:32+00:00",
        "comments_count": [
            "will-am",
            "yufengwhy",
            "will-am",
            "yufengwhy",
            "will-am",
            "yufengwhy",
            "will-am"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 579,
        "title": "请问自动问答就一点教程没有吗？求各位大神，neural_qa",
        "body": "请问自动问答就一点教程没有吗？求各位大神，neural_qa",
        "state": "closed",
        "user": "466821202",
        "closed_by": "luotao1",
        "created_at": "2018-01-18T11:58:46+00:00",
        "updated_at": "2018-01-29T01:57:31+00:00",
        "closed_at": "2018-01-29T01:57:31+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 583,
        "title": "typo in models/fluid/image_classification/se_resnext.py",
        "body": "1. \r\nThere must be` reader` instead of `datareader`.\r\n```\r\ntrain_reader = paddle.batch(datareader.train(), batch_size=batch_size)\r\n```\r\n\r\n2. I use the  flowers102 dataset from` paddle.dataset.flowers.train()` and set the batch size to 1, \r\nbut something wrong happened. \r\nHere is the log:\r\n```\r\nTraceback (most recent call last):\r\n  File \"se_resnext.py\", line 157, in <module>\r\n    train(learning_rate=0.1, batch_size=1, num_passes=100)\r\n  File \"se_resnext.py\", line 127, in train\r\n    exe.run(fluid.default_startup_program())\r\n  File \"/home/xingzhaolong/.jumbo/lib/python2.7/site-packages/paddle/v2/fluid/executor.py\", line 177, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.v2.fluid.core.EnforceNotMet: enforce allocating <= available failed, 10484135494 > 10440015616\r\n at [/home/xingzhaolong/pr/temp/do_something/paddle/platform/gpu_info.cc:89]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fab14ccdae6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7fab16b8c2eep paddle::platform::GpuMaxChunkSize() + 766\r\n2       0x7fab14d622ebp paddle::memory::GetGPUBuddyAllocator(int) + 139\r\n3       0x7fab14d624fcp void* paddle::memory::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace, unsigned long) + 28\r\n4       0x7fab14cd4f8ap paddle::framework::Tensor::PlaceholderImpl<paddle::platform::CUDAPlace>::PlaceholderImpl(paddle::platform::CUDAPlace, unsigned long, std::type_index) + 58\r\n\r\n```\r\nSeems something wrong with the memory allocating.\r\nI use the Graphics with about 10Gb memory.\r\n   2  Tesla K40m          On   | 0000:83:00.0     Off |                    0 |\r\n| N/A   37C    P0    61W / 235W |   1567MiB / 11439MiB |      0%      Default |\r\nI meet the same problem when running `fluid_mnist.py`.\r\nHelp welcome .",
        "state": "closed",
        "user": "NHZlX",
        "closed_by": "NHZlX",
        "created_at": "2018-01-19T14:27:22+00:00",
        "updated_at": "2018-01-21T05:41:26+00:00",
        "closed_at": "2018-01-21T05:40:02+00:00",
        "comments_count": [
            "NHZlX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 587,
        "title": "SSD中的中文文档有遗漏",
        "body": "这里的中文文档没有提供下载链接:[https://github.com/PaddlePaddle/models/blob/develop/ssd/README.cn.md#预训练模型准备](https://github.com/PaddlePaddle/models/blob/develop/ssd/README.cn.md#预训练模型准备)\r\n英文文档是提供了的:[https://github.com/PaddlePaddle/models/blob/develop/ssd/README.md#to-use-pre-trained-model](https://github.com/PaddlePaddle/models/blob/develop/ssd/README.md#to-use-pre-trained-model)\r\n",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-01-22T03:01:50+00:00",
        "updated_at": "2018-01-25T02:46:15+00:00",
        "closed_at": "2018-01-25T02:46:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 588,
        "title": "在目标检测的例子上,能否只使用VOC2007数据集",
        "body": "这个是目标检测的例子[https://github.com/PaddlePaddle/models/tree/develop/ssd](https://github.com/PaddlePaddle/models/tree/develop/ssd),它使用了VOC2007和VOC2012的数据集,但是VOC2012实在太大了,能否只是用VOC2007?",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-01-22T03:05:55+00:00",
        "updated_at": "2018-01-22T04:49:27+00:00",
        "closed_at": "2018-01-22T04:49:27+00:00",
        "comments_count": [
            "NHZlX",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 591,
        "title": "Add model for OCR CTC",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-01-23T10:58:39+00:00",
        "updated_at": "2018-03-07T09:38:40+00:00",
        "closed_at": "2018-03-07T09:38:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 592,
        "title": "fix Chinese document",
        "body": "fix #587 ",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "luotao1",
        "created_at": "2018-01-24T02:25:45+00:00",
        "updated_at": "2018-01-24T04:34:42+00:00",
        "closed_at": "2018-01-24T04:34:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 604,
        "title": "如何求两个vector的平均值？",
        "body": "翻遍API，没有找到... 只有pool里有Avg，但是是针对sequence的，又似乎没有把两个向量拼成seq的操作？ \r\n另外，如何求sum？使用addto吗？为什么感觉文档这么晦涩啊...\r\n\r\nsorry, 应该在paddle下提问！",
        "state": "closed",
        "user": "fseasy",
        "closed_by": "fseasy",
        "created_at": "2018-01-29T12:55:51+00:00",
        "updated_at": "2018-01-29T12:56:56+00:00",
        "closed_at": "2018-01-29T12:56:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 605,
        "title": "Add text classification with Fluid.",
        "body": "num_pass: 30\r\nbatch_size: 4\r\nuse_gpu: False\r\n\r\nTime cost:\r\n\r\nCPU: Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz\r\nTrain time: 7252.858182s\r\ncommit id:  fb1a0dfb157032f3eb7cdabcb445a77656ef2498\r\n\r\nCPU: Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\r\nTrain time: 5022.535137s\r\ncommit id: 4fb3c676a8f229684f0369d5e2e0d549c97565a8\r\n\r\n",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2018-01-30T10:52:33+00:00",
        "updated_at": "2018-01-31T12:35:12+00:00",
        "closed_at": "2018-01-31T12:35:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 590,
        "title": "sequence_tagging_for_ner/infer.py预测出错",
        "body": "训练日志中测试集上error < 0.05，但是测试集通过sequence_tagging_for_ner/infer.py的输出标签大部分都是错的。\r\n在infer.py的第15行，将start_id 赋值为0，这样每次输出都是从probs的初始位置开始，没有输出正确的预测标签。",
        "state": "closed",
        "user": "hujq1002",
        "closed_by": "shanyi15",
        "created_at": "2018-01-23T08:31:13+00:00",
        "updated_at": "2018-08-15T10:11:03+00:00",
        "closed_at": "2018-08-15T10:11:03+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 603,
        "title": "AttributeError: 'module' object has no attribute 'elementwise_mul'",
        "body": "When I run https://github.com/PaddlePaddle/models/blob/develop/fluid/image_classification/se_resnext.py,\r\nI met an error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"se_resnext.py\", line 160, in <module>\r\n    train(learning_rate=0.1, batch_size=8, num_passes=100)\r\n  File \"se_resnext.py\", line 110, in train\r\n    out = SE_ResNeXt(input=image, class_dim=class_dim)\r\n  File \"se_resnext.py\", line 91, in SE_ResNeXt\r\n    reduction_ratio=reduction_ratio)\r\n  File \"se_resnext.py\", line 62, in bottleneck_block\r\n    reduction_ratio=reduction_ratio)\r\n  File \"se_resnext.py\", line 31, in squeeze_excitation\r\n    scale = fluid.layers.elementwise_mul(x=input, y=excitation, axis=0)\r\nAttributeError: 'module' object has no attribute 'elementwise_mul'\r\n```\r\n\r\nThe PaddlePaddle is installed by `pip install paddlepaddle` and the version is 0.11.\r\nIt seems that it needs a new PaddlePaddle version.\r\n\r\nSince `models` are used for end users, maybe we need to test our implement from the user's point of view.",
        "state": "closed",
        "user": "gongweibao",
        "closed_by": "shanyi15",
        "created_at": "2018-01-27T05:56:24+00:00",
        "updated_at": "2018-08-15T10:11:00+00:00",
        "closed_at": "2018-08-15T10:11:00+00:00",
        "comments_count": [
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 598,
        "title": "贡献youtube的召回模型代码",
        "body": "我们用PaddlePaddle实现了youtube的召回模型，想要贡献到PaddlePaddle的models下。\r\n解决问题：模型主要用于从大规模的内容库中，召回用户感兴趣的个性化内容。",
        "state": "closed",
        "user": "Bella-Zhao",
        "closed_by": "lcy-seso",
        "created_at": "2018-01-25T07:18:38+00:00",
        "updated_at": "2020-05-06T10:17:07+00:00",
        "closed_at": "2018-02-03T03:40:10+00:00",
        "comments_count": [
            "ucasiggcas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 610,
        "title": "First commit test ",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "zhxfl",
        "created_at": "2018-01-31T04:04:49+00:00",
        "updated_at": "2018-02-02T05:59:10+00:00",
        "closed_at": "2018-02-02T05:59:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 608,
        "title": " Kick off DeepASR",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "pkuyym",
        "created_at": "2018-01-31T03:56:42+00:00",
        "updated_at": "2018-01-31T04:02:29+00:00",
        "closed_at": "2018-01-31T04:02:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 607,
        "title": "Profiling of text_classification with Fluid.",
        "body": "text_classification的Profiling结果，源码https://github.com/PaddlePaddle/models/tree/develop/fluid/text_classification：\r\n\r\n训练配置：\r\n```\r\nbatch_size: 4\r\nnum_of_batch: 500\r\ndict_size: 89528\r\n```\r\n\r\nProfiling Report 指标：\r\n```\r\nCalls: 表示总共调用的数量\r\nTotal：表示总共运行的时长\r\nMin：表示所有的调用中最短的一次调用时长\r\nMax：表示所有调用中最长的一次调用时长\r\nAve：表示所有调用的平均调用时长\r\n```\r\n\r\n训练500个batch的Profiling Report 结果：\r\n```\r\nThe dictionary size is : 89528\r\nTotal time: 16.033737\r\n\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: CPU\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                            Calls       Total       Min.        Max.        Ave.\r\nthread0::sgd                     3493        4830.48     0.009502    15.5302     1.3829\r\nthread0::lookup_table_grad       499         4775.31     9.31438     12.5104     9.56976\r\nthread0::sequence_conv_grad      499         1683.32     1.04954     15.5015     3.3734\r\nthread0::sequence_conv           499         1048.58     0.698105    14.0347     2.10136\r\nthread0::elementwise_add_grad    1497        210.856     0.013004    1.14577     0.140852\r\nthread0::elementwise_add         1497        122.64      0.00811     0.577024    0.0819238\r\nthread0::tanh                    499         117.027     0.090373    0.623305    0.234523\r\nthread0::sequence_pool           499         104.869     0.100548    0.479671    0.210159\r\nthread0::lookup_table            499         67.5452     0.059546    0.555258    0.135361\r\nthread0::tanh_grad               499         54.0636     0.044505    0.316446    0.108344\r\nthread0::sequence_pool_grad      499         36.3875     0.039143    0.18097     0.0729209\r\nthread0::mul_grad                998         35.8055     0.023166    0.237668    0.0358772\r\nthread0::mul                     998         26.0178     0.011744    0.074651    0.02607\r\nthread0::cast                    1996        19.4615     0.0061      0.158941    0.00975027\r\nthread0::sum                     998         15.1658     0.009326    0.09614     0.0151962\r\nthread0::top_k                   499         14.7059     0.025781    0.0949      0.0294708\r\nthread0::accuracy                499         10.6152     0.018964    0.059349    0.021273\r\nthread0::softmax                 499         8.14185     0.014948    0.044151    0.0163163\r\nthread0::cross_entropy_grad      499         7.07577     0.0132      0.023645    0.0141799\r\nthread0::cross_entropy           499         6.96024     0.012991    0.02396     0.0139484\r\nthread0::feed                    998         6.73899     0.004097    0.035801    0.00675249\r\nthread0::softmax_grad            499         6.43104     0.011922    0.032686    0.0128879\r\nthread0::fetch                   1497        5.35905     0.001853    0.019403    0.00357986\r\nthread0::elementwise_div         499         5.16685     0.008804    0.073607    0.0103544\r\nthread0::mean_grad               499         4.91204     0.009089    0.044894    0.00984377\r\nthread0::mean                    499         3.64095     0.006551    0.041162    0.00729649\r\nthread0::fill_constant           499         3.02958     0.005365    0.031708    0.00607131\r\n```\r\n\r\n训练1个pass的Profiling Report 结果：\r\n\r\n```\r\nThe dictionary size is : 89528\r\nTotal time: 246.533985\r\n\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: CPU\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                            Calls       Total       Min.        Max.        Ave.\r\nthread0::lookup_table_grad       6248        85039.4     12.9076     32.3335     13.6107\r\nthread0::sgd                     43736       68442.7     0.009991    35.3864     1.5649\r\nthread0::sequence_conv_grad      6248        24102.5     0.776669    45.2805     3.85763\r\nthread0::sequence_conv           6248        16146       0.47397     29.5967     2.58418\r\nthread0::elementwise_add_grad    18744       2645.15     0.013075    1.76686     0.14112\r\nthread0::elementwise_add         18744       1515.66     0.007877    1.35418     0.0808611\r\nthread0::tanh                    6248        1412.74     0.078598    2.58319     0.226111\r\nthread0::sequence_pool           6248        1296.17     0.084166    1.01645     0.207454\r\nthread0::lookup_table            6248        996.414     0.061383    2.69139     0.159477\r\nthread0::tanh_grad               6248        686.66      0.040493    3.34762     0.109901\r\nthread0::sequence_pool_grad      6248        460.941     0.03908     0.767207    0.0737741\r\nthread0::mul_grad                12496       455.801     0.023004    1.12555     0.0364757\r\nthread0::mul                     12496       323.891     0.011963    0.718241    0.0259196\r\nthread0::cast                    24992       319.577     0.006238    24.1128     0.0127872\r\nthread0::top_k                   6248        238.347     0.026201    12.0761     0.0381477\r\nthread0::sum                     12496       227.388     0.009395    16.0632     0.0181969\r\nthread0::accuracy                6248        171.487     0.020024    15.2487     0.0274467\r\nthread0::softmax                 6248        105.258     0.015404    0.702274    0.0168467\r\nthread0::feed                    12496       94.2271     0.003959    4.75252     0.00754058\r\nthread0::cross_entropy_grad      6248        90.4667     0.013344    0.148185    0.0144793\r\nthread0::cross_entropy           6248        88.0551     0.012642    0.698313    0.0140933\r\nthread0::softmax_grad            6248        84.509      0.012117    0.699262    0.0135258\r\nthread0::fetch                   18744       76.1771     0.001746    0.098168    0.00406408\r\nthread0::elementwise_div         6248        69.8883     0.009183    1.36969     0.0111857\r\nthread0::mean_grad               6248        62.9747     0.008981    0.056408    0.0100792\r\nthread0::mean                    6248        45.4185     0.006505    0.045735    0.00726928\r\nthread0::fill_constant           6248        38.8432     0.005422    0.637213    0.0062169\r\n```\r\n\r\n结论：\r\n其中 lookup_table_grad 时间占用明显过长\r\n ",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2018-01-30T11:34:32+00:00",
        "updated_at": "2018-08-15T10:10:56+00:00",
        "closed_at": "2018-08-15T10:10:56+00:00",
        "comments_count": [
            "peterzhang2029",
            "peterzhang2029",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 620,
        "title": "Multi-process pipeline for data augumentation",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-02-02T06:15:41+00:00",
        "updated_at": "2018-02-06T07:09:30+00:00",
        "closed_at": "2018-02-06T07:09:30+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 619,
        "title": "场景文字识别例子的一些问题",
        "body": "在[场景文字识别](https://github.com/PaddlePaddle/models/tree/develop/scene_text_recognition)这个例子中，更book中的例子有里很大的不同，我看了很久也看不懂所以然，路过的大神能否解答以下一些问题：\r\n1. 例子中很多都用到了`click`这个东西，这个有什么用，我猜是命令行里的参数，不知道是不是。\r\n2. 这个例子用用到的神经网络模型是什么，跟传统的图像分类不一样了。\r\n3. 如何修改这个例子才可以使用CPU运行\r\n4. 下面的训练输出日志正常吗？Eval后面没东西的\r\n```\r\nPass 73, batch 0, Samples 0, Cost 10.854516, Eval {}\r\nPass 73, batch 50, Samples 500, Cost 0.071530, Eval {}\r\nTest 73, Cost 12.956735, Eval {}\r\nPass 74, batch 0, Samples 0, Cost 15.511139, Eval {}\r\nPass 74, batch 50, Samples 500, Cost 0.054424, Eval {}\r\nTest 74, Cost 12.839751, Eval {}\r\n```\r\n\r\n谢谢各位大神",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-02-01T13:56:29+00:00",
        "updated_at": "2018-02-03T10:24:47+00:00",
        "closed_at": "2018-02-03T10:24:47+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 621,
        "title": "Need refine the directory structure for DeepASR",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-02-02T06:36:05+00:00",
        "updated_at": "2018-02-02T08:34:13+00:00",
        "closed_at": "2018-02-02T08:34:13+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 623,
        "title": "Need adapt the unit test for CI",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-02-02T06:41:09+00:00",
        "updated_at": "2018-02-02T07:42:00+00:00",
        "closed_at": "2018-02-02T07:42:00+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 622,
        "title": "Multi-device support for model training",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-02-02T06:37:44+00:00",
        "updated_at": "2018-02-07T07:18:12+00:00",
        "closed_at": "2018-02-07T07:18:12+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 626,
        "title": "split long sentence",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "zhxfl",
        "created_at": "2018-02-02T08:16:14+00:00",
        "updated_at": "2018-02-02T08:18:07+00:00",
        "closed_at": "2018-02-02T08:18:07+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 624,
        "title": "Performance profiling for model part",
        "body": "- [x] Profile the performance on single GPU device(#637).\r\n- [x] Measure the speedup ratio on multiple GPUs(#669).\r\n- [ ] Performance analysis and enhancement([#8750](https://github.com/PaddlePaddle/Paddle/issues/8750)). ",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-02-02T06:51:04+00:00",
        "updated_at": "2018-08-15T10:10:53+00:00",
        "closed_at": "2018-08-15T10:10:53+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 629,
        "title": "Need to parallel the data processing to speed up",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-02-02T08:35:46+00:00",
        "updated_at": "2018-02-02T08:36:55+00:00",
        "closed_at": "2018-02-02T08:36:55+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 627,
        "title": "split long sentence",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "zhxfl",
        "created_at": "2018-02-02T08:17:27+00:00",
        "updated_at": "2018-03-01T08:14:06+00:00",
        "closed_at": "2018-03-01T08:14:06+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 630,
        "title": "Need to parallel the data processing to speed up",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-02-02T08:36:48+00:00",
        "updated_at": "2018-02-06T04:48:24+00:00",
        "closed_at": "2018-02-06T04:48:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 633,
        "title": "add fluid mobilenet config",
        "body": "add fluid mobilenet config",
        "state": "closed",
        "user": "NHZlX",
        "closed_by": "NHZlX",
        "created_at": "2018-02-02T13:06:25+00:00",
        "updated_at": "2018-02-09T08:00:00+00:00",
        "closed_at": "2018-02-09T08:00:00+00:00",
        "comments_count": [],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 638,
        "title": "Turn off the error complaint when data reader is interrupted ",
        "body": "If the data reader is interrupted  by ```break``` in the ```for``` loop or ```ctrl+c``` from keyboard when loading batch data iteratively, there would output a lot of error complaints which look like\r\n\r\n```\r\nProcess Process-9:\r\nProcess Process-10:\r\nTraceback (most recent call last):\r\nProcess Process-5:\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nTraceback (most recent call last):\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/paddle_work/models/fluid/DeepASR/data_utils/data_reader.py\", line 264, in ordered_processing_task\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/paddle_work/models/fluid/DeepASR/data_utils/data_reader.py\", line 317, in batch_assembling_task\r\n    for sample in sample_generator():\r\n  File \"/paddle_work/models/fluid/DeepASR/data_utils/data_reader.py\", line 291, in _sample_generator\r\n    sample = sample_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    self.run()\r\n    self.run()\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "pkuyym",
        "created_at": "2018-02-06T06:16:25+00:00",
        "updated_at": "2018-02-06T12:32:18+00:00",
        "closed_at": "2018-02-06T12:32:18+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 631,
        "title": "add deconvolution and prelu support to caffe2paddle tools",
        "body": "add deconvolution and prelu support to caffe2paddle tools",
        "state": "closed",
        "user": "NHZlX",
        "closed_by": "shanyi15",
        "created_at": "2018-02-02T12:14:03+00:00",
        "updated_at": "2018-08-15T10:10:49+00:00",
        "closed_at": "2018-08-15T10:10:49+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 639,
        "title": "Augmentation should compute frame_dim @zhxf",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "zhxfl",
        "created_at": "2018-02-06T07:01:38+00:00",
        "updated_at": "2018-02-08T02:34:35+00:00",
        "closed_at": "2018-02-08T02:34:35+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 637,
        "title": "Profiling result on single GPU device",
        "body": "See the script for profiling in #636\r\nDevice:  Tesla K40m (12GB)\r\nConclusion: The computation of LSTMP layer, especially the backward, takes the most time.\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ndevice: GPU\r\nfeature_lst: data/feature.lst\r\nfirst_batches_to_skip: 1\r\nhidden_dim: 1024\r\nlabel_lst: data/label.lst\r\nlearning_rate: 0.002\r\nmax_batch_num: 10\r\nmean_var: data/global_mean_var_search26kHr\r\nparallel: False\r\nprint_train_acc: False\r\nproj_dim: 512\r\nsorted_key: total\r\nstacked_num: 5\r\n------------------------------------------------\r\n..........\r\nTime consumed: 18.386745 s, performance: 3199.098050 frames/s.\r\n\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: CUDA\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                            Calls       Total       Min.        Max.        Ave.\r\nthread0::lstmp_grad              45          9387.12     203.389     213.289     208.603\r\nthread0::lstmp                   45          4344.11     94.435      98.2327     96.5359\r\nthread0::mul_grad                54          1233.86     8.95155     42.5825     22.8492\r\nthread0::mul                     54          599.213     4.5631      20.7512     11.0965\r\nthread0::batch_norm_grad         54          570.634     8.05872     19.7179     10.5673\r\nthread0::batch_norm              54          505.514     7.44077     17.1559     9.36137\r\nthread0::sequence_conv_grad      9           441.255     45.7588     52.7421     49.0283\r\nthread0::sequence_conv           9           232.747     24.8565     27.555      25.8607\r\nthread0::elementwise_add_grad    63          105.817     0.516352    2.19734     1.67963\r\nthread0::elementwise_add         63          89.0073     0.371936    2.18442     1.41281\r\nthread0::adam                    369         55.4231     0.00704     0.808288    0.150198\r\nthread0::softmax                 9           44.3238     4.69805     5.15946     4.92487\r\nthread0::softmax_grad            9           19.5171     2.03376     2.31587     2.16857\r\nthread0::sigmoid_grad            54          17.3561     0.25632     0.58752     0.32141\r\nthread0::sigmoid                 54          12.0755     0.180064    0.403328    0.22362\r\nthread0::top_k                   9           8.62765     0.901312    1.02582     0.958628\r\nthread0::mean                    9           5.47344     0.571712    0.644768    0.60816\r\nthread0::elementwise_mul         369         2.65594     0.005856    0.008512    0.00719766\r\nthread0::cross_entropy_grad      9           2.55389     0.260096    0.311232    0.283765\r\nthread0::fill_constant           378         2.31142     0.005216    0.01536     0.00611488\r\nthread0::fill_zeros_like         216         1.52355     0.005504    0.012224    0.00705348\r\nthread0::fetch                   18          0.783648    0.025696    0.072096    0.043536\r\nthread0::accuracy                9           0.422208    0.046432    0.048224    0.046912\r\nthread0::feed                    18          0.192256    0.006144    0.02        0.0106809\r\nthread0::mean_grad               9           0.13536     0.013824    0.01536     0.01504\r\nthread0::cross_entropy           9           0.125536    0.012672    0.014688    0.0139484\r\nthread0::scale                   18          0.110144    0.005536    0.007744    0.00611911\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-02-05T12:40:26+00:00",
        "updated_at": "2018-08-15T10:07:34+00:00",
        "closed_at": "2018-08-15T10:07:34+00:00",
        "comments_count": [
            "zhxfl",
            "kuke",
            "zhxfl",
            "zhxfl",
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 644,
        "title": "Add sequence labeling model for Fluid.",
        "body": "Add sequence labeling model which can be tasks like NER or SRL in NLP to https://github.com/PaddlePaddle/models/tree/develop/fluid .\r\n\r\nCan take this model https://github.com/PaddlePaddle/models/tree/develop/sequence_tagging_for_ner as a reference, or any other state-of-art model. ",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2018-02-07T02:43:18+00:00",
        "updated_at": "2018-03-21T08:05:15+00:00",
        "closed_at": "2018-03-21T08:05:15+00:00",
        "comments_count": [
            "guru4elephant",
            "lcy-seso"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 643,
        "title": "Translate one model doc to help promote our business cooperation",
        "body": "PaddlePaddle Training Camp（[PaddlePaddle训练营](http://ai.baidu.com/paddlepaddle) ）,as a platform for business cooperation, displays cases of practical application of PaddlePaddle on its website. \r\n\r\nIn the new version of this website, it will use **Click-Through Rate prediction** as a good case to introduce PaddlePaddle to **Chinese** business cooperators. 2 models' link will be shown on the website: [Wide & deep 点击率预估模型](http://www.paddlepaddle.org/docs/develop/models/ctr/README.cn.html) and[ 基于深度因子分解机的点击率预估模型](http://www.paddlepaddle.org/docs/develop/models/deep_fm/README.html). However, the second model **only has English version** documentation.\r\n\r\n Since the new version of this website will be online on **8th Feb**. It's very urgent for us to translate this model documentation: [ 基于深度因子分解机的点击率预估模型](http://www.paddlepaddle.org/docs/develop/models/deep_fm/README.html)\r\n\r\n\r\nThank you very much!\r\n",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-02-06T09:31:17+00:00",
        "updated_at": "2018-03-12T00:37:16+00:00",
        "closed_at": "2018-03-12T00:37:16+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 645,
        "title": "Add N-gram language model for Fluid.",
        "body": "Add N-gram language model for Fluid.\r\n\r\nCan take this model https://github.com/PaddlePaddle/models/tree/develop/nce_cost as a reference, or any other state-of-art model.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:46:42+00:00",
        "updated_at": "2018-08-15T10:07:31+00:00",
        "closed_at": "2018-08-15T10:07:31+00:00",
        "comments_count": [
            "guru4elephant",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 646,
        "title": "Add RNN language model for Fluid.",
        "body": "Add RNN language model for Fluid.\r\n\r\nCan take this model as a reference https://github.com/PaddlePaddle/models/tree/develop/generate_sequence_by_rnn_lm or any other state-of-art model.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:48:08+00:00",
        "updated_at": "2018-08-15T10:07:28+00:00",
        "closed_at": "2018-08-15T10:07:28+00:00",
        "comments_count": [
            "alexqdh",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 647,
        "title": "Add Inception-V4 for Fluid.",
        "body": "Add inception-V4 for Fluid.\r\n\r\nCan take this https://github.com/PaddlePaddle/models/blob/develop/image_classification/inception_v4.py as a reference.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:53:26+00:00",
        "updated_at": "2018-08-15T10:07:20+00:00",
        "closed_at": "2018-08-15T10:07:20+00:00",
        "comments_count": [
            "xymyeah",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 648,
        "title": "Add Inception-Resnet-V2 for Fluid.",
        "body": "Add Inception-Resnet-V2 for Fluid.\r\n\r\nCan take this https://github.com/PaddlePaddle/models/blob/develop/image_classification/inception_resnet_v2.py as a reference.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:54:33+00:00",
        "updated_at": "2018-08-15T10:07:17+00:00",
        "closed_at": "2018-08-15T10:07:17+00:00",
        "comments_count": [
            "BigFishMaster",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 651,
        "title": "Fatal exception of sub process or thread should be threw and main process should be notified.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-02-07T08:51:49+00:00",
        "updated_at": "2018-02-08T03:04:51+00:00",
        "closed_at": "2018-02-08T03:04:51+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 649,
        "title": "Add Xception for Fluid",
        "body": "Add Xception for Fluid.\r\n\r\nCan take this https://github.com/PaddlePaddle/models/blob/develop/image_classification/xception.py as a reference.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:55:30+00:00",
        "updated_at": "2018-08-15T10:07:09+00:00",
        "closed_at": "2018-08-15T10:07:09+00:00",
        "comments_count": [
            "godson1024",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 650,
        "title": "Add LTR model for Fluid.",
        "body": "Add LTR model for Fluid.\r\n\r\nCan take this https://github.com/PaddlePaddle/models/tree/develop/ltr as a reference or any other state-of-art model.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T02:57:32+00:00",
        "updated_at": "2018-08-15T09:56:33+00:00",
        "closed_at": "2018-08-15T09:56:33+00:00",
        "comments_count": [
            "wangsouc",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "bootcamp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 654,
        "title": "Add the demo script for inference",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-02-07T09:32:28+00:00",
        "updated_at": "2018-02-08T12:19:10+00:00",
        "closed_at": "2018-02-08T12:19:10+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 658,
        "title": "Add the Transformer demo for NMT",
        "body": "Add the Transformer demo for NMT.",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "lcy-seso",
        "created_at": "2018-02-07T16:37:08+00:00",
        "updated_at": "2018-02-12T06:01:49+00:00",
        "closed_at": "2018-02-12T06:01:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 657,
        "title": "Need adapt data reader to support inference.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2018-02-07T13:02:43+00:00",
        "updated_at": "2018-08-15T09:56:29+00:00",
        "closed_at": "2018-08-15T09:56:29+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 661,
        "title": "Adapt data reader to support inference (without label)",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "kuke",
        "created_at": "2018-02-08T11:17:56+00:00",
        "updated_at": "2018-03-30T10:20:48+00:00",
        "closed_at": "2018-03-30T10:20:48+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 664,
        "title": "Enable checkpoints saving and training resuming",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-02-09T12:20:06+00:00",
        "updated_at": "2018-02-11T08:45:29+00:00",
        "closed_at": "2018-02-11T08:45:29+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 666,
        "title": "Profiling failed in multi-gpu mode",
        "body": "Need to improve the profiler to support multi-gpu mode. The log:\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ndevice: GPU\r\nfeature_lst: data/feature.lst\r\nfirst_batches_to_skip: 1\r\nhidden_dim: 1024\r\nlabel_lst: data/label.lst\r\nlearning_rate: 0.002\r\nmax_batch_num: 10\r\nmean_var: data/global_mean_var_search26kHr\r\nminimum_batch_size: 1\r\nparallel: True\r\nprint_train_acc: False\r\nproj_dim: 512\r\nsorted_key: total\r\nstacked_num: 5\r\n------------------------------------------------\r\nF0224 03:39:43.402420 20900 threadpool.h:96] The exception is thrown inside the thread pool. You should use RunAndGetException to handle the exception.\r\nThe default exception handler is LOG(FATAL).invalid resource handle at [/paddle_work/Paddle/paddle/fluid/platform/profiler.cc:59]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f8b5bb5ba7cp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572\r\n1       0x7f8b5bc09803p paddle::platform::Event::Event(paddle::platform::EventKind, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, paddle::platform::DeviceContext const*) + 979\r\n2       0x7f8b5bc0b2aap paddle::platform::PushEvent(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, paddle::platform::DeviceContext const*) + 314\r\n3       0x7f8b5bc0b89dp paddle::platform::RecordEvent::RecordEvent(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, paddle::platform::DeviceContext const*) + 93\r\n4       0x7f8b5bbfebc8p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 1336\r\n5       0x7f8b5c4a7f33p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > >, std::__future_base::_Result_base::_Deleter>, std::_Bind_simple<std::reference_wrapper<std::future<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > > paddle::framework::ThreadPool::RunAndGetException<paddle::operators::ParallelDoOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1}>(paddle::operators::ParallelDoOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1})::{lambda()#1}> ()>, std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > > >::_M_invoke(std::_Any_data const&) + 99\r\n6       0x7f8b5c4a4a1ep std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*) + 46\r\n7       0x7f8b95a05a99p\r\n8       0x7f8b5c4a5062p std::__future_base::_State_baseV2::_M_set_result(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>, bool) + 146\r\n9       0x7f8b5c4a5296p std::__future_base::_Task_state<std::future<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<std::unique_ptr> > > paddle::framework::ThreadPool::RunAndGetException<paddle::operators::ParallelDoOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1}>(paddle::operators::ParallelDoOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1})::{lambda()#1}, std::allocator<int>, std::default_delete<std::unique_ptr> ()>::_M_run() + 86\r\n10      0x7f8b5c6a86b4p paddle::framework::ThreadPool::TaskLoop() + 1012\r\n11      0x7f8b89d98c80p\r\n12      0x7f8b959fe6bap\r\n13      0x7f8b9573482dp clone + 109\r\n*** Check failure stack trace: ***\r\n    @     0x7f8b5c7814dd  google::LogMessage::Fail()\r\n    @     0x7f8b5c783828  google::LogMessage::SendToLog()\r\n    @     0x7f8b5c780feb  google::LogMessage::Flush()\r\n    @     0x7f8b5c7846fe  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f8b5c4a5cd7  std::_Function_handler<>::_M_invoke()\r\n    @     0x7f8b5c4a4a1e  std::__future_base::_State_baseV2::_M_do_set()\r\n    @     0x7f8b95a05a99  __pthread_once_slow\r\n    @     0x7f8b5c4a5062  std::__future_base::_State_baseV2::_M_set_result()\r\n    @     0x7f8b5c4a5121  std::__future_base::_Deferred_state<>::_M_complete_async()\r\n    @     0x7f8b5c4ad762  paddle::operators::ParallelDoOp::RunImpl()\r\n    @     0x7f8b5bbfec8e  paddle::framework::Executor::Run()\r\n    @     0x7f8b5bb78433  _ZZN8pybind1112cpp_function10initializeIZNS0_C4IvN6paddle9framework8ExecutorEIRKNS4_11ProgramDescEPNS4_5ScopeEibbEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vISO_S8_SA_ibbEISB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_\r\n    @     0x7f8b5bb76174  pybind11::cpp_function::dispatcher()\r\n    @           0x4cada2  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7f8b9564e830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\nAborted\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-02-24T03:45:15+00:00",
        "updated_at": "2018-02-28T08:56:10+00:00",
        "closed_at": "2018-02-28T08:56:10+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 669,
        "title": "Speedup ratio on multiple GPUs",
        "body": "Some important arguments:\r\n\r\n```\r\nbatch_size: 32\r\ndevice: GPU\r\nfirst_batches_to_skip: 1\r\nhidden_dim: 1024\r\nlearning_rate: 0.002\r\nmax_batch_num: 10\r\nmean_var: data/global_mean_var_search26kHr\r\nminimum_batch_size: 1\r\nparallel: True\r\nproj_dim: 512\r\nstacked_num: 5\r\n```\r\n\r\nSpeedup on different number of GPUs:\r\n\r\n| GPUs   |  Performance (frames/s)   |   Speedup ratio |\r\n|:--------:|:---------------------------:|:-----------------:|\r\n| 1      |  2590.32                  |     1.0x        |\r\n| 2      |  3004.38                  |     1.16x       |\r\n| 3      |  3183.40                  |     1.23x       |\r\n| 4      |  3459.31                  |     1.36x       |",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-02-26T04:58:39+00:00",
        "updated_at": "2018-08-15T09:56:25+00:00",
        "closed_at": "2018-08-15T09:56:25+00:00",
        "comments_count": [
            "kuke",
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 674,
        "title": "Need provide a demo for actually usable beam search ",
        "body": "- [x] Validate the weights sharing between training and inference\r\n- [ ] Add complex RNN model (with attention)\r\n- [x] Enhance the sequence_expand operator\r\n",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "ktlichkid",
        "created_at": "2018-03-01T03:36:25+00:00",
        "updated_at": "2018-08-06T10:36:20+00:00",
        "closed_at": "2018-08-06T10:36:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 673,
        "title": "Profiling results for sync data reader of DeepASR",
        "body": "测试采用实际音频数据，共run了10个batch，batch size=32，去掉异步和buffer，结论如下：\r\n1. 最主要热点是trans add delta，这个占用了超过80%的时间\r\n2. feeding操作耗时很少，可以暂不考虑优化\r\n\r\n主函数耗时分析：\r\n1. 热点是data processing\r\n2. feeding操作耗时很少，可以排除掉这个风险\r\n\r\n```python\r\nTotal time: 109.838 s\r\nFile: profile_sync_reader.py\r\nFunction: profile_reader at line 33\r\n\r\nLine #      Hits         Time  Per Hit   % Time  Line Contents\r\n==============================================================\r\n    33                                           @profile\r\n    34                                           def profile_reader(epoch_num, batch_size):\r\n    35         2         10.0      5.0      0.0      for epoch_id in xrange(epoch_num):\r\n    36         1          4.0      4.0      0.0          for batch_id, one_batch in enumerate(\r\n    37        11   95392189.0 8672017.2     86.8                  data_reader.batch_iterator(batch_size, batch_size)):\r\n    38        11      46440.0   4221.8      0.0              (bat_feature, bat_label, lod) = one_batch\r\n    39        11      83802.0   7618.4      0.1              res_feature.set(bat_feature, place)\r\n    40        11        452.0     41.1      0.0              res_feature.set_lod([lod])\r\n    41        11       1048.0     95.3      0.0              res_label.set(bat_label, place)\r\n    42        11         90.0      8.2      0.0              res_label.set_lod([lod])\r\n    43        11   14309543.0 1300867.5     13.0              time.sleep(1.3)\r\n    44        11         61.0      5.5      0.0              if batch_id > 9:\r\n    45         1       4296.0   4296.0      0.0                  break\r\n```\r\n",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2018-02-28T09:02:03+00:00",
        "updated_at": "2018-08-15T09:56:22+00:00",
        "closed_at": "2018-08-15T09:56:22+00:00",
        "comments_count": [
            "pkuyym",
            "pkuyym",
            "pkuyym",
            "pkuyym",
            "pkuyym",
            "kuke",
            "pkuyym",
            "kuke",
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 670,
        "title": "有关fluid的操作，好像还没有教程，能否出一个文件像book那样说明fluid的操作流程",
        "body": "比如在这个程序中https://github.com/PaddlePaddle/models/blob/develop/fluid/image_classification/mobilenet.py 能否写一下注释，还有预测部分好像也没有哦",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-02-26T05:07:20+00:00",
        "updated_at": "2018-03-09T04:49:57+00:00",
        "closed_at": "2018-03-09T04:49:57+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 676,
        "title": "The convergence comparison between Fluid and Houyi",
        "body": "To verify the correctness, we take about 1/13 training data, and carry out the contrast training of models on one single GPU with Adam optimizer. The benchmark is the model on the internal framework Houyi developed by the Speech team.\r\n\r\nSetting:\r\n\r\n```\r\nbatch_size: 32\r\ndevice: GPU\r\nhidden_dim: 1024\r\nlearning_rate: 0.00016\r\nminimum_batch_size: 1\r\nparallel: False\r\nproj_dim: 512\r\nstacked_num: 5\r\n```\r\n\r\n![training_acc](https://user-images.githubusercontent.com/3064195/36826671-efcc84fa-1d49-11e8-9826-7739f7a3972c.png)\r\n\r\nThe comparion shows that the two learning curvers match with each other very well. And we verify the convergence of DeepASR on part of training data.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-03-01T04:13:56+00:00",
        "updated_at": "2018-08-15T09:56:17+00:00",
        "closed_at": "2018-08-15T09:56:17+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 683,
        "title": "how to make parameter(layer) untrainable in fluid? ",
        "body": "In tensorflow, we can set variable untrainable by setting parameter's attribute (trainable=False)\r\nDo we have similar API In fluid?",
        "state": "closed",
        "user": "TomorrowIsAnOtherDay",
        "closed_by": "TomorrowIsAnOtherDay",
        "created_at": "2018-03-05T11:09:28+00:00",
        "updated_at": "2018-03-05T11:09:51+00:00",
        "closed_at": "2018-03-05T11:09:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 678,
        "title": "模型报错退出",
        "body": "采用5000图片用image_classification示例程序训练alexnet模型（二分类），报错退出（200样本【非5000子集】成功跑完70轮）\r\n\r\n1、报错如下：\r\n\r\n```\r\nPass 0, Batch 3, Cost 20.500000, {'classification_error_evaluator': 0.3203125}\r\nThread [139688770483968] Forwarding __fc_layer_2__,\r\n*** Aborted at 1519981919 (unix time) try \"date -d @1519981919\" if you are using GNU date ***\r\n] Forwarding __fc_layer_2__,\r\n*** Aborted at 1519981919 (unix time) try \"date -d @1519981919\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7f0b855a784e) received by PID 58007 (TID 0x7f0bd38b3700) from PID 18446744071651883086; stack trace: ***\r\n    @       0x318b20f500 (unknown)\r\n    @     0x7f0b855a784e sgemm_kernel_SANDYBRIDGE\r\n\r\nFloating point exception(core dumped)\r\n```\r\n\r\n2、添加error_clipping_threshold参数未有效解决\r\n![default](https://user-images.githubusercontent.com/36145868/36893751-30101a54-1e44-11e8-8bda-1150ece26564.png)",
        "state": "closed",
        "user": "yuanghbdbj",
        "closed_by": "shanyi15",
        "created_at": "2018-03-02T10:05:45+00:00",
        "updated_at": "2018-08-15T09:56:14+00:00",
        "closed_at": "2018-08-15T09:56:14+00:00",
        "comments_count": [
            "yeyupiaoling",
            "yeyupiaoling",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 682,
        "title": "how to make parameter(layer) untrainable in fluid?",
        "body": "In tensorflow, we can set variable untrainable by setting parameter's attribute (trainable=False)\r\nDo we have similar API In fluid?",
        "state": "closed",
        "user": "TomorrowIsAnOtherDay",
        "closed_by": "shanyi15",
        "created_at": "2018-03-05T10:11:35+00:00",
        "updated_at": "2018-08-15T09:56:10+00:00",
        "closed_at": "2018-08-15T09:56:10+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 680,
        "title": "场景文字识别的例子中，使用到的神经网络是什么？",
        "body": "在这个场景文字识别https://github.com/PaddlePaddle/models/tree/develop/scene_text_recognition 中，使用到的是什么神经网络模型，告诉我，我好去看相关论文，谢谢",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-03-04T12:21:25+00:00",
        "updated_at": "2018-05-09T09:21:58+00:00",
        "closed_at": "2018-03-08T03:58:28+00:00",
        "comments_count": [
            "peterzhang2029",
            "yeyupiaoling",
            "peterzhang2029"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 684,
        "title": "The README.md of mt_with_external_memory has some inaccurate points.",
        "body": "For training script, there should be `python train.py` instead of `python mt_with_external_memory.py`\r\n",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "lcy-seso",
        "created_at": "2018-03-06T06:26:38+00:00",
        "updated_at": "2018-03-06T06:46:29+00:00",
        "closed_at": "2018-03-06T06:46:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 693,
        "title": "Refine MobileNet SSD config and add mAP evaluator.",
        "body": "",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-03-07T11:51:55+00:00",
        "updated_at": "2018-03-07T11:57:33+00:00",
        "closed_at": "2018-03-07T11:57:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 687,
        "title": "Need convolutional sequence to sequence model",
        "body": "# Phases\r\n\r\n- [x] training task\r\n- [ ] effect tune\r\n- [ ] generate task\r\n\r\n# References\r\n- https://github.com/facebookresearch/fairseq-py",
        "state": "closed",
        "user": "Superjomn",
        "closed_by": "shanyi15",
        "created_at": "2018-03-06T06:57:23+00:00",
        "updated_at": "2018-08-15T09:56:07+00:00",
        "closed_at": "2018-08-15T09:56:07+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 691,
        "title": "Add RNN search model.",
        "body": "Add RNN search model (require multi-thread implementation) into https://github.com/PaddlePaddle/models/tree/develop/fluid/neural_machine_translation . Please use dataset.wmt16 as training and test dataset.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2018-03-07T03:41:03+00:00",
        "updated_at": "2018-08-15T09:56:03+00:00",
        "closed_at": "2018-08-15T09:56:03+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 697,
        "title": "Operators profiling in Transformer model.",
        "body": "### Operators profiling:\r\n\r\nRun 1 pass.\r\n\r\nGPU：TITAN X (Pascal, 12GB global memory)\r\n\r\n```\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: CUDA\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                            Calls       Total       Min.        Max.        Ave.\r\nthread0::mul_grad                43941       13300.3     0.171008    5.76614     0.302686\r\nthread0::layer_norm_grad         13590       12576.8     0.786432    58.5759     0.925442\r\nthread0::layer_norm              13590       9943.62     0.661504    0.884736    0.731687\r\nthread0::mul                     43941       6476.36     0.0768      3.70176     0.147388\r\nthread0::softmax                 453         3779.52     7.69248     9.76282     8.3433\r\nthread0::matmul_grad             16308       3431.95     0.145408    0.321536    0.210446\r\nthread0::elementwise_add_grad    33522       2000.51     0.004096    0.2816      0.0596776\r\nthread0::adam                    82899       1963.99     0.003072    0.421888    0.0236914\r\nthread0::sum                     22197       1780.81     0.01024     0.611328    0.0802277\r\nthread0::matmul                  16308       1413.82     0.034816    3.33517     0.0866951\r\nthread0::transpose               32616       1371.65     0.028672    2.69722     0.0420544\r\nthread0::transpose_grad          32616       1370.53     0.028672    0.070656    0.0420202\r\nthread0::elementwise_add         33522       1045.33     0.007168    24.4326     0.0311834\r\nthread0::dropout_grad            22650       644.103     0.009216    0.060416    0.0284372\r\nthread0::softmax_grad            453         611.858     0.900096    2.48218     1.35068\r\nthread0::dropout                 22650       600.103     0.006144    3.95059     0.0264946\r\nthread0::scale                   17214       395.886     0.003072    0.043008    0.0229979\r\nthread0::relu_grad               5436        355.256     0.04608     0.105472    0.0653524\r\nthread0::fill_zeros_like         49830       311.703     0.002048    0.026624    0.00625532\r\nthread0::elementwise_mul         83352       282.403     0.002976    0.048128    0.00338808\r\nthread0::relu                    5436        258.603     0.031744    10.8749     0.0475723\r\nthread0::elementwise_div_grad    8154        249.431     0.02048     0.062464    0.0305901\r\nthread0::reduce_sum_grad         8607        245.62      0.003072    0.070656    0.0285372\r\nthread0::lookup_table_grad       1812        191.795     0.043008    0.264192    0.105847\r\nthread0::reduce_sum              8607        136.825     0.004096    0.070656    0.015897\r\nthread0::exp_grad                8154        117.174     0.007168    0.043008    0.0143702\r\nthread0::elementwise_div         8154        96.2836     0.007168    0.046976    0.0118081\r\nthread0::cross_entropy_grad      453         86.9844     0.135168    0.362496    0.192019\r\nthread0::exp                     8154        76.608      0.004096    0.03072     0.00939514\r\nthread0::lookup_table            1812        73.7901     0.023552    0.106496    0.040723\r\nthread0::reshape                 33975       66.6537     0.001024    3.75808     0.00196184\r\nthread0::reshape_grad            33975       63.0589     0.001024    0.01536     0.00185604\r\nthread0::cross_entropy           453         2.26896     0.004096    0.013312    0.00500874\r\nthread0::elementwise_mul_grad    453         1.62397     0.003072    0.014336    0.00358492\r\n```\r\n\r\nCPU： Single thread\r\n\r\n```\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: CPU\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                            Calls       Total       Min.        Max.        Ave.\r\nthread0::mul_grad                43941       1.37484e+06 14.1704     934.205     31.2884\r\nthread0::transpose_grad          32616       1.02324e+06 20.8854     122.053     31.3724\r\nthread0::transpose               32616       1.0213e+06  20.8805     88.0507     31.3129\r\nthread0::mul                     43941       670698      7.00583     390.276     15.2636\r\nthread0::softmax                 453         462634      696.503     1808.74     1021.27\r\nthread0::layer_norm_grad         13590       375420      18.1468     95.6174     27.6247\r\nthread0::adam                    82899       318720      0.012018    177.504     3.84468\r\nthread0::layer_norm              13590       207723      10.2002     47.4344     15.285\r\nthread0::reduce_sum_grad         8607        205651      0.016318    131.23      23.8935\r\nthread0::softmax_grad            453         148503      222.244     589.22      327.821\r\nthread0::dropout                 22650       105028      1.1015      19.8472     4.637\r\nthread0::matmul_grad             16308       49075.7     1.43275     21.8065     3.0093\r\nthread0::elementwise_add         33522       34885.7     0.172053    33.2651     1.04068\r\nthread0::sum                     22197       33028.7     0.203313    22.527      1.48798\r\nthread0::elementwise_add_grad    33522       30067.1     0.109021    16.5107     0.896935\r\nthread0::relu_grad               5436        23078.8     2.31625     20.2764     4.24554\r\nthread0::dropout_grad            22650       20590.6     0.169235    8.56589     0.909077\r\nthread0::matmul                  16308       20140.8     0.559672    8.58716     1.23502\r\nthread0::elementwise_div_grad    8154        12677.3     0.598271    9.90769     1.55473\r\nthread0::fill_zeros_like         49830       12354.7     0.002088    9.29022     0.247938\r\nthread0::scale                   17214       11808.7     0.001299    5.37838     0.685996\r\nthread0::relu                    5436        7071.9      0.691306    14.388      1.30094\r\nthread0::lookup_table_grad       1812        5678.67     0.146436    21.6215     3.13392\r\nthread0::cross_entropy_grad      453         5495.68     5.93957     38.3655     12.1317\r\nthread0::reduce_sum              8607        5443.33     0.004744    4.33712     0.632431\r\nthread0::exp                     8154        3926.4      0.191484    3.60489     0.48153\r\nthread0::elementwise_div         8154        3443.53     0.1601      4.35008     0.422312\r\nthread0::exp_grad                8154        3120.79     0.124565    3.20178     0.382731\r\nthread0::lookup_table            1812        1550.32     0.497613    2.62074     0.855583\r\nthread0::elementwise_mul         83352       335.148     0.002086    0.041859    0.00402087\r\nthread0::reshape_grad            33975       308.679     0.003699    2.49831     0.00908548\r\nthread0::reshape                 33975       114.659     0.001462    2.63728     0.00337482\r\nthread0::cross_entropy           453         91.1172     0.110631    0.720848    0.201142\r\nthread0::elementwise_mul_grad    453         4.59584     0.007498    0.025791    0.0101453\r\n```",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2018-03-08T03:22:00+00:00",
        "updated_at": "2018-08-15T09:55:56+00:00",
        "closed_at": "2018-08-15T09:55:56+00:00",
        "comments_count": [
            "peterzhang2029",
            "peterzhang2029",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 696,
        "title": "Bad convergence when using momentum optimizer",
        "body": "The contrast training experiment shows the DeepASR model converges well when the Adam optimizer is used #676. But when changed to the momentum optimizer, the convergence turns out to be bad. There should be some problems in the implementation of the momentum optimizer in Fluid. \r\n\r\n\r\nHere is the comparsion of training accuracy on 4 GPUs between Fluid and Houyi with the same setting: \r\n\r\n![momentum_4_card](https://user-images.githubusercontent.com/3064195/37130152-322a47ec-22bd-11e8-8d3e-e2b74ad61d7f.png)\r\n\r\n\r\nParameters:\r\n\r\n```\r\nbatch_size: 128\r\ndevice: GPU\r\nhidden_dim: 1024\r\nlearning_rate: 0.00016\r\nminimum_batch_size: 1\r\nparallel: True\r\nproj_dim: 512\r\nstacked_num: 5\r\nmomentum: 0.9\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-03-08T02:41:43+00:00",
        "updated_at": "2018-08-15T09:55:59+00:00",
        "closed_at": "2018-08-15T09:55:59+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 698,
        "title": "text_classification model, 不支持paddle 0.10 ？报错",
        "body": "1. 安装了paddle 0.10 \r\n2. git 下载了models\r\n3. 运行text classification. 开始下载数据\r\n4. 报错\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 176, in <module>\r\n    main(args)\r\n  File \"train.py\", line 167, in main\r\n    model_save_dir=args.model_save_dir)\r\n  File \"train.py\", line 101, in train\r\n    paddle.init(use_gpu=False, trainer_count=1)\r\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/paddle/v2/__init__.py\", line 133, in init\r\n    set_omp_mkl_env_vars(kwargs.get('trainer_count', 1))\r\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/paddle/v2/__init__.py\", line 105, in set_omp_mkl_env_vars\r\n    num_cores = num_physical_cores()\r\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/paddle/v2/__init__.py\", line 86, in num_physical_cores\r\n    os.popen(\"lscpu |grep \\\"Socket\\\" |awk -F':' '{print $2}'|xargs\")\r\nValueError: invalid literal for int() with base 10: ''\r\n5. 什么都没改...直接git下来的代码就报的这个错",
        "state": "closed",
        "user": "VamWolf",
        "closed_by": "ranqiu92",
        "created_at": "2018-03-08T03:22:59+00:00",
        "updated_at": "2018-03-08T09:36:43+00:00",
        "closed_at": "2018-03-08T09:36:43+00:00",
        "comments_count": [
            "luotao1",
            "VamWolf",
            "ranqiu92"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 700,
        "title": "Transformer cost曲线",
        "body": "Fluid和Pytorch均使用如下的模型和训练参数（目前dropout_op有bug，这里暂时去掉dropout），并统一初始化方法，Transformer在WMT'16数据集上有如图的cost曲线对照图。\r\n\r\n```Python\r\n    # number of sequences contained in a mini-batch.\r\n    batch_size = 64\r\n    # the hyper params for Adam optimizer.\r\n    learning_rate = 0.001\r\n    beta1 = 0.9\r\n    beta2 = 0.98\r\n    eps = 1e-9\r\n    # the params for learning rate scheduling\r\n    warmup_steps = 4000\r\n\r\n    src_vocab_size=2909\r\n    trg_vocab_size=3149\r\n    # the dimension for word embeddings, which is also the last dimension of\r\n    # the input and output of multi-head attention, position-wise feed-forward\r\n    # networks, encoder and decoder.\r\n    d_model = 512\r\n    # size of the hidden layer in position-wise feed-forward networks.\r\n    d_inner_hid = 1024\r\n    # the dimension that keys are projected to for dot-product attention.\r\n    d_key = 64\r\n    # the dimension that values are projected to for dot-product attention.\r\n    d_value = 64\r\n    # number of head used in multi-head attention.\r\n    n_head = 8\r\n    # number of sub-layers to be stacked in the encoder and decoder.\r\n    n_layer = 6\r\n    # dropout rate used by all dropout layers.\r\n    dropout = 0.\r\n```\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/14105589/37189779-fb852cc8-2390-11e8-93fd-9f3b17557125.png)\r\n",
        "state": "closed",
        "user": "guoshengCS",
        "closed_by": "shanyi15",
        "created_at": "2018-03-09T04:06:30+00:00",
        "updated_at": "2018-08-15T09:55:49+00:00",
        "closed_at": "2018-08-15T09:55:49+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 699,
        "title": "请问这里的demo直接不能跑成功吗，alexnet跑flowers数据集，报错、不收敛",
        "body": "跑image_classification原汁原味的程序（单机cpu，PaddlePaddle 0.10.0，默认参数），python train.py alexnet （vgg13也是）\r\n![5e2f5e2f-9d86-4512-8738-b0f3faeae14a](https://user-images.githubusercontent.com/1950292/37137502-f160d4be-22e0-11e8-9c45-bec82e266b8a.JPG)\r\n\r\n1、看别的issue，这种情况貌似要添加bn；难道示例提供的demo程序和数据没有试验过吗\r\n2、添加bn，不报错但貌似还是不收敛\r\n![62b4e58e-10c2-4d8b-9782-3a3c271bde2f](https://user-images.githubusercontent.com/1950292/37137913-e5040752-22e2-11e8-82cd-79dde5950283.JPG)\r\n![ad488cb1-14e8-4e0e-a834-bd844a0de601](https://user-images.githubusercontent.com/1950292/37137920-ead184d4-22e2-11e8-985d-653b94297854.JPG)\r\n\r\n3、请问demo还需要做哪些改动；如果demo是好的，请问多少轮能收敛到什么程度（现在跑的不够？）",
        "state": "closed",
        "user": "Kayven",
        "closed_by": "shanyi15",
        "created_at": "2018-03-08T07:11:11+00:00",
        "updated_at": "2018-08-15T09:55:52+00:00",
        "closed_at": "2018-08-15T09:55:52+00:00",
        "comments_count": [
            "ranqiu92",
            "Kayven",
            "Kayven",
            "Kayven",
            "Kayven",
            "ranqiu92",
            "Kayven",
            "Kayven",
            "Kayven",
            "ranqiu92",
            "Kayven",
            "Kayven",
            "ranqiu92",
            "yeyupiaoling",
            "Kayven",
            "Kayven",
            "yeyupiaoling",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 705,
        "title": "We can improve the speed of DataReader for DeepASR model",
        "body": "Current implementation has much space to improve:\r\n1. Use process instead of thread for batch assembling task.\r\n2. Use process instead of thread for ordered data feeding task.\r\n3. In batch iterator, should avoid to sharing raw numpy array between processes.\r\n\r\n",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-03-11T13:47:57+00:00",
        "updated_at": "2018-03-13T08:19:27+00:00",
        "closed_at": "2018-03-13T08:19:27+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 702,
        "title": "SSD infer.py does not work on CPU",
        "body": "I tried to use CPU for inference of SSD , using pretrained model of SSD.\r\n\r\nso I modified  paddle init  from:\r\n_-    paddle.init(use_gpu=True, trainer_count=1)_                                                                  \r\nto:\r\n_+    paddle.init(use_gpu=False, trainer_count=1)_                \r\n\r\nInference crashed with an error:\r\n**Unknown pool type: cudnn-max-pool**\r\n\r\nCrash goes away when vgg_ssd_net.py got all instances of following line modified **from:**\r\n\r\n_-        pool_type=paddle.pooling.CudnnMax(),_                                                                         \r\n\r\n**to:**\r\n_+        pool_type=paddle.pooling.Max(),_         \r\n\r\n",
        "state": "closed",
        "user": "jczaja",
        "closed_by": "shanyi15",
        "created_at": "2018-03-09T11:59:06+00:00",
        "updated_at": "2018-08-15T09:55:46+00:00",
        "closed_at": "2018-08-15T09:55:46+00:00",
        "comments_count": [
            "peterzhang2029",
            "jczaja",
            "peterzhang2029",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 706,
        "title": "Translation Plan- Deep Factorization Machine for Click-Through Rate prediction-英译汉",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“Deep Factorization Machine for Click-Through Rate prediction”**英译汉**，对应的英文名字为 基于深度因子分解机的点击率预估模型，请勿改动\r\n2. 地址\r\n- 英文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/deep_fm/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/deep_fm/README.html)\r\n- 需要翻译的中文地址，暂无，可在英文版github下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:14:44+00:00",
        "updated_at": "2018-06-01T07:52:00+00:00",
        "closed_at": "2018-06-01T07:52:00+00:00",
        "comments_count": [],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 703,
        "title": "在Fluid版本下，图像分类dome中的一些疑问",
        "body": "比如下面这几行代码，有什么用，在非Fluid版本中，没有见过类似的\r\nhttps://github.com/PaddlePaddle/models/blob/df8060e7022fcac12fd33a8adf098c0663d8152d/fluid/image_classification/mobilenet.py#L175-L185\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/df8060e7022fcac12fd33a8adf098c0663d8152d/fluid/image_classification/mobilenet.py#L168\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/df8060e7022fcac12fd33a8adf098c0663d8152d/fluid/image_classification/mobilenet.py#L194\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/df8060e7022fcac12fd33a8adf098c0663d8152d/fluid/image_classification/mobilenet.py#L201\r\n\r\n是否能解答以上几行代码的作用",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-03-09T12:30:48+00:00",
        "updated_at": "2018-03-12T04:54:55+00:00",
        "closed_at": "2018-03-12T04:54:55+00:00",
        "comments_count": [
            "yeyupiaoling",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 707,
        "title": "Translation Plan-Globally Normalized Reader-英译汉",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“Globally Normalized Reader”**英译汉**\r\n\r\n2. 地址\r\n- 英文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/globally_normalized_reader/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/globally_normalized_reader/README.html)\r\n- 需要翻译的中文地址，暂无，可在英文版github下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:16:54+00:00",
        "updated_at": "2018-03-21T02:53:29+00:00",
        "closed_at": "2018-03-21T02:53:29+00:00",
        "comments_count": [],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 710,
        "title": "Translation Plan-基于双层序列的文本分类-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“基于双层序列的文本分类”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/nested_sequence/text_classification/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/nested_sequence/text_classification/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建英文版md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:20:10+00:00",
        "updated_at": "2018-06-04T03:17:35+00:00",
        "closed_at": "2018-06-04T03:17:35+00:00",
        "comments_count": [],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 708,
        "title": "Translation Plan-Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering-英译汉",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering”**英译汉**，中文名为“基于序列标注的事实型自动问答模型”，请勿改动\r\n\r\n2. 地址\r\n- 英文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/neural_qa/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/neural_qa/README.html)\r\n- 需要翻译的中文地址，暂无，可在英文版github下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:18:01+00:00",
        "updated_at": "2018-08-15T09:55:42+00:00",
        "closed_at": "2018-08-15T09:55:42+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 714,
        "title": "Translation Plan-中国古诗生成-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“中国古诗生成”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/generate_chinese_poetry/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/generate_chinese_poetry/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:23:54+00:00",
        "updated_at": "2018-06-01T07:19:37+00:00",
        "closed_at": "2018-06-01T07:19:37+00:00",
        "comments_count": [],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 709,
        "title": "Translation Plan-DeepSpeech2 on PaddlePaddle-英译汉",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“DeepSpeech2 on PaddlePaddle”**英译汉**，中文名为“语音识别: DeepSpeech2”，请勿改动\r\n\r\n2. 地址\r\n- 英文地址： [Github地址](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/README.md)，网页地址暂无\r\n- 需要翻译的中文地址，暂无，可在英文版github下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:18:59+00:00",
        "updated_at": "2018-03-20T04:05:35+00:00",
        "closed_at": "2018-03-13T02:05:35+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 711,
        "title": "Translation Plan-命名实体识别-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“命名实体识别”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/sequence_tagging_for_ner/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/sequence_tagging_for_ner/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建英文版md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:21:00+00:00",
        "updated_at": "2018-08-15T09:55:38+00:00",
        "closed_at": "2018-08-15T09:55:38+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 712,
        "title": "Translation Plan-Scheduled Sampling-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“Scheduled Sampling”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/scheduled_sampling/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/scheduled_sampling/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:21:43+00:00",
        "updated_at": "2018-06-01T07:16:57+00:00",
        "closed_at": "2018-06-01T07:16:57+00:00",
        "comments_count": [
            "vienous"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 713,
        "title": "Translation Plan-带外部记忆机制的神经机器翻译-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“带外部记忆机制的神经机器翻译”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/mt_with_external_memory/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/mt_with_external_memory/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:22:53+00:00",
        "updated_at": "2018-08-15T09:55:35+00:00",
        "closed_at": "2018-08-15T09:55:35+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 715,
        "title": "Translation Plan-场景文字识别-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“场景文字识别”**汉译英**，对应英文名为Scene Text Recognition\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/tree/develop/scene_text_recognition)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/scene_text_recognition/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:26:14+00:00",
        "updated_at": "2018-08-15T10:07:06+00:00",
        "closed_at": "2018-08-15T10:07:06+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 716,
        "title": "Translation Plan-排序学习-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“排序学习”**汉译英**，对应英文名为Learning To Rank\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/ltr/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/ltr/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "dzhwinter",
        "created_at": "2018-03-12T00:27:04+00:00",
        "updated_at": "2018-05-31T06:20:04+00:00",
        "closed_at": "2018-05-31T06:20:04+00:00",
        "comments_count": [],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 717,
        "title": "Translation Plan-文本分类-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“文本分类”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/text_classification/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/text_classification/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:31:35+00:00",
        "updated_at": "2018-08-15T10:07:00+00:00",
        "closed_at": "2018-08-15T10:07:00+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 718,
        "title": "Translation Plan-使用循环神经网语言模型生成文本-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“使用循环神经网语言模型生成文本”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/generate_sequence_by_rnn_lm/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/generate_sequence_by_rnn_lm/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:32:52+00:00",
        "updated_at": "2018-08-15T10:06:56+00:00",
        "closed_at": "2018-08-15T10:06:56+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 725,
        "title": "Can not resume single device's training from the checkpoint of ParallelDo",
        "body": "Error complaint:\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ncheckpoints:\r\ndevice: GPU\r\nhidden_dim: 1024\r\ninfer_models:\r\ninit_model_path: ../deep_asr_models/pass.7.ckpt\r\nlearning_rate: 0.00016\r\nmean_var: data/global_mean_var_search26kHr\r\nminimum_batch_size: 1\r\nparallel: False\r\npass_num: 100\r\nprint_per_batches: 10\r\nproj_dim: 512\r\nstacked_num: 5\r\ntrain_feature_lst: data/local_feature.lst\r\ntrain_label_lst: data/local_label.lst\r\nval_feature_lst: data/val_feature.lst\r\nval_label_lst: data/val_label.lst\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 265, in <module>\r\n    train(args)\r\n  File \"train.py\", line 223, in train\r\n    return_numpy=False)\r\n  File \"/home/disk1/liuyibing/envs/paddle_dev_latest/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 292, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: enforce param_dims == ctx->GetInputDim(\"Moment1\") failed, 512, 4096 != 512\r\nParam and Moment1 input of AdamOp should have same dimension at [/home/disk1/liuyibing/paddle_work/Paddle/paddle/fluid/operators/adam_op.cc:63]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f3c064b0916p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f3c06a2ac60p paddle::operators::AdamOp::InferShape(paddle::framework::InferShapeContext*) const + 2368\r\n2       0x7f3c06eac968p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 88\r\n3       0x7f3c065379bep paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 1214\r\n4       0x7f3c064c43cbp void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 555\r\n5       0x7f3c064bde1ap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2602\r\n6       0x7f3c54ebb3d4p PyEval_EvalFrameEx + 25956\r\n7       0x7f3c54ebc120p PyEval_EvalCodeEx + 2240\r\n8       0x7f3c54eba491p PyEval_EvalFrameEx + 22049\r\n9       0x7f3c54ebc120p PyEval_EvalCodeEx + 2240\r\n10      0x7f3c54eba491p PyEval_EvalFrameEx + 22049\r\n11      0x7f3c54ebc120p PyEval_EvalCodeEx + 2240\r\n12      0x7f3c54ebc232p PyEval_EvalCode + 50\r\n13      0x7f3c54ed661cp\r\n14      0x7f3c54ed66f0p PyRun_FileExFlags + 144\r\n15      0x7f3c54ed7bfcp PyRun_SimpleFileExFlags + 220\r\n16      0x7f3c54ee94bcp Py_Main + 3164\r\n17        0x318ae1ecddp __libc_start_main + 253\r\n18            0x400659p\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "reyoung",
        "created_at": "2018-03-13T03:09:32+00:00",
        "updated_at": "2018-03-15T04:31:33+00:00",
        "closed_at": "2018-03-15T04:31:33+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 720,
        "title": "Translation Plan-Hsigmoid加速词向量训练-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把Hsigmoid加速词向量训练”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/hsigmoid/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/hsigmoid/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:34:42+00:00",
        "updated_at": "2018-08-15T10:06:49+00:00",
        "closed_at": "2018-08-15T10:06:49+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 719,
        "title": "Translation Plan-使用噪声对比估计加速语言模型训练-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“使用噪声对比估计加速语言模型训练”**汉译英**\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/nce_cost/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/nce_cost/README.html)\r\n- 需要翻译的英文地址，暂无，可在中文版所在github目录下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-12T00:33:42+00:00",
        "updated_at": "2018-08-15T10:06:53+00:00",
        "closed_at": "2018-08-15T10:06:53+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 723,
        "title": "Translation Plan-models简介-汉译英",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“models简介”**汉译英**，英文为“Introduction to models”，请勿改动\r\n\r\n2. 地址\r\n- 中文地址： [Github地址](https://github.com/PaddlePaddle/models/blob/develop/README.cn.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/README.cn.html)\r\n- 需要翻译的英文地址， [Github地址](https://github.com/PaddlePaddle/models/blob/develop/README.md)，[网页地址](http://www.paddlepaddle.org/docs/develop/models/README.html)\r\n\r\n目前，英文版已有内容，但需要更新。\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-13T02:11:39+00:00",
        "updated_at": "2018-08-15T10:06:46+00:00",
        "closed_at": "2018-08-15T10:06:46+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "translation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 724,
        "title": "Can not save inference model in multi-GPU mode",
        "body": "Error complaint:\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ncheckpoints: ./checkpoints\r\ndevice: GPU\r\nhidden_dim: 1024\r\ninfer_models: ./infer_models\r\ninit_model_path: None\r\nlearning_rate: 0.002\r\nmean_var: data/global_mean_var_search26kHr\r\nminimum_batch_size: 1\r\nparallel: True\r\npass_num: 100\r\nprint_per_batches: 100\r\nproj_dim: 512\r\nstacked_num: 5\r\ntrain_feature_lst: data/feature.lst\r\ntrain_label_lst: data/label.lst\r\nval_feature_lst: data/val_feature.lst\r\nval_label_lst: data/val_label.lst\r\n------------------------------------------------\r\n..................................................................Traceback (most recent call last):\r\n  File \"train.py\", line 265, in <module>\r\n    train(args)\r\n  File \"train.py\", line 252, in train\r\n    [prediction], exe)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/fluid/io.py\", line 342, in save_inference_model\r\n    prepend_feed_ops(inference_program, feeded_var_names)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/fluid/io.py\", line 272, in prepend_feed_ops\r\n    out = global_block.var(name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/fluid/framework.py\", line 708, in var\r\n    raise ValueError(\"var %s not in this block\" % name)\r\nValueError: var feature not in this block\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-03-13T03:01:30+00:00",
        "updated_at": "2018-08-15T10:06:42+00:00",
        "closed_at": "2018-08-15T10:06:42+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 731,
        "title": "Add script for inference by using checkpoint",
        "body": "Due to #724",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-13T09:46:44+00:00",
        "updated_at": "2018-03-14T06:46:03+00:00",
        "closed_at": "2018-03-14T06:46:03+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 728,
        "title": "Add RNN Search Model for neural machine translation.",
        "body": "Reference source code: https://github.com/dzhwinter/benchmark/blob/master/fluid/machine_translation.py ",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2018-03-13T08:59:48+00:00",
        "updated_at": "2018-08-15T10:06:30+00:00",
        "closed_at": "2018-08-15T10:06:30+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 732,
        "title": "多线程batch包含特定数目样本时程序崩溃的问题",
        "body": "我遇到的一个比较奇怪的bug。使用\r\nbranch:jzy2   models/fluid/sequence_tagging_for_ner/train.py进行模型的训练时，\r\n使用conll03的训练集进行训练。\r\n我在设置batch_size为200时并不会报错，全程正常训练。但是如果我设置batch_size=35时，就会出现下面的错误。\r\n```\r\nF0313 07:55:52.990689 19937 threadpool.h:96] The exception is thrown inside the thread pool. You should use RunAndGetException to handle the exception.\r\nThe default exception handler is LOG(FATAL).enforce numel() > 0 failed, 0 <= 0\r\nWhen calling this method, the Tensor's numel must be larger than zero. Please check Tensor::Resize has been called first. at [/paddle/Paddle/paddle/fluid/framework/tensor_impl.h:123]\r\nPaddlePaddle Call Stacks: \r\n0       0x7feff9cc19acp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572\r\n1       0x7feff9cc7851p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::type_index) + 1233\r\n2       0x7feff9d9c9a0p paddle::framework::Vector<long>::resize(unsigned long) + 496\r\n3       0x7feffa066b46p paddle::operators::LookupTableGradKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 1190\r\n4       0x7feffa40fac4p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 1588\r\n5       0x7feffa40d418p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 72\r\n6       0x7feff9d6395ap paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 1482\r\n7       0x7feffa2b7aa3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > >, std::__future_base::_Result_base::_Deleter>, std::_Bind_simple<std::reference_wrapper<std::future<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > > paddle::framework::ThreadPool::RunAndGetException<paddle::operators::ParallelDoGradOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1}>(paddle::operators::ParallelDoGradOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1})::{lambda()#1}> ()>, std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<paddle::platform::EnforceNotMet> > > >::_M_invoke(std::_Any_data const&) + 99\r\n8       0x7feffa2b480ep std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*) + 46\r\n9       0x7ff045249a99p\r\n10      0x7feffa2b4e52p std::__future_base::_State_baseV2::_M_set_result(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>, bool) + 146\r\n11      0x7feffa2b4fc6p std::__future_base::_Task_state<std::future<std::unique_ptr<paddle::platform::EnforceNotMet, std::default_delete<std::unique_ptr> > > paddle::framework::ThreadPool::RunAndGetException<paddle::operators::ParallelDoGradOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1}>(paddle::operators::ParallelDoGradOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const::{lambda()#1})::{lambda()#1}, std::allocator<int>, std::default_delete<std::unique_ptr> ()>::_M_run() + 86\r\n12      0x7feffa425064p paddle::framework::ThreadPool::TaskLoop() + 1012\r\n13      0x7ff038025c80p\r\n14      0x7ff0452426bap\r\n15      0x7ff044f7841dp clone + 109\r\n*** Check failure stack trace: ***\r\n    @     0x7feffa53bf0d  google::LogMessage::Fail()\r\n    @     0x7feffa53e258  google::LogMessage::SendToLog()\r\n    @     0x7feffa53ba1b  google::LogMessage::Flush()\r\n    @     0x7feffa53f12e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7feffa2b59c7  std::_Function_handler<>::_M_invoke()\r\n    @     0x7feffa2b480e  std::__future_base::_State_baseV2::_M_do_set()\r\n    @     0x7ff045249a99  __pthread_once_slow\r\n    @     0x7feffa2b4e52  std::__future_base::_State_baseV2::_M_set_result()\r\n    @     0x7feffa2b4f11  std::__future_base::_Deferred_state<>::_M_complete_async()\r\n    @     0x7feffa2be33a  paddle::operators::ParallelDoGradOp::RunImpl()\r\n    @     0x7feffa40d418  paddle::framework::OperatorBase::Run()\r\n    @     0x7feff9d6395a  paddle::framework::Executor::Run()\r\n    @     0x7feff9cdf253  _ZZN8pybind1112cpp_function10initializeIZNS0_C4IvN6paddle9framework8ExecutorEIRKNS4_11ProgramDescEPNS4_5ScopeEibbEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vISO_S8_SA_ibbEISB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_\r\n    @     0x7feff9cdbdc4  pybind11::cpp_function::dispatcher()\r\n    @           0x4c37ed  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4eb30f  (unknown)\r\n    @           0x4e5422  PyRun_FileExFlags\r\n    @           0x4e3cd6  PyRun_SimpleFileExFlags\r\n    @           0x493ae2  Py_Main\r\n    @     0x7ff044e91830  __libc_start_main\r\n    @           0x4933e9  _start\r\n    @              (nil)  (unknown)\r\nAborted\r\n```\r\n事实上，不仅是BATCH_SIZE=35时会报错，BATCH_SIZE=50也会报错，这是因为训练样本数%50=35，所以最后一个batch会包含35个样本。另外BATCH_SIZE=34也会报错。\r\n因为样本在使用时会做shuffle，所以这不会是特定样本造成的。看上面提到的错误，是线程池出了问题，具体原因还请相关同学进行追查。追查时可以通过将原始的data/train文件复制多份合成一个大的训练集的方式，同样可以复现上述问题。",
        "state": "closed",
        "user": "jshower",
        "closed_by": "dzhwinter",
        "created_at": "2018-03-13T13:04:14+00:00",
        "updated_at": "2018-03-22T07:15:03+00:00",
        "closed_at": "2018-03-22T07:15:03+00:00",
        "comments_count": [
            "jacquesqiao",
            "dzhwinter",
            "jshower",
            "jshower"
        ],
        "labels": [
            "bug",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 739,
        "title": "Add model average option for OCR CTC model",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-03-18T15:13:03+00:00",
        "updated_at": "2018-03-27T04:53:27+00:00",
        "closed_at": "2018-03-27T04:53:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 735,
        "title": "Add pybind11 wrapper for decoder",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-14T10:05:43+00:00",
        "updated_at": "2018-03-17T07:49:58+00:00",
        "closed_at": "2018-03-17T07:49:58+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 737,
        "title": "Current status of model training",
        "body": "We are training the DeepASR model on the whole training dataset with duration 2000h. After 12 epoches' training, the model has well converged already.  \r\n\r\nSettings:\r\n```\r\nbatch_size: 128\r\ndevice: GPU\r\nhidden_dim: 1024\r\nlearning_rate: 0.00016\r\nminimum_batch_size: 1\r\nproj_dim: 512\r\nstacked_num: 5\r\noptimizer: Adam\r\n```\r\n\r\nEnv: 4 P40 GPUs, 15h per epoch.\r\n\r\n![training_acc_on_all_data](https://user-images.githubusercontent.com/3064195/37443696-9dc6fb18-2848-11e8-9af7-81a3b2cff568.png)\r\n\r\nAfter the decoder is ready, we will continue to fine tune this model to catch up with the performance in accuracy of benchmark.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-03-15T04:01:45+00:00",
        "updated_at": "2018-08-15T09:55:30+00:00",
        "closed_at": "2018-08-15T09:55:30+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 738,
        "title": "文本分类示例问题",
        "body": "按照 http://www.paddlepaddle.org/docs/develop/models/text_classification/README.html 中的自定义数据格式组织样本数据，中文切分成字符，然后指定test_data_dir参数，跑模型得出如下输出，\r\n\r\n[INFO 2018-03-15 10:03:03,443 train.py:81] class number is : 2.\r\n[INFO 2018-03-15 10:03:03,444 train.py:101] length of word dictionary is : 197.\r\nI0315 10:03:03.702831   214 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nI0315 10:03:03.768990   214 GradientMachine.cpp:94] Initing parameters..\r\nI0315 10:03:03.780875   214 GradientMachine.cpp:101] Init parameters done.\r\n[INFO 2018-03-15 10:03:05,168 train.py:134] Pass 0, Batch 0, Cost 0.723217, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.71875}\r\n\r\n[INFO 2018-03-15 10:03:20,437 train.py:134] Pass 0, Batch 100, Cost 0.002880, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:03:35,861 train.py:134] Pass 0, Batch 200, Cost 0.000867, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:03:51,160 train.py:134] Pass 0, Batch 300, Cost 0.000377, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:04:05,879 train.py:134] Pass 0, Batch 400, Cost 0.000256, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:04:20,718 train.py:134] Pass 0, Batch 500, Cost 0.000153, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:04:36,332 train.py:134] Pass 0, Batch 600, Cost 0.000151, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:04:51,897 train.py:134] Pass 0, Batch 700, Cost 0.000118, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:05:07,207 train.py:134] Pass 0, Batch 800, Cost 0.000073, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n[INFO 2018-03-15 10:05:21,856 train.py:134] Pass 0, Batch 900, Cost 0.000046, {'__auc_evaluator_0__': 0.0, 'classification_error_evaluator': 0.0}\r\n\r\n接下里都是的这两个参数都是0,直到cost也到达0.\r\n请问是原因是？看了其他issue，数据已经平衡，且直接用的text_classificationdemo代码，label数据已经是integer_value格式。",
        "state": "closed",
        "user": "tyabs",
        "closed_by": "tyabs",
        "created_at": "2018-03-15T12:15:35+00:00",
        "updated_at": "2018-03-15T12:47:30+00:00",
        "closed_at": "2018-03-15T12:47:30+00:00",
        "comments_count": [
            "tyabs"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 733,
        "title": "图片分类各batch的错误率差距极大",
        "body": "使用image_classification中alexnet做2分类，在demo的基础上做了如下改动：1）自己的样本，量较少，不到3000，且样本未打乱但保留了shuffle；2）调整学习率至0.0001（0.001训练会失败）。\r\n\r\n出现错误率稳定在某几个batch特别低，其他batch的错误率很高，且多个pass后仍然是这种情况，请问有可能是什么问题呢？\r\npass1的部分日志：\r\n![default](https://user-images.githubusercontent.com/36145868/37385595-8aef191c-278f-11e8-9802-66f3e0f15e4b.png)\r\npass75的部分日志：\r\n![default](https://user-images.githubusercontent.com/36145868/37385624-a1552660-278f-11e8-9685-78ec12ab8e73.png)\r\n\r\n",
        "state": "closed",
        "user": "yuanghbdbj",
        "closed_by": "shanyi15",
        "created_at": "2018-03-14T06:01:18+00:00",
        "updated_at": "2018-08-15T10:06:27+00:00",
        "closed_at": "2018-08-15T10:06:27+00:00",
        "comments_count": [
            "yuanghbdbj",
            "yeyupiaoling",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 747,
        "title": "Parallel training for MobileNet-SSD.",
        "body": "",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-03-21T03:06:05+00:00",
        "updated_at": "2018-03-21T05:12:08+00:00",
        "closed_at": "2018-03-21T05:12:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 743,
        "title": "\"relu\" or \"sigmoid\" should be added to the end of fc layer",
        "body": "I did a test, and found there's is a minor flaw in the code. https://github.com/PaddlePaddle/models/blob/develop/fluid/neural_machine_translation/transformer/model.py#L169, Add \"relu\" function might be better.",
        "state": "closed",
        "user": "gmcather",
        "closed_by": "shanyi15",
        "created_at": "2018-03-20T08:37:30+00:00",
        "updated_at": "2018-08-15T09:55:26+00:00",
        "closed_at": "2018-08-15T09:55:26+00:00",
        "comments_count": [
            "guoshengCS",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 752,
        "title": "Add decoder for deep asr model",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-21T14:49:38+00:00",
        "updated_at": "2018-03-27T02:59:26+00:00",
        "closed_at": "2018-03-27T02:59:26+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 759,
        "title": "Add memory optimization and se-resnext50 into se_resnext.py",
        "body": "",
        "state": "closed",
        "user": "BigFishMaster",
        "closed_by": "qingqing01",
        "created_at": "2018-03-22T17:50:20+00:00",
        "updated_at": "2018-03-27T09:48:25+00:00",
        "closed_at": "2018-03-27T09:48:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 768,
        "title": "Bug fix for async reader of DeepASR",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-03-26T06:21:46+00:00",
        "updated_at": "2018-03-26T06:37:23+00:00",
        "closed_at": "2018-03-26T06:37:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 771,
        "title": "Cannot find fetch variable in scope",
        "body": "In inference\r\n```\r\nTraceback (most recent call last):\r\n  File \"infer_by_ckpt.py\", line 180, in <module>\r\n    infer_from_ckpt(args)\r\n  File \"infer_by_ckpt.py\", line 165, in infer_from_ckpt\r\n    return_numpy=False)\r\n  File \"/home/baidu/liuyibing/paddle_envs/latest/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 373, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetch variable in scope, fetch_var_name is fc_5.tmp_2 at [/home/baidu/liuyibing/paddle_work/Paddle_tmp/paddle/fluid/operators/fetch_op.cc:40]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f1defb0b037p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 727\r\n1       0x7f1defe93205p paddle::operators::FetchOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 1573\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-26T08:25:48+00:00",
        "updated_at": "2018-03-27T02:41:35+00:00",
        "closed_at": "2018-03-27T02:41:35+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 757,
        "title": "Profiling for RNN Search model for multi-gpu.",
        "body": "| pass_id |single-gpu | two-gpu | three-gpu | four-gpu |\r\n| - | - | - | - | - |\r\n|0|207.810512|193.126689| 153.078007 | 131.083838 |\r\n|1|212.449378|191.684570| 151.617278 | 129.824058 |\r\n|2|209.937869|190.296914| 151.363250 | 129.944818 |\r\n|3|200.752512|196.673491|151.120727 | 130.697326 |\r\n|4|201.428616|193.513692| 155.460599 | 131.675840 |\r\n|avg:|206.4757774|193.0590712|152.5279722| 130.645176|\r\n\r\nGPU: TITAN X (Pascal)\r\n\r\npaddlepaddle commit id: cb3bbbd5c6690943d9ac14849e4f6eca7b3ba3bf",
        "state": "closed",
        "user": "peterzhang2029",
        "closed_by": "shanyi15",
        "created_at": "2018-03-22T04:31:13+00:00",
        "updated_at": "2018-08-15T09:55:23+00:00",
        "closed_at": "2018-08-15T09:55:23+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 775,
        "title": "Make buffer queues be AsyncReader's objects",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "kuke",
        "created_at": "2018-03-27T06:36:19+00:00",
        "updated_at": "2018-03-27T09:05:25+00:00",
        "closed_at": "2018-03-27T09:05:25+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 764,
        "title": "能否完善fluid下的OCR的文档",
        "body": "在这个OCR例子中：https://github.com/PaddlePaddle/models/tree/develop/fluid/ocr_recognition\r\n文档较少，能否完善一下文档，比如说说每个文件的作用。",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-03-25T15:10:14+00:00",
        "updated_at": "2018-04-09T14:05:30+00:00",
        "closed_at": "2018-04-09T14:05:30+00:00",
        "comments_count": [
            "shanyi15",
            "yeyupiaoling",
            "shanyi15",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 770,
        "title": "conv_seq2seq运行出错",
        "body": "down下程序和数据后，使用CPU机器运行，传入use_gpu=fasle，无修改运行出错：F0326 14:03:18.974588 25452 Matrix.cpp:3112] Check failed: index[i] < (int)tableSize (25628 vs. 22825) ，麻烦看下什么问题，多谢~",
        "state": "closed",
        "user": "fmantianxing",
        "closed_by": "shanyi15",
        "created_at": "2018-03-26T07:44:34+00:00",
        "updated_at": "2018-08-15T09:55:20+00:00",
        "closed_at": "2018-08-15T09:55:20+00:00",
        "comments_count": [
            "ranqiu92",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 777,
        "title": "SSD model changing CLASS_NUM leads error",
        "body": "No matter in PC or PaddleCloud, when I change the CLASS_NUM for the SSD model other than 21（class num of VOC dataset) and use my own dataset, the training cannot run and always occur the similar error:\r\n\r\nThread [0x7fffb74d33c0] Forwarding detection_output, \r\n*** Aborted at 1522136207 (unix time) try \"date -d @1522136207\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7fffae6f360a) received by PID 96282 (TID 0x7fffb74d33c0) stack trace: ***\r\n    @     0x7fffae7c6b3a _sigtramp\r\nFloating point exception: 8\r\n\r\nGuess something wrong in paddle.layer.detection_output().",
        "state": "closed",
        "user": "bipedalBit",
        "closed_by": "bipedalBit",
        "created_at": "2018-03-27T08:04:06+00:00",
        "updated_at": "2018-04-04T02:21:55+00:00",
        "closed_at": "2018-04-04T02:21:55+00:00",
        "comments_count": [
            "wanghaoshuang",
            "bipedalBit",
            "pkuyym",
            "bipedalBit",
            "bipedalBit",
            "pkuyym",
            "bipedalBit",
            "pkuyym",
            "bipedalBit"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 781,
        "title": "Add decoder init & verify output",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-27T12:52:07+00:00",
        "updated_at": "2018-03-30T02:21:24+00:00",
        "closed_at": "2018-03-30T02:21:24+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 778,
        "title": "如何通过mkl_set_num_threads设置mkl线程数？",
        "body": "线上多线程预测遇到QPS问题，已通过设置环境变量MKL_NUM_THREADS、OMP_NUM_THREADS解决。查阅issue发现还可以通过mkl库提供的API mkl_set_num_threads实现。请问该API应如何调用？",
        "state": "closed",
        "user": "Sunny-Dr",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-03-27T09:17:05+00:00",
        "updated_at": "2018-03-27T09:55:06+00:00",
        "closed_at": "2018-03-27T09:55:06+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "Sunny-Dr"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 782,
        "title": "Data reader fails after several iterations ",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 280, in <module>\r\n    train(args)\r\n  File \"train.py\", line 221, in train\r\n    args.minimum_batch_size)):\r\n  File \"/home/disk1/liuyibing/paddle_work/models_aishell/fluid/DeepASR/data_utils/async_data_reader.py\", line 422, in batch_iterator\r\n    3, self._manager)\r\n  File \"/home/disk1/liuyibing/paddle_work/models_aishell/fluid/DeepASR/data_utils/util.py\", line 168, in __init__\r\n    self._dict[name] = SharedNDArray(name)\r\n  File \"<string>\", line 2, in __setitem__\r\n  File \"/home/work/.jumbo/lib/python2.7/multiprocessing/managers.py\", line 773, in _callmethod\r\n    raise convert_to_error(kind, result)\r\nmultiprocessing.managers.RemoteError: \r\n---------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/work/.jumbo/lib/python2.7/multiprocessing/managers.py\", line 240, in serve_client\r\n    request = recv()\r\n  File \"/home/disk1/liuyibing/paddle_work/models_aishell/fluid/DeepASR/data_utils/util.py\", line 144, in __setstate__\r\n    self.zeros_like(state[1], state[2])\r\n  File \"/home/disk1/liuyibing/paddle_work/models_aishell/fluid/DeepASR/data_utils/util.py\", line 110, in zeros_like\r\n    self._name, posix_ipc.O_CREAT, size=size)\r\nOSError: This process already has the maximum number of files open\r\n---------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/work/.jumbo/lib/python2.7/multiprocessing/util.py\", line 261, in _run_finalizers\r\n  File \"/home/work/.jumbo/lib/python2.7/multiprocessing/util.py\", line 200, in __call__\r\n  File \"/home/work/.jumbo/lib/python2.7/shutil.py\", line 237, in rmtree\r\n  File \"/home/work/.jumbo/lib/python2.7/shutil.py\", line 235, in rmtree\r\nOSError: [Errno 24] Too many open files: '/tmp/pymp-KdbIU1'\r\n \r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "pkuyym",
        "created_at": "2018-03-27T14:02:18+00:00",
        "updated_at": "2018-03-29T10:14:09+00:00",
        "closed_at": "2018-03-29T10:14:09+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 790,
        "title": "Revert data reader for DeepASR",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-03-29T09:27:58+00:00",
        "updated_at": "2018-03-29T10:14:09+00:00",
        "closed_at": "2018-03-29T10:14:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 787,
        "title": "image_classification mobilenet.py training halfway throw exception",
        "body": "exception:\r\n```\r\nPass 0, batch 150, loss 4.19872951508, acc 0.0500000007451\r\nPass 0, batch 151, loss 4.3166437149, acc 0.0750000029802\r\nPass 0, batch 152, loss 4.25785493851, acc 0.10000000149\r\nPass 0, batch 153, loss 4.23684549332, acc 0.0689655169845\r\nTraceback (most recent call last):\r\n  File \"mobilenet.py\", line 224, in <module>\r\n    train(learning_rate=0.005, batch_size=40, num_passes=300)\r\n  File \"mobilenet.py\", line 212, in train\r\n    fetch_list=[avg_cost, b_acc_var, b_size_var])\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 349, in run\r\n    self.executor.run(program_cache.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetch variable in scope, fetch_var_name is mean_0.tmp_0 at [/paddle/paddle/fluid/operators/fetch_op.cc:36]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f67888c8026p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f6788d530c9p paddle::operators::FetchOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 2105\r\n2       0x7f67893d5788p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 88\r\n3       0x7f67889582aep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 1086\r\n4       0x7f67889592d0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 64\r\n5       0x7f67888dd37bp void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 555\r\n6       0x7f67888d6dd4p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n7             0x4c37edp PyEval_EvalFrameEx + 31165\r\n8             0x4b9ab6p PyEval_EvalCodeEx + 774\r\n9             0x4c16e7p PyEval_EvalFrameEx + 22711\r\n10            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n11            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n12            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n13            0x4eb30fp\r\n14            0x4e5422p PyRun_FileExFlags + 130\r\n15            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n16            0x493ae2p Py_Main + 1554\r\n17      0x7f67d9988830p __libc_start_main + 240\r\n18            0x4933e9p _start + 41\r\n```\r\nenv: docker\r\npaddlepadle version: lastest-gpu\r\n",
        "state": "closed",
        "user": "seiriosPlus",
        "closed_by": "shanyi15",
        "created_at": "2018-03-28T14:14:02+00:00",
        "updated_at": "2018-08-15T09:55:13+00:00",
        "closed_at": "2018-08-15T09:55:13+00:00",
        "comments_count": [
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 793,
        "title": "Expose acoustic scale in decoder",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-03-29T13:05:33+00:00",
        "updated_at": "2018-04-04T03:05:19+00:00",
        "closed_at": "2018-04-04T03:05:19+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 785,
        "title": "image_classification mobilenet.py get exception",
        "body": "Exception is:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/reader/decorator.py\", line 274, in handle_worker\r\n    r = mapper(sample)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/dataset/flowers.py\", line 63, in default_mapper\r\n    img = load_image_bytes(img)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/image.py\", line 131, in load_image_bytes\r\n    img = cv2.imdecode(file_bytes, flag)\r\nAttributeError: 'NoneType' object has no attribute 'imdecode'\r\n```\r\n\r\nenv: docker\r\npaddlepaddle: latest-gpu",
        "state": "closed",
        "user": "seiriosPlus",
        "closed_by": "seiriosPlus",
        "created_at": "2018-03-28T12:50:35+00:00",
        "updated_at": "2018-03-28T13:06:30+00:00",
        "closed_at": "2018-03-28T13:06:30+00:00",
        "comments_count": [
            "seiriosPlus",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 786,
        "title": "Debug nan for transformer",
        "body": "warmup_steps:\r\n\r\ndataset: WMT16\r\n\r\n| warmup steps | passed steps before NAN | \r\n| - | - |\r\n| 1 | 2 |\r\n| 10 | 7 |\r\n| 100 | 494 |\r\n| 1000 | 751 |\r\n| 10000 | - |",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "shanyi15",
        "created_at": "2018-03-28T13:12:22+00:00",
        "updated_at": "2018-08-15T09:55:16+00:00",
        "closed_at": "2018-08-15T09:55:16+00:00",
        "comments_count": [
            "pkuyym",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 800,
        "title": "`models/fluid/neural_machine_translation/transformer/train.py` doesn't work well.",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 190, in <module>\r\n    main()\r\n  File \"train.py\", line 175, in main\r\n    use_program_cache=True)\r\n  File \"/paddle/python/paddle/fluid/executor.py\", line 373, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: enforce ids_dims.size() == 2 failed, 1 != 2\r\n at [/paddle/paddle/fluid/operators/lookup_table_op.cc:43]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f4db200c89cp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572\r\n1       0x7f4db288db05p paddle::operators::LookupTableOp::InferShape(paddle::framework::InferShapeContext*) const + 1493\r\n2       0x7f4db2d9fb95p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 2213\r\n```",
        "state": "closed",
        "user": "gongweibao",
        "closed_by": "gongweibao",
        "created_at": "2018-04-02T03:41:36+00:00",
        "updated_at": "2018-04-02T07:39:37+00:00",
        "closed_at": "2018-04-02T07:39:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 797,
        "title": "policy_gradient 原理介绍部分内容格式存在问题",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/fluid/policy_gradient \r\npolicy_gradient  demo介绍部分，看起来格式存在问题，能辛苦调整下吗？或者以什么样的方式可以看到原始的文档呢？ @wanghaoshuang  @lcy-seso ",
        "state": "closed",
        "user": "leanna62",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-04-01T12:33:28+00:00",
        "updated_at": "2018-04-04T01:21:27+00:00",
        "closed_at": "2018-04-04T01:21:27+00:00",
        "comments_count": [
            "wanghaoshuang",
            "leanna62",
            "leanna62",
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 806,
        "title": "Doc discussion.",
        "body": "The basic document specification is as follows, but not limited to.\r\nThe doc of  DeepSpeech (https://github.com/paddlepaddle/deepspeech) is a good reference.\r\nThe following is just an example. Each model can adjust flexibly.\r\n\r\n\r\n---\r\nAt first, declare the version of Paddle. For example:\r\n\r\nThe minimum PaddlePaddle version needed for the code sample in this directory is v0.10.0. If you are on a version of PaddlePaddle earlier than v0.10.0, [please update your installation](http://www.paddlepaddle.org/docs/develop/documentation/en/build_and_install/pip_install_en.html).\r\n\r\n## Introduction\r\nThe introduction of model structure.  But not limited to.\r\n\r\n## Data Preparation\r\nIf download data automatically,  skip this part.\r\n\r\n## Training a Model\r\n### Data Augmentation Pipeline\r\nDescribe the data augmentation pipeline, but not limited to.\r\nBetter have the convergent curve\r\n\r\n## Evaluation\r\nHow to test model.\r\n## Inference and Visualization\r\nHow to do inference by Python API.\r\nBetter to visualize the results.\r\n## Finetuning\r\nHow to load a model to fine-tune.\r\n## Released Models\r\n  Need the URL of Released Models\r\n",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "shanyi15",
        "created_at": "2018-04-03T02:59:58+00:00",
        "updated_at": "2018-08-15T09:55:09+00:00",
        "closed_at": "2018-08-15T09:55:09+00:00",
        "comments_count": [
            "chengduoZH",
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 812,
        "title": "time delay operator",
        "body": "",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "shanyi15",
        "created_at": "2018-04-05T05:27:05+00:00",
        "updated_at": "2018-08-15T09:55:05+00:00",
        "closed_at": "2018-08-15T09:55:05+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 835,
        "title": "Add error rate measuring script",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-12T02:23:29+00:00",
        "updated_at": "2018-04-19T01:23:07+00:00",
        "closed_at": "2018-04-19T01:23:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 818,
        "title": "models/ltr/EADME.md   文档中的公式排版有问题",
        "body": "如题，应该是[readme](https://github.com/PaddlePaddle/models/tree/develop/ltr)中的md格式出问题了，开源文档上的demo应该很多人都会参考，这种格式问题给别人的感觉会很不好，可以修改一下。",
        "state": "closed",
        "user": "shenchong721",
        "closed_by": "shanyi15",
        "created_at": "2018-04-08T12:52:59+00:00",
        "updated_at": "2018-08-15T09:54:56+00:00",
        "closed_at": "2018-08-15T09:54:56+00:00",
        "comments_count": [
            "shanyi15",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 826,
        "title": "Update the parameter initialization of FC layer of SE-ResNeXt and add a README",
        "body": "The default parameter initialization method will influence  top-1 accuracy in ImageNet2012 classification by 1%. I resolve the problem by updating to new initialization method.",
        "state": "closed",
        "user": "BigFishMaster",
        "closed_by": "qingqing01",
        "created_at": "2018-04-10T07:30:43+00:00",
        "updated_at": "2018-04-28T03:02:14+00:00",
        "closed_at": "2018-04-28T03:02:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 817,
        "title": "跑了下ltr model的例子， ranknet的网络收敛，可是lambda rank的网络从loss看根本不收敛",
        "body": "最近在考虑ltr model的使用，尤其是listwise的方式。\r\n试了下paddle提供ranknet和lambda_rank两个模型(没做任何修改)，发现lambda_rank方式下cost并没有表现出减小的趋势，完全是无规律震荡的(如下图)。 于是又跑了下ranknet的模型，发现结果是收敛的。\r\n请教下，pairwise和listwise的方式，理论上效果上是几乎相等的，但为何在训练结果上的差别如此大？是因为部分超参并没有选好么？\r\n辛苦相关同学解答下。\r\n![image](https://user-images.githubusercontent.com/7055728/38467415-cfa3f96c-3b6a-11e8-9779-29956ef4ba2f.png)\r\n",
        "state": "closed",
        "user": "everal",
        "closed_by": "shanyi15",
        "created_at": "2018-04-08T12:22:35+00:00",
        "updated_at": "2018-08-15T09:55:00+00:00",
        "closed_at": "2018-08-15T09:55:00+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 823,
        "title": "image_classification 中是否提供imagenet上训练的v2.fliud接口的模型参数？",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/image_classification/models/model_download.sh\r\n这里只提供了 v2接口的 Vgg16，ResNet50，ResNet101。\r\n是否提供v2接口的其他模型？\r\n是否提供v2.fliud接口的模型？",
        "state": "closed",
        "user": "liuhuiCNN",
        "closed_by": "shanyi15",
        "created_at": "2018-04-09T16:39:39+00:00",
        "updated_at": "2018-08-15T10:06:21+00:00",
        "closed_at": "2018-08-15T10:06:21+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 830,
        "title": "youtube_recall 维度输入",
        "body": "",
        "state": "closed",
        "user": "gucasbrg",
        "closed_by": "shanyi15",
        "created_at": "2018-04-11T08:00:57+00:00",
        "updated_at": "2018-08-15T10:06:17+00:00",
        "closed_at": "2018-08-15T10:06:17+00:00",
        "comments_count": [
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 836,
        "title": "Experiments of OCR CTC on parallel executor",
        "body": "|ID| batch_size | GPUs | max_average_window|  average_window|time_per_pass| state|\r\n|---|---|---|---|---|---|---|\r\n|1 | 32 | 4 | 15000| 0.15|1,735.663s|running|\r\n|2 | 32 | 1 | 15000| 0.15|1,747.921s|running|\r\n|3 | 128 | 4 | 3750| 0.04|||\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/7534971/38653618-3569edda-3e3e-11e8-9029-5820b5f8855a.png)\r\n\r\nDetails: https://docs.google.com/spreadsheets/d/13FTzN55CS8K8jvd2jyBI__PjGuuwBT3l6f4INLCTyRs/edit?usp=sharing\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-04-12T02:36:24+00:00",
        "updated_at": "2018-05-03T02:53:02+00:00",
        "closed_at": "2018-05-03T02:53:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 842,
        "title": "Finish Fluid doc for MobileNet-v1 SSD.",
        "body": "- [x] Add eval.py  @qingqing01\r\n- [x] Add infer.py\r\n- [x] Visualize the predicted results.\r\n- [x] Released the model.  @qingqing01",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-04-13T09:51:56+00:00",
        "updated_at": "2018-06-19T14:40:47+00:00",
        "closed_at": "2018-06-19T14:40:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 843,
        "title": "Fix comments in OCR CTC model doc.",
        "body": "Fix some comments left over by pr #798 ",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-04-13T10:19:39+00:00",
        "updated_at": "2018-05-03T02:53:36+00:00",
        "closed_at": "2018-05-03T02:53:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 837,
        "title": "Configure OCR Attention model.",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "shanyi15",
        "created_at": "2018-04-12T03:02:53+00:00",
        "updated_at": "2018-08-15T10:06:11+00:00",
        "closed_at": "2018-08-15T10:06:11+00:00",
        "comments_count": [
            "shiwenguo",
            "shiwenguo",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 853,
        "title": "Add eval.py for MobileNet-SSD.",
        "body": "We need to tell users how to evaluate the test data.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-04-16T03:26:35+00:00",
        "updated_at": "2018-04-18T00:43:50+00:00",
        "closed_at": "2018-04-18T00:43:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 854,
        "title": "lstmp remove fc bias",
        "body": "https://github.com/PaddlePaddle/models/blob/03a0ae1dbfa837bc419d1773c09f6a0316b00732/fluid/DeepASR/model_utils/model.py#L53",
        "state": "closed",
        "user": "zhxfl",
        "closed_by": "zhxfl",
        "created_at": "2018-04-16T04:48:56+00:00",
        "updated_at": "2018-04-16T05:26:18+00:00",
        "closed_at": "2018-04-16T05:26:18+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 860,
        "title": "Add the aishell example & release data",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-16T16:41:16+00:00",
        "updated_at": "2018-04-17T05:26:22+00:00",
        "closed_at": "2018-04-17T05:26:22+00:00",
        "comments_count": [],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 855,
        "title": "Debug diff of convolution layer in OCR CTC model",
        "body": "## 背景\r\n用paddle fluid API实现的网络和用paddle V1 API实现的网络，在训练过程中，不能严格对齐。\r\n\r\n取一张图片做实验，batch_size为1，只执行一个pass(一次forward计算+一次backward计算)，对比V1 API和fluid API：\r\n forward结果一致；backward在第二个conv层出现diff，即第二个conv层计算出的input_grad不一致。\r\n\r\n取一张图片做实验，batch_size为1，只执行一个pass(一次forward计算+一次backward计算)；用fluid API实验两次，对比两次结果：\r\nGPU: forward一致; backward在第二个conv层出现diff，即第二个conv层计算出的input_grad不一致。\r\nCPU: forward和backward都一致\r\n\r\n## Debug\r\n\r\n### fluid GPU VS GPU\r\n\r\n从上述实验中抽出第二个conv层的`input data`,  `filter parameter`和`output grad`, 单独执行`conv_grad`。并对执行两次conv_grad的结果`input grad`统计对比，结果如下：\r\n```\r\nthrehold: 100; count: 0\r\nthrehold: 10.0; count: 0\r\nthrehold: 1.0; count: 0\r\nthrehold: 0.1; count: 0\r\nthrehold: 0.01; count: 0\r\nthrehold: 0.001; count: 0\r\nthrehold: 0.0001; count: 0\r\nthrehold: 1e-05; count: 0\r\nthrehold: 1e-06; count: 0\r\nthrehold: 1e-07; count: 0\r\nthrehold: 1e-08; count: 0\r\nthrehold: 1e-09; count: 0\r\nthrehold: 1e-10; count: 33 // 1e-11< diff < 1e-10\r\nthrehold: 1e-11; count: 507\r\nthrehold: 1e-12; count: 549\r\nthrehold: 1e-13; count: 737\r\nthrehold: 1e-14; count: 360\r\nthrehold: 1e-15; count: 132\r\nthrehold: 1e-16; count: 445\r\nthrehold: 1e-17; count: 0\r\n```\r\n上述结果表示diff在1e-11和1e-10之间的元素数量为33，以此类推。\r\n并将diff在1e-11和1e-10之间的元素打印如下：\r\n```\r\n-1.88291e-06 VS -1.8829e-06\r\n-1.48766e-06 VS -1.48767e-06\r\n-1.44663e-06 VS -1.44662e-06\r\n1.07083e-06 VS 1.07084e-06\r\n-2.38668e-06 VS -2.38669e-06\r\n6.31052e-06 VS 6.31053e-06\r\n1.62304e-06 VS 1.62303e-06\r\n1.41462e-06 VS 1.41461e-06\r\n-1.12677e-06 VS -1.12678e-06\r\n-1.15945e-06 VS -1.15944e-06\r\n-1.25673e-06 VS -1.25674e-06\r\n-2.85901e-06 VS -2.85902e-06\r\n-1.42249e-06 VS -1.42248e-06\r\n-1.829e-06 VS -1.82899e-06\r\n-1.22958e-06 VS -1.22959e-06\r\n-1.94547e-06 VS -1.94548e-06\r\n1.8461e-06 VS 1.84611e-06\r\n-1.34486e-06 VS -1.34487e-06\r\n1.80192e-06 VS 1.80193e-06\r\n2.2543e-06 VS 2.25429e-06\r\n-2.06272e-06 VS -2.06273e-06\r\n-1.89758e-06 VS -1.89759e-06\r\n1.39698e-06 VS 1.39699e-06\r\n-1.5601e-06 VS -1.56011e-06\r\n-1.00525e-06 VS -1.00524e-06\r\n1.06274e-06 VS 1.06273e-06\r\n1.0087e-06 VS 1.00871e-06\r\n-3.63364e-06 VS -3.63363e-06\r\n-3.16802e-06 VS -3.16801e-06\r\n1.57705e-06 VS 1.57706e-06\r\n5.08058e-06 VS 5.08057e-06\r\n1.71452e-06 VS 1.71453e-06\r\n-3.4769e-06 VS -3.47689e-06\r\n```\r\n\r\n### fluid CPU VS CPU\r\nCPU跑两次实验，无diff\r\n\r\n### fluid GPU VS CPU\r\n\r\n```\r\nthrehold: 100; count: 0\r\nthrehold: 10.0; count: 0\r\nthrehold: 1.0; count: 0\r\nthrehold: 0.1; count: 0\r\nthrehold: 0.01; count: 0\r\nthrehold: 0.001; count: 0\r\nthrehold: 0.0001; count: 0\r\nthrehold: 1e-05; count: 0\r\nthrehold: 1e-06; count: 0\r\nthrehold: 1e-07; count: 0\r\nthrehold: 1e-08; count: 0\r\nthrehold: 1e-09; count: 0\r\nthrehold: 1e-10; count: 82\r\nthrehold: 1e-11; count: 1216\r\nthrehold: 1e-12; count: 1307\r\nthrehold: 1e-13; count: 1554\r\nthrehold: 1e-14; count: 920\r\nthrehold: 1e-15; count: 338\r\nthrehold: 1e-16; count: 1058\r\nthrehold: 1e-17; count: 0\r\n```\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "qingqing01",
        "created_at": "2018-04-16T07:01:08+00:00",
        "updated_at": "2018-07-27T08:18:22+00:00",
        "closed_at": "2018-07-27T08:18:22+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 865,
        "title": "相同测试集，使用infer预测准确率与evaluator评估准确率差距较大",
        "body": "在使用paddle-v2版本时，遇到一个问题。\r\n描述下问题：基于nested_sequence/text_classification 的双序列文本分类模型。相同一批测试数据集，在模型训练时，最后一轮的评估结果'classification_error_evaluator': 0.0109，但使用训练好的模型，使用infer接口去预测该批测试数据时，准确率只有79%，比模型训练时的评估结果低了很多。\r\n想请教下，这种情况是怎么造成的呢？该如何排查原因呢",
        "state": "closed",
        "user": "liaibao120",
        "closed_by": "shanyi15",
        "created_at": "2018-04-17T14:49:11+00:00",
        "updated_at": "2018-08-15T10:06:07+00:00",
        "closed_at": "2018-08-15T10:06:07+00:00",
        "comments_count": [
            "jacquesqiao",
            "liaibao120",
            "liaibao120",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 867,
        "title": "ctr wide & deep模型中，readme.cn.md和network_conf.py中代码不一致",
        "body": "nerwork_conf.py中是这个，\r\n```\r\nself.lr_merged_input = layer.data(\r\n            name='lr_input',\r\n            type=paddle.data_type.sparse_float_vector(self.lr_input_dim))\r\n```\r\n\r\nreadme.cn.md中是这个，\r\n```\r\nlr_merged_input = layer.data(\r\n    name='lr_input',\r\n    type=paddle.data_type.sparse_binary_vector(data_meta_info['lr_input']))\r\n```\r\n\r\n而sparse_float_vector这个接口貌似mpi上paddle版本并不支持",
        "state": "closed",
        "user": "macomzzl",
        "closed_by": "shanyi15",
        "created_at": "2018-04-19T09:04:26+00:00",
        "updated_at": "2018-08-15T10:10:40+00:00",
        "closed_at": "2018-08-15T10:10:40+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 870,
        "title": "SSD 模型参数调优问题",
        "body": "![image](https://user-images.githubusercontent.com/13493253/39109634-497fb79e-4700-11e8-9593-c37eabfb4c5b.png)\r\n\r\n我的训练集图片是1280*720 的图片，然后我设置了图片大小为这个，然后就不停的包内存不足。\r\n然后我调整 batch_size 为1 ，可以运行但是跑到第1个 Pass 就报这个错误。",
        "state": "closed",
        "user": "HUSTGOC",
        "closed_by": "shanyi15",
        "created_at": "2018-04-23T06:13:33+00:00",
        "updated_at": "2018-08-15T09:54:51+00:00",
        "closed_at": "2018-08-15T09:54:51+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 871,
        "title": "SSD 模型训练过程中 test mAP提示并不准确",
        "body": " RT，通过设置 ssd 模型 pic size 为300 * 300  训练1280*720 的图片，然后通过400多轮的迭代训练，test 的 mAP稳定在95左右。\r\n\r\n然后我从训练的时候的测试集合随机挑选了5张图片进行验证，发现很多识别错误和漏识别，正确率只有50%左右。\r\n\r\n难道是我哪里做错了？",
        "state": "closed",
        "user": "HUSTGOC",
        "closed_by": "shanyi15",
        "created_at": "2018-04-23T06:16:10+00:00",
        "updated_at": "2018-08-15T09:54:47+00:00",
        "closed_at": "2018-08-15T09:54:47+00:00",
        "comments_count": [
            "HUSTGOC",
            "Yancey0623",
            "HUSTGOC",
            "Yancey0623",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 872,
        "title": "caffe转paddle的模型，请支持ROI Pooling",
        "body": "",
        "state": "closed",
        "user": "dyning",
        "closed_by": "shanyi15",
        "created_at": "2018-04-24T07:20:48+00:00",
        "updated_at": "2018-08-15T09:54:43+00:00",
        "closed_at": "2018-08-15T09:54:43+00:00",
        "comments_count": [
            "dyning",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 882,
        "title": "Enable the parallel training of mobilenet",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-26T04:13:48+00:00",
        "updated_at": "2018-04-26T04:20:33+00:00",
        "closed_at": "2018-04-26T04:20:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 875,
        "title": "caffe2fluid: support Reshape transformation",
        "body": "currently, Reshape layer cann't be converted to fluid, we need to support this",
        "state": "closed",
        "user": "walloollaw",
        "closed_by": "walloollaw",
        "created_at": "2018-04-24T09:02:12+00:00",
        "updated_at": "2018-04-26T09:49:56+00:00",
        "closed_at": "2018-04-26T09:49:56+00:00",
        "comments_count": [
            "walloollaw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 877,
        "title": "caffe2fluid:failed to do global pool layer convertion",
        "body": "when try to convert a caffe model with global pooling:\r\n```\r\nTraceback (most recent call last):\r\n  File \"../../convert.py\", line 80, in <module>\r\n    ret = main()\r\n  File \"../../convert.py\", line 76, in main\r\n    args.code_output_path, args.phase)\r\n  File \"../../convert.py\", line 35, in convert\r\n    transformer = Transformer(def_path, caffemodel_path, phase=phase)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py\", line 273, in __init__\r\n    self.load(def_path, data_path, phase)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py\", line 279, in load\r\n    graph = GraphBuilder(def_path, phase).build()\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/graph.py\", line 285, in build\r\n    graph.compute_output_shapes()\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/graph.py\", line 116, in compute_output_shapes\r\n    *NodeKind.compute_output_shape(node))\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/layers.py\", line 138, in compute_output_shape\r\n    val = LAYER_DESCRIPTORS[node.kind](node)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/shapes.py\", line 104, in shape_pool\r\n    return get_strided_kernel_output_shape(node, method)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/shapes.py\", line 38, in get_strided_kernel_output_shape\r\n    node.layer.kernel_parameters, round_func)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/layers.py\", line 213, in kernel_parameters\r\n    k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\r\n  File \"/home/vis/wanglong03/paddle_gits/models.git.wallo/fluid/image_classification/caffe2fluid/kaffe/layers.py\", line 206, in get_kernel_value\r\n    raise ValueError('Unable to determine kernel parameter!')\r\nValueError: Unable to determine kernel parameter!\r\n```",
        "state": "closed",
        "user": "walloollaw",
        "closed_by": "walloollaw",
        "created_at": "2018-04-25T07:58:50+00:00",
        "updated_at": "2018-04-26T02:45:17+00:00",
        "closed_at": "2018-04-26T02:45:17+00:00",
        "comments_count": [
            "walloollaw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 883,
        "title": "models/deep_fm",
        "body": "这个实现没有加dropout吧？\r\n\r\n没有加dropout，也可以跑到这个实验结果？（After training pass 9 batch 40000, the testing AUC is 0.807178 and the testing cost is 0.445196.）\r\n\r\n我试验的时候，没有dropout的时候，deepfm=fm",
        "state": "closed",
        "user": "yufengwhy",
        "closed_by": "kuke",
        "created_at": "2018-04-27T03:06:08+00:00",
        "updated_at": "2018-05-02T03:48:37+00:00",
        "closed_at": "2018-05-02T03:48:37+00:00",
        "comments_count": [
            "kuke",
            "yufengwhy",
            "kuke",
            "yufengwhy",
            "yufengwhy",
            "kuke"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 884,
        "title": "Check failed: ptr Fail to allocate GPU memory 1024 bytes",
        "body": "[INFO 2018-04-27 12:22:45,641 layers.py:2829] output for __pool_3__: c = 128, h = 11, w = 3, size = 4224\r\nF0427 12:22:45.654973 29609 Allocator.h:89] Check failed: ptr Fail to allocate GPU memory 1024 bytes\r\n*** Check failure stack trace: ***\r\n    @     0x7fc6072639cd  google::LogMessage::Fail()\r\n    @     0x7fc60726747c  google::LogMessage::SendToLog()\r\n    @     0x7fc6072634f3  google::LogMessage::Flush()\r\n    @     0x7fc60726898e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc60719912e  paddle::GpuAllocator::alloc()\r\n    @     0x7fc60718075f  paddle::PoolAllocator::alloc()\r\n    @     0x7fc60718016f  paddle::GpuMemoryHandle::GpuMemoryHandle()\r\n    @     0x7fc60719320e  paddle::GpuVectorT<>::GpuVectorT()\r\n    @     0x7fc6071933c8  paddle::VectorT<>::create()\r\n    @     0x7fc607193479  paddle::VectorT<>::createParallelVector()\r\n    @     0x7fc60701a526  paddle::Parameter::enableType()\r\n    @     0x7fc607015ccc  paddle::parameterInitNN()\r\n    @     0x7fc60701853e  paddle::NeuralNetwork::init()\r\n    @     0x7fc60704132f  paddle::GradientMachine::create()\r\n    @     0x7fc607240575  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7fc60724075f  GradientMachine::createByConfigProtoStr()\r\n    @     0x7fc606ecfbb7  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4c30ce  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d55f3  (unknown)\r\n    @           0x4eebee  (unknown)\r\n    @           0x4ee7f6  (unknown)\r\n    @           0x4aa9ab  (unknown)\r\n    @           0x4c15bf  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d55f3  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n    @           0x4bed3d  PyEval_EvalFrameEx\r\n\r\nAborted (core dumped)\r\n我的是系统是ubuntu 16.04.两块4G的N卡，怎么会报GPU 的错误，我是用scene_text_recognition例子的代码跑的\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro K2200        Off  | 00000000:01:00.0  On |                  N/A |\r\n| 42%   40C    P8     1W /  39W |    132MiB /  4040MiB |      4%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Quadro K2200        Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 42%   34C    P8     1W /  39W |      1MiB /  4043MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1057      G   /usr/lib/xorg/Xorg                           131MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n",
        "state": "closed",
        "user": "ecit241",
        "closed_by": "shanyi15",
        "created_at": "2018-04-27T04:28:34+00:00",
        "updated_at": "2018-08-15T09:54:36+00:00",
        "closed_at": "2018-08-15T09:54:36+00:00",
        "comments_count": [
            "ecit241",
            "kuke",
            "ecit241",
            "kuke",
            "ecit241",
            "kuke",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 887,
        "title": "Refine the document of image classification under fluid",
        "body": "the README document needs to be refined for further use.",
        "state": "closed",
        "user": "BigFishMaster",
        "closed_by": "shanyi15",
        "created_at": "2018-04-28T03:05:30+00:00",
        "updated_at": "2018-08-15T09:54:33+00:00",
        "closed_at": "2018-08-15T09:54:33+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 890,
        "title": "尝试应用weight layer报错",
        "body": "我尝试通过给样本赋予不同的重要性，通过\r\n`cost = paddle.layer.classification_cost(input=prob, label=lbl, weight=wei)`\r\n这里的wei定义为：\r\n`wei = paddle.layer.data(\"weight\", paddle.data_type.integer_value(1))`\r\n运行的时候会报下面的信息\r\nThread [139955584042752] Forwarding __cost_0__,\r\n不知道是出了什么问题\r\n\r\n具体的报错信息如下：\r\n[INFO 2018-05-01 09:01:54,403 train_conv_weighted.py:86] class number is : 3444.\r\n[INFO 2018-05-01 09:01:54,403 train_conv_weighted.py:106] length of word dictionary is : 599999.\r\nI0501 09:01:54.456384 16026 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1 \r\nI0501 09:01:55.129230 16026 GradientMachine.cpp:94] Initing parameters..\r\nI0501 09:02:06.899636 16026 GradientMachine.cpp:101] Init parameters done.\r\nThread [139955584042752] Forwarding __cost_0__, \r\n*** Aborted at 1525136527 (unix time) try \"date -d @1525136527\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x8) received by PID 16026 (TID 0x7f49f2df0700) from PID 8; stack trace: ***\r\n    @     0x7f49f25a7160 (unknown)\r\n    @     0x7f49b8f5bafb paddle::BaseMatrixT<>::dotMul()\r\n    @     0x7f49b8d40a3c paddle::CostLayer::forward()\r\n    @     0x7f49b8d80f4d paddle::NeuralNetwork::forward()\r\n    @     0x7f49b8d81c63 paddle::GradientMachine::forwardBackward()\r\n    @     0x7f49b9052a04 GradientMachine::forwardBackward()\r\n    @     0x7f49b8c1e689 _wrap_GradientMachine_forwardBackward\r\n    @     0x7f49f28c079f PyEval_EvalFrameEx\r\n    @     0x7f49f28c40bd PyEval_EvalCodeEx\r\n    @     0x7f49f28c1345 PyEval_EvalFrameEx\r\n    @     0x7f49f28c40bd PyEval_EvalCodeEx\r\n    @     0x7f49f28c1345 PyEval_EvalFrameEx\r\n    @     0x7f49f28c40bd PyEval_EvalCodeEx\r\n    @     0x7f49f28c1345 PyEval_EvalFrameEx\r\n    @     0x7f49f28c40bd PyEval_EvalCodeEx\r\n    @     0x7f49f28c1345 PyEval_EvalFrameEx\r\n    @     0x7f49f28c1460 PyEval_EvalFrameEx\r\n    @     0x7f49f28c40bd PyEval_EvalCodeEx\r\n    @     0x7f49f28c41f2 PyEval_EvalCode\r\n    @     0x7f49f28ecf42 PyRun_FileExFlags\r\n    @     0x7f49f28ee2d9 PyRun_SimpleFileExFlags\r\n    @     0x7f49f290400d Py_Main\r\n    @     0x7f49f1b01bd5 __libc_start_main\r\n    @           0x4007a1 (unknown)\r\n    @                0x0 (unknown)",
        "state": "closed",
        "user": "snowsteper",
        "closed_by": "shanyi15",
        "created_at": "2018-05-01T01:12:12+00:00",
        "updated_at": "2018-08-15T09:54:28+00:00",
        "closed_at": "2018-08-15T09:54:28+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 891,
        "title": "OCR Q3",
        "body": "## OCR端到端 \r\n\r\n### 1. east检测 (8周)\r\n目标： 对齐baseline\r\n上线模型training数据集：100W级别\r\n\r\n#### 1.0 编译环境 @wanghaoshuang\r\n#### 1.1 所需op\r\n\r\n- p0: dice-loss  （2周*1人）@wanghaoshuang\r\n- p1: 多边形的非最大抑制 (2周*1人)  @ocr\r\n- p2: IoU loss （2周*1人）@ocr\r\n- p3: Cos loss  （2周*1人）@wanghaoshuang\r\n\r\n\r\n#### 1.2 模型配置 （1周 * 1人）@ocr\r\n\r\n#### 1.3 data reader （1周 * 1人）@ocr\r\n\r\n#### 1.4 效果验证 （4周 * 2人）@ocr + @wanghaoshuang\r\n\r\n- benchmark training 效果对齐(icdar15)\r\n- 预测库效果对齐（caffe）\r\n\r\n### 2. 识别\r\n\r\n#### 2.1 CTC（done）\r\n\r\n#### 2.2 Attention （4周 * 1人）@shiwenguo + @wanghaoshuang\r\n\r\n- 1d attention效果验证\r\n- 2d attention效果验证\r\n\r\n\r\n### 3. 融合 (east检测 + CTC)\r\n\r\n#### 3.1 所需ops\r\n\r\n-  roi_perspective op\r\n\r\n#### 3.2 代码框架整合\r\n\r\n#### 3.3 合并DataReader\r\n\r\n\r\n\r\nTODO:\r\n- 确认tensorflow&caffe model转fluid model \r\n- 确认具体人力\r\n- 是否可开源\r\n- 确定east检测分支开发环境 \r\n\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "shanyi15",
        "created_at": "2018-05-02T11:34:17+00:00",
        "updated_at": "2018-08-15T09:54:25+00:00",
        "closed_at": "2018-08-15T09:54:25+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 893,
        "title": "sequence slice",
        "body": "请问一个序列长度N，维度为M，需要从中挑出指定序列位置（跟具体样本没关系，预先知道）的一些元素，维度不切片，怎么操作最简单？看了v2的api seq_slice sub_nested_seq都需要给出索引，这些索引不能是预定义好的python List，必须是paddle.v2.config_base.Layer，如果需要从reader的generator给出的话，应该怎么提供？用dense_vector不work,要用dense_array？",
        "state": "closed",
        "user": "yttbgf",
        "closed_by": "shanyi15",
        "created_at": "2018-05-07T11:48:28+00:00",
        "updated_at": "2018-08-15T09:54:17+00:00",
        "closed_at": "2018-08-15T09:54:17+00:00",
        "comments_count": [
            "qingqing01",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 892,
        "title": "math的script没渲染出来",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/nce_cost\r\n\r\n![46a825589b5b0c5aa416dac110ab7196](https://user-images.githubusercontent.com/24290262/39660929-d7b8f668-507b-11e8-9375-2535d8e8a708.JPG)\r\n",
        "state": "closed",
        "user": "shboy",
        "closed_by": "shanyi15",
        "created_at": "2018-05-05T07:50:17+00:00",
        "updated_at": "2018-08-15T09:54:20+00:00",
        "closed_at": "2018-08-15T09:54:20+00:00",
        "comments_count": [
            "dzhwinter",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 895,
        "title": "ctc+wfst解码",
        "body": "请问一下，有没有ctc+wfst解码的代码借鉴一下，谢谢\r\n",
        "state": "closed",
        "user": "tao-githup",
        "closed_by": "shanyi15",
        "created_at": "2018-05-08T10:07:59+00:00",
        "updated_at": "2018-08-15T09:54:13+00:00",
        "closed_at": "2018-08-15T09:54:13+00:00",
        "comments_count": [
            "bolt163",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 896,
        "title": "caffe2fluid can't generate fluid model from caffe",
        "body": "1. Install protobuf pip: $pip install protobuf\r\n2. Prepare caffepb.py: $ cd [root]/fluid/image_classification/caffe2fluid/proto && wget https://github.com/ethereon/caffe-tensorflow/raw/master/kaffe/caffe/caffepb.py\r\n3. Run convert.py: $ cd [root]/fluid/image_classification/caffe2fluid &&  python convert.py alexnet.prototxt --caffemodel alexnet.caffemodel --data-output-path alexnet.npy --code-output-path alexnet.py\r\n\r\nError message:\r\n\r\nregister layer[Axpy]\r\nregister layer[Flatten]\r\nregister layer[ArgMax]\r\nregister layer[Reshape]\r\nTraceback (most recent call last):\r\n  File \"convert.py\", line 80, in <module>\r\n    ret = main()\r\n  File \"convert.py\", line 76, in main\r\n    args.code_output_path, args.phase)\r\n  File \"convert.py\", line 35, in convert\r\n    transformer = Transformer(def_path, caffemodel_path, phase=phase)\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py\", line 287, in __init__\r\n    self.load(def_path, data_path, phase)\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py\", line 293, in load\r\n    graph = GraphBuilder(def_path, phase).build()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/graph.py\", line 167, in __init__\r\n    self.load()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/graph.py\", line 171, in load\r\n    self.params = get_caffe_resolver().NetParameter()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py\", line 43, in get_caffe_resolver\r\n    SHARED_CAFFE_RESOLVER = CaffeResolver()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py\", line 18, in __init__\r\n    self.import_caffe()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py\", line 28, in import_caffe\r\n    self.caffepb = import_caffepb()\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py\", line 12, in import_caffepb\r\n    import caffepb\r\n  File \"/work/models/fluid/image_classification/caffe2fluid/kaffe/caffe/../../proto/caffepb.py\", line 28, in <module>\r\n    type=None),\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/descriptor.py\", line 654, in __new__\r\n    _message.Message._CheckCalledFromGeneratedFile()\r\nTypeError: Descriptors should not be created directly, but only retrieved from their parent.\r\n",
        "state": "closed",
        "user": "sabreshao",
        "closed_by": "shanyi15",
        "created_at": "2018-05-09T08:07:38+00:00",
        "updated_at": "2018-08-15T09:54:09+00:00",
        "closed_at": "2018-08-15T09:54:09+00:00",
        "comments_count": [
            "qingqing01",
            "walloollaw",
            "sabreshao",
            "walloollaw",
            "sabreshao",
            "walloollaw",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 897,
        "title": "CRNN-CTC cannot download file data.tar.gz",
        "body": "### Problem description\r\nI cannot download CRNN-CTC dataset https://github.com/PaddlePaddle/models/blob/develop/fluid/ocr_recognition/ctc_reader.py#L14.\r\n Sever resets connection. I already retried on different networks and machines with the same result. Can you upload the file somewhere else? What is this file? Can I find it elsewhere?\r\n\r\n### Command run\r\n`python ctc_train.py`\r\n### Output\r\n```\r\nλ 2b5c263aa3a5 /dataset/sfraczek/paddle-models/fluid/ocr_recognition {develop} python ctc_train.py\r\n-----------  Configuration Arguments -----------\r\naverage_window: 0.15\r\nbatch_size: 32\r\neval_period: 15000\r\ninit_model: None\r\nlog_period: 1000\r\nmax_average_window: 15625\r\nmin_average_window: 10000\r\nparallel: False\r\npass_num: 100\r\nsave_model_dir: ./models\r\nsave_model_period: 15000\r\nuse_gpu: True\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py:64: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\nfile md5 b5df92d1c0ab0d585f4771e062a065e1 1de60d54d19632022144e4e58c2637b5\r\nCache file /root/.cache/paddle/dataset/ctc_data/data.tar.gz not found, downloading http://cloud.dlnel.org/filepub/?uuid=df937251-3c0b-480d-9a7b-0080dfeee65c\r\nTraceback (most recent call last):\r\n  File \"ctc_train.py\", line 150, in <module>\r\n    main()\r\n  File \"ctc_train.py\", line 146, in main\r\n    train(args, data_reader=ctc_reader)\r\n  File \"ctc_train.py\", line 52, in train\r\n    train_list_file=train_list)\r\n  File \"/dataset/sfraczek/paddle-models/fluid/ocr_recognition/ctc_reader.py\", line 166, in train\r\n    data_dir = download_data()\r\n  File \"/dataset/sfraczek/paddle-models/fluid/ocr_recognition/ctc_reader.py\", line 194, in download_data\r\n    DATA_URL, CACHE_DIR_NAME, DATA_MD5, save_name=SAVED_FILE_NAME)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/dataset/common.py\", line 90, in download\r\n    shutil.copyfileobj(r.raw, f)\r\n  File \"/usr/lib/python2.7/shutil.py\", line 49, in copyfileobj\r\n    buf = fsrc.read(length)\r\n  File \"/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/response.py\", line 311, in read\r\n    flush_decoder = True\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/response.py\", line 244, in _error_catcher\r\n    raise ProtocolError('Connection broken: %r' % e, e)\r\nrequests.packages.urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(15973 bytes read, 411 more expected)', IncompleteRead(15973 bytes read, 411 more expected))\r\n\r\n```\r\n@wanghaoshuang maybe you could help me?",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "qingqing01",
        "created_at": "2018-05-09T08:15:26+00:00",
        "updated_at": "2018-05-15T14:09:01+00:00",
        "closed_at": "2018-05-10T01:31:28+00:00",
        "comments_count": [
            "wanghaoshuang",
            "sfraczek",
            "wanghaoshuang",
            "sfraczek",
            "sfraczek",
            "sfraczek",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 905,
        "title": "如何编译成android库",
        "body": "能不能编译成android平台库",
        "state": "closed",
        "user": "vesung",
        "closed_by": "shanyi15",
        "created_at": "2018-05-11T11:29:17+00:00",
        "updated_at": "2018-08-15T09:54:05+00:00",
        "closed_at": "2018-08-15T09:54:05+00:00",
        "comments_count": [
            "luotao1",
            "vesung",
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 906,
        "title": "what's mean of light_imdb and tiny_imdb",
        "body": "Questions from @wojtuss: How can I get the dataset for the 'text_classification' model? It seems that it is imported to the scripts via python modules 'light_imdb' and 'tiny_imdb', but I cant find them anywhere.\r\n\r\n@gmcather Could you help fix this problem? Thanks very much!",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2018-05-11T14:51:12+00:00",
        "updated_at": "2018-05-14T01:50:44+00:00",
        "closed_at": "2018-05-14T01:50:44+00:00",
        "comments_count": [
            "gmcather",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 920,
        "title": "Develop PyramidBox model for face detection.",
        "body": "- Add PyramidBox model for face detection:  https://arxiv.org/abs/1803.07737",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-05-18T08:20:52+00:00",
        "updated_at": "2018-05-22T07:31:02+00:00",
        "closed_at": "2018-05-22T07:31:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 914,
        "title": "Add Inception_v4 model config in Fluid API",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-05-15T13:27:37+00:00",
        "updated_at": "2018-05-21T09:23:57+00:00",
        "closed_at": "2018-05-21T09:23:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 926,
        "title": "Add pre-trained model for pyramidbox model.",
        "body": "Load pretrained VGG model for face detection.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-05-22T11:17:59+00:00",
        "updated_at": "2018-05-23T02:54:27+00:00",
        "closed_at": "2018-05-22T13:47:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 928,
        "title": "Add data reader for WIDER Face dataset and train logic for face detection. ",
        "body": "- Add data reader for WIDER Face dataset. Now the data argumentation is the same as SSD objection detection. We will refine all these codes later.\r\n- Add simple VGG + SSD network.\r\n- Add train logic.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-05-23T10:10:46+00:00",
        "updated_at": "2018-05-24T01:41:45+00:00",
        "closed_at": "2018-05-24T01:41:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 909,
        "title": "CI of model repo cannot be triggered.",
        "body": "It seems that the CI in Paddle Model repo cannot be triggered. Some of the PRs are not well formatted if CI cannot be triggered no check will guarantee some basic checks. @panyx0718 ",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "lcy-seso",
        "created_at": "2018-05-14T02:30:14+00:00",
        "updated_at": "2018-05-14T08:26:48+00:00",
        "closed_at": "2018-05-14T08:25:09+00:00",
        "comments_count": [
            "panyx0718",
            "kuke",
            "kuke",
            "panyx0718",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 917,
        "title": "caffe2fluid doesn't support layers softmax_with_loss and accuracy",
        "body": "caffe2fluid fails to convert AlexNet and Googlenet with below message:\r\nConverting data...\r\nSaving data...\r\nSaving source...\r\nError encountered: No handler found for node kind: SoftmaxWithLoss (expected: map_softmax_with_loss)\r\n\r\nConverting data...\r\nSaving data...\r\nSaving source...\r\nError encountered: No handler found for node kind: Accuracy (expected: map_accuracy)",
        "state": "closed",
        "user": "sabreshao",
        "closed_by": "shanyi15",
        "created_at": "2018-05-16T10:32:23+00:00",
        "updated_at": "2018-08-15T09:54:02+00:00",
        "closed_at": "2018-08-15T09:54:02+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 929,
        "title": "Unify code for objection detection.",
        "body": "We develop several detection algorithms, like:\r\n\r\n- FaceDetection:  https://github.com/PaddlePaddle/models/tree/develop/fluid/face_detection\r\n- SSD: https://github.com/PaddlePaddle/models/tree/develop/fluid/object_detection \r\n\r\nand some other algorithms will also be added, like:\r\n\r\n- Faster-RCNN\r\n- Mask-RCNN\r\n- ...  etc.\r\n\r\nNow the face detection and object detection are located in two independent directories. But:\r\n\r\n- Some of them use the same data argumentation.\r\n- Some of them use the same base CNN network.\r\n- The train, eval, infer logic is also similar.\r\n- Some also can share the same dataset.\r\n\r\nSo we need to refine these code to unify them.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "shanyi15",
        "created_at": "2018-05-23T11:08:16+00:00",
        "updated_at": "2018-08-15T09:53:57+00:00",
        "closed_at": "2018-08-15T09:53:57+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 930,
        "title": "Polish the document of DeepASR",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "shanyi15",
        "created_at": "2018-05-24T02:13:05+00:00",
        "updated_at": "2018-08-15T09:53:53+00:00",
        "closed_at": "2018-08-15T09:53:53+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 935,
        "title": "F0526 15:26:19.539976 12033 RecurrentGradientMachine.cpp:381] Check failed: commonSeqInfo_[i].topLevelLength == seqInfo[i].topLevelLength (7 vs. 223)  RecurrentGroup __recurrent_group_0__ input 2 has mismatched sequence length",
        "body": "使用的是conv_seq2seq中的infer程序，当然是仿照他写的程序出现了上面的错误，请问是什么原因，我的padding_num是7",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-05-26T07:33:23+00:00",
        "updated_at": "2018-05-30T09:13:59+00:00",
        "closed_at": "2018-05-30T09:13:59+00:00",
        "comments_count": [
            "chenbblei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 942,
        "title": "Need to fix the bug in bbox sampling of SSD.",
        "body": "Refer https://github.com/weiliu89/caffe/commit/6feb7d99d3c6938321c9afd21d8f397a7a33b0a4",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-05-30T03:47:38+00:00",
        "updated_at": "2018-05-30T09:32:09+00:00",
        "closed_at": "2018-05-30T09:32:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 933,
        "title": "conv_seq2seq的测试集脚本怎么写",
        "body": "如题，例子中只有验证集合，验证集合是有target标签的，而测试集是没有的，该怎么写测试集的脚本呢",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "qingqing01",
        "created_at": "2018-05-25T08:34:59+00:00",
        "updated_at": "2018-05-28T04:32:49+00:00",
        "closed_at": "2018-05-28T04:32:49+00:00",
        "comments_count": [
            "qingqing01",
            "chenbblei",
            "qingqing01",
            "chenbblei",
            "chenbblei",
            "qingqing01"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 937,
        "title": "Conv input and filter dimensions do not match",
        "body": "When running the `eval.py` script for MobileNet-SSD with `pascalvoc` or `coco` dataset and a model trained accordingly on the dataset on CPU, the following exception is being thrown:\r\n```\r\npaddle.fluid.core.EnforceNotMet: enforce in_dims.size() == filter_dims.size() failed, 4 != 1\r\nConv input dimension and filter dimension should be the same. at [/paddle/paddle/fluid/operators/conv_op.cc:49]\r\n```\r\nHow can I fix this?\r\n\r\nPaddlePaddle call stack:\r\n```\r\n0       0x7f59ac396b38p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 466\r\n1       0x7f59acdb896ep paddle::operators::ConvOp::InferShape(paddle::framework::InferShapeContext*) const + 1602\r\n2       0x7f59acf7201bp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 127\r\n3       0x7f59acf6fa76p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 254\r\n4       0x7f59ac4f7920p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 698\r\n5       0x7f59ac4f4387p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 137\r\n6       0x7f59ac3c9380p pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}::operator()(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) const + 144\r\n7       0x7f59ac42d9eap void pybind11::detail::argument_loader<paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool>::call_impl<void, pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&, 0ul, 1ul, 2ul, 3ul, 4ul, 5ul>(pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&, pybind11::detail::index_sequence<0ul, 1ul, 2ul, 3ul, 4ul, 5ul>) + 212\r\n8       0x7f59ac4031ffp std::enable_if<std::is_void<void>::value, pybind11::detail::void_type>::type pybind11::detail::argument_loader<paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool>::call<void, pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&>(pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&) + 69\r\n9       0x7f59ac3e9927p void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::operator()(pybind11::detail::function_call) const + 201\r\n10      0x7f59ac3e9d91p void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 29\r\n11      0x7f59ac3a4bbep pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2581\r\n12            0x4c37edp PyEval_EvalFrameEx + 31165\r\n13            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n14            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n15            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n16            0x4c1e6fp PyEval_EvalFrameEx + 24639\r\n17            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n18            0x4c1e6fp PyEval_EvalFrameEx + 24639\r\n19            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n20            0x4eb30fp\r\n21            0x4e5422p PyRun_FileExFlags + 130\r\n22            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n23            0x493ae2p Py_Main + 1554\r\n24      0x7f59d09eb830p __libc_start_main + 240\r\n25            0x4933e9p _start + 41\r\n```\r\n",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "wojtuss",
        "created_at": "2018-05-28T08:57:01+00:00",
        "updated_at": "2018-05-30T09:36:12+00:00",
        "closed_at": "2018-05-30T09:36:12+00:00",
        "comments_count": [
            "baiyfbupt",
            "baiyfbupt",
            "wojtuss",
            "baiyfbupt",
            "qingqing01",
            "wojtuss"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 936,
        "title": "conv_seq2seq中的部分代码求解",
        "body": " padding_list = [context_len - 1 for (size, context_len) in dec_conv_blocks]\r\n    padding_num = reduce(lambda x, y: x + y, padding_list)\r\n在conv_seq2seq的infer.py中有这两行代码，这个是什么意思，为什么要这么做",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-05-26T09:36:44+00:00",
        "updated_at": "2018-05-29T12:04:56+00:00",
        "closed_at": "2018-05-29T12:04:56+00:00",
        "comments_count": [
            "qingqing01",
            "chenbblei",
            "guoshengCS",
            "chenbblei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 941,
        "title": "Dataset copyrights/licenses",
        "body": "@luotao1 , models from this repo use various datasets for training and testing (flowers, cifar10, the one from `models/fluid/DeepASR/examples/aishell`, etc.). Are there any copyright restrictions in using these datasets (and generally any datasets that the scripts from this repository download when training a model) in our tests validating the models?",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "shanyi15",
        "created_at": "2018-05-29T14:00:58+00:00",
        "updated_at": "2018-08-15T09:53:50+00:00",
        "closed_at": "2018-08-15T09:53:50+00:00",
        "comments_count": [
            "luotao1",
            "wojtuss",
            "luotao1",
            "shanyi15"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 946,
        "title": "deepFM 不定长特征处理",
        "body": "模型库里的deepFM的特征都是固定长度的，对于不定长的特征，在deepFM的deep部分，是否需要对这些不定长特征做一下padding。在网上搜索的话，发现deepFM对于这种case做了padding，但是我目前是以这个格式type=paddle.data_type.integer_value_sequence(sparse_feature_dim))输入，然后做一个pooling，发现可以运行。所以模型库里的deepFM对于这种不定长的特征建议以哪种方式处理？",
        "state": "closed",
        "user": "dpwu1994",
        "closed_by": "shanyi15",
        "created_at": "2018-05-30T08:11:42+00:00",
        "updated_at": "2018-08-15T10:06:01+00:00",
        "closed_at": "2018-08-15T10:06:01+00:00",
        "comments_count": [
            "kuke",
            "dpwu1994",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 949,
        "title": "Add Distill Knowledge Approach Implementation",
        "body": "Add Distill Knowledge Approach Implementation",
        "state": "closed",
        "user": "likesiwell",
        "closed_by": "shanyi15",
        "created_at": "2018-05-30T13:53:14+00:00",
        "updated_at": "2018-08-15T10:05:57+00:00",
        "closed_at": "2018-08-15T10:05:57+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 959,
        "title": "convolution initialization in paddle.v2",
        "body": "Is there  ‘’xavier‘’ initialization method for convolutional networks in paddle.v2?",
        "state": "closed",
        "user": "Panxjia",
        "closed_by": "shanyi15",
        "created_at": "2018-06-02T17:22:55+00:00",
        "updated_at": "2018-08-15T10:05:51+00:00",
        "closed_at": "2018-08-15T10:05:51+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 953,
        "title": "how to use pre-commit scripts to auto-format the code?",
        "body": "I try to contribute a new paddle implementation, but when I run pre-commit, there is always a yapf failed case and I don't know what happened. \r\nI create a new issue to PR the project, but PR shows The Travis CI build failed.\r\nCould anyone tell me what happened? \r\n\r\n[The Travis CI build failed message](https://travis-ci.org/PaddlePaddle/models/builds/386154623?utm_source=github_status&utm_medium=notification)\r\n![image](https://user-images.githubusercontent.com/8766415/40783674-c98f07ea-6515-11e8-8f92-ee446c151ad5.png)\r\n\r\n![image](https://user-images.githubusercontent.com/8766415/40783666-c1eadae6-6515-11e8-8a51-18125d455b68.png)\r\n\r\n",
        "state": "closed",
        "user": "likesiwell",
        "closed_by": "shanyi15",
        "created_at": "2018-05-31T13:01:36+00:00",
        "updated_at": "2018-08-15T10:05:54+00:00",
        "closed_at": "2018-08-15T10:05:54+00:00",
        "comments_count": [
            "luotao1",
            "likesiwell",
            "luotao1",
            "likesiwell",
            "luotao1",
            "likesiwell",
            "shanyi15"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 964,
        "title": "fluid/ocr_recognition例子的模型训练脚本缺少几个命令行参数解析",
        "body": "[models/fluid/ocr_recognition](https://github.com/PaddlePaddle/models/blob/develop/fluid/ocr_recognition)例子中的模型训练脚本ctc_train.py，缺少文档中提及的几个命令行参数的接收与解析过程。\r\n![1](https://user-images.githubusercontent.com/6863219/40956334-4be30598-68c2-11e8-8f99-ad74235e1c6b.png)\r\n![2](https://user-images.githubusercontent.com/6863219/40956336-4e463a4e-68c2-11e8-9488-326b245bbd17.png)",
        "state": "closed",
        "user": "bipedalBit",
        "closed_by": "shanyi15",
        "created_at": "2018-06-05T05:35:40+00:00",
        "updated_at": "2018-08-15T10:05:47+00:00",
        "closed_at": "2018-08-15T10:05:47+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 970,
        "title": "ParallelDo vs. ParallelExecutor",
        "body": "In many training scripts there are two separate methods for training: `train_parallel_do()` and `train_parallel_exe()`. The former use `ParallelDo`, the latter `ParallelExecutor`. The documentation on both is rather sparse.\r\nWhat is the difference between the two methods?",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "shanyi15",
        "created_at": "2018-06-07T09:45:08+00:00",
        "updated_at": "2018-08-15T10:05:44+00:00",
        "closed_at": "2018-08-15T10:05:44+00:00",
        "comments_count": [
            "luotao1",
            "wojtuss",
            "luotao1",
            "wojtuss",
            "luotao1",
            "shanyi15"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 976,
        "title": "generate_chinese_poetry AssertionError",
        "body": "  File \"train.py\", line 172, in <module>\r\n    train(args.num_passes, args.batch_size, args.use_gpu, args.trainer_count, args.save_dir_path, args.encoder_depth, args.decoder_depth, args.train_data_path, args.word_dict_path)\r\n  File \"train.py\", line 128, in train\r\n    max_length=9)\r\n  File \"/home/map/chenjiachuan/models-develop/generate_chinese_poetry/network_conf.py\", line 127, in encoder_decoder_network\r\n    input=group_inputs + [trg_emb])\r\n  File \"/home/map/wangxiaomin/soft/paddle/python27/lib/python2.7/site-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/home/map/wangxiaomin/soft/paddle/python27/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/home/map/wangxiaomin/soft/paddle/python27/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py\", line 3460, in recurrent_group\r\n    assert is_single_input(each_input)\r\nAssertionError",
        "state": "closed",
        "user": "shashlik007",
        "closed_by": "shanyi15",
        "created_at": "2018-06-11T01:36:39+00:00",
        "updated_at": "2018-08-15T09:53:35+00:00",
        "closed_at": "2018-08-15T09:53:35+00:00",
        "comments_count": [
            "shashlik007",
            "shateng",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 978,
        "title": "Add networks(VGG/DPN/GoogleNet/ResNet/AlexNet) and update Readme",
        "body": "",
        "state": "closed",
        "user": "BigFishMaster",
        "closed_by": "qingqing01",
        "created_at": "2018-06-11T11:56:57+00:00",
        "updated_at": "2018-06-15T01:31:07+00:00",
        "closed_at": "2018-06-15T01:31:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 971,
        "title": "v2版seq2seq预测模型的input数目",
        "body": "模型使用的是：https://github.com/PaddlePaddle/models/tree/develop/conv_seq2seq\r\n使用如下代码生成训练配置文件\r\n![image](https://user-images.githubusercontent.com/6702524/41101802-cd145f00-6a97-11e8-88b6-2b286702ef4f.png)\r\n\r\n已经指定了infer=True，但是在通过cpi实现的时候还是说需要4个input。目标应该是只需要src和src_pos两个input的。请问是什麽原因。\r\n\r\n",
        "state": "closed",
        "user": "fmantianxing",
        "closed_by": "shanyi15",
        "created_at": "2018-06-07T13:19:53+00:00",
        "updated_at": "2018-08-15T09:53:44+00:00",
        "closed_at": "2018-08-15T09:53:44+00:00",
        "comments_count": [
            "Superjomn",
            "guoshengCS",
            "shanyi15"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 974,
        "title": "crnn-ctc training: strange awk command and len(img_label_lines) != actual dataset size",
        "body": "Hi,\r\n\r\nI have analysed a little bit the code of DataGenerator in ctc_reader.py and I have minor comments for the code there:\r\n\r\nIn line https://github.com/PaddlePaddle/models/blob/f93838a4258c2a197cfa9e14c244b4da7a042a88/fluid/ocr_recognition/ctc_reader.py#L67  `sizes` equals 0 if batch_size equals the total number of images in the dataset. I found this when I set batch_size equal to size of dataset. The result was that there was no iterations calculated at all (instead of one), because the loop in the next line is not executed. \r\n\r\nThis has led me to the next thing:\r\nIn the line here https://github.com/PaddlePaddle/models/blob/f93838a4258c2a197cfa9e14c244b4da7a042a88/fluid/ocr_recognition/ctc_reader.py#L51 I have been testing what the command `sed 1,$((1 + RANDOM % 100))d` is supposed to do. \r\nI have left only 5 lines in the **img_label_list** file. I have then ran the command `cat /root/.cache/paddle/dataset/ctc_data/data/train.list | awk '{printf(\"%04d%.4f %s\\n\", $1, rand(), $0)}' | sort | sed 1,$(( RANDOM % 5))d` and it turns out that it outputs up to 4 lines. One of the lines is always missing. When I tried `sed 1,$(( RANDOM % 6))d` instead of `1,$(( RANDOM % 5))d`, I still got 4 or less lines. The conclusion is that there is always at least one file not present in output. I wonder if that was intended? **Does this lead to the first problem above**? Also, if I increase the number to 100, the probability of printing empty list increases drastically (I guesss that up to 95%). Is this intended behavior?\r\n\r\nAlso I found this:\r\nhttps://github.com/PaddlePaddle/models/blob/f93838a4258c2a197cfa9e14c244b4da7a042a88/fluid/ocr_recognition/ctc_reader.py#L43, I found **awk** applying no change to the result of the previous command, as the file contains only 4 columns. \r\n\r\nI couldn't analyse any more of this code part because I had to return to my duties. I hope you can find this useful. :)",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "shanyi15",
        "created_at": "2018-06-08T10:23:56+00:00",
        "updated_at": "2018-08-15T09:53:39+00:00",
        "closed_at": "2018-08-15T09:53:39+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 985,
        "title": "Change the transposed conv2d initializer. ",
        "body": "Change the transposed conv2d initializer to bilinear and set the learning rate to 0.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-06-13T02:03:38+00:00",
        "updated_at": "2018-06-15T10:10:15+00:00",
        "closed_at": "2018-06-15T10:10:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 993,
        "title": "Add Pyramidbox inference configure.",
        "body": "预测配置需要crop操作：\r\n\r\n1. 前面的VGG配置如下：\r\n\r\n    conv1 (C, H1, W1) ->pooling (C, H2, W2) (stride是2) ->conv2(C, H2, W2)\r\n    H1/W1 是偶数时， `H1=2 * H2`, `W1 = 2 * W2`。\r\n\r\n2. FPN部分：\r\n\r\n    conv2(C, H2, W2)->de-conv1(C, H3, W3)，\r\n    de-conv这里上采样，是将feature map扩大2倍。H3 = 2 * H2， W3 = 2 * W2。\r\n    de-conv1 * conv1 作为输入\r\n\r\n但是：如果H1,W1是奇数，1.中的pooling会取整(假定设置上取整)，例如 W1=59，则，W2=30.\r\n则 W3 = 60，此时， de-conv1和conv1的shape不一样，无法做点对点相乘。因为需要将de-conv1做crop。\r\n\r\n",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-06-19T07:03:35+00:00",
        "updated_at": "2018-06-20T13:10:41+00:00",
        "closed_at": "2018-06-20T13:10:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 983,
        "title": "使用capi实现conv_seq2seq模型的预测程序",
        "body": "capi实现代码如下：   \r\n```\r\n    paddle_arguments in_args = paddle_arguments_create_none();\r\n    paddle_error ret1 = paddle_arguments_resize(in_args, 4);\r\n    if (ret1 != kPD_NO_ERROR) {\r\n        return false;\r\n    }\r\n    paddle_gradient_machine local_machine = nullptr;\r\n    paddle_error local_mret = paddle_gradient_machine_create_shared_param(\r\n            _machine, _config_buf, _config_size, &local_machine);\r\n    if (local_mret != kPD_NO_ERROR) {\r\n        return false;\r\n    }\r\n    std::vector<int> query_ids;\r\n    std::vector<int> query_pos;\r\n    gen_input(query, &query_ids, &query_pos);\r\n\r\n    int* src_ids = (int*) query_ids.data();\r\n    unsigned int src_num = query_ids.size();\r\n    int* src_pos = (int*) query_pos.data();\r\n\r\n    std::vector<int> trg_query_ids;\r\n    std::vector<int> trg_query_pos;\r\n\r\n    int trg_ids[WIN_SIZE]; //WORD_PADDING};\r\n    int trg_pos[WIN_SIZE]; // = {POS_PADDING};\r\n\r\n    for (int i = 0; i < WIN_SIZE; ++i) {\r\n        trg_ids[i] = WORD_PADDING;\r\n        trg_pos[i] = POS_PADDING;\r\n    }\r\n    trg_ids[WIN_SIZE-1] = 0;\r\n    trg_pos[WIN_SIZE-1] = 0;\r\n\r\n    int src_pos_array[] = {0, (int) src_num};\r\n    paddle_ivector src_ids_vec = paddle_ivector_create(src_ids, src_num, false, false);\r\n    CHECK(paddle_arguments_set_ids(in_args, 0, src_ids_vec));\r\n    paddle_ivector src_seq_vec = paddle_ivector_create(src_pos_array, sizeof(src_pos_array) / sizeof(int), false, false);\r\n    CHECK(paddle_arguments_set_sequence_start_pos(in_args, 0, 0, src_seq_vec));\r\n\r\n    paddle_ivector src_pos_vec = paddle_ivector_create(src_pos, src_num, false, false);\r\n    CHECK(paddle_arguments_set_ids(in_args, 1, src_pos_vec));\r\n    paddle_ivector src_seq_pos_vec = paddle_ivector_create(src_pos_array, sizeof(src_pos_array) / sizeof(int), false, false);\r\n    CHECK(paddle_arguments_set_sequence_start_pos(in_args, 1, 0, src_seq_pos_vec));\r\n\r\n    int trg_pos_array[] = {0, (int) WIN_SIZE};\r\n    paddle_ivector trg_ids_vec = paddle_ivector_create(trg_ids, WIN_SIZE, false, false);\r\n    CHECK(paddle_arguments_set_ids(in_args, 2, trg_ids_vec));\r\n    paddle_ivector trg_seq_vec = paddle_ivector_create(trg_pos_array, sizeof(trg_pos_array) / sizeof(int), false, false);\r\n    CHECK(paddle_arguments_set_sequence_start_pos(in_args, 2, 0, trg_seq_vec));\r\n\r\n    paddle_ivector trg_pos_vec = paddle_ivector_create(trg_pos, WIN_SIZE, false, false);\r\n    CHECK(paddle_arguments_set_ids(in_args, 3, trg_pos_vec));\r\n    paddle_ivector trg_seq_pos_vec = paddle_ivector_create(trg_pos_array, sizeof(trg_pos_array) / sizeof(int), false, false);\r\n    CHECK(paddle_arguments_set_sequence_start_pos(in_args, 3, 0, trg_seq_pos_vec));\r\n\r\n    paddle_arguments out_args = paddle_arguments_create_none();\r\n    paddle_error ret4 = paddle_gradient_machine_forward(local_machine, in_args, out_args, false);\r\n    if (ret4 != kPD_NO_ERROR) {\r\n        return false;\r\n    }\r\n```\r\n线下模型地址：https://github.com/PaddlePaddle/models/tree/develop/conv_seq2seq\r\n出现了如下错误：\r\nF0612 17:35:47.277493 34148 RecurrentGradientMachine.cpp:758] Check failed: idSize == size (1 vs. 12) \r\n*** Check failure stack trace: ***\r\n    @     0x7fcb239cb63e  google::LogMessage::Fail()\r\n    @     0x7fcb239cb591  google::LogMessage::SendToLog()\r\n    @     0x7fcb239caf9f  google::LogMessage::Flush()\r\n    @     0x7fcb239ce088  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fcb23829604  paddle::RecurrentGradientMachine::copyScattedId()\r\n    @     0x7fcb23829e9d  paddle::RecurrentGradientMachine::createMemoryFrameInfo()\r\n    @     0x7fcb2382a807  paddle::RecurrentGradientMachine::forward()\r\n    @     0x7fcb23729391  paddle::RecurrentLayerGroup::forward()\r\n    @     0x7fcb23844d7c  paddle::NeuralNetwork::forward()\r\n    @     0x7fcb236c0796  paddle_gradient_machine_forward",
        "state": "closed",
        "user": "fmantianxing",
        "closed_by": "shanyi15",
        "created_at": "2018-06-12T10:00:23+00:00",
        "updated_at": "2018-08-15T09:53:30+00:00",
        "closed_at": "2018-08-15T09:53:30+00:00",
        "comments_count": [
            "nuoline",
            "lucywsq",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 995,
        "title": "Multi-scale testing  for PyramidBox model. ",
        "body": "",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "baiyfbupt",
        "created_at": "2018-06-20T12:06:34+00:00",
        "updated_at": "2018-06-20T13:10:22+00:00",
        "closed_at": "2018-06-20T13:10:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 999,
        "title": "Data anchor sampling. ",
        "body": "Please refer https://arxiv.org/abs/1803.07737",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-06-21T13:33:47+00:00",
        "updated_at": "2018-06-22T11:00:25+00:00",
        "closed_at": "2018-06-22T11:00:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 988,
        "title": "Do you have a list of layers for all supported networks?",
        "body": "Hi,\r\n\r\nI need to find specific layer pairs which could be fused together into fused MKLDNN primitives with inference_transpiler.\r\n\r\nDo you have a list of layers for each neural network topology supported by Paddle? That could save me a lot of time/work.  Or do I need to find out by reading source files or original publications? ",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "sfraczek",
        "created_at": "2018-06-15T10:56:22+00:00",
        "updated_at": "2018-08-01T07:42:49+00:00",
        "closed_at": "2018-08-01T07:42:49+00:00",
        "comments_count": [
            "luotao1",
            "sfraczek",
            "luotao1"
        ],
        "labels": [
            "question",
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 996,
        "title": "标签增强是什么",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/fluid/object_detection/README_cn.md\r\n![image](https://user-images.githubusercontent.com/4593091/41714439-f897fb5a-7582-11e8-8abb-26df7c8c4219.png)\r\n这里的标签增强怎么理解？",
        "state": "closed",
        "user": "helen88",
        "closed_by": "qingqing01",
        "created_at": "2018-06-21T10:43:39+00:00",
        "updated_at": "2018-06-21T13:43:14+00:00",
        "closed_at": "2018-06-21T13:43:14+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1001,
        "title": "Paddlepaddle pretrained model ",
        "body": "I find the imagenet pretrained models only has three, as shown in [pretrained model](https://github.com/PaddlePaddle/models/blob/develop/image_classification/models/model_download.sh#L28-L38). What is about the others? For example, the googlenet and inception. Is it forgotten to add to the download script?",
        "state": "closed",
        "user": "JiahaoYao",
        "closed_by": "shanyi15",
        "created_at": "2018-06-22T09:09:37+00:00",
        "updated_at": "2018-08-15T09:53:25+00:00",
        "closed_at": "2018-08-15T09:53:25+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1006,
        "title": "fluid/icnet图像语义分割Readme文档不完整，训练到iter 1000报错。",
        "body": "![image](https://user-images.githubusercontent.com/4593091/41828613-d495baa6-7868-11e8-8af2-3fddf1bfe826.png)\r\n",
        "state": "closed",
        "user": "helen88",
        "closed_by": "ktlichkid",
        "created_at": "2018-06-25T03:14:24+00:00",
        "updated_at": "2018-06-25T04:46:56+00:00",
        "closed_at": "2018-06-25T04:46:56+00:00",
        "comments_count": [
            "ktlichkid"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1017,
        "title": "Speed data reader in PyramidBox model.",
        "body": "The data reader is very time-consuming. \r\n\r\n测试数据：\r\n\r\n\r\n实验 | GPU个数 | BatchSize/GPU | 是否Load Data | 数据处理+拷贝 | Run时间 | 10个batch的时间\r\n-- | -- | -- | -- | -- | -- | --\r\nExecutor | 1 | 5 | Yes | 7.45 | 18.94 | 27.12\r\nExecutor | 1 | 5 | No | 0 | 18.77 | 19.60\r\nParallelExe | 2 | 5 | Yes | 16.03 | 25.96 | 41.99\r\nParallelExe | 2 | 5 | No | 0 | 25.56 | 25.57\r\nParallelExe | 4 | 5 | Yes | 31.15 | 32.43 | 63.58\r\nParallelExe | 4 | 5 | No | 0 | 30.48 | 30.47\r\n\r\n",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2018-06-27T13:09:42+00:00",
        "updated_at": "2018-06-29T05:07:40+00:00",
        "closed_at": "2018-06-29T05:07:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1015,
        "title": "Cannot open file mean_0.tmp_0@GRAD for load op during DeepASR inference using checkpoint",
        "body": "When I train the DeepASR model, save a checkpoint in `checkpoints/deep_asr.pass_0.checkpoint`, and then run inference using the saved checkpoint I get the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"infer_by_ckpt.py\", line 288, in <module>\r\n    infer_from_ckpt(args)\r\n  File \"infer_by_ckpt.py\", line 194, in infer_from_ckpt\r\n    fluid.io.load_persistables(exe, args.checkpoint)\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/io.py\", line 493, in load_persistables\r\n    filename=filename)\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/io.py\", line 373, in load_vars\r\n    filename=filename)\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/io.py\", line 404, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/executor.py\", line 441, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot open file checkpoints/deep_asr.pass_0.checkpoint/mean_0.tmp_0@GRAD for load op at [/home/wojtuss/repos/PaddlePaddle/Paddle/paddle/fluid/operators/load_op.cc:40]\r\n```\r\n\r\nI have verified that the `checkpoints/deep_asr.pass_0.checkpoint` directory contains `mean_1.tmp_0@GRAD` file but not  `mean_0.tmp_0@GRAD`.\r\n\r\nHow can I fix this?\r\n\r\nThe PaddlePaddle call stack:\r\n```\r\n0       0x7f59f61ea5a6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 466\r\n1       0x7f59f75b2977p paddle::operators::LoadOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 1313\r\n2       0x7f59f78c6cebp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 487\r\n3       0x7f59f63648c7p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 707\r\n4       0x7f59f63612d4p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 182\r\n5       0x7f59f622014cp pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}::operator()(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) const + 144\r\n6       0x7f59f628e676p void pybind11::detail::argument_loader<paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool>::call_impl<void, pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&, 0ul, 1ul, 2ul, 3ul, 4ul, 5ul>(pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&, pybind11::detail::index_sequence<0ul, 1ul, 2ul, 3ul, 4ul, 5ul>) + 212\r\n7       0x7f59f6260883p std::enable_if<std::is_void<void>::value, pybind11::detail::void_type>::type pybind11::detail::argument_loader<paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool>::call<void, pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&>(pybind11::cpp_function::cpp_function<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&) + 69\r\n8       0x7f59f62456f1p void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::operator()(pybind11::detail::function_call) const + 201\r\n9       0x7f59f6245b5bp void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 29\r\n10      0x7f59f61f7c4ep pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2581\r\n11            0x4c37edp PyEval_EvalFrameEx + 31165\r\n12            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n13            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n14            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n15            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n16            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n17            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n18            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n19            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n20            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n21            0x4c1e6fp PyEval_EvalFrameEx + 24639\r\n22            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n23            0x4eb30fp\r\n24            0x4e5422p PyRun_FileExFlags + 130\r\n25            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n26            0x493ae2p Py_Main + 1554\r\n27      0x7f5a3fd69830p __libc_start_main + 240\r\n28            0x4933e9p _start + 41\r\n```\r\n",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "shanyi15",
        "created_at": "2018-06-27T09:46:17+00:00",
        "updated_at": "2018-08-15T09:53:16+00:00",
        "closed_at": "2018-08-15T09:53:16+00:00",
        "comments_count": [
            "kuke",
            "wojtuss",
            "shanyi15"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1019,
        "title": "[face detection] Difference of cpm module between the code and description in Figure 2.(b) in original paper?",
        "body": "I find the implentation of cpm module is different from the original paper [here](https://github.com/PaddlePaddle/models/blob/8761ab3d1d35d07d47767fad7fa380ffdeba3da7/fluid/face_detection/pyramidbox.py#L165-L199). \r\n Could you tell the reason for that?",
        "state": "closed",
        "user": "YongtaoGe",
        "closed_by": "YongtaoGe",
        "created_at": "2018-06-29T04:54:09+00:00",
        "updated_at": "2018-06-29T09:31:57+00:00",
        "closed_at": "2018-06-29T09:31:57+00:00",
        "comments_count": [
            "takecareofbigboss",
            "YongtaoGe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1020,
        "title": "Need to clean code for face detection.",
        "body": "Now many codes are ugly. Need to clean.",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "shanyi15",
        "created_at": "2018-06-29T10:22:34+00:00",
        "updated_at": "2018-08-15T09:53:12+00:00",
        "closed_at": "2018-08-15T09:53:12+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1022,
        "title": "图像分类测试模型中缺少__model__文件",
        "body": "从https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification 这个页面下载的模型，解压后缺少__model__文件，导致模型加载失败。\r\n",
        "state": "closed",
        "user": "wuyan08",
        "closed_by": "shanyi15",
        "created_at": "2018-06-30T04:51:08+00:00",
        "updated_at": "2018-08-15T09:53:09+00:00",
        "closed_at": "2018-08-15T09:53:09+00:00",
        "comments_count": [
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1025,
        "title": "youtube recall: infer_user.py 疑惑",
        "body": "请教下，infer_user.py中，为啥将load的model的中以下字段初始化为0呢?\r\n是指仅保留userid 作为featue？\r\n线下是不是也做knn的检索就行？\r\n    \r\n\r\n# load the trained model.\r\n    with gzip.open(args.model_path) as f:\r\n        parameters = paddle.parameters.Parameters.from_tar(f)\r\n    parameters.set('_proj_province', \\\r\n            np.zeros(shape=parameters.get('_proj_province').shape))\r\n    parameters.set('_proj_city', \\\r\n            np.zeros(shape=parameters.get('_proj_city').shape))\r\n    parameters.set('_proj_phone', \\\r\n            np.zeros(shape=parameters.get('_proj_phone').shape))\r\n    parameters.set('_proj_history_clicked_items', \\\r\n            np.zeros(shape= parameters.get('_proj_history_clicked_items').shape))\r\n    parameters.set('_proj_history_clicked_categories', \\\r\n            np.zeros(shape= parameters.get('_proj_history_clicked_categories').shape))\r\n    parameters.set('_proj_history_clicked_tags', \\\r\n            np.zeros(shape= parameters.get('_proj_history_clicked_tags').shape))",
        "state": "closed",
        "user": "zachzh",
        "closed_by": "zachzh",
        "created_at": "2018-07-02T12:29:35+00:00",
        "updated_at": "2018-07-06T09:23:03+00:00",
        "closed_at": "2018-07-06T09:23:03+00:00",
        "comments_count": [
            "guoshengCS",
            "Bella-Zhao",
            "zachzh",
            "Bella-Zhao"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1041,
        "title": "deepFM有没有低于0.11.0 版本的实现方案",
        "body": "",
        "state": "open",
        "user": "dpwu1994",
        "closed_by": null,
        "created_at": "2018-07-09T03:18:33+00:00",
        "updated_at": "2018-07-09T03:30:25+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1043,
        "title": "ocr识别问题请教，感谢",
        "body": "各位老师：\r\n\r\n我用/models/ocr_recognition训练了模型，并且可以正确识别任意文字（使用与训练数据相同尺寸的图片），但是当我使用任意尺寸的图片时，例如700x68，就无法正确识别。\r\n\r\n我看到ctc_reader代码里有个DATA_SHAPE = [1, 48, 512]，不知是否与此有关？我将其改成[1,68,700]运行：\r\n env CUDA_VISIBLE_DEVICE=0 python infer.py     --model_path=\"models/model_330000\" --input_images_list=\"/home/dataset/predict.list\" --input_images_dir=\"/home/dataset/predict_images\"\r\n\r\n后直接报错：\r\n\r\npaddle.fluid.core.EnforceNotMet: enforce x_mat_dims[1] == y_mat_dims[0] failed, 1152 != 768\r\nFirst matrix's width must be equal with second matrix's height. at [/paddle/paddle/fluid/operators/mul_op.cc:59]\r\n\r\n请问如何可以识别不定尺寸图片的文字？非常感谢！",
        "state": "closed",
        "user": "fisipro",
        "closed_by": "ktlichkid",
        "created_at": "2018-07-11T07:09:59+00:00",
        "updated_at": "2019-04-02T05:53:58+00:00",
        "closed_at": "2019-04-02T05:52:23+00:00",
        "comments_count": [
            "ktlichkid",
            "fisipro",
            "wanghaoshuang",
            "fisipro",
            "ktlichkid"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1050,
        "title": "请教关于ocr模型在flask重用的问题",
        "body": "各位老师好：\r\n\r\n请教一个问题，我用ocr_recognition将训练好的模型放在flask上进行预测，预测文件用的是infer.py，因为每次模型都要重新加载，所以我想在flask app里重用这个模型，于是我进行了以下改造，尝试缓存加载好的exe或者prog对象，但是出现了奇怪的问题：\r\n\r\n当第一次HTTP请求时，一切都正常预测；当后续HTTP请求时，报出异常\r\n\r\n希望各位老师能帮忙看看，万分感谢！！\r\n\r\n改过的infer.py代码，app参数是调用文件传过来的flask对象：\r\n\r\n\r\ndef inference(app, infer=ctc_infer, data_reader=ctc_reader):\r\n\r\n    num_classes = data_reader.num_classes()\r\n    data_shape = data_reader.data_shape()\r\n    # define network\r\n    images = fluid.layers.data(name='pixel', shape=data_shape, dtype='float32')\r\n    sequence = infer(images, num_classes)\r\n    # data reader\r\n    infer_reader = data_reader.inference(\r\n        infer_images_dir=args.input_images_dir,\r\n        infer_list_file=args.input_images_list)\r\n\r\n    place = fluid.CPUPlace()\r\n    prog = None\r\n\r\n    if (hasattr(app, 'exe') == False):\r\n        # prepare environment\r\n        exe = fluid.Executor(place)\r\n\r\n        # load init model\r\n        model_dir = os.path.dirname(args.model_path)\r\n        model_file_name = os.path.basename(args.model_path)\r\n        prog = fluid.default_main_program()\r\n        fluid.io.load_params(exe, dirname=model_dir, main_program=prog, filename=model_file_name)\r\n\r\n        app.exe = exe\r\n        \r\n    # load dictionary\r\n    dict_map = keys.alphabet[:]\r\n    if args.dict is not None and os.path.isfile(args.dict):\r\n        dict_map = {}\r\n        with open(args.dict) as dict_file:\r\n            for i, word in enumerate(dict_file):\r\n                dict_map[i] = word.strip()\r\n        print \"Loaded dict from %s\" % args.dict\r\n\r\n    for data in infer_reader():\r\n        result = app.exe.run(prog,\r\n                         feed=get_feeder_data(\r\n                             data, place, need_label=False),\r\n                         fetch_list=[sequence],\r\n                         return_numpy=False)\r\n        indexes = np.array(result[0]).flatten()\r\n        if dict_map is not None:\r\n            s = \"\"\r\n            for index in indexes:\r\n                s += dict_map[index]\r\n                #s += str(index) + \" \"\r\n            print s\r\n        else:\r\n            print \"result: %s\" % (indexes, )\r\n\r\n\r\n\r\n后续请求报出的异常：\r\n\r\npaddle.fluid.core.EnforceNotMet\r\n\r\nEnforceNotMet: enforce in_dims.size() == filter_dims.size() failed, 4 != 1\r\nConv input dimension and filter dimension should be the same. at [/paddle/paddle/fluid/operators/conv_op.cc:49]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6d33160c76p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f6d33c6490ap paddle::operators::ConvOp::InferShape(paddle::framework::InferShapeContext*) const + 7482\r\n2       0x7f6d33f97a1bp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 91\r\n3       0x7f6d33f9518dp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 205\r\n4       0x7f6d331fc9efp paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 255\r\n5       0x7f6d331fda40p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n6       0x7f6d3317863bp pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 555\r\n7       0x7f6d33170b44p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n8       0x555e73c78d57p PyEval_EvalFrameEx + 29351\r\n9       0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n10      0x555e73c7724ep PyEval_EvalFrameEx + 22430\r\n11      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n12      0x555e73c7724ep PyEval_EvalFrameEx + 22430\r\n13      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n14      0x555e73c8b44cp\r\n15      0x555e73c5b33ep PyObject_Call + 62\r\n16      0x555e73c7477bp PyEval_EvalFrameEx + 11467\r\n17      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n18      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n19      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n20      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n21      0x555e73c8b1a9p\r\n22      0x555e73ca378ep\r\n23      0x555e73c5b33ep PyObject_Call + 62\r\n24      0x555e73cfed83p\r\n25      0x555e73c76f60p PyEval_EvalFrameEx + 21680\r\n26      0x555e73c8a888p\r\n27      0x555e73c72591p PyEval_EvalFrameEx + 2785\r\n28      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n29      0x555e73c777d3p PyEval_EvalFrameEx + 23843\r\n30      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n31      0x555e73c777d3p PyEval_EvalFrameEx + 23843\r\n32      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n33      0x555e73c777d3p PyEval_EvalFrameEx + 23843\r\n34      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n35      0x555e73c8b1a9p\r\n36      0x555e73ca378ep\r\n37      0x555e73c76f60p PyEval_EvalFrameEx + 21680\r\n38      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n39      0x555e73c777d3p PyEval_EvalFrameEx + 23843\r\n40      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n41      0x555e73c8b1a9p\r\n42      0x555e73ca378ep\r\n43      0x555e73ca333ap\r\n44      0x555e73c604abp\r\n45      0x555e73c76f60p PyEval_EvalFrameEx + 21680\r\n46      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n47      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n48      0x555e73c8b44cp\r\n49      0x555e73c5b33ep PyObject_Call + 62\r\n50      0x555e73c7477bp PyEval_EvalFrameEx + 11467\r\n51      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n52      0x555e73c76d72p PyEval_EvalFrameEx + 21186\r\n53      0x555e73c6f8cap PyEval_EvalCodeEx + 1754\r\n54      0x555e73c8b1a9p\r\n55      0x555e73ca378ep\r\n56      0x555e73c5b33ep PyObject_Call + 62\r\n57      0x555e73c7b360p PyEval_CallObjectWithKeywords + 48\r\n58      0x555e73d0e652p\r\n59      0x7f6da1a566dbp\r\n60      0x7f6da1d8f88fp clone + 63\r\n",
        "state": "open",
        "user": "fisipro",
        "closed_by": null,
        "created_at": "2018-07-15T01:46:22+00:00",
        "updated_at": "2018-09-06T01:05:14+00:00",
        "closed_at": null,
        "comments_count": [
            "fisipro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1045,
        "title": "AttributeError: 'ModelConverter' object has no attribute 'convert_PReLU_layer'",
        "body": "I want to convert a caffe model which includes prelu layer, but I get this error after running caffe2paddle.py script. So how can I translate prelu layer into paddle model?",
        "state": "open",
        "user": "YongtaoGe",
        "closed_by": null,
        "created_at": "2018-07-12T09:51:15+00:00",
        "updated_at": "2018-07-14T08:44:08+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "YongtaoGe",
            "YongtaoGe",
            "YongtaoGe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1052,
        "title": "Some profiling results on Transformer",
        "body": "See profiling script in #1051\r\n\r\nProfiling on single GPU:\r\n```\r\nNamespace(batch_size=3200, device='GPU', num_iters=10, opts=[], pool_size=200000, special_token=['<s>', '<e>', '<unk>'], src_vocab_fpath='data/vocab.bpe.32000', train_file_pattern='data/train.tok.clean.bpe.32000.en-de', trg_vocab_fpath='data/vocab.bpe.32000', use_token_batch=True)\r\nWarming up ...\r\nbatch: 0, sum loss: 12268.457031, avg loss: 10.885942, ppl: 53420.105469\r\nbatch: 1, sum loss: 12178.395508, avg loss: 10.863868, ppl: 52253.792969\r\nbatch: 2, sum loss: 8879.164062, avg loss: 10.815060, ppl: 49764.625000\r\n\r\nProfiling ...\r\nbatch: 0, sum loss: 12244.498047, avg loss: 10.864683, ppl: 52296.417969\r\nbatch: 1, sum loss: 12141.288086, avg loss: 10.830766, ppl: 50552.402344\r\nbatch: 2, sum loss: 8841.737305, avg loss: 10.769473, ppl: 47546.957031\r\nbatch: 3, sum loss: 9886.705078, avg loss: 10.781576, ppl: 48125.917969\r\nbatch: 4, sum loss: 14117.681641, avg loss: 10.818147, ppl: 49918.488281\r\nbatch: 5, sum loss: 12966.675781, avg loss: 10.760727, ppl: 47132.917969\r\nbatch: 6, sum loss: 13092.765625, avg loss: 10.749397, ppl: 46601.933594\r\nbatch: 7, sum loss: 11771.145508, avg loss: 10.681621, ppl: 43548.066406\r\nbatch: 8, sum loss: 13585.663086, avg loss: 10.680552, ppl: 43501.578125\r\nbatch: 9, sum loss: 14588.139648, avg loss: 10.632755, ppl: 41471.234375\r\n\r\n------------------------->     Profiling Report     <-------------------------\r\n\r\nPlace: All\r\nTime unit: ms\r\nSorted by total time in descending order in the same thread\r\n\r\nEvent                                       Calls       Total       Min.        Max.        Ave.        \r\nthread0::mul_grad                           960         650.981     0.339968    1.57696     0.678106    \r\nthread0::matmul_grad                        370         565.571     0.264192    53.889      1.52857     \r\nthread0::softmax_with_cross_entropy         10          469.709     45.5281     48.127      46.9709     \r\nthread0::dropout                            500         374.273     0.579584    1.0496      0.748546    \r\nthread0::matmul                             370         372.095     0.136192    34.4699     1.00566     \r\nthread0::mul                                960         314.561     0.162816    0.748544    0.327668    \r\nthread0::layer_norm_grad                    300         263.247     0.756736    0.930816    0.877489    \r\nthread0::elementwise_add_grad               740         153.038     0.050176    0.909312    0.206808    \r\nthread0::sum                                320         127.341     0.17408     3.48467     0.397939    \r\nthread0::softmax_grad                       180         127.295     0.503808    0.910336    0.707197    \r\nthread0::layer_norm                         300         123.037     0.352256    0.436224    0.410122    \r\nthread0::adam                               1810        88.9652     0.008192    2.20774     0.049152    \r\nthread0::elementwise_add                    740         83.4826     0.054272    0.25088     0.112814    \r\nthread0::softmax                            180         79.7266     0.326656    0.587776    0.442926    \r\nthread0::transpose                          720         61.1564     0.070656    2.22003     0.0849395   \r\nthread0::transpose_grad                     720         58.6763     0.069632    0.088064    0.0814948   \r\nthread0::softmax_with_cross_entropy_grad    10          53.2357     4.92954     5.63917     5.32357     \r\nthread0::label_smooth                       10          50.7187     4.66534     5.3975      5.07187     \r\nthread0::dropout_grad                       500         47.9016     0.077824    0.126976    0.0958033   \r\nthread0::relu_grad                          120         41.0081     0.288768    0.364544    0.341734    \r\nthread0::relu                               120         29.1768     0.205824    0.259072    0.24314     \r\nthread0::scale                              420         24.8033     0.008192    0.06656     0.0590555   \r\nthread0::fill_zeros_like                    1100        21.2132     0.008192    0.041984    0.0192847   \r\nthread0::one_hot                            10          19.67       1.79712     2.08896     1.967       \r\nthread0::reshape                            1110        15.6437     0.002048    0.063488    0.0140934   \r\nthread0::lookup_table_grad                  40          13.7851     0.164864    0.53248     0.344627    \r\nthread0::lookup_table                       40          4.0704      0.064512    0.181248    0.10176     \r\nthread0::reshape_grad                       1110        3.08541     0.002048    0.004096    0.00277965  \r\nthread0::feed                               190         1.96202     0.007168    0.034816    0.0103264   \r\nthread0::fetch                              20          0.835584    0.033792    0.053248    0.0417792   \r\nthread0::reduce_sum                         20          0.196608    0.009216    0.011264    0.0098304   \r\nthread0::elementwise_mul                    10          0.094208    0.009216    0.01024     0.0094208   \r\nthread0::reduce_sum_grad                    10          0.093184    0.009216    0.01024     0.0093184   \r\nthread0::elementwise_mul_grad               10          0.089088    0.008192    0.009216    0.0089088   \r\nthread0::elementwise_div                    10          0.089088    0.008192    0.009216    0.0089088   \r\n\r\nElapsed time: total 6.818273 s, in executor 5.527260 s\r\n```\r\n\r\n",
        "state": "open",
        "user": "kuke",
        "closed_by": null,
        "created_at": "2018-07-16T07:11:42+00:00",
        "updated_at": "2018-07-17T07:53:17+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1057,
        "title": "caffe mobilenet 模型转 fluid 模型失败, 转其他模型可以成功",
        "body": "<img width=\"330\" alt=\"2018-07-19 12 28 30\" src=\"https://user-images.githubusercontent.com/13360993/42921636-81cb3c66-8b4f-11e8-9624-9b5708253896.png\">\r\n\r\n 我遇到了这样一个问题, ubuntu 16.04 下 转 caffe mobilenet 模型 至 fluid 模型报错,  我要转换的模型地址:\r\n https://github.com/codeWorm2015/MobileNet-Caffe    \r\n使用的是这个页面 https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification/caffe2fluid 的脚本, 哪位同学帮忙解决下呀\r\n",
        "state": "open",
        "user": "RayLiu2015",
        "closed_by": null,
        "created_at": "2018-07-19T05:09:00+00:00",
        "updated_at": "2018-12-15T13:56:31+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "nizihan"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1058,
        "title": "Where to download transformer dataset from?",
        "body": "Hi,\r\n\r\nI need to work on Transformer model optimization. Could you please tell me where can I download dataset from? Should it be exactly WMT-16? Which archives?\r\n\r\nThank you.\r\n\r\nRegards,\r\nSylwester",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "sfraczek",
        "created_at": "2018-07-19T11:39:41+00:00",
        "updated_at": "2018-07-19T15:22:17+00:00",
        "closed_at": "2018-07-19T15:22:17+00:00",
        "comments_count": [
            "sfraczek",
            "sfraczek",
            "sfraczek"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1059,
        "title": "How to correctly run transformer?",
        "body": "Hi,\r\n\r\nI have encountered a number of problems with fluid/neural_machine_translation/**transformer** model. Am I doing something wrong? How to correctly run it?\r\n\r\n## Steps I have taken\r\nFollowing instructions in https://github.com/PaddlePaddle/models/blob/develop/fluid/neural_machine_translation/transformer/README_cn.md I have downloaded WMT'16 EN-DE from https://github.com/google/seq2seq/blob/master/docs/data.md by clicking download.\r\n\r\nNext I extracted it to `wmt16_en_de` directory.\r\n\r\nNext I did `paste -d ' \\ t ' train.tok.clean.bpe.32000.en train.tok.clean.bpe.32000.de > train.tok.clean.bpe.32000.en-de`\r\n\r\nThen I did `sed -i '1i\\<s>\\n<e>\\n<unk>' vocab.bpe.32000`\r\n\r\nin config.py I changed `use_gpu = True` to `False`.\r\nIn train.py I added `import multiprocessing` and changed `dev_count = fluid.core.get_cuda_device_count()` to `dev_count = fluid.core.get_cuda_device_count() if TrainTaskConfig.use_gpu else multiprocessing.cpu_count()`.\r\n\r\n### Training \r\nI launched training by `python -u train.py   --src_vocab_fpath wmt16_en_de/vocab.bpe.32000   --trg_vocab_fpath wmt16_en_de/vocab.bpe.32000   --special_token '<s>' '<e>' '<unk>'   --train_file_pattern wmt16_en_de/train.tok.clean.bpe.32000.en-de   --use_token_batch True   --batch_size 3200   --sort_type pool --pool_size 200000`\r\n\r\nbut I got\r\n```\r\nE0719 14:26:29.439303 55138 graph.cc:43] softmax_with_cross_entropy_grad input var not in all_var list: softmax_with_cross_entropy_0.tmp_0@GRAD\r\nepoch: 0, consumed 0.000161s\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 428, in <module>\r\n    train(args)\r\n  File \"train.py\", line 419, in train\r\n    \"pass_\" + str(pass_id) + \".checkpoint\"))\r\n  File \"/home/sfraczek/Paddle/build/python/paddle/fluid/io.py\", line 288, in save_persistables\r\n    filename=filename)\r\n  File \"/home/sfraczek/Paddle/build/python/paddle/fluid/io.py\", line 166, in save_vars\r\n    filename=filename)\r\n  File \"/home/sfraczek/Paddle/build/python/paddle/fluid/io.py\", line 197, in save_vars\r\n    executor.run(save_program)\r\n  File \"/home/sfraczek/Paddle/build/python/paddle/fluid/executor.py\", line 449, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: holder_ should not be null\r\nTensor not initialized yet when Tensor::type() is called. at [/home/sfraczek/Paddle/paddle/fluid/framework/tensor.h:139]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f060e948f1cp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572\r\n1       0x7f060e94b901p paddle::framework::Tensor::type() const + 209\r\n2       0x7f060f617bf6p paddle::operators::SaveOp::SaveLodTensor(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_,\r\nboost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::va\r\nriant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> con\r\nst&, paddle::framework::Variable*) const + 614\r\n3       0x7f060f618472p paddle::operators::SaveOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boos\r\nt::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::varian\r\nt::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::\r\ndetail::variant::void_> const&) const + 210\r\n```\r\nSo I have commented out \r\n```\r\n#fluid.io.save_persistables(\r\n#    exe,\r\n#    os.path.join(TrainTaskConfig.ckpt_dir,\r\n#                 \"pass_\" + str(pass_id) + \".checkpoint\"))\r\n``` \r\nand it worked.\r\n\r\n### Inference\r\nSo next I have tried to run inference.\r\nI have found  that the file **wmt16_en_de/newstest2013.tok.bpe.32000.en-de** doesn't exist but based on the README I guessed that I should run \r\n`paste -d ' \\ t ' newstest2013.tok.bpe.32000.en newstest2013.tok.bpe.32000.de > newstest2013.tok.bpe.32000.en-de` is this correct?\r\n\r\n`python -u infer.py   --src_vocab_fpath wmt16_en_de/vocab.bpe.32000   --trg_vocab_fpath wmt16_en_de/vocab.bpe.32000   --special_token '<s>' '<e>' '<unk>'   --test_file_pattern wmt16_en_de/newstest2013.tok.bpe.32000.en-de   --batch_size 4   model_path trained_models/pass_20.infer.model   beam_size 5` but there was no ouptut from the script. It ended without error too.\r\n\r\nI tried giving other files but it doesn't output anything either.\r\n\r\nI added profiling by adding `import paddle.fluid.profiler as profiler` and \r\n```\r\n+    parser.add_argument(\r\n+        \"--profile\",\r\n+        type=bool,\r\n+        default=False,\r\n+        help=\"Enables/disables profiling.\")\r\n```\r\nand\r\n```\r\n+    if args.profile:\r\n+        with profiler.profiler(\"CPU\", sorted_key='total') as cpuprof:\r\n+            infer(args)\r\n+    else:\r\n+        infer(args)\r\n```\r\nBut there is no output from the profile.\r\n\r\nPlease help.",
        "state": "open",
        "user": "sfraczek",
        "closed_by": "sfraczek",
        "created_at": "2018-07-19T15:07:56+00:00",
        "updated_at": "2018-09-03T06:09:40+00:00",
        "closed_at": null,
        "comments_count": [
            "sfraczek",
            "kuke",
            "sfraczek",
            "sfraczek",
            "sfraczek",
            "sfraczek",
            "guoshengCS",
            "sfraczek",
            "sfraczek",
            "sfraczek",
            "guoshengCS",
            "sfraczek",
            "guoshengCS",
            "mrysztow",
            "sfraczek",
            "sfraczek",
            "guoshengCS",
            "guoshengCS",
            "sfraczek",
            "sfraczek",
            "guoshengCS",
            "sfraczek",
            "sfraczek",
            "sfraczek",
            "guoshengCS"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1062,
        "title": "加载预训练模型",
        "body": "你好！非常感谢提供一个开源的框架让大家学习。想请问下这里可以去加载一些常用的预训练模型吗，类似于resnet，然后已经在imagenet上训练过的？我从官方文档中没找到",
        "state": "open",
        "user": "zgplvyou",
        "closed_by": null,
        "created_at": "2018-07-20T13:49:36+00:00",
        "updated_at": "2018-07-20T16:35:01+00:00",
        "closed_at": null,
        "comments_count": [
            "oraoto"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1063,
        "title": "分类预训练模型无法下了",
        "body": "sh model_download.sh ResNet50\r\nDownload ResNet50 model ...\r\n--2018-07-21 13:03:49--  http://cloud.dlnel.org/filepub/?uuid=f63f237a-698e-4a22-9782-baf5bb183019\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 202.108.23.203\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|202.108.23.203|:80... connected.\r\nHTTP request sent, awaiting response... 502 Bad Gateway\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\n2018-07-21 13:03:49 ERROR 502: Bad Gateway.\r\n\r\nFail to download the model!\r\n",
        "state": "closed",
        "user": "wenxingsen",
        "closed_by": "wenxingsen",
        "created_at": "2018-07-21T05:05:03+00:00",
        "updated_at": "2018-07-25T12:24:28+00:00",
        "closed_at": "2018-07-25T12:24:28+00:00",
        "comments_count": [
            "wenxingsen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1068,
        "title": "no 'name' argument for fluid.layers.relu",
        "body": "i found that `paddlepaddle-gpu==0.14.0.post85` no longer support 'name' argument in fluid.layers.relu ,  which is not consistent with other layers' interface. can we make them behave in the same way ?",
        "state": "closed",
        "user": "walloollaw",
        "closed_by": "qingqing01",
        "created_at": "2018-07-23T13:58:07+00:00",
        "updated_at": "2018-08-16T04:01:23+00:00",
        "closed_at": "2018-08-16T04:01:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1064,
        "title": "在训练fluid版本的图像分类的时候，loss输出不正常",
        "body": "我在训练这个https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification 程序时，报错如下，我只是换输出成为flowers数据集，之前输出还是正常的。换成服务器训练就不行了，使用的是GoogleNet网络\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ncheckpoint: None\r\nclass_dim: 102\r\nimage_shape: 3,224,224\r\nlr: 0.0001\r\nlr_strategy: piecewise_decay\r\nmodel: GoogleNet\r\nmodel_save_dir: output\r\nnum_epochs: 100\r\npretrained_model: None\r\ntotal_images: 6149\r\nuse_gpu: True\r\nwith_mem_opt: True\r\n------------------------------------------------\r\nGoogleNet\r\npiecewise_decay\r\nPass 0, trainbatch 0, loss 0.300000011921,                        acc1 0.0625, acc5 0.125 time 0.36 sec\r\nPass 0, trainbatch 10, loss 0.300000011921,                        acc1 0.0, acc5 0.03125 time 0.37 sec\r\nPass 0, trainbatch 20, loss 0.300000011921,                        acc1 0.0, acc5 0.09375 time 0.34 sec\r\nPass 0, trainbatch 30, loss 0.300000011921,                        acc1 0.03125, acc5 0.03125 time 0.34 sec\r\nPass 0, trainbatch 40, loss 0.300000011921,                        acc1 0.03125, acc5 0.0625 time 0.34 sec\r\nPass 0, trainbatch 50, loss 0.300000011921,                        acc1 0.03125, acc5 0.0625 time 0.34 sec\r\nPass 0, trainbatch 60, loss 0.300000011921,                        acc1 0.03125, acc5 0.15625 time 0.34 sec\r\nPass 0, trainbatch 70, loss 0.300000011921,                        acc1 0.0, acc5 0.15625 time 0.42 sec\r\nPass 0, trainbatch 80, loss 0.300000011921,                        acc1 0.0625, acc5 0.15625 time 0.34 sec\r\nPass 0, trainbatch 90, loss 0.300000011921,                        acc1 0.03125, acc5 0.15625 time 0.34 sec\r\nPass 0, trainbatch 100, loss 0.300000011921,                        acc1 0.0625, acc5 0.25 time 0.34 sec\r\nPass 0, trainbatch 110, loss 0.300000011921,                        acc1 0.15625, acc5 0.28125 time 0.36 sec\r\nPass 0, trainbatch 120, loss 0.300000011921,                        acc1 0.0625, acc5 0.09375 time 0.35 sec\r\nPass 0, trainbatch 130, loss 0.300000011921,                        acc1 0.0625, acc5 0.125 time 0.35 sec\r\nPass 0, trainbatch 140, loss 0.300000011921,                        acc1 0.0625, acc5 0.25 time 0.37 sec\r\nPass 0, trainbatch 150, loss 0.300000011921,                        acc1 0.0625, acc5 0.21875 time 0.34 sec\r\nPass 0, trainbatch 160, loss 0.300000011921,                        acc1 0.03125, acc5 0.15625 time 0.36 sec\r\nPass 0, trainbatch 170, loss 0.300000011921,                        acc1 0.0625, acc5 0.28125 time 0.34 sec\r\nPass 0, trainbatch 180, loss 0.300000011921,                        acc1 0.0625, acc5 0.25 time 0.34 sec\r\nPass 0, trainbatch 190, loss 0.300000011921,                        acc1 0.125, acc5 0.28125 time 0.33 sec\r\nPass 0,testbatch 0,loss 6.83010864258, acc1 0.1875,acc5 0.25,time 0.07 sec\r\nPass 0,testbatch 10,loss 7.35022115707, acc1 0.0,acc5 0.0625,time 0.10 sec\r\nPass 0,testbatch 20,loss 7.55748462677, acc1 0.0,acc5 0.0625,time 0.07 sec\r\nPass 0,testbatch 30,loss 6.9986410141, acc1 0.0,acc5 0.1875,time 0.07 sec\r\nPass 0,testbatch 40,loss 7.14085483551, acc1 0.0,acc5 0.125,time 0.07 sec\r\nPass 0,testbatch 50,loss 7.07055664062, acc1 0.0625,acc5 0.125,time 0.09 sec\r\nPass 0,testbatch 60,loss 7.38418912888, acc1 0.0625,acc5 0.125,time 0.07 sec\r\nEnd pass 0, train_loss 0.299999982119, train_acc1 0.0603841133416, train_acc5 0.16064453125, test_loss 7.31333882468, test_acc1 0.0248015873016, test_acc5 0.0982142857143\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-07-22T07:26:47+00:00",
        "updated_at": "2018-08-15T06:14:12+00:00",
        "closed_at": "2018-08-15T06:14:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 551,
        "title": "预训练模型无法下载",
        "body": "您好，最近在使用deepspeech时发现无法下载已经训练好的libr声学模型，报错：\r\nERROR 502: Bad Gateway.\r\n\r\n看之前也有人提到这个问题，不知道怎么了",
        "state": "closed",
        "user": "RongerSnow",
        "closed_by": "zh794390558",
        "created_at": "2018-07-22T12:09:49+00:00",
        "updated_at": "2021-05-12T05:13:35+00:00",
        "closed_at": "2021-05-12T05:13:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1070,
        "title": "[fluid/object_detection] 用模型提供的训练脚本训练不出任何模型",
        "body": "在 Fluid 里面的 Object Detection 中，运行提供的 `train.py`，在输出文件夹里没有任何 `__model__` 文件。 输出日志在这里：\r\n\r\n[output_10pass.txt](https://github.com/PaddlePaddle/models/files/2220607/output_10pass.txt)\r\n\r\n",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "qingqing01",
        "created_at": "2018-07-23T18:40:50+00:00",
        "updated_at": "2018-09-29T08:12:41+00:00",
        "closed_at": "2018-09-29T08:12:41+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1076,
        "title": "face_detection",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/fluid/face_detection\r\n这个我直接运行train.py报错了，定位在fluid.ParallelExecutor(),说找不到libnccl.so这个动态库。然后我把parallel设置成false了之后就报下面的错了\r\nFile \"/home/daimin/.conda/envs/py27new/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 443, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: enforce allocating <= available failed, 10244596957 > 1133575936\r\n at [/paddle/paddle/fluid/platform/gpu_info.cc:119]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f2c07a2e2f6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f2c088a65bep paddle::platform::GpuMaxChunkSize() + 766\r\n2       0x7f2c087d668cp void* paddle::memory::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace, unsigned long) + 444\r\n3       0x7f2c087cbd42p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace",
        "state": "closed",
        "user": "Fairydetail",
        "closed_by": "qingqing01",
        "created_at": "2018-07-27T00:45:05+00:00",
        "updated_at": "2018-09-29T08:13:13+00:00",
        "closed_at": "2018-09-29T08:13:13+00:00",
        "comments_count": [
            "ktlichkid"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1077,
        "title": "coco dataset obj detection num_class=81?",
        "body": "https://github.com/PaddlePaddle/models/blob/a56d95e65c775caacff86f681d616d5444cca180/fluid/object_detection/train.py#L53",
        "state": "closed",
        "user": "youngstu",
        "closed_by": "qingqing01",
        "created_at": "2018-07-27T03:35:48+00:00",
        "updated_at": "2018-09-29T08:12:04+00:00",
        "closed_at": "2018-09-29T08:12:04+00:00",
        "comments_count": [
            "xingyuanbu"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1078,
        "title": "带gpu跑object_detection时遇到错误",
        "body": "paddle.fluid.core.EnforceNotMet: enforce allocating <= available failed, 7433255387 > 366608128\r\n at [/paddle/paddle/fluid/platform/gpu_info.cc:119]\r\n",
        "state": "closed",
        "user": "smallhaes",
        "closed_by": "ktlichkid",
        "created_at": "2018-07-27T03:59:09+00:00",
        "updated_at": "2018-08-02T04:24:43+00:00",
        "closed_at": "2018-08-02T04:24:43+00:00",
        "comments_count": [
            "ktlichkid",
            "smallhaes",
            "ktlichkid",
            "smallhaes",
            "sanwushuosi",
            "ktlichkid"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1079,
        "title": "fluid跑ssd遇到这个错误，什么情况？",
        "body": "python -u train.py --batch_size=64 --dataset='pascalvoc'  --pretrained_model='pretrained/pretrained/mobilenet_v1_imagenet.tar.gz'\r\n\r\n-----------  Configuration Arguments -----------\r\nap_version: 11point\r\napply_distort: True\r\napply_expand: True\r\nbatch_size: 64\r\ndataset: pascalvoc\r\nis_toy: 0\r\nlearning_rate: 0.001\r\nmean_value_B: 127.5\r\nmean_value_G: 127.5\r\nmean_value_R: 127.5\r\nmodel_save_dir: model\r\nnms_threshold: 0.45\r\nnum_passes: 120\r\nparallel: True\r\npretrained_model: pretrained/pretrained/mobilenet_v1_imagenet.tar.gz\r\nresize_h: 300\r\nresize_w: 300\r\nuse_gpu: True\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py:69: Warning: The DetectionMAP is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.DetectionMAP instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\n*** Aborted at 1532680007 (unix time) try \"date -d @1532680007\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 19513 (TID 0x7f5e97a11740) from PID 0; stack trace: ***\r\n    @     0x7f5e9761a330 (unknown)\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)",
        "state": "open",
        "user": "wenxingsen",
        "closed_by": null,
        "created_at": "2018-07-27T08:29:46+00:00",
        "updated_at": "2019-08-11T07:43:15+00:00",
        "closed_at": null,
        "comments_count": [
            "wenxingsen",
            "fangzong12",
            "fangzong12",
            "wenxingsen",
            "fangzong12",
            "qingqing01",
            "huihuiustc"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1087,
        "title": "face_detection跑一段时间后出现nan",
        "body": "Pass 0, batch 4750, face loss 6.25504875183, head loss 5.29047966003, time 41.6653439999\r\nPass 0, batch 4760, face loss nan, head loss nan, time 42.216219902\r\nPass 0, batch 4770, face loss nan, head loss nan, time 42.0139110088\r\n\r\n\r\nface_detection跑一段时间后出现nan，这是为什么？",
        "state": "closed",
        "user": "rockstone533",
        "closed_by": "qingqing01",
        "created_at": "2018-07-31T05:24:42+00:00",
        "updated_at": "2018-09-29T08:08:50+00:00",
        "closed_at": "2018-09-29T08:08:50+00:00",
        "comments_count": [
            "YueXiNPU",
            "neverland0621",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1084,
        "title": "使用se_resnext训练时遇到问题，麻烦解答",
        "body": "训练集共近三万张图片，使用se_resnext网络训练过程中，遇到这个问题，\r\n![image](https://user-images.githubusercontent.com/26138842/43385064-59d3db0c-9412-11e8-9787-49c0bad0926f.png)\r\n是什么原因？此外之前用别的数据集别的网络的时候也经常遇到类似的貌似是说内存不够的问题？但数据集并不大，觉得很奇怪。\r\n![image](https://user-images.githubusercontent.com/26138842/43385166-9c2f10f2-9412-11e8-8817-089b7976b080.png)这是我们用的卡。\r\n",
        "state": "closed",
        "user": "jxingm",
        "closed_by": "luotao1",
        "created_at": "2018-07-30T08:07:23+00:00",
        "updated_at": "2018-07-31T03:07:56+00:00",
        "closed_at": "2018-07-31T03:07:56+00:00",
        "comments_count": [
            "yeyupiaoling",
            "jxingm",
            "yeyupiaoling",
            "jxingm",
            "luotao1",
            "yeyupiaoling",
            "jxingm",
            "luotao1",
            "yeyupiaoling"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1083,
        "title": "caffe2fluid报错Error encountered: Unknown layer type encountered: Crop",
        "body": "python convert.py imagenet_resnet_v1_50.prototxt --caffemodel imagenet_resnet_v1_50.caffemodel --data-output-path imagenet_resnet_v1_50.npy --\r\ncode-output-path imagenet_resnet_v1_50.py\r\n\r\n执行命令后报crop layer无法识别",
        "state": "open",
        "user": "iMuduo",
        "closed_by": null,
        "created_at": "2018-07-30T07:56:21+00:00",
        "updated_at": "2018-12-15T13:54:13+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "walloollaw",
            "Renwb1991",
            "nizihan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1088,
        "title": "You have error in image_classification/train.py",
        "body": "### error message\r\n```\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 236, in <module>\r\n    main()\r\n  File \"train.py\", line 232, in main\r\n    train(args)\r\n  File \"train.py\", line 160, in train\r\n    train_exe = fluid.ParallelExecutor(use_cuda=True, loss_name=avg_cost.name)\r\n  File \"/home/sfraczek/paddle/build/python/paddle/fluid/parallel_executor.py\", line 97, in __init__\r\n    for i in xrange(core.get_cuda_device_count()):\r\nAttributeError: 'module' object has no attribute 'get_cuda_device_count'\r\n```\r\n### the cause\r\nif use_gpu is False, you still pass use_cuda=True and cause the above error\r\n```\r\n    train_exe = fluid.ParallelExecutor(use_cuda=True, loss_name=avg_cost.name)\r\n```\r\n\r\n### additional note\r\nI compiled with `-DWITH_GPU=OFF`",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "luotao1",
        "created_at": "2018-07-31T09:03:13+00:00",
        "updated_at": "2018-08-01T01:10:09+00:00",
        "closed_at": "2018-08-01T01:10:09+00:00",
        "comments_count": [
            "luotao1",
            "sfraczek",
            "sfraczek",
            "luotao1"
        ],
        "labels": [
            "bug",
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1094,
        "title": "F0801 10:40:21.851949 61013 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537)",
        "body": "mpi跑一个任务的时候显示错误如下：\r\nWed Aug  1 10:40:16 2018[1,68]<stderr>:+ ./paddle_trainer --num_gradient_servers=80 --trainer_id=68 --pservers=10.73.88.48,10.73.87.27,10.73.87.28,10.73.87.33,10.73.87.35,10.73.87.38,10.73.87.39,10.73.87.40,10.73.87.42,10.73.87.44,10.73.87.47,10.73.87.50,10.73.87.51,10.73.87.53,10.73.87.55,10.73.88.11,10.73.88.13,10.73.88.17,10.73.88.24,10.73.88.25,10.73.88.31,10.73.88.35,10.73.88.37,10.73.88.38,10.73.88.40,10.73.88.41,10.73.88.47,10.73.87.26,10.73.88.50,10.73.88.51,10.73.88.52,10.73.88.53,10.73.88.54,10.73.90.11,10.73.90.12,10.73.90.13,10.73.90.14,10.73.62.52,10.73.90.19,10.73.90.20,10.73.62.51,10.73.62.48,10.73.91.41,10.73.91.43,10.73.91.44,10.73.91.45,10.73.91.46,10.73.91.47,10.73.91.48,10.73.98.15,10.73.98.16,10.73.98.17,10.73.98.22,10.73.98.26,10.73.98.50,10.73.99.33,10.73.99.36,10.73.99.37,10.73.99.39,10.73.99.48,10.75.51.11,10.75.51.12,10.75.51.13,10.75.51.14,10.75.51.16,10.75.51.19,10.75.51.20,10.75.52.38,10.75.54.13,10.75.54.14,10.75.54.39,10.75.54.41,10.75.54.43,10.75.54.46,10.75.54.49,10.75.55.11,10.75.55.12,10.75.55.13,10.75.55.22,10.75.55.36 --rdma_tcp=tcp --nics=xgbe0 --saving_period=1 --port=7164 --ports_num=1 --parallel_thread_num=50 --local=0 --comment=_job.742199.instances --dot_period=100000 --log_period=100000 --num_passes=20 --trainer_count=11 --enable_grad_share=0 --enable_grad_sparse_update=5000000 --use_sparse_updater=1 --use_old_updater=1 --show_parameter_stats_period=100000 --ports_num_for_sparse=1 --loadsave_parameters_in_pserver=0 --config=conf/trainer_config.conf --save_dir=./output --python_path=./python-gcc345 --python_bin=python2.7 --use_gpu=0\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:F0801 10:40:21.850185 61014 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rate\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:*** Check failure stack trace: ***\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:    @           0x8d7788  google::LogMessage::Fail()\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:    @           0x8d76e0  google::LogMessage::SendToLog()\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:    @           0x8d7175  google::LogMessage::Flush()\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:F0801 10:40:21.851949 61013 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rate\r\nWed Aug  1 10:40:21 2018[1,57]<stderr>:*** Check failure stack trace: ***\r\nWed Aug  1 10:40:21 2018[1,52]<stderr>:F0801 10:40:21.871891  8383 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rateF0801 10:40:21.872252  8387 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rate\r\nWed Aug  1 10:40:21 2018[1,52]<stderr>:*** Check failure stack trace: ***\r\nWed Aug  1 10:40:21 2018[1,68]<stderr>:F0801 10:40:21.867554 21665 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rate\r\nWed Aug  1 10:40:21 2018[1,52]<stderr>:F0801 10:40:21.871891  8385 SparseRowMatrix.h:134] Check failed: localIndices_->size() <= heightStore_ (1538 vs. 1537) You may consider increasing the value of --grad_sparse_update_max_sparse_rate\r\n\r\n请问这是什么原因导致的",
        "state": "open",
        "user": "know133",
        "closed_by": null,
        "created_at": "2018-08-01T05:17:40+00:00",
        "updated_at": "2018-08-01T05:17:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1089,
        "title": "You have error in image_classification/infer.py",
        "body": "### error message\r\n```\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 94, in <module>\r\n    main()\r\n  File \"infer.py\", line 90, in main\r\n    infer(args)\r\n  File \"infer.py\", line 68, in infer\r\n    test_reader = paddle.batch(reader.test(), batch_size=test_batch_size)\r\nTypeError: test() takes exactly 1 argument (0 given)\r\n```\r\n### cause\r\nThe test function takes 1 argument\r\nhttps://github.com/PaddlePaddle/models/blob/53937db0f1a29c90cd4e23c1198d34c81bfed1b2/fluid/image_classification/reader.py#L163\r\n### command\r\n```\r\npython infer.py --use_gpu 0  --batch_size 1\r\n```",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "luotao1",
        "created_at": "2018-07-31T10:03:04+00:00",
        "updated_at": "2018-08-01T01:10:09+00:00",
        "closed_at": "2018-08-01T01:10:09+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": [
            "bug",
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1097,
        "title": "PyramidAnchors in face_deteion  ",
        "body": "您好，看源码感觉每一层都设置了head，它的gt就是把face 的gt放大，分类label、priorbox和face的分类label、priorbox也都是一样的，感觉和paper里完全不一样啊",
        "state": "open",
        "user": "shz0519",
        "closed_by": null,
        "created_at": "2018-08-02T01:34:52+00:00",
        "updated_at": "2018-08-02T01:34:52+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1098,
        "title": "现在有支持paddle v22fluid的工具么？",
        "body": "",
        "state": "open",
        "user": "iMuduo",
        "closed_by": null,
        "created_at": "2018-08-02T05:41:35+00:00",
        "updated_at": "2018-08-02T05:42:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1099,
        "title": "cannot get deep_fm data",
        "body": "wget --no-check-certificate https://s3-eu-west-1.amazonaws.com/criteo-labs/dac.tar.gz\r\n\r\nConnecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.65.20|:443... connected.\r\nHTTP request sent, awaiting response... 403 Forbidden\r\n2018-08-03 18:08:32 ERROR 403: Forbidden.\r\n\r\n\r\n\r\nand i can't open https://s3-eu-west-1.amazonaws.com/criteo-labs/dac.tar.gz on my browser either.\r\n",
        "state": "open",
        "user": "martin6336",
        "closed_by": null,
        "created_at": "2018-08-03T10:09:57+00:00",
        "updated_at": "2018-08-03T10:09:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1101,
        "title": "Use paddlepaddle to do metric learning",
        "body": "",
        "state": "closed",
        "user": "BigFishMaster",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-08-06T04:01:13+00:00",
        "updated_at": "2018-08-29T03:21:44+00:00",
        "closed_at": "2018-08-29T03:21:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1132,
        "title": "一次预测多张图片",
        "body": " models/fluid/object_detection/infer.py\r\n目标检测mobilenet_ssd\r\ninfer.py一次只能输入一张图片\r\n怎么才能批量处理图片",
        "state": "closed",
        "user": "cjxb-hy",
        "closed_by": "cjxb-hy",
        "created_at": "2018-08-10T09:45:53+00:00",
        "updated_at": "2018-08-11T06:53:14+00:00",
        "closed_at": "2018-08-11T06:53:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1100,
        "title": "vgg_model.tar.gz link is not valid!",
        "body": "http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz\r\n赶紧修复吧..",
        "state": "closed",
        "user": "greathope",
        "closed_by": "greathope",
        "created_at": "2018-08-03T11:37:20+00:00",
        "updated_at": "2018-08-15T01:52:31+00:00",
        "closed_at": "2018-08-15T01:52:31+00:00",
        "comments_count": [
            "greathope"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1107,
        "title": "修改object_detection模型 在多机下运行，报错",
        "body": "paddle version 0.14\r\n模型：MobileNet-SSD\r\n代码库地址：https://github.com/PaddlePaddle/models/tree/develop/fluid/object_detection\r\n作业运行配置：\r\n2个pserver，4个trainer，每个trainer单卡\r\n启动脚本:\r\n```bash\r\nFLAGS_rpc_deadline=3000000 python -u thirdparty/train_dist.py --batch_size=64 --dataset='pascalvoc' --data_dir='./thirdparty/data/pascalvoc' --pretrained_model='./thirdparty/pretrained/ssd_mobilenet_v1_coco/' --num_passes=1 --update_method=pserver --async_mode=False --for_model_ce=True --iterations=20\r\n```\r\n**修改train.py 文件如下：**\r\n```bash\r\n\r\nadd_arg('update_method', str, 'local', 'Choose parameter update method')\r\nadd_arg('async_mode', bool, False, \"Whether start pserver in async mode to support ASGD\")\r\ndef dist_transpile(trainer_id, args):\r\n    if trainer_id < 0:\r\n        return None, None\r\n\r\n    # the port of all pservers, needed by both trainer and pserver\r\n    port = os.getenv(\"PADDLE_PORT\", \"6174\")\r\n    # comma separated ips of all pservers, needed by trainer and\r\n    # pserver\r\n    pserver_ips = os.getenv(\"PADDLE_PSERVERS\", \"\")\r\n    eplist = []\r\n    for ip in pserver_ips.split(\",\"):\r\n        eplist.append(':'.join([ip, port]))\r\n    pserver_endpoints = \",\".join(eplist)\r\n    # total number of workers/trainers in the job, needed by\r\n    # trainer and pserver\r\n    trainers = int(os.getenv(\"TRAINERS\"))\r\n    # the IP of the local machine, needed by pserver only\r\n    current_endpoint = os.getenv(\"POD_IP\", \"\") + \":\" + port\r\n    # the role, should be either PSERVER or TRAINER\r\n    training_role = os.getenv(\"TRAINING_ROLE\")\r\n\r\n    t = distribute_transpiler.DistributeTranspiler()\r\n    t.transpile(trainer_id, pservers=pserver_endpoints, trainers=trainers\r\n            ,sync_mode=not args.async_mode)\r\n    if training_role == \"PSERVER\":\r\n        pserver_program = t.get_pserver_program(current_endpoint)\r\n        pserver_startup_program = t.get_startup_program(current_endpoint,\r\n                                                        pserver_program)\r\n        return pserver_program, pserver_startup_program\r\n    elif training_role == \"TRAINER\":\r\n        train_program = t.get_trainer_program()\r\n        return train_program, fluid.default_startup_program()\r\n    else:\r\n        raise ValueError(\r\n            'TRAINING_ROLE environment variable must be either TRAINER or PSERVER'\r\n        )\r\n\r\ndef train(args,\r\n          train_file_list,\r\n          val_file_list,\r\n          data_args,\r\n          learning_rate,\r\n          batch_size,\r\n          num_passes,\r\n          model_save_dir,\r\n          pretrained_model=None):\r\n    image_shape = [3, data_args.resize_h, data_args.resize_w]\r\n    if 'coco' in data_args.dataset:\r\n        num_classes = 91\r\n    elif 'pascalvoc' in data_args.dataset:\r\n        num_classes = 21\r\n    \r\n    training_role = os.getenv(\"TRAINING_ROLE\", \"TRAINER\")\r\n    if training_role == \"PSERVER\" or (not args.use_gpu):\r\n        place = fluid.CPUPlace()\r\n        devices_num = int(os.environ.get('CPU_NUM', multiprocessing.cpu_count()))\r\n    else:\r\n        place = fluid.CUDAPlace(0)\r\n        devices_num = fluid.core.get_cuda_device_count()\r\n\r\n    image = fluid.layers.data(name='image', shape=image_shape, dtype='float32')\r\n    gt_box = fluid.layers.data(\r\n        name='gt_box', shape=[4], dtype='float32', lod_level=1)\r\n    gt_label = fluid.layers.data(\r\n        name='gt_label', shape=[1], dtype='int32', lod_level=1)\r\n    difficult = fluid.layers.data(\r\n        name='gt_difficult', shape=[1], dtype='int32', lod_level=1)\r\n\r\n    locs, confs, box, box_var = mobile_net(num_classes, image, image_shape)\r\n    nmsed_out = fluid.layers.detection_output(\r\n        locs, confs, box, box_var, nms_threshold=args.nms_threshold)\r\n    loss = fluid.layers.ssd_loss(locs, confs, gt_box, gt_label, box,\r\n                                 box_var)\r\n    loss = fluid.layers.reduce_sum(loss)\r\n\r\n    test_program = fluid.default_main_program().clone(for_test=True)\r\n    with fluid.program_guard(test_program):\r\n        map_eval = fluid.evaluator.DetectionMAP(\r\n            nmsed_out,\r\n            gt_label,\r\n            gt_box,\r\n            difficult,\r\n            num_classes,\r\n            overlap_threshold=0.5,\r\n            evaluate_difficult=False,\r\n            ap_version=args.ap_version)\r\n\r\n    if 'coco' in data_args.dataset:\r\n        # learning rate decay in 12, 19 pass, respectively\r\n        if '2014' in train_file_list:\r\n            epocs = 82783 / batch_size\r\n            boundaries = [epocs * 12, epocs * 19]\r\n        elif '2017' in train_file_list:\r\n            epocs = 118287 / batch_size\r\n            boundaries = [epocs * 12, epocs * 19]\r\n        values = [\r\n            learning_rate, learning_rate * 0.5, learning_rate * 0.25\r\n        ]\r\n    elif 'pascalvoc' in data_args.dataset:\r\n        epocs = 19200 / batch_size\r\n        boundaries = [epocs * 40, epocs * 60, epocs * 80, epocs * 100]\r\n        values = [\r\n            learning_rate, learning_rate * 0.5, learning_rate * 0.25,\r\n            learning_rate * 0.1, learning_rate * 0.01\r\n        ]\r\n    optimizer = fluid.optimizer.RMSProp(\r\n        learning_rate=fluid.layers.piecewise_decay(boundaries, values),\r\n        regularization=fluid.regularizer.L2Decay(0.00005), )\r\n\r\n    optimizer.minimize(loss)\r\n    nccl_id_var, num_trainers, trainer_id = (\r\n        None, 1, int(os.getenv(\"PADDLE_TRAINER_ID\", \"0\")))\r\n    if args.update_method == \"pserver\":\r\n        train_prog, startup_prog = dist_transpile(trainer_id, args)\r\n        if not train_prog:\r\n            raise Exception(\r\n                \"Must configure correct environments to run dist train.\")\r\n        if os.getenv(\"TRAINING_ROLE\") == \"PSERVER\":\r\n            place = core.CPUPlace()\r\n            exe = fluid.Executor(place)\r\n            exe.run(startup_prog)\r\n            exe.run(train_prog)\r\n            return\r\n    elif args.update_method == \"nccl2\":\r\n        train_prog = fluid.default_main_program()\r\n        startup_prog = fluid.default_startup_program()\r\n        nccl_id_var, num_trainers, trainer_id = append_nccl2_prepare(trainer_id)\r\n    else:\r\n        train_prog = fluid.default_main_program()\r\n        startup_prog = fluid.default_startup_program()\r\n    place = fluid.CUDAPlace(0) if args.use_gpu else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    exe.run(startup_prog)\r\n    strategy = fluid.ExecutionStrategy()\r\n    strategy.use_cuda = args.use_gpu\r\n     ...................\r\n\r\nif __name__ == '__main__':\r\n    args = parser.parse_args()\r\n    print_arguments(args)\r\n\r\n    data_dir = args.data_dir\r\n    label_file = 'label_list'\r\n    model_save_dir = args.model_save_dir\r\n    train_file_list = 'trainval.txt'\r\n    val_file_list = 'test.txt'\r\n    if 'coco' in args.dataset:\r\n        data_dir = 'data/coco'\r\n        if '2014' in args.dataset:\r\n            train_file_list = 'annotations/instances_train2014.json'\r\n            val_file_list = 'annotations/instances_val2014.json'\r\n        elif '2017' in args.dataset:\r\n            train_file_list = 'annotations/instances_train2017.json'\r\n            val_file_list = 'annotations/instances_val2017.json'\r\n\r\n    data_args = reader.Settings(\r\n        dataset=args.dataset,\r\n        data_dir=data_dir,\r\n        label_file=label_file,\r\n        resize_h=args.resize_h,\r\n        resize_w=args.resize_w,\r\n        mean_value=[args.mean_value_B, args.mean_value_G, args.mean_value_R],\r\n        apply_distort=args.apply_distort,\r\n        apply_expand=args.apply_expand,\r\n        ap_version = args.ap_version,\r\n        toy=args.is_toy)\r\n    train(\r\n        args,\r\n        train_file_list=train_file_list,\r\n        val_file_list=val_file_list,\r\n        data_args=data_args,\r\n        learning_rate=args.learning_rate,\r\n        batch_size=args.batch_size,\r\n        num_passes=args.num_passes,\r\n        model_save_dir=model_save_dir,\r\n        pretrained_model=args.pretrained_model)\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "typhoonzero",
        "created_at": "2018-08-07T13:52:03+00:00",
        "updated_at": "2018-08-14T05:18:28+00:00",
        "closed_at": "2018-08-14T05:18:28+00:00",
        "comments_count": [
            "ccmeteorljh",
            "typhoonzero",
            "ccmeteorljh",
            "typhoonzero",
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1134,
        "title": "models/fluid/chinese_ner/infer.py  用测程序不能正确运行",
        "body": "报错模块：models/fluid/chinese_ner/infer.py\r\n代码变更：train.py程序训练使用的是显卡，修改为使用CPU训练。\r\n程序运行环境：docker paddle\r\n执行步骤: 执行python train.py 后 output产生模型文件。\r\n报错步骤:执行python inferr.py 文件报错。\r\n报错信息:\r\n```\r\nFile \"infer.py\", line 64, in <module>\r\n    target_file=\"data/label_dict\")\r\n  File \"infer.py\", line 39, in infer\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 463, in run\r\n    fetch_var_name=fetch_var_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 310, in _add_feed_fetch_ops\r\n    if not has_feed_operators(global_block, feed, feed_var_name):\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 129, in has_feed_operators\r\n    \"Feed operators in program desc do not match 'feed_targets'\")\r\nException: Feed operators in program desc do not match 'feed_targets'\r\n```\r\n报错位置：\r\n```\r\n            crf_decode = exe.run(inference_program,\r\n                                 feed=feeder.feed(data),\r\n                                 fetch_list=fetch_targets,\r\n                                 return_numpy=False)\r\n```\r\n\r\n",
        "state": "open",
        "user": "wanbiguizhao",
        "closed_by": null,
        "created_at": "2018-08-12T11:30:46+00:00",
        "updated_at": "2018-08-12T11:30:46+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1148,
        "title": "ssd detector  got stuck when training",
        "body": "I use this paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7  docker images, and create my own coco-style dataset, but when training starts, it is stuck...  can anyone help me?",
        "state": "closed",
        "user": "greathope",
        "closed_by": "greathope",
        "created_at": "2018-08-14T13:24:59+00:00",
        "updated_at": "2018-08-15T01:52:22+00:00",
        "closed_at": "2018-08-15T01:52:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1152,
        "title": "CNN的CPU代码优化在哪里可以修改",
        "body": "如题",
        "state": "open",
        "user": "chenbblei",
        "closed_by": null,
        "created_at": "2018-08-16T06:41:47+00:00",
        "updated_at": "2018-08-16T06:41:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1140,
        "title": "Port models' code to Python3",
        "body": "According to the discussion in [PaddlePaddle issues](https://github.com/PaddlePaddle/Paddle/issues/12040), we should port current code in models to Python3",
        "state": "closed",
        "user": "velconia",
        "closed_by": "velconia",
        "created_at": "2018-08-13T11:21:03+00:00",
        "updated_at": "2018-09-28T06:39:20+00:00",
        "closed_at": "2018-09-28T06:39:20+00:00",
        "comments_count": [
            "velconia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1135,
        "title": "AI-shell_testdata_test.scp_wav_00000.compact.label和AI-shell_testdata_test.scp_wav_00000.compact.label_desc的格式能解释下么",
        "body": "0 2000 2\r\nBAC009S0770W0363 0 80 2784 696 1\r\nBAC009S0770W0174 0 3024 1980 495 1\r\nBAC009S0770W0320 0 5164 2948 737 1\r\nBAC009S0770W0304 0 8272 2804 701 1\r\nBAC009S0770W0348 0 11236 1412 353 1\r\nBAC009S0770W0185 0 12808 3144 786 1\r\nBAC009S0770W0162 0 16112 1988 497 1\r\nBAC009S0770W0159 0 18260 1700 425 1\r\nBAC009S0770W0337 0 20120 3620 905 1\r\nBAC009S0770W0345 0 23900 2496 624 1\r\nBAC009S0770W0164 0 26556 3480 870 1\r\n\r\n请问这个格式表示什么，每一个列表示什么意思",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-08-13T03:40:39+00:00",
        "updated_at": "2018-08-14T06:11:30+00:00",
        "closed_at": "2018-08-14T06:11:30+00:00",
        "comments_count": [
            "luotao1",
            "kuke",
            "pengeorge",
            "chenbblei",
            "chenbblei",
            "chenbblei",
            "pengeorge",
            "chenbblei"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1144,
        "title": "能支持局部参数更新么",
        "body": "我想做个自适应模型，能否做到前面基层参数不更新，只更新后面几层的呢",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-08-14T01:55:39+00:00",
        "updated_at": "2018-08-14T02:45:02+00:00",
        "closed_at": "2018-08-14T02:45:02+00:00",
        "comments_count": [
            "oraoto",
            "chenbblei",
            "oraoto",
            "chenbblei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1156,
        "title": "Floating point exception (core dumped)",
        "body": "今天尝试使用在PASCAL VOC数据集上使用paddle的ssd模型https://github.com/PaddlePaddle/models/tree/develop/ssd， 使用···data/prepare_voc_data.py···分割训练数据集后，运行···train.py···可以成功加载网络结构，初始化参数后程序在执行函数 paddle.trainer.SGD.train()时出现异常，显示：Floating point exception (core dumped)\r\n\r\n![image](https://user-images.githubusercontent.com/35247113/44207026-45023280-a18e-11e8-9c5c-00b1ee3c35e1.png)\r\n\r\n",
        "state": "open",
        "user": "SUYEgit",
        "closed_by": null,
        "created_at": "2018-08-16T11:55:16+00:00",
        "updated_at": "2018-08-16T11:55:16+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1162,
        "title": "models CE kpis ",
        "body": "\r\n模型 | 指标打开情况 | 说明\r\n-- | -- | --\r\nmnist  郭超容 | train_acc_kpi,         train_cost_kpi,         test_acc_kpi,         train_duration_kpi, | 列出的都打开了\r\nobject_detection  一帆 | train_cost_kpi,       test_acc_kpi,       train_speed_kpi,       train_cost_card4_kpi,       test_acc_card4_kpi,       train_speed_card4_kpi, | train_speed_kpi  未打卡   train_speed_card4_kpi 未打开\r\nimage_classification    一帆（代青青） | train_acc_top1_kpi,   train_acc_top5_kpi, train_cost_kpi, test_acc_top1_kpi,   test_acc_top5_kpi,   test_cost_kpi, train_speed_kpi, train_acc_top1_card4_kpi,   train_acc_top5_card4_kpi,   train_cost_card4_kpi, test_acc_top1_card4_kpi,   test_acc_top5_card4_kpi,   test_cost_card4_kpi, train_speed_card4_kpi | 打开了train_cost_card4_kpi\r\nocr_recognition 豪爽 | train_acc_kpi,         train_cost_kpi,         test_acc_kpi,         train_duration_kpi, | 都打开了\r\nicnet  豪爽 | train_cost_kpi,         train_duration_kpi, | 都打开了\r\nseq2seq    青晟 | train_cost_kpi,         test_cost_kpi,         train_duration_kpi, | 都打开了\r\nlanguage_model  超容 | imikolov_20_avg_ppl_kpi,         imikolov_20_pass_duration_kpi,     imikolov_20_avg_ppl_kpi_card4,         imikolov_20_pass_duration_kpi_card4, | 打开了   imikolov_20_pass_duration_kpi,   imikolov_20_pass_duration_kpi_card4,\r\ntransformer   郭晟 | train_cost_card1_kpi,         test_cost_card1_kpi,         train_duration_card1_kpi,         train_cost_card4_kpi,         test_cost_card4_kpi,         train_duration_card4_kpi, | 都打开了\r\nsequence_tagging_for_ner      毅冰 | train_acc_kpi,         test_acc_kpi,         train_duration_kpi, | 都打开了\r\ntext_classification   毅冰 | train_acc_kpi,         train_cost_kpi,         train_duration_kpi, | train_cost_kpi未打开\r\n\r\n",
        "state": "closed",
        "user": "guochaorong",
        "closed_by": "kolinwei",
        "created_at": "2018-08-17T04:08:56+00:00",
        "updated_at": "2019-05-10T09:46:32+00:00",
        "closed_at": "2019-05-10T09:46:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1154,
        "title": "I CANOT download the ssd model.",
        "body": "I CANOT download the ssd model.\r\nThe pretrained model link is http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz.\r\n\r\nThe SSD page link is https://github.com/PaddlePaddle/models/tree/develop/ssd",
        "state": "closed",
        "user": "wenyawei",
        "closed_by": "qingqing01",
        "created_at": "2018-08-16T08:58:57+00:00",
        "updated_at": "2018-10-30T08:43:39+00:00",
        "closed_at": "2018-10-30T08:43:39+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1168,
        "title": "如何打印出beam_search的每一步的输出过程",
        "body": "如题",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-08-18T03:51:51+00:00",
        "updated_at": "2018-08-23T03:17:51+00:00",
        "closed_at": "2018-08-23T03:17:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1164,
        "title": "fluid.io.load_inference_model 载入多个模型的时候会报错Error Occurs, info:enforce version == 0U failed, 1015534361 != 0 Only version 0 is supported ",
        "body": "我们有多个模型，需要做通用inference，需要载入多个模型\r\n如果只load任意一个模型都是ok的\r\n但如果load一个模型后，load另一个模型，如果其中一个模型用到lod_tensor，就会报错。\r\n函数代码如下：\r\n        place = fluid.CPUPlace()\r\n        exe = fluid.Executor(place)\r\n        [inference_program, _, fetch_targets] = (\r\n            fluid.io.load_inference_model(dirname=model_path[0], executor=exe,\r\n                                          model_filename=model_path[1],\r\n                                          params_filename=params_path[1]))\r\n\r\n\r\n错误如下：\r\nError Occurs, info:enforce version == 0U failed, 1015534361 != 0\r\nOnly version 0 is supported at [/paddle/paddle/fluid/framework/lod_tensor.cc:276]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f3e15df5376p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f3e16652872p paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 1330\r\n2       0x7f3e1645fe7ap paddle::operators::LoadCombineOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 778\r\n3       0x7f3e1660e450p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 208\r\n4       0x7f3e15e88cdfp paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 255\r\n5       0x7f3e15e89d30p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n6       0x7f3e15e0bfabp void pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::cpp_function::initialize<void, paddle::framework::Executor, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool)#1}&&, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 555\r\n7       0x7f3e15e0446cp pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2540\r\n8       0x7f3efe641fc7p PyEval_EvalFrameEx + 28695\r\n9       0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n10      0x7f3efe6419b8p PyEval_EvalFrameEx + 27144\r\n11      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n12      0x7f3efe6419b8p PyEval_EvalFrameEx + 27144\r\n13      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n14      0x7f3efe6419b8p PyEval_EvalFrameEx + 27144\r\n15      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n16      0x7f3efe6419b8p PyEval_EvalFrameEx + 27144\r\n17      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n18      0x7f3efe6419b8p PyEval_EvalFrameEx + 27144\r\n19      0x7f3efe642f9ep PyEval_EvalFrameEx + 32750\r\n20      0x7f3efe642f9ep PyEval_EvalFrameEx + 32750\r\n21      0x7f3efe642f9ep PyEval_EvalFrameEx + 32750\r\n22      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n23      0x7f3efe5cd377p\r\n24      0x7f3efe5a87a3p PyObject_Call + 67\r\n25      0x7f3efe63d4bep PyEval_EvalFrameEx + 9486\r\n26      0x7f3efe642f9ep PyEval_EvalFrameEx + 32750\r\n27      0x7f3efe642f9ep PyEval_EvalFrameEx + 32750\r\n28      0x7f3efe6444e9p PyEval_EvalCodeEx + 2025\r\n29      0x7f3efe5cd28ap\r\n30      0x7f3efe5a87a3p PyObject_Call + 67\r\n31      0x7f3efe5b763dp\r\n32      0x7f3efe5a87a3p PyObject_Call + 67\r\n33      0x7f3efe63aa58p PyEval_CallObjectWithKeywords + 72\r\n34      0x7f3efe673f36p\r\n35      0x7f3efe34be25p\r\n36      0x7f3efd96cbadp clone + 109",
        "state": "open",
        "user": "zyfo2",
        "closed_by": null,
        "created_at": "2018-08-17T07:19:28+00:00",
        "updated_at": "2021-03-02T01:52:13+00:00",
        "closed_at": null,
        "comments_count": [
            "zyfo2",
            "1138886114"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1171,
        "title": "训练自己的数据时，修改了检测的类别数，载入在VOC上预训练的VGG模型时出错",
        "body": "Traceback (most recent call last):\r\n  File \"train.py\", line 83, in <module>\r\n    init_model_path='vgg_model.tar.gz')\r\n  File \"train.py\", line 25, in train\r\n    parameters.init_from_tar(gzip.open(init_model_path))\r\n  File \"/home/liujh/.conda/envs/pd/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 402, in init_from_tar\r\n    self.set(pname, tar_param.get(pname))\r\n  File \"/home/liujh/.conda/envs/pd/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 270, in set\r\n    self.__setitem__(key=parameter_name, value=value)\r\n  File \"/home/liujh/.conda/envs/pd/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 223, in __setitem__\r\n    (shape, value.shape))\r\nValueError: Value shape mismatch, expect (1, 27648), should (1, 290304)\r\n\r\n",
        "state": "closed",
        "user": "Johumliu",
        "closed_by": "Johumliu",
        "created_at": "2018-08-20T06:27:18+00:00",
        "updated_at": "2018-08-20T09:25:44+00:00",
        "closed_at": "2018-08-20T09:25:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1167,
        "title": "beam_search这个函数现在可以返回最佳路径对应的每个lable的所有概率了么",
        "body": "如题",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-08-18T03:43:05+00:00",
        "updated_at": "2018-08-23T03:17:58+00:00",
        "closed_at": "2018-08-23T03:17:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1186,
        "title": "caffe2fluid 现在支持depthwise conv?",
        "body": "1. caffe2fluid 支持 depthwise conv？ 如果不支持，需要怎样支持 depthwise conv?\r\n2. caffe2fluid 支持 group conv ?",
        "state": "open",
        "user": "youngstu",
        "closed_by": null,
        "created_at": "2018-08-24T13:50:13+00:00",
        "updated_at": "2018-08-24T13:50:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1194,
        "title": "caffe2fluid priorbox layer bug?",
        "body": "",
        "state": "closed",
        "user": "youngstu",
        "closed_by": "youngstu",
        "created_at": "2018-08-27T07:03:31+00:00",
        "updated_at": "2018-08-27T07:41:09+00:00",
        "closed_at": "2018-08-27T07:40:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1179,
        "title": "Train error about ParamidBox",
        "body": "I use \r\n`pip install paddlepaddle-gpu==0.14.0.post85` \r\nto install paddlepaddle.\r\nWhen I run train.py\r\n\r\n> Traceback (most recent call last):\r\n>   File \"train.py\", line 178, in <module>\r\n>     train(args, config, train_file_list, optimizer_method=\"momentum\")\r\n>   File \"train.py\", line 52, in train\r\n>     sub_network=use_pyramidbox)\r\n>   File \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 76, in __init__\r\n>     self._pyramidbox()\r\n>   File \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 243, in _pyramidbox\r\n>     face_loc = permute_and_reshape(face_loc, 4)\r\n>   File \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 227, in permute_and_reshape\r\n>     np.array([0, -1, last_dim]).astype(\"int32\"))\r\n> TypeError: assign() takes exactly 2 arguments (1 given)\r\n\r\nBut, I alter \r\n`            run_shape = fluid.layers.assign(\r\n                np.array([0, -1, last_dim]).astype(\"int32\"))\r\n`\r\nto\r\n`           run_shape = fluid.layers.create_tensor(dtype='int32')`\r\n`            fluid.layers.assign(\r\n                np.array([0, -1, last_dim]).astype(\"int32\"),run_shape)\r\n`\r\n\r\nrun error is:\r\n> Traceback (most recent call last):\r\n>   File \"train.py\", line 178, in <module>\r\n>     train(args, config, train_file_list, optimizer_method=\"momentum\")\r\n>   File \"train.py\", line 81, in train\r\n>     optimizer.minimize(loss)\r\n>   File \"/home/daguo/anaconda2/envs/paddle-py27/lib/python2.7/site-packages/paddle/fluid/optimizer.py\", line 255, in minimize\r\n>     [error_clip_callback])\r\n>   File \"/home/daguo/anaconda2/envs/paddle-py27/lib/python2.7/site-packages/paddle/fluid/backward.py\", line 549, in append_backward\r\n>     grad_to_var, callbacks)\r\n>   File \"/home/daguo/anaconda2/envs/paddle-py27/lib/python2.7/site-packages/paddle/fluid/backward.py\", line 334, in _append_backward_ops_\r\n>     op.desc, no_grad_dict[block.idx], grad_sub_block_list)\r\n> paddle.fluid.core.EnforceNotMet: grad_op_maker_ should not be null\r\n> Operator GradOpMaker has not been registered. at [/paddle/paddle/fluid/framework/op_info.h:61]\r\n> PaddlePaddle Call Stacks: \r\n> 0       0x7fd0da959736p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n> 1       0x7fd0da95bfe9p paddle::framework::OpInfo::GradOpMaker() const + 137\r\n> 2       0x7fd0da955222p\r\n> 3       0x7fd0da969604p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n> 4       0x7fd1cf7122a3p PyEval_EvalFrameEx + 23091\r\n> 5       0x7fd1cf713dbep PyEval_EvalCodeEx + 2190\r\n> 6       0x7fd1cf7123fap PyEval_EvalFrameEx + 23434\r\n> 7       0x7fd1cf713dbep PyEval_EvalCodeEx + 2190\r\n> 8       0x7fd1cf7123fap PyEval_EvalFrameEx + 23434\r\n> 9       0x7fd1cf713dbep PyEval_EvalCodeEx + 2190\r\n> 10      0x7fd1cf7123fap PyEval_EvalFrameEx + 23434\r\n> 11      0x7fd1cf713dbep PyEval_EvalCodeEx + 2190\r\n> 12      0x7fd1cf7123fap PyEval_EvalFrameEx + 23434\r\n> 13      0x7fd1cf713dbep PyEval_EvalCodeEx + 2190\r\n> 14      0x7fd1cf713ed2p PyEval_EvalCode + 50\r\n> 15      0x7fd1cf733e10p PyRun_FileExFlags + 176\r\n> 16      0x7fd1cf733fefp PyRun_SimpleFileExFlags + 239\r\n> 17      0x7fd1cf7498f4p Py_Main + 3236\r\n> 18      0x7fd1ce947f45p __libc_start_main + 245\r\n> 19            0x400649p\r\n\r\nHow to solve this problem?",
        "state": "closed",
        "user": "DaleAG",
        "closed_by": "qingqing01",
        "created_at": "2018-08-21T07:34:39+00:00",
        "updated_at": "2018-09-29T07:57:17+00:00",
        "closed_at": "2018-09-29T07:57:17+00:00",
        "comments_count": [
            "ktlichkid",
            "hdjsjyl",
            "hdjsjyl",
            "hdjsjyl",
            "hdjsjyl",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1176,
        "title": "Chinese Ner inference profiling appears linear_chain_crf_grad op",
        "body": "When I downloaded the latest models and ran the train.sh , infer.sh in fluid/chinese_ner/scripts folder, I got the following profiling results:\r\n![image](https://user-images.githubusercontent.com/33643817/44344485-61baa500-a4c3-11e8-97b9-9961e984874a.png)\r\nlinear_chain_crf_grad op should not appear in the inference program. In fact, in the train.py script, it saved \"target\"  as the feed data with    \r\n` fluid.io.save_inference_model(save_dirname, ['word', 'mention', 'target'], [crf_decode], exe)`\r\nand load models in inference with\r\n`feeder = fluid.DataFeeder(feed_list=[word, mention, target], place=place)`\r\nwhich doesn't make sense to load label data while doing the inference. \r\nAfter I modified the infer.py ,train.py and let it neither save nor load \"target\", I got the following profiling results:\r\n![image](https://user-images.githubusercontent.com/33643817/44345112-fb368680-a4c4-11e8-9d77-cfd0f1f7657d.png)\r\n\r\nwhich seems correct.\r\n\r\n\r\n",
        "state": "closed",
        "user": "bingyanghuang",
        "closed_by": "Sand3r-",
        "created_at": "2018-08-20T14:07:53+00:00",
        "updated_at": "2018-08-29T20:36:38+00:00",
        "closed_at": "2018-08-29T20:36:38+00:00",
        "comments_count": [
            "Sand3r-"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1182,
        "title": "program为什么一定要用clone，还必须指定for_test=True?",
        "body": "在infer.py中进行验证，如果改为用test_program = fluid.default_main_program()，来做program，那么好像模型参数并没有读取回来，测试结果都不正确。如只去掉for_test参数，结果也是不正确。\r\n请教原因？\r\n执行fluid.io.load_vars(exe, pretrained_model, predicate=if_exist)是否已经把模型参数重载到fluid.default_main_program()中了？\r\n谢谢\r\n",
        "state": "open",
        "user": "Tristan-Hao",
        "closed_by": null,
        "created_at": "2018-08-22T06:29:35+00:00",
        "updated_at": "2018-09-02T01:47:49+00:00",
        "closed_at": null,
        "comments_count": [
            "ChuRao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1207,
        "title": "Installing paddle for CUDA9 and face detection errors",
        "body": "I use\r\npip install paddlepaddle-gpu for CUDA9 to install paddlepaddle.  But it shows I have installed paddlepaddle-gpu 1.14.0post87, which is for CUDA8, why it happens?\r\nWhen I run train.py\r\n\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 178, in \r\ntrain(args, config, train_file_list, optimizer_method=\"momentum\")\r\nFile \"train.py\", line 52, in train\r\nsub_network=use_pyramidbox)\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 76, in init\r\nself._pyramidbox()\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 243, in _pyramidbox\r\nface_loc = permute_and_reshape(face_loc, 4)\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 227, in permute_and_reshape\r\nnp.array([0, -1, last_dim]).astype(\"int32\"))\r\nTypeError: assign() takes exactly 2 arguments (1 given)",
        "state": "open",
        "user": "hdjsjyl",
        "closed_by": null,
        "created_at": "2018-08-29T18:39:07+00:00",
        "updated_at": "2018-08-29T18:39:07+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1199,
        "title": "will you support CPU training of Transformer?",
        "body": "https://github.com/PaddlePaddle/models/blob/ff63e48f5dd71143d7108198e71a61cdaa0895d9/fluid/neural_machine_translation/transformer/config.py#L2",
        "state": "closed",
        "user": "sfraczek",
        "closed_by": "luotao1",
        "created_at": "2018-08-28T09:42:40+00:00",
        "updated_at": "2018-08-29T06:36:01+00:00",
        "closed_at": "2018-08-29T06:36:01+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1203,
        "title": "resnet101 pretrained model?",
        "body": "I only found the pretrained model for resnet50, do you have resnet101 pretrained model available?",
        "state": "closed",
        "user": "xialeiliu",
        "closed_by": "xialeiliu",
        "created_at": "2018-08-29T06:24:54+00:00",
        "updated_at": "2018-09-03T17:07:14+00:00",
        "closed_at": "2018-09-03T17:07:14+00:00",
        "comments_count": [
            "qingqing01",
            "xialeiliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1209,
        "title": "Docker: paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7, it works in my computer, but when I install \"pip install paddlepaddle-gpu\", it does not work in my computer.",
        "body": "Docker: paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7, it works in my computer, but when I install \"pip install paddlepaddle-gpu\", it does not work in my computer. It shows the following error:\r\n\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 178, in\r\ntrain(args, config, train_file_list, optimizer_method=\"momentum\")\r\nFile \"train.py\", line 52, in train\r\nsub_network=use_pyramidbox)\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 76, in init\r\nself._pyramidbox()\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 243, in _pyramidbox\r\nface_loc = permute_and_reshape(face_loc, 4)\r\nFile \"/home/daguo/code/PaddlePaddle_models/fluid/face_detection/pyramidbox.py\", line 227, in permute_and_reshape\r\nnp.array([0, -1, last_dim]).astype(\"int32\"))\r\nTypeError: assign() takes exactly 2 arguments (1 given)",
        "state": "open",
        "user": "hdjsjyl",
        "closed_by": null,
        "created_at": "2018-08-29T23:50:13+00:00",
        "updated_at": "2018-08-29T23:50:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1234,
        "title": " 训练时向网络feed图像、标签、一维向量时出错",
        "body": "参考了fluid/icnet中的样例代码改写的：\r\n\r\n这里的图像shape为 [3, 256, 256]，label 的shape为 [1]，另一个 label 的 shape 为 [58]\r\n\r\n``` python\r\n...\r\nimages_t = fluid.LoDTensor()\r\nfeature_t = fluid.LoDTensor()\r\nlabel_t = fluid.LoDTensor()\r\n...\r\n        for batch_id, data in enumerate(train_reader()):\r\n            images = data[0]\r\n            labels = data[1]\r\n            locals = data[2]\r\n            images_t.set(images, place)\r\n            labels_t.set(labels, place)\r\n            locals_t.set(locals, place)\r\n...\r\n```\r\n报错如下：\r\n```\r\n    images_t.set(images, place)\r\nTypeError: set(): incompatible function arguments. The following argument types are supported:\r\n    1. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float32], arg1: paddle::platform::CPUPlace) -> None\r\n    2. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int32], arg1: paddle::platform::CPUPlace) -> None\r\n    3. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float64], arg1: paddle::platform::CPUPlace) -> None\r\n    4. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int64], arg1: paddle::platform::CPUPlace) -> None\r\n    5. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[bool], arg1: paddle::platform::CPUPlace) -> None\r\n    6. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint16], arg1: paddle::platform::CPUPlace) -> None\r\n    7. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint8], arg1: paddle::platform::CPUPlace) -> None\r\n    8. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float32], arg1: paddle::platform::CUDAPlace) -> None\r\n    9. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int32], arg1: paddle::platform::CUDAPlace) -> None\r\n    10. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float64], arg1: paddle::platform::CUDAPlace) -> None\r\n    11. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int64], arg1: paddle::platform::CUDAPlace) -> None\r\n    12. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[bool], arg1: paddle::platform::CUDAPlace) -> None\r\n    13. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint16], arg1: paddle::platform::CUDAPlace) -> None\r\n    14. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint8], arg1: paddle::platform::CUDAPlace) -> None\r\n    15. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float32], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    16. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int32], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    17. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[float64], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    18. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[int64], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    19. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[bool], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    20. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint16], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n    21. (self: paddle.fluid.core.Tensor, arg0: numpy.ndarray[uint8], arg1: paddle::platform::CUDAPinnedPlace) -> None\r\n\r\nInvoked with: <paddle.fluid.core.LoDTensor object at 0x7ff3c0531240>, (array([[[211., 223., 235., ..., 123., 125., 127.],\r\n        [204., 215., 231., ..., 116., 124., 134.],\r\n        [190., 195., 206., ..., 118., 122., 123.],\r\n        ...,\r\n        [111., 115., 117., ...,  46.,  51.,  52.],\r\n        [118., 117., 113., ...,  39.,  47.,  51.],\r\n        [115., 114., 112., ...,  32.,  42.,  50.]],\r\n\r\n       [[235., 244., 253., ..., 179., 181., 183.],\r\n        [228., 239., 249., ..., 172., 180., 190.],\r\n        [214., 219., 227., ..., 171., 175., 176.],\r\n        ...,\r\n        [121., 125., 128., ...,  49.,  56.,  57.],\r\n        [119., 118., 116., ...,  44.,  52.,  56.],\r\n        [112., 111., 112., ...,  37.,  47.,  55.]],\r\n\r\n       [[225., 235., 246., ..., 168., 170., 172.],\r\n        [218., 229., 242., ..., 161., 169., 179.],\r\n        [206., 211., 219., ..., 161., 166., 167.],\r\n        ...,\r\n        [105., 109., 112., ...,  53.,  59.,  60.],\r\n        [103., 102., 100., ...,  47.,  55.,  59.],\r\n        [ 97.,  96.,  96., ...,  40.,  50.,  58.]]]), 5707, array([-1.20006335e+00,  3.20534378e-01,  9.33335543e-01, -4.24015141e+00,\r\n        2.13111669e-01,  9.66773868e-01,  2.46572709e+00,  5.61143541e+00,\r\n        9.39076006e-01, -4.93136793e-01,  1.56456745e+00, -1.09997416e+00,\r\n...\r\n```\r\n\r\n最早的时候使用的是 `feeder = fluid.DataFeeder(place=place, feed_list=[image, label, locals])` 的方式，但是取值输出后发现读入的 locals 的值一直为NAN，而 image 和 label 的值正常",
        "state": "open",
        "user": "zhijl",
        "closed_by": null,
        "created_at": "2018-09-06T18:53:24+00:00",
        "updated_at": "2018-09-06T18:57:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1217,
        "title": "object detection eval.py issue",
        "body": "I met a problem in object detection eval.py scripts as below, could you help me to have a look on it?\r\n\r\n`python eval.py --dataset='pascalvoc' --model_dir='ssd_mobilenet_v1_pascalvoc' --data_dir='data/pascalvoc' --test_list='test.txt' --ap_version='11point' --nms_threshold=0.45 --use_gpu=False`\r\n-----------  Configuration Arguments -----------\r\nap_version: 11point\r\nbatch_size: 32\r\ndata_dir: data/pascalvoc\r\ndataset: pascalvoc\r\nmean_value_B: 127.5\r\nmean_value_G: 127.5\r\nmean_value_R: 127.5\r\nmodel_dir: ssd_mobilenet_v1_pascalvoc\r\nnms_threshold: 0.45\r\nresize_h: 300\r\nresize_w: 300\r\ntest_list: test.txt\r\nuse_gpu: 0\r\n------------------------------------------------\r\n/home/chuanqiw/.local/lib/python2.7/site-packages/paddle/fluid/evaluator.py:71: Warning: The DetectionMAP is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.DetectionMAP instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 127, in <module>\r\n    model_dir=args.model_dir)\r\n  File \"eval.py\", line 90, in eval\r\n    test()\r\n  File \"eval.py\", line 82, in test\r\n    for batch_id, data in enumerate(test_reader()):\r\n  File \"/home/chuanqiw/.local/lib/python2.7/site-packages/paddle/batch.py\", line 33, in batch_reader\r\n    r = reader()\r\nTypeError: 'generator' object is not callable\r\n",
        "state": "closed",
        "user": "chuanqi129",
        "closed_by": "baiyfbupt",
        "created_at": "2018-09-02T14:51:09+00:00",
        "updated_at": "2018-09-03T10:17:13+00:00",
        "closed_at": "2018-09-03T10:17:13+00:00",
        "comments_count": [
            "baiyfbupt",
            "chuanqi129"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1223,
        "title": "Can't verify accuracy with pre-trained Resnet50 model.",
        "body": "Cannot obtain any meaningful results when when trying to reproduce ResNet50 accuracy (76.63%/93.10%).\r\n\r\nUsing Image Net val dataset:\r\nval/659/ILSVRC2012_val_00046108.JPEG 659\r\nval/659/ILSVRC2012_val_00044030.JPEG 659\r\nval/659/ILSVRC2012_val_00042898.JPEG 659\r\nval/659/ILSVRC2012_val_00041481.JPEG 659\r\nval/659/ILSVRC2012_val_00039493.JPEG 659\r\nval/659/ILSVRC2012_val_00037864.JPEG 659\r\nval/659/ILSVRC2012_val_00037578.JPEG 659\r\nval/659/ILSVRC2012_val_00033095.JPEG 659\r\nval/659/ILSVRC2012_val_00031091.JPEG 659\r\nval/659/ILSVRC2012_val_00030154.JPEG 659\r\nval/659/ILSVRC2012_val_00029819.JPEG 659\r\nval/659/ILSVRC2012_val_00029360.JPEG 659\r\nval/659/ILSVRC2012_val_00028777.JPEG 659\r\n\r\nAnd provided model I keep getting:\r\n\r\n-----------  Configuration Arguments -----------\r\nclass_dim: 1000\r\nimage_shape: 3,224,224\r\nmodel: ResNet50\r\npretrained_model: /data/resnet_50/115\r\nuse_gpu: 0\r\nwith_mem_opt: 1\r\n------------------------------------------------\r\nTest-0-score: [30.961004], class [550]\r\nTest-1-score: [16.557055], class [550]\r\nTest-2-score: [21.98035], class [550]\r\nTest-3-score: [14.857814], class [505]\r\nTest-4-score: [12.008922], class [550]\r\nTest-5-score: [19.638456], class [550]\r\nTest-6-score: [16.092129], class [813]\r\nTest-7-score: [24.678347], class [550]\r\nTest-8-score: [18.044142], class [550]\r\nTest-9-score: [22.066696], class [550]\r\nTest-10-score: [15.797653], class [550]\r\nTest-11-score: [20.66053], class [550]\r\nTest-12-score: [16.733633], class [482]\r\nTest-13-score: [15.197915], class [550]\r\nTest-14-score: [18.904078], class [550]\r\nTest-15-score: [27.324083], class [550]\r\nTest-16-score: [16.564373], class [550]\r\nTest-17-score: [14.2177515], class [813]\r\n\r\nAnd:\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 1\r\nclass_dim: 1000\r\nimage_shape: 3,224,224\r\nmodel: ResNet50\r\npretrained_model: /data/resnet_50/115\r\nuse_gpu: 0\r\nwith_mem_opt: 1\r\n------------------------------------------------\r\nTestbatch 0,loss 12.8082323074, acc1 0.0,acc5 0.0,time 0.33 sec\r\nTestbatch 10,loss 25.0121593475, acc1 0.0,acc5 0.0,time 0.16 sec\r\nTestbatch 20,loss 20.8600234985, acc1 0.0,acc5 0.0,time 0.16 sec\r\nTestbatch 30,loss 21.9461364746, acc1 0.0,acc5 0.0,time 0.16 sec\r\nTestbatch 40,loss 14.2183275223, acc1 0.0,acc5 0.0,time 0.17 sec\r\nTestbatch 50,loss 22.2879886627, acc1 0.0,acc5 0.0,time 0.19 sec\r\nTestbatch 60,loss 15.6957626343, acc1 0.0,acc5 0.0,time 0.16 sec\r\nTestbatch 70,loss 18.4210853577, acc1 0.0,acc5 0.0,time 0.16 sec\r\nTestbatch 80,loss 26.5067806244, acc1 0.0,acc5 0.0,time 0.17 sec\r\n\r\nor\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\nclass_dim: 1000\r\nimage_shape: 3,224,224\r\nmodel: ResNet50\r\npretrained_model: /data/resnet_50/115\r\nuse_gpu: 0\r\nwith_mem_opt: 1\r\n------------------------------------------------\r\nTestbatch 0,loss 16.9630355835, acc1 0.03125,acc5 0.03125,time 4.76 sec\r\nTestbatch 10,loss 16.6469154358, acc1 0.0,acc5 0.0,time 24.60 sec\r\nTestbatch 20,loss 16.7011985779, acc1 0.0,acc5 0.0,time 3.54 sec\r\nTestbatch 30,loss 13.4966154099, acc1 0.0,acc5 0.0,time 3.48 sec\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "ddokupil",
        "closed_by": "qingqing01",
        "created_at": "2018-09-04T15:06:30+00:00",
        "updated_at": "2018-09-06T09:01:56+00:00",
        "closed_at": "2018-09-06T09:01:56+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01",
            "ddokupil"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1227,
        "title": "Pyramidbox 有官方训练的模型可以使用吗",
        "body": "",
        "state": "closed",
        "user": "zhengzhe97",
        "closed_by": "qingqing01",
        "created_at": "2018-09-06T06:40:56+00:00",
        "updated_at": "2018-09-11T06:32:41+00:00",
        "closed_at": "2018-09-11T06:32:41+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1236,
        "title": "能帮忙提供一下tensorflow mobilenet_ssd 模型转fluid 工具么？ ",
        "body": "我想转 mobilenet_0.5_ssd 模型转为fluid 作为pretrained model。能帮忙提供一个转换工具么？\r\n\r\nhttps://github.com/PaddlePaddle/models/tree/3f1fddbd3cca73cac6beee3b1dbfa1ac3909ab8d/fluid/object_detection\r\n这里有提到你们的mobilenet_ssd 模型pretrained model 是从tensorflow 转过来的，能否给一些思路。",
        "state": "closed",
        "user": "youngstu",
        "closed_by": "qingqing01",
        "created_at": "2018-09-07T02:56:56+00:00",
        "updated_at": "2018-09-29T08:04:05+00:00",
        "closed_at": "2018-09-29T08:04:05+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1237,
        "title": "DeepASR aishell 训练出错",
        "body": "先执行prepare_data.sh，再执行train.sh，就出错如下：\r\n----------- Configuration Arguments -----------\r\nbatch_size: 8\r\ncheckpoints: checkpoints\r\nclass_num: 3040\r\ndevice: GPU\r\nframe_dim: 80\r\nhidden_dim: 1024\r\ninfer_models:\r\ninit_model_path: None\r\nlearning_rate: 6.4e-05\r\nmean_var: data/global_mean_var\r\nminimum_batch_size: 1\r\nparallel: True\r\npass_num: 100\r\nprint_per_batches: 100\r\nproj_dim: 512\r\nstacked_num: 5\r\ntrain_feature_lst: data/train_feature.lst\r\ntrain_label_lst: data/train_label.lst\r\nval_feature_lst: data/val_feature.lst\r\nval_label_lst: data/val_label.lst\r\n------------------------------------------------\r\n....................................................................................................Traceback (most recent call last):\r\nFile \"../../train.py\", line 292, in <module>\r\ntrain(args)\r\nFile \"../../train.py\", line 254, in train\r\n(batch_id, lodtensor_to_ndarray(outs[0])[0],\r\nFile \"/home/nemo/models/fluid/DeepASR/data_utils/util.py\", line 31, in lodtensor_to_ndarray\r\ndims = lod_tensor._get_dims()\r\nAttributeError: 'paddle.fluid.core.LoDTensor' object has no attribute '_get_dims'",
        "state": "closed",
        "user": "nemo9903",
        "closed_by": "nemo9903",
        "created_at": "2018-09-10T01:24:31+00:00",
        "updated_at": "2018-09-13T10:34:20+00:00",
        "closed_at": "2018-09-13T10:34:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1245,
        "title": "face_detection 多卡下多个pass后,拿不到数据",
        "body": "paddle_version: 0.15.0\r\n相同配置下，跑两次，第一次挂在第61个pass，第二次挂在第10个pass\r\n```bash\r\nPass 61, batch 530, face loss 2.25895452499, head loss 2.0783700943, time 2.00991797447\r\nPass 61, batch 540, face loss 1.47570765018, head loss 1.28614866734, time 2.35021495819\r\nPass 61, batch 550, face loss 1.9905424118, head loss 1.82294678688, time 2.87708592415\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 181, in <module>\r\n    train(args, config, train_file_list, optimizer_method=\"momentum\")\r\n  File \"train.py\", line 132, in train\r\n    im, face_box, head_box, labels, lod = next(train_reader)\r\nTypeError: 'NoneType' object is not iterable\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2018-09-14T03:01:01+00:00",
        "updated_at": "2018-10-08T01:50:04+00:00",
        "closed_at": "2018-10-08T01:50:04+00:00",
        "comments_count": [
            "fangzong12",
            "ccmeteorljh",
            "fangzong12",
            "qingqing01",
            "ccmeteorljh",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1244,
        "title": "face_detection,单gpu可以跑，多个GPU报错",
        "body": "*** Aborted at 1536888942 (unix time) try \"date -d @1536888942\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 4956 (TID 0x7f5667200700) from PID 0; stack trace: ***\r\n    @     0x7f5666dfc390 (unknown)\r\n    @                0x0 (unknown)\r\n段错误 (核心已转储)\r\n",
        "state": "closed",
        "user": "fangzong12",
        "closed_by": "qingqing01",
        "created_at": "2018-09-14T02:21:26+00:00",
        "updated_at": "2018-09-29T07:52:53+00:00",
        "closed_at": "2018-09-29T07:52:53+00:00",
        "comments_count": [
            "fangzong12",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1249,
        "title": "ocr_recognition 模型设置GPU代码错误",
        "body": "![image](https://user-images.githubusercontent.com/10734244/45544895-38cfca80-b84b-11e8-8d07-89fb11332abf.png)\r\n![image](https://user-images.githubusercontent.com/10734244/45544918-4422f600-b84b-11e8-913d-ffe812e356a3.png)\r\n应该是CUDA_VISIBLE_DEVICES=0,1,2,3   说明文档中多了一个A。\r\n还有\r\n![image](https://user-images.githubusercontent.com/10734244/45544951-5bfa7a00-b84b-11e8-84fd-3c228356cb33.png)\r\nctc_train.py 已经没有这个文件了，可以修改一下。\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-09-14T10:24:23+00:00",
        "updated_at": "2018-09-18T05:01:18+00:00",
        "closed_at": "2018-09-18T05:01:18+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1246,
        "title": "运行DeepASR训练报错",
        "body": "使用文档中介绍的例子训练，执行sh train.sh ，一段时间后报错\r\nTraceback (most recent call last):\r\n  File \"../../train.py\", line 292, in <module>\r\n    train(args)\r\n  File \"../../train.py\", line 254, in train\r\n    (batch_id, lodtensor_to_ndarray(outs[0])[0],\r\n  File \"/source/models/fluid/DeepASR/data_utils/util.py\", line 34, in lodtensor_to_ndarray\r\n    ret.ravel()[i] = lod_tensor.get_float_element(i)\r\nAttributeError: 'paddle.fluid.core.LoDTensor' object has no attribute 'get_float_element'\r\n\r\n使用的Paddle版本为 v0.15.0\r\n将/source/models/fluid/DeepASR/data_utils/util.py 第34行改为\r\nret.ravel()[i] = np.array(lod_tensor)[i]\r\n可以运行",
        "state": "open",
        "user": "jeff41404",
        "closed_by": null,
        "created_at": "2018-09-14T04:11:49+00:00",
        "updated_at": "2018-09-25T10:24:57+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1248,
        "title": "fluid/object_detection 现在可否支持自有数据集(custom dataset)？",
        "body": "我在之前的版本看到过，通过调整 config/vgg_config.py 文件内 vgg 超参数等等，可以支持自有数据集的训练。现在出的版本貌似做了较大调整，请问还支持自有数据集吗？如果支持，应该如何做相应的调整呢？谢谢！",
        "state": "closed",
        "user": "YB17",
        "closed_by": "qingqing01",
        "created_at": "2018-09-14T09:00:13+00:00",
        "updated_at": "2018-09-29T07:52:13+00:00",
        "closed_at": "2018-09-29T07:52:13+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1258,
        "title": "icnet 模型单卡和多卡在100个batch 出现loss为nan",
        "body": "paddle_version: 9月13号编译的版本；\r\n运行结果：\r\n```bash\r\nIter[90]; train loss: 2.035; sub4_loss: 1.796; sub24_loss: 1.392; sub124_loss: 1.191\r\nkpis\ttrain_cost\t2.035351\r\nIter[100]; train loss: 2.213; sub4_loss: 1.871; sub24_loss: 1.518; sub124_loss: 1.307\r\nkpis\ttrain_cost\t2.213448\r\nSaved checkpoint: ./chkpnt//100\r\nIter[110]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[120]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[130]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[140]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[150]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[160]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[170]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[180]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[190]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\nkpis\ttrain_cost\tnan\r\nIter[200]; train loss: nan; sub4_loss: nan; sub24_loss: nan; sub124_loss: nan\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2018-09-18T06:38:40+00:00",
        "updated_at": "2018-09-26T11:17:48+00:00",
        "closed_at": "2018-09-26T11:07:21+00:00",
        "comments_count": [
            "neverland0621"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1253,
        "title": "DSSM 的 classification 模型中 source 和 target CNN 网络是否是 share 的？",
        "body": "我训练了一个 cnn 的 dssm 模型，看文档中 source 和 target 的 cnn 应该是单独的，但是把参数解压出来看发现不太一样。\r\n\r\n在 `network_conf.py` 代码中这样创建卷积层：\r\n```\r\n            conv_3 = create_conv(3, self.dnn_dims[1], 'cnn')\r\n            conv_4 = create_conv(4, self.dnn_dims[1], 'cnn')\r\n```\r\n\r\n<img width=\"1029\" alt=\"cnnori\" src=\"https://user-images.githubusercontent.com/10841135/45583041-6bca9a80-b8ed-11e8-8ed3-b5b8c4ca9835.png\">\r\n\r\n参数文件中没有区分开 source 和 target 的 cnn 网络。\r\n\r\n我尝试这样修改代码：\r\n```\r\n            conv_3 = create_conv(3, self.dnn_dims[1], prefix + '_cnn')\r\n            conv_4 = create_conv(4, self.dnn_dims[1], prefix + '_cnn')\r\n```\r\n\r\n然后解压出来的参数是这样（我的模型是三塔模型，有两个 source 和一个 target）：\r\n<img width=\"899\" alt=\"cnndebug\" src=\"https://user-images.githubusercontent.com/10841135/45583077-ff9c6680-b8ed-11e8-8301-31449786c2c9.png\">\r\n\r\n\r\n但是神奇的是上面两种做法最后测试起来没有分别。\r\n\r\n可能是我对网络结构不太清楚，原始代码里面 source 和 target 的 cnn 是 share 的吗？\r\n",
        "state": "closed",
        "user": "Miopas",
        "closed_by": "Miopas",
        "created_at": "2018-09-15T05:50:20+00:00",
        "updated_at": "2019-02-18T04:39:33+00:00",
        "closed_at": "2019-02-18T04:39:33+00:00",
        "comments_count": [
            "mapingshuo",
            "Miopas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1259,
        "title": "测试数据“Cannot open file output/159/conv2d_15.w_0”",
        "body": "我先用单张卡测试，遇见错误如下，我看到要求下载的预训练模型里只有conv2d_0.w_0到conv2d_14.w_0。所以conv2d_15.w_0是在哪里呢？\r\n报错具体如下：\r\nTraceback (most recent call last):\r\n  File \"widerface_eval.py\", line 312, in <module>\r\n    exe, args.model_dir, main_program=main_program)\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/io.py\", line 496, in load_persistables\r\n    filename=filename)\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/io.py\", line 376, in load_vars\r\n    filename=filename)\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/io.py\", line 407, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot open file output/159/conv2d_15.w_0 for load op at [/paddle/paddle/fluid/operators/load_op.cc:39]",
        "state": "closed",
        "user": "neverland0621",
        "closed_by": "qingqing01",
        "created_at": "2018-09-18T07:19:58+00:00",
        "updated_at": "2018-09-19T11:36:50+00:00",
        "closed_at": "2018-09-19T11:36:50+00:00",
        "comments_count": [
            "qingqing01",
            "YueXiNPU",
            "neverland0621",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1260,
        "title": "训练时出错",
        "body": "我用单张卡训练报错如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 183, in <module>\r\n    train(args, config, train_file_list, optimizer_method=\"momentum\")\r\n  File \"train.py\", line 92, in train\r\n    exe.run(fluid.default_startup_program())\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected allocating <= available, but received allocating:10243394109 > available:426114816.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:120]\r\n```\r\n\r\n应该是内存不足的问题，所以我换成了3张卡，结果还是报错：\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 183, in <module>\r\n    train(args, config, train_file_list, optimizer_method=\"momentum\")\r\n  File \"train.py\", line 92, in train\r\n    exe.run(fluid.default_startup_program())\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: cudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCount: no CUDA-capable device is detected at [/paddle/paddle/fluid/platform/gpu_info.cc:33]\r\n```\r\n麻烦解答，谢谢。",
        "state": "closed",
        "user": "neverland0621",
        "closed_by": "qingqing01",
        "created_at": "2018-09-18T07:31:47+00:00",
        "updated_at": "2018-09-21T02:11:27+00:00",
        "closed_at": "2018-09-21T02:11:27+00:00",
        "comments_count": [
            "qingqing01",
            "neverland0621",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1265,
        "title": "deeplabv3+ 模型README问题",
        "body": "# 1.链接失效\r\n![image](https://user-images.githubusercontent.com/10734244/45743594-f9c8bd00-bc2e-11e8-9ee8-8634592c818f.png)\r\n\r\n# 2.表述不清\r\n![image](https://user-images.githubusercontent.com/10734244/45743689-3b596800-bc2f-11e8-9572-5ada46243b44.png)\r\n--init_weights_path 这个是初始化的目录还是文件，这下面这个下载的图。是指定文件还是目录还是自己定义的一个空目录？\r\n![image](https://user-images.githubusercontent.com/10734244/45743732-57f5a000-bc2f-11e8-864c-0c82b081f8dd.png)\r\n--save_weights_path 这个也是相同的问题，是指定目录还是指定文件，还是自己会生成一个文件？\r\n**正确运行发现使用的都是指定到文件~**\r\n--dataset_path **这个指定到数据集后必须加上/**，否则也会报错，路径拼错。。。\r\n\r\n最终正确执行的命令\r\nnohup python ./train.py --batch_size=8 --parallel=true  --train_crop_size=769 --total_step=900 --init_weights_path=../../../init/deeplabv3plus_xception65_initialize.params --save_weights_path=./res --dataset_path=../../../cityscape/ > log.txt 2>&1 &\r\n\r\n之前错误的尝试，报错提示也有些莫名其妙\r\n![image](https://user-images.githubusercontent.com/10734244/45744050-19141a00-bc30-11e8-9afd-b66e68a96537.png)\r\n![image](https://user-images.githubusercontent.com/10734244/45744087-30530780-bc30-11e8-8b5f-4d14ada05387.png)\r\n\r\n# 3. mean IoU这个link是什么意思，链接到了本页。\r\n![image](https://user-images.githubusercontent.com/10734244/45744197-8627af80-bc30-11e8-8e7e-6e75ff71af13.png)\r\n\r\n# 4.这个模型是否不支持cudnn5？如果是，需要说明一下。\r\n![image](https://user-images.githubusercontent.com/10734244/45744243-ac4d4f80-bc30-11e8-952c-1e37efe1cd1d.png)\r\n\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "qingqing01",
        "created_at": "2018-09-19T09:23:37+00:00",
        "updated_at": "2018-09-29T01:29:38+00:00",
        "closed_at": "2018-09-29T01:29:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1268,
        "title": "Add resnet model with distributed mode",
        "body": "",
        "state": "closed",
        "user": "Yancey0623",
        "closed_by": "Yancey0623",
        "created_at": "2018-09-19T11:18:15+00:00",
        "updated_at": "2018-09-20T13:04:24+00:00",
        "closed_at": "2018-09-20T13:04:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1262,
        "title": "PyramidBox 测试内存不足问题，在线等！！！add my wechat: xiyue6911",
        "body": "最近，部署PyramidBox（ECCV 2018）工作。\r\nGPU信息：GTX 1080TI, 11G显存，3块。\r\n### 问题一,  有人配置，PyramidBox在单卡（GTX 1080TI, 11G显存），是否可以成功运行？\r\n### 问题二，使用官网发布的完整模型进行测试，尝试一块卡或者3块卡执行。执行语句为\r\npython -u widerface_eval.py --model_dir=output/159 --pred_dir=pred。\r\n本人已经尝试：export FLAGS_fraction_of_gpu_memory_to_use=0.1，没有效果！\r\n----------------------------------------------------------------\r\n错误如下：\r\n```\r\nconfs_threshold: 0.15\r\ndata_dir: data/WIDER_val/images/\r\nfile_list: data/wider_face_split/wider_face_val_bbx_gt.txt\r\nimage_path: data/WIDER_train/images/0--Parade/0_Parade_marchingband_1_219.jpg\r\ninfer: False\r\nmodel_dir: PyramidBox_WiderFace\r\npred_dir: pred\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"widerface_eval.py\", line 314, in <module>\r\n    infer(args, config)\r\n  File \"widerface_eval.py\", line 63, in infer\r\n    [det2, det3] = multi_scale_test(image, max_shrink)\r\n  File \"widerface_eval.py\", line 206, in multi_scale_test\r\n    det_b = detect_face(image, bt)\r\n  File \"widerface_eval.py\", line 124, in detect_face\r\n    return_numpy=False)\r\n  File \"/home/jw/.conda/envs/Paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\n### **paddle.fluid.core.EnforceNotMet: Enforce failed. Expected allocating <= available, but received allocating:10244596957 > available:1108868864.**\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:120]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f4f5456ca16p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f4f555baccep paddle::platform::GpuMaxChunkSize() + 782\r\n2       0x7f4f554e98ebp void* paddle::memory::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace, unsigned long) + 475\r\n3       0x7f4f554de972p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::type_index) + 834\r\n4       0x7f4f545a3511p float* paddle::framework::Tensor::mutable_data<float>(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>) + 65\r\n5       0x7f4f54d28696p paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 646\r\n6       0x7f4f54d2a593p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n7       0x7f4f5546799ep paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 526\r\n8       0x7f4f55464a2cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 252\r\n9       0x7f4f54634a29p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 393\r\n10      0x7f4f54635800p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n11      0x7f4f5455265dp\r\n12      0x7f4f5457d6f4p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n13      0x7f4fbc171fc7p PyEval_EvalFrameEx + 28695\r\n14      0x7f4fbc1744e9p PyEval_EvalCodeEx + 2025\r\n15      0x7f4fbc1719b8p PyEval_EvalFrameEx + 27144\r\n16      0x7f4fbc1744e9p PyEval_EvalCodeEx + 2025\r\n17      0x7f4fbc1719b8p PyEval_EvalFrameEx + 27144\r\n18      0x7f4fbc1744e9p PyEval_EvalCodeEx + 2025\r\n19      0x7f4fbc1719b8p PyEval_EvalFrameEx + 27144\r\n20      0x7f4fbc1744e9p PyEval_EvalCodeEx + 2025\r\n21      0x7f4fbc1719b8p PyEval_EvalFrameEx + 27144\r\n22      0x7f4fbc1744e9p PyEval_EvalCodeEx + 2025\r\n23      0x7f4fbc17470ap PyEval_EvalCode + 26\r\n24      0x7f4fbc18d9cdp\r\n25      0x7f4fbc18eb48p PyRun_FileExFlags + 120\r\n26      0x7f4fbc18fd68p PyRun_SimpleFileExFlags + 232\r\n27      0x7f4fbc1a1f8cp Py_Main + 2988\r\n28      0x7f4fbb3bdf45p __libc_start_main + 245\r\n29      0x7f4fbc6938bfp\r\n```\r\n",
        "state": "closed",
        "user": "YueXiNPU",
        "closed_by": "qingqing01",
        "created_at": "2018-09-18T12:00:31+00:00",
        "updated_at": "2020-02-28T16:52:26+00:00",
        "closed_at": "2018-09-21T02:11:20+00:00",
        "comments_count": [
            "neverland0621",
            "qingqing01",
            "YueXiNPU",
            "phamkhactu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1272,
        "title": "What is the speed of PyramidBox?",
        "body": "Dear Professor\r\n       I am a Ph.D Student from NPU and interested in your PyramidBox. With the help of @qingqing01, we manage to run the eval code. Many thanks to him. \r\n       In our experiment, it will take about 1.37s to eval an image. So, I check the paper about PyramidBox but fail to find experiments about the analysis of model speed. \r\n       Would you like to share something about model speed?",
        "state": "closed",
        "user": "YueXiNPU",
        "closed_by": "YueXiNPU",
        "created_at": "2018-09-20T02:55:21+00:00",
        "updated_at": "2018-09-21T06:02:41+00:00",
        "closed_at": "2018-09-21T06:02:41+00:00",
        "comments_count": [
            "qingqing01",
            "YueXiNPU"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1281,
        "title": "cycle_gan 模型问题，文档问题",
        "body": "> 需要使用develop分支最新的paddle编译版本，可以指明一下~\r\n\r\n![image](https://user-images.githubusercontent.com/10734244/45871971-65db2a80-bdc1-11e8-850f-f984bcd45ba7.png)\r\n> **TypeError:** 错误，在https://github.com/PaddlePaddle/Paddle/pull/13509/files/4fbe01ec38fb71afd3bbd8264f2f2c282a63000f 修复，待验证。\r\n\r\n![image](https://user-images.githubusercontent.com/10734244/45877613-008f3580-bdd1-11e8-92cb-6c4b72642ed7.png)\r\n\r\n\r\n>  这个路径在readme里没有说明，需要说明一下，而且路径也是有误，需要在*./data*下，见图\r\n\r\n![image](https://user-images.githubusercontent.com/10734244/45877075-41864a80-bdcf-11e8-883b-a3b06035e1df.png)\r\n\r\n> 预测的指令参数名称有变，需要修改一下~\r\n\r\n![image](https://user-images.githubusercontent.com/10734244/45877259-cc674500-bdcf-11e8-9788-ca3193f57c49.png)\r\n\r\n> --model_path 没有这个指令了\r\n\r\n![image](https://user-images.githubusercontent.com/10734244/45877271-d5581680-bdcf-11e8-8d0a-3ec5eb445ec2.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-09-21T10:55:22+00:00",
        "updated_at": "2018-09-26T11:41:34+00:00",
        "closed_at": "2018-09-26T11:41:34+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1289,
        "title": "key错了",
        "body": "https://github.com/PaddlePaddle/models/blob/d1e78e57184baa2ccd4036aaf8f0187f20ffc382/fluid/object_detection/train.py#L129\r\n\r\ntrain_params['epoch_num'] 应该是train_params['epoc_num']",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2018-09-26T03:05:04+00:00",
        "updated_at": "2018-09-26T11:02:40+00:00",
        "closed_at": "2018-09-26T11:02:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1282,
        "title": "Face and head loss are NAN, when training PyramidBox. Online Urgent!",
        "body": "Hello everyone and @qingqing01. I am training _PyramidBox (ECCV 2018)_ by Baidu with 3 GPUs of GTX 1080Ti, memory 11G. Training command is _python -u train.py --batch_size=3_. I try batch_size=4/5/6, but it does not work for me.\r\nNan is shown as below:\r\n![default](https://user-images.githubusercontent.com/34571270/45916935-62bf6780-beb1-11e8-99ec-4461bf3900a7.png)\r\nGPU information is shown as below:\r\n![default](https://user-images.githubusercontent.com/34571270/45916944-b5991f00-beb1-11e8-9064-2e9db0166597.png)\r\nAnyone can help me to solve this problem?\r\n\r\n",
        "state": "open",
        "user": "YueXiNPU",
        "closed_by": null,
        "created_at": "2018-09-22T11:52:50+00:00",
        "updated_at": "2018-09-27T13:58:50+00:00",
        "closed_at": null,
        "comments_count": [
            "YueXiNPU",
            "YueXiNPU",
            "qingqing01",
            "YueXiNPU",
            "neverland0621",
            "YueXiNPU",
            "qingqing01",
            "takecareofbigboss",
            "takecareofbigboss",
            "YueXiNPU",
            "neverland0621"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1287,
        "title": "ocr_recognition API changed",
        "body": "When I use command ` python train.py --use_gpu False --parallel=False --total_step 5 --save_model_period 5 --save_model_dir ./models`, I got below information. Could you have a look into it?\r\n\r\n`[chuanqiw@mlt-skx089 ocr_recognition]$ python train.py --use_gpu False --parallel=False --total_step 5 --save_model_period 5 --save_model_dir ./models\r\n-----------  Configuration Arguments -----------\r\naverage_window: 0.15\r\nbatch_size: 32\r\neval_period: 15000\r\ninit_model: None\r\nlog_period: 1000\r\nmax_average_window: 12500\r\nmin_average_window: 10000\r\nmodel: crnn_ctc\r\nparallel: 0\r\nprofile: False\r\nsave_model_dir: ./models\r\nsave_model_period: 5\r\nskip_batch_num: 0\r\nskip_test: False\r\ntotal_step: 5\r\nuse_gpu: 0\r\n------------------------------------------------\r\n/home/chuanqiw/.local/lib/python2.7/site-packages/paddle/fluid/evaluator.py:71: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 218, in <module>\r\n    main()\r\n  File \"train.py\", line 214, in main\r\n    train(args)\r\n  File \"train.py\", line 60, in train\r\n    args, data_shape, num_classes)\r\n  File \"/home/chuanqiw/workspace/aipg_paddle/models/fluid/ocr_recognition/crnn_ctc_model.py\", line 212, in ctc_train_net\r\n    max_average_window=args.max_average_window)\r\n  File \"/home/chuanqiw/.local/lib/python2.7/site-packages/paddle/fluid/optimizer.py\", line 1275, in __init__\r\n    self._add_average_apply_op(block, param_grad)\r\n  File \"/home/chuanqiw/.local/lib/python2.7/site-packages/paddle/fluid/optimizer.py\", line 1304, in _add_average_apply_op\r\n    layers.elementwise_div(x=sum, y=tmp, out=param)\r\nTypeError: elementwise_div() got an unexpected keyword argument 'out'\r\n`",
        "state": "open",
        "user": "chuanqi129",
        "closed_by": null,
        "created_at": "2018-09-25T13:45:05+00:00",
        "updated_at": "2018-09-26T11:39:27+00:00",
        "closed_at": null,
        "comments_count": [
            "kolinwei"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1291,
        "title": "image_classfication单机运行失败",
        "body": "train.py第36行add_args少一个逗号",
        "state": "closed",
        "user": "lipanpan03",
        "closed_by": "qingqing01",
        "created_at": "2018-09-26T04:53:39+00:00",
        "updated_at": "2018-09-26T12:13:44+00:00",
        "closed_at": "2018-09-26T12:13:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1290,
        "title": "image_classification分布式环境支持问题",
        "body": "image_classification的分布式运行尚未支持python3\r\ndist_train的readme文档中trainer文档有误，trainer的PADDLE_TRAINING_ROLE应为trainer",
        "state": "closed",
        "user": "lipanpan03",
        "closed_by": "velconia",
        "created_at": "2018-09-26T04:44:58+00:00",
        "updated_at": "2018-09-26T06:49:24+00:00",
        "closed_at": "2018-09-26T06:49:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1294,
        "title": "image_classification分布式运行在python环境下报错",
        "body": "dist_train.py文件中第310行print缺失括号\r\n第294行for arg, value in sorted(vars(args).iteritems()):报错'dict' object has no attribute 'iteritems'",
        "state": "closed",
        "user": "lipanpan03",
        "closed_by": "velconia",
        "created_at": "2018-09-26T06:54:39+00:00",
        "updated_at": "2018-09-26T09:47:41+00:00",
        "closed_at": "2018-09-26T09:47:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1296,
        "title": "paddle.fluid.core.EnforceNotMet: holder_ should not be null",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/fluid/neural_machine_translation/transformer/train.py\r\n把train.py 参数--use-mem-opt的default改为False￼\r\n报错￼\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 641, in <module>\r\n    train(args)\r\n  File \"train.py\", line 593, in train\r\n    token_num, predict, pyreader)\r\n  File \"train.py\", line 468, in train_loop\r\n    feed=feed_dict_list)\r\n  File \"/home/paddle/minqiyang/miniconda2/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 281, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: holder_ should not be null\r\nTensor not initialized yet when Tensor::type() is called. at [/paddle/paddle/fluid/framework/tensor.h:141]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f94e3e6e446p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f94e3e70a27p paddle::framework::Tensor::type() const + 151\r\n2       0x7f94e44c502bp paddle::operators::ElementwiseOpGrad::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 107\r\n3       0x7f94e4ef62bdp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 237\r\n4       0x7f94e4ef2e4cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 252\r\n5       0x7f94e4d4d9a7p\r\n6       0x7f94e4d6b190p\r\n7       0x7f94e4d6a9f5p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 805\r\n8       0x7f94e4d4d47fp paddle::framework::details::ComputationOpHandle::RunImpl() + 95\r\n9       0x7f94e4d6ba95p paddle::framework::details::OpHandleBase::Run(bool) + 117\r\n10      0x7f94e4d429afp\r\n11      0x7f94e3f3da13p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n12      0x7f94e3f3d1e7p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n13      0x7f9562d91be0p pthread_once + 80\r\n14      0x7f94e4d41ce2p\r\n15      0x7f94e3f3f284p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n16      0x7f9552b6bc5cp\r\n17      0x7f9562d8cdf3p\r\n18      0x7f95623b12cdp clone + 109",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "guoshengCS",
        "created_at": "2018-09-26T08:22:59+00:00",
        "updated_at": "2018-09-27T08:11:02+00:00",
        "closed_at": "2018-09-27T08:11:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1320,
        "title": "Invalid code",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/fluid/neural_machine_translation/transformer/model.py#L462",
        "state": "open",
        "user": "gongweibao",
        "closed_by": null,
        "created_at": "2018-09-28T11:55:40+00:00",
        "updated_at": "2018-09-28T11:55:50+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1305,
        "title": "KeyError: 'segmented_paragraphs'",
        "body": "https://github.com/xuezhong/models/tree/machine_reading_comprehesion/fluid/machine_reading_comprehesion/DuReader\r\n数据预处理出错：\r\n$ cat data/raw/trainset/search.train.json | python utils/preprocess.py > data/preprocessed/trainset/search.train.json\r\nTraceback (most recent call last):\r\n  File \"utils/preprocess.py\", line 218, in <module>\r\n    find_fake_answer(sample)\r\n  File \"utils/preprocess.py\", line 157, in find_fake_answer\r\n    for p_idx, para_tokens in enumerate(doc['segmented_paragraphs']):\r\nKeyError: 'segmented_paragraphs'",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "xuezhong",
        "created_at": "2018-09-27T10:02:57+00:00",
        "updated_at": "2018-09-28T02:29:01+00:00",
        "closed_at": "2018-09-28T02:29:01+00:00",
        "comments_count": [
            "xuezhong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1299,
        "title": "支持异步模式",
        "body": "https://github.com/PaddlePaddle/models/blob/19b3be8ff6feaab5476a93a6abecd2e3d3fed4fe/fluid/neural_machine_translation/transformer/train.py#L610\r\nsync_mode=args.sync",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2018-09-26T11:03:22+00:00",
        "updated_at": "2018-09-27T11:22:39+00:00",
        "closed_at": "2018-09-27T11:22:39+00:00",
        "comments_count": [
            "guoshengCS",
            "kolinwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1313,
        "title": "Port 1.0.0 models to Python3",
        "body": "According to the discussion in [PaddlePaddle issues](https://github.com/PaddlePaddle/Paddle/issues/12040), we should port current code in 1.0.0 models to Python3\r\n\r\n\r\n**烫:** \r\n\r\n需要在1.0.0发布前完成迁移的模型: \r\n\r\nNLP:\r\n- 毅冰: DAM [**_done_**](https://github.com/PaddlePaddle/models/pull/1334) P0\r\n\r\n- 学忠: BiDAF [**_done_**]() P0\r\n\r\n- 郭晟: transformer [**_done_**]()\r\n\r\nCV:\r\n- 豪爽:  CGAN  [**_done_**](https://github.com/PaddlePaddle/models/pull/1311) P0\r\n\r\n- 豪爽:  DCGAN [**_done_**](https://github.com/PaddlePaddle/models/pull/1311) P0\r\n\r\n- 豪爽:  CycleGAN [**_done_**](https://github.com/PaddlePaddle/models/pull/1311) P0\r\n\r\n- 冠中:  Faster-RCNN [**_done_**](https://github.com/PaddlePaddle/models/pull/1310)\r\n\r\n- 豪爽:  OCR-Attention [**_done_**](https://github.com/PaddlePaddle/models/pull/1315)\r\n\r\n- 青青: PyramidBox [**_done_**](https://github.com/PaddlePaddle/models/pull/1319)\r\n\r\n- 青青: MobileNet-SSD [**_done_**](https://github.com/PaddlePaddle/models/pull/1319) \r\n\r\n- 青青：DeepLab v3+ [**_done_**](https://github.com/PaddlePaddle/models/pull/1321)\r\n\r\n- 李甫:  video_classification [**_done_**](https://github.com/PaddlePaddle/models/pull/1331)\r\n\r\n- 杜玉宁:  metric_learning [**_done_**](https://github.com/PaddlePaddle/models/pull/1335/commits/cab2defd8566d4f3f90f656d43a71936bfbc63a1)\r\n\r\n- 陆宇飞:  HiNAS_models [**exclude**](https://github.com/PaddlePaddle/models/tree/develop/fluid/HiNAS_models)\r\n",
        "state": "closed",
        "user": "velconia",
        "closed_by": "velconia",
        "created_at": "2018-09-28T06:41:40+00:00",
        "updated_at": "2018-10-12T01:41:22+00:00",
        "closed_at": "2018-10-12T01:41:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1308,
        "title": "About ‘get_shrink()’ in 'models/fluid/face_detection/widerface_eval.py'",
        "body": "in 'models/fluid/face_detection/widerface_eval.py', we have \r\n`def get_shrink(height, width):\r\n    \"\"\"\r\n    Args:\r\n        height (int): image height.\r\n        width (int): image width.\r\n    \"\"\"\r\n    # avoid out of memory\r\n    max_shrink_v1 = (0x7fffffff / 577.0 / (height * width))**0.5\r\n    max_shrink_v2 = ((678 * 1024 * 2.0 * 2.0) / (height * width))**0.5\r\n\r\n    def get_round(x, loc):\r\n        str_x = str(x)\r\n        if '.' in str_x:\r\n            str_before, str_after = str_x.split('.')\r\n            len_after = len(str_after)\r\n            if len_after >= 3:\r\n                str_final = str_before + '.' + str_after[0:loc]\r\n                return float(str_final)\r\n            else:\r\n                return x\r\n\r\n    max_shrink = get_round(min(max_shrink_v1, max_shrink_v2), 2) - 0.3\r\n    if max_shrink >= 1.5 and max_shrink < 2:\r\n        max_shrink = max_shrink - 0.1\r\n    elif max_shrink >= 2 and max_shrink < 3:\r\n        max_shrink = max_shrink - 0.2\r\n    elif max_shrink >= 3 and max_shrink < 4:\r\n        max_shrink = max_shrink - 0.3\r\n    elif max_shrink >= 4 and max_shrink < 5:\r\n        max_shrink = max_shrink - 0.4\r\n    elif max_shrink >= 5:\r\n        max_shrink = max_shrink - 0.5\r\n\r\n    shrink = max_shrink if max_shrink < 1 else 1\r\n    return shrink, max_shrink`\r\n\r\nmy question is , why there are so many ... 'magic numbers' like 0.1, 0.2, etc. Or in other word, why we do this? \r\n \r\n",
        "state": "closed",
        "user": "math-yyj",
        "closed_by": "qingqing01",
        "created_at": "2018-09-28T03:14:31+00:00",
        "updated_at": "2019-07-02T16:51:46+00:00",
        "closed_at": "2018-09-29T07:51:54+00:00",
        "comments_count": [
            "takecareofbigboss",
            "scharron"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1338,
        "title": "ocr_attention test异常",
        "body": "paddle-version: fluid1.0 0930号编译版本\r\n模型：models/fluid/ocr_attention\r\n命令：\r\n```bash\r\npython -u train.py --batch_size 256 --model attention --total_step 320000\r\n```\r\n有时test异常，如下：\r\n```bash\r\n\r\nTime: 1538332948.57; Iter[13000]; Avg loss: 1.135; Avg seq err: 0.171\r\nkpis    train_cost      1.134649\r\nkpis    train_acc       0.828777\r\n\r\nTime: 1538333644.09; Iter[14000]; Avg loss: 1.090; Avg seq err: 0.168\r\nkpis    train_cost      1.090500\r\nkpis    train_acc       0.832238\r\n\r\nTime: 1538334340.52; Iter[15000]; Avg loss: 1.046; Avg seq err: 0.162\r\nkpis    train_cost      1.046496\r\nkpis    train_acc       0.837543\r\n\r\nTime: 1538334393.92; Iter[15000]; Test seq error: 1893743600000000.0.\r\n\r\nkpis    test_acc        -1893743556820991.000000\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2018-10-02T14:54:03+00:00",
        "updated_at": "2018-10-09T09:26:37+00:00",
        "closed_at": "2018-10-09T09:26:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1328,
        "title": "Faster RCNN 的相关问题",
        "body": "1、在训练阶段需要cocoapi 可以在readme中注明一下。\r\n2、下载脚本./pretrained/download.sh会把模型下载到./pretrained目录下载，但是train.py会在 . 目录下寻找初始模型，会出现找不到问题，不会报错，但训练loss 为nan，需要修改一下download.sh的下载解压路径\r\n3、训练过程会出现程序卡住，没有报错信息， gpu也占用，但是不输出log数据了。 目前已知大概率是驱动问题，384驱动会出问题，396不会。\r\n4、训练过程中异常。见图。\r\n![image](https://user-images.githubusercontent.com/10734244/46421274-5dd99e00-c764-11e8-8b5c-49c99ab06c01.png)\r\n![image](https://user-images.githubusercontent.com/10734244/46421289-65994280-c764-11e8-9073-34cd26ef85cf.png)\r\n![image](https://user-images.githubusercontent.com/10734244/46421297-692cc980-c764-11e8-9340-0f7ea58aaa43.png)\r\n\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "qingqing01",
        "created_at": "2018-09-30T02:15:35+00:00",
        "updated_at": "2018-10-30T08:42:04+00:00",
        "closed_at": "2018-10-30T08:42:03+00:00",
        "comments_count": [
            "jerrywgz",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1337,
        "title": "SSD 运行完指定pass数退出后，异常",
        "body": "paddle-version: fluid1.0 0930号编译版本\r\n模型：models/fluid/object_detection/README_cn.md\r\n命令：\r\n```bash\r\npython -u train.py --batch_size=256 --dataset='pascalvoc' --data_dir='./data/pascalvoc/' --pretrained_model='./pretrained/ssd_mobilenet_v1_coco/'\r\n```\r\n报错如下：\r\n```bash\r\n*** SIGTERM (@0xe) received by PID 134 (TID 0x7f0c2b50c700) from PID 14; stack trace: ***\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\n    @     0x7f0e32649390 (unknown)\r\n*** SIGTERM (@0xe) received by PID 128 (TID 0x7f0c2b50c700) from PID 14; stack trace: ***\r\n*** SIGTERM (@0xe) received by PID 131 (TID 0x7f0c2b50c700) from PID 14; stack trace: ***\r\n    @     0x7f0e32649390 (unknown)\r\n    @     0x7f0e32649390 (unknown)\r\n    @     0x7f0e3264851d __libc_read\r\n    @     0x7f0e3236b5d3 __select\r\n    @     0x7f0e32649390 (unknown)\r\n    @           0x589608 (unknown)\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @     0x7f0e3264851d __libc_read\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d55f3 (unknown)\r\n    @           0x4a577e PyObject_Call\r\n    @           0x4bed3d PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @     0x7f0de5dc20ee (unknown)\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d54b9 (unknown)\r\n    @           0x4eebee (unknown)\r\n    @           0x4ee7f6 (unknown)\r\n    @           0x4aa9ab (unknown)\r\n    @           0x4c15bf PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @     0x7f0e32649390 (unknown)\r\n    @     0x7f0e3264851d __libc_read\r\n    @     0x7f0e32649390 (unknown)\r\n    @     0x7f0de5dc20ee (unknown)\r\n    @           0x4d4c9d (unknown)\r\n    @           0x4bc9b6 PyEval_EvalFrameEx\r\n    @           0x4d4c9d (unknown)\r\n    @     0x7f0e3264851d __libc_read\r\n    @           0x4bc9b6 PyEval_EvalFrameEx\r\n    @           0x4d4c9d (unknown)\r\n    @           0x4bc9b6 PyEval_EvalFrameEx\r\n    @     0x7f0de5dc32b0 (unknown)\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c0d90 PyEval_EvalFrameEx\r\n    @           0x4d55f3 (unknown)\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4a577e PyObject_Call\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4bed3d PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n```\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2018-10-01T13:59:46+00:00",
        "updated_at": "2018-10-08T02:59:05+00:00",
        "closed_at": "2018-10-08T02:59:05+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1341,
        "title": "paddle最新版，fluid.layers.reduce_mean(input, dim=1)有bug。",
        "body": "",
        "state": "closed",
        "user": "helen88",
        "closed_by": "helen88",
        "created_at": "2018-10-08T02:16:14+00:00",
        "updated_at": "2018-10-08T02:31:15+00:00",
        "closed_at": "2018-10-08T02:30:33+00:00",
        "comments_count": [
            "helen88",
            "helen88"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1348,
        "title": "Metric learning model.",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/fluid/metric_learning\r\n\r\n1. Need to tell user what loss_name can be in the doc.\r\n2. Better to introduce the different loss and give the loss reference paper.",
        "state": "open",
        "user": "qingqing01",
        "closed_by": null,
        "created_at": "2018-10-08T14:05:34+00:00",
        "updated_at": "2018-10-08T14:05:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1352,
        "title": "deep_fm调用自己的数据时报错",
        "body": "我们的数据已通过/deep_fm/preprocess.py进行预处理，在调用train函数时报错，错误日志如下图，\r\n![1](https://user-images.githubusercontent.com/13231631/46674161-0fb61600-cc0e-11e8-86f4-25dd1839acb0.png)\r\n源代码如下，\r\n\r\n```\r\nimport paddle.v2 as paddle\r\n\r\nfactor_size = 5\r\nbatch_size = 128\r\nnum_passes = 10\r\ndense_feature_dim = 30\r\nsparse_feature_dim = 269\r\n\r\nfeeding = {\r\n    'dense_input': 0,\r\n    'sparse_input': 1,\r\n    'C1': 2,\r\n    'C2': 3,\r\n    'C3': 4,\r\n    'C4': 5,\r\n    'C5': 6,\r\n    'C6': 7,\r\n    'C7': 8,\r\n    'C8': 9,\r\n    'C9': 10,\r\n    'C10': 11,\r\n    'C11': 12,\r\n    'C12': 13,\r\n    'C13': 14,\r\n    'C14': 15,\r\n    'C15': 16,\r\n    'C16': 17,\r\n    'C17': 18,\r\n    'C18': 19,\r\n    'C19': 20,\r\n    'C20': 21,\r\n    'C21': 22,\r\n    'C22': 23,\r\n    'C23': 24,\r\n    'C24': 25,\r\n    'C25': 26,\r\n    'C26': 27,\r\n    'C27': 28,\r\n    'C28': 29,\r\n    'C29': 30,\r\n    'label': 31\r\n}\r\n\r\nclass Dataset:\r\n    def _reader_creator(self, path, is_infer):\r\n        def reader():\r\n            with open(path, 'r') as f:\r\n                for line in f:\r\n                    features = line.rstrip('\\n').split('\\t')\r\n                    dense_feature = map(float, features[0].split(','))\r\n                    sparse_feature = map(int, features[1].split(','))\r\n                    if not is_infer:\r\n                        label = [int(features[2])]\r\n                        yield [dense_feature, sparse_feature\r\n                               ] + sparse_feature + [label]\r\n                    else:\r\n                        yield [dense_feature, sparse_feature] + sparse_feature\r\n\r\n        return reader\r\n\r\n    def train(self, path):\r\n        return self._reader_creator(path, False)\r\n\r\n    def test(self, path):\r\n        return self._reader_creator(path, False)\r\n    \r\ndef fm_layer(input, factor_size, fm_param_attr):\r\n    first_order = paddle.layer.fc(input=input,\r\n                        size=1,\r\n                        act=paddle.activation.Linear())\r\n    second_order = paddle.layer.factorization_machine(\r\n        input=input,\r\n        factor_size=factor_size,\r\n        act=paddle.activation.Linear(),\r\n        param_attr=fm_param_attr)\r\n    out = paddle.layer.addto(\r\n        input=[first_order, second_order],\r\n        act=paddle.activation.Linear(),\r\n        bias_attr=False)\r\n    return out\r\n\r\n\r\ndef DeepFM(factor_size, infer=False):\r\n    dense_input = paddle.layer.data(\r\n        name=\"dense_input\",\r\n        type=paddle.data_type.dense_vector(dense_feature_dim))\r\n    sparse_input = paddle.layer.data(\r\n        name=\"sparse_input\",\r\n        type=paddle.data_type.sparse_binary_vector(sparse_feature_dim))\r\n    sparse_input_ids = [\r\n        paddle.layer.data(\r\n            name=\"C\" + str(i),\r\n            type=paddle.data_type.integer_value(sparse_feature_dim))\r\n        for i in range(1, 30)\r\n    ]\r\n    dense_fm = fm_layer(\r\n        dense_input,\r\n        factor_size,\r\n        fm_param_attr=paddle.attr.Param(name=\"DenseFeatFactors\"))\r\n    sparse_fm = fm_layer(\r\n        sparse_input,\r\n        factor_size,\r\n        fm_param_attr=paddle.attr.Param(name=\"SparseFeatFactors\"))\r\n    def embedding_layer(input):\r\n        return paddle.layer.embedding(\r\n            input=input,\r\n            size=factor_size,\r\n            param_attr=paddle.attr.Param(name=\"SparseFeatFactors\"))\r\n\r\n    sparse_embed_seq = map(embedding_layer, sparse_input_ids)\r\n    sparse_embed = paddle.layer.concat(sparse_embed_seq)\r\n    fc1 = paddle.layer.fc(input=[sparse_embed, dense_input],\r\n                          size=400,\r\n                          act=paddle.activation.Relu())\r\n    fc2 = paddle.layer.fc(input=fc1, size=400, act=paddle.activation.Relu())\r\n    fc3 = paddle.layer.fc(input=fc2, size=400, act=paddle.activation.Relu())\r\n\r\n    predict = paddle.layer.fc(input=[dense_fm, sparse_fm, fc3],\r\n                              size=1,\r\n                              act=paddle.activation.Sigmoid())\r\n    if not infer:\r\n        label = paddle.layer.data(\r\n            name=\"label\", type=paddle.data_type.integer_value(1))\r\n        cost = paddle.layer.multi_binary_label_cross_entropy_cost(\r\n            input=predict, label=label)\r\n        paddle.evaluator.classification_error(\r\n            name=\"classification_error\", input=predict, label=label)\r\n        paddle.evaluator.auc(name=\"auc\", input=predict, label=label)\r\n        return cost\r\n    else:\r\n        return predict\r\n\r\ndef train():\r\n    \r\n    paddle.init(use_gpu=False, trainer_count=1)\r\n    \r\n    optimizer = paddle.optimizer.Adam(learning_rate=1e-4)\r\n    model = DeepFM(factor_size)\r\n    params = paddle.parameters.create(model)\r\n    trainer = paddle.trainer.SGD(cost=model, parameters=params, update_equation=optimizer)\r\n\r\n    dataset = Dataset()\r\n\r\n    def __event_handler__(event):\r\n        if isinstance(event, paddle.event.EndIteration):\r\n            num_samples = event.batch_id * batch_size\r\n            if event.batch_id % 10 == 0:\r\n                print \"Pass %d, Batch %d, Samples %d, Cost %f, %s\" % (event.pass_id, event.batch_id, num_samples,\r\n                                event.cost, event.metrics)\r\n\r\n            if event.batch_id % 100 == 0:\r\n                result = trainer.test(\r\n                   reader=paddle.batch(\r\n                      dataset.test('data/valid.txt'),\r\n                      batch_size=batch_size),\r\n                      feeding=feeding)\r\n                print \"Test %d-%d, Cost %f, %s\" % (event.pass_id, event.batch_id, result.cost,\r\n                                    result.metrics)\r\n\r\n                #path = \"{}/model-pass-{}-batch-{}.tar.gz\".format(\r\n                #    model_output_dir, event.pass_id, event.batch_id)\r\n                #with gzip.open(path, 'w') as f:\r\n                #    trainer.save_parameter_to_tar(f)\r\n\r\n    trainer.train(\r\n        reader=paddle.batch(\r\n            paddle.reader.shuffle(\r\n                dataset.train('data/train.txt'),\r\n                buf_size=batch_size * 10000),\r\n            batch_size=batch_size),\r\n        feeding=feeding,\r\n        event_handler=__event_handler__, \r\n        num_passes=num_passes)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```",
        "state": "open",
        "user": "Ericzhuu",
        "closed_by": null,
        "created_at": "2018-10-09T08:20:39+00:00",
        "updated_at": "2018-10-10T13:29:11+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "Ericzhuu",
            "Ericzhuu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1353,
        "title": "Paddle CPU预测版本默认占用太多的CPU核了，怎么修改让它只占用少量核",
        "body": "如题",
        "state": "open",
        "user": "chenbblei",
        "closed_by": null,
        "created_at": "2018-10-09T08:48:25+00:00",
        "updated_at": "2018-10-09T14:06:09+00:00",
        "closed_at": null,
        "comments_count": [
            "tensor-tang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1358,
        "title": "test error : out of memory",
        "body": "Hello, thanks for your excellent work,\r\n\r\nwhen I try to test trained model , I got an error - out of memory, and I used nvidia K40.\r\nI find in multi_scale_test( ),the image size enlarged one times because of the parameter bt(or shrink),\r\nand that result in out of memory.\r\n\r\ni dont know how to solve this, could you please help me?\r\nthank you",
        "state": "closed",
        "user": "elezchan",
        "closed_by": "elezchan",
        "created_at": "2018-10-14T10:45:29+00:00",
        "updated_at": "2018-10-15T09:11:16+00:00",
        "closed_at": "2018-10-15T09:11:16+00:00",
        "comments_count": [
            "elezchan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1365,
        "title": "在paddle1.0.0.post97版本下测试sequence_tagging_for_ner模型时出现ValueError错误",
        "body": "\r\n![default](https://user-images.githubusercontent.com/41904587/47057548-cfe5c480-d1f3-11e8-9803-a4f2e9562cc3.png)\r\n\r\n",
        "state": "open",
        "user": "lipanpan03",
        "closed_by": null,
        "created_at": "2018-10-17T02:03:11+00:00",
        "updated_at": "2018-10-17T02:03:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1356,
        "title": "运行模型出错！",
        "body": "paddle.fluid.core.EnforceNotMet: cudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCount: no CUDA-capable device is detected at [/paddle/paddle/fluid/platform/gpu_info.cc:33]\r\n我机器有GPU，跑其他Paddle模型没问题。",
        "state": "closed",
        "user": "xiaolv3366",
        "closed_by": "xiaolv3366",
        "created_at": "2018-10-11T08:43:05+00:00",
        "updated_at": "2019-07-01T04:39:41+00:00",
        "closed_at": "2018-10-11T09:22:24+00:00",
        "comments_count": [
            "xiaolv3366",
            "bb9696aa"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1360,
        "title": "Cannot load any more object with static TLS while executing crnn_ctc on multi-devices",
        "body": "Error log:\r\n\r\n```\r\n  File \"/home/users/***/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 260, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Failed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS )\r\n Please specify its path correctly using following ways:\r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\n For instance, issue command: export LD_LIBRARY_PATH=...\r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/home/users/***/Paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:157]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f635169b626p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f6352bc3e9ep paddle::platform::dynload::GetWarpCTCDsoHandle() + 1822\r\n2       0x7f63527b7149p void std::__once_call_impl<std::_Bind_simple<decltype (get_warpctc_version({parm#1}...)) paddle::platform::dynload::DynLoad__get_warpctc_version::operator()<>()::{lambda()#1} ()> >() + 9\r\n3       0x7f63bf6edbe0p pthread_once + 80\r\n4       0x7f63527be4a8p paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*) + 136\r\n5       0x7f63527c0abbp paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 2763\r\n6       0x7f63527c2863p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n7       0x7f6352a3f04cp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 492\r\n8       0x7f6352a3b7bcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 252\r\n9       0x7f63529494c7p\r\n10      0x7f6352967100p\r\n11      0x7f6352966975p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 805\r\n12      0x7f6352948f9fp paddle::framework::details::ComputationOpHandle::RunImpl() + 95\r\n13      0x7f6352967a05p paddle::framework::details::OpHandleBase::Run(bool) + 117\r\n14      0x7f635290626ap\r\n15      0x7f635176c263p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n16      0x7f635176bb17p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n17      0x7f63bf6edbe0p pthread_once + 80\r\n18      0x7f6352905242p\r\n19      0x7f635176d7f4p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n20      0x7f636b73c070p\r\n21      0x7f63bf6e8df3p\r\n22      0x7f63bed0d2cdp clone + 109\r\n```",
        "state": "open",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-10-15T02:47:32+00:00",
        "updated_at": "2019-11-11T08:19:48+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "JiabinYang",
            "wanghaoshuang",
            "liushanshan07",
            "Dely-Yu",
            "wanghaoshuang",
            "wanghaoshuang",
            "luotao1"
        ],
        "labels": [
            "bug",
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1370,
        "title": "DeepASR 运行 AISHELL例子 training报错",
        "body": "各位好，我在编译运行deepasr aishell这个例子的时候，先是运行sh profile.sh，会报一个memory不够的问题。\r\n\r\n------------------------------------------------\r\n.........Traceback (most recent call last):\r\n  File \"../../tools/profile.py\", line 210, in <module>\r\n    profile(args)\r\n  File \"../../tools/profile.py\", line 193, in profile\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: ptr_ should not be null\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/framework/tensor.h:180]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fe12816db36p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n\r\n\r\n如果我直接运行sh train.sh, 会报如下错误。\r\n```\r\nxjia@nvidia:~/work/PaddlePaddle/models/fluid/DeepASR/examples/aishell$ sh train.sh\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 64\r\ncheckpoints: checkpoints\r\nclass_num: 3040\r\ndevice: GPU\r\nframe_dim: 80\r\nhidden_dim: 1024\r\ninfer_models:\r\ninit_model_path: None\r\nlearning_rate: 6.4e-05\r\nmean_var: data/global_mean_var\r\nminimum_batch_size: 1\r\nparallel: True\r\npass_num: 100\r\nprint_per_batches: 100\r\nproj_dim: 512\r\nstacked_num: 5\r\ntrain_feature_lst: data/train_feature.lst\r\ntrain_label_lst: data/train_label.lst\r\nval_feature_lst: data/val_feature.lst\r\nval_label_lst: data/val_label.lst\r\n------------------------------------------------\r\nAPI get_places is deprecated since 0.15.0. Please use ParallelExecutor instead.\r\nTraceback (most recent call last):\r\n  File \"../../train.py\", line 292, in <module>\r\n    train(args)\r\n  File \"../../train.py\", line 156, in train\r\n    parallel=args.parallel)\r\n  File \"/home/xjia/work/PaddlePaddle/models/fluid/DeepASR/model_utils/model.py\", line 91, in stacked_lstmp_model\r\n    pd = fluid.layers.ParallelDo(places)\r\nAttributeError: 'module' object has no attribute 'ParallelDo'\r\n```\r\n我是在一个单机1080ti的GPU上运行的，已经确认paddle成功安装。",
        "state": "open",
        "user": "IrishCoffee",
        "closed_by": null,
        "created_at": "2018-10-19T05:52:53+00:00",
        "updated_at": "2019-06-03T03:16:00+00:00",
        "closed_at": null,
        "comments_count": [
            "chengduoZH",
            "IrishCoffee",
            "chengduoZH",
            "IrishCoffee",
            "jiayifang1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1371,
        "title": "About PyramidBox, how to match head box with face gt? I could not find the code implementing formula(4) as in the papaer.",
        "body": "About PyramidBox, how to match head box with face gt? I could not find the code implementing formula(4) as in the papar.\r\nPlease comment. Thanks.",
        "state": "closed",
        "user": "Edwardmark",
        "closed_by": "qingqing01",
        "created_at": "2018-10-19T08:22:08+00:00",
        "updated_at": "2018-12-11T15:04:54+00:00",
        "closed_at": "2018-12-11T15:04:54+00:00",
        "comments_count": [
            "qingqing01",
            "Edwardmark",
            "qingqing01",
            "Edwardmark",
            "qingqing01",
            "Edwardmark",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1372,
        "title": "face_detection run error with paddle 1.0.2",
        "body": "paddle_version：1.0.2\r\nmodels：face_detection\r\nrun cmd：\r\n```bash\r\npython -u train.py --batch_size=16 --pretrained_model=vgg_ilsvrc_16_fc_reduced\r\n```\r\nmessage：\r\n```bash\r\nraceback (most recent call last):\r\n  File \"train.py\", line 233, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"train.py\", line 162, in train\r\n    loss_name=loss.name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 166, in __init__\r\n    build_strategy, num_trainers, trainer_id)\r\npaddle.fluid.core.EnforceNotMet: optimize operations cannot be depended by forward or backward node momentum -> fill_constant at [/paddle/paddle/fluid/framework/details/multi_devices_graph_pass.cc:273]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fa5df1e3be6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7fa5e028fbd5p paddle::framework::details::SortOpsAndDelayOptimizeOp(paddle::framework::ir::Graph const&) + 2053\r\n2       0x7fa5e0296416p paddle::framework::details::MultiDevSSAGraphBuilder::ApplyImpl(std::unique_ptr<paddle::framework::ir::Graph, std::default_delete<paddle::framework::ir::Graph> >) const + 86\r\n3       0x7fa5e0329fd8p paddle::framework::ir::Pass::Apply(std::unique_ptr<paddle::framework::ir::Graph, std::default_delete<paddle::framework::ir::Graph> >) const + 216\r\n4       0x7fa5df2bd3b8p paddle::framework::ApplyParallelExecutorPass(paddle::framework::ProgramDesc const&, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::string const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, bool, paddle::framework::details::BuildStrategy const&, paddle::platform::NCCLContextMap*) + 1400\r\n5       0x7fa5df2bf34ep paddle::framework::ParallelExecutor::ParallelExecutor(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long) + 1198\r\n6       0x7fa5df236095p void pybind11::cpp_function::initialize<void pybind11::detail::init<std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long>::execute<pybind11::class_<paddle::framework::ParallelExecutor>, , 0>(pybind11::class_<paddle::framework::ParallelExecutor>&)::{lambda(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long)#1}, void, paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long, pybind11::name, pybind11::is_method, pybind11::sibling>(void pybind11::detail::init<std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long>::execute<pybind11::class_<paddle::framework::ParallelExecutor>, , 0>(pybind11::class_<paddle::framework::ParallelExecutor>&)::{lambda(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long)#1}&&, void (*)(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::operator()(pybind11::detail::function_call) const + 789\r\n7       0x7fa5df2361eep void pybind11::cpp_function::initialize<void pybind11::detail::init<std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long>::execute<pybind11::class_<paddle::framework::ParallelExecutor>, , 0>(pybind11::class_<paddle::framework::ParallelExecutor>&)::{lambda(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long)#1}, void, paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long, pybind11::name, pybind11::is_method, pybind11::sibling>(void pybind11::detail::init<std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long>::execute<pybind11::class_<paddle::framework::ParallelExecutor>, , 0>(pybind11::class_<paddle::framework::ParallelExecutor>&)::{lambda(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long)#1}&&, void (*)(paddle::framework::ParallelExecutor*, std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) + 14\r\n8       0x7fa5df1f4824p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n9             0x4eebeep\r\n10            0x4ee7f6p\r\n11            0x4aa9abp\r\n12            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n13            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n14            0x4d55f3p\r\n15            0x4eebeep\r\n16            0x4ee7f6p\r\n17            0x4aa9abp\r\n18            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n19            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n20            0x4c1e6fp PyEval_EvalFrameEx + 24639\r\n21            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n22            0x4eb30fp\r\n23            0x4e5422p PyRun_FileExFlags + 130\r\n24            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n25            0x493ae2p Py_Main + 1554\r\n26      0x7fa63a6be830p __libc_start_main + 240\r\n27            0x4933e9p _start + 41\r\n```\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2018-10-20T02:58:48+00:00",
        "updated_at": "2018-10-30T08:46:51+00:00",
        "closed_at": "2018-10-30T08:46:51+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1383,
        "title": "SSD训练生成脚本，求共享",
        "body": "SSD训练生成脚本，求共享",
        "state": "closed",
        "user": "930083287",
        "closed_by": "qingqing01",
        "created_at": "2018-10-24T06:45:03+00:00",
        "updated_at": "2018-12-11T15:05:46+00:00",
        "closed_at": "2018-12-11T15:05:45+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1373,
        "title": "run policy_gradient failed",
        "body": "WARNING: Logging before InitGoogleLogging() is written to STDERR\r\nI1022 16:02:46.179663 104725 init.cc:47] Init commandline: dummy run.py --tryfromenv=use_pinned_memory,check_nan_inf,benchmark,warpctc_dir,eager_delete_scope,use_mkldnn,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,cpu_deterministic\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 14, in <module>\r\n    brain.build_net()\r\n  File \"/home/wangsijiang01/work/models/fluid/policy_gradient/brain.py\", line 38, in build_net\r\n    self.inferece_program = fluid.defaul_main_program().clone()\r\nAttributeError: 'module' object has no attribute 'defaul_main_program'",
        "state": "open",
        "user": "wangsouc",
        "closed_by": null,
        "created_at": "2018-10-22T08:03:37+00:00",
        "updated_at": "2018-10-22T08:23:25+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1385,
        "title": "http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz 下载失败",
        "body": "http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz 下载失败",
        "state": "closed",
        "user": "930083287",
        "closed_by": "qingqing01",
        "created_at": "2018-10-24T12:00:27+00:00",
        "updated_at": "2018-10-30T08:43:21+00:00",
        "closed_at": "2018-10-30T08:43:21+00:00",
        "comments_count": [
            "mapingshuo",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1418,
        "title": "提供的模型是否可以提供多个接口的模型？",
        "body": "保存模型的方式有很多种，文档：http://www.paddlepaddle.org/documentation/api/zh/1.0/io.html\r\n但是官方一般是提供：https://github.com/PaddlePaddle/models/blob/a8dc7ed3d95cf83d7ae0f7988628e6910f018a49/fluid/PaddleCV/image_classification/train.py#L257\r\n\r\n我的建议是4个接口保存模型的方式都提供，比如paddle-mobile使用但是`save_inference_model`接口保存的模型，但官网提供的模型也不是这个接口的，以后提供训练好的模型是否可以提供全部的模型。\r\n![image](https://user-images.githubusercontent.com/26297768/49350226-226a3a00-f6e9-11e8-840d-8ea40c754ef7.png)\r\n",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-11-01T03:40:12+00:00",
        "updated_at": "2018-12-03T03:41:46+00:00",
        "closed_at": "2018-12-03T03:41:46+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1375,
        "title": "多GPU执行问题，多GPU执行时任务挂起无法完成",
        "body": "以/models-develop/fluid/language_model为例，默认执行fluid train.py，任务长时间挂起，GPU的状态也很奇怪：内存和使用率都满的，但是从功率看，GPU芯片又几乎没有工作。如果改为非并行方式，单GPU时则没有问题。\r\npaddle版本1.0.2\r\n",
        "state": "closed",
        "user": "duanlin0505",
        "closed_by": "typhoonzero",
        "created_at": "2018-10-22T09:59:06+00:00",
        "updated_at": "2018-10-25T06:30:15+00:00",
        "closed_at": "2018-10-25T06:30:15+00:00",
        "comments_count": [
            "typhoonzero",
            "duanlin0505"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1420,
        "title": "image_classification运行报错",
        "body": "在models的新版本models/fluid/PaddleCV/image_classification/运行train.py时，发现报错ImportError: No module named 'learning_rate'如图\r\n![default](https://user-images.githubusercontent.com/41904587/47847615-b739f900-de06-11e8-83e0-96da323f6513.png)\r\n",
        "state": "open",
        "user": "lipanpan03",
        "closed_by": null,
        "created_at": "2018-11-01T10:48:33+00:00",
        "updated_at": "2018-11-01T11:02:29+00:00",
        "closed_at": null,
        "comments_count": [
            "kolinwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1423,
        "title": "python3 paddlepaddle1.1版本的language_model的lstm模型报错",
        "body": "在python3 paddlepaddle1.1版本环境下运行language_model的lstm模型时报错，AttributeError: 'str' object has no attribute 'decode'，如图\r\n![default](https://user-images.githubusercontent.com/41904587/47889857-163f5280-de87-11e8-972b-c22c951dec9f.png)\r\n",
        "state": "closed",
        "user": "lipanpan03",
        "closed_by": "phlrain",
        "created_at": "2018-11-02T02:07:49+00:00",
        "updated_at": "2018-11-02T07:31:23+00:00",
        "closed_at": "2018-11-02T07:31:23+00:00",
        "comments_count": [
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1426,
        "title": "GAN 的 dc_gan例子运行出错",
        "body": "paddle版本是0.15\r\n不使用GPU运行出错\r\n```\r\ntodd@todd-PC:~/gan/c_gan$ python dc_gan.py --output=\"./output\" --use_gpu=False\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 128\r\nepoch: 20\r\noutput: ./output\r\nuse_gpu: 0\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"dc_gan.py\", line 168, in <module>\r\n    train(args)\r\n  File \"dc_gan.py\", line 116, in train\r\n    fetch_list={g_img})[0]\r\n  File \"/home/todd/.local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:-79968 != -in_size:-80000.\r\nInvalid shape is given. at [/paddle/paddle/fluid/operators/reshape_op.cc:98]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6f9d91ad86p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f6f9dffdb76p paddle::operators::ReshapeOp::ValidateShape(std::vector<int, std::allocator<int> >, paddle::framework::DDim const&) + 2854\r\n2       0x7f6f9dffe24fp paddle::operators::ReshapeOp::InferShape(paddle::framework::InferShapeContext*) const + 703\r\n3       0x7f6f9e2eda69p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 73\r\n4       0x7f6f9e2ea00fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 255\r\n5       0x7f6f9d9d89d9p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 393\r\n6       0x7f6f9d9d95d0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n7       0x7f6f9d90265dp\r\n8       0x7f6f9d94d034p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n9       0x563ca4ee37cbp PyEval_EvalFrameEx + 34443\r\n10      0x563ca4ed8c7ap PyEval_EvalCodeEx + 1386\r\n11      0x563ca4ee07aep PyEval_EvalFrameEx + 22126\r\n12      0x563ca4ed8c7ap PyEval_EvalCodeEx + 1386\r\n13      0x563ca4ee0db4p PyEval_EvalFrameEx + 23668\r\n14      0x563ca4ed8c7ap PyEval_EvalCodeEx + 1386\r\n15      0x563ca4ed8709p PyEval_EvalCode + 25\r\n16      0x563ca4f0971fp\r\n17      0x563ca4f04472p PyRun_FileExFlags + 130\r\n18      0x563ca4f038edp PyRun_SimpleFileExFlags + 397\r\n19      0x563ca4eb2a2bp Py_Main + 1675\r\n20      0x7f6fc4b62a87p __libc_start_main + 231\r\n21      0x563ca4eb22aap _start + 42\r\n```\r\n@qingqing01",
        "state": "closed",
        "user": "toddwyl",
        "closed_by": "toddwyl",
        "created_at": "2018-11-02T08:02:54+00:00",
        "updated_at": "2018-11-08T08:29:52+00:00",
        "closed_at": "2018-11-08T08:29:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1428,
        "title": "object detection cpu启动失败",
        "body": "我是小白，在试着在无GPU服务器上搭建paaddlepaddle环境，按照https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/object_detection上的例子中的，执行到python -u train.py --batch_size=64 --dataset='pascalvoc' --pretrained_model='pretrained/ssd_mobilenet_v1_coco/' --use_gpu False 命令时，程序出错，没有跑起来；希望大神们指示，错误日志如下：\r\n\r\n----------- Configuration Arguments -----------\r\nap_version: 11point\r\nbatch_size: 64\r\ndata_dir: data/pascalvoc\r\ndataset: pascalvoc\r\nenable_ce: False\r\nepoc_num: 120\r\nimage_shape: 3,300,300\r\nlearning_rate: 0.001\r\nmean_BGR: 127.5,127.5,127.5\r\nmodel_save_dir: model\r\nparallel: True\r\npretrained_model: pretrained/ssd_mobilenet_v1_coco/\r\nuse_gpu: 0\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py:71: Warning: The DetectionMAP is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.DetectionMAP instead.\r\n% (self.__class__.__name__, self.__class__.__name__), Warning)\r\n*** Aborted at 1541382160 (unix time) try \"date -d @1541382160\" if you are using GNU date ***\r\nPC: @ 0x0 (unknown)\r\n*** SIGILL (@0x7fd6a4935002) received by PID 24290 (TID 0x7fd6ff134700) from PID 18446744072175702018; stack trace: ***\r\n@ 0x7fd6fed20390 (unknown)\r\n@ 0x7fd6a4935002 paddle::framework::VisitDataType<>()\r\n@ 0x7fd6a491d2ff paddle::operators::math::set_constant_with_place<>()\r\n@ 0x7fd6a3ee899b paddle::operators::FillConstantOp::RunImpl()\r\n@ 0x7fd6a48d0b58 paddle::framework::OperatorBase::Run()\r\n@ 0x7fd6a3d1f0fb paddle::framework::Executor::RunPreparedContext()\r\n@ 0x7fd6a3d1fee0 paddle::framework::Executor::Run()\r\n@ 0x7fd6a3c408bd _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL13pybind11_initEvEUlRNS2_9framework8ExecutorERKNS4_11ProgramDescEPNS4_5ScopeEibbE63_vIS6_S9_SB_ibbEINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNEST_\r\n@ 0x7fd6a3c90cb4 pybind11::cpp_function::dispatcher()\r\n@ 0x4cb2d4 PyEval_EvalFrameEx\r\n@ 0x4c2e05 PyEval_EvalCodeEx\r\n@ 0x4ca6b5 PyEval_EvalFrameEx\r\n@ 0x4c2e05 PyEval_EvalCodeEx\r\n@ 0x4caf42 PyEval_EvalFrameEx\r\n@ 0x4c2e05 PyEval_EvalCodeEx\r\n@ 0x4c2ba9 PyEval_EvalCode\r\n@ 0x4f20ef (unknown)\r\n@ 0x4eca72 PyRun_FileExFlags\r\n@ 0x4eb1f1 PyRun_SimpleFileExFlags\r\n@ 0x49e18a Py_Main\r\n@ 0x7fd6fe965830 __libc_start_main\r\n@ 0x49da19 _start\r\n@ 0x0 (unknown)\r\n非法指令 (核心已转储)",
        "state": "open",
        "user": "fuck-u-s",
        "closed_by": null,
        "created_at": "2018-11-05T01:59:37+00:00",
        "updated_at": "2018-11-05T05:08:17+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1438,
        "title": "PaddleNLP/language_model/gru/train.py some error in ce",
        "body": "https://github.com/PaddlePaddle/models/blob/8ea4299422257126605c0ee0989e955bfdc6b818/fluid/PaddleNLP/language_model/gru/train.py#L151\r\n\r\n应该改为gpu_num = get_cards(args)",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "kolinwei",
        "created_at": "2018-11-09T03:30:44+00:00",
        "updated_at": "2019-02-21T01:14:54+00:00",
        "closed_at": "2019-02-21T01:14:54+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1430,
        "title": "ctr模型使用is_sparse=True抛异常",
        "body": "在deepctr例子里，只要把`network_conf.py`这里改成:\r\n\r\n```\r\ndef embedding_layer(input):\r\n         return fluid.layers.embedding(\r\n             input=input,\r\n+            is_distributed=True,\r\n+            is_sparse=True,\r\n             size=[sparse_feature_dim, embedding_size],\r\n             param_attr=fluid.ParamAttr(name=\"SparseFeatFactors\", initializer=fluid.initializer.Normal(scale=1/math.sqrt(sparse_feature_dim))))\r\n```\r\n\r\n使用1worker 1ps训练， 就会报如下错误:\r\nWORKER\r\n```\r\n2018-11-06 16:29:39,757 - INFO - run dist training\r\n2018-11-06 16:29:39,789 - INFO - run trainer\r\npserver not ready, wait 3 sec to retry...\r\npserver not ready, wait 3 sec to retry...\r\nF1106 16:29:51.974265 25611 grpc_client.cc:348] PrefetchRPC name:[prefetch_compress_out_tmp_0], ep:[127.0.0.1:6174], status:[-1] meets grpc error, error_code:14 error_message:Socket closed error_details:\r\n*** Check failure stack trace: ***\r\n    @     0x7f650b3c254d  google::LogMessage::Fail()\r\n    @     0x7f650b3c5ffc  google::LogMessage::SendToLog()\r\n    @     0x7f650b3c2073  google::LogMessage::Flush()\r\n    @     0x7f650b3c750e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f650bef5ac1  paddle::operators::distributed::GRPCClient::Proceed()\r\n    @     0x7f6519d58678  execute_native_thread_routine_compat\r\n    @     0x7f65b4c33e25  start_thread\r\n    @     0x7f65b425834d  __clone\r\n    @              (nil)  (unknown)\r\n./start_trainer.sh: line 1: 25247 Aborted                 python train.py --train_data_path data/raw/train.txt --is_local 0 --role trainer --endpoints 127.0.0.1:6174 --trainers 1 --trainer_id=0 --sparse_feature_dim 1000001\r\n```\r\n\r\nPS\r\n```\r\n2018-11-06 16:29:43,886 - INFO - run dist training\r\n2018-11-06 16:29:43,917 - INFO - run pserver\r\nget_pserver_program() is deprecated, call get_pserver_programs() to get pserver main and startup in a single call.2018-11-06 16:29:43,921 - WARNING - distribute lookup table only support sgd optimizer, change it's optimizer to sgd instead of sgd\r\n*** Aborted at 1541492991 (unix time) try \"date -d @1541492991\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7f8a5564a644) received by PID 25435 (TID 0x7f8ac9577700) from PID 1432659524; stack trace: ***\r\n    @     0x7f8afe2945e0 (unknown)\r\n    @     0x7f8a5564a644 paddle::framework::SelectedRows::Get()\r\n    @     0x7f8a5519238c paddle::operators::LookupSparseTableOp::RunImpl()\r\n    @     0x7f8a55611f48 paddle::framework::OperatorBase::Run()\r\n    @     0x7f8a54a604eb paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7f8a5555708e paddle::operators::distributed::RequestPrefetchHandler::Handle()\r\n    @     0x7f8a5555e54e paddle::operators::distributed::RequestPrefetch::Process()\r\n    @     0x7f8a5555a0ba paddle::operators::distributed::AsyncGRPCServer::HandleRequest()\r\n    @     0x7f8a5555daff std::thread::_Impl<>::_M_run()\r\n    @     0x7f8a633b1678 execute_native_thread_routine_compat\r\n    @     0x7f8afe28ce25 start_thread\r\n    @     0x7f8afd8b134d __clone\r\n    @                0x0 (unknown)\r\n./start_ps.sh: line 1: 25435 Floating point exceptionpython train.py --is_local 0 --role pserver --endpoints 127.0.0.1:6174 --trainers 1 --sparse_feature_dim 1000001 --current_endpoint 127.0.0.1:6174\r\n```\r\n",
        "state": "closed",
        "user": "codescv",
        "closed_by": "guru4elephant",
        "created_at": "2018-11-06T08:31:17+00:00",
        "updated_at": "2018-11-14T06:23:18+00:00",
        "closed_at": "2018-11-13T01:32:42+00:00",
        "comments_count": [
            "codescv",
            "jacquesqiao",
            "jacquesqiao",
            "codescv"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1444,
        "title": "text_classification1.1和0.15版本中的prepare_data batch_size需要保持一致",
        "body": "https://github.com/PaddlePaddle/models/blob/133ec3ded6c48828f11cf9174c5c3d6d4d68fcfe/fluid/PaddleNLP/text_classification/train.py#L92\r\n0.15版本中batch_size=128，1.1中为4。\r\n需要更正1.1版本中的值保证CE正常运行",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "wzzju",
        "created_at": "2018-11-09T04:57:22+00:00",
        "updated_at": "2018-11-10T15:04:31+00:00",
        "closed_at": "2018-11-10T15:04:31+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1433,
        "title": "ocr_recognition二次开发应用到车牌识别，原ocr是62个字符，车牌是65个字符包含中文",
        "body": "原ocr是62个字符，包括0-9,a-z,和A-Z；我的车牌数据集是65个字符，包括汉字和0-9和A-Z；生成的车牌数据图片大小和原ocr数据集大小一样，都为【384,48,1】；把车牌数据输入给网络，训练和测试准确率迭代10000词全部都为0，这是不是和model原字典的a对应ASCII-33的值和num_class=95（62+33）有关系呢？任务紧急，感谢各位大神解答\r\n下面是原数据集和我生成的车牌数据集，还有运行参数和结果\r\n![default](https://user-images.githubusercontent.com/29424644/48183975-8a886300-e36b-11e8-939a-868e55615697.png)\r\n![default](https://user-images.githubusercontent.com/29424644/48183986-9116da80-e36b-11e8-9a5e-c724bd320cfa.png)\r\n![default](https://user-images.githubusercontent.com/29424644/48184004-9bd16f80-e36b-11e8-846e-9be3619a11b4.png)\r\n![default](https://user-images.githubusercontent.com/29424644/48184020-a68c0480-e36b-11e8-9c61-218bbc8dcc85.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "xiaoming521",
        "closed_by": "xiaoming521",
        "created_at": "2018-11-08T07:03:28+00:00",
        "updated_at": "2018-11-15T02:16:47+00:00",
        "closed_at": "2018-11-12T08:15:52+00:00",
        "comments_count": [
            "xiaoming521",
            "baihaojie2011",
            "wanghaoshuang",
            "xiaoming521",
            "qingqing01",
            "wanghaoshuang",
            "wanghaoshuang",
            "xiaoming521",
            "xiaoming521",
            "Yipeng-Sun",
            "xiaoming521",
            "qingqing01"
        ],
        "labels": [
            "question"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1434,
        "title": "mobilenet_ssd里的这两行是不是多余了？",
        "body": "```python\r\ndef conv_bn(input,\r\n            filter_size,\r\n            num_filters,\r\n            stride,\r\n            padding,\r\n            channels=None,\r\n            num_groups=1,\r\n            act='relu',\r\n            use_cudnn=True):\r\n    parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\r\n    conv = fluid.layers.conv2d(\r\n        input=input,\r\n        num_filters=num_filters,\r\n        filter_size=filter_size,\r\n        stride=stride,\r\n        padding=padding,\r\n        groups=num_groups,\r\n        act=None,\r\n        use_cudnn=use_cudnn,\r\n        param_attr=parameter_attr,\r\n        bias_attr=False)\r\n    parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\r\n    bias_attr = ParamAttr(learning_rate=0.2)\r\n    return fluid.layers.batch_norm(input=conv, act=act)\r\n```\r\n倒数第2、3两行是不是多余了？\r\n[mobilenet_ssd.py](https://github.com/PaddlePaddle/models/blob/release/1.1/fluid/PaddleCV/object_detection/mobilenet_ssd.py)",
        "state": "closed",
        "user": "ChuRao",
        "closed_by": "JiabinYang",
        "created_at": "2018-11-08T07:44:47+00:00",
        "updated_at": "2018-11-09T03:21:42+00:00",
        "closed_at": "2018-11-09T03:21:42+00:00",
        "comments_count": [
            "JiabinYang",
            "qingqing01"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1449,
        "title": "ocr代码换gpu运行时报错问题咨询",
        "body": "使用gpu运行代码时，报下面这个错误，cpu运行正常\r\n![default](https://user-images.githubusercontent.com/29424644/48334439-a22a5900-e695-11e8-98d8-3de2da2fdf5a.png)\r\n\r\n",
        "state": "closed",
        "user": "xiaoming521",
        "closed_by": "xiaoming521",
        "created_at": "2018-11-12T08:12:14+00:00",
        "updated_at": "2018-11-16T15:02:49+00:00",
        "closed_at": "2018-11-16T15:02:39+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1453,
        "title": "训练deep attention matching net报错",
        "body": "-----------  Configuration Arguments -----------\r\n_EOS_: 28270\r\nbatch_size: 256\r\nchannel1_num: 32\r\nchannel2_num: 16\r\ndata_path: ./data/data.pkl\r\nemb_size: 200\r\next_eval: False\r\nlearning_rate: 0.001\r\nmax_turn_len: 50\r\nmax_turn_num: 9\r\nnum_scan_data: 2\r\nsave_path: ./models\r\nstack_num: 5\r\nuse_cuda: True\r\nvocab_size: 434512\r\nword_emb_init: ./data/word_embedding.pkl\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"../train_and_evaluate.py\", line 269, in <module>\r\n    train(args)\r\n  File \"../train_and_evaluate.py\", line 120, in train\r\n    loss, logits = dam.create_network()\r\n  File \"/home/map/xiehongwei/models-develop/fluid/models-develop/fluid/deep_attention_matching_net/model.py\", line 61, in create_network\r\n    initializer=fluid.initializer.Normal(scale=0.1)))\r\n  File \"/home/map/.jumbo/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 255, in embedding\r\n    'padding_idx': padding_idx\r\n  File \"/home/map/.jumbo/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 46, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/map/.jumbo/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 862, in append_op\r\n    op = Operator(block=self, desc=op_desc, *args, **kwargs)\r\n  File \"/home/map/.jumbo/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 516, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core.EnforceNotMet: enforce ids_dims.size() == 2 failed, 3 != 2\r\n at [/paddle/paddle/fluid/operators/lookup_table_op.cc:43]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f1dcb93fce2p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482\r\n1       0x7f1dcc04b153p paddle::operators::LookupTableOp::InferShape(paddle::framework::InferShapeContext*) const + 2195\r\n2       0x7f1dcb9be017p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 903\r\n3       0x7f1dcb995169p _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework6OpDescEIRKNS4_9BlockDescEEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_KFT_DpT1_EDpRKT2_EUlPKS5_S8_E_vISN_S8_EIS9_SA_SB_EEEvOSD_PFSC_SF_ESL_ENUlRNS_6detail13function_callEE1_4_FUNESU_ + 201\r\n4       0x7f1dcb950932p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2338\r\n5       0x7f1e2576d3d4p PyEval_EvalFrameEx + 25956\r\n6       0x7f1e2576e120p PyEval_EvalCodeEx + 2240\r\n7       0x7f1e256fa26dp\r\n8       0x7f1e256d20e3p PyObject_Call + 83\r\n9       0x7f1e256e4f6fp\r\n10      0x7f1e256d20e3p PyObject_Call + 83\r\n11      0x7f1e257287fep\r\n12      0x7f1e25727468p\r\n13      0x7f1e256d20e3p PyObject_Call + 83\r\n14      0x7f1e2576add7p PyEval_EvalFrameEx + 16231\r\n15      0x7f1e2576e120p PyEval_EvalCodeEx + 2240\r\n16      0x7f1e256fa26dp\r\n17      0x7f1e256d20e3p PyObject_Call + 83\r\n18      0x7f1e2576add7p PyEval_EvalFrameEx + 16231\r\n19      0x7f1e2576e120p PyEval_EvalCodeEx + 2240\r\n20      0x7f1e2576c491p PyEval_EvalFrameEx + 22049\r\n21      0x7f1e2576e120p PyEval_EvalCodeEx + 2240\r\n22      0x7f1e2576c491p PyEval_EvalFrameEx + 22049\r\n23      0x7f1e2576cc46p PyEval_EvalFrameEx + 24022",
        "state": "open",
        "user": "bmapwei",
        "closed_by": null,
        "created_at": "2018-11-13T11:48:02+00:00",
        "updated_at": "2018-11-20T03:07:25+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "bmapwei",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1454,
        "title": "is_sparse=True下，如果特征不加mod会抛异常",
        "body": "ctr模型中，如果把reader.py改成这样：(特征不加mod)\r\n```\r\nfor idx in self.categorical_range_:\r\n      #sparse_feature.append([hash(\"%d_%s\" % (idx, features[idx])) % self.hash_dim_])\r\n      sparse_feature.append([hash(\"%d_%s\" % (idx, features[idx]))])\r\n```\r\n\r\n\r\n仍然会报错，错误信息:\r\n```\r\n2018-11-14 03:19:39,738 - INFO - run dist training\r\n2018-11-14 03:19:39,778 - INFO - run pserver\r\nget_pserver_program() is deprecated, call get_pserver_programs() to get pserver main and startup in a single call.2018-11-14 03:19:39,796 - WARNING - distribute lookup table only support sgd optimizer, change it's optimizer to sgd instead of sgd\r\nget_startup_program() is deprecated, call get_pserver_programs() to get pserver main and startup in a single call.passing pserver_program to get_startup_program() is deprecated, you can use new API get_pserver_programs() to get both pserver main program and startup program.F1114 03:19:54.470163    96 listen_and_serv_op.cc:73] run sub program:9 error Input rows index should less than height at [/Paddle/Paddle/paddle/fluid/operators/sgd_op.h:113]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fd627b387b7p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 727\r\n1       0x7fd628697e8dp paddle::operators::SGDOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 8493\r\n2       0x7fd62869829fp std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::SGDOpKernel<float>, paddle::operators::SGDOpKernel<double> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 47\r\n3       0x7fd6289ba5a2p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 658\r\n4       0x7fd6289b446dp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 269\r\n5       0x7fd627c1d66ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 270\r\n6       0x7fd6286e0972p\r\n7       0x7fd627cdeceep std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*) + 46\r\n8       0x7fd65c500a99p\r\n9       0x7fd6286df677p\r\n10      0x7fd6289d5577p paddle::framework::ThreadPool::TaskLoop() + 1911\r\n11      0x7fd5cb0d2c80p\r\n12      0x7fd65c4f96bap\r\n13      0x7fd65c22f41dp clone + 109\r\n*** Check failure stack trace: ***\r\n    @     0x7fd627bd3a8d  google::LogMessage::Fail()\r\n    @     0x7fd627bd5dd8  google::LogMessage::SendToLog()\r\n    @     0x7fd627bd359b  google::LogMessage::Flush()\r\n    @     0x7fd627bd6cae  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fd6286e0a53  _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIS0_IN6paddle8platform13EnforceNotMetESt14default_deleteISA_EEEES3_ESt12_Bind_simpleIFSt17reference_wrapperIZNS8_9framework10ThreadPool18RunAndGetExceptionIZNS8_9operatorsL21ParallelExecuteBlocksERKSt6vectorImSaImEEPNSI_8ExecutorERKSM_ISt10shared_ptrINSI_22ExecutorPrepareContextEESaISV_EEPNSI_11ProgramDescEPNSI_5ScopeEEUlvE_EESt6futureISD_ET_EUlvE_EvEESD_EEE9_M_invokeERKSt9_Any_data\r\n    @     0x7fd627cdecee  std::__future_base::_State_baseV2::_M_do_set()\r\n    @     0x7fd65c500a99  __pthread_once_slow\r\n    @     0x7fd6286df677  _ZNSt13__future_base11_Task_stateIZN6paddle9framework10ThreadPool18RunAndGetExceptionIZNS1_9operatorsL21ParallelExecuteBlocksERKSt6vectorImSaImEEPNS2_8ExecutorERKS6_ISt10shared_ptrINS2_22ExecutorPrepareContextEESaISF_EEPNS2_11ProgramDescEPNS2_5ScopeEEUlvE_EESt6futureISt10unique_ptrINS1_8platform13EnforceNotMetESt14default_deleteISS_EEET_EUlvE_SaIiEFSV_vEE6_M_runEv\r\n    @     0x7fd6289d5577  paddle::framework::ThreadPool::TaskLoop()\r\n    @     0x7fd5cb0d2c80  (unknown)\r\n    @     0x7fd65c4f96ba  start_thread\r\n    @     0x7fd65c22f41d  clone\r\n    @              (nil)  (unknown)\r\n*** Aborted at 1542165594 (unix time) try \"date -d @1542165594\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 1 (TID 0x7fd35bfff700) from PID 0; stack trace: ***\r\n    @     0x7fd65c503390 (unknown)\r\n    @     0x7fd65c15f196 abort\r\n    @     0x7fd627bdee07 google::DumpStackTraceAndExit()\r\n    @     0x7fd627bd3a8d google::LogMessage::Fail()\r\n    @     0x7fd627bd5dd8 google::LogMessage::SendToLog()\r\n    @     0x7fd627bd359b google::LogMessage::Flush()\r\n    @     0x7fd627bd6cae google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fd6286e0a53 _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIS0_IN6paddle8platform13EnforceNotMetESt14default_deleteISA_EEEES3_ESt12_Bind_simpleIFSt17reference_wrapperIZNS8_9framework10ThreadPool18RunAndGetExceptionIZNS8_9operatorsL21ParallelExecuteBlocksERKSt6vectorImSaImEEPNSI_8ExecutorERKSM_ISt10shared_ptrINSI_22ExecutorPrepareContextEESaISV_EEPNSI_11ProgramDescEPNSI_5ScopeEEUlvE_EESt6futureISD_ET_EUlvE_EvEESD_EEE9_M_invokeERKSt9_Any_data\r\n    @     0x7fd627cdecee std::__future_base::_State_baseV2::_M_do_set()\r\n    @     0x7fd65c500a99 __pthread_once_slow\r\n    @     0x7fd6286df677 _ZNSt13__future_base11_Task_stateIZN6paddle9framework10ThreadPool18RunAndGetExceptionIZNS1_9operatorsL21ParallelExecuteBlocksERKSt6vectorImSaImEEPNS2_8ExecutorERKS6_ISt10shared_ptrINS2_22ExecutorPrepareContextEESaISF_EEPNS2_11ProgramDescEPNS2_5ScopeEEUlvE_EESt6futureISt10unique_ptrINS1_8platform13EnforceNotMetESt14default_deleteISS_EEET_EUlvE_SaIiEFSV_vEE6_M_runEv\r\n    @     0x7fd6289d5577 paddle::framework::ThreadPool::TaskLoop()\r\n    @     0x7fd5cb0d2c80 (unknown)\r\n    @     0x7fd65c4f96ba start_thread\r\n    @     0x7fd65c22f41d clone\r\n    @                0x0 (unknown)\r\n```\r\n\r\n已经按#1430中打好了补丁，如果用mod的话，不会出错。\r\n\r\nrelated: #1430",
        "state": "open",
        "user": "codescv",
        "closed_by": null,
        "created_at": "2018-11-14T03:27:22+00:00",
        "updated_at": "2018-12-12T12:40:26+00:00",
        "closed_at": null,
        "comments_count": [
            "codescv",
            "jacquesqiao",
            "codescv"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1461,
        "title": "deepLab3+是基于paddlepaddle的哪个版本",
        "body": "",
        "state": "closed",
        "user": "zhengzhe97",
        "closed_by": "zhengzhe97",
        "created_at": "2018-11-17T02:37:53+00:00",
        "updated_at": "2018-11-17T06:54:08+00:00",
        "closed_at": "2018-11-17T06:54:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1462,
        "title": "TypeError: assign() takes exactly 2 arguments (1 given)",
        "body": "![a _rt 9n1lnn w2q 4i2d](https://user-images.githubusercontent.com/26462054/48655787-8a1c5600-ea56-11e8-85f8-c64fefdf3d7e.png)\r\n",
        "state": "closed",
        "user": "zhengzhe97",
        "closed_by": "zhengzhe97",
        "created_at": "2018-11-17T02:50:10+00:00",
        "updated_at": "2018-11-17T06:54:19+00:00",
        "closed_at": "2018-11-17T06:54:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1455,
        "title": "Training-aware INT8 for SSD-MobileNet",
        "body": "I would like to try training-aware INT8 for MobileNetSSD. I followed the instructions in https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/object_detection/README_quant.md and ran the below command:\r\n \r\npython main_quant.py --data_dir=/lustre/dataset/VOC/VOCdevkit/VOC2012 --mode='train' --init_model=ssd_mobilenet_v1_pascalvoc --act_quant_type='abs_max' --epoc_num=20 --learning_rate=0.0001 --batch_size=64 --model_save_dir=train_int8\r\n \r\nIt shows the error message:\r\nTraceback (most recent call last):\r\n  File \"main_quant.py\", line 275, in <module>\r\n    ap_version = args.ap_version)\r\n  File \"/home/hshen14/paddle_public_models/fluid/PaddleCV/object_detection/reader.py\", line 45, in __init__\r\n    for line in open(label_fpath):\r\nIOError: [Errno 2] No such file or directory: '/lustre/dataset/VOC/VOCdevkit/VOC2012/label_list'\r\n\r\nI attached the structure under /lustre/dataset/VOC/VOCdevkit/VOC2012/ for your reference:\r\nAnnotations/        JPEGImages/         SegmentationObject/\r\nImageSets/          SegmentationClass/\r\n\r\nFrom the error message, looks like there is no label_list file. Could you please show the full structure at you side? Thanks.\r\n\r\n@qingqing01 @Superjomn \r\n",
        "state": "closed",
        "user": "hshen14",
        "closed_by": "qingqing01",
        "created_at": "2018-11-15T07:56:02+00:00",
        "updated_at": "2018-11-16T05:35:45+00:00",
        "closed_at": "2018-11-16T05:35:45+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01",
            "hshen14",
            "qingqing01"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1459,
        "title": "How to save MobileNet-SSD model? with detection mAP evaluator?",
        "body": "When training a MobileNet-SSD model, the `train.py` script allows for saving persistables using\r\n```\r\nfluid.io.save_persistables(exe, model_path, main_program=main_prog)\r\n```\r\nBut how can we save the whole model?\r\nIn order to save the whole model for inference using:\r\n```\r\nfluid.io.save_inference_model(\"abc\", feed_dict, [target], exe)\r\n```\r\nwe need to provide `feed_dict` and `target`.\r\n1. What should the `feed_dict` be?\r\nUsually, the `feed` argument of `exe.run()` method suggest the answer, but in MobileNet-SSD, the `feed` is not defined. The `py_reader` is used there.\r\n2. What should the `target` be?\r\nSeveral attempts to put anything into target failed with message\r\n```\r\nTraceback (most recent call last):\r\n...\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/io.py\", line 654, in save_inference_model\r\n    main_program = main_program._prune(targets=target_vars)\r\n  File \"/home/wojtuss/repos/PaddlePaddle/Paddle/build/python/paddle/fluid/framework.py\", line 1739, in _prune\r\n    \"The target variable must have an \"\r\nValueError: The target variable must have an associated operator that generates it.\r\n```\r\n3. Is it possible to save the model with the `DetectionMAP` evaluator?\r\n",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "qingqing01",
        "created_at": "2018-11-16T09:20:29+00:00",
        "updated_at": "2018-11-26T12:54:13+00:00",
        "closed_at": "2018-11-22T11:22:14+00:00",
        "comments_count": [
            "qingqing01",
            "wojtuss",
            "qingqing01",
            "wojtuss"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1456,
        "title": "Transformer Pre-trained weight",
        "body": "I would like to run the reproduce the bleu for transformer model. May I know whether there is pre-trained weight for sharing? Thanks. @Superjomn @panyx0718 @luotao1 \r\n\r\nhttps://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleNLP/neural_machine_translation/transformer/README_cn.md",
        "state": "open",
        "user": "hshen14",
        "closed_by": null,
        "created_at": "2018-11-15T08:42:51+00:00",
        "updated_at": "2018-12-07T12:26:51+00:00",
        "closed_at": null,
        "comments_count": [
            "panyx0718",
            "guoshengCS",
            "hshen14",
            "guoshengCS",
            "hshen14"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1464,
        "title": "执行face_detection时出现“EnforceNotMet: ptr_ should not be null”错误",
        "body": "环境：v100+paddle1.1+cuda9+cudnn7\r\n\r\n```\r\n[root@gpu.baidu.com face_detection]# fluid -u train.py --batch_size=1 --pretrained_model=vgg_ilsvrc_16_fc_reduced\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 1\r\ndata_dir: data\r\nepoc_num: 160\r\nlearning_rate: 0.001\r\nmean_BGR: 104., 117., 123.\r\nmodel_save_dir: output\r\nparallel: True\r\npretrained_model: vgg_ilsvrc_16_fc_reduced\r\nresize_h: 640\r\nresize_w: 640\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\nwith_mem_opt: True\r\n------------------------------------------------\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  invalid resource handle at [/paddle/paddle/fluid/framework/details/op_handle_base.cc:37]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f26547c8d06p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f2655b07fa2p paddle::framework::details::OpHandleBase::~OpHandleBase() + 402\r\n2       0x7f2655ae19e1p paddle::framework::details::FetchOpHandle::~FetchOpHandle() + 17\r\n3       0x7f2655aa3a4ep std::vector<std::unique_ptr<paddle::framework::details::FetchOpHandle, std::default_delete<paddle::framework::details::FetchOpHandle> >, std::allocator<std::unique_ptr<paddle::framework::details::FetchOpHandle, std::default_delete<paddle::framework::details::FetchOpHandle> > > >::~vector() + 46\r\n4       0x7f2655aa2b46p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 4390\r\n5       0x7f2655aa6b37p paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 391\r\n6       0x7f26548a90b9p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 489\r\n7       0x7f26547bd540p\r\n8       0x7f26547df414p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n9       0x7f26dcedebb8p PyEval_EvalFrameEx + 25016\r\n10      0x7f26dcee20bdp PyEval_EvalCodeEx + 2061\r\n11      0x7f26dcedf345p PyEval_EvalFrameEx + 26949\r\n12      0x7f26dcee20bdp PyEval_EvalCodeEx + 2061\r\n13      0x7f26dcedf345p PyEval_EvalFrameEx + 26949\r\n14      0x7f26dcee20bdp PyEval_EvalCodeEx + 2061\r\n15      0x7f26dcee21f2p PyEval_EvalCode + 50\r\n16      0x7f26dcf0af42p PyRun_FileExFlags + 146\r\n17      0x7f26dcf0c2d9p PyRun_SimpleFileExFlags + 217\r\n18      0x7f26dcf2200dp Py_Main + 3149\r\n19      0x7f26dc11fbd5p __libc_start_main + 245\r\n20            0x4007a1p\r\n\r\n*** Aborted at 1542616343 (unix time) try \"date -d @1542616343\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x5284a) received by PID 337994 (TID 0x7f26dd40e700) from PID 337994; stack trace: ***\r\n    @     0x7f26dcbc5160 (unknown)\r\n    @     0x7f26dc1333f7 __GI_raise\r\n    @     0x7f26dc1347d8 __GI_abort\r\n    @     0x7f26ce656c65 __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f26ce654e06 __cxxabiv1::__terminate()\r\n    @     0x7f26ce653ec9 __cxa_call_terminate\r\n    @     0x7f26ce654a7a __gxx_personality_v0\r\n    @     0x7f26d0d84853 _Unwind_RaiseException_Phase2\r\n    @     0x7f26d0d84beb _Unwind_RaiseException\r\n    @     0x7f26ce655045 __cxa_throw\r\n    @     0x7f2655b07fc0 paddle::framework::details::OpHandleBase::~OpHandleBase()\r\n    @     0x7f2655ae19e1 paddle::framework::details::FetchOpHandle::~FetchOpHandle()\r\n    @     0x7f2655aa3a4e std::vector<>::~vector()\r\n    @     0x7f2655aa2b46 paddle::framework::details::ThreadedSSAGraphExecutor::Run()\r\n    @     0x7f2655aa6b37 paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run()\r\n    @     0x7f26548a90b9 paddle::framework::ParallelExecutor::Run()\r\n    @     0x7f26547bd540 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL13pybind11_initEvEUlRNS2_9framework16ParallelExecutorERKSt6vectorISsSaISsEERKSsE102_vIS6_SB_SD_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESV_\r\n    @     0x7f26547df414 pybind11::cpp_function::dispatcher()\r\n    @     0x7f26dcedebb8 PyEval_EvalFrameEx\r\n    @     0x7f26dcee20bd PyEval_EvalCodeEx\r\n    @     0x7f26dcedf345 PyEval_EvalFrameEx\r\n    @     0x7f26dcee20bd PyEval_EvalCodeEx\r\n    @     0x7f26dcedf345 PyEval_EvalFrameEx\r\n    @     0x7f26dcee20bd PyEval_EvalCodeEx\r\n    @     0x7f26dcee21f2 PyEval_EvalCode\r\n    @     0x7f26dcf0af42 PyRun_FileExFlags\r\n    @     0x7f26dcf0c2d9 PyRun_SimpleFileExFlags\r\n    @     0x7f26dcf2200d Py_Main\r\n    @     0x7f26dc11fbd5 __libc_start_main\r\n    @           0x4007a1 (unknown)\r\n    @                0x0 (unknown)\r\nAborted\r\n```\r\n",
        "state": "closed",
        "user": "duanlin0505",
        "closed_by": "qingqing01",
        "created_at": "2018-11-19T06:50:07+00:00",
        "updated_at": "2018-12-11T14:58:50+00:00",
        "closed_at": "2018-12-11T14:58:50+00:00",
        "comments_count": [
            "duanlin0505",
            "qingqing01",
            "duanlin0505",
            "duanlin0505",
            "qingqing01",
            "qingqing01",
            "duanlin0505",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1471,
        "title": "ocr_recognition 的参数说明与代码不相符",
        "body": "说明中的 --train_images 与 --train_list 两个参数，在代码中并不存在；运行时，带上这两个参数会报错。",
        "state": "closed",
        "user": "icedream2linxi",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-11-22T16:25:36+00:00",
        "updated_at": "2018-11-27T02:04:43+00:00",
        "closed_at": "2018-11-27T02:04:43+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1469,
        "title": "How the accumulative MAP is calculated?",
        "body": "I have a MobileNet-SSD model with trained parameters from Baidu. Also, I have generated a model with the `DetectionMAP` layer saved. However, I can see the `DetectionMAP` requires some parameters which are not present with the model from Baidu. These parameters are used for calculation of the accumulative MAP. \r\nHow the accumulative MAP is calculated?\r\nCan it be calculated without those missing parameters? (e.g. as an average of bach MAPs)\r\nDo you have also trained parameters for the `DetectionMAP` layer?",
        "state": "closed",
        "user": "wojtuss",
        "closed_by": "wojtuss",
        "created_at": "2018-11-22T10:31:24+00:00",
        "updated_at": "2018-11-26T12:57:48+00:00",
        "closed_at": "2018-11-26T12:57:47+00:00",
        "comments_count": [
            "qingqing01",
            "sfraczek",
            "wojtuss",
            "sfraczek",
            "qingqing01",
            "wojtuss"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1473,
        "title": "fluid版本加载自定义数据时怎么样自己去创建reader？",
        "body": "问题描述：我现在有一个V2版本的程序想转化成fluid版本，在转化版本的过程中，发现V2加载自定义数据集和fluid加载的方法完全不同。\r\n1.看了你们官方文档里fluid的准备数据的文档，但是里面讲的都很模糊，有没有直接加载自定数据的完整方法的demo？\r\n![image](https://user-images.githubusercontent.com/13358316/48975696-a866ff00-f0b1-11e8-8e87-968f394fc3bd.png)\r\n![image](https://user-images.githubusercontent.com/13358316/48975716-24614700-f0b2-11e8-8e2a-adbb7e67626b.png)\r\n![image](https://user-images.githubusercontent.com/13358316/48975720-48bd2380-f0b2-11e8-9af0-4450d8004e05.png)\r\n3.之前V2版本中有paddle.reader.xmap_readers这个函数对数据进行映射，但在fluid版本中没有。我如果想在AI studio上用怎么办？\r\n![image](https://user-images.githubusercontent.com/13358316/48975660-fe877280-f0b0-11e8-8999-b3b1a3051e85.png)\r\n4.想在fluid把自定义数据集加载进来，并创建自己reader，有没有更清楚的教程文档？face_detection那个demo中加载自定义数据集的代码太长了，没有看懂，有没有简单的demo？\r\n建议：\r\n1.paddlepaddle的fluid对加载自定义数据集的方法进行优化，简单点，更便于推广。\r\n2.官方出一个V2版本和fluid版本的对比说明，哪些是新加的API，哪些V2版本的API在fluid版本改动了？还有哪些API在fluid版本中不用了？\r\n附：\r\n要加载成fluid版本reader的自定义的数据和V2版本代码\r\n\r\n[verification_code.zip](https://github.com/PaddlePaddle/models/files/2612852/verification_code.zip)\r\n\r\n\r\n",
        "state": "open",
        "user": "315536712",
        "closed_by": null,
        "created_at": "2018-11-25T05:19:45+00:00",
        "updated_at": "2018-11-29T03:59:10+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "shanyi15",
            "315536712",
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1494,
        "title": "tagspace多机报错",
        "body": "**多机下报如下错误：**\r\n```bash\r\n    train()\r\n  File \"cluster_train.py\", line 134, in train\r\n    train_loop(t.get_trainer_program())\r\n  File \"cluster_train.py\", line 114, in train_loop\r\n    fluid.io.save_inference_model(save_dir, feed_var_names, fetch_vars, exe)\r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/io.py\", line 629, in save_inference_model\r\n    os.makedirs(dirname)\r\n  File \"/usr/local/lib/python2.7/os.py\", line 157, in makedirs\r\n    mkdir(name, mode)\r\nOSError: [Errno 17] File exists: 'cluster_model/epoch_5'\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2018-12-03T07:22:27+00:00",
        "updated_at": "2018-12-03T08:55:07+00:00",
        "closed_at": "2018-12-03T08:55:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1487,
        "title": "gru4rec",
        "body": "多机下reader读数据时候应该根据trainer_id 切分",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2018-11-30T08:46:06+00:00",
        "updated_at": "2018-12-10T08:02:20+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "jackyhawk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1485,
        "title": "gru4rec 4卡下报错",
        "body": "```bash\r\n('use_cuda:', True, 'parallel:', True)\r\nstart constuct word dict\r\nepoch_1 start\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 125, in <module>\r\n    train()\r\n  File \"train.py\", line 105, in train\r\n    fetch_list=fetch_list)\r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 277, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: an illegal memory access was encountered at [/paddle/paddle/fluid/platform/device_context.cc:250]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f50aa2abda6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f50ab9f5e32p paddle::platform::CUDADeviceContext::Wait() const + 258\r\n2       0x7f50ab67e3e2p paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 850\r\n3       0x7f50aa38c0b9p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 489\r\n4       0x7f50aa2a05e0p\r\n5       0x7f50aa2c24b4p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n6       0x7f510bba83f9p PyEval_EvalFrameEx + 22841\r\n7       0x7f510bba948cp PyEval_EvalCodeEx + 2076\r\n8       0x7f510bba828ap PyEval_EvalFrameEx + 22474\r\n9       0x7f510bba83acp PyEval_EvalFrameEx + 22764\r\n10      0x7f510bba948cp PyEval_EvalCodeEx + 2076\r\n11      0x7f510bba95a9p PyEval_EvalCode + 25\r\n12      0x7f510bbcd32ap PyRun_FileExFlags + 138\r\n13      0x7f510bbce827p PyRun_SimpleFileExFlags + 231\r\n14      0x7f510bbe4f31p Py_Main + 3265\r\n15      0x7f510b4d6830p __libc_start_main + 240\r\n16            0x4006e9p _start + 41\r\n\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  an illegal memory access was encountered at [/paddle/paddle/fluid/platform/device_context.cc:250]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f50aa2abda6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f50ab9f5e32p paddle::platform::CUDADeviceContext::Wait() const + 258\r\n2       0x7f50aa388065p paddle::framework::ParallelExecutor::~ParallelExecutor() + 69\r\n3       0x7f50aa2a9023p pybind11::class_<paddle::framework::ParallelExecutor>::dealloc(_object*) + 35\r\n4       0x7f50aa2c0c81p pybind11_object_dealloc + 49\r\n5       0x7f510bb35cdbp\r\n6       0x7f510bb5779ep\r\n7       0x7f510bb20bc9p\r\n8       0x7f510bbd6d7bp\r\n9       0x7f510bbd6d8bp\r\n10      0x7f510bb36b07p\r\n11      0x7f510bb38577p PyDict_SetItem + 103\r\n12      0x7f510bb39d14p PyDict_SetItemString + 68\r\n13      0x7f510bbbc0ffp PyImport_Cleanup + 335\r\n14      0x7f510bbce1bep Py_Finalize + 254\r\n15      0x7f510bbe4864p Py_Main + 1524\r\n16      0x7f510b4d6830p __libc_start_main + 240\r\n17            0x4006e9p _start + 41\r\n\r\n*** Aborted at 1543478033 (unix time) try \"date -d @1543478033\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x795) received by PID 1941 (TID 0x7f510c0b6700) from PID 1941; stack trace: ***\r\n    @     0x7f510b891390 (unknown)\r\n    @     0x7f510b4eb428 gsignal\r\n    @     0x7f510b4ed02a abort\r\n    @     0x7f510150792d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f5101505996 __cxxabiv1::__terminate()\r\n    @     0x7f5101504a49 __cxa_call_terminate\r\n    @     0x7f5101505335 __gxx_personality_v0\r\n    @     0x7f5101a5ff83 (unknown)\r\n    @     0x7f5101a60487 _Unwind_Resume\r\n    @     0x7f50ab9f5fd6 paddle::platform::CUDADeviceContext::Wait()\r\n    @     0x7f50aa388065 paddle::framework::ParallelExecutor::~ParallelExecutor()\r\n    @     0x7f50aa2a9023 pybind11::class_<>::dealloc()\r\n    @     0x7f50aa2c0c81 pybind11_object_dealloc\r\n    @     0x7f510bb35cdb dict_dealloc\r\n    @     0x7f510bb5779e subtype_dealloc\r\n    @     0x7f510bb20bc9 frame_dealloc\r\n    @     0x7f510bbd6d7b tb_dealloc\r\n    @     0x7f510bbd6d8b tb_dealloc\r\n    @     0x7f510bb36b07 insertdict\r\n    @     0x7f510bb38577 PyDict_SetItem\r\n    @     0x7f510bb39d14 PyDict_SetItemString\r\n    @     0x7f510bbbc0ff PyImport_Cleanup\r\n    @     0x7f510bbce1be Py_Finalize\r\n    @     0x7f510bbe4864 Py_Main\r\n    @     0x7f510b4d6830 __libc_start_main\r\n    @           0x4006e9 _start\r\n    @                0x0 (unknown)\r\nAborted\r\n```\r\n**paddle_version: 1.1\r\n单卡下正常；**",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "frankwhzhang",
        "created_at": "2018-11-29T08:55:21+00:00",
        "updated_at": "2018-11-30T03:24:12+00:00",
        "closed_at": "2018-11-30T03:24:12+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1488,
        "title": "tagspace 多卡下acc计算错误",
        "body": "```bash\r\nuse_cuda: False, parallel: True, batch_size: 500, neg_size: 3 \r\nstart read file\r\nepoch_1 start\r\nTRAIN --> pass: 0 batch_num: 5000 avg_cost: 0.413585573435, acc: 1.464\r\nTRAIN --> pass: 0 batch_num: 10000 avg_cost: 0.214088305831, acc: 2.07\r\nTRAIN --> pass: 0 batch_num: 15000 avg_cost: 0.101050801575, acc: 1.864\r\nTRAIN --> pass: 0 batch_num: 20000 avg_cost: 0.062430229038, acc: 2.724\r\nTRAIN --> pass: 0 batch_num: 25000 avg_cost: 0.0621923878789, acc: 2.804\r\nTRAIN --> pass: 0 batch_num: 30000 avg_cost: 0.0370592586696, acc: 3.414\r\nepoch:1 num_steps:59 time_cost(s):18.301616\r\nepoch_2 start\r\nTRAIN --> pass: 1 batch_num: 5000 avg_cost: 0.0559089556336, acc: 3.138\r\nTRAIN --> pass: 1 batch_num: 10000 avg_cost: 0.0269613582641, acc: 3.632\r\nTRAIN --> pass: 1 batch_num: 15000 avg_cost: 0.0369474329054, acc: 3.472\r\nTRAIN --> pass: 1 batch_num: 20000 avg_cost: 0.0210609175265, acc: 3.702\r\nTRAIN --> pass: 1 batch_num: 25000 avg_cost: 0.0291672684252, acc: 3.588\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "frankwhzhang",
        "created_at": "2018-11-30T12:21:39+00:00",
        "updated_at": "2018-12-02T05:42:02+00:00",
        "closed_at": "2018-12-02T05:42:02+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1495,
        "title": "object-detection train VOC dataset error",
        "body": "Epoc 119, batch 480, loss 1.927295, time 0.40952\r\nEpoc 119, batch 500, loss 2.137074, time 0.45071\r\nBatch 0, map [0.76862]\r\nBatch 10, map [0.75564057]\r\nBatch 20, map [0.7315956]\r\nBatch 30, map [0.7257414]\r\nBatch 40, map [0.731006]\r\nBatch 50, map [0.7274335]\r\nBatch 60, map [0.73014474]\r\nBatch 70, map [0.72777504]\r\nBatch 80, map [0.7303445]\r\nBatch 90, map [0.72797]\r\nBatch 100, map [0.7287172]\r\nBatch 110, map [0.7259103]\r\nBatch 120, map [0.72657454]\r\nBatch 130, map [0.72408175]\r\nBatch 140, map [0.7239978]\r\nBatch 150, map [0.7226571]\r\nEpoc 119, test map [0.72133386]\r\nBest test map 0.723139166832\r\nsave models to model/119\r\n*** Aborted at 1543875979 (unix time) try \"date -d @1543875979\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x8) received by PID 6048 (TID 0x7feafe425700) from PID 8; stack trace: ***\r\n    @     0x7feb5b6ac390 (unknown)\r\n    @           0x4bd6b0 PyEval_EvalFrameEx\r\n    @           0x4b9b66 PyEval_EvalCodeEx\r\n    @           0x4d57a3 (unknown)\r\n    @           0x4a587e PyObject_Call\r\n    @           0x4be51e PyEval_EvalFrameEx\r\n    @           0x4c141f PyEval_EvalFrameEx\r\n    @           0x4c141f PyEval_EvalFrameEx\r\n    @           0x4b9b66 PyEval_EvalCodeEx\r\n    @           0x4d5669 (unknown)\r\n    @           0x4eef5e (unknown)\r\n    @           0x4a587e PyObject_Call\r\n    @           0x4c5ef0 PyEval_CallObjectWithKeywords\r\n    @           0x589662 (unknown)\r\n    @     0x7feb5b6a26ba start_thread\r\n    @     0x7feb5b3d841d clone\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\n\r\n",
        "state": "closed",
        "user": "dreamonezero",
        "closed_by": "qingqing01",
        "created_at": "2018-12-04T02:03:11+00:00",
        "updated_at": "2019-01-24T06:39:53+00:00",
        "closed_at": "2019-01-24T06:39:53+00:00",
        "comments_count": [
            "qingqing01",
            "abcdvzz",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1496,
        "title": "使用save_inference_model()保存crnnctc的__model__文件",
        "body": "1. 在models/fluid/PaddleCV/ocr_recognition, 我想使用train.py的def test()里添加以下下面的代码来保存crnn_ctc的__model__文件\r\n\r\nfluid.io.save_inference_model(args.save_model_dir,[\"image\",\"label\"],test_seq_error,exe,main_program=inference_program)\r\n\r\n但运行有错误  ValueError: 'target_vars' should be a list of Variable.\r\n也尝试了 fluid.io.save_inference_model(args.save_model_dir,[\"image\",\"label\"],[test_seq_error[0]],exe,main_program=inference_program)，还是一样的错误，请问怎么存啊？\r\n\r\n2. 如果可以，能否提供crnn_ctc的__model__可以参考下，如果是有accuracy layer就更好了，没有的话我也可以自己存。 谢谢",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2018-12-04T04:23:45+00:00",
        "updated_at": "2018-12-04T12:58:22+00:00",
        "closed_at": "2018-12-04T12:49:53+00:00",
        "comments_count": [
            "luotao1",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1497,
        "title": "deeplabv3+如何自定义类别？",
        "body": "我换了一个数据集，将train.py的num_classes改成10并把models.py里的label_number改成10。但是运行就报错：\r\n  File \"./train.py\", line 148, in <module>\r\n    'label': labels})\r\n  File \"/home/cll/.local/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 277, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:-11235850 != -in_size:-11235859.\r\nInvalid shape is given. at [/paddle/paddle/fluid/operators/reshape_op.cc:98]\r\nPaddlePaddle Call Stacks:\r\n而且我发现只有调整为默认的19它才不报错，请问应该如何修改？\r\n还有train.py里的loss\r\nlabel_nignore = (label < num_classes).astype('float32')\r\n这个是什么意思？",
        "state": "open",
        "user": "408550969",
        "closed_by": null,
        "created_at": "2018-12-04T08:40:52+00:00",
        "updated_at": "2019-01-14T07:24:12+00:00",
        "closed_at": null,
        "comments_count": [
            "xieqingxing",
            "408550969",
            "cjld",
            "xieqingxing",
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1503,
        "title": "Is the fluid released resnet50 pretrained model converted from paddle v2 or retrained from the ImageNet?",
        "body": "Hello, we use the released pretrained ResNet50 model to extract features from the last pool layer to make bottleneck training. But we find that compared to original v2 version, fluid version has relatively 1~2 percent accuracy decline.  So here are two questions:\r\n1、Is the fluid released resnet50 pretrained model converted from paddle v2 version?\r\n2、Is there any way to convert v2 model weights to fluid model weights?",
        "state": "open",
        "user": "TheodoreG",
        "closed_by": null,
        "created_at": "2018-12-06T06:19:37+00:00",
        "updated_at": "2018-12-06T06:43:51+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1509,
        "title": "paddle.layer.classification_cost(input=out, label=label)这个api对应到fluid中需要怎么写？",
        "body": "paddle.layer.classification_cost(input=out, label=label)这个api对应到fluid中需要怎么写？",
        "state": "closed",
        "user": "315536712",
        "closed_by": "315536712",
        "created_at": "2018-12-08T14:52:32+00:00",
        "updated_at": "2018-12-08T14:57:24+00:00",
        "closed_at": "2018-12-08T14:57:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1504,
        "title": "This lines are so slow, consider to make pattern as a global variable.",
        "body": "https://github.com/PaddlePaddle/models/blob/8c32619e8ccb16bb66b900713de303233c9489dc/fluid/PaddleRec/word2vec/preprocess.py#L35-L36",
        "state": "closed",
        "user": "reyoung",
        "closed_by": "JiabinYang",
        "created_at": "2018-12-06T06:29:31+00:00",
        "updated_at": "2018-12-27T02:19:40+00:00",
        "closed_at": "2018-12-27T02:19:40+00:00",
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1506,
        "title": "ShuffleNet Pre-trained model and accuracy",
        "body": "shufflenet_v2.py is one of image classification models. Could you please share the pre-trained model and the corresponding accuracy?",
        "state": "closed",
        "user": "hshen14",
        "closed_by": "shippingwang",
        "created_at": "2018-12-07T08:34:11+00:00",
        "updated_at": "2019-05-13T14:05:51+00:00",
        "closed_at": "2019-04-12T07:21:57+00:00",
        "comments_count": [
            "shippingwang",
            "shippingwang",
            "zzchust"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1507,
        "title": "models/legacy/sequence_tagging_for_ner",
        "body": "models/legacy/sequence_tagging_for_ner 运行失败，提示除数为0",
        "state": "open",
        "user": "ylxsyf",
        "closed_by": null,
        "created_at": "2018-12-07T08:46:11+00:00",
        "updated_at": "2018-12-07T09:33:09+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1510,
        "title": "【自定义图像分类infer时出现错误】EnforceNotMet: Enforce failed. Expected in_dims[1] == filter_dims[1] * groups, but received in_dims[1]:4 != filter_dims[1] * groups:3.",
        "body": "问题描述：自定义图像数据集训练的是时候都没有问题，模型也都保存了，但是在进行预测的时候报错。\r\n使用的模型：vgg\r\n参照的代码：03.image_classification\r\n详细报错：\r\n---------------------------------------------------------------------------\r\nEnforceNotMet                             Traceback (most recent call last)\r\n<ipython-input-11-e5f85816241b> in <module>\r\n     61 \r\n     62 \r\n---> 63 infer(use_cuda=False, params_dirname='/home/aistudio/data2187/model')\r\n     64 print('over')\r\n\r\n<ipython-input-11-e5f85816241b> in infer(use_cuda, params_dirname)\r\n     44             inference_program,\r\n     45             feed={feed_target_names[0]: img},\r\n---> 46             fetch_list=fetch_targets)\r\n     47 \r\n     48         transpiler_results = exe.run(\r\n\r\n/opt/conda/envs/py35-paddle1.0.0/lib/python3.5/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    468 \r\n    469         self._feed_data(program, feed, feed_var_name, scope)\r\n--> 470         self.executor.run(program.desc, scope, 0, True, True)\r\n    471         outs = self._fetch_data(fetch_list, fetch_var_name, scope)\r\n    472         if return_numpy:\r\n\r\nEnforceNotMet: Enforce failed. Expected in_dims[1] == filter_dims[1] * groups, but received in_dims[1]:4 != filter_dims[1] * groups:3.\r\nThe number of input channels should be equal to filter channels * groups. at [/paddle/paddle/fluid/operators/conv_op.cc:60]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f3fe209e426p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f3fe290d616p paddle::operators::ConvOp::InferShape(paddle::framework::InferShapeContext*) const + 5622\r\n2       0x7f3fe2c121edp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 77\r\n3       0x7f3fe2c0e7bfp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 255\r\n4       0x7f3fe215f2eap paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 298\r\n5       0x7f3fe215fce0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n6       0x7f3fe2085cddp\r\n7       0x7f3fe20d0be4p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n8       0x7f401de1f199p PyCFunction_Call + 233\r\n9       0x7f401deba3f9p PyEval_EvalFrameEx + 33545\r\n10      0x7f401debc4b6p\r\n11      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n12      0x7f401debc4b6p\r\n13      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n14      0x7f401debc4b6p\r\n15      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n16      0x7f401debc5ebp PyEval_EvalCode + 59\r\n17      0x7f401deafc5dp\r\n18      0x7f401de1f179p PyCFunction_Call + 201\r\n19      0x7f401deb9dbep PyEval_EvalFrameEx + 31950\r\n20      0x7f401ddf3410p _PyGen_Send + 128\r\n21      0x7f401deb8953p PyEval_EvalFrameEx + 26723\r\n22      0x7f401ddf3410p _PyGen_Send + 128\r\n23      0x7f401deb8953p PyEval_EvalFrameEx + 26723\r\n24      0x7f401ddf3410p _PyGen_Send + 128\r\n25      0x7f401deb9d60p PyEval_EvalFrameEx + 31856\r\n26      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n27      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n28      0x7f401debc4b6p\r\n29      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n30      0x7f401ddfbc33p\r\n31      0x7f401ddca33ap PyObject_Call + 106\r\n32      0x7f401deb46eep PyEval_EvalFrameEx + 9726\r\n33      0x7f401debc4b6p\r\n34      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n35      0x7f401ddf26bap\r\n36      0x7f401deadaf6p\r\n37      0x7f401de1f179p PyCFunction_Call + 201\r\n38      0x7f401deb9dbep PyEval_EvalFrameEx + 31950\r\n39      0x7f401debc4b6p\r\n40      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n41      0x7f401ddf26bap\r\n42      0x7f401deadaf6p\r\n43      0x7f401de1f179p PyCFunction_Call + 201\r\n44      0x7f401deb9dbep PyEval_EvalFrameEx + 31950\r\n45      0x7f401debc4b6p\r\n46      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n47      0x7f401ddf26bap\r\n48      0x7f401deadaf6p\r\n49      0x7f401de1f179p PyCFunction_Call + 201\r\n50      0x7f401deb9dbep PyEval_EvalFrameEx + 31950\r\n51      0x7f401debc4b6p\r\n52      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n53      0x7f401ddfbb56p\r\n54      0x7f401ddca33ap PyObject_Call + 106\r\n55      0x7f401deb46eep PyEval_EvalFrameEx + 9726\r\n56      0x7f401ddf3410p _PyGen_Send + 128\r\n57      0x7f401deb9d60p PyEval_EvalFrameEx + 31856\r\n58      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n59      0x7f401debc4b6p\r\n60      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n61      0x7f401ddfbc33p\r\n62      0x7f401ddca33ap PyObject_Call + 106\r\n63      0x7f401deb46eep PyEval_EvalFrameEx + 9726\r\n64      0x7f401debc4b6p\r\n65      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n66      0x7f401ddfbb56p\r\n67      0x7f401ddca33ap PyObject_Call + 106\r\n68      0x7f401df2fccap\r\n69      0x7f401ddca33ap PyObject_Call + 106\r\n70      0x7f401deb64c5p PyEval_EvalFrameEx + 17365\r\n71      0x7f401debc4b6p\r\n72      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n73      0x7f401ddfbb56p\r\n74      0x7f401ddca33ap PyObject_Call + 106\r\n75      0x7f401deb46eep PyEval_EvalFrameEx + 9726\r\n76      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n77      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n78      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n79      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n80      0x7f401deba1d0p PyEval_EvalFrameEx + 32992\r\n81      0x7f401debc4b6p\r\n82      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n83      0x7f401debc4b6p\r\n84      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n85      0x7f401debc5ebp PyEval_EvalCode + 59\r\n86      0x7f401deafc5dp\r\n87      0x7f401de1f179p PyCFunction_Call + 201\r\n88      0x7f401deb9dbep PyEval_EvalFrameEx + 31950\r\n89      0x7f401debc4b6p\r\n90      0x7f401deb95b5p PyEval_EvalFrameEx + 29893\r\n91      0x7f401debc4b6p\r\n92      0x7f401debc5a8p PyEval_EvalCodeEx + 72\r\n93      0x7f401ddfbb56p\r\n94      0x7f401ddca33ap PyObject_Call + 106\r\n95      0x7f401df08ba1p\r\n96      0x7f401df094a5p Py_Main + 1493\r\n97            0x400b54p main + 356\r\n98      0x7f401ce7d830p __libc_start_main + 240\r\n99            0x400c01p",
        "state": "closed",
        "user": "315536712",
        "closed_by": "wzzju",
        "created_at": "2018-12-09T04:24:31+00:00",
        "updated_at": "2018-12-14T06:41:50+00:00",
        "closed_at": "2018-12-14T06:41:50+00:00",
        "comments_count": [
            "wzzju",
            "315536712"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1511,
        "title": "Face detection run error",
        "body": "Something went wrong when I ran the code:\r\n\r\n> -----------  Configuration Arguments -----------\r\nbatch_size: 16\r\ndata_dir: data\r\nepoc_num: 160\r\nlearning_rate: 0.001\r\nmean_BGR: 104., 117., 123.\r\nmodel_save_dir: output\r\nparallel: True\r\npretrained_model: vgg_ilsvrc_16_fc_reduced\r\nresize_h: 640\r\nresize_w: 640\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\nwith_mem_opt: True\r\n\r\n ------------------------------------------------\r\n\r\n>Traceback (most recent call last):\r\n  File \"train.py\", line 233, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"train.py\", line 133, in train\r\n    exe.run(startup_prog)\r\n  File \"/home/yzzc/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot run operator on place CUDAPlace(0) at [/paddle/paddle/fluid/framework/operator.cc:145]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6868e8bb16p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f6869c9e8e2p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 658\r\n2       0x7f6868f57140p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 224\r\n3       0x7f6868f57840p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n4       0x7f6868e7997bp\r\n5       0x7f6868ea9ba0p\r\n6             0x4ea137p PyCFunction_Call + 119\r\n7             0x53c176p PyEval_EvalFrameEx + 23030\r\n8             0x53fc97p\r\n9             0x53b83fp PyEval_EvalFrameEx + 20671\r\n10            0x5401efp\r\n11            0x53bc93p PyEval_EvalFrameEx + 21779\r\n12            0x53fc97p\r\n13            0x5409bfp PyEval_EvalCode + 31\r\n14            0x60cb42p\r\n15            0x60efeap PyRun_FileExFlags + 154\r\n16            0x60f7dcp PyRun_SimpleFileExFlags + 444\r\n17            0x640256p Py_Main + 1110\r\n18            0x4d0001p main + 225\r\n19      0x7f68c7758830p __libc_start_main + 240\r\n20            0x5d6999p _start + 41\r\n",
        "state": "closed",
        "user": "abcdvzz",
        "closed_by": "abcdvzz",
        "created_at": "2018-12-09T11:10:09+00:00",
        "updated_at": "2018-12-10T07:29:14+00:00",
        "closed_at": "2018-12-10T07:29:14+00:00",
        "comments_count": [
            "wzzju",
            "qingqing01"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1512,
        "title": "cuda error",
        "body": "> -----------  Configuration Arguments -----------\r\nbatch_size: 16\r\ndata_dir: data\r\nepoc_num: 160\r\nlearning_rate: 0.001\r\nmean_BGR: 104., 117., 123.\r\nmodel_save_dir: output\r\nparallel: True\r\npretrained_model: vgg_ilsvrc_16_fc_reduced\r\nresize_h: 640\r\nresize_w: 640\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\nwith_mem_opt: True\r\n------------------------------------------------\r\nW1209 20:38:51.853999 28655 device_context.cc:213] Please NOTE: device: 0, CUDA Capability: 61, Driver Version: 9.2, Runtime Version: 9.0\r\nW1209 20:38:51.854032 28655 device_context.cc:220] device: 0, cuDNN Version: 7.0.\r\nW1209 20:38:52.456357 28655 dynamic_loader.cc:101] Can not find library: libnccl.so. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 233, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"train.py\", line 162, in train\r\n    loss_name=loss.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/parallel_executor.py\", line 176, in __init__\r\n    build_strategy, num_trainers, trainer_id)\r\npaddle.fluid.core.EnforceNotMet: Failed to find dynamic library: libnccl.so ( libcudart.so.9.2: cannot open shared object file: No such file or directory ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:157]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f400bcba626p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f400d5ae12ep paddle::platform::dynload::GetNCCLDsoHandle() + 1822\r\n2       0x7f400bdb2099p void std::__once_call_impl<std::_Bind_simple<decltype (ncclCommInitAll({parm#1}...)) paddle::platform::dynload::DynLoad__ncclCommInitAll::operator()<ncclComm**, int, int*>(ncclComm**, int, int*)::{lambda()#1} ()> >() + 9\r\n3       0x7f407ae4ea99p\r\n4       0x7f400bdb575bp paddle::platform::NCCLContextMap::NCCLContextMap(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, ncclUniqueId*, unsigned long, unsigned long) + 2235\r\n5       0x7f400bdb109ep paddle::framework::ParallelExecutor::ParallelExecutor(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long) + 3854\r\n6       0x7f400bd1340cp\r\n7       0x7f400bd134fep\r\n8       0x7f400bce238ep\r\n9             0x4ea137p PyCFunction_Call + 119\r\n10            0x5c20e7p PyObject_Call + 71\r\n11            0x4fbfcep\r\n12            0x5c20e7p PyObject_Call + 71\r\n13            0x574c19p\r\n14            0x57f58cp\r\n15            0x5c20e7p PyObject_Call + 71\r\n16            0x53b656p PyEval_EvalFrameEx + 20182\r\n17            0x540b0bp PyEval_EvalCodeEx + 315\r\n18            0x4ec3f7p\r\n19            0x5c20e7p PyObject_Call + 71\r\n20            0x4fbfcep\r\n21            0x5c20e7p PyObject_Call + 71\r\n22            0x574c19p\r\n23            0x57f58cp\r\n24            0x5c20e7p PyObject_Call + 71\r\n25            0x53b656p PyEval_EvalFrameEx + 20182\r\n26            0x5401efp\r\n27            0x53bc93p PyEval_EvalFrameEx + 21779\r\n28            0x53fc97p\r\n29            0x5409bfp PyEval_EvalCode + 31\r\n30            0x60cb42p\r\n31            0x60efeap PyRun_FileExFlags + 154\r\n32            0x60f7dcp PyRun_SimpleFileExFlags + 444\r\n33            0x640256p Py_Main + 1110\r\n34            0x4d0001p main + 225\r\n35      0x7f407aa96830p __libc_start_main + 240\r\n36            0x5d6999p _start + 41\r\n at [/paddle/paddle/fluid/platform/nccl_helper.h:108]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f400bcba626p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f400bdb5961p paddle::platform::NCCLContextMap::NCCLContextMap(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, ncclUniqueId*, unsigned long, unsigned long) + 2753\r\n2       0x7f400bdb109ep paddle::framework::ParallelExecutor::ParallelExecutor(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, unsigned long, unsigned long) + 3854\r\n3       0x7f400bd1340cp\r\n4       0x7f400bd134fep\r\n5       0x7f400bce238ep\r\n6             0x4ea137p PyCFunction_Call + 119\r\n7             0x5c20e7p PyObject_Call + 71\r\n8             0x4fbfcep\r\n9             0x5c20e7p PyObject_Call + 71\r\n10            0x574c19p\r\n11            0x57f58cp\r\n12            0x5c20e7p PyObject_Call + 71\r\n13            0x53b656p PyEval_EvalFrameEx + 20182\r\n14            0x540b0bp PyEval_EvalCodeEx + 315\r\n15            0x4ec3f7p\r\n16            0x5c20e7p PyObject_Call + 71\r\n17            0x4fbfcep\r\n18            0x5c20e7p PyObject_Call + 71\r\n19            0x574c19p\r\n20            0x57f58cp\r\n21            0x5c20e7p PyObject_Call + 71\r\n22            0x53b656p PyEval_EvalFrameEx + 20182\r\n23            0x5401efp\r\n24            0x53bc93p PyEval_EvalFrameEx + 21779\r\n25            0x53fc97p\r\n26            0x5409bfp PyEval_EvalCode + 31\r\n27            0x60cb42p\r\n28            0x60efeap PyRun_FileExFlags + 154\r\n29            0x60f7dcp PyRun_SimpleFileExFlags + 444\r\n30            0x640256p Py_Main + 1110\r\n31            0x4d0001p main + 225\r\n32      0x7f407aa96830p __libc_start_main + 240\r\n33            0x5d6999p _start + 41\r\n",
        "state": "closed",
        "user": "abcdvzz",
        "closed_by": "abcdvzz",
        "created_at": "2018-12-09T13:00:58+00:00",
        "updated_at": "2018-12-10T07:29:28+00:00",
        "closed_at": "2018-12-10T07:29:28+00:00",
        "comments_count": [
            "wzzju",
            "qingqing01"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1514,
        "title": "Face detection Validation",
        "body": "When I ran the validation code, I encoutered this error. Pls help me . I raised lots of questions yesterday. Pls, or I'll be fired soon.\r\n> -----------  Configuration Arguments -----------\r\nconfs_threshold: 0.15\r\ndata_dir: data/WIDER_val/images/\r\nfile_list: data/wider_face_split/wider_face_val_bbx_gt.txt\r\nimage_path: \r\ninfer: False\r\nmodel_dir: PyramidBox_WiderFace/\r\npred_dir: pred\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\n\r\n> W1210\r\n\r\n 10:20:21.553225 13318 device_context.cc:203] Please NOTE: device: 0, CUDA Capability: 61, Driver Version: 9.2, Runtime Version: 9.0\r\nW1210 10:20:21.553249 13318 device_context.cc:210] device: 0, cuDNN Version: 7.0.\r\nW1210 10:20:22.738585 13318 system_allocator.cc:122] Cannot malloc 217.012 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use environment variable to a lower value. Current value is 5e-06\r\nW1210 10:20:22.738677 13318 legacy_allocator.cc:161] Cannot allocate 217.011719MB in GPU 0, available 201.375000MB\r\nW1210 10:20:22.738684 13318 legacy_allocator.cc:164] total 12787122176\r\nW1210 10:20:22.738692 13318 legacy_allocator.cc:165] GpuMinChunkSize 256.000000B\r\nW1210 10:20:22.738700 13318 legacy_allocator.cc:168] GpuMaxChunkSize 59.314453kB\r\nW1210 10:20:22.738708 13318 legacy_allocator.cc:171] GPU memory used: 902.250000kB\r\nTraceback (most recent call last):\r\n  File \"widerface_eval.py\", line 317, in <module>\r\n    infer(args, config)\r\n  File \"widerface_eval.py\", line 63, in infer\r\n    [det2, det3] = multi_scale_test(image, max_shrink)\r\n  File \"widerface_eval.py\", line 203, in multi_scale_test\r\n    det_b = detect_face(image, bt)\r\n  File \"widerface_eval.py\", line 121, in detect_face\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\nRuntimeError: parallel_for failed: out of memory\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  cudaFree{Host} failed in GPUAllocator::Free.: an illegal memory access was encountered at [/paddle/paddle/fluid/memory/detail/system_allocator.cc:150]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fa26295ce86p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7fa2641fda0ap paddle::memory::detail::GPUAllocator::Free(void*, unsigned long, unsigned long) + 266\r\n2       0x7fa2641fb922p paddle::memory::detail::BuddyAllocator::Free(void*) + 1122\r\n3       0x7fa2641f78a5p paddle::memory::allocation::LegacyAllocator::Free(paddle::memory::allocation::Allocation*) + 69\r\n4       0x7fa262960949p std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() + 57\r\n5       0x7fa262961cfdp paddle::framework::Variable::PlaceholderImpl<paddle::framework::LoDTensor>::~PlaceholderImpl() + 61\r\n6       0x7fa26419999dp paddle::framework::Scope::~Scope() + 141\r\n7       0x7fa2641998a1p paddle::framework::Scope::DropKids() + 81\r\n8       0x7fa26419992dp paddle::framework::Scope::~Scope() + 29\r\n9       0x7fa26295a80ap\r\n\r\n*** Aborted at 1544408422 (unix time) try \"date -d @1544408422\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x3e800003406) received by PID 13318 (TID 0x7fa2b30c2700) from PID 13318; stack trace: ***\r\n    @     0x7fa2b2cb9390 (unknown)\r\n    @     0x7fa2b2913428 gsignal\r\n    @     0x7fa2b291502a abort\r\n    @     0x7fa2a891884d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7fa2a89166b6 (unknown)\r\n    @     0x7fa2a89156a9 (unknown)\r\n    @     0x7fa2a8916005 __gxx_personality_v0\r\n    @     0x7fa2a8e37f83 (unknown)\r\n    @     0x7fa2a8e38487 _Unwind_Resume\r\n    @     0x7fa2641fbc75 paddle::memory::detail::BuddyAllocator::Free()\r\n    @     0x7fa2641f78a5 paddle::memory::allocation::LegacyAllocator::Free()\r\n    @     0x7fa262960949 std::_Sp_counted_base<>::_M_release()\r\n    @     0x7fa262961cfd paddle::framework::Variable::PlaceholderImpl<>::~PlaceholderImpl()\r\n    @     0x7fa26419999d paddle::framework::Scope::~Scope()\r\n    @     0x7fa2641998a1 paddle::framework::Scope::DropKids()\r\n    @     0x7fa26419992d paddle::framework::Scope::~Scope()\r\n",
        "state": "open",
        "user": "abcdvzz",
        "closed_by": null,
        "created_at": "2018-12-10T02:25:44+00:00",
        "updated_at": "2020-02-28T09:04:37+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "JWei-D",
            "abcdvzz",
            "YanYan0716",
            "LeLiu",
            "chengduoZH",
            "zhhsplendid",
            "LeLiu",
            "qingqing01",
            "LeLiu",
            "qingqing01",
            "LeLiu",
            "phamkhactu"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1513,
        "title": "Face detection only for one GPU?",
        "body": "When I trained the face detection model, I found that if there are more than one GPU visible, the training would encounter error： \r\n>  \r\n*** Aborted at 1544374351 (unix time) try \"date -d @1544374351\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 32735 (TID 0x7f5aa0848700) from PID 0; stack trace: ***\r\n    @     0x7f5aa0440390 (unknown)\r\n    @                0x0 (unknown)\r\n",
        "state": "open",
        "user": "abcdvzz",
        "closed_by": "qingqing01",
        "created_at": "2018-12-09T16:57:28+00:00",
        "updated_at": "2018-12-14T12:50:46+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "abcdvzz",
            "qingqing01",
            "abcdvzz"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1518,
        "title": "docker中升级python2.7到python3.5后，无法安装paddlepaddle？",
        "body": "\r\n安装完最新版的paddle的docker之后，升级python2.7到python3.5，在用pip install paddlepaddle安装不上paddle\r\n![clipboard](https://user-images.githubusercontent.com/13358316/49788962-b67d7680-fd65-11e8-8b43-11efc2d3b956.png)\r\n![clipboard1](https://user-images.githubusercontent.com/13358316/49788968-b9786700-fd65-11e8-8721-56cc6ec638ee.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "315536712",
        "closed_by": "315536712",
        "created_at": "2018-12-11T08:57:55+00:00",
        "updated_at": "2018-12-11T09:10:16+00:00",
        "closed_at": "2018-12-11T09:10:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1515,
        "title": "paddlepaddle 如何查看版本?",
        "body": "paddlepaddle 如何查看目前安装的是哪个版本?",
        "state": "open",
        "user": "jackyhawk",
        "closed_by": null,
        "created_at": "2018-12-10T08:00:02+00:00",
        "updated_at": "2018-12-12T02:45:51+00:00",
        "closed_at": null,
        "comments_count": [
            "imistyrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1517,
        "title": "环境1.2.0post87,跑 paddle 模型库里的ICNET出错，CPU运行正常，GPU出错如下 paddle.fluid.core.EnforceNotMet: CUDNN_STATUS_BAD_PARAM at [/paddle/paddle/fluid/operators/batch_norm_op.cu.cc:114]",
        "body": "raceback (most recent call last):\r\n  File \"/temp/icnet_test/train.py\", line 153, in <module>\r\n    main()\r\n  File \"/temp/icnet_test/train.py\", line 149, in main\r\n    train(args)\r\n  File \"/temp/icnet_test/train.py\", line 121, in train\r\n    fetch_list=[reduced_loss, loss_sub4, loss_sub24, loss_sub124])\r\n  File \"/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: CUDNN_STATUS_BAD_PARAM at [/paddle/paddle/fluid/operators/batch_norm_op.cu.cc:114]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f4b264f3776p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f4b267733bdp paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 5133\r\n2       0x7f4b26774123p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n3       0x7f4b27b6ec3cp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 492\r\n4       0x7f4b27b6b47fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 463\r\n5       0x7f4b265c143bp paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 219\r\n6       0x7f4b265c2090p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n7       0x7f4b264d6a5dp\r\n8       0x7f4b26509e84p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n9             0x4c5326p PyEval_EvalFrameEx + 37958\r\n10            0x4b9b66p PyEval_EvalCodeEx + 774\r\n11            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4eb69fp\r\n18            0x4e58f2p PyRun_FileExFlags + 130\r\n19            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n20            0x4938cep Py_Main + 1358\r\n21      0x7f4b67c65830p __libc_start_main + 240\r\n22            0x493299p _start + 41",
        "state": "open",
        "user": "Hizhaoyuan",
        "closed_by": null,
        "created_at": "2018-12-11T06:08:48+00:00",
        "updated_at": "2018-12-12T07:41:08+00:00",
        "closed_at": null,
        "comments_count": [
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1519,
        "title": "models/legacy/ctr 下 执行报错 （尝试了 paddlepaddle1.1.0 和 1.2.0 都报错）",
        "body": "+ /data0/home/jy/python_installed/bin/python train.py --train_data_path /data0/home/jy/models/legacy/ctr/output/train.txt --test_data_path /data0/home/jy/models/legacy/ctr/output/test.txt --data_meta_file /data0/home/jy/models/legacy/ctr/output/data.meta.txt --model_type=0                                                             \r\nI1211 17:36:28.149034 48067 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1                                                                              \r\nINFO:paddle:dnn input dim: 61                                                                                                                                          \r\nINFO:paddle:lr input dim: 10040001                                                                                                                                     \r\nI1211 17:36:28.244935 48067 GradientMachine.cpp:94] Initing parameters..                                                                                               \r\nI1211 17:36:28.840200 48067 GradientMachine.cpp:101] Init parameters done.                                                                                             \r\nINFO:paddle:load trainset from /data0/home/jy/models/legacy/ctr/output/train.txt                                                                                       \r\nWARNING:paddle:Pass 0, Samples 0, Cost 0.686135, {}                                                                                                                    \r\nINFO:paddle:load testset from /data0/home/jy/models/legacy/ctr/output/test.txt                                                                                         \r\nend___before                                                                                                                                                           \r\nbefore                                                                                                                                                                 \r\nTraceback (most recent call last):                                                                                                                                     \r\n  File \"train.py\", line 114, in <module>                                                                                                                               \r\n    train()                                                                                                                                                            \r\n  File \"train.py\", line 110, in train                                                                                                                                  \r\n    num_passes=args.num_passes)                                                                                                                                        \r\n  File \"/data0/home/jy/python_installed/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 206, in train                                                          \r\n    gm=self.__gradient_machine__))                                                                                                                                     \r\n  File \"train.py\", line 92, in __event_handler__                                                                                                                       \r\n    feeding=reader.feeding_index)                                                                                                                                      \r\n  File \"/data0/home/jy/python_installed/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 247, in test                                                           \r\n    evaluator=evaluator, cost=total_cost / num_samples)                                                                                                                \r\nZeroDivisionError: float division by zero                                                                                                                              \r\n~                                                  ",
        "state": "closed",
        "user": "jackyhawk",
        "closed_by": "jackyhawk",
        "created_at": "2018-12-11T09:39:41+00:00",
        "updated_at": "2019-02-25T12:28:40+00:00",
        "closed_at": "2018-12-12T03:42:44+00:00",
        "comments_count": [
            "Hizhaoyuan",
            "jackyhawk",
            "jackyhawk",
            "jackyhawk",
            "Yve-Neal"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1521,
        "title": "有没有各种模型在paddlepaddle上占用显存的信息可供参考以便设置batch_size?",
        "body": "如题，类似于[caffe-model](https://github.com/soeaver/caffe-model)，里面提供了各种经典模型所需显存大小已经训练的速度等参考信息.",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "colourful-tree",
        "created_at": "2018-12-12T02:33:56+00:00",
        "updated_at": "2018-12-14T06:22:49+00:00",
        "closed_at": "2018-12-14T06:22:26+00:00",
        "comments_count": [
            "colourful-tree"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1520,
        "title": "paddle 单机多卡训练为何问题不断？？",
        "body": "",
        "state": "closed",
        "user": "Hizhaoyuan",
        "closed_by": "qingqing01",
        "created_at": "2018-12-11T13:12:34+00:00",
        "updated_at": "2019-10-17T09:48:36+00:00",
        "closed_at": "2019-10-17T09:48:36+00:00",
        "comments_count": [
            "guru4elephant",
            "qianledan",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1527,
        "title": "改变模型输出shape后，paddle该如何加载模型参数, 或者说目前paddle并不支持这样操作",
        "body": "",
        "state": "open",
        "user": "Hizhaoyuan",
        "closed_by": null,
        "created_at": "2018-12-12T13:00:05+00:00",
        "updated_at": "2018-12-12T13:00:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1528,
        "title": "fluid/PaddleRec/gru4rec 的 cluster_train.py  中有几个 缩写（ ppl lod transpile ）全称是 ？",
        "body": "这几个全称是啥？\r\nppl\r\n lod \r\ntranspile\r\n多谢\r\n\r\n对应的code为：\r\n\r\nnewest_ppl = 0  \r\nutils.to_lodtensor\r\nlod_src_wordseq\r\nt.transpile(args.trainer_id, pservers=args.endpoints, trainers=args.trainers)  ",
        "state": "open",
        "user": "jackyhawk",
        "closed_by": null,
        "created_at": "2018-12-13T02:46:43+00:00",
        "updated_at": "2018-12-13T05:16:32+00:00",
        "closed_at": null,
        "comments_count": [
            "jackyhawk",
            "frankwhzhang",
            "jackyhawk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1534,
        "title": "fluid/PaddleNLP/sequence_tagging_for_ner 预测问题",
        "body": "用ner模型在预测的时候发现，给预测数据随意标记的label会影响到最终的预测结果；当把数据减少一些(比如10w)后，这个问题就没有了，数据比较大的时候term的预测结果就会往这个随意标记的类别大量倾斜。。。\r\n\r\n定义term的类别只有1和0， 预测是时候任意定义所有label=2，发现用较大预测数据集时候，大部分term的标签被预测为2，数据量较少时候，则是正常的\r\n\r\n预测结果正常：\r\n![image](https://user-images.githubusercontent.com/19464821/49934978-c2566d80-ff0a-11e8-8726-091f6b1a7549.png)\r\n\r\n预测结果出现问题：\r\n![image](https://user-images.githubusercontent.com/19464821/49934993-cf735c80-ff0a-11e8-8fb0-0a8bb720777c.png)\r\n",
        "state": "closed",
        "user": "zzulike",
        "closed_by": "jshower",
        "created_at": "2018-12-13T11:13:47+00:00",
        "updated_at": "2018-12-17T08:15:49+00:00",
        "closed_at": "2018-12-17T08:15:49+00:00",
        "comments_count": [
            "jshower",
            "jshower"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1535,
        "title": "Inconsistent code structure",
        "body": "In image classification, eval.py depends on \"from models.learning_rate import cosine_decay\", however, learning_rate is moved into utils. Please fix it. Thanks.",
        "state": "closed",
        "user": "hshen14",
        "closed_by": "qingqing01",
        "created_at": "2018-12-14T09:48:16+00:00",
        "updated_at": "2018-12-14T11:00:24+00:00",
        "closed_at": "2018-12-14T11:00:24+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1538,
        "title": "machine_reading_comprehension 执行时报错",
        "body": "实验环境：python3.5 paddlepaddle-gpu==1.0.0.post87  ubuntu16.04 GPU 使用 两个1080Ti\r\n执行 `sh run.sh --train --pass_num 10` 时， 在执行到`2018-12-17 11:15:38,728 - brc - INFO - Training the model...\r\n` 时 报错如下\r\n```bash \r\nTraceback (most recent call last):\r\n  File \"run.py\", line 636, in <module>\r\n    train(logger, args)\r\n  File \"run.py\", line 422, in train\r\n    return_numpy=False)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/paddle/fluid/parallel_executor.py\", line 260, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Variable must be type N6paddle9framework9LoDTensorE, the holding type is N6paddle9framework12SelectedRowsE at [/paddle/paddle/fluid/framework/variable.h:33]\r\nPaddlePaddle Call Stacks: \r\n0       0x7eff7151c486p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7eff715fbe6cp paddle::framework::LoDTensor const& paddle::framework::Variable::Get<paddle::framework::LoDTensor>() const + 300\r\n2       0x7eff72534e27p paddle::operators::SumOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 455\r\n3       0x7eff727a0127p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 199\r\n4       0x7eff7279d3fcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 252\r\n5       0x7eff725de157p\r\n6       0x7eff725fa780p\r\n7       0x7eff725f9fe5p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 805\r\n8       0x7eff725ddc2fp paddle::framework::details::ComputationOpHandle::RunImpl() + 95\r\n9       0x7eff725fb085p paddle::framework::details::OpHandleBase::Run(bool) + 117\r\n10      0x7eff725a9efap\r\n11      0x7eff715eaa03p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n12      0x7eff715ea1d7p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n13      0x7effe9501a99p\r\n14      0x7eff725a8ed2p\r\n15      0x7eff715ec1f4p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n16      0x7effe41b7c80p\r\n17      0x7effe94fa6bap\r\n18      0x7effe923041dp clone + 109\r\n```\r\n\r\n\r\n",
        "state": "open",
        "user": "xsscss",
        "closed_by": null,
        "created_at": "2018-12-16T12:08:13+00:00",
        "updated_at": "2018-12-17T09:17:40+00:00",
        "closed_at": null,
        "comments_count": [
            "hjchen2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1539,
        "title": "deeplab3+ 训练需要多大显存",
        "body": "",
        "state": "open",
        "user": "zhengzhe97",
        "closed_by": null,
        "created_at": "2018-12-17T05:37:09+00:00",
        "updated_at": "2019-03-01T08:03:56+00:00",
        "closed_at": null,
        "comments_count": [
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1541,
        "title": "paddle会上线VGG16 的预训练模型吗",
        "body": "",
        "state": "closed",
        "user": "zhizunbao-m",
        "closed_by": "qingqing01",
        "created_at": "2018-12-18T03:07:30+00:00",
        "updated_at": "2018-12-20T15:03:01+00:00",
        "closed_at": "2018-12-20T15:03:01+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1546,
        "title": "什么时候提供图像分类中mobilenet v2的预训练模型",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification#supported-models-and-performances\r\n\r\n官方提供了不少的预训练模型，但没有我需要的mobilenet v2，什么时候能够提供呢？\r\n\r\n希望越来越丰富？\r\n",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2018-12-19T08:10:05+00:00",
        "updated_at": "2018-12-21T03:18:06+00:00",
        "closed_at": "2018-12-21T03:18:06+00:00",
        "comments_count": [
            "qingqing01",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1543,
        "title": "deeplabv3+运行exe.run()时报paddle.fluid.core.EnforceNotMet: Enforce failed. Insufficient GPU memory to allocation.错误",
        "body": "Traceback (most recent call last):\r\n  File \"/home/***/models/fluid/PaddleCV/deeplabv3+/train.py\", line 129, in <module>\r\n    exe.run(sp)\r\n  File \"/usr/local/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected allocating <= available, but received allocating:10906743472 > available:10723983104.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:170]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f33f352cea6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f33f4dce9fep paddle::platform::GpuMaxChunkSize() + 782\r\n2       0x7f33f4dc621ap\r\n3       0x7f3431cd5a99p\r\n4       0x7f33f4dc568dp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 93\r\n5       0x7f33f4dc5975p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 37\r\n6       0x7f33f4dc6025p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long, paddle::memory::allocation::Allocator::Attr) + 389\r\n7       0x7f33f4dc7f6bp paddle::memory::allocation::Allocator::Allocate(unsigned long, paddle::memory::allocation::Allocator::Attr) + 27\r\n8       0x7f33f4db9d43p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 435\r\n9       0x7f33f4db9e61p paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 33\r\n10      0x7f33f4bc6570p paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 48\r\n11      0x7f33f4d727c7p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::type_index, paddle::memory::allocation::Allocator::Attr, unsigned long) + 151\r\n12      0x7f33f3ab13cep paddle::operators::FillConstantOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 958\r\n13      0x7f33f4d2dc7fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 463\r\n14      0x7f33f3601ba3p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 227\r\n15      0x7f33f36025d0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n16      0x7f33f3518c4bp\r\n17      0x7f33f355482ep\r\n18      0x564da23b1b94p _PyCFunction_FastCallDict + 340\r\n19      0x564da24417cep\r\n20      0x564da2463cbap _PyEval_EvalFrameDefault + 762\r\n21      0x564da243aa94p\r\n22      0x564da243b941p\r\n23      0x564da2441755p\r\n24      0x564da2463cbap _PyEval_EvalFrameDefault + 762\r\n25      0x564da243c459p PyEval_EvalCodeEx + 809\r\n26      0x564da243d1ecp PyEval_EvalCode + 28\r\n27      0x564da24b79a4p\r\n28      0x564da24b7da1p PyRun_FileExFlags + 161\r\n29      0x564da24b7fa4p PyRun_SimpleFileExFlags + 452\r\n30      0x564da24bba9ep Py_Main + 1598\r\n31      0x564da23834bep main + 238\r\n32      0x7f343191d830p __libc_start_main + 240\r\n33      0x564da246a773p\r\n\r\npaddle gpu版已成功安装cuda9.0cudnn7",
        "state": "open",
        "user": "silverfly1992",
        "closed_by": null,
        "created_at": "2018-12-18T11:07:38+00:00",
        "updated_at": "2019-03-01T08:02:29+00:00",
        "closed_at": null,
        "comments_count": [
            "silverfly1992",
            "silverfly1992",
            "Hukongtao",
            "silverfly1992",
            "geng007",
            "cjld",
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1548,
        "title": "fasterRCNN infer 维度不匹配",
        "body": "您好，我在使用paddle github上的代码看的时候，使用了cocoval2017中的一张图片做infer，运行的时候提示报错\r\n```\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected in_dims.size() == filter_dims.size(), but received in_dims.size():4 != filter_dims.size():1.\r\n```\r\n我查了图片的维度这一块，图片的大小被resize成(3, 800, 1190)，在infer.py里面，buildmodel的时候，设置的image size是[3, 1333, 1333]，默认配置我都没有修改，只改动了infer的图片，不知道是否跟模型的默认配置有关系呢？谢谢！\r\n\r\n我没有修改infer.py其他的代码，只是将cocoval2017修改为了cocoval2014，infer的脚本如下：\r\n\r\n```\r\npython infer.py \\\r\n  2               --dataset=coco2014 \\\r\n  3               --pretrained_model=./pretrained/imagenet_resnet50_fusebn  \\\r\n  4               --image_path=./dataset/coco/val2014/  \\                                                                            \r\n  5               --image_name=COCO_val2014_000000184613.jpg \\\r\n  6               --draw_threshold=0.6\r\n```\r\n\r\n",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "jerrywgz",
        "created_at": "2018-12-20T03:41:50+00:00",
        "updated_at": "2018-12-20T04:06:44+00:00",
        "closed_at": "2018-12-20T04:06:44+00:00",
        "comments_count": [
            "jerrywgz",
            "littletomatodonkey"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1551,
        "title": "DeepLabv3+ xception65_initialize weight, not compatible with paddlepaddle v1.1 or v1.2",
        "body": "env:\r\n`CUDA Capability: 61, Driver Version: 9.1, Runtime Version: 9.0\r\ndevice: 0, cuDNN Version: 7.0.`\r\n\r\nwhen load this weight: http://paddlemodels.cdn.bcebos.com/deeplab/deeplabv3plus_xception65_initialize.tar.gz\r\n\r\ncode:\r\n`fluid.io.load_params(\r\n            exe, dirname=\"\", filename=args.init_weights_path, main_program=tp)`\r\n\r\ngot error:\r\n`load from: init_weight\r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 135, in <module>\r\n    load_model()\r\n  File \"./train.py\", line 44, in load_model\r\n    exe, dirname=\"\", filename=args.init_weights_path, main_program=tp)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 487, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 395, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 436, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: tensor version 91 is not supported. at [/paddle/paddle/fluid/framework/lod_tensor.cc:284]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f777148be86p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f7772ae5c16p paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 646\r\n2       0x7f7771e9b6e2p paddle::operators::LoadCombineOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 722\r\n3       0x7f7772c8ec2fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 463\r\n4       0x7f7771562b53p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 227\r\n5       0x7f7771563580p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n6       0x7f7771477d3bp\r\n7       0x7f77714b3deep\r\n8             0x4c5326p PyEval_EvalFrameEx + 37958\r\n9             0x4b9b66p PyEval_EvalCodeEx + 774\r\n10            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n11            0x4b9b66p PyEval_EvalCodeEx + 774\r\n12            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n13            0x4b9b66p PyEval_EvalCodeEx + 774\r\n14            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n15            0x4b9b66p PyEval_EvalCodeEx + 774\r\n16            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n17            0x4b9b66p PyEval_EvalCodeEx + 774\r\n18            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4eb69fp\r\n21            0x4e58f2p PyRun_FileExFlags + 130\r\n22            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n23            0x4938cep Py_Main + 1358\r\n24      0x7f7815688830p __libc_start_main + 240\r\n25            0x493299p _start + 41`\r\n\r\nin v1.2: error is `tensor version 91 is not supported`\r\nin v1.1: error is `tensor version 8 is not supported`\r\n\r\nWhich version these weight belongs to? Or where I can get weight compatible with v1.2 ",
        "state": "open",
        "user": "tycallen",
        "closed_by": null,
        "created_at": "2018-12-20T09:10:57+00:00",
        "updated_at": "2019-03-01T08:03:16+00:00",
        "closed_at": null,
        "comments_count": [
            "luotao1",
            "tycallen",
            "qingqing01",
            "cjld",
            "xieqingxing",
            "xieqingxing",
            "cjld"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1556,
        "title": "chinese_ner/train.py paddle.fluid.core.EnforceNotMet: Cannot find fetch variable in scope, fetch_var_name is chunk_eval_0.tmp_3 at [/paddle/paddle/fluid/operators/controlflow/fetch_op.cc:37]",
        "body": "Traceback (most recent call last):\r\n  File \"train.py.bak\", line 356, in <module>\r\n    main(args)\r\n  File \"train.py.bak\", line 344, in main\r\n    [num_infer_chunks, num_label_chunks, num_correct_chunks])\r\n  File \"train.py.bak\", line 231, in test2\r\n    fetch_list=cur_fetch_list)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetch variable in scope, fetch_var_name is chunk_eval_0.tmp_3 at [/paddle/paddle/fluid/operators/controlflow/fetch_op.cc:37]",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2018-12-24T12:48:21+00:00",
        "updated_at": "2018-12-24T12:48:21+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1555,
        "title": "PaddleRec/word2vec 使用建议",
        "body": "1. word2vec模型放在PaddleNLP是不是更合理？\r\n2. 现在基于Fluid 1.2发布的模型是否能支持python2和python3，这个repo下的脚本只能支持python2。如果只能支持python2是否在Markdown上新增下说明。\r\n3. Preprocess脚本运行时，默认认为用户不是在local模式下使用的，会导致调用出错。对local模式和distribute模式的使用区别再文档中没有体现。\r\n4. 预处理的脚本可否考虑新增处理进度？",
        "state": "closed",
        "user": "ZeyuChen",
        "closed_by": "ZeyuChen",
        "created_at": "2018-12-24T12:04:01+00:00",
        "updated_at": "2020-12-02T14:27:09+00:00",
        "closed_at": "2020-12-02T14:27:09+00:00",
        "comments_count": [
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1557,
        "title": "icnet训练时没有问题，推断和评估时报维度错误",
        "body": "```\r\nroot@63a11f01a6d1:/work/paddlepaddle/icnet# python train.py --batch_size=4 --use_gpu=True --checkpoint_path=\"./chkpnt/\"\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 4\r\ncheckpoint_path: ./chkpnt/\r\ninit_model: None\r\nrandom_mirror: True\r\nrandom_scaling: True\r\nuse_gpu: 1\r\n------------------------------------------------\r\nW1225 04:23:18.551097    90 device_context.cc:203] Please NOTE: device: 0, CUDA Capability: 75, Driver Version: 10.0, Runtime Version: 9.0\r\nW1225 04:23:18.551133    90 device_context.cc:210] device: 0, cuDNN Version: 7.0.\r\nIter[100]; train loss: 0.655; sub4_loss: 0.835; sub24_loss: 0.529; sub124_loss: 0.310\r\nkpis\ttrain_cost\t0.654622\r\nSaved checkpoint: ./chkpnt//100\r\nkpis\ttrain_duration\t189.435656\r\nroot@63a11f01a6d1:/work/paddlepaddle/icnet# python eval.py --model_path=\"./chkpnt/100/\" --use_gpu=True\r\n-----------  Configuration Arguments -----------\r\nmodel_path: ./chkpnt/100/\r\nuse_gpu: 1\r\n------------------------------------------------\r\nW1225 04:27:08.380987   130 device_context.cc:203] Please NOTE: device: 0, CUDA Capability: 75, Driver Version: 10.0, Runtime Version: 9.0\r\nW1225 04:27:08.381017   130 device_context.cc:210] device: 0, cuDNN Version: 7.0.\r\nloaded model from: ./chkpnt/100/\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 96, in <module>\r\n    main()\r\n  File \"eval.py\", line 92, in main\r\n    eval(args)\r\n  File \"eval.py\", line 80, in eval\r\n    fetch_list=fetch_vars)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected x_dims[i + axis] == y_dims[i], but received x_dims[i + axis]:128 != y_dims[i]:213.\r\nBroadcast dimension mismatch. at [/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:63]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f48636d7e96p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f48639b0334p paddle::operators::get_mid_dims(paddle::framework::DDim const&, paddle::framework::DDim const&, int, int*, int*, int*) + 916\r\n2       0x7f4864a52d23p void paddle::operators::ElementwiseComputeEx<paddle::operators::AddFunctor<float>, paddle::platform::CUDADeviceContext, float, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, int, paddle::operators::AddFunctor<float>, paddle::framework::Tensor*) + 499\r\n3       0x7f4864a534a3p void paddle::operators::default_elementwise_add<paddle::platform::CUDADeviceContext, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, paddle::framework::Tensor*) + 115\r\n4       0x7f4864a53638p paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 344\r\n5       0x7f4864a536b3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, long>, paddle::operators::ElementwiseAddKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n6       0x7f4864edcafcp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 492\r\n7       0x7f4864ed8c3fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 463\r\n8       0x7f48637acb63p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 227\r\n9       0x7f48637ad590p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n10      0x7f48636c3c3bp\r\n11      0x7f48636ff81ep\r\n12            0x4e9ba7p PyCFunction_Call + 119\r\n13            0x53c6d5p PyEval_EvalFrameEx + 23029\r\n14            0x540199p\r\n15            0x53bd92p PyEval_EvalFrameEx + 20658\r\n16            0x53b7e4p PyEval_EvalFrameEx + 19204\r\n17            0x53b7e4p PyEval_EvalFrameEx + 19204\r\n18            0x540199p\r\n19            0x540e4fp PyEval_EvalCode + 31\r\n20            0x60c272p\r\n21            0x60e71ap PyRun_FileExFlags + 154\r\n22            0x60ef0cp PyRun_SimpleFileExFlags + 444\r\n23            0x63fb26p Py_Main + 1110\r\n24            0x4cfeb1p main + 225\r\n25      0x7f48b2fde830p __libc_start_main + 240\r\n26            0x5d6049p _start + 41\r\n\r\n```",
        "state": "closed",
        "user": "freekoy",
        "closed_by": "wanghaoshuang",
        "created_at": "2018-12-25T04:31:20+00:00",
        "updated_at": "2019-03-04T09:30:29+00:00",
        "closed_at": "2019-03-04T09:30:29+00:00",
        "comments_count": [
            "wanghaoshuang",
            "freekoy",
            "geng007",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1559,
        "title": "fasterRCNN rpn cls pred的问题",
        "body": "在mdoels中fasterRCNN复现模型中，计算`rpn cls score`的代码为:[链接](https://github.com/PaddlePaddle/models/blob/cbe656e04e9445699eea6612662995f1f4593a6c/fluid/PaddleCV/faster_rcnn/models/model_builder.py#L119)，这里卷积之后没有sigmoid激活函数进行处理，但是在后面使用`rpn_target_assign`调用rpn_cls_score的时候，我看paddle的[文档](http://www.paddlepaddle.org/documentation/docs/zh/1.2/api_cn/layers_cn.html#rpn-target-assign)里写了输入的`rpn cls score`需要是sigmoid logits，我想问一下现在的逻辑是在`rpn_target_assign`函数中对rpn conv的输出进行sigmoid的操作吗？我看[https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/detection/rpn_target_assign_op.cc](https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/detection/rpn_target_assign_op.cc)里面的代码没怎么看懂。。。没找到sigmoid对应的操作。。\r\n",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "qingqing01",
        "created_at": "2018-12-25T06:43:29+00:00",
        "updated_at": "2019-01-23T08:51:18+00:00",
        "closed_at": "2019-01-23T08:51:18+00:00",
        "comments_count": [
            "guoshengCS",
            "littletomatodonkey",
            "guoshengCS",
            "littletomatodonkey"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1561,
        "title": "icnet.py中atrous_conv这个函数中没有s_h和s_w参数",
        "body": "如下\r\n```\r\ndef atrous_conv(input,\r\n                k_h,\r\n                k_w,\r\n                c_o,\r\n                dilation,\r\n                relu=False,\r\n                padding=\"VALID\",\r\n                biased=False,\r\n                name=None):\r\n    act = None\r\n    if relu:\r\n        act = \"relu\"\r\n    tmp = input\r\n    if padding == \"SAME\":\r\n        padding_h = max(k_h - s_h, 0)\r\n        padding_w = max(k_w - s_w, 0)\r\n        padding_top = padding_h // 2\r\n        padding_left = padding_w // 2\r\n```",
        "state": "open",
        "user": "WangTaoSpace",
        "closed_by": null,
        "created_at": "2018-12-26T07:01:04+00:00",
        "updated_at": "2019-05-09T12:52:17+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "Einshein",
            "Einshein"
        ],
        "labels": [
            "bug",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1564,
        "title": "gpu版的paddle一直运行不成功，确定cuda安装正确，运行paddle官网安装页面测试程序报paddle.fluid.core.EnforceNotMet: Cannot run operator on place CUDAPlace(0) at [/paddle/paddle/fluid/framework/operator.cc:145]",
        "body": "只是将官网安装页面测试程序place = fluid.CPUPlace()改成了place = fluid.CUDAPlace(0)\r\n完整错误代码如下：\r\nTraceback (most recent call last):\r\n  File \"/home/silverfly/models/fluid/PaddleCV/deeplabv3+/paddle_test.py\", line 73, in <module>\r\n    train(save_dirname)\r\n  File \"/home/silverfly/models/fluid/PaddleCV/deeplabv3+/paddle_test.py\", line 46, in train\r\n    train_loop(fluid.default_main_program())\r\n  File \"/home/silverfly/models/fluid/PaddleCV/deeplabv3+/paddle_test.py\", line 30, in train_loop\r\n    exe.run(fluid.default_startup_program())\r\n  File \"/usr/local/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot run operator on place CUDAPlace(0) at [/paddle/paddle/fluid/framework/operator.cc:145]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fd23c8baaf6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7fd23d6cd892p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 658\r\n2       0x7fd23c9860f0p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 224\r\n3       0x7fd23c9867f0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n4       0x7fd23c8a895bp\r\n5       0x7fd23c8d8b80p\r\n6       0x55637a13cb94p _PyCFunction_FastCallDict + 340\r\n7       0x55637a1cc7cep\r\n8       0x55637a1eecbap _PyEval_EvalFrameDefault + 762\r\n9       0x55637a1c5a94p\r\n10      0x55637a1c6941p\r\n11      0x55637a1cc755p\r\n12      0x55637a1eecbap _PyEval_EvalFrameDefault + 762\r\n13      0x55637a1c5daep\r\n14      0x55637a1c6941p\r\n15      0x55637a1cc755p\r\n16      0x55637a1eecbap _PyEval_EvalFrameDefault + 762\r\n17      0x55637a1c5daep\r\n18      0x55637a1c6941p\r\n19      0x55637a1cc755p\r\n20      0x55637a1eecbap _PyEval_EvalFrameDefault + 762\r\n21      0x55637a1c7459p PyEval_EvalCodeEx + 809\r\n22      0x55637a1c81ecp PyEval_EvalCode + 28\r\n23      0x55637a2429a4p\r\n24      0x55637a242da1p PyRun_FileExFlags + 161\r\n25      0x55637a242fa4p PyRun_SimpleFileExFlags + 452\r\n26      0x55637a246a9ep Py_Main + 1598\r\n27      0x55637a10e4bep main + 238\r\n28      0x7fd26b493830p __libc_start_main + 240\r\n29      0x55637a1f5773p",
        "state": "open",
        "user": "silverfly1992",
        "closed_by": null,
        "created_at": "2018-12-27T03:28:44+00:00",
        "updated_at": "2019-06-23T03:20:07+00:00",
        "closed_at": null,
        "comments_count": [
            "zzdgit",
            "EvanLiu1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1560,
        "title": "gru4rec 在gpu下报个错   (cuda 版本不对，cudnn6 也按照  cudnn5 安装即可",
        "body": "执行命令为：CUDA_VISIBLE_DEVICES=0 /data0/jy/py27/bin/python train.py --train_dir train_data/ --use_cuda 1\r\n\r\n\r\n865 Traceback (most recent call last):\r\n866   File \"train.py\", line 124, in <module>\r\n867     train()\r\n868   File \"train.py\", line 75, in train\r\n869     exe.run(fluid.default_startup_program())\r\n870   File \"/data0/jy/py27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 472, in run\r\n871     self.executor.run(program.desc, scope, 0, True, True)\r\n872 paddle.fluid.core.EnforceNotMet: Cannot run operator on place CUDAPlace(0) at [/paddle/paddle/fluid/framework/operator.cc:145]\r\n873 PaddlePaddle Call Stacks:\r\n874 0       0x7f143f665986p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n875 1       0x7f144047a7f2p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlac\r\n    e, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, b\r\n    oost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::de\r\n    tail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::va\r\n    riant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 658\r\n876 2       0x7f143f733090p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) +\r\n    224\r\n877 3       0x7f143f733790p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n878 4       0x7f143f65400bp\r\n879 5       0x7f143f69f7c0p\r\n880 6       0x7f14c88f6918p PyEval_EvalFrameEx + 25016\r\n881 7       0x7f14c88f9e2dp PyEval_EvalCodeEx + 2061\r\n882 8       0x7f14c88f70a5p PyEval_EvalFrameEx + 26949\r\n883 9       0x7f14c88f71c0p PyEval_EvalFrameEx + 27232\r\n884 10      0x7f14c88f9e2dp PyEval_EvalCodeEx + 2061\r\n885 11      0x7f14c88f9f62p PyEval_EvalCode + 50\r\n886 12      0x7f14c8922d22p PyRun_FileExFlags + 146\r\n887 13      0x7f14c89240b9p PyRun_SimpleFileExFlags + 217\r\n888 14      0x7f14c8939f6dp Py_Main + 3149\r\n889 15      0x7f14c7b26b35p __libc_start_main + 245\r\n890 16            0x40071ep\r\n891 ",
        "state": "closed",
        "user": "jackyhawk",
        "closed_by": "jackyhawk",
        "created_at": "2018-12-26T03:05:55+00:00",
        "updated_at": "2018-12-26T07:51:46+00:00",
        "closed_at": "2018-12-26T07:51:46+00:00",
        "comments_count": [
            "jackyhawk",
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1565,
        "title": "CUDA Version 9.0.176 CUDNN7.0.4 paddlepaddle0.15.0  运行train_hinas.py报错",
        "body": "learning rate: 0.100000 -> 0.000100, cosine annealing\r\nepoch: 200\r\nbatch size: 128\r\nL2 decay: 0.000400\r\nToken is 7,5,8,1,2,10,9,2,2,2,8,8,8,2,9,4,9,11,7,4,3\r\nsep_3x3 \t-> shape (-1L, 64L, 32L, 32L)\r\nconv_1x3_3x1 \t-> shape (-1L, 64L, 32L, 32L)\r\nmaxpool_2x2 \t-> shape (-1L, 128L, 16L, 16L)\r\n============\r\nconv_2x2 \t-> shape (-1L, 128L, 16L, 16L)\r\nconv_3x3 \t-> shape (-1L, 128L, 16L, 16L)\r\navgpool_2x2 \t-> shape (-1L, 128L, 16L, 16L)\r\nmaxpool_3x3 \t-> shape (-1L, 256L, 8L, 8L)\r\n============\r\nconv_3x3 \t-> shape (-1L, 256L, 8L, 8L)\r\nconv_3x3 \t-> shape (-1L, 256L, 8L, 8L)\r\nconv_3x3 \t-> shape (-1L, 256L, 8L, 8L)\r\nmaxpool_2x2 \t-> shape (-1L, 256L, 8L, 8L)\r\nmaxpool_2x2 \t-> shape (-1L, 512L, 4L, 4L)\r\n============\r\nmaxpool_2x2 \t-> shape (-1L, 512L, 4L, 4L)\r\nconv_3x3 \t-> shape (-1L, 512L, 4L, 4L)\r\nmaxpool_3x3 \t-> shape (-1L, 512L, 4L, 4L)\r\nconv_1x2_2x1 \t-> shape (-1L, 512L, 4L, 4L)\r\nmaxpool_3x3 \t-> shape (-1L, 1024L, 2L, 2L)\r\n============\r\navgpool_3x3 \t-> shape (-1L, 1024L, 2L, 2L)\r\nsep_3x3 \t-> shape (-1L, 1024L, 2L, 2L)\r\nconv_1x2_2x1 \t-> shape (-1L, 1024L, 2L, 2L)\r\ndilated_2x2 \t-> shape (-1L, 1024L, 2L, 2L)\r\nReading file cifar-10-batches-py/data_batch_1\r\nReading file cifar-10-batches-py/data_batch_2\r\nReading file cifar-10-batches-py/data_batch_3\r\nReading file cifar-10-batches-py/data_batch_4\r\nReading file cifar-10-batches-py/data_batch_5\r\nTraceback (most recent call last):\r\n  File \"train_hinas.py\", line 44, in <module>\r\n    app.run(main)\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"train_hinas.py\", line 40, in main\r\n    model.run()\r\n  File \"/home/shangyw/git_rep/models/fluid/PaddleCV/HiNAS_models/nn_paddle.py\", line 139, in run\r\n    feed_order=['pixel', 'label'])\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/paddle/fluid/trainer.py\", line 405, in train\r\n    feed_order)\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/paddle/fluid/trainer.py\", line 461, in _train_by_executor\r\n    self._train_by_any_executor(event_handler, exe, num_epochs, reader)\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/paddle/fluid/trainer.py\", line 490, in _train_by_any_executor\r\n    for var in self.train_func_outputs\r\n  File \"/root/shangyw/.virtualenv/paddle0.15.0/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected dilations[i] == 1, but received dilations[i]:2 != 1:1.\r\nDilations conv is not supported in this cuDNN version(5.1.10). at [/paddle/paddle/fluid/platform/cudnn_helper.h:293]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f93a445cd06p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f93a507469fp paddle::platform::ScopedConvolutionDescriptor::descriptor(cudnnDataType_t, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&) + 1279\r\n2       0x7f93a50c2f5bp paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 859\r\n3       0x7f93a50c3e03p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7f93a5456b2ep paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 526\r\n5       0x7f93a5453bbcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 252\r\n6       0x7f93a4524d19p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 393\r\n7       0x7f93a4525af0p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 128\r\n8       0x7f93a444294dp\r\n",
        "state": "open",
        "user": "upwindflys",
        "closed_by": null,
        "created_at": "2018-12-27T06:48:48+00:00",
        "updated_at": "2019-03-14T11:39:26+00:00",
        "closed_at": null,
        "comments_count": [
            "chengduoZH"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1577,
        "title": "Is there an implementation of mnasnet model?",
        "body": "Like [MnasNet-PyTorch](https://github.com/AnjieZheng/MnasNet-PyTorch), I wrote a implementation from [mobilenet_v2.py](https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/image_classification/models/mobilenet_v2.py)\r\nIs there anyone can check the code ?\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport paddle.fluid as fluid\r\nfrom paddle.fluid.initializer import MSRA\r\nfrom paddle.fluid.param_attr import ParamAttr\r\n\r\n__all__ = ['Mnasnet']\r\n\r\ntrain_parameters = {\r\n    \"input_size\": [3, 224, 224],\r\n    \"input_mean\": [0.485, 0.456, 0.406],\r\n    \"input_std\": [0.229, 0.224, 0.225],\r\n    \"learning_strategy\": {\r\n        \"name\": \"piecewise_decay\",\r\n        \"batch_size\": 256,\r\n        \"epochs\": [30, 60, 90],\r\n        \"steps\": [0.1, 0.01, 0.001, 0.0001]\r\n    }\r\n}\r\n\r\nclass Mnasnet():\r\n    def __init__(self):\r\n        self.params = train_parameters\r\n\r\n    def conv_bn_layer(self,\r\n                      input,\r\n                      filter_size,\r\n                      num_filters,\r\n                      stride,\r\n                      padding,\r\n                      channels=None,\r\n                      num_groups=1,\r\n                      use_cudnn=True,\r\n                      if_act=True):\r\n        conv = fluid.layers.conv2d(\r\n            input=input,\r\n            num_filters=num_filters,\r\n            filter_size=filter_size,\r\n            stride=stride,\r\n            padding=padding,\r\n            groups=num_groups,\r\n            act=None,\r\n            use_cudnn=use_cudnn,\r\n            param_attr=ParamAttr(initializer=MSRA()),\r\n            bias_attr=False)\r\n        bn = fluid.layers.batch_norm(input=conv)\r\n        if if_act:\r\n            return fluid.layers.relu6(bn)\r\n        else:\r\n            return bn\r\n    \r\n    def shortcut(self, input, data_residual):\r\n        return fluid.layers.elementwise_add(input, data_residual)\r\n\r\n    def inverted_residual_unit(self, input, num_in_filter, num_filters,\r\n                               ifshortcut, stride, filter_size, padding,\r\n                               expansion_factor):\r\n        num_expfilter = int(round(num_in_filter * expansion_factor))\r\n        channel_expand = self.conv_bn_layer(\r\n            input=input,\r\n            num_filters=num_expfilter,\r\n            filter_size=1,\r\n            stride=1,\r\n            padding=0,\r\n            num_groups=1,\r\n            if_act=True)\r\n        bottleneck_conv = self.conv_bn_layer(\r\n            input=channel_expand,\r\n            num_filters=num_expfilter,\r\n            filter_size=filter_size,\r\n            stride=stride,\r\n            padding=filter_size//2,\r\n            num_groups=num_expfilter,\r\n            if_act=True,\r\n            use_cudnn=False)\r\n        linear_out = self.conv_bn_layer(\r\n            input=bottleneck_conv,\r\n            num_filters=num_filters,\r\n            filter_size=1,\r\n            stride=1,\r\n            padding=0,\r\n            num_groups=1,\r\n            if_act=False)\r\n        if ifshortcut:\r\n            out = self.shortcut(input=input, data_residual=linear_out)\r\n            return out\r\n        else:\r\n            return linear_out\r\n\r\n    def invresi_blocks(self, input, in_c, t, c, n, s,k):\r\n        first_block = self.inverted_residual_unit(\r\n            input=input,\r\n            num_in_filter=in_c,\r\n            num_filters=c,\r\n            ifshortcut=False,\r\n            stride=s,\r\n            filter_size=k,\r\n            padding=1,\r\n            expansion_factor=t)\r\n\r\n        last_residual_block = first_block\r\n        last_c = c\r\n\r\n        for i in range(1, n):\r\n            last_residual_block = self.inverted_residual_unit(\r\n                input=last_residual_block,\r\n                num_in_filter=last_c,\r\n                num_filters=c,\r\n                ifshortcut=True,\r\n                stride=1,\r\n                filter_size=k,\r\n                padding=1,\r\n                expansion_factor=t)\r\n        return last_residual_block\r\n    \r\n    def sepconv3x3(self,input,inp,oup):\r\n        input=self.conv_bn_layer(\r\n            input,\r\n            num_filters=inp,\r\n            filter_size=3,\r\n            stride=1,\r\n            padding=1,\r\n            num_groups=inp,\r\n            if_act=True)\r\n        conv=self.conv_bn_layer(\r\n            input,\r\n            num_filters=oup,\r\n            filter_size=1,\r\n            stride=1,\r\n            padding=0,\r\n            num_groups=1,\r\n            if_act=False)\r\n        return conv\r\n\r\n    def net(self, input, class_dim=1000, scale=1.0):\r\n        bottleneck_params_list = [\r\n            # t, c, n, s, k\r\n            [3, 24,  3, 2, 3],  # -> 56x56\r\n            [3, 40,  3, 2, 5],  # -> 28x28\r\n            [6, 80,  3, 2, 5],  # -> 14x14\r\n            [6, 96,  2, 1, 3],  # -> 14x14\r\n            [6, 192, 4, 2, 5],  # -> 7x7\r\n            [6, 320, 1, 1, 3],  # -> 7x7\r\n        ]\r\n        in_c = int(32 * scale)\r\n        input = self.conv_bn_layer(\r\n            input,\r\n            num_filters=in_c,\r\n            filter_size=3,\r\n            stride=2,\r\n            padding=1,\r\n            if_act=True)\r\n        input=self.sepconv3x3(input,in_c,16)\r\n\r\n        in_c =16\r\n        for layer_setting in bottleneck_params_list:\r\n            t, c, n, s, k = layer_setting\r\n            input = self.invresi_blocks(\r\n                input=input,\r\n                in_c=in_c,\r\n                t=t,\r\n                c=int(c * scale),\r\n                n=n,\r\n                s=s, \r\n                k=k)\r\n            in_c = int(c * scale)\r\n            \r\n\r\n        input = self.conv_bn_layer(\r\n            input=input,\r\n            num_filters=int(1280 * scale) if scale > 1.0 else 1280,\r\n            filter_size=1,\r\n            stride=1,\r\n            padding=0,\r\n            if_act=True)\r\n\r\n        input = fluid.layers.pool2d(\r\n            input=input,\r\n            pool_size=7,\r\n            pool_stride=1,\r\n            pool_type='avg',\r\n            global_pooling=True)\r\n\r\n        output = fluid.layers.fc(input=input,\r\n                                 size=class_dim,\r\n                                 act='softmax',\r\n                                 param_attr=ParamAttr(initializer=MSRA()))\r\n        return output\r\n```",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2018-12-28T11:45:32+00:00",
        "updated_at": "2021-07-20T03:49:20+00:00",
        "closed_at": "2021-07-20T03:49:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1575,
        "title": "在使用官方代码训练SSD时，出现AttributeError: module 'paddle.fluid' has no attribute 'program'",
        "body": "您好，研发老师，我在macos、Python3.7、paddlepaddle 1.2下运行https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/object_detection\r\n中的代码时，出现错误：\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 317, in <module>\r\n    val_file_list=val_file_list)\r\n  File \"train.py\", line 164, in train\r\n    is_train=True)\r\n  File \"train.py\", line 86, in build_program\r\n    with fluid.program.devices_num_guard(main_prog, startup_prog):\r\nAttributeError: module 'paddle.fluid' has no attribute 'program'\r\n```\r\n运行指令为：\r\n```bash\r\npython3 -u train.py --batch_size=64 --dataset='coco2017' --pretrained_model='pretrained/ssd_mobilenet_v1_coco/' --use_gpu=false\r\n```\r\n出错代码的前后文为：\r\n```Python\r\ndef build_program(main_prog, startup_prog, train_params, is_train):\r\n    image_shape = train_params['image_shape']\r\n    class_num = train_params['class_num']\r\n    ap_version = train_params['ap_version']\r\n    outs = []\r\n    with fluid.program.devices_num_guard(main_prog, startup_prog):\r\n        py_reader = fluid.layers.py_reader(\r\n            capacity=64,\r\n            shapes=[[-1] + image_shape, [-1, 4], [-1, 1], [-1, 1]],\r\n            lod_levels=[0, 1, 1, 1],\r\n            dtypes=[\"float32\", \"float32\", \"int32\", \"int32\"],\r\n            use_double_buffer=True)\r\n        with fluid.unique_name.guard():\r\n            image, gt_box, gt_label, difficult = fluid.layers.read_file(py_reader)\r\n            locs, confs, box, box_var = mobile_net(class_num, image, image_shape)\r\n            if is_train:\r\n                with fluid.unique_name.guard(\"train\"):\r\n                    loss = fluid.layers.ssd_loss(locs, confs, gt_box, gt_label, box,\r\n                        box_var)\r\n                    loss = fluid.layers.reduce_sum(loss)\r\n                    optimizer = optimizer_setting(train_params)\r\n                    optimizer.minimize(loss)\r\n                outs = [py_reader, loss]\r\n            else:\r\n                with fluid.unique_name.guard(\"inference\"):\r\n                    nmsed_out = fluid.layers.detection_output(\r\n                        locs, confs, box, box_var, nms_threshold=0.45)\r\n                    map_eval = fluid.evaluator.DetectionMAP(\r\n                        nmsed_out,\r\n                        gt_label,\r\n                        gt_box,\r\n                        difficult,\r\n                        class_num,\r\n                        overlap_threshold=0.5,\r\n                        evaluate_difficult=False,\r\n                        ap_version=ap_version)\r\n                # nmsed_out and image is used to save mode for inference\r\n                outs = [py_reader, map_eval, nmsed_out, image]\r\n    return outs\r\n```",
        "state": "closed",
        "user": "newdimitri",
        "closed_by": "qingqing01",
        "created_at": "2018-12-28T08:47:47+00:00",
        "updated_at": "2019-01-02T09:05:59+00:00",
        "closed_at": "2019-01-02T09:05:59+00:00",
        "comments_count": [
            "jacquesqiao",
            "newdimitri",
            "jacquesqiao",
            "newdimitri",
            "qingqing01",
            "newdimitri",
            "qingqing01",
            "newdimitri",
            "dzhwinter",
            "newdimitri",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1566,
        "title": "icnet这个模型中cityscape.py中IMG_MEAN这个变量起什么作用？",
        "body": "代码中变量定义\r\n```\r\nIMG_MEAN = np.array((103.939, 116.779, 123.68), dtype=np.float32)\r\n```\r\n使用这个变量的位置\r\n```\r\n        \"\"\"\r\n        Load image from file.\r\n        \"\"\"\r\n        image = dataset.image.load_image(\r\n            image, is_color=True).astype(\"float32\")\r\n        image -= IMG_MEAN\r\n```\r\n不太懂，麻烦解下惑",
        "state": "open",
        "user": "WangTaoSpace",
        "closed_by": null,
        "created_at": "2018-12-27T07:10:20+00:00",
        "updated_at": "2018-12-27T11:22:39+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "WangTaoSpace",
            "NHZlX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1579,
        "title": "BUG in ...(pyramidbox)/face_detection/image_util.py ?",
        "body": "In line 108, function:\r\n\r\ndef data_anchor_sampling(sampler, bbox_labels, image_width, image_height, scale_array, resize_width, resize_height):\r\n\r\nthe input \"sampler\" is never used, but I think I should be",
        "state": "open",
        "user": "math-yyj",
        "closed_by": null,
        "created_at": "2018-12-29T08:40:46+00:00",
        "updated_at": "2023-10-31T05:09:42+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1583,
        "title": "deeplabv3+训练的loss不断降低，但mIoU不变",
        "body": "训练过程如下：\r\ntotal number 500\r\nstep: 1, mIoU: 0.00036064465285404087\r\nstep 0, loss: 2.283701, step_time_cost: 24.394\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.00040592799008661094\r\nstep 1, loss: 2.281190, step_time_cost: 22.383\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.004588067474388075\r\nstep 2, loss: 2.277308, step_time_cost: 22.860\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.07668137479753885\r\nstep 3, loss: 2.260504, step_time_cost: 22.590\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.12360501949317738\r\nstep 4, loss: 2.255224, step_time_cost: 22.360\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.12360501949317738\r\nstep 5, loss: 2.239232, step_time_cost: 22.390\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.12360501949317738\r\nstep 6, loss: 2.223259, step_time_cost: 22.641\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.12360501949317738\r\nstep 7, loss: 2.205665, step_time_cost: 22.690\r\nModel is saved to output\r\nload from: output\r\ntotal number 500\r\nstep: 1, mIoU: 0.12360501949317738\r\nstep 8, loss: 2.187018, step_time_cost: 22.279\r\n\r\n使用deeplabv3+训练，改过num_classes，其余训练和验证的核心代码没有动，之前训练几万步 loss 降到很低后跑验证集发现 mIoU 还是很低，调试后发现每张图片的 mIoU 达到某个值过后就不再变了。如上面这张验证图片的 mIoU 达到 0.12360501949317738 后就再也不变了，请问是什么情况？",
        "state": "open",
        "user": "seanria",
        "closed_by": null,
        "created_at": "2018-12-30T01:58:27+00:00",
        "updated_at": "2020-12-08T05:14:51+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "xieqingxing",
            "cjld",
            "seanria",
            "seanria",
            "xieqingxing",
            "seanria",
            "cjld"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1584,
        "title": "预训练模型的infer结果不对",
        "body": "你好，\r\n我直接从这里：https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification 下载了图像分类的预训练模型。\r\n代码分支：develop\r\n运行平台：macosx\r\n预训练模型：AlexNet，VGG16，MobileNetV1等\r\n测试数据：infer了千分类中的4张图：dining table, zebra, laptop, orange.\r\n**其他啥都没改，但是基本所有模型的infer结果都明显不对，希望帮忙看下。**\r\n```\r\npython infer.py \\\r\n       --model=AlexNet \\\r\n       --class_dim=1000 \\\r\n       --image_shape=3,224,224 \\\r\n       --with_mem_opt=True \\\r\n       --pretrained_model=/Users/xxx/models/fluid/PaddleCV/image_classification/shortcuts/AlexNet_pretrained \\\r\n       --use_gpu=False\r\n```\r\n输出如下：\r\n```\r\n-----------  Configuration Arguments -----------\r\nclass_dim: 1000\r\nimage_shape: 3,224,224\r\nmodel: AlexNet\r\npretrained_model: /Users/xxx/models/fluid/PaddleCV/image_classification/shortcuts/AlexNet_pretrained\r\nuse_gpu: 0\r\nwith_mem_opt: 1\r\n------------------------------------------------\r\nTest-0-score: [0.01093278], class [973]\r\nTest-1-score: [0.01056511], class [973]\r\nTest-2-score: [0.01054511], class [973]\r\nTest-3-score: [0.01056188], class [973]\r\n```\r\n可以看到，测试的四张图片dining table, zebra, laptop, orange**都被infer成了[973]，score也很低，而且每次infer的结果还都不一样**。希望帮忙分析下原因，谢谢！\r\n",
        "state": "closed",
        "user": "ljayx",
        "closed_by": "shippingwang",
        "created_at": "2019-01-02T07:54:42+00:00",
        "updated_at": "2019-04-12T07:22:37+00:00",
        "closed_at": "2019-04-12T07:22:37+00:00",
        "comments_count": [
            "ljayx",
            "qingqing01",
            "ljayx",
            "ljayx",
            "shippingwang",
            "ljayx",
            "ljayx",
            "jerrywgz",
            "ljayx",
            "shippingwang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1580,
        "title": "The backbone for face detection.",
        "body": "Thanks for releasing the codes. I want to ask in the pyramidbox, if you have done the experiment on the backbone, such as the res50 and res101.And if this will be helpful for the wider_face val results.Thanks again.",
        "state": "closed",
        "user": "Sun-Fan",
        "closed_by": "qingqing01",
        "created_at": "2018-12-29T08:58:48+00:00",
        "updated_at": "2019-01-29T06:28:14+00:00",
        "closed_at": "2019-01-29T06:28:14+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1585,
        "title": "deeplabv3+在python3.6下报错",
        "body": "deeplabv3+在ubuntu14 cuda8 cudnn7 python3.6下有个报错，报错内容如下：\r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 148, in <module>\r\n    load_model()\r\n  File \"./train.py\", line 54, in load_model\r\n    exe, dirname=args.init_weights_path, main_program=tp)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/io.py\", line 487, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/io.py\", line 395, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/io.py\", line 436, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Cannot open file deeplabv3plus_xception65_initialize.params/xception_65/entry_flow/conv1/weights for load op at [/home/Paddle/paddle/fluid/operators/load_op.cc:39]\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-01-02T09:26:03+00:00",
        "updated_at": "2019-01-04T04:21:46+00:00",
        "closed_at": "2019-01-03T02:53:29+00:00",
        "comments_count": [
            "qingqing01",
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1598,
        "title": "icnet预训练模型的下载链接是无效的",
        "body": "",
        "state": "open",
        "user": "oxygenman",
        "closed_by": null,
        "created_at": "2019-01-04T11:41:29+00:00",
        "updated_at": "2019-01-04T11:41:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1592,
        "title": "在Fluid版本的图像分类中能否提供更多的没有指定参数的预训练模型",
        "body": "在图像分类模型中： https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification#supported-models-and-performances\r\n提供不少的预训练模型，不过没有指定parameter names的模型很少，我一般是不命名的，我决定模型的命名已经很好了，但是提供的模型是指定命名的，我又得修改网络的命名，这样很不好。能否尽快提供无指定parameter names的预训练模型吗？特别是MobieNet V1和MobileNet V2\r\n",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-01-03T05:03:22+00:00",
        "updated_at": "2019-01-04T04:55:12+00:00",
        "closed_at": "2019-01-04T04:55:12+00:00",
        "comments_count": [
            "qingqing01",
            "yeyupiaoling",
            "yeyupiaoling",
            "shippingwang",
            "qingqing01",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1601,
        "title": "ssr训练报错",
        "body": "环境：CentOS，python3.5\r\nssr在第一轮训练结束保存模型时有个报错：\r\n2019-01-05 12:05:18,962 - INFO - Train --> pass: 0 batch_id: 62138 avg_cost: [0.09472405], acc: 0.9921875\r\n2019-01-05 12:05:19,121 - INFO - Train --> pass: 0 batch_id: 62139 avg_cost: [0.09657063], acc: 0.703125\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 98, in <module>\r\n    main()\r\n  File \"train.py\", line 95, in main\r\n    start_train(args)\r\n  File \"train.py\", line 90, in start_train\r\n    [var.name for val in input_data],\r\n  File \"train.py\", line 90, in <listcomp>\r\n    [var.name for val in input_data],\r\nNameError: name 'var' is not defined\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-07T03:18:24+00:00",
        "updated_at": "2019-01-09T02:22:46+00:00",
        "closed_at": "2019-01-09T02:22:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1594,
        "title": "去掉MobileNet中的batch_norm层是否会影响模型的性能",
        "body": "如果我去掉MobileNet V1的batch_norm层，如下：\r\nhttps://github.com/PaddlePaddle/models/blob/5c6f919e36d4b849a787a6e4df5693ce86252b5f/fluid/PaddleCV/image_classification/models_name/mobilenet.py#L163-L169\r\n\r\n和MobileNet V2的batch_norm层，如下：\r\nhttps://github.com/PaddlePaddle/models/blob/5c6f919e36d4b849a787a6e4df5693ce86252b5f/fluid/PaddleCV/image_classification/models_name/mobilenet_v2.py#L111-L116\r\n\r\n是否会影响这个网络的性能，因为我电脑用不了CUDNN，我也不知道为什么，我在这里提了问题：https://github.com/PaddlePaddle/Paddle/issues/15140\r\n同时我conv和pool都设置了不使用cudnn，但是batch_norm层设置不了。我也提了问题：https://github.com/PaddlePaddle/Paddle/issues/15151",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-01-03T06:32:18+00:00",
        "updated_at": "2019-01-03T09:54:16+00:00",
        "closed_at": "2019-01-03T09:54:16+00:00",
        "comments_count": [
            "xuezhong",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1605,
        "title": "HiNAS_models运行报错",
        "body": "HiNAS_models运行报错，如下：\r\nfluid/PaddleCV/HiNAS_models/nn_paddle.py\", line 129, in run\r\n    trainer = fluid.Trainer(\r\nAttributeError: 'module' object has no attribute 'Trainer'\r\n\r\n环境CUDA9，cudnn 7 ，paddlpaddle1.2",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "qingqing01",
        "created_at": "2019-01-07T11:47:35+00:00",
        "updated_at": "2019-01-24T06:39:52+00:00",
        "closed_at": "2019-01-24T06:39:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1612,
        "title": "word2vec无法预处理数据",
        "body": "环境：CentOS6 , python2.7\r\nword2vec预处理数据后生成的文件都是空的（并没有提示出错），导致训练报错。\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 354, in <module>\r\n    train(args)\r\n  File \"train.py\", line 255, in train\r\n    is_sparse=args.is_sparse)\r\n  File \"/home/data/xiege/models_cuda8/models-develop/fluid/PaddleRec/word2vec/network_conf.py\", line 106, in skip_gram_word2vec\r\n    math.sqrt(dict_size))))\r\nZeroDivisionError: float division by zero\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "wzzju",
        "created_at": "2019-01-08T03:49:02+00:00",
        "updated_at": "2019-01-09T15:35:30+00:00",
        "closed_at": "2019-01-09T15:35:30+00:00",
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1602,
        "title": "deep_attention_matching_net在python3.5下训练报错",
        "body": "使用环境：CentOS，python3.5\r\ndeep_attention_matching_net在训练一段时间后有个报错：\r\nprocessed: [0.9888] ave loss: [0.6957890391349792]\r\nprocessed: [0.9984] ave loss: [0.7063019275665283]\r\nTraceback (most recent call last):\r\n  File \"train_and_evaluate.py\", line 404, in <module>\r\n    train(args)\r\n  File \"train_and_evaluate.py\", line 394, in train\r\n    .format(epoch, \"%2.2f sec\" % time.time() -begin_time ))\r\nTypeError: unsupported operand type(s) for -: 'str' and 'float'",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-07T03:24:44+00:00",
        "updated_at": "2019-01-10T11:08:18+00:00",
        "closed_at": "2019-01-10T11:08:18+00:00",
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1607,
        "title": "deeplabv3",
        "body": "![default](https://user-images.githubusercontent.com/38428867/50771442-a05fc900-12c5-11e9-8506-861bb46a73c9.png)\r\n![default](https://user-images.githubusercontent.com/38428867/50771469-b3729900-12c5-11e9-9966-b973fbf83016.png)\r\n\r\nread.py中\r\n        if six.PY2:\r\n            import commands\r\n            label_files = commands.getoutput(\r\n                \"find %s -type f | grep labelTrainIds | sort\" %\r\n                label_dirname).splitlines()\r\n            print(label_files)\r\n        else:\r\n            import subprocess\r\n            label_files = subprocess.getstatusoutput(\r\n                \"find %s -type f | grep labelTrainIds | sort\" %\r\n                label_dirname)[-1].splitlines()\r\n            print(label_files)\r\n\r\nlabel_files读取到的是空列表[],dataset是cityscape\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": "geng007",
        "created_at": "2019-01-07T13:44:39+00:00",
        "updated_at": "2019-01-08T05:14:49+00:00",
        "closed_at": null,
        "comments_count": [
            "busyboxs"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1608,
        "title": "deeplabv3修改类别后，出现错误",
        "body": "机器环境：ubuntu16.04 + CUDA8 + cudnn5.1 + paddlepaddle1.1（post85）+ anaconda(py2.7)\r\n\r\n如果不改类别数目，导入预训练模型可以正常运行；\r\n\r\n如果修改类别数目，不导入预训练模型可以正常运行；\r\n\r\n如果修改类别数目，导入预训练模型则会报错；\r\n\r\n错误为\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 169, in <module>\r\n    fetch_list=[pred, loss_mean])\r\n  File \"/home/yangshun/anaconda2/envs/paddle1.2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 470, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected in_dims.size() == filter_dims.size(), but received in_dims.size():4 != filter_dims.size():1.\r\nConv input dimension and filter dimension should be the same. at [/paddle/paddle/fluid/operators/conv_op.cc:50]\r\n```\r\n\r\n很奇怪，调试半天也不知道为什么，\r\n\r\n\r\n",
        "state": "closed",
        "user": "busyboxs",
        "closed_by": "busyboxs",
        "created_at": "2019-01-07T14:04:17+00:00",
        "updated_at": "2019-02-25T04:33:39+00:00",
        "closed_at": "2019-01-11T07:33:48+00:00",
        "comments_count": [
            "qingqing01",
            "busyboxs",
            "busyboxs",
            "hiudawn",
            "freekoy",
            "tycallen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1606,
        "title": "transformer模型训练时，没有训练就出现了StopIteration的错误",
        "body": "按照wiki https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleNLP/neural_machine_translation/transformer/README_cn.md 执行transformer，\r\n得到的日志为：\r\n65 [2019-01-07 20:15:17,001 INFO train.py:608] epoch: 25, consumed 0    .000111s\r\n 67 [2019-01-07 20:15:19,531 INFO train.py:608] epoch: 26, consumed 0    .000145s\r\n 69 [2019-01-07 20:15:21,376 INFO train.py:608] epoch: 27, consumed 0    .000136s\r\n 71 [2019-01-07 20:15:22,998 INFO train.py:608] epoch: 28, consumed 0    .000079s\r\n 73 [2019-01-07 20:15:24,641 INFO train.py:608] epoch: 29, consumed 0    .000208s\r\n并没有进行真正的训练，直接出现StopIteration的excetion。\r\n请问这个是什么原因？",
        "state": "open",
        "user": "dashulu",
        "closed_by": null,
        "created_at": "2019-01-07T12:40:00+00:00",
        "updated_at": "2019-01-08T06:11:57+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "dashulu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1610,
        "title": "Faster rcnn profile运行nan",
        "body": "\r\n![image](https://user-images.githubusercontent.com/13645332/50773747-9d1c0b80-12cc-11e9-98f2-5bc3d60fe306.png)\r\n\r\n跑了下profile， loss有点问题",
        "state": "closed",
        "user": "shippingwang",
        "closed_by": "shippingwang",
        "created_at": "2019-01-07T14:36:18+00:00",
        "updated_at": "2019-01-08T03:48:25+00:00",
        "closed_at": "2019-01-08T03:48:25+00:00",
        "comments_count": [
            "jerrywgz",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1611,
        "title": "URL can not open",
        "body": "https://github.com/baidu/Dialogue/DAM\r\nGet 404 error",
        "state": "closed",
        "user": "Lirunhua",
        "closed_by": "wzzju",
        "created_at": "2019-01-07T16:08:40+00:00",
        "updated_at": "2019-01-09T15:33:41+00:00",
        "closed_at": "2019-01-08T15:14:50+00:00",
        "comments_count": [
            "wzzju"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1613,
        "title": "我在安装DeepASR模块的时候遇到了下面的报错，请问该怎么解决？",
        "body": "[hhj@hhj decoder]$ sh setup.sh \r\nrunning build_ext\r\nbuilding 'post_latgen_faster_mapped' extension\r\ng++ -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -Ipybind11/include -I. -I/home/hhj/GradDesi/kaldi/src -I/home/hhj/GradDesi/kaldi/tools/openfst/src/include -IThreadPool -I/usr/include/python2.7 -c pybind.cc -o build/temp.linux-x86_64-2.7/pybind.o -std=c++11 -fopenmp -Wno-sign-compare -Wno-unused-variable -Wno-unused-local-typedefs -Wno-unused-but-set-variable -Wno-deprecated-declarations -Wno-unused-function\r\ng++ -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -Ipybind11/include -I. -I/home/hhj/GradDesi/kaldi/src -I/home/hhj/GradDesi/kaldi/tools/openfst/src/include -IThreadPool -I/usr/include/python2.7 -c post_latgen_faster_mapped.cc -o build/temp.linux-x86_64-2.7/post_latgen_faster_mapped.o -std=c++11 -fopenmp -Wno-sign-compare -Wno-unused-variable -Wno-unused-local-typedefs -Wno-unused-but-set-variable -Wno-deprecated-declarations -Wno-unused-function\r\ng++ -pthread -shared -Wl,-z,relro build/temp.linux-x86_64-2.7/pybind.o build/temp.linux-x86_64-2.7/post_latgen_faster_mapped.o -L/home/hhj/GradDesi/kaldi/tools/openfst/lib -L/home/hhj/GradDesi/kaldi/src/base -L/home/hhj/GradDesi/kaldi/src/matrix -L/home/hhj/GradDesi/kaldi/src/util -L/home/hhj/GradDesi/kaldi/src/tree -L/home/hhj/GradDesi/kaldi/src/hmm -L/home/hhj/GradDesi/kaldi/src/fstext -L/home/hhj/GradDesi/kaldi/src/decoder -L/home/hhj/GradDesi/kaldi/src/lat -L/usr/lib64 -Wl,-R/home/hhj/GradDesi/kaldi/tools/openfst/lib -Wl,-R/home/hhj/GradDesi/kaldi/src/base -Wl,-R/home/hhj/GradDesi/kaldi/src/matrix -Wl,-R/home/hhj/GradDesi/kaldi/src/util -Wl,-R/home/hhj/GradDesi/kaldi/src/tree -Wl,-R/home/hhj/GradDesi/kaldi/src/hmm -Wl,-R/home/hhj/GradDesi/kaldi/src/fstext -Wl,-R/home/hhj/GradDesi/kaldi/src/decoder -Wl,-R/home/hhj/GradDesi/kaldi/src/lat -lfst -lkaldi-base -lkaldi-util -lkaldi-matrix -lkaldi-tree -lkaldi-hmm -lkaldi-fstext -lkaldi-decoder -lkaldi-lat -lpython2.7 -o /home/hhj/GradDesi/models/fluid/DeepASR/decoder/post_latgen_faster_mapped.so\r\n**_/usr/bin/ld: cannot find -lkaldi-base\r\n/usr/bin/ld: cannot find -lkaldi-util\r\n/usr/bin/ld: cannot find -lkaldi-matrix\r\n/usr/bin/ld: cannot find -lkaldi-tree\r\n/usr/bin/ld: cannot find -lkaldi-hmm\r\n/usr/bin/ld: cannot find -lkaldi-fstext\r\n/usr/bin/ld: cannot find -lkaldi-decoder\r\n/usr/bin/ld: cannot find -lkaldi-lat\r\ncollect2: error: ld returned 1 exit status\r\nerror: command 'g++' failed with exit status 1_**",
        "state": "closed",
        "user": "wshhja",
        "closed_by": "wshhja",
        "created_at": "2019-01-08T07:20:31+00:00",
        "updated_at": "2019-01-09T08:48:39+00:00",
        "closed_at": "2019-01-09T08:48:39+00:00",
        "comments_count": [
            "wshhja"
        ],
        "labels": [
            "DeepASR"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1614,
        "title": "icnet项目中trian.py和infer.py 中images大小不一致，导致windows下预测报错",
        "body": "train.py中\r\n```\r\ndata_shape = (3, 720, 720)\r\nimages = fluid.layers.data(name='image', shape=data_shape, dtype='float32')\r\n```\r\ninfer.py中\r\n```\r\ndata_shape = [3, 1024, 2048]\r\nimages = fluid.layers.data(name='image', shape=train_shape, dtype='float32')\r\n```\r\n我是在windows上的paddlepaddle，infer时会报错。按照我的常识，infer中的data_shape应该和train中的一致，改成一致，infer能够执行，但是预测结果很差，这里就是应该不一致吗？",
        "state": "closed",
        "user": "WangTaoSpace",
        "closed_by": "WangTaoSpace",
        "created_at": "2019-01-08T08:15:05+00:00",
        "updated_at": "2019-01-17T05:51:34+00:00",
        "closed_at": "2019-01-17T05:51:34+00:00",
        "comments_count": [
            "wanghaoshuang",
            "WangTaoSpace",
            "wanghaoshuang",
            "wanghaoshuang",
            "WangTaoSpace",
            "wanghaoshuang",
            "geng007",
            "WangTaoSpace",
            "wanghaoshuang",
            "WangTaoSpace",
            "WangTaoSpace",
            "universea",
            "wanghaoshuang",
            "WangTaoSpace",
            "WangTaoSpace",
            "wanghaoshuang",
            "universea"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1618,
        "title": "lac安装时conf内容没下载下来",
        "body": "lac在linux下的安装没提示需要git-lfs，运行后报错也没看出来conf内容没下载。建议文档中加个需要下载git-lfs的提示",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "jshower",
        "created_at": "2019-01-09T06:49:32+00:00",
        "updated_at": "2019-01-10T03:03:05+00:00",
        "closed_at": "2019-01-10T03:03:05+00:00",
        "comments_count": [
            "jerrywgz",
            "jshower"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1617,
        "title": "face_detection和object_detection运行结束报错",
        "body": "face_detection和object_detection运行结束报错，并且object_detection在python2下运行结束会另外报'traceback' is not defined\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\n*** Aborted at 1545741303 (unix time) try \"date -d @1545741303\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\n*** SIGTERM (@0x186) received by PID 478 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 472 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 475 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 487 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 484 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 481 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 490 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n*** SIGTERM (@0x186) received by PID 493 (TID 0x7f8e2779d700) from PID 390; stack trace: ***\r\n    @     0x7f90564f3330 (unknown)\r\n    @     0x7f90564f3330 (unknown)\r\n    @     0x7f90564f3330 (unknown)\r\n    @           0x4f8611 PyUnicode_AsEncodedString\r\n    @     0x7f90564f3330 (unknown)\r\n    @     0x7f90564f3330 (unknown)\r\n    @     0x7f90564f3330 (unknown)\r\n    @     0x7f90564f3330 (unknown)\r\n    @           0x5ce5a8 (unknown)\r\n    @           0x513be0 PyUnicode_Format\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-01-09T06:47:06+00:00",
        "updated_at": "2019-01-24T06:39:52+00:00",
        "closed_at": "2019-01-24T06:39:52+00:00",
        "comments_count": [
            "qingqing01",
            "YanYan0716",
            "xiegegege",
            "YanYan0716",
            "xiegegege",
            "YanYan0716",
            "xiegegege"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1620,
        "title": "object_detection在使用coco数据集时需要修改data_dir",
        "body": "object_detection在使用coco数据集时需要修改data_dir（文档没提示）",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-01-09T06:55:53+00:00",
        "updated_at": "2019-01-24T06:39:52+00:00",
        "closed_at": "2019-01-24T06:39:52+00:00",
        "comments_count": [
            "jerrywgz",
            "xiegegege"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1619,
        "title": "video_classification数据路径问题",
        "body": "video_classification的train_list文件中定义的数据路径都是当前data路径，无法灵活设置数据。\r\n且需要在data目录下新建一个video_classification文件，并在其中存放train_pkl（readme中没提示）",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-09T06:53:29+00:00",
        "updated_at": "2019-01-24T09:53:46+00:00",
        "closed_at": "2019-01-24T09:53:46+00:00",
        "comments_count": [
            "jerrywgz",
            "SunGaofeng",
            "xiegegege"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1622,
        "title": "faster_rcnn的默认数据路径错误",
        "body": "faster_rcnn的默认数据路径是data/COCO17需要修改为dataset/coco",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-09T06:58:12+00:00",
        "updated_at": "2019-01-11T03:04:51+00:00",
        "closed_at": "2019-01-11T03:04:51+00:00",
        "comments_count": [
            "jerrywgz",
            "xiegegege",
            "jerrywgz",
            "xiegegege"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1621,
        "title": "neural_machine_translation的read me里的公式格式有问题",
        "body": "neural_machine_translation/rnn_search 的read me里的公式格式有问题",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shanyi15",
        "created_at": "2019-01-09T06:57:10+00:00",
        "updated_at": "2019-02-19T10:58:42+00:00",
        "closed_at": "2019-02-19T10:58:42+00:00",
        "comments_count": [
            "jerrywgz",
            "joodo"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1629,
        "title": "I",
        "body": "",
        "state": "closed",
        "user": "geng007",
        "closed_by": "geng007",
        "created_at": "2019-01-09T10:55:42+00:00",
        "updated_at": "2019-01-09T11:07:29+00:00",
        "closed_at": "2019-01-09T11:07:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1623,
        "title": "ctr的数据下载链接失效了",
        "body": "ctr的数据下载链接失效了",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-09T06:59:36+00:00",
        "updated_at": "2019-01-10T05:14:28+00:00",
        "closed_at": "2019-01-10T05:14:28+00:00",
        "comments_count": [
            "Superjomn",
            "xiegegege",
            "Superjomn",
            "jacquesqiao",
            "xiegegege"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1630,
        "title": "icnet",
        "body": "icnet中的infer.py中 `img = paddle.dataset.image.to_chw(image)[np.newaxis, :]`  , paddle读取到的img.shape =(1, 3, 1710, 3384) , 读取之后进行cv2.resize , 报错,请问 paddle读取的img 如何resize\r\n\r\n\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": null,
        "created_at": "2019-01-09T11:02:01+00:00",
        "updated_at": "2019-01-10T02:22:44+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1631,
        "title": "pytorch模型转fluid模型 脚本",
        "body": "请问可以提供一个 pytorch模型转fluid模型的demo吗？",
        "state": "closed",
        "user": "soldier828",
        "closed_by": "soldier828",
        "created_at": "2019-01-10T02:16:18+00:00",
        "updated_at": "2019-01-11T02:28:06+00:00",
        "closed_at": "2019-01-11T02:28:06+00:00",
        "comments_count": [
            "frankwhzhang",
            "soldier828",
            "frankwhzhang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1634,
        "title": "face_detection",
        "body": "hello, i want to know if the face_detection model could be used on CUDA8+CUDNN5.1 or it must be used on CUDA9+CUDNN7,thanks",
        "state": "closed",
        "user": "YanYan0716",
        "closed_by": "qingqing01",
        "created_at": "2019-01-10T06:57:48+00:00",
        "updated_at": "2019-01-25T16:24:16+00:00",
        "closed_at": "2019-01-25T16:24:16+00:00",
        "comments_count": [
            "qingqing01",
            "YanYan0716",
            "YanYan0716",
            "qingqing01",
            "YanYan0716",
            "qingqing01"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1633,
        "title": "图像分类中下载的ImageNet-2012图像数据到底多大？",
        "body": ">步骤二： 从ImageNet官网下载ImageNet-2012的图像数据。训练以及验证数据集会分别被下载到\"train\" 和 \"val\" 目录中。请注意，ImaegNet数据的大小超过40GB，下载非常耗时；已经自行下载ImageNet的用户可以直接将数据组织放置到data/ILSVRC2012。\r\n\r\n文档说是超过40GB，我以为是40GB左右，竟然单独训练数据就有138GB了，是脚本问题，还是文档写错了？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-01-10T06:54:18+00:00",
        "updated_at": "2019-01-10T08:31:56+00:00",
        "closed_at": "2019-01-10T08:31:56+00:00",
        "comments_count": [
            "qingqing01",
            "yeyupiaoling"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1641,
        "title": "分布训练是否要求每个node的gpu数量型号要一致？",
        "body": "分布训练是否要求每个node的gpu数量型号要一致？我有4台一台双K80，一台一块K80，一台p100，1台1080ti，可否允许分布训练？\r\n另外，如果有多台trainer，其中一台用gpu，一台用cpu，是否也可以执行分布训练？",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "wangguibao",
        "created_at": "2019-01-11T02:01:41+00:00",
        "updated_at": "2019-01-16T11:00:51+00:00",
        "closed_at": "2019-01-14T15:40:53+00:00",
        "comments_count": [
            "typhoonzero",
            "qianledan",
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1640,
        "title": "dist_train.py文档中的方法如何详解？",
        "body": "官网的github中的分布训练dist_train.py文档中，append_bn_repeat_ini_op()方法是什么作用？里面有个参数num_repeats，重复次数用于什么？global_block().相关的方法都是什么意思，没有文档看不懂代码。\r\n![qq 20190111092734](https://user-images.githubusercontent.com/45925696/51007828-0b3e2800-1584-11e9-9bc7-4c3921b7c3e9.png)\r\n",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "wangguibao",
        "created_at": "2019-01-11T01:34:14+00:00",
        "updated_at": "2019-01-16T07:02:20+00:00",
        "closed_at": "2019-01-14T15:41:38+00:00",
        "comments_count": [
            "wangguibao",
            "typhoonzero",
            "qianledan",
            "qianledan"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1642,
        "title": "fluid模型加载外部权重",
        "body": "fluid使用pytorch模型的问题。\r\n1. pytorch训练好的模型怎么用fluid加载？\r\n2. 或者我这边已经有了每一层的模型参数，怎样生成对应的fluid模型？\r\n请问有什么可以参考的code吗？",
        "state": "closed",
        "user": "soldier828",
        "closed_by": "wangguibao",
        "created_at": "2019-01-11T02:29:53+00:00",
        "updated_at": "2019-01-17T02:36:51+00:00",
        "closed_at": "2019-01-17T02:36:51+00:00",
        "comments_count": [
            "wangguibao",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1646,
        "title": "chinese_ner模型易用性问题",
        "body": "\r\n<img width=\"512\" alt=\"5abd8023a19241ee4c0a101ae74d4ada\" src=\"https://user-images.githubusercontent.com/46314656/51097482-5ca61b80-17ff-11e9-9655-b1b597655f20.png\">\r\nchinese_ner文档中是通过修改代码来设置参数，但命令行就可以，建议给出主要的参数设置列表，例如：python train.py --train_data_dir=data/train_files ...\r\n另外，为方便用户使用，建议告知用户使用python train.py --help查看参数说明",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-14T05:36:03+00:00",
        "updated_at": "2019-01-29T12:03:33+00:00",
        "closed_at": "2019-01-29T12:03:33+00:00",
        "comments_count": [
            "Xreki"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1644,
        "title": "分布式训练时提示CUBLAS: not initialized",
        "body": "使用[dist_train.py](https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/image_classification/dist_train/dist_train.py)进行分布式训练，提示\r\n```\r\nTraceback (most recent call last):\r\n  File \"dist_train.py\", line 23, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/ar/.jumbo/lib/python2.7/site-packages/paddle/fluid/__init__.py\", line 142, in <module>\r\n    __bootstrap__()\r\n  File \"/home/ar/.jumbo/lib/python2.7/site-packages/paddle/fluid/__init__.py\", line 136, in __bootstrap__\r\n    core.init_devices(not in_test)\r\npaddle.fluid.core.EnforceNotMet: CUBLAS: not initialized,  at [/paddle/paddle/fluid/platform/device_context.cc:218]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f0eb82fad06p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f0eb9917d7fp paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace) + 3135\r\n2       0x7f0eb9918a08p paddle::platform::DeviceContextPool::DeviceContextPool(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&) + 552\r\n3       0x7f0eb991b2d8p paddle::framework::InitDevices(bool, std::vector<int, std::allocator<int> >) + 696\r\n4       0x7f0eb991b50dp paddle::framework::InitDevices(bool) + 285\r\n5       0x7f0eb82d9a0ap\r\n6       0x7f0eb8311414p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596\r\n7       0x7f0f199c8679p PyEval_EvalFrameEx + 22473\r\n8       0x7f0f199ca160p PyEval_EvalCodeEx + 2240\r\n9       0x7f0f199c84d1p PyEval_EvalFrameEx + 22049\r\n10      0x7f0f199ca160p PyEval_EvalCodeEx + 2240\r\n11      0x7f0f199ca272p PyEval_EvalCode + 50\r\n12      0x7f0f199d9792p PyImport_ExecCodeModuleEx + 194\r\n13      0x7f0f199d9c36p\r\n14      0x7f0f199da9cdp\r\n15      0x7f0f199db0bfp\r\n16      0x7f0f199db354p\r\n17      0x7f0f199db9c8p\r\n18      0x7f0f199dc6f4p PyImport_ImportModuleLevel + 68\r\n19      0x7f0f199c1cdfp\r\n20      0x7f0f1992e123p PyObject_Call + 83\r\n21      0x7f0f199c21c3p PyEval_CallObjectWithKeywords + 67\r\n22      0x7f0f199c4cb3p PyEval_EvalFrameEx + 7683\r\n23      0x7f0f199ca160p PyEval_EvalCodeEx + 2240\r\n24      0x7f0f199ca272p PyEval_EvalCode + 50\r\n25      0x7f0f199e465cp\r\n26      0x7f0f199e4730p PyRun_FileExFlags + 144\r\n27      0x7f0f199e5c3cp PyRun_SimpleFileExFlags + 220\r\n28      0x7f0f199f74fcp Py_Main + 3164\r\n29        0x38bfc21b45p __libc_start_main + 245\r\n30            0x400699p`\r\n```\r\n\r\n使用的命令为\r\n```\r\nPADDLE_TRAINING_ROLE=PSERVER \\\r\nPADDLE_TRAINERS=2 \\\r\nPADDLE_PSERVER_IPS=127.0.0.1 \\\r\nPADDLE_CURRENT_IP=127.0.0.1 \\\r\nPADDLE_PSERVER_PORT=7164 \\\r\npython dist_train.py \\\r\n    --model=DistResnet \\\r\n    --batch_size=32 \\\r\n    --update_method=pserver \\\r\n    --device=CPU \\\r\n    --data_dir=../data/ILSVRC2012\r\n```\r\n\r\n而相同环境变量下使用单机多卡GPU版本时训练时并未提示需要cublas.",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "wangguibao",
        "created_at": "2019-01-11T06:54:48+00:00",
        "updated_at": "2019-01-14T03:01:02+00:00",
        "closed_at": "2019-01-13T03:17:00+00:00",
        "comments_count": [
            "wangguibao",
            "imistyrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1647,
        "title": "faster_rcnn如果一旦数据指定错误，活找不到训练文件，程序会一直夯着",
        "body": "",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "kolinwei",
        "created_at": "2019-01-14T07:45:50+00:00",
        "updated_at": "2019-02-21T01:13:38+00:00",
        "closed_at": "2019-02-21T01:13:38+00:00",
        "comments_count": [
            "jerrywgz",
            "jerrywgz",
            "kolinwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1651,
        "title": "fluid c++预测库(cuda8.0-cudnn7-avx)在p4卡上跑，CreatePaddlePredictor未成功直接退出",
        "body": "如题",
        "state": "closed",
        "user": "likeqinqin",
        "closed_by": "likeqinqin",
        "created_at": "2019-01-14T11:52:27+00:00",
        "updated_at": "2019-01-14T13:45:09+00:00",
        "closed_at": "2019-01-14T13:45:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1649,
        "title": "faster_rcnn运行失败ValueError: Shape not match. What is defined in data layer is (-1L, 3L, 1333L, 1333L), but receive (1, 3, 800, 1205)",
        "body": "标题：faster_rcnn训练过程失败\r\nValueError: Shape not match. What is defined in data layer is (-1L, 3L, 1333L, 1333L), but receive (1, 3, 800, 1205)\r\n\r\n版本、环境信息：\r\n   1）PaddlePaddle版本：a92860a3b1dce1ddd25885e06514dfe02839aabc\r\n   3）GPU：GPU型号V100、CUDA9、CUDNN7\r\n   3）系统环境：请您描述系统类型、版本，例如Mac OS 10.14，Python版本\r\n\r\n训练信息\r\n   1）单机，单卡/多卡\r\n\r\n复现信息：\r\nFLAGS_benchmark=true python train.py --model_save_dir=output/ --data_dir=dataset/coco/ --max_iter=10 --enable_ce --pretrained_model=./imagenet_resnet50_fusebn\r\n\r\n问题描述：\r\nW0114 15:51:07.217496 116714 device_context.cc:262] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0114 15:51:07.217563 116714 device_context.cc:270] device: 0, cuDNN Version: 7.0.\r\nW0114 15:51:07.217572 116714 device_context.cc:294] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.1, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\nFile \"/home/paddle/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\nself.run()\r\nFile \"/home/paddle/anaconda2/lib/python2.7/threading.py\", line 754, in run\r\nself.__target(*self.__args, **self.__kwargs)\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 563, in provider_thread\r\nfor tensors in func():\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 610, in tensor_provider\r\nfor slots in paddle_reader():\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 287, in reader_creator\r\nyield self.feed(item)\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 206, in feed\r\nret_dict[each_name] = each_converter.done()\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 92, in done\r\nself._check_shape(arr.shape)\r\nFile \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 79, in _check_shape\r\nformat(self.shape, shape))\r\nValueError: Shape not match. What is defined in data layer is (-1L, 3L, 1333L, 1333L), but receive (1, 3, 800, 1205)",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "qingqing01",
        "created_at": "2019-01-14T08:14:58+00:00",
        "updated_at": "2019-01-23T03:48:14+00:00",
        "closed_at": "2019-01-23T03:48:14+00:00",
        "comments_count": [
            "Xreki"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1654,
        "title": "deeplabv3+保存路径错误",
        "body": "<img width=\"826\" alt=\"wechatdacff939e2d48988e08360120ac1cf1f\" src=\"https://user-images.githubusercontent.com/46314656/51155617-05fa1980-18b3-11e9-9072-ca397479639e.png\">\r\ndeeplabv3+文档中的权重保存路径为output，运行后会报如下错误：\r\n<img width=\"1786\" alt=\"wechat401389064ec308b5146b9c96f9c43e07\" src=\"https://user-images.githubusercontent.com/46314656/51155850-f7603200-18b3-11e9-9814-95f85c880027.png\">\r\n改成--save_weights_path=output/ 后才能运行正常。",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shippingwang",
        "created_at": "2019-01-15T02:52:07+00:00",
        "updated_at": "2019-01-15T13:51:32+00:00",
        "closed_at": "2019-01-15T13:51:32+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1650,
        "title": "text_classification文档中链接失效",
        "body": "<img width=\"866\" alt=\"620f566b2cf1a57c596e7b4e3351aadb\" src=\"https://user-images.githubusercontent.com/46314656/51102054-5cfee080-1818-11e9-9030-03132077f390.png\">\r\n链接失效，报404",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shippingwang",
        "created_at": "2019-01-14T08:21:28+00:00",
        "updated_at": "2019-01-15T13:52:13+00:00",
        "closed_at": "2019-01-15T13:52:13+00:00",
        "comments_count": [
            "Xreki",
            "shippingwang"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1655,
        "title": "face_detection文档格式错误",
        "body": "<img width=\"925\" alt=\"af50e062e8cdca1c56f078a2b8f64514\" src=\"https://user-images.githubusercontent.com/46314656/51162289-a01c8a80-18d0-11e9-9476-a6e77c212528.png\">\r\n\r\n1、图中“物体检测SSD算法”链接失效了，报404\r\n2、文档中公式格式错误",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shippingwang",
        "created_at": "2019-01-15T06:21:21+00:00",
        "updated_at": "2019-01-23T02:55:55+00:00",
        "closed_at": "2019-01-15T13:51:07+00:00",
        "comments_count": [
            "luotao1",
            "shanyi15",
            "shippingwang",
            "xiegegege"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1656,
        "title": "faster_rcnn模型易用性问题",
        "body": "为方便用户使用，建议按照操作步骤来描述文档，在介绍预训练模型、cocoapi安装后再介绍运行命令python train.py .....",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-15T07:04:15+00:00",
        "updated_at": "2019-01-22T07:16:11+00:00",
        "closed_at": "2019-01-22T07:16:11+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1658,
        "title": "fluid textcnn模型训练+预测",
        "body": "想要使用fluid textcnn训练模型然后预测\r\n目前有自己的正负样本数据\r\n但是不知道怎么使用模型，\r\n1.数据应该按照什么样的格式\r\n2.数据应该放在哪儿，\r\n3.最终的产出模型在哪儿",
        "state": "closed",
        "user": "ninegsf",
        "closed_by": "shippingwang",
        "created_at": "2019-01-15T10:05:44+00:00",
        "updated_at": "2019-01-17T11:27:14+00:00",
        "closed_at": "2019-01-17T11:27:14+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1660,
        "title": "fluid textcnn模型，结果解读问题",
        "body": "paddlepaddle/models-develop/fluid/PaddleNLP/text_classification\r\n\r\n这个模型，跑完之后的预测部分，我有点儿疑问，\r\n我想要的预测是我给任意一个预测数据，能够给出正负样本的概率，但现在没有这样的输出，请问要怎么样才能有呢",
        "state": "closed",
        "user": "ninegsf",
        "closed_by": "heavengate",
        "created_at": "2019-01-16T04:58:54+00:00",
        "updated_at": "2019-01-16T07:23:48+00:00",
        "closed_at": "2019-01-16T07:23:25+00:00",
        "comments_count": [
            "ninegsf",
            "ninegsf",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1665,
        "title": "fluid textcnn模型，实现过程解读",
        "body": "使用fluid textcnn模型，想要拿到每一个测试样本的预测结果，\r\n同时想要改成自己想要的方式，但是对这个过程不是很了解，想要找相关同学了解一下",
        "state": "open",
        "user": "ninegsf",
        "closed_by": null,
        "created_at": "2019-01-16T11:23:26+00:00",
        "updated_at": "2019-01-16T11:24:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1661,
        "title": "训练速度慢，GPU占用率低",
        "body": "paddlepaddle-gpu 1.2 ,训练用的卡为P40，单卡测\r\n所用代码，已去除读取模块，由np生成的随机数直接灌入数据.\r\n```\r\n#coding=utf-8\r\nimport paddle.fluid as fluid\r\nimport numpy as np\r\nimport models\r\nimport time\r\nimport paddle.fluid.profiler as profiler\r\n\r\ndef test_speed():\r\n    image = fluid.layers.data(name=\"image\", shape=[3, 224, 224])\r\n    #label = fluid.layers.data(name=\"label\", shape=[1], dtype=\"int64\")\r\n    model=models.__dict__[\"AlexNet\"]()\r\n    predict=model.net(image)\r\n    #place = fluid.CPUPlace()\r\n    place=fluid.CUDAPlace(0) \r\n    exe = fluid.Executor(place)\r\n    exe.run(fluid.default_startup_program())\r\n    profiler.start_profiler('GPU')\r\n    index=0\r\n    while True:\r\n        t1 = time.time()\r\n        results=exe.run(feed={\"image\":np.random.random(size=(32, 3, 224, 224)).astype('float32')},\r\n        fetch_list=[predict])\r\n        t2=time.time()\r\n        print(\"time:\",t2-t1)\r\n        if index==2:\r\n            profiler.reset_profiler()\r\n        if index>=4:\r\n            profiler.stop_profiler('total', 'profile')\r\n        index+=1\r\nif __name__==\"__main__\":\r\n    test_speed()\r\n```\r\nprofile出来，GPU大段时间空闲，CPU中有80%的时间不知在干啥.",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-01-16T06:16:02+00:00",
        "updated_at": "2021-07-20T03:49:04+00:00",
        "closed_at": "2021-07-20T03:49:04+00:00",
        "comments_count": [
            "heavengate",
            "imistyrain",
            "heavengate",
            "imistyrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1667,
        "title": "量化后模型并没有变为原来的1/4",
        "body": "按照[量化](https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/object_detection/README_quant.md)的步骤来的，相关日志可查看[paddlepaddle int8量化](https://mp.csdn.net/postedit/85943850)\r\n正常量化结果应该是类似[mobilenet_v1_ssd](https://github.com/hjchen2/paddle-test/tree/master/fluid_models/mobilenet_v1_ssd)提供的\r\n\r\n",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "qingqing01",
        "created_at": "2019-01-17T06:53:34+00:00",
        "updated_at": "2019-01-28T03:44:52+00:00",
        "closed_at": "2019-01-28T03:44:52+00:00",
        "comments_count": [
            "hjchen2",
            "hjchen2",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1669,
        "title": "用create_lod_tensor创建一个lod_tensor,输入的data是numpy的array,执行len(tensor.shape)报错",
        "body": "代码:\r\nlabel_weight = np.array([[1,0,0,0,0,0,0,0,0],\r\n                             [0,30,0,0,0,0,0,0,0],\r\n                             [0,0,30,0,0,0,0,0,0],\r\n                             [0,0,0,30,0,0,0,0,0],\r\n                             [0,0,0,0,30,0,0,0,0],\r\n                             [0,0,0,0,0,30,0,0,0],\r\n                             [0,0,0,0,0,0,30,0,0],\r\n                             [0,0,0,0,0,0,0,30,0],\r\n                             [0,0,0,0,0,0,0,0,30]])\r\n\r\nlod_weight = fluid.create_lod_tensor(data=label_weight,recursive_seq_lens=[[9]],place=fluid.CUDAPlace(0))",
        "state": "open",
        "user": "xieqingxing",
        "closed_by": null,
        "created_at": "2019-01-17T12:14:11+00:00",
        "updated_at": "2019-01-18T02:22:01+00:00",
        "closed_at": null,
        "comments_count": [
            "xieqingxing",
            "hjchen2",
            "xieqingxing",
            "hjchen2",
            "xieqingxing",
            "xieqingxing",
            "hjchen2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1670,
        "title": "machine_reading_comprehension运行报operator elementwise_mul error",
        "body": "环境：ubuntu16 Cuda8 Cudnn7 python3.5  paddle的develop分支\r\nmachine_reading_comprehension在训练1000个batch后报operator elementwise_mul error\r\n\r\n<img width=\"890\" alt=\"bdc837f658c8188603b19d314ac9a088\" src=\"https://user-images.githubusercontent.com/46314656/51362440-a13afb00-1b0e-11e9-95c1-944866151ae7.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-18T02:49:02+00:00",
        "updated_at": "2019-02-15T11:02:46+00:00",
        "closed_at": "2019-02-15T11:02:46+00:00",
        "comments_count": [
            "xuezhong",
            "xuezhong",
            "xuezhong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1671,
        "title": "metric_learning 运行结束报错",
        "body": "环境：ubuntu16 Cuda8 Cudnn7 python3.5 paddle的develop分支\r\nmetric_learning运行结束后有报错：\r\n<img width=\"855\" alt=\"f698a4d9e18e21106128bfcd48f0b4af\" src=\"https://user-images.githubusercontent.com/46314656/51363875-f0842a00-1b14-11e9-8f2d-bd702067a0a7.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-01-18T03:34:09+00:00",
        "updated_at": "2019-01-29T06:27:29+00:00",
        "closed_at": "2019-01-29T06:27:29+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1673,
        "title": "word2vec运行报错",
        "body": "环境：ubuntu16 Cuda8 Cudnn7 python3.5 paddle的develop分支\r\nword2vec运行有报错，截图如下：\r\n<img width=\"884\" alt=\"f4a498ace1b377679ea6a0062ac68073\" src=\"https://user-images.githubusercontent.com/46314656/51373887-41f3df80-1b3c-11e9-9937-5aaef346fc4a.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-18T08:17:05+00:00",
        "updated_at": "2019-01-24T04:19:58+00:00",
        "closed_at": "2019-01-24T04:19:58+00:00",
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1672,
        "title": "C++ API 相关问题",
        "body": "CreatePaddlePredictor 这个C++的API 就相当于paddle-python最新版本里面的fluid.io.load_inference_model是一个功能吗 理论上CreatePaddlePredictor这个函数的返回值和fluid.io.load_inference_model的第二个输入参数产生的exe是等同的把？",
        "state": "open",
        "user": "xuzhenglei1991",
        "closed_by": null,
        "created_at": "2019-01-18T03:47:49+00:00",
        "updated_at": "2019-01-23T06:35:34+00:00",
        "closed_at": null,
        "comments_count": [
            "luotao1",
            "xuzhenglei1991",
            "xuzhenglei1991"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1678,
        "title": "machine_reading_comprehension 报编码错误",
        "body": "环境：ubuntu16 Cuda8 python3.6 paddle的develop分支\r\nmachine_reading_comprehension在运行一段时间后报错：\r\n<img width=\"885\" alt=\"58ba40ac9e549d58f1a2861efc026f8c\" src=\"https://user-images.githubusercontent.com/46314656/51510771-6ea83f80-1e39-11e9-8688-1be469a4336f.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-22T03:34:12+00:00",
        "updated_at": "2019-02-15T03:28:29+00:00",
        "closed_at": "2019-02-15T03:28:29+00:00",
        "comments_count": [
            "xuezhong",
            "xuezhong"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1675,
        "title": "DeepASR运行aishell在执行数据分析的时候，函数引不进来",
        "body": "在进行aishell数据分析步骤时，下面的import报错，找不到函数\r\n```js\r\n// 文件路径 models/fluid/DeepASR/tools/profile.py\r\nfrom data_utils.util import lodtensor_to_ndarray\r\n```\r\n\r\n报错信息如下：\r\n```js\r\n// 执行命令 sh profile.sh，执行路径models/fluid/DeepASR/examples/aishell\r\nTraceback (most recent call last):\r\n  File \"../../tools/profile.py\", line 19, in <module>\r\n    from data_utils.util import lodtensor_to_ndarray\r\nImportError: cannot import name lodtensor_to_ndarray\r\n```",
        "state": "open",
        "user": "wshhja",
        "closed_by": null,
        "created_at": "2019-01-21T01:30:41+00:00",
        "updated_at": "2019-02-22T11:48:29+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "wshhja"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1680,
        "title": "neural_machine_translation/transformer无法运行",
        "body": "环境：ubuntu16 cuda9 python3.6 paddle的develop分支\r\ntransformer无法运行，也没有报错信息，卡在了下图所示的状态中：\r\n<img width=\"822\" alt=\"325439b96b545d8b859a869ee4b0bcd8\" src=\"https://user-images.githubusercontent.com/46314656/51523092-dd9b8d80-1e65-11e9-9482-91cc3ff3d1ca.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "chengduoZH",
        "created_at": "2019-01-22T08:51:11+00:00",
        "updated_at": "2019-01-23T06:15:06+00:00",
        "closed_at": "2019-01-23T06:15:06+00:00",
        "comments_count": [
            "kolinwei",
            "chengduoZH"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1701,
        "title": "face_detection python3.7下报错",
        "body": "face_detection python3.7下报错，截图为：\r\n<img width=\"874\" alt=\"64a2d4ab3dbaca4b28c21a1ea18bf99b\" src=\"https://user-images.githubusercontent.com/46314656/51722692-3733d000-2091-11e9-8f02-e392cfd8c36d.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-01-25T03:06:19+00:00",
        "updated_at": "2019-01-25T16:06:35+00:00",
        "closed_at": "2019-01-25T16:06:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1686,
        "title": "deep_attention_matching_net报错",
        "body": "GPU类型为 V100 \r\n以下三个环境都有：\r\nubuntu16 Cuda9 python3.5 paddle的develop分支\r\nubuntu16 Cuda9 python3.6 paddle的develop分支\r\nubuntu16 Cuda9 python3.7 paddle的develop分支\r\ndeep_attention_matching_net在运行后报错：\r\n![default](https://user-images.githubusercontent.com/46928548/51596510-1b66e780-1f34-11e9-80d1-9365a0b7f17c.png)\r\n\r\n",
        "state": "closed",
        "user": "yuanfl",
        "closed_by": "yuanfl",
        "created_at": "2019-01-23T09:29:15+00:00",
        "updated_at": "2019-01-28T08:39:11+00:00",
        "closed_at": "2019-01-28T08:39:11+00:00",
        "comments_count": [
            "yuanfl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1689,
        "title": "human_pose_estimation运行报cv2.error",
        "body": "环境：ubuntu16 Cuda8 python2.7 gpu类型为p40\r\nhuman_pose_estimation运行报错，截图为：\r\n<img width=\"941\" alt=\"3777ecfcd342e150cc0c79949b43c1a4\" src=\"https://user-images.githubusercontent.com/46314656/51606922-37778280-1f4e-11e9-859e-e086e660f8de.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-23T12:35:38+00:00",
        "updated_at": "2019-01-25T07:58:20+00:00",
        "closed_at": "2019-01-25T07:58:20+00:00",
        "comments_count": [
            "kaiyuyue",
            "xiegegege",
            "kaiyuyue",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1690,
        "title": "word2vec运行报operator fill_constant error",
        "body": "环境：ubuntu16 Cuda8 python2.7 GPU类型: p40\r\nword2vec运行时报operator fill_constant error，截图如下：\r\n<img width=\"886\" alt=\"71405b9b8aa220e42bcefadbda83bfe0\" src=\"https://user-images.githubusercontent.com/46314656/51655030-d0051580-1fd5-11e9-9054-3f5105452fb0.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "sneaxiy",
        "created_at": "2019-01-24T04:43:09+00:00",
        "updated_at": "2019-01-25T15:37:26+00:00",
        "closed_at": "2019-01-25T15:37:26+00:00",
        "comments_count": [
            "JiabinYang",
            "sneaxiy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1703,
        "title": "deeplabv3",
        "body": "model.py在搭xception时定义了个[activation_fn_in_separable_conv](https://github.com/geng007/models/blob/022c0899a325107821eff6754702ea0f5fb82ed2/fluid/PaddleCV/deeplabv3%2B/models.py#L179) , 我的理解是paper中的SeparableConv相关的,这里具体指什么呢\r\n\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": null,
        "created_at": "2019-01-25T09:08:54+00:00",
        "updated_at": "2019-01-25T16:09:37+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1708,
        "title": "deeplab v3+模型训练",
        "body": "我使用官方给出的训练好的模型,在cityspace的验证集上eval,不能做到0.7+的miou,大概只有0.28.使用预训练模型进行训练在几万轮训练后,精度上升也不明显.\r\n另外想问下,在paddle中,如何设置各个类别的softmax_with_cross_entropy的权重,因为各个类别像素数量不是平均.",
        "state": "open",
        "user": "xieqingxing",
        "closed_by": null,
        "created_at": "2019-01-29T11:59:26+00:00",
        "updated_at": "2019-09-25T05:53:14+00:00",
        "closed_at": null,
        "comments_count": [
            "cjld",
            "Cugtyt",
            "eddieheyutong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1712,
        "title": "使用官网例程finetune se_resnext50不收敛",
        "body": "请教下，我安装了最新版的paddlepaddle_gpu-1.2.0.post85-cp27-cp27mu-linux_x86_64.whl，之后按照官网的例程（https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification  ）尝试在一个基本网络se_resnext50上用鸟类数据集CUB200来finetune（pretrain用的官网提供的imagenet预训练的模型，），但结果一直不收敛，loss完全不降，acc一致几乎是0，请问这会是什么问题呢？我已经删掉了pretrain里的fc6的文件，base lr=0.001",
        "state": "closed",
        "user": "yuanyc06",
        "closed_by": "qingqing01",
        "created_at": "2019-01-30T02:24:59+00:00",
        "updated_at": "2019-02-01T02:25:49+00:00",
        "closed_at": "2019-02-01T02:25:49+00:00",
        "comments_count": [
            "qingqing01",
            "yuanyc06"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1728,
        "title": "deep_attention_matching_net模型易用性问题",
        "body": "deep_attention_matching_net 预测得到的result.txt和score.txt文件里都只是一串数字，建议在数字前标明具体的指标名称\r\n<img width=\"582\" alt=\"667414348c6739131cba78702e48e8b2\" src=\"https://user-images.githubusercontent.com/46314656/52111371-830ce900-263e-11e9-9387-b82a24bc97e9.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "kuke",
        "created_at": "2019-02-01T08:30:02+00:00",
        "updated_at": "2019-02-28T10:16:54+00:00",
        "closed_at": "2019-02-28T10:16:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1713,
        "title": "怎样由caffe转过来的模型进行微调？",
        "body": "已经使用[caffe2fluid](https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/caffe2fluid)工具将caffe训练的模型转成了fluid模型，也使用fluid.io.load_inference_model加载进来获得了program，但是怎样将test的program转为train的program呢？有没有相关的示例演示下后序的步骤？\r\n或者用已有的[models](https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification)里面的也成，怎么由save_inference_model的模型进行微调？",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-01-30T03:22:16+00:00",
        "updated_at": "2019-02-01T08:28:38+00:00",
        "closed_at": "2019-02-01T08:28:38+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1729,
        "title": "Chinese_ner模型易用性问题",
        "body": "Chinese_ner执行python train.py训练时模型存储的默认路径是output, 预测时执行python infer.py使用的模型默认路径是models，建议改为一致",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "kuke",
        "created_at": "2019-02-01T08:38:17+00:00",
        "updated_at": "2019-02-28T09:28:24+00:00",
        "closed_at": "2019-02-28T09:28:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1714,
        "title": "在python3.7下安装cocoapi报错",
        "body": "环境：ubuntu16 Cuda8 Cudnn7 python3.7 \r\n在运行faster_rcnn时按要求安装了cocoapi，但在make install 时报了如下错误：\r\n<img width=\"781\" alt=\"372558a74b9b671eecabbf48e4d00b2d\" src=\"https://user-images.githubusercontent.com/46314656/51963930-faf0dd00-249f-11e9-9a91-0c6bff8da60c.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-01-30T07:02:29+00:00",
        "updated_at": "2019-01-30T13:18:04+00:00",
        "closed_at": "2019-01-30T13:18:04+00:00",
        "comments_count": [
            "jerrywgz",
            "xiegegege",
            "jerrywgz",
            "jerrywgz",
            "xiegegege",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1718,
        "title": "rcnn在多卡时训练过程中退出",
        "body": "单卡没问题",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "qingqing01",
        "created_at": "2019-01-31T03:47:23+00:00",
        "updated_at": "2019-02-01T02:34:06+00:00",
        "closed_at": "2019-02-01T02:34:06+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1731,
        "title": "关于icnet模型分类输出层的疑问",
        "body": "您好，在模型的最终类别输出层的act 类型有个疑问？即使icnet是像素级别的end to end模型，最终输出层的act 设置成softmax会不会更好一点，例如，依据某个像素坐标上的多个维度特征计算softmax，从而确定这个坐标像素的类别。\r\n\r\n我看了下代码，icnet中的act是None，pytorch版本的pspnet中的act是nn.LogSoftmax()，icnet中的act为啥是None",
        "state": "open",
        "user": "WangTaoSpace",
        "closed_by": null,
        "created_at": "2019-02-01T12:57:41+00:00",
        "updated_at": "2019-02-21T01:55:12+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "WangTaoSpace",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1748,
        "title": "squad v1.1任务在运行结束时无法退出且没有生成predict.json文件",
        "body": "bert模型在squad v1.1任务训练结束时无法退出，且没有生成predict.json文件\r\n<img width=\"885\" alt=\"1db9398c231918844c45405ff05cffc5\" src=\"https://user-images.githubusercontent.com/46314656/52706783-29eb7080-2fc1-11e9-9f3b-58a80c599a07.png\">\r\n卡在了如上图所示的状态，没有报错提示。",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-13T10:59:45+00:00",
        "updated_at": "2019-02-13T11:01:53+00:00",
        "closed_at": "2019-02-13T11:01:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1734,
        "title": "ZeroDivisionError: long division or modulo by zero",
        "body": "使用[object_detection](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/object_detection)训练mobilenet-ssd, 但是scale设为了0.25，得到\r\n```\r\n  File \"train.py\", line 338, in <module>\r\n    val_file_list=val_file_list)\r\n  File \"train.py\", line 183, in train\r\n    is_train=True)\r\n  File \"train.py\", line 112, in build_program\r\n    locs, confs, box, box_var = mobile_net(class_num, image, image_shape,scale=args.scale)\r\n  File \"mobilenet_ssd.py\", line 92, in mobile_net\r\n    module14 = extra_block(module13, 256, 512, 1, 2, scale)\r\n  File \"mobilenet_ssd.py\", line 58, in extra_block\r\n    padding=0)\r\n  File \"mobilenet_ssd.py\", line 26, in conv_bn\r\n    bias_attr=False)\r\n  File \"python2.7/site-packages/paddle/fluid/layers/nn.py\", line 1818, in conv2d\r\n    if num_channels % groups != 0:\r\nZeroDivisionError: long division or modulo by zero\r\n```\r\n经过调试，发现[mobilenet_ssd.py](https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/object_detection/mobilenet_ssd.py)57行处num_groups=int(num_groups * scale),由于传入的num_groups为1,导致计算出的num_groups结果为0.",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-02-02T02:38:13+00:00",
        "updated_at": "2021-07-20T03:48:50+00:00",
        "closed_at": "2021-07-20T03:48:50+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1750,
        "title": "softmax_with_cross_entropy优化报错",
        "body": "我自己写的程序\r\nb19 = fluid.layers.conv2d(x,num_filters=int(100),filter_size=[1, 1],stride=[1, 1],groups=1)\r\nb20 = fluid.layers.transpose(b19, perm=[0, 2, 3, 1])\r\nout1 = fluid.layers.reshape(b20, shape=[-1,100])\r\nout3 = fluid.layers.reshape(y, shape=[-1, 1])\r\nout2 = fluid.layers.cast(out3, dtype=\"int64\")\r\nloss=fluid.layers.softmax_with_cross_entropy(out1,out2)\r\navg=fluid.layers.reduce_mean(loss)\r\nreduced_loss = 0.9*avg\r\nregularizer = fluid.regularizer.L2Decay(0.0001)\r\noptimizer = fluid.optimizer.Momentum(\r\nlearning_rate=0.1, momentum=0.9, regularization=regularizer)\r\n_, params_grads = optimizer.minimize(reduced_loss)\r\n\r\n\r\n\r\n不运行最后一句 _, params_grads = optimizer.minimize(reduced_loss)\r\n\r\n不会报错，运行最后一句就会抱错\r\n\r\nEnforceNotMet: The input of cast op must be set at [E:\\dist\\Paddle\\paddle\\fluid\\operators\\cast_op.cc:42]\r\nPaddlePaddle Call Stacks: \r\nWindows not support stack backtrace yet.\r\n\r\n求大神指点",
        "state": "open",
        "user": "xyq019971",
        "closed_by": null,
        "created_at": "2019-02-14T04:51:38+00:00",
        "updated_at": "2019-02-14T04:51:38+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1749,
        "title": "AutoDL/LRC 模型训练 module 'paddle.fluid.layers' has no attribute 'adaptive_pool2d'",
        "body": "我使用版本为：python 3.5.2   paddlepaddle-gpu 1.2.1.post97\r\n\r\n执行./models/fluid/AutoDL/LRC/run.sh 时，报错如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_mixup.py\", line 247, in <module>\r\n    main()\r\n  File \"train_mixup.py\", line 116, in main\r\n    train(model, args, image_shape, steps_one_epoch)\r\n  File \"train_mixup.py\", line 153, in train\r\n    steps_one_epoch)\r\n  File \"train_mixup.py\", line 128, in build_program\r\n    args.batch_size, args.lrc_loss_lambda)\r\n  File \"/home/zhouzhengdong/models/fluid/AutoDL/LRC/model.py\", line 255, in train_model\r\n    self.logits, self.logits_aux = self.forward(init_channels, True)\r\n  File \"/home/zhouzhengdong/models/fluid/AutoDL/LRC/model.py\", line 217, in forward\r\n    out = fluid.layers.adaptive_pool2d(s1, (1, 1), \"avg\")\r\nAttributeError: module 'paddle.fluid.layers' has no attribute 'adaptive_pool2d'\r\n```\r\n\r\n我也去官网查了，在fluid.layers这个下面没有adaptive_pool2d方法。\r\n这要怎么解决？",
        "state": "closed",
        "user": "zzdgit",
        "closed_by": "shippingwang",
        "created_at": "2019-02-14T03:56:50+00:00",
        "updated_at": "2019-02-17T06:25:05+00:00",
        "closed_at": "2019-02-17T06:25:05+00:00",
        "comments_count": [
            "shippingwang",
            "ZhouFangru",
            "zzdgit",
            "ZhouFangru",
            "zzdgit",
            "zzdgit",
            "ZhouFangru",
            "zzdgit",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1751,
        "title": "图像分类模型使用run.sh 中的超参数训练VGG模型，模型不收敛",
        "body": "使用image_classification下run.sh中的指令对VGG模型进行训练，经过40多个eoch后，loss依然无明显降低，模型不收敛\r\n附件为VGG11和VGG13模型的log\r\n[VGG13.log](https://github.com/PaddlePaddle/models/files/2868371/VGG13.log)\r\n[VGG11.log](https://github.com/PaddlePaddle/models/files/2868372/VGG11.log)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-02-15T08:19:25+00:00",
        "updated_at": "2019-03-07T07:11:21+00:00",
        "closed_at": "2019-03-07T07:11:21+00:00",
        "comments_count": [
            "shippingwang",
            "dashulu",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1753,
        "title": "paddle.fluid.core.EnforceNotMet: Enforce failed. Expected in_dims[1] == filter_dims[1] * groups, but received in_dims[1]:32 != filter_dims[1] * groups:1024.",
        "body": "使用[object_detection](https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/object_detection)在自己的数据集(仅含两类，背景和物体)上进行微调时报错，与预训练的模型类别不一致。而如果不使用预训练模型的话则可以正常训练.\r\n所用命令为\r\n```\r\npython -u train.py --image_shape=3,$SHAPE,$SHAPE \\\r\n--pretrained_model='pretrained/ssd_mobilenet_v1_coco/' \\\r\n--model_save_dir=model\r\n```\r\n有没有类似于caffe中更改层的名字以便重新初始化模型参数的方法来在paddle中对最后这些层重新初始化而不是从预训练模型中加载呢？",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "heavengate",
        "created_at": "2019-02-15T09:02:08+00:00",
        "updated_at": "2019-02-15T15:00:30+00:00",
        "closed_at": "2019-02-15T15:00:30+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1752,
        "title": "face_detection模型无法正常退出，ctrl+c退出后还会占用GPU显存",
        "body": "执行前\r\n![image](https://user-images.githubusercontent.com/10734244/52845461-23d0cd80-3142-11e9-90d5-2ea76f0079c4.png)\r\n执行后,显存没有释放\r\n![image](https://user-images.githubusercontent.com/10734244/52845565-672b3c00-3142-11e9-9546-b5febd1b88c8.png)\r\n需要手动杀掉进程才行\r\n![image](https://user-images.githubusercontent.com/10734244/52845609-83c77400-3142-11e9-867f-763456afc3b7.png)\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "heavengate",
        "created_at": "2019-02-15T08:56:04+00:00",
        "updated_at": "2019-02-20T07:14:23+00:00",
        "closed_at": "2019-02-20T07:14:23+00:00",
        "comments_count": [
            "heavengate",
            "DDDivano",
            "heavengate",
            "DDDivano",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1754,
        "title": "video stnet模型在运行开始时异常退出",
        "body": "报错如下：\r\n[INFO: train.py:  221]: Namespace(batch_size=None, config='./configs/stnet.txt', epoch_num=60, learning_rate=None, log_interval=10, model_name='STNET', no_memory_optimize=False, no_use_pyreader=False, pretrain=None, resume=None, save_dir='checkpoints', use_gpu=True, valid_interval=1)\r\nW0215 20:03:56.300457 16342 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0215 20:03:56.303936 16342 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\n*** Aborted at 1550261088 (unix time) try \"date -d @1550261088\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x50) received by PID 16342 (TID 0x7fb0f3df1700) from PID 80; stack trace: ***\r\n    @     0x7fb0f39ce390 (unknown)\r\n    @     0x7faabf695415 (unknown)\r\n    @     0x7faabf68e5b0 (unknown)\r\n    @     0x7faabf69290d ncclCommInitAll\r\n    @     0x7fb08b3ccba8 paddle::platform::NCCLContextMap::NCCLContextMap()\r\n    @     0x7fb08b3c9072 paddle::framework::ParallelExecutor::ParallelExecutor()\r\n    @     0x7fb08b2c4542 _ZZN8pybind1112cpp_function10initializeIZNS_6detail8initimpl11constructorIIRKSt6vectorIN5boost7variantIN6paddle8platform9CUDAPlaceENS9_8CPUPlaceENS9_15CUDAPinnedPlaceENS6_6detail7variant5void_ESF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_SF_EESaISG_EERKSt13unordered_setINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4hashISR_ESt8equal_toISR_ESaISR_EERKNS8_9framework11ProgramDescERKSR_PNS10_5ScopeERS5_IS17_SaIS17_EERKNS10_7details17ExecutionStrategyERKNS1B_13BuildStrategyEEE7executeINS_6class_INS10_16ParallelExecutorEIEEEIELi0EEEvRT_DpRKT0_EUlRNS2_16value_and_holderESK_SZ_S13_S15_S17_S1A_S1E_S1H_E_vIS1U_SK_SZ_S13_S15_S17_S1A_S1E_S1H_EINS_4nameENS_9is_methodENS_7siblingENS2_24is_new_style_constructorEEEEvOS1N_PFT0_DpT1_EDpRKT2_ENUlRNS2_13function_callEE1_4_FUNES2B_\r\n    @     0x7fb08b284b2d pybind11::cpp_function::dispatcher()\r\n    @           0x60bb6b _PyMethodDef_RawFastCallDict\r\n    @           0x4eaf20 _PyObject_Call_Prepend\r\n    @           0x4eb56e PyObject_Call\r\n    @           0x43f655 (unknown)\r\n    @           0x52ab79 (unknown)\r\n    @           0x4e99ea _PyObject_FastCallKeywords\r\n    @           0x561224 _PyEval_EvalFrameDefault\r\n    @           0x55b39a _PyEval_EvalCodeWithName\r\n    @           0x4eb2e8 _PyObject_Call_Prepend\r\n    @           0x52d667 (unknown)\r\n    @           0x52ab79 (unknown)\r\n    @           0x4e9ad5 _PyObject_FastCallKeywords\r\n    @           0x56164b _PyEval_EvalFrameDefault\r\n    @           0x55b760 _PyEval_EvalCodeWithName\r\n    @           0x4ea963 _PyFunction_FastCallKeywords\r\n    @           0x55c2c9 _PyEval_EvalFrameDefault\r\n    @           0x55b39a _PyEval_EvalCodeWithName\r\n    @           0x55b123 PyEval_EvalCode\r\n    @           0x62ce02 (unknown)\r\n    @           0x62d26a PyRun_FileExFlags\r\n    @           0x62d027 PyRun_SimpleFileExFlags\r\n    @           0x606265 (unknown)\r\n    @           0x605eea _Py_UnixMain\r\n    @     0x7fb0f2ac0830 __libc_start_main\r\nscripts/train/train_stnet.sh: line 2: 16342 Segmentation fault      python train.py --model-name=\"STNET\" --config=./configs/stnet.txt --epoch-num=60 --valid-interval=1 --log-interval=10\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-16T01:36:43+00:00",
        "updated_at": "2019-03-26T09:10:23+00:00",
        "closed_at": "2019-03-26T09:10:23+00:00",
        "comments_count": [
            "SunGaofeng",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1755,
        "title": "AI studio部署Face Detector: PyramidBox 参数问题",
        "body": "我想把AI studio训练完的Face Detector: PyramidBox 模型在线部署，但是输入和输出参数应该如何去写？",
        "state": "open",
        "user": "ThinkPeace",
        "closed_by": "ThinkPeace",
        "created_at": "2019-02-16T14:53:18+00:00",
        "updated_at": "2020-01-07T04:26:32+00:00",
        "closed_at": null,
        "comments_count": [
            "lixuan1",
            "lixuan1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1758,
        "title": "video stnet 模型在训练一段时间后loss值变大",
        "body": "video stnet 模型在训练一段时间后loss值变大，截图如下：\r\n<img width=\"359\" alt=\"0b45bbfc7c3d5f1f9f797fa0c98d87f4\" src=\"https://user-images.githubusercontent.com/46314656/52932248-17d74c80-338a-11e9-90af-03e66dac40e8.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-18T06:33:12+00:00",
        "updated_at": "2019-03-28T09:08:12+00:00",
        "closed_at": "2019-03-28T09:08:12+00:00",
        "comments_count": [
            "SunGaofeng",
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1756,
        "title": "video tsn loss 下降很慢",
        "body": "video 下的tsn模型在运行到大概10个epoch后，loss下降的很缓慢，几乎没有变动，如图所示：\r\n<img width=\"638\" alt=\"cab56c604bac3a0b03738f0303f0fc5e\" src=\"https://user-images.githubusercontent.com/46314656/52926062-28c69480-336f-11e9-902c-a41d031a5fc4.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-18T03:21:29+00:00",
        "updated_at": "2019-02-20T03:41:41+00:00",
        "closed_at": "2019-02-20T03:41:41+00:00",
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1759,
        "title": "C++ RunPreparedContext接口使用问题",
        "body": "例子一：使用https://github.com/baidu/lac/tree/master/src 中的C++代码、模型以及对应的数据，工程能正确输出。\r\n\r\n例子二：将例子一中的输入数据、模型更换，输出的结果中全部是0。\r\n输入数据：检查过正确\r\n模型：python脚本训练出来的（fluid.io.save_inference_model储存的，v0.14.0）\r\n依赖的C++代码库： CONFIGS('baidu/paddlepaddle/paddle@0.14.0@git_branch')\r\nfetch_targets这个里面只有一个键值对：crf_decoding_0.tmp_0 个数是输入序列长度\r\n\r\n辛苦相关同学能帮我看下这个是什么原因吗\r\n",
        "state": "open",
        "user": "xuzhenglei1991",
        "closed_by": null,
        "created_at": "2019-02-18T06:59:43+00:00",
        "updated_at": "2019-02-19T03:14:25+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315",
            "Superjomn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1760,
        "title": "MobileNet V2 loss下降缓慢",
        "body": "运行了40个pass后依然保持较高的loss，和较低的acc，且变化速度缓慢，如图所示：\r\n<img width=\"1010\" alt=\"913d104b1b9adb8f243c3ff49b2915f3\" src=\"https://user-images.githubusercontent.com/46314656/52934457-73590880-3391-11e9-9d23-ada0f0921bc2.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-18T07:26:12+00:00",
        "updated_at": "2019-03-06T04:51:44+00:00",
        "closed_at": "2019-03-06T04:51:44+00:00",
        "comments_count": [
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1763,
        "title": "machine_reading_comprehension validation错误",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleNLP/machine_reading_comprehension/run.py#L527\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 641, in <module>\r\n       evaluate(logger, args)\r\n  File \"run.py\", line 527, in evaluate\r\n       place, dev_count, vocab, brc_data, logger, args)\r\n TypeError: validation() takes exactly 12 arguments (11 given)\r\n```\r\n",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-02-18T09:56:51+00:00",
        "updated_at": "2019-02-18T11:44:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1761,
        "title": "face_detection 评估报错",
        "body": "paddle 1.3 版本\r\n在训练完后执行评估脚本出现如下错误：\r\n```bash\r\npython -u widerface_eval.py --model_dir=output/159 --pred_dir=pred\r\n```\r\n```bash\r\n-----------  Configuration Arguments -----------\r\n 16000 confs_threshold: 0.15\r\n 16001 data_dir: data/WIDER_val/images/\r\n 16002 file_list: data/wider_face_split/wider_face_val_bbx_gt.txt\r\n 16003 image_path:\r\n 16004 infer: False\r\n 16005 model_dir: output/159\r\n 16006 pred_dir: pred\r\n 16007 use_gpu: True\r\n 16008 use_pyramidbox: True\r\n 16009 ------------------------------------------------\r\n 16010 W0216 09:08:20.877653 38705 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runti\r\n       me API Version: 8.0\r\n 16011 W0216 09:08:20.877743 38705 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\n 16012 W0216 09:08:20.877751 38705 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.1, but CU\r\n       DNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compat\r\n       ible CUDNN version.\r\n 16013 Traceback (most recent call last):\r\n 16014   File \"widerface_eval.py\", line 316, in <module>\r\n 16015     infer(args, config)\r\n 16016   File \"widerface_eval.py\", line 64, in infer\r\n 16017     det4 = multi_scale_test_pyramid(image, max_shrink)\r\n 16018   File \"widerface_eval.py\", line 230, in multi_scale_test_pyramid\r\n 16019     det_b = detect_face(image, 0.25)\r\n 16020   File \"widerface_eval.py\", line 127, in detect_face\r\n 16021     det_conf = detection[:, 1]\r\n 16022 IndexError: index 1 is out of bounds for axis 1 with size 1\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "jerrywgz",
        "created_at": "2019-02-18T08:18:11+00:00",
        "updated_at": "2019-02-18T12:35:48+00:00",
        "closed_at": "2019-02-18T12:35:48+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1762,
        "title": "softmax结果输出异常",
        "body": "用fc层作为最后的输出层，激活函数用softmax， 得到的结果的每一维为不在[0, 1]区间\r\n\r\n网络结构定义\r\n```\r\npred = fluid.layers.fc(input=concat_layer, size=class_dim, act='softmax')\r\n\r\nif is_infer:\r\n    return pred\r\n\r\ncost = fluid.layers.cross_entropy(pred, label, soft_label=False)\r\navg_loss = fluid.layers.mean(cost)\r\nreturn pred, avg_loss, label\r\n```\r\n\r\n预测输出样例， 每一个向量对应一个样本的预测输出\r\n[[ -9.730734    -5.1658783   -4.312685   ...  -9.696777    -9.710938\r\n   -9.711664  ]\r\n [ -5.516372    -2.8050585   -3.3510437  ...  -5.5714464   -5.56005\r\n   -5.5435977 ]\r\n [-10.428526     1.9235992    0.12796116 ... -10.483575   -10.507859\r\n  -10.4472065 ]\r\n ...\r\n [ -7.946624    -2.8772902   -0.85136795 ...  -7.904846    -7.9342504\r\n   -7.872521  ]\r\n [ -9.148515    -2.5952282   -3.140316   ...  -9.204101    -9.194347\r\n   -9.149537  ]\r\n [-10.096511     4.156999     1.2503562  ... -10.243605   -10.187681\r\n  -10.082199  ]]\r\n",
        "state": "closed",
        "user": "snowsteper",
        "closed_by": "junjun315",
        "created_at": "2019-02-18T08:50:03+00:00",
        "updated_at": "2019-02-18T13:32:10+00:00",
        "closed_at": "2019-02-18T13:32:10+00:00",
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1764,
        "title": "ImageNet 高性能加速模型问题汇总",
        "body": "以下均在P40集群测试\r\n\r\n**1、PG模型下出现 double free or corruption错误；**\r\n模型配置如下：\r\n```bash\r\npython train.py --update_method=nccl2 --num_threads 1 --fp16 True --scale_loss 8.0\r\n-----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 256\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ./data/ILSVRC2012\r\nenable_ce: False\r\nfp16: 1\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 1\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 8.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: nccl2\r\nuse_gpu: True\r\nuse_visiontool: True\r\nvisiontool_workers: 16\r\nwith_mem_opt: False\r\n------------------------------------------------\r\nTotal examples: 320512, total time: 737.57827, 434.54642 examples/sed\r\n\r\nPass: 0, Test Loss 41.2, test acc1: 0.08636667, test acc5: 0.21744126\r\n```\r\n报错如下：\r\n```bash\r\n*** Error in `python': double free or corruption (fasttop): 0x00007f2694000a30 ***\r\n======= Backtrace: =========\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x7354f)[0x7f27b601454f]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x78dbe)[0x7f27b6019dbe]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x79a97)[0x7f27b601aa97]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework8Variable15PlaceholderImplINS_9operators15AlgorithmsCacheI31cudnnConvolutionBwdFilterAlgo_tEEED0Ev+0x6d)[0x7f275168e12d]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework8Variable10GetMutableINS_9operators15AlgorithmsCacheI31cudnnConvolutionBwdFilterAlgo_tEEEEPT_v+0x164)[0x7f2751690eb4]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZNK6paddle9operators21CUDNNConvGradOpKernelINS_8platform7float16EE7ComputeERKNS_9framework16ExecutionContextE+0x1304)[0x7f275169d9e4]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm2EINS0_9operators21CUDNNConvGradOpKernelIfEENSA_IdEENSA_INS7_7float16EEEEEclEPKcSH_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_+0x23)[0x7f275169e973]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZNK6paddle9framework18OperatorWithKernel7RunImplERKNS0_5ScopeERKN5boost7variantINS_8platform9CUDAPlaceENS7_8CPUPlaceENS7_15CUDAPinnedPlaceENS5_6detail7variant5void_ESD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_EE+0x293)[0x7f27529a10f3]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework12OperatorBase3RunERKNS0_5ScopeERKN5boost7variantINS_8platform9CUDAPlaceENS7_8CPUPlaceENS7_15CUDAPinnedPlaceENS5_6detail7variant5void_ESD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_SD_EE+0x155)[0x7f275299e975]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(+0x2717016)[0x7f2752823016]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(+0x27305fd)[0x7f275283c5fd]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIFvvEE+0x325)[0x7f275283bf55]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework7details19ComputationOpHandle7RunImplEv+0x70)[0x7f2752822ce0]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework7details12OpHandleBase3RunEb+0x76)[0x7f275283cd86]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(+0x26b451d)[0x7f27527c051d]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework7details24ThreadedSSAGraphExecutor5RunOpERKSt10shared_ptrINS0_13BlockingQueueIPNS1_13VarHandleBaseEEEEPNS1_12OpHandleBaseE+0x51d)[0x7f27527c0f1d]\r\n*** Aborted at 1550253252 (unix time) try \"date -d @1550253252\" if you are using GNU date ***\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZN6paddle9framework7details24ThreadedSSAGraphExecutor3RunERKSt6vectorISsSaISsEE+0x914)[0x7f27527c2b94]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(+0x26af7b2)[0x7f27527bb7b2]\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 33450 (TID 0x7f26a8dfa700) from PID 0; stack trace: ***\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultISt6vectorIN6paddle9framework9LoDTensorESaISB_EEEES3_ESD_EEE9_M_invokeERKSt9_Any_data+0x2a)[0x7f27527be2aa]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZNSt13__future_base11_State_base9_M_do_setERSt8functionIFSt10unique_ptrINS_12_Result_baseENS3_8_DeleterEEvEERb+0x27)[0x7f2751b91547]\r\n/opt/compiler/gcc-4.8.2/lib/libpthread.so.0(pthread_once+0x53)[0x7f27b6a65973]\r\n    @     0x7f27b6a68160 (unknown)\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(+0x26af252)[0x7f27527bb252]\r\n/usr/local/lib/python2.7/site-packages/paddle/fluid/core.so(_ZZN10ThreadPoolC1EmENKUlvE_clEv+0x194)[0x7f2751b927d4]\r\n/opt/compiler/gcc-4.8.2/lib/libstdc++.so.6(+0xb08a0)[0x7f27ab0de8a0]\r\n/opt/compiler/gcc-4.8.2/lib/libpthread.so.0(+0x81c3)[0x7f27b6a601c3]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(clone+0x6d)[0x7f27b608812d]\r\n```\r\n**2、PG模式下出现 `python': invalid fastbin entry 问题；**\r\n**单机和多机都会出现，但时间较久，有时70+pass，有时出现在110+pass**\r\n模型配置如下：\r\n```bash\r\nstart cmd is: python train.py --update_method=local --num_threads 1 --fp16 True --scale_loss 8.0\r\n-----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 256\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ./data/ILSVRC2012\r\nenable_ce: False\r\nfp16: 1\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 1\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 8.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: local\r\nuse_gpu: True\r\nuse_visiontool: True\r\nvisiontool_workers: 16\r\nwith_mem_opt: False\r\n------------------------------------------------\r\n```\r\n```bash\r\nPass 74, batch [30/5004], loss 6.953, acc1: 0.78125, acc5: 0.90625, avg batch time 0.2261\r\nPass 74, batch [60/5004], loss 6.69, acc1: 0.78125, acc5: 0.93359375, avg batch time 0.2239\r\nPass 74, batch [90/5004], loss 8.305, acc1: 0.75, acc5: 0.90625, avg batch time 0.2247\r\nPass 74, batch [120/5004], loss 5.77, acc1: 0.8125, acc5: 0.93359375, avg batch time 0.2250\r\nPass 74, batch [150/5004], loss 8.36, acc1: 0.7734375, acc5: 0.9140625, avg batch time 0.2244\r\n*** Error in `python': invalid fastbin entry (free): 0x00007f99808d9a60 ***\r\n======= Backtrace: =========\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x7354f)[0x7f9b3fc6f54f]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x78dbe)[0x7f9b3fc74dbe]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x79a97)[0x7f9b3fc75a97]\r\n/usr/local/lib/python2.7/site-packages/visreader/transformer/libpytransform.so(_ZN7vistool16ImageTransformer3getEPNS_25transformer_output_data_tE+0x227)[0x7f9ac7d11fe7]\r\n/usr/local/lib/python2.7/site-packages/visreader/transformer/libpytransform.so(+0x168be42)[0x7f9ac7ceee42]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x46be)[0x7f9b409d880e]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x80d)[0x7f9b409da21d]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x43a1)[0x7f9b409d84f1]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x80d)[0x7f9b409da21d]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x43a1)[0x7f9b409d84f1]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x78613)[0x7f9b40949613]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x11b9)[0x7f9b409d5309]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x78613)[0x7f9b40949613]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x11b9)[0x7f9b409d5309]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x78613)[0x7f9b40949613]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x11b9)[0x7f9b409d5309]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x78613)[0x7f9b40949613]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x11b9)[0x7f9b409d5309]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x78613)[0x7f9b40949613]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x11b9)[0x7f9b409d5309]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x80d)[0x7f9b409da21d]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x83db5)[0x7f9b40954db5]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x43)[0x7f9b40923273]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x1426)[0x7f9b409d5576]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x482e)[0x7f9b409d897e]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x482e)[0x7f9b409d897e]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0x80d)[0x7f9b409da21d]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x83ce0)[0x7f9b40954ce0]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x43)[0x7f9b40923273]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x60c3d)[0x7f9b40931c3d]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x43)[0x7f9b40923273]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(PyEval_CallObjectWithKeywords+0x47)[0x7f9b409d3b67]\r\n/usr/local/bin/../lib/libpython2.7.so.1.0(+0x14cbf2)[0x7f9b40a1dbf2]\r\n/opt/compiler/gcc-4.8.2/lib/libpthread.so.0(+0x81c3)[0x7f9b406bb1c3]\r\n/opt/compiler/gcc-4.8.2/lib/libc.so.6(clone+0x6d)[0x7f9b3fce312d]\r\n```\r\n**3、运行结束后程序退出异常；**\r\n```bash\r\nPass: 119, Test Loss 0.995599, test acc1: 0.75795186, test acc5: 0.92903614\r\n\r\nF0215 15:37:24.769343 38469 grpc_client.cc:418] SendCompleteRPC name:[COMPLETE@RECV], ep:[10.255.118.18:30026], status:[-1] meets grpc error, error_code:14 error_message:OS Error error_details:\r\n*** Check failure stack trace: ***\r\n    @     0x7f317d9167ad  google::LogMessage::Fail()\r\n    @     0x7f317d91a25c  google::LogMessage::SendToLog()\r\n    @     0x7f317d9162d3  google::LogMessage::Flush()\r\n    @     0x7f317d91b76e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f317ed7199a  paddle::operators::distributed::GRPCClient::Proceed()\r\n    @     0x7f31d58f28a0  execute_native_thread_routine\r\n    @     0x7f31e32741c3  start_thread\r\n    @     0x7f31e289c12d  __clone\r\n    @              (nil)  (unknown)\r\n/root/paddlejob/run.sh: line 313: 38102 Aborted                 (core dumped) python train.py --update_method=nccl2 --num_threads 1\r\n*********************error messages********************\r\n```\r\n**4、MP模式下无报错信息结束；**\r\n> 换集群后不在出现该问题\r\n\r\n**5、P40下单机PG和MP均有加速效果，多机效果差；**\r\n\r\n\r\nGPUs | Base | Fluid   PG FP32 | Fluid   MP FP32 | Fliud   PG FP16 | Fluid   MP FP16\r\n-- | -- | -- | -- | -- | --\r\n8 | 553.31055   test acc1: 0.75941    test acc5: 0.93016 | 855   test acc1: 0.756278    test acc5: 0.928083 | 417*8   test acc1: 0.64468, test acc5: 0.85098 | 1002 | 423*8   test acc1: 0.64744, test acc5: 0.86174\r\n16 | 464.45 *2   test acc1: 0.76156, test acc5: 0.93018 | 426*2 | 113*8*2 |   | 145*8*2\r\n32 | 477*4   test acc1: 0.76148,   test acc5: 0.92962 | 334 *4   test acc1: 0.75795, test acc5: 0.929036 | 90*8*4   test acc1: 0.63722, test acc5: 0.85278 | 434*4 |  \r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-02-18T10:12:08+00:00",
        "updated_at": "2019-06-10T04:02:23+00:00",
        "closed_at": null,
        "comments_count": [
            "Yancey0623",
            "ccmeteorljh",
            "ccmeteorljh",
            "zwl22"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1773,
        "title": "deep_attention_matching_net 预测错误",
        "body": "\r\n[DAM 代码路径](https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleNLP/deep_attention_matching_net)\r\n** 错误日志如下 **\r\n```bash\r\nW0220 12:10:09.423650  3927 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runtime API Version: 8.0\r\nW0220 12:10:09.423739  3927 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0220 12:10:09.423753  3927 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.1, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nstart loading data ...\r\nfinish loading data ...\r\ntest batch num: 2500\r\nbegin inference ...\r\n2019-02-20 12:16:49\r\nTraceback (most recent call last):\r\n  File \"../test_and_evaluate.py\", line 226, in <module>\r\n    test(args)\r\n  File \"../test_and_evaluate.py\", line 199, in test\r\n    predicts = test_exe.run(feed=feed_list, fetch_list=[logits.name])\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 300, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetched variable.(Perhaps the main_program is not set to ParallelExecutor) at [/paddle/paddle/fluid/framework/details/threaded_ssa_graph_executor.cc:166]\r\nPaddlePaddle Call Stacks: \r\n0       0x7ff213393455p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7ff2133937d9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7ff214ca81f0p paddle::framework::details::ThreadedSSAGraphExecutor::InsertFetchOps(std::vector<std::string, std::allocator<std::string> > const&, std::vector<paddle::framework::details::FetchOpHandle*, std::allocator<paddle::framework::details::FetchOpHandle*> >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, std::unordered_map<paddle::framework::details::OpHandleBase*, unsigned long, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<std::pair<paddle::framework::details::OpHandleBase* const, unsigned long> > >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, paddle::framework::BlockingQueue<paddle::framework::details::VarHandleBase*>*, std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*) + 3104\r\n3       0x7ff214ca8938p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 1768\r\n4       0x7ff214c9fbeap paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 394\r\n5       0x7ff2134d1862p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 562\r\n6       0x7ff21338408ep\r\n7       0x7ff2133bea0ep\r\n8             0x4c37edp PyEval_EvalFrameEx + 31165\r\n9             0x4b9ab6p PyEval_EvalCodeEx + 774\r\n10            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n11            0x4c136fp PyEval_EvalFrameEx + 21823\r\n12            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n13            0x4eb30fp\r\n14            0x4e5422p PyRun_FileExFlags + 130\r\n15            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n16            0x493ae2p Py_Main + 1554\r\n17      0x7ff27200d830p __libc_start_main + 240\r\n18            0x4933e9p _start + 41\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "kuke",
        "created_at": "2019-02-20T13:03:49+00:00",
        "updated_at": "2019-02-28T10:16:54+00:00",
        "closed_at": "2019-02-28T10:16:54+00:00",
        "comments_count": [
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1771,
        "title": "softmax with cross entropy 请问到底该怎么用，真的不会啊",
        "body": "import paddle.fluid as fluid\r\nimport paddle\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport os\r\nfrom multiprocessing import cpu_count\r\nimport matplotlib.pyplot as plt\r\nimport cnn\r\nimport image\r\n\r\ntrainlist,label=image.gettrainlist('./train/',2)  \r\ntrainlist,label=image.messuplist(trainlist,label,5)\r\ndata=image.data_pro(trainlist,100,100)\r\n#print(data.shape)\r\n#print(label.shape)\r\n\r\na = fluid.layers.data(name='a', shape=[3,100,100],dtype='float32')\r\nb = fluid.layers.data(name='b', shape=[1],dtype='float32')\r\nout2=fluid.layers.reshape(b,shape=[-1,1])\r\nout5 = fluid.layers.cast(out2, dtype='int64')\r\n\r\nconv2d = fluid.layers.conv2d(a,num_filters=10,filter_size=[5, 5],stride=[1, 1],groups=1)\r\nd=paddle.fluid.layers.flatten(conv2d , axis=1, name=None)\r\nfc1 = fluid.layers.fc(input=d, size=1024, act='relu', name='fc1')\r\n    \r\nfc2 = fluid.layers.fc(input=fc1, size=2, name='fc2')\r\nout = fluid.layers.softmax_with_cross_entropy(logits=fc2, label=out5)\r\n'''cost = fluid.layers.cross_entropy(input=fc2, label=label)\r\navg_cost = fluid.layers.mean(x=cost)\r\nacc = fluid.layers.accuracy(input=fc2, label=label, k=1)'''\r\ntest_program = fluid.default_main_program().clone(for_test=True)\r\noptimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.001)\r\nopt = optimizer.minimize(out)\r\nplace = fluid.CUDAPlace(0)\r\nexe = fluid.Executor(place=place)\r\nexe.run(program=fluid.default_startup_program())\r\nfor pass_id in range(1):\r\n    train_cost, train_acc = exe.run(program=fluid.default_main_program(), \r\n                                        feed={'a': data, 'b': label}, \r\n                                        fetch_list=[fc2,out])\r\n    print(train_cost.shape, train_acc)\r\n\r\n很简单的猫狗分类了，但是报错啊怎么回事不懂啊\r\nEnforceNotMet: The input of cast op must be set at [/paddle/paddle/fluid/operators/cast_op.cc:42]\r\nPaddlePaddle Call Stacks: ",
        "state": "closed",
        "user": "xyq019971",
        "closed_by": "SunGaofeng",
        "created_at": "2019-02-19T12:34:38+00:00",
        "updated_at": "2019-02-20T10:04:48+00:00",
        "closed_at": "2019-02-20T10:04:48+00:00",
        "comments_count": [
            "SunGaofeng",
            "xyq019971"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1770,
        "title": "反向传播不更新参数，跪求大佬指点迷津",
        "body": "b21=enet.block4(b20)\r\nb22= fluid.layers.transpose(b21, perm=[0, 2, 3, 1])\r\nout1=fluid.layers.reshape(b22,shape=[-1,9])\r\nout2=fluid.layers.reshape(y,shape=[-1,1])\r\n#out3=paddle.fluid.layers.softmax(out1)\r\n_, out4 = fluid.layers.topk(out1, k=1)\r\nout5 = fluid.layers.cast(out4, dtype='float32')\r\nloss=paddle.fluid.layers.square_error_cost(out5, out2)\r\navg=fluid.layers.reduce_mean(loss)\r\nregularizer = fluid.regularizer.L2Decay(0.0001)\r\noptimizer = paddle.fluid.optimizer.AdamOptimizer(learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-08, regularization=regularizer)\r\n_, params_grads = optimizer.minimize(avg)\r\n\r\n\r\n代码很简单就是一个9通道的图进来之后做一个语意分割反向传播，程序一直可以运行，但是就是参数不更新，如果用1张图片训练avg永远都是那个数字不变。",
        "state": "open",
        "user": "xyq019971",
        "closed_by": null,
        "created_at": "2019-02-19T12:14:05+00:00",
        "updated_at": "2019-02-20T05:29:52+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "xyq019971",
            "xyq019971",
            "SunGaofeng",
            "xyq019971",
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1776,
        "title": "在场景文字识别的注意力模型中，为什么图片不都是同一shape",
        "body": "在场景文字识别的注意力模型中，图片的shape只是每一个batch相同而已，而不是全部都是同一个shape。\r\n跟`images = fluid.layers.data(name='pixel', shape=data_shape, dtype='float32')`都不是同一个，这是为什么呢？不应该要统一的吗？\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/67b52af0eb08a0cb339196971fc9164656250c7e/fluid/PaddleCV/ocr_recognition/data_reader.py#L92-L94",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-02-21T07:35:59+00:00",
        "updated_at": "2019-02-22T07:06:35+00:00",
        "closed_at": "2019-02-22T06:51:25+00:00",
        "comments_count": [
            "qingqing01",
            "yeyupiaoling"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1775,
        "title": "场景文字识别中，注意模型为什么要有两个label？",
        "body": "在场景文字识别中的注意模型，为什么会用到两个label，而是第一个label_in要在前面加[0]，第二个label_out要在后面加[1]。\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/67b52af0eb08a0cb339196971fc9164656250c7e/fluid/PaddleCV/ocr_recognition/data_reader.py#L100",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-02-21T07:24:29+00:00",
        "updated_at": "2019-02-22T07:49:41+00:00",
        "closed_at": "2019-02-22T07:49:40+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01",
            "yeyupiaoling"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1777,
        "title": "在场景文字识别的注意力模型中，是否可以保存预测模型",
        "body": "场景文字识别的注意力模型，与图片分类的模型不一样，注意力模型要复杂很多，但是如果我想保存预测模型inference_model，是否可以呢？\r\n\r\n在图像分类中，可以调用`paddle.fluid.io.save_inference_model`接口保存预测模型，之后需要时再调用`paddle.fluid.io.load_inference_model`预测图片，而且预测代码非常简单，不需要编写之前的模型代码。\r\n\r\n注意力模型是否也可以这样，保存预测模型，之后的预测中，只需要加载这预测模型，不需要再编写网络模型代码。\r\n\r\n",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-02-21T08:09:28+00:00",
        "updated_at": "2019-02-22T06:54:34+00:00",
        "closed_at": "2019-02-22T06:54:34+00:00",
        "comments_count": [
            "wanghaoshuang",
            "yeyupiaoling"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1778,
        "title": "在场景文字识别中有有一些小问题请教",
        "body": "在场景文字识别中，以下的三个if判断我不是很明白。比如关于停止训练，不是用for循环指定pass数更为直观吗？为啥好这样设计，意义有什么特别之处？\r\n\r\n第二个应该是纯粹输出信息，但是应该是有含义的吧？\r\n\r\n第三个就更不懂它要干啥了，请问它的作用是什么呢？\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/67b52af0eb08a0cb339196971fc9164656250c7e/fluid/PaddleCV/ocr_recognition/train.py#L140-L146",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-02-21T08:23:32+00:00",
        "updated_at": "2019-03-14T07:09:40+00:00",
        "closed_at": "2019-03-14T07:09:40+00:00",
        "comments_count": [
            "wanghaoshuang",
            "yeyupiaoling"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1780,
        "title": "ocr 模型训练到最后，loss上升，train_acc 下降到0",
        "body": " seq2seq+attention \r\n```\r\npython -u train.py --batch_size 128 --model attention --total_step 60000\r\n```\r\n```bash\r\nTime: 1550152015.93; Iter[56000]; Avg loss: 0.988; Avg seq err: 0.157\r\n 3123 kpis    train_cost  0.988109\r\n 3124 kpis    train_acc   0.842906\r\n 3125 \r\n 3126 Time: 1550152458.68; Iter[57000]; Avg loss: 2.187; Avg seq err: 0.212\r\n 3127 kpis    train_cost  2.187478\r\n 3128 kpis    train_acc   0.787953\r\n 3129 \r\n 3130 Time: 1550152898.15; Iter[58000]; Avg loss: 21.308; Avg seq err: 0.731\r\n 3131 kpis    train_cost  21.308087\r\n 3132 kpis    train_acc   0.269258\r\n 3133 \r\n 3134 Time: 1550153338.44; Iter[59000]; Avg loss: 22.564; Avg seq err: 1.000\r\n 3135 kpis    train_cost  22.564095\r\n 3136 kpis    train_acc   0.000000\r\n 3137 \r\n 3138 Time: 1550153776.94; Iter[60000]; Avg loss: 21.151; Avg seq err: 1.000\r\n 3139 kpis    train_cost  21.151212\r\n 3140 kpis    train_acc   0.000000\r\n 3141 \r\n 3142 Time: 1550153835.67; Iter[60000]; Test seq error: 1.0.\r\n 3143 \r\n 3144 kpis    test_acc    0.000000\r\n 3145 Saved model to: ./models/model_60000.\r\n```",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-02-21T09:44:32+00:00",
        "updated_at": "2019-09-04T06:59:16+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "ccmeteorljh",
            "wenston2006",
            "wenston2006",
            "banbishan",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1783,
        "title": "video 中的模型在单卡时无法正常训练",
        "body": "以stnet为例，在单卡时前80个iter训练结果如下：\r\n<img width=\"801\" alt=\"157f3740384ecbc0a3a4c67b7bbd0560\" src=\"https://user-images.githubusercontent.com/46314656/53311192-d810e780-38ea-11e9-9d78-55cce4be2360.png\">\r\n在8卡时正常的训练结果如下：\r\n<img width=\"879\" alt=\"731cf84aa687b0f658d1ffd555fd1a56\" src=\"https://user-images.githubusercontent.com/46314656/53311252-17d7cf00-38eb-11e9-8e07-5f5fc1612ad9.png\">\r\n单卡时无法有效降低loss, 升高acc，8卡时才能正常训练",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-25T02:51:19+00:00",
        "updated_at": "2019-02-28T07:05:45+00:00",
        "closed_at": "2019-02-28T07:05:45+00:00",
        "comments_count": [
            "SunGaofeng",
            "xiegegege",
            "SunGaofeng",
            "xiegegege",
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1785,
        "title": "图像分类SE_ResNeXt50_32x4d模型，在epoch=63后，test_acc1突降为0",
        "body": "图像分类SE_ResNeXt50_32x4d模型，在epoch=63后，trian_acc1继续稳步提升，但test_acc1突降为0\r\n![image](https://user-images.githubusercontent.com/37854899/53316842-58901200-3904-11e9-8e59-eda562bcaaf8.png)\r\n附件为SE_ResNeXt50_32x4d模型的log\r\n[SE_ResNeXt50_32x4d.log](https://github.com/PaddlePaddle/models/files/2899144/SE_ResNeXt50_32x4d.log)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-02-25T05:51:46+00:00",
        "updated_at": "2019-03-07T07:05:13+00:00",
        "closed_at": "2019-03-07T07:05:13+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1787,
        "title": "test loss随模型迭代而增加",
        "body": "如题\r\n训练日志如下：\r\nTest in epoch   0, Loss:        4.757947, Acc:  0.354800\r\nTest in epoch   0, Loss:        4.865430, Acc:  0.354230\r\nTest in epoch   0, Loss:        4.937966, Acc:  0.356729\r\nTest in epoch   1, Loss:        5.124760, Acc:  0.356336\r\nTest in epoch   1, Loss:        5.165730, Acc:  0.355902\r\nTest in epoch   1, Loss:        5.279254, Acc:  0.354999\r\nTest in epoch   2, Loss:        5.431847, Acc:  0.354028\r\nTest in epoch   2, Loss:        5.450323, Acc:  0.352916\r\nTest in epoch   2, Loss:        5.486628, Acc:  0.355298\r\nTest in epoch   3, Loss:        5.596898, Acc:  0.354946\r\nTest in epoch   3, Loss:        5.595257, Acc:  0.352510\r\nTest in epoch   3, Loss:        5.728043, Acc:  0.356146\r\nTest in epoch   4, Loss:        5.937518, Acc:  0.347627\r\nTest in epoch   4, Loss:        5.786941, Acc:  0.353117\r\nTest in epoch   4, Loss:        5.885833, Acc:  0.354856\r\nTest in epoch   5, Loss:        5.934639, Acc:  0.355649\r\nTest in epoch   5, Loss:        5.919194, Acc:  0.353639\r\nTest in epoch   5, Loss:        6.017453, Acc:  0.355212\r\nTest in epoch   6, Loss:        6.062719, Acc:  0.355775\r\nTest in epoch   6, Loss:        6.049249, Acc:  0.352780\r\nTest in epoch   6, Loss:        6.193391, Acc:  0.354625\r\nTest in epoch   7, Loss:        6.236372, Acc:  0.355126\r\nTest in epoch   7, Loss:        6.229053, Acc:  0.351142\r\nTest in epoch   7, Loss:        6.237000, Acc:  0.356059\r\nTest in epoch   8, Loss:        6.331445, Acc:  0.354839\r\nTest in epoch   8, Loss:        6.329272, Acc:  0.351808\r\nTest in epoch   8, Loss:        6.363647, Acc:  0.355070\r\nTest in epoch   9, Loss:        6.449283, Acc:  0.354044\r\nTest in epoch   9, Loss:        6.400001, Acc:  0.351498\r\nTest in epoch   9, Loss:        6.482876, Acc:  0.354735\r\n\r\n模型用cnn + softmax + cross_entropy loss\r\n训练程序如下：\r\n    ```\r\n    # Network\r\n    class_num = len(label_dict) + 1 \r\n    char_dict_num = len(char_dict) + 1 \r\n    word_dict_num = len(word_dict) + 1 \r\n    logger.info(\"char dict dim:\\t%s, word dict dim:\\t%s, class dim:\\t%s\", char_dict_num, word_dict_num, class_num)\r\n    pred, loss, label = network(char_dict_dim=char_dict_num, word_dict_dim=word_dict_num, class_dim=class_num, is_indep_char=is_indep_char)\r\n    pred.persistable = True\r\n    loss.persistable = True\r\n    label.persistable = True\r\n\r\n    # Program\r\n    main_program = fluid.default_main_program()\r\n    start_program = fluid.default_startup_program()\r\n    test_program = main_program.clone(for_test=True)\r\n\r\n    # Optimizer\r\n    optimizer = fluid.optimizer.AdamOptimizer(\r\n        learning_rate=0.01,\r\n        beta1=0.9,\r\n        beta2=0.999,\r\n        epsilon=1e-8)\r\n    optimizer.minimize(loss)\r\n    fluid.memory_optimize(main_program)\r\n\r\n    # Executor\r\n    exe = fluid.Executor(place)\r\n    exe.run(start_program)\r\n\r\n    # setting for cpu training\r\n    # exec_strategy = fluid.ExecutionStrategy()\r\n    # exec_strategy.num_threads = 1 # cpu thread num\r\n\r\n    parallel_executor = fluid.ParallelExecutor(\r\n        use_cuda=use_gpu, loss_name=loss.name,\r\n        main_program=main_program)\r\n\r\n    # test_exe = fluid.Executor(place)\r\n    test_executor = fluid.ParallelExecutor(\r\n        use_cuda=use_gpu,\r\n        share_vars_from=parallel_executor,\r\n        main_program=test_program)\r\n\r\n    # Feeder\r\n    feed_order = [\"char_data\", \"basic_data\", \"phrase_data\", \"label\"]\r\n    feed_var_list = [ main_program.global_block().var(var_name) for var_name in feed_order ]\r\n    feeder = fluid.DataFeeder(place=place, feed_list=feed_var_list)\r\n\r\n    def run_test(num_epoch):\r\n        test_batch = paddle.batch(test_data_reader, 256, drop_last=False)\r\n        # test_batch = paddle.batch(test_data_reader, batch_num, drop_last=False)\r\n        comp = fluid.metrics.CompositeMetric()\r\n        acc = Accuracy_TopN(topN=1)\r\n        comp.add_metric(acc)\r\n        comp.reset()\r\n        tot_loss = .0\r\n        tot_iter = 0\r\n        for index, data in enumerate(test_batch()):\r\n            preds, batch_avg_loss, labels = test_executor.run(fetch_list=[pred.name, loss.name, label.name], feed=feeder.feed(data))\r\n            # preds, batch_avg_loss, labels = test_exe.run(program=test_program, fetch_list=[pred, loss, label], feed=feeder.feed(data))\r\n            comp.update(preds=preds, labels=labels)\r\n            tot_loss += np.mean(batch_avg_loss)\r\n            tot_iter = index + 1\r\n        np_acc = comp.eval()\r\n        test_avg_loss = tot_loss / tot_iter\r\n        logger.info(\"Test in epoch %3d, Loss:\\t%.6f, Acc:\\t%.6f\", num_epoch, test_avg_loss, np_acc[0])\r\n\r\n    # Train Model\r\n    logger.info(\"Training...total pass:\\t%s\", pass_num)\r\n    for epoch in xrange(pass_num):\r\n        for index, data in enumerate(batch_data()):\r\n            avg_loss = parallel_executor.run(\r\n                [loss.name], feed=feeder.feed(data)\r\n            )\r\n            # avg_loss = exe.run(\r\n            #     program=main_program,\r\n            #     fetch_list=[loss.name], feed=feeder.feed(data)\r\n            # )\r\n            if index % 1000 == 0:\r\n                logger.info(\"Train epoch %3d, batch %6d, loss %f\", epoch, index, np.mean(avg_loss[0]))\r\n            if index % 12000 == 0 and index > 0:\r\n                run_test(epoch)\r\n\r\n        run_test(epoch)\r\n\r\n        feeded_var_names = [\"char_data\", \"basic_data\", \"phrase_data\"]\r\n        target_vars = [pred]\r\n        model_name = model_name_prefix + \"_pass_%04d\" % epoch\r\n        model_path = os.path.join(model_dir, model_name)\r\n        logger.info(\"Saving model, path:\\t%s\", model_path)\r\n        fluid.io.save_inference_model(dirname=model_path,\r\n                                      model_filename=model_name,\r\n                                      feeded_var_names=feeded_var_names,\r\n                                      target_vars=target_vars,\r\n                                      executor=exe,\r\n                                      main_program=test_program)\r\n```",
        "state": "open",
        "user": "snowsteper",
        "closed_by": null,
        "created_at": "2019-02-25T09:18:14+00:00",
        "updated_at": "2019-02-26T11:58:17+00:00",
        "closed_at": null,
        "comments_count": [
            "chengduoZH",
            "snowsteper",
            "kuke",
            "snowsteper"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1786,
        "title": "图像处理ResNet152，UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0",
        "body": "在使用ResNet152训练的过程中，log中出现\r\n\r\n![image](https://user-images.githubusercontent.com/37854899/53318660-f1c22700-390a-11e9-8e4e-b16229da5c50.png)\r\n虽然不影响最后的训练结果，但是用户体验非常不好\r\n附件为训练ResNet152模型的log\r\n[ResNet152.log](https://github.com/PaddlePaddle/models/files/2899227/ResNet152.log)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-02-25T06:41:18+00:00",
        "updated_at": "2019-03-07T07:05:02+00:00",
        "closed_at": "2019-03-07T07:05:02+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1788,
        "title": "图像分类模型SE_ResNeXt101_32x4d在epoch=4后，test_acc突降为0",
        "body": "模型SE_ResNeXt101_32x4d在epoch=4后，trian_acc1持续提升，但是test_acc1突降为0\r\n![image](https://user-images.githubusercontent.com/37854899/53387729-2db8c300-39c3-11e9-90f2-cec31d23ad34.png)\r\n附件为SE_ResNeXt101_32x4d模型的log\r\n[SE_ResNeXt101_32x4d.log](https://github.com/PaddlePaddle/models/files/2903805/SE_ResNeXt101_32x4d.log)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-02-26T04:42:07+00:00",
        "updated_at": "2019-03-07T07:04:52+00:00",
        "closed_at": "2019-03-07T07:04:52+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1790,
        "title": "face detection耗时太多",
        "body": "face detection里面的模块，inference的时候耗时太多如下图，单位为秒， 有能提升的建议吗？\r\n\r\n![image](https://user-images.githubusercontent.com/3112825/53394466-5ac4a000-39da-11e9-9dfb-b68dd5139241.png)\r\n",
        "state": "open",
        "user": "burness",
        "closed_by": null,
        "created_at": "2019-02-26T07:22:59+00:00",
        "updated_at": "2021-08-06T17:19:27+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "burness",
            "qingqing01",
            "burness",
            "neonin04"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1793,
        "title": "gru4rec infer.py缺少vocab_path参数",
        "body": "gru4rec非负采样部分的预测会报错：\r\n<img width=\"944\" alt=\"c752a62c1645a1f2157f20980551325d\" src=\"https://user-images.githubusercontent.com/46314656/53414412-ae021700-3a09-11e9-9b97-1bfe68f5e100.png\">\r\n且infer.py缺少vocab_path参数\r\n<img width=\"481\" alt=\"83a6e486fd6903f7a9b305a1cb01e574\" src=\"https://user-images.githubusercontent.com/46314656/53414544-f6213980-3a09-11e9-95ee-413ace3d6912.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-26T13:03:40+00:00",
        "updated_at": "2019-02-28T07:23:00+00:00",
        "closed_at": "2019-02-28T07:23:00+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1792,
        "title": "deeplabv3+ 模型无法复现给出的结果",
        "body": "paddlepaddle框架版本：1.3\r\nmodel库代码：最新\r\n**运行环境：p40,4卡**\r\n训练命令：\r\n```bash\r\npython ./train.py --batch_size=8 --parallel=true --train_crop_size=769 --total_step=90000 --init_weights_path=./deeplabv3plus_xception65_initialize.params --dataset_path=./cityscape/ --save_weights_path=./save_model/\r\n```\r\neval 命令：\r\n```bash\r\npython eval.py --dataset_path=./cityscape --init_weights=./save_model/ --verbose True\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/33303691/53410751-a2115780-39ff-11e9-8fae-50f819401acb.png)\r\n\r\n**运行环境：p40 单卡 batchsize=8，出现显存不够的情况**\r\n\r\n![image](https://user-images.githubusercontent.com/33303691/53411553-b9514480-3a01-11e9-9ee2-1bb4443aa827.png)\r\n\r\n\r\n",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-02-26T12:06:58+00:00",
        "updated_at": "2019-03-01T08:05:14+00:00",
        "closed_at": null,
        "comments_count": [
            "ccmeteorljh",
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1794,
        "title": "ctr 预测错误",
        "body": "ctr预测报错：\r\n<img width=\"887\" alt=\"cd9e40d4cae5e750a12c21678fa053ef\" src=\"https://user-images.githubusercontent.com/46314656/53462593-4ab2cc00-3a7f-11e9-822e-dda004f376ba.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-02-27T03:04:34+00:00",
        "updated_at": "2019-03-04T12:15:00+00:00",
        "closed_at": "2019-03-04T12:15:00+00:00",
        "comments_count": [
            "jacquesqiao",
            "xiegegege",
            "jacquesqiao",
            "xiegegege",
            "kjfren1985",
            "jacquesqiao",
            "kjfren1985",
            "xiegegege",
            "kjfren1985"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1800,
        "title": "tagspace 模型 样例数据多卡训练一个epoch后报错",
        "body": "tagspace 模型 直接跑样例数据单机多卡训练一个epoch后报错\r\npaddle1.3 \r\nCUDA9 cudnn7\r\ngpu ：4卡\r\n\r\n以下是报错日志：\r\nTRAIN --> pass: 0 batch_num: 950 avg_cost: 0.0400084555149, acc: 1.0\r\nTRAIN --> pass: 0 batch_num: 1000 avg_cost: 0.112019307911, acc: 0.4\r\nepoch:1 num_steps:199 time_cost(s):1.300218\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 128, in <module>\r\n    train()\r\n  File \"train.py\", line 123, in train\r\n    train_exe)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 1008, in save_inference_model\r\n    save_persistables(executor, dirname, main_program, params_filename)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 487, in save_persistables\r\n    filename=filename)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 174, in save_vars\r\n    filename=filename)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 210, in save_vars\r\n    executor.run(save_program)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 301, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\nTypeError: run(): incompatible function arguments. The following argument types are supported:\r\n    1. (self: paddle.fluid.core.ParallelExecutor, arg0: List[unicode], arg1: unicode) -> None\r\n\r\nInvoked with: <paddle.fluid.core.ParallelExecutor object at 0x7f78001ca688>, blocks {\r\n  idx: 0\r\n  parent_idx: -1\r\n  vars {\r\n    name: \"cnn\"\r\n    type {\r\n      type: LOD_TENSOR\r\n      lod_tensor {\r\n        tensor {\r\n          data_type: FP32\r\n          dims: 50\r\n          dims: 1000",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-02-28T07:55:55+00:00",
        "updated_at": "2019-02-28T09:33:37+00:00",
        "closed_at": "2019-02-28T09:33:37+00:00",
        "comments_count": [
            "guoshengCS",
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1804,
        "title": "word2vec模型代码bug，代码中死循环",
        "body": "train.py \r\n209行 while True:",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-02-28T12:41:06+00:00",
        "updated_at": "2019-07-25T08:40:45+00:00",
        "closed_at": "2019-07-25T08:40:45+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1801,
        "title": "cyclegan 跑了训练之后，如何infer",
        "body": "infer里的init_model怎么传参？ 我传checkpoints目录， 显示load 错误， 能说明下 infer.py的init_model是啥吗",
        "state": "closed",
        "user": "burness",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-02-28T08:12:10+00:00",
        "updated_at": "2019-03-05T08:23:15+00:00",
        "closed_at": "2019-03-05T06:05:51+00:00",
        "comments_count": [
            "burness",
            "guoshengCS",
            "burness",
            "guoshengCS",
            "burness",
            "wanghaoshuang",
            "wanghaoshuang",
            "burness"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1805,
        "title": "deeplabv3+多卡下训练报错",
        "body": "如下错误:\r\n1. pyreader没有stop函数\r\nTraining done. Model is saved to output1\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 228, in <module>\r\n    py_reader.stop()\r\nAttributeError: 'Variable' object has no attribute 'stop'\r\n2. 多卡时，训练报错\r\n  训练命令\r\n  python train.py --batch_size=4 --train_crop_size=769 --total_step=50 --save_weights_path=output1 --dataset_path=$DATASET_PATH --enable_ce\r\n![image](https://user-images.githubusercontent.com/22165420/53610251-3698d700-3c05-11e9-8687-6fd4326c7575.png)\r\n",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "kolinwei",
        "created_at": "2019-03-01T01:35:42+00:00",
        "updated_at": "2019-03-01T12:30:23+00:00",
        "closed_at": "2019-03-01T12:30:23+00:00",
        "comments_count": [
            "cjld"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1821,
        "title": "faster_rcnn使用output/model_final中模型进行评估报错",
        "body": "faster_rcnn使用output/model_final中模型进行评估报如下错：\r\n<img width=\"878\" alt=\"4ad3143eb5796cd32184d8480407a88d\" src=\"https://user-images.githubusercontent.com/46314656/53707267-431d6980-3e69-11e9-865d-9bad7614cf1e.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-03-04T02:37:44+00:00",
        "updated_at": "2019-03-05T05:01:24+00:00",
        "closed_at": "2019-03-05T05:01:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1809,
        "title": "batch_norm 层使用报错 Enforce failed. Expected ctx->GetInputDim(\"Scale\")[0] == C, but received ctx->GetInputDim(\"Scale\")[0]:0 != C:1",
        "body": "代码：\r\n\r\n```\r\nplace = fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\nexe.run(fluid.default_startup_program())\r\n\r\ndef nets():\r\n    x = fluid.layers.data(name='x', shape=[1], dtype='float32', lod_level=1)\r\n    re_shp = fluid.layers.reshape(x, shape=[-1, 1, 1, 3]) \r\n    bat_nom = fluid.layers.batch_norm(re_shp, param_attr=fluid.param_attr.ParamAttr(initializer=fluid.initializer.ConstantInitializer(value=1.0)))\r\n    return re_shp, bat_nom\r\n\r\nre_shp, bat_nom = nets()\r\n\r\na = fluid.create_lod_tensor(np.array([[1.1, 1.1, 1.1],[2.2, 2.2, 2.2],[3.3, 3.3, 3.3],[4.4, 4.4, 4.4]]).astype('float32'), [[1,1,1,1]], place)\r\n\r\nfetch_vars = [re_shp, bat_nom]\r\nresults = exe.run(fluid.default_main_program(),\r\n        feed={'x':a},\r\n         fetch_list=fetch_vars,return_numpy=False)\r\n\r\nprint results\r\nprint np.array(results[0])\r\n```\r\n\r\n得到报错信息\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected ctx->GetInputDim(\"Scale\")[0] == C, but received ctx->GetInputDim(\"Scale\")[0]:0 != C:1.\r\n at [/paddle/paddle/fluid/operators/batch_norm_op.cc:60]\r\n",
        "state": "open",
        "user": "snowsteper",
        "closed_by": null,
        "created_at": "2019-03-01T07:13:44+00:00",
        "updated_at": "2019-03-05T11:44:56+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "snowsteper",
            "wanghaoshuang",
            "wanghaoshuang",
            "snowsteper"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1820,
        "title": "deeplabv3+ eval 出错",
        "body": "报错如下：\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"./eval.py\", line 143, in <module>\r\n    print('\\rstep: %s, mIoU: %s' % (i + 1, miou2), end='\\r', flush=True)\r\nTypeError: 'flush' is an invalid keyword argument for this function\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "qingqing01",
        "created_at": "2019-03-03T14:39:08+00:00",
        "updated_at": "2019-04-01T08:25:53+00:00",
        "closed_at": "2019-04-01T08:25:53+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1825,
        "title": "tagspace文档中数据链接失效",
        "body": "ag news dataset 链接失效",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "frankwhzhang",
        "created_at": "2019-03-04T09:07:44+00:00",
        "updated_at": "2019-03-06T05:51:24+00:00",
        "closed_at": "2019-03-06T05:51:23+00:00",
        "comments_count": [
            "dashulu",
            "frankwhzhang",
            "frankwhzhang",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1828,
        "title": "models文档中installation document 链接失效",
        "body": "\r\n<img width=\"939\" alt=\"1551756833\" src=\"https://user-images.githubusercontent.com/14963836/53779284-8f84aa00-3f3a-11e9-878e-9b751634b430.png\">\r\n\r\n该链接失效，提示无该文档\r\n\r\n\r\n![Uploading cedc533655735e1fa25c70fffd99af0f.png…]()\r\n",
        "state": "closed",
        "user": "OliverLPH",
        "closed_by": "OliverLPH",
        "created_at": "2019-03-05T03:41:50+00:00",
        "updated_at": "2021-09-22T04:57:05+00:00",
        "closed_at": "2021-09-22T04:57:05+00:00",
        "comments_count": [
            "OliverLPH"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1834,
        "title": "image_classification infer错误",
        "body": "1. infer时read有问题，找不到数据\r\n<img width=\"884\" alt=\"3148d727abb5fd78b49061599251cdca\" src=\"https://user-images.githubusercontent.com/46314656/53787867-1a759c80-3f5b-11e9-925c-434eec172427.png\">\r\n2.infer.py没有文档中写的--batch_size参数\r\n<img width=\"623\" alt=\"693b723d98bca1715e4c93a041dbcb5d\" src=\"https://user-images.githubusercontent.com/46314656/53787935-455ff080-3f5b-11e9-9bc0-1ceb536d3c13.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-03-05T07:28:44+00:00",
        "updated_at": "2019-03-29T03:24:28+00:00",
        "closed_at": "2019-03-29T03:24:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1832,
        "title": "deeplabv3+易用性问题",
        "body": "1. eval运行结束后mIoU指标值显示消失\r\n<img width=\"272\" alt=\"ceb672f4d32211dd7959c9c7d05aad42\" src=\"https://user-images.githubusercontent.com/46314656/53779395-e12d3480-3f3a-11e9-97ba-360385ac91ce.png\">\r\n2.eval.py中没有文档中提到的--model_path参数\r\n<img width=\"421\" alt=\"a13f012791820821a9b57d60dac6e63c\" src=\"https://user-images.githubusercontent.com/46314656/53779530-61ec3080-3f3b-11e9-97a0-2fbdfbd63d20.png\">\r\n3.eval文档中参数为init_weights，代码中参数为init_weights_path，建议改为一致",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-03-05T05:15:14+00:00",
        "updated_at": "2019-04-03T03:35:11+00:00",
        "closed_at": "2019-04-03T03:35:11+00:00",
        "comments_count": [
            "qingqing01",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1836,
        "title": "metric learning 无法下载预训练模型",
        "body": "<img width=\"909\" alt=\"e5efa4d5ff5fca7417750aa5aba698dd\" src=\"https://user-images.githubusercontent.com/46314656/53789201-ddaba480-3f5e-11e9-9065-f8d5152a4d2d.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-03-05T07:54:08+00:00",
        "updated_at": "2019-04-01T05:42:06+00:00",
        "closed_at": "2019-03-30T01:49:28+00:00",
        "comments_count": [
            "qingqing01",
            "xiegegege",
            "qingqing01",
            "kebinC"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1837,
        "title": "SSD模型按照readme的文档配置后，训练20轮之后，map的值仅为0.02",
        "body": "如题， map值仅为0.02， 与文档说的训练120轮能到73.2%差了好多，请问这个是什么原因？",
        "state": "closed",
        "user": "dashulu",
        "closed_by": "dashulu",
        "created_at": "2019-03-05T08:11:06+00:00",
        "updated_at": "2019-03-05T09:17:53+00:00",
        "closed_at": "2019-03-05T09:17:53+00:00",
        "comments_count": [
            "qingqing01",
            "dashulu",
            "dashulu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1844,
        "title": "CPU环境 下训练模型(image_classification)有Bug",
        "body": "在图像识别的路径中，尝试在CPU下跑模型，均有该bug\r\n\r\n```shell\r\npython train.py \\\r\n> --model=VGG16 \\\r\n> --batch_size=256 \\\r\n> --total_images=1281167 \\\r\n> --class_dim=1000 \\\r\n> --lr_strategy=cosine_decay \\\r\n> --image_shape=3,224,224 \\\r\n> --model_category=models_name \\\r\n> --model_save_dir=output/ \\\r\n> --lr=0.01 \\\r\n> --num_epochs=90 \\\r\n> --with_mem_opt=True \\\r\n> --l2_decay=3e-4 \\\r\n> --use_gpu=False\r\n```\r\n\r\n参数配置如下图，关掉了gpu\r\n<img width=\"402\" alt=\"fe1224ecb4f90270f8a00ef9f11e462a\" src=\"https://user-images.githubusercontent.com/14963836/53867845-a6f18f00-402f-11e9-81f0-1d949446b77a.png\">\r\n\r\n报错如下\r\n<img width=\"763\" alt=\"1551862072\" src=\"https://user-images.githubusercontent.com/14963836/53867821-96d9af80-402f-11e9-8c4f-6bf0365ad259.png\">",
        "state": "closed",
        "user": "OliverLPH",
        "closed_by": "OliverLPH",
        "created_at": "2019-03-06T08:51:26+00:00",
        "updated_at": "2021-09-22T04:57:14+00:00",
        "closed_at": "2021-09-22T04:57:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1846,
        "title": "ocr_recognition 评估、预测错误",
        "body": "1、ocr_recognition CTC model eval.py有函数缺少参数：\r\n<img width=\"909\" alt=\"e8ec154b99d031a872f8f222e1088e92\" src=\"https://user-images.githubusercontent.com/46314656/53880163-453f1e00-404b-11e9-85c7-8dd84fe81020.png\">\r\n2、预测时CTC和attention模型的报错：\r\n<img width=\"987\" alt=\"93b4cc1a5a0309688355e42a33bddad7\" src=\"https://user-images.githubusercontent.com/46314656/53880294-9e0eb680-404b-11e9-9619-47c6bdaff889.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-03-06T12:09:02+00:00",
        "updated_at": "2019-04-15T13:01:47+00:00",
        "closed_at": "2019-04-15T10:59:58+00:00",
        "comments_count": [
            "wanghaoshuang",
            "JiaXiao243",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1848,
        "title": "DeepASR english model",
        "body": "DeepASR current has only aishell model released. do you plan of releasing any english model for DeepASR.\r\nThank you",
        "state": "open",
        "user": "saibharani",
        "closed_by": null,
        "created_at": "2019-03-06T13:42:09+00:00",
        "updated_at": "2019-03-07T11:27:50+00:00",
        "closed_at": null,
        "comments_count": [
            "wshhja"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1852,
        "title": "Deep Attention Matching Network文档链接失效",
        "body": "![image](https://user-images.githubusercontent.com/37854899/53953693-f490f900-410e-11e9-9c8a-879c6c7ffd64.png)\r\n如图s所示，点击该链接，显示404\r\n![image](https://user-images.githubusercontent.com/37854899/53953718-070b3280-410f-11e9-8dcb-92c1dc9d8ad8.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-03-07T11:27:55+00:00",
        "updated_at": "2019-03-07T11:27:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1849,
        "title": "image classification文档易用性部分汇总",
        "body": "1. 点击文档中超连接trian无法链接到文档中Training a model with flexible parameters位置\r\n  \r\n![image](https://user-images.githubusercontent.com/37854899/53927333-807c3400-40c1-11e9-9a0f-c21062f742a8.png)\r\n\r\n2. 点击Table of Contents处 Training a model with flexible parameters、Supported models and performances无法跳转到对应文档位置\r\n![image](https://user-images.githubusercontent.com/37854899/53927417-ce913780-40c1-11e9-8bbf-9691e2bc90f1.png)\r\n3. 文档中 installation document链接失效\r\n   \r\n![image](https://user-images.githubusercontent.com/37854899/53927463-f385aa80-40c1-11e9-8c38-9ec8e3e086b3.png)\r\n4. train.py 中参数with_mem_opt默认值为True，文档中写为False，两者不一致。\r\n   \r\n![image](https://user-images.githubusercontent.com/37854899/53927754-c259aa00-40c2-11e9-8d71-51336ceb5f08.png)\r\n![image](https://user-images.githubusercontent.com/37854899/53927791-d9000100-40c2-11e9-8d55-d1f283c83eec.png)\r\n5. 文档中parameter introduction处对训练参数介绍不全\r\n![image](https://user-images.githubusercontent.com/37854899/53927892-2c724f00-40c3-11e9-8a0e-93b75171c904.png)\r\n6.  Evaluation部分：pretrained models链接失效\r\n \r\n![image](https://user-images.githubusercontent.com/37854899/53928009-91c64000-40c3-11e9-8594-2b09cb13d1fa.png)\r\n7. Models with specified parameters names、Models without specified parameters处介绍不清\r\n文档中提供了(1)Released models: specify parameter names \r\n                      (2)Released models: not specify parameter names\r\n两种预训练模型，但是并没有阐述modle_catetory=modles/models_name的区别，在使用两种不同预训练模型在精度以及速度方面有何不同，用户不知道该选哪个，也不知道为何要列出这两种不同的预训练模型以供选择。\r\n![image](https://user-images.githubusercontent.com/37854899/53928088-d5b94500-40c3-11e9-855c-895461444aa7.png)\r\n\r\n\r\n\r\n\r\n  \r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-03-07T02:35:55+00:00",
        "updated_at": "2019-04-12T07:23:11+00:00",
        "closed_at": "2019-04-12T07:23:10+00:00",
        "comments_count": [
            "shippingwang",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1851,
        "title": "cycle_gan模型易用性问题",
        "body": "1、cycle_gan示例数据中缺少test数据\r\n2、建议infer中init_model和input的路径与train中设定保持一致，分别设为output_0/checkpoints/1和data/horse2zebra/testA/*\r\n<img width=\"643\" alt=\"cycle_gan\" src=\"https://user-images.githubusercontent.com/46314656/53951585-c1983680-4109-11e9-9796-2058d8be92dd.png\">\r\n3、运行中有告警：\r\ninfer.py:63: DeprecationWarning: `imsave` is deprecated!\r\n`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\r\nUse ``imageio.imwrite`` instead.\r\n  (fake_temp + 1) * 127.5).astype(np.uint8))\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-03-07T11:05:22+00:00",
        "updated_at": "2019-04-15T10:59:42+00:00",
        "closed_at": "2019-04-15T10:59:42+00:00",
        "comments_count": [
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1853,
        "title": "neural_machine_translation/rnn_search预测出错",
        "body": "neural_machine_translation/rnn_search预测有时会报错(非必现)，报错如下：\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 137, in <module>\r\n    infer()\r\n  File \"infer.py\", line 113, in infer\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/executor.py\", line 525, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/executor.py\", line 591, in _run\r\n    exe.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator fill_constant error.\r\nPython Callstacks:\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/layer_helper.py\", line 56, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/layers/tensor.py\", line 386, in fill_constant\r\n    stop_gradient=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/contrib/decoder/beam_search_decoder.py\", line 651, in early_stop\r\n    shape=[1], value=0, dtype='bool', force_cpu=True, out=self._cond)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/contrib/decoder/beam_search_decoder.py\", line 722, in decode\r\n    self.early_stop()\r\n  File \"/ssd1/xiege/model_3.6/models-develop/fluid/PaddleNLP/neural_machine_translation/rnn_search/attention_model.py\", line 215, in seq_to_seq_net\r\n    decoder.decode()\r\n  File \"infer.py\", line 60, in infer\r\n    max_length=args.max_length)\r\n  File \"infer.py\", line 137, in <module>\r\n    infer()\r\nC++ Callstacks:\r\nop fill_constant does not have kernel for data_type[bool]:data_layout[ANY_LAYOUT]:place[CUDAPlace(0)]:library_type[PLAIN] at [/paddle/paddle/fluid/framework/operator.cc:943]\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-03-07T12:50:47+00:00",
        "updated_at": "2019-09-24T07:26:39+00:00",
        "closed_at": "2019-09-24T07:26:39+00:00",
        "comments_count": [
            "tashengjinsheng",
            "liuyf1994",
            "JiaXiao243",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1857,
        "title": "machine_reading_comprehension易用性问题",
        "body": "1、data/results文件夹下找不到评估和预测的结果\r\n<img width=\"886\" alt=\"f7a1492a7697af1662eeb115891d0f13\" src=\"https://user-images.githubusercontent.com/46314656/54015985-79861c00-41bc-11e9-8ab9-7ad26fe817b0.png\">\r\n2、data/preprocessed/testset目录下没有search.dev.json，是search.test.json\r\n<img width=\"985\" alt=\"87c4380fe1f80ea9361e6ec893376bab\" src=\"https://user-images.githubusercontent.com/46314656/54016213-295b8980-41bd-11e9-8e21-28cccbdc494d.png\">\r\n<img width=\"622\" alt=\"9dc80a023df13d82bea9534c4032c9b3\" src=\"https://user-images.githubusercontent.com/46314656/54016359-93742e80-41bd-11e9-8ee1-32f75c43ad56.png\">\r\n3、预测时输入../data/会报找不到目录，输入./data/才可以\r\n<img width=\"984\" alt=\"02b66e6450238ffe5b68f2573081cfde\" src=\"https://user-images.githubusercontent.com/46314656/54016507-3036cc00-41be-11e9-89c9-d268fbc8ee60.png\">\r\n<img width=\"884\" alt=\"c3bf2dd6a0fe503717b6b38a32bd34c9\" src=\"https://user-images.githubusercontent.com/46314656/54016613-7429d100-41be-11e9-8e52-b68a38d18b48.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-03-08T08:23:32+00:00",
        "updated_at": "2019-04-17T05:18:57+00:00",
        "closed_at": "2019-04-17T05:18:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1855,
        "title": "人脸检测，多卡训练一段时间后会卡住",
        "body": "我想问下，为什么多卡训练一段时间后，cpu与gpu的使用率会变成0，整个程序感觉卡死了",
        "state": "open",
        "user": "chenjiapen12",
        "closed_by": null,
        "created_at": "2019-03-08T06:07:42+00:00",
        "updated_at": "2019-03-09T07:20:25+00:00",
        "closed_at": null,
        "comments_count": [
            "xuezhong",
            "chenjiapen12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1856,
        "title": "chinese_ner模型训练精度为0",
        "body": "用提供的数据集和参数，在chinese_ner目录下直接跑python train.py, 得到的精度为0（如下图所示），这个是什么原因？\r\n![image](https://user-images.githubusercontent.com/4484303/54012629-95d08b80-41b1-11e9-8e19-de0f6c1c9c1b.png)\r\n",
        "state": "closed",
        "user": "dashulu",
        "closed_by": "dashulu",
        "created_at": "2019-03-08T06:51:18+00:00",
        "updated_at": "2019-03-09T04:31:37+00:00",
        "closed_at": "2019-03-08T07:11:24+00:00",
        "comments_count": [
            "dashulu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1859,
        "title": "deep_attention_matching_net单卡训练log无内容输出，GPU利用率显示为0",
        "body": "deep_attention_matching_net单卡训练log无内容输出，GPU利用率显示为0\r\nlog如下所示：\r\n![image](https://user-images.githubusercontent.com/37854899/54029986-38563200-41e5-11e9-9844-16c27759c89e.png)\r\n显卡信息如下所示：\r\n![image](https://user-images.githubusercontent.com/37854899/54030041-591e8780-41e5-11e9-8e2c-9d0d44723df8.png)\r\n\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-03-08T13:01:57+00:00",
        "updated_at": "2019-03-09T04:41:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1858,
        "title": "human_pose_eatimation模型valid && test报错",
        "body": "1.valid报错信息如下\r\n<img width=\"795\" alt=\"fbdbca570e73b0d09700bc485479bec2\" src=\"https://user-images.githubusercontent.com/37854899/54026246-29b54e00-41d8-11e9-865e-b94274ff5d48.png\">\r\n2. test报错信息如下\r\n<img width=\"794\" alt=\"fa0c6f234c4f180899ed4e10d86d91de\" src=\"https://user-images.githubusercontent.com/37854899/54026259-32a61f80-41d8-11e9-92eb-402ab5b5c5ba.png\">\r\n3.文档链接失效\r\n![image](https://user-images.githubusercontent.com/37854899/54026319-64b78180-41d8-11e9-96e0-1b0ff7991bd6.png)\r\n![image](https://user-images.githubusercontent.com/37854899/54026332-6a14cc00-41d8-11e9-96dd-36ddbf5a6153.png)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-03-08T11:31:37+00:00",
        "updated_at": "2019-04-01T02:19:40+00:00",
        "closed_at": "2019-04-01T02:19:40+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1860,
        "title": "pyramidbox: why anchor down-sampled?",
        "body": "I have a question disturbed me. As we know, the anchor will be expanded to detect head and body from face anchors, but it is down-sampled to calculate IOU with region target to confirm the label. After all, the head and body are larger than face. Thank you very much.",
        "state": "open",
        "user": "chenkingwen",
        "closed_by": null,
        "created_at": "2019-03-09T11:22:35+00:00",
        "updated_at": "2019-03-11T15:00:38+00:00",
        "closed_at": null,
        "comments_count": [
            "takecareofbigboss",
            "takecareofbigboss",
            "chenkingwen",
            "takecareofbigboss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1861,
        "title": "faste-rcnn 训练代码可以支持VOC数据格式吗？",
        "body": "models/fluid/PaddleCV/rcnn   目前看faster-rcnn的训练代码reader只支持coco的数据格式，请问是否可以增加对VOC格式reader的支持？",
        "state": "closed",
        "user": "soldier828",
        "closed_by": "NHZlX",
        "created_at": "2019-03-11T02:44:10+00:00",
        "updated_at": "2019-03-12T08:09:58+00:00",
        "closed_at": "2019-03-12T08:09:58+00:00",
        "comments_count": [
            "Yancey0623",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1862,
        "title": "faster_rcnn eval出错",
        "body": "报错如下：\r\n<img width=\"876\" alt=\"4f092867dddd5037866d2af29acce10f\" src=\"https://user-images.githubusercontent.com/46314656/54098709-9dca3e80-43f0-11e9-9a90-5e3744e0920b.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-03-11T03:27:23+00:00",
        "updated_at": "2019-03-11T07:02:17+00:00",
        "closed_at": "2019-03-11T07:02:17+00:00",
        "comments_count": [
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1866,
        "title": "图像分类开启显存优化会hang住",
        "body": "```bash\r\nFLAGS_fraction_of_gpu_memory_to_use=0.0 CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 sh run.sh\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 256\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ./data/ILSVRC2012\r\nenable_ce: False\r\nfp16: False\r\nimage_shape: 3,224,224\r\nl2_decay: 0.0001\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: SE_ResNeXt50_32x4d\r\nmodel_category: models_name\r\nmodel_save_dir: output/\r\nmomentum_rate: 0.9\r\nnum_epochs: 120\r\npretrained_model: None\r\nscale_loss: 1.0\r\ntotal_images: 1281167\r\nuse_gpu: True\r\nwith_mem_opt: 1\r\n------------------------------------------------\r\nW0311 06:36:14.564357  3503 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0311 06:36:14.564435  3503 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0311 06:36:14.564447  3503 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nPass 0, trainbatch 0, loss 6.92884540558,                         acc1 0.00390625, acc5 0.0078125, lr0.10000, time 7.06 sec\r\n/usr/local/lib/python2.7/dist-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0\r\n  \" Skipping tag %s\" % (size, len(data), tag))\r\n/usr/local/lib/python2.7/dist-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\r\n  \" Skipping tag %s\" % (size, len(data), tag))\r\n```\r\n![image](https://user-images.githubusercontent.com/33303691/54104831-299d9400-440c-11e9-8ae9-f3051c314a1c.png)\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "shippingwang",
        "created_at": "2019-03-11T06:44:30+00:00",
        "updated_at": "2019-04-12T07:23:54+00:00",
        "closed_at": "2019-04-12T07:23:53+00:00",
        "comments_count": [
            "shippingwang",
            "ccmeteorljh",
            "shippingwang",
            "shippingwang"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1865,
        "title": "what is mention in fluid/PaddleNLP/chinese_ner/",
        "body": " mention_idx = []\r\n                for item in features[3].strip().split(\" \"):\r\n                    mention_idx.append(int(item))\r\nwhat is mention?",
        "state": "closed",
        "user": "WuDongxue518",
        "closed_by": "NHZlX",
        "created_at": "2019-03-11T06:37:46+00:00",
        "updated_at": "2019-03-12T08:09:43+00:00",
        "closed_at": "2019-03-12T08:09:43+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1873,
        "title": "gru4rec易用性问题",
        "body": "1. 负采样使用bpr loss、cross entrop loss的模型结果均保存在 model_bpr_recall20目录下(依次执行会在该目录下覆盖)，建议修改为model_neg_recall20。因为使用负采样cross entrop loss训练看到model_bpr_recall20会以为仅存放bpr loss的结果，会不知道负采样cross entrop loss训练出的模型存放在哪里。\r\n2. 文档实例训练的模型输出结果建议和infer输入的模型路径一致。\r\n 训练示例模型保存路径\r\n![image](https://user-images.githubusercontent.com/37854899/54179452-cc6d1580-44d3-11e9-93a7-ed377a7ba8cd.png)\r\ninfer示例模型加载路径\r\n![image](https://user-images.githubusercontent.com/37854899/54179495-e6a6f380-44d3-11e9-9335-0cd5a932b339.png)\r\n3. 为保证文档前后一致性，训练部分有全词表、负采样得示例，infer部分仅有全词表的示例，建议加负采样预测的示例。\r\n4.预测log中step输出中仅有数据，未标明数据含义，建议添加数据含义recall@20，并优化格式：去掉括号、单引号、空格；或在log中省略该部分。\r\n![image](https://user-images.githubusercontent.com/37854899/54179674-7482de80-44d4-11e9-9341-fc2933e610dc.png)\r\n\r\n ",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-03-12T06:49:45+00:00",
        "updated_at": "2019-03-12T06:49:45+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1868,
        "title": "fetch StNet pretrained model failed",
        "body": "failed to get StNet pretrained model from following url https://paddlemodels.bj.bcebos.com/video_classification/stnet_kinetics.tar.gz as described in https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/video/models/stnet/README.md.\r\nerror: {\"code\":\"NoSuchKey\",\"message\":\"The specified key does not exist.\",\"requestId\":\"04581481-d584-43c3-9b23-08789ce86f3b\"}",
        "state": "closed",
        "user": "xyoungli",
        "closed_by": "heavengate",
        "created_at": "2019-03-11T10:08:24+00:00",
        "updated_at": "2019-03-14T05:58:09+00:00",
        "closed_at": "2019-03-14T05:58:09+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1872,
        "title": "图像分类infer 没有batchsize参数",
        "body": "```bash\r\nusage: infer.py [-h] [--use_gpu USE_GPU] [--class_dim CLASS_DIM]\r\n                [--image_shape IMAGE_SHAPE] [--with_mem_opt WITH_MEM_OPT]\r\n                [--pretrained_model PRETRAINED_MODEL] [--model MODEL]\r\n                [--model_category MODEL_CATEGORY]\r\ninfer.py: error: unrecognized arguments: --batch_size=32\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-03-12T02:38:00+00:00",
        "updated_at": "2019-03-12T03:32:00+00:00",
        "closed_at": "2019-03-12T03:32:00+00:00",
        "comments_count": [
            "ccmeteorljh",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1875,
        "title": "###",
        "body": "",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-03-12T07:41:40+00:00",
        "updated_at": "2019-03-12T08:00:50+00:00",
        "closed_at": "2019-03-12T07:41:51+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1876,
        "title": "tag space infer log未标明数据含义",
        "body": "infer log如图所示，建议标明log输出数据含义\r\n<img width=\"294\" alt=\"edf51251543d697711357d8d535b2f73\" src=\"https://user-images.githubusercontent.com/37854899/54184001-84082480-44e0-11e9-89c8-a55d5494f478.png\">\r\n\r\n\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-03-12T08:04:41+00:00",
        "updated_at": "2019-03-12T08:04:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1878,
        "title": "文本分类text_classification训练选项不匹配",
        "body": "1. train.py中batch_size参数冗余\r\n\r\n2. 命令行选项gru配置错误\r\n\r\n3. GRU Layer embedding学习率默认配置过大，导致模型训练补课收敛。",
        "state": "closed",
        "user": "ZeyuChen",
        "closed_by": "kuke",
        "created_at": "2019-03-12T12:40:58+00:00",
        "updated_at": "2019-03-12T13:06:07+00:00",
        "closed_at": "2019-03-12T13:06:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1884,
        "title": "RNN模型的数据下载的链接失效",
        "body": "![image](https://user-images.githubusercontent.com/17102274/54261050-b4fe5d00-45a5-11e9-8239-f1ef759bcd2c.png)\r\nhttps://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleNLP/neural_machine_translation/rnn_search\r\nRNN模型下这几个数据下载的链接都失效了，可以提供下新的吗？",
        "state": "open",
        "user": "wzzju",
        "closed_by": "wzzju",
        "created_at": "2019-03-13T07:46:08+00:00",
        "updated_at": "2019-03-14T08:42:19+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1877,
        "title": "icnet加载model_1000预训练模型进行训练报错",
        "body": "1.使用如下指令训练：python train.py --batch_size=16 --use_gpu=True --init_model=\"./model_1000/\"  --checkpoint_path=\"./chkpnt/\"\r\n其中：/model_1000为文档中提供的预训练模型，其中并无conv6参数。\r\n<img width=\"970\" alt=\"bfd08a979fcb4f72bb443fbca3f53d3f\" src=\"https://user-images.githubusercontent.com/37854899/54199980-24704000-4505-11e9-9bf4-70dc09b0cc86.png\">\r\n2. 文档中eval和infer中的model_path建议改为./chkpnt/100，与训练输出保持一致\r\n![image](https://user-images.githubusercontent.com/37854899/54200167-aceee080-4505-11e9-9d1a-535a8a09df74.png)\r\n![image](https://user-images.githubusercontent.com/37854899/54200175-b2e4c180-4505-11e9-8cb7-68e5020ebc60.png)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-03-12T12:32:15+00:00",
        "updated_at": "2019-04-08T05:22:48+00:00",
        "closed_at": "2019-04-08T05:22:48+00:00",
        "comments_count": [
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1881,
        "title": "使用cycle_gan训练出来的模型执行预测命令报错",
        "body": "参考官方链接：http://www.paddlepaddle.org/paddle/ModelBase#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%0A%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90-CycleGAN\r\n训练平台：ubontu18.04，GPU，paddle1.3.0， 预测平台：win10，cpu，paddle1.3.0\r\n报错信息如下：\r\nPS C:\\Users\\yuzhengfei\\Desktop\\models\\models\\fluid\\PaddleCV\\gan\\cycle_gan> python infer.py --init_model=\"./output_0/chec\r\nkpoints/1\" --input=\"./data/horse2zebra\\inputA\\*\" --input_style A --output=\"./output\"\r\n-----------  Configuration Arguments -----------\r\ninit_model: ./output_0/checkpoints/1\r\ninput: ./data/horse2zebra\\inputA\\*\r\ninput_style: A\r\noutput: ./output\r\nuse_gpu: False\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 67, in <module>\r\n    infer(args)\r\n  File \"infer.py\", line 40, in infer\r\n    fluid.io.load_persistables(exe, args.init_model)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 701, in load_persistables\r\n    filename=filename)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 572, in load_vars\r\n    filename=filename)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 607, in load_vars\r\n    executor.run(load_prog)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 525, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 591, in _run\r\n    exe.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator load error.\r\nPython Callstacks:\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 593, in load_vars\r\n    attrs={'file_path': os.path.join(dirname, new_var.name)})\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 572, in load_vars\r\n    filename=filename)\r\n  File \"C:\\Users\\yuzhengfei\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 701, in load_persistables\r\n    filename=filename)\r\n  File \"infer.py\", line 40, in infer\r\n    fluid.io.load_persistables(exe, args.init_model)\r\n  File \"infer.py\", line 67, in <module>\r\n    infer(args)\r\nC++ Callstacks:\r\nCannot open file ./output_0/checkpoints/1\\g_A_c1_w for load op at [D:\\1.3\\paddle\\paddle\\fluid\\operators\\load_op.cc:39]\r\nPaddlePaddle Call Stacks:\r\nWindows not support stack backtrace yet.\r\n\r\n![image](https://user-images.githubusercontent.com/31945737/54250449-caac5c00-457e-11e9-98fc-b159be87d632.png)\r\n",
        "state": "open",
        "user": "yuzhengfei",
        "closed_by": null,
        "created_at": "2019-03-13T03:05:34+00:00",
        "updated_at": "2019-03-13T13:37:01+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "kolinwei",
            "yuzhengfei",
            "wzzju"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1882,
        "title": "使用transformer demo时报错",
        "body": "参考官网链接\r\nhttp://www.paddlepaddle.org/paddle/ModelBase#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%0A%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91-Transformer\r\n训练平台\r\nCentos 6.3; CUDA9.0; PaddlePaddle 1.3.0\r\n报错信息如下\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 772, in <module>\r\n    train(args)\r\n  File \"train.py\", line 691, in train\r\n    token_num, predict, pyreader)\r\n  File \"train.py\", line 544, in train_loop\r\n    feed=feed_dict_list)\r\n  File \"/home/work/anaconda3/envs/pytorch/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator lookup_table error.\r\nPython Callstacks:\r\n  File \"/home/work/anaconda3/envs/pytorch/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/work/anaconda3/envs/pytorch/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 56, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/work/anaconda3/envs/pytorch/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 364, in embedding\r\n    'padding_idx': padding_idx\r\n  File \"/home/work/paddle/transformer/model.py\", line 291, in prepare_encoder_decoder\r\n    initializer=fluid.initializer.Normal(0., src_emb_dim**-0.5)))\r\n  File \"/home/work/paddle/transformer/model.py\", line 652, in wrap_encoder\r\n    word_emb_param_name=word_emb_param_names[0])\r\n  File \"/home/work/paddle/transformer/model.py\", line 581, in transformer\r\n    enc_inputs, )\r\n  File \"train.py\", line 665, in train\r\n    is_test=False)\r\n  File \"train.py\", line 772, in <module>\r\n    train(args)\r\nC++ Callstacks:\r\nEnforce failed. Expected ids[i] < row_number, but received ids[i]:36548 >= row_number:36532.\r\n at [/paddle/paddle/fluid/operators/lookup_table_op.h:86]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fcece6f1e0dp void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 365\r\n1       0x7fcece6f2157p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fceceb180fap paddle::operators::LookupTableKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 2970\r\n3       0x7fceceb18533p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LookupTableKernel<float>, paddle::operators::LookupTableKernel<double> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7fced00ffd03p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 659\r\n5       0x7fced00fd575p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 341\r\n6       0x7fcecff73bd9p\r\n7       0x7fcecff6c081p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 769\r\n8       0x7fcecff7386cp paddle::framework::details::ComputationOpHandle::RunImpl() + 124\r\n9       0x7fcecff6cfc6p paddle::framework::details::OpHandleBase::Run(bool) + 118\r\n10      0x7fcecff570bap\r\n11      0x7fcecf2c53d3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n12      0x7fcecf2886f7p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n13      0x7fcf4788bbe0p pthread_once + 80\r\n14      0x7fcecff55b02p\r\n15      0x7fcecf289b24p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n16      0x7fcef41f1678p\r\n17      0x7fcf47886df3p\r\n18      0x7fcf475b42cdp clone + 109\r\n\r\nterminate called without an active exception\r\n*** Aborted at 1552404396 (unix time) try \"date -d @1552404396\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1f400005314) received by PID 21268 (TID 0x7fc9371de700) from PID 21268; stack trace: ***\r\n    @     0x7fcf4788e130 (unknown)\r\n    @     0x7fcf474f39d9 __GI_raise\r\n    @     0x7fcf474f50e8 __GI_abort\r\n    @     0x7fcef41d73df __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7fcef41d5b16 __cxxabiv1::__terminate()\r\n    @     0x7fcef41d5b4c std::terminate()\r\n    @     0x7fcef41d581e __gxx_personality_v0\r\n    @     0x7fcf3e975045 _Unwind_ForcedUnwind_Phase2\r\n    @     0x7fcf3e97531b _Unwind_ForcedUnwind\r\n    @     0x7fcf4788cd90 __GI___pthread_unwind\r\n    @     0x7fcf47887e15 __pthread_exit\r\n    @     0x7fcf47e876f9 PyThread_exit_thread\r\n    @     0x7fcf47d20d82 PyEval_RestoreThread.cold.739\r\n    @     0x7fcece70a4d9 pybind11::gil_scoped_release::~gil_scoped_release()\r\n    @     0x7fcece6d3c43 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE60_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESY_\r\n    @     0x7fcece71cc9e pybind11::cpp_function::dispatcher()\r\n    @     0x7fcf47dcf744 _PyCFunction_FastCallDict\r\n    @     0x7fcf47e5657e call_function\r\n    @     0x7fcf47e7b38a _PyEval_EvalFrameDefault\r\n    @     0x7fcf47e518c6 PyEval_EvalCodeEx\r\n    @     0x7fcf47e521a6 function_call\r\n    @     0x7fcf47dcf54e PyObject_Call\r\n    @     0x7fcf47e7ca6c _PyEval_EvalFrameDefault\r\n    @     0x7fcf47e5053b fast_function\r\n    @     0x7fcf47e56505 call_function\r\n    @     0x7fcf47e7b38a _PyEval_EvalFrameDefault\r\n    @     0x7fcf47e5053b fast_function\r\n    @     0x7fcf47e56505 call_function\r\n    @     0x7fcf47e7b38a _PyEval_EvalFrameDefault\r\n    @     0x7fcf47e50bab _PyFunction_FastCallDict\r\n    @     0x7fcf47dcfb0f _PyObject_FastCallDict\r\n    @     0x7fcf47dd46a3 _PyObject_Call_Prepend",
        "state": "open",
        "user": "ivychen0515",
        "closed_by": null,
        "created_at": "2019-03-13T03:33:06+00:00",
        "updated_at": "2019-03-28T02:24:20+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "ivychen0515",
            "guoshengCS",
            "YeLiuXiang"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1885,
        "title": "paddle 是否支持两维以上的变长tensor?",
        "body": "## Q1: 请问paddle 是否支持两维以上的变长tensor 如shape[-1, -1, 128]。\r\n\r\n## Q2:  Fluid 中的 layers.data中的shape可以支持变长吗？网络输入的就是一个大小不确定的矩阵。\r\n\r\n",
        "state": "closed",
        "user": "wzzju",
        "closed_by": "wzzju",
        "created_at": "2019-03-13T07:49:53+00:00",
        "updated_at": "2019-03-14T12:12:56+00:00",
        "closed_at": "2019-03-14T12:12:56+00:00",
        "comments_count": [
            "wzzju"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1889,
        "title": "faster rcnn eval报错",
        "body": "下载文档中的Faster RCNN的预训练模型Fluid RoIPool minibatch padding，执行指令：python eval_coco_map.py --dataset=coco2017 --pretrained_model=./model_pool_minibatch_padding/ --MASK_ON=False\r\n报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/54325883-5f768e80-463f-11e9-8318-e59e59d2f16d.png)\r\nPS:使用MASK RCNN的预训练模型Fluid mask no padding进行eval，得到正确结果。\r\n![image](https://user-images.githubusercontent.com/37854899/54325936-89c84c00-463f-11e9-93eb-e18fc4d86de4.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-03-14T01:58:07+00:00",
        "updated_at": "2019-03-21T15:20:32+00:00",
        "closed_at": "2019-03-21T15:20:32+00:00",
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1894,
        "title": "transformer infer无输出log",
        "body": "",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-03-14T09:19:04+00:00",
        "updated_at": "2019-03-15T07:43:13+00:00",
        "closed_at": "2019-03-15T07:43:13+00:00",
        "comments_count": [
            "JiaXiao243",
            "jerrywgz",
            "JiaXiao243",
            "guoshengCS",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1895,
        "title": "如何使用第二个GPU进行训练？",
        "body": "    if args.use_gpu:\r\n        # NOTE: for multi process mode: one process per GPU device.        \r\n        gpu_id = 0\r\n        if os.getenv(\"FLAGS_selected_gpus\"):\r\n            gpu_id = int(os.getenv(\"FLAGS_selected_gpus\"))\r\n    place = core.CUDAPlace(gpu_id) if args.use_gpu else core.CPUPlace()\r\n有两个问题：1、以上代码中FLAGS_selected_gpus参数找遍网络都没有相关的说明，哪里能提供文档资料说明？2、分布训练ps模式，单机双gpu，第一个trainer使用第一颗gpu是否使用place = core.CUDAPlace(0)？第二个trainer使用第二个GPU，是否使用place = core.CUDAPlace(1)代码？我在运行时提示出错，说place = core.CUDAPlace( )里的参数只能[0，1）之间。",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-03-14T11:02:01+00:00",
        "updated_at": "2019-11-12T06:19:20+00:00",
        "closed_at": null,
        "comments_count": [
            "qianledan",
            "qianledan",
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1896,
        "title": "运行官网例子单机分布训练ps模式出错",
        "body": "我运行官网github中分布训练的例子run_ps_mode.sh出现：（官网例子是否需要修改？）\r\n\r\n```\r\nqld@ifan-W580-G20:/data/paddle/image_classification/ImageNet_train_v1.3/dist_train$ sh run_ps_mode.sh\r\nqld@ifan-W580-G20:/data/paddle/image_classification/ImageNet_train_v1.3/dist_train$ -----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 32\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ../data/ILSVRC2012\r\nenable_ce: False\r\nfp16: False\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 8\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 1.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: pserver\r\nuse_gpu: True\r\nwith_mem_opt: False\r\n------------------------------------------------\r\n----------- Configuration envs -----------\r\nENV PADDLE_TRAINERS_NUM:2\r\nENV PADDLE_TRAINER_ID:0\r\nENV PADDLE_CURRENT_ENDPOINT:127.0.0.1:7160\r\nENV PADDLE_PSERVER_ENDPOINTS:127.0.0.1:7160,127.0.0.1:7161\r\nENV PADDLE_TRAINING_ROLE:TRAINER\r\n------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 32\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ../data/ILSVRC2012\r\nenable_ce: False\r\nfp16: False\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 8\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 1.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: pserver\r\nuse_gpu: True\r\nwith_mem_opt: False\r\n------------------------------------------------\r\n----------- Configuration envs -----------\r\nENV PADDLE_TRAINERS_NUM:2\r\nENV PADDLE_CURRENT_ENDPOINT:127.0.0.1:7160\r\nENV PADDLE_PSERVER_ENDPOINTS:127.0.0.1:7160,127.0.0.1:7161\r\nENV PADDLE_TRAINING_ROLE:PSERVER\r\n------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 32\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ../data/ILSVRC2012\r\nenable_ce: False\r\nfp16: False\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 8\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 1.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: pserver\r\nuse_gpu: True\r\nwith_mem_opt: False\r\n------------------------------------------------\r\n----------- Configuration envs -----------\r\nENV PADDLE_TRAINERS_NUM:2\r\nENV PADDLE_TRAINER_ID:1\r\nENV PADDLE_CURRENT_ENDPOINT:127.0.0.1:7161\r\nENV PADDLE_PSERVER_ENDPOINTS:127.0.0.1:7160,127.0.0.1:7161\r\nENV PADDLE_TRAINING_ROLE:TRAINER\r\n------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\nasync_mode: False\r\nbatch_size: 32\r\ncheckpoint: None\r\nclass_dim: 1000\r\ndata_dir: ../data/ILSVRC2012\r\nenable_ce: False\r\nfp16: False\r\nimage_shape: 3,224,224\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: DistResNet\r\nmodel_category: models\r\nmodel_save_dir: output\r\nmulti_batch_repeat: 1\r\nnum_epochs: 120\r\nnum_threads: 8\r\npretrained_model: None\r\nreduce_strategy: allreduce\r\nscale_loss: 1.0\r\nskip_unbalanced_data: False\r\nsplit_var: True\r\nstart_test_pass: 0\r\ntotal_images: 1281167\r\nupdate_method: pserver\r\nuse_gpu: True\r\nwith_mem_opt: False\r\n------------------------------------------------\r\n----------- Configuration envs -----------\r\nENV PADDLE_TRAINERS_NUM:2\r\nENV PADDLE_CURRENT_ENDPOINT:127.0.0.1:7161\r\nENV PADDLE_PSERVER_ENDPOINTS:127.0.0.1:7160,127.0.0.1:7161\r\nENV PADDLE_TRAINING_ROLE:PSERVER\r\n------------------------------------------------\r\nstart lr: 0.1, end lr: 0.2, decay boundaries: [600570, 1201140, 1601520]\r\nstart lr: 0.1, end lr: 0.2, decay boundaries: [600570, 1201140, 1601520]\r\nstart lr: 0.1, end lr: 0.2, decay boundaries: [600570, 1201140, 1601520]\r\nstart lr: 0.1, end lr: 0.2, decay boundaries: [600570, 1201140, 1601520]\r\nget_pserver_program() is deprecated, call get_pserver_programs() to get pserver main and startup in a single call.\r\nget_pserver_program() is deprecated, call get_pserver_programs() to get pserver main and startup in a single call.\r\nI0314 20:58:22.185073 36189 grpc_server.cc:430] Server listening on 127.0.0.1:7161 selected port: 7161\r\nI0314 20:58:23.730594 36240 grpc_server.cc:430] Server listening on 127.0.0.1:7160 selected port: 7160\r\nW0314 20:58:24.545244 35502 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 37, Driver API Version: 9.0, Runtime APIVersion: 9.0\r\nW0314 20:58:24.545289 35502 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0314 20:58:24.618002 35505 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 37, Driver API Version: 9.0, Runtime APIVersion: 9.0\r\nW0314 20:58:24.618052 35505 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nread images from 0, length: 640583, lines length: 640583, total: 1281167\r\nF0314 21:01:24.640844 36401 grpc_client.cc:408] GetRPC name:[conv2d_10.w_0.block1], ep:[127.0.0.1:7161], status:[-1] meets grpc error, error_code:4 error_message:Deadline Exceeded error_details:\r\n*** Check failure stack trace: ***\r\n    @     0x7f55771013fd  google::LogMessage::Fail()\r\n    @     0x7f5577104eac  google::LogMessage::SendToLog()\r\n    @     0x7f5577100f23  google::LogMessage::Flush()\r\n    @     0x7f55771063be  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f55785c82da  paddle::operators::distributed::GRPCClient::Proceed()\r\n    @     0x7f5619507c80  (unknown)\r\n    @     0x7f561bce86ba  start_thread\r\n    @     0x7f561b30e41d  clone\r\n    @              (nil)  (unknown)\r\nF0314 21:01:26.682222 36295 grpc_client.cc:408] SendRPC name:[fc_0.b_0@GRAD.trainer_0], ep:[127.0.0.1:7160], status:[-1] meets grpc error, error_code:4 error_message:Deadline Exceeded error_details:\r\n*** Check failure stack trace: ***\r\n    @     0x7fc9368dd3fd  google::LogMessage::Fail()\r\n    @     0x7fc9368e0eac  google::LogMessage::SendToLog()\r\n    @     0x7fc9368dcf23  google::LogMessage::Flush()\r\n    @     0x7fc9368e23be  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc937da42da  paddle::operators::distributed::GRPCClient::Proceed()\r\n    @     0x7fc9d8ce3c80  (unknown)\r\n    @     0x7fc9db4c46ba  start_thread\r\n    @     0x7fc9daaea41d  clone\r\n    @              (nil)  (unknown)\r\n```",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "jerrywgz",
        "created_at": "2019-03-14T11:13:23+00:00",
        "updated_at": "2019-12-20T13:29:22+00:00",
        "closed_at": "2019-12-20T13:29:22+00:00",
        "comments_count": [
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1901,
        "title": "video_classification模型训练报错",
        "body": "数据：6类数据\r\n\r\n环境：gpu cuda9 cudnn7  FLAGS_fraction_of_gpu_memory_to_use=0.02\r\n\r\n命令：python train.py --batch_size=50 --total_videos=585 --class_dim=6 --num_epochs=2 --image_shape=3,224,224 --model_save_dir=output/ --with_mem_opt=True --lr_init=0.01 --num_layers=50 --seg_num=7\r\n\r\n报错：\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  unhandled cuda error at [/paddle/paddle/fluid/platform/nccl_helper.h:67]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f89f49d21b5p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f89f49d2539p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f89f4b138d8p paddle::platform::NCCLGroupGuard::~NCCLGroupGuard() + 328\r\n3       0x7f89f62bb926p\r\n4       0x7f89f630034dp\r\n5       0x7f89f630034dp\r\n6       0x7f89f630034dp\r\n7       0x7f89f630034dp\r\n8       0x7f89f62ffc95p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 805\r\n9       0x7f89f62bcd08p paddle::framework::details::AllReduceOpHandle::RunImpl() + 2056\r\n10      0x7f89f6300bb6p paddle::framework::details::OpHandleBase::Run(bool) + 118\r\n11      0x7f89f6298fbdp\r\n12      0x7f89f5655be3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n13      0x7f89f5618f07p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n14      0x7f8a2bfa8be0p pthread_once + 80\r\n15      0x7f89f6297ca2p\r\n16      0x7f89f561a334p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n17      0x7f8a11cf0678p\r\n18      0x7f8a2bfa3df3p\r\n19      0x7f8a2b5c82cdp clone + 109\r\n\r\n*** Aborted at 1552898901 (unix time) try \"date -d @1552898901\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1f4000058ac) received by PID 22700 (TID 0x7f8869df2700) from PID 22700; stack trace: ***\r\n    @     0x7f8a2bfab130 (unknown)\r\n    @     0x7f8a2b5079d9 __GI_raise\r\n    @     0x7f8a2b5090e8 __GI_abort\r\n    @     0x7f8a11cd63df __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f8a11cd4b16 __cxxabiv1::__terminate()\r\n    @     0x7f8a11cd3f91 __cxa_call_terminate\r\n    @     0x7f8a11cd479d __gxx_personality_v0\r\n    @     0x7f8a20a93f56 _Unwind_RaiseException_Phase2\r\n    @     0x7f8a20a94244 _Unwind_RaiseException\r\n    @     0x7f8a11cd4d1b __cxa_throw\r\n    @     0x7f89f4b138f6 paddle::platform::NCCLGroupGuard::~NCCLGroupGuard()\r\n    @     0x7f89f62bb926 _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details17AllReduceOpHandle7RunImplEvEUlvE0_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f89f630034d _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f89f630034d _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f89f630034d _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f89f630034d _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f89f62ffc95 paddle::framework::details::OpHandleBase::RunAndRecordEvent()\r\n    @     0x7f89f62bcd08 paddle::framework::details::AllReduceOpHandle::RunImpl()\r\n    @     0x7f89f6300bb6 paddle::framework::details::OpHandleBase::Run()\r\n    @     0x7f89f6298fbd _ZZN6paddle9framework7details24ThreadedSSAGraphExecutor5RunOpERKSt10shared_ptrINS0_13BlockingQueueIPNS1_13VarHandleBaseEEEEPNS1_12OpHandleBaseEENKUlvE_clEv\r\n    @     0x7f89f5655be3 std::_Function_handler<>::_M_invoke()\r\n    @     0x7f89f5618f07 std::__future_base::_State_base::_M_do_set()\r\n    @     0x7f8a2bfa8be0 __GI___pthread_once\r\n    @     0x7f89f6297ca2 _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details24ThreadedSSAGraphExecutor5RunOpERKSt10shared_ptrINS3_13BlockingQueueIPNS4_13VarHandleBaseEEEEPNS4_12OpHandleBaseEEUlvE_vEESaIiEFvvEE6_M_runEv\r\n    @     0x7f89f561a334 _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\n    @     0x7f8a11cf0678 execute_native_thread_routine_compat\r\n    @     0x7f8a2bfa3df3 start_thread\r\n    @     0x7f8a2b5c82cd __clone\r\n    @                0x0 (unknown)\r\n",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-03-18T08:59:51+00:00",
        "updated_at": "2019-03-18T12:16:54+00:00",
        "closed_at": "2019-03-18T12:16:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1899,
        "title": "video模型train.py中parse_args中的参数名与train函数以及config中的参数名不一致",
        "body": "train.py中parse_args：参数名用的横线\r\n\r\ntrain函数以及config中的参数名用的下划线\r\n\r\n建议统一为下划线",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2019-03-18T03:27:02+00:00",
        "updated_at": "2019-04-09T07:14:51+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1897,
        "title": "Exception in thread",
        "body": "能正常训练，但是有时候会报：\r\n\r\n> Exception in thread Thread-2 (most likely raised during interpreter shutdown):Exception in thread Thread-5 (most likely raised during interpreter shutdown):Exception in thread Thread-9 (most likely raised during interpreter shutdown):Exception in thread Thread-6 (most likely raised during interpreter shutdown):Exception in thread Thread-10 (most likely raised during interpreter shutdown):Exception in thread Thread-7 (most likely raised during interpreter shutdown):Exception in thread Thread-4 (most likely raised during interpreter shutdown):\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nException in thread Thread-3 (most likely raised during interpreter shutdown):\r\nTraceback (most recent call last):\r\n  File \"/opt/python/cp27-cp27mu/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n  File \"/opt/python/cp27-cp27mu/lib/python2.7/threading.py\", line 754, in run\r\n  File \"/opt/python/cp27-cp27mu/lib/python2.7/threading.py\", line 801, in __bootstrap_innerTraceback (most recent call last):Traceback (most recent call last):Traceback (most recent call last):\r\n\r\n请问这是怎么回事，如何解决？",
        "state": "open",
        "user": "dubhex",
        "closed_by": null,
        "created_at": "2019-03-15T10:48:26+00:00",
        "updated_at": "2019-03-15T13:12:09+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1903,
        "title": "machine_reading_comprehension 模型中定义var使用‘：’分割，在多机中transplier中会挂掉",
        "body": "在模型定义中，定义var前缀时候，使用了':'字符，导致在做多机中transplier中挂掉\r\nhttps://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleNLP/machine_reading_comprehension/rc_model.py#L97\r\n\r\n![image](https://user-images.githubusercontent.com/33303691/54605577-8fc98d00-4a84-11e9-85ca-90254c1ffa5f.png)\r\n\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "kuke",
        "created_at": "2019-03-19T12:21:37+00:00",
        "updated_at": "2019-05-14T07:34:18+00:00",
        "closed_at": "2019-05-14T07:34:18+00:00",
        "comments_count": [
            "jacquesqiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1906,
        "title": "DAM模型中word_embedding.pkl的用途及产出程序",
        "body": "模型库中的DAM模型， 模型示例数据中有多个word_embedding.pkl文件， douban/data/word_embedding.pkl，  ubuntu/data/word_embedding.pkl ,，有没有示例程序告诉使用方如何产出，以及这个文件的用途。",
        "state": "open",
        "user": "sshilei",
        "closed_by": null,
        "created_at": "2019-03-20T03:23:39+00:00",
        "updated_at": "2019-07-31T06:47:55+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1907,
        "title": "icnet 多卡实现报错",
        "body": "paddle version:1.3.0\r\n错误如下：\r\n```bash\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\n/paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] >= 0 && label[i] < D || label[i] == ignore_index` failed.\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  unspecified launch failure at [/paddle/paddle/fluid/framework/details/op_handle_base.cc:37]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f61bf8398f5p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f61bf839c79p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f61c10b7db1p paddle::framework::details::OpHandleBase::~OpHandleBase() + 337\r\n3       0x7f61c10a5c61p paddle::framework::details::FetchOpHandle::~FetchOpHandle() + 17\r\n4       0x7f61bf8ea979p paddle::framework::ir::Node::~Node() + 73\r\n5       0x7f61bf8eab21p paddle::framework::ir::Node::~Node() + 17\r\n6       0x7f61c10a779bp paddle::framework::details::ClearFetchOp(paddle::framework::ir::Graph*, std::vector<paddle::framework::details::FetchOpHandle*, std::allocator<paddle::framework::details::FetchOpHandle*> >*) + 1995\r\n7       0x7f61c1053024p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 4660\r\n8       0x7f61c104978ap paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 394\r\n9       0x7f61bf977c92p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 562\r\n10      0x7f61bf82a28ep\r\n11      0x7f61bf8651fep\r\n12            0x4c37edp PyEval_EvalFrameEx + 31165\r\n13            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n14            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n15            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n16            0x4c16e7p PyEval_EvalFrameEx + 22711\r\n17            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n18            0x4d54b9p\r\n19            0x4a577ep PyObject_Call + 62\r\n20            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n21            0x4c136fp PyEval_EvalFrameEx + 21823\r\n22            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n23            0x4d55f3p\r\n24            0x4a577ep PyObject_Call + 62\r\n25            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n26            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n27            0x4d54b9p\r\n28            0x4eebeep\r\n29            0x4a577ep PyObject_Call + 62\r\n30            0x548253p\r\n31            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n32            0x4c136fp PyEval_EvalFrameEx + 21823\r\n33            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n34            0x4d55f3p\r\n35            0x4a577ep PyObject_Call + 62\r\n36            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n37            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n38            0x4d54b9p\r\n39            0x4eebeep\r\n40            0x4a577ep PyObject_Call + 62\r\n41            0x548253p\r\n42            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n43            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n44            0x4d55f3p\r\n45            0x4a577ep PyObject_Call + 62\r\n46            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n47            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n48            0x4d54b9p\r\n49            0x4eebeep\r\n50            0x4a577ep PyObject_Call + 62\r\n51            0x548253p\r\n52            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n53            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n54            0x4d55f3p\r\n55            0x4a577ep PyObject_Call + 62\r\n56            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n57            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n58            0x4d54b9p\r\n59            0x4eebeep\r\n60            0x4a577ep PyObject_Call + 62\r\n61            0x548253p\r\n62            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n63            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n64            0x4d55f3p\r\n65            0x4a577ep PyObject_Call + 62\r\n66            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n67            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n68            0x4d54b9p\r\n69            0x4eebeep\r\n70            0x4a577ep PyObject_Call + 62\r\n71            0x548253p\r\n72            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n73            0x4c136fp PyEval_EvalFrameEx + 21823\r\n74            0x4c136fp PyEval_EvalFrameEx + 21823\r\n75            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n76            0x4d55f3p\r\n77            0x4eebeep\r\n78            0x4a577ep PyObject_Call + 62\r\n79            0x4bed3dp PyEval_EvalFrameEx + 12045\r\n80            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n81            0x4d54b9p\r\n82            0x4eebeep\r\n83            0x4ee7f6p\r\n84            0x4aa9abp\r\n85            0x4c15bfp PyEval_EvalFrameEx + 22415\r\n86            0x4b9ab6p PyEval_EvalCodeEx + 774\r\n87            0x4eb30fp\r\n88            0x4e5422p PyRun_FileExFlags + 130\r\n89            0x4e3cd6p PyRun_SimpleFileExFlags + 390\r\n90            0x493ae2p Py_Main + 1554\r\n91      0x7f6222376830p __libc_start_main + 240\r\n92            0x4933e9p _start + 41\r\n\r\n*** Aborted at 1553054642 (unix time) try \"date -d @1553054642\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x6ef2) received by PID 28402 (TID 0x7f6222b57700) from PID 28402; stack trace: ***\r\n    @     0x7f6222731390 (unknown)\r\n    @     0x7f622238b428 gsignal\r\n    @     0x7f622238d02a abort\r\n    @     0x7f621972492d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f6219722996 __cxxabiv1::__terminate()\r\n    @     0x7f6219721a49 __cxa_call_terminate\r\n    @     0x7f6219722335 __gxx_personality_v0\r\n    @     0x7f621c10bf83 (unknown)\r\n    @     0x7f621c10c2eb _Unwind_RaiseException\r\n    @     0x7f6219722beb __cxa_throw\r\n    @     0x7f61c10b7dcf paddle::framework::details::OpHandleBase::~OpHandleBase()\r\n    @     0x7f61c10a5c61 paddle::framework::details::FetchOpHandle::~FetchOpHandle()\r\n    @     0x7f61bf8ea979 paddle::framework::ir::Node::~Node()\r\n    @     0x7f61bf8eab21 paddle::framework::ir::Node::~Node()\r\n    @     0x7f61c10a779b paddle::framework::details::ClearFetchOp()\r\n    @     0x7f61c1053024 paddle::framework::details::ThreadedSSAGraphExecutor::Run()\r\n    @     0x7f61c104978a paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run()\r\n    @     0x7f61bf977c92 paddle::framework::ParallelExecutor::Run()\r\n    @     0x7f61bf82a28e _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9framework16ParallelExecutorERKSt6vectorISsSaISsEERKSsE152_vIS8_SD_SF_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESX_\r\n    @     0x7f61bf8651fe pybind11::cpp_function::dispatcher()\r\n    @           0x4c37ed PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d54b9 (unknown)\r\n    @           0x4a577e PyObject_Call\r\n    @           0x4bed3d PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d55f3 (unknown)\r\nAborted\r\n```\r\nprint 具体的label值如下：\r\n发现里面存在负数",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-03-20T04:10:33+00:00",
        "updated_at": "2019-03-20T04:10:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1910,
        "title": "icnet如何准备数据？",
        "body": "![image](https://user-images.githubusercontent.com/4484303/54680787-b56a9b00-4b45-11e9-93d2-1ca57830d72c.png)\r\n数据中这个train.list和val.list在哪里下载？工具处理是数据是运行cityscapesScripts中的createTrainIdLabelImgs.py文件就可以了吗？",
        "state": "open",
        "user": "dashulu",
        "closed_by": null,
        "created_at": "2019-03-20T11:25:41+00:00",
        "updated_at": "2019-05-07T04:32:50+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "dashulu",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1915,
        "title": "lac训练报错",
        "body": "环境：paddle为最新的develop分支编译安装的，models也是最新的develop分支。\r\n在lac文件夹下执行：python python/train.py --num_iterations=10报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/54803688-879f6680-4cab-11e9-835e-62caec5aee9f.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "Superjomn",
        "created_at": "2019-03-22T06:05:56+00:00",
        "updated_at": "2019-05-09T06:44:45+00:00",
        "closed_at": "2019-05-09T06:44:45+00:00",
        "comments_count": [
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1917,
        "title": "video NeXtVLAD stuck at training ",
        "body": "video model NeXtVLAD stuck at training process.\r\nuse official docker image:  paddlepaddle/paddle:1.3.0-gpu-cuda9.0-cudnn7\r\nGPU environment: 8 Tesla V100， driver versioin:384.81 \r\n\r\nfollowing the youtuble-8m data preprocessing and then train.\r\ntrain script:\r\n```\r\n    export CUDA_VISIBLE_DEVICES=4,5,6,7\r\n    python train.py --model-name=\"NEXTVLAD\" --config=./configs/nextvlad.txt --epoch- \r\n                 num=6  --valid-interval=1 --log-interval=1\r\n```\r\n\r\nnextvlad.txt:\r\n`    num_gpus = 4`\r\n\r\ntraining stuck log:\r\n```\r\n[INFO: train.py:  221]: Namespace(batch_size=None, config='./configs/nextvlad.txt', epoch_num=6, learning_rate=None, log_interval=1, model_name='NEXTVLAD', no_memory_optimize=False, no_use_pyreader=False, pretrain=None, resume=None, save_dir='checkpoints', use_gpu=True, valid_interval=1)\r\nW0323 03:15:33.823276  2265 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0323 03:15:33.823355  2265 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\ncur_time:1553310943.58\r\nperiod:1.50254201889\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 0  , loss = 2941.624023, Hit@1 = 0.00, PERR = 0.00, GAP = 0.00\r\ncur_time:1553310945.17\r\nperiod:0.693611860275\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 1  , loss = 2904.056396, Hit@1 = 0.00, PERR = 0.00, GAP = 0.00\r\ncur_time:1553310945.94\r\nperiod:0.621890068054\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 2  , loss = 2848.791504, Hit@1 = 0.01, PERR = 0.01, GAP = 0.00\r\ncur_time:1553310946.64\r\nperiod:0.602577924728\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 3  , loss = 2775.756592, Hit@1 = 0.03, PERR = 0.01, GAP = 0.00\r\ncur_time:1553310947.47\r\nperiod:0.574059009552\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 4  , loss = 2688.623047, Hit@1 = 0.06, PERR = 0.03, GAP = 0.01\r\ncur_time:1553310948.13\r\nperiod:0.571026086807\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 5  , loss = 2595.953613, Hit@1 = 0.08, PERR = 0.04, GAP = 0.01\r\ncur_time:1553310948.77\r\nperiod:0.997609853745\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 6  , loss = 2510.459717, Hit@1 = 0.08, PERR = 0.05, GAP = 0.02\r\ncur_time:1553310949.85\r\nperiod:0.483380794525\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 7  , loss = 2416.960205, Hit@1 = 0.07, PERR = 0.02, GAP = 0.01\r\ncur_time:1553310950.42\r\nperiod:0.460392951965\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 8  , loss = 2313.718994, Hit@1 = 0.13, PERR = 0.07, GAP = 0.03\r\ncur_time:1553310950.95\r\nperiod:0.521590948105\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 9  , loss = 2227.182129, Hit@1 = 0.10, PERR = 0.04, GAP = 0.03\r\ncur_time:1553310951.56\r\n\r\n```\r\n\r\ntrace the log,  process is stuck at \r\ntools/train_utils.py L105:   train_outs = train_exe.run(fetch_list=train_fetch_list)\r\n\r\n#############################3\r\nactually there is one strange bug happened after install docker image: \r\n    `Failed to find dynamic library: libnccl.so ( libnccl.so: cannot open shared object file: No such file or directory )`\r\ni follow solution to solve the bug. \r\n```\r\n如果在GPU版本下用单机多卡训练，可能会报找不到nccl.so的错误，解决办法如下：\r\n# 如果使用的是cuda8的环境（nvcc --version查看）\r\n# 下载NCCL库 for cuda8\r\n$ wget 10.86.69.44:8192/nccl_2.1.4-1+cuda8.0_x86_64.txz\r\n$ tar -Jxf nccl_2.1.4-1+cuda8.0_x86_64.txz\r\n$ export LD_LIBRARY_PATH=`pwd`/nccl_2.1.4-1+cuda8.0_x86_64/lib:$LD_LIBRARY_PATH\r\n  \r\n# 如果使用的是cuda9的环境\r\n# 下载NCCL库 for cuda9\r\n$ wget 10.86.69.44:8192/nccl_2.2.12-1+cuda9.0_x86_64.txz\r\n$ tar -Jxf nccl_2.2.12-1+cuda9.0_x86_64.txz\r\n$ export LD_LIBRARY_PATH=`pwd`/nccl_2.2.12-1+cuda9.0_x86_64/lib:$LD_LIBRARY_PATH\r\n```\r\n\r\ndetailed bug log is following:\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 226, in <module>\r\n    train(args)\r\n  File \"train.py\", line 171, in train\r\n    main_program=train_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 191, in __init__\r\n    local_scopes, exec_strategy, build_strategy)\r\npaddle.fluid.core.EnforceNotMet: Failed to find dynamic library: libnccl.so ( libnccl.so: cannot open shared object file: No such file or directory )\r\n Please specify its path correctly using following ways:\r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\n For instance, issue command: export LD_LIBRARY_PATH=...\r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:163]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f52bacfd8f5p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f52bacfdc79p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f52bc7ac365p paddle::platform::dynload::GetNCCLDsoHandle() + 1813\r\n3       0x7f52bae3e7e9p void std::__once_call_impl<std::_Bind_simple<decltype (ncclCommInitAll({parm#1}...)) paddle::platform::dynload::DynLoad__ncclCommInitAll::operator()<ncclComm**, int, int*>(ncclComm**, int, int*)::{lambda()#1} ()> >() + 9\r\n4       0x7f5332f6ba99p\r\n5       0x7f52bae41c1dp paddle::platform::NCCLContextMap::NCCLContextMap(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, ncclUniqueId*, unsigned long, unsigned long) + 2093\r\n6       0x7f52bae3d952p paddle::framework::ParallelExecutor::ParallelExecutor(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, paddle::framework::ProgramDesc const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&) + 3922\r\n7       0x7f52bad5b098p\r\n8       0x7f52bad291fep\r\n9             0x4eef5ep\r\n10            0x4eeb66p\r\n11            0x4aaafbp\r\n12            0x4c166dp PyEval_EvalFrameEx + 22413\r\n13            0x4b9b66p PyEval_EvalCodeEx + 774\r\n14            0x4d57a3p\r\n15            0x4eef5ep\r\n16            0x4eeb66p\r\n17            0x4aaafbp\r\n18            0x4c166dp PyEval_EvalFrameEx + 22413\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n21            0x4b9b66p PyEval_EvalCodeEx + 774\r\n22            0x4eb69fp\r\n23            0x4e58f2p PyRun_FileExFlags + 130\r\n24            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n25            0x4938cep Py_Main + 1358\r\n26      0x7f5332bb3830p __libc_start_main + 240\r\n27            0x493299p _start + 41\r\n```\r\n\r\nCould anyone help me to solve the stuck problem?",
        "state": "closed",
        "user": "Haijunlv",
        "closed_by": "Haijunlv",
        "created_at": "2019-03-23T03:37:33+00:00",
        "updated_at": "2019-03-23T12:23:16+00:00",
        "closed_at": "2019-03-23T12:23:16+00:00",
        "comments_count": [
            "fc500110"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1919,
        "title": "why the net don't have any active function in googlenet.py in backbone?",
        "body": "for example:\r\n...        \r\nconv = self.conv_layer(\r\n            input=pool, num_filters=64, filter_size=1, stride=1, act=None)\r\nconv = self.conv_layer(\r\n            input=conv, num_filters=192, filter_size=3, stride=1, act=None)\r\n...",
        "state": "closed",
        "user": "wang-kangkang",
        "closed_by": "shippingwang",
        "created_at": "2019-03-26T02:16:51+00:00",
        "updated_at": "2019-04-12T07:25:03+00:00",
        "closed_at": "2019-04-12T07:25:03+00:00",
        "comments_count": [
            "SunGaofeng",
            "shippingwang",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1921,
        "title": "object detection使用最新develop分支源码编译paddle训练报错",
        "body": "环境：使用develop分支，编译安装paddle；\r\n调用训练指令：python -u train.py --batch_size=64 --dataset='pascalvoc' --pretrained_model='pretrained/ssd_mobilenet_v1_coco/' --epoc_num=1 \r\n报错信息如下：\r\n<img width=\"992\" alt=\"1429eff7a9de8f8e2941cb6574b0ab81\" src=\"https://user-images.githubusercontent.com/37854899/54974812-3d322880-4fd0-11e9-964c-6f6def339292.png\">\r\n具体log见附件，paddle==1.3.0、paddle==1.3.1可以正常训练。\r\n[object_detection.log](https://github.com/PaddlePaddle/models/files/3006725/object_detection.log)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "junjun315",
        "created_at": "2019-03-26T06:11:06+00:00",
        "updated_at": "2019-04-03T08:09:34+00:00",
        "closed_at": "2019-04-03T08:09:34+00:00",
        "comments_count": [
            "JiaXiao243",
            "SunGaofeng",
            "JiaXiao243",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1924,
        "title": "PyramidBox face_detection: is it possible to transpile to float16?",
        "body": "I have seen multiple references in PaddlePaddle code to transpiling to float16 with gains on Volta GPUs. This out of date doc gives instructions but I can't find anything for recent versions:\r\nhttp://www.paddlepaddle.org/documentation/docs/en/1.3/design/data_type/float16.html\r\n\r\nI don't know Chinese but it seems as though the feature has been removed or moved. Is it possible to convert the face detector and will it be faster?\r\n",
        "state": "open",
        "user": "colojaro",
        "closed_by": null,
        "created_at": "2019-03-27T04:53:50+00:00",
        "updated_at": "2019-03-27T12:19:05+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1929,
        "title": "PaddlePaddle从源码编译Ngraph问题和建议",
        "body": "系统：Ubuntu16.04\r\n[Ngraph文档](https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/image_classification/README_ngraph.md)中的编译语句\r\n\r\n```shell\r\ncmake ..  -DCMse -DWITH_GPU=OFF -DWITH_MKL=ON -DWITH_MKLDNN=ON  -DWITH_NGRAPH=ON\r\n```\r\n\r\n建议修改成：\r\n```shell\r\ncmake .. -DPY_VERSION=3.6 -DCMse -DWITH_GPU=OFF -DWITH_MKL=ON -DWITH_MKLDNN=ON  -DWITH_NGRAPH=ON\r\n# DPY_VERSION=3.6（python的版本）\r\n```",
        "state": "closed",
        "user": "OliverLPH",
        "closed_by": "OliverLPH",
        "created_at": "2019-03-27T10:39:36+00:00",
        "updated_at": "2019-03-28T01:52:37+00:00",
        "closed_at": "2019-03-28T01:52:37+00:00",
        "comments_count": [
            "OliverLPH",
            "qingqing01",
            "tensor-tang",
            "tensor-tang",
            "OliverLPH",
            "OliverLPH"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1935,
        "title": "GNN 模型问题汇总",
        "body": "1. 数据处理部分\r\n- 执行` python preprocess.py` 问题：\r\n  ```bash\r\n   Namespace(dataset='sample')\r\n   -- Starting @ 2019-03-28 05:49:51.411397s\r\n   Traceback (most recent call last):\r\n   File \"preprocess.py\", line 32, in <module>\r\n       with open(dataset, \"r\") as f:\r\n   IOError: [Errno 2] No such file or directory: 'sample_train-item-views.csv'\r\n  ```\r\n2. 模型训练部分\r\n- python3 下报错：\r\n  ```bash\r\n  Traceback (most recent call last):\r\n  File \"train.py\", line 131, in <module>\r\n    train()\r\n  File \"train.py\", line 111, in train\r\n    for data in data_reader.reader(batch_size, batch_size * 20, True):\r\n  File \"/home/crim/models/fluid/PaddleRec/gnn/reader.py\", line 93, in reader\r\n    random.shuffle(self.input)\r\n  File \"/opt/_internal/cpython-3.5.1/lib/python3.5/random.py\", line 269, in shuffle\r\n    for i in reversed(range(1, len(x))):\r\n  TypeError: object of type 'zip' has no len()\r\n  ```\r\n3. infer部分\r\n- infer模型文件夹建议用try.. except包起来：\r\n  ```bash\r\n  Traceback (most recent call last):\r\n  File \"infer.py\", line 75, in <module>\r\n    infer(index)\r\n  File \"infer.py\", line 54, in infer\r\n    model_path, exe)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 1078, in \r\n   load_inference_model\r\n    raise ValueError(\"There is no directory named '%s'\", dirname)\r\n    ValueError: (\"There is no directory named '%s'\", './saved_model/epoch_5')\r\n  ```\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-03-28T05:52:55+00:00",
        "updated_at": "2019-03-29T07:31:18+00:00",
        "closed_at": "2019-03-29T07:31:18+00:00",
        "comments_count": [
            "hutuxian",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1934,
        "title": "DIN 模型问题汇总",
        "body": "**1、数据处理部分**\r\n+ convert_pd.py 脚本依赖pandas，部分用户没有安装会报错，请给出提示；\r\n+  python2.7 下`remap_id.py` 脚本执行报错如下:\r\n    ```bash\r\n   File \"remap_id.py\", line 4\r\n    from __future__ import print_function\r\n   SyntaxError: from __future__ imports must occur at the beginning of the file\r\n   ```\r\n+ conver_pd 脚本在执行过程中，时间稍长，建议加入提示；\r\n+ python2.7 下 `build_dataset.py` 同样存在 `from __future__ import print_function`的问题；\r\n\r\n**2、数据处理部分**\r\n+ 训练超出一定的epoch 后会出现过拟合，建议给出说明\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-03-28T03:33:54+00:00",
        "updated_at": "2019-03-29T07:30:48+00:00",
        "closed_at": "2019-03-29T07:30:48+00:00",
        "comments_count": [
            "hutuxian",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1936,
        "title": " video NeXtVLAD training error",
        "body": "video model NeXtVLAD training process get one errer. it happens when model validate after one epoch training.  \r\nI tried to use same train and valid data to debug whether data is broken or not. And found eror always happen at the first epoch validatation.\r\nI have not modified any mian process code. Just try to train!\r\nHope someone can help me!\r\n\r\nenviroment\r\n    use official docker image: paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7\r\n    GPU environment: 8 Tesla V100， driver versioin:384.81\r\n\r\nfollowing the youtuble-8m data preprocessing and then train.\r\ntrain script:\r\n`    export CUDA_VISIBLE_DEVICES=4,5,6,7\r\n    python train.py --model-name=\"NEXTVLAD\" --config=./configs/nextvlad.txt --epoch- \r\n                 num=6  --valid-interval=1 --log-interval=1`\r\nin nextvlad.txt:\r\n`num_gpus = 4`\r\n\r\n\r\nerror log:\r\n`file path:/home/lvhaijun/dataset/youtube-8m/frame/pkl/train/train3581.pkl\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24299  , loss = 4.340643, Hit@1 = 0.88, PERR = 0.79, GAP = 0.84\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24300  , loss = 4.450137, Hit@1 = 0.86, PERR = 0.76, GAP = 0.82\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24301  , loss = 4.025729, Hit@1 = 0.82, PERR = 0.75, GAP = 0.83\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24302  , loss = 4.144448, Hit@1 = 0.84, PERR = 0.72, GAP = 0.82\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24303  , loss = 4.669774, Hit@1 = 0.88, PERR = 0.78, GAP = 0.82\r\n[INFO: metrics_util.py:   68]: [TRAIN] Epoch 0, iter 24304  , loss = 3.699670, Hit@1 = 0.93, PERR = 0.81, GAP = 0.86\r\n[INFO: train_utils.py:  122]: [TRAIN] Epoch 0 training finished, average time: 0.519670748235\r\nfile path:/home/lvhaijun/dataset/youtube-8m/frame/pkl/train/train0000.pkl\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 226, in <module>\r\n    train(args)\r\n  File \"train.py\", line 216, in train\r\n    test_fetch_list = valid_fetch_list, test_metrics = valid_metrics)\r\n  File \"/home/lvhaijun/video_recognition/utils_project/paddle-model/models/fluid/PaddleCV/video/tools/train_utils.py\", line 127, in train_with_pyreader\r\n    test_metrics, log_interval)\r\n  File \"/home/lvhaijun/video_recognition/utils_project/paddle-model/models/fluid/PaddleCV/video/tools/train_utils.py\", line 43, in test_with_pyreader\r\n    test_outs = test_exe.run(fetch_list=test_fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 192, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 543, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 444, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetched variable(sigmoid_0.tmp_0).(Perhaps the main_program is not set to ParallelExecutor) at [/paddle/paddle/fluid/framework/details/threaded_ssa_graph_executor.cc:142]\r\nPaddlePaddle Call Stacks:\r\n                                                                                                      28181,1       99%\r\npaddle.fluid.core.EnforceNotMet: Cannot find fetched variable(sigmoid_0.tmp_0).(Perhaps the main_program is not set to ParallelExecutor) at [/paddle/paddle/fluid/framework/details/threaded_ssa_graph_executor.cc:142]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f507444cf50p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f507444d2c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f5075d6707fp paddle::framework::details::ThreadedSSAGraphExecutor::InsertFetchOps(std::vector<std::string, std::allocator<std::string> > const&, std::vector<paddle::framework::details::FetchOpHandle*, std::allocator<paddle::framework::details::FetchOpHandle*> >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, std::unordered_set<paddle::framework::details::OpHandleBase*, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<paddle::framework::details::OpHandleBase*> >*, std::unordered_map<paddle::framework::details::OpHandleBase*, unsigned long, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<std::pair<paddle::framework::details::OpHandleBase* const, unsigned long> > >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*) + 5119\r\n3       0x7f5075d67632p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 1106\r\n4       0x7f5075d5818ap paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 394\r\n5       0x7f5074596072p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 562\r\n6       0x7f507443cc7ep\r\n7       0x7f507447362ep\r\n8             0x4c5326p PyEval_EvalFrameEx + 37958\r\n9             0x4b9b66p PyEval_EvalCodeEx + 774\r\n10            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n11            0x4b9b66p PyEval_EvalCodeEx + 774\r\n12            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n13            0x4b9b66p PyEval_EvalCodeEx + 774\r\n14            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n15            0x4b9b66p PyEval_EvalCodeEx + 774\r\n16            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n17            0x4b9b66p PyEval_EvalCodeEx + 774\r\n18            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n21            0x4b9b66p PyEval_EvalCodeEx + 774\r\n22            0x4eb69fp\r\n23            0x4e58f2p PyRun_FileExFlags + 130\r\n24            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n25            0x4938cep Py_Main + 1358\r\n26      0x7f50f1e69830p __libc_start_main + 240\r\n27            0x493299p _start + 41\r\n                                                                                                      28180,1       99%\r\nPaddlePaddle Call Stacks:\r\n0       0x7f507444cf50p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f507444d2c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f5075d6707fp paddle::framework::details::ThreadedSSAGraphExecutor::InsertFetchOps(std::vector<std::string, std::allocator<std::string> > const&, std::vector<paddle::framework::details::FetchOpHandle*, std::allocator<paddle::framework::details::FetchOpHandle*> >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, std::unordered_set<paddle::framework::details::OpHandleBase*, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<paddle::framework::details::OpHandleBase*> >*, std::unordered_map<paddle::framework::details::OpHandleBase*, unsigned long, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<std::pair<paddle::framework::details::OpHandleBase* const, unsigned long> > >*, std::unordered_set<paddle::framework::details::VarHandleBase*, std::hash<paddle::framework::details::VarHandleBase*>, std::equal_to<paddle::framework::details::VarHandleBase*>, std::allocator<paddle::framework::details::VarHandleBase*> >*, std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*) + 5119\r\n3       0x7f5075d67632p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 1106\r\n4       0x7f5075d5818ap paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 394\r\n5       0x7f5074596072p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 562\r\n6       0x7f507443cc7ep\r\n7       0x7f507447362ep\r\n8             0x4c5326p PyEval_EvalFrameEx + 37958\r\n9             0x4b9b66p PyEval_EvalCodeEx + 774\r\n10            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n11            0x4b9b66p PyEval_EvalCodeEx + 774\r\n12            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n13            0x4b9b66p PyEval_EvalCodeEx + 774\r\n14            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n15            0x4b9b66p PyEval_EvalCodeEx + 774\r\n16            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n17            0x4b9b66p PyEval_EvalCodeEx + 774\r\n18            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n21            0x4b9b66p PyEval_EvalCodeEx + 774\r\n22            0x4eb69fp\r\n23            0x4e58f2p PyRun_FileExFlags + 130\r\n24            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n25            0x4938cep Py_Main + 1358\r\n26      0x7f50f1e69830p __libc_start_main + 240\r\n27            0x493299p _start + 41`",
        "state": "open",
        "user": "Haijunlv",
        "closed_by": null,
        "created_at": "2019-03-28T11:15:28+00:00",
        "updated_at": "2019-03-29T04:15:28+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1937,
        "title": "sequence_conv_pool卷积实现逻辑？",
        "body": "如果我的特征是：\r\n[a1,b1,c1,d1,e1] \r\n[a2,b2,c2,d2,e2] \r\n[a3,b3,c3,d3,e3]\r\n\r\n1） 每一个单词映射成10维，如果我想用sequence_conv_pool进行卷积，那么我的win_size = len(a1,b1,...e1) = 5 * 10(embedding) = 50？？\r\n\r\n2） sequence_conv_pool是 ID进行横向3* 3的卷积吗？（假设窗口为3）",
        "state": "open",
        "user": "ylxsyf",
        "closed_by": null,
        "created_at": "2019-03-28T12:55:52+00:00",
        "updated_at": "2019-03-29T09:19:28+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "ylxsyf"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1941,
        "title": "word2vec 测试问题汇总",
        "body": "**1. 数据预处理部分:**\r\n- 路径部分请os.path.join(), 否则输出会多了 ‘/’\r\nhttps://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleRec/word2vec/preprocess.py#L110\r\nhttps://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleRec/word2vec/preprocess.py#L150\r\n\r\n  ```\r\n  build dict :  data/text//text8\r\n  ```\r\n**2. 训练部分：**\r\n- python3.5 下报错：\r\n ```bash\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 228, in <module>\r\n    train(args)\r\n  File \"train.py\", line 198, in train\r\n    filelist, 0, 1)\r\n  File \"/home/crim/models/fluid/PaddleRec/word2vec/reader.py\", line 79, in __init__\r\n    self.dict_size)) + \" word_all_count = \" + str(word_all_count)\r\n  TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\r\n  ```\r\n- 小数据训练报维度不匹配\r\n```bash\r\nwrite word2id file to : data/test_build_dict_word_to_id_\r\n('corpus_size:', 17005207)\r\ndict_size = 63642 word_all_count = 17005207\r\nCPU_NUM:5\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 228, in <module>\r\n    train(args)\r\n  File \"train.py\", line 223, in train\r\n    id_frequencys_pow)\r\n  File \"train.py\", line 151, in train_loop\r\n    loss_val = train_exe.run(fetch_list=[loss.name])\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator elementwise_add error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 56, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 8843, in _elementwise_op\r\n    'use_mkldnn': use_mkldnn})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 8884, in elementwise_add\r\n    return _elementwise_op(LayerHelper('elementwise_add', **locals()))\r\n  File \"/home/crim/models/fluid/PaddleRec/word2vec/net.py\", line 106, in skip_gram_word2vec\r\n    neg_xent, dim=1))\r\n  File \"train.py\", line 208, in train\r\n    neg_num=args.nce_num)\r\n  File \"train.py\", line 228, in <module>\r\n    train(args)\r\nC++ Callstacks: \r\nEnforce failed. Expected x_dims[i + axis] == y_dims[i], but received x_dims[i + axis]:1 != y_dims[i]:100.\r\nBroadcast dimension mismatch. at [/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:63]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fcec43777bdp void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 365\r\n1       0x7fcec4377b07p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fcec46a0fb0p paddle::operators::get_mid_dims(paddle::framework::DDim const&, paddle::framework::DDim const&, int, int*, int*, int*) + 400\r\n3       0x7fcec4e6d908p void paddle::operators::ElementwiseComputeEx<paddle::operators::AddFunctor<float>, paddle::platform::CPUDeviceContext, float, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, int, paddle::operators::AddFunctor<float>, paddle::framework::Tensor*) + 792\r\n4       0x7fcec4e713d9p paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 473\r\n5       0x7fcec4e718c3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n6       0x7fcec5390953p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 659\r\n7       0x7fcec538f47bp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 267\r\n8       0x7fcec5203353p\r\n9       0x7fcec5202fecp paddle::framework::details::ComputationOpHandle::RunImpl() + 124\r\n10      0x7fcec51fd16cp paddle::framework::details::OpHandleBase::Run(bool) + 28\r\n11      0x7fcec51e7d9ap\r\n12      0x7fcec4ba19a3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n13      0x7fcec4b6a697p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n14      0x7fcedcf7ba99p\r\n15      0x7fcec51e6b92p\r\n16      0x7fcec4b6bac4p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n17      0x7fced53d17e0p\r\n18      0x7fcedcf746bap\r\n19      0x7fcedccaa41dp clone + 109\r\n```\r\n\r\n- 给出要想复现论文结果的必备配置提示，embedding_size=300\r\n\r\n3. infer 问题\r\n- fluid.io.load_params代码建议用```try.. except..```包起来\r\n4. 文档易用性：\r\n全量数据集给出组织结构，并且和文档中的命令对应其来\r\n5. 多机运行失败\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"cluster_train.py\", line 250, in <module>\r\n    train(args)\r\n  File \"cluster_train.py\", line 202, in train\r\n    if not os.path.isdir(args.model_output_dir) and args.train_id == 0:\r\nAttributeError: 'Namespace' object has no attribute 'train_id'\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "frankwhzhang",
        "created_at": "2019-03-29T09:38:42+00:00",
        "updated_at": "2019-04-03T08:24:19+00:00",
        "closed_at": "2019-04-03T06:13:20+00:00",
        "comments_count": [
            "frankwhzhang",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1946,
        "title": "使用rcnn代码测试图片会出现”Cannot malloc 382.813 MB GPU memory“",
        "body": "使用训练后的faster rcnn模型对图像进行检测时，若图像的长边大于某个值时（1900左右）会出现以下问题，小于这个值则能正常对图像进行检测。同时，如果每次exe.run的时候如果feed多张图像，也会出现这样的问题。\r\n已经使用了”export CUDA_VISIBLE_DEVICES=3“，但是报错仍未在“device: 0”。\r\n```\r\nW0401 09:56:19.963274 30457 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0401 09:56:19.963361 30457 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0401 09:56:19.963380 30457 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nW0401 09:56:22.391635 30457 system_allocator.cc:122] Cannot malloc 382.813 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use environment variable to a lower value. Current value is 0\r\nW0401 09:56:22.391923 30457 legacy_allocator.cc:191] Cannot allocate 382.812500MB in GPU 0, available 177.562500MB\r\nW0401 09:56:22.391957 30457 legacy_allocator.cc:194] total 11996954624\r\nW0401 09:56:22.391997 30457 legacy_allocator.cc:195] GpuMinChunkSize 256.000000B\r\nW0401 09:56:22.392019 30457 legacy_allocator.cc:198] GpuMaxChunkSize 0.000000B\r\nW0401 09:56:22.392050 30457 legacy_allocator.cc:201] GPU memory used: 0.000000B\r\nTraceback (most recent call last):\r\n  File \"infer2.py\", line 117, in <module>\r\n    infer()\r\n  File \"infer2.py\", line 98, in infer\r\n    return_numpy=False)\r\n  File \"/home/XX/anaconda3/envs/icaffe/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 525, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/XX/anaconda3/envs/icaffe/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 591, in _run\r\n    exe.run(program.desc, scope, 0, True, True)\r\nRuntimeError: parallel_for failed: out of memory\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  cudaFree{Host} failed in GPUAllocator::Free.: an illegal memory access was encountered at [/paddle/paddle/fluid/memory/detail/system_allocator.cc:150]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f764b67a885p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f764b67ac09p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f764d13b7abp paddle::memory::detail::GPUAllocator::Free(void*, unsigned long, unsigned long) + 187\r\n3       0x7f764d139852p paddle::memory::detail::BuddyAllocator::Free(void*) + 1122\r\n4       0x7f764d135177p void paddle::memory::legacy::Free<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, void*, unsigned long) + 39\r\n5       0x7f764d1351edp paddle::memory::allocation::LegacyAllocator::Free(paddle::memory::allocation::Allocation*) + 77\r\n6       0x7f764b67d2d9p std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() + 57\r\n7       0x7f764b67e308p paddle::framework::Variable::PlaceholderImpl<paddle::framework::LoDTensor>::~PlaceholderImpl() + 56\r\n8       0x7f764d0da49dp paddle::framework::Scope::~Scope() + 157\r\n9       0x7f764d0da3b1p paddle::framework::Scope::DropKids() + 65\r\n10      0x7f764d0da41dp paddle::framework::Scope::~Scope() + 29\r\n11      0x7f764b7d1306p paddle::framework::ScopePool::DeleteScope(paddle::framework::Scope*) + 22\r\n12      0x7f764b7d1361p paddle::framework::ScopePool::Clear() + 65\r\n13      0x7f767b1343e0p\r\n14      0x7f767b1d2112p\r\n15      0x7f767b2950abp\r\n16      0x7f767b1d79a4p\r\n17      0x7f767b2e032ap _PyGC_CollectNoFail + 42\r\n18      0x7f767b2700c0p PyImport_Cleanup + 608\r\n19      0x7f767b2e03a6p Py_Finalize + 86\r\n20      0x7f767b2f15c1p Py_Main + 897\r\n21      0x7f767b1bb571p main + 225\r\n22      0x7f767a901b45p __libc_start_main + 245\r\n23      0x7f767b293f38p\r\n\r\n*** Aborted at 1554083783 (unix time) try \"date -d @1554083783\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1ff000076f9) received by PID 30457 (TID 0x7f767b0c1740) from PID 30457; stack trace: ***\r\n    @     0x7f767acb0130 (unknown)\r\n    @     0x7f767a9159d9 __GI_raise\r\n    @     0x7f767a9170e8 __GI_abort\r\n    @     0x7f76666c93df __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f76666c7b16 __cxxabiv1::__terminate()\r\n    @     0x7f76666c6f91 __cxa_call_terminate\r\n    @     0x7f76666c779d __gxx_personality_v0\r\n    @     0x7f7672f3cf56 _Unwind_RaiseException_Phase2\r\n    @     0x7f7672f3d3e9 _Unwind_Resume\r\n    @     0x7f764d139ba5 paddle::memory::detail::BuddyAllocator::Free()\r\n    @     0x7f764d135177 paddle::memory::legacy::Free<>()\r\n    @     0x7f764d1351ed paddle::memory::allocation::LegacyAllocator::Free()\r\n    @     0x7f764b67d2d9 std::_Sp_counted_base<>::_M_release()\r\n    @     0x7f764b67e308 paddle::framework::Variable::PlaceholderImpl<>::~PlaceholderImpl()\r\n    @     0x7f764d0da49d paddle::framework::Scope::~Scope()\r\n    @     0x7f764d0da3b1 paddle::framework::Scope::DropKids()\r\n    @     0x7f764d0da41d paddle::framework::Scope::~Scope()\r\n    @     0x7f764b7d1306 paddle::framework::ScopePool::DeleteScope()\r\n    @     0x7f764b7d1361 paddle::framework::ScopePool::Clear()\r\n    @     0x7f767b1343e0 capsule_dealloc.cold.413\r\n    @     0x7f767b1d2112 dict_dealloc\r\n    @     0x7f767b2950ab module_clear\r\n    @     0x7f767b1d79a4 collect\r\n    @     0x7f767b2e032a _PyGC_CollectNoFail\r\n    @     0x7f767b2700c0 PyImport_Cleanup\r\n    @     0x7f767b2e03a6 Py_Finalize\r\n    @     0x7f767b2f15c1 Py_Main\r\n    @     0x7f767b1bb571 main\r\n    @     0x7f767a901b45 __libc_start_main\r\n    @     0x7f767b293f38 (unknown)\r\nAborted\r\n```\r\n",
        "state": "open",
        "user": "SunAhong1993",
        "closed_by": null,
        "created_at": "2019-04-01T02:16:59+00:00",
        "updated_at": "2019-04-02T13:05:44+00:00",
        "closed_at": null,
        "comments_count": [
            "cjt222",
            "jerrywgz",
            "SunAhong1993",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1956,
        "title": "yolov",
        "body": "",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "shippingwang",
        "created_at": "2019-04-01T12:16:54+00:00",
        "updated_at": "2019-04-01T12:23:26+00:00",
        "closed_at": "2019-04-01T12:23:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1952,
        "title": "dc_gan模型训练出来之后，如何对比两个模型的效果？",
        "body": "fluid/PaddleCV/gan/dc_gan模型训练后，得到一系列d-loss和dg-loss以及output目录生成一系列图片，如何对比两个gan模型的效果?",
        "state": "open",
        "user": "dashulu",
        "closed_by": null,
        "created_at": "2019-04-01T09:08:22+00:00",
        "updated_at": "2019-04-01T10:42:07+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "dashulu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1955,
        "title": "yolov3.py中的grscore和use_label_smooth在原函数中未定义，是否应该注释掉？",
        "body": "￼\r\n<img width=\"867\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/55326666-e1c5d600-54ba-11e9-89ae-967e2ad0d4bb.png\">\r\n\r\n￼\r\n<img width=\"611\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/55326686-f013f200-54ba-11e9-937a-ff4c2ca4a91f.png\">\r\n\r\n￼",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "heavengate",
        "created_at": "2019-04-01T12:16:03+00:00",
        "updated_at": "2019-04-03T03:16:08+00:00",
        "closed_at": "2019-04-03T03:16:08+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1957,
        "title": "yolov3中Reader.py中96行和123行中，python3已经遗弃了has_key，会造成python2和python3的不兼容",
        "body": "",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "heavengate",
        "created_at": "2019-04-01T12:17:02+00:00",
        "updated_at": "2019-04-04T02:26:47+00:00",
        "closed_at": "2019-04-04T02:26:47+00:00",
        "comments_count": [
            "cjt222",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1958,
        "title": "yolov3加载darknet53去从头训练时，默认学习率0.001会出现NAN，把初始学习率调为0.0001后很难收敛。",
        "body": "yolov3加载darknet53去从头训练时，默认学习率0.001会出现NAN，把初始学习率调为0.0001后很难收敛，这是什么原因呢？",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "gongweibao",
        "created_at": "2019-04-01T12:35:54+00:00",
        "updated_at": "2019-04-02T12:01:39+00:00",
        "closed_at": "2019-04-02T12:01:39+00:00",
        "comments_count": [
            "heavengate",
            "heavengate",
            "cjt222",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1959,
        "title": "ssd算法中的infer.py中的类别数应为81类，而不是91类",
        "body": "<img width=\"567\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/55328010-fd7eab80-54bd-11e9-9546-bd7050012a08.png\">\r\nssd算法中的infer.py中的类别数应为81类，而不是91类",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "qingqing01",
        "created_at": "2019-04-01T12:38:09+00:00",
        "updated_at": "2019-04-03T13:23:23+00:00",
        "closed_at": "2019-04-03T13:23:23+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1961,
        "title": "deeplabv3+的train.py中，下面的变量卖弄未定义",
        "body": "当把命令行中的parallel改为False后，会直接跑单进程，下面的main变量会显示无定义变量，查看了下，之前确实没有定义过这个变量。\r\n![image](https://user-images.githubusercontent.com/17508662/55374443-06fa2900-553b-11e9-8487-a180eedfbb27.png)\r\n\r\n",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "qingqing01",
        "created_at": "2019-04-02T03:32:55+00:00",
        "updated_at": "2019-04-02T12:08:58+00:00",
        "closed_at": "2019-04-02T12:08:58+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1964,
        "title": "metric learning易用性汇总",
        "body": "1.句子不通顺\r\n![image](https://user-images.githubusercontent.com/37854899/55381215-1edea680-5555-11e9-8925-175e22b5ecc2.png)\r\n2.安装文档链接出错\r\n![image](https://user-images.githubusercontent.com/37854899/55381234-2f8f1c80-5555-11e9-8e2f-ffc874603b0c.png)\r\n![image](https://user-images.githubusercontent.com/37854899/55381237-328a0d00-5555-11e9-9b0a-14395792da03.png)\r\n3. 建议对infer.py输出的log进行优化，不简洁，表述不清；\r\n  \r\n![image](https://user-images.githubusercontent.com/37854899/55381330-7715a880-5555-11e9-9fa9-d84760872058.png)\r\n4. 建议模型训练部分添加ResNet50预训练模型的下载链接，并在文档中添加加载ResNet50预训练模型的表述。在加载ResNet50预训练模型前提下，使用默认超参数设置，才能达到文档中描述的Recall@Rank-1数值。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-04-02T06:51:24+00:00",
        "updated_at": "2019-04-08T04:40:04+00:00",
        "closed_at": "2019-04-08T04:40:04+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1963,
        "title": "可否基于树莓派实现paddlepaddle？",
        "body": "请问可否实现基于树莓派的paddlepaddle程序？如果可以，可否提供案例？",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-04-02T06:50:48+00:00",
        "updated_at": "2019-04-04T00:28:40+00:00",
        "closed_at": null,
        "comments_count": [
            "gongweibao",
            "qianledan"
        ],
        "labels": [
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1962,
        "title": "官网图像分类VGG16例子训练碰到问题",
        "body": "python train.py \\\r\n        --model=VGG16 \\\r\n        --batch_size=64 \\\r\n        --total_images=50000 \\\r\n        --class_dim=10 \\\r\n        --image_shape=3,32,32 \\\r\n        --model_save_dir=output/ \\\r\n        --with_mem_opt=True \\\r\n        --lr_strategy=other \\\r\n        --lr=0.001 \\\r\n        --num_epochs=120 \\\r\n        --l2_decay=1.2e-4 \\\r\n        --model_category=models_name \\\r\n\r\n官网中跑ImagNet数据集，我修改为Cifar10数据集跑VGG16 ，其中        \r\noptimizer = fluid.optimizer.Momentum(\r\n            learning_rate=lr,\r\n            momentum=momentum_rate,\r\n            regularization=fluid.regularizer.L2Decay(l2_decay))\r\n设置120pass，大概在20多个pass，loss值接近0，acc为1。。。找不出问题在哪里？请问该实例只能用于ImageNet数据集的训练吗？\r\n![QQ浏览器截图20190402144329](https://user-images.githubusercontent.com/45925696/55381480-e12e4d80-5555-11e9-9d00-5c9b2b9ee558.png)\r\n",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "shippingwang",
        "created_at": "2019-04-02T06:45:06+00:00",
        "updated_at": "2019-04-12T07:20:08+00:00",
        "closed_at": "2019-04-12T07:20:07+00:00",
        "comments_count": [
            "shippingwang",
            "qianledan",
            "shippingwang",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1975,
        "title": "图像分类在ILSVRC2012数据集缺少train_list.txt的情况下运行，程序占用显存，无法正常退出",
        "body": "环境：centos环境下，develop分支编译的paddle；\r\n预置条件：官方ILSVRC2012数据集删去train_list.txt；\r\n运行指令 python train.py --model=SE_ResNeXt50_32x4d --num_epochs=10\r\n预期结果：log中显示报错信息，程序正常退出；\r\n实际结果：log中显示报错信息，程序没有退出，占用显存，GPU利用率为0；\r\nlog信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/55468230-853af600-5635-11e9-934e-3bcbd22b9327.png)\r\n训练使用P40,4卡跑的训练，占用GPU 0，1，2，3\r\n![image](https://user-images.githubusercontent.com/37854899/55468273-9e43a700-5635-11e9-8315-2e68f0b620ad.png)\r\n![image](https://user-images.githubusercontent.com/37854899/55468279-a26fc480-5635-11e9-81e4-a1fb464aaaed.png)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-04-03T09:27:36+00:00",
        "updated_at": "2019-04-12T07:20:42+00:00",
        "closed_at": "2019-04-12T07:20:42+00:00",
        "comments_count": [
            "shippingwang",
            "JiaXiao243",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1986,
        "title": "PaddleRec/gnn模型cpu训练出错",
        "body": "python 2.7\r\ncuda 9.0 cudnn7.0\r\n\r\npython -u train.py --use_cuda 0 --epoch_num 1\r\n\r\npaddle fluid1.2报错\r\n\r\n2019-04-04 17:10:35,841 - INFO - load data complete\r\n2019-04-04 17:10:37,749 - INFO - begin train\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 131, in <module>\r\n    train()\r\n  File \"train.py\", line 113, in train\r\n    fetch_list=[loss.name, acc.name])\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 301, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:0 != -in_size:-6000.\r\nInvalid shape is given. at [/paddle/paddle/fluid/operators/reshape_op.cc:98]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f94250d76edp void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 365\r\n1       0x7f94250d7a37p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f9425486729p paddle::operators::ReshapeOp::ValidateShape(std::vector<int, std::allocator<int> >, paddle::framework::DDim const&) + 2249\r\n3       0x7f9425487e91p paddle::operators::ReshapeOp::InferShape(paddle::framework::InferShapeContext*) const + 689\r\n4       0x7f94254885a9p paddle::operators::Reshape2Op::InferShape(paddle::framework::InferShapeContext*) const + 521\r\n5       0x7f9426b9815fp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 607\r\n6       0x7f9426b962b5p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 341\r\n7       0x7f9426a0c7c9p\r\n8       0x7f9426a04c71p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 769\r\n9       0x7f9426a0c45cp paddle::framework::details::ComputationOpHandle::RunImpl() + 124\r\n10      0x7f9426a05bb6p paddle::framework::details::OpHandleBase::Run(bool) + 118\r\n11      0x7f942699dfbdp\r\n12      0x7f9425d5abe3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n13      0x7f9425d1df07p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n14      0x7f945c49fbe0p pthread_once + 80\r\n15      0x7f942699cca2p\r\n16      0x7f9425d1f334p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n17      0x7f94421eb678p\r\n18      0x7f945c49adf3p\r\n19      0x7f945babf2cdp clone + 109\r\n\r\n\r\npaddle develop 报错\r\n\r\n2019-04-04 17:19:39,193-INFO: load data complete\r\nParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\nW0404 17:19:39.320032 16823 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nI0404 17:19:41.131080 16823 build_strategy.cc:289] SeqOnlyAllReduceOps:0, num_trainers:1\r\n2019-04-04 17:19:41,270-INFO: begin train\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 131, in <module>\r\n    train()\r\n  File \"train.py\", line 113, in train\r\n    fetch_list=[loss.name, acc.name])\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 199, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 544, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 445, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator reshape2 error.\r\nPython Callstacks:\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1663, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/paddle/anaconda2/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 6409, in reshape\r\n    \"XShape\": x_shape})\r\n  File \"/home/paddle/zhengya01/paddle-ce/local_model/gnn/network.py\", line 72, in network\r\n    x=pre_state, shape=[batch_size, -1, hidden_size])\r\n  File \"train.py\", line 66, in train\r\n    args.step)\r\n  File \"train.py\", line 131, in <module>\r\n    train()\r\nC++ Callstacks:\r\nEnforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:0 != -in_size:-7400.\r\nInvalid shape is given. at [/paddle/paddle/fluid/operators/reshape_op.cc:101]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fd373541338p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7fd373541687p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fd373af1334p paddle::operators::ReshapeOp::ValidateShape(std::vector<int, std::allocator<int> >, paddle::framework::DDim const&) + 1956\r\n3       0x7fd373af3131p paddle::operators::ReshapeOp::InferShape(paddle::framework::InferShapeContext*) const + 689\r\n4       0x7fd373af3849p paddle::operators::Reshape2Op::InferShape(paddle::framework::InferShapeContext*) const + 521\r\n5       0x7fd3751e7365p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 613\r\n6       0x7fd3751e7b24p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 292\r\n7       0x7fd3751e543cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n8       0x7fd374ff8639p\r\n9       0x7fd374feb0f5p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 773\r\n10      0x7fd374ff82ccp paddle::framework::details::ComputationOpHandle::RunImpl() + 124\r\n11      0x7fd374feb400p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n12      0x7fd374f5398dp\r\n13      0x7fd3742a73c3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n14      0x7fd37360f997p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n15      0x7fd3ab82ebe0p pthread_once + 80\r\n16      0x7fd374f53522p\r\n17      0x7fd373610f14p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n18      0x7fd39157a678p\r\n19      0x7fd3ab829df3p\r\n20      0x7fd3aae4e2cdp clone + 109",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "hutuxian",
        "created_at": "2019-04-04T09:12:37+00:00",
        "updated_at": "2019-04-04T10:19:25+00:00",
        "closed_at": "2019-04-04T10:19:25+00:00",
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1994,
        "title": "machine_reading_comprehension 训练报错",
        "body": "sh run.sh --train\r\n\r\n2019-04-05 10:49:46,316 - brc - INFO - Running with args : Namespace(batch_size=32, dev_interval=-1, devset=['data/demo/devset/search.dev.json'], doc_num=5, drop_rate=0.0, embed_size=300, enable_ce=False, evaluate=False, hidden_size=150, learning_rate=0.001, load_dir='', log_interval=50, log_path=None, max_a_len=200, max_p_len=500, max_p_num=5, max_q_len=60, optim='adam', para_print=False, pass_num=5, predict=False, prepare=False, random_seed=123, result_dir='data/results/', result_name='test_result', save_dir='data/models', save_interval=1, testset=['data/demo/testset/search.test.json'], train=True, trainset=['data/demo/trainset/search.train.json'], use_gpu=True, vocab_dir='data/vocab', weight_decay=0.0001)\r\n2019-04-05 10:49:46,316 - INFO - Running with args : Namespace(batch_size=32, dev_interval=-1, devset=['data/demo/devset/search.dev.json'], doc_num=5, drop_rate=0.0, embed_size=300, enable_ce=False, evaluate=False, hidden_size=150, learning_rate=0.001, load_dir='', log_interval=50, log_path=None, max_a_len=200, max_p_len=500, max_p_num=5, max_q_len=60, optim='adam', para_print=False, pass_num=5, predict=False, prepare=False, random_seed=123, result_dir='data/results/', result_name='test_result', save_dir='data/models', save_interval=1, testset=['data/demo/testset/search.test.json'], train=True, trainset=['data/demo/trainset/search.train.json'], use_gpu=True, vocab_dir='data/vocab', weight_decay=0.0001)\r\n2019-04-05 10:49:46,317 - brc - INFO - Load data_set and vocab...\r\n2019-04-05 10:49:46,317 - INFO - Load data_set and vocab...\r\n2019-04-05 10:50:47,535 - brc - INFO - vocab size is 576278 and embed dim is 300\r\n2019-04-05 10:50:47,535 - INFO - vocab size is 576278 and embed dim is 300\r\n2019-04-05 10:50:47,640 - brc - INFO - Train set size: 95 questions.\r\n2019-04-05 10:50:47,640 - INFO - Train set size: 95 questions.\r\n2019-04-05 10:50:47,942 - brc - INFO - Dev set size: 100 questions.\r\n2019-04-05 10:50:47,942 - INFO - Dev set size: 100 questions.\r\n2019-04-05 10:42:52,829 - brc - INFO - Dev eval loss 10.7250499725\r\n2019-04-05 10:42:52,829 - INFO - Dev eval loss 10.7250499725\r\n2019-04-05 10:42:52,830 - brc - INFO - Dev eval result: {'Bleu-4': 6.516822191519035e-11, 'Rouge-L': 0.04326856861704951, 'Bleu-1': 1.1046810984229843e-10, 'Bleu-3': 7.277572299241399e-11, 'Bleu-2': 8.682206995432063e-11}\r\n2019-04-05 10:42:52,830 - INFO - Dev eval result: {'Bleu-4': 6.516822191519035e-11, 'Rouge-L': 0.04326856861704951, 'Bleu-1': 1.1046810984229843e-10, 'Bleu-3': 7.277572299241399e-11, 'Bleu-2': 8.682206995432063e-11}\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 648, in <module>\r\n    train(logger, args)\r\n  File \"run.py\", line 473, in train\r\n    pass_id, \"%.10f\" % (1.0 * total_loss / total_num)))\r\nZeroDivisionError: float division by zero",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2019-04-05T02:55:12+00:00",
        "updated_at": "2019-04-24T07:28:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1992,
        "title": "图像分类报错",
        "body": "1.训练时\r\n<img width=\"785\" alt=\"94bd932cd5ab389f472129e083de5e1c\" src=\"https://user-images.githubusercontent.com/46314656/55553960-33b56880-5714-11e9-83b2-9d3a592125cf.png\">\r\n2.评估和预测时，在python3下报错\r\n<img width=\"898\" alt=\"2dd3c9f40a6658fba9341901fba256ce\" src=\"https://user-images.githubusercontent.com/46314656/55554055-6bbcab80-5714-11e9-833f-3d15e2e427c0.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shippingwang",
        "created_at": "2019-04-04T12:01:34+00:00",
        "updated_at": "2019-04-08T05:40:29+00:00",
        "closed_at": "2019-04-08T05:40:29+00:00",
        "comments_count": [
            "Yancey0623"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 1997,
        "title": "When will PyramidBox++ be released?",
        "body": "https://arxiv.org/pdf/1904.00386.pdf",
        "state": "open",
        "user": "yxchng",
        "closed_by": null,
        "created_at": "2019-04-05T07:27:44+00:00",
        "updated_at": "2019-04-26T10:13:14+00:00",
        "closed_at": null,
        "comments_count": [
            "yxchng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2004,
        "title": "测试集精度太低",
        "body": "1、样本格式: 不定长输入（某用户搜过的词）\r\n类似：[1, 3, 4, 5 ....] [label]   \r\n           [1, 2,  3, .....] [label] 这个样子\r\n2、处理方法：\r\n利用LodTensor表征上述不定长输入（取对应位置的embedding池化（sum））转化成成定长输入\r\n3、paddle版本：\r\n1.3\r\n4、网络格式：\r\n与deepctr中一致，三层全链接层\r\n5、问题：\r\n训练集精度稳定上升。测试精度一直（注意：是一直，测试精度没有下降的过程，貌似和过拟合不太想）不高。\r\n\r\n```python\r\nclass ctr_model(object):\r\n    def __init__(self, args):\r\n        \"\"\"\r\n        创建整个模型\r\n        :param args: 配置文件\r\n        \"\"\"\r\n        self.args = args\r\n        place = fluid.CPUPlace()\r\n        # place = fluid.CUDAPlace(0)\r\n        self.exe = fluid.Executor(place)\r\n        self.main_program = fluid.default_main_program()\r\n\r\n        self._create_model()\r\n        # self._create_opts()\r\n\r\n    def _create_model(self):\r\n        \"\"\"\r\n        创建网络\r\n        \"\"\"\r\n        logger.info(\"create networks\")\r\n\r\n        with fluid.program_guard(self.main_program):\r\n            with fluid.unique_name.guard():\r\n                self.py_reader, self.words, self.predict, self.loss, self.acc = \\\r\n                                        ctr_dnn_model(self.args.embed_size, self.args.sparse_feature_dim,\r\n                                        is_training=self.args.is_training)\r\n\r\n                logger.info(\"create optimizer\")\r\n                self.optimizer = fluid.optimizer.Adam(learning_rate=self.args.lr)\r\n                self.optimizer.minimize(self.loss)\r\n\r\n    def _create_opts(self):\r\n        \"\"\"\r\n        创建优化器\r\n        \"\"\"\r\n        logger.info(\"create optimizer\")\r\n        self.optimizer = fluid.optimizer.Adam(learning_rate=self.args.lr)\r\n        self.optimizer.minimize(self.loss)\r\n\r\n    def train(self):\r\n        \"\"\"\r\n        循环迭代\r\n        \"\"\"\r\n        logger.info(\"run local training\")\r\n\r\n        # print [p.name for p in self.main_program.global_block().all_parameters()]\r\n\r\n        # 必须在加载模型前调用，否则会覆盖已经加载的模型参数导致错误\r\n        self.exe.run(fluid.default_startup_program())\r\n\r\n        if not os.path.exists(self.args.checkpoint):\r\n            os.makedirs(self.args.checkpoint)\r\n\r\n        dataset = Reader(self.args.sparse_feature_dim)\r\n\r\n        train_reader = paddle.batch(paddle.reader.shuffle(dataset.feed(glob.glob(os.path.join(self.args.train_dir, \"part-*\"))),\r\n                                     buf_size=self.args.batch_size * 100), batch_size=self.args.batch_size)\r\n\r\n        self.py_reader.decorate_paddle_reader(train_reader)\r\n\r\n        feed_list = []\r\n        fetch_list = [self.words[1], self.predict, self.loss, self.acc]\r\n        # place = fluid.CPUPlace()\r\n        # exe = fluid.Executor(place)\r\n\r\n        exec_strategy = fluid.ExecutionStrategy()\r\n        build_strategy = fluid.BuildStrategy()\r\n\r\n        if os.getenv(\"NUM_THREADS\", \"\"):\r\n            exec_strategy.num_threads = int(os.getenv(\"NUM_THREADS\"))\r\n\r\n        cpu_num = int(os.environ.get('CPU_NUM', cpu_count()))\r\n        build_strategy.reduce_strategy = \\\r\n                fluid.BuildStrategy.ReduceStrategy.Reduce if cpu_num > 1 \\\r\n                else fluid.BuildStrategy.ReduceStrategy.AllReduce\r\n\r\n\r\n        self.compiled_program = fluid.CompiledProgram(self.main_program) \\\r\n                            .with_data_parallel(loss_name=self.loss.name,\r\n                                                build_strategy=build_strategy,\r\n                                                exec_strategy=exec_strategy)\r\n\r\n        metric = fluid.metrics.Auc(name=\"train_auc\")\r\n        for pass_id in xrange(self.args.num_passes):\r\n            pass_start = time.time()\r\n            self.py_reader.start()\r\n            batch_id = 0\r\n            try:\r\n                while True:\r\n                    label, predict, loss, acc = self.exe.run(self.compiled_program,\r\n                                                fetch_list=[self.words[1].name,\r\n                                                self.predict.name,\r\n                                                self.loss.name,\r\n                                                self.acc.name])\r\n                    loss = np.mean(loss)\r\n                    acc = np.mean(acc)\r\n                    metric.update(predict, label)\r\n                    auc = metric.eval()\r\n                    logger.info(\"TRAIN --> pass: {} batch: {:0=4} loss: {} acc: {}  auc: {}\"\r\n                            .format(pass_id, batch_id, loss, acc, auc))\r\n\r\n                    if batch_id % 100 == 0 and batch_id != 0:\r\n\r\n                        if self.args.trainer_id == 0:\r\n                            self.save(self.args.checkpoint, feed_list, fetch_list, pass_id, batch_id)\r\n\r\n                    batch_id += 1\r\n\r\n            except fluid.core.EOFException:\r\n                self.py_reader.reset()\r\n\r\n            print(\"pass_id: %d, pass_time_cost: %f\" % (pass_id, time.time() - pass_start))\r\n\r\n            if self.args.trainer_id == 0:\r\n                self.save(self.args.checkpoint, feed_list, fetch_list, pass_id, batch_id)\r\n                pass\r\n\r\n    def save(self, path, feed_list, fetch_list, pass_id, batch_id):\r\n        \"\"\"\r\n        保存checkpoint\r\n        :param path: 路径\r\n        :param pass_id: epoch次数\r\n        :param batch_id: 迭代次数\r\n        \"\"\"\r\n        checkpoint_name = \"ctr_model.ckpt-%04d-%04d\" % (pass_id, batch_id)\r\n        model_dir = os.path.join(path, checkpoint_name)\r\n        # fluid.io.save_persistables(self.exe, model_dir, self.main_program)\r\n        fluid.io.save_inference_model(model_dir, feed_list, fetch_list, self.exe, self.main_program)\r\n\r\n    def load(self, path):\r\n        \"\"\"\r\n        加载checkpoint\r\n        :param path:路径\r\n        \"\"\"\r\n        logger.info(\"[*] Reading checkpoint...\")\r\n        models = glob.glob(os.path.join(path, \"*.ckpt-*\"))\r\n        if models:\r\n            models = sorted(models, key=lambda x: x[-4:])\r\n            fluid.io.load_persistables(self.exe, models[-1], self.main_program)\r\n            batch_id = int(models[-1][-4:])\r\n            return True\r\n\r\n        else:\r\n            return False\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    args = Config()\r\n    args = args()\r\n\r\n    ctr_demo = ctr_model(args)\r\n    ctr_demo.train()\r\n\r\n验证：\r\n# python\r\ndef eval():\r\n    \"\"\"\r\n    验证模型\r\n    \"\"\"\r\n    args = Config()\r\n    args = args()\r\n\r\n    place = fluid.CPUPlace()\r\n    inference_scope = fluid.core.Scope()\r\n\r\n    dataset = Reader(args.sparse_feature_dim)\r\n    test_reader = paddle.batch(dataset.feed(glob.glob(os.path.join(args.test_dir, \"part-*\"))),\r\n                                    batch_size=args.batch_size*100)\r\n\r\n    startup_program = fluid.framework.Program()\r\n    main_program = fluid.framework.Program()\r\n    with fluid.framework.program_guard(main_program, startup_program):\r\n        _, words, predict, loss, acc = ctr_dnn_model(args.embed_size, args.sparse_feature_dim, is_training=False)\r\n\r\n    feeder = fluid.DataFeeder(feed_list=words, place=place)\r\n    exe = fluid.Executor(place)\r\n    metric = fluid.metrics.Auc(name=\"valid_auc\")\r\n    while True:\r\n        logger.info(\"[*] Reading checkpoint...\")\r\n        ckpt = glob.glob(os.path.join(args.checkpoint, \"*.ckpt-*\"))\r\n\r\n        if ckpt:\r\n            logger.info(\"[*] Load Success...\")\r\n            ckpt = sorted(ckpt, key=lambda x: x[-9:])[-1]\r\n            logger.info(ckpt)\r\n            with fluid.scope_guard(inference_scope):\r\n                [inference_program, _, fetch_targets] = fluid.io.load_inference_model(ckpt, exe)\r\n\r\n                def set_zero(var_name):\r\n                    \"\"\"set auc state list to 0\"\"\"\r\n                    param = inference_scope.var(var_name).get_tensor()\r\n                    param_array = np.zeros(param._get_dims()).astype(\"int64\")\r\n                    param.set(param_array, place)\r\n\r\n                auc_states_names = ['_generated_var_2', '_generated_var_3']\r\n                # for name in auc_states_names:\r\n                #     set_zero(name)\r\n\r\n                for batch_id, data in enumerate(test_reader()):\r\n                    label, predict, loss, acc = exe.run(inference_program,\r\n                                                        feed=feeder.feed(data),\r\n                                                        fetch_list=fetch_targets)\r\n                    loss = np.mean(loss)\r\n                    acc = np.mean(acc)\r\n                    metric.update(predict, label)\r\n                    auc = metric.eval()\r\n                    # if batch_id % 100 == 0:\r\n                    logger.info(\"TEST --> batch: {} loss: {} acc: {} auc: {}\".format(batch_id, loss, acc, auc))\r\n        else:\r\n            logger.info(\"No checkpoint file found\")\r\n\r\n        time.sleep(EVAL_INTERVAL_SECS)\r\n\r\n\r\nif __name__ == '__main__':\r\n    eval()\r\n```",
        "state": "open",
        "user": "Annnnnnnnnnnnn",
        "closed_by": null,
        "created_at": "2019-04-08T03:59:47+00:00",
        "updated_at": "2019-04-08T04:03:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2000,
        "title": "SSD_loss 训练公开数据集在几个 epoch 后 loss 突然变 nan",
        "body": "![image](https://user-images.githubusercontent.com/6814767/55666420-629d1d00-5881-11e9-9193-6063421a36dc.png)   \r\n使用 object_detection  中的SSD 训练 deepfashion 数据集时，在经过几个 epoch 后会随机出现 loss nan 如图，（多次调整learning_rate, batch_size都会随机出现nan ），数据跑过一轮，应该不是数据标注问题， 猜测可能是 ssd_loss 中数值边界处理的问题   \r\n![image](https://user-images.githubusercontent.com/6814767/55666473-01c21480-5882-11e9-805f-608ff5672a3b.png)\r\n",
        "state": "open",
        "user": "xuzhm",
        "closed_by": null,
        "created_at": "2019-04-06T07:46:11+00:00",
        "updated_at": "2021-08-10T02:23:05+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "xuzhm",
            "qingqing01",
            "huihuiustc",
            "zakai86",
            "JiaoZiLang",
            "errllxj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2008,
        "title": "视频模型评估预测问题",
        "body": "1.stnet,tsn 运行test.py时会报显存不足，建议调低configs文件中TEST默认batch_size大小\r\n2.视频模型库中好几个模型readme infer.py中示例命令行的模型名都是小写，运行后会报错：\r\n<img width=\"749\" alt=\"64f7f729746da3ad61898579d45f308a\" src=\"https://user-images.githubusercontent.com/46314656/55702810-54c6d380-5a0a-11e9-9a25-e663c5649b7c.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "heavengate",
        "created_at": "2019-04-08T06:28:43+00:00",
        "updated_at": "2019-04-08T10:20:21+00:00",
        "closed_at": "2019-04-08T10:20:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2012,
        "title": "[PaddleSlim测试] distillation name conflicts error.",
        "body": "### 蒸馏任务执行失败\r\n\r\n#### 对应提测报告章节：3.2节\r\n\r\n#### 问题描述：\r\n执行任务后报错，提示batch norm layer的input channel和Scale的shape不一致。\r\n\r\n#### 原因：\r\n1. MobileNetV1和ResNet50第一个卷积层的weight名称都被强制指定为了`conv1_weights`,导致命名冲突。\r\n2. paddle/models/PaddleSlim/run.sh中下载的预训练模型，MobileNetV1和ResNet50的FC layer的parameter的名称都为fc_0.w_0和fc_0.b_0, 导致命名冲突。\r\n\r\n#### 解决办法：\r\n1. 修改PaddlePaddle/models/PaddleSlim/model/resnet.py, 将ResNet第一层conv层的名称修改为‘res_conv1’\r\n2. 修改PaddlePaddle/models/PaddleSlim/run.sh, 下载pretrain model之后，将ResNet的`conv1_weights`重命名为`res_conv1_weights`. 将ResNet的`fc_0.w_0`和`fc_0.b_0`重命名为`fc_1.w_0`和`fc_1.b_0`\r\n\r\n#### 错误类型：\r\nmodels repo示例错误",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-04-08T07:29:36+00:00",
        "updated_at": "2019-04-08T12:31:05+00:00",
        "closed_at": "2019-04-08T12:31:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2002,
        "title": "Avoid non-4-dimensional design in classification model",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/shufflenet_v2.py#L120\r\n\r\nFive-dimensional tensor has emerged, which is very unfriendly to the design of inference subgraph.\r\n\r\nSuggest:\r\n```\r\nx = fluid.layers.reshape(\r\n            x=x, shape=[batchsize, groups, channels_per_group, width * height])\r\n\r\nx = fluid.layers.transpose(x=x, perm=[0, 2, 1, 3])\r\nx = fluid.layers.reshape(\r\n            x=x, shape=[batchsize, num_channels, height, width])\r\n```\r\n",
        "state": "open",
        "user": "NHZlX",
        "closed_by": null,
        "created_at": "2019-04-08T03:22:06+00:00",
        "updated_at": "2019-04-12T07:24:23+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2006,
        "title": "human_pose_estimation问题汇总",
        "body": "1.在python3下报错：\r\n<img width=\"896\" alt=\"74c44dd6829460d07833919cd7d5c155\" src=\"https://user-images.githubusercontent.com/46314656/55696298-efb1b480-59ee-11e9-80d7-04d35cc816e7.png\">\r\n2.训练时log的显示有延时，建议添加sys.stdout.flush()在print后\r\n3.test时在开始的地方卡住不动，没有报错，保持下图gpu使用率为0%的状态：\r\n<img width=\"867\" alt=\"6cbcba3855bb2dffb2a1fa2614e0407e\" src=\"https://user-images.githubusercontent.com/46314656/55699293-c009a900-59fc-11e9-88d0-6278e9b22c9c.png\">\r\n4.val时在安装nms包后依然报错：\r\n<img width=\"747\" alt=\"2f708a0833598a8a021e9854a23d7804\" src=\"https://user-images.githubusercontent.com/46314656/55700325-6eafe880-5a01-11e9-9670-bab8edd009b2.png\">\r\n5.建议test.py和val.py去除掉不用的参数model_save_dir",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-08T05:24:25+00:00",
        "updated_at": "2019-04-12T06:22:37+00:00",
        "closed_at": "2019-04-12T06:22:37+00:00",
        "comments_count": [
            "xiegegege",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2018,
        "title": "face_detection训练报错",
        "body": "在1.4分支上训练报错，应该是最新框架合入导致的，报错如下：\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 271, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"train.py\", line 200, in train\r\n    [v.name for v in fetches])\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 205, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 544, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 445, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator reshape2 error.\r\nPython Callstacks:\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1663, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 6409, in reshape\r\n    \"XShape\": x_shape})\r\n  File \"/workspace/PaddleCV/face_detection/pyramidbox.py\", line 241, in permute_and_reshape\r\n    trans, shape=compile_shape, actual_shape=run_shape)\r\n  File \"/workspace/PaddleCV/face_detection/pyramidbox.py\", line 254, in _pyramidbox\r\n    head_loc = permute_and_reshape(head_loc, 4)\r\n  File \"/workspace/PaddleCV/face_detection/pyramidbox.py\", line 95, in __init__\r\n    self._pyramidbox()\r\n  File \"train.py\", line 93, in build_program\r\n    sub_network=use_pyramidbox)\r\n  File \"train.py\", line 139, in train\r\n    args=args)\r\n  File \"train.py\", line 271, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\nC++ Callstacks:\r\nEnforce failed. Expected capacity == in_size, but received capacity:51200 != in_size:204800.\r\nInvalid shape is given. at [/home/Paddle/paddle/fluid/operators/reshape_op.cc:106]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-10T02:53:24+00:00",
        "updated_at": "2019-04-10T06:24:36+00:00",
        "closed_at": "2019-04-10T06:24:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2017,
        "title": "machine_reading_comprehension训练种的Evaluating报错",
        "body": "[05:16:04]W:\t [Step 3/3] 2019-04-09 05:16:04,003-INFO: epoch: 1, epoch_time_cost: 176.34\r\n[05:16:04]W:\t [Step 3/3] 2019-04-09 05:16:04,004 - brc - INFO - Evaluating the model after epoch 1\r\n[05:16:04]W:\t [Step 3/3] 2019-04-09 05:16:04,004-INFO: Evaluating the model after epoch 1\r\n[05:16:04]W:\t [Step 3/3] ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\n[05:16:04]W:\t [Step 3/3] W0409 05:16:04.008666 23001 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\n[05:16:04]W:\t [Step 3/3] I0409 05:16:04.153195 23001 build_strategy.cc:297] SeqOnlyAllReduceOps:0, num_trainers:1\r\n[05:16:04]W:\t [Step 3/3] Traceback (most recent call last):\r\n[05:16:04]W:\t [Step 3/3]   File \"run.py\", line 648, in <module>\r\n[05:16:04]W:\t [Step 3/3]     train(logger, args)\r\n[05:16:04]W:\t [Step 3/3]   File \"run.py\", line 465, in train\r\n[05:16:04]W:\t [Step 3/3]     args)\r\n[05:16:04]W:\t [Step 3/3]   File \"run.py\", line 242, in validation\r\n[05:16:04]W:\t [Step 3/3]     return_numpy=False)\r\n[05:16:04]W:\t [Step 3/3]   File \"/opt/python/cp27-cp27mu/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 205, in run\r\n[05:16:04]W:\t [Step 3/3]     return_numpy=return_numpy)\r\n[05:16:04]W:\t [Step 3/3]   File \"/opt/python/cp27-cp27mu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 544, in run\r\n[05:16:04]W:\t [Step 3/3]     return_numpy=return_numpy)\r\n[05:16:04]W:\t [Step 3/3]   File \"/opt/python/cp27-cp27mu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 445, in _run_parallel\r\n[05:16:04]W:\t [Step 3/3]     exe.run(fetch_var_names, fetch_var_name)\r\n[05:16:04]W:\t [Step 3/3] paddle.fluid.core.EnforceNotMet: Cannot find fetched variable(array_to_lod_tensor_2.tmp_0).(Perhaps the main_program is not set to ParallelExecutor) at [/workspace/paddle/fluid/framework/details/threaded_ssa_graph_executor.cc:163]\r\n[05:16:04]W:\t [Step 3/3] PaddlePaddle Call Stacks: ",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "kolinwei",
        "created_at": "2019-04-09T08:14:46+00:00",
        "updated_at": "2019-04-15T11:36:29+00:00",
        "closed_at": "2019-04-15T11:36:29+00:00",
        "comments_count": [
            "kolinwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2020,
        "title": "transformer: 'utf-8' codec can't decode byte 0xed",
        "body": "I down the preprocessed data WMT16_EN_DE from https://transformer-res.bj.bcebos.com/wmt16_ende_data_bpe_clean.tar.gz.\r\n\r\nWhen I run infer.py, A UnicodeDecodeError come out:\r\n\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 323, in <module>\r\n    args = parse_args()\r\n  File \"infer.py\", line 81, in parse_args\r\n    src_dict = reader.DataReader.load_dict(args.src_vocab_fpath)\r\n  File \"/Users/xxx/Documents/GitHub/models/PaddleNLP/neural_machine_translation/transformer/reader.py\", line 281, in load_dict\r\n    line = line.decode()\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte\r\n\r\nOperating System: macOS 10.14\r\npython version: Python 3.6.5",
        "state": "open",
        "user": "Genie-Liu",
        "closed_by": null,
        "created_at": "2019-04-10T07:21:56+00:00",
        "updated_at": "2019-04-12T07:41:32+00:00",
        "closed_at": null,
        "comments_count": [
            "Genie-Liu",
            "Shajiu",
            "Genie-Liu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2033,
        "title": "PaddleCV/image_classification 训练时报错（CPU没问题GPU出错）",
        "body": "paddle 版本 1.3.2\r\nGPU 型号\r\n GeForce GTX 1080  8119MiB\r\nTesla K40m 11441MiB \r\nPlease NOTE: device: 1, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\ndevice: 1, cuDNN Version: 7.0.\r\n\r\n项目配置信息\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 256\r\n               checkpoint : None\r\n                class_dim : 61\r\n                 data_dir : ./data/ILSVRC2012\r\n                enable_ce : False\r\n                     fp16 : False\r\n              image_shape : 3,224,224\r\n                 l2_decay : 0.0001\r\n                       lr : 0.01\r\n              lr_strategy : piecewise_decay\r\n                    model : AlexNet\r\n           model_save_dir : output\r\n            momentum_rate : 0.9\r\n               num_epochs : 1\r\n         pretrained_model : None\r\n               scale_loss : 1.0\r\n             total_images : 31718\r\n                  use_gpu : True\r\n             with_mem_opt : False\r\n----------------------------------------------------\r\n报错信息\r\n*** Aborted at 1555033639 (unix time) try \"date -d @1555033639\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 22659 (TID 0x7f0f01560740) from PID 0; stack trace: ***\r\n    @     0x7f0f00a55330 (unknown)\r\n    @                0x0 (unknown)\r\nbash: 行 1: 22659 段错误               (核心已转储) env \"PYCHARM_MATPLOTLIB_PORT\"=\"59714\" \"PYTHONPATH\"=\"/home/masdir/.pycharm_helpers/pycharm_matplotlib_backend:/home/data/cwz/py36/image_classification\" \"PYTHONUNBUFFERED\"=\"1\" \"LD_LIBRARY_PATH\"=\"/usr/local/cuda/lib64\" \"FLAGS_fraction_of_gpu_memory_to_use\"=\"0.99\" \"JETBRAINS_REMOTE_RUN\"=\"1\" \"PYTHONIOENCODING\"=\"UTF-8\" \"PYCHARM_HOSTED\"=\"1\" /home/data/anaconda3/envs/py36-cwz/bin/python3.6 -u /home/data/cwz/py36/image_classification/train.py\r\n\r\nProcess finished with exit code 139\r\n----------------------------------------------------\r\n报错代码位置\r\n![image](https://user-images.githubusercontent.com/23010064/56007806-8db5bf80-5d0c-11e9-8b41-f2f8af2e6150.png)\r\n----------------------------------------------------\r\n对比样例只修改了数据读入方式的小部分代码\r\n`    def reader():\r\n        print(\"## now in reader\")\r\n        data_dict = {}\r\n        with open(file_list) as flist:\r\n            full_lines = json.load(flist)\r\n            if shuffle:\r\n                if pass_id_as_seed:\r\n                    np.random.seed(pass_id_as_seed)\r\n                np.random.shuffle(full_lines)\r\n\r\n            # for l in full_lines:\r\n            #     print(l)\r\n            print(\"## now in reader1\")\r\n            if mode == 'train' and os.getenv('PADDLE_TRAINING_ROLE'):\r\n                trainer_id = int(os.getenv(\"PADDLE_TRAINER_ID\", \"0\"))\r\n                trainer_count = int(os.getenv(\"PADDLE_TRAINERS_NUM\", \"1\"))\r\n                per_node_lines = len(full_lines) // trainer_count\r\n                lines = full_lines[trainer_id * per_node_lines:(trainer_id + 1)\r\n                                   * per_node_lines]\r\n                print(\r\n                    \"read images from %d, length: %d, lines length: %d, total: %d\"\r\n                    % (trainer_id * per_node_lines, per_node_lines, len(lines),\r\n                       len(full_lines)))\r\n            else:\r\n                lines = full_lines\r\n\r\n            print(\"## now in reader2\")\r\n            img_name = []\r\n            for image in lines:\r\n                img_name.append(image['image_id'])\r\n                data_dict[image['image_id']] = int(image['disease_class'])\r\n                # print(img_name[img_name.index(image['image_id'])])\r\n\r\n            print(\"## now in reader3\")\r\n            for index in range(len(img_name)):\r\n                if mode == 'train':\r\n                    img_path = img_name[index]\r\n                    img_path = img_path.replace(\"JPEG\", \"jpeg\")\r\n                    img_path = data_dir + '/train/' + img_path\r\n                    label = data_dict[img_name[index]]\r\n                    yield img_path, int(label)\r\n                elif mode == 'val':\r\n                    img_path = img_name[index]\r\n                    img_path = img_path.replace(\"JPEG\", \"jpeg\")\r\n                    img_path = data_dir + '/val/' + img_path\r\n                    label = data_dict[img_name[index]]\r\n                    yield img_path, int(label)\r\n                elif mode == 'test':\r\n                    img_path = img_name[index]\r\n                    img_path = img_path.replace(\"JPEG\", \"jpeg\")\r\n                    img_path = os.path.join(data_dir, img_path)\r\n                    yield [img_path]`\r\n\r\n\r\n[reader_cv2.txt](https://github.com/PaddlePaddle/models/files/3071302/reader_cv2.txt)\r\n[train.txt](https://github.com/PaddlePaddle/models/files/3071303/train.txt)\r\n\r\n\r\n",
        "state": "closed",
        "user": "liyutg",
        "closed_by": "liyutg",
        "created_at": "2019-04-12T02:26:10+00:00",
        "updated_at": "2019-04-12T11:34:11+00:00",
        "closed_at": "2019-04-12T06:10:54+00:00",
        "comments_count": [
            "liyutg",
            "liyutg",
            "tensor-tang",
            "luotao1",
            "tensor-tang",
            "luotao1",
            "liyutg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2034,
        "title": "bert squad任务运行错误",
        "body": "在运行结束保存模型时有个报错\r\nTraceback (most recent call last):\r\n  File \"run_squad.py\", line 427, in <module>\r\n    train(args)\r\n  File \"run_squad.py\", line 422, in train\r\n    ], processor)\r\n  File \"run_squad.py\", line 208, in predict\r\n    args.null_score_diff_threshold, args.verbose)\r\n  File \"/ssd1/xiege/LARK_4.10/LARK/BERT/reader/squad.py\", line 614, in write_predictions\r\n    result = unique_id_to_result[feature.unique_id]\r\nKeyError: 1000010824\r\nterminate called without an active exception",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-12T03:01:52+00:00",
        "updated_at": "2019-04-16T04:41:24+00:00",
        "closed_at": "2019-04-16T04:41:24+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2040,
        "title": "human_pose_estimation 评估问题",
        "body": "1. human_pose_estimation在paddle1.4分支下运行val和test时会报如下的错误：\r\nTraceback (most recent call last):\r\n  File \"val.py\", line 233, in <module>\r\n    valid(args)\r\n  File \"val.py\", line 127, in valid\r\n    loss_name=loss.name)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 134, in __init__\r\n    self._compiled_program._compile(place=self._place, scope=self._scope)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/compiler.py\", line 282, in _compile\r\n    scope=self._scope)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/compiler.py\", line 253, in _compile_data_parallel\r\n    self._exec_strategy, self._build_strategy, self._graph)\r\npaddle.fluid.core.EnforceNotMet: Illegal Pass. Generated graph shouldn't has cycle. at [/ssd1/xiege/paddle_ce/Paddle/paddle/fluid/framework/ir/pass.cc:35]\r\n在paddle 1.3运行正常\r\n\r\n2.在cpu下运行val.py会在运行22个epoch后报如下的错误：\r\nTraceback (most recent call last):\r\n  File \"val.py\", line 233, in <module>\r\n    valid(args)\r\n  File \"val.py\", line 160, in valid\r\n    feed=feeder.feed(data))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 278, in run\r\n    feed_tensor_dict)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected member_->places_.size() == lod_tensors.size(), but received member_->places_.size():26 != lod_tensors.size():14.\r\nThe number of samples of current batch is less than the count of devices, currently, it is not allowed. (26 vs 14) at [/paddle/paddle/fluid/framework/parallel_executor.cc:452]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-12T06:30:17+00:00",
        "updated_at": "2019-04-12T08:59:37+00:00",
        "closed_at": "2019-04-12T08:59:37+00:00",
        "comments_count": [
            "zeyu-liu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2022,
        "title": "量化训练模型删除指定op转换功能",
        "body": "```\r\nimport paddle.fluid as fluid\r\nfrom pyramidbox_test import PyramidBox\r\nfrom paddle.fluid.framework import IrGraph\r\nfrom paddle.fluid import core\r\nfrom paddle.fluid.contrib.slim.quantization.quantization_pass import *\r\nimport sys\r\nif __name__ == '__main__':\r\n    float_model_path_src = 'faceboxes_V016_float32_compress_0327_float'\r\n\r\n    place = fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n\r\n    # step1: define infer network without assign op\r\n    main_program = fluid.Program()\r\n    startup_program = fluid.Program()\r\n\r\n    with fluid.program_guard(main_program, startup_program):\r\n\r\n        print('debug: construct network')\r\n        network = PyramidBox(\r\n            data_shape=[3, 240, 320],\r\n            sub_network=True,\r\n            is_infer=True)\r\n        inference_program, nmsed_out = network.infer(main_program)\r\n        print('nmsed_out name: {}'.format(nmsed_out.name))\r\n    # step2: init variables\r\n    exe.run(startup_program)\r\n\r\n    # step3: insert quantzation operators into infer network\r\n    transform_pass = QuantizationTransformPass(\r\n            scope=fluid.executor.global_scope(),\r\n            place=place,\r\n            weight_bits=8,\r\n            activation_bits=8,\r\n            activation_quantize_type='range_abs_max')\r\n    eval_graph = IrGraph(core.Graph(inference_program.desc), for_test=True)\r\n    transform_pass.apply(eval_graph)\r\n\r\n\r\n    # step4: load float weights into global scope\r\n    fluid.io.load_inference_model(float_model_path_src, exe,\r\n                                   model_filename='model',\r\n                                   params_filename='weights')\r\n\r\n    # step5: convert to int8 model\r\n    freeze_pass = QuantizationFreezePass(\r\n                             scope=fluid.executor.global_scope(),\r\n                             place=place,\r\n                             weight_bits=8,\r\n                             activation_bits=8)\r\n    freeze_pass.apply(eval_graph)\r\n    convert_int8_pass = ConvertToInt8Pass(\r\n                               scope=fluid.executor.global_scope(),\r\n                               place=place)\r\n    convert_int8_pass.apply(eval_graph)\r\n\r\n\r\n\r\n    eval_graph.draw('.','eval')\r\n\r\n    # step6: save int8 model into filesystem\r\n    program = eval_graph.to_program()\r\n    out_vars = [program.global_block().var('detection_output_0.tmp_0')]\r\n    fluid.io.save_inference_model(\r\n           \"./output_int8\",\r\n           ['image'],\r\n           out_vars,\r\n           exe,\r\n           main_program=program,\r\n           model_filename='model',\r\n           params_filename='weights',\r\n           export_for_deployment=True)\r\n\r\n\r\n\r\n    # step7: load and check\r\n    program, feed_target_names, fetch_targets = fluid.io.load_inference_model(\"./output_int8\", exe,\r\n                                   model_filename='model',\r\n                                   params_filename='weights')\r\n    print(\"feed_target_names: {}\".format(feed_target_names))\r\n    print(\"fetch_targets: {}\".format(fetch_targets))\r\n\r\n    for op in program.global_block().ops:\r\n        print(\"op: {}\".format(op.type))\r\n\r\n    for var in program.list_vars():\r\n        if var.persistable:\r\n            print(\"var: {}\".format(var.name))\r\n```",
        "state": "open",
        "user": "wanghaoshuang",
        "closed_by": null,
        "created_at": "2019-04-10T09:44:25+00:00",
        "updated_at": "2019-04-11T04:00:29+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2041,
        "title": "yolov3易用性问题",
        "body": "1. 安装文档链接不存在\r\n![image](https://user-images.githubusercontent.com/37854899/56020887-c7052400-5d3a-11e9-9dc1-cefe9e4da309.png)\r\n![image](https://user-images.githubusercontent.com/37854899/56020897-cb314180-5d3a-11e9-9c7a-fa14a37fa5b1.png)\r\n\r\n2. 文档中午附录相关内容，删去附录字样\r\n![image](https://user-images.githubusercontent.com/37854899/56020945-e3a15c00-5d3a-11e9-9fe5-90fb827e3107.png)\r\n3. 安装cocoapi部分，放在模型训练部分前，与实际使用模型的配置顺序一致\r\n![image](https://user-images.githubusercontent.com/37854899/56021005-fae04980-5d3a-11e9-9ada-74f21f122c58.png)\r\n4. 下载预训练模型放在模型训练之前，与实际使用模型的配置顺序一致\r\n![image](https://user-images.githubusercontent.com/37854899/56021360-cd47d000-5d3b-11e9-8edf-40ff59ead1ab.png)\r\n\r\n5. cd PythonAPI 改为 cd cocoapi/PythonAPI\r\n![image](https://user-images.githubusercontent.com/37854899/56021138-4a267a00-5d3b-11e9-832b-d11f51a5e316.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "heavengate",
        "created_at": "2019-04-12T07:59:21+00:00",
        "updated_at": "2019-04-15T08:50:06+00:00",
        "closed_at": "2019-04-15T08:50:06+00:00",
        "comments_count": [
            "JiaXiao243",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2046,
        "title": "从AlexNet模型（正常跑通） 切换到ResNet50 模型时报错 ",
        "body": "**因为使用了自定义数据集，所以修改了读取数据的代码**\r\n### 系统信息\r\npaddle 版本 1.3.2\r\nGPU 型号\r\nTesla K40m 11441MiB \r\nPlease NOTE: device: 1, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\ndevice: 0, cuDNN Version: 7.0.\r\n\r\n### 项目配置信息\r\n```\r\n-------------  Configuration Arguments -------------\r\n      --model=ResNet50 \\\r\n      --batch_size=256 \\\r\n      --total_images=31718 \\\r\n      --class_dim=61 \\\r\n      --image_shape=3,224,224 \\\r\n      --model_save_dir=output/ \\\r\n      --with_mem_opt=True \\\r\n      --lr_strategy=piecewise_decay \\\r\n\t  --num_epochs=120 \\\r\n      --lr=0.1 \\\r\n      --l2_decay=1e-4 \\\r\n----------------------------------------------------\r\n```\r\n### 报错信息\r\nW0413 13:19:44.940369 13978 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0413 13:19:44.940452 13978 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0413 13:19:50.571400 16109 system_allocator.cc:122] Cannot malloc 9999.6 MB GPU memory. **Please shrink FLAGS_fraction_of_gpu_memory_to_use environment variable to a lower value. Current value is 0.92**\r\nW0413 13:19:50.571779 16109 legacy_allocator.cc:191] Cannot allocate 196.000000MB in GPU 0, available 1.214539GB\r\nW0413 13:19:50.571794 16109 legacy_allocator.cc:194] total 11996954624\r\nW0413 13:19:50.571805 16109 legacy_allocator.cc:195] GpuMinChunkSize 256.000000B\r\nW0413 13:19:50.571813 16109 legacy_allocator.cc:198] GpuMaxChunkSize 9.765232GB\r\nW0413 13:19:50.571827 16109 legacy_allocator.cc:201] GPU memory used: 9.633711GB\r\n*** Aborted at 1555132790 (unix time) try \"date -d @1555132790\" if you are using GNU date ***\r\n\r\n",
        "state": "closed",
        "user": "liyutg",
        "closed_by": "liyutg",
        "created_at": "2019-04-13T10:23:15+00:00",
        "updated_at": "2019-04-14T05:16:17+00:00",
        "closed_at": "2019-04-14T05:16:17+00:00",
        "comments_count": [
            "liyutg",
            "liyutg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2047,
        "title": "PaddleRL 运行不起来",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleRL/DeepQNetwork\r\n\r\n\r\nDeepQNetwork 跑不起来，感觉好像数据不太对。",
        "state": "closed",
        "user": "xinnian88",
        "closed_by": "TomorrowIsAnOtherDay",
        "created_at": "2019-04-14T14:08:39+00:00",
        "updated_at": "2019-04-15T11:37:01+00:00",
        "closed_at": "2019-04-15T11:37:01+00:00",
        "comments_count": [
            "JiabinYang",
            "TomorrowIsAnOtherDay",
            "xinnian88",
            "TomorrowIsAnOtherDay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2050,
        "title": "单精度训练，梯度下降计算时是否一定要转回双精度？？",
        "body": "官网例子中有一段代码：模型输入是fp16单精度的话，optimizer在反向梯度计算一定要转回fp32吗？\r\n![QQ图片20190415092900](https://user-images.githubusercontent.com/45925696/56102645-ed0c0d80-5f60-11e9-85eb-e1903fed74bc.png)\r\n\r\n\r\n",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-04-15T01:30:41+00:00",
        "updated_at": "2019-11-03T02:07:56+00:00",
        "closed_at": null,
        "comments_count": [
            "gongweibao"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2052,
        "title": "请问下，yolov3里的预训练模型darknet53里最后分类层的255这个参数不匹配？",
        "body": "尝试用yolov3训练voc的20类，但是数据做好之后是报参数不匹配。我已经修改成75（3x（20+5）），还要求我是255，但是我不用预训练模型就可以训练\r\n<img width=\"878\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/56119731-48f58700-5f9f-11e9-8832-0a4cf2811a36.png\">\r\n<img width=\"1360\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/56119769-5dd21a80-5f9f-11e9-9b3d-1fd77a44a3b7.png\">\r\n",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "heavengate",
        "created_at": "2019-04-15T08:57:18+00:00",
        "updated_at": "2019-04-15T13:14:32+00:00",
        "closed_at": "2019-04-15T13:14:32+00:00",
        "comments_count": [
            "heavengate",
            "cjt222",
            "heavengate",
            "cjt222",
            "heavengate",
            "cjt222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2064,
        "title": "bert 训练下 validation出现loss为inf的情况",
        "body": "paddle version：1.4\r\n开启fp16，loss_scaling=8的时候不收敛\r\n**训练参数：**\r\n```bash\r\nbatch_size: 4096                                                                                                                                         \r\nbert_config_path: bert_config.json                                                                                                                       \r\ncheckpoints: output/bert_normal_task                                                                                                                     \r\ndata_dir: train_data                                                                                                                                     \r\nepoch: 100                                                                                                                                               \r\nfor_test: False                                                                                                                                          \r\ngenerate_neg_sample: True                                                                                                                                \r\ninit_checkpoint: None                                                                                                                                    \r\nis_distributed: False                                                                                                                                    \r\nlearning_rate: 0.0001                                                                                                                                    \r\nloss_scaling: 8.0                                                                                                                                        \r\nlr_scheduler: noam_decay                                                                                                                                 \r\nmax_seq_len: 512                                                                                                                                         \r\nnum_train_steps: 1000000                                                                                                                                 \r\nreduce_master_grad: False                                                                                                                                \r\nsave_steps: 10000                                                                                                                                        \r\nskip_steps: 20                                                                                                                                           \r\ntest_set_dir:                                                                                                                                            \r\nuse_cuda: True                                                                                                                                           \r\nuse_fast_executor: False                                                                                                                                 \r\nuse_fp16: True                                                                                                                                           \r\nvalidation_set_dir: test_data                                                                                                                            \r\nvalidation_steps: 1000                                                                                                                                   \r\nvocab_path: vocab.txt                                                                                                                                    \r\nwarmup_steps: 4000                                                                                                                                       \r\nweight_decay: 0.01                                                                                                                                       \r\nweight_sharing: True\r\n```\r\n**训练结果：**\r\n```bash\r\nepoch: 1, progress: 1/100, step: 29360, loss: 60.687500, ppl: 1009.000000, next_sent_acc: 0.578125, speed: 2.013807 ste\r\nps/s, file: part-00097.gz                                                                                              \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29380, loss: 59.750000, ppl: 880.000000, next_sent_acc: 0.493056, speed: 2.013392 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29400, loss: 60.281250, ppl: 955.500000, next_sent_acc: 0.524306, speed: 2.010673 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29420, loss: 60.218750, ppl: 943.000000, next_sent_acc: 0.563194, speed: 2.014425 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29440, loss: 60.468750, ppl: 970.000000, next_sent_acc: 0.562847, speed: 2.021429 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29460, loss: 59.531250, ppl: 867.000000, next_sent_acc: 0.578125, speed: 2.014519 step\r\ns/s, file: part-00097.gz  \r\n```\r\n**开启fp16，scale_loss=32 和128的时候，出现validation的loss的inf的情况；**\r\n```bash\r\nepoch: 1, progress: 1/100, step: 980, loss: 232.250000, ppl: 697.000000, next_sent_acc: 0.531250, speed: 2.083186 steps\r\n/s, file: part-00054.gz                                                                                                \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000025                                                                                         \r\nepoch: 1, progress: 1/100, step: 1000, loss: 229.500000, ppl: 708.500000, next_sent_acc: 0.609375, speed: 2.078022 step\r\ns/s, file: part-00054.gz                                                                                               \r\n/root/paddlejob/workspace/env_run/predict.py:71: RuntimeWarning: overflow encountered in add                           \r\n  cost += each_total_cost                                                                                              \r\n[validation_set] epoch: 1, step: 816, loss: inf, global ppl: 649.037231, batch-averged ppl: 649.037231, next_sent_acc: \r\n0.491685, speed: 0.245354 steps/s                                                                                      \r\n('feed_queue size', 66L)                                                                                               \r\ncurrent learning_rate:0.000025                                                                                         \r\nepoch: 1, progress: 1/100, step: 1020, loss: 228.000000, ppl: 663.500000, next_sent_acc: 0.567708, speed: 0.219097 step\r\ns/s, file: part-00054.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000026                                                                                         \r\nepoch: 1, progress: 1/100, step: 1040, loss: 227.750000, ppl: 664.000000, next_sent_acc: 0.621875, speed: 2.050249 step\r\ns/s, file: part-00054.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000026                                                                                         \r\nepoch: 1, progress: 1/100, step: 1060, loss: 225.750000, ppl: 646.000000, next_sent_acc: 0.687500, speed: 2.059907 step\r\ns/s, file: part-00054.gz                                                                                               \r\n```\r\n\r\n",
        "state": "open",
        "user": "ccmeteorljh",
        "closed_by": null,
        "created_at": "2019-04-16T11:10:20+00:00",
        "updated_at": "2019-04-16T11:24:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2056,
        "title": "video non_local模型易用性问题",
        "body": "环境：paddle develop分支\r\nnon_local模型在某些epoch的训练结束后test之前会有报错，暂时没发现影响训练，但是影响体验\r\n*** Aborted at 1555279287 (unix time) try \"date -d @1555279287\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGTERM (@0xca84) received by PID 105196 (TID 0x7f1e86ad8700) from PID 51844; stack trace: ***\r\n    @     0x7f20bf6c57e0 (unknown)\r\n    @     0x7f20bf6c3a00 sem_wait\r\n    @     0x7f20bfa1e5c8 PyThread_acquire_lock\r\n    @     0x7f20bf9d70b6 PyEval_RestoreThread\r\n    @     0x7f20bfa23c1b (unknown)\r\n    @     0x7f20bf9df1fd PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9debf0 PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9debf0 PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9588b5 (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n    @     0x7f20bf9dbf22 PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9587e0 (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n    @     0x7f20bf93574d (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n    @     0x7f20bf992105 (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n    @     0x7f20bf9db764 PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9debf0 PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9debf0 PyEval_EvalFrameEx\r\n    @     0x7f20bf9ded1e PyEval_EvalFrameEx\r\n    @     0x7f20bf9e11fd PyEval_EvalCodeEx\r\n    @     0x7f20bf9587e0 (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n    @     0x7f20bf93574d (unknown)\r\n    @     0x7f20bf926d33 PyObject_Call\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-15T11:49:57+00:00",
        "updated_at": "2019-04-19T02:55:57+00:00",
        "closed_at": "2019-04-19T02:55:57+00:00",
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2065,
        "title": "bert 训练validation 出现loss为inf的情况",
        "body": "paddle version：1.4\r\n开启fp16，loss_scaling=8的时候不收敛\r\n**训练参数：**\r\n```bash\r\nbatch_size: 4096                                                                                                                                         \r\nbert_config_path: bert_config.json                                                                                                                       \r\ncheckpoints: output/bert_normal_task                                                                                                                     \r\ndata_dir: train_data                                                                                                                                     \r\nepoch: 100                                                                                                                                               \r\nfor_test: False                                                                                                                                          \r\ngenerate_neg_sample: True                                                                                                                                \r\ninit_checkpoint: None                                                                                                                                    \r\nis_distributed: False                                                                                                                                    \r\nlearning_rate: 0.0001                                                                                                                                    \r\nloss_scaling: 8.0                                                                                                                                        \r\nlr_scheduler: noam_decay                                                                                                                                 \r\nmax_seq_len: 512                                                                                                                                         \r\nnum_train_steps: 1000000                                                                                                                                 \r\nreduce_master_grad: False                                                                                                                                \r\nsave_steps: 10000                                                                                                                                        \r\nskip_steps: 20                                                                                                                                           \r\ntest_set_dir:                                                                                                                                            \r\nuse_cuda: True                                                                                                                                           \r\nuse_fast_executor: False                                                                                                                                 \r\nuse_fp16: True                                                                                                                                           \r\nvalidation_set_dir: test_data                                                                                                                            \r\nvalidation_steps: 1000                                                                                                                                   \r\nvocab_path: vocab.txt                                                                                                                                    \r\nwarmup_steps: 4000                                                                                                                                       \r\nweight_decay: 0.01                                                                                                                                       \r\nweight_sharing: True\r\n```\r\n**训练结果：**\r\n```bash\r\nepoch: 1, progress: 1/100, step: 29360, loss: 60.687500, ppl: 1009.000000, next_sent_acc: 0.578125, speed: 2.013807 ste\r\nps/s, file: part-00097.gz                                                                                              \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29380, loss: 59.750000, ppl: 880.000000, next_sent_acc: 0.493056, speed: 2.013392 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29400, loss: 60.281250, ppl: 955.500000, next_sent_acc: 0.524306, speed: 2.010673 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29420, loss: 60.218750, ppl: 943.000000, next_sent_acc: 0.563194, speed: 2.014425 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29440, loss: 60.468750, ppl: 970.000000, next_sent_acc: 0.562847, speed: 2.021429 step\r\ns/s, file: part-00097.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000037                                                                                         \r\nepoch: 1, progress: 1/100, step: 29460, loss: 59.531250, ppl: 867.000000, next_sent_acc: 0.578125, speed: 2.014519 step\r\ns/s, file: part-00097.gz  \r\n```\r\n**开启fp16，scale_loss=32 和128的时候，出现validation的loss的inf的情况；**\r\n```bash\r\nepoch: 1, progress: 1/100, step: 980, loss: 232.250000, ppl: 697.000000, next_sent_acc: 0.531250, speed: 2.083186 steps\r\n/s, file: part-00054.gz                                                                                                \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000025                                                                                         \r\nepoch: 1, progress: 1/100, step: 1000, loss: 229.500000, ppl: 708.500000, next_sent_acc: 0.609375, speed: 2.078022 step\r\ns/s, file: part-00054.gz                                                                                               \r\n/root/paddlejob/workspace/env_run/predict.py:71: RuntimeWarning: overflow encountered in add                           \r\n  cost += each_total_cost                                                                                              \r\n[validation_set] epoch: 1, step: 816, loss: inf, global ppl: 649.037231, batch-averged ppl: 649.037231, next_sent_acc: \r\n0.491685, speed: 0.245354 steps/s                                                                                      \r\n('feed_queue size', 66L)                                                                                               \r\ncurrent learning_rate:0.000025                                                                                         \r\nepoch: 1, progress: 1/100, step: 1020, loss: 228.000000, ppl: 663.500000, next_sent_acc: 0.567708, speed: 0.219097 step\r\ns/s, file: part-00054.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000026                                                                                         \r\nepoch: 1, progress: 1/100, step: 1040, loss: 227.750000, ppl: 664.000000, next_sent_acc: 0.621875, speed: 2.050249 step\r\ns/s, file: part-00054.gz                                                                                               \r\n('feed_queue size', 70L)                                                                                               \r\ncurrent learning_rate:0.000026                                                                                         \r\nepoch: 1, progress: 1/100, step: 1060, loss: 225.750000, ppl: 646.000000, next_sent_acc: 0.687500, speed: 2.059907 step\r\ns/s, file: part-00054.gz                                                                                               \r\n```\r\n\r\n",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-04-16T11:10:21+00:00",
        "updated_at": "2019-04-16T11:14:10+00:00",
        "closed_at": "2019-04-16T11:13:54+00:00",
        "comments_count": [
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2075,
        "title": "yolov3 eval python3不兼容",
        "body": "在单卡对yolov3的训练模型进行评估，\r\npython eval.py --batch_size=1 --weight=./output/model_iter499999 \r\n报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/56267401-4f137100-6121-11e9-9281-2269821ffa95.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "heavengate",
        "created_at": "2019-04-17T06:59:20+00:00",
        "updated_at": "2019-04-17T08:33:10+00:00",
        "closed_at": "2019-04-17T08:30:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2071,
        "title": "fast_imagenet程序出错有BUG",
        "body": "fast_imagenet程序训练无法正常进行，问题应该出在红框的不能同时，不然就出错：Segmentation fault (core dumped)，请官方检测一下，将bug修复。\r\n![QQ图片20190417180647](https://user-images.githubusercontent.com/45925696/56280720-5fd1e000-613d-11e9-8375-03014ca86ccc.png)\r\n",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "sandyhouse",
        "created_at": "2019-04-17T01:32:40+00:00",
        "updated_at": "2019-06-28T11:32:47+00:00",
        "closed_at": "2019-06-28T11:32:47+00:00",
        "comments_count": [
            "Yancey0623",
            "qianledan",
            "qianledan",
            "sandyhouse",
            "qianledan",
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2076,
        "title": "yolov3 训练速度不稳定",
        "body": "yolov3模型的训练某些Snapshot偶尔会出现训练速度不稳定的问题\r\n![image](https://user-images.githubusercontent.com/37854899/56267803-7454af00-6122-11e9-8199-b206df8eb29d.png)\r\n![image](https://user-images.githubusercontent.com/37854899/56267813-7ae32680-6122-11e9-94f0-34d112e8a37c.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "heavengate",
        "created_at": "2019-04-17T07:07:41+00:00",
        "updated_at": "2019-05-14T11:41:58+00:00",
        "closed_at": "2019-05-14T11:41:58+00:00",
        "comments_count": [
            "heavengate",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2077,
        "title": "word2vec易用性问题",
        "body": "1.preprocess.py第104行dict_path需要改成args.dict_path，不然会报错参数未定义\r\n2.下载命令里建议加上mkdir data，否则执行后text文件位置不对\r\n<img width=\"648\" alt=\"02f60e9f4f809a19b51a31ce0fbb686c\" src=\"https://user-images.githubusercontent.com/46314656/56269225-d4008980-6125-11e9-859c-16b0f29f3586.png\">\r\n3. 命令行中参数后带的/与代码中文件路径里的'/'重了，建议去掉一个，#1941 第一点有指出\r\n4.建议指出在哪个文件下执行测试数据集下载命令\r\n5.建议在预测命令中加上--last index",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "frankwhzhang",
        "created_at": "2019-04-17T07:49:17+00:00",
        "updated_at": "2019-04-17T08:47:16+00:00",
        "closed_at": "2019-04-17T08:47:16+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2082,
        "title": "用图像分类的的例子infer 程序报错",
        "body": "系统centos cuda9  加载MobileNetV2做测试，程序执行到exe.run(program.desc, scope, 0, True, True, fetch_var_name)报错：paddle.fluid.core.EnforceNotMet: Invoke operator fill_constant error.",
        "state": "closed",
        "user": "zhkfu",
        "closed_by": "shippingwang",
        "created_at": "2019-04-17T09:13:48+00:00",
        "updated_at": "2019-04-17T12:09:06+00:00",
        "closed_at": "2019-04-17T12:09:06+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2087,
        "title": "请教：gru训练语言模型，多GPU速度和单GPU速度基本一致，这是什么原因啊？",
        "body": "训练代码：https://github.com/PaddlePaddle/models/blob/develop/PaddleNLP/language_model/gru/train.py\r\n使用的上面给代码，稍微做了一些小修改，修改内容如下。\r\n![image](https://user-images.githubusercontent.com/5926307/56338408-7f6c1580-61dc-11e9-91a8-61e39c26eb17.png)\r\n![image](https://user-images.githubusercontent.com/5926307/56338421-90b52200-61dc-11e9-875b-7a26209b34c5.png)\r\n\r\n运行脚本:\r\n![image](https://user-images.githubusercontent.com/5926307/56338445-a591b580-61dc-11e9-9801-968a8b0d1a74.png)\r\n训练数据：github提供的ptb数据\r\n\r\npaddle版本paddlepaddle-gpu 1.3.0.post85 。\r\n\r\n训练速度：Tesla K40，单卡（GPU）一个epoch约100s，2个卡一个epoch约100s，时间几乎一致。\r\n",
        "state": "closed",
        "user": "Melonzhou",
        "closed_by": "wangguibao",
        "created_at": "2019-04-18T05:23:38+00:00",
        "updated_at": "2019-08-06T03:16:20+00:00",
        "closed_at": "2019-08-06T03:16:20+00:00",
        "comments_count": [
            "gavin1332",
            "Melonzhou",
            "gavin1332",
            "Melonzhou",
            "Melonzhou",
            "gavin1332",
            "gavin1332",
            "Melonzhou",
            "gavin1332",
            "Melonzhou",
            "wangguibao"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2093,
        "title": "请问deepFM怎么处理句子特征呢？",
        "body": "比如a输入的特征是长度为5的句子，b输入的特征是长度为4的句子。\r\n请问下这种情况是需要首先做padding么？还是直接lookup table再做pooling呢？",
        "state": "open",
        "user": "danche354",
        "closed_by": null,
        "created_at": "2019-04-19T00:57:35+00:00",
        "updated_at": "2019-04-19T00:57:35+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2085,
        "title": "rcnn 训练时偶现loss为nan的情况",
        "body": "'loss_rpn_cls': 0.177, time: 0.423\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:33.344396, iter: 31, lr: 0.00375, 'loss_bbox': 0.096, 'loss': 1.305, 'loss_rpn_bbox': 0.2, 'loss_cls': 0.545, 'loss_rpn_cls': 0.199, time: 0.376\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:33.612872, iter: 32, lr: 0.00376, 'loss_bbox': 0.096, 'loss': 1.576, 'loss_rpn_bbox': 0.226, 'loss_cls': 0.569, 'loss_rpn_cls': 0.199, time: 0.417\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:34.029198, iter: 33, lr: 0.00377, 'loss_bbox': 0.104, 'loss': 1.804, 'loss_rpn_bbox': 0.264, 'loss_cls': 0.702, 'loss_rpn_cls': 0.208, time: 0.268\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:34.467100, iter: 34, lr: 0.00379, 'loss_bbox': 0.108, 'loss': 1.804, 'loss_rpn_bbox': 0.292, 'loss_cls': 0.736, 'loss_rpn_cls': 0.212, time: 0.416\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:34.885436, iter: 35, lr: 0.00380, 'loss_bbox': 0.108, 'loss': 1.704, 'loss_rpn_bbox': 0.256, 'loss_cls': 0.736, 'loss_rpn_cls': 0.216, time: 0.438\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:35.298830, iter: 36, lr: 0.00381, 'loss_bbox': 0.11, 'loss': 1.804, 'loss_rpn_bbox': 0.292, 'loss_cls': 0.736, 'loss_rpn_cls': 0.216, time: 0.418\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:35.660818, iter: 37, lr: 0.00383, 'loss_bbox': 0.115, 'loss': 1.886, 'loss_rpn_bbox': 0.356, 'loss_cls': 0.765, 'loss_rpn_cls': 0.228, time: 0.413\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:36.077945, iter: 38, lr: 0.00384, 'loss_bbox': 0.115, 'loss': 2.083, 'loss_rpn_bbox': 0.666, 'loss_cls': 0.855, 'loss_rpn_cls': 0.228, time: 0.362\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:36.487068, iter: 39, lr: 0.00385, 'loss_bbox': 0.134, 'loss': 2.331, 'loss_rpn_bbox': 0.913, 'loss_cls': 0.944, 'loss_rpn_cls': 0.228, time: 0.417\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:36.930706, iter: 40, lr: 0.00387, 'loss_bbox': 0.149, 'loss': 2.488, 'loss_rpn_bbox': 0.934, 'loss_cls': 0.978, 'loss_rpn_cls': 0.252, time: 0.409\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:37.079967, iter: 41, lr: 0.00388, 'loss_bbox': 0.149, 'loss': 2.488, 'loss_rpn_bbox': 0.934, 'loss_cls': 0.978, 'loss_rpn_cls': 0.228, time: 0.444\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:37.238165, iter: 42, lr: 0.00389, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.228, time: 0.149\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:37.385581, iter: 43, lr: 0.00391, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.236, 'loss_cls': nan, 'loss_rpn_cls': 0.237, time: 0.158\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:37.530130, iter: 44, lr: 0.00392, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.275, time: 0.147\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:37.901628, iter: 45, lr: 0.00393, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.275, time: 0.145\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:38.250460, iter: 46, lr: 0.00395, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.275, time: 0.371\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:38.385452, iter: 47, lr: 0.00396, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.292, time: 0.349\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:38.768880, iter: 48, lr: 0.00397, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.342, time: 0.135\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:38.923392, iter: 49, lr: 0.00399, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.439, time: 0.383\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:39.301629, iter: 50, lr: 0.00400, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.062, 'loss_cls': nan, 'loss_rpn_cls': 0.526, time: 0.155\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:39.463345, iter: 51, lr: 0.00401, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 1.288, 'loss_cls': nan, 'loss_rpn_cls': 0.667, time: 0.378\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:39.875876, iter: 52, lr: 0.00403, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 0.814, 'loss_cls': nan, 'loss_rpn_cls': 0.667, time: 0.162\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:40.291572, iter: 53, lr: 0.00404, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 0.777, 'loss_cls': nan, 'loss_rpn_cls': 0.66, time: 0.413\"]\r\n[14:30:06] :\t [Step 3/3] [\"2019-04-17 14:29:40.650109, iter: 54, lr: 0.00405, 'loss_bbox': nan, 'loss': nan, 'loss_rpn_bbox': 0.777, 'loss_cls': nan, 'loss_rpn_cls': 0.66, time: 0.416\"]",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "qingqing01",
        "created_at": "2019-04-18T01:31:45+00:00",
        "updated_at": "2019-04-26T02:13:30+00:00",
        "closed_at": "2019-04-26T02:13:30+00:00",
        "comments_count": [
            "kolinwei",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2089,
        "title": "使用paddle develop分支编译安装的paddle，训练yolov3模型，显存不足 ",
        "body": "paddle develop分支默认显存优化是关闭的，训练yolov3，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/56340584-e55c9b00-61e4-11e9-9053-ecca76777ec6.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "heavengate",
        "created_at": "2019-04-18T06:19:37+00:00",
        "updated_at": "2019-04-18T06:56:43+00:00",
        "closed_at": "2019-04-18T06:56:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2088,
        "title": "图像分类加载预训练模型的时候，怎么修改最后全连接的名字，没找到地方修改？",
        "body": "用mobilenetv2训练，加载预训练模型，不知道怎么修改最后全连接的名字。Enforce failed. Expected x_dims[1] == labels_dims[1], but received x_dims[1]:1000 != labels_dims[1]:6.",
        "state": "closed",
        "user": "zhkfu",
        "closed_by": "shippingwang",
        "created_at": "2019-04-18T06:18:02+00:00",
        "updated_at": "2019-04-19T06:37:58+00:00",
        "closed_at": "2019-04-19T06:37:58+00:00",
        "comments_count": [
            "shippingwang",
            "zhkfu",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2094,
        "title": "模型类型转换",
        "body": "1：咱们paddle有直接将float32的模型转成float16的方式吗？\r\n2：我用1.3版本训练fp16 ，提示'module' object has no attribute 'collective'，看了几个版本，也没找到。\r\n3:有没脚本可以将double的模型转化成fp16 或者int8的",
        "state": "open",
        "user": "zhkfu",
        "closed_by": null,
        "created_at": "2019-04-19T02:56:58+00:00",
        "updated_at": "2019-04-25T02:01:24+00:00",
        "closed_at": null,
        "comments_count": [
            "hjchen2",
            "zhkfu",
            "hjchen2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2095,
        "title": "shufflenetV2 预训练模型",
        "body": "看公开的shufflenetV2 模型https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification#finetuning    没有用PIL库读数据的的top1/top5的准确率，是效果不好，还是没有做。",
        "state": "closed",
        "user": "zhkfu",
        "closed_by": "zhkfu",
        "created_at": "2019-04-19T06:17:21+00:00",
        "updated_at": "2019-04-19T06:42:20+00:00",
        "closed_at": "2019-04-19T06:34:44+00:00",
        "comments_count": [
            "shippingwang",
            "zhkfu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2099,
        "title": "使用ResNet34预训练模型eval报错",
        "body": "paddle使用develop分支编译安装或paddle1.4.0，执行如下指令，\r\npython eval.py --model=ResNet34 --pretrained_model=resnet34/resnet34_pretrained/\r\n报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/56425135-93e80500-62e5-11e9-8863-7909b427e6e0.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-04-19T12:56:31+00:00",
        "updated_at": "2019-05-14T12:09:43+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "JiaXiao243",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2135,
        "title": "ssr在windows环境infer报错",
        "body": "执行指令python infer.py --test_dir test_data --use_cuda 1 --batch_size 50 --model_dir model_output\r\n报错信息如下：\r\nWindows not support stack backtrace yet.\r\n![1](https://user-images.githubusercontent.com/37854899/56582818-ba21e380-660a-11e9-890a-ba53bb9bfc9e.PNG)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-04-23T13:00:15+00:00",
        "updated_at": "2019-04-23T13:00:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2132,
        "title": "bert squad在运行结束后报错",
        "body": "报错在bert squad退出时偶现，结果正常，不影响使用，但影响体验\r\nterminate called without an active exception\r\n*** Aborted at 1555884092 (unix time) try \"date -d @1555884092\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1b593) received by PID 112019 (TID 0x7efcc15fe700) from PID 112019; stack trace: ***\r\n    @     0x7f05bd1af7e0 (unknown)\r\n    @     0x7f05bc5ab4f5 __GI_raise\r\n    @     0x7f05bc5accd5 __GI_abort\r\n    @     0x7f05b68a7a8d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f05b68a5be6 (unknown)\r\n    @     0x7f05b68a5c13 std::terminate()\r\n    @     0x7f05b68a58a6 __gxx_personality_v0\r\n    @     0x7f05b6d1d1ce (unknown)\r\n    @     0x7f05b6d1d2b4 _Unwind_ForcedUnwind\r\n    @     0x7f05bd1adf60 __GI___pthread_unwind\r\n    @     0x7f05bd1a8175 __pthread_exit\r\n    @     0x7f05bd571c5f PyThread_exit_thread\r\n    @     0x7f05bd51e2aa PyEval_RestoreThread\r\n    @     0x7f04d8d7c339 pybind11::gil_scoped_release::~gil_scoped_release()\r\n    @     0x7f04d8d414e3 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE61_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESY_\r\n    @     0x7f04d8d9288e pybind11::cpp_function::dispatcher()\r\n    @     0x7f05bd487fbd _PyCFunction_FastCallDict\r\n    @     0x7f05bd51f138 (unknown)\r\n    @     0x7f05bd522acc _PyEval_EvalFrameDefault\r\n    @     0x7f05bd51efce (unknown)\r\n    @     0x7f05bd51f5f3 PyEval_EvalCodeEx\r\n    @     0x7f05bd4613f3 (unknown)\r\n    @     0x7f05bd42f34a PyObject_Call\r\n    @     0x7f05bd522e55 _PyEval_EvalFrameDefault\r\n    @     0x7f05bd51e660 (unknown)\r\n    @     0x7f05bd51f584 (unknown)\r\n    @     0x7f05bd522acc _PyEval_EvalFrameDefault\r\n    @     0x7f05bd51e660 (unknown)\r\n    @     0x7f05bd51f584 (unknown)\r\n    @     0x7f05bd522acc _PyEval_EvalFrameDefault\r\n    @     0x7f05bd51e660 (unknown)\r\n    @     0x7f05bd527c66 _PyFunction_FastCallDict\r\n\r\n",
        "state": "open",
        "user": "xiegegege",
        "closed_by": null,
        "created_at": "2019-04-23T03:02:19+00:00",
        "updated_at": "2019-04-23T12:59:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2100,
        "title": "图像分类预训练模型易用性",
        "body": "1. 建议解压后的预训练模型命名保持一致，都带pretrained字样或者都不带pretrained字样，并且字母大小写和官网文档提供的一致。\r\n![image](https://user-images.githubusercontent.com/37854899/56425168-b417c400-62e5-11e9-9d95-0657ed7728d3.png)\r\n![image](https://user-images.githubusercontent.com/37854899/56425173-b712b480-62e5-11e9-9086-6f3a6af047c4.png)\r\n2. resnet18和resnet34的预训练模型有2级目录，建议与其他预训练模型保持一致，保留1级目录\r\nresnet18目录下包含resnet18_pretrained子目录和run.log文件，建议仅保留resnet18_pretrained目录\r\n![image](https://user-images.githubusercontent.com/37854899/56425310-44560900-62e6-11e9-8181-15b7924acca3.png)\r\n3. model_list有几个模型名称一样，仅大小写有区别，建议删减区分一下，以免引起歧义；\r\n![image](https://user-images.githubusercontent.com/37854899/56425332-5b94f680-62e6-11e9-8dd0-c73901fc7d01.png)\r\n\r\n   ",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-04-19T13:03:26+00:00",
        "updated_at": "2019-05-14T12:17:36+00:00",
        "closed_at": "2019-05-14T12:17:36+00:00",
        "comments_count": [
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2102,
        "title": "程序升级为1.4，训练fast_imagenet 出现ParallelExecutor is deprecated等信息提示！！",
        "body": "memory_optimize is deprecated. Use CompiledProgram and Executor\r\nParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\nW0421 19:46:12.907804 10233 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nW0421 19:46:13.659762 10233 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 37, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0421 19:46:13.663028 10233 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\nI0421 19:46:15.136268 10233 build_strategy.cc:282] SeqOnlyAllReduceOps:0, num_trainers:1\r\nParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\nW0421 19:46:15.188122 10233 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nshare_vars_from is set, scope is ignored.\r\nI0421 19:46:15.251974 10233 build_strategy.cc:282] SeqOnlyAllReduceOps:0, num_trainers:1\r\n",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-04-21T11:49:56+00:00",
        "updated_at": "2019-05-13T03:16:53+00:00",
        "closed_at": null,
        "comments_count": [
            "qianledan",
            "heavengate",
            "Halfish",
            "qianledan",
            "liyutg",
            "sandyhouse",
            "qianledan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2137,
        "title": "Cannot use CUDAPlace in CPU only version at ",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/sentiment_classification\r\n在学习中文分词训练时顺序执行到\r\n*sh run.sh eval*\r\n遇到下面报错. 因为刚接触.不太清楚如何排查问题\r\n\r\n错误如下:\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 10\r\ncheckpoints: checkpoints\r\ndata_dir: ./senta_data/\r\ndo_infer: False\r\ndo_train: False\r\ndo_val: True\r\nepoch: 10\r\ninit_checkpoint: ./save_models/step_1800/\r\nlr: 0.002\r\nrandom_seed: 0\r\nsave_steps: 10000\r\nsenta_config_path: ./senta_config.json\r\nskip_steps: 10\r\ntask_name: senta\r\nuse_cuda: True\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: ./senta_data//word_dict.txt\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 369, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 164, in main\r\n    place = fluid.CUDAPlace(int(os.getenv('FLAGS_selected_gpus', '0')))\r\npaddle.fluid.core.EnforceNotMet: Cannot use CUDAPlace in CPU only version at [/home/teamcity/work/1ec40e2d88fa641/paddle/fluid/pybind/pybind.cc:806]\r\nPaddlePaddle Call Stacks:\r\n0          0x12186cc97p void paddle::platform::EnforceNotMet::Init<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, char const*, int) + 567\r\n1          0x12186ca00p paddle::platform::EnforceNotMet::EnforceNotMet(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, char const*, int) + 80\r\n2          0x1218ceca5p paddle::pybind::pybind11_init_core(pybind11::module&)::$_76::operator()(paddle::platform::CUDAPlace&, int) const + 69\r\n3          0x1218cec5ep void pybind11::detail::argument_loader<paddle::platform::CUDAPlace&, int>::call_impl<void, paddle::pybind::pybind11_init_core(pybind11::module&)::$_76&, 0ul, 1ul, pybind11::detail::void_type>(paddle::pybind::pybind11_init_core(pybind11::module&)::$_76&&&, pybind11::detail::index_sequence<0ul, 1ul>, pybind11::detail::void_type&&) + 14\r\n4          0x1218cec49p std::__1::enable_if<std::is_void<void>::value, pybind11::detail::void_type>::type pybind11::detail::argument_loader<paddle::platform::CUDAPlace&, int>::call<void, pybind11::detail::void_type, paddle::pybind::pybind11_init_core(pybind11::module&)::$_76&>(paddle::pybind::pybind11_init_core(pybind11::module&)::$_76&&&) + 9\r\n5          0x1218cec39p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init_core(pybind11::module&)::$_76, void, paddle::platform::CUDAPlace&, int, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init_core(pybind11::module&)::$_76&&, void (*)(paddle::platform::CUDAPlace&, int), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 153\r\n6          0x12182f707p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3399\r\n7          0x1085ad2adp PyObject_Call + 97\r\n8          0x1085b7b96p instancemethod_call + 163\r\n9          0x1085ad2adp PyObject_Call + 97\r\n10         0x1085f373bp slot_tp_init + 64\r\n11         0x1085f083ap type_call + 182\r\n12         0x1085ad2adp PyObject_Call + 97\r\n13         0x1086250a7p PyEval_EvalFrameEx + 1971\r\n14         0x108624702p PyEval_EvalCodeEx + 1551\r\n15         0x10862aa79p fast_function + 290\r\n16         0x108624b49p PyEval_EvalFrameEx + 597\r\n17         0x108624702p PyEval_EvalCodeEx + 1551\r\n18         0x1086240edp PyEval_EvalCode + 32\r\n19         0x108642e5fp run_mod + 49\r\n20         0x108642f06p PyRun_FileExFlags + 130\r\n21         0x108642a88p PyRun_SimpleFileExFlags + 706\r\n22         0x108653cf6p Py_Main + 3030\r\n23      0x7fffb35e0235p start + 1\r\n24                0x17p\r\n\r\n```\r\n本地mac mini \r\npython 2.7.15\r\n![image](https://user-images.githubusercontent.com/30944597/56626977-8aa8c080-6676-11e9-9359-345cda83d0bd.png)\r\n",
        "state": "closed",
        "user": "honourfuture",
        "closed_by": "honourfuture",
        "created_at": "2019-04-24T01:51:40+00:00",
        "updated_at": "2019-04-24T02:33:24+00:00",
        "closed_at": "2019-04-24T02:33:24+00:00",
        "comments_count": [
            "honourfuture"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2139,
        "title": "windows下word2vec infer报错",
        "body": "执行指令python infer.py --infer_epoch --test_dir data/test_mid_dir --dict_path data/test_build_dict_word_to_id_ --batch_size 20000 --model_dir v1_cpu5_b100_lr1dir/  --start_index 0 --last_index 0 对word2vec进行infer， 报错信息如下：\r\n![2](https://user-images.githubusercontent.com/37854899/56629580-6e118600-6680-11e9-9024-cafe303f097c.PNG)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-04-24T03:02:28+00:00",
        "updated_at": "2019-04-24T03:02:28+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2138,
        "title": "transformer下按照readme执行train.py报错",
        "body": "按照步骤download demo数据。\r\n但是执行训练 时报错。\r\npython -u train.py   (后面省略，就是示例命令)\r\n...\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 775, in <module>\r\n    train(args)\r\n  File \"train.py\", line 669, in train\r\n    is_test=False)\r\n  File \"../../models/neural_machine_translation/transformer/model.py\", line 552, in transformer\r\n    is_test)\r\n  File \"../../models/neural_machine_translation/transformer/model.py\", line 510, in make_all_py_reader_inputs\r\n    reader = layers.py_reader(\r\n**AttributeError: 'module' object has no attribute 'py_reader‘**",
        "state": "closed",
        "user": "MangoLiu",
        "closed_by": "hjchen2",
        "created_at": "2019-04-24T02:44:41+00:00",
        "updated_at": "2019-04-24T05:18:55+00:00",
        "closed_at": "2019-04-24T05:18:55+00:00",
        "comments_count": [
            "MangoLiu",
            "MangoLiu",
            "hjchen2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2140,
        "title": "window下ssr训练保存模型失败",
        "body": "window环境下，执行python train.py --train_dir train_data --use_cuda 1 --batch_size 50 --model_dir model_output对ssr模型进行训练，输出模型保存失败，报错信息如下：\r\n![3](https://user-images.githubusercontent.com/37854899/56630720-d19db280-6684-11e9-9d9d-78faaeb2e6a7.PNG)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-04-24T03:34:08+00:00",
        "updated_at": "2019-05-13T07:57:41+00:00",
        "closed_at": "2019-05-13T07:57:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2144,
        "title": "sequence_tagging_for_ner数据解压路径错误",
        "body": "sequence_tagging_for_ner的data/download.sh中数据解压路径错误，\r\n cp assignment2_release/data/ner/wordVectors.txt ./data\r\n cp assignment2_release/data/ner/vocab.txt ./data\r\n应改为：\r\n cp assignment2_release/data/ner/wordVectors.txt .\r\n cp assignment2_release/data/ner/vocab.txt .\r\n           \r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "kuke",
        "created_at": "2019-04-24T07:28:06+00:00",
        "updated_at": "2019-04-30T08:57:13+00:00",
        "closed_at": "2019-04-30T08:57:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2145,
        "title": "transformer进行模型预测时报错Segmentation fault",
        "body": "本人是刚接触这个的小白，按照文档走到模型预测这一步时报错：\r\n\r\npython -u infer.py \\\r\n--src_vocab_fpath gen_data/wmt16_ende_data_bpe/vocab_all.bpe.32000 \\\r\n--trg_vocab_fpath gen_data/wmt16_ende_data_bpe/vocab_all.bpe.32000 \\\r\n--special_token '<s>' '<e>' '<unk>' \\\r\n--test_file_pattern gen_data/wmt16_ende_data_bpe/newstest2014.tok.bpe.32000.en-de \\\r\n--token_delimiter ' ' \\\r\n--batch_size 32 \\\r\nmodel_path trained_models/iter_100000.infer.model \\\r\nbeam_size 5 \\\r\nmax_out_len 255\r\n----------------------------------------------------------------------------------------------------------\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\n*** Aborted at 1556128259 (unix time) try \"date -d @1556128259\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x50) received by PID 21182 (TID 0x7f7d33241740) from PID 80; stack trace: ***\r\n    @     0x7f7d32a525d0 (unknown)\r\n    @     0x7f7d33036b16 _dl_relocate_object\r\n    @     0x7f7d3303f59c dl_open_worker\r\n    @     0x7f7d3303a704 _dl_catch_error\r\n    @     0x7f7d3303eabb _dl_open\r\n    @     0x7f7d320a9992 do_dlopen\r\n    @     0x7f7d3303a704 _dl_catch_error\r\n    @     0x7f7d320a9a52 __GI___libc_dlopen_mode\r\n    @     0x7f7d32080e45 init\r\n    @     0x7f7d32a4fe40 __GI___pthread_once\r\n    @     0x7f7d32080f5c __GI___backtrace\r\n    @     0x7f7d0448c728 paddle::platform::EnforceNotMet::Init<>()\r\n    @     0x7f7d0448ca77 paddle::platform::EnforceNotMet::EnforceNotMet()\r\n    @     0x7f7d0446e334 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_8platform9CUDAPlaceEiE76_vIS8_iEINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESQ_\r\n    @     0x7f7d044bbfce pybind11::cpp_function::dispatcher()\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32cb9a55 (unknown)\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32d01a87 (unknown)\r\n    @     0x7f7d32d0079f (unknown)\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32d3f236 PyEval_EvalFrameEx\r\n    @     0x7f7d32d436bd PyEval_EvalFrameEx\r\n    @     0x7f7d32d4603d PyEval_EvalCodeEx\r\n    @     0x7f7d32d46142 PyEval_EvalCode\r\n    @     0x7f7d32d5f57f (unknown)\r\n    @     0x7f7d32d6073e PyRun_FileExFlags\r\n    @     0x7f7d32d619c9 PyRun_SimpleFileExFlags\r\n    @     0x7f7d32d72b7f Py_Main\r\n    @     0x7f7d31f8f3d5 __libc_start_main\r\n    @           0x40066e (unknown)\r\n    @                0x0 (unknown)\r\nSegmentation fault\r\n\r\n我是在自己电脑上的虚拟机跑的，请问是因为显存的问题吗？\r\n那么可不可以设置为使用CPU呢",
        "state": "closed",
        "user": "FiveSpeedFrog",
        "closed_by": "FiveSpeedFrog",
        "created_at": "2019-04-24T09:59:33+00:00",
        "updated_at": "2019-04-24T10:02:54+00:00",
        "closed_at": "2019-04-24T10:02:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2146,
        "title": "transformer模型预测时报错：Segmentation fault",
        "body": "按照文档执行到python  -u infer.py时报错如下：",
        "state": "closed",
        "user": "FiveSpeedFrog",
        "closed_by": "FiveSpeedFrog",
        "created_at": "2019-04-24T10:12:05+00:00",
        "updated_at": "2019-04-24T10:12:14+00:00",
        "closed_at": "2019-04-24T10:12:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2147,
        "title": "transformer模型预测时报错：Segmentation fault",
        "body": "按照文档执行到python -u infer.py时报错如下：\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\n*** Aborted at 1556128259 (unix time) try \"date -d @1556128259\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x50) received by PID 21182 (TID 0x7f7d33241740) from PID 80; stack trace: ***\r\n    @     0x7f7d32a525d0 (unknown)\r\n    @     0x7f7d33036b16 _dl_relocate_object\r\n    @     0x7f7d3303f59c dl_open_worker\r\n    @     0x7f7d3303a704 _dl_catch_error\r\n    @     0x7f7d3303eabb _dl_open\r\n    @     0x7f7d320a9992 do_dlopen\r\n    @     0x7f7d3303a704 _dl_catch_error\r\n    @     0x7f7d320a9a52 __GI___libc_dlopen_mode\r\n    @     0x7f7d32080e45 init\r\n    @     0x7f7d32a4fe40 __GI___pthread_once\r\n    @     0x7f7d32080f5c __GI___backtrace\r\n    @     0x7f7d0448c728 paddle::platform::EnforceNotMet::Init<>()\r\n    @     0x7f7d0448ca77 paddle::platform::EnforceNotMet::EnforceNotMet()\r\n    @     0x7f7d0446e334 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_8platform9CUDAPlaceEiE76_vIS8_iEINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESQ_\r\n    @     0x7f7d044bbfce pybind11::cpp_function::dispatcher()\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32cb9a55 (unknown)\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32d01a87 (unknown)\r\n    @     0x7f7d32d0079f (unknown)\r\n    @     0x7f7d32caaa63 PyObject_Call\r\n    @     0x7f7d32d3f236 PyEval_EvalFrameEx\r\n    @     0x7f7d32d436bd PyEval_EvalFrameEx\r\n    @     0x7f7d32d4603d PyEval_EvalCodeEx\r\n    @     0x7f7d32d46142 PyEval_EvalCode\r\n    @     0x7f7d32d5f57f (unknown)\r\n    @     0x7f7d32d6073e PyRun_FileExFlags\r\n    @     0x7f7d32d619c9 PyRun_SimpleFileExFlags\r\n    @     0x7f7d32d72b7f Py_Main\r\n    @     0x7f7d31f8f3d5 __libc_start_main\r\n    @           0x40066e (unknown)\r\n    @                0x0 (unknown)\r\nSegmentation fault\r\n请问是GPU的问题吗",
        "state": "open",
        "user": "FiveSpeedFrog",
        "closed_by": null,
        "created_at": "2019-04-24T10:14:13+00:00",
        "updated_at": "2019-04-24T10:14:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2142,
        "title": "window下language_models中的gru模型训练失败",
        "body": "window下执行python train.py 对language_models中的gru模型进行训练，window环境为cuda8, cudnn7,报错信息如下：\r\n![4](https://user-images.githubusercontent.com/37854899/56636688-2bf63d80-669c-11e9-90f2-0eec968cb012.PNG)\r\n\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-04-24T06:21:16+00:00",
        "updated_at": "2019-04-30T08:45:54+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2148,
        "title": "metric_learning 进行图片度量学习报There is no next data错误",
        "body": "目前环境是paddlepaddle 1.3.2版本，使用cpu训练（机器无gpu），修改了train_elem.py中devicenum数量\r\n![image](https://user-images.githubusercontent.com/5515268/56655861-80161780-66c6-11e9-91f6-ffcc5c9df178.png)\r\n执行报错\r\n![image](https://user-images.githubusercontent.com/5515268/56655968-cf5c4800-66c6-11e9-8a1c-b7b6279a64fd.png)\r\n\r\n",
        "state": "open",
        "user": "demohold",
        "closed_by": null,
        "created_at": "2019-04-24T11:26:13+00:00",
        "updated_at": "2019-04-24T11:26:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2150,
        "title": "PaddleCV/image_classification/models/GoogleNet  模型训练时报错",
        "body": "**因为使用了自定义数据集，所以修改了读取数据的代码 **\r\n### 系统信息\r\npaddle 版本 1.3.2 clone image_classification作为demo 使用自己数据集\r\nGPU 型号\r\nTesla K40m 11441MiB \r\nPlease NOTE: device: 1, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\ndevice: 0, cuDNN Version: 7.0.\r\n\r\n- 版本、环境信息：\r\n    1）GPU：Tesla K40m 11441MiB 、CUDA和CUDNN版本号 device: 0, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\n    2）系统环境：请您描述系统类型、版本，ubuntu 14.0，Python版本3.6\r\n\r\n- 训练信息\r\n    1）单机 单卡\r\n    2）显存信息 Tesla K40m 11441MiB \r\n\r\n### 配置信息\r\n```\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 128\r\n               checkpoint : None\r\n                class_dim : 61\r\n                 data_dir : ./data/ILSVRC2012\r\n                enable_ce : False\r\n                     fp16 : False\r\n              image_shape : 3,224,224\r\n              infer_model : ./infer_models\r\n                 l2_decay : 0.0001\r\n                       lr : 0.01\r\n              lr_strategy : piecewise_decay\r\n                    model : GoogleNet\r\n           model_save_dir : output/\r\n            momentum_rate : 0.9\r\n               num_epochs : 100\r\n         pretrained_model : None\r\n               scale_loss : 1.0\r\n              test_images : 4540\r\n             total_images : 31718\r\n                  use_gpu : True\r\n               visual_num : 1000\r\n             with_mem_opt : 1\r\n----------------------------------------------------\r\nW0425 00:56:32.982301 18073 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0425 00:56:32.982357 18073 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\n\r\n```\r\n### 训练信息\r\n![image](https://user-images.githubusercontent.com/23010064/56680630-321b0700-66fa-11e9-832f-781b1f8cea76.png)\r\n\r\n### 报错信息\r\n```\r\nass 0, trainbatch 0, loss 6.58166,                                             acc1 0.00781, acc5 0.05469, lr 0.01000, time 1.61 sec, scalar_train_index 0\r\nPass 0, trainbatch 24, loss 6.21634,                                             acc1 0.07812, acc5 0.18750, lr 0.01000, time 0.91 sec, scalar_train_index 1\r\nPass 0, trainbatch 48, loss 5.91886,                                             acc1 0.11719, acc5 0.31250, lr 0.01000, time 0.93 sec, scalar_train_index 2\r\nPass 0, trainbatch 72, loss 5.29668,                                             acc1 0.14062, acc5 0.45312, lr 0.01000, time 0.88 sec, scalar_train_index 3\r\nPass 0, trainbatch 96, loss 4.89611,                                             acc1 0.21875, acc5 0.55469, lr 0.01000, time 0.90 sec, scalar_train_index 4\r\nPass 0, trainbatch 120, loss 4.85930,                                             acc1 0.22656, acc5 0.51562, lr 0.01000, time 0.88 sec, scalar_train_index 5\r\nPass 0, trainbatch 144, loss 4.89562,                                             acc1 0.24219, acc5 0.53125, lr 0.01000, time 0.88 sec, scalar_train_index 6\r\nPass 0, trainbatch 168, loss 4.63307,                                             acc1 0.24219, acc5 0.53125, lr 0.01000, time 0.88 sec, scalar_train_index 7\r\nPass 0, trainbatch 192, loss 4.11545,                                             acc1 0.34375, acc5 0.67188, lr 0.01000, time 0.88 sec, scalar_train_index 8\r\nPass 0, trainbatch 216, loss 4.23675,                                             acc1 0.32031, acc5 0.60938, lr 0.01000, time 0.88 sec, scalar_train_index 9\r\nPass 0, trainbatch 240, loss 4.18755,                                             acc1 0.28125, acc5 0.63281, lr 0.01000, time 0.88 sec, scalar_train_index 10\r\nPass 0,testbatch 0,loss 6.68680,                                             acc1 0.00000,acc5 0.06250,time 0.34 sec ,scalar_test_index 0\r\nPass 0,testbatch 24,loss 1.63023,                                             acc1 0.31250,acc5 1.00000,time 0.07 sec ,scalar_test_index 1\r\nPass 0,testbatch 48,loss 4.17449,                                             acc1 0.43750,acc5 0.93750,time 0.08 sec ,scalar_test_index 2\r\nPass 0,testbatch 72,loss 2.61009,                                             acc1 0.43750,acc5 1.00000,time 0.08 sec ,scalar_test_index 3\r\nPass 0,testbatch 96,loss 6.07975,                                             acc1 0.18750,acc5 0.25000,time 0.08 sec ,scalar_test_index 4\r\nPass 0,testbatch 120,loss 1.64130,                                             acc1 0.62500,acc5 0.87500,time 0.08 sec ,scalar_test_index 5\r\nPass 0,testbatch 144,loss 1.27195,                                             acc1 0.75000,acc5 1.00000,time 0.08 sec ,scalar_test_index 6\r\nPass 0,testbatch 168,loss 6.13589,                                             acc1 0.00000,acc5 0.25000,time 0.08 sec ,scalar_test_index 7\r\nPass 0,testbatch 192,loss 2.45174,                                             acc1 0.87500,acc5 0.87500,time 0.07 sec ,scalar_test_index 8\r\nPass 0,testbatch 216,loss 4.23638,                                             acc1 0.37500,acc5 0.75000,time 0.07 sec ,scalar_test_index 9\r\nPass 0,testbatch 240,loss 1.77212,                                             acc1 0.68750,acc5 0.93750,time 0.07 sec ,scalar_test_index 10\r\nPass 0,testbatch 264,loss 3.91363,                                             acc1 0.37500,acc5 0.75000,time 0.07 sec ,scalar_test_index 11\r\nEnd pass 0, train_loss 4.95904, train_acc1 0.22267, train_acc5 0.51104, test_loss 3.59753, test_acc1 0.40449, test_acc5 0.72014\r\nPass 1, trainbatch 0, loss 4.20429,                                             acc1 0.29688, acc5 0.73438, lr 0.01000, time 1.61 sec, scalar_train_index 11\r\nPass 1, trainbatch 24, loss 3.92477,                                             acc1 0.36719, acc5 0.68750, lr 0.01000, time 0.90 sec, scalar_train_index 12\r\nPass 1, trainbatch 48, loss 4.04725,                                             acc1 0.27344, acc5 0.66406, lr 0.01000, time 0.89 sec, scalar_train_index 13\r\nPass 1, trainbatch 72, loss 3.83627,                                             acc1 0.30469, acc5 0.71094, lr 0.01000, time 0.92 sec, scalar_train_index 14\r\nPass 1, trainbatch 96, loss 6.53986,                                             acc1 0.07031, acc5 0.20312, lr 0.01000, time 0.88 sec, scalar_train_index 15\r\nPass 1, trainbatch 120, loss 6.48425,                                             acc1 0.03906, acc5 0.28125, lr 0.01000, time 0.88 sec, scalar_train_index 16\r\nPass 1, trainbatch 144, loss 6.45244,                                             acc1 0.05469, acc5 0.28906, lr 0.01000, time 0.89 sec, scalar_train_index 17\r\nPass 1, trainbatch 168, loss 6.45208,                                             acc1 0.08594, acc5 0.20312, lr 0.01000, time 0.87 sec, scalar_train_index 18\r\nPass 1, trainbatch 192, loss 6.40190,                                             acc1 0.11719, acc5 0.34375, lr 0.01000, time 0.87 sec, scalar_train_index 19\r\nPass 1, trainbatch 216, loss 6.41929,                                             acc1 0.07812, acc5 0.19531, lr 0.01000, time 0.87 sec, scalar_train_index 20\r\nPass 1, trainbatch 240, loss 6.36903,                                             acc1 0.09375, acc5 0.28906, lr 0.01000, time 0.87 sec, scalar_train_index 21\r\nPass 1,testbatch 0,loss 6.78550,                                             acc1 0.00000,acc5 0.00000,time 0.15 sec ,scalar_test_index 12\r\nPass 1,testbatch 24,loss 5.59329,                                             acc1 1.00000,acc5 1.00000,time 0.06 sec ,scalar_test_index 13\r\nPass 1,testbatch 48,loss 6.63706,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 14\r\nPass 1,testbatch 72,loss 6.58967,                                             acc1 0.00000,acc5 0.00000,time 0.08 sec ,scalar_test_index 15\r\nPass 1,testbatch 96,loss 6.71620,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 16\r\nPass 1,testbatch 120,loss 5.87767,                                             acc1 0.00000,acc5 0.93750,time 0.07 sec ,scalar_test_index 17\r\nPass 1,testbatch 144,loss 5.82598,                                             acc1 0.00000,acc5 1.00000,time 0.06 sec ,scalar_test_index 18\r\nPass 1,testbatch 168,loss 6.67258,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 19\r\nPass 1,testbatch 192,loss 6.20472,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 20\r\nPass 1,testbatch 216,loss 6.26085,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 21\r\nPass 1,testbatch 240,loss 6.48922,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 22\r\nPass 1,testbatch 264,loss 6.29944,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 23\r\nEnd pass 1, train_loss 6.07456, train_acc1 0.16669, train_acc5 0.41099, test_loss 6.34295, test_acc1 0.07768, test_acc5 0.28389\r\nPass 2, trainbatch 0, loss 6.30323,                                             acc1 0.11719, acc5 0.32031, lr 0.01000, time 1.54 sec, scalar_train_index 22\r\nPass 2, trainbatch 24, loss 6.33684,                                             acc1 0.08594, acc5 0.25781, lr 0.01000, time 0.91 sec, scalar_train_index 23\r\nPass 2, trainbatch 48, loss 6.27985,                                             acc1 0.06250, acc5 0.28125, lr 0.01000, time 0.93 sec, scalar_train_index 24\r\nPass 2, trainbatch 72, loss 6.29569,                                             acc1 0.07031, acc5 0.28125, lr 0.01000, time 0.87 sec, scalar_train_index 25\r\nPass 2, trainbatch 96, loss 6.24136,                                             acc1 0.09375, acc5 0.28906, lr 0.01000, time 0.87 sec, scalar_train_index 26\r\nPass 2, trainbatch 120, loss 6.27440,                                             acc1 0.07812, acc5 0.30469, lr 0.01000, time 0.87 sec, scalar_train_index 27\r\nPass 2, trainbatch 144, loss 6.16809,                                             acc1 0.11719, acc5 0.33594, lr 0.01000, time 0.87 sec, scalar_train_index 28\r\nPass 2, trainbatch 168, loss 6.29105,                                             acc1 0.06250, acc5 0.21094, lr 0.01000, time 0.87 sec, scalar_train_index 29\r\nPass 2, trainbatch 192, loss 6.24925,                                             acc1 0.03906, acc5 0.26562, lr 0.01000, time 0.87 sec, scalar_train_index 30\r\nPass 2, trainbatch 216, loss 6.20490,                                             acc1 0.11719, acc5 0.25000, lr 0.01000, time 0.87 sec, scalar_train_index 31\r\nPass 2, trainbatch 240, loss 6.21943,                                             acc1 0.06250, acc5 0.25000, lr 0.01000, time 0.87 sec, scalar_train_index 32\r\nPass 2,testbatch 0,loss 7.05680,                                             acc1 0.00000,acc5 0.00000,time 0.43 sec ,scalar_test_index 24\r\nPass 2,testbatch 24,loss 4.81013,                                             acc1 1.00000,acc5 1.00000,time 0.07 sec ,scalar_test_index 25\r\nPass 2,testbatch 48,loss 6.74531,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 26\r\nPass 2,testbatch 72,loss 6.61791,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 27\r\nPass 2,testbatch 96,loss 6.89023,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 28\r\nPass 2,testbatch 120,loss 5.39686,                                             acc1 0.00000,acc5 0.93750,time 0.07 sec ,scalar_test_index 29\r\nPass 2,testbatch 144,loss 5.29587,                                             acc1 0.00000,acc5 1.00000,time 0.07 sec ,scalar_test_index 30\r\nPass 2,testbatch 168,loss 6.78932,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 31\r\nPass 2,testbatch 192,loss 5.88945,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 32\r\nPass 2,testbatch 216,loss 6.10050,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 33\r\nPass 2,testbatch 240,loss 6.39842,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 34\r\nPass 2,testbatch 264,loss 6.07916,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 35\r\nEnd pass 2, train_loss 6.26088, train_acc1 0.07803, train_acc5 0.28214, test_loss 6.19724, test_acc1 0.07768, test_acc5 0.28389\r\nPass 3, trainbatch 0, loss 6.24757,                                             acc1 0.03125, acc5 0.25000, lr 0.01000, time 1.56 sec, scalar_train_index 33\r\nPass 3, trainbatch 24, loss 6.22961,                                             acc1 0.07812, acc5 0.25781, lr 0.01000, time 0.87 sec, scalar_train_index 34\r\nPass 3, trainbatch 48, loss 6.18353,                                             acc1 0.07812, acc5 0.24219, lr 0.01000, time 0.87 sec, scalar_train_index 35\r\nPass 3, trainbatch 72, loss 6.25078,                                             acc1 0.05469, acc5 0.21875, lr 0.01000, time 0.87 sec, scalar_train_index 36\r\nPass 3, trainbatch 96, loss 6.16289,                                             acc1 0.03906, acc5 0.29688, lr 0.01000, time 0.89 sec, scalar_train_index 37\r\nPass 3, trainbatch 120, loss 6.16478,                                             acc1 0.05469, acc5 0.29688, lr 0.01000, time 0.88 sec, scalar_train_index 38\r\nPass 3, trainbatch 144, loss 6.20497,                                             acc1 0.04688, acc5 0.24219, lr 0.01000, time 0.87 sec, scalar_train_index 39\r\nPass 3, trainbatch 168, loss 6.09273,                                             acc1 0.07031, acc5 0.32031, lr 0.01000, time 0.87 sec, scalar_train_index 40\r\nPass 3, trainbatch 192, loss 6.10254,                                             acc1 0.11719, acc5 0.28125, lr 0.01000, time 0.87 sec, scalar_train_index 41\r\nPass 3, trainbatch 216, loss 6.04383,                                             acc1 0.10938, acc5 0.30469, lr 0.01000, time 0.87 sec, scalar_train_index 42\r\nPass 3, trainbatch 240, loss 6.13893,                                             acc1 0.07812, acc5 0.25000, lr 0.01000, time 0.87 sec, scalar_train_index 43\r\nPass 3,testbatch 0,loss 7.25361,                                             acc1 0.00000,acc5 0.00000,time 0.20 sec ,scalar_test_index 36\r\nPass 3,testbatch 24,loss 4.50071,                                             acc1 1.00000,acc5 1.00000,time 0.07 sec ,scalar_test_index 37\r\nPass 3,testbatch 48,loss 6.80605,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 38\r\nPass 3,testbatch 72,loss 6.62261,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 39\r\nPass 3,testbatch 96,loss 7.07348,                                             acc1 0.00000,acc5 0.00000,time 0.08 sec ,scalar_test_index 40\r\nPass 3,testbatch 120,loss 5.02440,                                             acc1 0.00000,acc5 1.00000,time 0.08 sec ,scalar_test_index 41\r\nPass 3,testbatch 144,loss 5.04806,                                             acc1 0.00000,acc5 1.00000,time 0.06 sec ,scalar_test_index 42\r\nPass 3,testbatch 168,loss 6.88153,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 43\r\nPass 3,testbatch 192,loss 5.70489,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 44\r\nPass 3,testbatch 216,loss 5.98661,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 45\r\nPass 3,testbatch 240,loss 6.33267,                                             acc1 0.00000,acc5 0.00000,time 0.06 sec ,scalar_test_index 46\r\nPass 3,testbatch 264,loss 5.92419,                                             acc1 0.00000,acc5 0.00000,time 0.07 sec ,scalar_test_index 47\r\nEnd pass 3, train_loss 6.16399, train_acc1 0.07803, train_acc5 0.28201, test_loss 6.13189, test_acc1 0.07768, test_acc5 0.28389\r\nPass 4, trainbatch 0, loss 6.19262,                                             acc1 0.06250, acc5 0.27344, lr 0.01000, time 1.48 sec, scalar_train_index 44\r\nPass 4, trainbatch 24, loss 6.09134,                                             acc1 0.04688, acc5 0.29688, lr 0.01000, time 0.91 sec, scalar_train_index 45\r\nPass 4, trainbatch 48, loss 6.10587,                                             acc1 0.11719, acc5 0.28125, lr 0.01000, time 0.91 sec, scalar_train_index 46\r\nPass 4, trainbatch 72, loss 6.08864,                                             acc1 0.06250, acc5 0.32031, lr 0.01000, time 0.87 sec, scalar_train_index 47\r\nPass 4, trainbatch 96, loss 6.17017,                                             acc1 0.06250, acc5 0.26562, lr 0.01000, time 0.87 sec, scalar_train_index 48\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 536, in <module>\r\n    main()\r\n  File \"train.py\", line 532, in main\r\n    train(args)\r\n  File \"train.py\", line 401, in train\r\n    fetch_list=train_fetch_list)\r\n  File \"/home/fzuir/.local/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: an illegal memory access was encountered at [/paddle/paddle/fluid/platform/device_context.cc:328]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f93dc29de45p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f93dc29e1c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f93dddf8aa6p\r\n3       0x7f93dde1b1b4p paddle::platform::TemporaryAllocator::Release(std::function<void ()> const&) + 100\r\n4       0x7f93dddfaac1p paddle::platform::CUDADeviceContext::Wait() const + 113\r\n5       0x7f93ddb7b285p paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 1445\r\n6       0x7f93dc3d91f2p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 562\r\n7       0x7f93dc28dfcep\r\n8       0x7f93dc2c91eep\r\n9       0x7f942c334302p _PyCFunction_FastCallDict + 258\r\n10      0x7f942c3b995bp\r\n11      0x7f942c3bcd40p _PyEval_EvalFrameDefault + 11328\r\n12      0x7f942c3b8100p\r\n13      0x7f942c3b9b2ap\r\n14      0x7f942c3bd2ccp _PyEval_EvalFrameDefault + 12748\r\n15      0x7f942c3b8100p\r\n16      0x7f942c3b9b2ap\r\n17      0x7f942c3bcd40p _PyEval_EvalFrameDefault + 11328\r\n18      0x7f942c3b7514p\r\n19      0x7f942c3b9c88p\r\n20      0x7f942c3bcd40p _PyEval_EvalFrameDefault + 11328\r\n21      0x7f942c3b8100p\r\n22      0x7f942c3b8583p PyEval_EvalCodeEx + 99\r\n23      0x7f942c3b85cbp PyEval_EvalCode + 59\r\n24      0x7f942c3eaee0p PyRun_FileExFlags + 304\r\n25      0x7f942c3ec4a3p PyRun_SimpleFileExFlags + 371\r\n26      0x7f942c4078d5p Py_Main + 3621\r\n27            0x400c1dp main + 365\r\n28      0x7f942b396f45p __libc_start_main + 245\r\n29            0x4009e9p\r\n\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():  an illegal memory access was encountered at [/paddle/paddle/fluid/platform/device_context.cc:328]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f93dc29de45p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 357\r\n1       0x7f93dc29e1c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f93dddf8aa6p\r\n3       0x7f93dde1b1b4p paddle::platform::TemporaryAllocator::Release(std::function<void ()> const&) + 100\r\n4       0x7f93dddfaac1p paddle::platform::CUDADeviceContext::Wait() const + 113\r\n5       0x7f93dc3d7102p paddle::framework::ParallelExecutor::~ParallelExecutor() + 98\r\n6       0x7f93dc29933ap\r\n7       0x7f93dc2ccbfap\r\n8       0x7f93dc2ccd7fp\r\n9       0x7f942c329c3dp\r\n10      0x7f942c348bd5p\r\n11      0x7f942c30e632p\r\n12      0x7f942c3f65a7p\r\n13      0x7f942c3f65b7p\r\n14      0x7f942c3f65b7p\r\n15      0x7f942c327e57p\r\n16      0x7f942c328690p PyDict_SetItemString + 64\r\n17      0x7f942c3db723p PyImport_Cleanup + 131\r\n18      0x7f942c3e8523p Py_FinalizeEx + 115\r\n19      0x7f942c40711ap Py_Main + 1642\r\n20            0x400c1dp main + 365\r\n21      0x7f942b396f45p __libc_start_main + 245\r\n22            0x4009e9p\r\n\r\n*** Aborted at 1556126047 (unix time) try \"date -d @1556126047\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x3e800004699) received by PID 18073 (TID 0x7f942cb6e740) from PID 18073; stack trace: ***\r\n    @     0x7f942c063330 (unknown)\r\n    @     0x7f942b3abc37 gsignal\r\n    @     0x7f942b3af028 abort\r\n    @     0x7f9429eb6415 __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f9429eb4206 (unknown)\r\n    @     0x7f9429eb31c9 (unknown)\r\n    @     0x7f9429eb3b38 __gxx_personality_v0\r\n    @     0x7f9429c42f43 (unknown)\r\n    @     0x7f9429c4376e _Unwind_Resume\r\n    @     0x7f93dddfab93 paddle::platform::CUDADeviceContext::Wait()\r\n    @     0x7f93dc3d7102 paddle::framework::ParallelExecutor::~ParallelExecutor()\r\n    @     0x7f93dc29933a pybind11::class_<>::dealloc()\r\n    @     0x7f93dc2ccbfa pybind11::detail::clear_instance()\r\n    @     0x7f93dc2ccd7f pybind11_object_dealloc\r\n    @     0x7f942c329c3d dict_dealloc\r\n    @     0x7f942c348bd5 subtype_dealloc\r\n    @     0x7f942c30e632 frame_dealloc\r\n    @     0x7f942c3f65a7 tb_dealloc\r\n    @     0x7f942c3f65b7 tb_dealloc\r\n    @     0x7f942c3f65b7 tb_dealloc\r\n    @     0x7f942c327e57 insertdict\r\n    @     0x7f942c328690 PyDict_SetItemString\r\n    @     0x7f942c3db723 PyImport_Cleanup\r\n    @     0x7f942c3e8523 Py_FinalizeEx\r\n    @     0x7f942c40711a Py_Main\r\n    @           0x400c1d main\r\n    @     0x7f942b396f45 __libc_start_main\r\n    @           0x4009e9 (unknown)\r\n\r\n```",
        "state": "open",
        "user": "liyutg",
        "closed_by": null,
        "created_at": "2019-04-24T17:45:47+00:00",
        "updated_at": "2019-04-24T17:45:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2149,
        "title": "reading_comprehension 训练报错",
        "body": "gpu：v100   4卡\r\npython run.py --train 跑Demo数据\r\n\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 647, in <module>\r\n    train(logger, args)\r\n  File \"run.py\", line 473, in train\r\n    pass_id, \"%.10f\" % (1.0 * total_loss / total_num)))\r\nZeroDivisionError: float division by zero",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "HongyuLi2018",
        "created_at": "2019-04-24T11:35:52+00:00",
        "updated_at": "2019-05-07T08:49:16+00:00",
        "closed_at": "2019-05-07T08:49:15+00:00",
        "comments_count": [
            "HongyuLi2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2153,
        "title": "icnet utils.py should import fluid",
        "body": "03:09:17]W:\t [Step 3/3] W0425 03:09:17.928939 22016 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\n[03:09:23]W:\t [Step 3/3] Traceback (most recent call last):\r\n[03:09:23]W:\t [Step 3/3]   File \"train.py\", line 155, in <module>\r\n[03:09:23]W:\t [Step 3/3]     main()\r\n[03:09:23]W:\t [Step 3/3]   File \"train.py\", line 151, in main\r\n[03:09:23]W:\t [Step 3/3]     train(args)\r\n[03:09:23]W:\t [Step 3/3]   File \"train.py\", line 122, in train\r\n[03:09:23]W:\t [Step 3/3]     feed=get_feeder_data(data, place),\r\n[03:09:23]W:\t [Step 3/3]   File \"/workspace/modelce/tasks/icnet/utils.py\", line 82, in get_feeder_data\r\n[03:09:23]W:\t [Step 3/3]     image_t = fluid.LoDTensor()\r\n[03:09:23]W:\t [Step 3/3] NameError: global name 'fluid' is not defined",
        "state": "open",
        "user": "kolinwei",
        "closed_by": null,
        "created_at": "2019-04-25T05:08:50+00:00",
        "updated_at": "2019-04-30T08:27:15+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2154,
        "title": "box_clip出现段错误",
        "body": "使用bbox_clip的时候，出现段错误，具体代码如下。\r\n```\r\ncls_prob  = sum(cascade_cls_prob) # shape: (-1, class_num)\r\n# decoded_bbox shape：(-1, clsss_num*4)\r\ndecoded_bbox = fluid.layers.reshape(decoded_bbox, shape=(0, cfg.class_num, 4) )\r\ncliped_box = fluid.layers.box_clip( input=decoded_bbox, im_info=self.im_info )\r\n````\r\n出现段错误\r\n```\r\n*** Aborted at 1556170041 (unix time) try \"date -d @1556170041\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0xfffffffffffffff0) received by PID 22054 (TID 0x7ff1fc431700) from PID 18446744073709551600; stack trace: ***\r\n    @     0x7ff1fbbe7160 (unknown)\r\n    @     0x7ff1b5011292 paddle::operators::GPUBoxClipKernel<>::Compute()\r\n    @     0x7ff1b50116b3 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EJNS0_9operators16GPUBoxClipKernelINS7_17CUDADeviceContextEfEENSA_ISB_dEEEEclEPKcSG_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\n    @     0x7ff1b53f1ceb paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7ff1b53f010c paddle::framework::OperatorBase::Run()\r\n    @     0x7ff1b3c0751a paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7ff1b3c094f5 paddle::framework::Executor::Run()\r\n    @     0x7ff1b3ac605b _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbE103_vIS8_SB_SD_ibbEINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESV_\r\n    @     0x7ff1b3b0720e pybind11::cpp_function::dispatcher()\r\n    @     0x7ff1fbf0255f PyEval_EvalFrameEx\r\n    @     0x7ff1fbf0486d PyEval_EvalCodeEx\r\n    @     0x7ff1fbf019fc PyEval_EvalFrameEx\r\n    @     0x7ff1fbf0486d PyEval_EvalCodeEx\r\n    @     0x7ff1fbf019fc PyEval_EvalFrameEx\r\n    @     0x7ff1fbf0486d PyEval_EvalCodeEx\r\n    @     0x7ff1fbf019fc PyEval_EvalFrameEx\r\n    @     0x7ff1fbf0486d PyEval_EvalCodeEx\r\n    @     0x7ff1fbf019fc PyEval_EvalFrameEx\r\n    @     0x7ff1fbf01b17 PyEval_EvalFrameEx\r\n    @     0x7ff1fbf0486d PyEval_EvalCodeEx\r\n    @     0x7ff1fbf049a2 PyEval_EvalCode\r\n    @     0x7ff1fbf2d782 PyRun_FileExFlags\r\n    @     0x7ff1fbf2eaf9 PyRun_SimpleFileExFlags\r\n    @     0x7ff1fbf4482d Py_Main\r\n    @     0x7ff1fb141bd5 __libc_start_main\r\n    @           0x4007a1 (unknown)\r\n    @                0x0 (unknown)\r\nSegmentation fault\r\n```\r\n麻烦帮忙看下，谢谢。",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "jerrywgz",
        "created_at": "2019-04-25T05:36:52+00:00",
        "updated_at": "2019-12-20T13:28:01+00:00",
        "closed_at": "2019-12-20T13:28:01+00:00",
        "comments_count": [
            "jerrywgz",
            "littletomatodonkey",
            "littletomatodonkey",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2164,
        "title": "generate_chinese_poetry",
        "body": "generate_chinese_poetry 不支持paddle1.4",
        "state": "open",
        "user": "saigequn",
        "closed_by": null,
        "created_at": "2019-04-26T11:50:31+00:00",
        "updated_at": "2019-04-26T11:50:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2157,
        "title": "Windows系统不支持ParallelExecutor，影响模型训练列表",
        "body": "由于Windows系统不支持ParallelExecutor这个API，在window环境下跑模型训练，很多都会报如下错误：\r\n![image](https://user-images.githubusercontent.com/37854899/56736539-fa17d080-679a-11e9-85a9-69f72aa25fd5.png)\r\n包括：face_detection、cycle_gan、image_classification、metric_learning、object_detection、\r\nvideo_classification、deep_attantion_matching_net、gru、transformer等等模型。\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-04-25T12:46:41+00:00",
        "updated_at": "2019-06-11T06:47:17+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315",
            "wopeizl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2156,
        "title": "models/PaddleCV/yolo3训练时报错",
        "body": "一：在用paddle1.4.0和1.4.1训练yolov3时报如下错误：\r\nFile \"train.py\"，line 154，in <module>\r\n          train()\r\nC++ Callstacks:\r\nEnforce failed. Expected out_dims[j] == ins[i][j], but received out_dims[j]:38 != ins[i][j]:32.\r\n\r\n\r\n二：在/paddlepaddle_gpu-latest.19.04.25版本上训练yolov3报如下错误：\r\nloading annotations into memory...\r\nDone (t=26.37s)\r\ncreating index...\r\nindex created!\r\nLoad in 80 categories.\r\nF0425 09:12:42.189702  9812 device_context.cc:337] cudaGetLastError  invalid configuration argument errno:9\r\n*** Check failure stack trace: ***\r\n    @     0x7f1a62b49b2d  google::LogMessage::Fail()\r\n    @     0x7f1a62b4d5dc  google::LogMessage::SendToLog()\r\n    @     0x7f1a62b49653  google::LogMessage::Flush()\r\n    @     0x7f1a62b4eaee  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f1a64772fad  _ZNSt17_Function_handlerIFvvEZNK6paddle8platform17CUDADeviceContext4WaitEvEUlvE_E9_M_invokeERKSt9_Any_data\r\n    @     0x7f1a64780e04  paddle::platform::TemporaryAllocator::Release()\r\n    @     0x7f1a64775f21  paddle::platform::CUDADeviceContext::Wait()\r\n    @     0x7f1a64708771  paddle::framework::TransDataDevice()\r\n    @     0x7f1a6470780e  paddle::framework::TransformData()\r\n    @     0x7f1a646fe90d  paddle::framework::OperatorWithKernel::PrepareData()\r\n    @     0x7f1a646ffa26  paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7f1a646ffed1  paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7f1a646fd54c  paddle::framework::OperatorBase::Run()\r\n    @     0x7f1a6450d84a  paddle::framework::details::ComputationOpHandle::RunImpl()\r\n    @     0x7f1a645001e0  paddle::framework::details::OpHandleBase::Run()\r\n    @     0x7f1a644e9072  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp()\r\n    @     0x7f1a644e93af  _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsync\r\nEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_A\r\nny_data\r\n    @     0x7f1a637a3253  std::_Function_handler<>::_M_invoke()\r\n    @     0x7f1a62ae3ff7  std::__future_base::_State_base::_M_do_set()\r\n    @     0x7f1b38889e03  __pthread_once_internal\r\n    @     0x7f1a644e58c2  _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS4_12OpHandleBase\r\nESt6atomicIiESt4hashIS8_ESt8equal_toIS8_ESaISt4pairIKS8_SA_EEES8_RKSt10shared_ptrINS3_13BlockingQueueImEEEEUlvE_vEESaIiEFvvEE6_M_runEv\r\n    @     0x7f1a62ae5574  _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\n    @     0x7f1a80ffc470  (unknown)\r\n    @     0x7f1b38884aa1  start_thread\r\n    @     0x7f1b37f46c4d  clone\r\n    @              (nil)  (unknown)\r\n",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "heavengate",
        "created_at": "2019-04-25T09:36:36+00:00",
        "updated_at": "2019-08-09T07:09:43+00:00",
        "closed_at": "2019-04-26T02:09:34+00:00",
        "comments_count": [
            "fatwolf",
            "dingsiyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2158,
        "title": "Yolov3 random_shape参数问题",
        "body": "发现 random_shape 按照默认值True的话 是无法运行的，提示输入维度不对，是我姿势不对吗？\r\n",
        "state": "closed",
        "user": "fatwolf",
        "closed_by": "heavengate",
        "created_at": "2019-04-25T17:50:47+00:00",
        "updated_at": "2019-04-29T03:49:42+00:00",
        "closed_at": "2019-04-29T03:49:42+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2167,
        "title": "img['gt_labels'][gt_index] = self.category_to_id_map[target['category_id']]",
        "body": "yolov3.reader.py中img['gt_labels'][gt_index] = self.category_to_id_map[target['category_id']]这句代码会将我的种类ID转换成一个无关的数字",
        "state": "closed",
        "user": "aban77",
        "closed_by": "aban77",
        "created_at": "2019-04-27T13:10:08+00:00",
        "updated_at": "2019-04-27T15:05:46+00:00",
        "closed_at": "2019-04-27T15:05:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2162,
        "title": "Yolo V3 :TypeError: yolov3_loss() got an unexpected keyword argument 'gt_box'",
        "body": "------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 154, in <module>\r\n    train()\r\n  File \"train.py\", line 46, in train\r\n    model.build_model()\r\n  File \"/home/airobot/models/PaddleCV/yolov3/models/yolov3.py\", line 153, in build_model\r\n    name=\"yolo_loss\"+str(i))\r\nTypeError: yolov3_loss() got an unexpected keyword argument 'gt_box'\r\n",
        "state": "closed",
        "user": "universea",
        "closed_by": "heavengate",
        "created_at": "2019-04-26T05:27:55+00:00",
        "updated_at": "2019-04-29T03:48:53+00:00",
        "closed_at": "2019-04-29T03:48:53+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2168,
        "title": "ocr_recognition文档链接失效",
        "body": "如图点击安装文档链接，显示该链接页面找不到\r\n![image](https://user-images.githubusercontent.com/37854899/56864444-cfc14f80-69f4-11e9-8a32-a666609f3c1c.png)\r\n![image](https://user-images.githubusercontent.com/37854899/56864470-229b0700-69f5-11e9-8611-3343a762a0bd.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "kuke",
        "created_at": "2019-04-28T12:42:07+00:00",
        "updated_at": "2019-04-30T08:41:20+00:00",
        "closed_at": "2019-04-30T08:41:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2169,
        "title": "video AttentionCluster训练报错",
        "body": "在paddle1.4.1上，video AttentionCluster训练报错，报错如下：\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 251, in <module>\r\n    train(args)\r\n  File \"train.py\", line 241, in train\r\n    test_metrics=valid_metrics)\r\n  File \"/ssd1/xiege/model_4.29/models-develop/PaddleCV/video/tools/train_utils.py\", line 104, in train_with_pyreader\r\n    lr = fluid.global_scope().find_var(\"learning_rate\").get_tensor()\r\nAttributeError: 'NoneType' object has no attribute 'get_tensor'",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "heavengate",
        "created_at": "2019-04-29T03:40:10+00:00",
        "updated_at": "2019-05-06T10:30:53+00:00",
        "closed_at": "2019-05-06T10:30:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2177,
        "title": "PaddleCV中场景文字识别模型运行错误，提示缺依赖libwarpctc.so",
        "body": "![image](https://user-images.githubusercontent.com/48793257/57068422-49628180-6d04-11e9-9f90-de39e6e94e66.png)\r\n建议：建议在ReadMe中添加dependencies（安装libwarpctc.so）。",
        "state": "open",
        "user": "Steffy-zxf",
        "closed_by": null,
        "created_at": "2019-05-02T10:02:14+00:00",
        "updated_at": "2019-05-02T10:02:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2182,
        "title": "BUG! PaddleNLP，language_model中use_gpu参数指定为false，无法传入。",
        "body": "BUG! PaddleNLP，language_model中use_gpu参数指定为false，无法传入。\r\n当指定run.sh文件中use_gpu参数为false时，发现还是无法传入，显示结果为True。\r\n\r\n<img width=\"429\" alt=\"2cee2c9d48000ac2145db776ec03408a\" src=\"https://user-images.githubusercontent.com/48793257/57132153-44b7cf00-6dd1-11e9-91c2-5cf79149929b.png\">\r\n\r\n<img width=\"1388\" alt=\"a6c42f69aaab126f8d796046c8f356a4\" src=\"https://user-images.githubusercontent.com/48793257/57132210-7335aa00-6dd1-11e9-8974-94647ddc4609.png\">\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "Steffy-zxf",
        "closed_by": null,
        "created_at": "2019-05-03T10:31:01+00:00",
        "updated_at": "2019-05-03T10:31:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2184,
        "title": "deeplabv3+反复报warning",
        "body": "在paddle1.4.1下，由于deeplabv3+打开了显存优化，导致反复报如下的warning：\r\n<img width=\"956\" alt=\"db83046567521a831348d8eea6f2e46a\" src=\"https://user-images.githubusercontent.com/46314656/57190981-398cac80-6f53-11e9-9ffc-3a3c7b379d82.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "baiyfbupt",
        "created_at": "2019-05-05T08:42:11+00:00",
        "updated_at": "2019-05-16T09:39:55+00:00",
        "closed_at": "2019-05-16T09:39:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2171,
        "title": "无法复现PyramidBox论文结果",
        "body": "使用paddle在wider上重新训练了一下PyramidBox，发现hard上和开源的模型相差接近10个点，想问下是不是有什么训练细节没开源呀。。",
        "state": "open",
        "user": "chenjiapen12",
        "closed_by": null,
        "created_at": "2019-04-30T02:06:19+00:00",
        "updated_at": "2019-04-30T07:58:45+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "chenjiapen12",
            "qingqing01",
            "chenjiapen12"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2173,
        "title": "object_detection中的resize问题",
        "body": "在object_detection中对图像进行一系列的图像增强操作后，有resize操作，但是只resize了图像，没有resize gt_bboxes（[详细代码](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/object_detection/reader.py#L142)），这样做的意义何在？是否会影响检测结果？",
        "state": "closed",
        "user": "SunAhong1993",
        "closed_by": "sandyhouse",
        "created_at": "2019-04-30T06:54:17+00:00",
        "updated_at": "2019-04-30T08:45:08+00:00",
        "closed_at": "2019-04-30T08:45:08+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2170,
        "title": "video nonlocal 模型kill掉进程后无法自动释放显存",
        "body": "video nonlocal 模型kill掉进程后显存无法自动释放，如图所示：\r\n<img width=\"865\" alt=\"f4924b601212fa146634cb29eef3122f\" src=\"https://user-images.githubusercontent.com/46314656/56884565-c8558100-6a9c-11e9-9443-e6ab2691d593.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-04-29T08:35:35+00:00",
        "updated_at": "2019-05-14T09:34:37+00:00",
        "closed_at": "2019-05-14T09:34:37+00:00",
        "comments_count": [
            "hutuxian",
            "xiegegege",
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2187,
        "title": "图像分类GoogleNet训练报错",
        "body": "1.输入命令python train.py --model=GoogleNet后运行，120个batch后loss会出现nan\r\n<img width=\"652\" alt=\"cca65feb541bad8bde2e0c8eca86d4b3\" src=\"https://user-images.githubusercontent.com/46314656/57373852-0143d300-71cc-11e9-8ad9-462afcc179de.png\">\r\n2.在paddle develop分支下，跑训练一段时间后有报错(非必现)：\r\nPass 0, trainbatch 2330, loss nan,                         acc1 0.00000, acc5 0.00781, lr 0.10000, time 0.65 sec\r\nF0505 20:34:00.984820 209240 all_reduce_op_handle.cc:78] cudaStreamSynchronize an illegal memory access was encountered\r\n*** Check failure stack trace: ***\r\n    @     0x7f7ad2ed07ad  google::LogMessage::Fail()\r\n    @     0x7f7ad2ed425c  google::LogMessage::SendToLog()\r\n    @     0x7f7ad2ed02d3  google::LogMessage::Flush()\r\n    @     0x7f7ad2ed576e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7ad465d503  paddle::framework::details::AllReduceOpHandle::RunAllReduceFuncs()\r\n    @     0x7f7ad465eeee  paddle::framework::details::AllReduceOpHandle::RunImpl()\r\n    @     0x7f7ad46cebc0  paddle::framework::details::OpHandleBase::Run()\r\n    @     0x7f7ad46b6a72  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp()\r\n    @     0x7f7ad46b6daf  _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_Any_data\r\n    @     0x7f7ad400d3f3  std::_Function_handler<>::_M_invoke()\r\n    @     0x7f7ad2e6bc77  std::__future_base::_State_base::_M_do_set()\r\n    @     0x7f7bb5b49e03  __pthread_once_internal\r\n    @     0x7f7ad46b32c2  _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS4_12OpHandleBaseESt6atomicIiESt4hashIS8_ESt8equal_toIS8_ESaISt4pairIKS8_SA_EEES8_RKSt10shared_ptrINS3_13BlockingQueueImEEEEUlvE_vEESaIiEFvvEE6_M_runEv\r\n    @     0x7f7ad2e6d1f4  _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\n    @     0x7f7b6995d470  (unknown)\r\n    @     0x7f7bb5b44aa1  start_thread\r\n    @     0x7f7bb4ffec4d  clone\r\n    @              (nil)  (unknown)",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-05-06T04:46:29+00:00",
        "updated_at": "2019-08-08T08:05:16+00:00",
        "closed_at": "2019-08-08T08:05:16+00:00",
        "comments_count": [
            "shippingwang",
            "shippingwang",
            "lgone2000",
            "heavengate",
            "heavengate",
            "qingqing01",
            "xiegegege",
            "xiegegege",
            "heavengate",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2188,
        "title": "ocr_recognition预测问题",
        "body": "1.ctc模型预测报错：\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 153, in <module>\r\n    main()\r\n  File \"infer.py\", line 149, in main\r\n    inference(args)\r\n  File \"infer.py\", line 34, in inference\r\n    get_feeder_data = get_ctc_feeder_for_infer\r\nNameError: name 'get_ctc_feeder_for_infer' is not defined\r\n2.attention模型预测报错：\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 153, in <module>\r\n    main()\r\n  File \"infer.py\", line 149, in main\r\n    inference(args)\r\n  File \"infer.py\", line 93, in inference\r\n    return_numpy=False)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator sequence_expand error.\r\nPython Callstacks:\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1654, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 3940, in sequence_expand\r\n    attrs={'ref_level': ref_level})\r\n  File \"/ssd1/xiege/model/models-develop/PaddleCV/ocr_recognition/attention_model.py\", line 218, in simple_attention\r\n    x=decoder_state_proj, y=encoder_proj)\r\n  File \"/ssd1/xiege/model/models-develop/PaddleCV/ocr_recognition/attention_model.py\", line 279, in attention_infer\r\n    decoder_size)\r\n  File \"infer.py\", line 44, in inference\r\n    ids = infer(images, num_classes, use_cudnn=True if args.use_gpu else False)\r\n  File \"infer.py\", line 149, in main\r\n    inference(args)\r\n  File \"infer.py\", line 153, in <module>\r\n    main()\r\nC++ Callstacks:\r\nEnforce failed. Expected x_dims[0] == static_cast<int64_t>(y_lod[ref_level].size()) - 1, but received x_dims[0]:2 != static_cast<int64_t>(y_lod[ref_level].size()) - 1:1.\r\nWhen Input(X)'s lod is null, the dims[0] of Input(X) should match the size of Input(Y)'s referred level lod. at [/paddle/paddle/fluid/operators/sequence_ops/sequence_expand_op.cc:76]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-05-06T08:12:17+00:00",
        "updated_at": "2019-05-29T05:27:46+00:00",
        "closed_at": "2019-05-29T02:44:51+00:00",
        "comments_count": [
            "L-lei",
            "wanghaoshuang",
            "wanghaoshuang",
            "L-lei",
            "L-lei",
            "wanghaoshuang",
            "L-lei",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2190,
        "title": "在yolov3项目训练时，如果把random_shape打开，会出现layer进行concat时维度不匹配。关掉之后，可以正常训练",
        "body": "在yolov3项目训练时，如果把random_shape打开，会出现layer进行concat时维度不匹配。关掉之后，可以正常训练\r\n<img width=\"1106\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17508662/57224029-a4fd7980-703a-11e9-8847-03441b204975.png\">\r\n",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "heavengate",
        "created_at": "2019-05-06T12:08:14+00:00",
        "updated_at": "2019-05-08T12:09:00+00:00",
        "closed_at": "2019-05-08T12:08:59+00:00",
        "comments_count": [
            "cjt222",
            "JiaXiao243",
            "cjt222",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2198,
        "title": "windows下rnn_search infer报错",
        "body": "rnn_search训练执行成功，执行python infer.py对模型进行预测，报错信息如下：\r\n![1](https://user-images.githubusercontent.com/37854899/57302313-7ef4d980-710d-11e9-971c-e77df8992377.PNG)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-05-07T13:18:12+00:00",
        "updated_at": "2019-05-09T11:03:41+00:00",
        "closed_at": "2019-05-09T11:03:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2192,
        "title": "PaddleNLP/lexical_analysis 部分标点符号标识错误",
        "body": "在序列标注测试中, 发现对一些标点符号的标注有问题:\r\n\r\n- 错标 & 识别不了符号: `-`/`·`/`\"`等, 例如: \r\n原句:\r\n斯蒂芬-库里自己公布下赛季去向\r\n\r\n标注结果:\r\n```\r\n [CLS]/O 斯/PER-B 蒂/PER-I 芬/PER-I [UNK]/PER-I 库/PER-I 里/PER-I 自/r-B 己/r-I 公/v-B 布/v-I 下/q-B 赛/n-B 季/n-I 去/n-B 向/n-I ！/v-B [SEP]/O\r\n```\r\n\r\n查询了下, `vocab.txt`中不包含`-`/`·`/`\"`等比较常用的字符串, 如果直接在`vocab.txt`添加映射则会造成分词结果的不一致, 例子如下:\r\n\r\n原句:\r\n【纽约时报】斯蒂芬-库里下赛季去哪儿\r\n\r\n原有`vocab.txt`的标注结果:\r\n```\r\n[CLS]/O [UNK]/w-B 纽/nw-B 约/nw-I 时/nw-I 报/nw-I [UNK]/w-B 斯/PER-B 蒂/PER-I 芬/PER-I [UNK]/PER-I 库/PER-I 里/PER-I 下/v-B 赛/n-B 季/n-I 去/v-B 哪/v-I 儿/v-I [SEP]/O\r\n```\r\n\r\n增加`-`之后的`vocab.txt`\r\n```\r\n-   17963                                                                                                                                                             \r\n[UNK]   17964\r\n```\r\n标注结果如下:\r\n\r\n```\r\n[CLS]/O [UNK]/nt-B 纽/nt-I 约/nt-I 时/nt-I 报/nt-I [UNK]/nt-I 斯/nt-I 蒂/nt-I 芬/nt-I [UNK]/nt-I 库/PER-B 里/PER-I 下/v-B 赛/n-B 季/n-I 去/v-B 哪/v-I 儿/v-I [SEP]/O\r\n```\r\n\r\n 想请教下怎么解决这个问题比较好? \r\n(直接将这些字符替换成`vocab.txt`中自带的吗? 或者是增加映射的同时, 增加词向量)\r\n\r\n多谢!",
        "state": "open",
        "user": "Yingminzhou",
        "closed_by": null,
        "created_at": "2019-05-06T13:10:41+00:00",
        "updated_at": "2020-10-20T02:24:27+00:00",
        "closed_at": null,
        "comments_count": [
            "xbc0112"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2195,
        "title": "windows下icnet模型无法保存",
        "body": "对数据进行完预处理之后运行train.py，到了写入保存点这一步会报错显示无法创建保存点\r\n其中checkpoint_path被设定为./chkpnt\r\n```\r\nif iter_id % CHECKPOINT_PERIOD == 0 and args.checkpoint_path is not None: #写保存点\r\n    dir_name = args.checkpoint_path + \"/\" + str(iter_id)\r\n    fluid.io.save_persistables(exe, dirname=dir_name)\r\n    print(\"Saved checkpoint: %s\" % (dir_name))\r\n```\r\n\r\n终端显示\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 4\r\ncheckpoint_path: ./chkpnt\r\ninit_model: None\r\nrandom_mirror: True\r\nrandom_scaling: True\r\nuse_gpu: False\r\n------------------------------------------------\r\nIter[1]; train loss: 5.780; sub4_loss: 3.435; sub24_loss: 3.792; sub124_loss: 3.714\r\nkpis    train_cost      5.780251\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\a\\.vscode\\extensions\\ms-python.python-2019.3.6558\\pythonFiles\\ptvsd_launcher.py\", line 45, in <module>\r\n    main(ptvsdArgs)\r\n  File \"c:\\Users\\a\\.vscode\\extensions\\ms-python.python-2019.3.6558\\pythonFiles\\lib\\python\\ptvsd\\__main__.py\", line 391, in main\r\n    run()\r\n  File \"c:\\Users\\a\\.vscode\\extensions\\ms-python.python-2019.3.6558\\pythonFiles\\lib\\python\\ptvsd\\__main__.py\", line 272, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"d:\\icnet\\train.py\", line 155, in <module>\r\n    main()\r\n  File \"d:\\icnet\\train.py\", line 151, in main\r\n    train(args)\r\n  File \"d:\\icnet\\train.py\", line 144, in train\r\n    fluid.io.save_persistables(exe, dirname=dir_name)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 490, in save_persistables\r\n    filename=filename)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 176, in save_vars\r\n    filename=filename)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 212, in save_vars\r\n    executor.run(save_program)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\Users\\a\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\n**RuntimeError: ./chkpnt/1 mkdir failed!**\r\n```\r\n请问为什么会出现这种现象呢？",
        "state": "closed",
        "user": "Einshein",
        "closed_by": "junjun315",
        "created_at": "2019-05-07T07:00:42+00:00",
        "updated_at": "2019-05-09T02:03:02+00:00",
        "closed_at": "2019-05-09T02:03:02+00:00",
        "comments_count": [
            "xiegegege",
            "Einshein",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2194,
        "title": "shufflenetv2 pretrained model",
        "body": "The released pre-trained model and accuracy is for ShuffleNetV2_x0_5 or ShuffleNetV2_x1_0 or ShuffleNetV2_x1_5 or ShuffleNetV2_x2_0 ?\r\n\r\nand the pretrained model is configured with \"model_name\" or \"model\"  ?",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "shippingwang",
        "created_at": "2019-05-07T03:35:35+00:00",
        "updated_at": "2019-05-08T09:17:26+00:00",
        "closed_at": "2019-05-08T09:17:26+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2196,
        "title": "Todo: Image Classification ",
        "body": "TODO: \r\n- [ ] Check image classification pre-trained models one more time, to make sure it's consistent with the architecture, such as: \r\n> why don't VGG pre-trained model have offset params meanwhile vgg.py support bias? \r\n> Need to update the code\r\n- [x] some pre-trained models compressed on the mac, and will obtain redundancy folder: __MACOSX when decompressing on the Linux machine.\r\n- [x] Unify filename, format: #2100 \r\n- [ ] Bug: googlenet #2187 \r\n- [x] Bug: resnet34 #2099",
        "state": "open",
        "user": "shippingwang",
        "closed_by": null,
        "created_at": "2019-05-07T08:06:42+00:00",
        "updated_at": "2019-05-15T05:20:26+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2199,
        "title": "windows下icnet训练报错",
        "body": "执行python train.py --batch_size=16 --use_gpu=True --checkpoint_path=\"./chkpnt/\"，报错信息如下：\r\n![2](https://user-images.githubusercontent.com/37854899/57302770-823c9500-710e-11e9-8365-eaf9937ac05e.PNG)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-05-07T13:24:50+00:00",
        "updated_at": "2019-06-19T05:45:20+00:00",
        "closed_at": "2019-06-19T05:45:20+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2204,
        "title": "human_pose_estimation官网示例训练参数配置错误",
        "body": "按照human_pose_estimation官网示例训练参数进行配置，python train.py --dataset 'mpii' --data_root 'data/mpii'，报错信息如下：\r\n![3](https://user-images.githubusercontent.com/37854899/57351722-8cee3d00-7195-11e9-89fc-a1adc20a86ab.PNG)\r\ntrain.py无 --data_root参数字段\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-05-08T05:32:09+00:00",
        "updated_at": "2019-05-16T09:10:48+00:00",
        "closed_at": "2019-05-16T09:10:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2203,
        "title": "图片分类使用ResNet模型训练结果进行预测，预测结果不是归一值，使用softmax激活函数也没有作用",
        "body": "",
        "state": "open",
        "user": "demohold",
        "closed_by": null,
        "created_at": "2019-05-08T02:22:50+00:00",
        "updated_at": "2019-05-13T07:11:51+00:00",
        "closed_at": null,
        "comments_count": [
            "demohold",
            "JiaXiao243",
            "demohold",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2208,
        "title": "window下object detection训练报错",
        "body": "window下执行指令python -u train.py --use_gpu True --parallel False --batch_size=8 --dataset=pascalvoc --pretrained_model='pretrained/ssd_mobilenet_v1_coco/' --epoc_num=1 --model_save_dir='output_pasc'，对models进行训练，报错信息如下：\r\n![2](https://user-images.githubusercontent.com/37854899/57434689-1e30e280-726e-11e9-993c-ccc1f1705579.PNG)\r\n在output_pasc\\0和output_pasc\\best_model有训练权重输出。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-05-09T07:21:55+00:00",
        "updated_at": "2019-07-10T08:09:50+00:00",
        "closed_at": "2019-07-10T08:09:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2205,
        "title": "window下训练human_pose_estimation，提示不支持'mpii' ‘coco’数据集",
        "body": "在window下，正确配置数据路径，分别使用指令python train.py --dataset 'coco' ， python train.py --dataset 'mpii' 进行训练，其他相关配置均正确，报错信息如下：\r\n![4](https://user-images.githubusercontent.com/37854899/57353855-6bdd1a80-719c-11e9-972e-73e3412d1336.PNG)\r\n![5](https://user-images.githubusercontent.com/37854899/57353858-6d0e4780-719c-11e9-8380-a4841b08bf8d.PNG)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "gongweibao",
        "created_at": "2019-05-08T06:20:34+00:00",
        "updated_at": "2019-05-09T08:12:15+00:00",
        "closed_at": "2019-05-09T08:12:15+00:00",
        "comments_count": [
            "JiaXiao243",
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2209,
        "title": "object detection eval&infer报错",
        "body": "对object detection训练出的模型进行eval&infer报错信息如下：\r\n![3](https://user-images.githubusercontent.com/37854899/57436444-43275480-7272-11e9-9536-c99ab5ec00ba.PNG)\r\nmobilenet_ssd.py文件中并没有eval和infer中需要的mobile_net函数，可能需将eval.py&infer.py中的mobile_net修改为build_mobilenet_ssd",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-05-09T08:04:00+00:00",
        "updated_at": "2019-05-13T07:23:24+00:00",
        "closed_at": "2019-05-13T07:23:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2210,
        "title": "压缩工具paddleSlim问题",
        "body": "我刚接触这个工具,想请教下,\r\n1.这个工具压缩的模型是基于paddle所训练的模型吗?\r\n2.能直接对tensorflow,caffe所训练的模型进行压缩吗?\r\n3.如果不能,是否都需要重新用paddle训练才能够压缩?\r\n4.如果不能,是否有tensorflow转paddle的工具?\r\n5.这个caffe转的工具没效了,https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification/caffe2fluid\r\n谢谢.",
        "state": "closed",
        "user": "chenloveheimei",
        "closed_by": "gongweibao",
        "created_at": "2019-05-09T09:26:56+00:00",
        "updated_at": "2019-05-13T07:39:22+00:00",
        "closed_at": "2019-05-13T07:39:22+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2212,
        "title": "windows下deeplabV3 CPU训练报错",
        "body": "在window下执行python ./train.py --batch_size=1 -- --use_gpu False --parallel True --train_crop_size=769 --total_step=50 --norm_type=gn --init_weights_path=./deeplabv3plus_gn_init --save_weights_path=model --dataset_path=./data/cityscape，使用CPU对deeplabV3进行训练，报错信息如下：\r\n![10](https://user-images.githubusercontent.com/37854899/57457579-5eaa5380-72a2-11e9-95ac-6a94b4d00af7.PNG)\r\n由于window下使用GPU进行训练，提示显存不足，故无法做对比分析。\r\n![11](https://user-images.githubusercontent.com/37854899/57457682-8c8f9800-72a2-11e9-99a9-85379d4583e2.PNG)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-05-09T13:37:03+00:00",
        "updated_at": "2019-05-13T09:21:42+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2211,
        "title": "window下face_detection训练报错",
        "body": "windows下调用python -u train.py --epoc_num=1 --batch_size=2 --use_gpu False --parallel False --pretrained_model=vgg_ilsvrc_16_fc_reduced指令对face_detection模型进行训练，log中有多处报错信息，其中两处在windows下训练object_detection也有出现：\r\n![4](https://user-images.githubusercontent.com/37854899/57451782-ce194680-7294-11e9-909b-8f2281f75f99.PNG)\r\n![5](https://user-images.githubusercontent.com/37854899/57451786-cfe30a00-7294-11e9-91e4-5a70f2e17d0d.PNG)\r\n还有一大段报错信息是其特有的：\r\n![8](https://user-images.githubusercontent.com/37854899/57451816-dffae980-7294-11e9-8c57-d8975a1ef139.PNG)\r\n同时，在模型的output\\0路径有训练权重输出。\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "qingqing01",
        "created_at": "2019-05-09T11:59:25+00:00",
        "updated_at": "2019-07-11T05:08:33+00:00",
        "closed_at": "2019-07-10T08:09:50+00:00",
        "comments_count": [
            "yanggb",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2215,
        "title": "yolov3运行结束报错",
        "body": "在paddle develop分支下，设置迭代次数为4000，在运行结束后有报错：\r\n*** Aborted at 1557413520 (unix time) try \"date -d @1557413520\" if you are using GNU date ***\r\n*** Aborted at 1557413520 (unix time) try \"date -d @1557413520\" if you are using GNU date ***\r\n*** Aborted at 1557413520 (unix time) try \"date -d @1557413520\" if you are using GNU date ***\r\n*** Aborted at 1557413520 (unix time) try \"date -d @1557413520\" if you are using GNU date ***\r\n*** Aborted at 1557413520 (unix time) try \"date -d @1557413520\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\nPC: @                0x0 (unknown)\r\n*** SIGTERM (@0x2fd) received by PID 978 (TID 0x7f331d2fc700) from PID 765; stack trace: ***\r\nPC: @                0x0 (unknown)\r\n*** SIGTERM (@0x2fd) received by PID 987 (TID 0x7f331d2fc700) from PID 765; stack trace: ***\r\nPC: @                0x0 (unknown)\r\n*** SIGTERM (@0x2fd) received by PID 975 (TID 0x7f331d2fc700) from PID 765; stack trace: ***\r\n*** SIGTERM (@0x2fd) received by PID 966 (TID 0x7f331d2fc700) from PID 765; stack trace: ***\r\n*** SIGTERM (@0x2fd) received by PID 972 (TID 0x7f331d2fc700) from PID 765; stack trace: ***\r\n    @     0x7f3c7ff437e0 (unknown)\r\n    @     0x7f3c7ff437e0 (unknown)\r\n    @     0x7f3c7ff437e0 (unknown)\r\n    @     0x7f3c7ff437e0 (unknown)\r\n    @     0x7f3c7ff437e0 (unknown)\r\n    @     0x7f3c801d95d0 (unknown)\r\n    @     0x7f3c801db567 PyCode_Addr2Line\r\n    @     0x7f3c7f39682b __GI_memcpy\r\n    @     0x7f3c802b6836 _PyEval_EvalFrameDefault\r\n    @     0x7f3c802230a5 (unknown)\r\n    @     0x7f3c802b33e2 (unknown)\r\n    @     0x7f3c802f8fac PyTraceBack_Here\r\n    @     0x7f3c802235c4 (unknown)\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c801d0dcc PyBytes_FromStringAndSize\r\n    @     0x7f3c802b3e63 _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c8030bda8 _PyObject_GC_Resize\r\n    @     0x7f3c802b35f3 PyEval_EvalCodeEx\r\n    @     0x7f3c80264f8b PyUnicode_AsEncodedString\r\n    @     0x7f3c10222ad8 (unknown)\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c801f4695 PyFrame_New\r\n    @     0x7f3c801f53f3 (unknown)\r\n    @     0x7f3c8021be95 _PyCFunction_FastCallDict\r\n    @     0x7f3c802b32e2 (unknown)\r\n    @     0x7f3c802b35f3 PyEval_EvalCodeEx\r\n    @     0x7f3c802b262a (unknown)\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b33ca (unknown)\r\n    @     0x7f3c801f53f3 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6e55 _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b35f3 PyEval_EvalCodeEx\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6e55 _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c801f53f3 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b35f3 PyEval_EvalCodeEx\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c801f53f3 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6e55 _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6e55 _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b32e2 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6f4e _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b35f3 PyEval_EvalCodeEx\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c801f53f3 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802bbc66 _PyFunction_FastCallDict\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6e55 _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c359e _PyObject_FastCallDict\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802bbc66 _PyFunction_FastCallDict\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c801c368e _PyObject_Call_Prepend\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c801c359e _PyObject_FastCallDict\r\n    @     0x7f3c802bbafc _PyFunction_FastCallDict\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802bbc66 _PyFunction_FastCallDict\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c368e _PyObject_Call_Prepend\r\n    @     0x7f3c801c359e _PyObject_FastCallDict\r\n    @     0x7f3c8023b519 (unknown)\r\n    @     0x7f3c801c359e _PyObject_FastCallDict\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c801c368e _PyObject_Call_Prepend\r\n    @     0x7f3c80233d33 (unknown)\r\n    @     0x7f3c801c368e _PyObject_Call_Prepend\r\n    @     0x7f3c802bbc66 _PyFunction_FastCallDict\r\n    @     0x7f3c8023b519 (unknown)\r\n    @     0x7f3c801c34ab _PyObject_FastCallDict\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c801c359e _PyObject_FastCallDict\r\n    @     0x7f3c80233d33 (unknown)\r\n    @     0x7f3c8023b519 (unknown)\r\n    @     0x7f3c802b3138 (unknown)\r\n    @     0x7f3c80238c01 (unknown)\r\n    @     0x7f3c801c368e _PyObject_Call_Prepend\r\n    @     0x7f3c801c34ab _PyObject_FastCallDict\r\n    @     0x7f3c80233d33 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c801c34ab _PyObject_FastCallDict\r\n    @     0x7f3c801c334a PyObject_Call\r\n    @     0x7f3c802b3138 (unknown)\r\n    @     0x7f3c801c34ab _PyObject_FastCallDict\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3138 (unknown)\r\n    @     0x7f3c8023b519 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b3138 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c80233d33 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2fce (unknown)\r\n    @     0x7f3c801c34ab _PyObject_FastCallDict\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b3138 (unknown)\r\n    @     0x7f3c802b32e2 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b3584 (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault\r\n    @     0x7f3c802b2660 (unknown)\r\n    @     0x7f3c802b352f (unknown)\r\n    @     0x7f3c802b6acc _PyEval_EvalFrameDefault",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "heavengate",
        "created_at": "2019-05-10T03:35:37+00:00",
        "updated_at": "2019-05-24T12:04:52+00:00",
        "closed_at": "2019-05-24T12:04:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2213,
        "title": "fp16 training does not work",
        "body": "I want to run fp16 training on both CPU and GPU but I get the same error message.\r\n\r\n`python train.py --model=ResNet18 --batch_size=32 --use_gpu=True --fp16=True`\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 462, in <module>\r\n    main()\r\n  File \"train.py\", line 458, in main\r\n    train(args)\r\n  File \"train.py\", line 272, in train\r\n    args=args)\r\n  File \"train.py\", line 232, in build_program\r\n    params_grads, main_prog, startup_prog, args.scale_loss)\r\n  File \"/root/models/PaddleCV/image_classification/utils/fp16_utils.py\", line 94, in create_master_params_grads\r\n    reduced_master_grad = fluid.layers.collective._allreduce(master_grad)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/collective.py\", line 47, in _allreduce\r\n    \"sync_mode\": sync_mode})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1689, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1016, in __init__\r\n    proto = OpProtoHolder.instance().get_op_proto(type)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 905, in get_op_proto\r\n    raise ValueError(\"Operator \\\"%s\\\" has not been registered.\" % type)\r\nValueError: Operator \"allreduce\" has not been registered.\r\n```\r\n\r\nMy specs:\r\nos: ubuntu16.04\r\npp: `Release` version built from `develop` branch, enabled GPU support\r\nmodels: `develop` branch\r\n\r\nDisabling fp16: `--fp16=False` results in correct training *both* on GPU and CPU.\r\n\r\nCan you please help me resolve this issue (if it's mistake on my end) or fix it?",
        "state": "closed",
        "user": "ghost",
        "closed_by": "gavin1332",
        "created_at": "2019-05-09T20:06:09+00:00",
        "updated_at": "2020-01-26T16:08:05+00:00",
        "closed_at": "2020-01-26T16:08:05+00:00",
        "comments_count": [
            "gavin1332",
            "JiaXiao243",
            "sfraczek",
            "gavin1332",
            "gavin1332",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2217,
        "title": "lexical_analysis易用性",
        "body": "1. windows环境下，在models/PaddleNLP/lexical_analysis目录下执行python run_sequence_labeling.py  --train_data ./data/train.tsv --test_data ./data/test.tsv --do_train True  --do_test True  --do_infer False --save_model_per_batches 10000  --batch_size 100 --epoch 10 --use_gpu 0 --traindata_shuffle_buffer 200000 --word_emb_dim 768  --grnn_hidden_dim 768 对lexical_analysis模型进行训练，报错信息如下：\r\n![21](https://user-images.githubusercontent.com/37854899/57517132-bd2a0d00-7348-11e9-8488-08022edff794.PNG)\r\n需要将reader.py 57行sum(1 for line in open(filename, \"r\"))修改为 sum(1 for line in open(filename, \"r\"，encoding='UTF-8'))，模型可正常完成训练。linux下训练无该问题。\r\n2. 建议将现有默认数据名称./data/train_data、./data/test_data修改为./data/train.tsv、./data/test.tsv与下载数据名称保持一致；\r\n![22](https://user-images.githubusercontent.com/37854899/57517569-ba7be780-7349-11e9-9892-dff8f0752984.PNG)\r\n3. 建议将是否使用GPU设置：Whether or not to use GPU. -1 means CPU, else GPU id\r\n 修改为  0：使用CPU，1：使用GPU ；和其他模型use_GPU设置保持一致。\r\n![23](https://user-images.githubusercontent.com/37854899/57521226-409c2c00-7352-11e9-9865-8fa01aa3fd8f.PNG)\r\n4. run_sequence_labeling.py中没有用到do_valid字段，需要在代码中删除该冗余字段。\r\n![24](https://user-images.githubusercontent.com/37854899/57527098-b1971000-7361-11e9-9358-89b24613b241.PNG)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "kuke",
        "created_at": "2019-05-10T10:35:06+00:00",
        "updated_at": "2019-05-14T07:37:04+00:00",
        "closed_at": "2019-05-14T07:37:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2216,
        "title": "window下rcnn训练报错",
        "body": "windows下执行指令python train.py --use_gpu True --parallel False  --model_save_dir=faster_output --pretrained_model=imagenet_resnet50_fusebn --max_iter=5 --snapshot_stride=5对faster rcnn模型进行训练，报错信息如下：\r\n![01](https://user-images.githubusercontent.com/37854899/57503092-4c232f00-7321-11e9-941b-533817bd82c2.PNG)\r\n同时，运行mask rcnn也是上述报错信息。\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-05-10T04:44:52+00:00",
        "updated_at": "2019-05-14T11:45:06+00:00",
        "closed_at": "2019-05-14T11:45:06+00:00",
        "comments_count": [
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2219,
        "title": "Auto Dialogue Evaluationg文档需部分修正",
        "body": "1.  官方文档未提供示例数据\r\n<img width=\"924\" alt=\"data\" src=\"https://user-images.githubusercontent.com/37854899/57592744-e4602480-756a-11e9-9b4d-4131a0b54bbd.png\">\r\n2. 语句不通，应修改为可以显著提高该对话系统或场景的评估效果。\r\n<img width=\"1054\" alt=\"243\" src=\"https://user-images.githubusercontent.com/37854899/57593143-bf6cb100-756c-11e9-8153-819a63f32d5f.png\">\r\n3. 官方数据目录错误，word2ids存在于data目录下，而不是其子目录unlabel_data目录。\r\n<img width=\"861\" alt=\"word2ids\" src=\"https://user-images.githubusercontent.com/37854899/57593201-f93db780-756c-11e9-9085-5209aecf139f.png\">\r\n4. 目前改模型预测结果存放位置是test_path + '.infer'， 需要看代码才能知道预测结果的存放位置(data/dialeval/data/label_data/human/test.ids.infer)，目录结构较深，建议将预测结果存放位置在文档中加以说明，或存在result_infer等一个比较直观的目录中。\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "luluxing3",
        "created_at": "2019-05-13T02:49:33+00:00",
        "updated_at": "2019-05-15T09:41:09+00:00",
        "closed_at": "2019-05-15T09:41:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2218,
        "title": "auto_dialogue_evaluation模型finetune训练报错",
        "body": "在models/PaddleNLP/dialogue_model_toolkit/auto_dialogue_evaluation路径下执行\r\nTASK=human\r\npython -u main.py \\\r\n  --do_train True \\\r\n  --loss_type L2 \\\r\n  --use_cuda \\\r\n  --save_path model_files_tmp/${TASK}_finetuned \\\r\n  --init_model model_files/matching_pretrained \\\r\n  --train_path data/label_data/$TASK/train.ids \\\r\n  --val_path data/label_data/$TASK/val.ids \\\r\n  --print_step 1 \\\r\n  --save_step 1 \\\r\n  --num_scan_data 50\r\n对auto_dialogue_evaluation模型进行finetune报错信息如下：\r\n<img width=\"1001\" alt=\"finetuined_train\" src=\"https://user-images.githubusercontent.com/37854899/57592560-f392a280-7569-11e9-8296-4c2f7fcd4cd0.png\">\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "luluxing3",
        "created_at": "2019-05-13T02:29:27+00:00",
        "updated_at": "2019-05-16T03:09:10+00:00",
        "closed_at": "2019-05-16T03:09:10+00:00",
        "comments_count": [
            "luluxing3",
            "JiaXiao243",
            "luluxing3",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2224,
        "title": "icnet模型易用性问题",
        "body": "icnet模型的total_step, checkpoint_period, log_period, learning_rate等参数值写死在代码里了，建议设置成可通过命令行进行调整的参数\r\n<img width=\"288\" alt=\"8682d3a5197e599a110abba13e6dc04f\" src=\"https://user-images.githubusercontent.com/46314656/57614621-4ab96700-75ac-11e9-8bca-a86ff6310685.png\">\r\n",
        "state": "open",
        "user": "xiegegege",
        "closed_by": null,
        "created_at": "2019-05-13T10:25:48+00:00",
        "updated_at": "2019-05-18T13:58:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2221,
        "title": "transformer修改超参训练后，模型infer报错",
        "body": "paddle版本的transformer，如果修改了超参数（max_length改为64，d_model改为256，d_inner_hid改为512，n_head改成12），训练可以正常训练，但是预测时会出这个错误\r\n<img width=\"1144\" alt=\"c1e61a3e698da97918a8023e55850a53\" src=\"https://user-images.githubusercontent.com/28192236/57600953-d079ea00-758d-11e9-8275-710c42a4ba67.png\">",
        "state": "open",
        "user": "Lizhengo",
        "closed_by": null,
        "created_at": "2019-05-13T06:47:44+00:00",
        "updated_at": "2019-05-14T05:08:37+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "Lizhengo",
            "Lizhengo",
            "guoshengCS",
            "Lizhengo",
            "Lizhengo",
            "guoshengCS",
            "Lizhengo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2225,
        "title": "想循环处理model的输入tensor，如何实现？",
        "body": "在build program时，predict = model.net(input, class_dim=class_dim)。\r\n然后，我想修改model.net模型，想在net模型里对input进行迭代，处理每个input的通道值（想对大小进行排序）。因为input是tensor，shape是[-1,C,H,W]，无法对第一维进行循环。而且input是tensor，是空的，无法进行值得处理。请问有什么方法吗？？？\r\n\r\n比如：se-resnet中的SE模块计算，我想对excitation 后的每图片的各通道值（shape：[-1，C]）进行大小排序，如何实现？\r\n \r\n``` \r\ndef squeeze_excitation(self,\r\n                           input,\r\n                           num_channels,\r\n                           reduction_ratio,\r\n                           name=None):\r\n        pool = fluid.layers.pool2d(\r\n            input=input, pool_size=0, pool_type='avg', global_pooling=True)\r\n        stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)\r\n        squeeze = fluid.layers.fc(\r\n            input=pool,\r\n            size=num_channels // reduction_ratio,\r\n            act='relu',\r\n            param_attr=fluid.param_attr.ParamAttr(\r\n                initializer=fluid.initializer.Uniform(-stdv, stdv),\r\n                name=name + '_sqz_weights'),\r\n            bias_attr=ParamAttr(name=name + '_sqz_offset'))\r\n        stdv = 1.0 / math.sqrt(squeeze.shape[1] * 1.0)\r\n        excitation = fluid.layers.fc(\r\n            input=squeeze,\r\n            size=num_channels,\r\n            act='sigmoid',\r\n            param_attr=fluid.param_attr.ParamAttr(\r\n                initializer=fluid.initializer.Uniform(-stdv, stdv),\r\n                name=name + '_exc_weights'),\r\n            bias_attr=ParamAttr(name=name + '_exc_offset'))\r\n```",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-05-13T12:45:12+00:00",
        "updated_at": "2019-05-20T05:05:32+00:00",
        "closed_at": null,
        "comments_count": [
            "qianledan",
            "qianledan",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2220,
        "title": "deep_attention_matching模型评估加载--model_path路径名称错误",
        "body": "1. 在models/PaddleNLP/dialogue_model_toolkit/deep_attention_matching路径中，执行如下指令：\r\npython -u main.py \\\r\n  --do_test True \\\r\n  --use_cuda \\\r\n  --data_path ./data/ubuntu/data_small.pkl \\\r\n  --save_path ./model_files/ubuntu/step_372 \\\r\n  --model_path ./model_files/ubuntu/step_372 \\\r\n  --vocab_size 434512 \\\r\n  --_EOS_ 28270 \\\r\n  --batch_size 100\r\n对模型进行评估，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/57599329-df11d280-7588-11e9-8a78-59b5cf14af22.png)\r\n应将--model_path ./model_files/ubuntu/step_372 应修改为./model_files/ubuntu/step_78，加载的model_path应为训练输出的已存在的模型名称，而不是该模型评估结果的存放路径./model_files/ubuntu/step_372,建议step_372修改为 step_eval或其他，而不是没有意义的数字。\r\n 2. 官方文档缺少示例数据\r\n<img width=\"924\" alt=\"1\" src=\"https://user-images.githubusercontent.com/37854899/57599600-dc63ad00-7589-11e9-9f5b-4105b6cff2cc.png\">\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "luluxing3",
        "created_at": "2019-05-13T06:13:24+00:00",
        "updated_at": "2019-05-15T07:07:07+00:00",
        "closed_at": "2019-05-15T07:07:07+00:00",
        "comments_count": [
            "luluxing3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2231,
        "title": "对比baidu/Senta",
        "body": "https://github.com/baidu/Senta/issues/7 \r\n该issue显示，baidu/Senta repo给的model和百度ai开放平台的model相近。\r\n\r\n这里的PaddleNLP/sentiment_classification 目录也表示支持了百度ai的开放平台。\r\n\r\n我想问下，这两者是什么关系？这个更新一点？效果好一点？",
        "state": "open",
        "user": "shm007g",
        "closed_by": null,
        "created_at": "2019-05-14T08:19:05+00:00",
        "updated_at": "2019-05-14T08:19:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2232,
        "title": "video模型文档问题",
        "body": "1.文档中需要添加预训练模型部分的描述，否则无法复现实验结果\r\n2.更改参数值后，log显示不变，例如在train_tsm.sh中更改epoch值为1后，log中显示的仍未65\r\n<img width=\"536\" alt=\"1b8275909e853d020c259ede6a7e8906\" src=\"https://user-images.githubusercontent.com/46314656/57683613-a3e5d100-7666-11e9-992f-5abd25c40dc1.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-05-14T08:38:38+00:00",
        "updated_at": "2019-05-27T06:40:33+00:00",
        "closed_at": "2019-05-27T06:40:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2228,
        "title": "paddle.fluid.core.EnforceNotMet: Invoke operator reshape2 error. 做人体关节点检测时",
        "body": "使用coco数据集做validation的时候，报了shape mismatch的错误。\r\n`python val.py --dataset coco --checkpoint checkpoints/pose-resnet50-mpii-384x384 --data_root data/coco`\r\n使用的预训练模型就是官方下载的`pose-resnet50-mpii-384x384`，第一次用paddle，只能把全部error信息截下来，麻烦帮忙看一下。\r\n\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 128\r\ncheckpoint: checkpoints/pose-resnet50-mpii-384x384\r\ndata_root: data/coco\r\ndataset: coco\r\nflip_test: True\r\nkp_dim: 17\r\nlr: 0.001\r\nlr_strategy: piecewise_decay\r\nnum_epochs: 140\r\npost_process: True\r\npretrained_model: None\r\nshift_heatmap: True\r\ntotal_images: 6108\r\nuse_gpu: True\r\nwith_mem_opt: True\r\n------------------------------------------------\r\nW0514 14:09:25.998886  1357 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0514 14:09:25.998939  1357 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\nW0514 14:09:25.998944  1357 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.2, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nW0514 14:09:28.653494  1357 parallel_executor.cc:310] The number of graph should be only one, but the current graph has 2 sub_graphs. If you want to see the nodes of the sub_graphs, you should use 'FLAGS_print_sub_graph_dir' to specify the output dir. NOTES: if you not do training, please don't pass loss_var_name.\r\nloading annotations into memory...\r\nDone (t=0.41s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'person']\r\n=> num_images: 5000\r\ngenerating coco gt_db...\r\n=> num db: 6352\r\n=> num selected db: 6108\r\nTraceback (most recent call last):\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/val.py\", line 233, in <module>\r\n    valid(args)\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/val.py\", line 160, in valid\r\n    feed=feeder.feed(data))\r\n  File \"/home/yanhaonan/.local/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    self.executor.run(fetch_list, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator reshape2 error.\r\nPython Callstacks: \r\n  File \"/home/yanhaonan/.local/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/yanhaonan/.local/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 56, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/yanhaonan/.local/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 5998, in reshape\r\n    \"XShape\": x_shape})\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/lib/pose_resnet.py\", line 147, in calc_loss\r\n    x = fluid.layers.reshape(heatmap, (-1, self.k, h*w))\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/lib/pose_resnet.py\", line 115, in net\r\n    loss = self.calc_loss(out, target, target_weight)\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/val.py\", line 90, in valid\r\n    loss, output = model.net(input=image, target=target, target_weight=target_weight)\r\n  File \"/home/yanhaonan/.phn/work/paddle/models/PaddleCV/human_pose_estimation/val.py\", line 233, in <module>\r\n    valid(args)\r\nC++ Callstacks: \r\nEnforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:-7050240 != -in_size:-7077888.\r\nInvalid shape is given. at [/paddle/paddle/fluid/operators/reshape_op.cc:98]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f40a53b4e0dp void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 365\r\n1       0x7f40a53b5157p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f40a5760e79p paddle::operators::ReshapeOp::ValidateShape(std::vector<int, std::allocator<int> >, paddle::framework::DDim const&) + 2249\r\n3       0x7f40a57625e1p paddle::operators::ReshapeOp::InferShape(paddle::framework::InferShapeContext*) const + 689\r\n4       0x7f40a5762cf9p paddle::operators::Reshape2Op::InferShape(paddle::framework::InferShapeContext*) const + 521\r\n5       0x7f40a6dc2ccbp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 603\r\n6       0x7f40a6dc0575p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 341\r\n7       0x7f40a6c368eap paddle::framework::details::ComputationOpHandle::RunImpl() + 250\r\n8       0x7f40a6c2ffc6p paddle::framework::details::OpHandleBase::Run(bool) + 118\r\n9       0x7f40a6bc81ddp\r\n10      0x7f40a5f883d3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n11      0x7f40a5f4b6f7p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n12      0x7f410e499a99p\r\n13      0x7f40a6bc6ec2p\r\n14      0x7f40a5f4cb24p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n15      0x7f4109753678p\r\n16      0x7f410e4926bap\r\n17      0x7f410e1c841dp clone + 109\r\n",
        "state": "closed",
        "user": "yanhn",
        "closed_by": "qingqing01",
        "created_at": "2019-05-14T06:16:14+00:00",
        "updated_at": "2019-05-16T09:23:02+00:00",
        "closed_at": "2019-05-16T09:23:02+00:00",
        "comments_count": [
            "xiegegege",
            "yanhn",
            "xiegegege",
            "yanhn",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2234,
        "title": "PaddleNLP下面的transformer模型下载数据的问题",
        "body": "下载数据一直遇到下面问题\r\n```bash\r\n/root/paddle/models/PaddleNLP/neural_machine_translation/transformer/gen_data/wmt16_ende_data/train.tok.de is too long! at /root/paddle/models/PaddleNLP/neural_machine_translation/transformer/gen_data/mosesdecoder/scripts/training/clean-corpus-n.perl line 154, <E> line 4319333.\r\n```",
        "state": "open",
        "user": "huxiaoman7",
        "closed_by": null,
        "created_at": "2019-05-14T09:40:20+00:00",
        "updated_at": "2019-05-14T09:40:20+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2236,
        "title": "paddle里面models下面simnet和anyq中tools里面的simnet完全不一样，是两个东西吗？",
        "body": "paddle里面models下面simnet和anyq中tools里面的simnet完全不一样，是两个项目吗？",
        "state": "open",
        "user": "sea99back",
        "closed_by": null,
        "created_at": "2019-05-14T09:44:29+00:00",
        "updated_at": "2019-07-26T10:00:52+00:00",
        "closed_at": null,
        "comments_count": [
            "qujinqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2239,
        "title": "cpu utilization is low in PaddleRec/ctr model",
        "body": "When run ctr training model in PaddleRec/ctr on one 48 core server, it seems the  CPU utilization is very low (avg to be 200%) during training. It is same either in local mode or distributed mode.\r\n\r\n1. Cmd (Run in docker)\r\n\r\n` # export NUM_THREADS=20    `\r\n`# python train.py --train_data_path ./data/train.txt `\r\n\r\n\r\n\r\n2. Env\r\n\r\n- hub.baidubce.com/paddlepaddle/paddle:latest  \r\n\r\n3. Log   \r\n\r\n> 2019-05-14 11:51:05,883-INFO: run local training\r\n> 2019-05-14 11:51:05,884-INFO: num threads= 0\r\n> 2019-05-14 11:51:05,884-INFO: cpu num = 48\r\n> ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\n> W0514 11:51:05.886332  4342 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\n> 2019-05-14 11:51:14,050-INFO: TRAIN --> pass: 0 batch: 0 loss: 0.735086364746 auc: 0.503536689127, batch_auc: 0.504577935984\r\n> 2019-05-14 11:51:16,557-INFO: TRAIN --> pass: 0 batch: 1 loss: 0.687324645996 auc: 0.503425833509, batch_auc: 0.502190308561\r\n> 2019-05-14 11:51:25,562-INFO: TRAIN --> pass: 0 batch: 2 loss: 0.652316955566 auc: 0.49810737994, batch_auc: 0.511218654271\r\n> 2019-05-14 11:51:28,201-INFO: TRAIN --> pass: 0 batch: 3 loss: 0.624634887695 auc: 0.492766345222, batch_auc: 0.516552284336\r\n> 2019-05-14 11:51:36,096-INFO: TRAIN --> pass: 0 batch: 4 loss: 0.604645751953 auc: 0.491407935754, batch_auc: 0.521633943716\r\n> 2019-05-14 11:51:38,219-INFO: TRAIN --> pass: 0 batch: 5 loss: 0.591483703613 auc: 0.49000279105, batch_auc: 0.516322304276\r\n> 2019-05-14 11:51:46,069-INFO: TRAIN --> pass: 0 batch: 6 loss: 0.584241821289 auc: 0.489829021597, batch_auc: 0.519842867821\r\n> 2019-05-14 11:51:48,183-INFO: TRAIN --> pass: 0 batch: 7 loss: 0.578797851562 auc: 0.490242734155, batch_auc: 0.524336059192\r\n> 2019-05-14 11:51:56,606-INFO: TRAIN --> pass: 0 batch: 8 loss: 0.579120727539 auc: 0.490747555956, batch_auc: 0.526528383667\r\n> 2019-05-14 11:51:58,903-INFO: TRAIN --> pass: 0 batch: 9 loss: 0.577897460938 auc: 0.491967175691, batch_auc: 0.531965010737\r\n> 2019-05-14 11:52:06,682-INFO: TRAIN --> pass: 0 batch: 10 loss: 0.578246459961 auc: 0.493372356486, batch_auc: 0.52775468058\r\n> 2019-05-14 11:52:08,846-INFO: TRAIN --> pass: 0 batch: 11 loss: 0.578046508789 auc: 0.495237219199, batch_auc: 0.531861205473\r\n> 2019-05-14 11:52:17,071-INFO: TRAIN --> pass: 0 batch: 12 loss: 0.577464294434 auc: 0.497194691728, batch_auc: 0.536939430909\r\n> 2019-05-14 11:52:19,243-INFO: TRAIN --> pass: 0 batch: 13 loss: 0.580472900391 auc: 0.499336215148, batch_auc: 0.539940881903\r\n> 2019-05-14 11:52:27,277-INFO: TRAIN --> pass: 0 batch: 14 loss: 0.578672119141 auc: 0.501259237555, batch_auc: 0.545386792237\r\n> 2019-05-14 11:52:29,362-INFO: TRAIN --> pass: 0 batch: 15 loss: 0.572959228516 auc: 0.503349640492, batch_auc: 0.546570044491\r\n> 2019-05-14 11:52:37,339-INFO: TRAIN --> pass: 0 batch: 16 loss: 0.568415466309 auc: 0.505703493934, batch_auc: 0.553619374192\r\n> 2019-05-14 11:52:39,439-INFO: TRAIN --> pass: 0 batch: 17 loss: 0.572214294434 auc: 0.507821561535, batch_auc: 0.553008822041\r\n> 2019-05-14 11:52:47,451-INFO: TRAIN --> pass: 0 batch: 18 loss: 0.564864013672 auc: 0.509964511397, batch_auc: 0.556775745606\r\n> 2019-05-14 11:52:49,572-INFO: TRAIN --> pass: 0 batch: 19 loss: 0.559789306641 auc: 0.512298856513, batch_auc: 0.570818080853\r\n> pass_id: 0, pass_time_cost: 105.293049\r\n\r\n\r\n4. Top info    \r\n\r\n> top - 19:51:50 up 188 days,  3:56,  2 users,  load average: 42.83, 42.64, 42.54\r\n> Tasks: 787 total,   2 running, 785 sleeping,   0 stopped,   0 zombie\r\n> %Cpu(s):  4.3 us,  0.2 sy,  0.0 ni, 95.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n> KiB Mem : 19779323+total, 13814598+free, 11023284 used, 48623964 buff/cache\r\n> KiB Swap:  4194300 total,  3760116 free,   434184 used. 18493142+avail Mem\r\n> \r\n>    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\r\n>  60425 root      20   0 14.730g 2.927g  45432 S 170.9  1.6   1:30.33 python\r\n> ",
        "state": "open",
        "user": "lzha106",
        "closed_by": null,
        "created_at": "2019-05-14T12:01:03+00:00",
        "updated_at": "2019-05-20T04:54:09+00:00",
        "closed_at": null,
        "comments_count": [
            "lzha106",
            "seiriosPlus",
            "guru4elephant",
            "lzha106",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2250,
        "title": "deeplabv3+使用develop源码编译的paddle训练报错",
        "body": "paddle：使用develop源码编译安装paddle;\r\n执行指令python ./train.py --batch_size=1 --train_crop_size=769 --total_step=50 --norm_type=gn --init_weights_path=./deeplabv3plus_gn_init --save_weights_path=model --dataset_path=./data/cityscape进行训练，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/57770306-93a32400-7742-11e9-843a-9270717aac21.png)\r\n使用paddle1.4.1 deeplabv3+模型是可以训练的，安装最新的evelop源码编译安装paddle训练报该错误信息。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "baiyfbupt",
        "created_at": "2019-05-15T10:58:14+00:00",
        "updated_at": "2019-05-17T01:52:15+00:00",
        "closed_at": "2019-05-17T01:52:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2251,
        "title": "windows",
        "body": "",
        "state": "closed",
        "user": "kagome112",
        "closed_by": "kagome112",
        "created_at": "2019-05-15T12:00:13+00:00",
        "updated_at": "2019-05-15T12:00:37+00:00",
        "closed_at": "2019-05-15T12:00:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2244,
        "title": "Cannot find variable label_smooth_0.tmp_0@GRAD",
        "body": "I want to quantize a MobileNetV2 model with paddle-slim,  the [demo](https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/compress.py) works fine. However, I get an error when adding a label_smooth layer before cross_entropy layer,  the error information shows as the following picture.\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/57751221-976d8100-7717-11e9-8ef7-ac1413de8c9c.png)\r\n\r\nThe original demo is [demo](https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/compress.py)\r\n\r\nAnd my modified code is：\r\n\r\n```\r\n#cost = fluid.layers.cross_entropy(input=out, label=label)\r\n\r\nepsilon = 0.1\r\nlabel_one_hot = fluid.layers.one_hot(input=label, depth=args.class_dim)\r\nsmooth_label = fluid.layers.label_smooth(label=label_one_hot, epsilon=epsilon, dtype=\"float32\")\r\ncost = fluid.layers.cross_entropy(input=out, label=smooth_label, soft_label=True)\r\n```\r\n\r\n- System: Centos 6.3\r\n- Paddle: 1.4.1\r\n- CUDA: 8.0\r\n- CUDNN: v7\r\n",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-05-15T05:58:39+00:00",
        "updated_at": "2019-05-29T02:56:29+00:00",
        "closed_at": "2019-05-29T02:56:24+00:00",
        "comments_count": [
            "phlrain",
            "mzchtx",
            "mzchtx",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2248,
        "title": "阅读理解-采用预训练模型出错",
        "body": "      最近在采用这个模型学习，谢谢贡献者，我遇到一个问题就是明明GPU有很多的内存，就是总是malloc失败，无法进行下一步训练。这个是我在设置不同的参数的错误。\r\n 采用了Tesla P100显卡，目前显存使用为2443MiB/16276MiB。\r\n     FLAGS_fraction_of_fpu_memory_to_use 每个值都试过了，都有错误，我用的是同步的数据输入。\r\n",
        "state": "open",
        "user": "fw339wj",
        "closed_by": null,
        "created_at": "2019-05-15T09:19:45+00:00",
        "updated_at": "2019-05-16T15:20:43+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2241,
        "title": "yolov3 评估mAP出错",
        "body": "**修改了yolov3的tran.py和yolov3的代码，以便在训练中评估测试集mAP。\r\nyolov3 修改了几处：**\r\n**1.在bulid_input中修改测试集的数据格式**\r\nself.test_py_reader = fluid.layers.py_reader(\r\n                capacity=64,\r\n                shapes=[[-1] + self.image_shape,\r\n                        [-1, 1],\r\n                        [-1, 2],\r\n                        [-1, 4],\r\n                        [-1, 1],\r\n                        [-1, 1]],\r\n                lod_levels=[0, 0, 1, 1,1,1],\r\n                dtypes=['float32'] + ['int32'] *2+ ['float32']+['int32']+ ['float32'],\r\n                use_double_buffer=True)\r\n            print(\"test_input\")\r\n\r\n            self.image,  self.im_id, self.im_shape,self.gtbox, self.gtlabel, self.gtscore = \\\r\n                fluid.layers.read_file(self.test_py_reader)\r\n\r\n**2.预测环节，添加mAP计算**\r\n def get_pred(self):\r\n        yolo_boxes = fluid.layers.concat(self.boxes, axis=1)\r\n        yolo_scores = fluid.layers.concat(self.scores, axis=2)\r\n        nmsed_out=fluid.layers.multiclass_nms(\r\n            bboxes=yolo_boxes,\r\n            scores=yolo_scores,\r\n            score_threshold=cfg.valid_thresh,\r\n            nms_top_k=cfg.nms_topk,\r\n            keep_top_k=cfg.nms_posk,\r\n            nms_threshold=cfg.nms_thresh,\r\n            background_label=-1,\r\n            name=\"multiclass_nms\")\r\n        print(\"nmsed_out:{}\".format(nmsed_out))\r\n        print(\"11111\")\r\n        print(\" self.gtlabel:{}\".format(self.gtlabel))\r\n        print(\" self.gtbox:{}\".format(self.gtbox))\r\n        map_eval = fluid.metrics.DetectionMAP(\r\n            nmsed_out,\r\n            self.gtlabel,\r\n            self.gtbox,\r\n            self.gtscore,\r\n            class_num=self.class_num,\r\n            overlap_threshold=0.5,\r\n            evaluate_difficult=False,\r\n            ap_version='integral')\r\n        return [map_eval,nmsed_out]\r\n\r\n**train.py中关键测试代码**\r\ndef test(epoc_id, best_map):\r\n        cur_map, accum_map = map_eval.get_map_var()\r\n        #print(\"accum_map:{}\".format(accum_map))\r\n        fetch_test_list = [cur_map, accum_map]\r\n        map_eval.reset(exe)\r\n        every_epoc_map=[] # for CE\r\n        accum_map_v=[0.]\r\n        try:\r\n            batch_id = 0\r\n            test_py_reader.start()\r\n            while True:\r\n                print(\"test batch :{}\".format(batch_id))\r\n                _, accum_map_v= exe.run(test_prog, fetch_list=fetch_test_list,use_program_cache=True)\r\n                print(\"batch_id:{},accM_map_v:{}\".format(batch_id,accum_map_v))\r\n                if batch_id % 10 == 0:\r\n                    every_epoc_map.append(accum_map_v)\r\n                    print(\"Batch {0}, map {1}\".format(batch_id, accum_map_v))\r\n                batch_id += 1\r\n        except fluid.core.EOFException:\r\n            test_py_reader.reset()\r\n        mean_map = np.mean(every_epoc_map)\r\n        print(\"Epoc {0}, test map {1}\".format(epoc_id, accum_map_v[0]))\r\n        if accum_map_v[0] > best_map:\r\n            best_map = accum_map_v[0]\r\n            save_model('best_model', test_prog)\r\n        return best_map, mean_map\r\n\r\n**一旦训练到 调用测试程序时 出现会出现如下问题：**\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 313, in <module>\r\n    train()\r\n  File \"train.py\", line 304, in train\r\n    best_map, mean_map = test(epoch_id, best_map)\r\n  File \"train.py\", line 230, in test\r\n    _, accum_map_v= exe.run(test_prog, fetch_list=fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 625, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 702, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator concat error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1689, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/tensor.py\", line 203, in concat\r\n    attrs={'axis': axis})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/metrics.py\", line 645, in __init__\r\n    label = layers.concat([gt_label, gt_difficult, gt_box], axis=1)\r\n  File \"/home/yanglijuan/DLcode/models/PaddleCV/yolov3/models/yolov3.py\", line 242, in get_pred\r\n    ap_version='integral')\r\n  File \"train.py\", line 87, in build_program\r\n    map_eval,nmsed_out= model_test.get_pred()\r\n  File \"train.py\", line 133, in train\r\n    is_train=False)\r\n  File \"train.py\", line 313, in <module>\r\n    train()\r\nC++ Callstacks: \r\nEnforce failed. Expected out_dims[j] == ins[i][j], but received out_dims[j]:1 != ins[i][j]:9.\r\nInput tensors should have the same elements except the specify axis. at [/paddle/paddle/fluid/operators/concat_op.cc:68]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f8638158268p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f86381585b7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f86385c62bbp paddle::operators::ConcatOp::InferShape(paddle::framework::InferShapeContext*) const + 1275\r\n3       0x7f8639e86b4ep paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 302\r\n4       0x7f8639e86f71p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 545\r\n5       0x7f8639e845acp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n6       0x7f86382d52eep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n7       0x7f86382d612fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n8       0x7f863814787ep\r\n9       0x7f863818cfa6p\r\n10            0x4c5326p PyEval_EvalFrameEx + 37958\r\n11            0x4b9b66p PyEval_EvalCodeEx + 774\r\n12            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n13            0x4b9b66p PyEval_EvalCodeEx + 774\r\n14            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n15            0x4b9b66p PyEval_EvalCodeEx + 774\r\n16            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n17            0x4b9b66p PyEval_EvalCodeEx + 774\r\n18            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4eb69fp\r\n21            0x4e58f2p PyRun_FileExFlags + 130\r\n22            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n23            0x4938cep Py_Main + 1358\r\n24      0x7f86b3387830p __libc_start_main + 240\r\n25            0x493299p _start + 41\r\n",
        "state": "open",
        "user": "ellinyang",
        "closed_by": "ellinyang",
        "created_at": "2019-05-15T01:53:56+00:00",
        "updated_at": "2019-05-15T07:41:40+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "ellinyang",
            "heavengate",
            "ellinyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2247,
        "title": "中文机器阅读理解 错误，更改为一条数据预测 ValueError: feed_parallel takes multiple mini-batches. Each mini-batch will be feed on each device. The number of devices and number of mini-batches must be same.",
        "body": "尝试过更改设备数 dev_count 还是报错设备数据和预测数据需一致的错误，所以 我现在想只预测一条数据，求解，谢谢",
        "state": "open",
        "user": "xingzhoupy",
        "closed_by": null,
        "created_at": "2019-05-15T09:11:29+00:00",
        "updated_at": "2019-05-22T11:58:48+00:00",
        "closed_at": null,
        "comments_count": [
            "xingzhoupy",
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2253,
        "title": "object_detection infer的问题",
        "body": "我是用ssd_mobilenet_v1_coco预训练模型对自定义pascalvoc数据集进行训练，数据集中有两个标签dog和dog_leash,使用训练好的模型best_model对图像进行预测及可视化显示，但预测后的图像只标出了dog_leash。infer.py中confs_threshold调到0还是预测不到dog",
        "state": "closed",
        "user": "smallsung1999",
        "closed_by": "smallsung1999",
        "created_at": "2019-05-15T14:18:15+00:00",
        "updated_at": "2019-05-16T10:31:22+00:00",
        "closed_at": "2019-05-16T10:31:22+00:00",
        "comments_count": [
            "smallsung1999"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2273
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2258,
        "title": "阅读理解执行段落抽取报错",
        "body": "python3.6下阅读理解执行段落抽取时报错，报错如下：\r\nStart paragraph extraction, this may take a few hours\r\nSource dir: ../data/preprocessed\r\nTarget dir: ../data/extracted\r\nProcessing trainset\r\nTraceback (most recent call last):\r\n  File \"paragraph_extraction.py\", line 198, in <module>\r\n    print(json.dumps(sample, encoding='utf8', ensure_ascii=False))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)\r\nTypeError: __init__() got an unexpected keyword argument 'encoding'\r\nTraceback (most recent call last):\r\n  File \"paragraph_extraction.py\", line 198, in <module>\r\n    print(json.dumps(sample, encoding='utf8', ensure_ascii=False))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)\r\nTypeError: __init__() got an unexpected keyword argument 'encoding'\r\nProcessing devset\r\nTraceback (most recent call last):\r\n  File \"paragraph_extraction.py\", line 198, in <module>\r\n    print(json.dumps(sample, encoding='utf8', ensure_ascii=False))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "HongyuLi2018",
        "created_at": "2019-05-16T07:53:00+00:00",
        "updated_at": "2019-05-16T15:33:12+00:00",
        "closed_at": "2019-05-16T15:33:11+00:00",
        "comments_count": [
            "xyzhou-puck",
            "HongyuLi2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2271,
        "title": "auto_dialogue_evaluation训练报错",
        "body": "在python3.6下，auto_dialogue_evaluation训练报错，报错如下：\r\n<img width=\"889\" alt=\"8790bb1e8b9b46ca92730ab6d7c5faa1\" src=\"https://user-images.githubusercontent.com/46314656/58004219-4eea0500-7b15-11e9-8e89-2c5da525e5f0.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "kuke",
        "created_at": "2019-05-20T07:41:25+00:00",
        "updated_at": "2019-06-21T02:07:42+00:00",
        "closed_at": "2019-06-21T02:07:42+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2269,
        "title": "windows version",
        "body": "Can you provide a windows version? Thank you very much!",
        "state": "closed",
        "user": "skysunsun",
        "closed_by": "tensor-tang",
        "created_at": "2019-05-18T03:05:02+00:00",
        "updated_at": "2019-05-20T09:01:50+00:00",
        "closed_at": "2019-05-20T09:01:50+00:00",
        "comments_count": [
            "tensor-tang",
            "skysunsun",
            "tensor-tang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2275,
        "title": "paddle::operators::BeamSearchOp::GetExpectedKernelType()",
        "body": "transformer example在infer.py时出现如下错误，请问是什么原因：\r\n\r\n```W0520 17:37:07.204490 31227 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0520 17:37:07.204536 31227 device_context.cc:271] device: 0, cuDNN Version: 7.0.\r\n*** Aborted at 1558345027 (unix time) try \"date -d @1558345027\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 31227 (TID 0x7fea597af700) from PID 0; stack trace: ***\r\n    @     0x7fea59543390 (unknown)\r\n    @     0x7fea2c92c813 paddle::operators::BeamSearchOp::GetExpectedKernelType()\r\n    @     0x7fea2dad5630 paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7fea2dad3045 paddle::framework::OperatorBase::Run()\r\n    @     0x7fea2c114912 paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7fea2d5ff1f2 paddle::operators::WhileOp::RunImpl()\r\n    @     0x7fea2dad3045 paddle::framework::OperatorBase::Run()\r\n    @     0x7fea2c114912 paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7fea2c11685f paddle::framework::Executor::Run()\r\n    @     0x7fea2bfe548e _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE91_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\n    @     0x7fea2c0207ae pybind11::cpp_function::dispatcher()\r\n    @     0x7fea598981a7 PyEval_EvalFrameEx\r\n    @     0x7fea5989a6c9 PyEval_EvalCodeEx\r\n    @     0x7fea59897b98 PyEval_EvalFrameEx\r\n    @     0x7fea5989a6c9 PyEval_EvalCodeEx\r\n    @     0x7fea59897b98 PyEval_EvalFrameEx\r\n    @     0x7fea5989917e PyEval_EvalFrameEx\r\n    @     0x7fea5989a6c9 PyEval_EvalCodeEx\r\n    @     0x7fea5989a8ea PyEval_EvalCode\r\n    @     0x7fea598b3bad run_mod\r\n    @     0x7fea598b4d28 PyRun_FileExFlags\r\n    @     0x7fea598b5f48 PyRun_SimpleFileExFlags\r\n    @     0x7fea598c816c Py_Main\r\n    @     0x7fea58a78830 __libc_start_main\r\n    @     0x56171d68107f (unknown)\r\nSegmentation fault (core dumped)```",
        "state": "closed",
        "user": "tsaizehua",
        "closed_by": "JiabinYang",
        "created_at": "2019-05-20T09:40:12+00:00",
        "updated_at": "2019-06-17T03:12:26+00:00",
        "closed_at": "2019-05-21T08:05:13+00:00",
        "comments_count": [
            "guoshengCS",
            "tsaizehua",
            "Maxhyl",
            "yuzunrui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2278,
        "title": "DyGraph实现ResNet模型，Imagenet数据库Py_reader读取出错！",
        "body": "多谢百度paddle的各位兄弟帮忙！\r\n![CETH{}`_{7)RB$}DTR$VO8B](https://user-images.githubusercontent.com/45925696/58023389-3e9c4f00-7b42-11e9-8184-27323758e2b8.png)\r\n\r\n[train_resnet_DyGraph.zip](https://github.com/PaddlePaddle/models/files/3198008/train_resnet_DyGraph.zip)\r\n\r\n\r\n",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-05-20T13:00:38+00:00",
        "updated_at": "2019-05-22T11:30:20+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang",
            "qianledan",
            "qianledan",
            "DDDivano"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2279,
        "title": "lodtensor_to_ndarray这个函数找不到",
        "body": "你好，请问data_utils文件夹下的util.py文件的lodtensor_to_ndarray函数为什么是没有的",
        "state": "open",
        "user": "Maxhyl",
        "closed_by": null,
        "created_at": "2019-05-21T01:29:47+00:00",
        "updated_at": "2019-05-27T03:51:44+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "Maxhyl",
            "wzzju",
            "Maxhyl",
            "Maxhyl"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2277,
        "title": "benchmark分支下yolo v3 参数拼写错误",
        "body": "https://github.com/PaddlePaddle/models/blob/benchmark/PaddleCV/yolov3/train.py#L103\r\n\r\nuse_gpu 拼写错误",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "chengduoZH",
        "created_at": "2019-05-20T11:40:49+00:00",
        "updated_at": "2019-05-20T11:50:55+00:00",
        "closed_at": "2019-05-20T11:50:55+00:00",
        "comments_count": [
            "chengduoZH"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2286,
        "title": "Cannot Download baidu_en8k_model.tar.gz",
        "body": "When running download_model.sh, I get this problem:\r\n\r\n```Resolving cloud.dlnel.org (cloud.dlnel.org)... 180.76.189.142\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|180.76.189.142|:80... connected.\r\nHTTP request sent, awaiting response... 502 Bad Gateway\r\nCookie coming from cloud.dlnel.org attempted to set domain to cloud.dlnel.org\r\n2019-05-22 11:33:09 ERROR 502: Bad Gateway.\r\n```\r\n\r\nI tried adding cloud.dlnel /etc/hosts, still doesn't work. I tried pasting the link into a browser, and got 502 Bad Gateway NGINX. Please help, thank you.\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2019-05-22T03:49:45+00:00",
        "updated_at": "2019-05-22T04:06:30+00:00",
        "closed_at": "2019-05-22T04:06:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2282,
        "title": "deeplab v3+训练报错",
        "body": "使用models-1.4的deeplabv3+的代码在本地训练，用的是paddle1.4.1，出现以下错误,\r\n```\r\nI0521 16:51:32.690387 24805 build_strategy.cc:285] SeqOnlyAllReduceOps:0, num_trainers:1\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 585, in __provider_thread__\r\n    raise ex\r\nIndexError: list index out of range\r\n\r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 216, in <module>\r\n    train_loss, = exe.run(binary, fetch_list=[loss_mean])\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 580, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 446, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:92]\r\n```\r\n\r\n训练的脚本就是官网给出的脚本，想问一下这是什么问题呢？",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-05-21T08:55:45+00:00",
        "updated_at": "2019-09-25T06:04:47+00:00",
        "closed_at": "2019-05-23T12:57:07+00:00",
        "comments_count": [
            "qingqing01",
            "littletomatodonkey",
            "littletomatodonkey",
            "eddieheyutong",
            "littletomatodonkey"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2283,
        "title": "AutoDL HiNAS_models 要如何处理自定义图片分类数据进行训练预测",
        "body": "",
        "state": "open",
        "user": "demohold",
        "closed_by": null,
        "created_at": "2019-05-21T09:21:12+00:00",
        "updated_at": "2019-05-22T02:15:32+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2289,
        "title": "动态图Mnist 代码问题",
        "body": "这个mnist模型卷积层激活函数是不是没有传过来？\r\n![image](https://user-images.githubusercontent.com/10734244/58156749-6659f700-7ca9-11e9-85ba-52dba110a078.png)\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "DDDivano",
        "created_at": "2019-05-22T07:53:16+00:00",
        "updated_at": "2019-06-24T09:16:30+00:00",
        "closed_at": "2019-06-24T09:16:30+00:00",
        "comments_count": [
            "qianledan",
            "DDDivano",
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2291,
        "title": "动态图resnet（模型结构有修改）训练时内存溢出，是否模型结构有问题，帮忙看一下代码？",
        "body": "![QQ图片20190522181515](https://user-images.githubusercontent.com/45925696/58167442-8ba53000-7cbe-11e9-8d3f-b4e3531ad1f7.png)\r\n![QQ图片20190522181443](https://user-images.githubusercontent.com/45925696/58167447-8ea02080-7cbe-11e9-9cae-ca4d0d147d3c.png)\r\n用官网给的动态图resnet模型，batch_size设置16，能够正常跑。\r\n本人对该模型结构进行了部分的修改，训练时出现GPU内存溢出\r\n[Desktop.zip](https://github.com/PaddlePaddle/models/files/3206941/Desktop.zip)\r\n",
        "state": "closed",
        "user": "qianledan",
        "closed_by": "phlrain",
        "created_at": "2019-05-22T10:26:56+00:00",
        "updated_at": "2019-06-10T02:54:19+00:00",
        "closed_at": "2019-06-10T02:54:19+00:00",
        "comments_count": [
            "phlrain",
            "qianledan",
            "phlrain",
            "qianledan",
            "phlrain",
            "qianledan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2292,
        "title": "Insufficient GPU memory to allocation.",
        "body": "-----------  Configuration Arguments -----------\r\nbatch_size: 8\r\nclass_num: 80\r\ndata_dir: dataset/coco\r\ndataset: coco2017\r\ndebug: False\r\ndraw_thresh: 0.5\r\nimage_name: 000000000139.jpg\r\nimage_path: ./dataset/coco/val2017\r\ninput_size: 608\r\nlabel_smooth: True\r\nlearning_rate: 0.001\r\nmax_iter: 500200\r\nmodel_save_dir: checkpoints\r\nnms_posk: 100\r\nnms_thresh: 0.45\r\nnms_topk: 400\r\nno_mixup_iter: 40000\r\npretrain: weights/darknet53\r\nrandom_shape: True\r\nsnapshot_iter: 2000\r\nstart_iter: 0\r\nsyncbn: True\r\nuse_gpu: True\r\nuse_multiprocess: True\r\nvalid_thresh: 0.005\r\nweights: \r\n------------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.31s)\r\ncreating index...\r\nindex created!\r\nLoad in 80 categories.\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 80, in <module>\r\n    infer()\r\n  File \"infer.py\", line 63, in infer\r\n    feed=feeder.feed(data),\r\n  File \"/home/lwd/.local/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 246, in feed\r\n    ret_dict[each_name] = each_converter.done()\r\n  File \"/home/lwd/.local/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 95, in done\r\n    t.set(arr, self.place)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected allocating <= available, but received allocating:5403593101 > available:5300944640.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:262]\r\nPaddlePaddle Call Stacks: \r\n0       0x7eff92634228p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7eff92634577p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7eff9437c706p paddle::platform::GpuMaxChunkSize() + 630\r\n3       0x7eff943510a2p\r\n4       0x7effd8c62827p\r\n5       0x7eff9435074dp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 109\r\n6       0x7eff94351573p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 35\r\n7       0x7eff943519b5p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long, paddle::memory::allocation::Allocator::Attr) + 389\r\n8       0x7eff94376c6bp paddle::memory::allocation::Allocator::Allocate(unsigned long, paddle::memory::allocation::Allocator::Attr) + 27\r\n9       0x7eff943455b3p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 435\r\n10      0x7eff943456d1p paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 33\r\n11      0x7eff93f835a0p paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long, paddle::memory::allocation::Allocator::Attr) + 48\r\n12      0x7eff9431796ap paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, paddle::memory::allocation::Allocator::Attr, unsigned long) + 154\r\n13      0x7eff926447efp float* paddle::framework::Tensor::mutable_data<float>(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::memory::allocation::Allocator::Attr, unsigned long) + 79\r\n14      0x7eff92644cb6p\r\n15      0x7eff9268c457p\r\n16      0x7eff926667cep\r\n17            0x565d5cp _PyCFunction_FastCallDict + 860\r\n18            0x503073p\r\n19            0x506859p _PyEval_EvalFrameDefault + 1097\r\n20            0x502209p\r\n21            0x502f3dp\r\n22            0x506859p _PyEval_EvalFrameDefault + 1097\r\n23            0x502209p\r\n24            0x502f3dp\r\n25            0x506859p _PyEval_EvalFrameDefault + 1097\r\n26            0x502209p\r\n27            0x502f3dp\r\n28            0x506859p _PyEval_EvalFrameDefault + 1097\r\n29            0x504c28p\r\n30            0x506393p PyEval_EvalCode + 35\r\n31            0x634d52p\r\n32            0x634e0ap PyRun_FileExFlags + 154\r\n33            0x6385c8p PyRun_SimpleFileExFlags + 392\r\n34            0x63915ap Py_Main + 1402\r\n35            0x4a6f10p main + 224\r\n36      0x7effd8e93b97p __libc_start_main + 231\r\n37            0x5afa0ap _start + 42\r\n\r\n +-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 2060    Off  | 00000000:01:00.0  On |                  N/A |\r\n| N/A   47C    P8    11W /  N/A |    579MiB /  5896MiB |      2%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1164      G   /usr/lib/xorg/Xorg                            18MiB |\r\n|    0      1198      G   /usr/bin/gnome-shell                          51MiB |\r\n|    0      1472      G   /usr/lib/xorg/Xorg                           214MiB |\r\n|    0      1601      G   /usr/bin/gnome-shell                         189MiB |\r\n|    0      2153      G   ...quest-channel-token=4841798388314319105   103MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n",
        "state": "closed",
        "user": "Sparrow0817",
        "closed_by": "heavengate",
        "created_at": "2019-05-22T12:03:38+00:00",
        "updated_at": "2019-05-23T04:19:07+00:00",
        "closed_at": "2019-05-23T04:04:56+00:00",
        "comments_count": [
            "Sparrow0817",
            "heavengate",
            "Sparrow0817",
            "heavengate",
            "Sparrow0817",
            "heavengate",
            "Sparrow0817",
            "heavengate",
            "heavengate",
            "Sparrow0817"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2297,
        "title": "similarity_net在fluid1.4版本下的并行训练问题",
        "body": "现在直接用官方提供的similarity_net，提示\r\n\r\n> ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\nW0523 11:22:05.580132 14117 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\n\r\n应该没有使用多个cpu并行训练，系统只有一个cpu在使用。\r\n\r\n看了另外一个issue：https://github.com/PaddlePaddle/models/issues/2102\r\n也遇到过类似报错，说是需要用统一的Executor接口。\r\n\r\n官方提供的similarity_net代码是不是需要更新下了？\r\n",
        "state": "open",
        "user": "ybbz",
        "closed_by": null,
        "created_at": "2019-05-23T03:57:46+00:00",
        "updated_at": "2019-05-24T07:00:44+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "ybbz",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2293,
        "title": "YOLOv3 训练慢，内存占用高",
        "body": "版本、环境信息\r\n     1）docker镜像 paddlepaddle/paddle:1.4.0-gpu-cuda9.0-cudnn7\r\n     2）GPU Tesla V100 (16G显存)\r\n训练信息\r\n    1）单机单卡训练 \r\n    2）batchsize=1\r\n    3）图像大小800*800\r\n背景\r\n    修改了yolov3的数据读入接口和评估代码，并在训练中加入测试程序。\r\n**问题**\r\n    如果不设置FLAGS_fraction_of_gpu_memory_to_use ，batch_size=1的模型会占15G显存；设置了FLAGS_fraction_of_gpu_memory_to_use=0 ，模型会动态占用1G～7G的显存。当BatchSize>2时，报错如下：\r\n\r\n```\r\nW0521 08:04:10.744120 44911 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0521 08:04:10.749207 44911 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\nW0521 08:04:10.845206 44911 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nW0521 08:04:10.855835 44911 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nW0521 08:04:34.876225 44911 system_allocator.cc:121] Cannot malloc 39.0627 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use or FLAGS_initial_gpu_memory_in_mb or FLAGS_reallocate_gpu_memory_in_mbenvironment variable to a lower value. Current FLAGS_fraction_of_gpu_memory_to_use value is 0. Current FLAGS_initial_gpu_memory_in_mb value is 0. Current FLAGS_reallocate_gpu_memory_in_mb value is 0\r\nF0521 08:04:34.879753 44911 legacy_allocator.cc:201] Cannot allocate 39.062500MB in GPU 0, available 34.312500MBtotal 16936927232GpuMinChunkSize 256.000000BGpuMaxChunkSize 0.000000BGPU memory used: 0.000000B\r\n*** Check failure stack trace: ***\r\n    @     0x7f5afbd40ffd  google::LogMessage::Fail()\r\n    @     0x7f5afbd44aac  google::LogMessage::SendToLog()\r\n    @     0x7f5afbd40b23  google::LogMessage::Flush()\r\n    @     0x7f5afbd45fbe  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f5afd9c5ca7  paddle::memory::legacy::Alloc<>()\r\n    @     0x7f5afd9c5ee5  paddle::memory::allocation::LegacyAllocator::AllocateImpl()\r\n    @     0x7f5afd9eb21b  paddle::memory::allocation::Allocator::Allocate()\r\n    @     0x7f5afd9b9aa3  paddle::memory::allocation::AllocatorFacade::Alloc()\r\n    @     0x7f5afd9b9bc1  paddle::memory::allocation::AllocatorFacade::AllocShared()\r\n    @     0x7f5afd5e6270  paddle::memory::AllocShared()\r\n    @     0x7f5afd98b1ca  paddle::framework::Tensor::mutable_data()\r\n    @     0x7f5afc004606  paddle::operators::CUDNNConvOpKernel<>::Compute()\r\n    @     0x7f5afc005c63  _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EJNS0_9operators17CUDNNConvOpKernelIfEENSA_IdEENSA_INS7_7float16EEEEEclEPKcSH_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\n    @     0x7f5afd938b90  paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7f5afd938f71  paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7f5afd9365ac  paddle::framework::OperatorBase::Run()\r\n    @     0x7f5afbd872ee  paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7f5afbd8812f  paddle::framework::Executor::Run()\r\n    @     0x7f5afbbf987e  _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE98_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\n    @     0x7f5afbc3efa6  pybind11::cpp_function::dispatcher()\r\n    @           0x4c5326  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c17c6  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4eb69f  (unknown)\r\n    @           0x4e58f2  PyRun_FileExFlags\r\n    @           0x4e41a6  PyRun_SimpleFileExFlags\r\n    @           0x4938ce  Py_Main\r\n-----------  Configuration Arguments -----------\r\n\r\n\r\n```",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-05-22T12:13:32+00:00",
        "updated_at": "2019-05-22T13:03:42+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2305,
        "title": "Todo: Image Classification",
        "body": "- [ ] refine image classification codes and docs in another repo: paddle/book\r\n- [ ] https://github.com/PaddlePaddle/Paddle/issues/17149#issue-438126920\r\n- [ ] update cv2 acc and cv2 reader\r\n\r\n---\r\n\r\n",
        "state": "open",
        "user": "shippingwang",
        "closed_by": null,
        "created_at": "2019-05-23T17:09:38+00:00",
        "updated_at": "2019-05-23T17:09:48+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2301,
        "title": "检测模型如何使用 op 实现 multi crop 预测",
        "body": "当输入图片很大时，想把图片切成若干几张小图，合成一个 batch 输入 SSD 等检测模型中。\r\n想了解如何把这个 batch 的输出使用 op 进行后处理：\r\n\r\n1. 对这个 batch 中的每个检测框进行坐标偏差加减\r\n2. 合并这个 batch 中的所有检测框进行 nms\r\n\r\n谢谢！",
        "state": "open",
        "user": "lijiancheng0614",
        "closed_by": null,
        "created_at": "2019-05-23T07:15:34+00:00",
        "updated_at": "2019-05-24T03:15:43+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz",
            "lijiancheng0614"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2304,
        "title": "MAC下gnn下载模型数据失败",
        "body": "按照官方文档下载模型数据，执行指令cd data && sh download.sh，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/58248462-c8d8f300-7d8e-11e9-928d-cfc22c088cb8.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "hutuxian",
        "created_at": "2019-05-23T11:13:13+00:00",
        "updated_at": "2019-06-24T11:49:11+00:00",
        "closed_at": "2019-06-24T11:49:10+00:00",
        "comments_count": [
            "hutuxian"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2306,
        "title": "gnn 训练报错",
        "body": "macos 执行 CPU_NUM=1 python -u train.py --use_cuda 0 > log.txt 2>&1\r\n日志\r\n\r\n2019-05-24 10:01:06,870 - INFO - load data complete\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 172, in <module>\r\n    train()\r\n  File \"train.py\", line 104, in train\r\n    feeder = fluid.DataFeeder(feed_list=feed_list, place=place)\r\n  File \"/Users/iMac/anaconda3/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 161, in __init__\r\n    each_var.name)\r\nValueError: ('Variable {0} must has a batch size dimension', 'items')\r\n",
        "state": "closed",
        "user": "wangduan023",
        "closed_by": "hutuxian",
        "created_at": "2019-05-24T02:23:03+00:00",
        "updated_at": "2019-07-09T15:25:17+00:00",
        "closed_at": "2019-07-09T15:25:17+00:00",
        "comments_count": [
            "wangguibao",
            "wangduan023",
            "hutuxian",
            "JiaXiao243",
            "wangduan023"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2313,
        "title": "paddle language_model gru模型用int16训练出现了NaN",
        "body": "paddle model zoo中language_model/gru模型训练时，用float进行训练ppl收敛到125左右，但是gemm的精度改为int16进行训练时，到第六轮就出现了NaN，请问这个应该怎么去调整？",
        "state": "open",
        "user": "dashulu",
        "closed_by": null,
        "created_at": "2019-05-27T02:30:03+00:00",
        "updated_at": "2019-06-17T07:52:25+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2307,
        "title": "基于YOLOv3的实时目标检测",
        "body": "有人在paddle上做过这个项目吗\n\n<sub>Sent from <a href=\"https://itunes.apple.com/cn/app/id1314212521\">PPHub For GitHub</a></sub>",
        "state": "closed",
        "user": "Sparrow0817",
        "closed_by": "wangguibao",
        "created_at": "2019-05-24T06:14:29+00:00",
        "updated_at": "2020-04-01T10:36:43+00:00",
        "closed_at": "2019-05-24T06:31:52+00:00",
        "comments_count": [
            "wangguibao",
            "Sparrow0817",
            "huxianhe0",
            "wangguibao",
            "Sparrow0817"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2317,
        "title": "ctr模型没有预测代码",
        "body": "ctr模型没有预测infer代码，而且训练时也没有测试损失？",
        "state": "open",
        "user": "xiaolv3366",
        "closed_by": null,
        "created_at": "2019-05-27T09:27:49+00:00",
        "updated_at": "2019-05-27T15:58:33+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2327,
        "title": "PIL读取后图片尺寸为是whc，cv2读取后图片尺寸为hwc，在image_classification的reader中是否存在错误？",
        "body": "在models/PaddleCV/image_classification/reader.py中使用PIL读取图片，在117行random_crop函数中：\r\nimg = np.array(img).astype('float32').transpose((2, 0, 1)) / 255\r\n    img -= img_mean\r\n    img /= img_std\r\n使用该方法，transpose后应为cwh,会导致图片相较于chw传统的思路翻转了90度，虽然train，test均做了处理，最终导致模型训练没有影响，\r\n而在reader_cv2中的对应位置处理方式相同，是否存在问题？\r\n`def random_crop(img, size, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]):\r\n    aspect_ratio = math.sqrt(np.random.uniform(*ratio))\r\n    w = 1. * aspect_ratio\r\n    h = 1. / aspect_ratio\r\n\r\n    bound = min((float(img.size[0]) / img.size[1]) / (w**2),#在这一步是否存在问题？hw的顺序与cv2不同\r\n                (float(img.size[1]) / img.size[0]) / (h**2))\r\n    scale_max = min(scale[1], bound)\r\n    scale_min = min(scale[0], bound)\r\n\r\n    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min,\r\n                                                                scale_max)\r\n    target_size = math.sqrt(target_area)\r\n    w = int(target_size * w)\r\n    h = int(target_size * h)\r\n\r\n    i = np.random.randint(0, img.size[0] - w + 1)\r\n    j = np.random.randint(0, img.size[1] - h + 1)\r\n\r\n    img = img.crop((i, j, i + w, j + h))\r\n    img = img.resize((size, size), Image.LANCZOS)\r\n    return img`\r\n\r\n另在该代码中是否能增加一些注释，以便在使用时帮助理解，谢谢！",
        "state": "open",
        "user": "miraclebiu",
        "closed_by": null,
        "created_at": "2019-05-29T05:06:34+00:00",
        "updated_at": "2019-06-18T09:05:24+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2319,
        "title": "可否新增Tensor的操作，如topk()升序取前几项，tensor根据维度和索引赋值等？",
        "body": "对比了paddle和pytorch关于tensor的相关操作，本人需要用到“tensor的升序取最小的前面几项”处理，和根据索引赋值操作，但是paddle里没有相关的函数，pytorch里有，如：topk(k, dim=None, largest=True, sorted=True)，正反排序都可以。index_fill(dim, index, value)依据维度和索引赋值，index_select(dim, index)根据维度和索引选择。\r\n\r\npytorch里关于tensor的操作函数非常全面，而paddle里却不多，只有少数。希望工程师可以参照pytorch里的函数进行新增。",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-05-27T12:50:36+00:00",
        "updated_at": "2019-05-27T16:01:58+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2331,
        "title": "硬币识别问题",
        "body": "请问硬币识别用什么网络模型好？",
        "state": "open",
        "user": "hlguo",
        "closed_by": null,
        "created_at": "2019-05-29T09:31:40+00:00",
        "updated_at": "2019-06-28T02:33:00+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315",
            "hlguo",
            "lgone2000",
            "hlguo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2323,
        "title": "dialogue_general_understanding运行出错memory_optimize is deprecated. Use CompiledProgram and Executor",
        "body": "paddle1.4版本中运行dstc2、mrda报错\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-05-28T10:43:28+00:00",
        "updated_at": "2019-05-28T12:25:19+00:00",
        "closed_at": "2019-05-28T12:25:19+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2332,
        "title": "icnet模型训练细节",
        "body": "能否提供icnet的训练细节呢？比如说学习率策略，初始学习率，迭代轮数，weight decay等参数，谢谢",
        "state": "open",
        "user": "littletomatodonkey",
        "closed_by": null,
        "created_at": "2019-05-29T12:50:16+00:00",
        "updated_at": "2019-06-17T07:32:24+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2337,
        "title": "int8 量化训练float 和 int8文件夹下同一层对应fake_quantize_range_abs_max不一致",
        "body": "1.4.1 版本 int8 量化训练后保存的float 和 int8文件夹下同一层对应fake_quantize_range_abs_max不一致, 请问如何解决？",
        "state": "closed",
        "user": "dubhex",
        "closed_by": "dubhex",
        "created_at": "2019-05-30T03:41:46+00:00",
        "updated_at": "2019-06-10T05:51:02+00:00",
        "closed_at": "2019-06-10T05:51:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2334,
        "title": "DeepASR的decoder怎么才算安装成功呢,已经成了so文件，但是调用会报错",
        "body": "这个是安装后打印的结果\r\n![image](https://user-images.githubusercontent.com/49184062/58604038-8dc24c80-82c5-11e9-8e58-344379077ab0.png) \r\n",
        "state": "closed",
        "user": "Maxhyl",
        "closed_by": "Maxhyl",
        "created_at": "2019-05-30T02:28:11+00:00",
        "updated_at": "2019-06-03T03:42:04+00:00",
        "closed_at": "2019-06-03T03:42:04+00:00",
        "comments_count": [
            "junjun315",
            "Maxhyl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2338,
        "title": "yolov3 8卡训练报错",
        "body": "paddle：最新的develop分支代码编译安装；\r\nmodels： 最新的develop代码；\r\n单卡训练没有问题，多卡训练报错。\r\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\r\n执行 python train.py 报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/58616194-a0517b80-82ef-11e9-9ce0-b6ddf3b37472.png)\r\npython train.py --syncbn=False 可以跑通\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "gongweibao",
        "created_at": "2019-05-30T07:30:08+00:00",
        "updated_at": "2019-06-09T02:02:30+00:00",
        "closed_at": "2019-06-09T02:02:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2339,
        "title": "动态图文档说明优化",
        "body": "mnist需要加上多卡文档说明。\r\nptb需要加说明文档，目前没有。 ptb文件夹名写成pbt了需要改一下~",
        "state": "open",
        "user": "DDDivano",
        "closed_by": null,
        "created_at": "2019-05-30T10:37:58+00:00",
        "updated_at": "2019-05-30T13:03:10+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2343,
        "title": "faster rcnn eval报错",
        "body": "当下载官方Fluid RoIPool minibatch padding模型进行test时，feed数据时会报错\r\n![image](https://user-images.githubusercontent.com/17508662/58748331-9f644980-84a9-11e9-96e9-5a36792ae6a1.png)\r\n",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "cjt222",
        "created_at": "2019-06-01T12:12:55+00:00",
        "updated_at": "2019-06-03T02:42:33+00:00",
        "closed_at": "2019-06-03T02:42:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2345,
        "title": "fix error which cv2 is used but not import while loading mp4 file",
        "body": "1、fix error which cv2 is used but not import while loading mp4 file #2344\r\n2、while loading mp4 file, some frames may fail to be read and it may result in out of range in sampledFrames\r\n![image](https://user-images.githubusercontent.com/17508662/58764023-feeb5380-8594-11e9-9a60-89945561bf6c.png)\r\n",
        "state": "open",
        "user": "cjt222",
        "closed_by": null,
        "created_at": "2019-06-02T07:01:43+00:00",
        "updated_at": "2019-06-03T06:36:36+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2350,
        "title": "PaddleSlim是否支持yolov3等检测模型的剪枝压缩",
        "body": "",
        "state": "closed",
        "user": "herbiezhao",
        "closed_by": "sandyhouse",
        "created_at": "2019-06-03T11:55:22+00:00",
        "updated_at": "2019-08-13T12:36:04+00:00",
        "closed_at": "2019-06-04T05:10:08+00:00",
        "comments_count": [
            "sandyhouse",
            "herbiezhao",
            "sandyhouse",
            "sandyhouse",
            "gujingxiao",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2355,
        "title": "CycleGAN和pix2pix模型python3训练报错",
        "body": "python3.7环境下，在PaddleCV/gan目录下分别运行 bash scripts/run_cyclegan.sh 和bash scripts/run_pix2pix.sh，对cyclegan和pix2pix模型进行训练，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/58856640-cd2dd600-86d5-11e9-84fd-00e52e0a5fc1.png)\r\n![image](https://user-images.githubusercontent.com/37854899/58856691-e9ca0e00-86d5-11e9-8db8-257a729fa6cd.png)\r\npython2.7环境下，可以正常训练。需要将两个模型在python3上适配一下~\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-04T06:35:54+00:00",
        "updated_at": "2019-06-10T03:04:42+00:00",
        "closed_at": "2019-06-10T03:04:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2356,
        "title": "pix2pix infer报错",
        "body": "pix2pix在python2.7环境下训练完成后，执行bash scripts/infer_pix2pix.sh对训练好的模型进行预测，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/58860096-f3577400-86dd-11e9-9727-df45b0b7cccf.png)\r\n无法正确识别infer的input,在infer_pix2pix.sh中input后路径添加双引号，即\r\n将--input data/cityscapes/testB/*  修改为 --input \"data/cityscapes/testB/*\",可以正常infer，以下代码用到args.input：\r\n![image](https://user-images.githubusercontent.com/37854899/58860327-72e54300-86de-11e9-9409-025f06cb72d7.png)\r\n可能需要修改一下infer_pix2pix.sh脚本。\r\n\r\n ",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-04T07:37:23+00:00",
        "updated_at": "2019-06-10T08:10:57+00:00",
        "closed_at": "2019-06-10T08:10:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2351,
        "title": "attention_cluster和lstm预训练的3862类，是youtube8M哪些类？方便提供一下对应关系吗？",
        "body": "",
        "state": "closed",
        "user": "youidol",
        "closed_by": "sandyhouse",
        "created_at": "2019-06-03T11:57:58+00:00",
        "updated_at": "2019-06-06T07:23:15+00:00",
        "closed_at": "2019-06-04T05:12:58+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2353,
        "title": "增量训练",
        "body": "![image](https://user-images.githubusercontent.com/5461637/58853575-5e4c7f00-86cd-11e9-98ca-1e2eea09b1df.png)\r\ntransformer模型，load checkpoin之后，训练还是从loss很高开始降\r\n![image](https://user-images.githubusercontent.com/5461637/58853628-8d62f080-86cd-11e9-9980-2695372b2ec7.png)\r\n不知道是否读取正确\r\n![image](https://user-images.githubusercontent.com/5461637/58853739-bc796200-86cd-11e9-9b9c-4863289263e4.png)\r\n",
        "state": "open",
        "user": "yxzero",
        "closed_by": null,
        "created_at": "2019-06-04T05:34:49+00:00",
        "updated_at": "2019-06-05T10:32:21+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2358,
        "title": "face_detection Train",
        "body": "gpu单卡运行，11G，能够正常测试预发布模型，但是在运行训练代码过程中：\r\nexport CUDA_VISIBLE_DEVICES=0\r\npython -u train.py --batch_size=3 --pretrained_model=vgg_ilsvrc_16_fc_reduced\r\n执行这两个步骤之后，也是正常进入训练的，但是训练过程中是如下这样显示的！出现\".......MemoryError\"这样的问题，并卡在最后的训练处，不再继续进行，希望能得到大家的帮助！！！\r\n\r\nPass 0, batch 1890, face loss 3.608721, head loss 3.827300, time 0.82712\r\nPass 0, batch 1900, face loss 6.004067, head loss 6.459546, time 0.81461\r\nPass 0, batch 1910, face loss 4.193470, head loss 3.602981, time 0.82136\r\nProcess Process-7:\r\nTraceback (most recent call last):\r\n  File \"/home/jyf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/home/jyf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/jyf/anaconda3/lib/python3.6/site-packages/paddle/reader/decorator.py\", line 393, in _read_into_queue\r\n    for sample in reader():\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/reader.py\", line 267, in reader\r\n    image_path)\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/reader.py\", line 116, in preprocess\r\n    settings.min_face_size)\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/image_util.py\", line 424, in crop_image_sampling\r\n    sample_img = np.zeros((height, width, 3))\r\nMemoryError\r\nPass 0, batch 1920, face loss 4.207895, head loss 3.901461, time 0.81387\r\nPass 0, batch 1930, face loss 4.981308, head loss 4.160357, time 0.82922\r\nPass 0, batch 1940, face loss 4.242156, head loss 3.531482, time 0.89638\r\nPass 0, batch 1950, face loss 5.884556, head loss 3.824725, time 0.81456\r\nPass 0, batch 1960, face loss 3.307667, head loss 2.812590, time 0.81372\r\nPass 0, batch 1970, face loss 4.135998, head loss 4.142908, time 0.81373\r\nPass 0, batch 1980, face loss 3.992738, head loss 2.869507, time 0.81205\r\nPass 0, batch 1990, face loss 3.689611, head loss 3.299284, time 0.81052\r\nPass 0, batch 2000, face loss 2.499412, head loss 2.287693, time 0.81455\r\nPass 0, batch 2010, face loss 1.459440, head loss 1.841028, time 0.81367\r\nPass 0, batch 2020, face loss 2.988102, head loss 2.815126, time 0.83127\r\nPass 0, batch 2030, face loss 4.024381, head loss 3.740697, time 0.82407\r\nPass 0, batch 2040, face loss 3.497251, head loss 3.646049, time 0.80784\r\nPass 0, batch 2050, face loss 3.888634, head loss 3.634361, time 0.88443\r\nPass 0, batch 2060, face loss 4.123483, head loss 3.784822, time 0.81228\r\nPass 0, batch 2070, face loss 3.865510, head loss 3.366984, time 0.80212\r\nProcess Process-3:\r\nTraceback (most recent call last):\r\n  File \"/home/jyf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/home/jyf/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/jyf/anaconda3/lib/python3.6/site-packages/paddle/reader/decorator.py\", line 393, in _read_into_queue\r\n    for sample in reader():\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/reader.py\", line 267, in reader\r\n    image_path)\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/reader.py\", line 116, in preprocess\r\n    settings.min_face_size)\r\n  File \"/home/jyf/JYF/Pyramidbox/models/PaddleCV/face_detection/image_util.py\", line 424, in crop_image_sampling\r\n    sample_img = np.zeros((height, width, 3))\r\nMemoryError\r\nPass 0, batch 2080, face loss 4.575073, head loss 3.918978, time 1.04506\r\nPass 0, batch 2090, face loss 4.212999, head loss 3.976611, time 0.81284\r\nPass 0, batch 2100, face loss 4.210123, head loss 3.808105, time 0.80688\r\nPass 0, batch 2110, face loss 3.437980, head loss 2.679230, time 0.81080\r\nPass 0, batch 2120, face loss 2.723385, head loss 2.337259, time 0.80899\r\nPass 0, batch 2130, face loss 5.665165, head loss 5.790230, time 0.81662\r\nPass 0, batch 2140, face loss 5.166775, head loss 5.815830, time 0.81377\r\nPass 0, batch 2150, face loss 4.529456, head loss 4.198637, time 0.81539\r\nPass 0, batch 2160, face loss 1.446540, head loss 1.389654, time 0.85053\r\nPass 0, batch 2170, face loss 1.424659, head loss 1.341642, time 0.81604\r\n\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "jiayifang1",
        "closed_by": null,
        "created_at": "2019-06-04T11:15:04+00:00",
        "updated_at": "2019-06-25T11:48:14+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "jiayifang1",
            "jiayifang1",
            "qingqing01",
            "jiayifang1",
            "qingqing01",
            "jiayifang1",
            "qingqing01",
            "qingqing01",
            "jiayifang1",
            "jiayifang1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2367,
        "title": "AttributeError: module 'paddle.fluid.layers' has no attribute 'temporal_shift'",
        "body": "",
        "state": "closed",
        "user": "youidol",
        "closed_by": "youidol",
        "created_at": "2019-06-06T07:21:44+00:00",
        "updated_at": "2019-06-06T07:34:10+00:00",
        "closed_at": "2019-06-06T07:29:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2366,
        "title": "啥时候支持EfficientNet啊",
        "body": "如题，最近google新的分类模型出来，精确率提高好多。望早日有预训练模型出来",
        "state": "closed",
        "user": "JiaoZiLang",
        "closed_by": "shippingwang",
        "created_at": "2019-06-06T06:16:37+00:00",
        "updated_at": "2019-06-19T07:51:58+00:00",
        "closed_at": "2019-06-19T07:51:58+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "JiaXiao243",
            "lgone2000"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2376,
        "title": "cyclegan infer报错",
        "body": "在PaddleCV/gan目录下，执行bash scripts/infer_cyclegan.sh 对训练完成后的cycle_gan模型进行预测，报错信息如下\r\n1. 需要将infer_cyclegan.sh中的g_bash_dims修改为g_base_dims\r\n![image](https://user-images.githubusercontent.com/37854899/59179786-b3890480-8b95-11e9-9d1d-120b8370082a.png)\r\n2. 将infer_cyclegan.sh中的g_bash_dims修改为g_base_dims后，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59179886-006cdb00-8b96-11e9-8b6a-3452bbed8ee3.png)\r\n需要修改一下infer.py中cyclegan 预测部分的代码\r\n需要从CycleGAN_network中import CycleGAN_model类，而不是直接引入network_G、network_D函数\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-06-10T07:40:15+00:00",
        "updated_at": "2019-06-17T08:02:35+00:00",
        "closed_at": "2019-06-17T08:02:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2377,
        "title": "pretrained_model的问题（SE_RESNEXT）",
        "body": "",
        "state": "closed",
        "user": "XiaoheYou",
        "closed_by": "XiaoheYou",
        "created_at": "2019-06-10T07:50:42+00:00",
        "updated_at": "2019-06-10T08:54:47+00:00",
        "closed_at": "2019-06-10T08:54:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2374,
        "title": "[New Feature] 清除paddle控制设备占用存储",
        "body": "## 问题背景\r\n\r\n在类似AIStudio环境中，包括AIStudio，在启动Paddle程序，是对进程生命周期分配存储，导致第二次运行一个 jupyter code bock，内存未被释放。在某些情况下，我们只能重启Kernel来释放内存。\r\n\r\n## 复现场景\r\n\r\n```shell\r\nnvidia-smi\r\nnvidia-smi --gpu-reset -i 0 # https://devtalk.nvidia.com/default/topic/958159/cuda-programming-and-performance/11-gb-of-gpu-ram-used-and-no-process-listed-by-nvidia-smi/\r\n```\r\n\r\n```txt\r\nFri Jun  7 22:03:38 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  Off  | 00000000:00:07.0 Off |                    0 |\r\n| N/A   33C    P0    54W / 300W |  14912MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\nPCI device 00000000:00:08.0 must be reset with GPU 0 (00000000:00:07.0).\r\nOne or more incomplete sets of NVLink GPUs were specified.\r\nGPU Reset couldn't run because the specified GPUs could not be validated for NVLink reset.\r\n```\r\n\r\n我们发现 14/16 的内存被使用，但是找不到[process id](https://github.com/NVIDIA/nvidia-docker/issues/476)， 也不能在paddle中清除显存，只能手动重启Jupyter Kernel. \r\n\r\n## 问题对比\r\n\r\n1. 旧版本显存是针对进程生命周期分配的，在新版的Tensorflow 已经可以通过Gpu分配策略Tensorflow api释放gpu\r\n2. Colab从过往使用经验看，似乎没有类似问题\r\n\r\n## 可能解决方案和相关问题\r\n\r\n- 清除显存：https://stackoverflow.com/questions/39758094/clearing-tensorflow-gpu-memory-after-model-execution\r\n- 和NVIDIA驱动版本有关：https://github.com/tensorflow/tensorflow/issues/1727 \r\n- 使用多进程来解决： https://github.com/tensorflow/tensorflow/issues/17048\r\n- 使用numba.cuda: https://github.com/tensorflow/tensorflow/issues/17048\r\n- 使用Tensorflow gpu memory growth config: https://github.com/keras-team/keras/issues/12625\r\n\r\n",
        "state": "closed",
        "user": "yiakwy",
        "closed_by": "liupluswei",
        "created_at": "2019-06-07T14:31:51+00:00",
        "updated_at": "2019-07-03T12:54:50+00:00",
        "closed_at": "2019-07-03T12:54:50+00:00",
        "comments_count": [
            "liupluswei",
            "yiakwy",
            "liupluswei",
            "yiakwy",
            "liupluswei",
            "yiakwy",
            "liupluswei",
            "yiakwy",
            "liupluswei"
        ],
        "labels": [
            "user",
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2390,
        "title": "【dygraph resnet】 reader使用use_xmap=False参数时，reader性能会下降",
        "body": "use_xmap=False 时 reader 稳定后耗时在0.4s左右\r\n![image](https://user-images.githubusercontent.com/10734244/59320291-670e0800-8d00-11e9-840f-f3b9ed7b14c6.png)\r\n\r\nuse_xmap=True 时  reader稳定后耗时在0.001s左右\r\n![image](https://user-images.githubusercontent.com/10734244/59320943-d7b62400-8d02-11e9-9ab8-1fac455778e4.png)\r\n",
        "state": "open",
        "user": "DDDivano",
        "closed_by": null,
        "created_at": "2019-06-12T02:58:16+00:00",
        "updated_at": "2019-06-20T14:09:39+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2387,
        "title": "ParamAttr 设置trainable=False问题",
        "body": "我把一半以上的conv的ParamAttr 设置trainable=False进行finetuning，对训练效果和速率没有影响？",
        "state": "open",
        "user": "XiaoheYou",
        "closed_by": null,
        "created_at": "2019-06-11T10:25:47+00:00",
        "updated_at": "2019-06-13T06:35:41+00:00",
        "closed_at": null,
        "comments_count": [
            "luotao1",
            "XiaoheYou",
            "luotao1",
            "XiaoheYou",
            "XiaoheYou"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2382,
        "title": "resnet\\SEnet 训练出现loss Nan",
        "body": "版本、环境信息\r\n1）docker镜像 paddle:1.4.1-gpu-cuda9.0-cudnn7\r\n2）GPU Tesla V100 (16G显存)\r\n训练信息\r\n1）单机单卡训练\r\n2）batchsize=16\r\n3）图像resize448x448 (原图48*70)\r\n4）自定义数据集 8000样本,5大类\r\n**出现问题：**\r\nresnet 和SEnet 在训练自己的数据集时，正常训练几个batch便出现loss Nan ,acc变0。\r\n\r\n**详细细节**\r\n```\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 16\r\n               checkpoint : None\r\n                class_dim : 6\r\n                 data_dir : dataset\r\n                enable_ce : False\r\n                     fp16 : False\r\n              image_shape : 3,448,448\r\n                 l2_decay : 0.00012\r\n                       lr : 0.01\r\n              lr_strategy : cosine_decay\r\n                    model : SE_ResNeXt50_32x4d\r\n           model_save_dir : train_SE_ResNeXt50_32x4d_0610/export_models\r\n            momentum_rate : 0.9\r\n               num_epochs : 80\r\n         pretrained_model : SE_ResNeXt50_32x4d_pretrained\r\n               scale_loss : 1.0\r\n             total_images : 8557\r\n                  use_gpu : True\r\n             with_mem_opt : 1\r\n----------------------------------------------------\r\nPass 0, trainbatch 0, loss 1.49129,                         acc1 0.00000, acc5 0.62500, lr 0.01000, time 6.36 sec\r\nPass 0, trainbatch 10, loss 1.78435,                         acc1 0.31250, acc5 0.75000, lr 0.01000, time 0.59 sec\r\nPass 0, trainbatch 20, loss 1.04638,                         acc1 0.50000, acc5 0.87500, lr 0.01000, time 0.61 sec\r\nPass 0, trainbatch 30, loss 0.79907,                         acc1 0.43750, acc5 0.87500, lr 0.01000, time 0.60 sec\r\nPass 0, trainbatch 40, loss 1.52700,                         acc1 0.43750, acc5 0.93750, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 50, loss 1.00796,                         acc1 0.56250, acc5 0.87500, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 60, loss 0.65415,                         acc1 0.50000, acc5 0.81250, lr 0.01000, time 0.60 sec\r\nPass 0, trainbatch 70, loss 0.67213,                         acc1 0.56250, acc5 0.87500, lr 0.01000, time 0.60 sec\r\nPass 0, trainbatch 80, loss 1.23143,                         acc1 0.25000, acc5 0.68750, lr 0.01000, time 0.60 sec\r\nPass 0, trainbatch 90, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.65 sec\r\nPass 0, trainbatch 100, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 110, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.65 sec\r\nPass 0, trainbatch 120, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 130, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 140, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.65 sec\r\nPass 0, trainbatch 150, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 160, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 170, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 180, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 190, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.65 sec\r\nPass 0, trainbatch 200, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.71 sec\r\nPass 0, trainbatch 210, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.66 sec\r\nPass 0, trainbatch 220, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 230, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 240, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.66 sec\r\nPass 0, trainbatch 250, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.64 sec\r\nPass 0, trainbatch 260, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 270, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.63 sec\r\nPass 0, trainbatch 280, loss nan,                         acc1 0.00000, acc5 0.00000, lr 0.01000, time 0.65 sec\r\n```",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-06-10T12:06:54+00:00",
        "updated_at": "2019-09-20T03:23:55+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "ellinyang",
            "qingqing01",
            "CelineChen95"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2393,
        "title": "fix bug between py2 and py3 #2392",
        "body": "fix bug between py2 and py3 #2392 \r\nwhile caulclate x1 and y1, round will have different result between py2 and py3, which result in different inference output\r\n![image](https://user-images.githubusercontent.com/17508662/59333815-b584cc00-8d2b-11e9-816c-b8831aeea803.png)\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "cjt222",
        "closed_by": null,
        "created_at": "2019-06-12T08:02:57+00:00",
        "updated_at": "2019-06-18T14:13:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2399,
        "title": "cyclegan pix2pix 模型设置epoch<=100 训练报错",
        "body": "在PaddleCV/gan模型下，执行如下指令python train.py --model_net CycleGAN --dataset cityscapes --batch_size 1 --net_G resnet_9block --g_base_dim 32 --net_D basic --norm_type batch_norm --epoch 100 --load_size 286 --crop_size 256 --crop_type Random，对cyclegan进行训练，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/59410009-48843b80-8dea-11e9-8fab-e168f0d6e979.png)\r\n经过验证，在设置的epoch <=100的情况下进行训练，均报该错误，在epoch>100的情况下，可以正常训练。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-13T06:49:35+00:00",
        "updated_at": "2019-06-17T08:09:39+00:00",
        "closed_at": "2019-06-17T08:09:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2394,
        "title": "分布式训练 fluid.layers.embedding 设置 is_distributed=True 导致 Runtime error",
        "body": "使用 paddle 1.4.1 进行分布式训练,  fluid Embedding 接口设置 is_distributed=True 会导致 Runtime Error：\r\n\r\n    fluid.layers.embedding(is_sparse=True,` is_distributed=True）\r\n\r\nError 信息入下\r\n  File \"train_dist.py\", line 202, in <module>\r\n    train()\r\n  File \"train_dist.py\", line 151, in train\r\n    optimizer.minimize(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/incubate/fleet/parameter_server/distributed_transpiler/__init__.py\", line 283, in minimize\r\n    loss, startup_program, parameter_list, no_grad_set)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/optimizer.py\", line 510, in minimize\r\n    loss, startup_program=startup_program, params_grads=params_grads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/optimizer.py\", line 472, in apply_optimize\r\n    optimize_ops = self.apply_gradients(params_grads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/optimizer.py\", line 434, in apply_gradients\r\n    self._process_distribute_lookuptable(params_grads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/optimizer.py\", line 319, in _process_distribute_lookuptable\r\n    table_name = find_distributed_lookup_table(program)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/distribute_lookup_table.py\", line 73, in find_distributed_lookup_table\r\n    raise RuntimeError(\"all distributed lookup_table_ops\"\r\nRuntimeError: all distributed lookup_table_ops should have only one table\r\n\r\n",
        "state": "open",
        "user": "lzha106",
        "closed_by": null,
        "created_at": "2019-06-12T10:13:35+00:00",
        "updated_at": "2019-06-19T11:53:54+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus",
            "lzha106",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2395,
        "title": "kaldi-decoder",
        "body": "setip.sh cannot find kaldi decoder\r\n\r\n/home/hvir/models/models/PaddleSpeech/DeepASR/decoder/post_latgen_faster_mapped.so\r\n/usr/bin/ld: cannot find -lkaldi-decoder\r\ncollect2: error: ld returned 1 exit status",
        "state": "open",
        "user": "asdqweqq",
        "closed_by": null,
        "created_at": "2019-06-12T11:11:39+00:00",
        "updated_at": "2019-06-12T13:24:49+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "asdqweqq",
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2397,
        "title": "word2vec文档中数据解压少写了.gz",
        "body": "<img width=\"1008\" alt=\"90f5013aefaa06095922d1326b669d8b\" src=\"https://user-images.githubusercontent.com/46314656/59407717-bfb6d100-8de4-11e9-8017-6152f67db1a3.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "frankwhzhang",
        "created_at": "2019-06-13T06:09:12+00:00",
        "updated_at": "2019-06-13T06:51:40+00:00",
        "closed_at": "2019-06-13T06:51:39+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2400,
        "title": "文档错误 fast_imageNet",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification/fast_imagenet\r\nInstall the requirements by pip install -r requirement.txt.\r\n\r\n应该是\r\n\r\n```bash\r\npip install -r requirements.txt\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "sandyhouse",
        "created_at": "2019-06-13T07:40:07+00:00",
        "updated_at": "2019-06-15T16:40:06+00:00",
        "closed_at": "2019-06-15T16:40:06+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2402,
        "title": "fast_imagenet data_dir 不起作用",
        "body": "在train.py中 dataset_dir 路径写死了\r\n```bash\r\ndef prepare_reader(epoch_id, train_py_reader, train_bs, val_bs, trn_dir,\r\n                   img_dim, min_scale, rect_val):\r\n    train_reader = reader.train(\r\n        traindir=\"/data/imagenet/%strain\" % trn_dir,\r\n        sz=img_dim,\r\n        min_scale=min_scale,\r\n        shuffle_seed=epoch_id + 1)\r\n    train_py_reader.decorate_paddle_reader(\r\n        paddle.batch(\r\n            train_reader, batch_size=train_bs))\r\n\r\n    test_reader = reader.test(\r\n        valdir=\"/data/imagenet/%svalidation\" % trn_dir,\r\n        bs=val_bs * DEVICE_NUM,\r\n        sz=img_dim,\r\n        rect_val=rect_val)\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "sandyhouse",
        "created_at": "2019-06-13T07:49:55+00:00",
        "updated_at": "2019-06-15T16:38:36+00:00",
        "closed_at": "2019-06-15T16:38:36+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2404,
        "title": "Non-local模型的参数不能下载",
        "body": "Non-local模型的参数下载链接为空",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "shippingwang",
        "created_at": "2019-06-13T13:08:56+00:00",
        "updated_at": "2019-07-10T13:34:58+00:00",
        "closed_at": "2019-07-10T13:34:58+00:00",
        "comments_count": [
            "gongweibao",
            "cjt222",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2414,
        "title": "PaddleNLP/neural_machine_translation/transformer/infer.py报错",
        "body": "PaddleNLP/neural_machine_translation/transformer/infer.py报错，请问是什么原因，谢谢？\r\n```\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nW0614 19:29:48.624078 50964 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0614 19:29:48.762323 50964 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\nW0614 19:29:48.762387 50964 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\n*** Aborted at 1560511794 (unix time) try \"date -d @1560511794\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x38) received by PID 50964 (TID 0x7fd56a55c740) from PID 56; stack trace: ***\r\n    @     0x7fd56a3216d0 (unknown)\r\n    @     0x7fd56a539d56 _dl_relocate_object\r\n    @     0x7fd56a5427ac dl_open_worker\r\n    @     0x7fd56a53d914 _dl_catch_error\r\n    @     0x7fd56a541ccb _dl_open\r\n    @     0x7fd569979082 do_dlopen\r\n    @     0x7fd56a53d914 _dl_catch_error\r\n    @     0x7fd569979142 __GI___libc_dlopen_mode\r\n    @     0x7fd569950b45 init\r\n    @     0x7fd56a31ee70 __GI___pthread_once\r\n    @     0x7fd569950c5c __GI___backtrace\r\n    @     0x7fd537168b68 paddle::platform::EnforceNotMet::Init<>()\r\n    @     0x7fd537168eb7 paddle::platform::EnforceNotMet::EnforceNotMet()\r\n    @     0x7fd538eb3a86 paddle::platform::GpuMaxChunkSize()\r\n    @     0x7fd538e88422 _ZSt16__once_call_implISt12_Bind_simpleIFZN6paddle6memory6legacy20GetGPUBuddyAllocatorEiEUlvE_vEEEvv\r\n    @     0x7fd56a31ee70 __GI___pthread_once\r\n    @     0x7fd538e87acd paddle::memory::legacy::GetGPUBuddyAllocator()\r\n    @     0x7fd538e888f3 paddle::memory::legacy::Alloc<>()\r\n    @     0x7fd538e88d35 paddle::memory::allocation::LegacyAllocator::AllocateImpl()\r\n    @     0x7fd538eadfeb paddle::memory::allocation::Allocator::Allocate()\r\n    @     0x7fd538e7c933 paddle::memory::allocation::AllocatorFacade::Alloc()\r\n    @     0x7fd538e7ca51 paddle::memory::allocation::AllocatorFacade::AllocShared()\r\n    @     0x7fd538aba920 paddle::memory::AllocShared()\r\n    @     0x7fd538e4ecea paddle::framework::Tensor::mutable_data()\r\n    @     0x7fd537e27451 paddle::operators::FillConstantKernel<>::Compute()\r\n    @     0x7fd537e2a5f3 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EJNS0_9operators18FillConstantKernelIfEENSA_IdEENSA_IlEENSA_IiEENSA_INS7_7float16EEEEEclEPKcSJ_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\n    @     0x7fd538dfa6f6 paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7fd538dfae64 paddle::framework::OperatorWithKernel::RunImpl()\r\n    @     0x7fd538df878c paddle::framework::OperatorBase::Run()\r\n    @     0x7fd5372dd8be paddle::framework::Executor::RunPreparedContext()\r\n    @     0x7fd5372de6ff paddle::framework::Executor::Run()\r\n    @     0x7fd53715835e _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE97_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\nSegmentation fault (core dumped)\r\n```",
        "state": "open",
        "user": "yuzunrui",
        "closed_by": null,
        "created_at": "2019-06-14T11:41:15+00:00",
        "updated_at": "2019-06-21T08:55:44+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "yuzunrui",
            "yuzunrui",
            "guoshengCS",
            "yuzunrui",
            "yuzunrui",
            "guoshengCS",
            "yuzunrui",
            "yuzunrui",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2431,
        "title": "SE154_vd python3上eval报错",
        "body": "1.  SE154_vd python3上eval报错\r\n在python3.7环境下，PaddleCV/image_classification目录中下载SE154_vd_pretrained预训练模型，执行指令python eval.py --model SE154_vd --pretrained_model SE154_vd_pretrained --batch_size 25，对该模型进行评估，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59656627-c3759980-91d0-11e9-89c7-f4f9fb47b08a.png)\r\n在python2.7环境中，通过修改models/se_reasnext_vd文件，目前在本地可以跑起来；\r\n2. renset200_vd 预训练模型链接错误\r\n renset200_vd预训练模型链接是renset152_vd，需要修改一下。\r\n![image](https://user-images.githubusercontent.com/37854899/59656714-09caf880-91d1-11e9-886a-00f4deb291fc.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-18T05:58:30+00:00",
        "updated_at": "2019-06-18T06:00:40+00:00",
        "closed_at": "2019-06-18T06:00:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2418,
        "title": "resnet_vd模型eval报错",
        "body": "在PaddleCV/image_classification目录下执行python eval.py --model=ResNet101_vd --pretrained_model=./ResNet101_vd_pretrained指令，对下载的预训练模型ResNet101_vd进行评估，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59574871-87b4d400-90eb-11e9-99aa-ccec8639dcb6.png)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-06-17T02:34:20+00:00",
        "updated_at": "2019-06-19T07:50:45+00:00",
        "closed_at": "2019-06-19T07:50:44+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2422,
        "title": "window10运行object_detection报错",
        "body": "环境：win10+python3.7\r\nobject_detection和face_detection都存在这个错误。哪位朋友帮帮忙，无论是使用推荐数据还是自己的图片数据都报错\r\n\r\n\r\n\r\n参数配置：\r\nadd_arg('learning_rate',    float, 0.001,     \"Learning rate.\")\r\nadd_arg('batch_size',       int,   64,        \"Minibatch size of all devices.\")\r\nadd_arg('epoc_num',         int,   120,       \"Epoch number.\")\r\nadd_arg('use_gpu',          bool,  False,      \"Whether use GPU.\")\r\nadd_arg('parallel',         bool,  False,      \"Whether train in parallel on multi-devices.\")\r\nadd_arg('dataset',          str,   'pascalvoc', \"dataset can be coco2014, coco2017, and pascalvoc.\")\r\nadd_arg('model_save_dir',   str,   'model',     \"The path to save model.\")\r\nadd_arg('pretrained_model', str,   'pretrained/ssd_mobilenet_v1_coco/', \"The init model path.\")\r\nadd_arg('ap_version',       str,   '11point',           \"mAP version can be integral or 11point.\")\r\nadd_arg('image_shape',      str,   '3,300,300',         \"Input image shape.\")\r\nadd_arg('mean_BGR',         str,   '127.5,127.5,127.5', \"Mean value for B,G,R channel which will be subtracted.\")\r\nadd_arg('data_dir',         str,   'data/pascalvoc', \"Data directory.\")\r\nadd_arg('enable_ce',        bool,  True, \"Whether use CE to evaluate the model.\")\r\n\r\n\r\n报错log:\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"G:\\Python36\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"G:\\Python36\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"G:\\Python36\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 585, in __provider_thread__\r\n    raise ex\r\n  File \"G:\\Python36\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 567, in __provider_thread__\r\n    for tensors in func():\r\n  File \"G:\\Python36\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 617, in __tensor_provider__\r\n    for slots in paddle_reader():\r\n  File \"G:\\Python36\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 326, in __reader_creator__\r\n    for item in reader():\r\n  File \"G:\\Python36\\lib\\site-packages\\paddle\\reader\\decorator.py\", line 404, in queue_reader\r\n    p.start()\r\n  File \"G:\\Python36\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"G:\\Python36\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"G:\\Python36\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"G:\\Python36\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n  File \"G:\\Python36\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object 'multiprocess_reader.<locals>._read_into_queue'\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"G:\\Python36\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"G:\\Python36\\lib\\multiprocessing\\spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nEOFError: Ran out of input",
        "state": "closed",
        "user": "yanggb",
        "closed_by": "yanggb",
        "created_at": "2019-06-17T07:19:13+00:00",
        "updated_at": "2019-06-19T05:53:23+00:00",
        "closed_at": "2019-06-19T05:53:22+00:00",
        "comments_count": [
            "kolinwei",
            "JiaXiao243",
            "yanggb",
            "wopeizl",
            "yanggb"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2432,
        "title": "SE154_vd模型在 python3上eval报错",
        "body": "1.  SE154_vd python3上eval报错\r\n在python3.7环境下，PaddleCV/image_classification目录中下载SE154_vd_pretrained预训练模型，执行指令python eval.py --model SE154_vd --pretrained_model SE154_vd_pretrained --batch_size 25，对该模型进行评估，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59656627-c3759980-91d0-11e9-89c7-f4f9fb47b08a.png)\r\n在python2.7环境中，通过修改models/se_reasnext_vd文件，目前在本地可以跑起来；\r\n2. renset200_vd 预训练模型链接错误\r\n renset200_vd预训练模型链接是renset152_vd，需要修改一下。\r\n![image](https://user-images.githubusercontent.com/37854899/59656714-09caf880-91d1-11e9-886a-00f4deb291fc.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-06-18T05:59:24+00:00",
        "updated_at": "2019-06-19T07:57:35+00:00",
        "closed_at": "2019-06-19T07:57:35+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2433,
        "title": "PaddleNLP/neural_machine_translation/transformer/train.py读取的数据产生了空的",
        "body": "PaddleNLP/neural_machine_translation/transformer/train.py 第375行，在读取数据后，对于某些batch_id，data为空[ ]，请问原因是什么？谢谢\r\n（所用数据集中无空白行，调整batch_size和pool_size解决不了）\r\n\r\n```python\r\ndef py_reader_provider():\r\n        data_input_names = encoder_data_input_fields + \\\r\n                    decoder_data_input_fields[:-1] + label_data_input_fields\r\n        for batch_id, data in enumerate(data_reader()):\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/328693/59658103-4698ee80-91d5-11e9-8ec6-b3bf068b39ab.png)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/328693/59658110-48fb4880-91d5-11e9-93d2-a21b9df9d155.png)\r\n",
        "state": "open",
        "user": "yuzunrui",
        "closed_by": null,
        "created_at": "2019-06-18T06:19:09+00:00",
        "updated_at": "2019-06-18T06:29:39+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2450,
        "title": "Topk在动图中使用出现显存溢出问题。",
        "body": "paddle的动图用topk在模型中，结果出现了显存溢出。实在没有办法重新学习pytorch，在pytorch中同样的模型结构用topk就能够正常跑程序。\r\n\r\n另外：另外，paddle中的gather（input,index），index的rank=1，只能指定最外层的维度条目。跟pytorch中的ganther区别很大，功能已经被阉割了。希望能够将改函数的功能做成同pytorch中的一样。",
        "state": "open",
        "user": "qianledan",
        "closed_by": null,
        "created_at": "2019-06-19T11:39:20+00:00",
        "updated_at": "2019-06-20T14:02:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2441,
        "title": "最新版本yolov3单卡时报错",
        "body": "[22:53:26]W:\t [Step 3/3]   File \"train.py\", line 170, in <module>\r\n[22:53:26]W:\t [Step 3/3]     train()\r\n[22:53:26]W:\t [Step 3/3] C++ Callstacks: \r\n[22:53:26]W:\t [Step 3/3] invalid argument at [/workspace/paddle/fluid/operators/sync_batch_norm_op.cu:183]\r\n[22:53:26]W:\t [Step 3/3] PaddlePaddle Call Stacks: \r\n[22:53:26]W:\t [Step 3/3] 0       0x7f94ac7b1d50p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n[22:53:26]W:\t [Step 3/3] 1       0x7f94ac7b20c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n[22:53:26]W:\t [Step 3/3] 2       0x7f94aca0ecd0p paddle::operators::SyncBatchNormKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 5328\r\n[22:53:26]W:\t [Step 3/3] 3       0x7f94aca0ef43p _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EINS0_9operators19SyncBatchNormKernelINS7_17CUDADeviceContextEfEENSA_ISB_dEEEEclEPKcSG_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_ + 35\r\n[22:53:26]W:\t [Step 3/3] 4       0x7f94ae701027p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n[22:53:26]W:\t [Step 3/3] 5       0x7f94ae701401p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n[22:53:26]W:\t [Step 3/3] 6       0x7f94ae6fe9fcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n[22:53:26]W:\t [Step 3/3] 7       0x7f94ae4fbc5ap paddle::framework::details::ComputationOpHandle::RunImpl() + 250",
        "state": "closed",
        "user": "kolinwei",
        "closed_by": "heavengate",
        "created_at": "2019-06-19T02:49:28+00:00",
        "updated_at": "2019-06-21T02:31:50+00:00",
        "closed_at": "2019-06-21T02:31:50+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2439,
        "title": "YOLO v3 在CPU上只能跑1-2FPS吗？",
        "body": "我在CPU上读取视频，然后逐帧检测，输出的检测速度如下：\r\n\r\n**time: 1.53290700912\r\ntime: 1.17780613899\r\ntime: 1.15770196915\r\ntime: 1.2086918354\r\ntime: 1.1830239296\r\ntime: 1.1952021122\r\ntime: 1.20584702492\r\ntime: 1.1504240036\r\ntime: 1.17087602615\r\ntime: 1.16614413261\r\ntime: 1.1538939476**\r\n\r\n这是正常的吗  input_size=320 当input_size设置为608的时候，已经需要两秒了\r\n\r\ncpu信息：Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz\r\n\r\n有没有什么提速的建议？  因为设备限制，我只能在cpu上跑",
        "state": "open",
        "user": "weidom",
        "closed_by": null,
        "created_at": "2019-06-19T02:13:14+00:00",
        "updated_at": "2019-06-25T06:01:11+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn",
            "weidom"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2440,
        "title": "ResNet50_vc模型 infer报错",
        "body": "在PadleCV/image_classification目录下，下载并解压ResNet50_vc_pretrained预训练模型，执行指令python infer.py --model ResNet50_vc --pretrained_model ResNet50_vc_pretrained对该模型进行训练，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/59732191-dabd9100-927b-11e9-8ea1-b14b8de93601.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "shippingwang",
        "created_at": "2019-06-19T02:20:43+00:00",
        "updated_at": "2019-06-19T07:50:02+00:00",
        "closed_at": "2019-06-19T07:50:01+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2455,
        "title": "There is a small error in face_detection reader",
        "body": "https://github.com/PaddlePaddle/models/blob/55138a40a219975bcbbeb6c1edef5284de721f72/PaddleCV/face_detection/reader.py#L312\r\n\r\nthe code should be \r\n```\r\n img = img.convert('RGB')\r\n```\r\n",
        "state": "closed",
        "user": "lytk01",
        "closed_by": "qingqing01",
        "created_at": "2019-06-19T22:37:52+00:00",
        "updated_at": "2019-06-24T10:45:52+00:00",
        "closed_at": "2019-06-24T10:45:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2457,
        "title": "transformer在python3上训练报错",
        "body": "1. python3环境下，paddle==1.5，在PaddleNLP/unarchived/neural_machine_translation/transformer目录下执行训练命令:python -u train.py --src_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000 --trg_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000 --train_file_pattern wmt16_ende_data_bpe_clean/train.tok.clean.bpe.32000.en-de，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59815473-41f64680-934b-11e9-94a2-fec68be569f4.png)\r\n在python2.7上可以正常训练。\r\n2. 使用文档中安装文档链接失效\r\n![image](https://user-images.githubusercontent.com/37854899/59816243-fabd8500-934d-11e9-805d-16a71186f0a3.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-20T03:01:39+00:00",
        "updated_at": "2019-06-24T12:41:46+00:00",
        "closed_at": "2019-06-24T12:41:46+00:00",
        "comments_count": [
            "phlrain",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2458,
        "title": "视频库中NONLOCAL模型CPU infer时得到概率全为0，GPU正常",
        "body": "视频库中NONLOCAL模型CPU infer时得到概率全为0，GPU正常，貌似是某个op cpu实现的问题\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/nonlocal_model/README.md",
        "state": "open",
        "user": "cjt222",
        "closed_by": null,
        "created_at": "2019-06-20T03:29:32+00:00",
        "updated_at": "2019-06-21T03:52:55+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2461,
        "title": "动态图多卡训练reader报错",
        "body": "相关pr  https://github.com/PaddlePaddle/models/pull/2416\r\n![image](https://user-images.githubusercontent.com/10734244/59829595-61539a80-9370-11e9-9ecd-9a06a1901c86.png)\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "DDDivano",
        "created_at": "2019-06-20T07:31:58+00:00",
        "updated_at": "2019-06-20T07:33:25+00:00",
        "closed_at": "2019-06-20T07:33:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2459,
        "title": "fluid 如何无损重启训练？",
        "body": "通过paddle.fluid.io.load_persistables 方法虽然可以加载模型权重等参数，但是如step信息重启后已经发生变化，学习率计算又有重新从0开始，怎样无损resume?\r\n",
        "state": "open",
        "user": "youngstu",
        "closed_by": null,
        "created_at": "2019-06-20T06:37:53+00:00",
        "updated_at": "2019-06-21T02:24:31+00:00",
        "closed_at": null,
        "comments_count": [
            "youngstu",
            "youngstu",
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2460,
        "title": "fluid 怎样打印模型网络结构？",
        "body": "fluid 是否支持打印model，如pytorch？",
        "state": "open",
        "user": "youngstu",
        "closed_by": null,
        "created_at": "2019-06-20T06:59:17+00:00",
        "updated_at": "2019-06-21T02:30:20+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain",
            "youngstu",
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2462,
        "title": "DeepASR中的AI-shell_testdata_test.scp_wav_00000.compact.label和AI-shell_testdata_test.scp_wav_00000.compact.label_desc文件是怎么生成的，请问有脚本吗",
        "body": "",
        "state": "open",
        "user": "Maxhyl",
        "closed_by": null,
        "created_at": "2019-06-20T08:02:13+00:00",
        "updated_at": "2019-06-21T03:50:28+00:00",
        "closed_at": null,
        "comments_count": [
            "Maxhyl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2463,
        "title": "object_detection迁移android时模型保存问题",
        "body": "**PaddleCV/object_detection项目**\r\n保存模型原本用的如下方法：\r\nfluid.io.**save_persistables**(exe, model_path, main_program=main_prog)\r\n但是迁移到android需要使用如下方法保存model:\r\nfluid.io.**save_inference_model**()\r\n\r\n问题是不是很清楚feeded_var_names和target_vars这2个参数怎么使用，麻烦哪位朋友指点下\r\nfluid.io.save_inference_model(dirname=model_path,\r\n                                      feeded_var_names=[\"feed\"],\r\n                                      target_vars=[],\r\n                                      executor=exe,\r\n                                      main_program=main_prog)\r\n\r\n多谢！多谢！多谢！\r\n",
        "state": "closed",
        "user": "yanggb",
        "closed_by": "yanggb",
        "created_at": "2019-06-20T08:03:49+00:00",
        "updated_at": "2019-06-20T10:22:16+00:00",
        "closed_at": "2019-06-20T10:22:16+00:00",
        "comments_count": [
            "yanggb",
            "yanggb"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2465,
        "title": "ctr训练报错",
        "body": "在paddle1.5分支下，ctr训练有如下报错：\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 262, in <module>\r\n    train()\r\n  File \"train.py\", line 232, in train\r\n    train_loop(args, main_program, py_reader, loss, auc_var, batch_auc_var, 1, 0)\r\n  File \"train.py\", line 155, in train_loop\r\n    exec_strategy=exec_strategy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 175, in __init__\r\n    self._compiled_program._compile(place=self._place, scope=self._scope)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/compiler.py\", line 366, in _compile\r\n    scope=self._scope)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/compiler.py\", line 337, in _compile_data_parallel\r\n    self._exec_strategy, self._build_strategy, self._graph)\r\npaddle.fluid.core_avx.EnforceNotMet: If you set build_strategy.reduce with 'Reduce',the number of places must be greater than 1. at [/ssd1/xiege/paddle_ce/Paddle/paddle/fluid/framework/parallel_executor.cc:325]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-06-20T09:19:52+00:00",
        "updated_at": "2019-06-27T13:26:24+00:00",
        "closed_at": "2019-06-27T13:26:24+00:00",
        "comments_count": [
            "jacquesqiao",
            "kolinwei",
            "xiegegege"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2466,
        "title": "lstm语言模型输出的ppl为nan",
        "body": "在PaddleNLP/language_model目录下执行python train.py  --data_path data/simple-examples/data/ --model_type small --use_gpu True指令对lstm模型进行训练，输出信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/59837603-16418380-9380-11e9-9c6d-dd7de6d94fd3.png)\r\n在windows和linux下，该模型均有该问题。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-20T09:24:32+00:00",
        "updated_at": "2019-06-26T03:19:01+00:00",
        "closed_at": "2019-06-26T03:19:01+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2467,
        "title": "deeplabv3+ eval 报维度错误",
        "body": "在paddle1.5分支下，deeplabv3+ 的评估有如下报错：\r\nTraceback (most recent call last):\r\n  File \"./eval.py\", line 131, in <module>\r\n    fetch_list=[pred, miou, out_wrong, out_correct])\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator bilinear_interp error.\r\nPython Callstacks:\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1699, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 7637, in image_resize\r\n    attrs=attrs)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 7742, in resize_bilinear\r\n    align_corners, align_mode)\r\n  File \"./eval.py\", line 84, in <module>\r\n    img = fluid.layers.resize_bilinear(img, image_shape)\r\nC++ Callstacks:\r\nEnforce failed. Expected dim_x.size() == 4, but received dim_x.size():3 != 4:4.\r\nX's dimension must be 4 at [/ssd1/xiege/paddle_ce/Paddle/paddle/fluid/operators/interpolate_op.cc:40]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-06-20T09:29:17+00:00",
        "updated_at": "2019-06-21T10:38:53+00:00",
        "closed_at": "2019-06-21T10:38:53+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2470,
        "title": "resnet 单卡下没问题，八卡报错",
        "body": "paddle_version :1.5.0\r\n运行命令：\r\n```bash\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u train.py --model=ResNet101 --batch_size=256 --total_images=1281167 --class_dim=1000 --image_shape=3,224,224 --model_save_dir=output/ --pretrained_model=SE_ResNext50_32x4d_pretrained/ --data_dir=data/ILSVRC2012 --with_mem_opt=False --with_inplace=True --lr_strategy=cosine_decay --lr=0.1 --l2_decay=1.2e-4 --num_epochs=2\r\n```\r\n报错如下：\r\n```bash\r\nI0620 05:24:42.159507 21796 build_strategy.cc:285] SeqOnlyAllReduceOps:0, num_trainers:1\r\nPass 0, trainbatch 0, loss 7.05474,                         acc1 0.00000, acc5 0.00391, lr 0.10000, time 12.15 sec\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 498, in <module>\r\n    main()\r\n  File \"train.py\", line 494, in main\r\n    train(args)\r\n  File \"train.py\", line 393, in train\r\n    fetch_list=train_fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py\", line 205, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 580, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 446, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected infer_next_address == next_address, but received infer_next_address:0x1011e520240 != next_address:0x1011e520a40.\r\nThe address is not consistent. at [/paddle/paddle/fluid/framework/details/fused_all_reduce_op_handle.cc:142]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fd2cc104b68p void paddle:  :platform::EnforceNotMet::Init<std:  :string>(std:  :string, char const*, int) + 360\r\n1       0x7fd2cc104eb7p paddle:  :platform::EnforceNotMet::EnforceNotMet(std:  :string const&, char const*, int) + 87\r\n2       0x7fd2cdb63327p paddle::framework::details::FusedAllReduceOpHandle::RunImpl() + 4567\r\n3       0x7fd2cdb960e0p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n4       0x7fd2cdafd7adp\r\n5       0x7fd2cce70df3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "shippingwang",
        "created_at": "2019-06-20T12:28:10+00:00",
        "updated_at": "2019-06-21T09:14:50+00:00",
        "closed_at": "2019-06-21T09:14:49+00:00",
        "comments_count": [
            "xiegegege",
            "kolinwei",
            "shippingwang"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2468,
        "title": "transformer infer报错 ",
        "body": "在PaddleNLP/unarchived/neural_machine_translation/transformer目录下执行python -u infer.py  --src_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000 --trg_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000 --test_file_pattern wmt16_ende_data_bpe_clean/newstest2016.tok.bpe.32000.en-de model_path trained_models/iter_30000.infer.model指令，对训练的模型进行预测，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59839061-a1237d80-9382-11e9-8b51-0441cec6efb8.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-20T09:41:40+00:00",
        "updated_at": "2019-06-25T09:10:57+00:00",
        "closed_at": "2019-06-25T09:10:57+00:00",
        "comments_count": [
            "guoshengCS",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2479,
        "title": "电视台标识别，用哪个模型比较好？",
        "body": "用 faster-rcnn 来做效果会不会，单纯只用图片分类来作要好一些？",
        "state": "closed",
        "user": "JiaoZiLang",
        "closed_by": "JiaoZiLang",
        "created_at": "2019-06-21T06:43:12+00:00",
        "updated_at": "2019-07-05T08:27:29+00:00",
        "closed_at": "2019-07-05T08:27:29+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2480,
        "title": "machine reading comprehension多GPU下报错",
        "body": "![image](https://user-images.githubusercontent.com/10734244/59903982-f9b35300-9434-11e9-9bf0-0fb11bf8bfd0.png)\r\n",
        "state": "closed",
        "user": "DDDivano",
        "closed_by": "xyzhou-puck",
        "created_at": "2019-06-21T06:58:36+00:00",
        "updated_at": "2019-06-24T12:31:22+00:00",
        "closed_at": "2019-06-24T12:31:22+00:00",
        "comments_count": [
            "xyzhou-puck",
            "xyzhou-puck"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2486,
        "title": "dialogue_general_understanding --use_fp16 true 训练报错",
        "body": "在PaddleNLP/dialogue_model_toolkit/dialogue_general_understanding目录下，执行python -u train.py --task_name mrda --use_cuda true --do_train true --do_val true --do_test true --epoch 1 --batch_size 4096 --data_dir ./data/mrda  --bert_config_path ./uncased_L-12_H-768_A-12/bert_config.json --vocab_path ./uncased_L-12_H-768_A-12/vocab.txt --init_pretraining_params ./uncased_L-12_H-768_A-12/params --checkpoints ./output/mrda --save_steps 200 --learning_rate 2e-5 --weight_decay 0.01 --max_seq_len 128 --skip_steps 100 --validation_steps 500 --num_iteration_per_drop_scope 10 --use_fp16 true，对该模型进行训练，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/59920170-42cacd80-945c-11e9-91d9-eaa8806a0f2a.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "kuke",
        "created_at": "2019-06-21T11:39:31+00:00",
        "updated_at": "2019-06-24T07:07:09+00:00",
        "closed_at": "2019-06-24T07:07:09+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2481,
        "title": "图像分类dpn模型8卡运行报错",
        "body": "在paddle1.5分支下，图像分类dpn模型8卡运行报错，报错信息如下：\r\n\r\n Traceback (most recent call last):\r\n  File \"train.py\", line 588, in <module>\r\n    main()\r\n  File \"train.py\", line 584, in main\r\n    train(args)\r\n  File \"train.py\", line 469, in train\r\n    loss, acc1, acc5, lr = train_exe.run(fetch_list=train_fetch_list)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 280, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 665, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Enforce failed. Expected infer_next_address == next_address, but received infer_next_address:0x10126df9040 != next_address:0x1012bc4de40.\r\nThe address is not consistent. at [/ssd1/xiege/paddle_ce/Paddle/paddle/fluid/framework/details/fused_all_reduce_op_handle.cc:135]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "shippingwang",
        "created_at": "2019-06-21T09:01:16+00:00",
        "updated_at": "2019-06-21T09:13:31+00:00",
        "closed_at": "2019-06-21T09:13:31+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2483,
        "title": "window上deep_attention_matching训练报错",
        "body": "在window机器上，PaddleNLP/dialogue_model_toolkit/deep_attention_matching目录下，执行\r\npython -u main.py --do_train True --use_cuda --data_path ./data/ubuntu/data_small.pkl --save_path ./model_files/ubuntu  --use_pyreader --vocab_size 434512 --_EOS_ 28270  --batch_size 32对模型进行训练，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/59914242-8fa6a800-944c-11e9-8eaa-b9d8c7903619.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "wopeizl",
        "created_at": "2019-06-21T09:47:07+00:00",
        "updated_at": "2019-07-30T02:30:32+00:00",
        "closed_at": "2019-07-30T02:30:32+00:00",
        "comments_count": [
            "wopeizl"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2498,
        "title": "attgan训练报错",
        "body": "paddle==1.5, 在PaddleCV/gan目录下运行 bash script/run_attgan.sh报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59990138-9fa0d080-9674-11e9-80f6-8349b78b0f48.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "kolinwei",
        "created_at": "2019-06-24T03:38:58+00:00",
        "updated_at": "2019-06-24T08:55:48+00:00",
        "closed_at": "2019-06-24T08:55:48+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2487,
        "title": "ELMo模型训练报错",
        "body": "在LARK/ELMo目录下执行sh run.sh对ELMo模型进行训练，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59920652-cafda280-945d-11e9-95d0-23267f03bf0f.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JesseyXujin",
        "created_at": "2019-06-21T11:50:28+00:00",
        "updated_at": "2019-06-24T06:05:41+00:00",
        "closed_at": "2019-06-24T06:05:41+00:00",
        "comments_count": [
            "JesseyXujin",
            "JiaXiao243",
            "JesseyXujin",
            "JesseyXujin",
            "JesseyXujin",
            "JesseyXujin"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2504,
        "title": "window上metric_learning模型进行eval报MemoryError",
        "body": "在window机器上，paddle==1.5，在\\PaddleCV\\metric_learning，执行python eval.py --model=ResNet50 --batch_size=16 --pretrained_model=output，对模型进行eval，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/59996991-50679980-968e-11e9-9bfd-56de39349963.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-06-24T06:40:25+00:00",
        "updated_at": "2019-07-03T06:58:29+00:00",
        "closed_at": null,
        "comments_count": [
            "wopeizl",
            "jiayifang1"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2505,
        "title": "运行自动Killed",
        "body": "Killed\r\nrun.sh --total_images=4493: not found\r\nimage_classification\r\n\r\n\r\n#Example: SE_ResNext50_32x4d\r\npython train.py \\\r\n       --model=SE_ResNeXt50_32x4d \\\r\n       --batch_size=400 \\\r\n       --total_images=4493 \\\r\n       --class_dim=61 \\\r\n       --image_shape=3,224,224 \\\r\n       --model_save_dir=output/ \\\r\n       --with_mem_opt=True \\\r\n       --lr_strategy=cosine_decay \\\r\n       --lr=0.1 \\\r\n       --num_epochs=200 \\\r\n       --l2_decay=1.2e-4 \\\r\n#      >log_SE_ResNeXt50_32x4d.txt 2>&1 &\r\n",
        "state": "closed",
        "user": "huillll",
        "closed_by": "JiabinYang",
        "created_at": "2019-06-24T06:46:44+00:00",
        "updated_at": "2019-10-10T05:18:45+00:00",
        "closed_at": "2019-10-10T05:18:45+00:00",
        "comments_count": [
            "huillll",
            "JiabinYang",
            "huillll",
            "huillll",
            "JiabinYang",
            "huillll",
            "huillll",
            "huillll",
            "huillll",
            "huillll",
            "huxiaoman7",
            "JiabinYang",
            "huillll",
            "JiabinYang",
            "huillll",
            "huillll",
            "huillll",
            "huillll",
            "JiabinYang",
            "huillll",
            "huillll",
            "huillll",
            "huillll",
            "heavengate",
            "huillll",
            "heavengate",
            "huillll",
            "heavengate",
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2509,
        "title": "depthwise conv 5x5的conv GPU和CPU的结果不一致",
        "body": "depthwise conv 5x5的conv GPU和CPU的结果不一致，希望赶紧修一下～",
        "state": "open",
        "user": "cuicheng01",
        "closed_by": null,
        "created_at": "2019-06-24T07:50:57+00:00",
        "updated_at": "2019-06-24T13:18:58+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2511,
        "title": "window上image_classification训练报错",
        "body": "在window机器上，paddle==1.5, 在PaddleCV\\image_classification目录，执行python train.py --model=AlexNet --num_epochs=1  --batch_size 4，对AlexNet模型进行训练，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/60001944-3764e580-969a-11e9-822c-0e4bfa8f4487.png)\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-06-24T08:03:55+00:00",
        "updated_at": "2019-07-18T09:34:36+00:00",
        "closed_at": "2019-07-18T09:34:36+00:00",
        "comments_count": [
            "wopeizl",
            "kolinwei",
            "cuicheng01",
            "qingqing01",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2519,
        "title": "如何加快reader速度？",
        "body": "![image](https://user-images.githubusercontent.com/5461637/60015046-1067dd00-96b5-11e9-8aa0-33de133b2b6a.png)\r\n在50g数据下\r\nmodels/PaddleNLP/neural_machine_translation/transformer/\r\n这步读取数据非常慢",
        "state": "open",
        "user": "yxzero",
        "closed_by": null,
        "created_at": "2019-06-24T11:21:24+00:00",
        "updated_at": "2019-06-25T04:07:15+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang",
            "sneaxiy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2523,
        "title": "图像分类InceptionV4偶尔会报illegal memory access",
        "body": "在paddle1.5分支下，图像分类InceptionV4偶尔会报illegal memory access，截图如下：\r\nPass 0, trainbatch 470, loss 6.65145,                             acc1 0.00391, acc5 0.01953, lr 0.10000, time 0.47 sec\r\nF0624 09:12:36.741020 50191 device_context.cc:333] cudaStreamSynchronize an illegal memory access was encountered errno:77\r\n*** Check failure stack trace: ***\r\nF0624 09:1F:36.74102662  50194    9:device_context.cc:127336cudaStreamSynchronize .741029egal memory access was encountered errno:7750180 all_reduce_op_handle.cc:73] cudaStreamSynchronize an illegal memory access was encountered\r\n*** Check failure stack trace: ***\r\nF0624 09:1F:36.74102662  50194    9:device_context.cc:127336cudaStreamSynchronize .741029egal memory access was encountered errno:7750180 all_reduce_op_handle.cc:73] cudaStreamSynchronize an illegal memory access was encountered\r\n*** Check failure stack trace: ***\r\n    @     0x7f7a737c777d  google::LogMessage::Fail()\r\n    @     0x7f7a737c777d  google::LogMessage::Fail()\r\n    @     0x7f7a737c777d  google::LogMessage::Fail()\r\n    @     0x7f7a737cb22c  google::LogMessage::SendToLog()\r\n    @     0x7f7a737cb22c  google::LogMessage::SendToLog()\r\n    @     0x7f7a737cb22c  google::LogMessage::SendToLog()\r\n    @     0x7f7a737c72a3  google::LogMessage::Flush()\r\n    @     0x7f7a737c72a3  google::LogMessage::Flush()\r\n    @     0x7f7a737c72a3  google::LogMessage::Flush()\r\n    @     0x7f7a737cc73e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7a737cc73e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7a737cc73e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f7a7544a2ed  _ZNSt17_Function_handlerIFvvEZNK6paddle8platform17CUDADeviceContext4WaitEvEUlvE_E9_M_invokeERKSt9_Any_data",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-06-24T12:09:57+00:00",
        "updated_at": "2019-08-08T08:03:57+00:00",
        "closed_at": "2019-08-08T08:03:57+00:00",
        "comments_count": [
            "shippingwang",
            "qingqing01",
            "xiegegege",
            "xiegegege"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2530,
        "title": "有没有SRL模型，NLP模型里没有找到只有LAC模型",
        "body": "",
        "state": "open",
        "user": "ly303550688",
        "closed_by": null,
        "created_at": "2019-06-25T01:47:48+00:00",
        "updated_at": "2019-06-26T13:33:56+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "ly303550688",
            "wzzju"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2543,
        "title": "关于paddlepaddle的ocr模型数据提问",
        "body": "在follow模型当中的ocr模型的时候，对于数据字典我产生了一些疑问。\r\n模型当中使用的字典长度是95，但是参考数据当中使用到的字典内容仅仅包含了62个字符\r\n所以请问，其余的字典是什么呢？",
        "state": "open",
        "user": "DianaZhang",
        "closed_by": null,
        "created_at": "2019-06-25T08:31:30+00:00",
        "updated_at": "2019-07-02T05:58:17+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "DianaZhang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2546,
        "title": "您好，请问模型中下面的字典是用来干嘛的，好像没有被读取，是仅仅展示模型细节吗",
        "body": "```\r\ntrain_parameters = {\r\n    \"input_size\": [3, 224, 224],\r\n    \"input_mean\": [0.485, 0.456, 0.406],\r\n    \"input_std\": [0.229, 0.224, 0.225],\r\n    \"learning_strategy\": {\r\n        \"name\": \"piecewise_decay\",\r\n        \"batch_size\": 256,\r\n        \"epochs\": [30, 60, 90],\r\n        \"steps\": [0.1, 0.01, 0.001, 0.0001]\r\n    }\r\n}\r\n```",
        "state": "closed",
        "user": "yangninghua",
        "closed_by": "shippingwang",
        "created_at": "2019-06-25T09:16:06+00:00",
        "updated_at": "2019-06-26T08:32:43+00:00",
        "closed_at": "2019-06-26T08:21:08+00:00",
        "comments_count": [
            "yangninghua",
            "wzzju",
            "shippingwang",
            "yangninghua"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2548,
        "title": "paddleslim 量化时 loss 变成nan",
        "body": "```\r\nW0625 16:37:04.272953  1401 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0625 16:37:04.277964  1401 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\n2019-06-25 16:37:04,700-WARNING: Checkpints path doesn't exist: [./checkpoints_quan/]\r\n2019-06-25 16:37:04,701-INFO: Running evaluation\r\n2019-06-25 16:37:07,379-INFO: batch-0; ['acc_top1', 'acc_top5']=[0.75, 0.96875]\r\n2019-06-25 16:37:12,547-INFO: batch-20; ['acc_top1', 'acc_top5']=[0.625, 0.90625]\r\n2019-06-25 16:37:16,756-INFO: batch-40; ['acc_top1', 'acc_top5']=[0.6875, 0.890625]\r\n2019-06-25 16:37:21,288-INFO: batch-60; ['acc_top1', 'acc_top5']=[0.78125, 0.9375]\r\n...\r\n2019-06-25 16:40:20,955-INFO: Final eval result: ['acc_top1', 'acc_top5']=[0.70931906 0.8955403 ]\r\n2019-06-25 16:40:20,955-INFO: Finish evaluation\r\n2019-06-25 16:40:20,959-INFO: QuantizationStrategy::on_epoch_begin\r\nW0625 16:40:23.255398  1401 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\n2019-06-25 16:40:23,277-INFO: Finish QuantizationStrategy::on_epoch_begin\r\nI0625 16:40:25.002485  1401 build_strategy.cc:285] SeqOnlyAllReduceOps:0, num_trainers:1\r\n2019-06-25 16:40:25,245-INFO: epoch:0; batch_id:0; ['loss'] = [1.75]\r\n2019-06-25 16:40:31,022-INFO: epoch:0; batch_id:20; ['loss'] = [7.417]\r\n2019-06-25 16:40:36,357-INFO: epoch:0; batch_id:40; ['loss'] = [7.6]\r\n2019-06-25 16:40:41,937-INFO: epoch:0; batch_id:60; ['loss'] = [6.469]\r\n2019-06-25 16:40:47,443-INFO: epoch:0; batch_id:80; ['loss'] = [6.333]\r\n2019-06-25 16:40:53,054-INFO: epoch:0; batch_id:100; ['loss'] = [5.891]\r\n2019-06-25 16:40:58,743-INFO: epoch:0; batch_id:120; ['loss'] = [6.151]\r\n2019-06-25 16:41:04,335-INFO: epoch:0; batch_id:140; ['loss'] = [5.673]\r\n2019-06-25 16:41:10,044-INFO: epoch:0; batch_id:160; ['loss'] = [5.924]\r\n2019-06-25 16:41:15,735-INFO: epoch:0; batch_id:180; ['loss'] = [5.77]\r\n2019-06-25 16:41:21,532-INFO: epoch:0; batch_id:200; ['loss'] = [4.94]\r\n2019-06-25 16:41:27,042-INFO: epoch:0; batch_id:220; ['loss'] = [5.309]\r\n2019-06-25 16:41:32,918-INFO: epoch:0; batch_id:240; ['loss'] = [5.27]\r\n2019-06-25 16:41:38,628-INFO: epoch:0; batch_id:260; ['loss'] = [5.175]\r\n2019-06-25 16:41:44,336-INFO: epoch:0; batch_id:280; ['loss'] = [4.984]\r\n2019-06-25 16:41:49,705-INFO: epoch:0; batch_id:300; ['loss'] = [5.029]\r\n2019-06-25 16:41:55,633-INFO: epoch:0; batch_id:320; ['loss'] = [5.136]\r\n2019-06-25 16:42:01,450-INFO: epoch:0; batch_id:340; ['loss'] = [5.489]\r\n2019-06-25 16:42:07,112-INFO: epoch:0; batch_id:360; ['loss'] = [5.176]\r\n2019-06-25 16:42:12,710-INFO: epoch:0; batch_id:380; ['loss'] = [4.712]\r\n2019-06-25 16:42:18,569-INFO: epoch:0; batch_id:400; ['loss'] = [4.628]\r\n2019-06-25 16:42:24,568-INFO: epoch:0; batch_id:420; ['loss'] = [5.203]\r\n2019-06-25 16:42:30,541-INFO: epoch:0; batch_id:440; ['loss'] = [4.71]\r\n2019-06-25 16:42:36,521-INFO: epoch:0; batch_id:460; ['loss'] = [4.419]\r\n2019-06-25 16:42:42,294-INFO: epoch:0; batch_id:480; ['loss'] = [4.755]\r\n2019-06-25 16:42:48,355-INFO: epoch:0; batch_id:500; ['loss'] = [7.196]\r\n2019-06-25 16:42:54,225-INFO: epoch:0; batch_id:520; ['loss'] = [nan]\r\n2019-06-25 16:43:00,511-INFO: epoch:0; batch_id:540; ['loss'] = [nan]\r\n2019-06-25 16:43:06,494-INFO: epoch:0; batch_id:560; ['loss'] = [nan]\r\n2019-06-25 16:43:12,470-INFO: epoch:0; batch_id:580; ['loss'] = [nan]\r\n2019-06-25 16:43:18,527-INFO: epoch:0; batch_id:600; ['loss'] = [nan]\r\n2019-06-25 16:43:24,372-INFO: epoch:0; batch_id:620; ['loss'] = [nan]\r\n2019-06-25 16:43:30,409-INFO: epoch:0; batch_id:640; ['loss'] = [nan]\r\n2019-06-25 16:43:36,356-INFO: epoch:0; batch_id:660; ['loss'] = [nan]\r\n2019-06-25 16:43:42,149-INFO: epoch:0; batch_id:680; ['loss'] = [nan]\r\n2019-06-25 16:43:48,184-INFO: epoch:0; batch_id:700; ['loss'] = [nan]\r\n2019-06-25 16:43:54,426-INFO: epoch:0; batch_id:720; ['loss'] = [nan]\r\n2019-06-25 16:44:00,288-INFO: epoch:0; batch_id:740; ['loss'] = [nan]\r\n2019-06-25 16:44:06,483-INFO: epoch:0; batch_id:760; ['loss'] = [nan]\r\n2019-06-25 16:44:12,533-INFO: epoch:0; batch_id:780; ['loss'] = [nan]\r\n2019-06-25 16:44:18,773-INFO: epoch:0; batch_id:800; ['loss'] = [nan]\r\n```\r\n训练使用的脚本为:\r\n```\r\npython compress.py \\\r\n--batch_size 64 \\\r\n--model \"MobileNet\" \\\r\n--pretrained_model ./pretrain/MobileNetV1_pretrained \\\r\n--compress_config ./configs/quantization.yaml \r\n```\r\n",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-06-25T10:32:39+00:00",
        "updated_at": "2019-07-01T11:28:16+00:00",
        "closed_at": "2019-07-01T11:28:16+00:00",
        "comments_count": [
            "wzzju",
            "imistyrain"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2559,
        "title": "window上lexical_analysis infer报错",
        "body": "在PaddleNLP/lexical_analysis目录下，执行python run_sequence_labeling.py --do_train False --do_test False --do_infer True --batch_size 80 --word_emb_dim 768 --grnn_hidden_dim 768 --bigru_num 2   --use_cuda True  --init_checkpoint ./model_baseline/ --infer_data ./data/test.tsv --word_dict_path ./conf/word.dic --label_dict_path ./conf/tag.dic  --word_rep_dict_path ./conf/q2b.dic命令，对该模型进行预测，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/60176210-37a2e380-9848-11e9-88a4-cee89e6ce14b.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-06-26T11:26:04+00:00",
        "updated_at": "2019-06-26T12:46:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2550,
        "title": "slurm分布式训练使用nccl2会卡在run",
        "body": "![image](https://user-images.githubusercontent.com/5461637/60102934-3ebaea80-9791-11e9-8a32-c9179b12a045.png)\r\n\r\n\r\n使用model里面的transformer在集群训练时，发现任务会卡在exe.run，是否现在分布式训练方式变了，需要改成下图paddle文档上的样子么？\r\n![image](https://user-images.githubusercontent.com/5461637/60102925-38c50980-9791-11e9-9f81-9a3a9d64e797.png)\r\n\r\n\r\n并且集群gpu使用率是40%\r\n![image](https://user-images.githubusercontent.com/5461637/60103035-73c73d00-9791-11e9-9cd1-58f736639269.png)\r\n\r\n\r\n\r\n附slurm任务：http://yq01-sys-hic-v100-box-a225-0015.yq01.baidu.com:8388/v1/slurmjobs/47690/workspace",
        "state": "closed",
        "user": "yxzero",
        "closed_by": "yxzero",
        "created_at": "2019-06-25T13:37:49+00:00",
        "updated_at": "2019-07-03T06:41:22+00:00",
        "closed_at": "2019-07-03T06:41:22+00:00",
        "comments_count": [
            "gavin1332",
            "gavin1332",
            "yxzero",
            "gavin1332"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2555,
        "title": "nonlocal test 结束后有报错",
        "body": "在paddle 1.5分支，python3.6下运行nonlocal test部分，运行结束会有报错：\r\nFile \"test.py\", line 130, in <module>\r\n    test(args)\r\n  File \"test.py\", line 123, in test\r\n    test_metrics.finalize_and_log_out(\"[EVAL] eval finished. \")\r\n  File \"/ssd1/xiege/model_6.12/models/PaddleCV/video/metrics/metrics_util.py\", line 149, in finalize_and_log_out\r\n    self.calculator.finalize_metrics()\r\n  File \"/ssd1/xiege/model_6.12/models/PaddleCV/video/metrics/multicrop_test/multicrop_test_metrics.py\", line 90, in finalize_metrics\r\n    pickle.dump(self.results, f)\r\nTypeError: write() argument must be str, not bytes",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-06-26T07:11:37+00:00",
        "updated_at": "2019-07-03T11:37:59+00:00",
        "closed_at": "2019-07-03T11:37:59+00:00",
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2558,
        "title": "attgan模型和stgan模型训练大概率出nan",
        "body": "在PaddleCV/gan目录下，执行bash scripts/run_stgan.sh 对该模型进行训练，在epoch=30的时候，输出的d_loss为nan。log信息如下所示:\r\n![image](https://user-images.githubusercontent.com/37854899/60171773-e1c93e00-983d-11e9-8797-7dd6b5663037.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-06-26T10:12:14+00:00",
        "updated_at": "2019-07-08T11:32:43+00:00",
        "closed_at": "2019-07-08T11:32:43+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2563,
        "title": "利用stnet模型训练ufc-101数据出现过拟合，没有使用预训练模型。",
        "body": "尝试调整学习速率、权重衰减系数、增加了剪切旋转视频输入的帧数据，最终得到的验证集合和训练集的准确率相差很大。\r\n迭代到26代的时候已经相差50%啦。\r\n+ End pass: 26, train_loss: 1.074, train_acc1: 0.705, train_acc5: 0.926\r\n+ End pass: 26, test_loss: 11.127, test_acc1: 0.285, test_acc5: 0.515\r\n\r\n+ End pass: 59, train_loss: 0.066, train_acc1: 0.983, train_acc5: 0.999\r\n+ End pass: 59, test_loss: 7.522, test_acc1: 0.432, test_acc5: 0.676\r\n\r\n辛苦看下有什么方法可以解决以上过拟合的情况。",
        "state": "closed",
        "user": "stard",
        "closed_by": "stard",
        "created_at": "2019-06-26T12:34:53+00:00",
        "updated_at": "2020-02-26T09:03:30+00:00",
        "closed_at": "2019-08-06T08:50:42+00:00",
        "comments_count": [
            "SunGaofeng",
            "stard",
            "gtgtgt1117"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2580,
        "title": "yolov3 train with multi-process reader, then stuck at train process",
        "body": "i use yolov3 with multi-process train reader.\r\ntrain successfully first. But stuck at 15433 iter, almost 2 epochs\r\nI did not do many changes except modifying reader to read xml annotation.\r\nmy model config is :\r\n```\r\ngpu_num=2, batch_size=8, pretrain=init_weight/yolov3 ,use_multiprocess=True \r\nclass_num=7,  snapshot_iter=1000,  max_iter=500000, no_mixup_iter=40000, input_size=608 , learning_rate=0.001,  num_worker=8\r\n```\r\nmy dataset trainset includes 7088 images, 7 class nums.\r\nmy code is using branch develop yolov3.\r\npaddle version is released paddle:1.4.1-gpu-cuda9.0-cudnn7 docker image.\r\nenvironment is using V100 2GPU.\r\nIt seems something wrong with multiprocess reader. please help me find out the question.\r\n\r\nstuck log is:\r\n```\r\nW0627 04:02:17.841068   127 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.0, Runtime API Version: 9.0\r\nW0627 04:02:17.844712   127 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\nW0627 04:02:17.844794   127 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nW0627 04:02:18.923068   127 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\n2019-06-27 04:02:18,925-WARNING: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\n-----------  Configuration Arguments -----------\r\nbatch_size: 8\r\nclass_num: 7\r\ndata_dir: dataset/coco\r\ndataset: coco2017\r\ndebug: False\r\ndraw_thresh: 0.5\r\nenable_ce: False\r\nimage_name: None\r\nimage_path: image\r\ninput_size: 608\r\nlabel_smooth: True\r\nlearning_rate: 0.001\r\nmax_iter: 500000\r\nmodel_save_dir: work_dirs/uav_img608_lr0.001/\r\nnms_posk: 100\r\nnms_thresh: 0.45\r\nnms_topk: 400\r\nno_mixup_iter: 40000\r\npretrain: init_weight/yolov3_2\r\nrandom_shape: True\r\nsnapshot_iter: 1000\r\nstart_iter: 0\r\nsyncbn: True\r\nuse_gpu: True\r\nuse_multiprocess: 1\r\nvalid_thresh: 0.005\r\nweights: weights/yolov3\r\n------------------------------------------------\r\ncfg.class_num:7\r\nout:(-1L, 36L, 19L, 19L)\r\nout:(-1L, 36L, 38L, 38L)\r\nout:(-1L, 36L, 76L, 76L)\r\nFound 2 CUDA devices.\r\ntotal_iter:1000000;mixup_iter:920000, img nums:7088\r\nLoad in 7 categories.\r\ncategories:[{u'name': 'sedan', u'id': 0}, {u'name': 'truck', u'id': 1}, {u'name': 'bus', u'id': 2}, {u'name': 'motor', u'id': 3}, {u'name': 'tricycle', u'id': 4}, {u'name': 'person', u'id': 5}, {u'name': 'bicycle', u'id': 6}]\r\nI0627 04:02:19.906926   127 build_strategy.cc:282] set enable_sequential_execution:1\r\nI0627 04:02:24.266566   127 build_strategy.cc:285] SeqOnlyAllReduceOps:0, num_trainers:1\r\nIter 0, lr 0.000000, loss 8507.810547, time 0.01503\r\nIter 1, lr 0.000000, loss 9591.240234, time 46.43099\r\n\r\n.....\r\n\r\nIter 15425, lr 0.001000, loss 155.478741, time 0.92534\r\nIter 15426, lr 0.001000, loss 155.480361, time 0.45774\r\nIter 15427, lr 0.001000, loss 155.479925, time 1.11275\r\nIter 15428, lr 0.001000, loss 155.480860, time 0.69338\r\nIter 15429, lr 0.001000, loss 155.484091, time 0.77737\r\nIter 15430, lr 0.001000, loss 155.484229, time 0.59263\r\nIter 15431, lr 0.001000, loss 155.486114, time 1.31359\r\nIter 15432, lr 0.001000, loss 155.484561, time 0.86391\r\nIter 15433, lr 0.001000, loss 155.482944, time 0.96678\r\n```",
        "state": "open",
        "user": "Haijunlv",
        "closed_by": null,
        "created_at": "2019-06-27T11:51:51+00:00",
        "updated_at": "2019-07-01T04:43:05+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "xiangyubo",
            "Haijunlv",
            "heavengate",
            "Haijunlv"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2591,
        "title": "cycle_gan  train.py  训练报错",
        "body": "我的环境\r\npadddle 版本 1.4.1\r\npython版本：3.7\r\n系统：centos7.4   两核4G \r\ncpu 模式训练，报错如下，烦请大神给看下\r\n![2569383d19cefb642b75c2d4d62cac5](https://user-images.githubusercontent.com/8262664/60319984-e52e0800-99aa-11e9-9f60-28dbeca1b2ce.png)\r\n![ea8856bbb8e89d85f232d0c4096fd41](https://user-images.githubusercontent.com/8262664/60319985-e5c69e80-99aa-11e9-960b-e7a25c8f0804.png)\r\n\r\n",
        "state": "closed",
        "user": "hardphp",
        "closed_by": "wangguibao",
        "created_at": "2019-06-28T05:45:21+00:00",
        "updated_at": "2019-08-06T03:14:25+00:00",
        "closed_at": "2019-08-06T03:14:25+00:00",
        "comments_count": [
            "wangguibao",
            "JiaXiao243",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2595,
        "title": "transformer train windows下报错 paddle1.4.1 GPU版",
        "body": "ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.\r\nTraceback (most recent call last):\r\n  File \"E:/tmp/autoMaster/PaddleNLP/neural_machine_translation/transformer/train.py\", line 774, in <module>\r\n    train(args)\r\n  File \"E:/tmp/autoMaster/PaddleNLP/neural_machine_translation/transformer/train.py\", line 694, in train\r\n    token_num, predict, pyreader)\r\n  File \"E:/tmp/autoMaster/PaddleNLP/neural_machine_translation/transformer/train.py\", line 513, in train_loop\r\n    trainer_id=nccl2_trainer_id)\r\n  File \"E:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\parallel_executor.py\", line 134, in __init__\r\n    self._compiled_program._compile(place=self._place, scope=self._scope)\r\n  File \"E:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\compiler.py\", line 307, in _compile\r\n    scope=self._scope)\r\n  File \"E:\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\compiler.py\", line 278, in _compile_data_parallel\r\n    self._exec_strategy, self._build_strategy, self._graph)\r\npaddle.fluid.core.EnforceNotMet: Not compiled with CUDA at [D:\\1.4.1\\paddle\\paddle\\fluid\\framework\\parallel_executor.cc:275]\r\nPaddlePaddle Call Stacks: \r\nWindows not support stack backtrace yet.\r\nW0628 15:22:38.912901  8748 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 8.0\r\nW0628 15:22:38.916891  8748 device_context.cc:269] device: 0, cuDNN Version: 7.0.\r\nW0628 15:22:46.824911  8748 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!",
        "state": "closed",
        "user": "wang001",
        "closed_by": "wangguibao",
        "created_at": "2019-06-28T07:25:13+00:00",
        "updated_at": "2019-06-28T10:36:52+00:00",
        "closed_at": "2019-06-28T10:36:52+00:00",
        "comments_count": [
            "JiaXiao243",
            "wang001",
            "JiaXiao243",
            "wang001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2606,
        "title": "Paddle下面的LAC和baidu/lac的区别是什么？ c++版本需要自己根据paddle的接口去实现吗？",
        "body": "Paddle下面的LAC和baidu/lac的区别是什么？ c++版本需要自己根据paddle的接口去实现吗？",
        "state": "closed",
        "user": "miaozx",
        "closed_by": "wangguibao",
        "created_at": "2019-06-28T11:55:54+00:00",
        "updated_at": "2019-08-06T03:13:04+00:00",
        "closed_at": "2019-08-06T03:13:03+00:00",
        "comments_count": [
            "wangguibao",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2616,
        "title": "OCR运行错误，请问如何需要修改",
        "body": "我运行了OCR模型，有如下错误信息，请问如何修改。说明一下，train.py改名为testtx3.py, 放到了E:\\paddletest目录下，其他文件也复制过来，运行python testtx3.py,以下就是错误信息，文件train.py中只把use_cube改为False,其他没改。我的paddlepaddle是1.4.1版本，python是3.7.1版本。\r\n-------------------------------------------------------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\naverage_window: 0.15\r\nbatch_size: 32\r\neval_period: 15000\r\ninit_model: None\r\nlog_period: 1000\r\nmax_average_window: 12500\r\nmin_average_window: 10000\r\nmodel: crnn_ctc\r\nparallel: False\r\nprofile: False\r\nsave_model_dir: ./models\r\nsave_model_period: 15000\r\nskip_batch_num: 0\r\nskip_test: False\r\ntest_images: None\r\ntest_list: None\r\ntotal_step: 720000\r\ntrain_images: None\r\ntrain_list: None\r\nuse_gpu: False\r\n------------------------------------------------\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\evaluator.py:71: Warning\r\n: The EditDistance is deprecated, because maintain a modified program inside eva\r\nluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"testtx3.py\", line 217, in <module>\r\n    main()\r\n  File \"testtx3.py\", line 213, in main\r\n    train(args)\r\n  File \"testtx3.py\", line 147, in train\r\n    results = train_one_batch(data)\r\n  File \"testtx3.py\", line 108, in train_one_batch\r\n    fetch_list=fetch_vars)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", li\r\nne 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", li\r\nne 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator elementwise_sub error.\r\nPython Callstacks:\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", l\r\nine 1654, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\"\r\n, line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", l\r\nine 9232, in _elementwise_op\r\n    'use_mkldnn': use_mkldnn})\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", l\r\nine 9281, in elementwise_sub\r\n    return _elementwise_op(LayerHelper('elementwise_sub', **locals()))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\evaluator.py\", l\r\nine 268, in __init__\r\n    x=seq_num, y=seq_right_count)\r\n  File \"E:\\paddletest\\crnn_ctc_model.py\", line 195, in ctc_train_net\r\n    input=decoded_out, label=casted_label)\r\n  File \"testtx3.py\", line 60, in train\r\n    args, data_shape, num_classes)\r\n  File \"testtx3.py\", line 213, in main\r\n    train(args)\r\n  File \"testtx3.py\", line 217, in <module>\r\n    main()\r\nC++ Callstacks:\r\nTensor holds the wrong type, it holds int at [D:\\1.4.1\\paddle\\paddle/fluid/frame\r\nwork/tensor_impl.h:29]\r\nPaddlePaddle Call Stacks:\r\nWindows not support stack backtrace yet.",
        "state": "closed",
        "user": "githubusr1",
        "closed_by": "githubusr1",
        "created_at": "2019-06-29T08:38:37+00:00",
        "updated_at": "2019-07-06T05:44:44+00:00",
        "closed_at": "2019-07-02T03:42:36+00:00",
        "comments_count": [
            "gavin1332",
            "githubusr1",
            "gavin1332",
            "wanghaoshuang",
            "githubusr1",
            "wanghaoshuang",
            "wanghaoshuang",
            "githubusr1",
            "daniellibin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2619,
        "title": "lstm 第一个输出参数",
        "body": "我在自己建立的语言模型中,使用了fluid.layers.lstm模块,但是模块的第一个输出和文档描述不同\r\n![Screenshot from 2019-06-25 20-42-59](https://user-images.githubusercontent.com/29620676/60393279-71743280-9b45-11e9-86ff-bde7be402980.png)\r\n![Screenshot from 2019-06-25 20-43-23](https://user-images.githubusercontent.com/29620676/60393280-720cc900-9b45-11e9-99d9-125587ae4118.png)\r\n![Screenshot from 2019-06-25 20-43-39](https://user-images.githubusercontent.com/29620676/60393281-720cc900-9b45-11e9-8cd7-fcd4754bef1f.png)\r\n第一个输出和模型的输入是同一维度的,但是我觉得我的模型使用以及变量都没有问题,请问是哪里出了问题?\r\n\r\n\r\n",
        "state": "closed",
        "user": "wshongCola",
        "closed_by": "wshongCola",
        "created_at": "2019-06-30T06:45:08+00:00",
        "updated_at": "2019-07-04T13:28:42+00:00",
        "closed_at": "2019-07-04T13:28:42+00:00",
        "comments_count": [
            "Xreki",
            "phlrain",
            "wshongCola",
            "wshongCola",
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2615,
        "title": "用的是哪个词典",
        "body": "请问一下，OCR模型readme说明中有如下文字，文中说的词典在哪下载，我看了一下80是Q，但是ASII码Q是81，所以猜不出这个词典是哪个，请提供哪里下载。这个词典也应该包括中文。\r\n----------------------------------------------------------------------------------------------------\r\n在训练集中，每张图片对应的label是汉字在词典中的索引。 图1 对应的label如下所示：\r\n\r\n80,84,68,82,83,72,78,77,68,67\r\n在上边这个label中，80 表示字符Q的索引，67 表示英文字符D的索引。",
        "state": "closed",
        "user": "githubusr1",
        "closed_by": "githubusr1",
        "created_at": "2019-06-29T08:28:03+00:00",
        "updated_at": "2019-07-02T03:43:32+00:00",
        "closed_at": "2019-07-02T03:43:32+00:00",
        "comments_count": [
            "gavin1332",
            "githubusr1",
            "gavin1332",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2620,
        "title": "transformer train运行时自动关闭",
        "body": "[2019-06-30 15:55:14,971 INFO train.py:571] step_idx: 3000, epoch: 0, batch: 3000, avg loss: 2.779823, normalized loss: 1.634409, ppl: 16.116165, speed: 5.81 step/s\r\n[2019-06-30 15:55:32,400 INFO train.py:571] step_idx: 3100, epoch: 0, batch: 3100, avg loss: 3.257778, normalized loss: 2.112365, ppl: 25.991724, speed: 5.74 step/s\r\n[2019-06-30 15:55:49,902 INFO train.py:571] step_idx: 3200, epoch: 0, batch: 3200, avg loss: 3.192317, normalized loss: 2.046904, ppl: 24.344774, speed: 5.71 step/s\r\n*** Check failure stack trace: ***\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n\r\n上面是关闭时的最近几条输出，paddlepaddle-gpu==1.5.0.post87，显存占用不到一半",
        "state": "closed",
        "user": "wang001",
        "closed_by": "wang001",
        "created_at": "2019-06-30T08:00:37+00:00",
        "updated_at": "2019-06-30T08:14:01+00:00",
        "closed_at": "2019-06-30T08:14:01+00:00",
        "comments_count": [
            "wang001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2631,
        "title": "attention ocr infer报错",
        "body": "```\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 1\r\ndict: None\r\ninput_images_dir: None\r\ninput_images_list: None\r\niterations: 0\r\nmodel: attention\r\nmodel_path: models/ocr_attention_params\r\nprofile: False\r\nskip_batch_num: 0\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0701 11:41:15.507436 17863 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 9.0\r\nW0701 11:41:15.511775 17863 device_context.cc:267] device: 0, cuDNN Version: 7.4.\r\nInit model from: models/ocr_attention_params.\r\nPlease input the path of image: test/1.png\r\nTraceback (most recent call last):\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1741, in <module>\r\n    main()\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1735, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1135, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/root/lilw/pycharm/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 159, in <module>\r\n    main()\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 155, in main\r\n    inference(args)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 97, in inference\r\n    return_numpy=False)\r\n  File \"/root/lilw/anaconda3/envs/chineseocr/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/lilw/anaconda3/envs/chineseocr/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator im2sequence error.\r\nPython Callstacks: \r\n  File \"/root/lilw/anaconda3/envs/chineseocr/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/lilw/anaconda3/envs/chineseocr/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/root/lilw/anaconda3/envs/chineseocr/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 6164, in im2sequence\r\n    type='im2sequence', inputs=inputs, outputs={'Out': out}, attrs=attrs)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/attention_model.py\", line 71, in encoder_net\r\n    filter_size=[conv_features.shape[2], 1])\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/attention_model.py\", line 237, in attention_infer\r\n    images, is_test=True, use_cudnn=use_cudnn)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 48, in inference\r\n    ids = infer(images, num_classes, use_cudnn=True if args.use_gpu else False)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 155, in main\r\n    inference(args)\r\n  File \"/root/lilw/Paddle/models/PaddleCV/ocr_recognition/infer.py\", line 159, in <module>\r\n    main()\r\n  File \"/root/lilw/pycharm/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1135, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1735, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/root/lilw/pycharm/helpers/pydev/pydevd.py\", line 1741, in <module>\r\n    main()\r\nC++ Callstacks: \r\nEnforce failed. Expected numel() >= 0, but received numel():-31488 < 0:0.\r\nWhen calling this method, the Tensor's numel must be equal or larger than zero. Please check Tensor::Resize has been called first. at [/root/lilw/Paddle/paddle/fluid/framework/tensor.cc:43]\r\n```",
        "state": "closed",
        "user": "intgogo",
        "closed_by": "intgogo",
        "created_at": "2019-07-01T03:39:30+00:00",
        "updated_at": "2019-07-01T07:12:33+00:00",
        "closed_at": "2019-07-01T07:12:32+00:00",
        "comments_count": [
            "intgogo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2641,
        "title": "paddleslim有基于检测模型进行量化的例子吗？",
        "body": "[PaddleSlim](https://github.com/PaddlePaddle/models/tree/develop/PaddleSlim)里提供了不少诸如剪切、量化和蒸馏的案例，但他们都是分类的，有没有基于检测的案例，量化后map会降多少？有实验数据吗？",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-01T07:48:26+00:00",
        "updated_at": "2019-07-11T03:39:51+00:00",
        "closed_at": "2019-07-04T11:01:28+00:00",
        "comments_count": [
            "wanghaoshuang",
            "imistyrain",
            "qingqing01",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2638,
        "title": "真是垃圾！不负垃圾百度之名！",
        "body": "先说明下，最近刚发现百度这个开源项目，乍一看，CV的各种检测算法、分类模型、分割、文字识别、甚至是YOLO v3的支持，都让我心跳加速，恨没有早发现这个开源项目。怀着激动的心情，我开始了这段旅途~\r\n\r\n第一步，自然是源码构建，立马就躺了一坑。因为我习惯是在build目录下，再创建debug和release目录用来分开构建。岂料，死活就是构建不成功，报个什么snappy头文件的错误，来这里找答案也是毫无线索。倒腾来倒腾去，最后竟然是因为这里只能在build目录下进行构建，你们说傻不傻逼的！\r\n\r\n第二步，今天测试models/PaddleCV/ocr_recognition，ocr在github上开源的都比较零碎，质量不能说很高，比较好点的都是基于crnn+ctc的实现，但是在这里，我看到attention的实现貌似准确度要高不少，我果断的就先下载过来按照说明进行试验一番。结果立马又是一个坑，报个错`paddle.fluid.core_avx.EnforceNotMet: Invoke operator im2sequence error`，也是倒腾来倒腾去，找不到答案。最后竟然发现是因为图片必须是48像素高的，尼玛的！简直弱智了！\r\n\r\n开源不是这么玩的，这些小问题，对于我们新接触的人来说，就是一个个的坎，对于你们这些作者而言就是一句话、两行代码的事情。\r\n\r\n如果没有这种态度，还开源尼玛啊！早点滚蛋，不然各种浪费大家时间，你们不是在帮助这个世界，而是在阻碍世界的进展。一如曾经的微软！\r\n\r\n",
        "state": "closed",
        "user": "intgogo",
        "closed_by": "intgogo",
        "created_at": "2019-07-01T07:03:44+00:00",
        "updated_at": "2024-10-08T07:23:22+00:00",
        "closed_at": "2019-07-01T10:41:17+00:00",
        "comments_count": [
            "shippingwang",
            "Xreki",
            "githubusr1",
            "kagome112",
            "intgogo",
            "intgogo",
            "kagome112",
            "sanfengliu",
            "intgogo",
            "adaxi987",
            "jackaduma",
            "huxianhe0",
            "AmadeusSys",
            "hemengjita",
            "intgogo",
            "AIMSK",
            "intgogo",
            "tdynlildjl528",
            "intgogo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2648,
        "title": "训练及so预测时报错fuse_relu_before_depthwise_conv",
        "body": "paddle fluid版本1.3. so预测时报错： in conv2d 'fuse_relu_before_depthwise_conv': False\r\n![image](https://user-images.githubusercontent.com/10609885/60425142-7b209780-9c24-11e9-88d6-18de4520181e.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "sherylwang",
        "closed_by": "shippingwang",
        "created_at": "2019-07-01T09:21:48+00:00",
        "updated_at": "2019-07-01T11:29:22+00:00",
        "closed_at": "2019-07-01T11:29:22+00:00",
        "comments_count": [
            "shippingwang",
            "sherylwang",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2651,
        "title": "如何修改similarity_net中infer模式的模型output?",
        "body": "我在使用预训练好的开源pairwise bow similarity_net，目前模型的ouput只有left_bow和pred这两个变量，我想修改模型的返回结果（如令其返回right_bow和pred）。\r\nReadme中提到，可在../models/matching/中定制自己的模型，但我注意到这貌似只适用于training阶段。run_classifier.py中的infer模式甚至都没有调用../models/matching/bow.py，想问一下inference阶段模型的输出如何修改？",
        "state": "open",
        "user": "bb9696aa",
        "closed_by": null,
        "created_at": "2019-07-01T09:57:02+00:00",
        "updated_at": "2019-07-01T12:42:59+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2649,
        "title": "windows上transformer infer报错",
        "body": "在/PaddleNLP/neural_machine_translation/transformer路径下，执行python -u infer.py --src_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000 --trg_vocab_fpath wmt16_ende_data_bpe_clean/vocab_all.bpe.32000  --test_file_pattern wmt16_ende_data_bpe_clean/newstest2014.tok.bpe.32000.en-de  --batch_size 32 model_path base_model/iter_100000.infer.model beam_size 5 max_out_len 255，对模型进行预测，报错信息如下：\r\n![transformer](https://user-images.githubusercontent.com/37854899/60425128-765be380-9c24-11e9-81bd-7e65f7a1bb92.JPG)\r\nwindow上infer结果如下所示，存在异常字符，\r\n![T2](https://user-images.githubusercontent.com/37854899/60425347-e9fdf080-9c24-11e9-979d-00c3747aba32.JPG)\r\n对比linux上infer的输出结果，如图所示：\r\n![image](https://user-images.githubusercontent.com/37854899/60428994-ad35f780-9c2c-11e9-9a6b-b2c2936d93db.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-07-01T09:23:52+00:00",
        "updated_at": "2019-07-01T11:58:03+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2652,
        "title": "load checkpoint error",
        "body": "hi，load checkpoint error\r\n![image](https://user-images.githubusercontent.com/5461637/60427942-5f1ff480-9c2a-11e9-9ad5-d6b9baa07330.png)\r\n\r\nslurm log(http://yq01-sys-hic-v100-box-a223-0141.yq01.baidu.com:8388/v1/slurmjobs/49968/workspace)\r\n\r\nsave code\r\n![image](https://user-images.githubusercontent.com/5461637/60427979-74951e80-9c2a-11e9-9ab4-addb99858535.png)\r\nload code\r\n![image](https://user-images.githubusercontent.com/5461637/60428418-57ad1b00-9c2b-11e9-9774-6b3b000a0e3a.png)\r\n",
        "state": "open",
        "user": "yxzero",
        "closed_by": null,
        "created_at": "2019-07-01T10:08:52+00:00",
        "updated_at": "2019-07-02T02:06:06+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "yxzero",
            "shippingwang",
            "yxzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2654,
        "title": "PaddleDetection中的cascade模型CPU下训练报错",
        "body": "使用paddle 1.5分支，在CPU下运行PaddleDetection中的cascade模型，有如下报错：\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 204, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 159, in main\r\n    outs = exe.run(train_compile_program, fetch_list=train_values)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 665, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator distribute_fpn_proposals error.\r\nPython Callstacks:\r\n  File \"/opt/_internal/cpython-2.7.11-ucs2/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1764, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/_internal/cpython-2.7.11-ucs2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs2/lib/python2.7/site-packages/paddle/fluid/layers/detection.py\", line 2837, in distribute_fpn_proposals\r\n    'refer_scale': refer_scale\r\n  File \"/ssd1/xiege/model_7.1/models/PaddleCV/PaddleDetection/ppdet/modeling/roi_extractors/roi_extractor.py\", line 76, in __call__\r\n    rois, k_min, k_max, self.canconical_level, self.canonical_size)\r\n  File \"/ssd1/xiege/model_7.1/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 119, in build\r\n    roi_feat = self.roi_extractor(body_feats, proposals, spatial_scale)\r\n  File \"/ssd1/xiege/model_7.1/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 160, in train\r\n    return self.build(feed_vars, 'train')\r\n  File \"tools/train.py\", line 95, in main\r\n    train_fetches = model.train(feed_vars)\r\n  File \"tools/train.py\", line 204, in <module>\r\n    main()\r\nC++ Callstacks:\r\nEnforce failed. Expected begin_idx < end_idx, but received begin_idx:0 >= end_idx:0.\r\nThe start row index must be lesser than the end row index. at [/ssd1/xiege/paddle_wheel/Paddle_2.7/Paddle/paddle/fluid/framework/tensor.cc:78]",
        "state": "open",
        "user": "xiegegege",
        "closed_by": null,
        "created_at": "2019-07-01T12:19:23+00:00",
        "updated_at": "2019-07-25T03:32:14+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "xiegegege",
            "suyali",
            "xiegegege"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2665
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2658,
        "title": "使用PaddleVideo中的AttentionCluster模型做infer时的几个问题",
        "body": "请教作者几个问题，感谢！\r\n1.做视频分类时，我使用AttentionCluster模型做infer，结果保存在AttentionCluster_infer_result.pkl文件中，但是不明白里面的数字表示的含义，怎样得到所测视频的类别呢？\r\n2.在paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7镜像制作的容器中运行infer.py.我将use_gpu设置为False时能正常运行，设置为True时报错如下：\r\n\r\n[INFO: infer.py:  169]: Namespace(batch_size=1, config='configs/attention_cluster.txt', filelist='/data4/hk/docker-hk_paddle/models-master/PaddleCV/PaddleVideo/dataset/youtube8m/val.list', infer_topk=20, log_interval=1, model_name='AttentionCluster', save_dir='./save', use_gpu=True, weights=None)\r\nW0701 12:56:50.640410  4601 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.1, Runtime API Version: 9.0\r\nW0701 12:56:50.645512  4601 device_context.cc:267] device: 0, cuDNN Version: 7.4.\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 171, in <module>\r\n    infer(args)\r\n  File \"infer.py\", line 118, in infer\r\n    fluid.default_main_program(), place)\r\n  File \"/data4/hk/docker-hk_paddle/models-master/PaddleCV/PaddleVideo/models/model.py\", line 139, in load_test_weights\r\n    fluid.io.load_params(exe, weights, main_program=prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 707, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 620, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 657, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load error.\r\nPython Callstacks:\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1766, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 642, in load_vars\r\n    'file_path': os.path.join(load_dirname, new_var.name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 620, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 707, in load_params\r\n    filename=filename)\r\n  File \"/data4/hk/docker-hk_paddle/models-master/PaddleCV/PaddleVideo/models/model.py\", line 139, in load_test_weights\r\n    fluid.io.load_params(exe, weights, main_program=prog)\r\n  File \"infer.py\", line 118, in infer\r\n    fluid.default_main_program(), place)\r\n  File \"infer.py\", line 171, in <module>\r\n    infer(args)\r\nC++ Callstacks:\r\nEnforce failed. Expected allocating <= available, but received allocating:10244597154 > available:711458560.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:262]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fe869864b98p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7fe869864ee7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fe86b8d7776p paddle::platform::GpuMaxChunkSize() + 630\r\n3       0x7fe86b8aba0ap\r\n4       0x7fe9a702ba99p\r\n5       0x7fe86b8ab0adp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 109\r\n6       0x7fe86b8abef5p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 37\r\n7       0x7fe86b8ac495p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long) + 421\r\n8       0x7fe86b8a0555p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 181\r\n9       0x7fe86b8a06dap paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 26\r\n10      0x7fe86b4a76acp paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 44\r\n11      0x7fe86b872f84p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long) + 148\r\n12      0x7fe86b876624p paddle::framework::TensorCopy(paddle::framework::Tensor const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::platform::DeviceContext const&, paddle::framework::Tensor*) + 452\r\n13      0x7fe86b87a21bp paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&) + 699\r\n14      0x7fe86b462fb0p paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 576\r\n15      0x7fe86a32eb09p paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>::LoadLodTensor(std::istream&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::Variable*, paddle::framework::ExecutionContext const&) const + 89\r\n16      0x7fe86a32f030p paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 432\r\n17      0x7fe86a32f3f3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, signed char>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n18      0x7fe86b81d8c7p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n19      0x7fe86b81dca1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n20      0x7fe86b81b2acp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n21      0x7fe8699f125ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n22      0x7fe8699f432fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n23      0x7fe869855b3dp\r\n24      0x7fe8698974a6p\r\n25            0x4c5326p PyEval_EvalFrameEx + 37958\r\n26            0x4b9b66p PyEval_EvalCodeEx + 774\r\n27            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n30            0x4b9b66p PyEval_EvalCodeEx + 774\r\n31            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n32            0x4b9b66p PyEval_EvalCodeEx + 774\r\n33            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n34            0x4b9b66p PyEval_EvalCodeEx + 774\r\n35            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n36            0x4c141fp PyEval_EvalFrameEx + 21823\r\n37            0x4c141fp PyEval_EvalFrameEx + 21823\r\n38            0x4b9b66p PyEval_EvalCodeEx + 774\r\n39            0x4eb69fp\r\n40            0x4e58f2p PyRun_FileExFlags + 130\r\n41            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n42            0x4938cep Py_Main + 1358\r\n43      0x7fe9a6c73830p __libc_start_main + 240\r\n44            0x493299p _start + 41",
        "state": "open",
        "user": "haokuan361",
        "closed_by": null,
        "created_at": "2019-07-01T13:17:32+00:00",
        "updated_at": "2019-07-24T13:07:51+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "haokuan361",
            "haokuan361",
            "SunGaofeng",
            "wangs311"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2666
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2660,
        "title": "gnn工程里network的batch_size 问题",
        "body": "![image](https://user-images.githubusercontent.com/8130720/60478239-87543580-9cb4-11e9-81e4-ddf9e5219f62.png)\r\n\r\n现在这个batch_size 需要外面传参数进来， 为什么不可以像Tensorflow一样 传None或者-1根据数据量来动态适应。    因为我在使用预测的时候 可能一条数据一条数据的进行预测。",
        "state": "closed",
        "user": "Alucardmini",
        "closed_by": "hutuxian",
        "created_at": "2019-07-02T02:33:37+00:00",
        "updated_at": "2019-07-26T07:31:44+00:00",
        "closed_at": "2019-07-26T07:31:44+00:00",
        "comments_count": [
            "heavengate",
            "Alucardmini",
            "Alucardmini",
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2661,
        "title": "PaddleDetection中的Mask-RCNN-FPN训练出的模型可能效果很差",
        "body": "在paddle1.5分支下，Cuda9 Cudnn7下训练Mask-RCNN-FPN模型，训练最后的log会有些异常，loss_bbox值很小。训练得到模型test效果很差。\r\n<img width=\"634\" alt=\"e6c8cfdc0b1f13c3fc83f89eeba51a83\" src=\"https://user-images.githubusercontent.com/46314656/60479064-16624d00-9cb7-11e9-903e-a7983fdf34ea.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "qingqing01",
        "created_at": "2019-07-02T02:50:58+00:00",
        "updated_at": "2019-07-26T02:12:25+00:00",
        "closed_at": "2019-07-26T02:12:25+00:00",
        "comments_count": [
            "jerrywgz"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2662,
        "title": "PaddleSlim中的compress.py是基于哪个train.py改写的？",
        "body": "目前image_classification和ssd的[train.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/ssd/train.py)均使用了py_reader进行异步读取的，而[compress.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/compress.py)中使用的Compressor其内部实现还是同步的方式，如何将预训练模型中的py_reader节点改造成能适应同步读入的方式？",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-02T03:32:39+00:00",
        "updated_at": "2019-07-04T11:01:44+00:00",
        "closed_at": "2019-07-04T11:01:44+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2667,
        "title": "文本检测相关模型库",
        "body": "请问是否有已经实现的paddle文本检测相关模型库，如CTPN，east等文本检测模型？",
        "state": "open",
        "user": "930083287",
        "closed_by": null,
        "created_at": "2019-07-02T06:10:52+00:00",
        "updated_at": "2019-07-02T07:42:56+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2669,
        "title": "PaddleGAN中attgan保存模型报错",
        "body": "在在PaddleCV/PaddleGAN目录中，执行bash scripts/run_attgan.sh，对attgan模型进行训练，在保存模型时报错，报错信息如下:\r\n![image](https://user-images.githubusercontent.com/37854899/60489578-415c9900-9cd7-11e9-8d29-e66c13b6d143.png)\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-07-02T06:40:07+00:00",
        "updated_at": "2019-07-02T11:17:08+00:00",
        "closed_at": "2019-07-02T07:26:34+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2668,
        "title": "win 10根据文档描述启动train.py 断言报错",
        "body": "-----------  Configuration Arguments -----------\r\nap_version: 11point\r\nbatch_size: 64\r\ndata_dir: data/pascalvoc\r\ndataset: 'pascalvoc'\r\nenable_ce: False\r\nepoc_num: 120\r\nimage_shape: 3,300,300\r\nlearning_rate: 0.001\r\nmean_BGR: 127.5,127.5,127.5\r\nmodel_save_dir: model\r\nparallel: True\r\npretrained_model: 'pretrained/ssd_mobilenet_v1_coco/'\r\nuse_gpu: 0\r\n------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\untitled\\pratice\\ssd\\train.py\", line 332, in <module>\r\n    main()\r\n  File \"D:\\untitled\\pratice\\ssd\\train.py\", line 292, in main\r\n    assert dataset in ['pascalvoc', 'coco2014', 'coco2017']\r\nAssertionError",
        "state": "closed",
        "user": "liuzengzhen1",
        "closed_by": "liuzengzhen1",
        "created_at": "2019-07-02T06:39:57+00:00",
        "updated_at": "2019-07-02T08:29:54+00:00",
        "closed_at": "2019-07-02T07:07:52+00:00",
        "comments_count": [
            "heavengate",
            "JiaXiao243",
            "liuzengzhen1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2674,
        "title": "请问预训练模型后缀的vc,vd是什么意思？",
        "body": "比如ResNet50_vd",
        "state": "closed",
        "user": "cassiaaaaaa",
        "closed_by": "heavengate",
        "created_at": "2019-07-02T07:45:45+00:00",
        "updated_at": "2023-06-08T02:34:35+00:00",
        "closed_at": "2019-07-02T08:24:58+00:00",
        "comments_count": [
            "jerrywgz",
            "jerrywgz",
            "cassiaaaaaa",
            "cassiaaaaaa",
            "heavengate",
            "byhwdy",
            "cww97",
            "XEric7"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2678,
        "title": "视频库中CTCN在python3.6下无法加载数据",
        "body": "在python3.6下，视频库中CTCN会无法正确加载数据，然后异常退出：\r\n[INFO: ctcn_reader.py:  391]: Error when loading E0xXymnjDkc\r\n[INFO: ctcn_reader.py:  391]: Error when loading _6mQ9_DQr0Q\r\n[INFO: ctcn_reader.py:  391]: Error when loading WmOTDAim7XM\r\n[INFO: ctcn_reader.py:  391]: Error when loading vMdSEzQkRTg\r\n[INFO: ctcn_reader.py:  391]: Error when loading YmGXXV6ztUo\r\n[INFO: ctcn_reader.py:  391]: Error when loading 0EDEA8dZeGo\r\n[INFO: ctcn_reader.py:  391]: Error when loading BO0vQ6ASVlo\r\n[INFO: ctcn_reader.py:  391]: Error when loading rt3t2n6K_ww\r\n[INFO: ctcn_reader.py:  391]: Error when loading 6yVhTyPaaLQ\r\n[INFO: ctcn_reader.py:  391]: Error when loading nxDAt9SkPoA\r\n[INFO: train_utils.py:  196]: [TRAIN] Epoch 0 training finished, average time: nan\r\n/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\r\n  out=out, **kwargs)\r\n/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\r\n  ret = ret.dtype.type(ret / rcount)\r\nTraceback (most recent call last):\r\n  File \"/ssd1/xiege/model_7.2/models/PaddleCV/PaddleVideo/tools/train_utils.py\", line 170, in train_with_pyreader\r\n    train_outs = train_exe.run(fetch_list=train_fetch_list)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/parallel_executor.py\", line 280, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 665, in run\r\n    return_numpy=return_numpy)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:92]",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-07-02T11:20:22+00:00",
        "updated_at": "2019-07-04T02:31:14+00:00",
        "closed_at": "2019-07-02T13:26:43+00:00",
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2680,
        "title": "视频库中CTCN训练ctr+c退出后显卡无法释放",
        "body": "视频库中CTCN模型在训练时ctr+c退出后，显卡占用无法自动释放，且kill不掉相关进程。\r\n<img width=\"669\" alt=\"39156a3cfe2c63eb11b4cee114f679c0\" src=\"https://user-images.githubusercontent.com/46314656/60511957-daa2a400-9d05-11e9-896b-077a7ba32153.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-07-02T12:14:09+00:00",
        "updated_at": "2019-07-04T02:30:54+00:00",
        "closed_at": "2019-07-02T13:26:21+00:00",
        "comments_count": [
            "SunGaofeng",
            "imistyrain"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2682,
        "title": "paddle.fluid.core_avx.EnforceNotMet: Enforce failed. Expected end > start, but received end:1917 <= start:1917.",
        "body": "用ssd训练的一个二分类的检测网络，用save_persistables保存模型，使用load_persistable加载报错，但是把该模型用save_inference_model转成inference模型后可以正常使用.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/***/.vscode/extensions/ms-python.python-2019.3.6558/pythonFiles/ptvsd_launcher.py\", line 45, in <module>\r\n    main(ptvsdArgs)\r\n  File \"/Users/***/.vscode/extensions/ms-python.python-2019.3.6558/pythonFiles/lib/python/ptvsd/__main__.py\", line 391, in main\r\n    run()\r\n  File \"/Users/gongyanhe/.vscode/extensions/ms-python.python-2019.3.6558/pythonFiles/lib/python/ptvsd/__main__.py\", line 272, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/Users/***/infer.py\", line 95, in <module>\r\n    main(args)\r\n  File \"/Users/***/infer.py\", line 88, in main\r\n    fetch_list=nmsed_out,return_numpy=False)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 744, in _run\r\n    fetch_var_name=fetch_var_name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 429, in _add_feed_fetch_ops\r\n    for i, var in enumerate(fetch_list):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 884, in __getitem__\r\n    'decrease_axis': decrease_axis\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1141, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: Enforce failed. Expected end > start, but received end:1917 <= start:1917.\r\nend should greater than start at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/operators/slice_op.cc:57]\r\nPaddlePaddle Call Stacks: \r\n0          0x11fa563b4p void paddle::platform::EnforceNotMet::Init<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, char const*, int) + 628\r\n1          0x11fa560e0p paddle::platform::EnforceNotMet::EnforceNotMet(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, char const*, int) + 80\r\n2          0x11fcc94a4p paddle::operators::SliceOp::InferShape(paddle::framework::InferShapeContext*) const + 2324\r\n3          0x11fbb3b88p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 1464\r\n4          0x11fb0d536p void pybind11::cpp_function::initialize<pybind11::cpp_function::cpp_function<void, paddle::framework::OpDesc, paddle::framework::BlockDesc const&, pybind11::name, pybind11::is_method, pybind11::sibling>(void (paddle::framework::OpDesc::*)(paddle::framework::BlockDesc const&) const, pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(paddle::framework::OpDesc const*, paddle::framework::BlockDesc const&), void, paddle::framework::OpDesc const*, paddle::framework::BlockDesc const&, pybind11::name, pybind11::is_method, pybind11::sibling>(void&&, paddle::framework::OpDesc (*)(paddle::framework::BlockDesc const&), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 198\r\n5          0x11fa35a08p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3400\r\n6          0x10075dd09p PyCFunction_Call + 281\r\n7          0x1007ebf25p PyEval_EvalFrameEx + 38741\r\n8          0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n9          0x1007ec9a7p PyEval_EvalCodeEx + 71\r\n10         0x10073884ap function_call + 186\r\n11         0x100705783p PyObject_Call + 99\r\n12         0x10072086cp method_call + 140\r\n13         0x100705783p PyObject_Call + 99\r\n14         0x10077ba81p slot_tp_init + 81\r\n15         0x1007723c4p type_call + 212\r\n16         0x100705783p PyObject_Call + 99\r\n17         0x1007e7fb4p PyEval_EvalFrameEx + 22500\r\n18         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n19         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n20         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n21         0x1007ec9a7p PyEval_EvalCodeEx + 71\r\n22         0x10073884ap function_call + 186\r\n23         0x100705783p PyObject_Call + 99\r\n24         0x10072086cp method_call + 140\r\n25         0x100705783p PyObject_Call + 99\r\n26         0x100777459p slot_sq_item + 153\r\n27         0x1007399cep iter_iternext + 62\r\n28         0x100727d0dp enum_next + 45\r\n29         0x1007e5454p PyEval_EvalFrameEx + 11396\r\n30         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n31         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n32         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n33         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n34         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n35         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n36         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n37         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n38         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n39         0x1007eca01p PyEval_EvalCode + 81\r\n40         0x1007dfc2fp builtin_exec + 623\r\n41         0x10075dcd9p PyCFunction_Call + 233\r\n42         0x1007ebe34p PyEval_EvalFrameEx + 38500\r\n43         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n44         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n45         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n46         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n47         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n48         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n49         0x1007ea424p PyEval_EvalFrameEx + 31828\r\n50         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n51         0x1007ea28ap PyEval_EvalFrameEx + 31418\r\n52         0x1007ec8a0p _PyEval_EvalCodeWithName + 2400\r\n53         0x1007eca01p PyEval_EvalCode + 81\r\n54         0x10081ab7ep PyRun_FileExFlags + 206\r\n55         0x10081ae2fp PyRun_SimpleFileExFlags + 463\r\n56         0x100833d12p Py_Main + 3554\r\n57         0x100000e32p\r\n58         0x100000c84p\r\n```",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-02T12:45:09+00:00",
        "updated_at": "2019-07-03T06:03:54+00:00",
        "closed_at": "2019-07-03T06:03:20+00:00",
        "comments_count": [
            "heavengate",
            "imistyrain",
            "heavengate",
            "imistyrain",
            "imistyrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2684,
        "title": "paddleCV/ssd training error ： Local variable 'test_map' referenced before assignment",
        "body": "/home/sunchao/anaconda3/envs/python35/bin/python3.5 /home/sunchao/models-develop/PaddleCV/ssd/train.py\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\nap_version: 11point\r\nbatch_size: 64\r\ndata_dir: data/pascalvoc\r\ndataset: pascalvoc\r\nenable_ce: False\r\nepoc_num: 120\r\nimage_shape: 3,300,300\r\nlearning_rate: 0.001\r\nmean_BGR: 127.5,127.5,127.5\r\nmodel_save_dir: model\r\nparallel: True\r\npretrained_model: pretrained/ssd_mobilenet_v1_coco/\r\nuse_gpu: False\r\n------------------------------------------------\r\nI0704 11:00:20.832667  6615 parallel_executor.cc:329] The number of CPUPlace, which is used in ParallelExecutor, is 2. And the Program will be copied 2 copies\r\nI0704 11:00:21.723721  6615 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\nimport ujson error: No module named 'ujson' use json\r\nimport ujson error: No module named 'ujson' use json\r\nEpoc 0, batch 0, loss 38.866570, time 0.00049\r\nEpoc 0, batch 10, loss 10.186079, time 14.33592\r\nEpoc 0, batch 20, loss 8.082126, time 22.44005\r\nEpoc 0, batch 30, loss 7.095359, time 19.11344\r\nEpoc 0, batch 40, loss 7.257343, time 19.97595\r\nEpoc 0, batch 50, loss 7.060732, time 8.09673\r\nEpoc 0, batch 60, loss 6.570441, time 45.05368\r\nEpoc 0, batch 70, loss 7.062677, time 8.17861\r\nEpoc 0, batch 80, loss 5.846516, time 12.95178\r\nEpoc 0, batch 90, loss 6.432323, time 13.21465\r\nEpoc 0, batch 100, loss 5.780276, time 16.27642\r\nEpoc 0, batch 110, loss 5.577415, time 12.16178\r\nEpoc 0, batch 120, loss 5.725643, time 18.41036\r\nEpoc 0, batch 130, loss 4.751263, time 8.13912\r\nEpoc 0, batch 140, loss 5.574385, time 9.84319\r\nEpoc 0, batch 150, loss 5.201525, time 8.12551\r\nEpoc 0, batch 160, loss 5.676281, time 8.15622\r\n/home/sunchao/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\r\n  out=out, **kwargs)\r\n/home/sunchao/.local/lib/python3.5/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\r\n  ret = ret.dtype.type(ret / rcount)\r\nTraceback (most recent call last):\r\n  File \"/home/sunchao/models-develop/PaddleCV/ssd/train.py\", line 332, in <module>\r\n    main()\r\n  File \"/home/sunchao/models-develop/PaddleCV/ssd/train.py\", line 328, in main\r\n    val_file_list=val_file_list)\r\n  File \"/home/sunchao/models-develop/PaddleCV/ssd/train.py\", line 266, in train\r\n    best_map, mean_map = test(epoc_id, best_map)\r\n  File \"/home/sunchao/models-develop/PaddleCV/ssd/train.py\", line 222, in test\r\n    print(\"Epoc {0}, test map {1}\".format(epoc_id, test_map[0]))\r\nUnboundLocalError: local variable 'test_map' referenced before assignment\r\n",
        "state": "closed",
        "user": "SunChao3555",
        "closed_by": "SunChao3555",
        "created_at": "2019-07-03T02:52:43+00:00",
        "updated_at": "2019-07-05T03:25:45+00:00",
        "closed_at": "2019-07-05T03:25:45+00:00",
        "comments_count": [
            "qingqing01",
            "SunChao3555"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2686,
        "title": "文档有误",
        "body": "PaddleNLP/unarchived/neural_machine_translation/rnn_search/\r\n\r\nrun.sh包含训练程序的主函数，要使用默认参数开始训练，只需要简单地执行：\r\npython run.sh\r\n\r\npython infer.sh\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "phlrain",
        "created_at": "2019-07-03T03:33:12+00:00",
        "updated_at": "2019-07-11T08:15:03+00:00",
        "closed_at": "2019-07-11T08:15:03+00:00",
        "comments_count": [
            "phlrain"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2688,
        "title": "文档有误",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/dialogue_model_toolkit\r\n\r\ndialogue_general_understanding: 通用对话理解模型，支持意图识别、**槽位时别**、匹配、对话状态追踪、对话行为识别等对话模型训练；\r\n\r\n有错别字",
        "state": "open",
        "user": "bobkentt",
        "closed_by": null,
        "created_at": "2019-07-03T05:32:44+00:00",
        "updated_at": "2019-07-04T01:34:23+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2687,
        "title": "翻译模型/rnn_search在paddle1.4版本上运行报错",
        "body": "文档：\r\n[运行本目录下的范例模型需要安装PaddlePaddle Fluid 1.0版。]\r\n\r\npaddle1.4版本运行报错：\r\n python train.py --src_lang en --tar_lang vi --attention True --num_layers 2 --hidden_size 512 --src_vocab_size 17191 --tar_vocab_size 7709 --batch_size 128 --dropout 0.2 --init_scale 0.1 --max_grad_norm 5.0 --train_data_prefix data/en-vi/train --eval_data_prefix data/en-vi/tst2012 --test_data_prefix data/en-vi/tst2013 --vocab_prefix data/en-vi/vocab --use_gpu True --max_epoch 2\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 40, in <module>\r\n    from base_model import BaseModel\r\n  File \"/home/paddle/zhengya01/paddle-ce/local/rnn_search/base_model.py\", line 24, in <module>\r\n    from paddle.fluid.contrib.layers import basic_lstm, BasicLSTMUnit\r\nImportError: No module named layers",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-07-03T03:47:46+00:00",
        "updated_at": "2019-07-11T08:39:44+00:00",
        "closed_at": "2019-07-11T08:39:44+00:00",
        "comments_count": [
            "kolinwei",
            "kuke"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2689,
        "title": "'DetectionMAP' object has no attribute 'name'",
        "body": "在使用[PaddleSlim](https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/compress.py)量化检测模型时，需要拿到test_program的输出，但是提示'DetectionMAP' object has no attribute 'name'.\r\n```\r\nval_fetch_list = [('map', map_eval.name)]\r\ntrain_fetch_list = [('loss', loss.name)]\r\n```",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-03T06:49:57+00:00",
        "updated_at": "2019-08-13T12:52:05+00:00",
        "closed_at": "2019-07-04T07:25:09+00:00",
        "comments_count": [
            "wanghaoshuang",
            "imistyrain",
            "imistyrain",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2692,
        "title": "PaddleSlim 量化检测 代码",
        "body": "基于[ssd](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/ssd/train.py)和[quant_low_level_api](https://github.com/PaddlePaddle/models/tree/develop/PaddleSlim/quant_low_level_api)改的，大佬帮忙看下有啥问题没?",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-03T08:17:36+00:00",
        "updated_at": "2019-07-04T07:23:52+00:00",
        "closed_at": "2019-07-04T07:23:52+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2706,
        "title": "windows10 SSD model 添加自定义训练集预测出错",
        "body": "下载官网SSD模型根据PASCAL数据集的格式上上传相关训练数据，修改label_list文本改写为：\r\nbackground\r\nnewType\r\n并修改train_parameters =  里数据集class_num 等于2\r\n训练调用参数如下：\r\n\r\n```\r\nap_version: 11point\r\nbatch_size: 16\r\ndata_dir: D:/untitled/pratice/ssdTest/data/pascalvoc\r\ndataset: pascalvoc\r\nenable_ce: False\r\nepoc_num: 5\r\nimage_shape: 3,300,300\r\nlearning_rate: 0.001\r\nmean_BGR: 127.5,127.5,127.5\r\nmodel_save_dir: D:\\untitled\\pratice\\ssdTest\\model\r\nparallel: 0\r\npretrained_model: 'pretrained/ssd_mobilenet_v1_coco/'\r\nuse_gpu: 0\r\n预测验证报错\r\n-----------  Configuration Arguments -----------\r\nconfs_threshold: 0.5\r\ndataset: pascalvoc\r\nimage_path: D:\\untitled\\pratice\\ssdTest\\data\\pascalvoc\\VOCdevkit\\VOC2007\\JPEGImages\\000001.jpg\r\nmean_value_B: 127.5\r\nmean_value_G: 127.5\r\nmean_value_R: 127.5\r\nmodel_dir: D:\\untitled\\pratice\\ssdTest\\model\\best_model\r\nnms_threshold: 0.45\r\nresize_h: 300\r\nresize_w: 300\r\nuse_gpu: 0\r\n------------------------------------------------\r\nD:\\untitled\\pratice\\ssdTest\\model\\best_model\r\nTraceback (most recent call last):\r\n  File \"D:\\untitled\\pratice\\ssdTest\\infer.py\", line 145, in <module>\r\n    model_dir=args.model_dir)\r\n  File \"D:\\untitled\\pratice\\ssdTest\\infer.py\", line 76, in infer\r\n    return_numpy=False)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator reshape2 error.\r\nPython Callstacks:\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1654, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 6424, in reshape\r\n    \"XShape\": x_shape})\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\detection.py\", line 1675, in multi_box_head\r\n    conf_loc, shape=compile_shape, actual_shape=run_shape)\r\n  File \"D:\\untitled\\pratice\\ssdTest\\mobilenet_ssd.py\", line 55, in ssd_net\r\n    flip=True)\r\n  File \"D:\\untitled\\pratice\\ssdTest\\mobilenet_ssd.py\", line 126, in build_mobilenet_ssd\r\n    return ssd_model.ssd_net()\r\n  File \"D:\\untitled\\pratice\\ssdTest\\infer.py\", line 54, in infer\r\n    image_shape)\r\n  File \"D:\\untitled\\pratice\\ssdTest\\infer.py\", line 145, in <module>\r\n    model_dir=args.model_dir)\r\nC++ Callstacks:\r\nEnforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:-2163 != -in_size:-2166.\r\nInvalid shape is given. at [D:\\1.4.1\\paddle\\paddle\\fluid\\operators\\reshape_op.cc:101]\r\nPaddlePaddle Call Stacks:\r\nWindows not support stack backtrace yet.\r\n\r\n```\r\n\r\n是我再更换数据集的时候有参数没有修改导致还是什么原因，请求支援",
        "state": "closed",
        "user": "liuzengzhen1",
        "closed_by": "qingqing01",
        "created_at": "2019-07-03T11:29:59+00:00",
        "updated_at": "2019-07-16T08:53:02+00:00",
        "closed_at": "2019-07-16T08:53:02+00:00",
        "comments_count": [
            "qingqing01",
            "liuzengzhen1",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2709,
        "title": "如何用save_inference_model保存int8的模型",
        "body": "用PaddleSlim量化得到了int8的模型，但是还是和save_vars类似由很多文件组成，调用save_inference_model时报错，提示holder_ should not be null",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-07-04T02:31:37+00:00",
        "updated_at": "2019-08-13T12:56:42+00:00",
        "closed_at": "2019-07-04T11:03:31+00:00",
        "comments_count": [
            "junjun315",
            "imistyrain",
            "junjun315",
            "imistyrain",
            "wanghaoshuang",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2718,
        "title": "PaddleDetection eval 当权重路径不存在不会停止运行",
        "body": "PaddleDetection eval 当权重路径不存在时程序没有停止，依然在进行评估。\r\n<img width=\"908\" alt=\"72d271f5229020ee778fbf9a034ede84\" src=\"https://user-images.githubusercontent.com/46314656/60652287-8d940e80-9e7a-11e9-86aa-42982d51c29b.png\">\r\n\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "heavengate",
        "created_at": "2019-07-04T08:44:41+00:00",
        "updated_at": "2019-07-11T00:05:28+00:00",
        "closed_at": "2019-07-04T09:28:47+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2725,
        "title": "icnet 存在的几个问题",
        "body": "[icnet](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/icnet)里存在诸多问题:\r\n1.文档有误，--model_path=\"./cnkpnt/100\"应该是--model_path=\"./chkpnt/100\"\r\n2.训练时没有输出中间过程信息，仅在最后输出几个loss信息\r\n3.文档中给的预训练模型无法用于infer，能提供下训好的cnkpnt/100模型吗？",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-07-05T02:35:44+00:00",
        "updated_at": "2019-07-19T12:21:50+00:00",
        "closed_at": "2019-07-19T12:21:50+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2748,
        "title": "attentionlstm",
        "body": "",
        "state": "closed",
        "user": "lixiangchun",
        "closed_by": "lixiangchun",
        "created_at": "2019-07-08T06:39:28+00:00",
        "updated_at": "2019-07-08T07:00:40+00:00",
        "closed_at": "2019-07-08T06:41:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2742,
        "title": "文档有误",
        "body": "这个文档：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/docs/tutorial.md\r\n1、里面有多处公式渲染不正确：\r\n![图片](https://user-images.githubusercontent.com/35131887/60710113-876a6480-9f44-11e9-842f-4abfc4e3e63b.png)\r\n2、文章4.2节的配图丢失，疑似链接有误：\r\n写的是images/tutorial/light-nas-block.png\r\n但是实际应该是images/light-nas-block.png",
        "state": "open",
        "user": "houj04",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-07-05T08:48:23+00:00",
        "updated_at": "2019-09-04T04:20:25+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "yma-admin",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2744,
        "title": "ocr_recognition运行报错",
        "body": "RuntimeError: E:/release_cuda87/build_python35_CPU_MKL/third_party/install/warpctc/lib/warpctc.dll not found.",
        "state": "open",
        "user": "daniellibin",
        "closed_by": null,
        "created_at": "2019-07-06T03:36:35+00:00",
        "updated_at": "2019-07-11T02:06:16+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "DDDivano",
            "wopeizl",
            "daniellibin",
            "daniellibin",
            "daniellibin",
            "SunGaofeng",
            "daniellibin",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2750,
        "title": "attgan设置batch_size=1 infer报错",
        "body": "在 PaddleGAN目录下执行python infer.py --batch_size 1 --model_net AttGAN --init_model output_attgan/checkpoints/40/ --dataset_dir \"data/celeba/\" --image_size 128 --output infer_attgan，对该模型进行预测报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/60797756-7cad0b00-a1a2-11e9-9992-2c5618012867.png)\r\ninfer的batch_size设置为其他值，可以正常infer。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-07-08T09:07:40+00:00",
        "updated_at": "2019-07-11T07:35:51+00:00",
        "closed_at": "2019-07-11T07:35:51+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2749,
        "title": "yolov3预测错误",
        "body": "Connected to pydev debugger (build 191.7479.19)\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 2\r\nclass_num: 4\r\ndata_dir: /home/chenlei/dataset/voc/dianmian\r\ndataset: coco2017\r\ndebug: True\r\ndraw_thresh: 0.5\r\nenable_ce: False\r\nimage_name: 165.jpg\r\nimage_path: image/\r\ninput_size: 608\r\nlabel_smooth: True\r\nlearning_rate: 0.001\r\nmax_iter: 50020\r\nmodel_save_dir: checkpoints\r\nnms_posk: 100\r\nnms_thresh: 0.45\r\nnms_topk: 400\r\nno_mixup_iter: 4000\r\npretrain: weights/darknet53\r\nrandom_shape: True\r\nsnapshot_iter: 2000\r\nstart_iter: 0\r\nsyncbn: True\r\ntrain_data_dir: img\r\ntrain_file_list: cocoformatJson/voc_2019_my_trainval.json\r\nuse_gpu: False\r\nuse_multiprocess_reader: True\r\nval_data_dir: img\r\nval_file_list: cocoformatJson/voc_2019_my_test.json\r\nvalid_thresh: 0.005\r\nweights: weights/yolov3\r\n------------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\nLoad in 4 categories.\r\nTraceback (most recent call last):\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1758, in <module>\r\n    main()\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1752, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1147, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/media/chenlei/文档/project/paddlepaddle/test/yolov3/infer.py\", line 134, in <module>\r\n    infer()\r\n  File \"/media/chenlei/文档/project/paddlepaddle/test/yolov3/infer.py\", line 116, in infer\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator yolo_box error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py\", line 1654, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/detection.py\", line 705, in yolo_box\r\n    attrs=attrs)\r\n  File \"/media/chenlei/文档/project/paddlepaddle/test/yolov3/models/yolov3.py\", line 194, in build_model\r\n    name=\"yolo_box\" + str(i))\r\n  File \"/media/chenlei/文档/project/paddlepaddle/test/yolov3/infer.py\", line 80, in infer\r\n    model.build_model()\r\n  File \"/media/chenlei/文档/project/paddlepaddle/test/yolov3/infer.py\", line 134, in <module>\r\n    infer()\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1147, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1752, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/media/chenlei/系统/develop/IntelliJ IDEA 2018.2/myplugins/python/helpers/pydev/pydevd.py\", line 1758, in <module>\r\n    main()\r\nC++ Callstacks: \r\nEnforce failed. Expected dim_x[1] == anchor_num * (5 + class_num), but received dim_x[1]:255 != anchor_num * (5 + class_num):27.\r\nInput(X) dim[1] should be equal to (anchor_mask_number * (5 + class_num)). at [/paddle/paddle/fluid/operators/detection/yolo_box_op.cc:43]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f637eb71c68p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f637eb71fb7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f637f82b79ep paddle::operators::YoloBoxOp::InferShape(paddle::framework::InferShapeContext*) const + 3150\r\n3       0x7f637fd1da48p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 584\r\n4       0x7f637fd1e594p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 292\r\n5       0x7f637fd1c76bp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 267\r\n6       0x7f637ecd6f3ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 158\r\n7       0x7f637ecd9f1fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n8       0x7f637eb623cep\r\n9       0x7f637eba10fep\r\n10            0x4ea137p PyCFunction_Call + 119\r\n11            0x53c176p PyEval_EvalFrameEx + 23030\r\n12            0x53fc97p\r\n13            0x53bc93p PyEval_EvalFrameEx + 21779\r\n14            0x53fc97p\r\n15            0x53b83fp PyEval_EvalFrameEx + 20671\r\n16            0x53b294p PyEval_EvalFrameEx + 19220\r\n17            0x53fc97p\r\n18            0x5409bfp PyEval_EvalCode + 31\r\n19            0x54a435p\r\n20            0x4ea10fp PyCFunction_Call + 79\r\n21            0x53e935p PyEval_EvalFrameEx + 33205\r\n22            0x53fc97p\r\n23            0x53b83fp PyEval_EvalFrameEx + 20671\r\n24            0x53fc97p\r\n25            0x53b83fp PyEval_EvalFrameEx + 20671\r\n26            0x53b294p PyEval_EvalFrameEx + 19220\r\n27            0x53fc97p\r\n28            0x5409bfp PyEval_EvalCode + 31\r\n29            0x60cb42p\r\n30            0x60efeap PyRun_FileExFlags + 154\r\n31            0x60f7dcp PyRun_SimpleFileExFlags + 444\r\n32            0x640256p Py_Main + 1110\r\n33            0x4d0001p main + 225\r\n34      0x7f63b7811830p __libc_start_main + 240\r\n35            0x5d6999p _start + 41\r\n",
        "state": "closed",
        "user": "L-lei",
        "closed_by": "L-lei",
        "created_at": "2019-07-08T08:53:09+00:00",
        "updated_at": "2019-07-11T09:25:20+00:00",
        "closed_at": "2019-07-11T09:25:20+00:00",
        "comments_count": [
            "sandyhouse",
            "L-lei",
            "L-lei",
            "heavengate",
            "L-lei",
            "L-lei",
            "L-lei",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2751,
        "title": "Lac 模型,加载用户词典后，处理包含字符\" /\"字符串崩溃。",
        "body": "### 出错代码\r\n\r\n```\r\nimport paddlehub as hub\r\nlac = hub.Module(name=\"lac\")\r\ninputs = {\"text\": [\"早上测量血糖10.1mmol/l\"]}\r\nlac.lexical_analysis(data=inputs,user_dict=\"dic/n.txt\")\r\n```\r\n输出结果\r\n```\r\n[2019-07-08 18:01:17,530] [    INFO] - Installing lac module\r\n[2019-07-08 18:01:17,563] [    INFO] - Module lac already installed in /Users/yanglei/.paddlehub/modules/lac\r\n[2019-07-08 18:01:17,648] [    INFO] - 20 pretrained paramaters loaded by PaddleHub\r\nLoading dict...\r\nSucessfully loaded unigram.dict, got 1366604 words.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-238-f336a48e1bad> in <module>\r\n      2 lac = hub.Module(name=\"lac\")\r\n      3 inputs = {\"text\": [\"早上测量血糖10.1mmol/l\"]}\r\n----> 4 print( lac.lexical_analysis(data=inputs,user_dict=\"dic/n.txt\"))\r\n\r\n/usr/local/lib/python3.7/site-packages/paddlehub/module/module.py in __call__(self, sign_name, data, use_gpu, batch_size, **kwargs)\r\n    488                 }\r\n    489                 result += self.processor.postprocess(sign_name, data_out,\r\n--> 490                                                      sub_data, **kwargs)\r\n    491                 index += len(batch)\r\n    492 \r\n\r\n~/.paddlehub/modules/lac/python/768674b70a7b2e508cb1e3938cfad300.py in postprocess(self, sign_name, data_out, data_info, **kwargs)\r\n    311                 if kwargs.get('user_dict', None) is not None:\r\n    312                     query = Query(seg_result)\r\n--> 313                     seg_result = self.interventer.run(query)\r\n    314 \r\n    315                 result.append(seg_result)\r\n\r\n~/.paddlehub/modules/lac/python/768674b70a7b2e508cb1e3938cfad300.py in run(self, query)\r\n    203         final_result = {'word':[], 'tag':[]}\r\n    204         for phrase in final_phrase_list:\r\n--> 205             word, tag = phrase.split(\"/\")\r\n    206             final_result['word'].append(word)\r\n    207             final_result['tag'].append(tag)\r\n\r\nValueError: too many values to unpack (expected 2)\r\n```\r\n\r\n### 不加载用户字典，代码行为正常\r\n```\r\nimport paddlehub as hub\r\nlac = hub.Module(name=\"lac\")\r\ninputs = {\"text\": [\"早上测量血糖10.1mmol/l\"]}\r\nlac.lexical_analysis(data=inputs)\r\n```\r\n正常输出\r\n```\r\n[2019-07-08 18:00:39,220] [    INFO] - Installing lac module\r\n[2019-07-08 18:00:39,257] [    INFO] - Module lac already installed in /Users/yanglei/.paddlehub/modules/lac\r\n[2019-07-08 18:00:39,378] [    INFO] - 20 pretrained paramaters loaded by PaddleHub\r\n```",
        "state": "closed",
        "user": "chaosfish",
        "closed_by": "chaosfish",
        "created_at": "2019-07-08T10:14:14+00:00",
        "updated_at": "2019-07-12T08:10:06+00:00",
        "closed_at": "2019-07-12T08:10:06+00:00",
        "comments_count": [
            "sandyhouse",
            "chaosfish",
            "Steffy-zxf",
            "nepeplwu",
            "chaosfish",
            "chaosfish",
            "nepeplwu",
            "Steffy-zxf",
            "chaosfish"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2754,
        "title": "yolo v3 在训练过程中会卡死",
        "body": "ubuntu 16.04 \r\npaddlepaddle-1.5.0\r\nRTX 2080Ti\r\n执行命令 python train.py --model_save_dir output/ --pretrain weights/ --data_dir dataset/coco/ --class_num 80 --batch_size 4 --learning_rate 0.0001\r\n在训练过程中卡死，请问是出了什么问题\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 4\r\nclass_num: 80\r\ndata_dir: dataset/coco/\r\ndataset: coco2017\r\ndebug: False\r\ndraw_thresh: 0.5\r\nenable_ce: False\r\nimage_name: None\r\nimage_path: image\r\ninput_size: 608\r\nlabel_smooth: True\r\nlearning_rate: 0.0001\r\nmax_iter: 500200\r\nmodel_save_dir: output/\r\nnms_posk: 100\r\nnms_thresh: 0.45\r\nnms_topk: 400\r\nno_mixup_iter: 40000\r\npretrain: weights/\r\nrandom_shape: True\r\nsnapshot_iter: 2000\r\nstart_iter: 0\r\nsyncbn: True\r\nuse_gpu: True\r\nuse_multiprocess_reader: True\r\nvalid_thresh: 0.005\r\nweights: weights/yolov3\r\n------------------------------------------------\r\nFound 1 CUDA devices.\r\nW0708 19:33:51.657316  2893 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0708 19:33:52.296442  2893 device_context.cc:267] device: 0, cuDNN Version: 7.6.\r\nDisable syncbn in single device\r\nWARNING:root:\r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\nloading annotations into memory...\r\nDone (t=25.48s)\r\ncreating index...\r\nindex created!\r\nLoad in 80 categories.\r\nI0708 19:34:19.215874  2893 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0708 19:34:19.342849  2893 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^",
        "state": "closed",
        "user": "Knightsll",
        "closed_by": "sandyhouse",
        "created_at": "2019-07-08T11:42:02+00:00",
        "updated_at": "2019-07-17T13:38:40+00:00",
        "closed_at": "2019-07-08T16:15:17+00:00",
        "comments_count": [
            "sandyhouse",
            "Knightsll",
            "sandyhouse",
            "AIaiAIaiAIaiAI"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2755,
        "title": "fp16 训练分类模型 hang 住",
        "body": "### 环境\r\n\r\n+ paddle 版本：1.5.0.post97\r\n+ python: 2.7\r\n+ 代码：[image_classification](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification)\r\n\r\n#### 问题1\r\n\r\n[utility.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/utils/utility.py#L75) 此处缩进有问题，多了一个空格，会报错：\r\n\r\n```\r\nIndentationError: unexpected indent \r\n```\r\n\r\n#### 问题2\r\n\r\n[train.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/train.py) 中已经没有 `input_dtype` 参数，而在 [run.sh](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/run.sh) 中还大量存在\r\n\r\n#### 问题3\r\n\r\n`ResNet50_vd + fp16=True + use_label_smoothing=True` 出错：\r\n\r\n命令如下：\r\n```\r\npython train.py \\                                                                                                                                                                                     \r\n        --model=ResNet50_vd \\                                                                                                                                                                         \r\n        --batch_size=256 \\                                                                                                                                                                            \r\n        --fp16=True \\                                                                                                                                                                                 \r\n        --total_images=1281167 \\                                                                                                                                                                      \r\n        --image_shape=3,224,224 \\                                                                                                                                                                     \r\n        --class_dim=1000 \\                                                                                                                                                                            \r\n        --lr_strategy=cosine_decay \\                                                                                                                                                                  \r\n        --lr=0.1 \\                                                                                                                                                                                    \r\n        --num_epochs=200 \\                                                                                                                                                                            \r\n        --with_mem_opt=False \\                                                                                                                                                                         \r\n        --model_save_dir=output/ \\                                                                                                                                                                    \r\n        --l2_decay=7e-5 \\                                                                                                                                                                             \r\n        --use_mixup=True \\                                                                                                                                                                            \r\n        --use_label_smoothing=True \\                                                                                                                                                                  \r\n        --label_smoothing_epsilon=0.1 \r\n```\r\n\r\n错误信息：\r\n```\r\nTraceback (most recent call last):                                                                                                                                                                    \r\n  File \"train.py\", line 655, in <module>                                                                                                                                                              \r\n    main()                                                                                                                                                                                            \r\n  File \"train.py\", line 651, in main                                                                                                                                                                  \r\n    train(args)                                                                                                                                                                                       \r\n  File \"train.py\", line 530, in train                                                                                                                                                                 \r\n    loss, lr = train_exe.run(fetch_list=train_fetch_list)                                                                                                                                             \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py\", line 280, in run                                                                                                   \r\n    return_numpy=return_numpy)                                                                                                                                                                        \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 665, in run                                                                                                            \r\n    return_numpy=return_numpy)                                                                                                                                                                        \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel                                                                                                  \r\n    exe.run(fetch_var_names, fetch_var_name)                                                                                                                                                          \r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator cross_entropy error.                                                                                                                             \r\nPython Callstacks:                                                                                                                                                                                    \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1748, in append_op                                                                                                    \r\n    attrs=kwargs.get(\"attrs\", None))                                                                                                                                                                  \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op                                                                                                   \r\n    return self.main_program.current_block().append_op(*args, **kwargs)                                                                                                                               \r\n  File \"/usr/local/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 1547, in cross_entropy                                                                                                \r\n    \"ignore_index\": ignore_index})                                                                                                                                                                    \r\n  File \"train.py\", line 235, in calc_loss                                                                                                                                                             \r\n    loss = fluid.layers.cross_entropy(input=softmax_out, label=smooth_label, soft_label=True)                                                                                                         \r\n  File \"train.py\", line 275, in net_config                                                                                                                                                            \r\n    loss_a = calc_loss(epsilon,y_a,class_dim,softmax_out,use_label_smoothing)                                                                                                                         \r\n  File \"train.py\", line 332, in build_program                                                                                                                                                         \r\n    avg_cost = net_config(image=image, y_a=y_a, y_b=y_b, lam=lam, model=model, args=args, label=0, is_train=True)                                                                                     \r\n  File \"train.py\", line 401, in train                                                                                                                                                                 \r\n    args=args)                                                                                                                                                                                        \r\n  File \"train.py\", line 651, in main                                                                                                                                                                  \r\n    train(args)                                                                                                                                                                                       \r\n  File \"train.py\", line 655, in <module>                                                                                                                                                              \r\n    main()                                                                                                                                                                                            \r\nC++ Callstacks: \r\n```\r\n\r\n#### 问题4\r\n\r\n`ResNet50_vd + fp16=True + use_label_smoothing=False`  hang 住：\r\n\r\n命令如下：\r\n```\r\npython train.py \\                                                                                                                                                                                     \r\n        --model=ResNet50_vd \\                                                                                                                                                                         \r\n        --batch_size=256 \\                                                                                                                                                                            \r\n        --fp16=True \\                                                                                                                                                                                 \r\n        --total_images=1281167 \\                                                                                                                                                                      \r\n        --image_shape=3,224,224 \\                                                                                                                                                                     \r\n        --class_dim=1000 \\                                                                                                                                                                            \r\n        --lr_strategy=cosine_decay \\                                                                                                                                                                  \r\n        --lr=0.1 \\                                                                                                                                                                                    \r\n        --num_epochs=200 \\                                                                                                                                                                            \r\n        --with_mem_opt=False \\                                                                                                                                                                         \r\n        --model_save_dir=output/ \\                                                                                                                                                                    \r\n        --l2_decay=7e-5 \\                                                                                                                                                                             \r\n        --use_mixup=True \\                                                                                                                                                                            \r\n        --use_label_smoothing=False \\                                                                                                                                                                  \r\n        --label_smoothing_epsilon=0.1 \r\n```",
        "state": "open",
        "user": "mzchtx",
        "closed_by": null,
        "created_at": "2019-07-08T11:47:35+00:00",
        "updated_at": "2019-07-19T07:21:07+00:00",
        "closed_at": null,
        "comments_count": [
            "sandyhouse",
            "sandyhouse",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2762,
        "title": "so，tensorRT对小网络以及nas网络支持不友好",
        "body": "实测MobileNetV2的FLOPs只有MobileNetV1的一半，ShuffleNetV2更少一些，但是无论是so还是tensorRT，ShuffleNet和MobileNet的infer时间都会更长。另外，最近测试mnasnet和EfficientNet，速度也不行，在FLOPs明显降低很多的情况下速度还是太慢。还有一点，在非relu激活函数的网络里，tensorRT往往表现的比so预测更慢一些。希望tensorRT尽快支持对MobileNetV2，ShuffleNetV2，Nas系列的支持，也希望支持更多常见的激活函数。",
        "state": "open",
        "user": "cuicheng01",
        "closed_by": null,
        "created_at": "2019-07-09T03:55:27+00:00",
        "updated_at": "2019-07-09T13:34:05+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX"
        ],
        "labels": [
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2763,
        "title": "multiview_simnet模型运行准确率没有提升",
        "body": "multiview_simnet直接运行python train.py，在运行完10个epoch后，准确率跟初始值差不多，没有提升。\r\n<img width=\"693\" alt=\"8f9430940cb5b7d62e9820136631b13f\" src=\"https://user-images.githubusercontent.com/46314656/60859475-673ced00-a245-11e9-9346-405585eca7ab.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-07-09T04:32:20+00:00",
        "updated_at": "2019-07-11T00:04:48+00:00",
        "closed_at": "2019-07-09T07:44:32+00:00",
        "comments_count": [
            "xiegegege"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2765,
        "title": "hub run lac和  “AI开放平台-词法分析“线上体验输出结果不一样？",
        "body": "hub run lac --input_text \"美批准售台百辆M1A2坦克 价值20亿美元\"\r\n[{'word': ['美批准', '售', '台', '百辆', 'M1A2坦克', ' ', '价值', '20亿美元'], 'tag': ['ORG', 'v', 'n', 'm', 'nz', 'w', 'n', 'm']}]\r\n\r\nAI开放平台-词法分析 线上体验 https://ai.baidu.com/tech/nlp/lexical\r\n输出： 美 ns 批准 v 售 v 台 n 百辆 m M1A2坦克 nz 价值 n 20亿美元 m",
        "state": "closed",
        "user": "fupeng",
        "closed_by": "fupeng",
        "created_at": "2019-07-09T06:30:27+00:00",
        "updated_at": "2019-07-09T13:57:22+00:00",
        "closed_at": "2019-07-09T13:55:43+00:00",
        "comments_count": [
            "Steffy-zxf",
            "fupeng",
            "Steffy-zxf",
            "fupeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2768,
        "title": "gnn的一些疑问",
        "body": "感谢提供paddle的实现， 目前在复现过程中遇到一些问题. 在文件夹`PaddleRec\\gnn`\r\n1.首先`reader.py中make_data()函数的定义`，关于label.append(e[1] - 1)中，为什么需要对label减1这样处理\r\n2.关于`network.py中network()函数的定义`, 关于gnn多步传播的过程中，关于step>1的计算shape疑问。\r\n```\r\n for i in range(step):\r\n        pre_state = layers.reshape(x=pre_state, shape=[batch_size, -1, hidden_size])  \r\n        state_in = layers.fc(input=pre_state, size=hidden_size, )\r\n        state_out = layers.fc(input=pre_state, size=hidden_size, )\r\n        state_adj_in = layers.matmul(adj_in, state_in)\r\n        ...\r\n        pre_state, _, _ = fluid.layers.gru_unit( input=gru_fc,\r\n            hidden=layers.reshape(x=pre_state, shape=[-1, hidden_size]),\r\n            size=3 * hidden_size)  \r\n```\r\n当 `step>1, i =0` , 此时`pre_state：[batch_size, uniq_max, hidden_size]`, 经过GRU之后的`pre_state`输出:  `[batch_size, hidden_size]`.\r\n当i=1时， 此时`pre_state： [batch_size, 1, hidden_size]`，`adj_in: [batch_size, uniq_max, uniq_max]`. 此时`layers.matmul(adj_in, state_in)： [batch_size, uniq_max, uniq_max] * [batch_size, 1, hidden_size]`无法进行运算。麻烦帮忙解释下~多谢",
        "state": "closed",
        "user": "searchlink",
        "closed_by": "hutuxian",
        "created_at": "2019-07-09T09:39:42+00:00",
        "updated_at": "2020-12-03T11:58:20+00:00",
        "closed_at": "2019-07-26T07:31:36+00:00",
        "comments_count": [
            "hutuxian",
            "zhiweilin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2769,
        "title": "auto_dialogue_evaluation的训练实际没有执行",
        "body": "auto_dialogue_evaluation运行命令python -u main.py --do_train True --save_path model_files_tmp/matching_pretrained --train_path data/unlabel_data/train.ids --val_path data/unlabel_data/val.ids进行训练，每个pass耗时都是0s：\r\n<img width=\"392\" alt=\"eb82efc50b2c437ea13dad7319ab631b\" src=\"https://user-images.githubusercontent.com/46314656/60887136-2e713800-a286-11e9-8fc2-8dae546ffbdc.png\">\r\nmain.py中有一段实际没执行：\r\n<img width=\"668\" alt=\"5982852d6e22ebff28d64e4c2b515908\" src=\"https://user-images.githubusercontent.com/46314656/60887301-9758b000-a286-11e9-86c9-650d169102cf.png\">\r\n",
        "state": "closed",
        "user": "xiegegege",
        "closed_by": "xiegegege",
        "created_at": "2019-07-09T12:18:22+00:00",
        "updated_at": "2019-07-10T02:38:48+00:00",
        "closed_at": "2019-07-10T02:38:48+00:00",
        "comments_count": [
            "xiegegege"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2774,
        "title": "add WebVision2018 code and models",
        "body": "add WebVision2018 code and models",
        "state": "closed",
        "user": "yuanpengcheng",
        "closed_by": "qingqing01",
        "created_at": "2019-07-10T04:29:42+00:00",
        "updated_at": "2019-07-15T07:38:40+00:00",
        "closed_at": "2019-07-15T07:38:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2771,
        "title": "SimNet通过向量计算句子之间的相似度吗？如果是，怎样获得句子的向量值？",
        "body": "",
        "state": "closed",
        "user": "jreros",
        "closed_by": "jreros",
        "created_at": "2019-07-09T16:45:44+00:00",
        "updated_at": "2019-07-16T13:43:59+00:00",
        "closed_at": "2019-07-10T10:03:49+00:00",
        "comments_count": [
            "ceci3",
            "jreros",
            "ceci3",
            "jreros",
            "zhouchunyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2778,
        "title": "CTCN数据下载",
        "body": "Activity1.3_train_rgb.listformat, Activity1.3_val_rgb.listformat, labels.txt, test_val_label.list, val_duration_frame.list 这些文件在哪里下载",
        "state": "open",
        "user": "swordlidev",
        "closed_by": null,
        "created_at": "2019-07-10T07:25:31+00:00",
        "updated_at": "2020-05-01T13:29:03+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "swordlidev",
            "HUSTLX",
            "swordlidev",
            "Qinying-Liu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2782,
        "title": "视频模型使用kinetics数据集时如果train.list不存在会hang住",
        "body": "<img width=\"891\" alt=\"image\" src=\"https://user-images.githubusercontent.com/46314656/60967594-a48ca200-a34d-11e9-9c21-16b8ef9fde1a.png\">\r\n",
        "state": "open",
        "user": "xiegegege",
        "closed_by": null,
        "created_at": "2019-07-10T12:02:45+00:00",
        "updated_at": "2019-07-11T04:09:15+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2788,
        "title": "PaddleGAN中的infer不支持cgan和dcgan",
        "body": "在PaddleCV/PaddleGAN目录中执行python infer.py --model_net CGAN --init_model=output_cgan/checkpoints/0/，对训练完的cgan进行预测，信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/61033185-7d89ab00-a3f5-11e9-9935-56f6c592e0e7.png)\r\n需要在infer.py中添加对cgan和dcgan预测的支持。",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-07-11T08:04:12+00:00",
        "updated_at": "2019-07-16T04:20:54+00:00",
        "closed_at": "2019-07-16T04:20:54+00:00",
        "comments_count": [],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2783,
        "title": "Can not find library: libcublas.so",
        "body": "bug\r\n![image](https://user-images.githubusercontent.com/38428867/61016234-7e084e80-a3c1-11e9-8c4f-1a8598ba5124.png)\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": null,
        "created_at": "2019-07-11T01:48:24+00:00",
        "updated_at": "2019-07-19T15:21:37+00:00",
        "closed_at": null,
        "comments_count": [
            "L-lei",
            "qingqing01",
            "geng007",
            "geng007",
            "geng007",
            "luotao1",
            "luotao1",
            "L-lei",
            "L-lei",
            "luotao1",
            "L-lei",
            "L-lei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2785,
        "title": "PaddleDetection log建议",
        "body": "建议输出剩余时间，可参考detectron或者mmdetection或者maskrcnn-benchmark\r\n同时建议loss输出位数统一",
        "state": "open",
        "user": "LaoYang1994",
        "closed_by": null,
        "created_at": "2019-07-11T04:57:49+00:00",
        "updated_at": "2019-07-19T09:14:34+00:00",
        "closed_at": null,
        "comments_count": [
            "AIpioneer",
            "LaoYang1994",
            "AIpioneer",
            "LaoYang1994",
            "qingqing01"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2792,
        "title": "如何修剪自定义的模型",
        "body": "请问下，工具可以用来剪枝和量化自定义的检测模型么，以mobilenetv2为骨干加了反卷积等操作的。如果可以，可以说一下大概操作么，感谢",
        "state": "open",
        "user": "leonzgtee",
        "closed_by": null,
        "created_at": "2019-07-12T01:36:52+00:00",
        "updated_at": "2019-07-22T10:19:12+00:00",
        "closed_at": null,
        "comments_count": [
            "zhaoyuchen2018",
            "kayzss",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2793,
        "title": "bug???Insufficient GPU memory to allocation.",
        "body": "测试程序：\r\n![1562907919(1)](https://user-images.githubusercontent.com/48506731/61103740-cf8a0980-a4a5-11e9-9f71-426675afaee1.png)\r\n报错：\r\n![image](https://user-images.githubusercontent.com/48506731/61103780-052ef280-a4a6-11e9-9ca3-228cfacb1d14.png)\r\n查过了显卡使用情况\r\n![image](https://user-images.githubusercontent.com/48506731/61103813-37d8eb00-a4a6-11e9-98c7-5e67c09e2cc9.png)\r\n显存应该是足够的，而且按照export CUDA_VISIBLE_DEVICES指定显卡，也已经按照FLAGS_fraction_of_gpu_memory_to_use = 0.8修改过的。\r\n版本是python3.6.8，到底是不是cudnn版本的问题呢？",
        "state": "open",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": "AIaiAIaiAIaiAI",
        "created_at": "2019-07-12T05:13:52+00:00",
        "updated_at": "2019-07-19T11:17:15+00:00",
        "closed_at": null,
        "comments_count": [
            "wopeizl",
            "wopeizl",
            "AIaiAIaiAIaiAI",
            "wopeizl",
            "AIaiAIaiAIaiAI",
            "AIaiAIaiAIaiAI"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2795,
        "title": "短文本语义相似度模型实际输出与模型定义不一致",
        "body": "短文本语义相匹配（models/PaddleNLP/similarity_net/）中预训练了一个SimNet-BOW-Pairwise语义匹配模型，通过源码（models/PaddleNLP/similarity_net/run_classifier.py）追溯到用到的模型定义是models/PaddleNLP/models/matching/bow.py中的BOW，BOW的定义如下：\r\n\r\n```\r\nclass BOW(object):\r\n    \"\"\"\r\n    BOW\r\n    \"\"\"\r\n\r\n    def __init__(self, conf_dict):\r\n        \"\"\"\r\n        initialize\r\n        \"\"\"\r\n        self.dict_size = conf_dict[\"dict_size\"]\r\n        self.task_mode = conf_dict[\"task_mode\"]\r\n        self.emb_dim = conf_dict[\"net\"][\"emb_dim\"]\r\n        self.bow_dim = conf_dict[\"net\"][\"bow_dim\"]\r\n\r\n    def predict(self, left, right):\r\n        \"\"\"\r\n        Forward network\r\n        \"\"\"\r\n        # embedding layer\r\n        emb_layer = layers.EmbeddingLayer(self.dict_size, self.emb_dim, \"emb\")\r\n        left_emb = emb_layer.ops(left)\r\n        right_emb = emb_layer.ops(right)\r\n        # Presentation context\r\n        pool_layer = layers.SequencePoolLayer(\"sum\")\r\n        left_pool = pool_layer.ops(left_emb)\r\n        right_pool = pool_layer.ops(right_emb)\r\n        softsign_layer = layers.SoftsignLayer()\r\n        left_soft = softsign_layer.ops(left_pool)\r\n        right_soft = softsign_layer.ops(right_pool)\r\n        # matching layer\r\n        if self.task_mode == \"pairwise\":\r\n            bow_layer = layers.FCLayer(self.bow_dim, \"relu\", \"fc\")\r\n            left_bow = bow_layer.ops(left_soft) # 不会有负值**\r\n            right_bow = bow_layer.ops(right_soft)\r\n            cos_sim_layer = layers.CosSimLayer()\r\n            pred = cos_sim_layer.ops(left_bow, right_bow)\r\n            return left_bow, pred\r\n        else:\r\n            concat_layer = layers.ConcatLayer(1)\r\n            concat = concat_layer.ops([left_soft, right_soft])\r\n            bow_layer = layers.FCLayer(self.bow_dim, \"relu\", \"fc\")\r\n            concat_fc = bow_layer.ops(concat)\r\n            softmax_layer = layers.FCLayer(2, \"softmax\", \"cos_sim\")\r\n            pred = softmax_layer.ops(concat_fc)\r\n            return left_soft, pred\r\n```\r\n\r\n结合models/PaddleNLP/models/matching/bow.py和models/PaddleNLP/similarity_net/run_classifier.py可知，在pairwise模式下，模型会对外输出left_bow和pred，根据模型定义可知，left_bow是由left_bow = bow_layer.ops(left_soft)得到，而**bow_layer = layers.FCLayer(self.bow_dim, \"relu\", \"fc\")是一个接了‘relu’的全连接层**，所以**left_bow中不应该有负值**。\r\n\r\n在尝试运行 bash run.sh infer 的过程中（实际上运行的是run_classifer.py），**如果在run_classifier.py的infer函数中打印 output[0]（对应BOW模型输出的left_bow）**，会发现里面**包含负值**，**这与模型定义的left_bow的输出（relu不会有负值出现）不一致**。",
        "state": "open",
        "user": "IceFlameWorm",
        "closed_by": null,
        "created_at": "2019-07-12T07:19:24+00:00",
        "updated_at": "2020-05-21T02:54:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zhouchunyi",
            "IceFlameWorm",
            "zhouchunyi",
            "IceFlameWorm",
            "zhouchunyi",
            "IceFlameWorm",
            "yw1991",
            "IceFlameWorm",
            "IceFlameWorm",
            "gotogoal",
            "IceFlameWorm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2796,
        "title": "SE_ResNeXt101_32x4d网络修改图像尺寸修改",
        "body": "请问，使用SE_ResNeXt101_32x4d网络，不想采用224*224*3的图片尺寸，想扩大图片尺寸，都需要改哪些？",
        "state": "closed",
        "user": "930083287",
        "closed_by": "zhhsplendid",
        "created_at": "2019-07-12T09:52:59+00:00",
        "updated_at": "2019-12-12T02:36:32+00:00",
        "closed_at": "2019-12-12T02:36:32+00:00",
        "comments_count": [
            "zhhsplendid",
            "930083287",
            "zhhsplendid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2797,
        "title": "训练错误",
        "body": "环境ubuntu18.04 cuda10 nvida 1070 8G 运行\r\nenv CUDA_VISIBLE_DEVICES=0 python train.py\r\n出现下面的错误，系统找这个库找不到\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py:71: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\nfinish batch shuffle\r\nW0712 18:06:16.222995  6743 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0712 18:06:16.697011  6743 device_context.cc:267] device: 0, cuDNN Version: 7.5.\r\nW0712 18:06:16.774031  6743 dynamic_loader.cc:140] Failed to find dynamic library: /usr/local/cuda/extras/CUPTI/lib64/libcupti.so (/usr/local/cuda/extras/CUPTI/lib64/libcupti.so: cannot open shared object file: No such file or directory)\r\nW0712 18:06:16.774173  6743 dynamic_loader.cc:109] Can not find library: libcupti.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nW0712 18:06:16.774191  6743 dynamic_loader.cc:168] Failed to find dynamic library: libcupti.so ( libcupti.so: cannot open shared object file: No such file or directory ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled.\r\nSegmentation fault (core dumped)\r\n",
        "state": "open",
        "user": "huillll",
        "closed_by": null,
        "created_at": "2019-07-12T10:10:39+00:00",
        "updated_at": "2019-07-13T13:30:21+00:00",
        "closed_at": null,
        "comments_count": [
            "huillll",
            "huillll"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2799,
        "title": "PaddleDetection 训练同时做eval，fpn实现问题",
        "body": "版本：\r\npaddlepaddle/models release1.5分支\r\n操作：\r\npython tools/train.py --config=configs/retinanet_r101_fpn_1x.yml --eval\r\n\r\n报错：\r\nassertionError\r\n\r\n原因：\r\ntrain和eval共用一个model实例。\r\nmodel.train时  models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py 174行修改了实例的self.spatial_scale属性。\r\n导致model.eval时 models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py 151行的分支进不去，特征没叠加。",
        "state": "closed",
        "user": "gilbert1989",
        "closed_by": "qingqing01",
        "created_at": "2019-07-12T10:58:08+00:00",
        "updated_at": "2019-07-16T06:40:38+00:00",
        "closed_at": "2019-07-16T06:40:38+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2798,
        "title": "PaddleDetection retinanet50、101训练好的模型，预测时显存溢出",
        "body": "- 版本、环境信息：\r\n    1）PaddlePaddle版本：v1.5\r\n    2）GPU：p4\r\n    3）系统环境：官方docker \r\n\r\n- 复现信息：python tools/infer.py --config=configs/retinanet_r50_fpn_1x.yml --infer_dir=dataset/coco/test/\r\n- 问题描述：batch_size=1,训练和eval没有问题，infer.py进行预测时，提示显存问题。\r\n[](url)",
        "state": "open",
        "user": "gilbert1989",
        "closed_by": null,
        "created_at": "2019-07-12T10:55:51+00:00",
        "updated_at": "2019-07-19T12:55:33+00:00",
        "closed_at": null,
        "comments_count": [
            "gilbert1989",
            "wopeizl",
            "gilbert1989",
            "qingqing01",
            "xiegegege"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2802,
        "title": "建议 pretrained model 文档中加上训练参数和相应日志",
        "body": "希望 pretrained model 都能加上相对应的训练参数以及必要的日志信息，以方便复现。\r\n\r\n可参考[gluon-cv](https://github.com/dmlc/gluon-cv)",
        "state": "open",
        "user": "mzchtx",
        "closed_by": null,
        "created_at": "2019-07-13T03:09:31+00:00",
        "updated_at": "2019-07-16T07:19:15+00:00",
        "closed_at": null,
        "comments_count": [
            "cuicheng01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2803,
        "title": "Errors in image_classification/eval.py and image_classification/infer.py",
        "body": "When I run the following command\r\n```python\r\npython eval.py --pretrained_model ResNet50_vd_pretrained --model ResNet50_vd\r\n```\r\n\r\nError occurs:\r\n```\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 256\r\n                class_dim : 1000\r\n              image_shape : 3,224,224\r\n                    model : ResNet50_vd\r\n         pretrained_model : ResNet50_vd_pretrained\r\n        resize_short_size : 256\r\n                  use_gpu : True\r\n             with_mem_opt : True\r\n----------------------------------------------------\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nW0714 13:31:15.868573 89099 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.1, Runtime API Version: 9.0\r\nW0714 13:31:15.871407 89099 device_context.cc:267] device: 0, cuDNN Version: 7.3.\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 143, in <module>\r\n    main()\r\n  File \"eval.py\", line 139, in main\r\n    eval(args)\r\n  File \"eval.py\", line 100, in eval\r\n    val_reader = paddle.batch(reader.val(settings=args), batch_size=args.batch_size)\r\nTypeError: val() missing 1 required positional argument: 'batch_size'\r\n```\r\n\r\nWhen `batch_size` was added on line 100:\r\n```python\r\nval_reader = paddle.batch(reader.val(settings=args, batch_size=args.batch_size), batch_size=args.batch_size)\r\n```\r\nOther error occurred:\r\n```\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 256\r\n                class_dim : 1000\r\n              image_shape : 3,224,224\r\n                    model : ResNet50_vd\r\n         pretrained_model : ResNet50_vd_pretrained\r\n        resize_short_size : 256\r\n                  use_gpu : True\r\n             with_mem_opt : True\r\n----------------------------------------------------\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nW0714 13:34:55.088060 89222 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.1, Runtime API Version: 9.0\r\nW0714 13:34:55.091224 89222 device_context.cc:267] device: 0, cuDNN Version: 7.3.\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 143, in <module>\r\n    main()\r\n  File \"eval.py\", line 139, in main\r\n    eval(args)\r\n  File \"eval.py\", line 109, in eval\r\n    feed=feeder.feed(data))\r\n  File \"/media/ssd1/software/install/anaconda3/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 282, in feed\r\n    \"len(feed_list) (%s)\") % (len(each_sample), len(converter))\r\nAssertionError: The number of fields in data (256) does not match len(feed_list) (2)\r\n```\r\n\r\nError also found for `infer.py`\r\n```python\r\npython infer.py --pretrained_model ResNet50_vd_pretrained --model ResNet50_vd\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 117, in <module>\r\n    main()\r\n  File \"infer.py\", line 113, in main\r\n    infer(args)\r\n  File \"infer.py\", line 94, in infer\r\n    test_reader = paddle.batch(reader.test(settings=args), batch_size=test_batch_size)\r\nTypeError: test() missing 1 required positional argument: 'batch_size'\r\n```\r\n\r\nWhen added `batch_size` on Line 94:\r\n```python\r\ntest_reader = paddle.batch(reader.test(settings=args, batch_size=test_batch_size), batch_size=test_batch_size)\r\n```\r\nNew error:\r\n```\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nW0714 14:08:49.436848 89879 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.1, Runtime API Version: 9.0\r\nW0714 14:08:49.439999 89879 device_context.cc:267] device: 0, cuDNN Version: 7.3.\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/media/ssd1/software/install/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\r\n    self.run()\r\n  File \"/media/ssd1/software/install/anaconda3/lib/python3.7/threading.py\", line 865, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/media/ssd1/software/install/anaconda3/lib/python3.7/site-packages/paddle/reader/decorator.py\", line 303, in handle_worker\r\n    r = mapper(sample)\r\n  File \"/media/ssd1/project/deep_learning/colonoscopy/resnet50_vd/reader_cv2.py\", line 223, in process_batch_data\r\n    process_image(sample, settings, mode, color_jitter, rotate))\r\n  File \"/media/ssd1/project/deep_learning/colonoscopy/resnet50_vd/reader_cv2.py\", line 198, in process_image\r\n    img = resize_short(img, target_size)\r\n  File \"/media/ssd1/project/deep_learning/colonoscopy/resnet50_vd/reader_cv2.py\", line 94, in resize_short\r\n    percent = float(target_size) / min(img.shape[0], img.shape[1])\r\nAttributeError: 'NoneType' object has no attribute 'shape'\r\n```",
        "state": "closed",
        "user": "lixiangchun",
        "closed_by": "shippingwang",
        "created_at": "2019-07-14T05:37:59+00:00",
        "updated_at": "2019-07-22T09:59:38+00:00",
        "closed_at": "2019-07-22T09:59:38+00:00",
        "comments_count": [
            "Shixiaowei02"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2805,
        "title": "test过程中如何输出中间结果",
        "body": "想load模型参数后，打印出中间结果，可是executor.run的output执行中，在对应的网络层并不能打印出来。想知道怎么才能把中间结果输出",
        "state": "closed",
        "user": "zhouchunyi",
        "closed_by": "zhhsplendid",
        "created_at": "2019-07-15T01:44:38+00:00",
        "updated_at": "2019-07-15T07:21:34+00:00",
        "closed_at": "2019-07-15T07:21:34+00:00",
        "comments_count": [
            "zhhsplendid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2808,
        "title": "[PyramidBox] Questions about the conv_fc layers in the VGG backbone",
        "body": "The PyramidBox paper indicates that,\r\n> We use the base convolution layers and extra convolutional layers in S^3FD as our backbone layers, which keep layers of VGG16 from conv1_1 to pool5, then convert fc6 and fc7 of VGG16 to conv_fc layers, and then add more convolutional layers to make it deeper.\r\n\r\nHowever, from [this line of source code](https://github.com/PaddlePaddle/models/blob/33d384b47ae1436a6de4f01fec4317daf9760d39/PaddleCV/face_detection/pyramidbox.py#L122) and [the definition of conv_block](https://github.com/PaddlePaddle/models/blob/33d384b47ae1436a6de4f01fec4317daf9760d39/PaddleCV/face_detection/pyramidbox.py#L35), we can tell that the dilation conv is not applied as [S^3FD](https://arxiv.org/abs/1708.05237) or [DeepLabv1](https://arxiv.org/abs/1412.7062).\r\n\r\nIs it a miss or dilation conv not working well?\r\n",
        "state": "closed",
        "user": "fengyuentau",
        "closed_by": "fengyuentau",
        "created_at": "2019-07-15T13:02:54+00:00",
        "updated_at": "2019-07-16T07:56:21+00:00",
        "closed_at": "2019-07-16T07:56:21+00:00",
        "comments_count": [
            "qingqing01",
            "fengyuentau",
            "qingqing01",
            "fengyuentau"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2810,
        "title": "GAN运行官方例子出错",
        "body": "运行环境：\r\nwindows10 1903 \r\nGPU：rtx2070 \r\nCPU：intel core i5 3570\r\n内存：12GB ddr3\r\ncuda：9.0.176 \r\ncudnn：7.3.0.29\r\npython：3.6.7\r\npaddlepaddle-gpu： 1.5.1.post97\r\n\r\nG:\\keti\\models\\PaddleCV\\PaddleGAN>python train.py --model_net CycleGAN --dataset cityscapes --batch_size 1 --net_G resnet_9block --g_base_dim 32 --net_D basic --norm_type batch_norm --epoch 200 --load_size 286 --crop_size 256 --crop_type Random  > log_out 2>log_err\r\n\r\n[log_out.txt](https://github.com/PaddlePaddle/models/files/3393188/log_out.txt)\r\n[log-err.txt](https://github.com/PaddlePaddle/models/files/3393189/log-err.txt)\r\n",
        "state": "closed",
        "user": "Free-Cloud",
        "closed_by": "Free-Cloud",
        "created_at": "2019-07-15T16:20:31+00:00",
        "updated_at": "2019-07-16T01:58:37+00:00",
        "closed_at": "2019-07-16T01:58:37+00:00",
        "comments_count": [
            "Free-Cloud"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2813,
        "title": "PaddleSlim 搜索过程中断",
        "body": "进行了一些 PaddleSlim 实验，主要遇到以下两个问题：\r\n1. 搜到大网络时会在 \"Running evaluation\" 后出现 \"Cannot malloc XXX MB GPU memory.\"，而搜到小网络则不会报错。因为并不知道搜索过程中出现的大网络会有多大，希望加入报错中断的判断，跳过该网络继续搜索。\r\n2. 出现 \"Segmentation fault\" 未知错误。在集群搜索时遇到，查看相关 log 并不知道为什么会中断，因为实验前期跑过相同流程，而对于当前搜到的网络，训练和测试部分 batch 能通过：\r\n```\r\nINFO:paddle.fluid.contrib.slim.core.compressor:Finish evaluation\r\n2019-07-13 15:19:25,898-INFO: epoch:4603; batch_id:0; ['loss'] = [1.663]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:epoch:4603; batch_id:0; ['loss'] = [1.663]\r\n2019-07-13 15:19:39,971-INFO: epoch:4603; batch_id:20; ['loss'] = [1.694]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:epoch:4603; batch_id:20; ['loss'] = [1.694]\r\n2019-07-13 15:19:54,306-INFO: epoch:4603; batch_id:40; ['loss'] = [1.583]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:epoch:4603; batch_id:40; ['loss'] = [1.583]\r\n2019-07-13 15:20:01,012-INFO: Running evaluation\r\nINFO:paddle.fluid.contrib.slim.core.compressor:Running evaluation\r\n2019-07-13 15:20:02,553-INFO: batch-0; ['acc_top1', 'acc_top5']=[0.46875, 0.92578125]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:batch-0; ['acc_top1', 'acc_top5']=[0.46875, 0.92578125]\r\n2019-07-13 15:20:03,057-INFO: Final eval result: ['acc_top1', 'acc_top5']=[0.43929303 0.9280546 ]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:Final eval result: ['acc_top1', 'acc_top5']=[0.43929303 0.9280546 ]\r\n2019-07-13 15:20:03,057-INFO: Finish evaluation\r\nINFO:paddle.fluid.contrib.slim.core.compressor:Finish evaluation\r\n2019-07-13 15:20:04,224-INFO: epoch:4604; batch_id:0; ['loss'] = [1.544]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:epoch:4604; batch_id:0; ['loss'] = [1.544]\r\n2019-07-13 15:20:18,097-INFO: epoch:4604; batch_id:20; ['loss'] = [1.598]\r\nINFO:paddle.fluid.contrib.slim.core.compressor:epoch:4604; batch_id:20; ['loss'] = [1.598]\r\n```\r\n如上，log 挂在 `batch_id:20`，而从前面 log 知 `evaluation` 还有 `batch_id:40`。",
        "state": "open",
        "user": "lijiancheng0614",
        "closed_by": null,
        "created_at": "2019-07-16T03:36:36+00:00",
        "updated_at": "2019-08-16T15:54:00+00:00",
        "closed_at": null,
        "comments_count": [
            "ysh329",
            "vincentXiyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2816,
        "title": "PaddleDetection CascadeRCNN  中 num_classes 硬编码 bug",
        "body": "此处 [code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/ppdet/modeling/roi_heads/cascade_head.py#L200) 使用了针对 COCO 数据集（num_classes = 81）的硬编码，对于自定义数据预测将出现下述错误：\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61270462-5572c100-a7d4-11e9-8891-7214f589b755.png)\r\n\r\n需要将：\r\n```\r\nbbox_pred_new = fluid.layers.expand(bbox_pred_new, [1, 81, 1])\r\n```\r\n\r\n修改为：\r\n```\r\nbbox_pred_new = fluid.layers.expand(bbox_pred_new, [1, self.num_classes, 1])\r\n```",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "qingqing01",
        "created_at": "2019-07-16T06:21:11+00:00",
        "updated_at": "2019-07-16T07:10:30+00:00",
        "closed_at": "2019-07-16T07:10:30+00:00",
        "comments_count": [
            "ysh329",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2821,
        "title": "windows下CPU运行RCNN的infer.py出错",
        "body": "在windows下CPU运行RCNN的infer.py出错,下载的权重是按照pretrained里面的download.sh的地址下载的,使用的paddle 1.5版本,报错的信息如下:\r\nC++ Callstacks: \r\nholder_ should not be null\r\nTensor not initialized yet when Tensor::type() is called. at [E:\\release_cuda87\\paddle\\paddle/fluid/framework/tensor.h:139]\r\nPaddlePaddle Call Stacks: \r\nWindows not support stack backtrace yet.\r\n配置里面已经把设置了使用CPU\r\n  add_arg('use_gpu',          bool,  False,      \"Whether use GPU.\")\r\n请问这个是什么问题呢?这个不支持windows的?\r\n",
        "state": "closed",
        "user": "hong3731",
        "closed_by": "hong3731",
        "created_at": "2019-07-16T10:02:49+00:00",
        "updated_at": "2019-07-19T06:19:49+00:00",
        "closed_at": "2019-07-19T06:19:49+00:00",
        "comments_count": [
            "FDInSky",
            "hong3731",
            "FDInSky",
            "hong3731",
            "JiaXiao243",
            "hong3731"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2822,
        "title": "PaddleDetection \"ValueError: var im_shape not in this block\"",
        "body": "使用下述命令进行 inference 并保存 inference model 出现 `ValueError: var im_shape not in this block` 错误。\r\n\r\n```\r\npython tools/infer.py -c configs/cascade_rcnn_r50_fpn_1x.yml --infer_dir=./images --save_inference_model\r\n```\r\n\r\n代码中 `feeded_var_names` 只删除了 `im_id` ，还保留了 `image`，`im_info`，`im_shape` ，而 CascadeRcnn 只需要 `image`，`im_info`，删了 `im_shape` 即可，不知道是否有些模型还会需要 `im_shape`？\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61293914-4eb17180-a807-11e9-9901-68e82719219b.png)\r\n\r\n对应的代码位置：[code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/tools/infer.py#L90)",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "heavengate",
        "created_at": "2019-07-16T12:28:22+00:00",
        "updated_at": "2019-07-18T02:14:14+00:00",
        "closed_at": "2019-07-18T02:14:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2815,
        "title": "crnn_ctc 运行没问题，attention模式出错",
        "body": "```shell\r\nenv CUDA_VISIBLE_DEVICES=0 python train.py --skip_test=True --log_period=1000 --save_model_dir=./models_attention --model=attention\r\n-----------  Configuration Arguments -----------\r\naverage_window: 0.15\r\nbatch_size: 32\r\neval_period: 15000\r\ninit_model: None\r\nlog_period: 1000\r\nmax_average_window: 12500\r\nmin_average_window: 10000\r\nmodel: attention\r\nparallel: False\r\nprofile: False\r\nsave_model_dir: ./models_attention\r\nsave_model_period: 15000\r\nskip_batch_num: 0\r\nskip_test: 1\r\ntest_images: None\r\ntest_list: None\r\ntotal_step: 720000\r\ntrain_images: None\r\ntrain_list: None\r\nuse_gpu: True\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py:71: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n  % (self.__class__.__name__, self.__class__.__name__), Warning)\r\nfinish batch shuffle\r\nW0716 12:37:56.041159  6098 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0716 12:37:56.043552  6098 device_context.cc:267] device: 0, cuDNN Version: 7.5.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 218, in <module>\r\n    main()\r\n  File \"train.py\", line 214, in main\r\n    train(args)\r\n  File \"train.py\", line 148, in train\r\n    results = train_one_batch(data)\r\n  File \"train.py\", line 109, in train_one_batch\r\n    fetch_list=fetch_vars)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator edit_distance error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 5392, in edit_distance\r\n    attrs={\"normalized\": normalized})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/evaluator.py\", line 261, in __init__\r\n    input=input, label=label, ignored_tokens=ignored_tokens)\r\n  File \"/home/luhui/ai-baidu/models/PaddleCV/ocr_recognition/attention_model.py\", line 187, in attention_train_net\r\n    input=maxid, label=label_out, ignored_tokens=[sos, eos])\r\n  File \"train.py\", line 60, in train\r\n    args, data_shape, num_classes)\r\n  File \"train.py\", line 214, in main\r\n    train(args)\r\n  File \"train.py\", line 218, in <module>\r\n    main()\r\nC++ Callstacks: \r\nReference string 10 is empty. at [/paddle/paddle/fluid/operators/edit_distance_op.cu:92]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fa9d28407d0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7fa9d2840b49p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7fa9d2ce17b4p paddle::operators::EditDistanceGPUKernel<paddle::platform::CUDAPlace, float>::Compute(paddle::framework::ExecutionContext const&) const + 5476\r\n3       0x7fa9d2ce1bc3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::EditDistanceGPUKernel<paddle::platform::CUDAPlace, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7fa9d48c5887p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n5       0x7fa9d48c5c61p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n6       0x7fa9d48c325cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n7       0x7fa9d29cc4bep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n8       0x7fa9d29cf55fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n9       0x7fa9d2831c5dp\r\n10      0x7fa9d28736f6p\r\n11      0x55ee22475fe5p PyEval_EvalFrameEx + 32869\r\n12      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n13      0x55ee22473c38p PyEval_EvalFrameEx + 23736\r\n14      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n15      0x55ee224735fep PyEval_EvalFrameEx + 22142\r\n16      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n17      0x55ee22473c38p PyEval_EvalFrameEx + 23736\r\n18      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n19      0x55ee22473c38p PyEval_EvalFrameEx + 23736\r\n20      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n21      0x55ee22473c38p PyEval_EvalFrameEx + 23736\r\n22      0x55ee2246bd0ap PyEval_EvalCodeEx + 1754\r\n23      0x55ee2246b629p PyEval_EvalCode + 25\r\n24      0x55ee2249c61fp\r\n25      0x55ee22497322p PyRun_FileExFlags + 130\r\n26      0x55ee2249667dp PyRun_SimpleFileExFlags + 397\r\n27      0x55ee224451abp Py_Main + 1675\r\n28      0x7faa104bbb97p __libc_start_main + 231\r\n29      0x55ee22444a2ap _start + 42\r\n```",
        "state": "open",
        "user": "huillll",
        "closed_by": null,
        "created_at": "2019-07-16T04:42:49+00:00",
        "updated_at": "2019-09-02T11:03:34+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "huillll",
            "slf12",
            "wanghaoshuang",
            "slf12",
            "huillll",
            "slf12",
            "slf12",
            "slf12",
            "vison20080808",
            "slf12",
            "vison20080808",
            "slf12",
            "geng007",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2824,
        "title": "len(feed_target_names) 出错 ",
        "body": "运行NLP模型里面的对话理解预测脚本\r\n保存模型报feed_target_names 为None 没长度\r\n\r\nfeed_target_names = pred_results.get('feed_target_name', None)\r\n\r\n查看define_paradigm.py里面的\r\nresults = {\"probs\": probs, \"feed_targets_name\": feed_targets_name}\r\n\r\n\r\n这个里面的KEY值是不是错了？\r\n改成feed_targets_name就可以了",
        "state": "closed",
        "user": "lylyhs",
        "closed_by": "0YuanZhang0",
        "created_at": "2019-07-16T14:02:56+00:00",
        "updated_at": "2019-07-23T02:49:24+00:00",
        "closed_at": "2019-07-23T02:49:24+00:00",
        "comments_count": [
            "0YuanZhang0"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2825,
        "title": "dureader cannot open file ../data/saved_model/pn_decoder_random_attn_fc_w for load op at [/home/teamcity/work/...可是这个文件明明就有.",
        "body": "",
        "state": "open",
        "user": "miaohaa",
        "closed_by": null,
        "created_at": "2019-07-16T16:21:58+00:00",
        "updated_at": "2019-07-17T03:15:30+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2826,
        "title": "关于lexical_analysis在aistudio的一些问题",
        "body": "1.git clone过慢\r\n在aistudio下 git clone https://github.com/PaddlePaddle/models.git 基本在20%就不动了\r\n解决方案：本地下载后再当作数据集上传到aistudio中\r\n建议：把官方模型集成在aistudio中\r\n\r\n2.aistudio使用的是dash而不是bash\r\n所以 sh run.sh eval会报错：Syntax error: \"(\" unexpected\r\n并且aistudio不支持sudo,无法直接更改\r\n解决方案：bash run.sh eval\r\n建议：大多数Ubuntu系统都为dash，建议在文档中加一行注释\r\n\r\n3.选择gpu问题\r\n在run.sh 中CUDA_VISIBLE_DEVICES默认为2而aistudo只有一块gpu\r\n并且run_ernie.sh中CUDA_VISIBLE_DEVICES默认为0与run.sh不同\r\n解决方案：CUDA_VISIBLE_DEVICES=0\r\n建议：默认为0\r\n\r\n4.文件缺失\r\n在run_ernie.sh中有ERNIE_PRETRAINED_MODEL_PATH，而实际文件中不存在/pretrained/这个目录和ernie_config.json这个文件\r\n![image](https://user-images.githubusercontent.com/52971357/61311874-d60fdc80-a829-11e9-9b6a-8df08356d71a.png)\r\n![image](https://user-images.githubusercontent.com/52971357/61311914-ed4eca00-a829-11e9-8f1e-c9f6d6977ab0.png)\r\n\r\n5.python版本\r\n文档中说依赖于python2.7，实际上在python2.7中报错，python3.5中正常运行，建议每个项目都先写好环境要求\r\n\r\n",
        "state": "open",
        "user": "Zeno-Zou",
        "closed_by": null,
        "created_at": "2019-07-16T16:38:35+00:00",
        "updated_at": "2019-07-18T02:44:06+00:00",
        "closed_at": null,
        "comments_count": [
            "Halfish",
            "weiexcelpro",
            "Zeno-Zou",
            "Halfish"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2843,
        "title": "GPU training process killed",
        "body": "Hi, \r\n\r\nI've been trying to run ResNet50 training on GPU from `models\\PaddleCV\\image_classification\\train.py` with following command:\r\n```\r\ncudaid=${object_detection_cudaid:=0}\r\nexport CUDA_VISIBLE_DEVICES=$cudaid\r\n\r\npython train.py \\\r\n       --model=ResNet50 \\\r\n       --batch_size=4 \\\r\n       --class_dim=1000 \\\r\n       --image_shape=3,224,224 \\\r\n       --with_mem_opt=False \\\r\n       --use_gpu=True \\\r\n       --total_images=1281167 \\\r\n       --model_save_dir=output/ \\\r\n       --lr_strategy=piecewise_decay \\\r\n       --num_epochs=1 \\\r\n       --lr=0.1 \\\r\n       --data_dir=/root/data/ILSVRC2012\r\n```\r\nI've build PaddlePaddle from sources on `develop` branch inside Docker container. I used Dockerfile from top level directory in PaddlePaddle repository. It was build with GPU support. \r\n\r\nUnfortunately every time I'm trying to run training the process is killed:\r\n```\r\nPass 0, trainbatch 2010, loss 7.22243,                             acc1 0.00000, acc5 0.00000, lr 0.10000, time 0.22 sec\r\nPass 0, trainbatch 2020, loss 6.67906,                             acc1 0.00000, acc5 0.00000, lr 0.10000, time 0.20 sec\r\nPass 0, trainbatch 2030, loss 7.07748,                             acc1 0.00000, acc5 0.00000, lr 0.10000, time 0.22 sec\r\nPass 0, trainbatch 2040, loss 6.63177,                             acc1 0.00000, acc5 0.25000, lr 0.10000, time 0.26 sec\r\nPass 0, trainbatch 2050, loss 6.74798,                             acc1 0.00000, acc5 0.00000, lr 0.10000, time 0.22 sec\r\n./run_train.sh: line 21:  9815 Killed                  python train.py --model=ResNet50 --batch_size=4 --class_dim=1000 --image_shape=3,224,224 --with_mem_opt=False --use_gpu=True --total_images=1281167 --model_save_dir=output/ --lr_strategy=piecewise_decay --num_epochs=1 --lr=0.1 --l2_decay=1e-4 --data_dir=/root/data/ILSVRC2012\r\n```\r\n\r\nI've two 1080Ti with 10GB each. Every time maximum available memory is used. \r\n\r\nCan anyone help me why the training process may be stopped?",
        "state": "closed",
        "user": "arogowie-intel",
        "closed_by": "arogowie-intel",
        "created_at": "2019-07-17T15:04:33+00:00",
        "updated_at": "2021-03-19T08:42:14+00:00",
        "closed_at": "2021-03-19T08:42:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2829,
        "title": "请教2个问题: 关于冻结训练层和获取网络信息的功能",
        "body": "请教2个问题：\r\n1） 我们从预训练的模型中迁移学习时，需要在不同的训练阶段，冻结模型中的某些层，譬如先把特征提取层冻结设置为Trainable=False.  请问paddle中有相关函数吗？\r\n2）另外一个相关的问题是，冻结时可能会需要写明 层的名字， paddle是否有函数可以方便地打印出所有层的名称；另外冻结时是否支持 正在表达式 表示，以便设置一下子冻结多个层",
        "state": "closed",
        "user": "greatjinyun",
        "closed_by": "MRXLT",
        "created_at": "2019-07-17T06:08:23+00:00",
        "updated_at": "2019-07-31T08:46:31+00:00",
        "closed_at": "2019-07-31T08:46:31+00:00",
        "comments_count": [
            "MRXLT",
            "greatjinyun",
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2834,
        "title": "用Paddlepaddle训练的模型，用paddlehub推理时缺少module_desc.pb文件",
        "body": "用Paddlepaddle训练的模型，用paddlehub加载做推理时缺少module_desc.pb文件，有解决方法吗\r\n还是用paddlehub加载的模型必须用paddlehub训练?",
        "state": "closed",
        "user": "lambert-lan",
        "closed_by": "MRXLT",
        "created_at": "2019-07-17T08:57:24+00:00",
        "updated_at": "2019-07-18T02:51:38+00:00",
        "closed_at": "2019-07-18T02:50:42+00:00",
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2846,
        "title": "PaddeDetection里的YoloV3-MobileNetV3为什么模型有90多M",
        "body": "ssd_mobile一般有20多M,为什么Yolo这么大，通过save_inference保存策略是否能降低模型大小？",
        "state": "closed",
        "user": "universea",
        "closed_by": "universea",
        "created_at": "2019-07-18T03:13:49+00:00",
        "updated_at": "2019-07-18T05:56:54+00:00",
        "closed_at": "2019-07-18T05:56:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2835,
        "title": "fasterrcnn跑voc数据集",
        "body": "有人尝试过fasterrcnn在voc数据集训练嘛，训练的报显存不够了，但是在coco训练集下是可以的，是因为.yml配置不对导致的嘛",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "qingqing01",
        "created_at": "2019-07-17T08:58:29+00:00",
        "updated_at": "2019-07-26T02:12:42+00:00",
        "closed_at": "2019-07-26T02:12:42+00:00",
        "comments_count": [
            "qingqing01",
            "dbcool",
            "jerrywgz",
            "dbcool"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2836,
        "title": "Resnet 中 elementwise_add 的顺序影响显存大小？",
        "body": "使用 Resnet 训练分类模型，发现 `elementwise_add` layer 中变量`x` 和 `y` 的顺序会影响 10% 以上。\r\n\r\n```\r\nreturn fluid.layers.elementwise_add(x=short, y=conv2, act='relu',name=name+\".add.output.5\")\r\n\r\nreturn fluid.layers.elementwise_add(x=short, y=conv1, act='relu')\r\n\r\n```\r\n\r\n修改为：\r\n```\r\nreturn fluid.layers.elementwise_add(x=conv2, y=short, act='relu',name=name+\".add.output.5\")\r\n\r\nreturn fluid.layers.elementwise_add(x=conv2, y=short, act='relu')\r\n\r\n```\r\n\r\n显存占用从 5.3 G 降低到 4.8 G，请问是因为影响了显存复用导致的吗？\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61364542-a825a900-a8b8-11e9-92ef-90aa750f0d1d.png)\r\n\r\n[code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/resnet.py#L150-L173)",
        "state": "open",
        "user": "mzchtx",
        "closed_by": null,
        "created_at": "2019-07-17T09:36:07+00:00",
        "updated_at": "2019-07-19T02:12:55+00:00",
        "closed_at": null,
        "comments_count": [
            "liupluswei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2850,
        "title": "使用paddlepaddle的阅读理解功能，saved_model缺失文件问题",
        "body": "使用sh run.sh --evaluate  --load_dir ../data/saved_model --devset ../data/extracted/devset/zhidao.dev.json ../data/extracted/devset/search.dev.json 和 \r\nsh run.sh --predict  --load_dir  ../data/saved_model --testset ../data/extracted/testset/zhidao.test.json 进行预测时，加载模型时，出现问题\r\n\r\nCannot open file ../data/saved_model/pn_decoder_random_attn_fc_w for load op at [/paddle/paddle/fluid/operators/load_op.h:37]\r\nPaddlePaddle Call Stacks:",
        "state": "open",
        "user": "w279805299",
        "closed_by": null,
        "created_at": "2019-07-18T09:41:21+00:00",
        "updated_at": "2019-07-19T02:21:40+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2852,
        "title": "语言模型lm_lstm似乎只有PTB数据集的预训练版本，没有中文数据集的预训练模型？",
        "body": "",
        "state": "closed",
        "user": "jreros",
        "closed_by": "jreros",
        "created_at": "2019-07-18T20:06:10+00:00",
        "updated_at": "2019-07-23T11:39:10+00:00",
        "closed_at": "2019-07-19T15:09:10+00:00",
        "comments_count": [
            "kuke",
            "jreros",
            "jtyoui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2874,
        "title": "similarity",
        "body": "",
        "state": "closed",
        "user": "yw1991",
        "closed_by": "yw1991",
        "created_at": "2019-07-22T06:27:22+00:00",
        "updated_at": "2019-07-22T06:29:26+00:00",
        "closed_at": "2019-07-22T06:29:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2875,
        "title": "similarity",
        "body": "",
        "state": "closed",
        "user": "yw1991",
        "closed_by": "yw1991",
        "created_at": "2019-07-22T06:27:31+00:00",
        "updated_at": "2019-07-22T06:29:17+00:00",
        "closed_at": "2019-07-22T06:29:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2865,
        "title": "yolov3的python接口问题",
        "body": "用py3.6运行yolov3的train.py程序，提示\r\n![image](https://user-images.githubusercontent.com/48506731/61531665-1f467300-aa5a-11e9-8e7c-1ed5817ac409.png)，在PythonAPI路径下，\r\n![image](https://user-images.githubusercontent.com/48506731/61531730-4b61f400-aa5a-11e9-8b9a-c98355671a9e.png)\r\n根据makefile文件的提示，编译setup文件。会发现pycocotools里面的文件变多了，此时pycocotools里面的包才可以使用。\r\n\r\n然而！！！我换成了py352之后，又是同样报错！！！\r\n![image](https://user-images.githubusercontent.com/48506731/61531924-dcd16600-aa5a-11e9-8e58-e58eb1d73c74.png)\r\n简直不知道怎么处理这种细碎的问题！！！",
        "state": "closed",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": "AIaiAIaiAIaiAI",
        "created_at": "2019-07-19T11:25:26+00:00",
        "updated_at": "2019-07-27T03:33:07+00:00",
        "closed_at": "2019-07-27T03:33:07+00:00",
        "comments_count": [
            "heavengate",
            "AIaiAIaiAIaiAI",
            "heavengate",
            "AIaiAIaiAIaiAI",
            "AIaiAIaiAIaiAI",
            "heavengate",
            "AIaiAIaiAIaiAI",
            "heavengate",
            "AIaiAIaiAIaiAI",
            "heavengate",
            "AIaiAIaiAIaiAI"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2868,
        "title": "MobileNet-SSD 的 backbone 存在 bug",
        "body": "如下图1， 2中，`_extra_block` 函数调用的地方已经写死 `num_groups` 为 1，而 `scale` 参数为传入的，假设 `scale` < 1，比如 0.5 或者 0.25，则会出现调用 `self._conv_norm` 的时候 `num_groups` 为 0 的情况。\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61533480-a1856600-aa5f-11e9-821a-f29add347860.png)\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61533542-c679d900-aa5f-11e9-86e4-a2d895aa87d1.png)\r\n\r\n具体代码位于：\r\n[code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/ppdet/modeling/backbones/mobilenet.py#L122-L146) 和 [code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/ppdet/modeling/backbones/mobilenet.py#L188-L195)\r\n",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "qingqing01",
        "created_at": "2019-07-19T12:04:13+00:00",
        "updated_at": "2019-07-25T09:29:05+00:00",
        "closed_at": "2019-07-25T09:29:05+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2876,
        "title": "similarity-net这个模型具体怎么用？",
        "body": "",
        "state": "open",
        "user": "yw1991",
        "closed_by": null,
        "created_at": "2019-07-22T06:28:42+00:00",
        "updated_at": "2019-09-13T02:16:09+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "yw1991",
            "yw1991",
            "yw1991",
            "kuke",
            "yw1991",
            "qujinqiang",
            "zhangyimi",
            "yw1991",
            "Lizhengo",
            "xinaiwunai"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2889,
        "title": "文档缺失",
        "body": "在ocr的代码中有[fluid.evaluator.EditDistance](https://github.com/PaddlePaddle/models/blob/0bd09f6433ee934c415a2e2a7599eb9f1dc2cf11/PaddleCV/ocr_recognition/crnn_ctc_model.py#L194)，但是查阅文档的时候，只有[fluid.metrics.EditDistance](https://www.paddlepaddle.org.cn/documentation/docs/zh/1.5/api_cn/metrics_cn.html#editdistance)，看完文档后感觉这两个不是一个类，而且文档中找evaluator.EditDistance的时候是找不到的，可以在官网的docs中说明一下吗?\r\n还有文档中reset的用法没有说，就贴上来一个代码，看不懂什么意思啊\r\n![image](https://user-images.githubusercontent.com/16537232/61630900-82831000-acbb-11e9-864f-bb130a454ecf.png)\r\n",
        "state": "closed",
        "user": "char256",
        "closed_by": "gongweibao",
        "created_at": "2019-07-22T12:01:44+00:00",
        "updated_at": "2019-07-24T10:45:33+00:00",
        "closed_at": "2019-07-24T10:45:33+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2892,
        "title": "指定gpu,但是运行程序总是用另一个GPU",
        "body": "每次加载到就不动了，查看了下显卡，显示\r\n![TIM图片20190722204302](https://user-images.githubusercontent.com/48506731/61633269-510d4300-acc1-11e9-9cb5-30329a641f98.png)\r\n我指定了使用device 1，但是程序非要去使用device 0，如图\r\n[图片]\r\n![TIM图片20190722204016](https://user-images.githubusercontent.com/48506731/61633137-fe338b80-acc0-11e9-92b0-6105260e6372.png)\r\n然后立刻报内存不足的错误，\r\n仔细看了下，还有个问题，提示会复制一份文件，意思是两个GPU都跑同一个程序？这又是为啥？\r\n[图片]\r\n![4O@%NHKHYZH`2D_I19}{4RL](https://user-images.githubusercontent.com/48506731/61633213-2fac5700-acc1-11e9-871f-d9e591dc2423.png)\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": null,
        "created_at": "2019-07-22T12:44:44+00:00",
        "updated_at": "2019-07-27T04:01:57+00:00",
        "closed_at": null,
        "comments_count": [
            "AIaiAIaiAIaiAI",
            "kuke",
            "AIaiAIaiAIaiAI",
            "heavengate",
            "chengduoZH",
            "AIaiAIaiAIaiAI"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2893,
        "title": "PaddleDetection Infer.py run error",
        "body": "python tools/infer.py -c configs/yolov3_mobilenet_v1.yml --infer_img=demo/000000570688.jpg --save_inference_model\r\nW0722 20:50:18.140080  2945 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0722 20:50:18.190894  2945 device_context.cc:267] device: 0, cuDNN Version: 7.6.\r\n2019-07-22 20:50:18,213-INFO: Loading checkpoint from /home/airobot/models/PaddleCV/PaddleDetection/output/yolov3_mobilenet_v1/14000...\r\nTraceback (most recent call last):\r\n  File \"tools/infer.py\", line 257, in <module>\r\n    main()\r\n  File \"tools/infer.py\", line 167, in main\r\n    save_infer_model(FLAGS, exe, feed_vars, test_fetches, infer_prog)\r\n  File \"tools/infer.py\", line 113, in save_infer_model\r\n    feeded_var_names = prune_feed_vars(feeded_var_names, target_vars, infer_prog)\r\n  File \"tools/infer.py\", line 95, in prune_feed_vars\r\n    prog = prog._prune(targets=target_vars)\r\n  File \"/home/airobot/anaconda3/envs/paddlepaddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3236, in _prune\r\n    raise ValueError(\"All targets of prune() can only be \"\r\nValueError: All targets of prune() can only be Variable or Operator.\r\n",
        "state": "closed",
        "user": "universea",
        "closed_by": "gongweibao",
        "created_at": "2019-07-22T12:55:43+00:00",
        "updated_at": "2019-07-24T10:45:12+00:00",
        "closed_at": "2019-07-24T10:45:12+00:00",
        "comments_count": [
            "universea",
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2897,
        "title": "请问剪枝和量化后output（weight/model），怎么用呢？",
        "body": "",
        "state": "open",
        "user": "kayzss",
        "closed_by": null,
        "created_at": "2019-07-23T03:22:52+00:00",
        "updated_at": "2019-07-25T10:01:07+00:00",
        "closed_at": null,
        "comments_count": [
            "kayzss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2895,
        "title": "怎么把量化或剪枝后的output模型（weight&&model），转成TF模型或者txt等可读文件呢",
        "body": "",
        "state": "open",
        "user": "kayzss",
        "closed_by": "gongweibao",
        "created_at": "2019-07-23T01:52:53+00:00",
        "updated_at": "2019-07-26T00:03:29+00:00",
        "closed_at": null,
        "comments_count": [
            "kayzss",
            "gongweibao",
            "kayzss",
            "wanghaoshuang",
            "wanghaoshuang",
            "kayzss",
            "wanghaoshuang",
            "kayzss",
            "kayzss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2898,
        "title": "请问有小伙伴可以分享一下ImageNet数据集中的train_list.txt以及val_list.txt吗？ Could anybody  share train_list.txt and val_list.txt in the ImageNet dataset with me? THANKS!!!?",
        "body": "",
        "state": "closed",
        "user": "TCfirefly",
        "closed_by": "gongweibao",
        "created_at": "2019-07-23T04:15:52+00:00",
        "updated_at": "2019-07-24T10:38:24+00:00",
        "closed_at": "2019-07-24T10:38:24+00:00",
        "comments_count": [
            "kayzss",
            "TCfirefly",
            "kayzss",
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2899,
        "title": "language_model训练完了怎么使用计算一句话的PPL",
        "body": "",
        "state": "closed",
        "user": "jtyoui",
        "closed_by": "jtyoui",
        "created_at": "2019-07-23T07:51:23+00:00",
        "updated_at": "2020-09-20T03:24:38+00:00",
        "closed_at": "2020-09-20T03:24:38+00:00",
        "comments_count": [
            "phlrain",
            "jtyoui",
            "jtyoui",
            "phlrain",
            "jtyoui",
            "guoshengCS",
            "gezimonkey",
            "igfuns"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2902,
        "title": "lexical_analysis在python3环境f1基本为0，python2环境没问题",
        "body": "RT。\r\n用的P40，训练数据是自己生成的。",
        "state": "open",
        "user": "AltenLi",
        "closed_by": null,
        "created_at": "2019-07-23T09:59:56+00:00",
        "updated_at": "2019-07-24T10:28:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2901,
        "title": "paddle有没有类似TFRecord的数据格式",
        "body": "直接一次性加载结构化的数据，不需要在训练过程中解析。",
        "state": "closed",
        "user": "sshilei",
        "closed_by": "gongweibao",
        "created_at": "2019-07-23T09:26:53+00:00",
        "updated_at": "2019-07-23T11:29:25+00:00",
        "closed_at": "2019-07-23T11:29:25+00:00",
        "comments_count": [
            "gongweibao",
            "sshilei",
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2903,
        "title": "增量训练中添加optimizer后报错",
        "body": "` with fluid.program_guard(self.train_program, self.startup_program):\r\n            self.image = fluid.layers.data(name='image', shape=[3, 224, 224], dtype='float32')\r\n            self.label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n            # model definition ++++++++++++++++++++++++++++++++++++++++++\r\n            model = models.__dict__[model_name]()\r\n            out = model.net(input=self.image, class_dim=class_dim)  # 概率数组\r\n            #\r\n            cost, pred = fluid.layers.softmax_with_cross_entropy(\r\n                out,\r\n                self.label,\r\n                return_softmax=True\r\n            )\r\n\r\n            avg_cost = fluid.layers.mean(x=cost)\r\n            acc_top1 = fluid.layers.accuracy(input=pred,\r\n                                             label=self.label,\r\n                                             k=1)\r\n            acc_top5 = fluid.layers.accuracy(input=pred,\r\n                                             label=self.label,\r\n                                             k=5)\r\n            optimizer = fluid.optimizer.SGD(learning_rate=0.01)\r\n            optimizer.minimize(avg_cost)\r\n            self.parallel_program = compiler.CompiledProgram(self.train_program)\r\n            self.parallel_program.with_data_parallel(loss_name=avg_cost.name)\r\n            # load pretrained vars,load data to default main program\r\n            self.exe = fluid.Executor(self.exe_place)\r\n            fluid.io.load_persistables(\r\n                self.exe,\r\n                output_dir if self.mode == 'inference' else pretrain_dir,\r\n                main_program=self.startup_program\r\n            )\r\n`\r\n\r\n``\r\n       \r\n![image](https://user-images.githubusercontent.com/170311/61711063-c4788880-ad85-11e9-85b6-dadf662bbce8.png)\r\n",
        "state": "closed",
        "user": "leaf918",
        "closed_by": "gongweibao",
        "created_at": "2019-07-23T12:07:55+00:00",
        "updated_at": "2019-07-25T06:32:10+00:00",
        "closed_at": "2019-07-24T03:51:26+00:00",
        "comments_count": [
            "leaf918",
            "guoshengCS",
            "leaf918",
            "guoshengCS",
            "leaf918",
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2907,
        "title": "undefined symbol: mkldnn_primitive_desc_query_pd",
        "body": "centos7 安装paddle_gpu 1.5.1，之后运行paddle_video下的infer.py脚本，参数如下`python infer.py --model_name=CTCN --config=configs/ctcn.txt --log_interval=1 --filelist=./infer_videos/`，接着报错：\r\n![image](https://user-images.githubusercontent.com/15357846/61757956-523f8c80-adf5-11e9-8099-21a39364bbac.png)\r\n请问：是paddle环境没配置好吗？需要修改哪里？",
        "state": "open",
        "user": "dagongji10",
        "closed_by": null,
        "created_at": "2019-07-24T01:28:40+00:00",
        "updated_at": "2019-07-25T10:44:23+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2908,
        "title": "动态图多卡报 NCCL 错误",
        "body": "# 环境\r\n\r\n+ system: centos6u3\r\n+ python: 2.7.14\r\n+ paddle: 1.5.1.post97\r\n+ nccl: 2.2.13\r\n\r\n# 问题\r\n\r\n运行 resnet50 的动态图[示例](https://github.com/PaddlePaddle/models/tree/develop/dygraph/resnet)，单卡运行没问题，4卡运行报 NCCL 问题，如下图所示：\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61760803-4b1d7c00-adff-11e9-9fe7-65fee5134702.png)\r\n\r\n运行静态图的多卡训练没问题，请问动态图是对 NCCL 版本有要求吗？还是其他的问题？\r\n\r\n",
        "state": "open",
        "user": "mzchtx",
        "closed_by": null,
        "created_at": "2019-07-24T02:40:48+00:00",
        "updated_at": "2019-07-27T09:28:23+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang",
            "mzchtx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2909,
        "title": "FP16 训练 ResNet50，loss 为负数",
        "body": "# 环境\r\n\r\n+ system: centos6u3\r\n+ python: 2.7.14\r\n+ paddle: 1.5.1.post97\r\n+ nccl: 2.2.13\r\n\r\n# 问题\r\n\r\n使用 FP16 训练 ResNet50:\r\n\r\n如果在 fc layer 里加上 softmax 激活，然后使用 `cross_entropy` 损失，会出现几个 batch 后 loss 为负数的情况。如下：\r\n\r\n```python\r\nout = ResNet50().net(input=image, class_dim=class_dim)\r\ncost = fluid.layers.cross_entropy(input=out, label=label)\r\navg_cost = fluid.layers.mean(x=cost)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61769557-4071df80-ae1d-11e9-989e-28d5023db4be.png)\r\n\r\n\r\n如果在 fc layer 不加 softmax 激活，然后使用 `softmax_with_cross_entropy` 损失，则结果正常。如下：\r\n\r\n```python\r\nout = ResNet50().net(input=image, class_dim=class_dim)\r\ncost = fluid.layers.softmax_with_cross_entropy(input=out, label=label)\r\navg_cost = fluid.layers.mean(x=cost)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61769622-757e3200-ae1d-11e9-9a5c-718ebd007287.png)\r\n\r\n\r\n上述两种方式使用 fp32 进行训练都没问题。",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "gavin1332",
        "created_at": "2019-07-24T06:15:31+00:00",
        "updated_at": "2019-07-30T06:19:09+00:00",
        "closed_at": "2019-07-30T06:19:09+00:00",
        "comments_count": [
            "shippingwang",
            "gavin1332",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2910,
        "title": "FP16 训练 ResNet50 添加 label_smooth 报错",
        "body": "# 环境\r\n\r\n+ system: centos6u3\r\n+ python: 2.7.14\r\n+ paddle: 1.5.1.post97\r\n+ nccl: 2.2.13\r\n\r\n# 问题\r\n\r\n使用 FP16 训练 ResNet50，如果添加 `label_smooth` 则会报错，代码如下：\r\n\r\n```python\r\nout = ResNet50().net(input=image, class_dim=class_dim)\r\n\r\nepsilon = 0.1\r\none_hot_label = fluid.layers.one_hot(input=label, depth=class_dim)\r\nsmooth_label = fluid.layers.label_smooth(label=one_hot_label, epsilon=epsilon)\r\ncost = fluid.layers.softmax_with_cross_entropy(out, smooth_label, soft_label=True)\r\navg_cost = fluid.layers.mean(x=cost)\r\n```\r\n\r\n错误信息：\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/61770869-dfe4a180-ae20-11e9-8b90-7f275e9ee65e.png)\r\n\r\n去掉 `label_smooth` 正常：\r\n```python\r\nout = ResNet50().net(input=image, class_dim=class_dim)\r\ncost = fluid.layers.softmax_with_cross_entropy(out, label, soft_label=True)\r\navg_cost = fluid.layers.mean(x=cost)\r\n```\r\n",
        "state": "open",
        "user": "mzchtx",
        "closed_by": null,
        "created_at": "2019-07-24T06:40:56+00:00",
        "updated_at": "2019-08-02T08:44:02+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "guoshengCS",
            "mzchtx",
            "A1exy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2912,
        "title": "reading_comprehension模型预测报错",
        "body": "在用reading_comprehension模型进行预测时（按照官方文档操作），遇到如下错误：\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 652, in <module>\r\n    predict(logger, args)\r\n  File \"run.py\", line 575, in predict\r\n    exe, args.load_dir, main_program=main_program)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 701, in load_persistables\r\n    filename=filename)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 572, in load_vars\r\n    filename=filename)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 607, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 525, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 591, in _run\r\n    exe.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator load error.\r\nPython Callstacks:\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1317, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 593, in load_vars\r\n    attrs={'file_path': os.path.join(dirname, new_var.name)})\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 572, in load_vars\r\n    filename=filename)\r\n  File \"/var/c20732a/paddle/paddle_env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 701, in load_persistables\r\n    filename=filename)\r\n  File \"run.py\", line 575, in predict\r\n    exe, args.load_dir, main_program=main_program)\r\n  File \"run.py\", line 652, in <module>\r\n    predict(logger, args)\r\nC++ Callstacks:\r\nCannot open file ../data/saved_model/pn_decoder_random_attn_fc_w for load op at [/paddle/paddle/fluid/operators/load_op.cc:39]\r\n\r\n检查目录发现有pn_decoder:random_attn_fc_w这个文件。读取的模型文件是直接wget下来的并解压的，所以可能是在load模型文件时发生的错误。请帮忙看下如何解决。谢谢。\r\n（试了paddlepaddle 1.3.1, 1.5.0, 1.5.1 都是同样的错误）\r\n",
        "state": "open",
        "user": "AzureDreamDing",
        "closed_by": null,
        "created_at": "2019-07-24T09:44:35+00:00",
        "updated_at": "2019-07-30T07:48:06+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "AzureDreamDing",
            "AzureDreamDing",
            "xyzhou-puck",
            "AzureDreamDing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2918,
        "title": "ssd use_multiprocess设置为True后，训练过程会出现停止的情况",
        "body": "如题，环境AI STUDIO GPU:V100 16GB  CPU：32GB，'use_multiprocess', bool,  True时训练不到一个epoch就停止不动了，设置为False后读取变慢，但是不会出现停止假死的情况",
        "state": "closed",
        "user": "universea",
        "closed_by": "universea",
        "created_at": "2019-07-24T23:43:58+00:00",
        "updated_at": "2019-07-26T23:05:38+00:00",
        "closed_at": "2019-07-26T23:05:38+00:00",
        "comments_count": [
            "wanghaoshuang",
            "universea",
            "universea"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2919,
        "title": "利用训练好的SimNet-BOW-Pairwise语义匹配模型的问题",
        "body": "利用训练好的SimNet-BOW-Pairwise语义匹配模型进行短文本相似度计算效果很差，就是感觉就是单单的基于词向量进行匹配，和百度展示的实例要向相差很多，那这个意义是什么？",
        "state": "open",
        "user": "yw1991",
        "closed_by": null,
        "created_at": "2019-07-25T02:16:35+00:00",
        "updated_at": "2019-07-27T01:42:48+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "yw1991"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2920,
        "title": "PaddleDetection CPU模式下训练中断",
        "body": "loading annotations into memory...\r\nDone (t=12.66s)\r\ncreating index...\r\nindex created!\r\n2019-07-25 10:18:14,038-INFO: 118287 samples in file dataset/coco/annotations/instances_train2017.json\r\n2019-07-25 10:18:15,180-WARNING: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\n2019-07-25 10:18:15,841-INFO: Load model and fuse batch norm from https://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_cos_pretrained.tar...\r\n2019-07-25 10:18:15,848-INFO: Found /home/suyali/.cache/paddle/weights/ResNet50_cos_pretrained\r\nThe CPU_NUM is not specified, you should set CPU_NUM in the environment variable list, i.e export CPU_NUM=1. CPU_NUM indicates that how many CPUPlace are used in the current task.\r\n!!! The default number of CPUPlaces is 1.\r\n\r\nI0725 10:18:16.109668  2658 parallel_executor.cc:329] The number of CPUPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0725 10:18:16.152879  2658 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n2019-07-25 10:18:56,877-INFO: iter: 0, lr: 0.003333, b'loss_bbox': 0.050583, b'loss_rpn_cls': 0.693647, b'loss': 5.588, b'loss_rpn_bbox': 0.23873, b'loss_cls': 4.60504, time: 0.000\r\n2019-07-25 10:19:37,233-INFO: iter: 1, lr: 0.003347, b'loss_bbox': 0.121054, b'loss_rpn_cls': 0.692905, b'loss': 5.256546, b'loss_rpn_bbox': 0.213924, b'loss_cls': 4.228662, time: 40.777\r\n2019-07-25 10:20:17,638-INFO: iter: 2, lr: 0.003360, b'loss_bbox': 0.050583, b'loss_rpn_cls': 0.693647, b'loss': 4.925092, b'loss_rpn_bbox': 0.23873, b'loss_cls': 3.852284, time: 40.356\r\n浮点数例外 (核心已转储)\r\n\r\n无论是mask_rcnn_r50_1x.yml 还是faster_rcnn_r50_1x.yml，都出现这个问题.\r\n\r\n\r\n",
        "state": "closed",
        "user": "suyali",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-07-25T02:33:00+00:00",
        "updated_at": "2019-07-25T13:05:03+00:00",
        "closed_at": "2019-07-25T13:05:03+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2922,
        "title": "paddleSlim在压缩yolo3后遇到的问题",
        "body": "1.  我使用的是keras-yolo3的代码，之后使用 X2paddle 转换成了paddle的格式，并且经过测试，生成的paddle代码可以用来做预测，之后在压缩项目中对yolo3代码做出微调具体如下\r\n![图1](https://user-images.githubusercontent.com/49752023/61844504-41187d80-aed2-11e9-8b4b-740e9b955ab4.png)\r\n![2](https://user-images.githubusercontent.com/49752023/61844737-0bc05f80-aed3-11e9-95dd-6c4eb4454a9b.png)\r\n2.  压缩工程中 yolo3(paddle版本)的输出是：\r\n![A{3)UP@E UKJ)7Z~~@ P@E](https://user-images.githubusercontent.com/49752023/61844847-89846b00-aed3-11e9-889e-a5e9252cb04c.png)\r\n3. 取到压缩模型的地方\r\n![ER$(W2_%{7G{C9L)WB)64G4](https://user-images.githubusercontent.com/49752023/61844915-c94b5280-aed3-11e9-9cc0-5ad4b62d37f2.png)\r\n![V2BKZTHHBO@(% N8ASLZ%L4](https://user-images.githubusercontent.com/49752023/61844922-ccded980-aed3-11e9-984a-1441e0dc538a.png)\r\n4. 加载压缩模型对应的输出信息\r\n![ZYJFRUP` FF~XW7W_3`ETZ6](https://user-images.githubusercontent.com/49752023/61844948-eb44d500-aed3-11e9-9b0f-2e011532468d.png)\r\n5. 疑问：压缩前后，模型的输出，怎么会有差异呢？！望各位大佬们能给出一定的指导。。\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "FocueAI",
        "closed_by": "FocueAI",
        "created_at": "2019-07-25T04:07:17+00:00",
        "updated_at": "2024-10-23T01:43:45+00:00",
        "closed_at": "2024-10-23T01:43:45+00:00",
        "comments_count": [
            "Yipeng-Sun",
            "FocueAI",
            "FocueAI",
            "wanghaoshuang",
            "FocueAI"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2924,
        "title": "PaddleDetection: when i use CPU running infer, there occured an error as follow",
        "body": "my command: python tools/infer.py -c configs/faster_rcnn_r50_1x.yml --infer_img=demo/000000570688.jpg   --save_inference_model\r\nerror: \r\n2019-07-25 15:43:24,798-INFO: Loading checkpoint from output/faster_rcnn_r50_1x...\r\nTraceback (most recent call last):\r\n  File \"tools/infer.py\", line 257, in <module>\r\n    main()\r\n  File \"tools/infer.py\", line 167, in main\r\n    save_infer_model(FLAGS, exe, feed_vars, test_fetches, infer_prog)\r\n  File \"tools/infer.py\", line 113, in save_infer_model\r\n    feeded_var_names = prune_feed_vars(feeded_var_names, target_vars, infer_prog)\r\n  File \"tools/infer.py\", line 95, in prune_feed_vars\r\n    prog = prog._prune(targets=target_vars)\r\n  File \"/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3236, in _prune\r\n    raise ValueError(\"All targets of prune() can only be \"\r\nValueError: All targets of prune() can only be Variable or Operator.\r\nCan anyone help me please?",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-07-25T07:50:47+00:00",
        "updated_at": "2019-07-26T03:51:16+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "jerrywgz",
            "endy-see",
            "endy-see"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2927,
        "title": "fix lexical_analysis infer error python3",
        "body": "python3的infer报错",
        "state": "open",
        "user": "qqraise",
        "closed_by": null,
        "created_at": "2019-07-25T08:32:17+00:00",
        "updated_at": "2019-07-25T09:46:00+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "qqraise"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2930,
        "title": "video nextvlad pretrained error",
        "body": "load model zoo中训练好的NeXtVlad模型报错：    \r\nfluid.io.load_params(exe, pretrain, main_program=prog)\r\n  File \"train.py\", line 192, in train\r\n    train_model.load_pretrain_params(exe, pretrain, train_prog, place)\r\n  File \"train.py\", line 294, in <module>\r\n    train(args)\r\nC++ Callstacks: \r\nCannot open file pretrained_model/nextvlad_youtube8m/eigen_param for load op at [/paddle/paddle/fluid/operators/load_op.h:37]\r\n在文件夹中查看下载下来的预训练模型没有eigen_param文件",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-07-25T09:25:03+00:00",
        "updated_at": "2020-04-01T08:27:39+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "wwjjy",
            "SunGaofeng",
            "sportzhang",
            "ucas010"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2932,
        "title": "wget命令在cmd界面执行需要下载特定软件",
        "body": "rt",
        "state": "open",
        "user": "BertramRay",
        "closed_by": null,
        "created_at": "2019-07-25T12:40:14+00:00",
        "updated_at": "2019-07-25T12:41:08+00:00",
        "closed_at": null,
        "comments_count": [
            "BertramRay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2931,
        "title": "修改run.sh和senta-config.json时需要注意的问题",
        "body": "•修改run.sh和senta_config.json中的配置（使用预训练模型）（**注意区别**）\r\n\r\n**•run.sh脚本修改如下：**\r\n\r\n•MODEL_PATH=./senta_model/bilstm_model/\r\n\r\n**•# 在eval()函数中，修改如下参数：**\r\n\r\n•--vocab_path ${MODEL_PATH}/word_dict.txt\\\r\n\r\n•--init_checkpoint ${MODEL_PATH}/params\\\r\n\r\n**•senta_config.json中需要修改如下：**\r\n\r\n•\"vocab_size\": 1256606",
        "state": "open",
        "user": "BertramRay",
        "closed_by": null,
        "created_at": "2019-07-25T12:37:46+00:00",
        "updated_at": "2019-07-28T12:51:37+00:00",
        "closed_at": null,
        "comments_count": [
            "sunyh214"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2936,
        "title": " Invoke operator conv2d error.",
        "body": "docker+Paddle+YOLOv3。Paddle为：latest-gpu-cuda9.0-cudnn7。\r\n应该是cudnn的问题，请问怎么解决\r\n======\r\nssh://root@127.0.0.1:8022/usr/bin/python -u /project/PaddleCV/yolov3/infer.py --data_dir=/dataset/coco --dataset=coco2017 --weights=./weights/yolov3 --image_path=/dataset/coco/val2017/ --image_name=000000000139.jpg\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 8\r\nclass_num: 80\r\ndata_dir: /dataset/coco\r\ndataset: coco2017\r\ndebug: False\r\ndraw_thresh: 0.5\r\nimage_name: 000000000139.jpg\r\nimage_path: /dataset/coco/val2017/\r\ninput_size: 608\r\nlabel_smooth: True\r\nlearning_rate: 0.001\r\nmax_iter: 500200\r\nmodel_save_dir: checkpoints\r\nnms_posk: 100\r\nnms_thresh: 0.45\r\nnms_topk: 400\r\nno_mixup_iter: 40000\r\npretrain: weights/darknet53\r\nrandom_shape: True\r\nsnapshot_iter: 2000\r\nstart_iter: 0\r\nuse_gpu: True\r\nuse_multiprocess: True\r\nvalid_thresh: 0.005\r\nweights: ./weights/yolov3\r\n------------------------------------------------\r\nW0726 03:05:00.758013   994 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0726 03:05:00.760088   994 device_context.cc:267] device: 0, cuDNN Version: 7.4.\r\nloading annotations into memory...\r\nDone (t=0.39s)\r\ncreating index...\r\nindex created!\r\nLoad in 80 categories.\r\nAn exception was thrown!\r\n Invoke operator conv2d error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1773, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 2194, in conv2d\r\n    'fuse_relu_before_depthwise_conv': False\r\n  File \"/project/PaddleCV/yolov3/models/darknet.py\", line 37, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/project/PaddleCV/yolov3/models/darknet.py\", line 98, in add_DarkNet53_conv_body\r\n    name=\"yolo_input\")\r\n  File \"/project/PaddleCV/yolov3/models/yolov3.py\", line 110, in build_model\r\n    blocks = add_DarkNet53_conv_body(self.image, not self.is_train)\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 36, in infer\r\n    model.build_model()\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 85, in <module>\r\n    infer()\r\nC++ Callstacks: \r\nCUDNN_STATUS_EXECUTION_FAILED at [/paddle/paddle/fluid/operators/conv_cudnn_op.cu.cc:145]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6754be5978p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f6754be5cc7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f67550ece9ep paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 2382\r\n3       0x7f67550ed333p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7f6756c3a5abp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 411\r\n5       0x7f6756c3aba1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n6       0x7f6756c37f1cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n7       0x7f6754d71f1ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 398\r\n8       0x7f6754d74f6fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n9       0x7f6754bd6b3dp\r\n10      0x7f6754c182c6p\r\n11            0x4c5326p PyEval_EvalFrameEx + 37958\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n18            0x4c141fp PyEval_EvalFrameEx + 21823\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4eb69fp\r\n21            0x4e58f2p PyRun_FileExFlags + 130\r\n22            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n23            0x4938cep Py_Main + 1358\r\n24      0x7f67b9199830p __libc_start_main + 240\r\n25            0x493299p _start + 41\r\n\r\nTraceback (most recent call last):\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 85, in <module>\r\n    infer()\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 69, in infer\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 644, in run\r\n    raise e\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator conv2d error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1773, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 2194, in conv2d\r\n    'fuse_relu_before_depthwise_conv': False\r\n  File \"/project/PaddleCV/yolov3/models/darknet.py\", line 37, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/project/PaddleCV/yolov3/models/darknet.py\", line 98, in add_DarkNet53_conv_body\r\n    name=\"yolo_input\")\r\n  File \"/project/PaddleCV/yolov3/models/yolov3.py\", line 110, in build_model\r\n    blocks = add_DarkNet53_conv_body(self.image, not self.is_train)\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 36, in infer\r\n    model.build_model()\r\n  File \"/project/PaddleCV/yolov3/infer.py\", line 85, in <module>\r\n    infer()\r\nC++ Callstacks: \r\nCUDNN_STATUS_EXECUTION_FAILED at [/paddle/paddle/fluid/operators/conv_cudnn_op.cu.cc:145]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6754be5978p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f6754be5cc7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f67550ece9ep paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 2382\r\n3       0x7f67550ed333p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7f6756c3a5abp paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 411\r\n5       0x7f6756c3aba1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n6       0x7f6756c37f1cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n7       0x7f6754d71f1ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 398\r\n8       0x7f6754d74f6fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n9       0x7f6754bd6b3dp\r\n10      0x7f6754c182c6p\r\n11            0x4c5326p PyEval_EvalFrameEx + 37958\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n18            0x4c141fp PyEval_EvalFrameEx + 21823\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4eb69fp\r\n21            0x4e58f2p PyRun_FileExFlags + 130\r\n22            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n23            0x4938cep Py_Main + 1358\r\n24      0x7f67b9199830p __libc_start_main + 240\r\n25            0x493299p _start + 41\r\n\r\n\r\nProcess finished with exit code 1\r\n",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-07-26T03:05:32+00:00",
        "updated_at": "2019-07-29T07:27:22+00:00",
        "closed_at": null,
        "comments_count": [
            "mozpp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2934,
        "title": "Invoke operator conv2d error",
        "body": "程序运行时报错,yolov3+darknet的实验,paddle1.5.0.\r\n\r\n```\r\nWARNING: 07-25 22:05:29: compiler.py:239 * 140666825238272 \r\nYou can try our memory optimize feature to save your memory usage:\r\n# create a build_strategy variable to set memory optimize option\r\nbuild_strategy = compiler.BuildStrategy()\r\nbuild_strategy.enable_inplace = True\r\nbuild_strategy.memory_optimize = True\r\n\r\n# pass the build_strategy to with_data_parallel API\r\ncompiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\nloss_name=loss.name, build_strategy=build_strategy)\r\n\r\n!!! Memory optimize is our experimental feature !!!\r\nsome variables may be removed/reused internal to save memory usage, \r\nin order to fetch the right value of the fetch_list, please set the \r\npersistable property to true for each variable in fetch_list\r\n\r\n# Sample\r\nconv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n# if you need to fetch conv1, then:\r\nconv1.persistable = True\r\n\r\n\r\nW0725 22:05:30.738020 25347 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0725 22:05:30.740799 25347 device_context.cc:267] device: 0, cuDNN Version: 7.0.\r\nW0725 22:05:30.740815 25347 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nINFO: 07-25 22:05:35: checkpoint.py:58 * 140666825238272 Loading pretrained model from ./thirdparty/pretrain_models/ppdet/DarkNet53_pretrained/...\r\nI0725 22:05:36.072645 25347 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 8. And the Program will be copied 8 copies\r\nI0725 22:05:39.439227 25347 build_strategy.cc:329] set enable_sequential_execution:1\r\nI0725 22:05:39.817229 25347 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\ngo into aiflow reader.py...\r\nuse visreader as now!!!\r\nINFO: 07-25 22:05:47: reader.py:131 * 140485943351040 connect to filesystem[afs://tianqi.afs.baidu.com:9902]\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 63, in <module>\r\ntrainmain()\r\nFile \"train.py\", line 58, in trainmain\r\ntrain.main()\r\nFile \"thirdparty/paddlemodels/PaddleDetection/tools/train_aiflow_yolov3.py\", line 217, in main\r\ntrainmain(FLAGS)\r\nFile \"thirdparty/paddlemodels/PaddleDetection/tools/train_aiflow_yolov3.py\", line 182, in trainmain\r\nouts = exe.run(train_compile_program, fetch_list=train_values)\r\nFile \"/home/slurm/job/tmp/job-12703/python27-gcc482/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 665, in run\r\nreturn_numpy=return_numpy)\r\nFile \"/home/slurm/job/tmp/job-12703/python27-gcc482/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel\r\nexe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator conv2d error.\r\nPython Callstacks: \r\nFile \"/home/slurm/job/tmp/job-12703/python27-gcc482/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\nattrs=kwargs.get(\"attrs\", None))\r\nFile \"/home/slurm/job/tmp/job-12703/python27-gcc482/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\nreturn self.main_program.current_block().append_op(*args, **kwargs)\r\nFile \"/home/slurm/job/tmp/job-12703/python27-gcc482/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 2171, in conv2d\r\n'fuse_relu_before_depthwise_conv': False\r\nFile \"thirdparty/paddlemodels/PaddleDetection/ppdet/modeling/backbones/darknet.py\", line 63, in _conv_norm\r\nbias_attr=False)\r\nFile \"thirdparty/paddlemodels/PaddleDetection/ppdet/modeling/backbones/darknet.py\", line 145, in __call__\r\nname=\"yolo_input\")\r\nFile \"thirdparty/paddlemodels/PaddleDetection/ppdet/modeling/architectures/yolov3.py\", line 46, in build\r\nbody_feats = self.backbone(im)\r\nFile \"thirdparty/paddlemodels/PaddleDetection/ppdet/modeling/architectures/yolov3.py\", line 66, in train\r\nreturn self.build(feed_vars, mode='train')\r\nFile \"thirdparty/paddlemodels/PaddleDetection/tools/train_aiflow_yolov3.py\", line 109, in trainmain\r\ntrain_fetches = model.train(feed_vars)\r\nFile \"thirdparty/paddlemodels/PaddleDetection/tools/train_aiflow_yolov3.py\", line 217, in main\r\ntrainmain(FLAGS)\r\nFile \"train.py\", line 58, in trainmain\r\ntrain.main()\r\nFile \"train.py\", line 63, in <module>\r\ntrainmain()\r\nC++ Callstacks: \r\nCUDNN_STATUS_INTERNAL_ERROR at [/paddle/paddle/fluid/platform/device_context.cc:217]\r\nPaddlePaddle Call Stacks: \r\n0 0x7fef2855a6a0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1 0x7fef2855aa19p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2 0x7fef2a52dd14p paddle::platform::CudnnHolder::CudnnHolder(CUstream_st* const*, paddle::platform::CUDAPlace const&) + 996\r\n3 0x7fef2a52dfe0p\r\n4 0x7fef8b832973p pthread_once + 83\r\n5 0x7fef2a52d25bp paddle::platform::CUDADeviceContext::cudnn_holder() const + 91\r\n6 0x7fef2a52d289p paddle::platform::CUDADeviceContext::cudnn_handle() const + 9\r\n7 0x7fef2897519cp paddle::platform::CanCUDNNBeUsed(paddle::framework::ExecutionContext const&) + 204\r\n8 0x7fef2897111bp paddle::operators::ConvOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 219\r\n9 0x7fef2a4b58fbp paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&, paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 235\r\n10 0x7fef2a4b7a68p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 728\r\n11 0x7fef2a4b7ce1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n12 0x7fef2a4b52dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n13 0x7fef2a2b1a2ap paddle::framework::details::ComputationOpHandle::RunImpl() + 250\r\n14 0x7fef2a2a43d0p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n15 0x7fef2a285746p paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*) + 310\r\n16 0x7fef2a2843afp paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*) + 47\r\n17 0x7fef2a28476fp\r\n18 0x7fef2878eb43p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n19 0x7fef28625787p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n20 0x7fef8b832973p pthread_once + 83\r\n21 0x7fef2a27fdf2p\r\n22 0x7fef28626d04p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n23 0x7fef7a4b88a0p\r\n24 0x7fef8b82d1c3p\r\n25 0x7fef8ae5512dp clone + 109\r\n```\r\n",
        "state": "open",
        "user": "littletomatodonkey",
        "closed_by": null,
        "created_at": "2019-07-25T14:10:50+00:00",
        "updated_at": "2019-07-26T02:11:12+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2937,
        "title": "Test VOC dataset error",
        "body": "I run PaddleDetection's faster_rcnn_r50_fpn_2x on my own dataset of VOC format success, but there occured an error when i run infer.py , the error as follows:\r\nTraceback (most recent call last):\r\n  File \"tools/eval.py\", line 119, in <module>\r\n    main()\r\n  File \"tools/eval.py\", line 107, in main\r\n    eval_results(results, eval_feed, cfg.metric, resolution, FLAGS.output_file)\r\n  File \"/home/zhaoyanmei/models/PaddleCV/PaddleDetection/ppdet/utils/eval_utils.py\", line 114, in eval_results\r\n    res = np.mean(results[-1]['accum_map'][0])\r\nKeyError: 'accum_map'\r\n\r\nCan anyone help me please?",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-07-26T04:01:10+00:00",
        "updated_at": "2019-07-26T07:13:36+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn",
            "endy-see",
            "qingqing01",
            "endy-see"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2940,
        "title": "sentiment_classification 报错  no CUDA-capable device is detected at [/paddle/paddle/fluid/platform/gpu_info.cc:97]",
        "body": "paddle版本： paddlepaddle-gpu    1.5.1.post97　（注：GPU版按照官网进行测试，提示正常）\r\npython版本：２.７\r\n相关错误摘要：\r\nW0726 16:44:50.211505 71262 init.cc:128] Compiled with WITH_GPU, but no GPU found in runtime.\r\n\r\ncudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCount: no CUDA-capable device is detected at [/paddle/paddle/fluid/platform/gpu_info.cc:97]",
        "state": "open",
        "user": "qujinqiang",
        "closed_by": null,
        "created_at": "2019-07-26T08:50:24+00:00",
        "updated_at": "2019-08-02T06:44:46+00:00",
        "closed_at": null,
        "comments_count": [
            "BertramRay",
            "qujinqiang",
            "qujinqiang",
            "zhengya01",
            "qujinqiang",
            "zhengya01",
            "qujinqiang",
            "zhengya01",
            "qujinqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2942,
        "title": "可以分享metric_learning训练好的模型吗？",
        "body": "单卡训练，充其量就是70%左右的top1的recall，不知道是不是和这个有关系？",
        "state": "open",
        "user": "hectorgui",
        "closed_by": null,
        "created_at": "2019-07-26T11:10:44+00:00",
        "updated_at": "2019-07-26T11:14:31+00:00",
        "closed_at": null,
        "comments_count": [
            "hectorgui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2946,
        "title": "sh run.sh",
        "body": "",
        "state": "closed",
        "user": "sunyh214",
        "closed_by": "sunyh214",
        "created_at": "2019-07-28T12:42:17+00:00",
        "updated_at": "2019-07-28T12:54:32+00:00",
        "closed_at": "2019-07-28T12:54:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2949,
        "title": "模型的预加载与删除",
        "body": "Hello:有类似于tensorflow那样的先预加载模型，然后根据需要剔除部分网络层的预加载，再进行训练的函数吗！？最好能给一下示例，谢谢！",
        "state": "closed",
        "user": "suyali",
        "closed_by": "suyali",
        "created_at": "2019-07-29T02:46:09+00:00",
        "updated_at": "2019-07-29T06:14:58+00:00",
        "closed_at": "2019-07-29T06:14:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2943,
        "title": "在运行paddlenlp下面的sentiment_classification下的run_ernie时报gpu错误",
        "body": "![image](https://user-images.githubusercontent.com/21213333/61991903-75826a00-b089-11e9-83ac-0554fade9b5a.png)\r\n",
        "state": "closed",
        "user": "yw1991",
        "closed_by": "yw1991",
        "created_at": "2019-07-27T08:13:34+00:00",
        "updated_at": "2019-07-27T22:27:20+00:00",
        "closed_at": "2019-07-27T22:27:20+00:00",
        "comments_count": [
            "yw1991"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2944,
        "title": "yolov3模型和自己训练出的结果不一样是为何？",
        "body": "用官网提供的训练好的yolov模型，自己也训练了一遍yolov3.分别将两个模型用来执行eval.py程序，发现结果不一样，没有官方给出的模型效果好。\r\n[图片]\r\n![TIM图片20190727164023](https://user-images.githubusercontent.com/48506731/61992162-453cca80-b08d-11e9-9eb5-c23221b49044.png)\r\n\r\n而且，执行infer.py的时候，得到的结果自然也是没有官方给出的模型效果好。自己的训练的结果，无法识别出这么大的熊！！！\r\n![TIM图片20190727164145](https://user-images.githubusercontent.com/48506731/61992176-7a491d00-b08d-11e9-80e7-9b2a4bb44147.png)官网的模型结果就可以\r\n\r\n![TIM图片20190727164245](https://user-images.githubusercontent.com/48506731/61992185-98168200-b08d-11e9-938f-26b52803b380.png)\r\n以下几个也是\r\n![TIM图片20190727164348](https://user-images.githubusercontent.com/48506731/61992214-f6436500-b08d-11e9-8231-8a8ec7d2c849.png)\r\n![TIM图片20190727164351](https://user-images.githubusercontent.com/48506731/61992219-f9d6ec00-b08d-11e9-8a6b-3b64e48db0d2.png)\r\n![TIM图片20190727164505](https://user-images.githubusercontent.com/48506731/61992222-fa6f8280-b08d-11e9-8972-abdc7165f25d.png)\r\n![TIM图片20190727164502](https://user-images.githubusercontent.com/48506731/61992221-fa6f8280-b08d-11e9-84ed-83a089a3bc54.png)\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": null,
        "created_at": "2019-07-27T08:49:37+00:00",
        "updated_at": "2019-07-29T13:29:46+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "AIaiAIaiAIaiAI"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2947,
        "title": "解析模型时报错了",
        "body": "/sentiment_classification/config.py\", line 27, in _parse     config_path) OSError: Error in parsing bert model config file './senta_config.json'\r\n\r\n是不是因为python3的原因，不知怎么处理？",
        "state": "open",
        "user": "sunyh214",
        "closed_by": null,
        "created_at": "2019-07-28T13:41:17+00:00",
        "updated_at": "2019-07-29T12:27:44+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2951,
        "title": "PaddleDetection train.py:设置resume_checkpoint",
        "body": "加载预训练模型时：设置resume_checkpoint为home/user/.cache/paddle/weightd/ResNet50_cos_pretrained/报错：\r\npaddle.fluid.core_avx.EnforceNotMet:Invoke operator load error\r\n\r\nCannot open file home/user/.cache/paddle/weightd/ResNet50_cos_pretrained/conv_rpn_w for load op at [/paddle/paddle/fluid/operators/load_op.h]",
        "state": "closed",
        "user": "suyali",
        "closed_by": "heavengate",
        "created_at": "2019-07-29T03:47:52+00:00",
        "updated_at": "2019-07-30T04:02:05+00:00",
        "closed_at": "2019-07-30T04:02:05+00:00",
        "comments_count": [
            "suyali",
            "JiaXiao243",
            "xiegegege",
            "suyali",
            "suyali",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2957,
        "title": "请问，NLG自动文本生成这块，可以再添加两个demo样例吗",
        "body": "请问，NLG自动文本生成这块，可以再添加两个demo样例吗",
        "state": "open",
        "user": "cucumberpieces",
        "closed_by": null,
        "created_at": "2019-07-29T09:30:31+00:00",
        "updated_at": "2019-10-23T06:07:35+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "cucumberpieces",
            "cucumberpieces",
            "kuke",
            "xyzhou-puck",
            "cucumberpieces"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2952,
        "title": "请问，这个参数是做什么的呢？什么意思呢？parser.add_argument('--enable_ce', action='store_true', help='If set, run the task with continuous evaluation logs.')",
        "body": "",
        "state": "open",
        "user": "fengbecky",
        "closed_by": null,
        "created_at": "2019-07-29T05:32:56+00:00",
        "updated_at": "2019-07-31T08:11:56+00:00",
        "closed_at": null,
        "comments_count": [
            "xiegegege",
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2959,
        "title": "关于lstm输出维度",
        "body": "        init_h1 = fluid.layers.fill_constant([num_layers*2, batch_size, hidden_size], 'float32', 0.0)\r\n        init_c1 = fluid.layers.fill_constant([num_layers*2, batch_size, hidden_size], 'float32', 0.0)\r\n        print(\"bi-lstm1 input shape\", input.shape)\r\n        output1, last_h1, last_c1 = fluid.layers.lstm(input=input, init_h=init_h1, init_c=init_c1,\r\n                                                      max_len=max_len, hidden_size=hidden_size, num_layers=num_layers,\r\n                                                      is_bidirec=True)\r\n        print(\"bi-lstm1 output shape\", output1.shape)\r\n\r\n        output1 = fluid.layers.transpose(output1, [1, 0, 2])  # B T C\r\n        output1 = fluid.layers.fc(output1, self.hidden_size, num_flatten_dims=2)\r\n        output1 = fluid.layers.transpose(output1, [1, 0, 2])  # T B C\r\n\r\n        init_h2 = fluid.layers.fill_constant([num_layers*2, batch_size, hidden_size], 'float32', 0.0)\r\n        init_c2 = fluid.layers.fill_constant([num_layers*2, batch_size, hidden_size], 'float32', 0.0)\r\n        print(\"bi-lstm2 input shape\", output1.shape)\r\n        output2, last_h2, last_c2 = fluid.layers.lstm(input=output1, init_h=init_h2, init_c=init_c2,\r\n                                                      max_len=max_len, hidden_size=hidden_size, num_layers=num_layers,\r\n                                                      is_bidirec=True)\r\n        print(\"bi-lstm2 output shape\", output2.shape)\r\n输出：\r\nbi-lstm1 input shape (26, -1, 512)\r\nbi-lstm1 output shape (26, -1, 512)\r\nbi-lstm2 input shape (26, -1, 444)\r\nbi-lstm2 output shape (26, -1, 444)\r\n我发现lstm的输出是和输入维度一样的，hidden_size没有影响，是我代码写的有问题吗？",
        "state": "open",
        "user": "fengchun1213",
        "closed_by": null,
        "created_at": "2019-07-29T10:31:02+00:00",
        "updated_at": "2019-07-30T09:01:09+00:00",
        "closed_at": null,
        "comments_count": [
            "sneaxiy",
            "fengchun1213"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2958,
        "title": "训练的时候发现这个问题，同样的数据，同样的代码，时而出错，时而正常运行",
        "body": "![image](https://user-images.githubusercontent.com/5461637/62037966-65a08c80-b227-11e9-8cee-86c86a812206.png)\r\n",
        "state": "open",
        "user": "yxzero",
        "closed_by": null,
        "created_at": "2019-07-29T09:37:15+00:00",
        "updated_at": "2019-07-29T11:05:28+00:00",
        "closed_at": null,
        "comments_count": [
            "sneaxiy",
            "yxzero",
            "sneaxiy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2963,
        "title": "Cannot malloc 6652.83 MB GPU memory",
        "body": "When i try to infer many images in a dir, it occured follow problem:\r\nCannot malloc 6652.83 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use or FLAGS_initial_gpu_memory_in_mb or FLAGS_reallocate_gpu_memory_in_mbenvironment variable to a lower value. Current FLAGS_fraction_of_gpu_memory_to_use value is 0.92. Current FLAGS_initial_gpu_memory_in_mb value is 0. Current FLAGS_reallocate_gpu_memory_in_mb value is 0\r\nF0729 21:37:01.823541 108811 legacy_allocator.cc:201] Cannot allocate 112.500000MB in GPU 0, available 632.937500MBtotal 7981694976GpuMinChunkSize 256.000000BGpuMaxChunkSize 6.496908GBGPU memory used: 6.412701GB\r\n\r\nI also try to use multi-gpu to do infer, bu still appear this problem",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2019-07-29T13:42:54+00:00",
        "updated_at": "2019-07-31T03:29:03+00:00",
        "closed_at": "2019-07-29T13:49:22+00:00",
        "comments_count": [
            "endy-see",
            "parap1uie-s"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2960,
        "title": "gpu并行训练时batch_size设置问题",
        "body": "reader在yield数据时，要求batch_size必须能够整除gpu_num。但是却没有加断言，建议作者加入断言。",
        "state": "closed",
        "user": "904281665",
        "closed_by": "heavengate",
        "created_at": "2019-07-29T12:19:27+00:00",
        "updated_at": "2019-07-30T08:57:02+00:00",
        "closed_at": "2019-07-30T08:57:02+00:00",
        "comments_count": [
            "heavengate",
            "904281665",
            "heavengate",
            "904281665",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2966,
        "title": "image classification MobileNet V2开启mixup一直报AssertError",
        "body": "PaddleCV里的image_classification中采用MobileNetV2_x0_5 开启mixup后一直报AssertError：\r\n![image](https://user-images.githubusercontent.com/7035538/62105291-95f23480-b2d4-11e9-9725-322548571c5e.png)\r\n",
        "state": "open",
        "user": "A1exy",
        "closed_by": null,
        "created_at": "2019-07-30T06:17:22+00:00",
        "updated_at": "2019-08-31T11:10:45+00:00",
        "closed_at": null,
        "comments_count": [
            "A1exy",
            "lixiangchun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2964,
        "title": "[detection evaluatation] compute AP for each class",
        "body": "Paddle affords a very simple layer(DetectionMAP) to compute mAP for the evaluation of detection. eg. https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/ssd/eval.py#L55\r\n\r\nHowever, is there any advice for the computation for AP of each category? ",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "zzchust",
        "created_at": "2019-07-29T14:12:21+00:00",
        "updated_at": "2019-07-29T14:26:27+00:00",
        "closed_at": "2019-07-29T14:26:27+00:00",
        "comments_count": [
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2968,
        "title": "similarity_net 运行报错",
        "body": "环境：\r\npython：2.7.15\r\npaddle：1.5\r\ncuda：9\r\ncudnn：7\r\ngpu：v100\r\n\r\n命令：\r\npython run_classifier.py  --compute_accuracy False --valid_data_dir ./data/test_pairwise_data --task_name simnet --config_path ./config/bow_pairwise.json --do_train True --do_valid False --vocab_path ./data/term2id.dict --do_infer False --save_steps 1000 --batch_size 128 --use_cuda True --train_data_dir ./data/train_pairwise_data --epoch 1 --skip_steps 10 --output_dir output_1 --test_data_dir ./data/test_pairwise_data --verbose_result False --infer_data_dir ./data/infer_data --task_mode pairwise --validation_steps 100 --do_test True\r\n\r\n报错：\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 471, in <module>\r\n    main(conf_dict, args)\r\n  File \"run_classifier.py\", line 448, in main\r\n    train(conf_dict, args)\r\n  File \"run_classifier.py\", line 306, in train\r\n    mode=\"test\")\r\n  File \"run_classifier.py\", line 190, in valid_and_test\r\n    fetch_list=[pred.name])\r\nNameError: free variable 'pred' referenced before assignment in enclosing scope",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2019-07-30T06:23:47+00:00",
        "updated_at": "2019-08-01T05:22:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zhangyimi",
            "Lizhengo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2972,
        "title": "paddle实现的Transformer翻译模型解码速度如何？",
        "body": "在知乎上看到你们宣传训练速度，特别想知道paddle实现的transformer在解码速度上面对比其他框架有无优势。这是[WNMT2018](https://docs.google.com/spreadsheets/d/1wZQegK-9CKY378eAWRlahg23Fq155WTm4TQ8ikf8_6E/)的结果，里面是WMT14 En-De任务上各个框架的性能对比，包括解码时间、显存占用和内存占用等。\r\n",
        "state": "closed",
        "user": "huchinlp",
        "closed_by": "heavengate",
        "created_at": "2019-07-30T07:52:13+00:00",
        "updated_at": "2019-07-30T09:15:11+00:00",
        "closed_at": "2019-07-30T09:15:11+00:00",
        "comments_count": [
            "guoshengCS",
            "huchinlp",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2969,
        "title": "wrong evaluation function in lexical analysis model ",
        "body": "For each batch, the evalution function saves F1 score based on the accumulated counts from begining. \r\nThe final F1 score is the average of the F1 scores from each batch.\r\n\r\n[Link to the code](https://github.com/PaddlePaddle/models/blob/681aca5e3e6de53331795f0d911f8d10e0c78381/PaddleNLP/lexical_analysis/run_ernie_sequence_labeling.py#L183)",
        "state": "open",
        "user": "BladeSun",
        "closed_by": null,
        "created_at": "2019-07-30T07:00:47+00:00",
        "updated_at": "2019-08-01T04:59:08+00:00",
        "closed_at": null,
        "comments_count": [
            "Halfish"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2973,
        "title": "A mistake in your ssd reader.py",
        "body": "https://github.com/PaddlePaddle/models/blob/681aca5e3e6de53331795f0d911f8d10e0c78381/PaddleCV/ssd/reader.py#L74  \r\nI think this line of code should be set for the `apply_expand` property.",
        "state": "closed",
        "user": "XFeiF",
        "closed_by": "heavengate",
        "created_at": "2019-07-30T08:21:39+00:00",
        "updated_at": "2019-07-30T08:41:32+00:00",
        "closed_at": "2019-07-30T08:41:32+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2979,
        "title": "使用PyramidBox如何实现多张图循环测试输出",
        "body": "使用PYramidBox的官方模型进行测试输出时，想对文件夹里面的所有图进行测试，使用for循环第一张图可以测试成功，第二张图的时候就会出现模型路径加载错误，应该怎么修改呢？",
        "state": "closed",
        "user": "cjxhwxj",
        "closed_by": "cjxhwxj",
        "created_at": "2019-07-30T14:35:43+00:00",
        "updated_at": "2019-07-31T04:57:54+00:00",
        "closed_at": "2019-07-31T04:57:31+00:00",
        "comments_count": [
            "cjxhwxj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2978,
        "title": "开启multiprocess_reader 后训练效果变差",
        "body": "版本、环境信息：\r\n   1）PaddlePaddle版本：1.5.1\r\n   2）GPU v100\r\n   3）系统环境：centos\r\n\r\n代码：ssd (release-1.1)\r\n训练基本设置：batch_size=12，input_size=640*640，做默认的数据增强（开启distort/expand），数据集类型 \"pascalvoc\"\r\n\r\n问题描述：\r\n1.在训练mobilenetSSD时，单进程读取数据特别慢，读一个batch_size大约8-12s之间，统计大部分时间在数据预处理上，因此开了 `paddle.reader.multiprocess_reader(readers, False)` 加快读取速度，但相比单进程的mAP下降约10%，请问是什么原因？\r\n2.paddle.reader.multiprocess_reader 是否还支持recordio的读取，为啥每次用这个读recordio的reader 都会卡住。。。是否是recordio不支持多进程读取？",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-07-30T12:18:23+00:00",
        "updated_at": "2019-08-05T07:49:53+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "ellinyang",
            "heavengate",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2981,
        "title": "基础模型精度和速度统计可能存在问题",
        "body": "在选择basemodel时，发现[这里](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification)的实验结果超出了我的认知。\r\n\r\n![image](https://user-images.githubusercontent.com/6135871/62182566-a0223a80-b389-11e9-8afd-7c647f335b77.png)\r\n\r\n希望能给出说明和解释，谢谢！！\r\n",
        "state": "open",
        "user": "zzchust",
        "closed_by": null,
        "created_at": "2019-07-31T03:54:54+00:00",
        "updated_at": "2019-07-31T05:11:16+00:00",
        "closed_at": null,
        "comments_count": [
            "zzchust",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2980,
        "title": "SSD Inconsistent function call ",
        "body": "In your `eval_coco_map.py` file, you imported one function [`mobile_net `](https://github.com/PaddlePaddle/models/blob/8d7328017dc50c4b82d25733cc7a4cd14ad4469f/PaddleCV/ssd/eval_coco_map.py#L10) that do not exist in the `mobilenet_ssd.py` file.  And the function call [below](https://github.com/PaddlePaddle/models/blob/8d7328017dc50c4b82d25733cc7a4cd14ad4469f/PaddleCV/ssd/eval_coco_map.py#L52) should be modified too.",
        "state": "closed",
        "user": "XFeiF",
        "closed_by": "qingqing01",
        "created_at": "2019-07-30T16:54:11+00:00",
        "updated_at": "2019-07-31T11:54:04+00:00",
        "closed_at": "2019-07-31T11:54:03+00:00",
        "comments_count": [
            "XFeiF",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2983,
        "title": "NameError: global name 'bufsize' is not defined",
        "body": "当运行[PaddleDetection](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/PaddleDetection)中推理的代码\r\n```\r\nexport PYTHONPATH=`pwd`:$PYTHONPATH\r\npython tools/infer.py -c configs/mask_rcnn_r50_1x.yml \\\r\n    -o weights=https://paddlemodels.bj.bcebos.com/object_detection/mask_rcnn_r50_1x.tar \\\r\n    --infer_img=demo/000000570688.jpg\r\n```\r\n提示\r\n```\r\nTraceback (most recent call last):\r\n  File \"tools/infer.py\", line 261, in <module>\r\n    main()\r\n  File \"tools/infer.py\", line 161, in main\r\n    reader = create_reader(test_feed)\r\n  File \"PaddleDetection/ppdet/data/data_feed.py\", line 101, in create_reader\r\n    'bufsize': bufsize,\r\nNameError: global name 'bufsize' is not defined\r\n```",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "qingqing01",
        "created_at": "2019-07-31T07:57:59+00:00",
        "updated_at": "2019-08-06T06:54:18+00:00",
        "closed_at": "2019-08-06T06:54:18+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2984,
        "title": "load pretrained model后训练时报错",
        "body": "paddle load pretrained model进行训练就报Enforce failed. Expected in_dims[1] == filter_dims[1] * groups的错误， 如果不load pretrained model就可以正常训练。\r\n\r\n因此怀疑pretrained_model的参数纬度和自己的模型不匹配，但是如果参数shape不匹配只是参数名相同可以正常load model吗？\r\n\r\n答案是肯定的。希望paddle后续在load pretrained_model的时候就能做参数shape检查。",
        "state": "open",
        "user": "zzchust",
        "closed_by": null,
        "created_at": "2019-07-31T08:21:29+00:00",
        "updated_at": "2019-08-05T09:22:50+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2985,
        "title": "使用PaddleSlim进行SSD剪枝结果不正常",
        "body": "我在训练好SSD模型后，尝试使用Slim进行剪枝和量化训练。在使用量化训练时，效果良好，没有遇到任何问题，但是在进行剪枝时，出现了完全没有效果的问题，具体描述如下：\r\n![微信截图_20190731182813](https://user-images.githubusercontent.com/13788388/62205170-6e2cca80-b3c1-11e9-9fdf-0ef538d73052.png)\r\n\r\n一开始训练，我加载我训好的模型，就出现如图所示打印，显示Pruned size为0，Pruned flops也为0.然后就进入到了训练中\r\n![微信截图_20190731182823](https://user-images.githubusercontent.com/13788388/62205244-9caaa580-b3c1-11e9-9c58-5e369fbd0a87.png)\r\n![微信截图_20190731182840](https://user-images.githubusercontent.com/13788388/62205361-dda2ba00-b3c1-11e9-8208-52812a0d8eba.png)\r\n训练一切正常，每个epoch完事儿也都会进行eval，然后保存checkpoints，但是看不到任何剪枝的效果，config中的剪枝param也完全看不到，训练了十多个epoch，每个checkpoint大小都一模一样，预测结果也几乎相同，请相关技术人员帮忙解答，谢谢。",
        "state": "closed",
        "user": "gujingxiao",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-07-31T10:35:35+00:00",
        "updated_at": "2019-09-11T07:34:57+00:00",
        "closed_at": "2019-09-11T07:34:57+00:00",
        "comments_count": [
            "gujingxiao",
            "zzchust",
            "ZiruiChen",
            "gujingxiao",
            "wanghaoshuang",
            "zzchust",
            "wanghaoshuang",
            "ZiruiChen"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2991,
        "title": "视频分类中用CPU跑的时候没有结果，用的模型是attention lstm。python3.5。paddle1.5.1。Ubuntu系统跑的",
        "body": "/usr/bin/python3.5 /media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/train.py\r\n[INFO: train.py:  295]: Namespace(batch_size=None, config='configs/attention_lstm.txt', enable_ce=False, epoch=10, learning_rate=None, log_interval=10, model_name='AttentionLSTM', no_memory_optimize=False, no_use_pyreader=False, pretrain=None, resume=None, save_dir='checkpoints', use_gpu=False, valid_interval=1)\r\n[INFO: config.py:   66]: ---------------- Train Arguments ----------------\r\n[INFO: config.py:   68]: TRAIN:\r\n[INFO: config.py:   70]:     use_gpu:False\r\n[INFO: config.py:   70]:     filelist:dataset/youtube8m/train.list\r\n[INFO: config.py:   70]:     weight_decay:0.0008\r\n[INFO: config.py:   70]:     num_samples:5000000\r\n[INFO: config.py:   70]:     decay_epochs:[5]\r\n[INFO: config.py:   70]:     pretrain_base:None\r\n[INFO: config.py:   70]:     learning_rate:0.001\r\n[INFO: config.py:   70]:     decay_gamma:0.1\r\n[INFO: config.py:   70]:     num_gpus:8\r\n[INFO: config.py:   70]:     epoch:10\r\n[INFO: config.py:   70]:     batch_size:1024\r\n[INFO: config.py:   68]: MODEL:\r\n[INFO: config.py:   70]:     drop_rate:0.5\r\n[INFO: config.py:   70]:     embedding_size:512\r\n[INFO: config.py:   70]:     bone_nework:None\r\n[INFO: config.py:   70]:     name:AttentionLSTM\r\n[INFO: config.py:   70]:     feature_dims:[1024, 128]\r\n[INFO: config.py:   70]:     dataset:YouTube-8M\r\n[INFO: config.py:   70]:     num_classes:3862\r\n[INFO: config.py:   70]:     lstm_size:1024\r\n[INFO: config.py:   70]:     feature_names:['rgb', 'audio']\r\n[INFO: config.py:   70]:     feature_num:2\r\n[INFO: config.py:   70]:     topk:20\r\n[INFO: config.py:   68]: INFER:\r\n[INFO: config.py:   70]:     filelist:dataset/youtube8m/infer.list\r\n[INFO: config.py:   70]:     batch_size:1\r\n[INFO: config.py:   68]: VALID:\r\n[INFO: config.py:   70]:     filelist:dataset/youtube8m/val.list\r\n[INFO: config.py:   70]:     batch_size:1024\r\n[INFO: config.py:   68]: TEST:\r\n[INFO: config.py:   70]:     filelist:dataset/youtube8m/test.list\r\n[INFO: config.py:   70]:     batch_size:128\r\n[INFO: config.py:   71]: -------------------------------------------------\r\nThe CPU_NUM is not specified, you should set CPU_NUM in the environment variable list, i.e export CPU_NUM=1. CPU_NUM indicates that how many CPUPlace are used in the current task.\r\n!!! The default number of CPUPlaces is 1.\r\n\r\n[WARNING: compiler.py:  239]: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\nI0801 09:07:25.790300  4196 parallel_executor.cc:329] The number of CPUPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0801 09:07:25.808480  4196 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n[WARNING: compiler.py:  239]: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\nshare_vars_from is set, scope is ignored.\r\nI0801 09:07:25.817261  4196 parallel_executor.cc:329] The number of CPUPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0801 09:07:25.818228  4196 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n[INFO: train_utils.py:   30]: ------- learning rate [0.], learning rate counter [-1] -----\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.5/threading.py\", line 862, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/io.py\", line 596, in __provider_thread__\r\n    raise ex\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/io.py\", line 578, in __provider_thread__\r\n    for tensors in func():\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/io.py\", line 628, in __tensor_provider__\r\n    for slots in paddle_reader():\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/data_feeder.py\", line 416, in __reader_creator__\r\n    for item in reader():\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/datareader/feature_reader.py\", line 69, in reader\r\n    nframes = record[b'nframes']\r\nKeyError: b'nframes'\r\n\r\n/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\r\n  out=out, **kwargs)\r\n/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\r\n  ret = ret.dtype.type(ret / rcount)\r\n[INFO: train_utils.py:  198]: [TRAIN] Epoch 0 training finished, average time: nan\r\nTraceback (most recent call last):\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/tools/train_utils.py\", line 172, in train_with_pyreader\r\n    train_outs = train_exe.run(fetch_list=train_fetch_list)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/parallel_executor.py\", line 280, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 666, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 528, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:92]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/train.py\", line 300, in <module>\r\n    train(args)\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/train.py\", line 288, in train\r\n    test_metrics=valid_metrics)\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/tools/train_utils.py\", line 200, in train_with_pyreader\r\n    \"_epoch{}\".format(epoch))\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/tools/train_utils.py\", line 221, in save_model\r\n    fluid.io.save_persistables(exe, model_path, main_program=program)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 512, in save_persistables\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 193, in save_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 231, in save_vars\r\n    executor.run(save_program)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator save error.\r\nPython Callstacks: \r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 215, in save_vars\r\n    'file_path': os.path.join(save_dirname, new_var.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 193, in save_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 512, in save_persistables\r\n    filename=filename)\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/tools/train_utils.py\", line 221, in save_model\r\n    fluid.io.save_persistables(exe, model_path, main_program=program)\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/tools/train_utils.py\", line 200, in train_with_pyreader\r\n    \"_epoch{}\".format(epoch))\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/train.py\", line 288, in train\r\n    test_metrics=valid_metrics)\r\n  File \"/media/hxc/新加卷/models-develop/PaddleCV/PaddleVideo/train.py\", line 300, in <module>\r\n    train(args)\r\nC++ Callstacks: \r\nholder_ should not be null\r\nTensor not initialized yet when Tensor::type() is called. at [/paddle/paddle/fluid/framework/tensor.h:139]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f208c10eb58p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f208c10eea7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f208c10f84bp paddle::framework::Tensor::type() const + 107\r\n3       0x7f208d450dbdp paddle::framework::GetDataTypeOfVar(paddle::framework::Variable const*) + 157\r\n4       0x7f208c9273d3p paddle::operators::SaveOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 67\r\n5       0x7f208d45420bp paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&, paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 235\r\n6       0x7f208d4556c8p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 728\r\n7       0x7f208d455cd1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n8       0x7f208d453b7bp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 267\r\n9       0x7f208c28dc7ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 206\r\n10      0x7f208c290cffp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n11      0x7f208c100e7dp\r\n12      0x7f208c13d95ep\r\n13            0x4ea137p PyCFunction_Call + 119\r\n14            0x53c176p PyEval_EvalFrameEx + 23030\r\n15            0x53fc97p\r\n16            0x53bc93p PyEval_EvalFrameEx + 21779\r\n17            0x53fc97p\r\n18            0x53b83fp PyEval_EvalFrameEx + 20671\r\n19            0x53fc97p\r\n20            0x53b83fp PyEval_EvalFrameEx + 20671\r\n21            0x53fc97p\r\n22            0x53b83fp PyEval_EvalFrameEx + 20671\r\n23            0x53fc97p\r\n24            0x53b83fp PyEval_EvalFrameEx + 20671\r\n25            0x53fc97p\r\n26            0x53b83fp PyEval_EvalFrameEx + 20671\r\n27            0x53fc97p\r\n28            0x53b83fp PyEval_EvalFrameEx + 20671\r\n29            0x5401efp\r\n30            0x53bc93p PyEval_EvalFrameEx + 21779\r\n31            0x53fc97p\r\n32            0x5409bfp PyEval_EvalCode + 31\r\n33            0x60cb42p\r\n34            0x60efeap PyRun_FileExFlags + 154\r\n35            0x60f7dcp PyRun_SimpleFileExFlags + 444\r\n36            0x640256p Py_Main + 1110\r\n37            0x4d0001p main + 225\r\n38      0x7f20b41de830p __libc_start_main + 240\r\n39            0x5d6999p _start + 41\r\n\r\n\r\nProcess finished with exit code 1\r\n",
        "state": "open",
        "user": "yuye-img",
        "closed_by": null,
        "created_at": "2019-08-01T01:12:04+00:00",
        "updated_at": "2019-10-15T02:26:00+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang",
            "yuye-img",
            "yuye-img",
            "SunGaofeng",
            "yuye-img",
            "sportzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2992,
        "title": "kinetics-400数据集不全",
        "body": "用了官方repo的脚本下载后发现数据集缺了2W视频，请问你们有完整版的数据集可以共享的嘛，万分感谢。",
        "state": "open",
        "user": "chenbohua3",
        "closed_by": null,
        "created_at": "2019-08-01T01:33:44+00:00",
        "updated_at": "2019-08-01T09:00:05+00:00",
        "closed_at": null,
        "comments_count": [
            "chenbohua3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2993,
        "title": "models/dygraph 下的实现是否可以给出示例任务在 paddle release 版本下性能的 benchmark ",
        "body": "特别关注 models/dygraph/transformers 相较于静态图在多卡/多机下的性能对比 ",
        "state": "closed",
        "user": "nbcc",
        "closed_by": "JiabinYang",
        "created_at": "2019-08-01T02:04:28+00:00",
        "updated_at": "2019-09-16T02:56:09+00:00",
        "closed_at": "2019-09-16T02:56:09+00:00",
        "comments_count": [
            "JiabinYang",
            "DDDivano",
            "nbcc",
            "DDDivano",
            "DDDivano"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3001,
        "title": "PaddleSlim剪切报错 pruner.py 维度上的index报错",
        "body": "配置文件如下\r\nversion: 1.0\r\npruners:\r\n    pruner_1:\r\n        class: 'StructurePruner'\r\n        pruning_axis:\r\n            '*': 0\r\n        criterions:\r\n            '*': 'l1_norm'\r\nstrategies:\r\n    uniform_pruning_strategy:\r\n        class: 'UniformPruneStrategy'\r\n        pruner: 'pruner_1'\r\n        start_epoch: 0\r\n        target_ratio: 0.5\r\n        pruned_params: 'conv.*w_0'\r\n        metric_name: 'map'\r\n    quantization_strategy:\r\n        class: 'QuantizationStrategy'\r\n        start_epoch: 10\r\n        end_epoch: 14\r\n        float_model_save_path: './output/float'\r\n        mobile_model_save_path: './output/mobile'\r\n        int8_model_save_path: './output/int8'\r\n        weight_bits: 8\r\n        activation_bits: 8\r\n        weight_quantize_type: 'abs_max'\r\n        activation_quantize_type: 'abs_max'\r\ncompressor:\r\n    epoch: 15\r\n    #init_model: './checkpoints/0' # Please enable this option for loading checkpoint.\r\n    checkpoint_path: './checkpoint/'\r\n    strategies:\r\n        - uniform_pruning_strategy\r\n        - quantization_strategy\r\n报错如下\r\n2019-08-01 20:44:03,772-INFO: _get_best_ratios\r\n2019-08-01 20:44:03,772-INFO: _get_best_ratios\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/core/compressor.py\", line 534, in run\r\n    strategy.on_epoch_begin(context)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 640, in on_epoch_begin\r\n    params, ratios = self._get_best_ratios(context)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 618, in _get_best_ratios\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 477, in _prune_parameters\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 322, in _forward_pruning_ralated_params\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 159, in _prune_parameter_by_idx\r\n    np.array(param_t), pruned_idx, pruned_axis, lazy=lazy)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/pruner.py\", line 95, in prune_tensor\r\n    mask[pruned_idx] = True\r\nIndexError: index 513 is out of bounds for axis 0 with size 512\r\n2019-08-01 20:44:03,957-ERROR: None\r\n2019-08-01 20:44:03,957-ERROR: None\r\n2019-08-01 20:44:03,979-WARNING: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n",
        "state": "closed",
        "user": "universea",
        "closed_by": "JiabinYang",
        "created_at": "2019-08-01T12:47:25+00:00",
        "updated_at": "2019-08-13T12:31:34+00:00",
        "closed_at": "2019-08-01T13:36:34+00:00",
        "comments_count": [
            "A1exy",
            "A1exy",
            "universea",
            "universea",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3002,
        "title": "PaddleSlim剪切报错 pruner.py 维度上的index报错，未解决",
        "body": "data_dir work/coco/train2017\r\nuse_multiprocess  False\r\n2019-08-01 23:19:57,543-INFO: checkpoints: []\r\n2019-08-01 23:19:57,543-INFO: checkpoints: []\r\n2019-08-01 23:19:57,544-INFO: _get_best_ratios\r\n2019-08-01 23:19:57,544-INFO: _get_best_ratios\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/core/compressor.py\", line 534, in run\r\n    strategy.on_epoch_begin(context)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 640, in on_epoch_begin\r\n    params, ratios = self._get_best_ratios(context)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 618, in _get_best_ratios\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 477, in _prune_parameters\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 322, in _forward_pruning_ralated_params\r\n    param_shape_backup=param_shape_backup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/prune_strategy.py\", line 159, in _prune_parameter_by_idx\r\n    np.array(param_t), pruned_idx, pruned_axis, lazy=lazy)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/contrib/slim/prune/pruner.py\", line 95, in prune_tensor\r\n    mask[pruned_idx] = True\r\nIndexError: index 257 is out of bounds for axis 0 with size 256\r\n2019-08-01 23:19:58,209-ERROR: None\r\n2019-08-01 23:19:58,209-ERROR: None\r\n2019-08-01 23:19:58,228-WARNING: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\nI0801 23:20:01.227057  1035 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0801 23:20:01.267546  1035 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1",
        "state": "closed",
        "user": "universea",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-01T15:21:38+00:00",
        "updated_at": "2019-09-11T07:34:57+00:00",
        "closed_at": "2019-09-11T07:34:57+00:00",
        "comments_count": [
            "universea",
            "universea",
            "universea",
            "universea",
            "universea",
            "wanghaoshuang",
            "universea",
            "universea",
            "wanghaoshuang",
            "universea",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "zzchust"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3005,
        "title": "When I use attentation model training a recognition model, the 'train_acc' always be 0.000000, and after 2 epoch, train_cost became nan",
        "body": "When I use attentation model training a recognition model, the 'train_acc' always be 0.000000, and after 2 epoch, train_cost became nan, and train_acc still 0.000000, the training info is as follow:\r\n___________________________________________________________________________________________________\r\n\r\nI0802 11:10:00.041497  2313 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 4. And the Program will be copied 4 copies\r\nI0802 11:10:01.277854  2313 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n\r\nTime: 1564715520.4697154; Iter[1000]; Avg loss: 25.504; Avg seq err: 1.000\r\nkpis\ttrain_cost\t25.504290\r\nkpis\ttrain_acc\t0.000000\r\n\r\nTime: 1564715634.926904; Iter[2000]; Avg loss: 22.807; Avg seq err: 1.000\r\nkpis\ttrain_cost\t22.807307\r\nkpis\ttrain_acc\t0.000000\r\n\r\nTime: 1564715748.7402227; Iter[3000]; Avg loss: nan; Avg seq err: 1.000\r\nkpis\ttrain_cost\tnan\r\nkpis\ttrain_acc\t0.000000\r\n\r\nTime: 1564715862.1550791; Iter[4000]; Avg loss: nan; Avg seq err: 1.000\r\nkpis\ttrain_cost\tnan\r\nkpis\ttrain_acc\t0.000000\r\n\r\nTime: 1564715975.961236; Iter[5000]; Avg loss: nan; Avg seq err: 1.000\r\nkpis\ttrain_cost\tnan\r\nkpis\ttrain_acc\t0.000000\r\n\r\nTime: 1564716089.7519104; Iter[6000]; Avg loss: nan; Avg seq err: 1.000\r\nkpis\ttrain_cost\tnan\r\nkpis\ttrain_acc\t0.000000\r\n____________________________________________________________________________________\r\nThe dataset used for training recognition is provised by \"实例数据\" in README\r\n![image](https://user-images.githubusercontent.com/13143336/62342123-56b42580-b518-11e9-851c-0301f813a20b.png)\r\n\r\nThank you in advance!",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-08-02T03:26:23+00:00",
        "updated_at": "2019-08-07T04:54:04+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "endy-see",
            "slf12",
            "slf12",
            "slf12"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 2998,
        "title": "PaddleSlim对MobileNet进行Uniform剪切报错",
        "body": "Windows环境下使用PaddleSlim示例对MobileNet进行Uniform剪切报错\r\n![image](https://user-images.githubusercontent.com/7035538/62279838-70545f00-b47d-11e9-93c8-17f07357e040.png)\r\n\r\nPaddle的问题有点多。。。",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-01T08:57:52+00:00",
        "updated_at": "2019-09-11T07:34:57+00:00",
        "closed_at": "2019-09-11T07:34:57+00:00",
        "comments_count": [
            "wanghaoshuang",
            "A1exy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3006,
        "title": "similarity_net 基于字训练报错",
        "body": "使用场景：\r\n 企业名相识度计算，由于企业名通过分词很难进行细分；基本上都是一个完整的整体。因此，考虑采用基于字进行训练\r\n\r\n问题：\r\n训练过程中，验证集的预测结果会偶然出现None的情况\r\n\r\n代码：\r\nbatch_data = paddle.batch(reader, args.batch_size, drop_last=False)\r\n        pred_list = []\r\n        for data in batch_data():\r\n            _pred = executor.run(program=program,\r\n                                 feed=feeder.feed(data),\r\n                                 fetch_list=[pred.name])\r\n            pred_list += list(_pred)\r\n\r\npred_list 在某些批次的迭代验证中会出现：\r\n[[nan nan]\r\n [nan nan]\r\n [nan nan]\r\n ...\r\n [nan nan]\r\n [nan nan]\r\n [nan nan]]\r\n\r\n因此，后续计算准确率会报错......\r\n\r\n其中使用到的是cnn_pointwise模型\r\n模型训练入口的官方链接地址：\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/similarity_net\r\n",
        "state": "open",
        "user": "qujinqiang",
        "closed_by": null,
        "created_at": "2019-08-02T03:28:52+00:00",
        "updated_at": "2019-09-03T09:25:33+00:00",
        "closed_at": null,
        "comments_count": [
            "18628271760",
            "Lizhengo",
            "qujinqiang",
            "qujinqiang",
            "qujinqiang",
            "LielinJiang",
            "qujinqiang",
            "qujinqiang",
            "Lizhengo",
            "Lizhengo",
            "qujinqiang",
            "Lizhengo",
            "Lizhengo",
            "qujinqiang",
            "Lizhengo",
            "qujinqiang",
            "Lizhengo",
            "qujinqiang",
            "Lizhengo",
            "qujinqiang",
            "qujinqiang",
            "qujinqiang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3009,
        "title": "PaddleSlim对Uniform剪切后的MobileNet模型进行infer.py报错",
        "body": "在Unbutu16.04下，对Uniform剪切后的MobileNet模型进行inference:\r\n![image](https://user-images.githubusercontent.com/7035538/62347533-984ecb80-b52c-11e9-9bc6-6b208c1e3c17.png)\r\n![image](https://user-images.githubusercontent.com/7035538/62347558-abfa3200-b52c-11e9-9fa1-5905d7590ee8.png)\r\n\r\n问题真的多，有点醉人。。。",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2019-08-02T05:52:51+00:00",
        "updated_at": "2019-08-20T03:42:00+00:00",
        "closed_at": "2019-08-20T03:42:00+00:00",
        "comments_count": [
            "wanghaoshuang",
            "A1exy",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "A1exy",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "zzchust",
            "A1exy",
            "zzchust",
            "wanghaoshuang",
            "zzchust",
            "A1exy"
        ],
        "labels": [
            "user",
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3007,
        "title": "Failed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS ) ",
        "body": "My local environment:\r\nCentOS: release 6.9\r\nNCCL: v2.4.7\r\ncuda: 9.0.176\r\ncudnn: 7.3.1\r\nPaddle: 1.5.1\r\nPython: 3.7.3\r\n\r\nWhen i start training ocr_recognition model with crnn_ctc model, paddle occured error as follow:\r\n\r\n(paddle) [ocr_recognition]# env CUDA_VISIBLE_DEVICES=0 python train.py --train_images dataset/public_data_english/train_images --train_list dataset/public_data_english/train.list --test_images dataset/public_data_english/test_images --test_list dataset/public_data_english/test.list\r\n----------- Configuration Arguments -----------\r\naverage_window: 0.15\r\nbatch_size: 32\r\neval_period: 15000\r\ninit_model: None\r\nlog_period: 1000\r\nmax_average_window: 12500\r\nmin_average_window: 10000\r\nmodel: crnn_ctc\r\nparallel: False\r\nprofile: False\r\nsave_model_dir: ./models\r\nsave_model_period: 15000\r\nskip_batch_num: 0\r\nskip_test: False\r\ntest_images: dataset/public_data_english/test_images\r\ntest_list: dataset/public_data_english/test.list\r\ntotal_step: 720000\r\ntrain_images: dataset/public_data_english/train_images\r\ntrain_list: dataset/public_data_english/train.list\r\nuse_gpu: True\r\n/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/evaluator.py:71: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.\r\n% (self.class.name, self.class.name), Warning)\r\nfinish batch shuffle\r\nW0801 21:22:58.187352 37850 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0801 21:22:58.192481 37850 device_context.cc:267] device: 0, cuDNN Version: 7.3.\r\nW0801 21:22:59.779482 37850 dynamic_loader.cc:140] Failed to find dynamic library: /paddle/build/third_party/install/warpctc/lib/libwarpctc.so (dlopen: cannot load any more object with static TLS)\r\nW0801 21:22:59.779705 37850 dynamic_loader.cc:109] Can not find library: libwarpctc.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 222, in \r\nmain()\r\nFile \"train.py\", line 218, in main\r\ntrain(args)\r\nFile \"train.py\", line 151, in train\r\nresults = train_one_batch(data)\r\nFile \"train.py\", line 112, in train_one_batch\r\nfetch_list=fetch_vars)\r\nFile \"/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 651, in run\r\nuse_program_cache=use_program_cache)\r\nFile \"/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 749, in run\r\nexe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator warpctc error.\r\nPython Callstacks:\r\nFile \"/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\nattrs=kwargs.get(\"attrs\", None))\r\nFile \"/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\nreturn self.main_program.current_block().append_op(args, kwargs)\r\nFile \"/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 5573, in warpctc\r\n'use_cudnn': use_cudnn\r\nFile \"/home/zhaoyanmei/models/PaddleCV/ocr_recognition/crnn_ctc_model.py\", line 189, in ctc_train_net\r\ninput=fc_out, label=label, blank=num_classes, norm_by_times=True)\r\nFile \"train.py\", line 61, in train\r\nargs, data_shape, num_classes)\r\nFile \"train.py\", line 218, in main\r\ntrain(args)\r\nFile \"train.py\", line 222, in \r\nmain()\r\nC++ Callstacks:\r\nFailed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS )\r\nPlease specify its path correctly using following ways:\r\nMethod. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\nFor instance, issue command: export LD_LIBRARY_PATH=...\r\nNote: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:166]\r\nPaddlePaddle Call Stacks:\r\n0 0x7fe93ff05830p void paddle::platform::EnforceNotMet::Init<char const>(char const, char const, int) + 352\r\n1 0x7fe93ff05ba9p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr::exception_ptr, char const*, int) + 137\r\n2 0x7fe941f09f9bp paddle::platform::dynload::GetWarpCTCDsoHandle() + 1835\r\n3 0x7fe940177be9p void std::once_call_impl<std::Bind_simple<paddle::platform::dynload::DynLoad__get_warpctc_version::operator()<>()::{lambda()#1} ()> >() + 9\r\n4 0x7fe9b196fbe0p pthread_once + 80\r\n5 0x7fe9401809b8p paddle::operators::WarpCTCFunctorpaddle::platform::CUDADeviceContext::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*) + 136\r\n6 0x7fe940183206p paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 2390\r\n7 0x7fe940184ab3p std::Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::M_invoke(std::Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n8 0x7fe941e6bf07p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n9 0x7fe941e6c2e1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n10 0x7fe941e698dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n11 0x7fe94009061ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n12 0x7fe9400936bfp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocatorstd::string > const&, bool) + 143\r\n13 0x7fe93fef6ebdp\r\n14 0x7fe93ff38166p\r\n15 0x7fe9b1f1b6e4p _PyMethodDef_RawFastCallKeywords + 612\r\n16 0x7fe9b1f1b801p _PyCFunction_FastCallKeywords + 33\r\n17 0x7fe9b1f777aep _PyEval_EvalFrameDefault + 21374\r\n18 0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761\r\n19 0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903\r\n20 0x7fe9b1f738fep _PyEval_EvalFrameDefault + 5326\r\n21 0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761\r\n22 0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903\r\n23 0x7fe9b1f738fep _PyEval_EvalFrameDefault + 5326\r\n24 0x7fe9b1eb8db9p _PyEval_EvalCodeWithName + 3001\r\n25 0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903\r\n26 0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046\r\n27 0x7fe9b1eb8db9p _PyEval_EvalCodeWithName + 3001\r\n28 0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903\r\n29 0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046\r\n30 0x7fe9b1f1a79bp _PyFunction_FastCallKeywords + 251\r\n31 0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046\r\n32 0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761\r\n33 0x7fe9b1eb93c4p PyEval_EvalCodeEx + 68\r\n34 0x7fe9b1eb93ecp PyEval_EvalCode + 28\r\n35 0x7fe9b1fd1874p\r\n36 0x7fe9b1fdbb81p PyRun_FileExFlags + 161\r\n37 0x7fe9b1fdbd73p PyRun_SimpleFileExFlags + 451\r\n38 0x7fe9b1fdce5fp\r\n39 0x7fe9b1fdcf7cp _Py_UnixMain + 60\r\n40 0x7fe9b15c3b45p __libc_start_main + 245\r\n41 0x7fe9b1f82122p\r\n\r\n(paddle) [ocr_recognition]#\r\n\r\nCan anyone help me? Thank you in advance！",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-08-02T03:32:05+00:00",
        "updated_at": "2019-12-03T01:44:37+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "endy-see",
            "JiabinYang",
            "JiabinYang",
            "BeyondYourself"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3010,
        "title": "创建数据集时最后一步点击创建按钮对话框不消失",
        "body": "1，创建个人数据集时，按照向导一步步走到最后。\r\n2，在最后一步，点击创建按钮，对话框没有反应，不跳转，也不提示创建成功。\r\n3，隔一段时间，忍无可忍，把对话框关掉。\r\n4，返回数据集列表，发现数据集已经创建成功。",
        "state": "open",
        "user": "arvinwong1980",
        "closed_by": null,
        "created_at": "2019-08-02T10:32:05+00:00",
        "updated_at": "2019-08-02T15:12:24+00:00",
        "closed_at": null,
        "comments_count": [
            "universea"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3013,
        "title": "进行分类训练 莫名自动不运行了",
        "body": "请教下 我用 models/PaddleCV/image_classification/  这个进行分类训练 程序运行了200次左右就不再运行了 这个问题困扰我很久了 哪位大神帮忙看下？\r\n已做的尝试如下  1 增加内存  2 再AIstudio 上训练   3 更换数据集",
        "state": "open",
        "user": "sckalman123",
        "closed_by": null,
        "created_at": "2019-08-05T03:32:16+00:00",
        "updated_at": "2019-09-30T08:20:33+00:00",
        "closed_at": null,
        "comments_count": [
            "sckalman123",
            "sckalman123",
            "wopeizl",
            "sckalman123",
            "wopeizl",
            "sckalman123",
            "sckalman123",
            "sckalman123",
            "wangguibao",
            "sckalman123",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3011,
        "title": "Cannot allocate GPU memory.",
        "body": "Hello, I have a problem.\r\n\r\nI successfully run ResNet50 with batch_size 64 on Titan V card (12gb). Even with batch_size 96 it works well, but with batch_size 128 it stops working.\r\n\r\nI tried shrinking FLAGS_fraction_of_gpu_memory_to_use from 0.98 (default) even to 0.1 but it doesn't work...\r\n\r\n`Cannot malloc 49.0002 MB GPU memory. Please shrink FLAGS_fraction_of_gpu_memory_to_use or FLAGS_initial_gpu_memory_in_mb or FLAGS_reallocate_gpu_memory_in_mbenvironment variable to a lower value. Current FLAGS_fraction_of_gpu_memory_to_use value is 0.1. Current FLAGS_initial_gpu_memory_in_mb value is 0. Current FLAGS_reallocate_gpu_memory_in_mb value is 0.`\r\n\r\nWhat's the problem here? Can you help me with that?",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2019-08-02T13:52:16+00:00",
        "updated_at": "2019-08-05T09:14:24+00:00",
        "closed_at": "2019-08-05T09:14:24+00:00",
        "comments_count": [
            "wzzju",
            "yw1991",
            "ghost",
            "zhhsplendid",
            "ghost"
        ],
        "labels": [
            "user",
            "Error Message"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3015,
        "title": "PaddleSlim量化模型加载(arm或x86_64)",
        "body": "1.目前x86的python API不能加载int8量化模型，是否有计划加入这个API？\r\n2.paddle-mobile可以加载paddleslim导出的mobile模型(大小和int8模型相同)，是否代表paddle-mobile支持int8量化模型，有没有计划更新mobile的doc，给加载量化模型提供一些参考？",
        "state": "open",
        "user": "zhizunbao-y",
        "closed_by": null,
        "created_at": "2019-08-05T06:29:54+00:00",
        "updated_at": "2019-08-06T07:58:14+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3019,
        "title": "PaddleCV/rcnn: Invoke operator conv2d error",
        "body": "rcnn目录下执行命令：\r\n`python infer.py --pretrained_model=imagenet_resnet50_fusebn/bn2a_branch1_offset --image_path=dataset/coco/val2017/000000527784.jpg --draw_threshold=0.6`\r\n\r\n出现以下错误：\r\n`-----------  Configuration Arguments -----------\r\nMASK_ON: False\r\nanchor_sizes: [32, 64, 128, 256, 512]\r\naspect_ratios: [0.5, 1.0, 2.0]\r\nbatch_size_per_im: 512\r\nclass_num: 81\r\ndata_dir: dataset/coco\r\ndataset: coco2017\r\ndraw_threshold: 0.6\r\nenable_ce: False\r\nim_per_batch: 1\r\nimage_path: dataset/coco/val2017/000000527784.jpg\r\nlearning_rate: 0.01\r\nlog_window: 20\r\nmax_iter: 180000\r\nmax_size: 1333\r\nmodel_save_dir: output\r\nnms_thresh: 0.5\r\npadding_minibatch: False\r\nparallel: True\r\npixel_means: [102.9801, 115.9465, 122.7717]\r\npretrained_model: imagenet_resnet50_fusebn/bn2a_branch1_offset\r\nrpn_nms_thresh: 0.7\r\nrpn_stride: [16.0, 16.0]\r\nscales: [800]\r\nscore_thresh: 0.05\r\nsnapshot_stride: 10000\r\nuse_gpu: True\r\nuse_profile: False\r\nuse_pyreader: True\r\nvariance: [1.0, 1.0, 1.0, 1.0]\r\n------------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.55s)\r\ncreating index...\r\nindex created!\r\nW0805 17:37:38.763368 29134 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW0805 17:37:38.765338 29134 device_context.cc:267] device: 0, cuDNN Version: 7.5.\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 96, in <module>\r\n    infer()\r\n  File \"infer.py\", line 76, in infer\r\n    return_numpy=False)\r\n  File \"/home/cambricon/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/cambricon/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator conv2d error.\r\nPython Callstacks:\r\n  File \"/home/cambricon/anaconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/cambricon/anaconda3/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/cambricon/anaconda3/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 2181, in conv2d\r\n    'fuse_relu_before_depthwise_conv': False\r\n  File \"/home/cambricon/workSpace/paddlepaddleModels/models/PaddleCV/rcnn/models/resnet.py\", line 71, in conv_affine_layer\r\n    name=name + '.conv2d.output.1')\r\n  File \"/home/cambricon/workSpace/paddlepaddleModels/models/PaddleCV/rcnn/models/resnet.py\", line 144, in add_ResNet50_conv4_body\r\n    body_input, ch_out=64, filter_size=7, stride=2, padding=3, name=\"conv1\")\r\n  File \"/home/cambricon/workSpace/paddlepaddleModels/models/PaddleCV/rcnn/models/model_builder.py\", line 39, in build_model\r\n    body_conv = self.add_conv_body_func(self.image)\r\n  File \"infer.py\", line 49, in infer\r\n    model.build_model(image_shape)\r\n  File \"infer.py\", line 96, in <module>\r\n    infer()\r\nC++ Callstacks:\r\nholder_ should not be null\r\nTensor not initialized yet when Tensor::type() is called. at [/paddle/paddle/fluid/framework/tensor.h:139]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f6ad524ee78p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f6ad524f1c7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f6ad524fbfbp paddle::framework::Tensor::type() const + 107\r\n3       0x7f6ad567677bp paddle::operators::ConvOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 299\r\n4       0x7f6ad72db04bp paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&, paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 235\r\n5       0x7f6ad72dd1b8p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 728\r\n6       0x7f6ad72dd431p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n7       0x7f6ad72daa2cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n8       0x7f6ad53d973ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n9       0x7f6ad53dc7dfp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n10      0x7f6ad523ffddp\r\n11      0x7f6ad5281286p\r\n12      0x564f8634d6e4p _PyMethodDef_RawFastCallKeywords + 612\r\n13      0x564f8634d801p _PyCFunction_FastCallKeywords + 33\r\n14      0x564f863a97aep _PyEval_EvalFrameDefault + 21374\r\n15      0x564f862ea4f9p _PyEval_EvalCodeWithName + 761\r\n16      0x564f8634ca27p _PyFunction_FastCallKeywords + 903\r\n17      0x564f863a58fep _PyEval_EvalFrameDefault + 5326\r\n18      0x564f862ea4f9p _PyEval_EvalCodeWithName + 761\r\n19      0x564f8634ca27p _PyFunction_FastCallKeywords + 903\r\n20      0x564f863a58fep _PyEval_EvalFrameDefault + 5326\r\n21      0x564f862eadb9p _PyEval_EvalCodeWithName + 3001\r\n22      0x564f8634ca27p _PyFunction_FastCallKeywords + 903\r\n23      0x564f863a4846p _PyEval_EvalFrameDefault + 1046\r\n24      0x564f862ea4f9p _PyEval_EvalCodeWithName + 761\r\n25      0x564f862eb3c4p PyEval_EvalCodeEx + 68\r\n26      0x564f862eb3ecp PyEval_EvalCode + 28\r\n27      0x564f86403874p\r\n28      0x564f8640db81p PyRun_FileExFlags + 161\r\n29      0x564f8640dd73p PyRun_SimpleFileExFlags + 451\r\n30      0x564f8640ee5fp\r\n31      0x564f8640ef7cp _Py_UnixMain + 60\r\n32      0x7f6b05686830p __libc_start_main + 240\r\n33      0x564f863b4122p`\r\n",
        "state": "open",
        "user": "CerrieJ",
        "closed_by": null,
        "created_at": "2019-08-05T09:40:25+00:00",
        "updated_at": "2019-08-05T12:05:39+00:00",
        "closed_at": null,
        "comments_count": [
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3018,
        "title": "yolov3 backbone修改为shufflenetv2后报错",
        "body": "修改yolov3代码库中的[basemodel](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/yolov3/models/yolov3.py#L125) 为[shufflenetv2](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/shufflenet_v2.py)\r\n\r\n错误信息：\r\n![image](https://user-images.githubusercontent.com/6135871/62452916-b70ac780-b7a3-11e9-8a5f-8e16140d8182.png)\r\n\r\n错误定位：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/shufflenet_v2.py#L138",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "zzchust",
        "created_at": "2019-08-05T09:10:52+00:00",
        "updated_at": "2019-08-05T09:49:28+00:00",
        "closed_at": "2019-08-05T09:49:28+00:00",
        "comments_count": [
            "zzchust",
            "heavengate",
            "zzchust",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3020,
        "title": "Python3 + fluid1.5环境下报错",
        "body": "该项目在Python3.5 + fluid1.5 环境下报错：\r\n\r\nTraceback (most recent call last):\r\n  File \"paragraph_extraction.py\", line 198, in <module>\r\n    print(json.dumps(sample, encoding='utf8', ensure_ascii=False))\r\n  File \"/usr/lib/python3.5/json/__init__.py\", line 237, in dumps\r\n    **kw).encode(obj)\r\nTypeError: __init__() got an unexpected keyword argument 'encoding'\r\n\r\n并且，显示无法使用GPU。本地已安装并配置GPU相关环境。",
        "state": "closed",
        "user": "TingquanGao",
        "closed_by": "wangguibao",
        "created_at": "2019-08-05T10:09:55+00:00",
        "updated_at": "2019-09-30T08:18:43+00:00",
        "closed_at": "2019-09-30T08:18:43+00:00",
        "comments_count": [
            "wangguibao",
            "wangguibao",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3021,
        "title": "Enforce failed. Expected numel() >= 0, but received numel():-1179648 < 0:0.",
        "body": "when i use PaddleCV/ocr_recognize to train my own dataset, it occurs error as follow:\r\n________________________________________________________________________________________________________\r\n![image](https://user-images.githubusercontent.com/13143336/62462996-74ed8000-b7bb-11e9-9c56-cab63545c8eb.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463047-92224e80-b7bb-11e9-87bf-c38d7835f3bc.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463060-99e1f300-b7bb-11e9-8c9b-f07ac00d20e8.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463090-b0884a00-b7bb-11e9-91a3-c5c4c28d9762.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463105-bb42df00-b7bb-11e9-8705-9a4df401d7fe.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463114-c3028380-b7bb-11e9-897b-c94038341163.png)\r\n![image](https://user-images.githubusercontent.com/13143336/62463127-ca299180-b7bb-11e9-8121-368c49d42563.png)\r\n__________________________________________________________________________________________\r\nI don't know why..",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "wangguibao",
        "created_at": "2019-08-05T11:56:30+00:00",
        "updated_at": "2019-09-30T08:17:54+00:00",
        "closed_at": "2019-09-30T08:17:54+00:00",
        "comments_count": [
            "wangguibao",
            "wangguibao",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3022,
        "title": "句法分析",
        "body": "您好，是否可以提供基于ERNIE的句法分析模型？",
        "state": "closed",
        "user": "AnShengqiang",
        "closed_by": "AnShengqiang",
        "created_at": "2019-08-05T12:51:06+00:00",
        "updated_at": "2019-08-13T11:11:54+00:00",
        "closed_at": "2019-08-13T11:11:54+00:00",
        "comments_count": [
            "xyzhou-puck",
            "AnShengqiang",
            "AnShengqiang",
            "xyzhou-puck",
            "xyzhou-puck",
            "AnShengqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3028,
        "title": "请问如何在网络里创建一个包含固定值矩阵的variable？",
        "body": "如题，需要在网络里保存一个固定矩阵",
        "state": "open",
        "user": "guoxpl",
        "closed_by": null,
        "created_at": "2019-08-06T07:40:17+00:00",
        "updated_at": "2019-08-06T08:58:45+00:00",
        "closed_at": null,
        "comments_count": [
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3023,
        "title": "NeXtVLAD模型使用cpu进行预测时（use_gpu=False）出现错误：RuntimeError: code is too big",
        "body": "我在gpu环境下，能够正确运行NeXtVLAD模型进行预测，但是选择使用cpu（use_gpu=False）后，会出现RuntimeError: code is too big",
        "state": "closed",
        "user": "GeTai",
        "closed_by": "Aurelius84",
        "created_at": "2019-08-05T13:10:44+00:00",
        "updated_at": "2020-04-01T08:31:35+00:00",
        "closed_at": "2019-08-12T02:07:38+00:00",
        "comments_count": [
            "wangguibao",
            "wangguibao",
            "gavin1332",
            "GeTai",
            "SunGaofeng",
            "ucas010"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3025,
        "title": "paddle slim裁剪+量化 中途报错的问题",
        "body": "使用Uniform裁剪mobilenet时，裁剪过后的fine-tune训练会报错，错误类型如下：\r\n![e408470d2a61535f56d6b9767f9528d8](https://user-images.githubusercontent.com/20850734/62510314-30a4c300-b841-11e9-8c8c-7c8b4f2eef85.png)\r\n看起来像是裁剪过后的通道数和分组卷积的group数不同导致的，但是如果紧跟着量化训练的话，模型就可以正常的训练。请问这是什么问题呀。具体的配置如下：\r\n\r\n```\r\npruners:\r\n    pruner_1:\r\n        class: 'StructurePruner'\r\n        pruning_axis:\r\n            '*': 0\r\n        criterions:\r\n            '*': 'l1_norm'\r\n\r\nstrategies:\r\n    uniform_pruning_strategy:\r\n        class: 'UniformPruneStrategy'\r\n        pruner: 'pruner_1'\r\n        start_epoch: 5\r\n        target_ratio: 0.5\r\n        pruned_params: 'conv'\r\n        metric_name: 'acc_top1'\r\n    quantization_strategy:\r\n        class: 'QuantizationStrategy'\r\n        start_epoch: 10\r\n        end_epoch: 15\r\n        float_model_save_path: './output/float'\r\n        mobile_model_save_path: './output/mobile'\r\n        int8_model_save_path: './output/int8'\r\n        weight_bits: 8\r\n        activation_bits: 8\r\n        weight_quantize_type: 'abs_max'\r\n        activation_quantize_type: 'abs_max'\r\n        save_in_nodes: ['image']\r\n        save_out_nodes: ['fc_0.tmp_2']\r\ncompressor:\r\n    epoch: 16\r\n    checkpoint_path: './checkpoints_model/'\r\n    strategies:\r\n        - uniform_pruning_strategy\r\n        - quantization_strategy\r\n\r\n```",
        "state": "closed",
        "user": "wwjjy",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-06T03:59:47+00:00",
        "updated_at": "2019-09-11T07:34:57+00:00",
        "closed_at": "2019-09-11T07:34:57+00:00",
        "comments_count": [
            "A1exy",
            "A1exy",
            "wwjjy",
            "A1exy",
            "A1exy",
            "wwjjy",
            "wzzju",
            "A1exy",
            "wzzju",
            "A1exy",
            "wzzju",
            "wzzju",
            "wwjjy",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "wanghaoshuang",
            "wanghaoshuang",
            "wwjjy",
            "wwjjy",
            "wanghaoshuang",
            "zzchust"
        ],
        "labels": [
            "user",
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3029,
        "title": "视频分类模型中数据集是youtobe-8M的问题",
        "body": "在跑视频分类attention lstm分类是，发现想测试自己的视频时，需要https://github.com/google/youtube-8m/tree/master/feature_extractor经过youtube-8M抽帧后过一下inception模型，得到视频帧的特征向量，然后在作为attention lstm的输入。\r\n\r\n这个为什么这么做，以及以youtube-8M数据集为输入的模型，能不能做成个可输入自己视频呢。",
        "state": "open",
        "user": "stard",
        "closed_by": null,
        "created_at": "2019-08-06T09:10:01+00:00",
        "updated_at": "2019-08-06T10:40:06+00:00",
        "closed_at": null,
        "comments_count": [
            "gavin1332",
            "stard"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3030,
        "title": "文档有误",
        "body": "文档链接：https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/docs/usage.md\r\n![d66ddfa2fecad0a18a853043d4fe2edd](https://user-images.githubusercontent.com/52770436/62527062-09fc8180-b86d-11e9-9402-4a45e96737fc.png)\r\n这里应为『该』\r\n![a039de6a479f3a41ec32a02127f1c6b2](https://user-images.githubusercontent.com/52770436/62527095-1a146100-b86d-11e9-8852-1ce3597909a4.png)\r\n这里多了个字",
        "state": "closed",
        "user": "mamingjie-China",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-06T09:10:56+00:00",
        "updated_at": "2019-08-07T02:00:05+00:00",
        "closed_at": "2019-08-07T02:00:05+00:00",
        "comments_count": [
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3038,
        "title": "Please specify --config=configure_file_path.",
        "body": "Please specify --config=configure_file_path.\r\n模型训练时报错，请问这个应该怎么解决呢？",
        "state": "open",
        "user": "zdyai",
        "closed_by": null,
        "created_at": "2019-08-07T01:53:59+00:00",
        "updated_at": "2019-08-08T03:48:56+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "Xreki"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3043,
        "title": "BERT 采用fp16预测出错",
        "body": "paddel: 1.5.1, CUDA9,\r\n在xnli任务上用如下脚本启动finetune(不加载pretrian参数，直接冷启动)会出错。如果加载pretrain参数`--init_pretraining_params ${MODEL_PATH}/params`会出一样的错误。\r\n```script\r\n./app/bin/python3 -u run_classifier.py \\\r\n                   --use_cuda true \\\r\n                   --do_train true \\\r\n                   --do_val true \\\r\n                   --do_test false \\\r\n                   --verbose true \\\r\n                   --batch_size 8192 \\\r\n                   --in_tokens true \\\r\n                   --data_dir ./xnli_data/ \\\r\n                   --vocab_path ${MODEL_PATH}/vocab.txt \\\r\n                   --bert_config_path ${MODEL_PATH}/ernie_config.json \\\r\n                   --checkpoints ./checkpoints \\\r\n                   --task_name xnli \\\r\n                   --save_steps 1000 \\\r\n                   --weight_decay  0.01 \\\r\n                   --warmup_proportion 0.0 \\\r\n                   --validation_steps 1000 \\\r\n                   --use_fp16 true \\\r\n                   --epoch 3 \\\r\n                   --max_seq_len 512 \\\r\n                   --learning_rate 1e-4 \\\r\n                   --skip_steps 10 \\\r\n                   --num_iteration_per_drop_scope 1 \\\r\n                   --random_seed 1\r\n~\r\n```\r\n\r\n报错信息：\r\n```script\r\nPython Callstacks:\r\n  File \"/home/work/chenxuyi/gits/models/PaddleNLP/language_representations_kit/BERT/app/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/work/chenxuyi/gits/models/PaddleNLP/language_representations_kit/BERT/app/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 1383, in _append_optimize_op\r\n    stop_gradient=True)\r\n  File \"/home/work/chenxuyi/gits/models/PaddleNLP/language_representations_kit/BERT/app/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 386, in _create_optimization_pass\r\n    param_and_grad)\r\n  File \"/home/work/chenxuyi/gits/models/PaddleNLP/language_representations_kit/BERT/app/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 532, in apply_gradients\r\n    optimize_ops = self._create_optimization_pass(params_grads)\r\n  File \"/home/work/chenxuyi/gits/models/PaddleNLP/language_representations_kit/BERT/optimization.py\", line 107, in optimization\r\n    optimizer.apply_gradients(master_param_grads)\r\n  File \"run_classifier.py\", line 209, in main\r\n    loss_scaling=args.loss_scaling)\r\n  File \"run_classifier.py\", line 426, in <module>\r\n    main(args)\r\nC++ Callstacks:\r\nTensor holds the wrong type, it holds ::paddle::platform::float16, but desires to be float at [/paddle/paddle/fluid/framework/tensor_impl.h:30]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f5c1be70890p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f5c1be70c09p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f5c1be77c89p float const* paddle::framework::Tensor::data<float>() const + 233\r\n3       0x7f5c1d2aa10bp paddle::operators::AdamOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 6507\r\n4       0x7f5c1d2aae53p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::Ad\r\namOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::AdamOpKernel<paddle::platform::CUDADeviceContext, double> >::operator()(char const*, char const*, int) const::{lambda(paddle::fra\r\nmework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n5       0x7f5c1defef67p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinned\r\nPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::deta\r\nil::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_\r\n, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n6       0x7f5c1deff341p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinned\r\nPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::deta\r\nil::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_\r\n, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n```",
        "state": "closed",
        "user": "Meiyim",
        "closed_by": "Meiyim",
        "created_at": "2019-08-07T08:17:23+00:00",
        "updated_at": "2019-08-09T07:17:19+00:00",
        "closed_at": "2019-08-09T07:17:19+00:00",
        "comments_count": [
            "Meiyim",
            "Xreki",
            "kuke"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3051,
        "title": "language_model 中 加profile 报错",
        "body": "环境：\r\npython：2.7.15\r\npaddle：1.5.1\r\ncuda：9\r\ncudnn：7\r\ngpu：P40\r\n\r\n执行命令：\r\npython train.py  --profile True --rnn_model static --log_path tmp_log_file --max_epoch 1 --data_path data/simple-examples/data/ --batch_size 8 --save_model_dir models_1 --use_gpu False --model_type test --use_py_reader True --parallel True\r\n\r\n报错信息：\r\n/paddle/paddle/fluid/platform/device_tracer.cc:414: error: function dynload::cuptiEnableCallback( 1, subscriber_, CUPTI_CB_DOMAIN_RUNTIME_API, cbid) failed with error CUPTI_ERROR_INVALID_PARAMETER.",
        "state": "closed",
        "user": "zhengya01",
        "closed_by": "zhengya01",
        "created_at": "2019-08-08T03:49:50+00:00",
        "updated_at": "2019-08-08T07:03:18+00:00",
        "closed_at": "2019-08-08T07:03:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3045,
        "title": "ocr_recognition 运行infer报错，看了很久没看出问题",
        "body": "```\r\n(pd) root@EDLL20190423:/mnt/e/ocr_recognition/ocr_recognition# python infer.py --model_path=\"./models/model_15000\" --inp\r\nut_images_list=\"input_list.txt\" --input_images_dir=\"input_images\" --use_gpu=\"False\" --model=\"attention\"\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 1\r\ndict: None\r\ninput_images_dir: input_images\r\ninput_images_list: input_list.txt\r\niterations: 0\r\nmodel: attention\r\nmodel_path: ./models/model_15000\r\nprofile: False\r\nskip_batch_num: 0\r\nuse_gpu: 0\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 157, in <module>\r\n    main()\r\n  File \"infer.py\", line 153, in main\r\n    inference(args)\r\n  File \"infer.py\", line 78, in inference\r\n    fluid.io.load_params(exe, dirname=model_dir, filename=model_file_name)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 699, in load_params\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 611, in load_vars\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 648, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load_combine error.\r\nPython Callstacks:\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 647, in load_vars\r\n    attrs={'file_path': os.path.join(load_dirname, filename)})\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 611, in load_vars\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/pd/lib/python3.6/site-packages/paddle/fluid/io.py\", line 699, in load_params\r\n    filename=filename)\r\n  File \"infer.py\", line 78, in inference\r\n    fluid.io.load_params(exe, dirname=model_dir, filename=model_file_name)\r\n  File \"infer.py\", line 153, in main\r\n    inference(args)\r\n  File \"infer.py\", line 157, in <module>\r\n    main()\r\nC++ Callstacks:\r\nYou are not allowed to load partial data via load_combine_op, use load_op instead. at [/paddle/paddle/fluid/operators/load_combine_op.h:100]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fa8d0743650p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7fa8d07439c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7fa8d0fa23b4p paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const + 1620\r\n3       0x7fa8d0fa275ep paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 798\r\n4       0x7fa8d0fa2b33p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n5       0x7fa8d1a8a547p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n6       0x7fa8d1a8acb1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n7       0x7fa8d1a88b5bp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 267\r\n8       0x7fa8d08c2c9ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 206\r\n9       0x7fa8d08c5d1fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n10      0x7fa8d0735e9dp\r\n11      0x7fa8d077297ep\r\n12      0x7fa8f134cc54p _PyCFunction_FastCallDict + 340\r\n13      0x7fa8f13d4c0ep\r\n14      0x7fa8f13f775ap _PyEval_EvalFrameDefault + 778\r\n15      0x7fa8f13cde66p\r\n16      0x7fa8f13ceed6p\r\n17      0x7fa8f13d4b95p\r\n18      0x7fa8f13f851cp _PyEval_EvalFrameDefault + 4300\r\n19      0x7fa8f13cde66p\r\n20      0x7fa8f13cee73p\r\n21      0x7fa8f13d4b95p\r\n22      0x7fa8f13f775ap _PyEval_EvalFrameDefault + 778\r\n23      0x7fa8f13cde66p\r\n24      0x7fa8f13ceed6p\r\n25      0x7fa8f13d4b95p\r\n26      0x7fa8f13f851cp _PyEval_EvalFrameDefault + 4300\r\n27      0x7fa8f13cde66p\r\n28      0x7fa8f13ceed6p\r\n29      0x7fa8f13d4b95p\r\n30      0x7fa8f13f851cp _PyEval_EvalFrameDefault + 4300\r\n31      0x7fa8f13cde66p\r\n32      0x7fa8f13ceed6p\r\n33      0x7fa8f13d4b95p\r\n34      0x7fa8f13f851cp _PyEval_EvalFrameDefault + 4300\r\n35      0x7fa8f13ce29ep\r\n36      0x7fa8f13ceed6p\r\n37      0x7fa8f13d4b95p\r\n38      0x7fa8f13f775ap _PyEval_EvalFrameDefault + 778\r\n39      0x7fa8f13cec5bp\r\n40      0x7fa8f13d4b95p\r\n41      0x7fa8f13f775ap _PyEval_EvalFrameDefault + 778\r\n42      0x7fa8f13cf9b9p PyEval_EvalCodeEx + 809\r\n43      0x7fa8f13d075cp PyEval_EvalCode + 28\r\n44      0x7fa8f1450744p\r\n45      0x7fa8f1450b41p PyRun_FileExFlags + 161\r\n46      0x7fa8f1450d43p PyRun_SimpleFileExFlags + 451\r\n47      0x7fa8f1454833p Py_Main + 1555\r\n48      0x7fa8f131e88ep main + 238\r\n49      0x7fa8f0a30830p __libc_start_main + 240\r\n50      0x7fa8f13fe160p\r\n```",
        "state": "closed",
        "user": "banbishan",
        "closed_by": "banbishan",
        "created_at": "2019-08-07T08:59:04+00:00",
        "updated_at": "2019-12-16T08:06:55+00:00",
        "closed_at": "2019-08-07T10:05:52+00:00",
        "comments_count": [
            "Xreki",
            "banbishan",
            "gaozheyuan"
        ],
        "labels": [
            "user",
            "Error Message"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3050,
        "title": "PaddleCV/Research/landmark推理时报错",
        "body": "环境\r\nUbuntu 16.04 \r\nRTX 2080Ti \r\ndocker:  hub.baidubce.com/paddlepaddle/paddle:1.5.1-gpu-cuda9.0-cudnn7\r\n\r\n按 Readme 要求在./pypredict 文件夹编译完PyCNNPredict 等 so文件，将so文件夹移至 ./inference 文件夹下 \r\n\r\n运行  \r\npython infer_retrieval.py test_retrieval res152_arcmargin\r\n报错\r\n\r\nTraceback (most recent call last):\r\n  File \"infer_retrieval.py\", line 10, in <module>\r\n    from PyCNNPredict import PyCNNPredict\r\nImportError: ./so/PyCNNPredict.so: undefined symbol: _ZN6paddle14AnalysisConfig18EnableAnakinEngineEiSt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt6vectorIiSaIiEESt4lessIS7_ESaISt4pairIKS7_SA_EEEiNS0_9PrecisionEbS8_IS7_SaIS7_EESK_\r\n\r\n",
        "state": "open",
        "user": "Jonxjdong",
        "closed_by": null,
        "created_at": "2019-08-08T02:16:45+00:00",
        "updated_at": "2019-10-30T06:26:18+00:00",
        "closed_at": null,
        "comments_count": [
            "Forrest-ht",
            "Forrest-ht"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3059,
        "title": "paddle代码在gpu环境运行，相同配置有时成功有时失败",
        "body": "在gpu集群运行ernie模型的预测代码，相同的配置 相同的程序 相同的数据 一次成功一次失败。gpu集群系统同学排查了机器环境每没有问题，烦请paddle同学帮排查下到底是哪里的问题。\r\njobid分别是d74b7752c02000跟d746b851818000",
        "state": "open",
        "user": "liuguolian",
        "closed_by": null,
        "created_at": "2019-08-08T08:52:28+00:00",
        "updated_at": "2019-08-08T13:20:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3055,
        "title": "百度之星Demo(int 8量化)改动后，量化失败",
        "body": "参考的源代码：https://aistudio.baidu.com/aistudio/projectdetail/86232\r\n![Cache_-6cb8d60c727cff60](https://user-images.githubusercontent.com/34909131/62679578-8024f380-b9e7-11e9-96be-74cb2b695558.jpg)\r\n上图是代码结果，代码和源代码不一样的地方就是：源代码读数据用的不是py_reader，而我改成了py_reader。代码如下：\r\n[main.py.zip](https://github.com/PaddlePaddle/models/files/3480121/main.py.zip)\r\n我在多台机器（环境不同）上测试过，发现结果都一样，所以我判断可能是我代码的问题，希望百度的大佬能指点一下，怎么改，非常感谢！\r\n环境信息：paddle版本1.5 、ubuntu16.04、cuda9.2、cudnn7.4、RTX2080TI、\r\n\r\n",
        "state": "open",
        "user": "TimeChi",
        "closed_by": null,
        "created_at": "2019-08-08T06:31:12+00:00",
        "updated_at": "2019-08-08T11:46:38+00:00",
        "closed_at": null,
        "comments_count": [
            "TimeChi",
            "wanghaoshuang",
            "TimeChi"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3056,
        "title": "导入两个模型进行inference，第二个模型运行出错，请帮忙看看",
        "body": "\r\n[decide.py.zip](https://github.com/PaddlePaddle/models/files/3480167/decide.py.zip)\r\n此文件会导入两个已训练的模型，再对输入的文件分别用这两个模型进行预测。\r\n导入不同模型看起来没有直接报错，但在运行时报了。请看：\r\n![0357b5b7edcaa9f9424cff2aa5046bca](https://user-images.githubusercontent.com/41142435/62680675-59b48780-b9ea-11e9-8576-3080aa3a459c.png)\r\n第一个模型可以正确预测，第二会报错，反过来也试过，同样是第二个出错。\r\n是否是create_eval_program内对每个模型进行定义和导入的方法错误，还是执行器的用法不对，请帮忙指正，多谢\r\n",
        "state": "closed",
        "user": "Tristan-Hao",
        "closed_by": "Tristan-Hao",
        "created_at": "2019-08-08T06:42:36+00:00",
        "updated_at": "2019-08-08T08:21:56+00:00",
        "closed_at": "2019-08-08T08:21:56+00:00",
        "comments_count": [
            "Tristan-Hao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3058,
        "title": "models/face_detection 使用发布模型PyramidBox_WiderFace做预测，发现对图片中的狗脸也框选出来了",
        "body": "",
        "state": "open",
        "user": "fengbecky",
        "closed_by": null,
        "created_at": "2019-08-08T07:57:57+00:00",
        "updated_at": "2019-08-08T12:27:17+00:00",
        "closed_at": null,
        "comments_count": [
            "fengbecky",
            "fengbecky",
            "fengbecky",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3057,
        "title": "百度之星Demo(int 8量化)baseline model量化后map很低",
        "body": "",
        "state": "closed",
        "user": "ZiruiChen",
        "closed_by": "ZiruiChen",
        "created_at": "2019-08-08T07:12:09+00:00",
        "updated_at": "2019-08-13T02:31:04+00:00",
        "closed_at": "2019-08-13T02:31:04+00:00",
        "comments_count": [
            "ZiruiChen",
            "ZiruiChen",
            "adaxi987",
            "ZiruiChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3061,
        "title": "wgan_loss使用gp的时候报错",
        "body": "https://github.com/PaddlePaddle/models/blob/v1.5.1/PaddleCV/PaddleGAN/trainer/StarGAN.py 根据stargan 的训练模式train，加入gp_loss 可是一直报错，d_loss+=gp_loss 时候 报错 grad_op_maker_ should not be null ，好像是 gp_loss 梯度截断有问题",
        "state": "closed",
        "user": "HLinShan",
        "closed_by": "shippingwang",
        "created_at": "2019-08-08T08:58:55+00:00",
        "updated_at": "2019-08-08T13:20:55+00:00",
        "closed_at": "2019-08-08T13:20:55+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3060,
        "title": "wgan_loss使用gp的时候报错",
        "body": "https://github.com/PaddlePaddle/models/blob/v1.5.1/PaddleCV/PaddleGAN/trainer/StarGAN.py 根据stargan 的训练模式train，加入gp_loss 可是一直报错，d_loss+=gp_loss 时候 报错 grad_op_maker_ should not be null ，好像是 gp_loss 梯度截断有问题",
        "state": "open",
        "user": "HLinShan",
        "closed_by": null,
        "created_at": "2019-08-08T08:58:42+00:00",
        "updated_at": "2019-08-15T02:55:52+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "HLinShan",
            "HLinShan",
            "HLinShan",
            "HLinShan",
            "ceci3",
            "luotao1",
            "Xreki"
        ],
        "labels": [
            "Error Message"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3064,
        "title": "编译出来的模型在ubuntu 上能使用 在android 上加载就报错",
        "body": "编译出来的模型在ubuntu 上能使用 在android 上加载就报错\r\ndemo 使用官方 的http://mms-graph.bj.bcebos.com/paddle-mobile%2FPaddleMobile_Android.zip\r\n没有更改任何代码 只更换了编译出来的model  报错信息如下\r\n\r\n2019-08-08 19:07:00.600 22732-22732/com.baidu.paddle I/paddle_mobile LOG built on Jul 12 2018 14:53:45: load invoked\r\n2019-08-08 19:07:00.648 22732-22732/com.baidu.paddle A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0 in tid 22732 (om.baidu.paddle), pid 22732 (om.baidu.paddle)\r\n",
        "state": "open",
        "user": "sckalman123",
        "closed_by": null,
        "created_at": "2019-08-08T11:18:48+00:00",
        "updated_at": "2019-08-16T11:29:25+00:00",
        "closed_at": null,
        "comments_count": [
            "sckalman123",
            "smilejames",
            "smilejames"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3068,
        "title": "PaddleCV/Research/astar2019/reader.py中的bug",
        "body": "[PaddleCV/Research/astar2019/reader.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/Research/astar2019/reader.py)中第74行有一处bug，代码如下\r\n\r\n```\r\n    @property\r\n    def apply_distort(self):    # line 74: 按功能，此处应该是 def apply_expand(self):\r\n        return self._apply_expand\r\n\r\n    @property\r\n    def apply_distort(self):\r\n        return self._apply_distort\r\n```",
        "state": "closed",
        "user": "brodra",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-08T14:55:47+00:00",
        "updated_at": "2019-08-12T12:50:03+00:00",
        "closed_at": "2019-08-12T12:50:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3062,
        "title": "请问下KT-NET代码怎么没有了呢？",
        "body": "如题",
        "state": "closed",
        "user": "shuxiaobo",
        "closed_by": "shuxiaobo",
        "created_at": "2019-08-08T09:04:00+00:00",
        "updated_at": "2019-08-16T05:30:35+00:00",
        "closed_at": "2019-08-16T05:30:35+00:00",
        "comments_count": [
            "shippingwang",
            "xyzhou-puck",
            "shuxiaobo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3066,
        "title": "DCGAN模板迁移到Baidu AI Studio平台上不能正确训练",
        "body": "训练指令!python train.py --model_net DCGAN --dataset mnist --noise_size 100 --batch_size 32 --epoch 10 --print_freq 100\r\n下图为训练到第九轮1600批次的结果，下半部分为生成器输出图形，没有东西\r\n![图片](https://user-images.githubusercontent.com/53502666/62701077-fc363000-ba15-11e9-8713-5c40ab47bb40.png)\r\n同时loss在训练两轮完就不变了\r\n![图片](https://user-images.githubusercontent.com/53502666/62701285-7bc3ff00-ba16-11e9-9dc1-7ee386ea0b75.png)\r\n",
        "state": "open",
        "user": "Yinxy1201",
        "closed_by": null,
        "created_at": "2019-08-08T11:58:12+00:00",
        "updated_at": "2019-08-19T13:30:08+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "Yinxy1201",
            "Yinxy1201",
            "Yinxy1201",
            "ceci3",
            "ceci3",
            "Yinxy1201",
            "ceci3",
            "Yinxy1201"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3067,
        "title": "PaddleDetection中的ssd什么时候可以训练coco数据集呀",
        "body": "",
        "state": "closed",
        "user": "universea",
        "closed_by": "shippingwang",
        "created_at": "2019-08-08T14:13:10+00:00",
        "updated_at": "2019-08-08T14:33:22+00:00",
        "closed_at": "2019-08-08T14:33:22+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3075,
        "title": "怎么对tensor进行reshape",
        "body": "我想将一个tensor(1000x4) reshape为一个(-1x4)的tensor，想问下这个怎么实现呢？",
        "state": "open",
        "user": "littletomatodonkey",
        "closed_by": null,
        "created_at": "2019-08-09T14:12:53+00:00",
        "updated_at": "2019-08-12T05:35:21+00:00",
        "closed_at": null,
        "comments_count": [
            "tensor-tang",
            "littletomatodonkey",
            "tensor-tang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3072,
        "title": "PaddleSlime量化后的模型是否对server-intelCPU的inference有加速作用",
        "body": "如题。\r\n\r\n目前针对server-intelCPU进行速度优化，希望之后经过paddleslim量化的model，使用paddle-cpu版本进行inference是否会有加速作用？\r\n\r\n针对server-intelCPU， paddle有哪些加速策略？\r\n我能想到的： 小型化模型、剪枝、mkldnn加速库",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "zzchust",
        "created_at": "2019-08-09T07:27:25+00:00",
        "updated_at": "2019-08-14T06:40:21+00:00",
        "closed_at": "2019-08-14T06:40:21+00:00",
        "comments_count": [
            "tensor-tang",
            "zzchust",
            "wzzju",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3076,
        "title": "关于fluid.layers.fc的简单疑问",
        "body": "![image](https://user-images.githubusercontent.com/2511581/62785340-07ab5900-baf3-11e9-87d7-0e4643767954.png)\r\npytorch的全链接层示例\r\n\r\n![image](https://user-images.githubusercontent.com/2511581/62785362-1560de80-baf3-11e9-91f4-1150db5d632d.png)\r\npaddle的示例，会报错`paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul error.`\r\n但换作是注释行是可以正常执行。\r\n\r\n是`mean`跟`fc`这两个OP对数据的要求不一样，还是说`fc`不支持这么写需要初始化w/b之类？",
        "state": "open",
        "user": "tsaizehua",
        "closed_by": null,
        "created_at": "2019-08-09T14:19:22+00:00",
        "updated_at": "2019-08-13T03:33:09+00:00",
        "closed_at": null,
        "comments_count": [
            "tensor-tang",
            "tsaizehua"
        ],
        "labels": [
            "Error Message"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3078,
        "title": "修改paddle bert报错NameError: global name 'epoch' is not defined",
        "body": "如题\r\n------------------------------------------------\r\nW0811 18:55:44.980177  2901 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 9.0, Runtime API Version: 8.0\r\nW0811 18:55:44.989336  2901 device_context.cc:267] device: 0, cuDNN Version: 6.0.\r\nW0811 18:55:44.989390  2901 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.1, but CUDNN version in your machine is 6.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nLoad pretraining parameters from models/base/uncased_L-12_H-768_A-12/params.\r\nWARNING:root:\r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n\r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n\r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage,\r\n         in order to fetch the right value of the fetch_list, please set the\r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None)\r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n\r\nI0811 18:55:46.771148  2901 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0811 18:55:46.947717  2901 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/home/work/anaconda2/envs/paddle_gpu/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/home/work/anaconda2/envs/paddle_gpu/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/work/anaconda2/envs/paddle_gpu/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 593, in __provider_thread__\r\n    raise ex\r\nNameError: global name 'epoch' is not defined\r\n\r\nTraceback (most recent call last):\r\n  File \"hae.py\", line 295, in <module>\r\n    main()\r\n  File \"hae.py\", line 272, in main\r\n    total_cost.extend(np_loss * np_num_seqs)\r\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'long'",
        "state": "closed",
        "user": "littlepan0413",
        "closed_by": "junjun315",
        "created_at": "2019-08-11T11:14:22+00:00",
        "updated_at": "2019-08-12T02:42:43+00:00",
        "closed_at": "2019-08-12T02:42:43+00:00",
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3077,
        "title": "求问paddle在做增量训练的时候，没有输入数据，生成的模型是原始的init的模型吗",
        "body": "求问paddle在做增量训练的时候，没有输入数据，生成的模型是原始的init的模型吗\r\n发现这种情况的模型并不是，不是知道在这种情况下paddle的模型生成机制是什么?",
        "state": "open",
        "user": "Emma-Ding",
        "closed_by": null,
        "created_at": "2019-08-09T14:29:35+00:00",
        "updated_at": "2019-08-11T03:24:52+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3085,
        "title": "PaddleDetection  使用 save_infer_model 后的模型infer报错 ",
        "body": "\r\nEnforce failed. Expected out_h > 0, but received out_h:0 <= 0:0   \r\n\r\n\r\n_upsample  时， out_shape 为0 ， 怀疑save_infer_model 没有保存获取 shape 的操作 shape_nchw = fluid.layers.shape(input)  导致",
        "state": "closed",
        "user": "xuzhm",
        "closed_by": "xuzhm",
        "created_at": "2019-08-12T07:49:49+00:00",
        "updated_at": "2019-08-12T10:00:41+00:00",
        "closed_at": "2019-08-12T10:00:41+00:00",
        "comments_count": [
            "wopeizl",
            "xuzhm",
            "qingqing01",
            "xuzhm",
            "heavengate",
            "xuzhm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3080,
        "title": "SSD模型加载预训练模型准确率很低",
        "body": "1.根据文档下载pascalvoc数据，以及预训练模型\r\n2.调试相应参数执行train.py \r\n\r\n\r\n-----------  Configuration Arguments -----------\r\nap_version: 11point\r\nbatch_size: 8\r\ndata_dir: D:/untitled/pratice/ssd/data/pascalvoc\r\ndataset: pascalvoc\r\nenable_ce: False\r\nepoc_num: 1000\r\nimage_shape: 3,300,300\r\nlearning_rate: 0.001\r\nmean_BGR: 127.5,127.5,127.5\r\nmodel_save_dir: D:\\untitled\\pratice\\ssd\\model\r\nparallel: 0\r\npretrained_model: D:\\untitled\\pratice\\ssd\\pretrained\\mobilenet_v1_imagenet\r\nuse_gpu: 0\r\n-------------------------------------\r\n3.执行结果：\r\nBatch 10, map [0.00233454]\r\nBatch 20, map [0.00179878]\r\nBatch 30, map [0.00124445]\r\nBatch 40, map [0.00154742]\r\nBatch 50, map [0.00117008]\r\nBatch 60, map [0.00101512]\r\nBatch 70, map [0.0009321]\r\nBatch 80, map [0.00084877]\r\nBatch 90, map [0.00079377]\r\nBatch 100, map [0.00078082]\r\nBatch 110, map [0.00077564]\r\nBatch 120, map [0.00079855]\r\nBatch 130, map [0.00077792]\r\nBatch 140, map [0.00077779]\r\nBatch 150, map [0.00077369]\r\nBatch 160, map [0.00073959]\r\nBatch 170, map [0.00072543]\r\nBatch 180, map [0.00071779]\r\nBatch 190, map [0.00069148]\r\nBatch 200, map [0.00067471]\r\nBatch 210, map [0.00065191]\r\nBatch 220, map [0.00062474]\r\nBatch 230, map [0.00062316]\r\nBatch 240, map [0.00062389]\r\n\r\n请问执行准确率这么低是什么原因？，是我操作传入参数有问题么？另外这个模型提供预训练模型，我想看下实际的准确率情况能否直接infer.py，将model_dir更改为预训练模型路径？我尝试了下报错，是不能这样验证么？\r\n\r\n\r\n",
        "state": "closed",
        "user": "liuzengzhen1",
        "closed_by": "liuzengzhen1",
        "created_at": "2019-08-12T03:27:29+00:00",
        "updated_at": "2019-08-12T10:30:41+00:00",
        "closed_at": "2019-08-12T10:30:41+00:00",
        "comments_count": [
            "qingqing01",
            "liuzengzhen1",
            "qingqing01",
            "liuzengzhen1",
            "liuzengzhen1",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3088,
        "title": "关于paddle.fluid.incubate.data_generator.MultiSlotDataGenerator的疑问",
        "body": "这个类怎么在官网的API中搜不到？我现在想处理一个用pickle保存的DataFrame文件，请问应该怎么做呢？我写了一个版本，但是读进来的貌似不是dataframe格式的。我的代码附在了下面",
        "state": "open",
        "user": "snksnc",
        "closed_by": null,
        "created_at": "2019-08-12T09:10:06+00:00",
        "updated_at": "2019-08-12T09:10:36+00:00",
        "closed_at": null,
        "comments_count": [
            "snksnc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3092,
        "title": "ernie代码输入结构修改导致np_loss=",
        "body": "",
        "state": "closed",
        "user": "littlepan0413",
        "closed_by": "littlepan0413",
        "created_at": "2019-08-12T11:59:47+00:00",
        "updated_at": "2019-08-12T12:06:27+00:00",
        "closed_at": "2019-08-12T12:06:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle-Lite",
        "number": 1790,
        "title": "ocr attention模型在ubuntu可以，但在android下报错",
        "body": "ocr attention模型在电脑上可以前向运算，但通过save_inference_model保存模型，在android上用c++调用的时候就报如下的错误\r\n![image](https://user-images.githubusercontent.com/13417277/62852352-c0ec7780-bd1b-11e9-8efd-656c8bf2d31e.png)\r\n",
        "state": "closed",
        "user": "banbishan",
        "closed_by": "qili93",
        "created_at": "2019-08-12T08:12:50+00:00",
        "updated_at": "2024-02-05T13:27:25+00:00",
        "closed_at": "2024-02-05T13:27:25+00:00",
        "comments_count": [
            "banbishan",
            "smilejames",
            "banbishan",
            "Superjomn",
            "xiaolvtaomi"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3090,
        "title": "预训练模型的默认学习策略是什么？迁移学习的时候，对于学习策略有什么要求？",
        "body": "预训练模型的默认学习策略是什么？迁移学习的时候，对于学习策略有什么要求？\r\nlr_strategy: learning rate changing strategy. Default: \"piecewise_decay\".\r\npretrained_model: model path for pretraining. Default: None.\r\n\r\n",
        "state": "open",
        "user": "lea4n",
        "closed_by": null,
        "created_at": "2019-08-12T10:18:00+00:00",
        "updated_at": "2019-08-26T02:37:56+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "lea4n",
            "lea4n"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3098,
        "title": "win10 YOLOv3 安装COCO-API报错",
        "body": "1.参照介绍文档安装报错\r\n`$ make install\r\n# install pycocotools to the Python site-packages\r\npython setup.py build_ext install\r\nrunning build_ext\r\nskipping 'pycocotools\\_mask.c' Cython extension (up-to-date)\r\nbuilding 'pycocotools._mask' extension\r\nerror: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools\r\nmake: *** [Makefile:8: install] Error 1\r\n`\r\n2.根据百度提示需要安装visual Studio 环境可以避免，在电脑安装Visual Studio 2015依然无法解决\r\n<img width=\"332\" alt=\"微信图片_20190813145530\" src=\"https://user-images.githubusercontent.com/52186737/62921247-bd6bf580-bdda-11e9-938e-8a0540e61128.png\">\r\n\r\n3.python 版本3.5.2\r\n",
        "state": "closed",
        "user": "liuzengzhen1",
        "closed_by": "liuzengzhen1",
        "created_at": "2019-08-13T06:59:20+00:00",
        "updated_at": "2019-08-15T10:50:21+00:00",
        "closed_at": "2019-08-13T10:49:02+00:00",
        "comments_count": [
            "heavengate",
            "liuzengzhen1"
        ],
        "labels": [
            "question"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3096,
        "title": "GPU is not fully utilized",
        "body": "when I use PaddleCV/ocr_recognition to train a recognition model, I found my four GPU only used one, other three GPU not be fully used, the result is as follows:\r\n\r\n![7610aacf88d8b1906a36bf597](https://user-images.githubusercontent.com/13143336/62868851-27d45580-bd49-11e9-940e-247faec3f936.png)\r\n\r\nCan anyone help to solve this problem?",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2019-08-12T13:37:30+00:00",
        "updated_at": "2019-08-15T10:49:48+00:00",
        "closed_at": "2019-08-13T10:40:02+00:00",
        "comments_count": [
            "SunGaofeng",
            "endy-see"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3093,
        "title": "ernie1.0代码输入结构修改导致np_loss=NoneType",
        "body": "因实验需要，在paddle bert代码的输入层增加了一层特征，导致loss为NoneType，\r\n一个样本\r\nunique_id: 1000000008\r\nexample_index: 8\r\ndoc_span_index: 0\r\ntokens: [CLS] life die instrument [SEP] allied successes were marred by the collision of two royal navy helicopters over the persian gulf in which all six british crew members and one american were killed [SEP]\r\ntoken_to_orig_map: 5:0 6:1 7:2 8:3 9:4 10:5 11:6 12:7 13:8 14:9 15:10 16:11 17:12 18:13 19:14 20:15 21:16 22:17 23:18 24:19 25:20 26:21 27:22 28:23 29:24 30:25 31:26 32:27\r\ntoken_is_max_context: 5:True 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True\r\ninput_ids: 101 2166 3280 6602 102 6035 14152 2020 24563 2011 1996 12365 1997 2048 2548 3212 12400 2058 1996 4723 6084 1999 2029 2035 2416 2329 3626 2372 1998 2028 2137 2020 2730 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\ninput_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\nsegment_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\nhistory_marker_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\nstart_position: 13\r\nend_position: 16\r\nanswer: two royal navy helicopters\r\n\r\n下面的hae.py和run_squad.py差不多\r\n\r\n报错信息\r\n【train】 current step 0 , loss None, num_seqs [0], time 59.1902229786s\r\nTraceback (most recent call last):\r\n  File \"hae.py\", line 295, in <module>\r\n    main()\r\n  File \"hae.py\", line 275, in main\r\n    total_cost.extend(np_loss * np_num_seqs)\r\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'long'\r\n\r\n\r\n模型修改部分如下\r\nmodel/bert.py\r\n![image](https://user-images.githubusercontent.com/6512760/62864087-5b10e780-bd3d-11e9-97c4-376a23ae0193.png)\r\n\r\nhae.py\r\n![image](https://user-images.githubusercontent.com/6512760/62864158-8c89b300-bd3d-11e9-8f04-1d290eab82b9.png)\r\n\r\n",
        "state": "closed",
        "user": "littlepan0413",
        "closed_by": "0YuanZhang0",
        "created_at": "2019-08-12T12:13:02+00:00",
        "updated_at": "2019-08-15T10:47:44+00:00",
        "closed_at": "2019-08-13T10:21:50+00:00",
        "comments_count": [
            "kuke",
            "0YuanZhang0",
            "0YuanZhang0"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3099,
        "title": "医学文本分词预处理",
        "body": "非常感谢百度能够提供这么多实用、好用的深度学习模型，现有个问题咨询一下。\r\n\r\n我想通过`PaddleNLP/preprocess`下提供的分词预处理脚本`tokenizer.py`对医学文本进行分词，使用过程中发现该脚本依赖于预训练模型`--model_path`、`--word_dict_path`、`--label_dict_path`和`--word_rep_dict_path`等参数。\r\n\r\n**我想针对特定的医学文本数据生成上述四个参数所需要的文件**，但不知从何下手。望各位给予帮助和解答，非常感谢。",
        "state": "closed",
        "user": "lixiangchun",
        "closed_by": "lixiangchun",
        "created_at": "2019-08-13T09:16:39+00:00",
        "updated_at": "2019-08-26T13:06:02+00:00",
        "closed_at": "2019-08-26T13:06:02+00:00",
        "comments_count": [
            "Halfish"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3100,
        "title": "operator matmul error",
        "body": "我根据\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/language_representations_kit/BERT 中介绍的方法下载 XNLI dev/test set 和 XNLI machine-translated training set，然后解压到同一个目录。\r\n启动 Fine-tuning ， **启动脚本如下**：\r\n\r\n```shell\r\n    export FLAGS_sync_nccl_allreduce=0\r\n    export FLAGS_eager_delete_tensor_gb=1\r\n    export CUDA_VISIBLE_DEVICES=${1}\r\n\r\n    BERT_BASE_PATH=hqa/uncased_L-12_H-768_A-12\r\n    TASK_NAME='XNLI'\r\n    DATA_PATH=hqa/ace/sent_v1/xnli\r\n    CKPT_PATH=hqa/checkpoints-sent\r\n\r\n    python -u run_classifier.py \\\r\n                       --task_name ${TASK_NAME} \\\r\n                       --use_cuda true \\\r\n                       --do_train true \\\r\n                       --do_val true \\\r\n                       --do_test true \\\r\n                       --batch_size 32 \\\r\n                       --in_tokens false \\\r\n                       --init_pretraining_params ${BERT_BASE_PATH}/params \\\r\n                       --data_dir ${DATA_PATH} \\\r\n                       --vocab_path ${BERT_BASE_PATH}/vocab.txt \\\r\n                       --checkpoints ${CKPT_PATH} \\\r\n                       --save_steps 1000 \\\r\n                       --weight_decay  0.01 \\\r\n                       --warmup_proportion 0.1 \\\r\n                       --validation_steps 100 \\\r\n                       --epoch 1 \\\r\n                       --max_seq_len 60 \\\r\n                       --bert_config_path ${BERT_BASE_PATH}/bert_config.json \\\r\n                       --learning_rate 1e-5 \\\r\n                       --skip_steps 10 \\\r\n                       --num_iteration_per_drop_scope 10 \\\r\n                       --use_fp16 true \\\r\n                       --verbose true\r\n```\r\n\r\n**错误信息如下**：\r\n```shell\r\nshare_vars_from is set, scope is ignored.\r\nI0813 17:18:54.545492 23654 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0813 17:18:54.568922 23654 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\ntrain pyreader queue size: 50, learning rate: 0.000000\r\nepoch: 0, progress: 1697/392702, step: 0, ave loss: nan, ave acc: 0.34375\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 444, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 321, in main\r\n    outputs = train_exe.run(fetch_list=fetch_list)\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/parallel_executor.py\", line 280, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 666, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 528, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator matmul error.\r\nPython Callstacks:\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/work/anaconda2/envs/yuanzhen3/lib/python3.5/site-packages/paddle/fluid/layers/nn.py\", line 5255, in matmul\r\n    'alpha': float(alpha),\r\n  File \"/home/work/liuyuanzhen/baidu/event-graph/ERNIE/BERT/model/bert.py\", line 116, in _build_model\r\n    x=input_mask, y=input_mask, transpose_y=True)\r\n  File \"/home/work/liuyuanzhen/baidu/event-graph/ERNIE/BERT/model/bert.py\", line 81, in __init__\r\n    self._build_model(src_ids, position_ids, sentence_ids, input_mask)\r\n  File \"/home/work/liuyuanzhen/baidu/event-graph/ERNIE/BERT/model/classifier.py\", line 48, in create_model\r\n    use_fp16=args.use_fp16)\r\n  File \"run_classifier.py\", line 199, in main\r\n    num_labels=num_labels)\r\n  File \"run_classifier.py\", line 444, in <module>\r\n    main(args)\r\nC++ Callstacks:\r\nCUBLAS: arch mismatch,  at [/paddle/paddle/fluid/operators/math/blas_impl.cu.h:149]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f3f380cdf00p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f3f380ce279p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f3f3884a4e7p void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<paddle::platform::float16>(paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::platform::float16, paddle::framework::Tensor*, paddle::platform::float16) const + 1415\r\n3       0x7f3f3884aa60p paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16>::Compute(paddle::framework::ExecutionContext const&) const + 784\r\n4       0x7f3f3884ab73p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 2ul, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n5       0x7f3f3a14d157p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n6       0x7f3f3a14d531p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n7       0x7f3f3a14ab2cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n8       0x7f3f39f46bcap paddle::framework::details::ComputationOpHandle::RunImpl() + 250\r\n9       0x7f3f39f39570p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n10      0x7f3f39e9285cp paddle::framework::details::ThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*) + 316\r\n11      0x7f3f39e8d767p paddle::framework::details::ThreadedSSAGraphExecutor::RunTracedOps(std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> > const&) + 71\r\n12      0x7f3f39e95a7bp paddle::framework::details::ThreadedSSAGraphExecutor::RunImpl(std::vector<std::string, std::allocator<std::string> > const&) + 3547\r\n13      0x7f3f39e92282p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 482\r\n14      0x7f3f39e7e69cp paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 124\r\n15      0x7f3f382a4df1p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 305\r\n16      0x7f3f380bf25ep\r\n17      0x7f3f38100816p\r\n18      0x7f3f897d62d8p PyCFunction_Call + 120\r\n19      0x7f3f89831dd6p PyEval_EvalFrameEx + 23686\r\n20      0x7f3f89831aa4p PyEval_EvalFrameEx + 22868\r\n21      0x7f3f89831351p PyEval_EvalFrameEx + 20993\r\n22      0x7f3f89831351p PyEval_EvalFrameEx + 20993\r\n23      0x7f3f8982cc20p PyEval_EvalFrameEx + 2768\r\n24      0x7f3f898372adp PyEval_EvalCodeEx + 525\r\n25      0x7f3f898381fcp PyEval_EvalCode + 28\r\n26      0x7f3f898958d4p\r\n27      0x7f3f89896f41p PyRun_FileExFlags + 161\r\n28      0x7f3f8989715ep PyRun_SimpleFileExFlags + 478\r\n29      0x7f3f8989780dp Py_Main + 1485\r\n30      0x7f3f89761571p main + 225\r\n31      0x7f3f88ea7b45p __libc_start_main + 245\r\n32      0x7f3f89839f38p\r\n```",
        "state": "closed",
        "user": "OOMMYY",
        "closed_by": "OOMMYY",
        "created_at": "2019-08-13T09:25:29+00:00",
        "updated_at": "2019-08-15T10:50:53+00:00",
        "closed_at": "2019-08-13T14:08:24+00:00",
        "comments_count": [
            "SunGaofeng",
            "OOMMYY",
            "OOMMYY",
            "SunGaofeng",
            "OOMMYY"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3101,
        "title": "请问IJCAI2019-MMPMS的微博数据集哪里可以下载呢，里面的链接是论文，而论文的数据链接失效了",
        "body": "",
        "state": "closed",
        "user": "YiLing28",
        "closed_by": "YiLing28",
        "created_at": "2019-08-13T09:45:26+00:00",
        "updated_at": "2019-08-15T10:46:53+00:00",
        "closed_at": "2019-08-14T06:38:20+00:00",
        "comments_count": [
            "sserdoubleh",
            "YiLing28"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3103,
        "title": "ocr attention模型用fluid.io.save_inference_model保存模型后，load运行报错",
        "body": "我在infer.py里加了\r\npath = \"./infer_model\"\r\nfluid.io.save_inference_model(dirname=path, feeded_var_names=['pixel'],target_vars=[ids])\r\n\r\nload运行后报错如下\r\n![image](https://user-images.githubusercontent.com/13417277/62933585-19dc0e80-bdf5-11e9-8277-d023d6228301.png)\r\nload代码：\r\n```\r\nimport paddle.fluid as fluid\r\nimport numpy as np\r\n\r\nfile_name = 'demo_1_3_48_384_nchw_float'\r\nfile = np.fromfile(file_name,'f')\r\n\r\nexe = fluid.Executor(fluid.CPUPlace())\r\npath = \"/mnt/e/docker/infer_model\"\r\n[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=path, executor=exe)\r\nresults = exe.run(inference_program,\r\n              feed={feed_target_names[0]: file},\r\n              fetch_list=fetch_targets)\r\n```",
        "state": "closed",
        "user": "banbishan",
        "closed_by": "banbishan",
        "created_at": "2019-08-13T10:07:26+00:00",
        "updated_at": "2019-08-22T04:13:07+00:00",
        "closed_at": "2019-08-22T04:13:07+00:00",
        "comments_count": [
            "wanghaoshuang",
            "OliverLPH",
            "OliverLPH",
            "banbishan"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3106,
        "title": "最近 LAC 总挂",
        "body": "之前跑了至少一个月，没有问题，现在总挂。怀疑是 RowwiseAdd 的问题。 @kuke \r\n\r\n`*** Aborted at 1565738568 (unix time) try \"date -d @1565738568\" if you are using GNU date ***          [34/1890]\r\nPC: @                0x0 (unknown)                                                                              \r\n*** SIGFPE (@0x7f5928dc75bb) received by PID 24783 (TID 0x7f598b8c3740) from PID 685536699; stack trace: ***    \r\n    @     0x7f598b4ae890 (unknown)                                                                              \r\n    @     0x7f5928dc75bb paddle::operators::math::RowwiseAdd<>::operator()()                                    \r\n    @     0x7f5927caadbf paddle::operators::GRUCPUKernel<>::BatchCompute()                                      \r\n    @     0x7f5927cac2b3 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelReg$\r\nstrarFunctorINS0_8platform8CPUPlaceELb0ELm0EJNS0_9operators12GRUCPUKernelIfEENSA_IdEEEEclEPKcSF_iEUlS4_E_E9_M_i$\r\nvokeERKSt9_Any_dataS4_                                                                                          \r\n    @     0x7f5928d99376 paddle::framework::OperatorWithKernel::RunImpl()                                       \r\n    @     0x7f5928d99ae4 paddle::framework::OperatorWithKernel::RunImpl()                                       \r\n    @     0x7f5928d9740c paddle::framework::OperatorBase::Run()                                                 \r\n    @     0x7f592727c3fe paddle::framework::Executor::RunPreparedContext()                                      \r\n    @     0x7f592727d23f paddle::framework::Executor::Run()                                                     \r\n    @     0x7f59270f98de _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL18pybind11_init_coreERNS_6mod$\r\nleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE97_vIS8_SB_SD_ibbSI_EIN$\r\n_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_          \r\n    @     0x7f592713c7ce pybind11::cpp_function::dispatcher()                                                   \r\n    @     0x562becacf9e4 _PyCFunction_FastCallDict                                                              \r\n    @     0x562becb5cf4e call_function                                                                          \r\n    @     0x562becb8194a _PyEval_EvalFrameDefault                                                               \r\n    @     0x562becb56206 _PyEval_EvalCodeWithName                                                               \r\n    @     0x562becb571cf fast_function                                                                          \r\n    @     0x562becb5ced5 call_function                                                                          \r\n    @     0x562becb82715 _PyEval_EvalFrameDefault                                                               \r\n    @     0x562becb56206 _PyEval_EvalCodeWithName                                                               \r\n    @     0x562becb571cf fast_function\r\n    @     0x562becb5ced5 call_function\r\n    @     0x562becb82715 _PyEval_EvalFrameDefault\r\n    @     0x562becb5662e _PyEval_EvalCodeWithName\r\n    @     0x562becb57897 _PyFunction_FastCallDict\r\n    @     0x562becacfdaf _PyObject_FastCallDict\r\n    @     0x562becad4a73 _PyObject_Call_Prepend\r\n    @     0x562becacfbcb _PyObject_FastCallDict\r\n    @     0x562becbc44b2 partial_call\r\n    @     0x562becacfbcb _PyObject_FastCallDict\r\n    @     0x562becb5748a _PyObject_FastCallKeywords\r\n    @     0x562becb5cf4e call_function\r\n    @     0x562becb82715 _PyEval_EvalFrameDefault\r\n`\r\n[lac_error_log.txt](https://github.com/PaddlePaddle/models/files/3499290/lac_error_log.txt)\r\n",
        "state": "open",
        "user": "daming-lu",
        "closed_by": null,
        "created_at": "2019-08-13T23:54:01+00:00",
        "updated_at": "2020-04-10T15:26:59+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "daming-lu",
            "mibxu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3105,
        "title": "关于ARNOR论文中的数据集",
        "body": "您好，首先感谢百度飞桨公开的数据集\r\n我对ARNOR这篇论文很感兴趣，最近也在复现这篇论文，但是遇到几个问题想请教一下\r\n1.数据集中entityMentions字段中的start有什么含义吗？\r\n2.dev.jaon和test.json也有部分\"is_noise\": true的数据，这部分数据在论文里Evaluation时都用上了吗？\r\n3.文中所说的sentencelevel evaluation 和 bag-level evaluation 具体是怎么做呢？这块没太读明白。\r\n再次感谢您",
        "state": "open",
        "user": "HeYilong0316",
        "closed_by": null,
        "created_at": "2019-08-13T18:30:05+00:00",
        "updated_at": "2019-08-19T06:38:42+00:00",
        "closed_at": null,
        "comments_count": [
            "HeYilong0316",
            "kahitomi",
            "HeYilong0316",
            "kahitomi",
            "HeYilong0316",
            "kahitomi",
            "HeYilong0316"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3107,
        "title": "similarity_net infer报错",
        "body": "BUG复现步骤：\r\n\r\n环境：\r\n\r\nlinux\r\n\r\npython2.7\r\n\r\npaddle1.5.1\r\n\r\ncuda 9\r\n\r\ncudnn 7\r\n\r\n\r\n\r\n命令\r\nsh run.sh infer\r\n\r\n报错信息：\r\nstart test process ...\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 476, in <module>\r\n    main(conf_dict, args)\r\n  File \"run_classifier.py\", line 457, in main\r\n    infer(args)\r\n  File \"run_classifier.py\", line 435, in infer\r\n    infer_file.write(_data + \"\\t\" + _pred + \"\\n\")\r\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\u4f60' in position 0: ordinal not in range(128)\r\n\r\n",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2019-08-14T02:42:57+00:00",
        "updated_at": "2019-08-14T12:16:27+00:00",
        "closed_at": null,
        "comments_count": [
            "Lizhengo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3111,
        "title": "neural_machine_translation/transformer没有models.py文件",
        "body": "没有找到model.py文件，下载的big_model及base_model是替代models.py文件吗？如何使用big_model及base_model文件",
        "state": "open",
        "user": "o0Monica0o",
        "closed_by": null,
        "created_at": "2019-08-14T11:06:16+00:00",
        "updated_at": "2019-08-15T11:34:35+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3110,
        "title": "[PaddleSlim] mobilenet_v1_ssd剪裁率是0",
        "body": "![image](https://user-images.githubusercontent.com/50459712/63013504-b4108500-becf-11e9-8040-6f08ded81118.png)\r\n如图 pruned size 和pruned flops 是0 没有剪裁效果",
        "state": "closed",
        "user": "ZiruiChen",
        "closed_by": "ZiruiChen",
        "created_at": "2019-08-14T10:11:59+00:00",
        "updated_at": "2019-08-23T03:22:38+00:00",
        "closed_at": "2019-08-23T03:22:38+00:00",
        "comments_count": [
            "ZiruiChen",
            "ZiruiChen",
            "ZiruiChen",
            "ZiruiChen",
            "ZiruiChen",
            "ZiruiChen",
            "wanghaoshuang",
            "ZiruiChen",
            "wanghaoshuang",
            "ZiruiChen",
            "ZiruiChen",
            "zzchust",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "zzchust",
            "ZiruiChen",
            "ZiruiChen",
            "wanghaoshuang",
            "slf12",
            "slf12",
            "slf12",
            "ZiruiChen",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3112,
        "title": "attention_lstm模型无法运行",
        "body": "运行官网两种test方式都报错，\r\n![I{K81RIH(Q55JY48(DZMCIU](https://user-images.githubusercontent.com/48506731/63016681-e23d9700-bec6-11e9-8af9-860ed27738c8.png)\r\n\r\n下载的是youtube8m的frame格式文件，并且已经转成了pkl格式的。\r\n",
        "state": "open",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": null,
        "created_at": "2019-08-14T11:10:03+00:00",
        "updated_at": "2019-09-19T02:11:09+00:00",
        "closed_at": null,
        "comments_count": [
            "AIaiAIaiAIaiAI",
            "AIaiAIaiAIaiAI",
            "SunGaofeng",
            "trawy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3113,
        "title": "BERT predict_classifier.py脚本保存的inference_model需要怎么使用load使用",
        "body": "我想通过load_inference_model函数来加载模型参数，然后进行预测，代码如下：\r\nargs = parser.parse_args()\r\nplace = fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\ntask_name = args.task_name.lower()\r\nprocessors = {\r\n    'xnli': reader.XnliProcessor,\r\n    'cola': reader.ColaProcessor,\r\n    'mrpc': reader.MrpcProcessor,\r\n    'mnli': reader.MnliProcessor,\r\n}\r\n\r\nprocessor = processors[task_name](data_dir=args.data_dir,\r\n                                  vocab_path=args.vocab_path,\r\n                                  max_seq_len=args.max_seq_len,\r\n                                  do_lower_case=args.do_lower_case,\r\n                                  in_tokens=False)\r\nnum_labels = len(processor.get_labels())\r\npredict_pyreader = fluid.layers.py_reader(\r\n    capacity=50,\r\n    shapes=[[-1, args.max_seq_len, 1], [-1, args.max_seq_len, 1],\r\n            [-1, args.max_seq_len, 1], [-1, args.max_seq_len, 1], [-1, 1]],\r\n    dtypes=['int64', 'int64', 'int64', 'float32', 'int64'],\r\n    lod_levels=[0, 0, 0, 0, 0],\r\n    name='predict_reader',\r\n    use_double_buffer=True)\r\ninfer_program, feed_list, fetch_target = fluid.io.load_inference_model(\"infer_model/checkpoints_inference_model\", exe)\r\npredict_pyreader.decorate_tensor_provider(\r\n        processor.data_generator(\r\n            batch_size=args.batch_size, phase='test', epoch=1, shuffle=False))\r\npredict_pyreader.start()\r\nall_results = []\r\ntime_begin = time.time()\r\nwhile True:\r\n    try:\r\n        results = exe.run(infer_program, fetch_list=fetch_target)\r\n        all_results.extend(results[0])\r\n    except fluid.core.EOFException:\r\n        predict_pyreader.reset()\r\n        break\r\ntime_end = time.time()\r\n\r\nnp.set_printoptions(precision=4, suppress=True)\r\nprint(\"-------------- prediction results --------------\")\r\nprint(\"example_id\\t\" + '  '.join(processor.get_labels()))\r\nfor index, result in enumerate(all_results):\r\n    print(str(index) + '\\t{}'.format(result))\r\n运行后错误信息如下：\r\n<img width=\"1021\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63021540-64cc5380-bed3-11e9-97c6-4f2043cce0bf.png\">\r\n请问应该如何正确使用predict_classifier.py保存的固化模型",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-08-14T12:39:23+00:00",
        "updated_at": "2019-08-14T12:49:11+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3115,
        "title": "gan例子infer错误",
        "body": "我使用https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/PaddleGAN，里的infer.py和https://paddle-gan-models.bj.bcebos.com/stargan_G.tar.gz的预训练模型去预测老是出错：\r\nC++ Callstacks:\r\nEnforce failed. Expected in_dims[1] == filter_dims[1] * groups, but received in_\r\ndims[1]:16 != filter_dims[1] * groups:8.\r\nThe number of input channels should be equal to filter channels * groups. at [D:\r\n\\1.4.1\\paddle\\paddle\\fluid\\operators\\conv_op.cc:64]\r\nPaddlePaddle Call Stacks:\r\nWindows not support stack backtrace yet.\r\n\r\n详细输出信息见附件output.txt文件。文件基本没改。我调试的一点看法是, exe.run初始化能print看到里网络输出了,(1,3,128,128)数据，表示网络没问题，feed数据后就exe.run就报错，判断是输入不对，检查输入input:(1,3,128,128), label trg (1,13)和data定义一样，但就是报错，没办法了，请帮助。infer.py,data_reaer.py有小小改动，需要发给你，基本和没改一样。\r\n环境信息：\r\npython:3.7.1\r\npaddle: 1.4.1\r\nos: win7 64bit\r\ngpu: no\r\n[output.txt](https://github.com/PaddlePaddle/models/files/3504616/output.txt)\r\n",
        "state": "closed",
        "user": "githubusr1",
        "closed_by": "githubusr1",
        "created_at": "2019-08-15T07:39:52+00:00",
        "updated_at": "2019-08-17T08:32:57+00:00",
        "closed_at": "2019-08-17T08:32:56+00:00",
        "comments_count": [
            "sandyhouse",
            "githubusr1",
            "githubusr1",
            "githubusr1",
            "ceci3",
            "githubusr1",
            "githubusr1",
            "githubusr1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3117,
        "title": "ELMo 的train.py脚本中貌似有错误哦~",
        "body": "train.py的第392行的training_role变量貌似没有定义就直接被使用了~\r\n还有就是我 想通过命令行的方式将local参数改为false，但是程序运行还是true，如下：\r\n<img width=\"1021\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63090843-1da39880-bf8f-11e9-9e4e-5ebfb264e6c0.png\">\r\n",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-08-15T11:02:59+00:00",
        "updated_at": "2019-08-16T08:07:58+00:00",
        "closed_at": null,
        "comments_count": [
            "sandyhouse",
            "JesseyXujin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3116,
        "title": "关于fluid.layers.detection 中函数使用的疑问",
        "body": "detection_output 这个函数的功能是否等同于  box_coder（解码）+ multiclass_nms\r\n我针对官方ssd模型的输出利用上面两种方法获取nms_out进行比较发现差距比较大。部分代码如下\r\n1. \r\n```\r\nimage = fluid.layers.data(name='image', shape=[3,300,300], dtype='float32')\r\nlocs, confs, box, box_var = mobilenet_ssd.build_mobilenet_ssd(image, 81, [3,300,300])\r\nboxes = fluid.layers.box_coder(box,box_var,locs,code_type=\"decode_center_size\")\r\nscores = fluid.layers.transpose(confs,perm=[0,2,1])\r\nnms_out = fluid.layers.multiclass_nms(\r\n            bboxes=boxes,\r\n            scores=scores,\r\n            score_threshold=0.01,\r\n            nms_top_k=-1,\r\n            nms_threshold=0.45,\r\n            keep_top_k=-1,\r\n            normalized=False)\r\n```\r\n2.\r\n```\r\nimage = fluid.layers.data(name='image', shape=[3,300,300], dtype='float32')\r\nlocs, confs, box, box_var = mobilenet_ssd.build_mobilenet_ssd(image, 81, [3,300,300])\r\nnms_out = fluid.layers.detection_output(\r\n            locs, confs, box, box_var, nms_threshold=0.45)\r\n```\r\n如果第一种方法有误，望指点正确的操作，谢谢。",
        "state": "closed",
        "user": "WangTaoSpace",
        "closed_by": "WangTaoSpace",
        "created_at": "2019-08-15T07:54:07+00:00",
        "updated_at": "2019-08-16T11:57:09+00:00",
        "closed_at": "2019-08-16T11:57:09+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse",
            "WangTaoSpace"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3120,
        "title": "/models-1.5/PaddleCV/image_classification执行infer和eval报同样错误",
        "body": "[image_classification]$ fluid infer.py                                        \r\n/home/hicqa/paddle/paddle_release_home/python/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\r\n  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\r\n-------------  Configuration Arguments -------------\r\n                class_dim : 1000\r\n              image_shape : 3,224,224\r\n                    model : SE_ResNeXt50_32x4d\r\n         pretrained_model : None\r\n        resize_short_size : 256\r\n           save_inference : False\r\n                  use_gpu : True\r\n             with_mem_opt : True\r\nmemory_optimize is deprecated. Use CompiledProgram and Executor\r\nW0816 11:01:36.875445 44793 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW0816 11:01:36.880609 44793 device_context.cc:267] device: 0, cuDNN Version: 7.4.\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 115, in <module>\r\n    main()\r\n  File \"infer.py\", line 111, in main\r\n    infer(args)\r\n  File \"infer.py\", line 80, in infer\r\n    fluid.io.load_persistables(exe, pretrained_model)\r\n  File \"/home/hicqa/paddle/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/io.py\", line 747, in load_persistables\r\n    filename=filename)\r\n  File \"/home/hicqa/paddle/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/io.py\", line 599, in load_vars\r\n    load_dirname = os.path.normpath(dirname)\r\n  File \"/home/hicqa/paddle/paddle_release_home/python/lib/python2.7/posixpath.py\", line 335, in normpath\r\n    initial_slashes = path.startswith('/')\r\nAttributeError: 'NoneType' object has no attribute 'startswith'",
        "state": "open",
        "user": "duanlin0505",
        "closed_by": null,
        "created_at": "2019-08-16T03:05:14+00:00",
        "updated_at": "2019-08-26T04:18:05+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "duanlin0505"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3123,
        "title": "DeepCTR 的数据读取问题",
        "body": "如题，DeepCTR的reader是不是针对raw data写的，而不是preprocess写的，使用preprocess处理过数据后，数据存储的格式和raw data不一样，但是reader的读取方式看起来应该时读取raw data的方式~",
        "state": "closed",
        "user": "wwjjy",
        "closed_by": "ceci3",
        "created_at": "2019-08-16T11:39:21+00:00",
        "updated_at": "2019-08-19T03:02:22+00:00",
        "closed_at": "2019-08-19T03:02:22+00:00",
        "comments_count": [
            "ceci3",
            "wwjjy",
            "ceci3",
            "ceci3",
            "wwjjy",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3124,
        "title": "error: function dynload::cuptiEnableCallback( 1, subscriber_, CUPTI_CB_DOMAIN_RUNTIME_API, cbid) failed with error CUPTI_ERROR_INVALID_PARAMETER",
        "body": "My docker image: \r\n<img width=\"1405\" alt=\"1\" src=\"https://user-images.githubusercontent.com/13143336/63169460-7182b000-c069-11e9-9ec4-6651ce37f29b.png\">\r\nMy System info:       Ubuntu 16.04.5 LTS \\n \\l\r\nMy CUDA Version:   CUDA Version 10.0.130\r\n\r\nWhen I run PaddleCV/ocr_recognition model, there is a problem:\r\n<img width=\"1202\" alt=\"2\" src=\"https://user-images.githubusercontent.com/13143336/63169488-82cbbc80-c069-11e9-90e7-9b6cac5f1f05.png\">\r\n\r\nIn addition,  below images also has similar problem:\r\n![WX20190816-205718](https://user-images.githubusercontent.com/13143336/63169153-a80bfb00-c068-11e9-9eb6-11d70372e6aa.png)\r\n\r\nCan anyone help me solve this problem as soon as possible? Thank you in advance!",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-08-16T12:59:16+00:00",
        "updated_at": "2020-12-25T03:29:45+00:00",
        "closed_at": null,
        "comments_count": [
            "mmglove",
            "endy-see",
            "mmglove",
            "endy-see",
            "endy-see",
            "ceci3",
            "wang-kangkang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3121,
        "title": "量化结束后未保存任何模型",
        "body": "使用的代码如下，但是并没有任何模型保存下来\r\n```\r\n    com_pass = Compressor(\r\n        place,\r\n        fluid.global_scope(),\r\n        train_prog,\r\n        train_reader=train_py_reader,\r\n        train_feed_list=None,\r\n        train_fetch_list=train_fetch_list,\r\n        eval_program=test_prog,\r\n        eval_reader=test_py_reader,\r\n        eval_feed_list=None,\r\n        eval_fetch_list=val_fetch_list,\r\n        train_optimizer=None)\r\n\r\n    com_pass.config(args.compress_config)\r\n    com_pass.run()\r\n```\r\nconfig：\r\n```\r\nversion: 1.0\r\nstrategies:\r\n    quantization_strategy:\r\n        class: 'QuantizationStrategy'\r\n        start_epoch: 0\r\n        end_epoch: 9\r\n        float_model_save_path: './output/float'\r\n        mobile_model_save_path: './output/mobile'\r\n        int8_model_save_path: './output/int8'\r\n        weight_bits: 8\r\n        activation_bits: 8\r\n        weight_quantize_type: 'abs_max'\r\n        activation_quantize_type: 'range_abs_max'\r\n        save_in_nodes: ['read_file_0.tmp_0']\r\n        save_out_nodes: ['detection_output_0.tmp_0']\r\ncompressor:\r\n    epoch: 10\r\n    checkpoint_path: './checkpoints_quan_fintune/'\r\n    strategies:\r\n        - quantization_strategy\r\n```",
        "state": "closed",
        "user": "imistyrain",
        "closed_by": "imistyrain",
        "created_at": "2019-08-16T09:07:54+00:00",
        "updated_at": "2019-08-20T12:30:18+00:00",
        "closed_at": "2019-08-20T12:30:18+00:00",
        "comments_count": [
            "wanghaoshuang",
            "imistyrain",
            "wanghaoshuang",
            "wanghaoshuang",
            "imistyrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3125,
        "title": "yolov3训练自己的数据，无法读取图像数据",
        "body": "我在utility.py中更改了数据根目录和数据集，同时，在read.py中更改了自己的json文件地址\r\n![image](https://user-images.githubusercontent.com/48506731/63174510-a6e0cb00-c074-11e9-8d8d-163895d02a1e.png)\r\n\r\n![image](https://user-images.githubusercontent.com/48506731/63174611-e27b9500-c074-11e9-83f6-cd282694779c.png)\r\n运行命令指定了参数，\r\n![image](https://user-images.githubusercontent.com/48506731/63174851-62096400-c075-11e9-9ce1-61579ddd2200.png)\r\n但是一直报错\r\n![image](https://user-images.githubusercontent.com/48506731/63174656-03dc8100-c075-11e9-8a6b-d778476447fd.png)\r\n是数据为空的意思？？？？？？？\r\n\r\n这是我的目录格式\r\n![image](https://user-images.githubusercontent.com/48506731/63174958-95e48980-c075-11e9-8a3f-1ba0e2ee1694.png)\r\n![image](https://user-images.githubusercontent.com/48506731/63175419-8fa2dd00-c076-11e9-805b-9bcffbe20f0d.png)\r\n\r\n是按照coco目录存放好的，而且图像也是用的coco中的一部分而已。是路径不对？还是哪里操作有误？？？特此求助\r\n\r\n",
        "state": "open",
        "user": "AIaiAIaiAIaiAI",
        "closed_by": null,
        "created_at": "2019-08-16T14:41:11+00:00",
        "updated_at": "2019-08-20T09:42:56+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "AIaiAIaiAIaiAI",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3127,
        "title": "如果我想在训练时获取训练的损失值，梯度等信息并传给另个一正在训练的模型该怎么做？",
        "body": "我能不能打破paddlepaddle封装的exe.run()方法来实现联邦学习？",
        "state": "open",
        "user": "HoyTiger",
        "closed_by": null,
        "created_at": "2019-08-18T05:12:39+00:00",
        "updated_at": "2019-08-19T07:05:18+00:00",
        "closed_at": null,
        "comments_count": [
            "zhaoyuchen2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3128,
        "title": "PaddleDetection 中 DataFeed 中的 `target_size` 是否可改成配置或参数形式？",
        "body": "如下图所示，ppdet 中的 DataFeed 的中，对 `target_size` 参数使用了硬编码的形式，导致修改输入到网络的 tensor 的 shape 不是很方便，改成在 config 里配置或者参数的形式是否更合理？\r\n\r\n![image](https://user-images.githubusercontent.com/37564754/63222931-c0068a80-c1e0-11e9-9a8b-3ded7d6e0158.png)\r\n\r\n另外，此处[model zoo doc](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/docs/MODEL_ZOO.md)存在一个拼写错误，可以顺便改了\r\n![image](https://user-images.githubusercontent.com/37564754/63222991-6488cc80-c1e1-11e9-84ad-d369e4426f5e.png)\r\n",
        "state": "closed",
        "user": "mzchtx",
        "closed_by": "qingqing01",
        "created_at": "2019-08-18T09:57:01+00:00",
        "updated_at": "2019-08-23T05:58:13+00:00",
        "closed_at": "2019-08-23T05:58:13+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "qingqing01",
            "mzchtx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3129,
        "title": "关于训练网络时，内存占满问题",
        "body": "使用代码框架是改自官方ssd代码https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/ssd，仅仅修改了backbone。\r\n也就是读取数据是用的异步读取py_reader\r\n具体情况：同样的代码\r\n　　　　　在RTX2080TI，６４G内存条下，CPU多线程只能开４个，此时显卡利用率较高９０左右。若再多开线程，则程序占用内存会不断增加，直到内存占满。然后一段时间后内存全部释放，程序不动了，也不打印错误，也不终止。\r\n                  在GTX１080TI，６４G内存条下，CPU只能单线程，此时显卡利用率一会０一会９０以上。若再多开线程，则程序占用内存会不断增加，直到内存占满。然后一段时间后内存全部释放，程序不动了，也不打印错误，也不终止。\r\npy_reader参数：\r\npy_reader = fluid.layers.py_reader(\r\n            capacity=64,\r\n            shapes=[[-1] + image_shape, [-1, 4], [-1, 1], [-1, 1]],\r\n            lod_levels=[0, 1, 1, 1],\r\n            dtypes=[\"float32\", \"float32\", \"int32\", \"int32\"],\r\n            use_double_buffer=True)\r\n\r\n最后，如果没记错，官方ssd源码好像是不存在这个问题，进程开的多也没事，只是进程开多了GPU的利用率会很低，大概二三十左右。\r\n大概问题就是这些，技术小哥有空的话，可以测试一下，如有需要请联系我qq1007890785",
        "state": "open",
        "user": "TimeChi",
        "closed_by": null,
        "created_at": "2019-08-18T12:13:38+00:00",
        "updated_at": "2019-11-07T09:04:45+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "TimeChi",
            "yghstill",
            "TimeChi",
            "Yogurt2019"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3130,
        "title": "SSD训练coco数据出现NAN错误",
        "body": "![image](https://user-images.githubusercontent.com/6135871/63237625-52586e00-c275-11e9-9696-fbb72d7fe82c.png)\r\n\r\nSSD的backbone改为shufflenetv2之后训练coco数据集，在前54个epoch均正常，后续突然出现nan错误，不知道是否有遇到过？",
        "state": "open",
        "user": "zzchust",
        "closed_by": null,
        "created_at": "2019-08-19T03:35:53+00:00",
        "updated_at": "2023-01-05T11:52:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zzchust",
            "TimeChi",
            "qingqing01",
            "TimeChi",
            "zzchust",
            "qingqing01",
            "TimeChi",
            "qingqing01",
            "qingqing01",
            "Liaoqing-up",
            "Liaoqing-up"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3137,
        "title": "更换optimizer恢复训练",
        "body": "先使用Adadelta训练，使用save_persistables保存模型，现在想换adam继续训练，但是由于adam参数多了，比如moment，那么请问应该怎么加载之前训练的模型呢？",
        "state": "closed",
        "user": "fengchun1213",
        "closed_by": "fengchun1213",
        "created_at": "2019-08-19T06:41:28+00:00",
        "updated_at": "2019-08-19T10:48:00+00:00",
        "closed_at": "2019-08-19T10:48:00+00:00",
        "comments_count": [
            "liupluswei",
            "fengchun1213"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3144,
        "title": "[PaddleSlim] Support list of parameters in pruning strategy",
        "body": "fix #2985",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-20T00:45:58+00:00",
        "updated_at": "2019-09-11T07:34:57+00:00",
        "closed_at": "2019-09-11T07:34:57+00:00",
        "comments_count": [],
        "labels": [
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3138,
        "title": "SSD模型源码fluid.layers.py_reader方法参数问题",
        "body": "想学习下paddle下了SSD的开源模型代码，里有涉及这个异步读取数据方法，对应api文档没有太看懂，具体代码如下：\r\n`py_reader = fluid.layers.py_reader(\r\n            capacity=64,\r\n            shapes=[[-1] + image_shape, [-1, 4], [-1, 1], [-1, 1]],\r\n            lod_levels=[0, 1, 1, 1],\r\n            dtypes=[\"float32\", \"float32\", \"int32\", \"int32\"],\r\n            use_double_buffer=True)`\r\n主要是shapes这个参数，和lod_levels 实际应用传的什么呢，没有理解这4个参数具体对应的是什么",
        "state": "closed",
        "user": "liuzengzhen1",
        "closed_by": "qingqing01",
        "created_at": "2019-08-19T07:18:01+00:00",
        "updated_at": "2019-08-23T05:59:41+00:00",
        "closed_at": "2019-08-23T05:59:41+00:00",
        "comments_count": [
            "liupluswei",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3145,
        "title": "使用DGC训练ResNet50出现NAN",
        "body": "* paddle版本：1.5.1\r\n* models版本：release/1.5\r\n* 训练脚本：models/PaddleCV/image_classification/dist_train\r\n使用nccl2在单机8卡V100训练resnet50，fp32在90epoch精度正常 top1@76.3，增加enable_dgc=True参数进行训练，实验多次在第38个epoch左右loss出现NAN，后续精度全部错误。\r\nlog如下：\r\n![image](https://user-images.githubusercontent.com/5974551/63312574-8cd51000-c334-11e9-8bb6-5fe0de283629.png)\r\n\r\n训练脚本如下：\r\n```Bash\r\n#!/bin/bash\r\nset -e\r\n\r\nenable_dgc=True\r\n\r\nwhile true ; do\r\n  case \"$1\" in\r\n    -enable_dgc) enable_dgc=\"$2\" ; shift 2 ;;\r\n    *)\r\n       if [[ ${#1} > 0 ]]; then\r\n          echo \"not supported arugments ${1}\" ; exit 1 ;\r\n       else\r\n           break\r\n       fi\r\n       ;;\r\n  esac\r\ndone\r\n\r\ncase \"${enable_dgc}\" in\r\n    True) ;;\r\n    False) ;;\r\n    *) echo \"not support argument -enable_dgc: ${dgc}\" ; exit 1 ;;\r\nesac\r\n\r\nexport MODEL=\"DistResNet\"\r\nexport PADDLE_TRAINER_ENDPOINTS=\"127.0.0.1:7160,127.0.0.1:7161,127.0.0.1:7162,127.0.0.1:7163,127.0.0.1:7164,127.0.0.1:7165,127.0.0.1:7166,127.0.0.1:7167\"\r\n# PADDLE_TRAINERS_NUM is used only for reader when nccl2 mode\r\nexport PADDLE_TRAINERS_NUM=\"8\"\r\n\r\nmkdir -p logs\r\n\r\n# NOTE: set NCCL_P2P_DISABLE so that can run nccl2 distribute train on one node.\r\n\r\n# You can set vlog to see more details' log.\r\n# export GLOG_v=1\r\n# export GLOG_logtostderr=1\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7160\" \\\r\nPADDLE_TRAINER_ID=\"0\" \\\r\nCUDA_VISIBLE_DEVICES=\"0\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg --update_method nccl2 --batch_size 32   &> logs/tr0.log &\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7161\" \\\r\nPADDLE_TRAINER_ID=\"1\" \\\r\nCUDA_VISIBLE_DEVICES=\"1\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr1.log &\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7162\" \\\r\nPADDLE_TRAINER_ID=\"2\" \\\r\nCUDA_VISIBLE_DEVICES=\"2\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125  --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr2.log &\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7163\" \\\r\nPADDLE_TRAINER_ID=\"3\" \\\r\nCUDA_VISIBLE_DEVICES=\"3\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr3.log &\r\n\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7164\" \\\r\nPADDLE_TRAINER_ID=\"4\" \\\r\nCUDA_VISIBLE_DEVICES=\"4\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr4.log &\r\n\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7165\" \\\r\nPADDLE_TRAINER_ID=\"5\" \\\r\nCUDA_VISIBLE_DEVICES=\"5\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr5.log &\r\n\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7166\" \\\r\nPADDLE_TRAINER_ID=\"6\" \\\r\nCUDA_VISIBLE_DEVICES=\"6\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr6.log &\r\n\r\nPADDLE_TRAINING_ROLE=\"TRAINER\" \\\r\nPADDLE_CURRENT_ENDPOINT=\"127.0.0.1:7167\" \\\r\nPADDLE_TRAINER_ID=\"7\" \\\r\nCUDA_VISIBLE_DEVICES=\"7\" \\\r\nNCCL_P2P_DISABLE=\"1\" \\\r\npython -u dist_train.py --enable_dgc ${enable_dgc} --lr 0.0125 --model $MODEL --data_dir /data/imagenet-jpeg/ --update_method nccl2 --batch_size 32  &> logs/tr7.log &\r\n```\r\n\r\n\r\n",
        "state": "open",
        "user": "listenlink",
        "closed_by": null,
        "created_at": "2019-08-20T02:23:49+00:00",
        "updated_at": "2019-10-24T12:03:46+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "listenlink",
            "listenlink",
            "wangxicoding",
            "wangxicoding"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3146,
        "title": "dcn添加偏置，出现Nan错误",
        "body": "\r\n\r\n### `_**paddle.fluid.core.EnforceNotMet:**_ Invoke operator auc error.`\r\nPython Callstacks: \r\n  File \"/usr/lib64/python2.7/site-packages/paddle/fluid/framework.py\", line 1712, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/fluid/layers/metric_op.py\", line 172, in auc\r\n    \"StatNegOut\": [batch_stat_neg]\r\n  File \"dcn1.py\", line 221, in ctr_wide_deep_model\r\n    auc_var, batch_auc_var, auc_states = fluid.layers.auc(input=predict, label=label)\r\n  File \"dcn1.py\", line 238, in train\r\n    datas, predict, loss, auc, auc_batch = ctr_wide_deep_model()\r\n  File \"dcn1.py\", line 369, in <module>\r\n    train()\r\nC++ Callstacks: \r\nEnforce failed. Expected predict_data <= 1, but received predict_data:-nan > 1:1.\r\nThe predict data must less or equal 1. at [/home/amy/eason/install/Paddle/paddle/fluid/operators/metrics/auc_op.h:80]\r\nPaddlePaddle Call Stacks: ",
        "state": "open",
        "user": "lijun900302",
        "closed_by": null,
        "created_at": "2019-08-20T02:28:53+00:00",
        "updated_at": "2019-08-29T09:43:34+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "mmglove",
            "lijun900302"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3149,
        "title": "LAC模型 lexical_analysis(）函数特殊字符会崩溃，建议增加参数的容错性",
        "body": "# 现象:\r\n当:lac.lexical_analysis()函数接收到包含空格字符串时崩溃。\r\n# 版本\r\n```\r\n➜  ~ hub version\r\nhub 1.1.1\r\n\r\n➜  ~ hub show lac\r\n\r\n+-----------------+----------------------------------------------------+\r\n|   ModuleName    |lac                                                 |\r\n+-----------------+----------------------------------------------------+\r\n|     Version     |1.1.1                                               |\r\n+-----------------+----------------------------------------------------+\r\n|     Summary     |Baidu's open-source lexical analysis tool for Chin  |\r\n|                 |ese, including word segmentation, part-of-speech t  |\r\n|                 |agging & named entity recognition                   |\r\n+-----------------+----------------------------------------------------+\r\n|     Author      |baidu-nlp                                           |\r\n+-----------------+----------------------------------------------------+\r\n|  Author-Email   |nlp@baidu.com                                       |\r\n+-----------------+----------------------------------------------------+\r\n|    Location     |/Users/yanglei/.paddlehub/modules/lac               |\r\n+-----------------+----------------------------------------------------+\r\n```\r\n# 重现代码\r\n```\r\ndef test_lac_bug():\r\n    inputs = {\"text\": [\" \"]}\r\n    import paddlehub as hub\r\n    lac = hub.Module(name = \"lac\")\r\n    print(hub)\r\n    results = lac.lexical_analysis(data=inputs)\r\n    print(results)\r\n```\r\n# 崩溃信息\r\n```\r\nTesting started at 15:55 ...\r\n/usr/local/bin/python3.7 /Applications/PyCharm.app/Contents/helpers/pycharm/_jb_pytest_runner.py --target test_lac_bug.py::test_lac_bug\r\nLaunching pytest with arguments test_lac_bug.py::test_lac_bug in /Users/yanglei/Documents/code/information_extraction/tests\r\n\r\n============================= test session starts ==============================\r\nplatform darwin -- Python 3.7.3, pytest-4.3.0, py-1.8.0, pluggy-0.8.1 -- /usr/local/opt/python/bin/python3.7\r\ncachedir: .pytest_cache\r\nrootdir: /Users/yanglei/Documents/code/information_extraction/tests, inifile:\r\nplugins: celery-4.3.0\r\ncollecting ... collected 1 item\r\n\r\ntest_lac_bug.py::test_lac_bug \r\nProcess finished with exit code 136 (interrupted by signal 8: SIGFPE)\r\n\r\n```",
        "state": "open",
        "user": "chaosfish",
        "closed_by": null,
        "created_at": "2019-08-20T08:07:56+00:00",
        "updated_at": "2020-01-05T15:52:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3147,
        "title": "paddle怎么初始化d维度的偏置W，W需要学？",
        "body": "x + W; X 和W 维度相同；x为输入，W是需要学的偏置权值，W怎么初始化？tf可以这么做   tf.get_variable(name=, shape=）\r\n\r\n",
        "state": "open",
        "user": "lijun900302",
        "closed_by": null,
        "created_at": "2019-08-20T03:28:17+00:00",
        "updated_at": "2019-08-25T08:59:38+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "lijun900302",
            "lijun900302",
            "wanghaoshuang",
            "lijun900302"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3148,
        "title": "如何将pretrained-model的参数名称与模型配置文件中的层一一对应",
        "body": "现有一模型的配置文件以及对应的pretrained model，pretrained model的参数名称由系统默认赋予。\r\n \r\n现在修改模型的配置文件，对每层的参数赋予自定义名称，如何将这些自定义的名称pretrained model参数一一对应起来呢？",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "zzchust",
        "created_at": "2019-08-20T07:38:05+00:00",
        "updated_at": "2019-08-23T02:37:37+00:00",
        "closed_at": "2019-08-23T02:37:37+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "zzchust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3151,
        "title": "DeepASR中infer_by_ckpy.py接口错误",
        "body": "我碰到了两个问题\r\n1. 其他issue里面提到过的DeepASR/data_utils/util.py里面没有lodtensor_to_ndarray的问题，我用了paddle/Paddle/python/paddle/fluid/tests/unittests/test_dynrnn_static_input.py里面的_lodtensor_to_ndarray来替代，这样有没有问题？\r\n2. 在infer_by_ckpt.py里会碰到下面的问题：\r\nTraceback (most recent call last):\r\n  File \"../../infer_by_ckpt.py\", line 273, in <module>\r\n    infer_from_ckpt(args)\r\n  File \"../../infer_by_ckpt.py\", line 197, in infer_from_ckpt\r\n    parallel=args.parallel)\r\nTypeError: stacked_lstmp_model() got an unexpected keyword argument 'frame_dim'\r\nstacked_lstmp_model()的参数与定义对不上。在model.py里面的stacked_lstmp_model()定义并没有frame_dim, 但是有feature和label。而在infer_by_ckpt.py里面的调用却没有feature和label。我去掉frame_dim以后仍然会报错。\r\n我对代码的理解是exe.run() 里的feed参数会把feature和label填充到参数里面，但似乎在之前调用的时候仍然需要填充feature和label？\r\n",
        "state": "open",
        "user": "MornJ",
        "closed_by": null,
        "created_at": "2019-08-20T08:45:44+00:00",
        "updated_at": "2019-08-28T02:24:18+00:00",
        "closed_at": null,
        "comments_count": [
            "MornJ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3152,
        "title": "训练出core",
        "body": "我有个程序，这个程序有两个网络a和b，我有两台机器A和B，都装了paddle1.5，cuda版本一样，输入一样。现在a在A上跑通，在B上core；b在B上core，在A上core。如果B换成1.5.1，则b在B上跑通，a在B上core。\r\n提示：Segmentation fault (core dumped)\r\n",
        "state": "open",
        "user": "Angus07",
        "closed_by": null,
        "created_at": "2019-08-20T09:44:28+00:00",
        "updated_at": "2019-08-21T08:37:12+00:00",
        "closed_at": null,
        "comments_count": [
            "Shixiaowei02"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3154,
        "title": "Floating point exception (core dumped) 求关注!",
        "body": "复现了ThunderNet，双阶段目标检测，用到了faster_rcnn的anchor_generator和proposal相关api，backbone单独拿出来训练是没问题的，但是整个模型一起训练的时候出现Floating point exception (core dumped)\r\n![e332d4ec04df7da1cf8cdb18c2fa33e](https://user-images.githubusercontent.com/13444641/63351896-ad33b780-c392-11e9-964b-fd5a07224bba.png)\r\n![1ce78400ee43f42af27301dd6570fef](https://user-images.githubusercontent.com/13444641/63351904-aefd7b00-c392-11e9-89b3-b84125923b35.png)\r\n",
        "state": "open",
        "user": "universea",
        "closed_by": null,
        "created_at": "2019-08-20T13:37:55+00:00",
        "updated_at": "2019-09-02T08:28:33+00:00",
        "closed_at": null,
        "comments_count": [
            "Shixiaowei02",
            "universea",
            "universea",
            "jiweibo",
            "jiweibo",
            "universea"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3157,
        "title": "预测结果不稳定，预测结果也不对",
        "body": "训练代码:\r\nlabel = fluid.layers.data(name='label', shape=[1], dtype='int64', lod_level=0)\r\nindex = fluid.layers.data(name='index', shape=[1], dtype='int64', lod_level=1)\r\nfeature = fluid.layers.data(name='feature', shape=[1], dtype='float32', lod_level=1)\r\n\r\n\r\n预测代码:\r\nstd::unique_ptr<ZeroCopyTensor> input_index = predictor->GetInputTensor(\"index\");\r\ninput_index->Reshape({1, 1});\r\n// 设置LOD\r\nstd::vector<std::vector<size_t>> lod_data = {{0}, {0}};\r\ninput_index->SetLoD({{0,index_len}});\r\ninput_index->copy_from_cpu(index_data);\r\nstd::unique_ptr<ZeroCopyTensor> input_feature = predictor->GetInputTensor(\"feature\");\r\ninput_feature->Reshape({1, 1});\r\ninput_feature->copy_from_cpu(feature_data);\r\ninput_feature->SetLoD({{0,feature_len}});\r\n\r\n\r\nCHECK(predictor->ZeroCopyRun());\r\n\r\nstd::vector<float> out_data;\r\nstd::vector<std::string> output_names = predictor->GetOutputNames();\r\nstd::unique_ptr<ZeroCopyTensor> output_t = predictor->GetOutputTensor(output_names[0]);\r\nstd::vector<int> output_shape = output_t->shape();\r\nint out_num = std::accumulate(output_shape.begin(), output_shape.end(), 1, std::multiplies<int>());\r\n\r\nout_data.resize(out_num);\r\noutput_t->copy_to_cpu(out_data.data());\r\nstd::cout<<\"output data:\"<<std::endl;\r\nfor(unsigned int num = 0; num < out_data.size(); num++)\r\n{\r\n    std::cout<<out_data[num]<<std::endl;\r\n}\r\nstd::cout<<out_data.data()<<std::endl;\r\n\r\n执行预测代码：\r\n有时显示0 1 有时显示1 0 有时显示0.626493 0.373507\r\n麻烦看看这是啥问题？",
        "state": "open",
        "user": "xiongbinbtbu",
        "closed_by": null,
        "created_at": "2019-08-21T09:02:03+00:00",
        "updated_at": "2019-08-21T09:02:03+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3155,
        "title": "在icnet中的cityscapes数据集应该选择哪一版本？文档说明不清楚啊？",
        "body": "README中介绍的需要自己下载cityscape数据集，但是官网很多不同大小内容版本，不知道选择哪一个进行下载\r\n",
        "state": "closed",
        "user": "epylice",
        "closed_by": "epylice",
        "created_at": "2019-08-21T02:44:47+00:00",
        "updated_at": "2019-09-19T02:20:04+00:00",
        "closed_at": "2019-09-19T02:19:27+00:00",
        "comments_count": [
            "LielinJiang",
            "ZeyuChen",
            "epylice"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3162,
        "title": "量化后模型的保存问题",
        "body": "在使用paddle slim进行量化训练时，发现量化后保存的模型结构如下图所示：\r\n<img width=\"513\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63481361-c8ecaa00-c4c7-11e9-98aa-f7a8d9ba63b9.png\">\r\n训练阶段有没有哪个参数可以让模型保存的时候，保持原来的模型结构不变，也就是不保存图中的fake_quantize_abs_max和fake_dequantize_abs_max。或者可以在模型load进来后，通过哪种操作可以达到上述目的。",
        "state": "closed",
        "user": "wwjjy",
        "closed_by": "zhhsplendid",
        "created_at": "2019-08-22T02:33:59+00:00",
        "updated_at": "2019-08-23T09:39:03+00:00",
        "closed_at": "2019-08-23T09:39:03+00:00",
        "comments_count": [
            "wzzju",
            "wwjjy",
            "wzzju"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3158,
        "title": "预测结果不稳定，预测结果也不对",
        "body": "训练代码:\r\nlabel = fluid.layers.data(name='label', shape=[1], dtype='int64', lod_level=0)\r\nindex = fluid.layers.data(name='index', shape=[1], dtype='int64', lod_level=1)\r\nfeature = fluid.layers.data(name='feature', shape=[1], dtype='float32', lod_level=1)\r\n\r\n\r\n预测代码:\r\nstd::unique_ptr<ZeroCopyTensor> input_index = predictor->GetInputTensor(\"index\");\r\ninput_index->Reshape({1, 1});\r\n// 设置LOD\r\nstd::vector<std::vector<size_t>> lod_data = {{0}, {0}};\r\ninput_index->SetLoD({{0,index_len}});\r\ninput_index->copy_from_cpu(index_data);\r\nstd::unique_ptr<ZeroCopyTensor> input_feature = predictor->GetInputTensor(\"feature\");\r\ninput_feature->Reshape({1, 1});\r\ninput_feature->copy_from_cpu(feature_data);\r\ninput_feature->SetLoD({{0,feature_len}});\r\n\r\n\r\nCHECK(predictor->ZeroCopyRun());\r\n\r\nstd::vector<float> out_data;\r\nstd::vector<std::string> output_names = predictor->GetOutputNames();\r\nstd::unique_ptr<ZeroCopyTensor> output_t = predictor->GetOutputTensor(output_names[0]);\r\nstd::vector<int> output_shape = output_t->shape();\r\nint out_num = std::accumulate(output_shape.begin(), output_shape.end(), 1, std::multiplies<int>());\r\n\r\nout_data.resize(out_num);\r\noutput_t->copy_to_cpu(out_data.data());\r\nstd::cout<<\"output data:\"<<std::endl;\r\nfor(unsigned int num = 0; num < out_data.size(); num++)\r\n{\r\n    std::cout<<out_data[num]<<std::endl;\r\n}\r\nstd::cout<<out_data.data()<<std::endl;\r\n\r\n执行预测代码：\r\n有时显示0 1 有时显示1 0 有时显示0.626493 0.373507\r\n麻烦看看这是啥问题？",
        "state": "open",
        "user": "xiongbinbtbu",
        "closed_by": null,
        "created_at": "2019-08-21T09:03:11+00:00",
        "updated_at": "2019-08-26T05:18:49+00:00",
        "closed_at": null,
        "comments_count": [
            "Shixiaowei02",
            "xiongbinbtbu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3160,
        "title": "关于DIN模型中attention部分实现问题",
        "body": "论文attention中的out product是外积的意思吗？\r\n论文中attention是将  [hist, target_expand, out product（hist，target_expand)]做了个拼接。而paddle中代码实现却是concat = fluid.layers.concat( [hist, target_expand, hist - target_expand, hist * target_expand], axis=2)\r\n请问out product（hist，target_expand）和hist - target_expand, hist * target_expand之间存在什么关联？谢谢",
        "state": "open",
        "user": "tz28",
        "closed_by": null,
        "created_at": "2019-08-21T12:43:25+00:00",
        "updated_at": "2022-03-29T01:45:06+00:00",
        "closed_at": null,
        "comments_count": [
            "Shixiaowei02",
            "tz28",
            "houkai",
            "liduo1997"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3163,
        "title": "使用fluid.layers.concat出现梯度问题。",
        "body": "使用fluid.layers.concat出现以上梯度问题。\r\n![image](https://user-images.githubusercontent.com/32633299/63483509-3819cc80-c4cf-11e9-8058-bde893fd87c5.png)\r\n相关代码如下：\r\n![image](https://user-images.githubusercontent.com/32633299/63484201-6e584b80-c4d1-11e9-828b-914d815010d8.png)\r\n\r\n\r\n",
        "state": "open",
        "user": "ZhangC2",
        "closed_by": null,
        "created_at": "2019-08-22T02:48:50+00:00",
        "updated_at": "2019-08-22T06:13:14+00:00",
        "closed_at": null,
        "comments_count": [
            "zhhsplendid",
            "ZhangC2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3166,
        "title": "自建数据集，COCO格式，进行rcnn中mask-rcnn模型训练错误，尝试清除GPU缓存，但并没有效果Insufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:262]",
        "body": "Traceback (most recent call last):\r\n  File \"train.py\", line 258, in <module>\r\n    train()\r\n  File \"train.py\", line 112, in train\r\n    exe.run(fluid.default_startup_program())\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator fill_constant error.\r\nPython Callstacks: \r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1842, in _prepend_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/initializer.py\", line 189, in __call__\r\n    stop_gradient=True)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1625, in create_var\r\n    kwargs['initializer'](var, self)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/layer_helper_base.py\", line 383, in set_variable_initializer\r\n    initializer=initializer)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 317, in _add_accumulator\r\n    var, initializer=Constant(value=float(fill_value)))\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 760, in _create_accumulators\r\n    self._add_accumulator(self._velocity_acc_str, p)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 364, in _create_optimization_pass\r\n    [p[0] for p in parameters_and_grads])\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 532, in apply_gradients\r\n    optimize_ops = self._create_optimization_pass(params_grads)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 562, in apply_optimize\r\n    optimize_ops = self.apply_gradients(params_grads)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 601, in minimize\r\n    loss, startup_program=startup_program, params_grads=params_grads)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 87, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"</home/gpu-server2/anaconda3/envs/CNdetection/lib/python3.7/site-packages/decorator.py:decorator-gen-20>\", line 2, in minimize\r\n  File \"train.py\", line 102, in train\r\n    optimizer.minimize(loss)\r\n  File \"train.py\", line 258, in <module>\r\n    train()\r\nC++ Callstacks: \r\nEnforce failed. Expected allocating <= available, but received allocating:10725104759 > available:10702159616.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:262]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f6b521d2e78p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f6b521d31c7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f6b54324c66p paddle::platform::GpuMaxChunkSize() + 630\r\n3       0x7f6b542f8f5ap\r\n4       0x7f6b84277827p\r\n5       0x7f6b542f85fdp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 109\r\n6       0x7f6b542f9445p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 37\r\n7       0x7f6b542f9985p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long) + 421\r\n8       0x7f6b542edaa5p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 181\r\n9       0x7f6b542edc2ap paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 26\r\n10      0x7f6b53ee676cp paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 44\r\n11      0x7f6b542bf7f4p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long) + 148\r\n12      0x7f6b52fe7a2ep paddle::operators::FillConstantKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 494\r\n13      0x7f6b52feab43p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::FillConstantKernel<float>, paddle::operators::FillConstantKernel<double>, paddle::operators::FillConstantKernel<long>, paddle::operators::FillConstantKernel<int>, paddle::operators::FillConstantKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n14      0x7f6b54261057p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n15      0x7f6b54261431p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n16      0x7f6b5425ea2cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n17      0x7f6b5235d81ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 606\r\n18      0x7f6b523607dfp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n19      0x7f6b521c3fddp\r\n20      0x7f6b52205286p\r\n21      0x55e9977a8744p _PyMethodDef_RawFastCallKeywords + 596\r\n22      0x55e9977a8861p _PyCFunction_FastCallKeywords + 33\r\n23      0x55e9978146e8p _PyEval_EvalFrameDefault + 21240\r\n24      0x55e997758539p _PyEval_EvalCodeWithName + 761\r\n25      0x55e9977a7f57p _PyFunction_FastCallKeywords + 903\r\n26      0x55e9978108ccp _PyEval_EvalFrameDefault + 5340\r\n27      0x55e997758539p _PyEval_EvalCodeWithName + 761\r\n28      0x55e9977a7ef5p _PyFunction_FastCallKeywords + 805\r\n29      0x55e99780fa93p _PyEval_EvalFrameDefault + 1699\r\n30      0x55e997758d09p _PyEval_EvalCodeWithName + 2761\r\n31      0x55e9977a7f57p _PyFunction_FastCallKeywords + 903\r\n32      0x55e99780f806p _PyEval_EvalFrameDefault + 1046\r\n33      0x55e997758539p _PyEval_EvalCodeWithName + 761\r\n34      0x55e997759424p PyEval_EvalCodeEx + 68\r\n35      0x55e99775944cp PyEval_EvalCode + 28\r\n36      0x55e99786eb74p\r\n37      0x55e997878eb1p PyRun_FileExFlags + 161\r\n38      0x55e9978790a3p PyRun_SimpleFileExFlags + 451\r\n39      0x55e99787a195p\r\n40      0x55e99787a2bcp _Py_UnixMain + 60\r\n41      0x7f6b83e98b97p __libc_start_main + 231\r\n42      0x55e99781f062p\r\n",
        "state": "closed",
        "user": "MaxWellerVladimir",
        "closed_by": "MaxWellerVladimir",
        "created_at": "2019-08-22T07:09:59+00:00",
        "updated_at": "2019-09-04T14:16:47+00:00",
        "closed_at": "2019-09-04T14:16:47+00:00",
        "comments_count": [
            "qingqing01",
            "MaxWellerVladimir"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3165,
        "title": "YoloV3的Darknet53有了，什么时候可以上线一个Tiny-yolo？",
        "body": "YoloV3的Darknet53有了，什么时候可以上线一个Tiny-yolo？",
        "state": "closed",
        "user": "kiols6",
        "closed_by": "kiols6",
        "created_at": "2019-08-22T03:47:56+00:00",
        "updated_at": "2019-09-05T01:49:40+00:00",
        "closed_at": "2019-09-05T01:49:40+00:00",
        "comments_count": [
            "qingqing01",
            "kiols6"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3177,
        "title": "PaddleRL policy_gradient Typo",
        "body": "default_main_program误写为defaul_main_program\r\nall_act_prob 未被声明为成员变量",
        "state": "closed",
        "user": "jeffzjzhang",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-23T11:53:15+00:00",
        "updated_at": "2019-09-02T06:09:32+00:00",
        "closed_at": "2019-09-02T06:09:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3171,
        "title": "语言生成模型",
        "body": "generate_chinese_poetry模型之前在V2版本，打算移到fuild版本吗？\r\n这个模型做的不错，有计划吗？",
        "state": "closed",
        "user": "xiaolv3366",
        "closed_by": "ysh329",
        "created_at": "2019-08-23T07:57:57+00:00",
        "updated_at": "2019-09-10T06:01:28+00:00",
        "closed_at": "2019-08-26T02:03:13+00:00",
        "comments_count": [
            "xiaolv3366",
            "ysh329",
            "xiaolv3366",
            "xiaolv3366"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3172,
        "title": "PaddleDetection 中的 test_architectures.py 存在路径错误",
        "body": "运行`python ppdet/modeling/tests/test_architectures.py`出现如下错误\r\n![image](https://user-images.githubusercontent.com/38153092/63576862-aa69da00-c5bf-11e9-8e2e-54facb9ccae8.png)\r\n**下图`test_architectures.py`中`ssd_mobilenet_v1_voc.yml`的路径应改为`configs/ssd/ssd_mobilenet_v1_voc.yml`**\r\n![image](https://user-images.githubusercontent.com/38153092/63576693-50691480-c5bf-11e9-857e-d02d8e290bfe.png)\r\n修改后测试 OK\r\n![image](https://user-images.githubusercontent.com/38153092/63576781-7f7f8600-c5bf-11e9-8292-58d853773149.png)\r\n",
        "state": "closed",
        "user": "snowhou",
        "closed_by": "ysh329",
        "created_at": "2019-08-23T08:05:28+00:00",
        "updated_at": "2019-08-26T02:01:44+00:00",
        "closed_at": "2019-08-26T02:01:23+00:00",
        "comments_count": [
            "ysh329"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3179,
        "title": "PaddleDetection eval 时内存溢出",
        "body": "在进行se154的模型eval.py的时候，电脑的内存使用不断增长，最终内存使用完毕，电脑死机，过一段时间自动killed。",
        "state": "closed",
        "user": "universea",
        "closed_by": "MRXLT",
        "created_at": "2019-08-24T05:19:10+00:00",
        "updated_at": "2019-10-08T06:53:41+00:00",
        "closed_at": "2019-10-08T06:53:41+00:00",
        "comments_count": [
            "MRXLT",
            "qingqing01",
            "universea",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3180,
        "title": "stnet网络模型的infer.list制作",
        "body": "请问在paddlevideo中使用stnet模型训练完毕后，怎样制作infer.ist进行推断？同时为什么在aistudio上面保存的checkpoints文件打不开？",
        "state": "closed",
        "user": "LALAliyao",
        "closed_by": "MRXLT",
        "created_at": "2019-08-24T06:53:12+00:00",
        "updated_at": "2019-10-08T06:53:53+00:00",
        "closed_at": "2019-10-08T06:53:53+00:00",
        "comments_count": [
            "MRXLT",
            "LALAliyao",
            "SunGaofeng",
            "LALAliyao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3181,
        "title": "ssd 在 coco 上训练，出现 loss 为 Nan，test map 过低的问题",
        "body": "训练的命令是\r\n```shell\r\npython3 -u train.py --dataset coco2017 --data_dir datasets/coco --batch_size 32 --pretrain\r\ned_model pretrained/ssd_mobilenet_v1_coco --learning_rate 0.001\r\n```\r\n加载的是官方的 mobileNet + ssd 与训练模型，\r\n然后在 epoch == 4 的时候就出现 loss 为 Nan 的问题了\r\n![img](http://ww4.sinaimg.cn/large/006y8mN6gy1g6b4pzjzr4j30t60p0ad2.jpg)\r\n\r\n训练的时候 best_model 对应的 map 有 0.3 左右，但测试的时候只有 0.02\r\n已经考虑到 91 -> 81 的问题...\r\n",
        "state": "open",
        "user": "Aneureka",
        "closed_by": null,
        "created_at": "2019-08-24T14:21:27+00:00",
        "updated_at": "2019-09-02T03:12:44+00:00",
        "closed_at": null,
        "comments_count": [
            "yghstill",
            "Aneureka",
            "yghstill",
            "PJSSABER",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3185,
        "title": "mobilenetSSD剪裁后map降低很多",
        "body": "mobilenetssd能加载预训练模型，通过打印parameter以及计算MAdds也能反映剪裁成功，加载预训练模型单纯量化训练的map值为0.19, 加入剪裁策略后得到模型预测map趋于0\r\n![图片](https://user-images.githubusercontent.com/50459712/63667915-cb793780-c818-11e9-9c9c-0b308f1c7ec6.png)\r\n",
        "state": "closed",
        "user": "ZiruiChen",
        "closed_by": "ZiruiChen",
        "created_at": "2019-08-26T05:47:32+00:00",
        "updated_at": "2020-01-13T00:28:17+00:00",
        "closed_at": "2019-08-28T09:33:32+00:00",
        "comments_count": [
            "ZiruiChen",
            "slf12",
            "ZiruiChen",
            "slf12",
            "ZiruiChen",
            "slf12",
            "ZiruiChen",
            "ZiruiChen",
            "slf12",
            "slf12",
            "ZiruiChen",
            "ZiruiChen",
            "morgan-bc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3190,
        "title": "dureader基线模型问题咨询",
        "body": "dureader基线模型的网络定义中部分代码如下：\r\n<img width=\"424\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63672961-c2d33200-c815-11e9-8071-775964fc488b.png\">\r\np_vec的获得依赖于start_labels的lod，在实际infer中，是不是必须有ground_truth，如果没有的话需要怎样使用该代码",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-08-26T07:30:38+00:00",
        "updated_at": "2019-08-26T09:06:46+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3198,
        "title": "全局梯度裁剪",
        "body": "原始代码运行正常，结构如下：\r\n```\r\nmain_program = fluid.default_main_program()\r\nstart_program = fluid.default_startup_program()\r\nmodel,loss = get_model()\r\nval_program = main_program.clone(for_test=True)\r\noptimizer = optimizer_program(args)\r\noptimizer.minimize(avg_cost)\r\n```\r\n\r\n但是我希望加入梯度裁剪，修改为\r\n```\r\nmain_program = fluid.default_main_program()\r\nstart_program = fluid.default_startup_program()\r\nmodel,loss = get_model()\r\nfluid.clip.set_gradient_clip(\r\n        clip=fluid.clip.GradientClipByGlobalNorm(clip_norm=1.0))\r\nval_program = main_program.clone(for_test=True)\r\noptimizer = optimizer_program(args)\r\noptimizer.minimize(avg_cost)\r\n```\r\n此时就报错了：\r\n```\r\nTraceback (most recent call last):\r\n  File \"trainer.py\", line 418, in <module>\r\n    main(use_cuda)\r\n  File \"trainer.py\", line 407, in main\r\n    train(use_cuda=use_cuda, params_dirname=save_path)\r\n  File \"trainer.py\", line 311, in train\r\n    train_loop()\r\n  File \"trainer.py\", line 270, in train_loop\r\n    fetch_list=[avg_cost.name, mean.name,mean_predict.name])\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 666, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 528, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator elementwise_mul error.\r\nPython Callstacks:\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 9904, in _elementwise_op\r\n    'use_mkldnn': use_mkldnn})\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 9965, in elementwise_mul\r\n    return _elementwise_op(LayerHelper('elementwise_mul', **locals()))\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/clip.py\", line 334, in _create_operators\r\n    x=grad, y=self.context[group_scale_name])\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/clip.py\", line 395, in append_gradient_clip_ops\r\n    res.append(clip_attr._create_operators(param=p, grad=g))\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 526, in apply_gradients\r\n    params_grads = append_gradient_clip_ops(params_grads)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 562, in apply_optimize\r\n    optimize_ops = self.apply_gradients(params_grads)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 601, in minimize\r\n    loss, startup_program=startup_program, params_grads=params_grads)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\", line 87, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"</home/vis/yourenchun/anaconda3/envs/padpy36/lib/python3.6/site-packages/decorator.py:decorator-gen-20>\", line 2, in minimize\r\n  File \"trainer.py\", line 181, in train\r\n    optimizer.minimize(avg_cost)\r\n  File \"trainer.py\", line 407, in main\r\n    train(use_cuda=use_cuda, params_dirname=save_path)\r\n  File \"trainer.py\", line 418, in <module>\r\n    main(use_cuda)\r\nC++ Callstacks:\r\nholder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:23]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f1bc3069c88p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f1bc3069fd7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f1bc5025cd9p paddle::framework::Tensor::check_memory_size() const + 185\r\n3       0x7f1bc3070a89p float const* paddle::framework::Tensor::data<float>() const + 25\r\n4       0x7f1bc4823b5cp void paddle::operators::ElementwiseComputeEx<paddle::operators::MulFunctor<float>, paddle::platform::CUDADeviceContext, float, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, int, paddle::operators::MulFunctor<float>, paddle::framework::Tensor*) + 76\r\n5       0x7f1bc48244a3p void paddle::operators::default_elementwise_mul<paddle::platform::CUDADeviceContext, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, paddle::framework::Tensor*) + 115\r\npython -u trainer.py --lr 0.01 --num_epochs 100 --mode resnet101 --multiscale False --pretrained_model ./pretrain_backbone/ResNet101_pretrained/\r\n6       0x7f1bc482480bp paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 811\r\n7       0x7f1bc4824c93p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, long>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n8       0x7f1bc4fcfe07p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n9       0x7f1bc4fd01e1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n10      0x7f1bc4fcd7dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n11      0x7f1bc4dc8fc9p\r\n12      0x7f1bc4dba3adp\r\n13      0x7f1bc4dbb0e4p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function<void ()> const&) + 116\r\n14      0x7f1bc4dc8c5cp paddle::framework::details::ComputationOpHandle::RunImpl() + 124\r\n15      0x7f1bc4dbb680p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n16      0x7f1bc4d9c9f6p paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*) + 310\r\n17      0x7f1bc4d9b65fp paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*) + 47\r\n18      0x7f1bc4d9ba1fp\r\n19      0x7f1bc329c6c3p std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&) + 35\r\n20      0x7f1bc3133477p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n21      0x7f1c6d6d5b23p pthread_once + 83\r\n22      0x7f1bc4d970a2p\r\n23      0x7f1bc31349f4p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404\r\n24      0x7f1be7a2e421p\r\n25      0x7f1c6d6d0851p\r\n26      0x7f1c6d41e67dp clone + 109\r\n```",
        "state": "open",
        "user": "guozhiyao",
        "closed_by": null,
        "created_at": "2019-08-27T03:35:30+00:00",
        "updated_at": "2019-08-28T08:34:33+00:00",
        "closed_at": null,
        "comments_count": [
            "hong19860320",
            "guozhiyao",
            "hong19860320",
            "chengduoZH"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3201,
        "title": "Floating point exception",
        "body": "我用hub run 运行的时候是正确的，然后用python运行的时候就会出现这个错误",
        "state": "open",
        "user": "yJun-Chen",
        "closed_by": null,
        "created_at": "2019-08-27T10:03:48+00:00",
        "updated_at": "2019-08-27T12:33:53+00:00",
        "closed_at": null,
        "comments_count": [
            "yJun-Chen",
            "hong19860320",
            "hong19860320"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3202,
        "title": "PaddleDetection下进行cascade训练时候出错",
        "body": "在最新的代码PaddleDetection下进行cascade训练，指令如下\r\npython -u tools/train.py -c configs/dcn/cascade_rcnn_dcn_r101_vd_fpn_1x.yml\r\n出现错误:\r\n  File \"tools/train.py\", line 239, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 97, in main\r\n    model = create(main_arch)\r\n  File \"/data/daibing/models/models-develop/PaddleCV/PaddleDetection/ppdet/core/workspace.py\", line 187, in create\r\n    kwargs[k] = create(target_key)\r\n  File \"/data/daibing/models/models-develop/PaddleCV/PaddleDetection/ppdet/core/workspace.py\", line 149, in create\r\n    config.validate()\r\n  File \"/data/daibing/models/models-develop/PaddleCV/PaddleDetection/ppdet/core/config/schema.py\", line 159, in validate\r\n    self.name, \", \".join(extra_keys)))\r\nValueError: Extraneous param for class<ResNet>: dcn_stages",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "qingqing01",
        "created_at": "2019-08-27T11:25:26+00:00",
        "updated_at": "2019-08-27T12:03:46+00:00",
        "closed_at": "2019-08-27T12:03:46+00:00",
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3206,
        "title": "ocr_recognition",
        "body": "> et environment variable LD_LIBRARY_PATH on Linux是什么意思呢\r\n>>![图片](https://user-images.githubusercontent.com/38428867/63821321-22008600-c97f-11e9-95f7-ec33d59c6db3.png)\r\n",
        "state": "closed",
        "user": "geng007",
        "closed_by": "geng007",
        "created_at": "2019-08-28T02:34:31+00:00",
        "updated_at": "2019-09-02T02:38:30+00:00",
        "closed_at": "2019-09-02T02:38:30+00:00",
        "comments_count": [
            "wangchaochaohu",
            "geng007",
            "wangchaochaohu",
            "geng007",
            "geng007",
            "geng007"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3218,
        "title": "attention ocr 的训练数据图片宽和高的设置,以及label长度有什么要求吗?",
        "body": "首先感谢你们开源了代码; 我在使用attention ocr时候发现你们提供的训练数据宽和高分别设置为384和48, 应该是进行了预处理; 但DataGenerator的reader()函数里面, 似乎是根据每个batch的第一张图片的宽度来作为整个batch所有图片缩放的宽度的; 这样的话如果我自己的训练数据没有进行预处理, 那么不同图片的宽度不是统一的, 不同batch的图片宽度也会不一样,这样对训练的结果影响大不大? 第二个问题是 label的长度有没有什么限制?比如我的训练样本里面多数label长度为8-15个汉字, 但还有一批label长度超过20个汉字的图片,这些图片如果缩放到(宽:384,高:48)的尺寸, 有可能产生形变, 这种情况下是否对训练结果造成影响? ",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "qingqing01",
        "created_at": "2019-08-29T03:25:08+00:00",
        "updated_at": "2019-09-02T08:22:05+00:00",
        "closed_at": "2019-08-30T02:54:52+00:00",
        "comments_count": [
            "qingqing01",
            "wenston2006",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3220,
        "title": "ernie的代码过于陈旧，不能infer，请将ERNIE项目的代码进行同步",
        "body": "infer时报错，没有task.reader.py 中_convert_example_to_record函数报label_id不存在",
        "state": "closed",
        "user": "wang001",
        "closed_by": "wang001",
        "created_at": "2019-08-29T06:47:09+00:00",
        "updated_at": "2019-09-05T08:49:57+00:00",
        "closed_at": "2019-09-05T08:49:57+00:00",
        "comments_count": [
            "tianxin1860",
            "wang001",
            "wang001",
            "tianxin1860",
            "wang001",
            "wang001",
            "tianxin1860",
            "tianxin1860",
            "wang001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3222,
        "title": "关于视频动作识别TSN模型 参数加载的问题",
        "body": "该代码训练时，如果没有指定预训练的参数，那么它会自动的下载model zoo中预训练的模型，但是该模型应该是基于tsn.txt中如下图配置的方式训练的，此时网络的输入是（3，224，224）\r\n<img width=\"571\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63924448-de8b4200-ca7a-11e9-8a96-2dd4f83e56f7.png\">\r\n但是如果我们将该配置改为seg_num = 3，seglen = 2，那么网络的输入相应的会变成（6，224，224）。此时会由于卷积的维度和输入的通道数不符报错，错误信息如下：\r\n<img width=\"1020\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/63924694-4b9ed780-ca7b-11e9-81f9-3ff1a6a74196.png\">\r\n貌似在程序中没有找到通过哪个参数可以避免掉这种情况发生，只能手动删掉下载并加载预训练参数的部分。\r\n同理在infer时，如果没有指定权重的路径，会自动下载并加载预训练的权重路径，如果使用自定义的数据集，在用户忘了指定权重路径时，应该提示他没有指定路径，而不是使用预训练的权重进行推断，这在排查问题以及测试模型效果时很不友好。",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-08-29T08:45:40+00:00",
        "updated_at": "2020-07-20T00:23:59+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3224,
        "title": "mobilenetssd load_persistables报错",
        "body": "相关环境：训练GPU v100, paddle1.4.1\r\n                  重载环境：GPU v100, paddle1.5.0\r\n背景：训练时只使用save_persistables保存为单个文件，现想重载权重文件进行评估和预测，但一直失败。\r\n\r\n训练时使用\r\n```\r\nmodel_ckpt_name = 'params_pass_%05d.ckpt' % (epoch)\r\n fluid.io.save_persistables(self.exe, self.checkpoint_dir,\r\n                                   main_program=self.test_program,\r\n                                   filename=model_ckpt_name)\r\n```\r\n加载模型时，报错\r\n`fluid.io.load_persistables(exe, model_dir,test_prog, filename=\"params_pass_00065.ckpt\")`\r\n\r\n错误日志如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 339, in <module>\r\n    save_dir=args.save_dir)\r\n  File \"infer.py\", line 90, in infer\r\n    fluid.io.load_persistables(exe, model_dir,test_prog, filename=\"params_pass_00065.ckpt\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 645, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load_combine error.\r\nPython Callstacks:\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 644, in load_vars\r\n    attrs={'file_path': os.path.join(load_dirname, filename)})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"infer.py\", line 90, in infer\r\n    fluid.io.load_persistables(exe, model_dir,test_prog, filename=\"params_pass_00065.ckpt\")\r\n  File \"infer.py\", line 339, in <module>\r\n    save_dir=args.save_dir)\r\nC++ Callstacks:\r\nCannot parse tensor desc at [/paddle/paddle/fluid/framework/tensor_util.cu:462]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f85567706a0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f8556770a19p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f855872b703p paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&) + 1315\r\n3       0x7f855831a8d0p paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 576\r\n4       0x7f8557451a30p paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const + 352\r\n5       0x7f85574523aep paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 798\r\n6       0x7f8557452823p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n7       0x7f85586cd907p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n8       0x7f85586cdce1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n9       0x7f85586cb2dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n10      0x7f85568fc38ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n11      0x7f85568ff42fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n12      0x7f8556761b2dp\r\n13      0x7f85567a35c6p\r\n14            0x4c5326p PyEval_EvalFrameEx + 37958\r\n15            0x4b9b66p PyEval_EvalCodeEx + 774\r\n16            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n17            0x4b9b66p PyEval_EvalCodeEx + 774\r\n18            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n19            0x4b9b66p PyEval_EvalCodeEx + 774\r\n20            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n21            0x4b9b66p PyEval_EvalCodeEx + 774\r\n22            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n23            0x4b9b66p PyEval_EvalCodeEx + 774\r\n24            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n25            0x4b9b66p PyEval_EvalCodeEx + 774\r\n26            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n27            0x4b9b66p PyEval_EvalCodeEx + 774\r\n28            0x4eb69fp\r\n29            0x4e58f2p PyRun_FileExFlags + 130\r\n30            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n31            0x4938cep Py_Main + 1358\r\n32      0x7f86a1d78830p __libc_start_main + 240\r\n33            0x493299p _start + 41\r\n```",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-08-29T09:19:15+00:00",
        "updated_at": "2019-08-29T13:10:30+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3239,
        "title": "gpu版本安装失败，出现paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul error.",
        "body": "![image](https://user-images.githubusercontent.com/50409171/64070731-1a045700-cc9b-11e9-8871-f0c4b02e16a3.png)\r\nwindows版本安装gpu版本，cuda 9.0 + cudnn7.3。\r\n\r\n安装完测试 运行paddle.fluid.install_check.run_check() 时，出现如图所示问题，这是什么问题？？谢谢",
        "state": "open",
        "user": "woshijqo",
        "closed_by": null,
        "created_at": "2019-09-01T01:32:16+00:00",
        "updated_at": "2019-09-01T01:32:16+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3225,
        "title": "使用fleet.save_inference_model,ERROR:A protocol message was rejected because it was too big (more than 67108864 bytes).",
        "body": "from paddle.fluid.incubate.fleet.parameter_server.distribute_transpiler import fleet\r\nfleet.save_inference_model(executor=exe, dirname=model_dir, feeded_var_names=feed_var_names, target_vars=[auc_var, batch_auc_var])保存模型出错，\r\n\r\n /usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py:1084: UserWarning: save_inference_model specified the param `program_only` to True, It will not save params of Program.\r\n2019-08-28 21:33:25\t2019-08-28 13:33:23,876 [INFO] [10.38.26.135] --- \"save_inference_model specified the param `program_only` to True, It will not save params of Program.\"\r\n2019-08-28 21:33:25\t2019-08-28 13:33:24,698 [INFO] [10.38.26.135] --- [libprotobuf ERROR /paddle/build/third_party/protobuf/src/extern_protobuf/src/google/protobuf/io/coded_stream.cc:208] A protocol message was rejected because it was too big (more than 67108864 bytes). To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\r\n2019-08-28 21:33:25\t2019-08-28 13:33:25,202 [INFO] [10.38.26.135] --- Traceback (most recent call last):\r\n2019-08-28 21:33:25\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- File \"/paddle/task-20190828201029-87895/dnn_dense_interaction.py\", line 374, in <module>\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- train()\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- File \"/paddle/task-20190828201029-87895/dnn_dense_interaction.py\", line 363, in train\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- fleet.save_inference_model(executor=exe, dirname=model_dir, feeded_var_names=feed_var_names, target_vars=[auc_var, batch_auc_var])\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/incubate/fleet/parameter_server/distribute_transpiler/__init__.py\", line 157, in save_inference_model\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- program = Program.parse_from_string(program_desc_str)\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 3315, in parse_from_string\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,203 [INFO] [10.38.26.135] --- p.desc = core.ProgramDesc(binary_str)\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- paddle.fluid.core_avx.EnforceNotMet: Fail to parse program_desc from binary string. at [/paddle/paddle/fluid/framework/program_desc.cc:95]\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- PaddlePaddle Call Stacks:\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 0 0x7fa349ef999ap void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 506\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 1 0x7fa349efa6a5p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 165\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 2 0x7fa34a0c97bep paddle::framework::ProgramDesc::ProgramDesc(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 782\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 3 0x7fa349fbbb66p\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 4 0x7fa349f26a14p\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 5 0x4eef5ep\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 15 0x4b9b66p PyEval_EvalCodeEx + 774\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 16 0x4eb69fp\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 17 0x4e58f2p PyRun_FileExFlags + 130\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 13 0x4b9b66p PyEval_EvalCodeEx + 774\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 14 0x4c1f56p PyEval_EvalFrameEx + 24694\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 6 0x4eeb66p\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,204 [INFO] [10.38.26.135] --- 7 0x4aaafbp\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 8 0x4c166dp PyEval_EvalFrameEx + 22413\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 9 0x4b9b66p PyEval_EvalCodeEx + 774\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 10 0x4c1f56p PyEval_EvalFrameEx + 24694\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 11 0x4b9b66p PyEval_EvalCodeEx + 774\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 12 0x4c17c6p PyEval_EvalFrameEx + 22758\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 18 0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 19 0x4938cep Py_Main + 1358\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 20 0x7fa3bcf7a830p __libc_start_main + 240\r\n2019-08-28 21:33:26\t2019-08-28 13:33:25,205 [INFO] [10.38.26.135] --- 21 0x493299p _start + 41",
        "state": "open",
        "user": "lijun900302",
        "closed_by": null,
        "created_at": "2019-08-29T09:30:28+00:00",
        "updated_at": "2019-09-09T02:11:56+00:00",
        "closed_at": null,
        "comments_count": [
            "lijun900302",
            "MrChengmo",
            "MrChengmo",
            "lijun900302",
            "MrChengmo",
            "lijun900302",
            "MrChengmo",
            "lijun900302",
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3233,
        "title": "使用paddle slim的filter_pruning_uniform裁剪后，应用inference报错",
        "body": "使用原始filter_pruning_uniform.yaml文件，对数据集Stanford Dogs进行训练MobileNet模型并裁剪。\r\n训练裁剪完成后，模型大小剪为6.7M。\r\n在应用该裁剪模型时报错：\r\n![b95fcc9001811ede38935e261f8767e4](https://user-images.githubusercontent.com/41142435/63996419-3df65a00-cb2e-11e9-9022-fd59bca62efa.png)\r\n请问是哪里的问题？谢谢\r\n另外，如果用原始的mobilenetv1_resnet50_distillation.yaml训练裁剪也提示错误，但仍能继续，只是最后没有看到有最终大小有被裁剪：\r\n![96c6d7f564a69e9945b272aa60273631](https://user-images.githubusercontent.com/41142435/63996766-28356480-cb2f-11e9-9bb8-799432ce3b24.png)\r\n",
        "state": "closed",
        "user": "Tristan-Hao",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-08-30T06:06:11+00:00",
        "updated_at": "2019-09-03T12:06:14+00:00",
        "closed_at": "2019-09-03T12:06:14+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Tristan-Hao",
            "Tristan-Hao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3238,
        "title": "Missing 'fluid.layers' before 'control_flow.Switch'",
        "body": "https://github.com/PaddlePaddle/models/blob/eb1fbf5cd847521a030ad97f0152e9a142803a8a/PaddleCV/image_classification/utils/learning_rate.py#L57\r\n\r\nshould read as:\r\n\r\n```python\r\nwith fluid.layers.control_flow.Switch() as switch:\r\n```",
        "state": "open",
        "user": "lixiangchun",
        "closed_by": null,
        "created_at": "2019-08-31T11:25:37+00:00",
        "updated_at": "2019-09-05T10:47:41+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3241,
        "title": "nonlocal模型的问题请教",
        "body": "您好，请教个问题，为什么nonlocal模型在预测的时候crop的size会从224变成256。使用训练阶段一样的224+fc的模式会有什么问题？\r\n当我在进行预测时，由于输入大小为256*256，所以经过（7 * 7）的pooling后tensor的shape变为了（-1, 2048, 1, 2, 2），此时使用（10, 2048, 1, 1, 1）的卷积进行预测是否合理。此时网络的输出如下：\r\n<img width=\"649\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20850734/64089354-4641d580-cd78-11e9-8deb-f26bdcdb8c11.png\">\r\n看起来也不是很像softmax后的输出，此时还是选择最大值对应的类别最为分类结果吗？\r\n",
        "state": "closed",
        "user": "wwjjy",
        "closed_by": "gongweibao",
        "created_at": "2019-09-02T03:56:55+00:00",
        "updated_at": "2019-09-03T02:14:18+00:00",
        "closed_at": "2019-09-03T02:14:18+00:00",
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3243,
        "title": "PADDLEGAN base_network cal padding mistake?",
        "body": "in models/PaddleCV/PaddleGAN/network/base_network.py line 159 the top padding and left_padding are all using input.shape[2]? why?\r\n\r\nthe same mistake is in Line 247",
        "state": "closed",
        "user": "miraclebiu",
        "closed_by": "ceci3",
        "created_at": "2019-09-02T07:16:53+00:00",
        "updated_at": "2019-09-04T07:21:52+00:00",
        "closed_at": "2019-09-04T07:21:52+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3246,
        "title": "softmax_with_cross_entropy运行报错",
        "body": "![image](https://user-images.githubusercontent.com/5461637/64101563-b5cbbb00-cda0-11e9-9726-6cce4589a3f0.png)\r\n计算softmax_with_cross_entropy报错，打印labels和logits分别为\r\n![image](https://user-images.githubusercontent.com/5461637/64101642-e01d7880-cda0-11e9-9955-591e9355f4a4.png)\r\n运行时报错信息为\r\n![image](https://user-images.githubusercontent.com/5461637/64101683-f62b3900-cda0-11e9-88d6-44575da16607.png)\r\n是什么原因呢？",
        "state": "closed",
        "user": "yxzero",
        "closed_by": "yxzero",
        "created_at": "2019-09-02T08:43:27+00:00",
        "updated_at": "2019-09-02T08:57:25+00:00",
        "closed_at": "2019-09-02T08:57:25+00:00",
        "comments_count": [
            "yxzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3248,
        "title": "[BUG] document is broken",
        "body": "right here: [Paddle模型压缩工具库算法原理介绍](https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/docs/tutorial.md)\r\n\r\nIt shows something like `$$ r = min(max(x, a), b)$$ $$ s = \\frac{b - a}{n - 1} $$ $$ q = \\left \\lfloor \\frac{r - a}{s} \\right \\rceil $$`",
        "state": "closed",
        "user": "jeng1220",
        "closed_by": "jeng1220",
        "created_at": "2019-09-02T10:15:12+00:00",
        "updated_at": "2019-09-06T01:49:11+00:00",
        "closed_at": "2019-09-06T01:49:11+00:00",
        "comments_count": [
            "gongweibao",
            "jeng1220"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3262,
        "title": "图像分类模型库中的有几个预训练模型链接失效了",
        "body": "如题，发现[image_classification README](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification)中\r\n[`ShuffleNetV2_x1_0` ](https://paddle-imagenet-models-name.bj.bcebos.com/ShuffleNetV2_x1_0_pretrained.tar)\r\n[`GoogLeNet`](https://paddle-imagenet-models-name.bj.bcebos.com/GoogleNet_pretrained.tar)\r\n[`Xception_41`](https://paddle-imagenet-models-name.bj.bcebos.com/Xception41_pretrained.tar)\r\n这三个模型的下载链接失效了。",
        "state": "closed",
        "user": "OliverLPH",
        "closed_by": "shippingwang",
        "created_at": "2019-09-04T07:19:58+00:00",
        "updated_at": "2019-09-05T13:16:46+00:00",
        "closed_at": "2019-09-05T13:16:46+00:00",
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3249,
        "title": "quantization of word embedding",
        "body": "```\r\n               thres = 0.01\r\n110         word = np.array(fluid.global_scope().find_var(\"word_embedding\").get_tensor())\r\n111         word[abs(word)>thres] = 0\r\n112         tmp = np.log(np.abs(word) + 1)\r\n113         max_range = np.max(tmp)\r\n114         tmp = np.floor(127*tmp/max_range)\r\n115         word = (np.exp(tmp * max_range / 127)-1) * np.sign(word)\r\n116         fluid.global_scope().find_var(\"word_embedding\").get_tensor().set(word, place)\r\n117         logger.info(\"------------------quan done-------------------\")\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-09-02T12:28:50+00:00",
        "updated_at": "2019-09-05T08:51:45+00:00",
        "closed_at": "2019-09-05T08:51:45+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3256,
        "title": "image_classification 预训练出错",
        "body": "您好，我用ImageNet的模型，进行finetune的时候出错，用的预训练模型和分类数是   \r\n    --pretrained_model=pretrained_model/ResNeXt50_vd_64x4d_pretrained\\\r\n    --class_dim=14 \\\r\n训练指令为:\r\npython train.py \\\r\n    --model=ResNeXt50_vd_64x4d \\\r\n    --batch_size=32 \\\r\n    --num_epochs=100 \\\r\n    --total_images=833458 \\\r\n    --data_dir=\"./data/terror_detail/\" \\\r\n    --pretrained_model=pretrained_model/ResNeXt50_vd_64x4d_pretrained\\\r\n    --class_dim=14 \\\r\n    --image_shape=3,224,224 \\\r\n    --model_save_dir=output/ \\\r\n    --with_mem_opt=False \\\r\n    --with_inplace=True \\\r\n    --lr_strategy=piecewise_decay \\\r\n    --lr=0.001\r\n\r\n\r\n报错:\r\ntrain_fetch_list [u'mean_0.tmp_0', u'accuracy_0.tmp_0', u'accuracy_1.tmp_0', u'learning_rate']\r\n.....\r\n  File \"train.py\", line 622, in <module>\r\n    main()\r\nC++ Callstacks:\r\nEnforce failed. Expected param_dim == ctx->GetInputDim(\"Velocity\"), but received param_dim:1000 != ctx->GetInputDim(\"Velocity\"):14.\r\nParam and Velocity of MomentumOp should have the same dimension. at [/paddle/paddle/fluid/operators/optimizers/momentum_op.h:65]\r\n",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "dbcool",
        "created_at": "2019-09-03T04:02:26+00:00",
        "updated_at": "2019-09-12T03:08:48+00:00",
        "closed_at": "2019-09-12T03:08:47+00:00",
        "comments_count": [
            "guoshengCS",
            "shippingwang",
            "dbcool"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3251,
        "title": "PaddleSlim量化训练时总是出现Nan，请问是怎么回事？量化训练的学习率以及收敛问题",
        "body": "1、环境 Ubuntu16.04，1080ti，而且我在ai studio上训练也一样，总是出现nan，换了两台机器都是这个问题，学习率也设置了，0.001一直设置到好小，也出现nan，\r\n2、顺便问一下，量化训练的学习率如何设置，也是从0.001开始吗？\r\n3、还有，我训练好的baseline进行量化训练第一次迭代时的loss和进行常规训练时差不多都是4左右，然后从下一个迭代就会变到十几，而且以后一直在10左右徘徊，这种量化训练正常吗，浮动比较大，一般需要多久才能收敛到常规训练的水平？",
        "state": "open",
        "user": "wonyoungsen",
        "closed_by": null,
        "created_at": "2019-09-03T01:26:16+00:00",
        "updated_at": "2019-09-04T03:49:21+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "slf12",
            "wonyoungsen",
            "wonyoungsen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3264,
        "title": "attention ocr调小学习率后,仍出现loss=nan",
        "body": "我用attention ocr 训练中文识别,我的样本都是些标签长度不均一的中文短语; 最初将attention_model. py 中的学习率LR设置为0.1, 训练了1.8万次, 开头train_acc, test_acc一直在上升, 但突然loss变为nan; 我将LR降低为0.01后,训练了1000次, loss就为nan了;这种情况下是否学习率应该调高而不是降低?请问LR可调范围大约是多少?此外decoder_size, word_vector_dim这几个参数对训练影响大吗?应如何调整?",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wenston2006",
        "created_at": "2019-09-04T07:55:23+00:00",
        "updated_at": "2019-09-05T01:27:08+00:00",
        "closed_at": "2019-09-05T01:27:08+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wenston2006"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3265,
        "title": "如何在模型中添加regularization loss?添加后如何在训练时获取该loss?",
        "body": "请问regularization loss是否可通过某些optimizer中的regularization参数添加(如:class paddle.fluid.optimizer.LarsMomentumOptimizer(learning_rate, momentum, lars_coeff=0.001, lars_weight_decay=0.0005, regularization=None, name=None))? 此外如何获取训练中的regularization loss?\r\n",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wenston2006",
        "created_at": "2019-09-04T08:00:42+00:00",
        "updated_at": "2019-09-05T01:26:56+00:00",
        "closed_at": "2019-09-05T01:26:56+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wenston2006"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3266,
        "title": "cascade rcnn",
        "body": "\r\n![44444](https://user-images.githubusercontent.com/50400428/64246857-307f0c80-cf40-11e9-8520-61ebfdb1f180.png)\r\n这是什么原因啊，我没有修改过train的代码\r\n\r\n",
        "state": "closed",
        "user": "pandaxue",
        "closed_by": "jerrywgz",
        "created_at": "2019-09-04T10:17:42+00:00",
        "updated_at": "2020-07-15T01:30:25+00:00",
        "closed_at": "2019-12-20T13:25:19+00:00",
        "comments_count": [
            "jerrywgz",
            "pandaxue",
            "jerrywgz",
            "houboowen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3267,
        "title": "求训练cascade的完整步骤",
        "body": "在哪里有训练cascade rcnn的详细步骤啊，我想用自己的数据跑一下cascade_rcnn可形变卷积，以前用mmdetection框架跑过，只试过voc数据集，现在用paddle不知道从哪开始修改class",
        "state": "closed",
        "user": "pandaxue",
        "closed_by": "jerrywgz",
        "created_at": "2019-09-04T10:20:57+00:00",
        "updated_at": "2020-01-13T05:36:31+00:00",
        "closed_at": "2019-12-20T13:24:33+00:00",
        "comments_count": [
            "jerrywgz",
            "pandaxue",
            "jerrywgz",
            "pandaxue",
            "yghstill",
            "pandaxue",
            "jerrywgz",
            "pandaxue",
            "jerrywgz"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3270,
        "title": "PaddleDetection中训练的模型能否进行视频目标检测？",
        "body": "",
        "state": "closed",
        "user": "MaxWellerVladimir",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-09-04T14:49:23+00:00",
        "updated_at": "2019-09-05T09:00:19+00:00",
        "closed_at": "2019-09-05T09:00:19+00:00",
        "comments_count": [
            "jerrywgz",
            "MaxWellerVladimir"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3272,
        "title": "如何连续验证多个模型（yolov3）",
        "body": "验证次数多了爆显存，如何用scope_guard？",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-09-05T02:17:34+00:00",
        "updated_at": "2019-09-17T02:14:41+00:00",
        "closed_at": null,
        "comments_count": [
            "mozpp",
            "mozpp",
            "mozpp",
            "heavengate",
            "mozpp",
            "heavengate",
            "mozpp",
            "mozpp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3271,
        "title": "attention ocr的文字识别率如何进一步提高?",
        "body": "先说说我的训练和测试数据: 都是些长短不一的短语,最长的有30多个汉字,最短的只有一个字符; 训练数据有30万张图片; 目前用attention ocr训练,验证集上识别率达到80.5%; 要想让这个结果进一步提高,有什么办法没有?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-09-05T01:30:29+00:00",
        "updated_at": "2019-09-11T05:46:07+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "wenston2006",
            "wanghaoshuang",
            "arcral",
            "wenston2006"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3276,
        "title": "attention ocr infer.py不能顺利加载模型",
        "body": "attention ocr 采用train.py训练和保存模型, 运行infer.py时不能顺利加载模型; 控制台打印的信息如下:\r\n\r\n/usr/bin/python3.5 /home/liusong/program_install/pycharm-2018.3.4/helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 127.0.0.1 --port 33763 --file /home/liusong/work_proj_2/paddle-models/PaddleCV/ocr_recognition/infer.py --model_path=gpu_model/model_51000\r\npydev debugger: process 9120 is connecting\r\n\r\nConnected to pydev debugger (build 183.5429.31)\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 1\r\ndict: None\r\ninput_images_dir: None\r\ninput_images_list: None\r\niterations: 0\r\nmodel: crnn_ctc\r\nmodel_path: gpu_model/model_51000\r\nprofile: False\r\nskip_batch_num: 0\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0905 14:58:19.599503  9120 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0905 14:58:19.635993  9120 device_context.cc:267] device: 0, cuDNN Version: 7.3.\r\nTraceback (most recent call last):\r\n  File \"/home/liusong/program_install/pycharm-2018.3.4/helpers/pydev/pydevd.py\", line 1741, in <module>\r\n    main()\r\n  File \"/home/liusong/program_install/pycharm-2018.3.4/helpers/pydev/pydevd.py\", line 1735, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/home/liusong/program_install/pycharm-2018.3.4/helpers/pydev/pydevd.py\", line 1135, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/home/liusong/program_install/pycharm-2018.3.4/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/liusong/work_proj_2/paddle-models/PaddleCV/ocr_recognition/infer.py\", line 169, in <module>\r\n    main()\r\n  File \"/home/liusong/work_proj_2/paddle-models/PaddleCV/ocr_recognition/infer.py\", line 165, in main\r\n    inference(args)\r\n  File \"/home/liusong/work_proj_2/paddle-models/PaddleCV/ocr_recognition/infer.py\", line 90, in inference\r\n    fluid.io.load_params(exe, dirname=model_dir, filename=model_file_name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 699, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 611, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/io.py\", line 648, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\nMemoryError: std::bad_alloc\r\n\r\n\r\n",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wenston2006",
        "created_at": "2019-09-05T07:11:32+00:00",
        "updated_at": "2019-09-05T07:13:06+00:00",
        "closed_at": "2019-09-05T07:13:06+00:00",
        "comments_count": [
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3277,
        "title": "pycharm中运行代码经常遇到CUDNN_STATUS_INTERNAL_ERROR",
        "body": "按照别的issue提示,采用rm -rf .nv 删除缓存; 同时在~/.bashrc文件中末尾添加 export CUDA_VISIBLE_DEVICES=0, 然后source ~/.bashrc生效; 但旺旺重启pycharm或运行一个新的.py文件就会出现CUDNN_STATUS_INTERNAL_ERROR; 请问对这个问题有没有更有效的解决办法?\r\n\r\n",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-09-05T07:42:02+00:00",
        "updated_at": "2019-09-09T03:14:00+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn",
            "wenston2006"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3288,
        "title": "Auto DL 中的HiNAS模型是根据什么样的策略搜索出来的呢",
        "body": "如题，和现有的NAS方面有啥区别，有木有文档参考一下~",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2019-09-06T08:01:20+00:00",
        "updated_at": "2019-09-09T06:52:56+00:00",
        "closed_at": null,
        "comments_count": [
            "lixingjian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3289,
        "title": "DeepFM的实现问题",
        "body": "看了Paddle_baseline_KDD2019下network_confv6.py中关于DeepFM的实现\r\n\r\n作者在实现FM的embedding时，将embedding矩阵命名为：\r\n    sparse_fm_param_attr = fluid.param_attr.ParamAttr(name=\"SparseFeatFactors\",\r\n                                                      initializer=fluid.initializer.Normal(\r\n                                                          scale=1 / math.sqrt(sparse_feature_dim)))\r\n\r\n而在实现Deep侧时，将名称也取为SparseFeatFactors\r\n            param_attr=fluid.ParamAttr(name=\"SparseFeatFactors\",\r\n                                       initializer=fluid.initializer.Uniform()))\r\n\r\n这样做的目的是为了实现DeepFM中“FM侧与DNN侧共享embedding”的设计思路吗？\r\n\r\n如果是的话，又为什么二次调用的初始化方式不同？到底是按哪次的方式初始化的？\r\n\r\n又为什么不在代码中，两次调用生成的embedding矩阵大小时，采用完全不同的长度变量？之所以没出问题，是因为这些变量的赋值恰好相同罢了。",
        "state": "open",
        "user": "stasi009",
        "closed_by": null,
        "created_at": "2019-09-06T11:57:25+00:00",
        "updated_at": "2019-09-09T06:13:26+00:00",
        "closed_at": null,
        "comments_count": [
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3293,
        "title": "fluid.layers.cross_entropy 可否支持权重系数",
        "body": "fluid.layers.cross_entropy 可否支持权重系数，指定每个类别占loss的权重",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "dbcool",
        "created_at": "2019-09-09T03:13:40+00:00",
        "updated_at": "2019-09-09T05:25:27+00:00",
        "closed_at": "2019-09-09T05:25:27+00:00",
        "comments_count": [
            "tensor-tang",
            "dbcool"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3306,
        "title": "models里面的bert训练时异常退出（很大可能是显存不足），报0xC0000409",
        "body": "尝试过bert-wwm（哈工大提供的），在keras上面可以跑batch_size=6，max_seq=512。\r\n但是，在这里面只能跑batch=1，seq_len=300（我试过）\r\n版本、环境信息：\r\n1）PaddlePaddle版本：1.5.0.post87\r\n2）CPU：i5 9400f\r\n3）GPU：1080ti，通过anaconda安装的cudatoolkit  8.0，cudnn7.1.4\r\n4）系统环境：win10专业版，64位，Python版本 3.6.8\r\n- 模型信息\r\n1）模型名称：bert 2）datafountain-ccf-情感分析比赛 3）使用算法名称 4）模型链接：https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/language_representations_kit/BERT\r\n- 复现信息：将哈工大提供的bert-wwm通过上面代码库中convert_params.py转为paddle模型，然后设置max_seq=512，batch=1，运行即可。\r\n- 问题描述：在max_seq=300，batch_size=1时发现可以正常运行，但是我在keras上面可以设置batch=6，max_seq=512。显存利用存在很大的问题。",
        "state": "open",
        "user": "wang001",
        "closed_by": null,
        "created_at": "2019-09-10T06:23:04+00:00",
        "updated_at": "2019-09-10T08:44:44+00:00",
        "closed_at": null,
        "comments_count": [
            "sneaxiy",
            "wang001",
            "sneaxiy",
            "wang001",
            "sneaxiy",
            "wang001",
            "wang001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3309,
        "title": "elmo的一个问题",
        "body": "文件ELMo/LAC_demo/bilm.py，函数encoder_wrapper对lstm出来的双向向量concat时，反向向量好像没有进行reverse，不确定这个是错误，还是本意如此；\r\n使用hub里的elmo时，使trainable=False，但嵌入的结果仍然有随机变化，是否dropout没有正常关闭",
        "state": "open",
        "user": "arcral",
        "closed_by": null,
        "created_at": "2019-09-10T08:21:26+00:00",
        "updated_at": "2019-09-10T12:34:25+00:00",
        "closed_at": null,
        "comments_count": [
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3294,
        "title": "attention ocr 识别长文本不太理想",
        "body": "长宽比例较大时(比如输入文本图片高28个像素,宽900个像素时), 文字识别效果不甚理想; 是否需要在训练数据中加入这种长宽比例较大的图片进行训练?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-09-09T03:21:54+00:00",
        "updated_at": "2019-09-10T06:27:21+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3310,
        "title": "unsqueeze问题",
        "body": "我使用unsqueeze的示例程序能正确扩展维度：   \r\n  x = fluid.layers.data(name='x', shape=[5, 10])\r\n  y = fluid.layers.unsqueeze(input=x, axes=[1])\r\n但是当我使用自己读取的图片数据，在动态图中转变为variable之后，却总是报错：\r\n    with fluid.dygraph.guard():\r\n        img_l = fluid.dygraph.to_variable(img_l)\r\n        img_r = fluid.dygraph.to_variable(img_r)\r\n        disp_l = fluid.dygraph.to_variable(disp_l)\r\n        disp_r = fluid.dygraph.to_variable(disp_r)\r\n        img_l  = paddle.fluid.layers.stack([img_l],axis=0)\r\n        img_r  = paddle.fluid.layers.stack([img_r],axis=0)\r\n        disp = paddle.fluid.layers.unsqueeze(input=disp_l, axes=[0])\r\n        ···\r\n报错信息如下：\r\nD:\\ProgramData\\Anaconda3\\envs\\deeplearning\\python.exe D:/IresNet-PaddlePaddle/stn.py\r\nTraceback (most recent call last):\r\n  File \"D:/IresNet-PaddlePaddle/stn.py\", line 188, in <module>\r\n    disp = paddle.fluid.layers.unsqueeze(input=disp_l, axes=[0])\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 6941, in unsqueeze\r\n    \"XShape\": x_shape})\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1762, in append_op\r\n    kwargs.get(\"stop_gradient\", False))\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\paddle\\fluid\\dygraph\\tracer.py\", line 59, in trace_op\r\n    framework._current_expected_place(), stop_gradient)\r\npaddle.fluid.core_avx.EnforceNotMet: op_kernel should not be null\r\nonly support op with kernel at [D:\\1.5.1\\release_cuda97\\paddle\\paddle\\fluid\\imperative\\tracer.cc:217]\r\nPaddlePaddle Call Stacks: \r\nWindows not support stack backtrace yet.\r\n\r\nProcess finished with exit code 1\r\n请问是什么问题呢，我的图片数据是读取正确的，并转换为numpy数组",
        "state": "open",
        "user": "xubin1994",
        "closed_by": null,
        "created_at": "2019-09-10T09:37:02+00:00",
        "updated_at": "2019-09-11T03:30:48+00:00",
        "closed_at": null,
        "comments_count": [
            "zhengya01",
            "xubin1994",
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3313,
        "title": "why word2vec  stop_gradient",
        "body": "word2vec 代码中这一行 不太明白\r\nneg_word_reshape.stop_gradient = True\r\n\r\ndata层本来stop_gradient默认参数就是True， 为什么还要设置一下？\r\npaddle.fluid.layers.data(name, shape, append_batch_size=True, dtype='float32', lod_level=0, type=VarType.LOD_TENSOR, stop_gradient=True)",
        "state": "open",
        "user": "liusilver1116",
        "closed_by": null,
        "created_at": "2019-09-11T08:28:24+00:00",
        "updated_at": "2019-09-11T09:27:38+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3314,
        "title": "BERT/ERNIE下跑squad模型，CPU内存一直增长",
        "body": "squad模型在加载完examples数据后，以生成器的方式产生和yield数据，理论上，CPU内存会在一个范围内，不会呈线性增长，目前大规模数据训练或者预测会因为内存问题挂掉；",
        "state": "open",
        "user": "0YuanZhang0",
        "closed_by": null,
        "created_at": "2019-09-11T09:02:16+00:00",
        "updated_at": "2021-09-07T08:08:53+00:00",
        "closed_at": null,
        "comments_count": [
            "0YuanZhang0",
            "zhengya01",
            "0YuanZhang0",
            "zhengya01",
            "Wanjun0511"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3319,
        "title": "SE_ResNeXt50_32x4d_vd预训练模型",
        "body": "看见SE_ResNet50_vd预训练模型已经提供了，不知道SE_ResNeXt50_32x4d_vd预训练模型近期能否提供呢?",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "shippingwang",
        "created_at": "2019-09-12T04:11:21+00:00",
        "updated_at": "2019-09-12T04:59:17+00:00",
        "closed_at": "2019-09-12T04:33:16+00:00",
        "comments_count": [
            "shippingwang",
            "cuicheng01",
            "cuicheng01",
            "dbcool"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3320,
        "title": "image_classification训练报warning",
        "body": "您好，用最新的分类代码训练，warning一直报，\r\n\r\n\r\nWARNING:root:\r\n     Detect that memory optimize or inplace is enabled, but the some variables in the fetch\r\n     list is not persistable, you may get wrong fetched value, or an exeception may be thrown\r\n     about cannot find variable of the fetch list.\r\n     TO FIX this:\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None)\r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "shippingwang",
        "created_at": "2019-09-12T06:47:08+00:00",
        "updated_at": "2019-09-12T07:01:56+00:00",
        "closed_at": "2019-09-12T06:58:01+00:00",
        "comments_count": [
            "ysh329",
            "dbcool",
            "ysh329",
            "qingqing01",
            "shippingwang",
            "dbcool"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3324,
        "title": "PaddleCV/image_classification 推理时间",
        "body": "您好，我用自己训练的SE_ResNet50_vd模型，在NVIDIA® Tesla® P4，python下进行inference，平均一张图70ms，但是在官网给的Paddle Fluid inference time时间是10ms左右，如下所示:\r\n\r\nModel | Top-1 | Top-5 | Paddle Fluid inference time(ms) | Paddle TensorRT inference time(ms)\r\n---|----|----|----|---\r\nSE_ResNet50_vd | 79.52% | 94.75% | 10.345 | 7.662\r\n\r\n所以有几个问题, \r\n1)python下推理时间70ms左右是正常的嘛?python下有没有可能达到10ms?\r\n2)官网给的是C++的时间嘛？\r\n",
        "state": "open",
        "user": "dbcool",
        "closed_by": null,
        "created_at": "2019-09-15T03:23:45+00:00",
        "updated_at": "2019-09-28T01:15:26+00:00",
        "closed_at": null,
        "comments_count": [
            "wangguibao",
            "wangguibao",
            "wangguibao",
            "dbcool",
            "mzchtx",
            "A1exy",
            "mzchtx",
            "A1exy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3325,
        "title": "怎么总是下载不了，下载到一半就说网络错误，下载也很慢",
        "body": "怎么总是下载不了，下载到一半就说网络错误，下载也很慢",
        "state": "closed",
        "user": "szfranciszhao",
        "closed_by": "wangguibao",
        "created_at": "2019-09-15T07:55:47+00:00",
        "updated_at": "2019-09-30T08:16:48+00:00",
        "closed_at": "2019-09-30T08:16:48+00:00",
        "comments_count": [
            "wangguibao",
            "szfranciszhao",
            "wangguibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3321,
        "title": "run.sh Syntax error",
        "body": "运行sh run.sh eval时，报\r\n`run.sh: 9: run.sh: Syntax error: \"(\" unexpected`\r\n\r\n把里面的python命令提取出来是可以运行的",
        "state": "open",
        "user": "chuj625",
        "closed_by": null,
        "created_at": "2019-09-12T07:07:05+00:00",
        "updated_at": "2020-04-07T11:52:33+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "Ailing-Zou",
            "lijingquan1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3329,
        "title": "PaddleDetection的eval.py出错 ",
        "body": "您好，我在用PaddleDetection进行eval.py的时候，出错:  \r\n**File \"/data/daibing/model-factory/logo_detection/ppdet/utils/voc_eval.py\", line 73, in bbox_eval\r\n    gt_boxes = t['gt_box'][0]\r\nKeyError: u'gt_box'**\r\n应该是下面这段代码出错\r\n   for t in results:\r\n        bboxes = t['bbox'][0]\r\n        bbox_lengths = t['bbox'][1][0]\r\n        if bboxes.shape == (1, 1) or bboxes is None:\r\n            continue\r\n        gt_boxes = t['gt_box'][0]\r\n可否帮忙解答一下",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "jerrywgz",
        "created_at": "2019-09-16T08:40:09+00:00",
        "updated_at": "2019-09-17T04:15:41+00:00",
        "closed_at": "2019-09-17T04:15:41+00:00",
        "comments_count": [
            "gavin1332",
            "dbcool",
            "jerrywgz",
            "dbcool",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3331,
        "title": "多轮match模型，请问下多轮和单轮的兼容问题有什么好的策略吗？",
        "body": "比如第二轮时候，可以走多轮，也可以走单轮，这时怎么办。\r\n谢谢！",
        "state": "open",
        "user": "guotong1988",
        "closed_by": null,
        "created_at": "2019-09-16T10:02:38+00:00",
        "updated_at": "2019-09-17T01:59:44+00:00",
        "closed_at": null,
        "comments_count": [
            "guotong1988",
            "gavin1332",
            "guotong1988",
            "gavin1332",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3333,
        "title": "PaddleGAN 模型测试中的参数 --net_G 的含义与使用方法",
        "body": " 模型测试中的参数 --net_G 的含义及其使用方法，README 中没有相关说明",
        "state": "closed",
        "user": "linshuliang",
        "closed_by": "linshuliang",
        "created_at": "2019-09-16T11:31:38+00:00",
        "updated_at": "2019-09-24T03:33:24+00:00",
        "closed_at": "2019-09-24T03:33:24+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3337,
        "title": "如何提取dynamic_lstm的在各个时刻的隐含状态输出？",
        "body": "假如如下使用 dynamic_lstm:\r\n\r\nimport paddle.fluid as fluid\r\nemb_dim = 256\r\nvocab_size = 10000\r\nhidden_dim = 512\r\n\r\ndata = fluid.layers.data(name='x', shape=[1],\r\n               dtype='int32', lod_level=1)\r\nemb = fluid.layers.embedding(input=data, size=[vocab_size, emb_dim], is_sparse=True)\r\n\r\nforward_proj = fluid.layers.fc(input=emb, size=hidden_dim * 4,\r\n                               bias_attr=False)\r\nforward, _ = fluid.layers.dynamic_lstm(\r\n    input=forward_proj, size=hidden_dim * 4, use_peepholes=False)\r\n文档中说： 返回的forward是（T x D）形，且LoD保持与输入一致。\r\n\r\n如何提取 隐藏状态（hidden state）即上面的 forward中各个时刻（t=1, 2,...T）的输出呢？",
        "state": "open",
        "user": "lch1234",
        "closed_by": null,
        "created_at": "2019-09-16T13:19:23+00:00",
        "updated_at": "2019-09-17T02:01:01+00:00",
        "closed_at": null,
        "comments_count": [
            "gavin1332",
            "lch1234",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3341,
        "title": "Floating point exception(core dumped) ./ $pro1 , ",
        "body": "I use the yolov3 to train the picture for detecting the action and emotion of person.\r\n  but when training several minute , the above error occur.\r\nI really can not sovle it ,could anybody  give us hand?",
        "state": "open",
        "user": "lipenggao0923",
        "closed_by": null,
        "created_at": "2019-09-17T01:37:19+00:00",
        "updated_at": "2019-09-17T01:40:16+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3340,
        "title": "报错信息“EnforceNotMet: Invoke operator fetch error.”",
        "body": "**根据5种花卉分类的Resnet做102分类，却报错，而且是在运行一个batch后报错，为什么？**\r\n\r\n \r\n\r\n> 错误信息如下：\r\n> \r\n> 2019-09-16 23:10:09,740 - <ipython-input-1-71f8491f418c>[line:549] - INFO: create prog success\r\n> 2019-09-16 23:10:09,742 - <ipython-input-1-71f8491f418c>[line:550] - INFO: train config: {'image_count': 6552, 'sgd_strategy': {'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002], 'lr_epochs': [20, 40, 60, 80, 100], 'learning_rate': 0.002}, 'save_persistable_dir': './persistable-params', 'continue_train': False, 'label_dict': {}, 'image_enhance_strategy': {'need_crop': True, 'need_rotate': True, 'hue_delta': 18, 'need_distort': True, 'brightness_prob': 0.5, 'saturation_delta': 0.5, 'contrast_prob': 0.5, 'hue_prob': 0.5, 'brightness_delta': 0.125, 'contrast_delta': 0.5, 'need_flip': True, 'saturation_prob': 0.5}, 'momentum_strategy': {'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002], 'lr_epochs': [20, 40, 60, 80, 100], 'learning_rate': 0.002}, 'adam_strategy': {'learning_rate': 0.002}, 'early_stop': {'successive_limit': 3, 'sample_frequency': 30, 'good_acc1': 0.85}, 'train_batch_size': 15, 'save_freeze_dir': './freeze-model', 'num_epochs': 40, 'mode': 'train', 'use_gpu': True, 'train_file_list': 'train.txt', 'mean_rgb': [127.5, 127.5, 127.5], 'input_size': [3, 224, 224], 'data_dir': 'data/data12479/hackathon-blossom-flower-classification/flower_data', 'rsm_strategy': {'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002], 'lr_epochs': [20, 40, 60, 80, 100], 'learning_rate': 0.002}, 'class_dim': 102}\r\n> 2019-09-16 23:10:09,743 - <ipython-input-1-71f8491f418c>[line:551] - INFO: build input custom reader and data feeder\r\n> 2019-09-16 23:10:09,747 - <ipython-input-1-71f8491f418c>[line:564] - INFO: build newwork\r\n> 2019-09-16 23:10:11,887 - <ipython-input-1-71f8491f418c>[line:594] - INFO: current pass: 0, start read image\r\n> 2019-09-16 23:10:18,417 - <ipython-input-1-71f8491f418c>[line:609] - INFO: Pass 0, trainbatch 10, loss 7.132730960845947, acc1 0.06666667014360428, time 0.14 sec\r\n> ---------------------------------------------------------------------------EnforceNotMet                             Traceback (most recent call last)<ipython-input-1-71f8491f418c> in <module>\r\n>     646     init_log_config()\r\n>     647     init_train_parameters()\r\n> --> 648     train()\r\n> <ipython-input-1-71f8491f418c> in train()\r\n>     598             loss, acc1, pred_ot = exe.run(main_program,\r\n>     599                                           feed=feeder.feed(data),\r\n> --> 600                                           fetch_list=train_fetch_list)\r\n>     601             t2 = time.time()\r\n>     602             batch_id += 1\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n>     648                 scope=scope,\r\n>     649                 return_numpy=return_numpy,\r\n> --> 650                 use_program_cache=use_program_cache)\r\n>     651         else:\r\n>     652             if fetch_list and program._is_data_parallel and program._program and (\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/executor.py in _run(self, program, exe, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n>     746         self._feed_data(program, feed, feed_var_name, scope)\r\n>     747         if not use_program_cache:\r\n> --> 748             exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\n>     749         else:\r\n>     750             exe.run_cached_prepared_ctx(ctx, scope, False, False, False)\r\n> EnforceNotMet: Invoke operator fetch error.\r\n> Python Callstacks: \r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n>     attrs=kwargs.get(\"attrs\", None))\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 437, in _add_feed_fetch_ops\r\n>     attrs={'col': i})\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 744, in _run\r\n>     fetch_var_name=fetch_var_name)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n>     use_program_cache=use_program_cache)\r\n>   File \"<ipython-input-1-71f8491f418c>\", line 600, in train\r\n>     fetch_list=train_fetch_list)\r\n>   File \"<ipython-input-1-71f8491f418c>\", line 648, in <module>\r\n>     train()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\r\n>     exec(code_obj, self.user_global_ns, self.user_ns)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\r\n>     if (yield from self.run_code(code, result)):\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\r\n>     interactivity=interactivity, compiler=compiler, result=result)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n>     coro.send(None)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\r\n>     return runner(coro)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\r\n>     raw_cell, store_history, silent, shell_futures)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n>     res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\r\n>     yielded = next(result)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\r\n>     user_expressions, allow_stdin,\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\r\n>     yielded = next(result)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\r\n>     yield gen.maybe_future(handler(stream, idents, msg))\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\r\n>     yielded = next(result)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\r\n>     yield gen.maybe_future(dispatch(*args))\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/gen.py\", line 1147, in run\r\n>     yielded = self.gen.send(value)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/gen.py\", line 1233, in inner\r\n>     self.run()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\r\n>     return fn(*args, **kwargs)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/ioloop.py\", line 758, in _run_callback\r\n>     ret = callback()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/asyncio/events.py\", line 127, in _run\r\n>     self._callback(*self._args)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\r\n>     handle._run()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\r\n>     self._run_once()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\r\n>     self.asyncio_loop.run_forever()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\r\n>     self.io_loop.start()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n>     app.start()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n>     app.launch_new_instance()\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/runpy.py\", line 85, in _run_code\r\n>     exec(code, run_globals)\r\n>   File \"/opt/conda/envs/python35-paddle120-env/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\r\n>     \"__main__\", mod_spec)\r\n> C++ Callstacks: \r\n> cudaMemcpy failed in paddle::platform::GpuMemcpySync (0x7f0b7e9eba40 -> 0x7f0a9abff040, length: 4): unspecified launch failure at [/paddle/paddle/fluid/platform/gpu_info.cc:280]\r\n> PaddlePaddle Call Stacks: \r\n> 0       0x7f0ea056e2e0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n> 1       0x7f0ea056e659p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n> 2       0x7f0ea25849ccp paddle::platform::GpuMemcpySync(void*, void const*, unsigned long, cudaMemcpyKind) + 188\r\n> 3       0x7f0ea06f7079p void paddle::memory::Copy<paddle::platform::CPUPlace, paddle::platform::CUDAPlace>(paddle::platform::CPUPlace, void*, paddle::platform::CUDAPlace, void const*, unsigned long, CUstream_st*) + 249\r\n> 4       0x7f0ea2524454p paddle::framework::TensorCopySync(paddle::framework::Tensor const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::Tensor*) + 900\r\n> 5       0x7f0ea1f65490p paddle::operators::FetchOp::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 656\r\n> 6       0x7f0ea24c702cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n> 7       0x7f0ea06f847ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n> 8       0x7f0ea06fb51fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n> 9       0x7f0ea055f96dp\r\n> 10      0x7f0ea05a0ca6p\r\n> 11      0x7f0f245e2199p PyCFunction_Call + 233\r\n> 12      0x7f0f2467d3f9p PyEval_EvalFrameEx + 33545\r\n> 13      0x7f0f2467f4b6p\r\n> 14      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 15      0x7f0f2467f4b6p\r\n> 16      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 17      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 18      0x7f0f2467f4b6p\r\n> 19      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 20      0x7f0f2467f5ebp PyEval_EvalCode + 59\r\n> 21      0x7f0f24672c5dp\r\n> 22      0x7f0f245e2179p PyCFunction_Call + 201\r\n> 23      0x7f0f2467cdbep PyEval_EvalFrameEx + 31950\r\n> 24      0x7f0f245b6410p _PyGen_Send + 128\r\n> 25      0x7f0f2467b953p PyEval_EvalFrameEx + 26723\r\n> 26      0x7f0f245b6410p _PyGen_Send + 128\r\n> 27      0x7f0f2467b953p PyEval_EvalFrameEx + 26723\r\n> 28      0x7f0f245b6410p _PyGen_Send + 128\r\n> 29      0x7f0f2467cd60p PyEval_EvalFrameEx + 31856\r\n> 30      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 31      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 32      0x7f0f2467f4b6p\r\n> 33      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 34      0x7f0f245bec33p\r\n> 35      0x7f0f2458d33ap PyObject_Call + 106\r\n> 36      0x7f0f246776eep PyEval_EvalFrameEx + 9726\r\n> 37      0x7f0f2467f4b6p\r\n> 38      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 39      0x7f0f245b56bap\r\n> 40      0x7f0f24670af6p\r\n> 41      0x7f0f245e2179p PyCFunction_Call + 201\r\n> 42      0x7f0f2467cdbep PyEval_EvalFrameEx + 31950\r\n> 43      0x7f0f2467f4b6p\r\n> 44      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 45      0x7f0f245b56bap\r\n> 46      0x7f0f24670af6p\r\n> 47      0x7f0f245e2179p PyCFunction_Call + 201\r\n> 48      0x7f0f2467cdbep PyEval_EvalFrameEx + 31950\r\n> 49      0x7f0f2467f4b6p\r\n> 50      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 51      0x7f0f245b56bap\r\n> 52      0x7f0f24670af6p\r\n> 53      0x7f0f245e2179p PyCFunction_Call + 201\r\n> 54      0x7f0f2467cdbep PyEval_EvalFrameEx + 31950\r\n> 55      0x7f0f2467f4b6p\r\n> 56      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 57      0x7f0f245beb56p\r\n> 58      0x7f0f2458d33ap PyObject_Call + 106\r\n> 59      0x7f0f246776eep PyEval_EvalFrameEx + 9726\r\n> 60      0x7f0f245b6410p _PyGen_Send + 128\r\n> 61      0x7f0f2467cd60p PyEval_EvalFrameEx + 31856\r\n> 62      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 63      0x7f0f2467f4b6p\r\n> 64      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 65      0x7f0f245bec33p\r\n> 66      0x7f0f2458d33ap PyObject_Call + 106\r\n> 67      0x7f0f246776eep PyEval_EvalFrameEx + 9726\r\n> 68      0x7f0f2467f4b6p\r\n> 69      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 70      0x7f0f245beb56p\r\n> 71      0x7f0f2458d33ap PyObject_Call + 106\r\n> 72      0x7f0f246f2ccap\r\n> 73      0x7f0f2458d33ap PyObject_Call + 106\r\n> 74      0x7f0f246794c5p PyEval_EvalFrameEx + 17365\r\n> 75      0x7f0f2467f4b6p\r\n> 76      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 77      0x7f0f245beb56p\r\n> 78      0x7f0f2458d33ap PyObject_Call + 106\r\n> 79      0x7f0f246776eep PyEval_EvalFrameEx + 9726\r\n> 80      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 81      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 82      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 83      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 84      0x7f0f2467d1d0p PyEval_EvalFrameEx + 32992\r\n> 85      0x7f0f2467f4b6p\r\n> 86      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 87      0x7f0f2467f4b6p\r\n> 88      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 89      0x7f0f2467f5ebp PyEval_EvalCode + 59\r\n> 90      0x7f0f24672c5dp\r\n> 91      0x7f0f245e2179p PyCFunction_Call + 201\r\n> 92      0x7f0f2467cdbep PyEval_EvalFrameEx + 31950\r\n> 93      0x7f0f2467f4b6p\r\n> 94      0x7f0f2467c5b5p PyEval_EvalFrameEx + 29893\r\n> 95      0x7f0f2467f4b6p\r\n> 96      0x7f0f2467f5a8p PyEval_EvalCodeEx + 72\r\n> 97      0x7f0f245beb56p\r\n> 98      0x7f0f2458d33ap PyObject_Call + 106\r\n> 99      0x7f0f246cbba1p",
        "state": "closed",
        "user": "tmylla",
        "closed_by": "tmylla",
        "created_at": "2019-09-16T15:16:32+00:00",
        "updated_at": "2019-09-20T06:45:01+00:00",
        "closed_at": "2019-09-20T06:45:01+00:00",
        "comments_count": [
            "gavin1332",
            "tmylla"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3342,
        "title": "能否提供实现gpt-2的思路？",
        "body": "请问能否提供gpt-2（open ai）代码实现思路？\r\n我对其中decoder部分里面的masked multi head attention不太理解，请问能否有思路或相关实现提供？",
        "state": "closed",
        "user": "AnShengqiang",
        "closed_by": "AnShengqiang",
        "created_at": "2019-09-17T03:19:47+00:00",
        "updated_at": "2019-11-18T06:24:53+00:00",
        "closed_at": "2019-11-18T06:24:53+00:00",
        "comments_count": [
            "AnShengqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3345,
        "title": "PaddleDetection 检测网络配置是否支持设置短边像素自动缩放图片大小并保存长高比例",
        "body": "\r\n![image](https://user-images.githubusercontent.com/8444061/65016198-3a4c3b00-d956-11e9-98cd-9c43015f6685.png)\r\n\r\nPaddleDetection 中 Faster-RCNN 训练支持图片任意长宽比例输入，通过设置短边像素值（一般取600）自动缩放保存长高比不变吗？\r\n\r\n如果有，请问应该在哪里进行配置，在配置文件中未看到相关的配置选项，上述图片中的 DataFeed 感觉输入图像的像素值和长高比例是设置死的。",
        "state": "open",
        "user": "PamixSun",
        "closed_by": null,
        "created_at": "2019-09-17T06:23:16+00:00",
        "updated_at": "2019-09-17T10:49:18+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz",
            "jerrywgz",
            "PamixSun",
            "jerrywgz",
            "PamixSun",
            "jerrywgz"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3346,
        "title": "使用量化压缩装载int8模型运行提示op mul Y must be the same. Get (float) != (int8_t)",
        "body": "- 系统环境：\r\n    - Paddle版本：1.5.1，CPU，无使用其他加速模块\r\n    - 系统: CentOS 6.3\r\n\r\n- 问题描述：\r\n    - 使用paddle.fluid.contrib.slim.Compressor模块进行模型压缩\r\n    - 压缩后的模型，float能正常运行，int8版出现以下错误：\r\n![image](https://user-images.githubusercontent.com/23732409/65028813-40024a80-d96f-11e9-8654-0881e8e0023d.png)\r\n\r\n- 问题复现：\r\n```\r\ngit clone https://github.com/Bond-SYSU/paddle_compress.git\r\ncd paddle_compress\r\nsh run.sh compress   # 执行模型压缩\r\npython inference_model.py --inference_save_dir ./output/float/  # 测试float版\r\npython inference_model.py --inference_save_dir ./output/int8/  # 测试int8版，报错\r\n```\r\n\r\n",
        "state": "open",
        "user": "Bond-H",
        "closed_by": null,
        "created_at": "2019-09-17T09:22:51+00:00",
        "updated_at": "2020-07-06T03:18:00+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "Bond-H",
            "Xreki",
            "Bond-H",
            "Xreki",
            "Bond-H",
            "Xreki",
            "Bond-H",
            "ZhiyiLan"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3348,
        "title": "paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul_grad error",
        "body": "多卡训练过程中报错paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul_grad error\r\n```\r\nTraceback (most recent call last):\r\n328   File \"train.py\", line 165, in <module>\r\n329     train(args)\r\n330   File \"train.py\", line 134, in train\r\n331     infer_outs = exe.run(compiler_prog, fetch_list=fetch_list)\r\n332   File \"/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 666, in run\r\n333     return_numpy=return_numpy)\r\n334   File \"/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 528, in _run_p    arallel\r\n335     exe.run(fetch_var_names, fetch_var_name)\r\n336 paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul_grad error.\r\n337 Python Callstacks:\r\n338   File \"/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 1771, in appe    nd_op\r\n339     attrs=kwargs.get(\"attrs\", None))\r\n340   File \"/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in app    end_op\r\n341     return self.main_program.current_block().append_op(*args, **kwargs)\r\n342   File \"/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 334, in fc\r\n343     \"y_num_col_dims\": 1})\r\n344   File \"/home/work/lixiaokang04/data/ernie/vvt_ernie_embs/models/video_text/tsn_res_model.py\", line 158, in net\r\n345     size=output_dim, bias_attr=False)\r\n346   File \"/home/work/lixiaokang04/data/ernie/vvt_ernie_embs/models/video_text/video_text.py\", line 157, in build_model\r\n347     self.video_emb_neg = videomodel.net(input = self.feature_input[7], output_dim=cfg['tsn_output_size'])\r\n348   File \"train.py\", line 99, in train\r\n349     train_model.build_model()\r\n350   File \"train.py\", line 165, in <module>\r\n351     train(args)\r\n352 C++ Callstacks:\r\n353 The places of matrices must be same at [/paddle/paddle/fluid/operators/math/blas_impl.h:392]\r\n354 PaddlePaddle Call Stacks:\r\n355 0       0x7f953cc9aad0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n356 1       0x7f953cc9ae49p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n357 2       0x7f953d42a46cp void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<float>(paddle::framework::Tensor co    nst&, bool, paddle::framework::Tensor const&, bool, float, paddle::framework::Tensor*, float) const + 412\r\n```",
        "state": "open",
        "user": "lxk1990727",
        "closed_by": null,
        "created_at": "2019-09-17T11:20:51+00:00",
        "updated_at": "2019-09-18T13:20:28+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "lxk1990727",
            "shippingwang",
            "lxk1990727",
            "shippingwang",
            "lxk1990727",
            "shippingwang",
            "lxk1990727",
            "shippingwang",
            "lxk1990727"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3350,
        "title": "PaddleNLP\\similarity_net模型训练后无模型输出",
        "body": "在win10下操作，命令行如下。完成训练后，并没有任何结果在--output_dir ./model_files中。请问如何才能将训练后的结果保存？\r\n\r\n```\r\nPS E:\\paddlehub\\models\\PaddleNLP\\similarity_net> python run_classifier.py    --task_name 'wyh_simmilarity_net_fine_tune_test'    --use_cuda false     --do_train True      --do_valid True      --do_test True       --do_infer True     --batch_size 128     --train_data_dir ./data/qqsim     --valid_data_dir ./data/qqsim     --test_data_dir ./data/qqsim       --infer_data_dir ./data/infer_data     --output_dir ./model_files      --config_path ./config/bow_pairwise.json     --vocab_path ./data/term2id.dict       --epoch 10        --save_steps 1000      --validation_steps 100   --task_mode 'pairwise'  --compute_accuracy False      --lamda 0.958\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 128\r\ncompute_accuracy: False\r\nconfig_path: ./config/bow_pairwise.json\r\ndo_infer: True\r\ndo_test: True\r\ndo_train: True\r\ndo_valid: True\r\nenable_ce: False\r\nepoch: 10\r\ninfer_data_dir: ./data/infer_data\r\ninfer_result_path: infer_result\r\ninit_checkpoint: None\r\nlamda: 0.958\r\noutput_dir: ./model_files\r\nsave_steps: 1000\r\nskip_steps: 10\r\ntask_mode: pairwise\r\ntask_name: wyh_simmilarity_net_fine_tune_test\r\ntest_data_dir: ./data/qqsim\r\ntest_result_path: test_result\r\ntrain_data_dir: ./data/qqsim\r\nuse_cuda: False\r\nvalid_data_dir: ./data/qqsim\r\nvalidation_steps: 100\r\nverbose_result: True\r\nvocab_path: ./data/term2id.dict\r\n------------------------------------------------\r\n```\r\n\r\n\r\n```\r\ndevice count: 1\r\nstart train process ...\r\nI0918 08:48:18.885494  9960 parallel_executor.cc:334] The number of CPUPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0918 08:48:18.889495  9960 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\nepoch: 0, loss: 0.004120, used time: 7 sec\r\nepoch: 1, loss: 0.000024, used time: 7 sec\r\nepoch: 2, loss: 0.000006, used time: 7 sec\r\nepoch: 3, loss: 0.000000, used time: 7 sec\r\nepoch: 4, loss: 0.000000, used time: 7 sec\r\nepoch: 5, loss: 0.000000, used time: 7 sec\r\nglobal_steps: 100, valid_auc: 0.605413\r\nepoch: 6, loss: 0.000000, used time: 7 sec\r\nepoch: 7, loss: 0.000000, used time: 7 sec\r\nepoch: 8, loss: 0.000000, used time: 7 sec\r\nepoch: 9, loss: 0.000000, used time: 7 sec\r\nAUC of test is 0.605461\r\n```",
        "state": "closed",
        "user": "xinaiwunai",
        "closed_by": "xinaiwunai",
        "created_at": "2019-09-18T00:52:42+00:00",
        "updated_at": "2019-10-12T02:04:49+00:00",
        "closed_at": "2019-10-12T02:04:49+00:00",
        "comments_count": [
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3351,
        "title": "PaddleDetection计算mAP有异常",
        "body": "您好，我在PaddleDetection用eval.py计算mAP的时候，出现了mAP=99.03,但是实际上模型infer.py结果却一般，想问下这是什么情况？\r\n\r\nI0918 02:33:16.505477   491 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\r\n2019-09-18 02:33:18,616-INFO: Test iter 0\r\n2019-09-18 02:33:34,774-INFO: Test finish iter 99\r\n2019-09-18 02:33:34,775-INFO: Total number of images: 99, inference time: 5.41008615843 fps.\r\n2019-09-18 02:33:34,775-INFO: Start evaluate...\r\n2019-09-18 02:33:34,789-INFO: Accumulating evaluatation results...\r\n2019-09-18 02:33:34,791-INFO: mAP(0.50, 11point) = 99.03",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "jerrywgz",
        "created_at": "2019-09-18T02:36:04+00:00",
        "updated_at": "2019-09-18T08:58:48+00:00",
        "closed_at": "2019-09-18T08:58:48+00:00",
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3359,
        "title": "deeplabv3_xception65给出的miou=0.79，直接下载权重使用paddleseg评测只有0.59，是否可以给出复现的具体过程",
        "body": "从github上下载deeplabv3_xception65_bn的权重参数，直接用paddleseg加载进行预测，使用默认的参数配置，输出的miou只有0.59\r\n\r\n[EVAL]#image=500 acc=0.9114 IoU=0.5917\r\n[EVAL]Category IoU: [0.9464 0.6721 0.8490 0.4693 0.4214 0.2727 0.3392 0.4761 0.8506 0.5234 0.8905 0.5392 0.2792 0.8313 0.6819 0.7244 0.6624 0.2800 0.5329]\r\n[EVAL]Category Acc: [0.9841 0.8093 0.9030 0.7519 0.6044 0.5073 0.6370 0.7179 0.8937 0.7346 0.9478 0.7009 0.5528 0.8958 0.7783 0.8263 0.8320 0.6636 0.6784]\r\n\r\n参数配置如下\r\nTRAIN_CROP_SIZE: (512, 512) # (width, height), for unpadding rangescaling and stepscaling\r\nEVAL_CROP_SIZE: (512, 512) # (width, height), for unpadding rangescaling and stepscaling\r\nAUG:\r\n    AUG_METHOD: \"unpadding\" # choice unpadding rangescaling and stepscaling\r\n    FIX_RESIZE_SIZE: (512, 512) # (width, height), for unpadding\r\n\r\n    INF_RESIZE_VALUE: 500  # for rangescaling\r\n    MAX_RESIZE_VALUE: 600  # for rangescaling\r\n    MIN_RESIZE_VALUE: 400  # for rangescaling\r\n\r\n    MAX_SCALE_FACTOR: 1.25  # for stepscaling\r\n    MIN_SCALE_FACTOR: 0.75  # for stepscaling\r\n    SCALE_STEP_SIZE: 0.25  # for stepscaling\r\n    MIRROR: True\r\nBATCH_SIZE: 4\r\nDATASET:\r\n    DATA_DIR: \"E:/dakeai/cityscape\"\r\n    IMAGE_TYPE: \"rgb\"  # choice rgb or rgba\r\n    NUM_CLASSES: 19\r\n    TEST_FILE_LIST: \"E:/dakeai/cityscape/list/cityscapes_val_list.txt\"\r\n    TRAIN_FILE_LIST: \"E:/dakeai/cityscape/list/cityscapes_train_list.txt\"\r\n    VAL_FILE_LIST: \"E:/dakeai/cityscape/list/cityscapes_val_list.txt\"\r\n    VIS_FILE_LIST: \"E:/dakeai/cityscape/list/cityscapes_val_list.txt\"\r\n    IGNORE_INDEX: 255\r\n    SEPARATOR: \" \"\r\nFREEZE:\r\n    MODEL_FILENAME: \"__model__\"\r\n    PARAMS_FILENAME: \"__params__\"\r\nMODEL:\r\n    MODEL_NAME: \"deeplabv3p\"\r\n    DEFAULT_NORM_TYPE: \"bn\"\r\n    DEEPLAB:\r\n        BACKBONE: \"xception_65\"\r\nTRAIN:\r\n    PRETRAINED_MODEL_DIR: \"./pretrained_model/deeplabv3p_xception65_bn_coco/\"\r\n    MODEL_SAVE_DIR: \"./saved_model/deeplabv3p_xception65_bn_pet/\"\r\n    SNAPSHOT_EPOCH: 10\r\nTEST:\r\n    TEST_MODEL: \"./saved_model/deeplabv3p_xception65_bn_pet/final\"\r\nSOLVER:\r\n    NUM_EPOCHS: 100\r\n    LR: 0.005\r\n    LR_POLICY: \"poly\"\r\n    OPTIMIZER: \"sgd\"\r\n",
        "state": "open",
        "user": "stuhailiu",
        "closed_by": null,
        "created_at": "2019-09-18T06:33:30+00:00",
        "updated_at": "2019-09-18T11:12:22+00:00",
        "closed_at": null,
        "comments_count": [
            "LutaoChu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3353,
        "title": "有关于LAC模型词典干预的问题",
        "body": "请问，我在使用LAC模型加入自己的词典的时候，发现不支持我自己新建一个词性，之后是否能够支持？",
        "state": "open",
        "user": "JayJQK",
        "closed_by": null,
        "created_at": "2019-09-18T03:01:58+00:00",
        "updated_at": "2019-09-19T05:57:14+00:00",
        "closed_at": null,
        "comments_count": [
            "JesseyXujin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3360,
        "title": "error: function dynload::cuptiActivityFlushAll(CUPTI_ACTIVITY_FLAG_FLUSH_FORCED) failed with error CUPTI_ERROR_NOT_INITIALIZED",
        "body": "我这边用ocr_recognition跑识别训练时碰见了如下问题，麻烦帮忙看一下\r\n![paddle_err](https://user-images.githubusercontent.com/13143336/65122203-f4a97400-da22-11e9-9280-b018830648ad.png)\r\n",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2019-09-18T06:45:43+00:00",
        "updated_at": "2019-09-18T12:04:32+00:00",
        "closed_at": "2019-09-18T12:04:32+00:00",
        "comments_count": [
            "shippingwang",
            "endy-see",
            "wanghaoshuang",
            "endy-see",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3361,
        "title": "deepFM代码问题",
        "body": "models/PaddleRec/ctr/deepfm/network_conf.py代码的第26和40行在定义embedding层的size时，为什么是num_feat+1而不是直接用num_feat？",
        "state": "open",
        "user": "machuw",
        "closed_by": null,
        "created_at": "2019-09-18T07:27:15+00:00",
        "updated_at": "2020-01-10T03:07:08+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "machuw",
            "jinyryr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3363,
        "title": "如果eos发生变化无法做infer的操作",
        "body": "[attention_model.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/ocr_recognition/attention_model.py)这个文件中如果eos发生变化无法做infer的操作（比如因为要识别有数字所以eos改成了其他值）\r\nattention_infer的方法中\r\n```xml\r\nselected_ids, selected_scores = fluid.layers.beam_search(\r\n            pre_ids,\r\n            pre_score,\r\n            topk_indices,\r\n            accu_scores,\r\n            beam_size,\r\n            eos,  # 这里应该从1改成eos，否则eos如果发生变化会导致无法做infer操作\r\n            #level=0\r\n        )\r\n```",
        "state": "closed",
        "user": "xiaolvtaomi",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-09-19T03:22:29+00:00",
        "updated_at": "2019-09-20T07:03:18+00:00",
        "closed_at": "2019-09-20T07:03:18+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": [
            "enhancement",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3368,
        "title": "could not broadcast input array from shape (3,128,58) into shape (3,128)",
        "body": "训练完一轮报以上错误，程序还可以继续运行，但每运行完一轮就会报错；\r\n但一直不提示错误在哪里；\r\n这个是什么原因",
        "state": "closed",
        "user": "qwertyuiop194",
        "closed_by": "heavengate",
        "created_at": "2019-09-19T07:01:06+00:00",
        "updated_at": "2019-09-19T13:51:37+00:00",
        "closed_at": "2019-09-19T13:51:27+00:00",
        "comments_count": [
            "heavengate",
            "qwertyuiop194",
            "heavengate",
            "qwertyuiop194"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3379,
        "title": "ocr attention如何画出attention center?",
        "body": "在某些文献中看到给出了样本图片中的attention center, 请问paddlepaddle中如何画出attention center? ",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-09-20T07:24:04+00:00",
        "updated_at": "2019-09-20T07:24:04+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3370,
        "title": "ocr attention 模型运行报错",
        "body": "系统：ubuntu18.08\r\npaddle版本：1.5 cpu\r\n图片为宽高不一的图片，宽/高都小于512/48，示例如下\r\n294 28 img_0000001.jpg 7,66,714,51,1441,14,293,407,1746,3257,78\r\n92 22 img_0000002.jpg 617,569,1434,1423\r\n62 28 img_0000003.jpg 137,36\r\n\r\n报错如下：\r\n```\r\nfinish batch shuffle\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 235, in <module>\r\n    main()\r\n  File \"train.py\", line 231, in main\r\n    train(args)\r\n  File \"train.py\", line 164, in train\r\n    results = train_one_batch(data)\r\n  File \"train.py\", line 125, in train_one_batch\r\n    fetch_list=fetch_vars)\r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 651, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 749, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator edit_distance error.\r\nPython Callstacks: \r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1771, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 5430, in edit_distance\r\n    attrs={\"normalized\": normalized})\r\n  File \"/home/jason/anaconda3/envs/pdc/lib/python3.6/site-packages/paddle/fluid/evaluator.py\", line 261, in __init__\r\n    input=input, label=label, ignored_tokens=ignored_tokens)\r\n  File \"/home/jason/dataset/ocr_recognition/attention_model.py\", line 200, in attention_train_net\r\n    input=maxid, label=label_out, ignored_tokens=[sos, eos])\r\n  File \"train.py\", line 74, in train\r\n    args, data_shape, num_classes)\r\n  File \"train.py\", line 231, in main\r\n    train(args)\r\n  File \"train.py\", line 235, in <module>\r\n    main()\r\nC++ Callstacks: \r\nReference string 12 is empty. at [/paddle/paddle/fluid/operators/edit_distance_op.h:42]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f0424dd6650p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f0424dd69c9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f04253f2582p paddle::operators::EditDistanceKernel<paddle::platform::CPUPlace, float>::Compute(paddle::framework::ExecutionContext const&) const + 2946\r\n3       0x7f04253f2603p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::EditDistanceKernel<paddle::platform::CPUPlace, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n4       0x7f042611d547p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n5       0x7f042611dcb1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n6       0x7f042611bb5bp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 267\r\n7       0x7f0424f55c9ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 206\r\n8       0x7f0424f58d1fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n9       0x7f0424dc8e9dp\r\n10      0x7f0424e0597ep\r\n11      0x560291d56c54p _PyCFunction_FastCallDict + 340\r\n12      0x560291ddec0ep\r\n13      0x560291e0175ap _PyEval_EvalFrameDefault + 778\r\n14      0x560291dd7e66p\r\n15      0x560291dd8ed6p\r\n16      0x560291ddeb95p\r\n17      0x560291e0251cp _PyEval_EvalFrameDefault + 4300\r\n18      0x560291dd7e66p\r\n19      0x560291dd8ed6p\r\n20      0x560291ddeb95p\r\n21      0x560291e0251cp _PyEval_EvalFrameDefault + 4300\r\n22      0x560291dd829ep\r\n23      0x560291dd8ed6p\r\n24      0x560291ddeb95p\r\n25      0x560291e0175ap _PyEval_EvalFrameDefault + 778\r\n26      0x560291dd829ep\r\n27      0x560291dd8ed6p\r\n28      0x560291ddeb95p\r\n29      0x560291e0175ap _PyEval_EvalFrameDefault + 778\r\n30      0x560291dd8c5bp\r\n31      0x560291ddeb95p\r\n32      0x560291e0175ap _PyEval_EvalFrameDefault + 778\r\n33      0x560291dd99b9p PyEval_EvalCodeEx + 809\r\n34      0x560291dda75cp PyEval_EvalCode + 28\r\n35      0x560291e5a744p\r\n36      0x560291e5ab41p PyRun_FileExFlags + 161\r\n37      0x560291e5ad43p PyRun_SimpleFileExFlags + 451\r\n38      0x560291e5e833p Py_Main + 1555\r\n39      0x560291d2888ep main + 238\r\n40      0x7f0440ce5b97p __libc_start_main + 231\r\n41      0x560291e08160p\r\n```",
        "state": "closed",
        "user": "banbishan",
        "closed_by": "banbishan",
        "created_at": "2019-09-19T07:37:19+00:00",
        "updated_at": "2019-10-22T09:41:48+00:00",
        "closed_at": "2019-10-22T09:41:48+00:00",
        "comments_count": [
            "wanghaoshuang",
            "banbishan",
            "wanghaoshuang",
            "banbishan"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3378,
        "title": "如何实现自定义层?",
        "body": "目前需要自定以一个层起到crop的功能,该层的定义可用如下公式表示:\r\n\r\nF_t=Crop(F, c_t, Ph, Pw)\r\nF, Ph, Pw分别来自输入图片和手动标记结果; c_t是由深度学习网络中另一个层的参数计算得到, 现在需要定义F_t这个层, 实现将梯度反向传递给c_t, 请问该如何自定义?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-09-20T07:17:44+00:00",
        "updated_at": "2019-09-25T02:47:10+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3372,
        "title": "Compiled with WITH_GPU, but no GPU found in runtime.",
        "body": "Compiled with WITH_GPU, but no GPU found in runtime.\r\n明明GPU都没在工作呀，为什么没有gpu呢\r\n![77](https://user-images.githubusercontent.com/50400428/65244979-500c5c80-db1e-11e9-9753-e3a0bd6e72d4.png)\r\n",
        "state": "open",
        "user": "pandaxue",
        "closed_by": null,
        "created_at": "2019-09-19T12:44:58+00:00",
        "updated_at": "2023-04-11T08:37:50+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "pandaxue",
            "heavengate",
            "heavengate",
            "pandaxue",
            "heavengate",
            "pandaxue",
            "BeyondYourself",
            "yinhaiyang",
            "happybear1015"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3373,
        "title": "PaddleDetection不支持加载检测网络header相关参数",
        "body": "- 问题描述：PaddleDetection的配置文件直接加载骨干网络的预训练模型。如果单纯训练COCO任务，那么让检测头权重随机初始化很合理。实际中，一般是使用COCO训练好的整体网络再去finetune其他任务，效果会更好。\r\n\r\n- 对比实验：分别使用paddle原始的yolov3和PaddleDetection的yolov3，训练同一个任务（只有一个类别的检测任务），前者比后者map高0.02左右（前者0.81，后者0.79）。推测是加载权重的差异导致的，paddle原始的yolov3可以加载整个网络（backbone+yolov3检测头）的权重，PaddleDetection默认只加载backbone的权重。\r\n\r\n- 参考code链接：\r\nPaddleDetection： https://github.com/PaddlePaddle/models/blob/ad1a917fd8588931eff310f8bc8962e2c02eecaf/PaddleCV/PaddleDetection/configs/yolov3_darknet.yml#L11\r\npaddle原始的yolov3：https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/yolov3  最下面的「模型fine-tune」方式\r\n![123](https://user-images.githubusercontent.com/10766225/65295387-b8495580-db93-11e9-92d4-6d84c144fe85.jpg)\r\n\r\n",
        "state": "open",
        "user": "soldier828",
        "closed_by": null,
        "created_at": "2019-09-20T02:37:44+00:00",
        "updated_at": "2019-10-08T07:11:28+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz",
            "soldier828",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3380,
        "title": "fluid.install_check.run_check()",
        "body": "fluid.install_check.run_check()在验证这个安装的时候出错，不知道为什么",
        "state": "open",
        "user": "pandaxue",
        "closed_by": null,
        "created_at": "2019-09-20T08:33:52+00:00",
        "updated_at": "2019-09-27T01:22:09+00:00",
        "closed_at": null,
        "comments_count": [
            "kolinwei",
            "pandaxue",
            "JepsonWong",
            "pandaxue",
            "JepsonWong",
            "pandaxue",
            "JepsonWong",
            "pandaxue"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3381,
        "title": "更新LAC模型",
        "body": "更新内容包含以下几点：\r\n- 基于新版开发规范更新模型的接口，增强易用性\r\n- 对模型的更新，显著提升模型计算效率，并降低模型的体积，同时模型效果也有一定的提升\r\n- 修复模型infer模式时输入空串报错的问题（对应issue#3149和issue#3106，待paddlehub更新）",
        "state": "closed",
        "user": "Bond-H",
        "closed_by": "Bond-H",
        "created_at": "2019-09-20T09:54:05+00:00",
        "updated_at": "2019-09-26T01:44:54+00:00",
        "closed_at": "2019-09-26T01:44:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3385,
        "title": "使用PaddleNLP可否实现语义依存分析？",
        "body": "使用PaddleNLP可否实现语义依存分析？",
        "state": "open",
        "user": "az235",
        "closed_by": null,
        "created_at": "2019-09-22T07:32:32+00:00",
        "updated_at": "2019-09-23T01:41:56+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3393,
        "title": "ocr attention 模型可否提供基于dygraph版本的?",
        "body": "目前提供的是静态图版本的,调试起来比较困难.",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "sandyhouse",
        "created_at": "2019-09-24T03:33:17+00:00",
        "updated_at": "2019-09-25T08:32:44+00:00",
        "closed_at": "2019-09-25T04:04:08+00:00",
        "comments_count": [
            "sandyhouse",
            "wenston2006",
            "sandyhouse",
            "wenston2006",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3388,
        "title": "legacy 下的dssm模型请问现在对应在fiuld框架下的哪个文件下",
        "body": "",
        "state": "open",
        "user": "yangyan1227",
        "closed_by": null,
        "created_at": "2019-09-23T07:22:51+00:00",
        "updated_at": "2019-09-23T11:41:25+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian",
            "yangyan1227"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3402,
        "title": "language_representations_kit/ERNIE下的XNLI任务报错",
        "body": "环境：paddle1.5.2  python3.7\r\n\r\n执行命令：sh script/zh_task/ernie_base/run_xnli.sh\r\n错误信息：\r\n![image-20190923191924-yclpte](https://user-images.githubusercontent.com/19245678/65563000-c378f880-df7a-11e9-8e85-185aa460fe31.png)\r\n需要手动建log文件夹，建议可以自动创建。",
        "state": "open",
        "user": "xiaosang",
        "closed_by": null,
        "created_at": "2019-09-25T01:57:02+00:00",
        "updated_at": "2019-10-08T13:11:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3396,
        "title": "yolov3能否增加slim的相应代码",
        "body": "https://github.com/PaddlePaddle/models/issues/2350\r\n当前根据官方的slim-ssd修改yolov3代码，遇到很多问题。“reader要改，模型结构要改，配置文件要改，保存结果也要改，需要修改不少源码。”\r\n而且paddle的ssd和yolo的代码风格很不一样，改起来遇到很多问题。",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-09-24T07:05:12+00:00",
        "updated_at": "2019-10-30T06:35:19+00:00",
        "closed_at": null,
        "comments_count": [
            "mozpp",
            "mozpp",
            "mozpp",
            "wanghaoshuang",
            "Ezra-Yu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3394,
        "title": "light_nas search 遇到大模型显存超限",
        "body": "报错信息：\r\n![image](https://user-images.githubusercontent.com/38800877/65475893-c1983200-deb3-11e9-8f9f-4aef936025a2.png)\r\n这是在5个epoch后，计算的MobileNetV2 reward:0.454199999571,latency:27.92442;尝试新的token训练时报上面的错误，\r\n配置：\r\n![image](https://user-images.githubusercontent.com/38800877/65475928-dbd21000-deb3-11e9-9043-d338d685be25.png)\r\nbatch_size=256 ,4张P40，开启GC：\r\n![image](https://user-images.githubusercontent.com/38800877/65476023-2489c900-deb4-11e9-8de2-ec9cb8bf1a29.png)\r\n\r\n",
        "state": "closed",
        "user": "mmglove",
        "closed_by": "mmglove",
        "created_at": "2019-09-24T06:08:53+00:00",
        "updated_at": "2019-10-09T03:00:15+00:00",
        "closed_at": "2019-10-09T03:00:15+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3399,
        "title": "develop分支yolov3模型如果内存不足程序退出后，reader不会自己退出，还会占用内存",
        "body": "",
        "state": "open",
        "user": "suoych",
        "closed_by": null,
        "created_at": "2019-09-24T11:56:44+00:00",
        "updated_at": "2019-09-26T04:53:31+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "suoych"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3403,
        "title": "face_detection的速度问题",
        "body": "您好，这边有两个疑问:\r\n一是face_detection的infer只用det0 = detect_face(image, shrink)，fps=5左右，是否可以提高\r\n二是face_detection的infer目前只支持单张图像的infer，是否可以设置batchsize=10这样",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "qingqing01",
        "created_at": "2019-09-25T02:35:43+00:00",
        "updated_at": "2019-12-11T02:58:58+00:00",
        "closed_at": "2019-11-04T03:13:24+00:00",
        "comments_count": [
            "FDInSky",
            "qingqing01",
            "lyw615"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3405,
        "title": "paddle官网给出的deeplabv3+测试总提示越界",
        "body": "想请教下大家，我在github上下载了deeplabv3+的代码，以及最终训练好的模型，也在cityscape下载了数据集，我现在想做的就是能测试就行，但是开始我\r\npython ./eval.py \\\r\n    --init_weights_path=deeplabv3plus_gn \\\r\n    --norm_type=gn \\\r\n    --dataset_path=$DATASET_PATH\r\n打出这个指令提示缺少val.list然后我根据cityscape生成了一个list路径文件，但是在输入这个指令会报数组越界的错误，想知道下是我哪里的操作有问题吗？刚刚接触paddle实在是有点乏力，希望大佬们能来答疑解惑一下",
        "state": "closed",
        "user": "eddieheyutong",
        "closed_by": "eddieheyutong",
        "created_at": "2019-09-25T03:18:31+00:00",
        "updated_at": "2019-10-17T07:07:48+00:00",
        "closed_at": "2019-10-17T07:07:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3417,
        "title": "在train.py中实现的交叉熵损失不下降",
        "body": "您好，我自己再train.py中实现了带有ignore_labels的交叉熵函数，但是训练过程中损失函数不收敛，请问是哪里写的不太对吗？或者是反传需要什么特殊处理？用API的交叉熵是没有问题的。\r\n（其中mask是一个过滤掉label小于-1的位置的模板）\r\ndef cross_entropy_loss(fc, labels_int32, class_num):\r\n    # labels: int32 to int64 and double\r\n    labels_double = fluid.layers.cast(x=labels_int32, dtype='double')\r\n    labels_int64  = fluid.layers.cast(x=labels_int32, dtype='int64')\r\n    # generate mask\r\n    ignore_labels = fluid.layers.fill_constant(shape=[1], value=0, dtype='int64') # mask thres\r\n    mask_bool = fluid.layers.greater_equal(x=labels_int64, y=ignore_labels)\r\n    mask_int = fluid.layers.cast(x=mask_bool, dtype='int64')\r\n    mask_float = fluid.layers.cast(x=mask_bool, dtype='float32')\r\n    # softmax the input fc\r\n    fc_softmax = fluid.layers.softmax(input=fc)\r\n    # change -1 to 1 in label\r\n    labels_double_abs = paddle.fluid.layers.abs(x=labels_double)\r\n    labels_int64_abs = fluid.layers.cast(x=labels_double_abs, dtype='int64')\r\n    labels_int64_abs.stop_gradient=True # must\r\n    # calculate loss\r\n    labels = fluid.layers.one_hot(labels_int64_abs, depth=class_num)\r\n    loss = -1.0 * fluid.layers.log(fc_softmax) * labels\r\n    # mask the loss\r\n    loss = fluid.layers.elementwise_mul(loss, mask_float)\r\n    loss_mean = fluid.layers.reduce_sum(loss)\r\n    return loss_mean",
        "state": "open",
        "user": "SnowWhite11235",
        "closed_by": null,
        "created_at": "2019-09-25T12:11:31+00:00",
        "updated_at": "2019-09-26T10:34:14+00:00",
        "closed_at": null,
        "comments_count": [
            "FDInSky"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3407,
        "title": "list index out of range",
        "body": "在原始代码上，载入自己的训练集，出现如下错误；print（len(b_out)） = 4; 里面是double_buffer_0, mean、accuracy1，accuracy2; 共4项\r\n\r\n这里面也没有loss等参数啊，为何在将其赋值为loss\r\n train_py_reader, train_cost, train_acc1, train_acc5, global_lr = b_out[0],b_out[1],b_out[2],b_out[3],b_out[4]\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 622, in <module>\r\n    main()\r\n  File \"train.py\", line 618, in main\r\n    train(args)\r\n  File \"train.py\", line 379, in train\r\n    train_py_reader, train_cost, train_acc1, train_acc5, global_lr = b_out[0],b_out[1],b_out[2],b_out[3],b_out[4]\r\nIndexError: list index out of range",
        "state": "open",
        "user": "qwertyuiop194",
        "closed_by": null,
        "created_at": "2019-09-25T05:34:32+00:00",
        "updated_at": "2019-10-12T10:51:05+00:00",
        "closed_at": null,
        "comments_count": [
            "eddieheyutong",
            "qwertyuiop194"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3419,
        "title": "PaddleSlim classification pruning问题",
        "body": "如链接所示 https://github.com/PaddlePaddle/models/tree/develop/PaddleSlim/classification/pruning\r\n![image](https://user-images.githubusercontent.com/7035538/65605075-0c609980-dfdb-11e9-8dde-6166adae44e4.png)\r\n然而在Paddle官网上并没有找到1.6版本的Paddle，是不是代表这个功能暂时还用不了。\r\nPaddle1.5.2报错了，还有请问Pruning测试的结果大概什么时候可以公布。\r\n@wanghaoshuang \r\n",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2019-09-25T13:27:41+00:00",
        "updated_at": "2019-09-27T01:48:32+00:00",
        "closed_at": "2019-09-26T11:57:28+00:00",
        "comments_count": [
            "A1exy",
            "ceci3",
            "wanghaoshuang",
            "A1exy",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3427,
        "title": "about the nextvlad input size ",
        "body": "I read the 2d youtube-8m nextvlad tensorflow code: https://github.com/linrongc/youtube-8m/blob/4810b4e7763c9aa2430ee0cc45b86ad72faecc7b/nextvlad.py#L26, the input is such as [1, 300, 1024] which means the [batch, frames, feature_size] I think it only support batch_size: 1. so I want to know. the padlepaddle version suppot other num batch_size ? I mean the input size:https://github.com/PaddlePaddle/models/blob/554d8864eb0ec9416c06357a7bca1789fc750f78/PaddleCV/PaddleVideo/models/nextvlad/nextvlad_model.py#L43",
        "state": "closed",
        "user": "Usernamezhx",
        "closed_by": "Usernamezhx",
        "created_at": "2019-09-26T11:46:44+00:00",
        "updated_at": "2020-04-01T05:31:10+00:00",
        "closed_at": "2019-09-27T03:23:38+00:00",
        "comments_count": [
            "SunGaofeng",
            "Usernamezhx",
            "wanglc2008",
            "ucas010"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3421,
        "title": "训练KT-NET时执行cd reading_comprehension && sh ./run_record_twomemory.sh报错",
        "body": "09/25/2019 14:17:39 - INFO - utils.args - -----------  Configuration Arguments -----------\r\n09/25/2019 14:17:39 - INFO - utils.args - batch_size: 6\r\n09/25/2019 14:17:39 - INFO - utils.args - bert_config_path: cased_L-24_H-1024_A-16/bert_config.json\r\n09/25/2019 14:17:39 - INFO - utils.args - checkpoints: output/\r\n09/25/2019 14:17:39 - INFO - utils.args - concept_embedding_path: ../retrieve_concepts/KB_embeddings/wn_concept2vec.txt\r\n09/25/2019 14:17:39 - INFO - utils.args - dev_retrieved_nell_concept_path: ../retrieve_concepts/retrieve_nell/output_record/dev.retrieved_nell_concepts.data\r\n09/25/2019 14:17:39 - INFO - utils.args - do_lower_case: False\r\n09/25/2019 14:17:39 - INFO - utils.args - do_predict: True\r\n09/25/2019 14:17:39 - INFO - utils.args - do_train: True\r\n09/25/2019 14:17:39 - INFO - utils.args - do_val: False\r\n09/25/2019 14:17:39 - INFO - utils.args - doc_stride: 128\r\n09/25/2019 14:17:39 - INFO - utils.args - ema_decay: 0.9999\r\n09/25/2019 14:17:39 - INFO - utils.args - epoch: 4\r\n09/25/2019 14:17:39 - INFO - utils.args - freeze: False\r\n09/25/2019 14:17:39 - INFO - utils.args - in_tokens: False\r\n09/25/2019 14:17:39 - INFO - utils.args - init_checkpoint: None\r\n09/25/2019 14:17:39 - INFO - utils.args - init_pretraining_params: cased_L-24_H-1024_A-16/params\r\n09/25/2019 14:17:39 - INFO - utils.args - learning_rate: 3e-05\r\n09/25/2019 14:17:39 - INFO - utils.args - loss_scaling: 1.0\r\n09/25/2019 14:17:39 - INFO - utils.args - lr_scheduler: linear_warmup_decay\r\n09/25/2019 14:17:39 - INFO - utils.args - max_answer_length: 30\r\n09/25/2019 14:17:39 - INFO - utils.args - max_query_length: 64\r\n09/25/2019 14:17:39 - INFO - utils.args - max_seq_len: 384\r\n09/25/2019 14:17:39 - INFO - utils.args - n_best_size: 20\r\n09/25/2019 14:17:39 - INFO - utils.args - null_score_diff_threshold: 0.0\r\n09/25/2019 14:17:39 - INFO - utils.args - num_iteration_per_drop_scope: 1\r\n09/25/2019 14:17:39 - INFO - utils.args - predict_file: ../data//ReCoRD/dev.json\r\n09/25/2019 14:17:39 - INFO - utils.args - random_seed: 45\r\n09/25/2019 14:17:39 - INFO - utils.args - retrieved_synset_path: ../retrieve_concepts/retrieve_wordnet/output_record/retrived_synsets.data\r\n09/25/2019 14:17:39 - INFO - utils.args - save_steps: 4000\r\n09/25/2019 14:17:39 - INFO - utils.args - skip_steps: 10\r\n09/25/2019 14:17:39 - INFO - utils.args - train_file: ../data//ReCoRD/train.json\r\n09/25/2019 14:17:39 - INFO - utils.args - train_retrieved_nell_concept_path: ../retrieve_concepts/retrieve_nell/output_record/train.retrieved_nell_concepts.data\r\n09/25/2019 14:17:39 - INFO - utils.args - use_cuda: True\r\n09/25/2019 14:17:39 - INFO - utils.args - use_ema: True\r\n09/25/2019 14:17:39 - INFO - utils.args - use_fast_executor: False\r\n09/25/2019 14:17:39 - INFO - utils.args - use_fp16: False\r\n09/25/2019 14:17:39 - INFO - utils.args - use_nell: False\r\n09/25/2019 14:17:39 - INFO - utils.args - use_wordnet: True\r\n09/25/2019 14:17:39 - INFO - utils.args - validation_steps: 1000\r\n09/25/2019 14:17:39 - INFO - utils.args - verbose: False\r\n09/25/2019 14:17:39 - INFO - utils.args - version_2_with_negative: False\r\n09/25/2019 14:17:39 - INFO - utils.args - vocab_path: cased_L-24_H-1024_A-16/vocab.txt\r\n09/25/2019 14:17:39 - INFO - utils.args - warmup_proportion: 0.1\r\n09/25/2019 14:17:39 - INFO - utils.args - weight_decay: 0.01\r\n09/25/2019 14:17:39 - INFO - utils.args - ------------------------------------------------\r\n09/25/2019 14:17:39 - INFO - model.bert - attention_probs_dropout_prob: 0.1\r\n09/25/2019 14:17:39 - INFO - model.bert - directionality: bidi\r\n09/25/2019 14:17:39 - INFO - model.bert - hidden_act: gelu\r\n09/25/2019 14:17:39 - INFO - model.bert - hidden_dropout_prob: 0.1\r\n09/25/2019 14:17:39 - INFO - model.bert - hidden_size: 1024\r\n09/25/2019 14:17:39 - INFO - model.bert - initializer_range: 0.02\r\n09/25/2019 14:17:39 - INFO - model.bert - intermediate_size: 4096\r\n09/25/2019 14:17:39 - INFO - model.bert - max_position_embeddings: 512\r\n09/25/2019 14:17:39 - INFO - model.bert - num_attention_heads: 16\r\n09/25/2019 14:17:39 - INFO - model.bert - num_hidden_layers: 24\r\n09/25/2019 14:17:39 - INFO - model.bert - pooler_fc_size: 768\r\n09/25/2019 14:17:39 - INFO - model.bert - pooler_num_attention_heads: 12\r\n09/25/2019 14:17:39 - INFO - model.bert - pooler_num_fc_layers: 3\r\n09/25/2019 14:17:39 - INFO - model.bert - pooler_size_per_head: 128\r\n09/25/2019 14:17:39 - INFO - model.bert - pooler_type: first_token_transform\r\n09/25/2019 14:17:39 - INFO - model.bert - type_vocab_size: 2\r\n09/25/2019 14:17:39 - INFO - model.bert - vocab_size: 28996\r\n09/25/2019 14:17:39 - INFO - model.bert - ------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"src/run_record.py\", line 594, in <module>\r\n    train(args)\r\n  File \"src/run_record.py\", line 332, in train\r\n    max_query_length=args.max_query_length)\r\n  File \"/home/KTNET/ACL2019-KTNET/reading_comprehension/src/reader/record.py\", line 538, in __init__\r\n    vocab_file=vocab_path, do_lower_case=do_lower_case)\r\n  File \"/home/KTNET/ACL2019-KTNET/reading_comprehension/src/tokenization.py\", line 113, in __init__\r\n    self.vocab = load_vocab(vocab_file)\r\n  File \"/home/KTNET/ACL2019-KTNET/reading_comprehension/src/tokenization.py\", line 73, in load_vocab\r\n    for num, line in enumerate(fin):\r\n  File \"/usr/lib/python3.5/encodings/ascii.py\", line 26, in decode\r\n    return codecs.ascii_decode(input, self.errors)[0]\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xc2 in position 1323: ordinal not in range(128)",
        "state": "open",
        "user": "Soulmate303",
        "closed_by": null,
        "created_at": "2019-09-26T03:19:23+00:00",
        "updated_at": "2019-10-07T09:30:34+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "Soulmate303",
            "Soulmate303",
            "yangapku"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3424,
        "title": "transformer为什么要加attention的bias？",
        "body": "transfomer的模型代码里self-attention里点击的时候加了一个attention的bias。\r\n![image](https://user-images.githubusercontent.com/2673581/65668437-4f228000-e074-11e9-900b-a6e63812203c.png)\r\n但是没有看到更新这个bias的地方。\r\n\r\n请问加这个bias的目的是什么？",
        "state": "open",
        "user": "littleKaa",
        "closed_by": null,
        "created_at": "2019-09-26T07:44:10+00:00",
        "updated_at": "2019-10-07T16:43:37+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "littleKaa"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3428,
        "title": "预测库infer的结果和正常infer结果不同",
        "body": "我根据 https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_usage/deploy/inference/python_infer_cn.html 进行YOLOv3的服务部署。\r\nmodel是用https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/yolov3/infer.py 保存的\r\n结果不同！！！\r\n```\r\n# -*- coding: utf-8 -*-\r\nimport argparse\r\nimport numpy as np\r\n\r\nfrom paddle.fluid.core import PaddleBuf\r\nfrom paddle.fluid.core import PaddleDType\r\nfrom paddle.fluid.core import PaddleTensor\r\nfrom paddle.fluid.core import AnalysisConfig\r\nfrom paddle.fluid.core import create_paddle_predictor\r\nimport cv2\r\n\r\ndef main():\r\n    args = parse_args()\r\n\r\n    # Set config\r\n    config = AnalysisConfig(args.model_dir)\r\n    # config.disable_gpu()\r\n\r\n    # Create PaddlePredictor\r\n    predictor = create_paddle_predictor(config)\r\n\r\n    # Set inputs\r\n    inputs = fake_input(args.batch_size)\r\n    # img = cv2.imread('test.jpg')\r\n    # img = img_reader1(img, 608)\r\n    # inputs={'image':img}\r\n    # Infer\r\n    outputs = predictor.run(inputs)\r\n\r\n    # parse outputs\r\n    output = outputs[0]\r\n    print(output.name)\r\n    output_data = output.data.float_data()\r\n    print(len(output_data))\r\n    b=np.array(output_data)\r\n    b=b.reshape([-1,6])\r\n    print(b)\r\n    # bboxes = np.array(outputs[0])\r\n    # print(bboxes)\r\n    # assert len(output_data) == 512 * args.batch_size\r\n    # for i in range(args.batch_size):\r\n    #     print(np.argmax(output_data[i * 512:(i + 1) * 512]))\r\n\r\ndef fake_input(batch_size):\r\n    image = PaddleTensor()\r\n    image.name = \"image\"\r\n\r\n\r\n    image.dtype = PaddleDType.FLOAT32\r\n    # image.data = PaddleBuf(\r\n    #     np.random.randn(*image.shape).flatten().astype(\"float32\").tolist())\r\n    img = cv2.imread('test.jpg')\r\n    h, w, _ = img.shape\r\n    input_size=608\r\n    image.shape = [batch_size, 3, input_size, input_size]\r\n    # pixel mean values\r\n    pixel_means = [0.485, 0.456, 0.406]\r\n    # pixel std values\r\n    pixel_stds = [0.229, 0.224, 0.225]\r\n    img=img_reader1(img,input_size,pixel_means,pixel_stds)\r\n    img=img.reshape(image.shape)\r\n    image.data=PaddleBuf(img.flatten().astype(\"float32\").tolist())\r\n    im_shape= PaddleTensor()\r\n    im_shape.name=\"im_shape\"\r\n    im_shape.dtype=PaddleDType.INT32\r\n    im_shape.shape = [batch_size,2]\r\n    im_shape.data=PaddleBuf(\r\n        np.array([h,w]).flatten().astype(\"int32\").tolist())\r\n    return [image,im_shape]\r\n\r\ndef img_reader1(im, size, mean, std):\r\n    h, w, _ = im.shape\r\n    im_scale_x = size / float(w)\r\n    im_scale_y = size / float(h)\r\n    out_img = cv2.resize(im, None, None,\r\n                         fx=im_scale_x, fy=im_scale_y,\r\n                         interpolation=cv2.INTER_CUBIC)\r\n    mean = np.array(mean).reshape((1, 1, -1))\r\n    std = np.array(std).reshape((1, 1, -1))\r\n    out_img = (out_img / 255.0 - mean) / std\r\n    out_img = out_img.transpose((2, 0, 1))\r\n    return out_img\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--model_dir\", type=str, help=\"model dir\")\r\n    parser.add_argument(\"--prog_file\", type=str, help=\"program filename\")\r\n    parser.add_argument(\"--params_file\", type=str, help=\"parameter filename\")\r\n    parser.add_argument(\"--batch_size\", type=int, default=1, help=\"batch size\")\r\n\r\n    return parser.parse_args()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```",
        "state": "closed",
        "user": "mozpp",
        "closed_by": "zhaoyuchen2018",
        "created_at": "2019-09-27T03:13:25+00:00",
        "updated_at": "2019-10-10T10:37:29+00:00",
        "closed_at": "2019-09-30T03:26:47+00:00",
        "comments_count": [
            "mozpp",
            "mozpp",
            "heavengate",
            "heavengate",
            "mozpp"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3430,
        "title": "关于pyramidbox中的感受野",
        "body": "您好！\r\n在PyramidBox中，为了避免过大感受野带来的影响，在特征融合时，并没有融合高层的特征．\r\n但是在CPM模块，又使用了3*3的conv，这又会增大感受野．\r\n感觉有点矛盾．\r\n\r\n麻烦了！",
        "state": "closed",
        "user": "foralliance",
        "closed_by": "zhaoyuchen2018",
        "created_at": "2019-09-27T05:14:09+00:00",
        "updated_at": "2020-05-25T10:01:28+00:00",
        "closed_at": "2019-12-06T08:59:15+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "tangxuvis",
            "tangxuvis",
            "924175302",
            "924175302"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3431,
        "title": "transformer模型预测时怎么使用PaddlePredictor？",
        "body": "模型已经训练完成并保存为inference model，现在需要进行预测。\r\n预测方法为：\r\ndef prediction(predictor, predict_data_generator):\r\n    for sample in predict_data_generator():\r\n        max_seq_len = sample[0].shape[1]\r\n        src_word = fake_input(sample[0], PaddleDType.INT64)\r\n        src_pos = fake_input(sample[1], PaddleDType.INT64)\r\n        src_slf_attn_bias = fake_input(sample[2], PaddleDType.FLOAT32)\r\n        trg_word = fake_input(sample[3], PaddleDType.INT64)\r\n        init_score = fake_input(sample[4], PaddleDType.FLOAT32)\r\n        init_idx = fake_input(sample[5], PaddleDType.INT32)\r\n        trg_src_attn_bias = fake_input(sample[6], PaddleDType.FLOAT32)\r\n        seq_ids, seq_scores = predictor.run([\r\n            src_word,\r\n            src_pos,\r\n            src_slf_attn_bias,\r\n            trg_word,\r\n            init_score,\r\n            init_idx,\r\n            trg_src_attn_bias])\r\n        return seq_ids, seq_scores\r\ndef fake_input(ids, dtype):\r\n    data = PaddleTensor()\r\n    data.name = \"data\"\r\n    data.shape = list(ids.shape)\r\n    data.dtype = dtype\r\n    data.data = PaddleBuf(ids.flatten().tolist())\r\n    return data\r\n但是sample[3]和sample[4]为lod_tensor没办法用fake_input方法进行转换，那对于lod_tensor应该怎么办呢？",
        "state": "closed",
        "user": "tianjie491",
        "closed_by": "zhaoyuchen2018",
        "created_at": "2019-09-27T06:04:49+00:00",
        "updated_at": "2019-10-14T02:33:46+00:00",
        "closed_at": "2019-10-14T02:33:46+00:00",
        "comments_count": [
            "tianjie491",
            "zhaoyuchen2018",
            "tianjie491",
            "tianjie491",
            "zhaoyuchen2018",
            "tianjie491",
            "zhaoyuchen2018"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3455,
        "title": "异步读取问题",
        "body": "你好，我需要封一个ernie的分词接口，提供给别人使用\r\n在用PaddleNLP/lexical_analysis/run_ernie_sequence_labeling.py时，发现采用的是一个异步读文件的方式进行预测\r\n首先，对为什么采用异步读文件的方式感到奇怪，也不太理解\r\n其次，对如何改为接口传参的方式，反复调用，感到无从下手\r\n\r\n求指导\r\n\r\n附，部分代码理解如下，如不正确，请指正，非常感谢\r\n\r\n```\r\n    #这部分，我已经重新封了一个类，完成了[string] -> reader.data_generator\r\n    #reader = task_reader.SequenceLabelReader(\r\n    reader=ListReader(\r\n            vocab_path=args.vocab_path,\r\n        label_map_config=args.label_map_config,\r\n        max_seq_len=args.max_seq_len,\r\n        do_lower_case=args.do_lower_case,\r\n        in_tokens=False,\r\n        random_seed=args.random_seed)\r\n   \r\n    lines = read_file(args.infer_set) # 读文件返回[\"a b c\"]\r\n　。。。\r\n    with 。。。\r\n         with 。。。\r\n              # 这里提供lines\r\n              infer_pyreader.decorate_tensor_provider(\r\n                reader.data_generator(\r\n                    lines, args.batch_size, phase='infer', epoch=1, shuffle=False\r\n                )\r\n            )\r\n\r\n     ...\r\n     infer_pyreader.start()\r\n\r\n    while True:\r\n        try:\r\n            # 问题是，这里没办法在lines里数据变化时，反复地给出预测结果\r\n            (words, crf_decode) = exe.run(infer_program,\r\n                                          fetch_list=[infer_ret[\"words\"], infer_ret[\"crf_decode\"]],\r\n                                          return_numpy=False)\r\n            # User should notice that words had been clipped if long than args.max_seq_len\r\n            results = utils.parse_result(words, crf_decode, dataset)\r\n            for result in results:\r\n                print(type(result), result)\r\n        except fluid.core.EOFException:\r\n            infer_pyreader.reset()\r\n            break\r\n\r\n```\r\n\r\nListReader代码如下\r\n```\r\nclass ListReader(task_reader.SequenceLabelReader):\r\n    def _read_tsv(self, list_input, quotechar=None):\r\n        res = list_input\r\n        Example = namedtuple('LR', \"text_a\")\r\n        exam = []\r\n        for l in res:\r\n            l = l.strip()\r\n            #l = l.decode(\"utf-8\")\r\n            example = Example(l)\r\n            exam.append(example)\r\n        return exam\r\n\r\n    def _reseg_token_label(self, tokens, tokenizer):\r\n        ret_tokens = []\r\n        ret_labels = []\r\n        for token in tokens:\r\n            sub_token = tokenizer.tokenize(token)\r\n            if len(sub_token) == 0:\r\n                continue\r\n            ret_tokens.extend(sub_token)\r\n        ret_labels = ['t']*len(ret_tokens)\r\n        assert len(ret_tokens) == len(ret_labels)\r\n        return ret_tokens, ret_labels\r\n\r\n    def _convert_example_to_record(self, example, max_seq_length, tokenizer):\r\n      \r\n        tokens = tokenization.convert_to_unicode(example.text_a).split(u\"\u0002\")\r\n        tokens, labels = self._reseg_token_label(tokens, tokenizer)\r\n\r\n        if len(tokens) > max_seq_length - 2:\r\n            tokens = tokens[0:(max_seq_length - 2)]\r\n            labels = labels[0:(max_seq_length - 2)]\r\n\r\n        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\r\n        # tokens to ids\r\n        token_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n        position_ids = list(range(len(token_ids)))\r\n        text_type_ids = [0] * len(token_ids)\r\n        no_entity_id = len(self.label_map) - 1\r\n        labels = [label if label in self.label_map else u\"O\" for label in labels]\r\n        label_ids = [no_entity_id] + [\r\n            self.label_map[label] for label in labels\r\n        ] + [no_entity_id]\r\n\r\n        Record = namedtuple(\r\n            'Record',\r\n            ['token_ids', 'text_type_ids', 'position_ids', 'label_ids'])\r\n        record = Record(\r\n            token_ids=token_ids,\r\n            text_type_ids=text_type_ids,\r\n            position_ids=position_ids,\r\n            label_ids=label_ids)\r\n        return record\r\n\r\n```\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "chuj625",
        "closed_by": null,
        "created_at": "2019-09-29T09:32:15+00:00",
        "updated_at": "2019-10-12T08:02:44+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3439,
        "title": "如何实现Wide&Deep中，用FTRL优化wide, 用Adam优化Deep",
        "body": "经典的wide & deep中，需要使用到两个optimizer，用FTRL优化wide, 用Adam优化Deep。\r\n\r\nTensorFlow中用是用tf.group，将两个optimize ops合并成一个。\r\n\r\n在PaddlePaddle中，如何实现在一个program中使用两个optimizer?",
        "state": "closed",
        "user": "stasi009",
        "closed_by": "zhaoyuchen2018",
        "created_at": "2019-09-27T12:13:03+00:00",
        "updated_at": "2019-10-14T02:31:55+00:00",
        "closed_at": "2019-10-14T02:31:55+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "stasi009"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3441,
        "title": "优雅的重置auc",
        "body": "\r\n几乎所有的有关分类的代码，都有如下重置auc的代码\r\nauc_states_names = ['_generated_var_0','_generated_var_1','_generated_var_2', '_generated_var_3']\r\n                for name in auc_states_names:\r\n                    set_zero(name)\r\n\r\n\r\n我实在搞不清楚，难道无论谁写的paddle程序，auc的变量都叫那几个名字？？？\r\n\r\n一看那些variable的名字，就是paddle自动生成的。\r\n\r\n那么，我自己写的代码，如果要重置auc，应该使用哪些变量名？我怎么才能知道，我应该用哪些变量名？？\r\n\r\n\r\n",
        "state": "closed",
        "user": "stasi009",
        "closed_by": "wilhelmzh",
        "created_at": "2019-09-27T13:00:03+00:00",
        "updated_at": "2019-12-22T15:19:56+00:00",
        "closed_at": "2019-12-22T15:19:56+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "wilhelmzh",
            "stasi009"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3462,
        "title": "develop版paddle的yolov3训练无法收敛",
        "body": "develop版本的paddle（https://paddle-wheel.bj.bcebos.com/latest-gpu-cuda10-cudnn7-mkl/paddlepaddle_gpu-latest-cp27-cp27mu-linux_x86_64.whl ），yolov3(https://github.com/PaddlePaddle/models/tree/release/1.5/PaddleCV/yolov3 )训练无法收敛。\r\n换回1.5版本，可以收敛。\r\n很诡异的bug。",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-09-30T06:02:54+00:00",
        "updated_at": "2019-10-12T10:42:30+00:00",
        "closed_at": null,
        "comments_count": [
            "Shixiaowei02",
            "mozpp",
            "linghaolu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3451,
        "title": "paddleDetection中SSD的mean和std不一致情况",
        "body": "在使用PaddleDetection配置ssd mean和std参数时，发现和以前的ssd库的参数不同，而且查了一下PaddleDetection ssd的几个示例配置文件，也不太一样。请问是哪一个是标准的训练参数？这些不同设置有何影响？\r\n\r\n**以前的ssd:**\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/ssd/reader.py\r\n   **mean_value=[127.5, 127.5, 127.5],\r\n   std=0.007843**\r\n\r\n**PaddleDetection** :\r\nssd_vgg16_512.yml\r\n![image](https://user-images.githubusercontent.com/20673237/65827960-4b873700-e2c8-11e9-9475-077d2f625072.png)\r\n\r\nssd_vgg16_512_voc.yml\r\n![image](https://user-images.githubusercontent.com/20673237/65827979-6eb1e680-e2c8-11e9-8169-8e166d598079.png)\r\n\r\n而mobilenet_ssd_v1_voc.yml中使用默认参数\r\n![image](https://user-images.githubusercontent.com/20673237/65827989-796c7b80-e2c8-11e9-8aa6-e9349392e0a7.png)\r\n\r\nDecodeImage中都设置了to_rgb=True，所以都应该转为 rgb格式了。",
        "state": "closed",
        "user": "ellinyang",
        "closed_by": "qingqing01",
        "created_at": "2019-09-29T06:49:32+00:00",
        "updated_at": "2019-10-13T04:53:12+00:00",
        "closed_at": "2019-10-13T04:53:12+00:00",
        "comments_count": [
            "yghstill",
            "ellinyang",
            "yghstill",
            "ellinyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3469,
        "title": "PaddleDetection保存预测模型报错",
        "body": "git clone PaddlePaddle/models 的develop分支，在本机上能够将实现图片预测，但是保存预测模型准备进行生产环境部署测试是，保存预测模型错误。步骤如下：\r\n\r\n1、在PaddleDetection下执行python tools/infer.py -c configs/mask_rcnn_r50_1x.yml \\\r\n    -o weights=https://paddlemodels.bj.bcebos.com/object_detection/mask_rcnn_r50_1x.tar \\\r\n    --infer_img=demo/000000570688.jpg，能够看到预测的图片上已经识别物体打上标记框\r\n\r\n2、执行python tools/infer.py -c configs/mask_rcnn_r50_1x.yml --infer_img=demo/000000570688.jpg --save_inference_model ，增加了--save_inference_model参数进行预测模型导出，提示错误如下：\r\n\r\n2019-10-03 10:17:20,007-INFO: Loading parameters from output/mask_rcnn_r50_1x/model_final...\r\nTraceback (most recent call last):\r\n  File \"tools/infer.py\", line 317, in <module>\r\n    main()\r\n  File \"tools/infer.py\", line 184, in main\r\n    save_infer_model(FLAGS, exe, feed_vars, test_fetches, infer_prog)\r\n  File \"tools/infer.py\", line 128, in save_infer_model\r\n    infer_prog)\r\n  File \"tools/infer.py\", line 109, in prune_feed_vars\r\n    prog = prog._prune(feeded_var_names, targets=target_vars)\r\nTypeError: _prune() got multiple values for argument 'targets'\r\n\r\n",
        "state": "closed",
        "user": "zhangzhiyong",
        "closed_by": "MRXLT",
        "created_at": "2019-10-03T02:18:00+00:00",
        "updated_at": "2019-10-08T06:51:40+00:00",
        "closed_at": "2019-10-08T06:51:40+00:00",
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3481,
        "title": "LAC module 在 Hub 下可以被找到，但无法运行",
        "body": "问题如下，可以引入 Hub，也能找到 LAC module，但无法使用。\r\n\r\n![Screen Shot 2019-10-08 at 3 07 05 PM](https://user-images.githubusercontent.com/5635322/66437035-92b6ab80-e9dd-11e9-8027-8cfc58b93a07.png)\r\n",
        "state": "open",
        "user": "daming-lu",
        "closed_by": null,
        "created_at": "2019-10-08T22:09:10+00:00",
        "updated_at": "2019-10-12T10:52:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3470,
        "title": "models/PaddleNLP/emotion_detection/",
        "body": "我看给的对话情绪识别下面有二级标签，类似生气、开心等，我看训练数据只有正向负向和中性？",
        "state": "open",
        "user": "sjm1992st",
        "closed_by": null,
        "created_at": "2019-10-07T02:57:38+00:00",
        "updated_at": "2019-10-12T03:26:28+00:00",
        "closed_at": null,
        "comments_count": [
            "wangchaochaohu",
            "sjm1992st",
            "wangchaochaohu",
            "sjm1992st",
            "wangchaochaohu",
            "sjm1992st",
            "wangchaochaohu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3474,
        "title": "paddleSlim量化shufflenet模型后finetune loss为nan",
        "body": "采用cpu版本的paddlepaddle，Python3.6.4\r\n采用paddleslim量化shufflenet时，可以进行eval操作，量化后finetune损失为nan\r\n减小学习率和bachsize没有效果\r\n希望有大神能给解决\r\n![CCD9491DD7F5155764FA72A0DAFE0A4C](https://user-images.githubusercontent.com/35206066/66375615-63ee0480-e9e0-11e9-8650-7de88b28dd61.JPG)\r\n",
        "state": "closed",
        "user": "Verazjy",
        "closed_by": "Verazjy",
        "created_at": "2019-10-08T07:29:38+00:00",
        "updated_at": "2019-10-15T07:56:36+00:00",
        "closed_at": "2019-10-15T07:56:36+00:00",
        "comments_count": [
            "Verazjy",
            "baiyfbupt",
            "Verazjy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3492,
        "title": "从输入图片或某个feature map中抠出一块来,应该如何操作?",
        "body": "paddle中抠图有专门的crop函数吗?如果想抠一块矩形出来, 可否像python数组的切片操作那样,通过指定数组下标范围来简单抠出来.",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-10-10T08:14:40+00:00",
        "updated_at": "2019-10-12T10:49:47+00:00",
        "closed_at": null,
        "comments_count": [
            "xyoungli",
            "wenston2006",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3489,
        "title": "PaddleDetection load params failed",
        "body": "config file: yolov3_mobilenet_v1_voc.yml\r\n\r\ncode:\r\n```\r\ndef main():\r\n    cfg = load_config(FLAGS.config)\r\n    if 'architecture' in cfg:\r\n        main_arch = cfg.architecture\r\n    else:\r\n        raise ValueError(\"'architecture' not specified in config file.\")\r\n\r\n    merge_config(FLAGS.opt)\r\n    if 'log_iter' not in cfg:\r\n        cfg.log_iter = 20\r\n\r\n    # check if set use_gpu=True in paddlepaddle cpu version\r\n    check_gpu(cfg.use_gpu)\r\n\r\n    if cfg.use_gpu:\r\n        devices_num = fluid.core.get_cuda_device_count()\r\n    else:\r\n        devices_num = int(\r\n            os.environ.get('CPU_NUM', multiprocessing.cpu_count()))\r\n\r\n    if 'train_feed' not in cfg:\r\n        train_feed = create(main_arch + 'TrainFeed')\r\n    else:\r\n        train_feed = create(cfg.train_feed)\r\n\r\n    if 'eval_feed' not in cfg:\r\n        eval_feed = create(main_arch + 'EvalFeed')\r\n    else:\r\n        eval_feed = create(cfg.eval_feed)\r\n\r\n    place = fluid.CUDAPlace(0) if cfg.use_gpu else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n    lr_builder = create('LearningRate')\r\n    optim_builder = create('OptimizerBuilder')\r\n\r\n    # build program\r\n    startup_prog = fluid.Program()\r\n    train_prog = fluid.Program()\r\n    with fluid.program_guard(train_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            model = create(main_arch)\r\n            train_pyreader, feed_vars = create_feed(train_feed)\r\n            train_fetches = model.train(feed_vars)\r\n            loss = train_fetches['loss']\r\n            lr = lr_builder()\r\n            optimizer = optim_builder(lr)\r\n            optimizer.minimize(loss)\r\n\r\n#    graph = IrGraph(core.Graph(train_prog.desc), for_test=True)\r\n#    marked_nodes = set()\r\n#    for op in graph.all_op_nodes():\r\n#        print(op.name())\r\n#        if op.name().find('conv') > -1:\r\n#            marked_nodes.add(op)\r\n#    graph.draw('.', 'forward', marked_nodes)\r\n#\r\n#    return\r\n\r\n    train_reader = create_reader(train_feed, cfg.max_iters * devices_num,\r\n                                 FLAGS.dataset_dir)\r\n    train_pyreader.decorate_sample_list_generator(train_reader, place)\r\n\r\n    # parse train fetches\r\n    train_keys, train_values, _ = parse_fetches(train_fetches)\r\n    train_values.append(lr)\r\n\r\n    train_fetch_list=[]\r\n    for k, v in zip(train_keys, train_values):\r\n        train_fetch_list.append((k, v))\r\n    print(\"train_fetch_list: {}\".format(train_fetch_list))\r\n\r\n    eval_prog = fluid.Program()\r\n    with fluid.program_guard(eval_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            model = create(main_arch)\r\n            eval_pyreader, feed_vars = create_feed(eval_feed)\r\n            fetches = model.eval(feed_vars)\r\n    eval_prog = eval_prog.clone(True)\r\n\r\n    eval_reader = create_reader(eval_feed, args_path=FLAGS.dataset_dir)\r\n    eval_pyreader.decorate_sample_list_generator(eval_reader, place)\r\n\r\n    # parse eval fetches\r\n    extra_keys = []\r\n    if cfg.metric == 'COCO':\r\n        extra_keys = ['im_info', 'im_id', 'im_shape']\r\n    if cfg.metric == 'VOC':\r\n        extra_keys = ['gt_box', 'gt_label', 'is_difficult']\r\n    eval_keys, eval_values, eval_cls = parse_fetches(fetches, eval_prog,\r\n                                                         extra_keys)\r\n\r\n    eval_fetch_list=[]\r\n    for k, v in zip(eval_keys, eval_values):\r\n        eval_fetch_list.append((k, v))\r\n\r\n\r\n    exe.run(startup_prog)\r\n\r\n    start_iter = 0\r\n\r\n\r\n    checkpoint.load_params(exe, train_prog, cfg.pretrain_weights, ignore_params=[])\r\n```\r\n\r\nmodels commit:\r\n```\r\ncommit b860c3baf7fadad705ff94bff0f058e4ebaf9680\r\n```\r\n\r\n\r\nerror log:\r\n```\r\n2019-10-10 02:59:24,844-INFO: Decompressing /root/.cache/paddle/weights/MobileNetV1_pretrained.tar...\r\nTraceback (most recent call last):\r\n  File \"compress.py\", line 231, in <module>\r\n    main()\r\n  File \"compress.py\", line 160, in main\r\n    checkpoint.load_params(exe, train_prog, cfg.pretrain_weights, ignore_params=[])\r\n  File \"/root/models/PaddleCV/PaddleDetection/ppdet/utils/checkpoint.py\", line 92, in load_params\r\n    path = _get_weight_path(path)\r\n  File \"/root/models/PaddleCV/PaddleDetection/ppdet/utils/checkpoint.py\", line 77, in _get_weight_path\r\n    path = get_weights_path(path)\r\n  File \"/root/models/PaddleCV/PaddleDetection/ppdet/utils/download.py\", line 72, in get_weights_path\r\n    return get_path(url, WEIGHTS_HOME)\r\n  File \"/root/models/PaddleCV/PaddleDetection/ppdet/utils/download.py\", line 171, in get_path\r\n    _decompress(fullname)\r\n  File \"/root/models/PaddleCV/PaddleDetection/ppdet/utils/download.py\", line 287, in _decompress\r\n    tf.extractall(path=fpath_tmp)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 2081, in extractall\r\n    self.extract(tarinfo, path)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 2118, in extract\r\n    self._extract_member(tarinfo, os.path.join(path, tarinfo.name))\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 2194, in _extract_member\r\n    self.makefile(tarinfo, targetpath)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 2235, in makefile\r\n    copyfileobj(source, target)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 266, in copyfileobj\r\n    shutil.copyfileobj(src, dst)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/shutil.py\", line 63, in copyfileobj\r\n    buf = fsrc.read(length)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 831, in read\r\n    buf += self.fileobj.read(size - len(buf))\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 743, in read\r\n    return self.readnormal(size)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 758, in readnormal\r\n    return self.__read(size)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/tarfile.py\", line 750, in __read\r\n    raise ReadError(\"unexpected end of data\")\r\ntarfile.ReadError: unexpected end of data\r\n```\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-10-10T03:06:18+00:00",
        "updated_at": "2019-10-10T03:21:14+00:00",
        "closed_at": "2019-10-10T03:21:13+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3493,
        "title": "网络的loss由两个loss构成, 在做backward()运算时应该对两个loss分别执行backward()运算吗?",
        "body": "还是新定义一个loss变量, total_loss=loss1 + loss2,  然后执行total_loss.backward()?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-10-10T09:14:02+00:00",
        "updated_at": "2019-10-12T10:49:27+00:00",
        "closed_at": null,
        "comments_count": [
            "xyoungli",
            "wenston2006",
            "wenston2006",
            "xyoungli",
            "wenston2006",
            "xyoungli",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3504,
        "title": "请问在哪里找官方的分类网络预训练模型？",
        "body": "请问在哪里找官方的分类网络预训练模型？",
        "state": "open",
        "user": "Stealers",
        "closed_by": null,
        "created_at": "2019-10-11T00:33:47+00:00",
        "updated_at": "2019-10-12T02:55:17+00:00",
        "closed_at": null,
        "comments_count": [
            "yongqiangma"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3506,
        "title": "PaddlePaddle/Paddle transformer c++版本预测 加载两次模型输出不一致",
        "body": "服务使用用stream做加速，有两个predictor，在输入tensor一样的情况下，输出不一致，这是什么原因呢？\r\n![image](https://user-images.githubusercontent.com/5461637/66623274-7a34d400-ec1d-11e9-81d7-88a504061ba9.png)\r\n",
        "state": "open",
        "user": "yxzero",
        "closed_by": null,
        "created_at": "2019-10-11T03:52:29+00:00",
        "updated_at": "2019-10-18T05:56:37+00:00",
        "closed_at": null,
        "comments_count": [
            "chalsliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3511,
        "title": " labelme2coco.py将labelme转换为coco数据集问题",
        "body": "Generating dataset from: /Users/shuxsu/Downloads/cityscape/gtFine_trainvaltest/gtFine/train/ccc/.json\r\nTraceback (most recent call last):\r\n  File \"labelme2coco.py\", line 246, in <module>\r\n    main()\r\n  File \"labelme2coco.py\", line 223, in main\r\n    args.json_input_dir)\r\n  File \"labelme2coco.py\", line 117, in deal_json\r\n    with open(label_file) as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/shuxsu/Downloads/cityscape/gtFine_trainvaltest/gtFine/train/ccc/.json'\r\n会正常运行几个之后就会出现这样的错误，数据集使用为cityscape数据集，但是数据集本身无imagePath属性，为自己添加。错误提示就是这个，检查了每一个json文件，确认格式以及imagePath均正确",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "yongqiangma",
        "created_at": "2019-10-11T06:38:19+00:00",
        "updated_at": "2019-10-12T02:32:35+00:00",
        "closed_at": "2019-10-12T02:32:35+00:00",
        "comments_count": [
            "SunAhong1993",
            "shuxsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3516,
        "title": "PaddleDetection库使用体验",
        "body": "用PaddleDetection训练自己的数据的时候发现PaddleDetection有点封装得过头了，不管是设计自己的模型还是改datalayer层 或者数据格式，整体上入口要么太深，就是入口不明显 config的设置也过于复杂，这块体验不是特别好，希望PaddlePaddle这块可以尽可能的优化下。谢谢！",
        "state": "open",
        "user": "fuyi02",
        "closed_by": null,
        "created_at": "2019-10-11T10:00:42+00:00",
        "updated_at": "2019-10-12T02:30:49+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3512,
        "title": "PaddleDetection训练自己的数据集问题",
        "body": "要训练的数据集放在项目下的dataset/coco下，指定训练集路径后会下载coco的train2017不知为何原因，后看终端提示try searching /Users/shuxsu/.cache/paddle/dataset or downloading dataset...，将数据集拷贝至/Users/shuxsu/.cache/paddle/dataset/coco下 再次运行不再下载，并且终端提示 found annotations/instance_train.json 等。后控制台报错：\r\n2019-10-11 12:58:43,488-WARNING: fail to map op [DecodeImage_348189] with error: [Errno 21] Is a directory: '/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/dataset/coco/train2017/' and stack:\r\nTraceback (most recent call last):\r\n  File \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/transform/__init__.py\", line 77, in _mapper\r\n    out = f(sample, ctx)\r\n  File \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/transform/operators.py\", line 99, in __call__\r\n    with open(sample['im_file'], 'rb') as f:\r\nIsADirectoryError: [Errno 21] Is a directory: '/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/dataset/coco/train2017/'\r\n\r\n2019-10-11 12:58:43,488-WARNING: consumer failed with error: failed to map consumer[%s], error: [Errno 21] Is a directory: '/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/dataset/coco/train2017/'\r\n2019-10-11 12:58:43,488-WARNING: fail to map op [DecodeImage_348189] with error: [Errno 21] Is a directory: '/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/dataset/coco/train2017/' and stack:\r\nTraceback (most recent call last):\r\n  File \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/transform/__init__.py\", line 77, in _mapper\r\n    out = f(sample, ctx)\r\n  File \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/transform/operators.py\", line 99, in __call__\r\n    with open(sample['im_file'], 'rb') as f:\r\nIsADirectoryError: [Errno 21] Is a directory: '/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/dataset/coco/train2017/'\r\n想知道是不是和我的json文件中的file_name都为空字符串有关系",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "heavengate",
        "created_at": "2019-10-11T06:45:35+00:00",
        "updated_at": "2019-10-13T04:23:28+00:00",
        "closed_at": "2019-10-13T04:23:28+00:00",
        "comments_count": [
            "heavengate",
            "shuxsu",
            "shuxsu",
            "shuxsu",
            "shuxsu",
            "heavengate",
            "shuxsu",
            "SunAhong1993",
            "heavengate",
            "SunAhong1993",
            "shuxsu",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3520,
        "title": "paddleDection数据集路径以及配置问题",
        "body": "2019-10-11 21:12:13,636-INFO: Found /Users/shuxsu/.cache/paddle/dataset/coco/train2017\r\n2019-10-11 21:12:13,636-INFO: Found /Users/shuxsu/.cache/paddle/dataset/coco/val2017\r\n2019-10-11 21:12:13,636-INFO: Found /Users/shuxsu/.cache/paddle/dataset/coco/annotations\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 284, in \r\nmain()\r\nFile \"train.py\", line 165, in main\r\ndevices_num, FLAGS.dataset_dir)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/data_feed.py\", line 139, in create_reader\r\nmy_source)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/reader.py\", line 135, in create\r\nreturn reader._make_reader(mode, my_source)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/reader.py\", line 51, in _make_reader\r\nsc = build_source(sc_conf)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/source/init.py\", line 61, in build_source\r\nreturn RoiDbSource(**args)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/data/source/roidb_source.py\", line 63, in init\r\nanno_file), 'invalid file[%s] for RoiDbSource' % (anno_file)\r\nAssertionError: invalid file[/Users/shuxsu/.cache/paddle/dataset/coco/annotations/instances_train.json] for RoiDbSource\r\n数据集是通过项目提供的labelme2coco.py将 labelme数据集转换的coco数据集  ",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "qingqing01",
        "created_at": "2019-10-12T04:12:26+00:00",
        "updated_at": "2019-10-26T12:18:32+00:00",
        "closed_at": "2019-10-26T12:18:32+00:00",
        "comments_count": [
            "SunAhong1993"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3521,
        "title": "paddleDection operators注释有问题？",
        "body": "![image](https://user-images.githubusercontent.com/46473363/66695946-d53bf900-ecf9-11e9-93d5-844e0e40aa50.png)\r\n\r\nHi 同学，\r\n\r\n       我在使用PaddleCV/PaddleDetection时候，注意到了ExpandImage如截图红框这边的注释，请问是想要表述为“Scale the image width and height”的意思吗？还是我理解有误？\r\n\r\n多谢啦",
        "state": "closed",
        "user": "ronghaoLee",
        "closed_by": "heavengate",
        "created_at": "2019-10-12T06:11:20+00:00",
        "updated_at": "2019-10-12T09:01:21+00:00",
        "closed_at": "2019-10-12T09:01:21+00:00",
        "comments_count": [
            "MyPandaShaoxiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3523,
        "title": "rcnn 通过load_inference_model 加载模型 报错 Tensor holds no memory",
        "body": "rcnn  模型，通过 save_inference_model 保存后，通过fluid.io.load_inference_model 加载模型 预测发生错误。\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 185, in <module>\r\n    infer2()\r\n  File \"infer.py\", line 71, in infer2\r\n    return_numpy=False)\r\n  File \"/home/work/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/work/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator generate_proposals error.\r\nPython Callstacks:\r\n  File \"/home/work/anaconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/work/anaconda3/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/work/anaconda3/lib/python3.6/site-packages/paddle/fluid/layers/detection.py\", line 2497, in generate_proposals\r\n    'RpnRoiProbs': rpn_roi_probs})\r\n  File \"/home/ssd1/caohaitao/rcnn/models/model_builder.py\", line 234, in rpn_heads\r\n    eta=eta)\r\n  File \"/home/ssd1/caohaitao/rcnn/models/model_builder.py\", line 41, in build_model\r\n    self.rpn_heads(body_conv)\r\n  File \"export.py\", line 24, in export\r\n    model.build_model(image_shape)\r\n  File \"export.py\", line 46, in <module>\r\n    export()\r\nC++ Callstacks:\r\nholder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:23]\r\nPaddlePaddle Call Stacks:\r\n0       0x7fc3bac1ff88p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7fc3bac202d7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fc3bcd23c29p paddle::framework::Tensor::check_memory_size() const + 185\r\n3       0x7fc3bcd24e2cp paddle::framework::Tensor::Slice(long, long) const + 44\r\n4       0x7fc3bc64cd7ap paddle::operators::GenerateProposalsKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 2682\r\n5       0x7fc3bc64d423p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::GenerateProposalsKernel<float>, pa$dle::operators::GenerateProposalsKernel<double> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) +\r\n35\r\n6       0x7fc3bcc93f87p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::$oid_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detai$::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, $oost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n7       0x7fc3bcc94361p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::$oid_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detai$::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, $oost::detail::variant::void_> const&) const + 529\r\n8       0x7fc3bcc9195cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boo$t::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant$:void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::det$il::variant::void_> const&) + 332\r\n9       0x7fc3bada9bfep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n10      0x7fc3badacc9fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n11      0x7fc3bac110edp\r\n12      0x7fc3bac52426p\r\n13      0x7fc3f279a364p _PyCFunction_FastCallDict + 340\r\n14      0x7fc3f282d00ep\r\n15      0x7fc3f284e62ap _PyEval_EvalFrameDefault + 778\r\n16      0x7fc3f2825f24p\r\n17      0x7fc3f2826dc1p\r\n18      0x7fc3f282cf95p\r\n19      0x7fc3f284f3e7p _PyEval_EvalFrameDefault + 4295\r\n20      0x7fc3f2825f24p\r\n21      0x7fc3f2826dc1p\r\n22      0x7fc3f282cf95p\r\n23      0x7fc3f284f3e7p _PyEval_EvalFrameDefault + 4295\r\n24      0x7fc3f282628ep\r\n25      0x7fc3f2826dc1p\r\n26      0x7fc3f282cf95p\r\n27      0x7fc3f284e62ap _PyEval_EvalFrameDefault + 778\r\n28      0x7fc3f28278d9p PyEval_EvalCodeEx + 809\r\n29      0x7fc3f282867cp PyEval_EvalCode + 28\r\n30      0x7fc3f28a2ce4p\r\n31      0x7fc3f28a30e1p PyRun_FileExFlags + 161\r\n32      0x7fc3f28a32e4p PyRun_SimpleFileExFlags + 452\r\n33      0x7fc3f28a6dafp Py_Main + 1535\r\n34      0x7fc3f276d8bep main + 238\r\n35      0x7fc3f1ebe7c5p __libc_start_main + 245\r\n36      0x7fc3f28550dap",
        "state": "open",
        "user": "linghaolu",
        "closed_by": null,
        "created_at": "2019-10-12T07:08:25+00:00",
        "updated_at": "2019-10-12T11:59:02+00:00",
        "closed_at": null,
        "comments_count": [
            "linghaolu",
            "linghaolu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3526,
        "title": "如何执行数据强制转换?我有个数组variable, 是float类型的, 想转换为int类型,不知该用什么函数?",
        "body": "",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-10-12T08:50:55+00:00",
        "updated_at": "2019-10-14T01:22:22+00:00",
        "closed_at": null,
        "comments_count": [
            "MyPandaShaoxiang",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3528,
        "title": "没有训练，直接使用官方提供的weights的YOLOV3模型进行infer报错。",
        "body": "我在云服务器上ubuntu18.04和windows主机上，进行YOLOV3试用，没有训练，直接使用官方提供的weights进行infer，均报错，报错的截图如下：\r\n![image](https://user-images.githubusercontent.com/53200354/66698554-839f6880-ed11-11e9-9fef-4e3c9ba98ca3.png)\r\n![image](https://user-images.githubusercontent.com/53200354/66698562-931eb180-ed11-11e9-9a8e-b62a25fe7aa3.png)\r\n请问，这是什么原因？",
        "state": "closed",
        "user": "dhdljd",
        "closed_by": "heavengate",
        "created_at": "2019-10-12T08:59:17+00:00",
        "updated_at": "2019-10-12T14:10:39+00:00",
        "closed_at": "2019-10-12T14:10:39+00:00",
        "comments_count": [
            "heavengate",
            "dhdljd",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3531,
        "title": "PaddleDetection infer时候出错",
        "body": "您好，我在进行paddle检测的infer时候，\r\n在运行\r\n            outs = exe.run(infer_prog,\r\n                           feed=feeder.feed(data),\r\n                           fetch_list=values,\r\n                           return_numpy=False)\r\n这一行的时候出错:\r\nTraceback (most recent call last):\r\n  File \"tools/infer_video.py\", line 442, in <module>\r\n    main()\r\n  File \"tools/infer_video.py\", line 316, in main\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator multiclass_nms error.\r\nPython Callstacks:\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/detection.py\", line 2771, in multiclass_nms\r\n    outputs={'Out': output})\r\n  File \"/home/daibing/baidu_daibing/cncert-source/logo_detection/ppdet/core/workspace.py\", line 95, in partial_apply\r\n    return op(*args, **kwargs_)\r\n  File \"/home/daibing/baidu_daibing/cncert-source/logo_detection/ppdet/modeling/roi_heads/bbox_head.py\", line 300, in get_prediction\r\n    pred_result = self.nms(bboxes=cliped_box, scores=cls_prob)\r\n  File \"/home/daibing/baidu_daibing/cncert-source/logo_detection/ppdet/modeling/architectures/faster_rcnn.py\", line 120, in build\r\n    im_shape)\r\n  File \"/home/daibing/baidu_daibing/cncert-source/logo_detection/ppdet/modeling/architectures/faster_rcnn.py\", line 130, in test\r\n    return self.build(feed_vars, 'test')\r\n  File \"tools/infer_video.py\", line 257, in main\r\n    test_fetches = model.test(feed_vars)\r\n  File \"tools/infer_video.py\", line 442, in <module>\r\n    main()\r\nC++ Callstacks:\r\nEnforce failed. Expected begin_idx < end_idx, but received begin_idx:103 >= end_idx:103.\r\nThe start row index must be lesser than the end row index. at [/paddle/paddle/fluid/framework/tensor.cc:78]\r\nPaddlePaddle Call Stacks:",
        "state": "open",
        "user": "dbcool",
        "closed_by": null,
        "created_at": "2019-10-12T11:30:02+00:00",
        "updated_at": "2019-11-07T11:46:41+00:00",
        "closed_at": null,
        "comments_count": [
            "MyPandaShaoxiang",
            "qingqing01",
            "dbcool",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3538,
        "title": "run KT-NET 时候，ema.update()报 ‘dict’ object has no attribute 'has_key' ",
        "body": "环境：ubuntu16  cuda9.0   cudnn 7.3 python3.7\r\npaddle是按照官网通过pip安装的\r\n在执行 sh ./run_record_twomemory_finetune.sh 时候报如下错误\r\nTraceback (most recent call last):\r\n  File \"src/run_record_twomemory.py\", line 628, in <module>\r\n    train(args)\r\n  File \"src/run_record_twomemory.py\", line 429, in train\r\n    ema.update()\r\n  File \"/home/thj18/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 2624, in update\r\n    if self._ema_vars.has_key(param.name + '.master'):\r\nAttributeError: 'dict' object has no attribute 'has_key'\r\n",
        "state": "closed",
        "user": "euphratica",
        "closed_by": "euphratica",
        "created_at": "2019-10-13T07:16:46+00:00",
        "updated_at": "2019-10-14T08:34:16+00:00",
        "closed_at": "2019-10-14T08:34:16+00:00",
        "comments_count": [
            "chenwhql",
            "euphratica"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3540,
        "title": "Linux环境下对PaddleSeg 进行C++预测库部署的时候，在最后进行编译生成可执行文件时遇到的问题，希望大神能帮忙解答一下",
        "body": "会报出以下的错误：（本人系统为ubuntu18.04 GCC/G++ 版本为4.8.5 CUDA版本10.0）\r\n/root/projects/opencv3/lib64/libopencv_core.a(hal_internal.cpp.o)：在函数‘lapack_QR32f(float*, unsigned long, int, int, int, float*, unsigned long, float*, int*)’中：\r\nhal_internal.cpp:(.text._Z12lapack_QR32fPfmiiiS_mS_Pi+0x250)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR32fPfmiiiS_mS_Pi+0x2bc)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR32fPfmiiiS_mS_Pi+0x6e9)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR32fPfmiiiS_mS_Pi+0x751)：对‘sgels_’未定义的引用\r\n/root/projects/opencv3/lib64/libopencv_core.a(hal_internal.cpp.o)：在函数‘lapack_QR64f(double*, unsigned long, int, int, int, double*, unsigned long, double*, int*)’中：\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x295)：对‘dgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x325)：对‘dgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x5ee)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x63e)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x8de)：对‘dgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0x96f)：对‘dgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0xb14)：对‘sgels_’未定义的引用\r\nhal_internal.cpp:(.text._Z12lapack_QR64fPdmiiiS_mS_Pi+0xb64)：对‘sgels_’未定义的引用\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/demo.dir/build.make:131: recipe for target 'demo' failed\r\nmake[2]: *** [demo] Error 1\r\nCMakeFiles/Makefile2:68: recipe for target 'CMakeFiles/demo.dir/all' failed\r\nmake[1]: *** [CMakeFiles/demo.dir/all] Error 2\r\nMakefile:83: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n",
        "state": "closed",
        "user": "eddieheyutong",
        "closed_by": "eddieheyutong",
        "created_at": "2019-10-13T13:20:22+00:00",
        "updated_at": "2019-10-17T07:08:21+00:00",
        "closed_at": "2019-10-17T07:08:21+00:00",
        "comments_count": [
            "chenwhql"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3549,
        "title": "如何使用定制化词典",
        "body": "我在customization.dic 按如下格式新加词典，但是发现并未生效\r\n[D:LOC]\r\n彭山里\r\n三水道\r\n也没发现那里有加载这个文件的地方，请问该怎么办",
        "state": "open",
        "user": "jude2014",
        "closed_by": null,
        "created_at": "2019-10-14T02:58:21+00:00",
        "updated_at": "2020-04-25T00:15:56+00:00",
        "closed_at": null,
        "comments_count": [
            "zhupengyang",
            "zhupengyang",
            "bityigoss",
            "yanggu01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3557,
        "title": "图像分类模型的data feeder变量个数的问题",
        "body": "您好，在image_classification模型中，我想要加两个格式不同的标签作为约束（类别和关键点），\r\npy_reader = fluid.layers.py_reader(\r\n                capacity=16,\r\n                shapes=[[-1] + image_shape, [-1, len(class_dim)], [-1, 8, 56, 56]],\r\n                lod_levels=[0, 0, 0],\r\n                dtypes=[\"float32\", \"int64\", \"float32\"],\r\n                use_double_buffer=True）\r\nimage, label, kpts_gt = fluid.layers.read_file(py_reader)\r\navg_cost, out = net_config(image, kpts_gt, model, args, label=label, is_train=is_train)\r\n\r\n但是运行时报错\r\nFile \"/home/baixue/tools/anaconda3/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 282, in feed\r\n    \"len(feed_list) (%s)\") % (len(each_sample), len(converter))\r\nAssertionError: The number of fields in data (2) does not match len(feed_list) (3)\r\n\r\n我理解应该有一个feeder = fluid.DataFeeder(feed_list=[img, label], place=p)这样的函数，让我把feed_list写进去，但我没有找到（infer.py和test.py都有，train.py没有），请问是这样嘛？在哪里呢？谢谢~",
        "state": "open",
        "user": "SnowWhite11235",
        "closed_by": null,
        "created_at": "2019-10-14T07:03:07+00:00",
        "updated_at": "2019-10-14T08:42:27+00:00",
        "closed_at": null,
        "comments_count": [
            "zhhsplendid",
            "SnowWhite11235",
            "zhhsplendid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3558,
        "title": "可否提供flownet, flownet2, PWC net等光流估计的模型？pytorch有写cuda的第三方库，paddle可否也提供一些correlation layer？",
        "body": "pytorch实现时有一些第三方自己写的cuda代码，例如nvidia的\r\n```\r\nhttps://github.com/NVIDIA/flownet2-pytorch/tree/master/networks/correlation_package\r\n```\r\n在paddle中如何实现？可否提供一些参考。",
        "state": "closed",
        "user": "zhhezhhe",
        "closed_by": "zhhezhhe",
        "created_at": "2019-10-14T07:17:55+00:00",
        "updated_at": "2020-01-15T08:31:20+00:00",
        "closed_at": "2020-01-15T08:31:20+00:00",
        "comments_count": [
            "zhupengyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3571,
        "title": "采用win10笔记本电脑跑YOLOV3模型推理的耗时2.4s",
        "body": "![image](https://user-images.githubusercontent.com/53200354/66791489-3bf22a00-ef27-11e9-88c6-1e249207b095.png)\r\n\r\n屏幕截图如上，其中，used_time：4.438s代表从模型加载到推理完成的时间，model_interpreter_time：2.407s代表从模型开始推理到结束的时间。\r\n采用官方提供的infer文件、权重。\r\n环境是：\r\n联想x1笔记本电脑；\r\nnoGPU\r\n酷睿i5CPU\r\nwin10系统。\r\n请问，这样的耗时是否正常？是否需要在什么地方做优化？\r\n\r\n---------------------------\r\n\r\n另外，在同样的平台，采用opencv+YOLOV3模型，耗时在500~1000ms之间，调用的opencv语句是：\r\nlabel = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\r\n截图如下：\r\n![image](https://user-images.githubusercontent.com/53200354/66792110-d5224000-ef29-11e9-957c-1ec3258dcd86.png)\r\n\r\n-----------------------------\r\n在同样的平台，采用tensorflow跑lite模型，耗时基本上也要在500ms以上。",
        "state": "closed",
        "user": "dhdljd",
        "closed_by": "qingqing01",
        "created_at": "2019-10-15T00:45:49+00:00",
        "updated_at": "2019-10-20T03:10:46+00:00",
        "closed_at": "2019-10-20T03:10:46+00:00",
        "comments_count": [
            "willthefrog",
            "qingqing01",
            "dhdljd",
            "qingqing01",
            "dhdljd",
            "OliverLPH",
            "dhdljd"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3576,
        "title": "_pickle.UnpicklingError：pickle data was truncated",
        "body": "在训练的过程中，会出现这种错误，是由于什么导致的呢？\r\n![image](https://user-images.githubusercontent.com/16151674/66797629-fdb43500-ef3d-11e9-8c1b-e9c243986d8b.png)\r\n",
        "state": "open",
        "user": "sportzhang",
        "closed_by": null,
        "created_at": "2019-10-15T03:22:01+00:00",
        "updated_at": "2019-10-16T11:12:27+00:00",
        "closed_at": null,
        "comments_count": [
            "willthefrog",
            "SunGaofeng",
            "sportzhang",
            "SunGaofeng",
            "sportzhang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3577,
        "title": "关于训练模型的配置信息问题",
        "body": "想知道关于训练的  epoch  step这些配置信息参数的问题 是在哪修改 是在模型.yml文件吗\r\n类似这种吗？ 还有  有些信息都是缩写  实在是搞不懂都代表什么含义  是否有中文文档呢？能否提供一下 终端训练过程中  好多简写 缩写 实在是搞不懂含义 也不知道训练到第几个周期了。。\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/configs/mask_rcnn_r50_1x.yml",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "willthefrog",
        "created_at": "2019-10-15T03:24:21+00:00",
        "updated_at": "2019-10-15T09:30:54+00:00",
        "closed_at": "2019-10-15T09:30:54+00:00",
        "comments_count": [
            "willthefrog",
            "shuxsu",
            "willthefrog",
            "shuxsu",
            "willthefrog",
            "shuxsu",
            "willthefrog",
            "shuxsu",
            "willthefrog",
            "shuxsu",
            "shuxsu",
            "shuxsu",
            "willthefrog"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3582,
        "title": "用PaddleSeg中的模型导出文件导出模型和参数后，在用之前部署的C++预测库时遇到问题",
        "body": "如题，我在通过export_model.py文件导出了下载的Paddle 官方预训练模型，deeplabv3p_xception65_bn_cityscapes，然后用之前部署的C++预测库进行预测的时候，报出以下错误\r\n/root/projects/PaddleSeg/inference/build# ./demo --conf=/root/projects/PaddleSeg/inference/conf/deploy.yaml --input_dir=/root/projects/PaddleSeg/inference/images/cityscapes/\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nI1015 16:15:59.258088 19235 analysis_predictor.cc:88] Profiler is deactivated, and no profiling report will be generated.\r\nI1015 16:15:59.278381 19235 op_compatible_info.cc:201] The default operator required version is missing. Please update the model version.\r\nI1015 16:15:59.278416 19235 analysis_predictor.cc:841] MODEL VERSION: 0.0.0\r\nI1015 16:15:59.278431 19235 analysis_predictor.cc:843] PREDICTOR VERSION: 0.0.0\r\nW1015 16:15:59.278589 19235 analysis_predictor.cc:855]  - Version incompatible (1) batch_norm\r\nW1015 16:15:59.278600 19235 analysis_predictor.cc:855]  - Version incompatible (1) bilinear_interp\r\nW1015 16:15:59.278607 19235 analysis_predictor.cc:855]  - Version incompatible (1) concat\r\nW1015 16:15:59.278614 19235 analysis_predictor.cc:855]  - Version incompatible (1) conv2d\r\nW1015 16:15:59.278622 19235 analysis_predictor.cc:855]  - Version incompatible (1) depthwise_conv2d\r\nW1015 16:15:59.278630 19235 analysis_predictor.cc:855]  - Version incompatible (1) dropout\r\nW1015 16:15:59.278637 19235 analysis_predictor.cc:855]  - Version incompatible (1) elementwise_add\r\nW1015 16:15:59.278646 19235 analysis_predictor.cc:855]  - Version incompatible (1) feed\r\nW1015 16:15:59.278652 19235 analysis_predictor.cc:855]  - Version incompatible (1) fetch\r\nW1015 16:15:59.278659 19235 analysis_predictor.cc:855]  - Version incompatible (1) reduce_mean\r\nW1015 16:15:59.278667 19235 analysis_predictor.cc:855]  - Version incompatible (1) relu\r\nW1015 16:15:59.278674 19235 analysis_predictor.cc:855]  - Version incompatible (1) scale\r\nW1015 16:15:59.278682 19235 analysis_predictor.cc:855]  - Version incompatible (1) softmax\r\nW1015 16:15:59.278688 19235 analysis_predictor.cc:855]  - Version incompatible (1) transpose2\r\nW1015 16:15:59.278705 19235 analysis_predictor.cc:148] WARNING: Results may be DIFF! Using same versions between model and lib.\r\n--- Running analysis [ir_graph_build_pass]\r\n--- Running analysis [ir_graph_clean_pass]\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [is_test_pass]\r\n--- Running IR pass [simplify_with_basic_ops_pass]\r\n--- Running IR pass [fc_fuse_pass]\r\n--- Running IR pass [fc_elementwise_layernorm_fuse_pass]\r\n--- Running IR pass [conv_affine_channel_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_affine_channel_fuse_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n---  detected 78 subgraphs\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_act_fuse_pass]\r\n---  detected 53 subgraphs\r\n--- Running IR pass [conv_elementwise_add2_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_fuse_pass]\r\n---  detected 26 subgraphs\r\n--- Running IR pass [transpose_flatten_concat_fuse_pass]\r\n--- Running IR pass [runtime_context_cache_pass]\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\nI1015 16:16:00.083369 19235 ir_params_sync_among_devices_pass.cc:41] Sync params from CPU to GPU\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI1015 16:16:00.203075 19235 analysis_predictor.cc:473] ======= optimize end =======\r\n---  skip [feed], feed -> image\r\n---  skip [save_infer_model/scale_0], fetch -> fetch\r\nW1015 16:16:00.567735 19235 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1015 16:16:00.571164 19235 device_context.cc:243] device: 0, cuDNN Version: 7.6.\r\nruntime = 14236\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:01.581390 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\nruntime = 10389\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:01.682529 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\nruntime = 8927\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:01.771071 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\nruntime = 9973\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:01.857481 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\nruntime = 6773\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:01.934250 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\nruntime = 6660\r\nsize of outputs[0]: (1,19,512,512,)\r\nE1015 16:16:02.018646 19235 seg_predictor.cpp:74]  [FATAL] unequal: input vs output [7864320|4980736]\r\n\r\n然后图片的文件夹中并没有生成预测的图片，想请问下大佬们这个是什么原因呢？",
        "state": "closed",
        "user": "eddieheyutong",
        "closed_by": "eddieheyutong",
        "created_at": "2019-10-15T08:36:02+00:00",
        "updated_at": "2019-10-17T07:09:06+00:00",
        "closed_at": "2019-10-17T07:09:06+00:00",
        "comments_count": [
            "willthefrog",
            "sjtubinlong"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3584,
        "title": "测试已经训练好的模型出现问题",
        "body": "错误信息\r\n```\r\nlibprotobuf ERROR /home/teamcity/work/ef54dc8a5b211854/build/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type \"paddle.framework.proto.VarType.TensorDesc\" because it is missing required fields: (cannot determine missing fields for lite message)\r\nTraceback (most recent call last):\r\nFile \"infer.py\", line 319, in \r\nmain()\r\nFile \"infer.py\", line 183, in main\r\ncheckpoint.load_checkpoint(exe, infer_prog, cfg.weights)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/utils/checkpoint.py\", line 89, in load_checkpoint\r\nfluid.io.load_persistables(exe, path, prog)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 755, in load_persistables\r\nfilename=filename)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 619, in load_vars\r\nfilename=filename)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 656, in load_vars\r\nexecutor.run(load_prog)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 657, in run\r\nuse_program_cache=use_program_cache)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 755, in run\r\nexe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load error.\r\nPython Call stacks:\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1774, in append_op\r\nattrs=kwargs.get(\"attrs\", None))\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 641, in load_vars\r\n'file_path': os.path.join(load_dirname, new_var.name)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 619, in load_vars\r\nfilename=filename)\r\nFile \"/Library/anaconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 755, in load_persistables\r\nfilename=filename)\r\nFile \"/Users/shuxsu/Downloads/models-develop/PaddleCV/PaddleDetection/ppdet/utils/checkpoint.py\", line 89, in load_checkpoint\r\nfluid.io.load_persistables(exe, path, prog)\r\nFile \"infer.py\", line 183, in main\r\ncheckpoint.load_checkpoint(exe, infer_prog, cfg.weights)\r\nFile \"infer.py\", line 319, in \r\nmain()\r\nC++ Call stacks:\r\nCannot parse tensor desc at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/framework/tensor_util.cc:466]\r\nPaddlePaddle Call Stacks:\r\n0 0x1a26508f8cp void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 636\r\n1 0x1a26508cbbp paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 139\r\n2 0x1a27916e30p paddle::framework::TensorFromStream(std::1::basic_istream<char, std::1::char_traits >&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&) + 1248\r\n3 0x1a27620b0fp paddle::framework::DeserializeFromStream(std::1::basic_istream<char, std::1::char_traits >&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 431\r\n4 0x1a268791d1p paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, float>::LoadLodTensor(std::1::basic_istream<char, std::1::char_traits >&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::Variable*, paddle::framework::ExecutionContext const&) const + 97\r\n5 0x1a26878a83p paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 627\r\n6 0x1a268787d0p std::1::function::func<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, long long> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&), std::1::allocator<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadOpKernel<paddle::platform::CPUDeviceContext, long long> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&)>, void (paddle::framework::ExecutionContext const&)>::operator()(paddle::framework::ExecutionContext const&) + 32\r\n7 0x1a278d52c5p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 485\r\n8 0x1a278d5038p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 488\r\n9 0x1a278d17f4p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 324\r\n10 0x1a2667e27fp paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 319\r\n11 0x1a2667dd2cp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator > > > const&, bool) + 172\r\n12 0x1a265706fdp void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init_core_avx(pybind11::module&)::$_84, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator > > > const&, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init_core_avx(pybind11::module&)::$_84&&, void ()(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope, int, bool, bool, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits, std::__1::allocator > > > const&), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 301\r\n13 0x1a264eda38p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3400\r\n14 0x10b2cc10ap _PyCFunction_FastCallDict + 362\r\n15 0x10b253171p _PyObject_FastCallKeywords + 385\r\n16 0x10b3a1718p call_function + 392\r\n17 0x10b39f175p _PyEval_EvalFrameDefault + 46837\r\n18 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n19 0x10b3a1a8ap fast_function + 362\r\n20 0x10b3a167cp call_function + 236\r\n21 0x10b39f225p _PyEval_EvalFrameDefault + 47013\r\n22 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n23 0x10b3a1a8ap fast_function + 362\r\n24 0x10b3a167cp call_function + 236\r\n25 0x10b39f175p _PyEval_EvalFrameDefault + 46837\r\n26 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n27 0x10b3a1a8ap fast_function + 362\r\n28 0x10b3a167cp call_function + 236\r\n29 0x10b39f225p _PyEval_EvalFrameDefault + 47013\r\n30 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n31 0x10b3a1a8ap fast_function + 362\r\n32 0x10b3a167cp call_function + 236\r\n33 0x10b39f225p _PyEval_EvalFrameDefault + 47013\r\n34 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n35 0x10b3a1a8ap fast_function + 362\r\n36 0x10b3a167cp call_function + 236\r\n37 0x10b39f175p _PyEval_EvalFrameDefault + 46837\r\n38 0x10b3a19dcp fast_function + 188\r\n39 0x10b3a167cp call_function + 236\r\n40 0x10b39f175p _PyEval_EvalFrameDefault + 46837\r\n41 0x10b3a19dcp fast_function + 188\r\n42 0x10b3a167cp call_function + 236\r\n43 0x10b39f175p _PyEval_EvalFrameDefault + 46837\r\n44 0x10b3928c9p _PyEval_EvalCodeWithName + 425\r\n45 0x10b3eb55cp PyRun_FileExFlags + 252\r\n46 0x10b3eaa34p PyRun_SimpleFileExFlags + 372\r\n47 0x10b4117c6p Py_Main + 3734\r\n48 0x10b242f59p main + 313\r\n49 0x7fff715d73d5p start + 1\r\n50 0x6p\r\n```",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "jerrywgz",
        "created_at": "2019-10-15T09:11:55+00:00",
        "updated_at": "2019-11-04T02:54:04+00:00",
        "closed_at": "2019-11-04T02:54:04+00:00",
        "comments_count": [
            "willthefrog",
            "jerrywgz",
            "shuxsu",
            "shuxsu",
            "jerrywgz",
            "shuxsu",
            "jerrywgz",
            "shuxsu",
            "qingqing01",
            "shuxsu",
            "shuxsu",
            "jerrywgz",
            "shuxsu",
            "jerrywgz",
            "shuxsu",
            "jerrywgz",
            "shuxsu",
            "shuxsu",
            "jerrywgz"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3593,
        "title": "YOLOV3收敛过快",
        "body": "没有加载预训练模型，类别为两类，训练集共12000张图像，batchsize为10，收敛速度过快，一轮不到就拟合了，请问可能是什么问题",
        "state": "open",
        "user": "zhizunbao-y",
        "closed_by": null,
        "created_at": "2019-10-16T03:43:26+00:00",
        "updated_at": "2019-10-18T06:47:17+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "zhizunbao-y"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3589,
        "title": "测试过程中报错ImportError: cannot import name 'ColorTTY'",
        "body": "输出原图片\r\n另外想咨询一下 mask_rcnn_r50_1x.yml   mask_rcnn_r50_fpn_1x.yml 这些是不是都是模型  我修改了 r50是不是不需要修改第二个   因为我是用 mask_rcnn_r50_1x.yml进行训练的  但是现在输出结果是没有标注框的  我的训练集是cityscape数据集  不知道什么原因",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "jerrywgz",
        "created_at": "2019-10-16T02:07:53+00:00",
        "updated_at": "2019-11-04T02:53:24+00:00",
        "closed_at": "2019-11-04T02:53:24+00:00",
        "comments_count": [
            "qingqing01",
            "shuxsu",
            "qingqing01",
            "shuxsu",
            "shuxsu",
            "qingqing01",
            "shuxsu",
            "shuxsu",
            "qingqing01",
            "shuxsu",
            "shuxsu",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3586,
        "title": "model_optimize_tool转PyramidBox发布的模型出错",
        "body": "环境：Ubuntu 18.04.3\r\n下载的这个模型http://paddlemodels.bj.bcebos.com/PyramidBox_WiderFace.tar.gz\r\n\r\n./model_optimize_tool --model_dir=PyramidBox_WiderFace --optimize_out_type=naive_buffer --optimize_out=PyramidBox_WiderFace222 --valid_targets=arm --prefer_int8_kernel=false\r\n[I 10/15 20:31:46.884 ...5/github/Paddle-Lite/lite/api/cxx_api.cc:96 Build] load from memory 0\r\n[F 10/15 20:31:47. 20 .../github/Paddle-Lite/lite/core/program.cc:141 Build] Check failed: op: no Op found for depthwise_conv2d_transpose\r\n",
        "state": "closed",
        "user": "yyf1986",
        "closed_by": "willthefrog",
        "created_at": "2019-10-15T12:34:17+00:00",
        "updated_at": "2019-10-15T12:43:24+00:00",
        "closed_at": "2019-10-15T12:43:15+00:00",
        "comments_count": [
            "willthefrog"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3622,
        "title": "ELMO 源码 数据处理 疑问  data.py  431 行 zip操作",
        "body": "代码没有问题，我自己看错了，忽略",
        "state": "closed",
        "user": "memorygarden",
        "closed_by": "memorygarden",
        "created_at": "2019-10-16T09:33:43+00:00",
        "updated_at": "2019-10-16T09:43:21+00:00",
        "closed_at": "2019-10-16T09:42:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3604,
        "title": "paddleslim的使用问题",
        "body": "使用paddlepaddle训练完成模型之后， 使用paddleslim的量化对模型进行压缩， 测试的时候发现准确率下降6.5%。 不知道配置是不是出现了问题。 \r\n使用configs/quantization.yaml\r\n内容如下：\r\nversion: 1.0\r\nstrategies:\r\n    quantization_strategy:\r\n        class: 'QuantizationStrategy'\r\n        start_epoch: 0\r\n        end_epoch: 1999\r\n        float_model_save_path: './output/float'\r\n        mobile_model_save_path: './output/mobile'\r\n        int8_model_save_path: './output/int8'\r\n        weight_bits: 8\r\n        activation_bits: 8\r\n        weight_quantize_type: 'abs_max'\r\n        activation_quantize_type: 'moving_average_abs_max'\r\n        save_in_nodes: ['pixel']\r\n        save_out_nodes: ['fc_0.tmp_2']\r\ncompressor:\r\n    epoch: 2000\r\n    checkpoint_path: './checkpoints_quan/'\r\n    strategies:\r\n        - quantization_strategy\r\n\r\n\r\n使用的compress.py如下所示\r\n[compress.zip](https://github.com/PaddlePaddle/models/files/3732705/compress.zip)\r\n把zip后缀修改为py即可\r\n\r\n",
        "state": "open",
        "user": "esun0087",
        "closed_by": null,
        "created_at": "2019-10-16T06:25:06+00:00",
        "updated_at": "2019-10-21T02:07:26+00:00",
        "closed_at": null,
        "comments_count": [
            "slf12",
            "esun0087",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3615,
        "title": "PaddleVideo_STNET",
        "body": "\r\n> 您好\r\n>>不明白STNET 是如果做到视频不等长分类的\r\n>>>![image](https://user-images.githubusercontent.com/38428867/66899114-07689600-f02d-11e9-8192-cf8cddd1ea9e.png)\r\n\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": null,
        "created_at": "2019-10-16T07:54:15+00:00",
        "updated_at": "2020-07-20T00:31:53+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "geng007",
            "SunGaofeng",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3616,
        "title": "PaddleDetection 的动态链接库调用方法",
        "body": "您好，图像分类有提供动态链接库调用方法，不知道目标检测这块的是否可以提供python版的动态链接库的调用环境呢？",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "qingqing01",
        "created_at": "2019-10-16T08:28:39+00:00",
        "updated_at": "2019-11-04T02:53:37+00:00",
        "closed_at": "2019-11-04T02:53:37+00:00",
        "comments_count": [
            "qingqing01",
            "pangr",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3630,
        "title": "使用Docker镜像运行PyramidBox遇到的问题以及一些建议",
        "body": "相关issue: https://github.com/PaddlePaddle/Paddle/issues/20667\r\n\r\n受限于Docker版本，在我的机器上只能使用cuda9.0及以下版本的Docker镜像。机器的GPU是16GB显存的P100。\r\n\r\n首先我拉取了`paddlepaddle/paddle:latest-gpu-cuda9.0-cudnn7`，并且尝试运行这个repo下最新的PyramidBox代码，但是遇到了以下错误：\r\n```shell\r\nroot@df3a17988b31:~/pyramidbox# python3.6 -u widerface_eval.py --model_dir=/root/pyramidbox/models/PyramidBox_WiderFace\r\n-----------  Configuration Arguments -----------\r\nconfs_threshold: 0.15\r\ndata_dir: data/WIDER_val/images/\r\nfile_list: data/wider_face_split/wider_face_val_bbx_gt.txt\r\nimage_path:\r\ninfer: False\r\nmodel_dir: /root/pyramidbox/models/PyramidBox_WiderFace\r\npred_dir: pred\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"widerface_eval.py\", line 328, in <module>\r\n    exe, args.model_dir, main_program=infer_program)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/io.py\", line 803, in load_persistables\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/io.py\", line 643, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/io.py\", line 664, in load_vars\r\n    assert var_temp != None, \"can't not find var: \" + each_var.name\r\nAssertionError: can't not find var: conv2d_61.w_0\r\n```\r\n可以保证的是，模型文件的确是放置在了指定的路径下，而且`conv2d_61.w_0`这个文件也是有的。\r\n\r\n从相关issue中得知latest是develop分支，感觉可能是develop分支的问题，于是转而拉取了`paddlepaddle/paddle:1.5.0-cuda9.0-cudnn7`，并且以同样的步骤运行同样的PyramidBox代码。这次运行没有报找不到模型文件的错，而是报出了显存不足的错：\r\n```shell\r\nroot@fe31a5b0b0bd:~/pyramidbox# python widerface_eval.py --model_dir=models/PyramidBox_WiderFace\r\n-----------  Configuration Arguments -----------\r\nconfs_threshold: 0.15\r\ndata_dir: data/WIDER_val/images/\r\nfile_list: data/wider_face_split/wider_face_val_bbx_gt.txt\r\nimage_path:\r\ninfer: False\r\nmodel_dir: models/PyramidBox_WiderFace\r\npred_dir: pred\r\nuse_gpu: True\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\nW1016 11:56:06.097822    14 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1016 11:56:06.101693    14 device_context.cc:267] device: 0, cuDNN Version: 7.4.\r\nTraceback (most recent call last):\r\n  File \"widerface_eval.py\", line 328, in <module>\r\n    exe, args.model_dir, main_program=infer_program)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 645, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load error.\r\nPython Callstacks:\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 630, in load_vars\r\n    'file_path': os.path.join(load_dirname, new_var.name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"widerface_eval.py\", line 328, in <module>\r\n    exe, args.model_dir, main_program=infer_program)\r\nC++ Callstacks:\r\nEnforce failed. Expected allocating <= available, but received allocating:14920696460 > available:13418495744.\r\nInsufficient GPU memory to allocation. at [/paddle/paddle/fluid/platform/gpu_info.cc:262]\r\nPaddlePaddle Call Stacks:\r\n0       0x7f23f14bfbc8p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f23f14bff17p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f23f34d7996p paddle::platform::GpuMaxChunkSize() + 630\r\n3       0x7f23f34abc8ap\r\n4       0x7f24deb1ea99p\r\n5       0x7f23f34ab32dp paddle::memory::legacy::GetGPUBuddyAllocator(int) + 109\r\n6       0x7f23f34ac175p void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long) + 37\r\n7       0x7f23f34ac6b5p paddle::memory::allocation::LegacyAllocator::AllocateImpl(unsigned long) + 421\r\n8       0x7f23f34a07d5p paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 181\r\n9       0x7f23f34a095ap paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 26\r\n10      0x7f23f30adfccp paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long) + 44\r\n11      0x7f23f3473204p paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long) + 148\r\n12      0x7f23f34768a4p paddle::framework::TensorCopy(paddle::framework::Tensor const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::platform::DeviceContext const&, paddle::framework::Tensor*) + 452\r\n13      0x7f23f347a49bp paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&) + 699\r\n14      0x7f23f30698d0p paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&) + 576\r\n15      0x7f23f1f72f99p paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>::LoadLodTensor(std::istream&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::Variable*, paddle::framework::ExecutionContext const&) const + 89\r\n16      0x7f23f1f734c0p paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 432\r\n17      0x7f23f1f73883p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, signed char>, paddle::operators::LoadOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n18      0x7f23f341c907p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n19      0x7f23f341cce1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n20      0x7f23f341a2dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n21      0x7f23f164b38ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n22      0x7f23f164e42fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n23      0x7f23f14b0b2dp\r\n24      0x7f23f14f25c6p\r\n25            0x4c5326p PyEval_EvalFrameEx + 37958\r\n26            0x4b9b66p PyEval_EvalCodeEx + 774\r\n27            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n30            0x4b9b66p PyEval_EvalCodeEx + 774\r\n31            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n32            0x4b9b66p PyEval_EvalCodeEx + 774\r\n33            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n34            0x4b9b66p PyEval_EvalCodeEx + 774\r\n35            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n36            0x4b9b66p PyEval_EvalCodeEx + 774\r\n37            0x4eb69fp\r\n38            0x4e58f2p PyRun_FileExFlags + 130\r\n39            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n40            0x4938cep Py_Main + 1358\r\n41      0x7f24de766830p __libc_start_main + 240\r\n42            0x493299p _start + 41\r\n```\r\n从https://github.com/PaddlePaddle/models/issues/1259 和https://github.com/PaddlePaddle/models/issues/1262#issuecomment-422724707 得知可能有超显存的风险，并且可以通过加入显存优化策略缓解这个问题：\r\n```shell\r\ninfer_program, nmsed_out = network.infer(main_program)\r\nfluid.memory_optimize(infer_program)\r\n```\r\n加了这一行之后的确可以跑widerface的val和test了，虽然在paddle1.5.0中提示这个api已经被舍弃了。\r\n\r\n我的建议是：\r\n1. 能否在PyramidBox的Readme中加入支持的Paddle版本的说明？\r\n2. 能否在PyramidBox的Readme中加入这个模型对显存的需求的说明？\r\n3. 能否提供新api下显存优化策略的用法？\r\n\r\n这样能够极大地提升和节省使用者的效率和时间。谢谢！",
        "state": "closed",
        "user": "fengyuentau",
        "closed_by": "fengyuentau",
        "created_at": "2019-10-17T03:05:09+00:00",
        "updated_at": "2019-10-18T02:27:04+00:00",
        "closed_at": "2019-10-18T02:27:04+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3631,
        "title": "请问是否可以提供支持测试优化的whl包",
        "body": "https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/beginners_guide/install/Tables.html#id3\r\n编译选项 ON_INFER 默认是off\r\nhttps://www.paddlepaddle.org.cn/documentation/docs/zh/develop/beginners_guide/install/Tables.html#whl-dev\r\n里面的包都没有测试优化，请问是否可以提供支持测试优化的whl包",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-10-17T03:27:06+00:00",
        "updated_at": "2019-10-18T09:16:10+00:00",
        "closed_at": null,
        "comments_count": [
            "mozpp",
            "qingqing01",
            "mozpp",
            "fc500110",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3637,
        "title": "PaddleSeg：在自定义的数据准备时通过labelme生成了原图对应的.json文件，但是在数据格式转换时报错ModuleNotFoundError: No module named 'labelme'",
        "body": "如题，原图和对应文件都已经准备好，labelme也已经安装好，但是在数据格式转换的时候报错\r\nTraceback (most recent call last):\r\n  File \"labelme2seg.py\", line 15, in <module>\r\n    import labelme\r\nModuleNotFoundError: No module named 'labelme'\r\n这个文件中我已经import了，也试着加上了sys.path.append('path')，但是还是会提示找不到这个labelme模块，请问下大神们这是什么缘由？",
        "state": "closed",
        "user": "eddieheyutong",
        "closed_by": "qingqing01",
        "created_at": "2019-10-17T07:20:32+00:00",
        "updated_at": "2019-10-18T09:19:44+00:00",
        "closed_at": "2019-10-18T09:19:44+00:00",
        "comments_count": [
            "LutaoChu",
            "eddieheyutong",
            "eddieheyutong",
            "LutaoChu",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3641,
        "title": "如何通过搭建自己的字典来提升ocr的准确率?",
        "body": "我现在有一项应用, 是识别票据上的汉字和数字; 目前汉字识别率约85%, 现在我想借助搭建字典,通过类似lexicon search来提升识别率; 不知道paddlepaddle有没有相关的库函数?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-10-17T08:30:19+00:00",
        "updated_at": "2019-10-17T09:53:10+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3681,
        "title": "There is no params of batch norm in model /weights/mask_rcnn_r50_1x.",
        "body": "训练命令：python train.py -c=/home/shuxsu/PaddleDetection/configs/mask_rcnn_r50_1x.yml -d=/home/shuxsu/PaddleDetection/dataset/coco\r\n\r\n错误信息：2019-10-21 11:55:16,802-INFO: Found /home/shuxsu/.cache/paddle/weights/mask_rcnn_r50_1x\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 284, in <module>\r\n    main()\r\n  File \"train.py\", line 160, in main\r\n    checkpoint.load_and_fusebn(exe, train_prog, cfg.pretrain_weights)\r\n  File \"/home/shuxsu/PaddleDetection/ppdet/utils/checkpoint.py\", line 253, in load_and_fusebn\r\n    path))\r\nValueError: There is no params of batch norm in model /home/shuxsu/.cache/paddle/weights/mask_rcnn_r50_1x.\r\n在yml配置里添加了finetune_exclude_pretrained_params: ['cls_score','bbox_pred','mask_fcn_logits']\r\n",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "jerrywgz",
        "created_at": "2019-10-21T04:00:06+00:00",
        "updated_at": "2019-10-25T02:05:48+00:00",
        "closed_at": "2019-10-25T02:05:48+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01",
            "shuxsu",
            "qingqing01",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3713,
        "title": "release image inpainting codes for LBAM ICCV19",
        "body": "release image inpainting codes for LBAM ICCV19",
        "state": "closed",
        "user": "xhuanlc",
        "closed_by": "SunGaofeng",
        "created_at": "2019-10-22T09:00:17+00:00",
        "updated_at": "2019-11-04T05:07:15+00:00",
        "closed_at": "2019-11-04T05:07:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3710,
        "title": "labelme2coco.py代码错误",
        "body": "labelme2coco.py生成的json文件中，\"annotations\"数组段中每个目标的\"id\"值不正确，\"id\"值与\"image_id\"只不应该是完全相同的，\"image_id\"是图片的id值，\"id\"是目标的id值，如果一个图片中包含多个目标，那么\"id\"与\"image_id\"就不相同。该问题会导致训练出的模型在检测多个目标的图片时只能检测出一个目标。\r\n\r\n代码中deal_json函数、annotations_polygon函数和annotations_rectangle函数需要修改。修改后测试OK。\r\n\r\ndeal_json函数代码修改后如下（num变量改为image_num， 增加了object_num 变量）：\r\ndef deal_json(img_path, json_path):\r\n    data_coco = {}\r\n    label_to_num = {}\r\n    images_list = []\r\n    categories_list = []\r\n    annotations_list = []\r\n    labels_list = []\r\n    image_num = -1\r\n    object_num = -1\r\n    for img_file in os.listdir(img_path):\r\n        img_label = img_file.split('.')[0]\r\n        label_file = osp.join(json_path, img_label + '.json')\r\n        print('Generating dataset from:', label_file)\r\n        image_num = image_num + 1\r\n        with open(label_file) as f:\r\n            data = json.load(f)\r\n            images_list.append(images(data, image_num))\r\n            for shapes in data['shapes']:\r\n                object_num = object_num + 1\r\n                label = shapes['label']\r\n                if label not in labels_list:\r\n                    categories_list.append(categories(label, labels_list))\r\n                    labels_list.append(label)\r\n                    label_to_num[label] = len(labels_list)\r\n                points = shapes['points']\r\n                p_type = shapes['shape_type']\r\n                if p_type == 'polygon':\r\n                    annotations_list.append(\r\n                        annotations_polygon(data['imageHeight'], data[\r\n                            'imageWidth'], points, label, image_num, object_num, **label_to_num))**\r\n                if p_type == 'rectangle':\r\n                    points.append([points[0][0], points[1][1]])\r\n                    points.append([points[1][0], points[0][1]])\r\n                    annotations_list.append(\r\n                        annotations_rectangle(points, label, image_num, object_num, label_to_num))\r\n    data_coco['images'] = images_list\r\n    data_coco['categories'] = categories_list\r\n    data_coco['annotations'] = annotations_list\r\n    return data_coco\r\n\r\nannotations_polygon函数代码修改后如下（增加了object_num 变量）：\r\ndef annotations_rectangle(points, label, image_num, object_num, label_to_num):\r\n    annotation = {}\r\n    seg_points = np.asarray(points).copy()\r\n    seg_points[1, :] = np.asarray(points)[2, :]\r\n    seg_points[2, :] = np.asarray(points)[1, :]\r\n    annotation['segmentation'] = [list(seg_points.flatten())]\r\n    annotation['iscrowd'] = 0\r\n    annotation['image_id'] = image_num + 1\r\n    annotation['bbox'] = list(\r\n        map(float, [\r\n            points[0][0], points[0][1], points[1][0] - points[0][0], points[1][\r\n                1] - points[0][1]\r\n        ]))\r\n    annotation['area'] = annotation['bbox'][2] * annotation['bbox'][3]\r\n    annotation['category_id'] = label_to_num[label]\r\n    annotation['id'] = object_num + 1\r\n    return annotation\r\n\r\nannotations_rectangle函数代码修改后如下（增加了object_num 变量）：\r\ndef annotations_polygon(height, width, points, label, image_num, object_num, label_to_num):\r\n    annotation = {}\r\n    annotation['segmentation'] = [list(np.asarray(points).flatten())]\r\n    annotation['iscrowd'] = 0\r\n    annotation['image_id'] = image_num + 1\r\n    annotation['bbox'] = list(map(float, get_bbox(height, width, points)))\r\n    annotation['area'] = annotation['bbox'][2] * annotation['bbox'][3]\r\n    annotation['category_id'] = label_to_num[label]\r\n    annotation['id'] = object_num + 1\r\n    return annotation\r\n",
        "state": "closed",
        "user": "zhuyushi",
        "closed_by": "qingqing01",
        "created_at": "2019-10-22T08:45:06+00:00",
        "updated_at": "2019-10-23T10:41:03+00:00",
        "closed_at": "2019-10-23T10:41:03+00:00",
        "comments_count": [
            "SunAhong1993",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3715,
        "title": "PaddleDetection训练私有数据检测数据集显存利用率较低",
        "body": "Hi 您好，\r\n\r\n     我在使用ppdet训练私有数据集时，出现了显存利用率过低的情况，希望可以帮助定位计算速度的瓶颈在哪。\r\n     使用版本：paddle 1.5.1\r\n     使用的配置文件：frcnn_r50_1x, ssd_500（图片预处理修改至1024*1024, 根据数据集情况修改过anchor设置）\r\n     数据集情况：50张图，每张图分辨率1024*1024，上面总共存在1w个小型boundingbox\r\n     使用体验：训练yolo_darknet_v3时明显比训练frcnn_r50和ssd_500快很多，而且在训练frcnn&ssd时，GPU的平均显存利用率很低。\r\n\r\n希望可以定位到计算瓶颈所在，多谢啦！",
        "state": "closed",
        "user": "ronghaoLee",
        "closed_by": "ronghaoLee",
        "created_at": "2019-10-22T09:15:10+00:00",
        "updated_at": "2019-10-29T11:16:30+00:00",
        "closed_at": "2019-10-29T11:16:30+00:00",
        "comments_count": [
            "heavengate",
            "ronghaoLee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3716,
        "title": "如何将snapshot的模型保存为model_final模型 & 如何暂停和继续训练模型",
        "body": "请教两个问题，谢谢\r\n1、使用PaddleDetection，在训练迭代一定数量后过会snapshot很多模型，最后完成训练会生成model_final。model_final模型可以用来推理，但是snapshot模型不能用来推理。请问如何将snapshot模型转存为model_final模型。\r\n2、完成训练后生成了一系列snapshot模型和最后一个model_final模型，我是否可以在这个基础上继续训练。如果可以，应该如何继续训练，有没有命令或者写好python脚本。\r\n谢谢。",
        "state": "open",
        "user": "zhuyushi",
        "closed_by": null,
        "created_at": "2019-10-22T09:16:54+00:00",
        "updated_at": "2019-10-23T03:50:07+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3724,
        "title": "paddle无法在子进程中进行预测",
        "body": "我想起多个进程，其中一个进程先初始化模型，然后不断预测。发现paddle和python的多进程multiprocessing有冲突\r\n```\r\nclass exec_alg_process(mp.Process):\r\n    def __init__(self, camera_rtsp):\r\n        mp.Process.__init__(self)\r\n\r\n        self.camera_rtsp = camera_rtsp\r\n\r\n        # \"\"\"\r\n        # 初始化人头检测算法实例\r\n        self.instance_head_detect \\\r\n            = pd.head_detect_cls(model_path='person_detect_mod/model/PHS3_frz_model')\r\n\r\n        print(\"instance_head_detect ok\")\r\n    def run(self):\r\n        record_index = 0\r\n        self.video_capture = cv2.VideoCapture(self.camera_rtsp)\r\n\r\n        while True:\r\n            instance_tic_toc = ct.tic_toc_cls(\"head_detect\")\r\n            instance_tic_toc.tic()\r\n\r\n            ret, frame = self.video_capture.read()\r\n            if ret != True:\r\n                # print(\"video_capture.read fail\")\r\n                # break\r\n                continue\r\n\r\n            # 执行人头检测算法\r\n            # head_detect_result_list = np.zeros(0, dtype=int)\r\n            head_detect_result_list = self.instance_head_detect(frame)\r\n```\r\n\r\n```\r\ndef load_predictor(model_path):\r\n    config = AnalysisConfig(model_path)\r\n    print('gpu id: ',config.gpu_device_id())\r\n\r\n    # 使能GPU\r\n    config.enable_use_gpu(1000, 0)\r\n\r\n    # config.disable_gpu()\r\n    # config.switch_ir_optim(True)  # 开启IR优化\r\n    # config.enable_mkldnn()  # 开启MKLDNN\r\n    # Create PaddlePredictor\r\n    predictor = create_paddle_predictor(config)\r\n    return predictor\r\n\r\ndef pre_process(ori_im, batch_size):\r\n\r\n    image = PaddleTensor()\r\n    image.name = \"image\"\r\n    image.dtype = PaddleDType.FLOAT32\r\n    # image.data = PaddleBuf(\r\n    #     np.random.randn(*image.shape).flatten().astype(\"float32\").tolist())\r\n    img = ori_im\r\n    h, w, _ = img.shape\r\n    input_size=320\r\n    image.shape = [batch_size, 3, input_size, input_size]\r\n    # pixel mean values\r\n    pixel_means = [0.485, 0.456, 0.406]\r\n    # pixel std values\r\n    pixel_stds = [0.229, 0.224, 0.225]\r\n\r\n    img=img_reader1(img,input_size,pixel_means,pixel_stds)\r\n    img=img.reshape(image.shape)\r\n    image.data=PaddleBuf(img.flatten().astype(\"float32\"))\r\n    im_shape= PaddleTensor()\r\n    im_shape.name=\"im_shape\"\r\n    im_shape.dtype=PaddleDType.INT32\r\n    im_shape.shape = [batch_size,2]\r\n    im_shape.data=PaddleBuf(\r\n        np.array([h,w]).flatten().astype(\"int32\"))\r\n\r\n    print(im_shape.data.int32_data())\r\n    # print(\"time: {}s, fps: {}\".format(end - start, 1 / (end - start)))\r\n    # print(\"{} {} {} {} {}\".format(time1-time0,time2-time1,time2d5-time2,time3-time2d5,time4-time3))\r\n    return [image,im_shape]\r\n\r\ndef img_reader1(im, size, mean, std):\r\n    h, w, _ = im.shape\r\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\r\n    im_scale_x = size / float(w)\r\n    im_scale_y = size / float(h)\r\n    out_img = cv2.resize(im, None, None,\r\n                         fx=im_scale_x, fy=im_scale_y,\r\n                         interpolation=cv2.INTER_CUBIC)\r\n    mean = np.array(mean).reshape((1, 1, -1))\r\n    std = np.array(std).reshape((1, 1, -1))\r\n    out_img = (out_img / 255.0 - mean) / std\r\n    out_img = out_img.transpose((2, 0, 1))\r\n    return out_img\r\n\r\nclass head_detect_cls:\r\n    def __init__(self,model_path='/project/LFFD-Deepsort/face_detection/head_detect_mod/model/PHS3_frz_model',\\\r\n                 det_thresh=0.05):\r\n        # self.config = AnalysisConfig(model_path)\r\n        # print('gpu id: ', self.config.gpu_device_id())\r\n\r\n        # 使能GPU\r\n        # self.config.enable_use_gpu(1000, 0)\r\n\r\n        # self.predictor = create_paddle_predictor(self.config)\r\n\r\n        self.predictor=load_predictor(model_path)\r\n        self.det_thresh=det_thresh\r\n\r\n    def __call__(self, frame):\r\n        print('start call')\r\n        frame_ = pre_process(frame, 1)\r\n        outputs= self.predictor.run(frame_)\r\n        output = outputs[0]\r\n        output_data = output.data.float_data()\r\n\r\n        b = np.array(output_data)\r\n        if b.shape[0] < 6:\r\n            print(\"No object found.\")\r\n            return\r\n\r\n        bboxes = b.reshape([-1, 6])\r\n        bboxes = bboxes[bboxes[:, 1] > self.det_thresh]\r\n\r\n        cls_ids = bboxes[:, 0].astype('int32')\r\n        cls_conf = bboxes[:, 1].astype('float32')\r\n        boxes = bboxes[:, 2:].astype('float32')\r\n\r\n        bbox_xcycwh = boxes\r\n        bbox_xcycwh[:, 2] = (boxes[:, 2] - boxes[:, 0])\r\n        bbox_xcycwh[:, 3] = (boxes[:, 3] - boxes[:, 1])\r\n\r\n\r\n        if bbox_xcycwh is not None:\r\n            # select class person\r\n            mask = cls_ids == 0\r\n            bbox_xcycwh = bbox_xcycwh[mask]\r\n\r\n        if bboxes.shape[1] != 6:\r\n            print(\"No object found after det_thresh.\")\r\n            return\r\n        \r\n        return bbox_xcycwh\r\n```\r\n\r\nTypeError: can't pickle paddle.fluid.core_avx.AnalysisPredictor objects",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-10-23T06:10:43+00:00",
        "updated_at": "2019-10-24T10:13:08+00:00",
        "closed_at": null,
        "comments_count": [
            "mozpp",
            "fc500110"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3727,
        "title": "Transformer based neural machine translation for high-performance inference",
        "body": "Hi, I notice that you have released Transformer based NMT model at https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/neural_machine_translation/transformer. Excellent work!!!\r\n\r\nI want to try the current model in production which has high QPS requirement. I wonder if PaddlePaddle has any plan to release a Transformer based NMT model for high performance inference, just like what you have done for PaddleDetection (https://github.com/PaddlePaddle/models/pull/3529).\r\n\r\nAny help will be appreciated.",
        "state": "closed",
        "user": "xptree",
        "closed_by": "xptree",
        "created_at": "2019-10-23T06:35:43+00:00",
        "updated_at": "2019-10-24T11:36:09+00:00",
        "closed_at": "2019-10-24T11:31:34+00:00",
        "comments_count": [
            "xptree",
            "guoshengCS",
            "xptree"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3730,
        "title": "使用PaddleDetection进行模型训练出现cudaGetLastError",
        "body": "Hi，\r\n        我在使用faster rcnn/ssd训练非公开数据集时，会出现‘cudaGetLastError’报错，请问可能是什么原因呢？\r\n       示例如下：使用修改后的faster_rcnn_r50_fpn_1x的配置文件（优化器使用adadelat），会出现以下情况：【注：调小学习率可能会避免这种情况，但是模型收敛效果不能保证】\r\n![image](https://user-images.githubusercontent.com/46473363/67368406-dbf42700-f5a9-11e9-8935-57492086aee9.png)\r\n",
        "state": "closed",
        "user": "ronghaoLee",
        "closed_by": "ronghaoLee",
        "created_at": "2019-10-23T07:30:40+00:00",
        "updated_at": "2019-10-28T13:05:28+00:00",
        "closed_at": "2019-10-28T13:05:28+00:00",
        "comments_count": [
            "qingqing01",
            "jerrywgz",
            "ronghaoLee"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3729,
        "title": "多进程训练时内存占用过高导致训练程序崩溃",
        "body": "使用近期更新的models/PaddleCV/image_classification中的多进程训练进行训练时，在validate过程中会出现内存迅速占满128G导致程序崩溃问题，之前在训练的时候就已经占很高了，我的训练环境及参数是:\r\n自己的数据34万张图\r\nbatchsize 120\r\n3张tesla v100\r\n128G内存\r\npy_reader的容量为4\r\nreader_thread为6\r\nreader_bufsize为1024\r\ntrain_num为3\r\n请问应该如何调整参数，以使训练时内存占用不会过大?",
        "state": "closed",
        "user": "Yogurt2019",
        "closed_by": "Yogurt2019",
        "created_at": "2019-10-23T07:22:54+00:00",
        "updated_at": "2019-11-07T08:30:50+00:00",
        "closed_at": "2019-11-07T08:30:50+00:00",
        "comments_count": [
            "Yogurt2019",
            "wanghaoshuang",
            "Yogurt2019",
            "Yogurt2019",
            "wanghaoshuang",
            "Yogurt2019"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3731,
        "title": "使用faster_rcnn_dcn_r50_vd_fpn_2x_voc转tensorrt后，infer报错",
        "body": "在使用tensorrt的方法做faster_rcnn_dcn_r50_vd_fpn_2x_voc的infer时会出现下面的问题\r\n<img width=\"1326\" alt=\"MacHi 2019-10-23 16-33-19\" src=\"https://user-images.githubusercontent.com/5838111/67373827-dd761d00-f5b2-11e9-89dc-5f5e5c245c7a.png\">\r\n\r\n环境：\r\ntensorrt 5.1\r\ncuda9.0\r\npaddle1.5",
        "state": "closed",
        "user": "pangr",
        "closed_by": "pangr",
        "created_at": "2019-10-23T08:31:35+00:00",
        "updated_at": "2019-10-24T07:37:12+00:00",
        "closed_at": "2019-10-24T07:37:12+00:00",
        "comments_count": [
            "qingqing01",
            "pangr",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3737,
        "title": "generative_paddle run error",
        "body": "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  **import imp\r\nstage 0\r\nTraceback (most recent call last):\r\n  File \"network.py\", line 529, in <module>\r\n    train(config)\r\n  File \"network.py\", line 480, in train\r\n    optimizer.minimize(bow_loss)**\r\n  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-20>\", line 2, in minimize\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 87, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 594, in minimize\r\n    no_grad_set=no_grad_set)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 493, in backward\r\n    no_grad_set, callbacks)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/backward.py\", line 578, in append_backward\r\n    _append_backward_vars_(root_block, fwd_op_num, grad_to_var, grad_info_map)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/backward.py\", line 392, in _append_backward_vars_\r\n    op_desc.infer_shape(block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: Enforce failed. Expected x_dims[i] * expand_times[i] == out_dims[i], but received x_dims[i] * expand_times[i]:-500 != out_dims[i]:-1.\r\nEach dimension size of Input(Out@GRAD) should be equal to multiplication of crroresponding dimension size of Input(X) and Attr(expand_times) value. at [/paddle/paddle/fluid/operators/expand_op.cc:153]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f9b41b3dc28p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7f9b41b3df77p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7f9b42186401p paddle::operators::ExpandGradOp::InferShape(paddle::framework::InferShapeContext*) const + 1425\r\n3       0x7f9b41ca4d2ep paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 862\r\n4       0x7f9b41be0afcp\r\n5       0x7f9b41b6caf6p\r\n6       0x55a5eecfa744p _PyMethodDef_RawFastCallKeywords + 596\r\n7       0x55a5eecfa861p _PyCFunction_FastCallKeywords + 33\r\n8       0x55a5eed666e8p _PyEval_EvalFrameDefault + 21240\r\n9       0x55a5eecf9ccbp _PyFunction_FastCallKeywords + 251\r\n10      0x55a5eed61806p _PyEval_EvalFrameDefault + 1046\r\n11      0x55a5eecaa539p _PyEval_EvalCodeWithName + 761\r\n12      0x55a5eecf9ef5p _PyFunction_FastCallKeywords + 805\r\n13      0x55a5eed61806p _PyEval_EvalFrameDefault + 1046\r\n14      0x55a5eecaa539p _PyEval_EvalCodeWithName + 761\r\n15      0x55a5eecf9f57p _PyFunction_FastCallKeywords + 903\r\n16      0x55a5eed628ccp _PyEval_EvalFrameDefault + 5340\r\n17      0x55a5eecaa539p _PyEval_EvalCodeWithName + 761\r\n18      0x55a5eecab635p _PyFunction_FastCallDict + 469\r\n19      0x55a5eed63232p _PyEval_EvalFrameDefault + 7746\r\n20      0x55a5eecaa81ap _PyEval_EvalCodeWithName + 1498\r\n21      0x55a5eecab635p _PyFunction_FastCallDict + 469\r\n22      0x55a5eed63232p _PyEval_EvalFrameDefault + 7746\r\n23      0x55a5eecaa81ap _PyEval_EvalCodeWithName + 1498\r\n24      0x55a5eecf9f57p _PyFunction_FastCallKeywords + 903\r\n25      0x55a5eed61806p _PyEval_EvalFrameDefault + 1046\r\n26      0x55a5eecaa539p _PyEval_EvalCodeWithName + 761\r\n27      0x55a5eecf9ef5p _PyFunction_FastCallKeywords + 805\r\n28      0x55a5eed61a93p _PyEval_EvalFrameDefault + 1699\r\n29      0x55a5eecf9ccbp _PyFunction_FastCallKeywords + 251\r\n30      0x55a5eed61806p _PyEval_EvalFrameDefault + 1046\r\n31      0x55a5eecaa539p _PyEval_EvalCodeWithName + 761\r\n32      0x55a5eecab424p PyEval_EvalCodeEx + 68\r\n33      0x55a5eecab44cp PyEval_EvalCode + 28\r\n34      0x55a5eedc0b74p\r\n35      0x55a5eedcaeb1p PyRun_FileExFlags + 161\r\n36      0x55a5eedcb0a3p PyRun_SimpleFileExFlags + 451\r\n37      0x55a5eedcc195p\r\n38      0x55a5eedcc2bcp _Py_UnixMain + 60\r\n39      0x7f9b60115830p __libc_start_main + 240\r\n40      0x55a5eed71062p",
        "state": "open",
        "user": "universea",
        "closed_by": null,
        "created_at": "2019-10-23T15:37:05+00:00",
        "updated_at": "2019-10-24T10:15:30+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "cchan19",
            "cchan19"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3738,
        "title": " 转换预训练参数在paddlepaddle下使用",
        "body": "请问下楼主有什么方法可以将pytorch或者tf的weights转换成paddlepaddle的格式吗？ 谢谢",
        "state": "open",
        "user": "yyaaa1",
        "closed_by": null,
        "created_at": "2019-10-23T22:19:58+00:00",
        "updated_at": "2019-10-24T10:15:49+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3745,
        "title": "请问Paddle 1.6什么时候发布",
        "body": "如标题。",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2019-10-24T08:13:09+00:00",
        "updated_at": "2019-10-25T02:30:58+00:00",
        "closed_at": "2019-10-25T02:30:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3739,
        "title": "Pose estimation seems to work only for single person",
        "body": "https://github.com/PaddlePaddle/models/blob/8aa202ade1a142d6476a67a65baf8160ad9e4b70/PaddleCV/human_pose_estimation/utils/utility.py#L341\r\n\r\n@qingqing01  @KaiyuYue This postprocessing operation only gets max keypoints prediction from the heatmap. What if there are multiple persons? Is there any way to get multi-person pose?",
        "state": "closed",
        "user": "xueeinstein",
        "closed_by": "xueeinstein",
        "created_at": "2019-10-24T01:59:42+00:00",
        "updated_at": "2019-10-31T03:40:51+00:00",
        "closed_at": "2019-10-31T03:40:51+00:00",
        "comments_count": [
            "Noplz",
            "xueeinstein"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3744,
        "title": "fluid中是否有nll_criterion计算？",
        "body": "需求中需要自己搭建loss，其中之前在pytorch上使用了nll_criterion，请问在paddle上是否有这种算子？\r\n另外问一下有没有类似pytorch的masked_select这种方法？谢谢！",
        "state": "closed",
        "user": "Yogurt2019",
        "closed_by": "Yogurt2019",
        "created_at": "2019-10-24T07:49:45+00:00",
        "updated_at": "2019-10-30T07:50:54+00:00",
        "closed_at": "2019-10-30T07:50:54+00:00",
        "comments_count": [
            "LielinJiang",
            "Yogurt2019"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3762,
        "title": "lexical_analysis中sh run_ernie.sh eval报错",
        "body": "![image](https://user-images.githubusercontent.com/29849325/67542310-cd7b4c00-f71e-11e9-9777-2ca33259ae02.png)\r\n",
        "state": "open",
        "user": "flytoylf",
        "closed_by": null,
        "created_at": "2019-10-25T03:59:54+00:00",
        "updated_at": "2019-10-28T07:51:43+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus",
            "flytoylf"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3747,
        "title": "compress.py 压缩报错",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/PaddleDetection/slim/quantization/compress.py\r\n运行:\r\n!python compress.py \\\r\n                    -s yolov3_mobilenet_v1_slim.yaml \\\r\n                    -c yolov3_mobilenet_v1_voc.yml\r\n错误日志:\r\nTraceback (most recent call last):\r\n  File \"compress.py\", line 50, in <module>\r\n    from ppdet.utils.check import check_gpu, check_version\r\nImportError: cannot import name 'check_version' from 'ppdet.utils.check' (../../ppdet/utils/check.py)",
        "state": "closed",
        "user": "aixier",
        "closed_by": "Superjomn",
        "created_at": "2019-10-24T08:37:00+00:00",
        "updated_at": "2019-10-29T10:14:33+00:00",
        "closed_at": "2019-10-29T10:14:33+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3768,
        "title": "PaddleDetection数据transform这个地方代码有问题吧",
        "body": "这地方代码有些问题吧\r\nhttps://github.com/PaddlePaddle/models/blob/361e10fb542c2c90966f8ee77a411d7e21c88932/PaddleCV/PaddleDetection/ppdet/data/transform/__init__.py#L70\r\n\r\n用format时{是转义，'{{}}'输出的就是'{}了\r\n代码应该是\r\n```python\r\n  op_repr.append('{{{}}}'.format(str(o)))  # or op_repr.append('{}'.format(str(o)))\r\n```\r\n![image](https://user-images.githubusercontent.com/10208305/67550554-4dd98700-f6f6-11e9-985f-ec120c10654e.png)\r\n",
        "state": "closed",
        "user": "wangxicoding",
        "closed_by": "qingqing01",
        "created_at": "2019-10-25T07:09:16+00:00",
        "updated_at": "2019-10-25T09:34:43+00:00",
        "closed_at": "2019-10-25T09:34:43+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3772,
        "title": "Deformable Convolutional Networks",
        "body": "> 您好,  model 库中 有paddle版的Deformable Convolutional Networks吗",
        "state": "closed",
        "user": "geng007",
        "closed_by": "qingqing01",
        "created_at": "2019-10-25T08:14:24+00:00",
        "updated_at": "2019-11-07T11:41:00+00:00",
        "closed_at": "2019-11-07T11:41:00+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3778,
        "title": "cascade rcnn、",
        "body": "",
        "state": "closed",
        "user": "ShenChen96",
        "closed_by": "ShenChen96",
        "created_at": "2019-10-26T05:04:17+00:00",
        "updated_at": "2019-10-26T05:04:38+00:00",
        "closed_at": "2019-10-26T05:04:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3773,
        "title": "用自己的VOC数据训练Cascade RCNN",
        "body": "我已经将Config cascade_rcnn_r50_fpn_1x.yml中相应的参数设置为：\r\n\r\nmetric: VOC\r\n\r\nFasterRCNNTrainFeed:\r\n  batch_size: 1\r\n  dataset:\r\n    dataset_dir: dataset/voc\r\n    annotation: VOCdevkit/VOC_all/ImageSets/Main/train.txt\r\n    image_dir: VOCdevkit/VOC_all/JPEGImages\r\n  batch_transforms:\r\n  - !PadBatch\r\n    pad_to_stride: 32\r\n  drop_last: false\r\n  num_workers: 2\r\n\r\nFasterRCNNEvalFeed:\r\n  batch_size: 1\r\n  dataset:\r\n    dataset_dir: dataset/voc\r\n    annotation: VOCdevkit/VOC_all/ImageSets/Main/val.txt\r\n    image_dir: VOCdevkit/VOC_all/JPEGImages\r\n  batch_transforms:\r\n  - !PadBatch\r\n    pad_to_stride: 32\r\n\r\nFasterRCNNTestFeed:\r\n  batch_size: 1\r\n  dataset:\r\n    annotation: VOCdevkit/VOC_all/ImageSets/Main/test.txt\r\n  batch_transforms:\r\n可是在使用脚本python tools/train.py -c configs/cascade_rcnn_r50_fpn_1x.yml训练时报错显示：\r\n consumer failed with error: failed to map consumer[%s], error: [Errno 2] No such file or directory: 'dataset/voc/VOCdevkit/VOC_all/JPEGImages/15524713780796.json'\r\n请问，使用自己的VOC数据训练CascadeRCNN我还需要修改哪些内容。\r\n",
        "state": "closed",
        "user": "ShenChen96",
        "closed_by": "qingqing01",
        "created_at": "2019-10-25T08:23:14+00:00",
        "updated_at": "2019-11-04T02:49:29+00:00",
        "closed_at": "2019-11-04T02:49:29+00:00",
        "comments_count": [
            "qingqing01",
            "ShenChen96",
            "ShenChen96",
            "qingqing01",
            "ShenChen96"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3779,
        "title": "关于PLATO训练过程中负样本的构造问题",
        "body": "从源代码上看(https://github.com/PaddlePaddle/models/blob/release/1.6/PaddleNLP/Research/Dialogue-PLATO/models/unified_transformer.py#L326)，负样本的构造貌似是直接将正样本做了个反转？\r\n如果是这样的话，基于反转构造的负样本会不会太简单了，导致这是个trivial loss？\r\n",
        "state": "closed",
        "user": "jiqiujia",
        "closed_by": "jiqiujia",
        "created_at": "2019-10-26T06:31:41+00:00",
        "updated_at": "2019-10-28T14:33:57+00:00",
        "closed_at": "2019-10-28T14:33:57+00:00",
        "comments_count": [
            "sserdoubleh",
            "jiqiujia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3780,
        "title": "lac模型保存问题",
        "body": "根据 https://github.com/PaddlePaddle/models/tree/release/1.6/PaddleNLP/lexical_analysis#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98\r\n\r\n如果想保存 `ERNIE finetuned model` 是否是如下命令？\r\n`python inference_model.py --init_checkpoint ./model_finetuned --inference_save_dir ./inference_model` \r\n\r\n下图是我使用 ERNIE finetuned model 调用   inference_model.py 后的结果，请问是哪里出了问题吗？\r\n![QQ截图20191027181019](https://user-images.githubusercontent.com/13502799/67632981-27c60980-f8e5-11e9-941d-74a14b483f3e.png)\r\n\r\n我使用的是 release1.6分支。麻烦帮忙看看，十分感谢!!\r\n\r\n",
        "state": "open",
        "user": "loserdog-err",
        "closed_by": null,
        "created_at": "2019-10-27T10:09:44+00:00",
        "updated_at": "2020-03-02T05:42:25+00:00",
        "closed_at": null,
        "comments_count": [
            "Bond-H",
            "loserdog-err",
            "Vvegetables"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3782,
        "title": "where is PaddleMT",
        "body": "PaddleMT is 404",
        "state": "open",
        "user": "ares5221",
        "closed_by": null,
        "created_at": "2019-10-28T02:24:24+00:00",
        "updated_at": "2019-10-31T11:31:38+00:00",
        "closed_at": null,
        "comments_count": [
            "tensor-tang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3784,
        "title": "paddleDetection训练模型时，报错并终止训练",
        "body": "在训练中途显示报错：\r\nValueError: all consumers exited, no more samples\r\n\r\n2019-10-28 12:36:37,664-INFO: iter: 920, lr: 0.001000, 'loss_cls_0': '0.484241', 'loss_cls_2': '0.106703', 'loss_rpn_bbox': 'nan', 'loss_cls_1': '0.233949', 'loss_rpn_cls': '0.246742', 'loss_loc_1': '0.219890', 'loss': 'nan', 'loss_loc_2': '0.042145', 'loss_loc_0': '0.321073', time: 0.246, eta: 6:05:22\r\n2019-10-28 12:36:42,503-INFO: iter: 940, lr: 0.001000, 'loss_cls_0': '0.667223', 'loss_cls_2': '0.101810', 'loss_rpn_bbox': '0.195698', 'loss_cls_1': '0.243394', 'loss_rpn_cls': '0.176546', 'loss_loc_1': '0.315209', 'loss': '2.159427', 'loss_loc_2': '0.075595', 'loss_loc_0': '0.365450', time: 0.238, eta: 5:52:37\r\n2019-10-28 12:36:47,423-INFO: iter: 960, lr: 0.001000, 'loss_cls_0': '0.503310', 'loss_cls_2': '0.108281', 'loss_rpn_bbox': 'nan', 'loss_cls_1': '0.239438', 'loss_rpn_cls': '0.143339', 'loss_loc_1': '0.274694', 'loss': 'nan', 'loss_loc_2': '0.095471', 'loss_loc_0': '0.394992', time: 0.244, eta: 6:02:17\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 338, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 244, in main\r\n    outs = exe.run(compiled_train_prog, fetch_list=train_values)\r\n  File \"/home/wzj/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 672, in run\r\n    return_numpy=return_numpy)\r\n  File \"/home/wzj/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 534, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:92]\r\n\r\n我检查了我的数据集，似乎是没有问题的。不知道为啥会这样",
        "state": "open",
        "user": "ShenChen96",
        "closed_by": null,
        "created_at": "2019-10-28T04:59:44+00:00",
        "updated_at": "2019-11-07T11:44:45+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3790,
        "title": "paddle slim模型保存在哪里？",
        "body": "用paddle slim例子 做模型蒸馏训练，五个小时训练完成，中间没有日志，最后模型也没有保存，请问是什么原因？",
        "state": "closed",
        "user": "1145520074",
        "closed_by": "baiyfbupt",
        "created_at": "2019-10-28T08:04:49+00:00",
        "updated_at": "2019-10-29T08:36:04+00:00",
        "closed_at": "2019-10-29T08:36:04+00:00",
        "comments_count": [
            "wanghaoshuang",
            "1145520074",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3793,
        "title": "再提问一次，求解答：lexical_analysis中sh run_ernie.sh eval报错",
        "body": "![image](https://user-images.githubusercontent.com/29849325/67677781-e6eef300-f9bf-11e9-83ee-b7b3477a09d2.png)\r\n没有任何改动，就是按照README中的步骤傻瓜式执行的，sh run.sh eval是可以跑通的",
        "state": "open",
        "user": "flytoylf",
        "closed_by": null,
        "created_at": "2019-10-28T12:17:23+00:00",
        "updated_at": "2019-10-28T14:19:13+00:00",
        "closed_at": null,
        "comments_count": [
            "loserdog-err"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3798,
        "title": "cannot import name 'ColorTTY'",
        "body": "按照官网安装教程安装的都没有问题，pip install -r requirements.txt 需要的依赖也都装了。\r\n在跑示例的时候，可以正常训练，但是Infer的时候就不行了。\r\npython -u tools/infer.py -c configs/yolov3_mobilenet_v1_fruit.yml --infer_img=demo/orange_71.jpg -o output/yolov3_mobilenet_v1_fruit.tar\r\n提示报错。\r\n File \"/home/wjf/models-develop/PaddleCV/PaddleDetection/ppdet/core/config/schema.py\", line 29, in doc_parse\r\n    from ppdet.utils.cli import ColorTTY\r\nImportError: cannot import name 'ColorTTY'\r\n求解答，谢谢\r\n",
        "state": "open",
        "user": "Wzj02200059",
        "closed_by": null,
        "created_at": "2019-10-29T03:45:50+00:00",
        "updated_at": "2019-10-31T04:09:54+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz",
            "qingqing01",
            "qingqing01",
            "Wzj02200059",
            "qingqing01",
            "Wzj02200059"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3803,
        "title": "data/dataset/youtube8m将tfrecord转为pkl",
        "body": "当文件较多时，后面的转换速度会越来越慢，有没有好的处理方式？tf2pkl.py",
        "state": "open",
        "user": "liuzhijie03",
        "closed_by": null,
        "created_at": "2019-10-29T12:08:09+00:00",
        "updated_at": "2020-05-09T10:11:07+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "haoyijiang"
        ],
        "labels": [
            "help wanted"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3807,
        "title": "Non-local",
        "body": "> 您好\r\n>>  请教您 : 我理解 non local 的 paper 是每隔1帧取1帧得到的最终 video_length\r\n>>>paddle 的 non local 中的nonlocal.txt , 设置 video_length = 8 和sample_rate = 1得到的每个视频的帧数 连续的 8 帧, 是否是网络的输入呢\r\n>>> ![image](https://user-images.githubusercontent.com/38428867/67786443-d74bd900-faa9-11e9-9fb1-a6067b76ae33.png)\r\n>>> ![image](https://user-images.githubusercontent.com/38428867/67786549-06fae100-faaa-11e9-9373-100d214d55a2.png)\r\n\r\n",
        "state": "open",
        "user": "geng007",
        "closed_by": null,
        "created_at": "2019-10-29T16:17:19+00:00",
        "updated_at": "2019-11-07T12:10:53+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3828,
        "title": "How to run BERT model correctly and interpret results?",
        "body": "Hi,\r\n\r\nI have a question regarding BERT model. I use the model from this repository and run it with parameters you suggest, I run the `pretraining` stage, so I use `train.py` script. I only change batch size and max_seq_len parameters, but config and every other parameter is the same as recommended.  \r\n\r\n1. Now my question is - how to interpret the results? For example if I run with batch_size 1024 and I get the following output:\r\n```\r\nepoch: 4, progress: 1/1, step: 8720, loss: 8.089045, ppl: 1050.821289, next_sent_acc: 0.250000, speed: 5.793753 steps/s, file: demo_wiki_train.gz\r\n```\r\ndoes that mean that BERT processed `1024 * 5.79` sentences per second? Or just `5.79` sentences per second? What does this `step` mean in that context?\r\n\r\n2. Second question - why can't I set `batch_size` smaller that `max_seq_len`? I would like to run some tests on batch 8 for example but I cannot do that. \r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 449, in <module>\r\n    train(args)\r\n  File \"train.py\", line 270, in train\r\n    batch_size=args.batch_size // args.max_seq_len)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/contrib/memory_usage_calc.py\", line 75, in memory_usage\r\n    raise ValueError(\"The batch size need to be positive.\")\r\nValueError: The batch size need to be positive.\r\n```\r\nI don't understand why this is the case. In other DL frameworks I can run whatever batch I want regardless of max_seq_len.\r\n\r\n3. Last question - why doesn't fp16 speed things up? When I run `batch_size=512, max_seq_len=128` with fp32 I get roughly 18-20 `steps/s`, then when I use `--use_fp16=true` I get the same numbers. Is this desired behavior? I use NVIDIA V100 16GB. I see now that for larger batch_size it does indeed speed things up a bit and less memory is used.\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2019-10-30T12:17:41+00:00",
        "updated_at": "2019-10-31T11:48:40+00:00",
        "closed_at": "2019-10-31T11:48:40+00:00",
        "comments_count": [],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3819,
        "title": "ARNOR模型代码什么时候开源呢",
        "body": "ARNOR模型代码什么时候开源呢",
        "state": "open",
        "user": "dhName",
        "closed_by": null,
        "created_at": "2019-10-30T08:15:57+00:00",
        "updated_at": "2019-10-31T11:30:01+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3826,
        "title": "期待更新Gaussian loss",
        "body": "https://github.com/jwchoi384/Gaussian_YOLOv3",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-10-30T11:48:00+00:00",
        "updated_at": "2019-11-04T02:54:23+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3838,
        "title": "Add dialogue_domain_classification Model",
        "body": "",
        "state": "open",
        "user": "aprilvkuo",
        "closed_by": null,
        "created_at": "2019-10-31T05:00:06+00:00",
        "updated_at": "2019-10-31T05:00:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3829,
        "title": "models-develop版本的inference跑yolov3模型出错",
        "body": "按照https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/PaddleDetection/inference\r\n上的指引去做，linux平台和windows平台都试了下，自带的模型可以，但是用paddlehub上下下来的yolov3_coco2017，就跑出错，是不是对yolov3的支持都不太好？或者没有测试过？",
        "state": "closed",
        "user": "spiritsky123",
        "closed_by": "qingqing01",
        "created_at": "2019-10-31T01:51:05+00:00",
        "updated_at": "2019-11-04T07:34:53+00:00",
        "closed_at": "2019-11-04T07:34:53+00:00",
        "comments_count": [
            "jerrywgz",
            "spiritsky123",
            "jerrywgz",
            "spiritsky123",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3847,
        "title": "吐槽",
        "body": "paddle model写的有点。。，各种回调，封装也就算了，但正常实现一个pr\\f1指标的实现，会发现目前的run_classify.py的各种判断（train\\dev\\test\\infer），main函数写的一堆代码，真的。。；我看懂了aistudio的pr\\f1指标的计算，各种变量参数传递，debug通了都不想按照demo的方式去做，自己实现一个pr\\f1指标的计算，你们底层借鉴人家sklearn的metrics计算，自己对外输出是否应该友好一些呢？",
        "state": "closed",
        "user": "shiwl0329",
        "closed_by": "shiwl0329",
        "created_at": "2019-10-31T08:18:39+00:00",
        "updated_at": "2019-10-31T08:19:00+00:00",
        "closed_at": "2019-10-31T08:19:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3841,
        "title": "DeepFM-loss正常收敛，但auc_val一直都是0.00000",
        "body": "",
        "state": "open",
        "user": "guomq1",
        "closed_by": "guomq1",
        "created_at": "2019-10-31T06:13:08+00:00",
        "updated_at": "2019-12-04T08:22:18+00:00",
        "closed_at": null,
        "comments_count": [
            "guomq1",
            "wilhelmzh",
            "guomq1",
            "shuDaoNan9",
            "shuDaoNan9"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3851,
        "title": "TSM",
        "body": "> 您好\r\n>> 请教个问题\r\n>>> 我将paddle [目标检测的dcn模块](https://github.com/PaddlePaddle/models/blob/bdcdf79da97b868ad2b50c5f8f7583d4ab7a807d/PaddleCV/PaddleDetection/ppdet/modeling/backbones/resnet.py#L37)搬到TSM的[tsm_res_model.py](https://github.com/gentelyang/models-develop/blob/e368f5375e1e7d5865fdc7cabc8676ead1e351fd/PaddleCV/video/models/tsm/tsm_res_model.py#L22)中,  原版paddle版的 tsm代码的top1_acc 由 70 变成了 25, 假设我加 dcn 后的resnet 50  没搭错, 是否有可能是TSM网络等其他方面的原因导致不work呢?\r\n>>>>  感谢答疑",
        "state": "closed",
        "user": "geng007",
        "closed_by": "geng007",
        "created_at": "2019-10-31T12:05:28+00:00",
        "updated_at": "2019-10-31T15:08:05+00:00",
        "closed_at": "2019-10-31T13:59:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3843,
        "title": "dialogue_general_understanding 是否支持ERNIE中文预训练模型",
        "body": "dialogue_general_understanding 是否支持ERNIE中文预训练模型？\r\n文档中写的支持的预训练模型中只列出来了ERNIE, english。没有ERNIE, chinese,不知是否支持。\r\n",
        "state": "closed",
        "user": "linuxsong",
        "closed_by": "jerrywgz",
        "created_at": "2019-10-31T07:08:02+00:00",
        "updated_at": "2019-12-20T13:22:35+00:00",
        "closed_at": "2019-12-20T13:22:35+00:00",
        "comments_count": [
            "jerrywgz",
            "linuxsong",
            "jerrywgz",
            "linuxsong",
            "jerrywgz",
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3856,
        "title": "关于ARNOR",
        "body": "请问ARNOR代码会开源吗？我在数据集中发现了数据泄露的问题，想用代码上验证一下",
        "state": "open",
        "user": "shentielin",
        "closed_by": null,
        "created_at": "2019-11-01T07:36:52+00:00",
        "updated_at": "2019-11-08T07:05:36+00:00",
        "closed_at": null,
        "comments_count": [
            "kahitomi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3862,
        "title": "win10无法运行yolov3！",
        "body": "首先是我的环境配置\r\n1）PaddlePaddle版本：paddlepaddle-gpu，1.6.0.post107\r\n2）使用GPU进行训练，CUDA10，cuDNN,7.3\r\n3）系统环境：WIN10\r\n\r\n跑官网下载的yolov3目标检测算法报错，报错信息：\r\nWARNING:root:paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\nFound 2 CUDA devices.\r\nW1103 20:15:19.473218 8236 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW1103 20:15:19.535706 8236 device_context.cc:243] device: 0, cuDNN Version: 7.3.\r\nloading annotations into memory...\r\nDone (t=0.11s)\r\ncreating index...\r\nindex created!\r\nLoad in 1 categories.\r\nC:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py:774: UserWarning: The following exception is not an EOF exception.\r\n\"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 219, in\r\ntrain(cfg)\r\nFile \"train.py\", line 180, in train\r\nfetch_list=[v.name for v in fetch_list])\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 775, in run\r\nsix.reraise(*sys.exc_info())\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\six.py\", line 693, in reraise\r\nraise value\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 770, in run\r\nuse_program_cache=use_program_cache)\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 819, in _run_impl\r\nprogram._compile(scope, self.place)\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\compiler.py\", line 392, in _compile\r\nplaces=self._places)\r\nFile \"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\compiler.py\", line 355, in _compile_data_parallel\r\nself._exec_strategy, self._build_strategy, self._graph)\r\npaddle.fluid.core_avx.EnforceNotMet: Windows not support stack backtrace yet.PaddleCheckError: Windows can support Single GPU only. at [D:\\1.6.0\\paddle\\paddle\\fluid\\framework\\parallel_executor.cc:417]\r\n\r\n试了多次都不行，求助！",
        "state": "open",
        "user": "shengyuqing",
        "closed_by": null,
        "created_at": "2019-11-03T12:30:22+00:00",
        "updated_at": "2019-11-27T09:14:43+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "zhaotun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3867,
        "title": "fluid1.5.0 mobilenetSSD nms输出坐标不在0-1之间",
        "body": "硬件环境：GPU v100\r\n软件环境：fluid1.5.0 ，batch=12, input_size=640\r\n问题：用fluid1.5.0 mobilenetSSD640训练模型时，训练集mAP1.0,测试集0.0;打印fluid.layers.detection_output 结果，发现很多坐标超出0-1范围, 请问detection_output内部会限制0-1范围吗？为什么会出现这种情况？\r\nlodTensor转Numpy输出结果：\r\n![image](https://user-images.githubusercontent.com/20673237/68101009-5e63db80-ff06-11e9-90d3-0bdbea9aedba.png)\r\n",
        "state": "closed",
        "user": "ellinyang",
        "closed_by": "qingqing01",
        "created_at": "2019-11-04T05:11:28+00:00",
        "updated_at": "2019-11-05T04:09:00+00:00",
        "closed_at": "2019-11-05T04:09:00+00:00",
        "comments_count": [
            "qingqing01",
            "ellinyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3871,
        "title": "sentiment_classification跑不到给出的结果",
        "body": "你好\r\n[文档](https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/sentiment_classification) 中给出的实验结果准确率在90%左右，我理解的是表格中的结果左边是没用预训练，右边用了预训练；但是我用目前的代码只能跑到70%左右，然后devloss就开始上涨了，默认参数基本上没有改动，只是把batch_size改成了32，希望能够帮忙看一下问题出在哪里了。\r\n以下是部分日志，dev loss最低的时候大概为0.62：\r\n[dev evaluation] ave loss: 0.648370, ave acc: 0.710833, elapsed time: 1.372104 s\r\nstep: 7860, ave loss: 0.330971, ave acc: 0.843750, speed: 3.124809 steps/s\r\nstep: 7870, ave loss: 0.449688, ave acc: 0.687500, speed: 5.640100 steps/s\r\nstep: 7880, ave loss: 0.437291, ave acc: 0.656250, speed: 5.932377 steps/s\r\nstep: 7890, ave loss: 0.399466, ave acc: 0.875000, speed: 6.088658 steps/s\r\nstep: 7900, ave loss: 0.367463, ave acc: 0.906250, speed: 6.215408 steps/s\r\ndo evalatation\r\n[dev evaluation] ave loss: 0.647289, ave acc: 0.706667, elapsed time: 1.353274 s\r\nstep: 7910, ave loss: 0.358904, ave acc: 0.812500, speed: 3.332746 steps/s\r\nstep: 7920, ave loss: 0.398318, ave acc: 0.781250, speed: 6.083976 steps/s\r\nstep: 7930, ave loss: 0.325438, ave acc: 0.906250, speed: 3.674678 steps/s\r\nstep: 7940, ave loss: 0.315872, ave acc: 0.843750, speed: 5.414906 steps/s\r\nstep: 7950, ave loss: 0.315895, ave acc: 0.875000, speed: 5.962798 steps/s\r\ndo evalatation\r\n[dev evaluation] ave loss: 0.647060, ave acc: 0.707500, elapsed time: 1.633162 s\r\nstep: 7960, ave loss: 0.524899, ave acc: 0.687500, speed: 2.950875 steps/s\r\nstep: 7970, ave loss: 0.454106, ave acc: 0.812500, speed: 5.759536 steps/s\r\nstep: 7980, ave loss: 0.245226, ave acc: 0.937500, speed: 6.064020 steps/s\r\nstep: 7990, ave loss: 0.312347, ave acc: 0.843750, speed: 6.042671 steps/s\r\nstep: 8000, ave loss: 0.327485, ave acc: 0.843750, speed: 4.937799 steps/s\r\ndo evalatation\r\n[dev evaluation] ave loss: 0.649432, ave acc: 0.709167, elapsed time: 1.446141 s\r\nstep: 8010, ave loss: 0.269960, ave acc: 0.906250, speed: 3.160801 steps/s\r\nstep: 8020, ave loss: 0.310272, ave acc: 0.812500, speed: 6.020429 steps/s\r\nstep: 8030, ave loss: 0.374136, ave acc: 0.750000, speed: 5.688697 steps/s\r\nstep: 8040, ave loss: 0.432397, ave acc: 0.781250, speed: 6.041522 steps/s\r\nstep: 8050, ave loss: 0.366272, ave acc: 0.843750, speed: 6.063380 steps/s\r\ndo evalatation\r\n[dev evaluation] ave loss: 0.651746, ave acc: 0.710000, elapsed time: 1.460297 s\r\nstep: 8060, ave loss: 0.431585, ave acc: 0.750000, speed: 3.163170 steps/s\r\nstep: 8070, ave loss: 0.365779, ave acc: 0.750000, speed: 5.453197 steps/s\r\nstep: 8080, ave loss: 0.406466, ave acc: 0.781250, speed: 5.655510 steps/s\r\nstep: 8090, ave loss: 0.314121, ave acc: 0.875000, speed: 5.909949 steps/s\r\nstep: 8100, ave loss: 0.357805, ave acc: 0.875000, speed: 6.067416 steps/s\r\ndo evalatation\r\n[dev evaluation] ave loss: 0.651485, ave acc: 0.706667, elapsed time: 1.423898 s\r\nstep: 8110, ave loss: 0.330592, ave acc: 0.843750, speed: 3.281906 steps/s\r\nstep: 8120, ave loss: 0.406624, ave acc: 0.781250, speed: 4.848600 steps/s\r\nstep: 8130, ave loss: 0.274350, ave acc: 0.875000, speed: 5.724158 steps/s\r\n",
        "state": "closed",
        "user": "isofun",
        "closed_by": "ChinaLiuHao",
        "created_at": "2019-11-04T13:32:25+00:00",
        "updated_at": "2019-11-13T02:12:38+00:00",
        "closed_at": "2019-11-13T02:12:23+00:00",
        "comments_count": [
            "ChinaLiuHao",
            "isofun",
            "ChinaLiuHao",
            "ChinaLiuHao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3874,
        "title": "ModuleNotFoundError: No module named '_sqlite3‘",
        "body": "在一个server里安装了paddle，在import paddle, 就出现了这个错误。 但是_sqlite3好像只用在python2上，我用的是python3.6。为啥会需要这个呢？我在其他server里没有遇到这个问题。在那个server里，python是自己编译的，在编译python的时候，我用了如下command。\r\n\r\nCC=/opt/compiler/gcc-4.8.2/bin/gcc ./configure --prefix=/home/dingcheng/workspace/python_3.6.1 --enable-unicode=ucs4 --enable-loadable-sqlite-extensions --enable-shared  --enable-optimizations\r\n\r\n这里面也包括sqlite。\r\n\r\n这种情况该怎么修复呢？",
        "state": "open",
        "user": "leonleeldc",
        "closed_by": null,
        "created_at": "2019-11-04T23:22:19+00:00",
        "updated_at": "2020-11-19T12:18:12+00:00",
        "closed_at": null,
        "comments_count": [
            "OliverLPH",
            "leon-zhu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3872,
        "title": "检测模型YOLOv3卷积通道剪裁，使用自己的数据集时，报缺缺‘im_id’错误",
        "body": "![image](https://user-images.githubusercontent.com/18586273/68128026-f2a76000-ff51-11e9-8d3e-801ad829e805.png)\r\n我查看源码，在eval.py中，以及results的每一个item的dict中，就是缺少‘im_id’\r\n![image](https://user-images.githubusercontent.com/18586273/68128114-14084c00-ff52-11e9-9ffc-a605f0637034.png)\r\n我自己尝试修改eval_run方法，但没有任何效果",
        "state": "closed",
        "user": "Ezra-Yu",
        "closed_by": "Ezra-Yu",
        "created_at": "2019-11-04T14:27:33+00:00",
        "updated_at": "2021-07-22T05:45:20+00:00",
        "closed_at": "2021-07-22T05:45:20+00:00",
        "comments_count": [
            "slf12",
            "wanghaoshuang",
            "Ezra-Yu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3877,
        "title": "场景识别attention_model在paddle1.5，1.4，1.6版本上都存在收敛问题",
        "body": "`场景文字识别attention_model存在收敛问题，这个模型文档上说在1.5上面存在，实则在1.5，1.4，1.6的版本上都存在收敛问题。在aistudio平台上面1.4版本日志，1.5和1.6是开始训练就有。\r\n`\r\nTime: 1572957349.9853573; Iter[16000]; Avg loss: 0.217; Avg seq err: 0.016\r\nkpis    train_cost      0.216565\r\nkpis    train_acc       0.984461\r\n\r\nTime: 1572957645.2934074; Iter[16000]; Test seq error: 0.0085.\r\n\r\nkpis    test_acc        0.991500\r\n\r\nTime: 1572958057.7032695; Iter[17000]; Avg loss: 0.202; Avg seq err: 0.014\r\nkpis    train_cost      0.202122\r\nkpis    train_acc       0.985672\r\n\r\nTime: 1572958362.20513; Iter[17000]; Test seq error: 0.0081.\r\n\r\nkpis    test_acc        0.991900\r\n\r\nTime: 1572958767.431849; Iter[18000]; Avg loss: nan; Avg seq err: 0.771\r\nkpis    train_cost      nan\r\nkpis    train_acc       0.228555\r\n\r\nTime: 1572959085.0010662; Iter[18000]; Test seq error: 1.0.\r\n\r\nkpis    test_acc        0.000000\r\n\r\nTime: 1572959485.3717132; Iter[19000]; Avg loss: nan; Avg seq err: 1.000\r\nkpis    train_cost      nan\r\nkpis    train_acc       0.000000`",
        "state": "open",
        "user": "L-lei",
        "closed_by": null,
        "created_at": "2019-11-05T13:27:25+00:00",
        "updated_at": "2019-11-06T05:06:37+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "L-lei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3875,
        "title": "py_func 输出值的lod_level指定",
        "body": "![image](https://user-images.githubusercontent.com/14270174/68174215-4187e080-ffb8-11e9-9822-4e7831288318.png)\r\n想问下在py_func怎么指定输出的lod level呢？如图中的pred_result，想让它的lod_level为[N,6]，和标准的nms相同。",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-11-05T02:40:08+00:00",
        "updated_at": "2019-11-05T09:20:22+00:00",
        "closed_at": "2019-11-05T09:20:22+00:00",
        "comments_count": [
            "xiangyubo",
            "xiangyubo",
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3890,
        "title": "官方代码depthwise_conv2d的flops计算错误",
        "body": "https://github.com/PaddlePaddle/models/blob/7c73360fbaca386300376f9e63e2ac1701590cf2/PaddleCV/Research/astar2019/utils.py#L121\r\n![图片](https://user-images.githubusercontent.com/25809906/68279843-411e4100-00af-11ea-95e9-83dd9a5c5dd6.png)\r\n如图，一个7通道、3*3可分离卷积的param最后算得9。（一定算错了）\r\n我自身模型文件是没问题的。",
        "state": "open",
        "user": "mozpp",
        "closed_by": null,
        "created_at": "2019-11-06T08:08:17+00:00",
        "updated_at": "2019-11-12T06:42:32+00:00",
        "closed_at": null,
        "comments_count": [
            "FDInSky"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3891,
        "title": "texcnn finetune是不是限制了只能三分类",
        "body": "在做二分类task的时候，发现报错如下：\r\n![image](https://user-images.githubusercontent.com/13725297/68285017-792a8180-00b9-11ea-8b49-567701484ba6.png)\r\n",
        "state": "closed",
        "user": "shiwl0329",
        "closed_by": "heavengate",
        "created_at": "2019-11-06T09:19:08+00:00",
        "updated_at": "2019-11-06T14:17:34+00:00",
        "closed_at": "2019-11-06T14:17:34+00:00",
        "comments_count": [
            "heavengate",
            "shiwl0329",
            "heavengate",
            "shiwl0329",
            "heavengate",
            "shiwl0329"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3895,
        "title": "模型剪裁后，fps降低了，是什么原因",
        "body": "![image](https://user-images.githubusercontent.com/18586273/68352027-221bbf80-0140-11ea-8750-34a57ccc6e77.png)\r\n\r\n我跑了yolo，backbone是mobileNet，在剪裁后模型的fps由69.8降低为54.8，就很奇怪。\r\n其他参数都很正常",
        "state": "closed",
        "user": "Ezra-Yu",
        "closed_by": "Ezra-Yu",
        "created_at": "2019-11-07T01:24:41+00:00",
        "updated_at": "2021-07-22T05:45:09+00:00",
        "closed_at": "2021-07-22T05:45:09+00:00",
        "comments_count": [
            "Ezra-Yu",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3893,
        "title": "can not import ppdet.core.workspace",
        "body": "在PaddleDetection目录下，直接运行，提示无法导入，运行python，再导入，是没问题的，想问下这是什么问题呢？\r\n\r\n![image](https://user-images.githubusercontent.com/14270174/68285650-a1ff4680-00ba-11ea-8ec8-ba39555e16c6.png)\r\n",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-11-06T09:28:09+00:00",
        "updated_at": "2019-11-06T14:17:57+00:00",
        "closed_at": "2019-11-06T09:49:15+00:00",
        "comments_count": [
            "heavengate",
            "littletomatodonkey",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3897,
        "title": "特征提取",
        "body": "请问对于BSN和BMN，如果我要使用其他数据集，特征提取是怎么做的呢？用dense_flow提取出视频文件的RGB和FLow Image后，如何用预训练的TSN模型得到 csv_mean_100这里面的csv特征呢？",
        "state": "open",
        "user": "sunnymoon155",
        "closed_by": null,
        "created_at": "2019-11-07T08:12:31+00:00",
        "updated_at": "2020-03-21T18:39:41+00:00",
        "closed_at": null,
        "comments_count": [
            "wzmsltw",
            "leemengxing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3898,
        "title": "softmax改造sigmoid输出",
        "body": "![image](https://user-images.githubusercontent.com/13725297/68381993-c8da7d00-018d-11ea-9391-f9dca06d4f8a.png)\r\nact=\"softmax\"，单纯改成act=\"sigmoid\"，训练会出错，求解",
        "state": "open",
        "user": "shiwl0329",
        "closed_by": null,
        "created_at": "2019-11-07T10:39:15+00:00",
        "updated_at": "2019-11-11T10:29:15+00:00",
        "closed_at": null,
        "comments_count": [
            "fc500110",
            "shiwl0329"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3899,
        "title": "Imagenet图像分类工程，内存一直不停增长直到占满",
        "body": "你好，我使用的是github上最新1.6版本的models工程PaddleCV中的image_classification，PaddlePaddle版本1.6，工程基本没有改动，使用我自己的数据集，在多进程训练时，内存会一直不停增长，直到内存全部占满。\r\n我的内存大小是128G，使用的显卡是Tesla V100\r\n**另外我尝试调整过reader_thread、reader_buf_size和batch size，已经调整到足够小了，再小的话会影响性能，reader_thread为6，reader_buf_size为512，PyReader的capacity调整为4，而且我开启了FLAGS_eager_delete_tensor_gb=0，打开inplace策略等，内存还是会一直不停增长，直到128G内存全部占满。**\r\n请问这种情况如何解决？\r\n\r\n我刚刚试了一下，使用imagenet数据集来训练，内存会一直不断的上涨，我的训练参数是：\r\npython -m paddle.distributed.launch train.py\r\n--model=ResNet34\r\n--batch_size=300\r\n--reader_thread=12\r\n--reader_buf_size=2048\r\n其他全部为默认值，内存依然不断上涨，内存已经占超过70G了\r\n![image](https://user-images.githubusercontent.com/49382659/68395704-3d6fe480-01ab-11ea-9df2-ae57f9f06107.png)\r\n",
        "state": "closed",
        "user": "Yogurt2019",
        "closed_by": "Yogurt2019",
        "created_at": "2019-11-07T10:55:03+00:00",
        "updated_at": "2019-11-16T12:25:23+00:00",
        "closed_at": "2019-11-16T12:25:23+00:00",
        "comments_count": [
            "LielinJiang",
            "Yogurt2019",
            "LielinJiang",
            "Yogurt2019",
            "LielinJiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3902,
        "title": "ppdet,mstest报错",
        "body": "报错信息如下：\r\n\r\n``` \r\n File \"/home/vis/gry/code/github/PaddleDetection/ppdet/utils/post_process.py\", line 186, in mstest_box_post_process\r\n    bbox_pred = get_nms_result(ms_boxes, ms_scores, cfg)\r\n  File \"/home/vis/gry/code/github/PaddleDetection/ppdet/utils/post_process.py\", line 143, in get_nms_result\r\n    cfg.MultiScaleTEST['vote_thresh'])\r\n  File \"/home/vis/gry/code/github/PaddleDetection/ppdet/utils/post_process.py\", line 126, in box_voting\r\n    top_dets[k, 1:] = np.average(boxes_to_vote, axis=0, weights=ws)\r\n  File \"/home/vis/gry/paddle-release/python-gcc482-paddle/lib/python2.7/site-packages/numpy/lib/function_base.py\", line 1158, in average\r\n    \"Weights sum to zero, can't be normalized\")\r\nZeroDivisionError: Weights sum to zero, can't be normalized\r\n```\r\n\r\n单尺度预测没有问题~模型为cascade_fpn_dcnv2",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-11-08T00:25:41+00:00",
        "updated_at": "2019-11-08T06:45:36+00:00",
        "closed_at": "2019-11-08T06:45:36+00:00",
        "comments_count": [
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3904,
        "title": "是没有上传最新版本的code吗？distill、prune、quantitation的 compress.py中调用的时候出现paddle.fluid.contrib.slim.core.Compressor中未定义的参数",
        "body": " 在distill、prune、quantitation的 compress.py中调用的时候出现paddle.fluid.contrib.slim.core.Compressor中未定义的参数，例如eval_func，save_eval_model，prune_infer_model，log_period",
        "state": "open",
        "user": "ARQlalala",
        "closed_by": null,
        "created_at": "2019-11-11T04:03:48+00:00",
        "updated_at": "2019-11-12T11:36:16+00:00",
        "closed_at": null,
        "comments_count": [
            "sandyhouse",
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3905,
        "title": "关于语音识别模型：BaiduCN1.2k Model",
        "body": "你好，请问该模型是使用DeepSpeech2训练出来的吗？\r\n\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/develop/README_cn.md",
        "state": "closed",
        "user": "cyy0523xc",
        "closed_by": "sandyhouse",
        "created_at": "2019-11-11T08:19:27+00:00",
        "updated_at": "2019-11-12T06:56:03+00:00",
        "closed_at": "2019-11-12T06:56:03+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3922,
        "title": "load_persistables ERROR",
        "body": "",
        "state": "closed",
        "user": "YNZH",
        "closed_by": "YNZH",
        "created_at": "2019-11-13T13:06:38+00:00",
        "updated_at": "2019-11-14T05:15:53+00:00",
        "closed_at": "2019-11-14T05:15:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3915,
        "title": "你好，请问lac模型加入词典干涉的时候，怎样设置如果遇见词典的词直接用词典的词性？",
        "body": "你好，请问lac模型加入词典干涉的时候，怎样设置如果遇见词典的词直接用词典的词性？\r\n比如我现在词典里有苔，但是分词标注词性的时候 还不是我词典中的词性。",
        "state": "open",
        "user": "JayJQK",
        "closed_by": null,
        "created_at": "2019-11-13T01:40:30+00:00",
        "updated_at": "2019-11-18T01:51:19+00:00",
        "closed_at": null,
        "comments_count": [
            "jangqh",
            "JayJQK"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3909,
        "title": "paddle_detection 配置文件中class_aware_sampling意义？",
        "body": "同学您好：\r\n        我发现paddle_detection中新增了config/obj365/cascade_rcnn_dcnv2_se154_vd_fpn_gn_cas.yml文件，请问文件中 “FasterRCNNTrainFeed”中的 “class_aware_sampling” 是什么意义呢？或者有没有相关的参考资料。多谢啦",
        "state": "closed",
        "user": "ronghaoLee",
        "closed_by": "ronghaoLee",
        "created_at": "2019-11-12T02:28:06+00:00",
        "updated_at": "2019-11-18T01:38:16+00:00",
        "closed_at": "2019-11-18T01:38:16+00:00",
        "comments_count": [
            "ceci3",
            "qingqing01",
            "ronghaoLee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3928,
        "title": "数组访问除了切片访问,是否支持以数组为索引,来批量访问不同位置的数据?",
        "body": "比如我有数组A[10], 现在要访问第1,3,5,6,9这几个数据, 假设Id = [1,3,5,6,9], 可否通过A[Id]来访问第1,3,5,6,9这几个数据?",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wenston2006",
        "created_at": "2019-11-14T07:37:01+00:00",
        "updated_at": "2019-11-22T08:45:27+00:00",
        "closed_at": "2019-11-22T08:45:27+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "wenston2006",
            "zhaoyuchen2018",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3929,
        "title": "dygraph有没有类似sequence_slice这样的函数?",
        "body": "说明文档里看到静态图支持sequence_slice函数,不知道动态图是否支持类似函数",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-11-14T08:20:56+00:00",
        "updated_at": "2019-11-14T10:42:21+00:00",
        "closed_at": null,
        "comments_count": [
            "zhaoyuchen2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3934,
        "title": "models/legacy/generate_sequence_by_rnn_lm 代码使用新版paddle 1.6.1无法使用",
        "body": "models/legacy/generate_sequence_by_rnn_lm 代码使用新版paddle 1.6.1无法使用。\r\n代码都是老代码，根本没有办法进行运行测试",
        "state": "closed",
        "user": "skriser",
        "closed_by": "skriser",
        "created_at": "2019-11-14T13:22:03+00:00",
        "updated_at": "2019-11-18T03:07:45+00:00",
        "closed_at": "2019-11-18T03:07:45+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "skriser",
            "zhaoyuchen2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3936,
        "title": "similarity net什么时候可以提供基于预训练模型的微调功能？",
        "body": "similarity net目前好像不支持基于预训练模型的微调功能，如果能提供基于预训练模型下针对自己的业务数据进行微调功能，效果应该会提升很多吧。",
        "state": "closed",
        "user": "linuxsong",
        "closed_by": "linuxsong",
        "created_at": "2019-11-15T03:38:43+00:00",
        "updated_at": "2019-11-18T08:01:14+00:00",
        "closed_at": "2019-11-18T08:01:14+00:00",
        "comments_count": [
            "liupluswei",
            "linuxsong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3937,
        "title": "乘法运算用*号和用fluid.layers.mul(), 哪个速度更快?取数组元素用中括号[]或用layer.slice()哪个快?",
        "body": "现在用dygraph做开发, 发现乘法用*号和mul()都可以, 但不知道哪个更快?发现两种运算所得输出数组的维度大小不大一致; 我定义的函数涉及到梯度反向运算; 应该用哪个更合适? 此外取数组元素用中括号[]如A[i] 或用layer.slice(A, axes=0, start=[i], end=[i+1])哪个效率更高?  ",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-11-15T07:15:49+00:00",
        "updated_at": "2019-11-15T09:14:55+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3939,
        "title": "类似RELU的函数如何自定义?(其中变量参与forward和backward运算)",
        "body": "函数公式如下图\r\n![Screenshot from 2019-11-15 15-32-38](https://user-images.githubusercontent.com/18213760/68925680-808b1280-07be-11ea-9e90-7229af31d534.png)\r\n公式中R_j和T_j为两个输入变量, 公式左边的p为输出; R_j参与forward和backward运算,这个函数的代码应该如何编写?",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-11-15T07:44:43+00:00",
        "updated_at": "2019-12-04T08:11:09+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84",
            "wenston2006",
            "Aurelius84",
            "wenston2006",
            "Aurelius84",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3940,
        "title": "对paddleNLP中的transformer翻译模型有疑问，期待解答。",
        "body": "模型：paddleNLP中的transformer翻译模型。\r\n疑问：其中的decoder实现，在Attention is all you need论文中提到，有一个masked multi-head attention，但在本仓库的实现中，没有看到明显的mask操作，这里不太明白，请问这里的mask是怎么实现的？\r\n相关代码：\r\nhttps://github.com/PaddlePaddle/models/blob/eee28b3e52ad190fecc3afef35705e00512bfd1c/PaddleNLP/PaddleMT/transformer/transformer.py#L414",
        "state": "closed",
        "user": "AnShengqiang",
        "closed_by": "AnShengqiang",
        "created_at": "2019-11-15T14:49:22+00:00",
        "updated_at": "2019-11-18T06:12:51+00:00",
        "closed_at": "2019-11-18T06:12:50+00:00",
        "comments_count": [
            "guoshengCS",
            "AnShengqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3943,
        "title": "请问Paddle版yolov3模型是否与darknet版yolov3模型互转",
        "body": "我这边在darknet上用自己的训练样本预训练了一版yolov3模型，想要添加新数据后放在paddlepaddle继续训练，在paddle上训练出新版模型后再将模型转回darknet版yolov3。请问现在有没有这种方法，谢谢。",
        "state": "open",
        "user": "ShuoWillWang",
        "closed_by": null,
        "created_at": "2019-11-18T09:34:29+00:00",
        "updated_at": "2019-11-18T12:41:48+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3941,
        "title": "pyreader队列size周期性变化导致训练速度时快时慢",
        "body": "hi，我使用\r\n`print(\"queue size:\", train_py_reader.queue.size())`\r\n打印queuesize，发现queuesize一直增长，等size满了以后就不增长了，一直下降为0，然后所有GPU使用率都为0，卡住一段时间以后queue才增长，我发现这个现象严重影响训练时间，如何让queue一直为满，GPU使用率不为0，充分利用计算资源?\r\n我使用的是paddlepaddle1.6版本 和1.6版本的models，ubuntu 18.04 CUDA10.0 cuDNN7.3\r\n使用的是多进程训练\r\n我已经开启了double_buffer,models1.6版本代码已经开启了这个功能\r\n`py_reader = fluid.io.DataLoader.from_generator(\r\n            feed_list=[feed_image, feed_label],\r\n            capacity=32,\r\n            use_double_buffer=True,\r\n            iterable=False)`\r\n以及训练参数:\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 80\r\n               checkpoint : ./output/tax/0/ResNet34/4\r\n                class_dim : 6711\r\n            crop_img_size : 336\r\n                crop_size : 672\r\n                 data_dir : /data\r\n             decay_epochs : 2.4\r\n               decay_rate : 0.97\r\n        drop_connect_rate : 0.2\r\n                ema_decay : 0.9999\r\n               image_mean : [0.485, 0.456, 0.406]\r\n              image_shape : 3,672,672\r\n                image_std : [0.229, 0.224, 0.225]\r\n            interpolation : None\r\n                 l2_decay : 0.0001\r\n  label_smoothing_epsilon : 0.1\r\n              lower_ratio : 0.75\r\n              lower_scale : 0.08\r\n                       lr : 0.1\r\n              lr_strategy : piecewise_decay\r\n              mixup_alpha : 0.2\r\n                    model : ResNet34\r\n           model_save_dir : ./output\r\n            momentum_rate : 0.9\r\n               num_epochs : 100\r\n             padding_type : SAME\r\n         pretrained_model : None\r\n               print_step : 10\r\n              random_seed : None\r\n          reader_buf_size : 512\r\n            reader_thread : 10\r\n        resize_short_size : 0\r\n                save_step : 1\r\n              step_epochs : [10, 20, 30]\r\n          test_batch_size : 40\r\n             total_images : 439860\r\n              upper_ratio : 1.3333333333333333\r\n                   use_aa : False\r\n              use_distill : False\r\n                  use_ema : False\r\n                  use_gpu : True\r\n      use_label_smoothing : False\r\n                use_mixup : False\r\n                   use_se : False\r\n           warm_up_epochs : 5.0",
        "state": "closed",
        "user": "Yogurt2019",
        "closed_by": "Yogurt2019",
        "created_at": "2019-11-16T12:07:59+00:00",
        "updated_at": "2019-11-29T02:13:17+00:00",
        "closed_at": "2019-11-29T02:13:17+00:00",
        "comments_count": [
            "xiaosang",
            "Yogurt2019",
            "Yogurt2019"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3944,
        "title": "ctr 下的dcn模型求助",
        "body": "我的环境是win7 系统  最新的fluid版本，是在python版本是3.6.5.是在pycharm 中直接运行local_train.py文件的，数据集用的和原数据集一致。\r\n exe.train_from_dataset(\r\n            program=fluid.default_main_program(),\r\n            dataset=dataset,\r\n            fetch_list=[\r\n                dcn_model.loss, dcn_model.avg_logloss, dcn_model.auc_var,dcn_model.net_input\r\n            ],\r\n            fetch_info=['total_loss', 'avg_logloss', 'auc'],\r\n            debug=False,\r\n            print_period=1)\r\n我想看训练输出结果  但是为什么没输出呢",
        "state": "closed",
        "user": "LBSIX",
        "closed_by": "ysh329",
        "created_at": "2019-11-19T02:54:41+00:00",
        "updated_at": "2019-12-05T12:45:11+00:00",
        "closed_at": "2019-11-20T01:45:41+00:00",
        "comments_count": [
            "JiaXiao243",
            "LBSIX",
            "ysh329",
            "LBSIX",
            "ysh329",
            "wilhelmzh",
            "shuDaoNan9",
            "LBSIX",
            "shuDaoNan9",
            "LBSIX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3949,
        "title": "ctr 下的dcn模型 ",
        "body": "可以具体说下 你们跑这个模型的环境版本吗  ubuntu？ python 3.65？ fluid 版本",
        "state": "closed",
        "user": "LBSIX",
        "closed_by": "ysh329",
        "created_at": "2019-11-19T12:20:41+00:00",
        "updated_at": "2019-11-20T01:48:13+00:00",
        "closed_at": "2019-11-20T01:48:12+00:00",
        "comments_count": [
            "ysh329"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3952,
        "title": "dygraph 下实现CRNN+CTC的问题",
        "body": "您好，我想要使用动态图来实现CRNN+CTC，目前参考https://github.com/PaddlePaddle/models/tree/a92e212932b764e500a833527e0fb772ac9a491a/dygraph/ocr_recognition 这个项目实现了CRNN部分，但是该部分的输出是一个3-D的定长tensor，我看了fluid.layers.warpctc op如果使用定长tensor作为输入的话需要指定每个序列的长度，如果不指定的话直接运行会报 段错误，请问这边我需要怎么将CRNN部分的输出以及label转为lod_tensor嘞",
        "state": "closed",
        "user": "wwjjy",
        "closed_by": "lfchener",
        "created_at": "2019-11-20T03:14:32+00:00",
        "updated_at": "2020-01-21T06:52:30+00:00",
        "closed_at": "2020-01-21T06:52:30+00:00",
        "comments_count": [
            "wwjjy",
            "MRXLT",
            "wwjjy",
            "wwjjy",
            "wanghaoshuang",
            "wwjjy",
            "songyouwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3954,
        "title": "fp16混合精度训练如何使用？",
        "body": "直接在train的时候开启fp16之后，数据会一直读取但是并不开始训练过程。如果关闭fp16 util里的reduce_master_grad的话，也就是不运行fluid.layers.collective._allreduce的话，可以正常训练。请问这个all reduce的作用是什么，在文档里没有找到。",
        "state": "open",
        "user": "AstomMars",
        "closed_by": null,
        "created_at": "2019-11-20T05:38:27+00:00",
        "updated_at": "2019-11-20T17:27:41+00:00",
        "closed_at": null,
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3953,
        "title": "ctr 下的dcn模型在百度aistudio终端运行出错的问题",
        "body": "运行环境  python 3.7，paddle1.6，百度aistudio终端。\r\n在命令行 使用命令  nohup python -u infer.py --test_epoch 2 > test.log &，训练出错 具体见附件 train.log.\r\n![1](https://user-images.githubusercontent.com/52662095/69209150-22c94280-0b91-11ea-89b6-f6c383727819.png)\r\n\r\n![2](https://user-images.githubusercontent.com/52662095/69209203-53a97780-0b91-11ea-8662-a34074418ecb.png)\r\n[train .log](https://github.com/PaddlePaddle/models/files/3867322/train.log)\r\n",
        "state": "open",
        "user": "LBSIX",
        "closed_by": null,
        "created_at": "2019-11-20T04:29:29+00:00",
        "updated_at": "2019-11-21T07:58:50+00:00",
        "closed_at": null,
        "comments_count": [
            "wilhelmzh",
            "LBSIX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3958,
        "title": "验证集上效果和测试集上效果相差较大",
        "body": "目前遇到的问题是验证集上的效果和测试集上的效果相差较大，当前相差五个点左右，可能的原因是在训练过程中将验证集上的数据也train了，以下是我的训练脚本，目前暂未排查出问题，希望paddle同学可以协助排查，非常感谢！\r\n\r\npaddle 1.5.0版本\r\n\r\n```python\r\n#!/usr/bin/env python\r\n#-*- coding:utf8 -*-\r\n\r\nimport json\r\nimport os\r\nimport sys\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddle.fluid.param_attr as attr\r\nimport numpy as np\r\n\r\nimport sklearn\r\nfrom sklearn.metrics import roc_auc_score\r\n\r\nfrom model.double_tower import ResnetErnie\r\nfrom model.double_tower import ResnetBow\r\nfrom reader.tokenization import FullTokenizer\r\nfrom reader.relevance_reader import RelevanceReader\r\n\r\ndef main():\r\n    instance = ResnetBow()\r\n    instance.forward()    \r\n    pred = instance.logits\r\n    loss = instance.loss\r\n    input_label = instance.input_hard_label\r\n    \r\n    test_program = fluid.default_main_program().clone(for_test=True)\r\n    fluid.optimizer.Adam(learning_rate=0.001).minimize(loss)\r\n    \r\n    places = fluid.cuda_places() if config_use_cuda else fluid.CPUPlace()\r\n    place = fluid.CUDAPlace(0)\r\n    print(fluid.core.get_cuda_device_count())\r\n    exe = fluid.Executor(place)\r\n    exe.run(fluid.default_startup_program())\r\n   \r\n    init_model(\r\n            exe=exe, \r\n            program=fluid.default_main_program(), \r\n            file_name=some_file_name)\r\n\r\n    exec_strategy = fluid.ExecutionStrategy()\r\n    exec_strategy.num_threads = fluid.core.get_cuda_device_count()\r\n    exec_strategy.num_iteration_per_drop_scope = 100\r\n\r\n    build_strategy = fluid.BuildStrategy()\r\n    build_strategy.enable_inplace = True\r\n\r\n    train_exe = fluid.ParallelExecutor(\r\n            use_cuda=config_use_cuda,\r\n            main_program=fluid.default_main_program(),\r\n            loss_name=loss.name,\r\n            build_strategy=build_strategy,\r\n            exec_strategy=exec_strategy)\r\n    test_exe = fluid.ParallelExecutor(\r\n            use_cuda=config_use_cuda,\r\n            main_program=test_program,\r\n            build_strategy=build_strategy,\r\n            share_vars_from=train_exe,\r\n            exec_strategy=exec_strategy)\r\n    \r\n    data_reader = RelevanceReader()     \r\n\r\n    feed_list = [\r\n        instance.input_src_ids,\r\n        instance.input_txt_ids,\r\n        instance.input_pos_ids,\r\n        instance.input_mask,\r\n        instance.input_image,\r\n        instance.input_hard_label]\r\n    train_batch_gen = data_reader.multiprocessing_wrapper(\r\n            file_names=train_file_name,\r\n            data_sizes=train_data_size,           \r\n            num_workers=5,\r\n            epochs=10)\r\n    test_batch_gen = data_reader.batch_wrapper(\r\n            file_name=test_file_name,\r\n            data_size=test_data_size,          \r\n            batch_size=128,            \r\n            shuffle=True)\r\n    train_reader = fluid.io.PyReader(\r\n            feed_list=feed_list,\r\n            capacity=5,\r\n            use_double_buffer=True,\r\n            iterable=True)\r\n    train_reader.decorate_batch_generator(train_batch_gen, places=places)  \r\n    test_reader = fluid.io.PyReader(\r\n            feed_list=feed_list,\r\n            capacity=5,\r\n            use_double_buffer=True,\r\n            iterable=True)\r\n    test_reader.decorate_batch_generator(test_batch_gen, places=places)\r\n    \r\n    cnt = 0 \r\n    for train_data in train_reader():\r\n        _loss = train_exe.run(\r\n                feed=train_data,\r\n                fetch_list=[loss.name])\r\n        print(\"{}\\t{}\".format(cnt, _loss[0]))\r\n        cnt += 1\r\n        if cnt % 200 == 0:\r\n            test_cnt = 0\r\n            auces = []\r\n            losses = []\r\n            for test_data in test_reader():\r\n                _test_loss, _pred, _label = test_exe.run(\r\n                        feed=test_data,\r\n                        fetch_list=[loss.name, pred.name, input_label.name],\r\n                        return_numpy=True)               \r\n                test_cnt += 1\r\n                if test_cnt >= 5:               \r\n                    break                            \r\n\r\nif __name__ == \"__main__\":\r\n    config_use_cuda = True\r\n   \r\n    train_file_names = \"/home/work/train_set\"\r\n    train_data_sizes = 10078937\r\n\r\n    test_file_name = \"/home/work/dev.data\"\r\n    test_data_size = 1110000\r\n\r\n    main()\r\n\r\n```",
        "state": "closed",
        "user": "JingChunzhen",
        "closed_by": "MRXLT",
        "created_at": "2019-11-20T07:49:34+00:00",
        "updated_at": "2019-11-22T02:42:52+00:00",
        "closed_at": "2019-11-22T02:42:52+00:00",
        "comments_count": [
            "JingChunzhen",
            "MRXLT",
            "JingChunzhen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3961,
        "title": "YOLOV3 水果数据集 No next data",
        "body": "能正常跑一会;然后就出现如下错误;\r\n\r\n配置信息：\r\narchitecture: YOLOv3\r\ntrain_feed: YoloTrainFeed\r\neval_feed: YoloEvalFeed\r\ntest_feed: YoloTestFeed\r\nuse_gpu: true\r\nmax_iters: 20000\r\nlog_smooth_window: 20\r\nsave_dir: output\r\nsnapshot_iter: 200\r\nmetric: VOC\r\nmap_type: 11point\r\npretrain_weights: https://paddlemodels.bj.bcebos.com/object_detection/yolov3_mobilenet_v1.tar\r\nweights: output/yolov3_mobilenet_v1_fruit/best_model\r\nnum_classes: 3\r\nfinetune_exclude_pretrained_params: ['yolo_output']\r\n\r\nYOLOv3:\r\n  backbone: MobileNet\r\n  yolo_head: YOLOv3Head\r\n\r\nMobileNet:\r\n  norm_type: sync_bn\r\n  norm_decay: 0.\r\n  conv_group_scale: 1\r\n  with_extra_blocks: false\r\n\r\nYOLOv3Head:\r\n  anchor_masks: [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\r\n  anchors: [[10, 13], [16, 30], [33, 23],\r\n            [30, 61], [62, 45], [59, 119],\r\n            [116, 90], [156, 198], [373, 326]]\r\n  norm_decay: 0.\r\n  ignore_thresh: 0.7\r\n  label_smooth: true\r\n  nms:\r\n    background_label: -1\r\n    keep_top_k: 100\r\n    nms_threshold: 0.45\r\n    nms_top_k: 1000\r\n    normalized: false\r\n    score_threshold: 0.01\r\n\r\nLearningRate:\r\n  base_lr: 0.000002\r\n  schedulers:\r\n  - !PiecewiseDecay\r\n    gamma: 0.1\r\n    milestones:\r\n    - 15000\r\n    - 18000\r\n  - !LinearWarmup\r\n    start_factor: 0.\r\n    steps: 100\r\n\r\nOptimizerBuilder:\r\n  optimizer:\r\n    momentum: 0.9\r\n    type: Momentum\r\n  regularizer:\r\n    factor: 0.0005\r\n    type: L2\r\n\r\nYoloTrainFeed:\r\n  batch_size: 1\r\n  dataset:\r\n    dataset_dir: dataset/fruit/fruit-detection\r\n    annotation: train.txt\r\n    use_default_label: false\r\n  num_workers: 16\r\n  bufsize: 128\r\n  use_process: true\r\n  mixup_epoch: -1\r\n  sample_transforms:\r\n  - !DecodeImage\r\n    to_rgb: true\r\n    with_mixup: false\r\n  - !NormalizeBox {}\r\n  - !ExpandImage\r\n    max_ratio: 4.0\r\n    mean: [123.675, 116.28, 103.53]\r\n    prob: 0.5\r\n  - !RandomInterpImage\r\n    max_size: 0\r\n    target_size: 608\r\n  - !RandomFlipImage\r\n    is_mask_flip: false\r\n    is_normalized: true\r\n    prob: 0.5\r\n  - !NormalizeImage\r\n    is_channel_first: false\r\n    is_scale: true\r\n    mean:\r\n    - 0.485\r\n    - 0.456\r\n    - 0.406\r\n    std:\r\n    - 0.229\r\n    - 0.224\r\n    - 0.225\r\n  - !Permute\r\n    channel_first: true\r\n    to_bgr: false\r\n  batch_transforms:\r\n  - !RandomShape \r\n    sizes: [608] \r\n  with_background: false\r\n\r\nYoloEvalFeed:\r\n  batch_size: 1\r\n  image_shape: [3, 608, 608]\r\n  dataset:\r\n    dataset_dir: dataset/fruit/fruit-detection\r\n    annotation:  val.txt\r\n    use_default_label: false\r\n \r\n\r\nYoloTestFeed:\r\n  batch_size: 1\r\n  image_shape: [3, 608, 608]\r\n  dataset:\r\n    dataset_dir: dataset/fruit\r\n    use_default_label: false\r\n\r\n报错信息如下：\r\n\r\n\r\n\r\nI1120 17:06:49.690585  9759 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1120 17:06:49.924094  9759 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n2019-11-20 17:06:50,362-INFO: iter: 0, lr: 0.000000, 'loss': '16984.570312', time: 0.163, eta: 0:54:11\r\n2019-11-20 17:06:52,587-INFO: iter: 20, lr: 0.000000, 'loss': '9977.352539', time: 0.190, eta: 1:03:09\r\n2019-11-20 17:06:54,451-INFO: iter: 40, lr: 0.000001, 'loss': '673.993042', time: 0.094, eta: 0:31:10\r\n2019-11-20 17:06:56,082-INFO: iter: 60, lr: 0.000001, 'loss': '166.233780', time: 0.082, eta: 0:27:06\r\n2019-11-20 17:06:57,709-INFO: iter: 80, lr: 0.000002, 'loss': '103.996521', time: 0.081, eta: 0:26:59\r\n2019-11-20 17:06:59,353-INFO: iter: 100, lr: 0.000002, 'loss': '72.225800', time: 0.082, eta: 0:27:10\r\n2019-11-20 17:07:00,999-INFO: iter: 120, lr: 0.000002, 'loss': '57.962166', time: 0.083, eta: 0:27:22\r\n2019-11-20 17:07:02,637-INFO: iter: 140, lr: 0.000002, 'loss': '52.966858', time: 0.082, eta: 0:27:05\r\n2019-11-20 17:07:04,310-INFO: iter: 160, lr: 0.000002, 'loss': '51.043819', time: 0.083, eta: 0:27:31\r\n2019-11-20 17:07:06,543-INFO: iter: 180, lr: 0.000002, 'loss': '44.794296', time: 0.107, eta: 0:35:12\r\n2019-11-20 17:07:09,575-INFO: iter: 200, lr: 0.000002, 'loss': '38.660149', time: 0.153, eta: 0:50:26\r\n2019-11-20 17:07:09,703-INFO: Save model to output/yolov3_mobilenet_v1_fruit/200.\r\n2019-11-20 17:07:14,636-INFO: iter: 220, lr: 0.000002, 'loss': '36.993340', time: 0.256, eta: 1:24:30\r\n2019-11-20 17:07:17,816-WARNING: fail to map op [ExpandImage_909a9c] with error: Unable to allocate array with shape (10016, 10016, 3) and data type float64 and stack:\r\nTraceback (most recent call last):\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/dataset.py\", line 48, in reset\r\n    (self.__class__.__name__))\r\nNotImplementedError: MappedDataset.reset not available\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/dataset.py\", line 48, in reset\r\n    (self.__class__.__name__))\r\nNotImplementedError: BatchedDataset.reset not available\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/__init__.py\", line 77, in _mapper\r\n    out = f(sample, ctx)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/operators.py\", line 611, in __call__\r\n    expand_im = np.uint8(expand_im * np.squeeze(self.mean))\r\nMemoryError: Unable to allocate array with shape (10016, 10016, 3) and data type float64\r\n\r\n2019-11-20 17:07:17,905-INFO: iter: 240, lr: 0.000002, 'loss': '35.379051', time: 0.164, eta: 0:54:03\r\n2019-11-20 17:07:19,741-INFO: iter: 260, lr: 0.000002, 'loss': '41.599369', time: 0.092, eta: 0:30:16\r\n2019-11-20 17:07:21,477-INFO: iter: 280, lr: 0.000002, 'loss': '28.459013', time: 0.087, eta: 0:28:27\r\n2019-11-20 17:07:23,173-INFO: iter: 300, lr: 0.000002, 'loss': '29.857658', time: 0.085, eta: 0:27:54\r\n2019-11-20 17:07:24,858-INFO: iter: 320, lr: 0.000002, 'loss': '31.095598', time: 0.084, eta: 0:27:36\r\n2019-11-20 17:07:26,532-INFO: iter: 340, lr: 0.000002, 'loss': '25.751993', time: 0.084, eta: 0:27:25\r\n2019-11-20 17:07:28,204-INFO: iter: 360, lr: 0.000002, 'loss': '34.456688', time: 0.084, eta: 0:27:21\r\n2019-11-20 17:07:28,962-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64\r\n2019-11-20 17:07:29,879-INFO: iter: 380, lr: 0.000002, 'loss': '23.786648', time: 0.084, eta: 0:27:23\r\n2019-11-20 17:07:31,552-INFO: iter: 400, lr: 0.000002, 'loss': '23.337822', time: 0.084, eta: 0:27:18\r\n2019-11-20 17:07:31,569-INFO: Save model to output/yolov3_mobilenet_v1_fruit/400.\r\n2019-11-20 17:07:32,793-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits]\r\n2019-11-20 17:07:32,794-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits]\r\n2019-11-20 17:07:32,797-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits]\r\n2019-11-20 17:07:32,798-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits]\r\n2019-11-20 17:07:32,800-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits]\r\n2019-11-20 17:07:32,802-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits]\r\n2019-11-20 17:07:32,803-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits]\r\n2019-11-20 17:07:32,805-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits]\r\n2019-11-20 17:07:32,806-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits]\r\n2019-11-20 17:07:32,807-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits]\r\n2019-11-20 17:07:32,823-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits][consumer[consumer-1f9_13] exits]\r\n2019-11-20 17:07:32,825-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits][consumer[consumer-1f9_13] exits][consumer[consumer-1f9_15] exits]\r\n2019-11-20 17:07:32,843-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits][consumer[consumer-1f9_13] exits][consumer[consumer-1f9_15] exits][consumer[consumer-1f9_11] exits]\r\n2019-11-20 17:07:32,845-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits][consumer[consumer-1f9_13] exits][consumer[consumer-1f9_15] exits][consumer[consumer-1f9_11] exits][consumer[consumer-1f9_7] exits]\r\n2019-11-20 17:07:32,856-WARNING: consumer failed with error: failed to map consumer[%s], error: Unable to allocate array with shape (10016, 10016, 3) and data type float64[consumer[consumer-1f9_2] exits][consumer[consumer-1f9_12] exits][consumer[consumer-1f9_5] exits][consumer[consumer-1f9_3] exits][consumer[consumer-1f9_4] exits][consumer[consumer-1f9_10] exits][consumer[consumer-1f9_6] exits][consumer[consumer-1f9_9] exits][consumer[consumer-1f9_0] exits][consumer[consumer-1f9_14] exits][consumer[consumer-1f9_13] exits][consumer[consumer-1f9_15] exits][consumer[consumer-1f9_11] exits][consumer[consumer-1f9_7] exits][consumer[consumer-1f9_1] exits]\r\n2019-11-20 17:07:32,857-WARNING: Your reader has raised an exception!\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.5/threading.py\", line 862, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/reader.py\", line 488, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/six.py\", line 696, in reraise\r\n    raise value\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/reader.py\", line 468, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/reader.py\", line 542, in __tensor_reader_impl__\r\n    for slots in paddle_reader():\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/data_feeder.py\", line 454, in __reader_creator__\r\n    for item in reader():\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/reader.py\", line 103, in _reader\r\n    for _batch in batched_ds:\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/dataset.py\", line 30, in __next__\r\n    return self.next()\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 57, in next\r\n    sample = self._ds.next()\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 99, in next\r\n    out = self._ds.next()\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/zhangyu/Paddle/models/PaddleCV/PaddleDetection/ppdet/data/transform/parallel_map.py\", line 187, in next\r\n    raise ValueError(\"all consumers exited, no more samples\")\r\nValueError: all consumers exited, no more samples\r\n\r\n2019-11-20 17:07:33,468-INFO: iter: 420, lr: 0.000002, 'loss': '33.105843', time: 0.096, eta: 0:31:16\r\n2019-11-20 17:07:35,167-INFO: iter: 440, lr: 0.000002, 'loss': '21.036983', time: 0.085, eta: 0:27:38\r\n2019-11-20 17:07:36,835-INFO: iter: 460, lr: 0.000002, 'loss': '21.888847', time: 0.084, eta: 0:27:15\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 358, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 245, in main\r\n    outs = exe.run(compiled_train_prog, fetch_list=train_values)\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/six.py\", line 696, in reraise\r\n    raise value\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 770, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 829, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/home/zhangyu/.local/lib/python3.5/site-packages/paddle/fluid/executor.py\", line 669, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:90]\r\n",
        "state": "closed",
        "user": "yhzhangyu",
        "closed_by": "yhzhangyu",
        "created_at": "2019-11-20T09:22:18+00:00",
        "updated_at": "2019-11-22T04:36:09+00:00",
        "closed_at": "2019-11-22T04:36:09+00:00",
        "comments_count": [
            "jerrywgz",
            "yhzhangyu",
            "jerrywgz",
            "yhzhangyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3963,
        "title": "PaddlePaddle is not utilizing GPU fully",
        "body": "As I'm using the Dialogue-PLATO model, My Nvidia Volta v100 GPU seems to be not fully utilized:\r\n![Screen Shot 2019-11-18 at 1 33 51 PM](https://user-images.githubusercontent.com/20453742/69239377-565c9a80-0b9a-11ea-930a-e9e35cc68dfd.png)\r\n\r\nWhile other models I tested have been utilizing the GPU fully. I'm running on batch size 1. When bs is 2 I get an OOM error. I tried playing with `FLAGS_fraction_of_gpu_memory_to_use` but to no avail.",
        "state": "closed",
        "user": "dimeldo",
        "closed_by": "dimeldo",
        "created_at": "2019-11-20T12:34:56+00:00",
        "updated_at": "2019-11-20T12:40:07+00:00",
        "closed_at": "2019-11-20T12:40:07+00:00",
        "comments_count": [
            "dimeldo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3968,
        "title": "使用图像分类进行训练报错",
        "body": "Ubuntu 16.04 + cuda 9.0 + cudnn 7.6.1 + paddlepaddle 1.6.1 + python 3.5.2,使用从github上下载的代码，加载自定义的数据进行图像分类训练报错：\r\nroot@P510:/home/work/models/PaddleCV/image_classification# python3 train.py --model=ResNet50 --batch_size=4 --total_images=8178 --class_dim=2 --image_shape=3,224,224 --model_save_dir=output/ --lr_strategy=piecewise_decay --lr=0.1 --data_dir=/home/work/Data --use_gpu=true\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 4\r\n               checkpoint : None\r\n                class_dim : 2\r\n                crop_size : 224\r\n                 data_dir : /home/work/Data\r\n             decay_epochs : 2.4\r\n               decay_rate : 0.97\r\n        drop_connect_rate : 0.2\r\n                ema_decay : 0.9999\r\n               image_mean : [0.485, 0.456, 0.406]\r\n              image_shape : 3,224,224\r\n                image_std : [0.229, 0.224, 0.225]\r\n            interpolation : None\r\n              is_profiler : 0\r\n                 l2_decay : 0.0001\r\n  label_smoothing_epsilon : 0.1\r\n              lower_ratio : 0.75\r\n              lower_scale : 0.08\r\n                       lr : 0.1\r\n              lr_strategy : piecewise_decay\r\n                 max_iter : 0\r\n              mixup_alpha : 0.2\r\n                    model : ResNet50\r\n           model_save_dir : output/\r\n            momentum_rate : 0.9\r\n               num_epochs : 120\r\n             padding_type : SAME\r\n         pretrained_model : None\r\n               print_step : 10\r\n            profiler_path : ./\r\n              random_seed : None\r\n          reader_buf_size : 2048\r\n            reader_thread : 8\r\n        resize_short_size : 256\r\n                save_step : 1\r\n              step_epochs : [30, 60, 90]\r\n          test_batch_size : 16\r\n             total_images : 8178\r\n              upper_ratio : 1.3333333333333333\r\n                   use_aa : False\r\n                  use_ema : False\r\n                  use_gpu : 1\r\n      use_label_smoothing : False\r\n                use_mixup : False\r\n                   use_se : True\r\n                 validate : 1\r\n           warm_up_epochs : 5.0\r\n----------------------------------------------------\r\nW1122 18:14:27.471949  3272 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW1122 18:14:27.475286  3272 device_context.cc:243] device: 0, cuDNN Version: 7.6.\r\nI1122 18:14:28.221356  3272 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI1122 18:14:28.250690  3272 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1122 18:14:28.286288  3272 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1122 18:14:28.305943  3272 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py:774: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 258, in <module>\r\n    main()\r\n  File \"train.py\", line 254, in main\r\n    train(args)\r\n  File \"train.py\", line 208, in train\r\n    fetch_list=train_fetch_list)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/lib/python3/dist-packages/six.py\", line 686, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 770, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 829, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 669, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::TopkOp::InferShape(paddle::framework::InferShapeContext*) const\r\n3   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const\r\n5   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\r\n6   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n7   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n8   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n9   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n10  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n11  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py\", line 2459, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/nn.py\", line 7127, in topk\r\n    attrs=attrs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/metric_op.py\", line 87, in accuracy\r\n    topk_out, topk_indices = nn.topk(input, k=k)\r\n  File \"/home/work/models/PaddleCV/image_classification/build_model.py\", line 51, in _basic_model\r\n    acc_top5 = fluid.layers.accuracy(input=softmax_out, label=label, k=5)\r\n  File \"/home/work/models/PaddleCV/image_classification/build_model.py\", line 118, in create_model\r\n    loss_out = _basic_model(data, model, args, is_train)\r\n  File \"train.py\", line 77, in build_program\r\n    data_loader, loss_out = create_model(model, args, is_train)\r\n  File \"train.py\", line 151, in train\r\n    args=args)\r\n  File \"train.py\", line 254, in main\r\n    train(args)\r\n  File \"train.py\", line 258, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPaddleCheckError: Expected input_dims[input_dims.size() - 1] >= k, but received input_dims[input_dims.size() - 1]:2 < k:5.\r\ninput must have >= k columns at [/paddle/paddle/fluid/operators/top_k_op.cc:40]\r\n  [operator < top_k > error]\r\nterminate called without an active exception\r\nW1122 18:14:28.673591  3314 init.cc:205] *** Aborted at 1574417668 (unix time) try \"date -d @1574417668\" if you are using GNU date ***\r\nW1122 18:14:28.676206  3314 init.cc:205] PC: @                0x0 (unknown)\r\nW1122 18:14:28.676353  3314 init.cc:205] *** SIGABRT (@0xcc8) received by PID 3272 (TID 0x7fa1b77fe700) from PID 3272; stack trace: ***\r\nW1122 18:14:28.678809  3314 init.cc:205]     @     0x7fa290b4d390 (unknown)\r\nW1122 18:14:28.681226  3314 init.cc:205]     @     0x7fa2907a7428 gsignal\r\nW1122 18:14:28.682956  3314 init.cc:205]     @     0x7fa2907a902a abort\r\nW1122 18:14:28.684118  3314 init.cc:205]     @     0x7fa27fe1a84d __gnu_cxx::__verbose_terminate_handler()\r\nW1122 18:14:28.685487  3314 init.cc:205]     @     0x7fa27fe186b6 (unknown)\r\nW1122 18:14:28.686635  3314 init.cc:205]     @     0x7fa27fe18701 std::terminate()\r\nW1122 18:14:28.687683  3314 init.cc:205]     @     0x7fa27fe182e0 __gxx_personality_v0\r\nW1122 18:14:28.688696  3314 init.cc:205]     @     0x7fa28033b059 (unknown)\r\nW1122 18:14:28.689709  3314 init.cc:205]     @     0x7fa28033b3b4 _Unwind_ForcedUnwind\r\nW1122 18:14:28.691023  3314 init.cc:205]     @     0x7fa290b4c070 __GI___pthread_unwind\r\nW1122 18:14:28.692456  3314 init.cc:205]     @     0x7fa290b44845 __pthread_exit\r\nW1122 18:14:28.692644  3314 init.cc:205]     @           0x623f35 PyThread_exit_thread\r\nW1122 18:14:28.692802  3314 init.cc:205]     @           0x530264 PyEval_RestoreThread\r\nW1122 18:14:28.693331  3314 init.cc:205]     @     0x7fa271edc7ba (unknown)\r\nW1122 18:14:28.693490  3314 init.cc:205]     @           0x4e1307 PyCFunction_Call\r\nW1122 18:14:28.693657  3314 init.cc:205]     @           0x530b94 PyEval_EvalFrameEx\r\nW1122 18:14:28.693820  3314 init.cc:205]     @           0x5350e4 PyEval_EvalFrameEx\r\nW1122 18:14:28.693984  3314 init.cc:205]     @           0x53a81b PyEval_EvalCodeEx\r\nW1122 18:14:28.694154  3314 init.cc:205]     @           0x4e3537 (unknown)\r\nW1122 18:14:28.694278  3314 init.cc:205]     @           0x5c3bd7 PyObject_Call\r\nW1122 18:14:28.694414  3314 init.cc:205]     @           0x5f7968 (unknown)\r\nW1122 18:14:28.694522  3314 init.cc:205]     @           0x5c3bd7 PyObject_Call\r\nW1122 18:14:28.694653  3314 init.cc:205]     @           0x5354af PyEval_EvalFrameEx\r\nW1122 18:14:28.694779  3314 init.cc:205]     @           0x53af6a PyEval_EvalCodeEx\r\nW1122 18:14:28.694914  3314 init.cc:205]     @           0x4e3537 (unknown)\r\nW1122 18:14:28.695022  3314 init.cc:205]     @           0x5c3bd7 PyObject_Call\r\nW1122 18:14:28.695153  3314 init.cc:205]     @           0x532a22 PyEval_EvalFrameEx\r\nW1122 18:14:28.695284  3314 init.cc:205]     @           0x5350e4 PyEval_EvalFrameEx\r\nW1122 18:14:28.695415  3314 init.cc:205]     @           0x5350e4 PyEval_EvalFrameEx\r\nW1122 18:14:28.695538  3314 init.cc:205]     @           0x53a81b PyEval_EvalCodeEx\r\nW1122 18:14:28.695672  3314 init.cc:205]     @           0x4e3423 (unknown)\r\nW1122 18:14:28.695799  3314 init.cc:205]     @           0x5c3bd7 PyObject_Call\r\n已放弃 (核心已转储)\r\nroot@P510:/home/work/models/PaddleCV/image_classification# \r\n",
        "state": "closed",
        "user": "ff3141044702",
        "closed_by": "ff3141044702",
        "created_at": "2019-11-22T02:26:52+00:00",
        "updated_at": "2019-11-22T04:33:11+00:00",
        "closed_at": "2019-11-22T04:33:10+00:00",
        "comments_count": [
            "ff3141044702"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3969,
        "title": "关于数据集转换提取的问题",
        "body": "想咨询一下  您这边当时提供了cityscape数据集转换为coco数据集格式\r\n假如原cityscape数据集有30类  但我只想要其中的5类进行训练\r\n是直接在转换数据集的脚本中进行操作  还是在代码中加条件  在训练时进行提取呢？\r\n谢谢",
        "state": "open",
        "user": "shuxsu",
        "closed_by": null,
        "created_at": "2019-11-22T02:52:25+00:00",
        "updated_at": "2019-11-27T06:15:18+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang",
            "shuxsu",
            "shuxsu",
            "LielinJiang",
            "shuxsu",
            "shuxsu",
            "LielinJiang",
            "shuxsu",
            "shuxsu",
            "LielinJiang",
            "LielinJiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3970,
        "title": "you should delete the master tree",
        "body": "you should delete the master tree. In that tree ,there is nothong info for us to use",
        "state": "open",
        "user": "BeyondYourself",
        "closed_by": null,
        "created_at": "2019-11-22T08:42:59+00:00",
        "updated_at": "2019-11-25T10:43:20+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3972,
        "title": "layer_norm使用问题",
        "body": "layer_norm在使用时会强制tensor的编译时shape和运行时shape相同吗？在使用的时候，遇到了以下的问题\r\n![image](https://user-images.githubusercontent.com/14270174/69508436-ac518980-0f70-11ea-8d72-232233481189.png)\r\n输入tensor的shape如下：\r\n![image](https://user-images.githubusercontent.com/14270174/69508452-b7a4b500-0f70-11ea-96cf-78c3d610a63c.png)\r\n\r\n",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-11-25T02:48:39+00:00",
        "updated_at": "2019-11-25T10:02:23+00:00",
        "closed_at": "2019-11-25T10:02:23+00:00",
        "comments_count": [
            "littletomatodonkey",
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3971,
        "title": "ctr  下的dcn模型在云服务器运行失败",
        "body": "自己在本地跑dcn模型https://github.com/PaddlePaddle/models/tree/develop/PaddleRec/ctr/dcn可以成功运行,但是在云端服务器运行时，跑不通，第一次用的百度的aistudio，第二次租了其他的服务器，都是哦linux 环境。这是第二次的输出日志。还请百度的小哥哥帮我看看。本地跑的话太慢了，完全无法调试模型。前面有我发的第一次在aistudio跑的模型日志，下面是第二次的\r\nepoch1 start ...\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n(dl) root@562de4acacdf:/input/data/data/dcn# ;j;o\r\n-bash: 未预期的符号 `;' 附近有语法错误\r\n[1]+  已杀死               python -u local_train.py > train.log\r\n(dl) root@562de4acacdf:/input/data/data/dcn# python -u local_train.py > train.log &\r\n[1] 7719\r\n(dl) root@562de4acacdf:/input/data/data/dcn# \r\nepoch1 start ...\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\nTraceback (most recent call last):\r\n    criteo_dataset.run_from_stdin()\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    criteo_dataset.run_from_stdin()\r\n    sys.stdout.write(self._gen_str(sample))\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    sys.stdout.write(self._gen_str(sample))\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nTraceback (most recent call last):\r\n  File \"reader.py\", line 96, in <module>\r\n    criteo_dataset.run_from_stdin()\r\n  File \"/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 135, in run_from_stdin\r\n    sys.stdout.write(self._gen_str(sample))\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n\r\n",
        "state": "open",
        "user": "LBSIX",
        "closed_by": null,
        "created_at": "2019-11-22T15:19:01+00:00",
        "updated_at": "2021-04-17T15:05:55+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang",
            "yolearn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3973,
        "title": "关于在两块GPU下batch_size与max_iter的选择",
        "body": "我这边正在使用COCO数据集从darknet53开始训练一个Paddle版本的yolov3。我在研究输入参数时发现batch_size默认为8，但是这是以8个GPU为基础的batch参数。我这里只有2个RTX-2080Ti显卡，如果想要达到网页上类似的测试效果，是否需要根据GPU调节batch_size或max_iter？另外，其他的参数是否也需要调节？谢谢\r\n\r\nPS：我尝试将batch_size改为16，发现运行2-3分钟就有Out of Memory的问题。使用batch_size=8（其余的不改）训练到最后，发现与网页上宣称的map少了4个百分点。",
        "state": "open",
        "user": "ShuoWillWang",
        "closed_by": null,
        "created_at": "2019-11-25T03:00:22+00:00",
        "updated_at": "2019-11-27T10:36:56+00:00",
        "closed_at": null,
        "comments_count": [
            "shuxsu",
            "ShuoWillWang",
            "shuxsu",
            "ShuoWillWang",
            "shuxsu",
            "ShuoWillWang",
            "shuxsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3975,
        "title": "bert fp32 和fp16运行失败",
        "body": "\r\npaddle commit-id :691ced87c087d3b25c2069e96c74c17a36ff2de2\r\nfp32报错如下：\r\n```bash\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\nbert_config_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/bert_config.json\r\ncheckpoints: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/save\r\ndata_dir: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/data\r\ndecr_every_n_nan_or_inf: 2\r\ndecr_ratio: 0.8\r\ndo_lower_case: True\r\ndo_test: True\r\ndo_train: True\r\ndo_val: True\r\nenable_ce: False\r\nepoch: 2\r\nin_tokens: False\r\nincr_every_n_steps: 1000\r\nincr_ratio: 2.0\r\ninit_checkpoint: None\r\ninit_loss_scaling: 4294967296\r\ninit_pretraining_params: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params\r\nlearning_rate: 5e-05\r\nlr_scheduler: linear_warmup_decay\r\nmax_seq_len: 128\r\nnum_iteration_per_drop_scope: 1\r\nrandom_seed: 1\r\nsave_steps: 1000\r\nshuffle: True\r\nskip_steps: 100\r\ntask_name: XNLI\r\nuse_cuda: True\r\nuse_dynamic_loss_scaling: True\r\nuse_fast_executor: False\r\nuse_fp16: False\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/vocab.txt\r\nwarmup_proportion: 0.1\r\nweight_decay: 0.01\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\ndirectionality: bidi\r\nhidden_act: gelu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nintermediate_size: 3072\r\nmax_position_embeddings: 512\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\npooler_fc_size: 768\r\npooler_num_attention_heads: 12\r\npooler_num_fc_layers: 3\r\npooler_size_per_head: 128\r\npooler_type: first_token_transform\r\ntype_vocab_size: 2\r\nvocab_size: 21128\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 392702\r\nMax train steps: 24543\r\nNum warmup steps: 2454\r\nW1124 22:17:56.750891 20557 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1124 22:17:56.756631 20557 device_context.cc:244] device: 0, cuDNN Version: 7.4.\r\nLoad pretraining parameters from /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params.\r\nI1124 22:18:00.329705 20557 parallel_executor.cc:423] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI1124 22:18:00.433110 20557 build_strategy.cc:364] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1124 22:18:00.579540 20557 parallel_executor.cc:287] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1124 22:18:00.645557 20557 parallel_executor.cc:370] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:773: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 331, in main\r\n    outputs = exe.run(train_compiled_program, fetch_list=fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 774, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 769, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 828, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 668, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n5   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n6   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n9   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2479, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 424, in _init_non_iterable\r\n    outputs={'Out': self._feed_list})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 331, in __init__\r\n    self._init_non_iterable()\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 258, in from_generator\r\n    return_list)\r\n  File \"/home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/model/classifier.py\", line 45, in create_model\r\n    feed_list=inputs, capacity=50, iterable=False)\r\n  File \"run_classifier.py\", line 211, in main\r\n    num_labels=num_labels)\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: The feeded Variable input_mask should have dimensions = 3, shape = [-1, 128, 1], but received feeded shape [32, 125, 1]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:133)\r\n  [operator < read > error]\r\n```\r\nfp16报错如下：\r\n```bash\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\nbert_config_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/bert_config.json\r\ncheckpoints: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/save\r\ndata_dir: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/data\r\ndecr_every_n_nan_or_inf: 2\r\ndecr_ratio: 0.8\r\ndo_lower_case: True\r\ndo_test: True\r\ndo_train: True\r\ndo_val: True\r\nenable_ce: False\r\nepoch: 2\r\nin_tokens: False\r\nincr_every_n_steps: 1000\r\nincr_ratio: 2.0\r\ninit_checkpoint: None\r\ninit_loss_scaling: 4294967296\r\ninit_pretraining_params: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params\r\nlearning_rate: 5e-05\r\nlr_scheduler: linear_warmup_decay\r\nmax_seq_len: 128\r\nnum_iteration_per_drop_scope: 1\r\nrandom_seed: 1\r\nsave_steps: 1000\r\nshuffle: True\r\nskip_steps: 100\r\ntask_name: XNLI\r\nuse_cuda: True\r\nuse_dynamic_loss_scaling: True\r\nuse_fast_executor: False\r\nuse_fp16: True\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/vocab.txt\r\nwarmup_proportion: 0.1\r\nweight_decay: 0.01\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\ndirectionality: bidi\r\nhidden_act: gelu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nintermediate_size: 3072\r\nmax_position_embeddings: 512\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\npooler_fc_size: 768\r\npooler_num_attention_heads: 12\r\npooler_num_fc_layers: 3\r\npooler_size_per_head: 128\r\npooler_type: first_token_transform\r\ntype_vocab_size: 2\r\nvocab_size: 21128\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 392702\r\nMax train steps: 24543\r\nNum warmup steps: 2454\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'dtype' in fluid.embedding only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in cast only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in dropout only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'y' in matmul only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in matmul only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'input' in fc only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in reshape only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in transpose only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'input' in softmax only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in mean only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'input' in accuracy only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\nW1124 23:13:03.476914 21451 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1124 23:13:03.490574 21451 device_context.cc:244] device: 0, cuDNN Version: 7.4.\r\nLoad pretraining parameters from /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params.\r\nCast parameters to float16 data format.\r\nI1124 23:13:08.745292 21451 parallel_executor.cc:423] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI1124 23:13:08.883260 21451 build_strategy.cc:364] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1124 23:13:09.099370 21451 parallel_executor.cc:287] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1124 23:13:09.196668 21451 parallel_executor.cc:370] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:773: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 331, in main\r\n    outputs = exe.run(train_compiled_program, fetch_list=fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 774, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 769, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 828, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 668, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::platform::float16 const* paddle::framework::Tensor::data<paddle::platform::float16>() const\r\n3   void paddle::operators::ElementwiseComputeEx<paddle::operators::MulFunctor<paddle::platform::float16, void>, paddle::platform::CUDADeviceContext, paddle::platform::float16, paddle::platform::float16>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, int, paddle::operators::MulFunctor<paddle::platform::float16, void>, paddle::framework::Tensor*)\r\n4   void paddle::operators::default_elementwise_mul<paddle::platform::CUDADeviceContext, paddle::platform::float16>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, paddle::framework::Tensor*)\r\n5   paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16>::Compute(paddle::framework::ExecutionContext const&) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 4ul, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, long>, paddle::operators::ElementwiseMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n8   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::details::ComputationOpHandle::RunImpl()\r\n11  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n12  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n13  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n14  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n15  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2479, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/math_op_patch.py\", line 239, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/optimization.py\", line 153, in optimization\r\n    param.name] * weight_decay * scheduled_lr\r\n  File \"run_classifier.py\", line 227, in main\r\n    decr_ratio=args.decr_ratio)\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Tensor holds the wrong type, it holds float, but desires to be ::paddle::platform::float16.\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] at (/paddle/paddle/fluid/framework/tensor_impl.h:33)\r\n  [operator < elementwise_mul > error]\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-11-25T03:40:10+00:00",
        "updated_at": "2019-11-25T05:20:51+00:00",
        "closed_at": "2019-11-25T05:20:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3974,
        "title": "bert fp32 和fp16运行失败",
        "body": "\r\npaddle commit-id :691ced87c087d3b25c2069e96c74c17a36ff2de2\r\n```bash\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\nbert_config_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/bert_config.json\r\ncheckpoints: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/save\r\ndata_dir: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/data\r\ndecr_every_n_nan_or_inf: 2\r\ndecr_ratio: 0.8\r\ndo_lower_case: True\r\ndo_test: True\r\ndo_train: True\r\ndo_val: True\r\nenable_ce: False\r\nepoch: 2\r\nin_tokens: False\r\nincr_every_n_steps: 1000\r\nincr_ratio: 2.0\r\ninit_checkpoint: None\r\ninit_loss_scaling: 4294967296\r\ninit_pretraining_params: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params\r\nlearning_rate: 5e-05\r\nlr_scheduler: linear_warmup_decay\r\nmax_seq_len: 128\r\nnum_iteration_per_drop_scope: 1\r\nrandom_seed: 1\r\nsave_steps: 1000\r\nshuffle: True\r\nskip_steps: 100\r\ntask_name: XNLI\r\nuse_cuda: True\r\nuse_dynamic_loss_scaling: True\r\nuse_fast_executor: False\r\nuse_fp16: False\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/vocab.txt\r\nwarmup_proportion: 0.1\r\nweight_decay: 0.01\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\ndirectionality: bidi\r\nhidden_act: gelu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nintermediate_size: 3072\r\nmax_position_embeddings: 512\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\npooler_fc_size: 768\r\npooler_num_attention_heads: 12\r\npooler_num_fc_layers: 3\r\npooler_size_per_head: 128\r\npooler_type: first_token_transform\r\ntype_vocab_size: 2\r\nvocab_size: 21128\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 392702\r\nMax train steps: 24543\r\nNum warmup steps: 2454\r\nW1124 22:17:56.750891 20557 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1124 22:17:56.756631 20557 device_context.cc:244] device: 0, cuDNN Version: 7.4.\r\nLoad pretraining parameters from /home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/chinese_L-12_H-768_A-12/params.\r\nI1124 22:18:00.329705 20557 parallel_executor.cc:423] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI1124 22:18:00.433110 20557 build_strategy.cc:364] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1124 22:18:00.579540 20557 parallel_executor.cc:287] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1124 22:18:00.645557 20557 parallel_executor.cc:370] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:773: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 331, in main\r\n    outputs = exe.run(train_compiled_program, fetch_list=fetch_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 774, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 769, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 828, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 668, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n5   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n6   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n9   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2479, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 424, in _init_non_iterable\r\n    outputs={'Out': self._feed_list})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 331, in __init__\r\n    self._init_non_iterable()\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/reader.py\", line 258, in from_generator\r\n    return_list)\r\n  File \"/home/crim/benchmark/models/PaddleNLP/PaddleLARK/BERT/model/classifier.py\", line 45, in create_model\r\n    feed_list=inputs, capacity=50, iterable=False)\r\n  File \"run_classifier.py\", line 211, in main\r\n    num_labels=num_labels)\r\n  File \"run_classifier.py\", line 428, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: The feeded Variable input_mask should have dimensions = 3, shape = [-1, 128, 1], but received feeded shape [32, 125, 1]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:133)\r\n  [operator < read > error]\r\n```",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "ccmeteorljh",
        "created_at": "2019-11-25T03:37:17+00:00",
        "updated_at": "2020-01-16T06:23:39+00:00",
        "closed_at": "2020-01-16T06:23:38+00:00",
        "comments_count": [
            "ccmeteorljh",
            "ccmeteorljh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3979,
        "title": "batch_norm效果异常求解答",
        "body": "实现了一个ranknet，网络是fc-bn-fc-bn-fc-bn-fc-bn-fc-bn-fc，fc神经元的数量除了最后一层是1，其他都是32. fc没有激活，bn用的relu。 输入是 样本label永远是1，左边是pos，右边是neg，左边永远大于右边；设计是希望pos和neg走同一个上面的网络，计算出最后一层结果，然后进入margin_rank_loss，所以永远是pos-neg，然后做sigmoid和二元交叉熵logloss，最后取均值作为loss。\r\n逻辑是，希望网络能够根据特征计算相关性得分，然后pos-neg差值越大越好。\r\n\r\n**现在问题是，训练时loss迅速降为0.001，预测时效果很差**。加载训练好的模型再进行训练，loss 0.001，但是一旦bn使用全局状态（use_global_stats设为True，不更新bn参数，模拟预测），立刻loss暴涨。 辛苦帮忙看下是bn层有异常么？\r\n其中一层FC-bn\r\n![BaiduHi_2019-11-26_10-41-4](https://user-images.githubusercontent.com/9897441/69595050-5268c680-1039-11ea-8100-31e6072bf16e.png)\r\n最后一层fc\r\n![2](https://user-images.githubusercontent.com/9897441/69594918-ce164380-1038-11ea-8f4e-e97f17850061.png)\r\nloss的构成\r\n![3](https://user-images.githubusercontent.com/9897441/69594932-d53d5180-1038-11ea-8c51-8369d650ba60.png)\r\n",
        "state": "open",
        "user": "Archimondecy",
        "closed_by": null,
        "created_at": "2019-11-26T02:38:38+00:00",
        "updated_at": "2019-11-28T09:01:02+00:00",
        "closed_at": null,
        "comments_count": [
            "cyj1986"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3978,
        "title": "DGU支持中文训练数据吗？",
        "body": "![image](https://user-images.githubusercontent.com/28988355/69592138-fd748280-102f-11ea-9634-2cc449a8ffa7.png)\r\n",
        "state": "open",
        "user": "jtyoui",
        "closed_by": null,
        "created_at": "2019-11-26T01:35:03+00:00",
        "updated_at": "2019-11-28T02:21:39+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3984,
        "title": "x2coco.py 程序无法正常运行",
        "body": "1、设置test_proportion 0.0   时\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/iot/dataset_my/coco_pothole1/test/737.jpg'\r\n\r\n\r\n2、设置了test_propotion不为0时找不到json_path\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./ppdet/data/tools/x2coco.py\", line 294, in <module>\r\n    main()\r\n  File \"./ppdet/data/tools/x2coco.py\", line 280, in main\r\n    val_data_coco = deal_json(args.output_dir + '/val', args.json_input_dir)\r\nTypeError: deal_json() missing 1 required positional argument: 'json_path'",
        "state": "closed",
        "user": "ss3b3",
        "closed_by": "ss3b3",
        "created_at": "2019-11-26T06:12:50+00:00",
        "updated_at": "2019-11-26T06:14:04+00:00",
        "closed_at": "2019-11-26T06:14:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3986,
        "title": "x2coco.py 程序无法正常运行",
        "body": "1、设置test_proportion 0.0   时\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/iot/dataset_my/coco_pothole1/test/737.jpg'\r\n\r\n\r\n2、设置了test_propotion不为0时找不到json_path\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./ppdet/data/tools/x2coco.py\", line 294, in <module>\r\n    main()\r\n  File \"./ppdet/data/tools/x2coco.py\", line 280, in main\r\n    val_data_coco = deal_json(args.output_dir + '/val', args.json_input_dir)\r\nTypeError: deal_json() missing 1 required positional argument: 'json_path'",
        "state": "closed",
        "user": "ss3b3",
        "closed_by": "ss3b3",
        "created_at": "2019-11-26T06:12:50+00:00",
        "updated_at": "2019-11-26T06:14:47+00:00",
        "closed_at": "2019-11-26T06:14:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3985,
        "title": "x2coco.py 程序无法正常运行",
        "body": "1、设置test_proportion 0.0   时\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/iot/dataset_my/coco_pothole1/test/737.jpg'\r\n\r\n\r\n2、设置了test_propotion不为0时找不到json_path\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./ppdet/data/tools/x2coco.py\", line 294, in <module>\r\n    main()\r\n  File \"./ppdet/data/tools/x2coco.py\", line 280, in main\r\n    val_data_coco = deal_json(args.output_dir + '/val', args.json_input_dir)\r\nTypeError: deal_json() missing 1 required positional argument: 'json_path'",
        "state": "closed",
        "user": "ss3b3",
        "closed_by": "ss3b3",
        "created_at": "2019-11-26T06:12:50+00:00",
        "updated_at": "2019-11-26T06:14:36+00:00",
        "closed_at": "2019-11-26T06:14:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3981,
        "title": "关于多卡训练Detection",
        "body": "咨询一些问题\r\n之前是单卡p4000训练\r\n现在是4张2080ti\r\n为什么同样的config  训练的速度并没有提升呢  \r\nbatch_size只能设置为2  超过2就out of memory\r\nnorm type：affine_channel   设置bn连2都会报out of memory\r\n还有num_workers这个多线程只和cpu相关么   设置有什么建议或要求吗\r\n时间并没有变快是什么原因呢？\r\n\r\n有没有关于paddle的相关训练 调参建议呢   ",
        "state": "open",
        "user": "shuxsu",
        "closed_by": null,
        "created_at": "2019-11-26T03:24:03+00:00",
        "updated_at": "2019-11-28T04:27:18+00:00",
        "closed_at": null,
        "comments_count": [
            "cyj1986"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3982,
        "title": "关于多卡训练Detection显存溢出的问题",
        "body": "使用快速开始的示例程序（yolo识别水果）的能够正常使用4个GPU，同样config换成自定义的数据集就无法多卡使用，程序启动时仅仅使用0号GPU，然后爆显存，程序卡死，nvidia-smi读取不到GPU，每次都需要重启\r\ngpu是4张TITAn X（Pascal）11G显存\r\n内存64G",
        "state": "open",
        "user": "ss3b3",
        "closed_by": null,
        "created_at": "2019-11-26T05:58:57+00:00",
        "updated_at": "2019-12-03T11:34:43+00:00",
        "closed_at": null,
        "comments_count": [
            "cyj1986",
            "cyj1986",
            "shuxsu",
            "ss3b3",
            "cyj1986",
            "cyj1986",
            "ss3b3",
            "shuxsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3983,
        "title": "x2coco.py 程序无法正常运行",
        "body": "1、设置test_proportion 0.0   时\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/iot/dataset_my/coco_pothole1/test/737.jpg'\r\n\r\n\r\n2、设置了test_propotion不为0时找不到json_path\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./ppdet/data/tools/x2coco.py\", line 294, in <module>\r\n    main()\r\n  File \"./ppdet/data/tools/x2coco.py\", line 280, in main\r\n    val_data_coco = deal_json(args.output_dir + '/val', args.json_input_dir)\r\nTypeError: deal_json() missing 1 required positional argument: 'json_path'",
        "state": "open",
        "user": "ss3b3",
        "closed_by": null,
        "created_at": "2019-11-26T06:12:49+00:00",
        "updated_at": "2019-12-08T02:45:01+00:00",
        "closed_at": null,
        "comments_count": [
            "cyj1986",
            "shuxsu",
            "ss3b3",
            "shuxsu",
            "ss3b3",
            "shuxsu",
            "shuxsu",
            "shuxsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3987,
        "title": "paddleDetection yaml中的batch_size在同步和异步读取时的含义",
        "body": "代码：paddleDeteciton\r\n环境：v100,  paddle1.5.1； GPU=2；batch_size=1\r\n\r\n背景：将paddleDeteciton yaml文件中的batch_size设为1，两个gpu训练，原始代码训练正常；但由于业务需求，需将异步读取改为同步读取，即feed模式，训练报错；\r\n![image](https://user-images.githubusercontent.com/20673237/69608305-1eee6200-1062-11ea-87b3-fe1dbea44810.png)\r\n\r\n问题：\r\n1. yml 里的 batch_size ，对于异步读取的pyreader来说是每个GPU的batch_size；\r\n对于同步读取的feed来说是所有GPUs的总batch_size;  \r\n请问是什么原因导致这样的差别？是否有策略让两种读取方式最后输出的batch_size保持一致？\r\n2.每个迭代 Images分配给GPUs的策略  平均分？还是优先第一个gpu?\r\n",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-11-26T07:10:30+00:00",
        "updated_at": "2019-11-26T14:28:12+00:00",
        "closed_at": null,
        "comments_count": [
            "sneaxiy",
            "shuxsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3988,
        "title": "PaddleCV/image_classification/下的脚本在CPU版的paddle报错",
        "body": "涉及到两个脚本\r\n1：reader.py 271行\r\nbatch_size = settings.batch_size / paddle.fluid.core.get_cuda_device_count() \r\n2：utils/utility.py 419行\r\nexec_strategy.num_threads = fluid.core.get_cuda_device_count()\r\n\r\n",
        "state": "closed",
        "user": "zouxiaodong",
        "closed_by": "shippingwang",
        "created_at": "2019-11-26T07:35:33+00:00",
        "updated_at": "2019-12-02T05:17:22+00:00",
        "closed_at": "2019-12-02T05:17:22+00:00",
        "comments_count": [
            "cyj1986",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3989,
        "title": "能否在image_classification的训练脚本里面增加visualdl可视化输出？",
        "body": "现在的脚本训练时只能在控制台看输出，无法可视化看效果",
        "state": "closed",
        "user": "zouxiaodong",
        "closed_by": "shippingwang",
        "created_at": "2019-11-26T07:37:09+00:00",
        "updated_at": "2019-12-02T05:17:13+00:00",
        "closed_at": "2019-12-02T05:17:13+00:00",
        "comments_count": [
            "linshuliang",
            "zouxiaodong",
            "linshuliang",
            "zouxiaodong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3999,
        "title": "有提供中文-wwm的预训练模型么。适用于paddle的bert的版本的。",
        "body": null,
        "state": "open",
        "user": "baymaxZ0Z0",
        "closed_by": null,
        "created_at": "2019-11-28T02:24:22+00:00",
        "updated_at": "2024-02-26T05:13:50+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4008,
        "title": "可以将训练好的caffe模型进行int8量化吗？",
        "body": "你好，请问一下，我有一个训练好的caffe模型，如何将这个模型进行int8量化，看文档说明好像只能量化几个固定网络架构的模型，谢谢",
        "state": "closed",
        "user": "Wayne-pw",
        "closed_by": "Wayne-pw",
        "created_at": "2019-11-28T11:46:49+00:00",
        "updated_at": "2019-11-28T12:42:43+00:00",
        "closed_at": "2019-11-28T12:42:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3995,
        "title": "image_classification 训练自定义数据集batch问题",
        "body": "数据集总共:6390，训练集有 5112行记录，batch_size设置为8,训练脚本输出的batch,train 和 test 只到70+\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/46236818/69712327-98a74e00-113d-11ea-8a6f-7fc9394f62f8.png)\r\n\r\n\r\n\r\n执行的脚本如下：\r\npython train.py \\\r\n       --data_dir=/root/paddle/lemon/data/ \\\r\n       --model=ResNet50 \\\r\n       --batch_size=8 \\\r\n       --total_images=6390 \\\r\n       --class_dim=3 \\\r\n       --image_shape=3,900,900 \\\r\n       --model_save_dir=/root/paddle/lemon/train_model/ \\\r\n       --lr_strategy=piecewise_decay \\\r\n       --lr=0.1 \\\r\n       --reader_thread=8 \\\r\n       --use_gpu=false",
        "state": "closed",
        "user": "zouxiaodong",
        "closed_by": "shippingwang",
        "created_at": "2019-11-27T09:45:02+00:00",
        "updated_at": "2019-12-02T05:17:05+00:00",
        "closed_at": "2019-12-02T05:17:05+00:00",
        "comments_count": [
            "zouxiaodong",
            "xyoungli",
            "zouxiaodong",
            "xyoungli",
            "zouxiaodong",
            "shippingwang",
            "zouxiaodong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 3991,
        "title": "CoKE中使用kbc_test.sh脚本做评估时，GPU Memory Usage占满而GPU-Util却为0%",
        "body": "sh kbc_test.sh ./configs/fb15k_job_config.sh 1\r\n![image](https://user-images.githubusercontent.com/26144974/69696691-70a6f300-111b-11ea-9f07-d2aa9922dca9.png)\r\n\r\n",
        "state": "open",
        "user": "WonderMind",
        "closed_by": null,
        "created_at": "2019-11-27T05:40:45+00:00",
        "updated_at": "2019-11-28T09:36:43+00:00",
        "closed_at": null,
        "comments_count": [
            "xyoungli",
            "WonderMind",
            "xyoungli"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4005,
        "title": "在自己的数据集上通过 finetune 训练出来的图像分类模型，如何进行模型合并和测试？",
        "body": "你好，我是 paddle 新手，参考 [图像分类以及模型库](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification) 的内容，在自己的数据集上进行 finetune 训练图像分类模型，使用的命令是\r\n```shell\r\npython train.py --data_dir=data/Faces --model=MobileNetV1_x0_25 --pretrained_model=pre_trained_model/MobileNetV1_x0_25_pretrained --batch_size=16 --total_images=49779 \r\n--class_dim=2 --image_shape=3,224,224 --model_save_dir=output/ --lr_strategy=piecewise_decay --lr=0.001\r\n```\r\n训练后在 output/MobileNetV1_x0_25 目录下得到了每个epoch保存的模型\r\n![image](https://user-images.githubusercontent.com/13940249/69786466-74a74380-11f5-11ea-92e2-b3bad19b3766.png)\r\n每个文件夹中有200多个文件\r\n![image](https://user-images.githubusercontent.com/13940249/69786510-8d175e00-11f5-11ea-9b66-9adab6a7be20.png)\r\n \r\n怎么把这些模型文件合并，转为`__model__` 文件呢？在 [#1022](https://github.com/PaddlePaddle/models/issues/1022) 看到一句 “可以先自行使用 fluid.io.save_inference_model保存，便有了__model__ 文件。”，但是 save_inference_model 函数的几个参数不知道怎么给啊，能不能给个完整的例子，谢谢！",
        "state": "open",
        "user": "zhaotun",
        "closed_by": null,
        "created_at": "2019-11-28T08:30:02+00:00",
        "updated_at": "2019-12-04T01:17:29+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "zhaotun",
            "shippingwang",
            "zhaotun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4010,
        "title": "ResNeXt101_32x48d_wsl 继续训练时checkpoint 出错",
        "body": "这是报错信息\r\n\r\n```\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPaddleCheckError: Cannot open file output/ResNeXt101_32x48d_wsl/9/tmp_4 for load op at [/paddle/paddle/fluid/operators/load_op.h:37]\r\n  [operator < load > error]\r\n```\r\n这是配置\r\n\r\n```\r\n##Training details\r\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\r\nexport FLAGS_fast_eager_deletion_mode=1\r\nexport FLAGS_eager_delete_tensor_gb=0.0\r\nexport FLAGS_fraction_of_gpu_memory_to_use=0.98\r\n\r\npython train.py \\\r\n       --model=ResNeXt101_32x48d_wsl \\\r\n       --batch_size=128 \\\r\n       --total_images=12000 \\\r\n       --class_dim=121 \\\r\n       --image_shape=3,224,224 \\\r\n       --model_save_dir=output/ \\\r\n       --lr_strategy=cosine_decay \\\r\n       --num_epochs=260 \\\r\n       --lr=0.1 \\\r\n       --reader_thread=4 \\\r\n       --l2_decay=1e-4 \\\r\n       --checkpoint=\"output/ResNeXt101_32x48d_wsl/9/\"\r\n\r\n```\r\n\r\n自动保存的时候没保存这个tmp_4吗？\r\n",
        "state": "open",
        "user": "Otis4631",
        "closed_by": null,
        "created_at": "2019-11-29T10:39:01+00:00",
        "updated_at": "2019-12-10T12:39:08+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "Otis4631",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4012,
        "title": "调用image_classification的eval.py脚本报错",
        "body": "训练时输入shape为3，900，900\r\npython eval.py \\\r\n       --data_dir=/root/paddle/lemon/data/augmentation/ \\\r\n       --model=ResNet50 \\\r\n       --batch_size=8 \\\r\n       --class_dim=3 \\\r\n       --image_shape=3,900,900 \\\r\n       --crop_size=900 \\\r\n       --use_gpu=false \\\r\n       --pretrained_model=/root/paddle/lemon/new_train_model/ResNet50/119/\r\n\r\n==错误信息如下：\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 8\r\n                class_dim : 3\r\n                crop_size : 900\r\n                 data_dir : /root/paddle/lemon/data/augmentation/\r\n               image_mean : [0.485, 0.456, 0.406]\r\n              image_shape : 3,900,900\r\n                image_std : [0.229, 0.224, 0.225]\r\n            interpolation : None\r\n                    model : ResNet50\r\n             padding_type : SAME\r\n         pretrained_model : /root/paddle/lemon/new_train_model/ResNet50/119/\r\n          reader_buf_size : 2048\r\n            reader_thread : 8\r\n        resize_short_size : 256\r\n                  use_gpu : 0\r\n                   use_se : True\r\n----------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 154, in <module>\r\n    main()\r\n  File \"eval.py\", line 150, in main\r\n    eval(args)\r\n  File \"eval.py\", line 119, in eval\r\n    feed=feeder.feed(data))\r\n  File \"/root/miniconda3/envs/lemon/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 296, in feed\r\n    ret_dict[each_name] = each_converter.done()\r\n  File \"/root/miniconda3/envs/lemon/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 105, in done\r\n    arr = numpy.array(self.data, dtype=self.dtype)\r\nValueError: could not broadcast input array from shape (3,256,297) into shape (3)\r\nterminate called without an active exception\r\nW1202 11:51:39.412518 13898 init.cc:205] *** Aborted at 1575258699 (unix time) try \"date -d @1575258699\" if you are using GNU date ***\r\nW1202 11:51:39.416721 13898 init.cc:205] PC: @                0x0 (unknown)\r\nFATAL: exception not rethrown\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/46236818/69926451-8176b080-14ef-11ea-8514-a934e92e4db0.png)\r\n",
        "state": "closed",
        "user": "zouxiaodong",
        "closed_by": "willthefrog",
        "created_at": "2019-12-02T02:36:26+00:00",
        "updated_at": "2019-12-02T07:00:09+00:00",
        "closed_at": "2019-12-02T07:00:09+00:00",
        "comments_count": [
            "willthefrog",
            "zouxiaodong",
            "shippingwang",
            "zouxiaodong"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4013,
        "title": "reshape输出shape的问题",
        "body": "在reshape中，如果参数shape是lodtensor的话，那么编译时，所有值都是-1，而conv2d要求channel必须是明确的值(>0)，感觉这一块需要修改一下，不然每次用tensor进行reshape的话，编译时就会报错~",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "littletomatodonkey",
        "created_at": "2019-12-02T03:54:32+00:00",
        "updated_at": "2019-12-02T07:15:34+00:00",
        "closed_at": "2019-12-02T07:15:33+00:00",
        "comments_count": [
            "liym27",
            "littletomatodonkey",
            "liym27",
            "littletomatodonkey",
            "liym27",
            "littletomatodonkey"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4014,
        "title": "KT-NET模型编码错误",
        "body": "数据集SQuAD中的数据夹杂一些Unicode编码例如L\\u00facia Moniz，KT-NET模型预处理时不能有效转化为正常的字符从而报错，不知如何解决",
        "state": "open",
        "user": "Soulmate303",
        "closed_by": null,
        "created_at": "2019-12-02T04:46:21+00:00",
        "updated_at": "2020-03-23T13:42:29+00:00",
        "closed_at": null,
        "comments_count": [
            "willthefrog",
            "kuke",
            "Soulmate303",
            "Soulmate303",
            "Dogy06"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4016,
        "title": "在训练过程中配置是默认存在resize的吗？在测试过程中并没有resize？是否会影响输出结果",
        "body": "使用的PaddleDetection的mask rcnn模型 发现在configs中默认存在resize\r\n我的图片尺寸过大都是2048.1024\r\n默认配置的resize后测试时是否会影响我的结果？",
        "state": "closed",
        "user": "shuxsu",
        "closed_by": "shuxsu",
        "created_at": "2019-12-02T06:44:42+00:00",
        "updated_at": "2019-12-30T02:44:18+00:00",
        "closed_at": "2019-12-30T02:44:18+00:00",
        "comments_count": [
            "willthefrog"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4021,
        "title": "我训练模型然后我用模型测试，结果数据里面说没有那个文件",
        "body": "PaddleCheckError: Cannot open file ./conv2d_61.w_0 for load op at [/paddle/paddle/fluid/operators/load_op.h:37]\r\n  [operator < load > error]\r\naistudio@jupyter-115314-196260:~/work/face_detection$  --model_dir=output/1/ --image_path=data/WIDER_train/images/0--Parade/0_Parade_Parade_0_605.jpg\r\nbash: --model_dir=output/1/: No such file or directory\r\n\r\n\r\npython widerface_eval.py --infer=True --confs_threshold=0.15\r\n --model_dir=output/1/ --image_path=data/WIDER_train/images/0--Parade/0_Parade_Parade_0_605.jpg\r\n\r\n\r\n在output/1/中有这个文件，但是读取不到。。。，我试了很多个都说不能读取这个文件\r\n\r\n![image](https://user-images.githubusercontent.com/49876859/70021985-8742c380-15cd-11ea-90f6-16ead2931c14.png)\r\n\r\n求解\r\n\r\nface_detection",
        "state": "open",
        "user": "LopSdir",
        "closed_by": null,
        "created_at": "2019-12-03T05:06:22+00:00",
        "updated_at": "2024-02-26T05:13:44+00:00",
        "closed_at": null,
        "comments_count": [
            "LielinJiang",
            "LopSdir",
            "shuxsu"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4019,
        "title": "faster rcnn r50网络设置max_iters为180000默认值是否过拟合？",
        "body": "麻烦请问：\r\n我用的是faster rcnn r50 1X网络进行训练\r\n数据集是我自己准备的数据，一共80张\r\n参数为默认参数：max_iters: 180000\r\n1、帮忙查看一下训练结果是否过拟合了？\r\n2、如果过拟合，训练参数设置多少比较合适？\r\n3、使用该网络进行训练，正常训练完成后训练日志中正常的参数为多少？\r\n![2830ef4e7523998aa5b6f339b8e05c2](https://user-images.githubusercontent.com/13723642/69948570-dedc2300-152a-11ea-8936-42b01ccf2dca.jpg)\r\n",
        "state": "open",
        "user": "michaelwangtd",
        "closed_by": null,
        "created_at": "2019-12-02T09:50:21+00:00",
        "updated_at": "2019-12-03T02:34:43+00:00",
        "closed_at": null,
        "comments_count": [
            "willthefrog",
            "michaelwangtd",
            "willthefrog",
            "michaelwangtd",
            "willthefrog",
            "willthefrog",
            "willthefrog"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4024,
        "title": "embedding层是否会提供word2vec或glove模型？",
        "body": "如题，paddle的embedding它是可以替换为其他的预训练的已有词向量，比如，word2vet或glove或conll05。但是paddle并没有提供word2vec或glove的，只提供了conll05。自己想要替换时，需要自己去改代码，改数据，比较繁琐。就问下是否会提供？",
        "state": "open",
        "user": "xiaoqinghuang",
        "closed_by": null,
        "created_at": "2019-12-04T03:38:52+00:00",
        "updated_at": "2024-02-26T05:13:43+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4026,
        "title": "多方向文字识别如何实现？目前的ocr model好像只能用于水平方向文字识别",
        "body": "比如现在有一行文字，里面的每个字顺时针或逆时针旋转了９０度（这种情况是存在的，比如一列中文汉字旋转到水平方向）；这中情况下应如何处理？由于目前的模型都是针对行文本设计的，是否应该再针对顺时针或逆时针旋转，分别训练两个文字识别模型？",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wenston2006",
        "created_at": "2019-12-04T08:25:34+00:00",
        "updated_at": "2019-12-11T01:05:20+00:00",
        "closed_at": "2019-12-11T01:05:20+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wenston2006"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4027,
        "title": "图像分类DALI出错",
        "body": "进行图像分类时使用DALI出错\r\n配置:nvidia-dali:0.16.0, paddle:1.6.1, gcc:5.4,cuda10\r\n我的运行指令:\r\nexport CUDA_VISIBLE_DEVICES=0,1,2,3 \r\nexport FLAGS_fraction_of_gpu_memory_to_use=0.80\r\npython -m paddle.distributed.launch train.py \\\r\n    --model=SE_ResNet50_vd \\\r\n    --pretrained_model=pretrain_model/SE_ResNet50_vd_pretrained/ \\\r\n    --batch_size=200 \\\r\n    --data_dir=data/terror_detail/ \\\r\n    --num_epochs=60 \\\r\n    --total_images=437462 \\\r\n    --class_dim=14 \\\r\n    --model_save_dir=terror/output_terror_detail/ \\\r\n    --lr_strategy=cosine_decay_warmup \\\r\n    --use_label_smoothing=True \\\r\n    --use_mixup=True \\\r\n    --use_dali=True \\\r\n    --reader_thread=4 \\\r\n    --lr=0.01\r\n错误是:\r\n                 validate : 1\r\n           warm_up_epochs : 5.0\r\n----------------------------------------------------\r\nW1204 09:21:20.665040  4048 device_context.cc:235] Please NOTE: device: 3, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1204 09:21:20.671504  4048 device_context.cc:243] device: 3, cuDNN Version: 7.6.\r\nW1204 09:21:20.693971  4045 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1204 09:21:20.700013  4045 device_context.cc:243] device: 0, cuDNN Version: 7.6.\r\nW1204 09:21:20.711027  4046 device_context.cc:235] Please NOTE: device: 1, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1204 09:21:20.716599  4046 device_context.cc:243] device: 1, cuDNN Version: 7.6.\r\nW1204 09:21:20.730718  4047 device_context.cc:235] Please NOTE: device: 2, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1204 09:21:20.735841  4047 device_context.cc:243] device: 2, cuDNN Version: 7.6.\r\nW1204 09:21:22.707733  4045 init.cc:205] *** Aborted at 1575451282 (unix time) try \"date -d @1575451282\" if you are using GNU date ***\r\nW1204 09:21:22.709415  4045 init.cc:205] PC: @                0x0 (unknown)\r\nW1204 09:21:22.709626  4045 init.cc:205] *** SIGSEGV (@0x0) received by PID 4045 (TID 0x7fa1d202c740) from PID 0; stack trace: ***",
        "state": "closed",
        "user": "dbcool",
        "closed_by": "shippingwang",
        "created_at": "2019-12-04T09:26:54+00:00",
        "updated_at": "2019-12-10T11:23:45+00:00",
        "closed_at": "2019-12-10T11:23:44+00:00",
        "comments_count": [
            "shippingwang",
            "dbcool",
            "shippingwang",
            "dbcool",
            "zhiqiu",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4029,
        "title": "resnet34 yolov3 paddleslim pruning问题",
        "body": "@wanghaoshuang \r\n您好，mobilenetv1 yolov3按照示例是可以pruning成功的，infer也正常。我想在resnet34 yolov3上编写配置文件进行pruning，报错了，仔细核对了代码，没找出问题出在哪里，可以帮忙看一下吗，多谢！\r\n配置文件如下：\r\n![image](https://user-images.githubusercontent.com/7035538/70142120-7c725680-16d3-11ea-9844-bfe6db75dfa5.png)\r\n进行Pruning报错如下：\r\n![image](https://user-images.githubusercontent.com/7035538/70142168-9875f800-16d3-11ea-8f30-865291cb2bd0.png)\r\n",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2019-12-04T12:21:58+00:00",
        "updated_at": "2019-12-05T03:02:05+00:00",
        "closed_at": "2019-12-05T03:02:05+00:00",
        "comments_count": [
            "A1exy",
            "wanghaoshuang",
            "A1exy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4031,
        "title": "ctcn 模型GPU报错 Each dimension size given in out_shape must be greater than 0",
        "body": "\r\n<img width=\"1429\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/52739577/70229970-434ceb80-1792-11ea-812f-90a22d29b782.png\">\r\n\r\n错误信息：\r\n<img width=\"989\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/52739577/70213803-3cfc4680-1775-11ea-9142-11bc67f0449d.png\">\r\n\r\n",
        "state": "open",
        "user": "hysunflower",
        "closed_by": null,
        "created_at": "2019-12-05T07:35:50+00:00",
        "updated_at": "2019-12-06T09:48:25+00:00",
        "closed_at": null,
        "comments_count": [
            "SunGaofeng",
            "hysunflower"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4038,
        "title": "运行DANet报错",
        "body": "model                         : danet\r\nbackbone                      : resnet101\r\ndataset                       : cityscapes\r\nnum_classes                   : 19\r\ndata_folder                   : ./dataset\r\nbase_size                     : 1024\r\ncrop_size                     : 768\r\naux                           : True\r\nse_loss                       : True\r\nepoch_num                     : 1200\r\nstart_epoch                   : 0\r\nbatch_size                    : 2\r\ntest_batch_size               : 2\r\nlr                            : 0.01\r\nlr_scheduler                  : poly\r\nlr_pow                        : 0.9\r\nlr_step                       : None\r\nwarm_up                       : False\r\nwarmup_epoch                  : 5\r\ntotal_step                    : 500000\r\nstep_per_epoch                : 185\r\nmomentum                      : 0.9\r\nweight_decay                  : 0.0001\r\ncuda                          : True\r\nuse_data_parallel             : True\r\nseed                          : 1\r\nlog_root                      : ./\r\nsave_model                    : ./checkpoint/\r\nload_pretrained_model         : True\r\nload_better_model             : False\r\nmulti_scales                  : True\r\nflip                          : True\r\ndilated                       : True\r\nmulti_grid                    : True\r\nmulti_dilation                : [4, 8, 16]\r\nscale                         : True\r\nGPU设备数量： 1\r\nbackbone resnet101, dilated=True, multi_grid=True, multi_dilation=[4, 8, 16]\r\nW1206 21:06:35.003026 59479 dynamic_loader.cc:120] Can not find library: libcublas.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\n  File \"train_dygraph.py\", line 315, in <module>\r\n    main(args)\r\n  File \"train_dygraph.py\", line 157, in main\r\n    model = get_model(args)\r\n  File \"train_dygraph.py\", line 43, in get_model\r\n    multi_dilation=args.multi_dilation)\r\n  File \"/ssd1/yulu/danet/danet.py\", line 597, in __init__\r\n    multi_grid=multi_grid, multi_dilation=multi_dilation)\r\n  File \"/ssd1/yulu/danet/danet.py\", line 194, in __init__\r\n    self._conv = ConvBN(name_scope, 64, 7, 2, act='relu')\r\n  File \"/ssd1/yulu/danet/danet.py\", line 71, in __init__\r\n    moving_variance_name='running_var'\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/dygraph/nn.py\", line 1268, in __init__\r\n    default_initializer=Constant(1.0))\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 101, in create_parameter\r\n    default_initializer)\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\", line 325, in create_parameter\r\n    **attr._to_kwargs(with_initializer=True))\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2377, in create_parameter\r\n    initializer(param, self)\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/initializer.py\", line 189, in __call__\r\n    stop_gradient=True)\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2486, in _prepend_op\r\n    kwargs.get(\"stop_gradient\", False))\r\n  File \"/home/yulu/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\", line 47, in trace_op\r\n    not stop_gradient)\r\npaddle.fluid.core_avx.EnforceNotMet: 0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::dynload::GetCublasDsoHandle()\r\n3   void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__cublasCreate_v2::operator()<cublasContext**>(cublasContext**)::{lambda()#1} ()> >()\r\n4   paddle::platform::CublasHandleHolder::CublasHandleHolder(CUstream_st*, cublasMath_t)\r\n5   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\r\n6   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\r\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\r\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n9   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\r\n10  paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\r\n11  paddle::imperative::PreparedOp::Prepare(paddle::framework::RuntimeContext const&, paddle::framework::OperatorWithKernel const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::map<std::string, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > >, std::less<std::string>, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > > > > > const&)\r\n12  paddle::imperative::OpBase::Run(std::map<std::string, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > >, std::less<std::string>, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > >, std::less<std::string>, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > > > > > const&)\r\n13  paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > >, std::less<std::string>, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > >, std::less<std::string>, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<paddle::imperative::VarBase>, std::allocator<std::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, bool)\r\nPaddleCheckError: Failed to find dynamic library: libcublas.so ( libcublas.so: cannot open shared object file: No such file or directory )\r\n Please specify its path correctly using following ways:\r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\n For instance, issue command: export LD_LIBRARY_PATH=...\r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177]",
        "state": "open",
        "user": "Anikily",
        "closed_by": null,
        "created_at": "2019-12-06T13:11:11+00:00",
        "updated_at": "2024-02-26T05:13:40+00:00",
        "closed_at": null,
        "comments_count": [
            "Exception-star",
            "Exception-star"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4039,
        "title": "GoogLeNet模型训练完成后读取参数出现问题",
        "body": "读取其他模型的参数均没有问题，但GoogLeNet出现问题：Traceback (most recent call last):\r\n  File \"D:/python_adver/attack_code/acc.py\", line 135, in <module>\r\n    out = fluid.layers.softmax(out_logits)\r\n  File \"D:\\python_adver\\attack_code\\venv\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 1983, in softmax\r\n    \"use_cudnn\": use_cudnn})\r\n  File \"D:\\python_adver\\attack_code\\venv\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"D:\\python_adver\\attack_code\\venv\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"D:\\python_adver\\attack_code\\venv\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1095, in __init__\r\n    \"not suprt args type , should be[ string_type, binary_type, Varibale]\"\r\nValueError: not suprt args type , should be[ string_type, binary_type, Varibale]",
        "state": "open",
        "user": "IWQOS-ASTBAR",
        "closed_by": null,
        "created_at": "2019-12-07T09:43:47+00:00",
        "updated_at": "2024-02-26T05:13:39+00:00",
        "closed_at": null,
        "comments_count": [
            "IWQOS-ASTBAR",
            "lea4n",
            "IWQOS-ASTBAR",
            "shippingwang",
            "IWQOS-ASTBAR",
            "lanxianghit",
            "IWQOS-ASTBAR",
            "IWQOS-ASTBAR",
            "lanxianghit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4043,
        "title": "landmark模型测试出现问题，如下",
        "body": "在测试landmark recognition模型时，pypredict编译通过，但是运行inference时，                        \r\n  python infer_recognition.py test_cls test_data/0.jpg res152_softmax_v2,\r\n出现如下问题，请问是什么原因？？怎样解决？？\r\nImportError: ./so/PyCNNPredict.so: undefined symbol: _ZN6paddle14AnalysisConfig18EnableAnakinEngineEiSt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt6vectorIiSaIiEESt4lessIS7_ESaISt4pairIKS7_SA_EEEiNS0_9PrecisionEbS8_IS7_SaIS7_EESK_",
        "state": "closed",
        "user": "Julyliying",
        "closed_by": "Julyliying",
        "created_at": "2019-12-09T10:06:22+00:00",
        "updated_at": "2020-02-18T12:00:00+00:00",
        "closed_at": "2020-01-06T03:47:33+00:00",
        "comments_count": [
            "dyning",
            "Julyliying",
            "Superjomn",
            "dyning",
            "dyning",
            "Julyliying",
            "dyning"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4054,
        "title": "求FOTS论文的实现！",
        "body": "",
        "state": "closed",
        "user": "whereitogo",
        "closed_by": "whereitogo",
        "created_at": "2019-12-10T13:42:40+00:00",
        "updated_at": "2019-12-11T02:50:35+00:00",
        "closed_at": "2019-12-11T02:50:35+00:00",
        "comments_count": [
            "dyning"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4059,
        "title": "How about the time cost of per image inferring for pyramidbox?",
        "body": "Could you provide your time **cost details** when inferring? Just like average per image inferring **time** , average image size ,and Gpu type. If it's convenient for you, i will be appreciate a lot.",
        "state": "closed",
        "user": "lyw615",
        "closed_by": "lyw615",
        "created_at": "2019-12-11T07:10:57+00:00",
        "updated_at": "2020-05-11T00:40:00+00:00",
        "closed_at": "2020-05-11T00:40:00+00:00",
        "comments_count": [
            "lyw615",
            "liym27",
            "qingqing01",
            "lyw615",
            "lyw615",
            "qingqing01",
            "lyw615",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4060,
        "title": "TypeError: only integer scalar arrays can be converted to a scalar index",
        "body": "有人遇到过这么问题吗？",
        "state": "open",
        "user": "jiayalu123",
        "closed_by": null,
        "created_at": "2019-12-11T08:25:19+00:00",
        "updated_at": "2024-02-26T05:13:38+00:00",
        "closed_at": null,
        "comments_count": [
            "liym27",
            "jiayalu123",
            "liym27",
            "jiayalu123",
            "liym27",
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4061,
        "title": "语音识别DeepVoice3",
        "body": "paddle版本如下:\r\n    Name: paddlepaddle-gpu\r\n    Version: 1.6.1.post107\r\n\r\n第1个错误:DeepVoice3/deepvoice3_paddle/modules.py中371行\r\n--------------------------------------------------------------------------------------------------self.embed._w.value().get_tensor().set(\r\n            array, fluid.framework._current_expected_place())\r\n--------------------------------------------------------------------------------------------------\r\nself.embed._w后面是没有value函数的,我这边直接注释调了\r\n\r\n\r\n第2个错误: DeepVoice3/deepvoice3_paddle/deepvoice3.py中223\r\nx = self.embed(x)\r\n错误信息如下:\r\n--------------------------------------------------------------------------------------------------\r\nPaddleCheckError: Expected ids_dims[ids_rank - 1] == 1, but received ids_dims[ids_rank - 1]:153 != 1:1.\r\nShapeError: The last dimensions of the 'Ids' tensor must be 1. But received Ids's last dimensions = 153, Ids's shape = [16, 153]. at [/paddle/paddle/fluid/operators/lookup_table_op.cc:51]\r\n--------------------------------------------------------------------------------------------------\r\nEmbedding 需要的最后一个维度是1,这个我在版本提交记录中看到被修复过了,不知道是不是没全部提交导致的.临时解决方式\r\n--------------------------------------------------------------------------------------------------\r\n#x = self.embed(fluid.layers.reshape(x,[x.shape[0],x.shape[1],1]))\r\n--------------------------------------------------------------------------------------------------\r\n版本记录地址:\r\nhttps://github.com/PaddlePaddle/models/pull/4048/files/264f2ba4a829e3cfef65b4d9ef2f9167756f840f\r\n\r\n\r\n我本地数据集只有20个音频文件,也没法测试被我改动后是否还有效果",
        "state": "closed",
        "user": "L-lei",
        "closed_by": "L-lei",
        "created_at": "2019-12-11T09:35:43+00:00",
        "updated_at": "2019-12-12T05:04:19+00:00",
        "closed_at": "2019-12-12T05:04:19+00:00",
        "comments_count": [
            "iclementine",
            "L-lei"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4064,
        "title": "ERROR 2019-12-12 04:02:41,061 launch.py:269] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0, 2] was aborted. Please check its log.",
        "body": "本地环境：cuda10，cudnn: 7.6.3, models的develop分支最新代码，paddle1.6.1，gcc version: 5.4.0\r\n\r\n在用DALI训练image_classification时报错：\r\n[root@5d564e9b351a image_classification]# sh train_dali.sh\r\n-----------  Configuration Arguments -----------\r\ncluster_node_ips: 127.0.0.1\r\nlog_dir: None\r\nnode_ip: 127.0.0.1\r\nprint_config: True\r\nselected_gpus: None\r\nstarted_port: 6170\r\ntraining_script: train.py\r\ntraining_script_args: ['--model=ResNet50', '--batch_size=32', '--lr_strategy=cosine_decay_warmup', '--num_epochs=240', '--lr=0.05', '--l2_decay=3e-5', '--lower_scale=0.64', '--lower_ratio=0.8', '--upper_ratio=1.2', '--use_dali=True']\r\nuse_paddlecloud: True\r\n------------------------------------------------\r\ntrainers_endpoints: 127.0.0.1:6170,127.0.0.1:6171,127.0.0.1:6172,127.0.0.1:6173 , node_id: 0 , current_node_ip: 127.0.0.1 , num_nodes: 1 , node_ips: ['127.0.0.1'] , nranks: 4\r\n-------------  Configuration Arguments -------------\r\n               batch_size : 32\r\n               checkpoint : None\r\n                class_dim : 1000\r\n                 data_dir : ./data/ILSVRC2012/\r\n             decay_epochs : 2.4\r\n               decay_rate : 0.97\r\n        drop_connect_rate : 0.2\r\n                ema_decay : 0.9999\r\n                enable_ce : False\r\n               image_mean : [0.485, 0.456, 0.406]\r\n              image_shape : [3, 224, 224]\r\n                image_std : [0.229, 0.224, 0.225]\r\n            interpolation : None\r\n              is_profiler : 0\r\n                 l2_decay : 3e-05\r\n  label_smoothing_epsilon : 0.1\r\n              lower_ratio : 0.8\r\n              lower_scale : 0.64\r\n                       lr : 0.05\r\n              lr_strategy : cosine_decay_warmup\r\n                 max_iter : 0\r\n              mixup_alpha : 0.2\r\n                    model : ResNet50\r\n           model_save_dir : ./output\r\n            momentum_rate : 0.9\r\n               num_epochs : 240\r\n             padding_type : SAME\r\n         pretrained_model : None\r\n               print_step : 10\r\n            profiler_path : ./\r\n              random_seed : None\r\n          reader_buf_size : 2048\r\n            reader_thread : 8\r\n        resize_short_size : 256\r\n                same_feed : 0\r\n                save_step : 1\r\n              step_epochs : [30, 60, 90]\r\n          test_batch_size : 16\r\n             total_images : 1281167\r\n              upper_ratio : 1.2\r\n                   use_aa : False\r\n                 use_dali : 1\r\n                  use_ema : False\r\n                  use_gpu : True\r\n      use_label_smoothing : False\r\n                use_mixup : False\r\n                   use_se : True\r\n                 validate : 1\r\n           warm_up_epochs : 5.0\r\n----------------------------------------------------\r\nW1212 04:02:31.290369 24045 device_context.cc:235] Please NOTE: device: 3, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW1212 04:02:31.302067 24045 device_context.cc:243] device: 3, cuDNN Version: 7.6.\r\nW1212 04:02:31.330199 24044 device_context.cc:235] Please NOTE: device: 2, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW1212 04:02:31.333243 24043 device_context.cc:235] Please NOTE: device: 1, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW1212 04:02:31.337818 24044 device_context.cc:243] device: 2, cuDNN Version: 7.6.\r\nW1212 04:02:31.340380 24043 device_context.cc:243] device: 1, cuDNN Version: 7.6.\r\nW1212 04:02:31.444458 24042 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW1212 04:02:31.451699 24042 device_context.cc:243] device: 0, cuDNN Version: 7.6.\r\nW1212 04:02:33.282218 24043 init.cc:205] *** Aborted at 1576123353 (unix time) try \"date -d @1576123353\" if you are using GNU date ***\r\nW1212 04:02:33.285073 24043 init.cc:205] PC: @                0x0 (unknown)\r\nW1212 04:02:33.285284 24043 init.cc:205] *** SIGSEGV (@0x0) received by PID 24043 (TID 0x7fe6e3b9a740) from PID 0; stack trace: ***\r\nW1212 04:02:33.287878 24043 init.cc:205]     @     0x7fe6e37785d0 (unknown)\r\nW1212 04:02:33.288434 24043 init.cc:205]     @     0x7fe68db87e3b (unknown)\r\nW1212 04:02:33.288965 24043 init.cc:205]     @     0x7fe68dbc21df (unknown)\r\nW1212 04:02:33.289500 24043 init.cc:205]     @     0x7fe68db91522 (unknown)\r\nW1212 04:02:33.290030 24043 init.cc:205]     @     0x7fe68dbc1f02 PyInit_backend_impl\r\nW1212 04:02:33.291326 24043 init.cc:205]     @     0x559a8cfd08e5 _PyImport_LoadDynamicModuleWithSpec\r\nW1212 04:02:33.292248 24043 init.cc:205]     @     0x559a8cfd0ae5 _imp_create_dynamic\r\nW1212 04:02:33.293475 24043 init.cc:205]     @     0x559a8cecca61 PyCFunction_Call\r\nW1212 04:02:33.294788 24043 init.cc:205]     @     0x559a8cf80fdb _PyEval_EvalFrameDefault\r\nW1212 04:02:33.295608 24043 init.cc:205]     @     0x559a8cf52a94 _PyEval_EvalCodeWithName\r\nW1212 04:02:33.296420 24043 init.cc:205]     @     0x559a8cf53941 fast_function\r\nW1212 04:02:33.297256 24043 init.cc:205]     @     0x559a8cf59755 call_function\r\nW1212 04:02:33.298564 24043 init.cc:205]     @     0x559a8cf7bcba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.299376 24043 init.cc:205]     @     0x559a8cf5370b fast_function\r\nW1212 04:02:33.300211 24043 init.cc:205]     @     0x559a8cf59755 call_function\r\nW1212 04:02:33.301522 24043 init.cc:205]     @     0x559a8cf7bcba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.302337 24043 init.cc:205]     @     0x559a8cf5370b fast_function\r\nW1212 04:02:33.303174 24043 init.cc:205]     @     0x559a8cf59755 call_function\r\nW1212 04:02:33.304481 24043 init.cc:205]     @     0x559a8cf7bcba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.305295 24043 init.cc:205]     @     0x559a8cf5370b fast_function\r\nW1212 04:02:33.306128 24043 init.cc:205]     @     0x559a8cf59755 call_function\r\nW1212 04:02:33.307440 24043 init.cc:205]     @     0x559a8cf7bcba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.308254 24043 init.cc:205]     @     0x559a8cf5370b fast_function\r\nW1212 04:02:33.309087 24043 init.cc:205]     @     0x559a8cf59755 call_function\r\nW1212 04:02:33.310396 24043 init.cc:205]     @     0x559a8cf7bcba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.311619 24043 init.cc:205]     @     0x559a8cf53d7b _PyFunction_FastCallDict\r\nW1212 04:02:33.312815 24043 init.cc:205]     @     0x559a8cec9f5f _PyObject_FastCallDict\r\nW1212 04:02:33.314150 24043 init.cc:205]     @     0x559a8cf0e670 _PyObject_CallMethodIdObjArgs\r\nW1212 04:02:33.315428 24043 init.cc:205]     @     0x559a8cec0a70 PyImport_ImportModuleLevelObject\r\nW1212 04:02:33.316738 24043 init.cc:205]     @     0x559a8cf7e033 _PyEval_EvalFrameDefault\r\nW1212 04:02:33.318001 24043 init.cc:205]     @     0x559a8cf54459 PyEval_EvalCodeEx\r\nW1212 04:02:33.319205 24043 init.cc:205]     @     0x559a8cf551ec PyEval_EvalCode\r\nW1212 04:02:33.400863 24044 init.cc:205] *** Aborted at 1576123353 (unix time) try \"date -d @1576123353\" if you are using GNU date ***\r\nW1212 04:02:33.403725 24044 init.cc:205] PC: @                0x0 (unknown)\r\nW1212 04:02:33.403934 24044 init.cc:205] *** SIGSEGV (@0x0) received by PID 24044 (TID 0x7f6406bd7740) from PID 0; stack trace: ***\r\nW1212 04:02:33.406607 24044 init.cc:205]     @     0x7f64067b55d0 (unknown)\r\nW1212 04:02:33.407167 24044 init.cc:205]     @     0x7f63b0bc4e3b (unknown)\r\nW1212 04:02:33.407702 24044 init.cc:205]     @     0x7f63b0bff1df (unknown)\r\nW1212 04:02:33.408239 24044 init.cc:205]     @     0x7f63b0bce522 (unknown)\r\nW1212 04:02:33.408773 24044 init.cc:205]     @     0x7f63b0bfef02 PyInit_backend_impl\r\nW1212 04:02:33.410063 24044 init.cc:205]     @     0x55615a8c98e5 _PyImport_LoadDynamicModuleWithSpec\r\nW1212 04:02:33.410984 24044 init.cc:205]     @     0x55615a8c9ae5 _imp_create_dynamic\r\nW1212 04:02:33.412220 24044 init.cc:205]     @     0x55615a7c5a61 PyCFunction_Call\r\nW1212 04:02:33.413537 24044 init.cc:205]     @     0x55615a879fdb _PyEval_EvalFrameDefault\r\nW1212 04:02:33.414355 24044 init.cc:205]     @     0x55615a84ba94 _PyEval_EvalCodeWithName\r\nW1212 04:02:33.415171 24044 init.cc:205]     @     0x55615a84c941 fast_function\r\nW1212 04:02:33.416003 24044 init.cc:205]     @     0x55615a852755 call_function\r\nW1212 04:02:33.417318 24044 init.cc:205]     @     0x55615a874cba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.418129 24044 init.cc:205]     @     0x55615a84c70b fast_function\r\nW1212 04:02:33.418969 24044 init.cc:205]     @     0x55615a852755 call_function\r\nW1212 04:02:33.419068 24045 init.cc:205] *** Aborted at 1576123353 (unix time) try \"date -d @1576123353\" if you are using GNU date ***\r\nW1212 04:02:33.420289 24044 init.cc:205]     @     0x55615a874cba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.421099 24044 init.cc:205]     @     0x55615a84c70b fast_function\r\nW1212 04:02:33.421872 24045 init.cc:205] PC: @                0x0 (unknown)\r\nW1212 04:02:33.421942 24044 init.cc:205]     @     0x55615a852755 call_function\r\nW1212 04:02:33.422075 24045 init.cc:205] *** SIGSEGV (@0x0) received by PID 24045 (TID 0x7f8121536740) from PID 0; stack trace: ***\r\nW1212 04:02:33.423307 24044 init.cc:205]     @     0x55615a874cba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.424119 24044 init.cc:205]     @     0x55615a84c70b fast_function\r\nW1212 04:02:33.424721 24045 init.cc:205]     @     0x7f81211145d0 (unknown)\r\nW1212 04:02:33.424958 24044 init.cc:205]     @     0x55615a852755 call_function\r\nW1212 04:02:33.425238 24045 init.cc:205]     @     0x7f80c0f8de3b (unknown)\r\nW1212 04:02:33.425730 24045 init.cc:205]     @     0x7f80c0fc81df (unknown)\r\nW1212 04:02:33.426224 24045 init.cc:205]     @     0x7f80c0f97522 (unknown)\r\nW1212 04:02:33.426277 24044 init.cc:205]     @     0x55615a874cba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.426712 24045 init.cc:205]     @     0x7f80c0fc7f02 PyInit_backend_impl\r\nW1212 04:02:33.427100 24044 init.cc:205]     @     0x55615a84c70b fast_function\r\nW1212 04:02:33.427959 24044 init.cc:205]     @     0x55615a852755 call_function\r\nW1212 04:02:33.428014 24045 init.cc:205]     @     0x5573e9a5f8e5 _PyImport_LoadDynamicModuleWithSpec\r\nW1212 04:02:33.428985 24045 init.cc:205]     @     0x5573e9a5fae5 _imp_create_dynamic\r\nW1212 04:02:33.429309 24044 init.cc:205]     @     0x55615a874cba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.430250 24045 init.cc:205]     @     0x5573e995ba61 PyCFunction_Call\r\nW1212 04:02:33.430562 24044 init.cc:205]     @     0x55615a84cd7b _PyFunction_FastCallDict\r\nW1212 04:02:33.431604 24045 init.cc:205]     @     0x5573e9a0ffdb _PyEval_EvalFrameDefault\r\nW1212 04:02:33.431788 24044 init.cc:205]     @     0x55615a7c2f5f _PyObject_FastCallDict\r\nW1212 04:02:33.432447 24045 init.cc:205]     @     0x5573e99e1a94 _PyEval_EvalCodeWithName\r\nW1212 04:02:33.433146 24044 init.cc:205]     @     0x55615a807670 _PyObject_CallMethodIdObjArgs\r\nW1212 04:02:33.433285 24045 init.cc:205]     @     0x5573e99e2941 fast_function\r\nW1212 04:02:33.434139 24045 init.cc:205]     @     0x5573e99e8755 call_function\r\nW1212 04:02:33.434453 24044 init.cc:205]     @     0x55615a7b9a70 PyImport_ImportModuleLevelObject\r\nW1212 04:02:33.435487 24045 init.cc:205]     @     0x5573e9a0acba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.435796 24044 init.cc:205]     @     0x55615a877033 _PyEval_EvalFrameDefault\r\nW1212 04:02:33.436323 24045 init.cc:205]     @     0x5573e99e270b fast_function\r\nW1212 04:02:33.437090 24044 init.cc:205]     @     0x55615a84d459 PyEval_EvalCodeEx\r\nW1212 04:02:33.437180 24045 init.cc:205]     @     0x5573e99e8755 call_function\r\nW1212 04:02:33.438321 24044 init.cc:205]     @     0x55615a84e1ec PyEval_EvalCode\r\nW1212 04:02:33.438518 24045 init.cc:205]     @     0x5573e9a0acba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.439347 24045 init.cc:205]     @     0x5573e99e270b fast_function\r\nW1212 04:02:33.440203 24045 init.cc:205]     @     0x5573e99e8755 call_function\r\nW1212 04:02:33.441527 24045 init.cc:205]     @     0x5573e9a0acba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.442353 24045 init.cc:205]     @     0x5573e99e270b fast_function\r\nW1212 04:02:33.443202 24045 init.cc:205]     @     0x5573e99e8755 call_function\r\nW1212 04:02:33.444519 24045 init.cc:205]     @     0x5573e9a0acba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.445341 24045 init.cc:205]     @     0x5573e99e270b fast_function\r\nW1212 04:02:33.446188 24045 init.cc:205]     @     0x5573e99e8755 call_function\r\nW1212 04:02:33.447504 24045 init.cc:205]     @     0x5573e9a0acba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.448730 24045 init.cc:205]     @     0x5573e99e2d7b _PyFunction_FastCallDict\r\nW1212 04:02:33.449932 24045 init.cc:205]     @     0x5573e9958f5f _PyObject_FastCallDict\r\nW1212 04:02:33.451252 24045 init.cc:205]     @     0x5573e999d670 _PyObject_CallMethodIdObjArgs\r\nW1212 04:02:33.452535 24045 init.cc:205]     @     0x5573e994fa70 PyImport_ImportModuleLevelObject\r\nW1212 04:02:33.453855 24045 init.cc:205]     @     0x5573e9a0d033 _PyEval_EvalFrameDefault\r\nW1212 04:02:33.455127 24045 init.cc:205]     @     0x5573e99e3459 PyEval_EvalCodeEx\r\nW1212 04:02:33.456331 24045 init.cc:205]     @     0x5573e99e41ec PyEval_EvalCode\r\nW1212 04:02:33.783942 24042 init.cc:205] *** Aborted at 1576123353 (unix time) try \"date -d @1576123353\" if you are using GNU date ***\r\nW1212 04:02:33.786825 24042 init.cc:205] PC: @                0x0 (unknown)\r\nW1212 04:02:33.787039 24042 init.cc:205] *** SIGSEGV (@0x0) received by PID 24042 (TID 0x7efd88a12740) from PID 0; stack trace: ***\r\nW1212 04:02:33.789687 24042 init.cc:205]     @     0x7efd885f05d0 (unknown)\r\nW1212 04:02:33.790251 24042 init.cc:205]     @     0x7efd329ffe3b (unknown)\r\nW1212 04:02:33.790787 24042 init.cc:205]     @     0x7efd32a3a1df (unknown)\r\nW1212 04:02:33.791326 24042 init.cc:205]     @     0x7efd32a09522 (unknown)\r\nW1212 04:02:33.791860 24042 init.cc:205]     @     0x7efd32a39f02 PyInit_backend_impl\r\nW1212 04:02:33.793159 24042 init.cc:205]     @     0x55fcbae418e5 _PyImport_LoadDynamicModuleWithSpec\r\nW1212 04:02:33.794075 24042 init.cc:205]     @     0x55fcbae41ae5 _imp_create_dynamic\r\nW1212 04:02:33.795310 24042 init.cc:205]     @     0x55fcbad3da61 PyCFunction_Call\r\nW1212 04:02:33.796627 24042 init.cc:205]     @     0x55fcbadf1fdb _PyEval_EvalFrameDefault\r\nW1212 04:02:33.797446 24042 init.cc:205]     @     0x55fcbadc3a94 _PyEval_EvalCodeWithName\r\nW1212 04:02:33.798260 24042 init.cc:205]     @     0x55fcbadc4941 fast_function\r\nW1212 04:02:33.799093 24042 init.cc:205]     @     0x55fcbadca755 call_function\r\nW1212 04:02:33.800408 24042 init.cc:205]     @     0x55fcbadeccba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.801223 24042 init.cc:205]     @     0x55fcbadc470b fast_function\r\nW1212 04:02:33.802060 24042 init.cc:205]     @     0x55fcbadca755 call_function\r\nW1212 04:02:33.803372 24042 init.cc:205]     @     0x55fcbadeccba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.804188 24042 init.cc:205]     @     0x55fcbadc470b fast_function\r\nW1212 04:02:33.805022 24042 init.cc:205]     @     0x55fcbadca755 call_function\r\nW1212 04:02:33.806337 24042 init.cc:205]     @     0x55fcbadeccba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.807153 24042 init.cc:205]     @     0x55fcbadc470b fast_function\r\nW1212 04:02:33.807986 24042 init.cc:205]     @     0x55fcbadca755 call_function\r\nW1212 04:02:33.809303 24042 init.cc:205]     @     0x55fcbadeccba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.810118 24042 init.cc:205]     @     0x55fcbadc470b fast_function\r\nW1212 04:02:33.810961 24042 init.cc:205]     @     0x55fcbadca755 call_function\r\nW1212 04:02:33.812273 24042 init.cc:205]     @     0x55fcbadeccba _PyEval_EvalFrameDefault\r\nW1212 04:02:33.813495 24042 init.cc:205]     @     0x55fcbadc4d7b _PyFunction_FastCallDict\r\nW1212 04:02:33.814693 24042 init.cc:205]     @     0x55fcbad3af5f _PyObject_FastCallDict\r\nW1212 04:02:33.816009 24042 init.cc:205]     @     0x55fcbad7f670 _PyObject_CallMethodIdObjArgs\r\nW1212 04:02:33.817297 24042 init.cc:205]     @     0x55fcbad31a70 PyImport_ImportModuleLevelObject\r\nW1212 04:02:33.818611 24042 init.cc:205]     @     0x55fcbadef033 _PyEval_EvalFrameDefault\r\nW1212 04:02:33.819876 24042 init.cc:205]     @     0x55fcbadc5459 PyEval_EvalCodeEx\r\nW1212 04:02:33.821080 24042 init.cc:205]     @     0x55fcbadc61ec PyEval_EvalCode\r\nERROR 2019-12-12 04:02:41,061 launch.py:269] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0, 2] was aborted. Please check its log.\r\n",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2019-12-12T04:08:37+00:00",
        "updated_at": "2019-12-12T06:05:34+00:00",
        "closed_at": "2019-12-12T06:05:34+00:00",
        "comments_count": [
            "FrostML",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4071,
        "title": "dygraph 中的attention ocr部分只有训练代码，如果进行测试必须得输入ｌａｂｅｌ的ground truth　",
        "body": "测试时怎么改代码，把输入label的ground truth给去掉？毕竟测试时是没有提供label的ground truth的．我的意思是指OCRAttention的forward函数的参数label_in，在训练时label_in是训练数据的label ground truth，但在测试时就应该去掉了，因为测试数据的ｌａｂｅｌ ground truth一般是未知的，但不知代码应该如何改，　label_in应该如何替换． ",
        "state": "open",
        "user": "wenston2006",
        "closed_by": "cryoco",
        "created_at": "2019-12-13T05:23:33+00:00",
        "updated_at": "2019-12-30T07:20:07+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain",
            "wenston2006",
            "cryoco",
            "wenston2006"
        ],
        "labels": [
            "feature required"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4068,
        "title": "image classification分类的batch计算问题",
        "body": "跑训练时，单卡时，train和test跑的batch数==图片数/batch_size；不是单卡时，test的batch数正常，而train的batch数==num_gpu*训练图片数/train_batch_size；请问为什么？",
        "state": "closed",
        "user": "chenqiuhui",
        "closed_by": "shippingwang",
        "created_at": "2019-12-12T14:09:58+00:00",
        "updated_at": "2019-12-20T06:46:54+00:00",
        "closed_at": "2019-12-20T06:46:54+00:00",
        "comments_count": [
            "FrostML",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4074,
        "title": "度量学习中只有一个模型吗，可以多实现一些流行的模型吗",
        "body": "尊敬的Paddle开发者，您好。最近行人重识别与人脸识别领域出了很多的有竞争力的模型，比如MGN，DGN，请问有没有Paddle的实现",
        "state": "open",
        "user": "qiusuor",
        "closed_by": null,
        "created_at": "2019-12-13T13:38:19+00:00",
        "updated_at": "2024-02-26T05:13:35+00:00",
        "closed_at": null,
        "comments_count": [
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4080,
        "title": "从bert pretrain打印的结果如何计算吞吐率性能？",
        "body": "跑单机单卡, batch_size: 16, 打印的结果如下：\r\n\r\n`epoch: 1, progress: 1/64, step: 2, loss: 11.409644, ppl: 14829.729492, next_sent_acc: 0.562500, speed: 5.488533 steps/s, file: part-00012-01b065c2-8e4a-442b-9920-d986845ab3d2-c000.txt.gz`\r\n\r\n跑单机4卡, batch_size: 64, 打印的结果如下：\r\n`epoch: 1, progress: 1/64, step: 3, loss: 8.647623, ppl: 2778.657471, next_sent_acc: 0.433594, speed: 1.436274 steps/s, file: part-00035-01b065c2-8e4a-442b-9920-d986845ab3d2-c000.txt.gz`\r\n\r\n我的问题是：\r\n单机单卡的速度是5.488533 steps/s， 换算成吞吐率是：5.488533 * 16 = 87.816528 sample/s。\r\n\r\n单机4卡的速度是1.436274 steps/s， 换算成吞吐率是：1.436274 * 64 = 91.921536 samples/s。\r\n\r\n那么，4卡相对于单卡，加速比是 91.921536/87.816528 = 1.046。\r\n\r\n1）请问这样计算吞吐率和加速比的方法是正确的吗？\r\n2）如果计算方式是正确的，请问加速比很低的原因是什么？\r\n3）如果计算方式是错误的，请问正确的计算方法是什么？\r\n\r\n\r\n附上我的运行命令：\r\n仓库：https://github.com/PaddlePaddle/models.git\r\ncommit: 4ffbe264e69b296cab387b4879e0ee0a37801c61\r\n\r\n单机单卡：\r\n```\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython3 -u PaddleNLP/PaddleLARK/BERT/train.py \\\r\n\t--is_distributed false \\\r\n        --use_cuda true \\\r\n        --weight_sharing true \\\r\n        --batch_size 16 \\\r\n        --in_tokens False \\\r\n        --data_dir $PADDLE_BERT_DATA_DIR \\\r\n        --validation_set_dir $PADDLE_BERT_DATA_DIR \\\r\n        --bert_config_path $CONFIG_PATH \\\r\n        --vocab_path $VOCAB_PATH \\\r\n        --num_train_steps 120 \\\r\n        --warmup_steps 0 \\\r\n        --epoch 1 \\\r\n        --max_seq_len 128 \\\r\n        --skip_steps 1 \\\r\n        --generate_neg_sample=False\r\n```\r\n\r\n单机4卡：\r\n```\r\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\r\npython3 -u PaddleNLP/PaddleLARK/BERT/train.py \\\r\n\t--is_distributed false \\\r\n        --use_cuda true \\\r\n        --weight_sharing true \\\r\n        --batch_size 64 \\\r\n        --in_tokens False \\\r\n        --data_dir $PADDLE_BERT_DATA_DIR \\\r\n        --validation_set_dir $PADDLE_BERT_DATA_DIR \\\r\n        --bert_config_path $CONFIG_PATH \\\r\n        --vocab_path $VOCAB_PATH \\\r\n        --num_train_steps 120 \\\r\n        --warmup_steps 0 \\\r\n        --epoch 1 \\\r\n        --max_seq_len 128 \\\r\n        --skip_steps 1 \\\r\n        --generate_neg_sample=False\r\n```",
        "state": "closed",
        "user": "mir-of",
        "closed_by": "kuke",
        "created_at": "2019-12-17T14:21:50+00:00",
        "updated_at": "2020-01-02T07:44:44+00:00",
        "closed_at": "2020-01-02T07:44:44+00:00",
        "comments_count": [
            "kuke",
            "mir-of",
            "mir-of",
            "kuke",
            "mir-of"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4075,
        "title": "训练时报错PaddleCheckError: CUBLAS",
        "body": "```\r\n---------------------------------------------------------------------------EnforceNotMet                             Traceback (most recent call last)<ipython-input-11-c202560c70bc> in <module>\r\n     61             avg_loss = fluid.layers.mean(loss)\r\n     62             print('avg_loss:{}'.format(avg_loss.numpy()))\r\n---> 63             avg_loss.backward()\r\n     64             adam.minimize(avg_loss)\r\n     65             model.clear_gradients()\r\n</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-133> in backward(self, backward_strategy)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py in __impl__(func, *args, **kwargs)\r\n     23     def __impl__(func, *args, **kwargs):\r\n     24         wrapped_func = decorator_func(func)\r\n---> 25         return wrapped_func(*args, **kwargs)\r\n     26 \r\n     27     return __impl__\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in __impl__(*args, **kwargs)\r\n    205         assert in_dygraph_mode(\r\n    206         ), \"We Only support %s in Dygraph mode, please use fluid.dygraph.guard() as context to run it in Dygraph Mode\" % func.__name__\r\n--> 207         return func(*args, **kwargs)\r\n    208 \r\n    209     return __impl__\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in backward(self, backward_strategy)\r\n    889                 backward_strategy.sort_sum_gradient = False\r\n    890 \r\n--> 891             self._ivar._run_backward(backward_strategy, _dygraph_tracer())\r\n    892         else:\r\n    893             raise ValueError(\r\nEnforceNotMet: 0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   void paddle::operators::math::CUBlas<float>::AXPY<cublasContext*, int, float*, float const*, int, float*, int>(cublasContext*, int, float*, float const*, int, float*, int)\r\n3   paddle::imperative::TensorAdd(paddle::framework::Variable const&, paddle::framework::Variable*)\r\n4   paddle::imperative::EagerGradientAccumulator::Add(std::shared_ptr<paddle::imperative::VarBase>, unsigned long)\r\n5   paddle::imperative::BasicEngine::SumGradient(paddle::imperative::OpBase*, std::shared_ptr<paddle::imperative::VarBase>, paddle::imperative::VarBase*)\r\n6   paddle::imperative::BasicEngine::Execute()\r\nPaddleCheckError: CUBLAS: execution failed,  at [/paddle/paddle/fluid/operators/math/blas_impl.cu.h:39]\r\n```\r\n训练到几十个batch后会出现这个错误，输出loss查看都是正常的数值，不知道问题出在哪\r\n模型是seq2seq\r\n参照https://github.com/PaddlePaddle/models/blob/develop/dygraph/sentiment/main.py",
        "state": "open",
        "user": "pfan8",
        "closed_by": null,
        "created_at": "2019-12-15T03:43:12+00:00",
        "updated_at": "2019-12-17T03:42:31+00:00",
        "closed_at": null,
        "comments_count": [
            "songyouwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4082,
        "title": "PaddleCV/face_detection/widerface_eval.py",
        "body": "models/PaddleCV/face_detection/widerface_eval.py \r\nLine 307\r\n    max_shrink = get_round(min(max_shrink_v1, max_shrink_v2), 2) - 0.3\r\n\r\nThis will generate a negative value when the image size is bigger and make the execution crashed.",
        "state": "closed",
        "user": "EthanZBY",
        "closed_by": "EthanZBY",
        "created_at": "2019-12-18T00:51:34+00:00",
        "updated_at": "2019-12-23T03:05:31+00:00",
        "closed_at": "2019-12-23T03:05:31+00:00",
        "comments_count": [
            "MrChengmo",
            "EthanZBY",
            "EthanZBY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4085,
        "title": "关于cudnn版本问题",
        "body": "你好，我是在用cudnn7.5.0训练stnet，看到您之前回复的issue说是用cudnn5。\r\n我需要下降cudnn版本到5进行训练吗？谢谢",
        "state": "closed",
        "user": "zhanghongruiupup",
        "closed_by": "MrChengmo",
        "created_at": "2019-12-18T03:39:12+00:00",
        "updated_at": "2019-12-19T10:19:08+00:00",
        "closed_at": "2019-12-19T10:19:08+00:00",
        "comments_count": [
            "MrChengmo",
            "zhanghongruiupup",
            "SunGaofeng",
            "zhanghongruiupup",
            "zhanghongruiupup",
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4086,
        "title": "Does anyone else feel unconvenient scanning so many repositories?",
        "body": "",
        "state": "closed",
        "user": "Ailing-Zou",
        "closed_by": "Ailing-Zou",
        "created_at": "2019-12-18T03:44:21+00:00",
        "updated_at": "2019-12-20T09:43:42+00:00",
        "closed_at": "2019-12-20T09:43:42+00:00",
        "comments_count": [
            "Ailing-Zou",
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4092,
        "title": "DeepVoice3模块训练中保存模型时保存的语音有效果,合成的却是噪音",
        "body": "DeepVoice3模块训练中保存模型时会自动保存一个合成语音,那个语音有效果,但是不管是训练时的测试合成的还是最后的预测合成的语音却是噪音",
        "state": "closed",
        "user": "L-lei",
        "closed_by": "L-lei",
        "created_at": "2019-12-19T06:23:22+00:00",
        "updated_at": "2019-12-25T06:56:35+00:00",
        "closed_at": "2019-12-25T06:56:35+00:00",
        "comments_count": [
            "iclementine",
            "L-lei",
            "L-lei",
            "iclementine",
            "L-lei",
            "L-lei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4098,
        "title": "python api预测bug",
        "body": "python api链接：[https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_usage/deploy/inference/python_infer_cn.html](https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_usage/deploy/inference/python_infer_cn.html)\r\n\r\n使用转换完的分类model和params二进制文件，预处理完之后，必须使用.copy()做一次深拷贝，否则预测结果和fluid预测结果对不上，复现的代码在这里：https://github.com/PaddlePaddle/models/blob/54f64c665e2f737a91c39f42e973fa121b80d8b4/PaddleCV/image_classification/predict.py#L91\r\n去除.copy()即可复现该问题\r\n",
        "state": "open",
        "user": "littletomatodonkey",
        "closed_by": null,
        "created_at": "2019-12-21T09:58:49+00:00",
        "updated_at": "2019-12-23T10:03:25+00:00",
        "closed_at": null,
        "comments_count": [
            "Superjomn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4094,
        "title": "server not ready, wait 3 sec to retry... not ready endpoints:['127.0.0.1:6171', '127.0.0.1:6172', '127.0.0.1:6173']",
        "body": "训练image_classification时出现如下问题：\r\n![3333333333](https://user-images.githubusercontent.com/13143336/71179771-c64e6580-22ab-11ea-98f5-ee3e5198fbd1.png)\r\n\r\n麻烦帮忙看一下",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2019-12-19T14:05:13+00:00",
        "updated_at": "2023-06-25T09:24:35+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "endy-see",
            "endy-see",
            "shippingwang",
            "endy-see",
            "JACKLPJ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4110,
        "title": "BMN/BSN模型评估时报错",
        "body": "错误如下：\r\nProcess Process-13:\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda\\lib\\multiprocessing\\process.py\", line 297, in _bootstrap\r\n    self.run()\r\n  File \"D:\\Anaconda\\lib\\multiprocessing\\process.py\", line 99, in run\r\n    self._target(*self._args, **self._kwargs\r\n  File \"G:\\models-develop\\PaddleCV\\PaddleVideo\\models\\bsn\\bsn_utils.py\", line 124, in video_process\r\n    result_dict[video_name[2:]] = proposal_list\r\nNameError: name 'result_dict' is not defined\r\n[INFO: metrics_util.py:  420]: [EVAL] eval finished.    Loss = nan\r\nW1223 18:39:51.984580 17320 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW1223 18:39:51.997812 17320 device_context.cc:244] device: 0, cuDNN Version: 7.6.\r\n\r\n请问该怎么解决，谢谢！\r\n![捕获](https://user-images.githubusercontent.com/59164417/71354279-665f0400-25b6-11ea-95b9-abab41c2abce.PNG)\r\n\r\n",
        "state": "closed",
        "user": "li-900406",
        "closed_by": "huangjun12",
        "created_at": "2019-12-23T11:00:03+00:00",
        "updated_at": "2020-04-16T08:49:02+00:00",
        "closed_at": "2020-04-16T08:49:02+00:00",
        "comments_count": [
            "wilhelmzh",
            "huangjun12",
            "li-900406",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4117,
        "title": "如何获取指定层的输出",
        "body": "当我在用NEXTVALD模型对视频分类的时候，我想提取视频的embedding向量，请问paddle有获取指定层的输出的方法吗？我该怎么做？",
        "state": "open",
        "user": "mrright2019",
        "closed_by": null,
        "created_at": "2019-12-24T02:16:57+00:00",
        "updated_at": "2019-12-31T10:03:47+00:00",
        "closed_at": null,
        "comments_count": [
            "yaoxuefeng6",
            "mrright2019"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4123,
        "title": "CTCN模型训练一段时间后NAN",
        "body": "使用CTCN模型代码，输入数据是自己的数据\r\n1. 测试1，img_size=512, concept_size=512, batch_size = 16. 第一个epoch训练正常，第二个epoch在中间出现NAN\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 0  Loss = 8.644265174865723,   loc_loss = 5.305370330810547,   cls_loss = 3.338895320892334\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 10     Loss = 6.298323631286621,   loc_loss = 3.9766969680786133,  cls_loss = 2.3216264247894287\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 20     Loss = 7.81887149810791,    loc_loss = 4.746278762817383,   cls_loss = 3.0725927352905273\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 30     Loss = 9.531373977661133,   loc_loss = 5.976119041442871,   cls_loss = 3.555255174636841\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 40     Loss = 8.562569618225098,   loc_loss = 4.903314590454102,   cls_loss = 3.659255027770996\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 50     Loss = 7.116206169128418,   loc_loss = 3.607116222381592,   cls_loss = 3.509089946746826\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 60     Loss = 8.900976181030273,   loc_loss = 4.741877555847168,   cls_loss = 4.1590986251831055\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 70     Loss = 7.006552219390869,   loc_loss = 4.304408550262451,   cls_loss = 2.702143430709839\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 80     Loss = 7.706241607666016,   loc_loss = 4.250545978546143,   cls_loss = 3.455695867538452\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 90     Loss = 8.307282447814941,   loc_loss = 4.759175777435303,   cls_loss = 3.5481057167053223\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 100    Loss = 7.775359630584717,   loc_loss = 4.987478733062744,   cls_loss = 2.7878808975219727\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 110    Loss = 8.040206909179688,   loc_loss = 4.403718948364258,   cls_loss = 3.6364874839782715\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 120    Loss = 9.691923141479492,   loc_loss = 4.130779266357422,   cls_loss = 5.561143398284912\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 130    Loss = 7.779775619506836,   loc_loss = 4.071199417114258,   cls_loss = 3.708575963973999\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 140    Loss = 7.102745532989502,   loc_loss = 4.228488922119141,   cls_loss = 2.8742568492889404\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 150    Loss = 6.970609188079834,   loc_loss = 3.9636733531951904,  cls_loss = 3.006936550140381\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 160    Loss = nan,     loc_loss = 21.078128814697266,  cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 170    Loss = nan,     loc_loss = 20.18567657470703,   cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 180    Loss = nan,     loc_loss = 20.06766700744629,   cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 190    Loss = nan,     loc_loss = 20.610614776611328,  cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 200    Loss = nan,     loc_loss = 19.23656463623047,   cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 210    Loss = nan,     loc_loss = 19.809160232543945,  cls_loss = nan\r\n\r\n\r\n2. 测试2，img_size=512, concept_size=256, batch_size = 16. 第一个epoch训练正常，第二个epoch在中间出现NAN\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 0  Loss = 8.087115287780762,   loc_loss = 4.917365074157715,   cls_loss = 3.169750213623047\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 10     Loss = 7.561893463134766,   loc_loss = 4.704628944396973,   cls_loss = 2.857264280319214\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 20     Loss = 7.202031135559082,   loc_loss = 4.352816581726074,   cls_loss = 2.8492140769958496\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 30     Loss = 7.938170433044434,   loc_loss = 5.153167247772217,   cls_loss = 2.7850029468536377\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 40     Loss = 8.291640281677246,   loc_loss = 5.546207904815674,   cls_loss = 2.7454323768615723\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 50     Loss = 7.575397968292236,   loc_loss = 4.737273216247559,   cls_loss = 2.838124990463257\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 60     Loss = 7.889821529388428,   loc_loss = 4.824648857116699,   cls_loss = 3.0651731491088867\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 70     Loss = 8.803262710571289,   loc_loss = 4.728842735290527,   cls_loss = 4.074419975280762\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 80     Loss = 9.253735542297363,   loc_loss = 4.693952560424805,   cls_loss = 4.559782981872559\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 90     Loss = 8.738704681396484,   loc_loss = 4.8759965896606445,  cls_loss = 3.862708568572998\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 100    Loss = 7.218425750732422,   loc_loss = 4.249882698059082,   cls_loss = 2.96854305267334\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 110    Loss = 7.345929145812988,   loc_loss = 4.364291191101074,   cls_loss = 2.981637716293335\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 120    Loss = 7.921400547027588,   loc_loss = 4.798431873321533,   cls_loss = 3.122968912124634\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 130    Loss = 8.251079559326172,   loc_loss = 4.602048873901367,   cls_loss = 3.6490306854248047\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 140    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 150    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 160    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 170    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 180    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 190    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 200    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 210    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 220    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 230    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 240    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n[INFO: metrics_util.py:  282]: [TRAIN] Epoch 1, iter 250    Loss = nan,     loc_loss = nan,     cls_loss = nan\r\n\r\n",
        "state": "open",
        "user": "linrjing",
        "closed_by": null,
        "created_at": "2019-12-25T05:34:06+00:00",
        "updated_at": "2020-07-05T02:59:12+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "baiyfbupt",
            "linrjing",
            "baiyfbupt",
            "linrjing",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4132,
        "title": "models/PaddleNLP/emotion_detection/ 官方代码运行sh run.sh eval评估出错",
        "body": "PaddleNLP/emotion_detection/项目我还没有修改模型代码，运行官方评估代码时出错，如图\r\n<img width=\"566\" alt=\"屏幕快照 2019-12-26 下午2 54 04\" src=\"https://user-images.githubusercontent.com/9459980/71463170-7d893600-27f0-11ea-9aa4-37540c08afcf.png\">\r\n但，保存的模型下是有正确存放该模型参数的，如图\r\n<img width=\"456\" alt=\"屏幕快照 2019-12-26 下午2 59 31\" src=\"https://user-images.githubusercontent.com/9459980/71463215-9abe0480-27f0-11ea-9109-f3ffe76ab6d6.png\">\r\n请问，这是什么问题呢？\r\n\r\n",
        "state": "closed",
        "user": "lixuan1",
        "closed_by": "lixuan1",
        "created_at": "2019-12-26T07:02:02+00:00",
        "updated_at": "2019-12-26T08:00:48+00:00",
        "closed_at": "2019-12-26T08:00:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4127,
        "title": "PaddleDetection Retinanet 评估失败 Cannot find fetched variable(im_id)",
        "body": "软硬件环境：GPU P4, CUDA7.0; CUDNN9.0\r\n代码版本 paddleDetection（ commit_id d7fcd54d7b038823ae0938ea48242cd38b7ec942）\r\npaddle 1.6.2\r\n背景：将异步读取的pyreader改为同步feeder读取\r\n```python\r\n`def eval_run_feeder(exe, compile_program, reader, feeder, keys, values, cls):\r\n    \"\"\"\r\n    Run evaluation program, return program outputs.\r\n    \"\"\"\r\n    iter_id = 0\r\n    results = []\r\n    if len(cls) != 0:\r\n        values = []\r\n        for i in range(len(cls)):\r\n            _, accum_map = cls[i].get_map_var()\r\n            cls[i].reset(exe)\r\n            values.append(accum_map)\r\n    print(\"@@@@@@values\", values)\r\n    images_num = 0\r\n    start_time = time.time()\r\n    has_bbox = 'bbox' in keys\r\n\r\n\r\n    for it, data in enumerate(reader()):\r\n        print(\"data\",data)\r\n        outs = exe.run(compile_program,\r\n                       feed=feeder.feed(data),\r\n                       fetch_list=values,\r\n                       return_numpy=False)\r\n\r\n        res = {\r\n            k: (np.array(v), v.recursive_sequence_lengths())\r\n            for k, v in zip(keys, outs)\r\n        }\r\n        results.append(res)\r\n        if iter_id % 100 == 0:\r\n            logger.info('Test iter {}'.format(iter_id))\r\n        iter_id += 1\r\n        images_num += len(res['bbox'][1][0]) if has_bbox else 1\r\n\r\n\r\n    end_time = time.time()\r\n    fps = images_num / (end_time - start_time)\r\n    if has_bbox:\r\n        logger.info('Total number of images: {}, inference time: {} fps.'.\r\n                    format(images_num, fps))\r\n    else:\r\n        logger.info('Total iteration: {}, inference time: {} batch/s.'.format(\r\n            images_num, fps))\r\n\r\n    return results\r\n`\r\n```\r\n\r\n**报错如下**：\r\n```shell\r\n`1225 12:21:15.713791 20964 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI1225 12:21:15.724485 20964 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1225 12:21:15.738996 20964 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"tools/train_feeder.py\", line 374, in <module>\r\n    main()\r\n  File \"tools/train_feeder.py\", line 299, in main\r\n    eval_keys, eval_values, eval_cls)\r\n  File \"tools/train_feeder.py\", line 79, in eval_run_feeder\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 834, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 674, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::framework::details::FastThreadedSSAGraphExecutor::InsertFetchOps(std::vector<std::string, std::allocator<std::string> > const&, std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*, std::unordered_map<std::string, std::vector<paddle::framework::details::VarHandleBase*, std::allocator<paddle::framework::details::VarHandleBase*> >, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, std::vector<paddle::framework::details::VarHandleBase*, std::allocator<paddle::framework::details::VarHandleBase*> > > > >*, std::unordered_map<paddle::framework::details::OpHandleBase*, std::atomic<int>, std::hash<paddle::framework::details::OpHandleBase*>, std::equal_to<paddle::framework::details::OpHandleBase*>, std::allocator<std::pair<paddle::framework::details::OpHandleBase* const, std::atomic<int> > > >*, std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> >*, std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> >*)\r\n3   paddle::framework::details::FastThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n4   paddle::framework::details::ScopeBufferedMonitor::Apply(std::function<void ()> const&, bool)\r\n5   paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n6   paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot find fetched variable(im_id).(Perhaps the main_program is not set to ParallelExecutor) at (/paddle/paddle/fluid/framework/details/fast_threaded_ssa_graph_executor.cc:145)`\r\n```",
        "state": "open",
        "user": "ellinyang",
        "closed_by": null,
        "created_at": "2019-12-25T12:26:19+00:00",
        "updated_at": "2019-12-30T06:43:35+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "ellinyang",
            "baiyfbupt",
            "baiyfbupt",
            "ellinyang",
            "ellinyang",
            "qingqing01",
            "ellinyang",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4129,
        "title": "PaddleCV/image_classification 是否支持 openimages 数据集这种multi-label分类",
        "body": "PaddleCV/image_classification 是否支持 openimages 数据集这种multi-label分类 训练/预测?",
        "state": "closed",
        "user": "linghaolu",
        "closed_by": "linghaolu",
        "created_at": "2019-12-26T02:29:38+00:00",
        "updated_at": "2019-12-27T01:25:01+00:00",
        "closed_at": "2019-12-27T01:25:01+00:00",
        "comments_count": [
            "iclementine",
            "linghaolu",
            "iclementine"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4139,
        "title": "图像分类代码问题 killed",
        "body": "问题：分类代码运行一段时间，显示killed 程序退出\r\n原因：可能是内存占满\r\n分析方法：在程序运行过程中，实时的监测下内存占用情况，如果程序占用内存一直在涨的话，可能问题出现在reader过程中，不断的缓存数据\r\n解决办法：调整xmapreader的num_thread 和buffer_size，具体调整方法参考：(WIP)",
        "state": "closed",
        "user": "shippingwang",
        "closed_by": "shippingwang",
        "created_at": "2019-12-29T11:35:47+00:00",
        "updated_at": "2021-06-10T15:06:30+00:00",
        "closed_at": "2019-12-30T04:06:24+00:00",
        "comments_count": [
            "hongyuzlx"
        ],
        "labels": [
            "FAQ"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4144,
        "title": "为何ocr attention 模型训练出来后，经常将长文本识别错？",
        "body": "训练时候验证集上识别率达到８０％多，但实际使用时效果较差，特别是对于长文本识别较差，这是否是训练时过拟合了？",
        "state": "closed",
        "user": "wenston2006",
        "closed_by": "wanghaoshuang",
        "created_at": "2019-12-30T09:09:58+00:00",
        "updated_at": "2020-01-16T07:52:45+00:00",
        "closed_at": "2020-01-16T07:52:45+00:00",
        "comments_count": [
            "XingWu01",
            "wanghaoshuang",
            "wenston2006",
            "cnzhujg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4143,
        "title": "OCR训练如何添加图片扩增（data augmentation)功能?",
        "body": "OCR训练中发现attention model很容易过拟合，　因此想在训练时候进行图片扩增（实时的进行旋转，裁剪，加噪声，扭曲），请问有没有这方面的功能？",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2019-12-30T08:18:17+00:00",
        "updated_at": "2024-02-26T05:13:27+00:00",
        "closed_at": null,
        "comments_count": [
            "XingWu01",
            "wanghaoshuang",
            "lishiyu93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4145,
        "title": "PaddleDetection快速开始tools/train.py 报错CUDNN_STATUS_BAD_PARAM ",
        "body": "系统：ubuntu16.04\r\nCUDA Version 10.0.130\r\nCUDnn 7.4.2\r\nNccl  2.4.8\r\npython 3.7\r\n\r\npython -u tools/train.py -c configs/yolov3_mobilenet_v1_fruit.yml --use_tb=True --tb_log_dir=tb_fruit_dir/scalar --eval\r\n运行时，报错如下：\r\nuse_gpu: true\r\nweights: output/yolov3_mobilenet_v1_fruit/best_model\r\n\r\n2019-12-30 17:02:35,740-INFO: places would be ommited when DataLoader is not iterable\r\nW1230 17:02:36.778067  9089 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1230 17:02:36.781242  9089 device_context.cc:244] device: 0, cuDNN Version: 7.4.\r\nW1230 17:02:36.781275  9089 device_context.cc:270] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.4, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\n2019-12-30 17:02:37,792-INFO: Found /home/css/.cache/paddle/weights/yolov3_mobilenet_v1\r\n2019-12-30 17:02:37,792-INFO: Loading parameters from /home/css/.cache/paddle/weights/yolov3_mobilenet_v1...\r\n2019-12-30 17:02:37,797-INFO: In load_params, ignore yolo_output.0.conv.weights\r\n2019-12-30 17:02:37,797-INFO: In load_params, ignore yolo_output.0.conv.bias\r\n2019-12-30 17:02:37,798-INFO: In load_params, ignore yolo_output.1.conv.weights\r\n2019-12-30 17:02:37,798-INFO: In load_params, ignore yolo_output.1.conv.bias\r\n2019-12-30 17:02:37,800-INFO: In load_params, ignore yolo_output.2.conv.weights\r\n2019-12-30 17:02:37,800-INFO: In load_params, ignore yolo_output.2.conv.bias\r\n2019-12-30 17:02:39,540-INFO: places would be ommited when DataLoader is not iterable\r\nI1230 17:02:39.740296  9089 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI1230 17:02:39.834806  9089 graph_pattern_detector.cc:96] ---  detected 1 subgraphs\r\nI1230 17:02:39.953145  9089 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI1230 17:02:40.066726  9089 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI1230 17:02:40.164924  9089 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 340, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 246, in main\r\n    outs = exe.run(compiled_train_prog, fetch_list=train_values)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/six.py\", line 696, in reraise\r\n    raise value\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 834, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 674, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n2   paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n8   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n10  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n11  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n12  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 4363, in batch_norm\r\n    attrs=attrs)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/modeling/backbones/mobilenet.py\", line 97, in _conv_norm\r\n    moving_variance_name=bn_name + '_variance')\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/modeling/backbones/mobilenet.py\", line 157, in __call__\r\n    input, 3, int(32 * scale), 2, 1, name=self.prefix_name + \"conv1\")\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/modeling/architectures/yolov3.py\", line 56, in build\r\n    body_feats = self.backbone(im)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/modeling/architectures/yolov3.py\", line 80, in train\r\n    return self.build(feed_vars, mode='train')\r\n  File \"tools/train.py\", line 128, in main\r\n    train_fetches = model.train(feed_vars)\r\n  File \"tools/train.py\", line 340, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: CUDNN_STATUS_BAD_PARAM at (/paddle/paddle/fluid/operators/batch_norm_op.cu:183)\r\n  [operator < batch_norm > error]\r\n\r\n^CError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\nProcess Process-6:\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\r\n    pid, sts = os.waitpid(self.pid, flag)\r\nKeyboardInterrupt\r\nTraceback (most recent call last):\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/dataset.py\", line 48, in reset\r\n    (self.__class__.__name__))\r\nNotImplementedError: MappedDataset.reset not available\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/transform/transformer.py\", line 44, in _proxy_method\r\n    return func(*args, **kwargs)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/dataset.py\", line 48, in reset\r\n    (self.__class__.__name__))\r\nNotImplementedError: BatchedDataset.reset not available\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\r\n    self.run()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/process.py\", line 99, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/transform/parallel_map.py\", line 153, in _consume\r\n    outq.put(result)\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/transform/shared_queue/queue.py\", line 71, in put\r\n    super(SharedQueue, self).put(buff, **kwargs)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/queues.py\", line 89, in put\r\n    self._notempty.notify()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/threading.py\", line 352, in notify\r\n    waiter.release()\r\n  File \"/home/css/work/fl/pp_env/fast_rcnn/PaddleDetection/PaddleDetection/ppdet/data/transform/parallel_map.py\", line 226, in _reader_exit\r\n    sys.exit()\r\nSystemExit\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\r\n    util._exit_function()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\r\n    _run_finalizers()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\r\n    finalizer()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\r\n    res = self._callback(*self._args, **self._kwargs)\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\r\n    thread.join()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/threading.py\", line 1044, in join\r\n    self._wait_for_tstate_lock()\r\n  File \"/home/css/anaconda3/envs/fl_pp_env/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\r\n    elif lock.acquire(block, timeout):\r\nKeyboardInterrupt\r\n\r\npython ppdet/modeling/tests/test_architectures.py，确认通过\r\n\r\n",
        "state": "closed",
        "user": "mikeFang1986",
        "closed_by": "mikeFang1986",
        "created_at": "2019-12-30T09:14:47+00:00",
        "updated_at": "2020-01-03T01:32:02+00:00",
        "closed_at": "2020-01-03T01:32:02+00:00",
        "comments_count": [
            "mikeFang1986",
            "mikeFang1986",
            "mikeFang1986",
            "xiegegege",
            "mikeFang1986"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4149,
        "title": "这个模型能不能把导出模型代码补上(models/PaddleNLP/PaddleTextGEN/seq2seq/）",
        "body": "https://github.com/PaddlePaddle/models/tree/c35c10a8fdd69039cc79c76f19cee87d04bc400b/PaddleNLP/PaddleTextGEN/seq2seq\r\n\r\n",
        "state": "open",
        "user": "aixier",
        "closed_by": null,
        "created_at": "2019-12-31T09:02:04+00:00",
        "updated_at": "2024-02-26T05:13:24+00:00",
        "closed_at": null,
        "comments_count": [
            "1024er",
            "lixuan1",
            "lixuan1",
            "lixuan1",
            "1024er",
            "lixuan1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4151,
        "title": "使用 QuantizationFreezePass 量化模型报错",
        "body": "我按照 PaddleDetection 中 `slim\\quantization\\freeze.py`  量化训练好的 MobileNetV1_SSD 模型，在使用 QuantizationFreezePass  时报错，主要代码如下\r\n```Python\r\n    use_gpu = cfg.model.use_gpu\r\n\r\n    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    exe.run(fluid.default_startup_program())\r\n\r\n    test_prog, feed_var_names, fetch_vars = fluid.io.load_inference_model(model_path, exe)\r\n    test_graph = IrGraph(fluid.core.Graph(test_prog.desc), for_test=True)\r\n    \r\n    # ret = eval_run(cfg, exe, test_prog, feed_var_names, fetch_vars)\r\n\r\n    freeze_pass = QuantizationFreezePass(fluid.global_scope(), place)\r\n    freeze_pass.apply(test_graph)\r\n    float_prog = test_graph.to_program()\r\n\r\n    basename = os.path.basename(model_path)\r\n    tmp_path = os.path.join(output_path, basename+'_float')\r\n    checkpoint.save_inference_model(tmp_path, exe, float_prog, feed_var_names, fetch_vars)\r\n```\r\n错误信息如下\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\freeze_model.py\", line 91, in quantize\r\n    freeze_pass.apply(test_graph)\r\n  File \"C:\\Users\\morgan\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\quantization_pass.py\", line 683, in apply\r\n    self._insert_post_dequant_op(graph, op_node)\r\n  File \"C:\\Users\\morgan\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\quantization_pass.py\", line 789, in _insert_post_dequant_op\r\n    scale_v = self._var_scale_map[original_var_name]\r\nKeyError: 'conv7_1_sep_weights'\r\n```\r\n使用环境为：win10, Python 3.6.8,  paddle 1.6.2.\r\n加载的模型能够正确预测，QuantizationFreezePass 每次报错 KeyError 都不一样，我是新手，请问训练后量化怎么做才是正确的呢？\r\n\r\n\r\n",
        "state": "closed",
        "user": "morgan-bc",
        "closed_by": "morgan-bc",
        "created_at": "2020-01-01T13:56:43+00:00",
        "updated_at": "2020-01-13T03:08:55+00:00",
        "closed_at": "2020-01-13T03:08:55+00:00",
        "comments_count": [
            "LDOUBLEV",
            "slf12",
            "morgan-bc",
            "slf12",
            "morgan-bc",
            "slf12",
            "morgan-bc",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4147,
        "title": "LAC模型利用paddleHub加载后，可否使用paddlehub集成的MsraNER数据集训练？",
        "body": "如题，利用以下三行代码可以实现预测\r\nimport paddlehub as hub\r\nlac=hub.Module(name='lac')\r\nresults=lac.lexical_analysis(data=inputs)\r\n但若我想基于另一个数据集（hub.dataset.MsraNER()）将LAC训练后再使用，该怎么做? #",
        "state": "open",
        "user": "sataliulan",
        "closed_by": null,
        "created_at": "2019-12-30T12:45:04+00:00",
        "updated_at": "2020-01-19T14:20:28+00:00",
        "closed_at": null,
        "comments_count": [
            "XingWu01",
            "XingWu01",
            "sataliulan",
            "Steffy-zxf",
            "sataliulan",
            "sataliulan",
            "Steffy-zxf",
            "sataliulan",
            "sataliulan",
            "Bond-H",
            "sataliulan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4153,
        "title": "按教程进行预训练报错：“finetune_exclude_pretrained_params”",
        "body": "按照官方教程（https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification）进行预训练微调参数，训练自己的数据时需要滤掉最后的FC层报错：”train.py: error: unrecognized arguments: --finetune_exclude_pretrained_params=fc_offset,fc_weights“\r\n\r\n错误很明显：官方的train.py代码中没有“finetune_exclude_pretrained_params”参数，请官方人员回复一下，如果没有这个参数，我做微调如何去掉最后一层的参数呢？？？\r\n\r\n1）官方给的命令：\r\npython train.py \\\r\n        --data_dir=./data/ILSVRC2012/ \\\r\n        --total_images=1281167 \\\r\n        --class_dim=1000 \\\r\n        --validate=True \\\r\n        --model=ResNet50_vd \\\r\n        --batch_size=256 \\  \r\n        --lr=0.1 \\\r\n        --num_epochs=200 \\\r\n        --model_save_dir=output/ \\\r\n        --l2_decay=7e-5 \\\r\n        --pretrained_model=${path_to_pretrain_model} \\\r\n        --finetune_exclude_pretrained_params=fc_0.w_0,fc_0.b_0\r\n\r\n2）我的命令：\r\npython train.py --model=DPN107 --data_dir=input_image/train_images --total_images=20580 --class_dim=120 --batch_size=30 --pretrained_model=models_parameters/pretrained_model/DPN107 --model_save_dir=models_parameters/training_model/DPN107 --finetune_exclude_pretrained_params=fc_offset,fc_weights",
        "state": "open",
        "user": "ryliu68",
        "closed_by": null,
        "created_at": "2020-01-03T14:43:58+00:00",
        "updated_at": "2020-01-07T11:01:42+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "ryliu68",
            "kuke",
            "chliang",
            "ryliu68",
            "kuke",
            "chliang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4156,
        "title": "分类 评估预测 结果和 部署预测结果不一致",
        "body": "models/PaddleCV/image_classification/ 中\r\ninfer.py  的结果 和 predict.py 的结果  不一致，其中  predict.py 用的模型是 infer.py用的模型固化后的模型\r\n`paddlepaddle-gpu              1.6.2.post97`\r\n`模型 Xception41, Xception65, Xception71`\r\n\r\n\r\n",
        "state": "open",
        "user": "chliang",
        "closed_by": null,
        "created_at": "2020-01-05T04:44:14+00:00",
        "updated_at": "2020-01-07T09:45:10+00:00",
        "closed_at": null,
        "comments_count": [
            "littletomatodonkey",
            "chliang",
            "littletomatodonkey",
            "littletomatodonkey",
            "littletomatodonkey",
            "FrostML",
            "chliang",
            "FrostML",
            "FrostML",
            "silingtong123",
            "silingtong123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4157,
        "title": "用paddleNLP中的emotion detection模型库，当文本类别好几千时，算出来avg loss: nan如何解决？",
        "body": "版本为fluid 1.4, CUDA 9.0, cuDNN Version: 7.0;\r\n我的类别从0一直到6600，有六千多个类，log信息如下：\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 64\r\nconfig_path: ./config.json\r\ndata_dir: ./data/\r\ndo_infer: False\r\ndo_train: True\r\ndo_val: True\r\nepoch: 60\r\ninit_checkpoint: None\r\nlr: 0.002\r\noutput_dir: ./save_models/bilstm\r\nrandom_seed: 0\r\nsave_steps: 1000\r\nskip_steps: 1000\r\ntask_name: topic_detection\r\nuse_cuda: True\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: ./data/vocab.txt\r\n------------------------------------------------\r\nNum train examples: 966363\r\nMax train steps: 905966\r\nstep: 1000, avg loss: nan, avg acc: 0.312500, speed: 68.159301 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.285054, elapsed time: 4.126837 s\r\nstep: 2000, avg loss: nan, avg acc: 0.328125, speed: 54.500267 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.288556, elapsed time: 4.153094 s\r\nstep: 3000, avg loss: nan, avg acc: 0.265625, speed: 55.482941 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.289574, elapsed time: 5.376837 s\r\nstep: 4000, avg loss: nan, avg acc: 0.234375, speed: 51.638327 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.289897, elapsed time: 3.970590 s\r\nstep: 5000, avg loss: nan, avg acc: 0.312500, speed: 55.464049 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.289997, elapsed time: 3.967897 s\r\nstep: 6000, avg loss: nan, avg acc: 0.281250, speed: 55.519344 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.290493, elapsed time: 4.155741 s\r\nstep: 7000, avg loss: nan, avg acc: 0.281250, speed: 54.741381 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.290816, elapsed time: 4.073371 s\r\nstep: 8000, avg loss: nan, avg acc: 0.359375, speed: 55.044019 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.290990, elapsed time: 4.118042 s\r\nstep: 9000, avg loss: nan, avg acc: 0.343750, speed: 50.080564 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.290990, elapsed time: 4.061233 s\r\nstep: 10000, avg loss: nan, avg acc: 0.281250, speed: 53.257747 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.291015, elapsed time: 3.943664 s\r\nstep: 11000, avg loss: nan, avg acc: 0.281250, speed: 55.656405 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.291139, elapsed time: 4.204237 s\r\nstep: 12000, avg loss: nan, avg acc: 0.250000, speed: 53.648392 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.291164, elapsed time: 3.995078 s\r\n\r\n到第69000时\r\nstep: 69000, avg loss: 3125000062627741696.000000, avg acc: 0.359375, speed: 54.769828 steps/s\r\n[dev evaluation] avg loss: nan, avg acc: 0.291909, elapsed time: 4.050528 s\r\n但后面双变成nan",
        "state": "closed",
        "user": "xfyu1999",
        "closed_by": "chenbjin",
        "created_at": "2020-01-06T04:02:05+00:00",
        "updated_at": "2020-01-07T06:34:24+00:00",
        "closed_at": "2020-01-07T06:34:23+00:00",
        "comments_count": [
            "chenbjin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4166,
        "title": "目前paddle可以支持以下操作吗",
        "body": "目前paddle可以支持以下操作吗？\r\n1. 初始化两个相同的网络， 一个（N1）训练，另一个（N2）stop gradient， 更新一次网络参数后，  对N1的网络参数加权累加到N2\r\n2. 初始化一个 buffer， 训练时不更新， 更新一次网络参数后， 再手动修改buffer局部的值",
        "state": "closed",
        "user": "kebinC",
        "closed_by": "gongweibao",
        "created_at": "2020-01-06T12:42:23+00:00",
        "updated_at": "2020-01-07T12:08:42+00:00",
        "closed_at": "2020-01-07T12:08:42+00:00",
        "comments_count": [
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4167,
        "title": "AutoDL跳转路径有问题，难道就没有人发现吗？也一直没人更正。。。",
        "body": "打开\r\nhttps://github.com/PaddlePaddle/models/tree/develop/fluid/AutoDL/LRC\r\n跳转提示：404\r\n\r\n明显是地址给错了，难道就没人发现？一直没见人改。。。",
        "state": "open",
        "user": "ryliu68",
        "closed_by": null,
        "created_at": "2020-01-06T13:30:39+00:00",
        "updated_at": "2024-02-26T05:13:21+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4168,
        "title": "模型滤波器通道数报错",
        "body": "图像分类，输入图像通道改为6，配置文件 `'--image_shape 6 500  512', `中通道也改成了6，\r\n但是 运行过程中报错。\r\n使用最简单的 alexnet测试。\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/alexnet.py\r\n```\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: The number of input channels should be equal to filter channels * groups. But received: the input channels is [6], the \r\nshapeof input is [1, 6, 500, 512], the filter \r\nchannel is [3], the shape of filter is [64, 3, 11, 11],the groups is [1]\r\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:6 != filter_dims[1] * groups:3.] at (D:\\1.6.2\\paddle\\paddle\\fluid\\operators\\conv_op.cc:94)     \r\n  [operator < conv2d > error]\r\n```\r\n\r\n问题 ，滤波器的通道数怎么改，里面是默认是3 么？不应该是和输入数据的通道数一致么",
        "state": "closed",
        "user": "chliang",
        "closed_by": "chliang",
        "created_at": "2020-01-07T04:57:44+00:00",
        "updated_at": "2020-01-09T08:14:44+00:00",
        "closed_at": "2020-01-09T04:55:36+00:00",
        "comments_count": [
            "guoshengCS",
            "chliang",
            "guoshengCS",
            "guoshengCS",
            "shippingwang",
            "chliang",
            "chliang",
            "wulipc",
            "chliang",
            "wulipc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4169,
        "title": "上线部署问题",
        "body": "[https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/emotion_detection](https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/emotion_detection)情感识别项目的部署。已经通过调用paddle.fluid.io.save_inference_model实现了模型的保存。但测试时无法成功，可能是参数设置有问题。自定义参数转换之后，产生如下错误：\r\n<img width=\"1095\" alt=\"屏幕快照 2020-01-07 下午3 21 12\" src=\"https://user-images.githubusercontent.com/9459980/71876311-6851c700-3161-11ea-9cbb-1fb7a4d433f0.png\">\r\n`\"errorCode\": 500,\r\n    \"errorMsg\": \"服务异常:Connect to studio-2057:8016 [studio-2057/172.18.134.54] failed: Connection refused`\r\n使用默认参数，不设置参数转换器时，也会报错:\r\n`\"error_code\": 500, \"error_msg\": \"System error: 'weight_r'\"`\r\n。实在不知道哪里有问题，希望得到解答。另外，预测时应该也需要用到vocab.txt。但部署中似乎没有这个？\r\n另外，为了排除我自己的参数设置有问题，我测试部署了官方文档中的[房价预测项目的部署](https://ai.baidu.com/ai-doc/AISTUDIO/bk3e382cq#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%9C%A8%E7%BA%BF%E6%9C%8D%E5%8A%A1)，根据官方教程文档中的代码，设置了自定义参数转换器，同样发生服务异常，连接被拒的情况，如下：\r\n`\"errorMsg\": \"服务异常:Connect to studio-2057:8016 [studio-2057/172.18.134.54] failed: Connection refused`服务异常的情况。望解答\r\n@ZeyuChen @Yancey1989 ",
        "state": "open",
        "user": "lixuan1",
        "closed_by": null,
        "created_at": "2020-01-07T07:32:10+00:00",
        "updated_at": "2024-02-26T05:13:19+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "lixuan1",
            "lixuan1",
            "lixuan1",
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4173,
        "title": "GPU一直显示各种内存溢出",
        "body": "代码是cycleGan的内容，报错内容是\r\nOut of memory error on GPU 0. Cannot allocate 80.000244MB memory on GPU 0, available memory is only 76.089062MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.50 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n使用源码而且尝试了网上所说的 os.environ[\"FLAGS_fraction_of_gpu_memory_to_use\"]=\"0.7\"也无法解决，求助",
        "state": "open",
        "user": "shanzhengliu",
        "closed_by": null,
        "created_at": "2020-01-08T01:44:26+00:00",
        "updated_at": "2024-02-26T05:13:18+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "callmeivy",
            "shanzhengliu",
            "callmeivy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4174,
        "title": "dialogue_general_understanding linux python3 报错",
        "body": "train udc start..........\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 23, in <module>\r\n    from train import do_train\r\n  File \"/ssd2/zhengya01/devlop_conv/test/models/PaddleNLP/PaddleDialogue/dialogue_general_understanding/train.py\", line 29, in <module>\r\n    import dgu.reader as reader\r\n  File \"/ssd2/zhengya01/devlop_conv/test/models/PaddleNLP/PaddleDialogue/dialogue_general_understanding/dgu/reader.py\", line 26, in <module>\r\n    reload(sys)\r\nNameError: name 'reload' is not defined\r\ntrain udc finish..........",
        "state": "open",
        "user": "zhengya01",
        "closed_by": null,
        "created_at": "2020-01-08T03:37:43+00:00",
        "updated_at": "2020-01-13T03:29:07+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "zhengya01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4178,
        "title": "多显卡服务器中，用单显卡训练图片分类时，出现Pass中batch数不对的问题",
        "body": "相关参数设置如下：\r\n`add_arg('total_images',             int,    777,                \"The number of total training images.\")\r\nadd_arg('batch_size',               int,    32,                      \"Minibatch size on a device.\")\r\n`\r\n具体显示如下：\r\n`[Pass 1, train batch 186]       loss 2.17508, acc1 0.50000, acc5 0.75000, lr 0.00188, elapse 0.0189 sec\r\n[Pass 1, train batch 187]       loss 2.31072, acc1 0.25000, acc5 0.50000, lr 0.00188, elapse 0.0188 sec\r\n[Pass 1, train batch 188]       loss 2.21176, acc1 0.25000, acc5 0.75000, lr 0.00188, elapse 0.0185 sec\r\n[Pass 1, train batch 189]       loss 2.14681, acc1 0.75000, acc5 0.75000, lr 0.00188, elapse 0.0201 sec\r\n[Pass 1, train batch 190]       loss 1.80597, acc1 0.75000, acc5 1.00000, lr 0.00188, elapse 0.0181 sec\r\n[Pass 1, train batch 191]       loss 1.95061, acc1 0.50000, acc5 0.75000, lr 0.00188, elapse 0.0194 sec\r\n[Pass 1, train batch 192]       loss 2.30522, acc1 0.25000, acc5 0.50000, lr 0.00188, elapse 0.0193 sec\r\n[Pass 1, train batch 193]       loss 2.49756, acc1 0.25000, acc5 0.50000, lr 0.00188, elapse 0.0199 sec\r\n`\r\nPass中的batch数应为24，却有193个batch",
        "state": "closed",
        "user": "youwei2567",
        "closed_by": "youwei2567",
        "created_at": "2020-01-09T03:17:00+00:00",
        "updated_at": "2020-01-14T01:40:40+00:00",
        "closed_at": "2020-01-14T01:40:40+00:00",
        "comments_count": [
            "youwei2567",
            "youwei2567",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4183,
        "title": "是否支持Reflection padding op",
        "body": "hi，paddle现在是否具有类似pytorch中reflection padding 这样的非0 padding op？",
        "state": "open",
        "user": "Overtown",
        "closed_by": null,
        "created_at": "2020-01-10T07:29:13+00:00",
        "updated_at": "2024-02-26T05:13:16+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4187,
        "title": "autodl.py中类别参数写死了，self.class_num = 1000，无法使用微调命令进行传参",
        "body": "微调命令：\r\npython train.py    --class_dim=xxx",
        "state": "open",
        "user": "ryliu68",
        "closed_by": null,
        "created_at": "2020-01-13T03:18:25+00:00",
        "updated_at": "2024-02-26T05:13:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 4201
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4186,
        "title": "请问deepFM中为什么epoch的时间这么短？",
        "body": "请问在按照deepFM中所说的步骤走的情况下，为什么最后在local_train阶段epoch的时间会这么短？\r\n\r\n以下为得到的结果：\r\nargs.embedding_size: 10\r\nargs.num_field: 39\r\nargs.num_feat: 1086460\r\nargs.layer_sizes: [400, 400, 400]\r\nargs.act: relu\r\nargs.reg: 0.0001\r\n---------------------------------------------\r\nepoch1 is finished and takes 0.069958 s\r\nepoch2 is finished and takes 0.030759 s\r\nepoch3 is finished and takes 0.031983 s\r\nepoch4 is finished and takes 0.039973 s\r\nepoch5 is finished and takes 0.032980 s\r\nepoch6 is finished and takes 0.033335 s\r\nepoch7 is finished and takes 0.029980 s\r\nepoch8 is finished and takes 0.029713 s\r\nepoch9 is finished and takes 0.029981 s\r\nepoch10 is finished and takes 0.038977 s\r\nepoch11 is finished and takes 0.044971 s\r\nepoch12 is finished and takes 0.028981 s\r\nepoch13 is finished and takes 0.040977 s\r\nepoch14 is finished and takes 0.037975 s\r\nepoch15 is finished and takes 0.032979 s\r\nepoch16 is finished and takes 0.032980 s\r\nepoch17 is finished and takes 0.030980 s\r\nepoch18 is finished and takes 0.031979 s\r\nepoch19 is finished and takes 0.033981 s\r\nepoch20 is finished and takes 0.032983 s\r\nepoch21 is finished and takes 0.033988 s\r\nepoch22 is finished and takes 0.031253 s\r\nepoch23 is finished and takes 0.033978 s\r\nepoch24 is finished and takes 0.031979 s\r\nepoch25 is finished and takes 0.032640 s\r\nepoch26 is finished and takes 0.032981 s\r\nepoch27 is finished and takes 0.032980 s\r\nepoch28 is finished and takes 0.036979 s\r\nepoch29 is finished and takes 0.031981 s\r\nepoch30 is finished and takes 0.030977 s\r\n\r\nProcess finished with exit code 0\r\n",
        "state": "closed",
        "user": "witness99",
        "closed_by": "witness99",
        "created_at": "2020-01-12T10:44:55+00:00",
        "updated_at": "2020-11-25T07:53:28+00:00",
        "closed_at": "2020-11-25T07:53:28+00:00",
        "comments_count": [
            "frankwhzhang",
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4189,
        "title": "PaddleNLP/PaddleDialogue/dialogue_general_understanding 的 DSTC2 数据building有问题",
        "body": "测试dstc2数据的时候发现，bash run.sh dstc2 predict 的时候会报错 - data format error。\r\n\r\n原因在于你们在build DSTC2 的数据的时候build_dstc2_dataset.py 文件的line 109 和 110\r\nfw.write(u\"%s\\n\" % out.encode('utf8'))\r\nfw_asr.write(u\"%s\\n\" % out_asr.encode('utf8'))\r\n把数据的length合并成1了。读出来的时候也只有一个。。\r\n\r\n解决办法可以把 .encode('utf8') 提前。\r\nout = \"%s\\t%s\\1%s\\t%s\" % (session_id.encode('utf8'), mach.encode('utf8'), user.encode('utf8'), labels_ids)\r\nuser_asr = log_turn['input']['live']['asr-hyps'][0]['asr-hyp'].strip()\r\nout_asr = \"%s\\t%s\\1%s\\t%s\" % (session_id.encode('utf8'), mach.encode('utf8'), user_asr.encode('utf8'), labels_ids)\r\nfw.write(u\"%s\\n\" % out)\r\nfw_asr.write(u\"%s\\n\" % out_asr)\r\n\r\n我是这么处理的，可以避开这个错误。",
        "state": "closed",
        "user": "huey0528",
        "closed_by": "huey0528",
        "created_at": "2020-01-13T09:19:07+00:00",
        "updated_at": "2020-01-17T05:56:17+00:00",
        "closed_at": "2020-01-17T05:56:17+00:00",
        "comments_count": [
            "xyzhou-puck",
            "xixiaoyao",
            "huey0528",
            "wangxiao1021"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4199,
        "title": "PaddleSlim载入int8量化模型的问题",
        "body": "我从链接https://github.com/PaddlePaddle/models/blob/develop/PaddleSlim/docs/model_zoo.md下载的ResNet50的int8量化预训练模型，解压以后有三种精度的模型{float, int8, mobile}，在PaddleSlim/classification/eval.py中正确设置了int8模型路径和测试图片路径，运行以后报错，如下图所示\r\n![int8](https://user-images.githubusercontent.com/11373817/72415033-8f864500-37ae-11ea-831c-039768111d33.png)\r\n之后我把模型路径改为float，运行正常。\r\n最后我把模型路径改为mobile，又报错，如下图所示\r\n![mobile](https://user-images.githubusercontent.com/11373817/72415243-fdcb0780-37ae-11ea-8ff1-6487536dc93d.png)\r\n请问这是为什么？该如何解决？请不吝赐教",
        "state": "closed",
        "user": "AndrewZhao",
        "closed_by": "AndrewZhao",
        "created_at": "2020-01-15T07:52:40+00:00",
        "updated_at": "2020-03-12T10:04:01+00:00",
        "closed_at": "2020-03-12T10:04:01+00:00",
        "comments_count": [
            "slf12",
            "AndrewZhao",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4193,
        "title": "评估模型采用CPU方式执行报错",
        "body": "```\r\npython eval.py        --model=ResNet50        --pretrained_model=workspace/ResNet50_pretrained        --data_dir=ILSVRC/Data/CLS-LOC/        --batch_size=256 --use_gpu=False\r\n2020-01-14 17:52:27,036-INFO: -------------  Configuration Arguments -------------\r\n2020-01-14 17:52:27,036-INFO:                batch_size : 256\r\n2020-01-14 17:52:27,036-INFO:                 class_dim : 1000\r\n2020-01-14 17:52:27,036-INFO:                  data_dir : ILSVRC/Data/CLS-LOC/\r\n2020-01-14 17:52:27,036-INFO:                image_mean : [0.485, 0.456, 0.406]\r\n2020-01-14 17:52:27,036-INFO:               image_shape : [3, 224, 224]\r\n2020-01-14 17:52:27,036-INFO:                 image_std : [0.229, 0.224, 0.225]\r\n2020-01-14 17:52:27,036-INFO:             interpolation : None\r\n2020-01-14 17:52:27,036-INFO:                     model : ResNet50\r\n2020-01-14 17:52:27,036-INFO:              padding_type : SAME\r\n2020-01-14 17:52:27,036-INFO:          pretrained_model : workspace/ResNet50_pretrained\r\n2020-01-14 17:52:27,036-INFO:                print_step : 1\r\n2020-01-14 17:52:27,036-INFO:           reader_buf_size : 2048\r\n2020-01-14 17:52:27,037-INFO:             reader_thread : 8\r\n2020-01-14 17:52:27,037-INFO:         resize_short_size : 256\r\n2020-01-14 17:52:27,037-INFO:                 same_feed : 0\r\n2020-01-14 17:52:27,037-INFO:            save_json_path : None\r\n2020-01-14 17:52:27,037-INFO:                   use_gpu : 0\r\n2020-01-14 17:52:27,037-INFO:                    use_se : True\r\n2020-01-14 17:52:27,037-INFO: ----------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 199, in <module>\r\n    main()\r\n  File \"eval.py\", line 195, in main\r\n    eval(args)\r\n  File \"eval.py\", line 124, in eval\r\n    test_program).with_data_parallel(places=places)\r\nUnboundLocalError: local variable 'places' referenced before assignment\r\n```\r\n\r\n原因分析：在eval.py的代码中\r\n由于设置了use_gpu=Flase, 使得places未赋值就使用了导致失败。源码如下：\r\n```\r\n120     if args.use_gpu:\r\n121         places = fluid.framework.cuda_places()\r\n122\r\n123     compiled_program = fluid.compiler.CompiledProgram(\r\n124         test_program).with_data_parallel(places=places)\r\n```",
        "state": "open",
        "user": "hexiaoting",
        "closed_by": null,
        "created_at": "2020-01-14T08:54:54+00:00",
        "updated_at": "2020-02-07T15:10:01+00:00",
        "closed_at": null,
        "comments_count": [
            "hexiaoting",
            "shippingwang",
            "hexiaoting"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4197,
        "title": "The code for paper \"Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs\" cannot be found",
        "body": "Hello, just as is shown in the title of the issue, when I try access the repo for Paper \"Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs\", it's shown 404 not found. Is the code for that paper moved to somewhere else?",
        "state": "open",
        "user": "yana-xuyan",
        "closed_by": null,
        "created_at": "2020-01-14T15:13:11+00:00",
        "updated_at": "2021-02-06T00:17:56+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "jind11"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4210,
        "title": "models/PaddleCV/ocr_recognition的数据集问题",
        "body": "你们的效果是在示例数据上跑出来的吗",
        "state": "closed",
        "user": "XingShell",
        "closed_by": "XingShell",
        "created_at": "2020-01-17T03:26:52+00:00",
        "updated_at": "2020-01-17T04:14:17+00:00",
        "closed_at": "2020-01-17T04:14:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4208,
        "title": "PaddleMT/transformer 对海量数据的处理不友好",
        "body": "1.tensor2tensor和fairseq都是在训练前加了一个预处理，把token转id了，然后后面直接读进来就是id\r\n2. paddle这里是预处理和训练耦合在一起了，先把整个训练数据全部load进来转成id存放在内存，然后再训练；\r\n3.这个对小数量的训练集没影响，但是海量数据的时候就不友好了，需要先切片文件，然后对不同的文件重启训练，并且在训练的时候重启训练，都会重新加载全量数据",
        "state": "open",
        "user": "ganfoubudalian",
        "closed_by": null,
        "created_at": "2020-01-17T03:06:22+00:00",
        "updated_at": "2020-01-21T08:21:27+00:00",
        "closed_at": null,
        "comments_count": [
            "ganfoubudalian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4209,
        "title": "ocr模块，效果图有些疑惑",
        "body": "1.没有划分验证集合，那么是否是将测试集作为了验证集，并记录了最好的结果。而且看你们的训练错误曲线，很平滑，但是我自己的测试集合错误方差很大。\r\n2.你们的两个模型对比，训练集和验证集颜色不统一。",
        "state": "open",
        "user": "XingShell",
        "closed_by": null,
        "created_at": "2020-01-17T03:24:10+00:00",
        "updated_at": "2020-05-08T12:55:40+00:00",
        "closed_at": null,
        "comments_count": [
            "XingShell",
            "lishiyu93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4219,
        "title": "BaiduCN1.2k Model模型超参问题",
        "body": "请问：\r\nBaiduCN1.2k Model模型没有推断预测的例子，模型如何加载，它的超参是不公开的吗？\r\n那如果，该模型的训练数据不公开，模型超参不公开，那模型放出来有什么用呢？\r\n真心求问。。。",
        "state": "open",
        "user": "shenyanni",
        "closed_by": null,
        "created_at": "2020-01-20T03:59:02+00:00",
        "updated_at": "2024-02-26T05:13:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4215,
        "title": "paddle检测跑evaluate在开头会偶发SIGSEGV错误",
        "body": "paddle版本\r\nconda install --yes paddlepaddle-gpu=1.6.2=py36_gpu_cuda9.0_many_linux\r\n\r\n开始会偶发SIGSEGV错误\r\n[INFO 2020-01-1~~~~8 12:23:37,190 PID:2820 voc_eval.py:get_category_info:136] Load categories from ckpt_dir/model_best/label_list.txt\r\n2020-01-18 12:23:37,831-INFO: places would be ommited when DataLoader is not iterable\r\n[INFO 2020-01-18 12:23:37,831 PID:2820 reader.py:set_batch_generator:565] places would be ommited when DataLoader is not iterable\r\nW0118 12:23:38.818670  2820 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 9.0\r\nW0118 12:23:38.823060  2820 device_context.cc:244] device: 0, cuDNN Version: 7.3.\r\n2020-01-18 12:23:39,749-INFO: Loading parameters from ckpt_dir/model_best...\r\n[INFO 2020-01-18 12:23:39,749 PID:2820 checkpoint.py:load_params:100] Loading parameters from ckpt_dir/model_best...\r\nI0118 12:23:40.311836  2820 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\r\nI0118 12:23:40.325747  2820 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0118 12:23:40.338858  2820 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0118 12:23:40.349560  2820 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\nW0118 12:23:40.418445  2981 init.cc:206] *** Aborted at 1579321420 (unix time) try \"date -d @1579321420\" if you are using GNU date ***\r\nW0118 12:23:40.422102  2981 init.cc:206] PC: @                0x0 (unknown)\r\nW0118 12:23:40.422422  2981 init.cc:206] *** SIGSEGV (@0x5e380c) received by PID 2820 (TID 0x7fa4beb8f700) from PID 6174732; stack trace: ***\r\nW0118 12:23:40.425122  2981 init.cc:206]     @     0x7fa4f4a56390 (unknown)\r\nW0118 12:23:40.427670  2981 init.cc:206]     @     0x7fa4f46ff512 cfree\r\nW0118 12:23:40.429601  2981 init.cc:206]     @     0x7fa4a4b05fd9 (unknown)\r\nW0118 12:23:40.431500  2981 init.cc:206]     @     0x7fa4a48f6318 (unknown)\r\nW0118 12:23:40.434484  2981 init.cc:206]     @     0x7fa4f4f9bc54 _PyCFunction_FastCallDict\r\nW0118 12:23:40.437188  2981 init.cc:206]     @     0x7fa4f5023abc call_function\r\nW0118 12:23:40.440032  2981 init.cc:206]     @     0x7fa4f504675a _PyEval_EvalFrameDefault\r\nW0118 12:23:40.442719  2981 init.cc:206]     @     0x7fa4f501ce66 _PyEval_EvalCodeWithName\r\nW0118 12:23:40.445508  2981 init.cc:206]     @     0x7fa4f501e37e _PyFunction_FastCallDict\r\nW0118 12:23:40.448176  2981 init.cc:206]     @     0x7fa4f4f9c01f _PyObject_FastCallDict\r\nW0118 12:23:40.450846  2981 init.cc:206]     @     0x7fa4f4fa0aa3 _PyObject_Call_Prepend\r\nW0118 12:23:40.453565  2981 init.cc:206]     @     0x7fa4f4f9ba5e PyObject_Call\r\nW0118 12:23:40.456017  2981 init.cc:206]     @     0x7fa4f4ff5371 slot_tp_call\r\nW0118 12:23:40.458570  2981 init.cc:206]     @     0x7fa4f4f9be3b _PyObject_FastCallDict\r\nW0118 12:23:40.461006  2981 init.cc:206]     @     0x7fa4f5023c0e call_function\r\nW0118 12:23:40.463598  2981 init.cc:206]     @     0x7fa4f504675a _PyEval_EvalFrameDefault\r\nW0118 12:23:40.466158  2981 init.cc:206]     @     0x7fa4f501e2db _PyFunction_FastCallDict\r\nW0118 12:23:40.468714  2981 init.cc:206]     @     0x7fa4f4f9c01f _PyObject_FastCallDict\r\nW0118 12:23:40.471263  2981 init.cc:206]     @     0x7fa4f4fa0aa3 _PyObject_Call_Prepend\r\nW0118 12:23:40.473860  2981 init.cc:206]     @     0x7fa4f4f9ba5e PyObject_Call\r\nW0118 12:23:40.476251  2981 init.cc:206]     @     0x7fa4f4ff5371 slot_tp_call\r\nW0118 12:23:40.478822  2981 init.cc:206]     @     0x7fa4f4f9be3b _PyObject_FastCallDict\r\nW0118 12:23:40.481257  2981 init.cc:206]     @     0x7fa4f5023c0e call_function\r\nW0118 12:23:40.483852  2981 init.cc:206]     @     0x7fa4f504675a _PyEval_EvalFrameDefault\r\nW0118 12:23:40.486279  2981 init.cc:206]     @     0x7fa4f501ce66 _PyEval_EvalCodeWithName\r\nW0118 12:23:40.488840  2981 init.cc:206]     @     0x7fa4f501e37e _PyFunction_FastCallDict\r\nW0118 12:23:40.491394  2981 init.cc:206]     @     0x7fa4f4f9c01f _PyObject_FastCallDict\r\nW0118 12:23:40.493947  2981 init.cc:206]     @     0x7fa4f4fa0aa3 _PyObject_Call_Prepend\r\nW0118 12:23:40.496541  2981 init.cc:206]     @     0x7fa4f4f9ba5e PyObject_Call\r\nW0118 12:23:40.498962  2981 init.cc:206]     @     0x7fa4f508f592 partial_call\r\nW0118 12:23:40.501513  2981 init.cc:206]     @     0x7fa4f4f9be3b _PyObject_FastCallDict\r\nW0118 12:23:40.503947  2981 init.cc:206]     @     0x7fa4f5023c0e call_function\r\n#目前跑评估结束会偶发SIGABRT错误\r\n[INFO 2020-01-18 11:17:57,662 PID:10701 evaluate.py:evaluate:340] evaluate metrics is : [{'mAP(integral)': 0.06508312584639582}]\r\nW0118 11:17:57.795034 10953 init.cc:206] *** Aborted at 1579317477 (unix time) try \"date -d @1579317477\" if you are using GNU date ***\r\nW0118 11:17:57.799403 10953 init.cc:206] PC: @                0x0 (unknown)\r\nW0118 11:17:57.799712 10953 init.cc:206] *** SIGABRT (@0x29cd) received by PID 10701 (TID 0x7f4ead860700) from PID 10701; stack trace: ***\r\nW0118 11:17:57.804036 10953 init.cc:206]     @     0x7f4ed474d390 (unknown)\r\nW0118 11:17:57.808117 10953 init.cc:206]     @     0x7f4ed43a7428 gsignal\r\nW0118 11:17:57.811921 10953 init.cc:206]     @     0x7f4ed43a902a abort\r\nW0118 11:17:57.815824 10953 init.cc:206]     @     0x7f4ed43e97ea (unknown)\r\nW0118 11:17:57.819382 10953 init.cc:206]     @     0x7f4ed43e980e __libc_fatal\r\nW0118 11:17:57.822870 10953 init.cc:206]     @     0x7f4ed474c030 unwind_cleanup\r\nW0118 11:17:57.826090 10953 init.cc:206]     @     0x7f4eb94f6713 cv::Mat::create()\r\nW0118 11:17:57.829103 10953 init.cc:206]     @     0x7f4eb956bf45 cv::_OutputArray::create()\r\nW0118 11:17:57.832098 10953 init.cc:206]     @     0x7f4eb9c294de cv::resize()\r\nW0118 11:17:57.835079 10953 init.cc:206]     @     0x7f4eccdf77a4 pyopencv_cv_resize()\r\nW0118 11:17:57.838836 10953 init.cc:206]     @     0x7f4ed4c92c54 _PyCFunction_FastCallDict\r\nW0118 11:17:57.842471 10953 init.cc:206]     @     0x7f4ed4cbf690 _PyCFunction_FastCallKeywords\r\nW0118 11:17:57.845892 10953 init.cc:206]     @     0x7f4ed4d1aabc call_function\r\nW0118 11:17:57.849356 10953 init.cc:206]     @     0x7f4ed4d3e51c _PyEval_EvalFrameDefault\r\nW0118 11:17:57.852572 10953 init.cc:206]     @     0x7f4ed4d13e66 _PyEval_EvalCodeWithName\r\nW0118 11:17:57.855959 10953 init.cc:206]     @     0x7f4ed4d1537e _PyFunction_FastCallDict\r\nW0118 11:17:57.859200 10953 init.cc:206]     @     0x7f4ed4c9301f _PyObject_FastCallDict\r\nW0118 11:17:57.862426 10953 init.cc:206]     @     0x7f4ed4c97aa3 _PyObject_Call_Prepend\r\nW0118 11:17:57.865718 10953 init.cc:206]     @     0x7f4ed4c92a5e PyObject_Call\r\nW0118 11:17:57.868629 10953 init.cc:206]     @     0x7f4ed4cec371 slot_tp_call\r\nW0118 11:17:57.871692 10953 init.cc:206]     @     0x7f4ed4c92e3b _PyObject_FastCallDict\r\nW0118 11:17:57.874684 10953 init.cc:206]     @     0x7f4ed4d1ac0e call_function\r\nW0118 11:17:57.877710 10953 init.cc:206]     @     0x7f4ed4d3d75a _PyEval_EvalFrameDefault\r\nW0118 11:17:57.880630 10953 init.cc:206]     @     0x7f4ed4d152db _PyFunction_FastCallDict\r\nW0118 11:17:57.883533 10953 init.cc:206]     @     0x7f4ed4c9301f _PyObject_FastCallDict\r\nW0118 11:17:57.886440 10953 init.cc:206]     @     0x7f4ed4c97aa3 _PyObject_Call_Prepend\r\nW0118 11:17:57.889334 10953 init.cc:206]     @     0x7f4ed4c92a5e PyObject_Call\r\nW0118 11:17:57.891978 10953 init.cc:206]     @     0x7f4ed4cec371 slot_tp_call\r\nW0118 11:17:57.894749 10953 init.cc:206]     @     0x7f4ed4c92e3b _PyObject_FastCallDict\r\nW0118 11:17:57.897379 10953 init.cc:206]     @     0x7f4ed4d1ac0e call_function\r\nW0118 11:17:57.900142 10953 init.cc:206]     @     0x7f4ed4d3d75a _PyEval_EvalFrameDefault\r\nW0118 11:17:57.903038 10953 init.cc:206]     @     0x7f4ed4d13e66 _PyEval_EvalCodeWithName",
        "state": "open",
        "user": "chenqiuhui",
        "closed_by": null,
        "created_at": "2020-01-18T07:04:05+00:00",
        "updated_at": "2020-02-03T08:37:27+00:00",
        "closed_at": null,
        "comments_count": [
            "gavin1332",
            "gavin1332",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4230,
        "title": "BERT阅读理解单独做预测时不能正确加载训练模型的参数",
        "body": "使用paddle paddle的模型库中的bert模型代码及squad v2.0的数据来训练阅读理解模型是，当把do_train参数和do_predict参数都设置为true时（训练和预测一起做），预测结果是正常的。但当保存了训练模型后，把do_train设置为false，把do_predict设置为true，并使用同一份dev数据来做预测时，预测答案与问题基本上都不相关，也与同训练一起预测时的答案基本没有相同的。应该是单独做预测时没有能正确加载训练模型的参数，但看代码中也有写了加载训练模型的代码，不知道问题究竟出在哪里？\r\n",
        "state": "open",
        "user": "Chenxiuling-Amy",
        "closed_by": null,
        "created_at": "2020-01-26T15:00:38+00:00",
        "updated_at": "2020-02-04T08:51:57+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke",
            "Chenxiuling-Amy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4235,
        "title": "resnet50 训练报错",
        "body": "机器环境：linux_centos_cuda10_cudnn7_c++\r\npaddle版本：release1.6\r\n报错信息：\r\n[21:49:25]W:     [Step 1/1] Traceback (most recent call last):\r\n[21:49:25]W:     [Step 1/1]   File \"train.py\", line 293, in <module>\r\n[21:49:25]W:     [Step 1/1]     main()\r\n[21:49:25]W:     [Step 1/1]   File \"train.py\", line 289, in main\r\n[21:49:25]W:     [Step 1/1]     train(args)\r\n[21:49:25]W:     [Step 1/1]   File \"train.py\", line 216, in train\r\n[21:49:25]W:     [Step 1/1]     train_fetch_vars[0], exe)\r\n[21:49:25]W:     [Step 1/1]   File \"/paddle/models/PaddleCV/image_classification/utils/utility.py\", line 524, in best_strategy_compiled\r\n[21:49:25]W:     [Step 1/1]     build_strategy.fuse_bn_act_ops = args.fuse_bn_act_ops\r\n[21:49:25]W:     [Step 1/1] AttributeError: 'paddle.fluid.core_avx.BuildStrategy' object has no attribute 'fuse_bn_act_ops'",
        "state": "closed",
        "user": "wzzju",
        "closed_by": "wzzju",
        "created_at": "2020-02-04T03:44:11+00:00",
        "updated_at": "2020-02-04T04:25:46+00:00",
        "closed_at": "2020-02-04T04:25:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4232,
        "title": "finetune_exclude_pretrained_params参数不存在",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification\r\n做分类的时候，想要finetune imagenet模型，最后一层由于分类数量不同，所以维度不匹配，然后 --finetune_exclude_pretrained_params=fc_0.w_0,fc_0.b_0 提示这个参数不存在",
        "state": "open",
        "user": "spiced-egg",
        "closed_by": null,
        "created_at": "2020-01-31T10:17:26+00:00",
        "updated_at": "2020-02-07T15:05:37+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang",
            "dyning",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4231,
        "title": "检测识别使用随机尺寸，图片翻转。",
        "body": "       新年快乐！我在使用桨检测的时候，不知道如何在识别结果检测中使用随机尺寸，和图片翻转。我英语不好，我使用翻译翻阅了相关文档，并没有看到相关的说明。希望有人能帮我，谢谢！",
        "state": "closed",
        "user": "nhaxin204",
        "closed_by": "MRXLT",
        "created_at": "2020-01-30T14:41:47+00:00",
        "updated_at": "2020-05-22T08:42:00+00:00",
        "closed_at": "2020-05-22T08:42:00+00:00",
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4261,
        "title": "ocr_recognition识别模型训练过程中出现NaN导致无法训练",
        "body": "报错信息是：NaN or Inf found in input tensor\r\n此时的学习率已经调到0.0001，训练很慢了，但是还会出现NaN，请问该怎么处理这个问题？\r\n",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-12T00:50:24+00:00",
        "updated_at": "2020-02-13T02:28:14+00:00",
        "closed_at": "2020-02-13T02:28:14+00:00",
        "comments_count": [
            "chenwhql",
            "endy-see",
            "chenwhql",
            "endy-see",
            "dyning",
            "endy-see",
            "chenwhql",
            "endy-see",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4260,
        "title": "请问训练好的识别模型如何导出成__param__和__model__的格式",
        "body": "现在训练好的模型是一个整体，无法做c++部署",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-12T00:42:33+00:00",
        "updated_at": "2020-02-13T03:06:39+00:00",
        "closed_at": "2020-02-12T09:10:38+00:00",
        "comments_count": [
            "chenwhql",
            "chenwhql",
            "endy-see",
            "chenwhql",
            "endy-see",
            "chenwhql",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4262,
        "title": "transformer  中 inference_model.py产出的模型应该怎样调用呢？有没有示例脚本",
        "body": "如题，辛苦帮忙看下~",
        "state": "open",
        "user": "wwjjy",
        "closed_by": null,
        "created_at": "2020-02-12T11:57:08+00:00",
        "updated_at": "2024-02-26T05:13:03+00:00",
        "closed_at": null,
        "comments_count": [
            "chenwhql",
            "wwjjy",
            "chenwhql",
            "wwjjy",
            "chenwhql",
            "wwjjy",
            "guoshengCS",
            "wwjjy",
            "chenwhql",
            "hong19860320"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4263,
        "title": "paddle训练反向传播报错 IndexError: _Map_base::at",
        "body": "`\r\n\r\n    # define network\r\n    inputs, labels = init_inputs(args, pad_num)\r\n    # conv feature\r\n    block_feats = get_base_features(inputs['node_images'])\r\n    # node feats\r\n    roi_feats = get_roi_features(block_feats, inputs['node_roi'])\r\n    # node mask\r\n    roi_feats, mask = lodtensor_to_tensor_with_mask(roi_feats, pad_num)\r\n    node_mask, edge_mask = get_padding_mask(mask, pad_num)\r\n    # relation loss\r\n    feats = get_graph_features(roi_feats,\r\n            inputs['node_shape'], inputs['edge_shape'],\r\n            node_mask, edge_mask, pad_num)\r\n    node_out, edge_out = graph_net(feats['node_feats'], feats['edge_feats'],\r\n            feats['edge_shape_feats'], node_mask, edge_mask, pad_num)\r\n    node_label = fluid.layers.cast(x=labels['node_label'], dtype='int64')\r\n    node_loss = fluid.layers.softmax_with_cross_entropy(node_out, node_label)\r\n    node_loss = fluid.layers.reduce_sum(node_loss * node_mask)\r\n\r\n    edge_label = fluid.layers.unsqueeze(labels['edge_label'], axes=[3])\r\n    fg_num = fluid.layers.reduce_sum(edge_label, dim=[1, 2, 3])\r\n    edge_label = fluid.layers.cast(x=edge_label, dtype='float32')\r\n    edge_loss = fluid.layers.sigmoid_focal_loss(edge_out, edge_label, fg_num, gamma=2.0, alpha=0.25)\r\n    edge_loss = fluid.layers.reduce_sum(edge_loss * edge_mask)\r\n\r\n    cost = node_loss + edge_loss * args.lamb\r\n\r\n    # evaluate\r\n    node_index = fluid.layers.argmax(node_out, axis=2)\r\n    node_index = fluid.layers.cast(node_index, dtype='int32')\r\n    edge_score = fluid.layers.sigmoid(edge_out)\r\n\r\n    fetch_vars = [node_loss, edge_loss, node_index,\r\n                  edge_score, node_mask, edge_mask]\r\n\r\n    inference_program = fluid.default_main_program().clone(for_test=True)\r\n    if args.learning_rate_decay == \"piecewise_decay\":\r\n        learning_rate = fluid.layers.piecewise_decay([\r\n            args.total_step // 4, args.total_step // 4 * 3\r\n        ], [args.lr, args.lr * 0.1, args.lr * 0.01])\r\n    else:\r\n        learning_rate = lr\r\n\r\n    optimizer = fluid.optimizer.Adam(learning_rate=learning_rate)\r\n    _, params_grads = optimizer.minimize(cost)`\r\n\r\n实现了一个lod_tensor加padding转成tensor的函数如下：\r\n![image](https://user-images.githubusercontent.com/3764907/74337554-77203f00-4ddb-11ea-8d81-08e5ce8ebd7e.png)\r\n\r\n报错\r\n> \r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"model/train.py\", line 262, in <module>\r\n    main()\r\n  File \"model/train.py\", line 258, in main\r\n    train(args)\r\n  File \"model/train.py\", line 119, in train\r\n    _, params_grads = optimizer.minimize(cost)\r\n  File \"</home/liyulin/anaconda2/lib/python2.7/site-packages/decorator.pyc:decorator-gen-20>\", line 2, in minimize\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/base.py\", line 87, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/optimizer.py\", line 609, in minimize\r\n    no_grad_set=no_grad_set)\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/optimizer.py\", line 494, in backward\r\n    no_grad_set, callbacks)\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/backward.py\", line 706, in append_backward\r\n    _append_backward_vars_(root_block, fwd_op_num, grad_to_var, grad_info_map)\r\n  File \"/home/liyulin/anaconda2/lib/python2.7/site-packages/paddle/fluid/backward.py\", line 518, in _append_backward_vars_\r\n    op_desc.infer_shape(block.desc)\r\nIndexError: _Map_base::at\r\n> ",
        "state": "closed",
        "user": "linan142857",
        "closed_by": "linan142857",
        "created_at": "2020-02-12T12:43:59+00:00",
        "updated_at": "2020-02-14T03:05:58+00:00",
        "closed_at": "2020-02-14T03:05:58+00:00",
        "comments_count": [
            "chenwhql",
            "linan142857"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4268,
        "title": "aistudio上运行PaddleNLP-sentiment_classification，训练sh run.sh train 报错",
        "body": "paddle-gpu版本为aistudio默认安装版本\r\n\r\npaddlehub 1.0.0 \r\npaddlepaddle-gpu 1.4.1.post97\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"run_classifier.py\", line 327, in <module>\r\n    main(args)\r\n  File \"run_classifier.py\", line 157, in main\r\n    shuffle=True)\r\n  File \"/home/aistudio/work/models-develop/PaddleNLP/sentiment_classification/reader.py\", line 75, in data_generator\r\n    return fluid.io.batch(self.get_train_examples(self.data_dir, epoch, self.max_seq_len), batch_size)\r\nAttributeError: module 'paddle.fluid.io' has no attribute 'batch'\r\n\r\n\r\n\r\n是需要升级paddlepaddle版本么",
        "state": "closed",
        "user": "casolxia",
        "closed_by": "casolxia",
        "created_at": "2020-02-13T09:04:58+00:00",
        "updated_at": "2020-02-14T04:32:42+00:00",
        "closed_at": "2020-02-14T04:32:42+00:00",
        "comments_count": [
            "casolxia",
            "zhupengyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4299,
        "title": "evaluate PyramidBox_WiderFace error",
        "body": "python widerface_eval.py --infer=True --confs_threshold=0.15 --model_di\r\nr=./models/PyramidBox_WiderFace --image_path=./test_img/0001.png, 提示Error: Cannot open file models/PyramidBox_WiderFace/conv2d_61.w_0 for load op at (/paddle/paddle/fluid/operators/load_op.h:37)\r\n  [operator < load > error]\r\n，请问这是什么原因造成的？",
        "state": "open",
        "user": "gtfaiwxm",
        "closed_by": null,
        "created_at": "2020-02-17T07:25:14+00:00",
        "updated_at": "2024-02-26T05:13:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4272,
        "title": "请问如何debug官网上c++部署的demo？",
        "body": "官网c++部署部分的地址（包含demo）：https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_usage/deploy/inference/native_infer.html\r\n我这边已经备好了paddle的部署环境，也能跑通官方的demo（mobilenetv1那个），现在有个问题，就是我对c++代码不是很熟悉，修改一下就时常导致崩溃，有时候也看不到问题原因，这时希望能看一下在执行sh run.sh过程中的debug情况，网上看了一下说用gdb可以实现debug，但是看到的例子都是直接debug cpp文件，没有debug bash脚本的，所以想问一下怎么debug sh run.sh的过程?",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-13T10:27:25+00:00",
        "updated_at": "2020-02-14T08:16:49+00:00",
        "closed_at": "2020-02-14T08:16:48+00:00",
        "comments_count": [
            "zhupengyang",
            "endy-see",
            "zhupengyang",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4307,
        "title": "口罩识别模型视频检测速度慢",
        "body": "在mac上，用opencv读视频流数据，并用pyramidbox_lite_server_mask 检测是否佩戴口罩，模型推理速度慢，应该怎么加速？",
        "state": "open",
        "user": "yiershanxll",
        "closed_by": null,
        "created_at": "2020-02-18T05:10:47+00:00",
        "updated_at": "2024-02-26T05:13:00+00:00",
        "closed_at": null,
        "comments_count": [
            "yiicy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4303,
        "title": "ocr识别模型部署时遇到ShapeError",
        "body": "具体错误如下：\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: The number of input channels should be equal to filter channels * groups. But received: the input channels is [3], the shapeof input is [1, 3, 48, 86], the filter channel is [1], the shape of filter is [16, 1, 3, 3],the groups is [1]\r\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:3 != filter_dims[1] * groups:1.] at (/home/install/Paddle/paddle/fluid/operators/conv_op.cc:94)\r\n  [operator < conv2d_fusion > error]\r\nrun_impl.sh: line 28: 32112 Aborted                 (core dumped) ./${DEMO_NAME}\r\n[root@8d7415071953 infer_ocr]#\r\n请问识别模型部署的时候有什么需要注意的么？",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-17T13:48:04+00:00",
        "updated_at": "2020-02-19T02:18:06+00:00",
        "closed_at": "2020-02-19T02:18:06+00:00",
        "comments_count": [
            "wanghaoshuang",
            "endy-see",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4312,
        "title": "ocr识别模型部署时遇到Error: The width of each timestep in Input(Label) should be 1.",
        "body": "具体错误信息如下：\r\n\r\n--- Running analysis [ir_graph_build_pass]\r\n--- Running analysis [ir_graph_clean_pass]\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [is_test_pass]\r\n--- Running IR pass [simplify_with_basic_ops_pass]\r\n--- Running IR pass [conv_affine_channel_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_affine_channel_fuse_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\nI0218 13:31:01.658505 36056 graph_pattern_detector.cc:96] ---  detected 8 subgraphs\r\n--- Running IR pass [multihead_matmul_fuse_pass]\r\n--- Running IR pass [fc_fuse_pass]\r\nI0218 13:31:01.665282 36056 graph_pattern_detector.cc:96] ---  detected 2 subgraphs\r\n--- Running IR pass [fc_elementwise_layernorm_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_act_fuse_pass]\r\nI0218 13:31:01.667009 36056 graph_pattern_detector.cc:96] ---  detected 8 subgraphs\r\n--- Running IR pass [conv_elementwise_add2_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_fuse_pass]\r\n--- Running IR pass [transpose_flatten_concat_fuse_pass]\r\n--- Running IR pass [runtime_context_cache_pass]\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\nI0218 13:31:01.671290 36056 ir_params_sync_among_devices_pass.cc:41] Sync params from CPU to GPU\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [memory_optimize_pass]\r\nI0218 13:31:01.678493 36056 memory_optimize_pass.cc:223] Cluster name : gru_0.tmp_0  size: 800\r\nI0218 13:31:01.678519 36056 memory_optimize_pass.cc:223] Cluster name : gru_0.tmp_2  size: 800\r\nI0218 13:31:01.678534 36056 memory_optimize_pass.cc:223] Cluster name : batch_norm_3.tmp_3  size: 3072\r\nI0218 13:31:01.678550 36056 memory_optimize_pass.cc:223] Cluster name : batch_norm_1.tmp_3  size: 3072\r\nI0218 13:31:01.678565 36056 memory_optimize_pass.cc:223] Cluster name : pixel  size: 192\r\nI0218 13:31:01.678618 36056 memory_optimize_pass.cc:223] Cluster name : fc_0.tmp_1  size: 2400\r\nI0218 13:31:01.678634 36056 memory_optimize_pass.cc:223] Cluster name : gru_0.tmp_3  size: 800\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI0218 13:31:01.685699 36056 analysis_predictor.cc:470] ======= optimize end =======\r\nI0218 13:31:01.685760 36056 naive_executor.cc:105] ---  skip [feed], feed -> pixel\r\nI0218 13:31:01.686285 36056 naive_executor.cc:105] ---  skip [gru_0.tmp_2], fetch -> fetch\r\nI0218 13:31:01.686311 36056 naive_executor.cc:105] ---  skip [fc_0.tmp_1], fetch -> fetch\r\nI0218 13:31:01.686329 36056 naive_executor.cc:105] ---  skip [batch_norm_1.tmp_3], fetch -> fetch\r\nW0218 13:31:01.996632 36056 device_context.cc:236] Please NOTE: device: 1, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 9.0\r\nW0218 13:31:02.002913 36056 device_context.cc:244] device: 1, cuDNN Version: 7.6.\r\nterminate called after throwing an instance of 'paddle::platform::EnforceNotMet'\r\n  what():\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > paddle::platform::GetTraceBackString<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*, int)\r\n2   paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::NaiveExecutor::Run()\r\n8   paddle::AnalysisPredictor::ZeroCopyRun()\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2459, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 7526, in warpctc\r\n    'norm_by_times': norm_by_times,\r\n  File \"/data/xxx/projects/models-1.6/models/PaddleCV/ocr_recognition/crnn_ctc_model.py\", line 202, in ctc_train_net\r\n    input=fc_out, label=label, blank=num_classes, norm_by_times=True)\r\n  File \"train.py\", line 84, in train\r\n    args, data_shape, num_classes)\r\n  File \"train.py\", line 254, in main\r\n    train(args)\r\n  File \"train.py\", line 258, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: The width of each timestep in Input(Label) should be 1.\r\n  [Hint: Expected label_dims[0] == label->numel(), but received label_dims[0]:48 != label->numel():9600.] at (/home/install/Paddle/paddle/fluid/operators/warpctc_op.h:170)\r\n  [operator < warpctc > error]\r\nrun_impl.sh: line 28: 36056 Aborted                 (core dumped) ./${DEMO_NAME}",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-19T02:24:31+00:00",
        "updated_at": "2020-02-19T07:04:50+00:00",
        "closed_at": "2020-02-19T07:03:54+00:00",
        "comments_count": [
            "wanghaoshuang",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4309,
        "title": "异步读取数据格式要求",
        "body": "把1.5版本sentiment_classification更改为其他文本分类过程，运行没出错，但是出现训练轮数只能1，其他调试不了。可能异步读取数据有误导致，所以想详细知道数据格式要求是怎么样滴？",
        "state": "open",
        "user": "gekelly",
        "closed_by": null,
        "created_at": "2020-02-18T07:31:52+00:00",
        "updated_at": "2024-02-26T05:12:59+00:00",
        "closed_at": null,
        "comments_count": [
            "yiicy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4313,
        "title": "ocr识别模型保存inference model时遇到类型不匹配的问题",
        "body": "将训练好的模型在infer.py中加载，并用infer net保存inference model时出错，保存的代码如下：\r\nfluid.io.save_inference_model(args.save_model_dir+filename, feeded_var_names=['pixel'], target_vars=[ids], executor=exe, main_program=inference_program, params_filename=\"__params__\")\r\n其中inference_program是在inference model load时候生成的。\r\n报错如下：\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 194, in <module>\r\n    main()\r\n  File \"infer.py\", line 190, in main\r\n    inference(args)\r\n  File \"infer.py\", line 156, in inference\r\n    if args.save_inference_model:\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1141, in save_inference_model\r\n    var, 1., name=\"save_infer_model/scale_{}\".format(i))\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 14031, in scale\r\n    name=name, dtype=x.dtype, persistable=False)\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\", line 355, in create_variable\r\n    return self.main_program.current_block().create_var(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2301, in create_var\r\n    var = Variable(block=self, *args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 684, in __init__\r\n    \"matched.\".format(self.name, old_dtype, dtype))\r\nValueError: Variable save_infer_model/scale_0 has been created before. The previous data type is VarType.FP32; the new data type is VarType.INT64. They are not matched.\r\n",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-02-19T07:08:20+00:00",
        "updated_at": "2020-02-19T08:24:53+00:00",
        "closed_at": "2020-02-19T08:24:53+00:00",
        "comments_count": [
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4321,
        "title": "请问如何将使用fluid.io.save_inference_model保存的模型转换成deeplabv3+中group norm的模型格式",
        "body": null,
        "state": "open",
        "user": "ecko4869",
        "closed_by": null,
        "created_at": "2020-02-20T09:25:41+00:00",
        "updated_at": "2024-02-26T05:12:58+00:00",
        "closed_at": null,
        "comments_count": [
            "DannyIsFunny"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4325,
        "title": "字典干预时出现错误",
        "body": "## 用户词典:\r\n&emsp;货币资金        n       100000000\r\n&emsp;年末    TIME    13601\r\n&emsp;货币资金年末额  n       10000000000000000\r\n## 测试代码\r\n### test_interventer.py\r\n&emsp;from Interventer import Query, Interventer  \r\n&emsp;query = Query({'word': ['货币', '资金', '年末额'], 'tag': ['n', 'n', 'n']})  \r\n&emsp;i = Interventer(\"unigram.dict\", \"user.dict\")  \r\n&emsp;result = i.run(query)  \r\n&emsp;print(result)  \r\n### Interventer.py为lac目录下62730a1a1357db5e1964cf3209c030ed.py\r\n## 解决方法\r\n![image](https://user-images.githubusercontent.com/45001329/74937967-1bcbfd80-5428-11ea-89be-f07fa0c6f476.png)\r\n\r\n     测试后，成功解决该bug",
        "state": "open",
        "user": "luzm3",
        "closed_by": null,
        "created_at": "2020-02-20T13:30:01+00:00",
        "updated_at": "2024-02-26T05:12:56+00:00",
        "closed_at": null,
        "comments_count": [
            "DannyIsFunny",
            "luzm3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4330,
        "title": "models/PaddleNLP/emotion_detection/ 部署",
        "body": "这个如何部署呢，因为有中文语句的输入，部署的参数设置代码应该怎么编写呢？另外，该推断模型应该要用到vocab.txt的，但部署这里应该怎么设置呢？希望得到解答",
        "state": "open",
        "user": "lixuan1",
        "closed_by": null,
        "created_at": "2020-02-21T12:45:35+00:00",
        "updated_at": "2020-02-24T09:36:39+00:00",
        "closed_at": null,
        "comments_count": [
            "jiweibo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4331,
        "title": "关于models/PaddleCv/imagessification 预加载BUG",
        "body": "使用了预加载模型，用Finetune时，后面的那个参数finetune_exclude_pretrained_params识别不了，如下图BUG\r\n\r\n![image](https://user-images.githubusercontent.com/38208463/75046786-b4ce4780-5500-11ea-826a-7a1920863ca7.png)\r\n",
        "state": "open",
        "user": "muzhen1108",
        "closed_by": null,
        "created_at": "2020-02-21T15:19:25+00:00",
        "updated_at": "2020-04-12T17:57:09+00:00",
        "closed_at": null,
        "comments_count": [
            "jiweibo",
            "muzhen1108",
            "jiweibo",
            "edencfc",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4333,
        "title": "关于物品冷启动推荐的问题（PaddleRec, DIN/SSR）",
        "body": "作者你们好，在使用DIN、SSR模型的时候，发现infer都是面向有进入到embedding层字典里面的item的，那么如果推荐系统中新上item，使用这两款模型应该怎么实现推荐呢？\r\n\r\n还望不吝赐教~",
        "state": "closed",
        "user": "stevenkwong",
        "closed_by": "frankwhzhang",
        "created_at": "2020-02-24T02:04:05+00:00",
        "updated_at": "2020-03-16T05:37:30+00:00",
        "closed_at": "2020-03-16T05:37:30+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4340,
        "title": "ocr_recognition识别模型训练时不能用百度提供的预训练模型",
        "body": "我的模型NUM_CLASS是3840, 用attention_ctc，加载前我将fc层stop_gradient 想finetune确总是会报错，You are not allowed to load partial data via load_combine_op, use load_op \r\n",
        "state": "closed",
        "user": "cisco08",
        "closed_by": "LDOUBLEV",
        "created_at": "2020-02-25T08:16:20+00:00",
        "updated_at": "2020-03-03T04:27:47+00:00",
        "closed_at": "2020-03-03T04:27:47+00:00",
        "comments_count": [
            "LDOUBLEV"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4341,
        "title": "LogWriter突然不出图了",
        "body": "![image](https://user-images.githubusercontent.com/8415114/75229278-92804680-57ec-11ea-86b0-72dabdd1d1a6.png)\r\n",
        "state": "closed",
        "user": "cisco08",
        "closed_by": "juncaipeng",
        "created_at": "2020-02-25T08:33:53+00:00",
        "updated_at": "2020-03-02T04:43:00+00:00",
        "closed_at": "2020-03-02T04:43:00+00:00",
        "comments_count": [
            "cisco08",
            "juncaipeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4347,
        "title": "models/dygraph/lac/   RuntimeError",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/dygraph/lac\r\n`sh eval.sh`\r\n`sh predict.sh`\r\n\r\n`RuntimeError: Parameter file [ ./padding_models/step_120000.pdparams ] not exists`\r\n\r\ndownloads.py 里没有发布对应的动态图版本的lac模型\r\n直接指向静态图版本的lac模型也无法读取",
        "state": "open",
        "user": "lxgend",
        "closed_by": null,
        "created_at": "2020-02-26T11:46:39+00:00",
        "updated_at": "2024-02-26T05:12:53+00:00",
        "closed_at": null,
        "comments_count": [
            "songyouwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4348,
        "title": "LAC字典干预",
        "body": "hi，我在使用lac使用词典干预的时候，比如货币资金和资金这种包含关系，经常分不好，请问你们有什么比较好的使用技巧么",
        "state": "closed",
        "user": "luzm3",
        "closed_by": "luzm3",
        "created_at": "2020-02-26T13:11:29+00:00",
        "updated_at": "2020-03-08T01:40:22+00:00",
        "closed_at": "2020-03-08T01:40:21+00:00",
        "comments_count": [
            "Bond-H",
            "luzm3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4349,
        "title": "macOS python2.7.15 安装paddlepaddle1.7.0 失败！",
        "body": "本机环境：\r\n系统版本：mac OS 10.12.6\r\ncpu：Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\r\n\r\n在使用命令\r\npython -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\r\n安装完paddlepaddle1.7.0之后\r\nimport paddle.fluid as fluid\r\n报错信息如下：\r\nIllegal instruction: 4\r\n看了很多人说是CPU不支持AVX2.0造成的，查了下本机的CPU只支持AVX1.0，但是官网貌似没有提供给MAC版本的no-avx版本的安装包。\r\n请问这种情况怎么处理呢？",
        "state": "open",
        "user": "achiver781168307",
        "closed_by": null,
        "created_at": "2020-02-27T01:44:27+00:00",
        "updated_at": "2020-03-02T09:10:21+00:00",
        "closed_at": null,
        "comments_count": [
            "JepsonWong",
            "achiver781168307",
            "JepsonWong",
            "achiver781168307",
            "achiver781168307",
            "achiver781168307",
            "DDDivano"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4353,
        "title": "用paddle视频分类模型进行finetune开发报错。",
        "body": "用paddle视频分类的TSN模型进行finetune开发。下载了Paddle提供的Model Zoo里已发布模型，通过--resume指定权重存放路径。使用的命令行为：\r\npython train.py --model_name=TSN --config=./configs/tsn.yaml --log_interval=10 --valid_interval=1 --use_gpu=True --save_dir='./checkpoints' --fix_random_seed=False --resume='./TSN_final.pdparams' \r\n\r\n报如下错误：（改成TSM模型、STNET模型等，一直报如下错误。之前用paddle1.6.3也是报错，现在升级到1.7.0还是报如下错误。同样的模型，用eval和predict不会报错，是我的用法有问题吗？）\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"d:/paddle/PaddleVideo/train.py\", line 265, in <module>\r\n    train(args)\r\n  File \"d:/paddle/PaddleVideo/train.py\", line 172, in train\r\n    exe, '', main_program=train_prog, filename=args.resume)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 917, in load_persistables\r\n    filename=filename)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 742, in load_vars\r\n    filename=filename)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 794, in load_vars\r\n    executor.run(load_prog)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\", line 693, in reraise\r\n    raise value\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 831, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 905, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\nWindows not support stack backtrace yet.\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 792, in load_vars\r\n    'model_from_memory': vars_from_memory\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 742, in load_vars\r\n    filename=filename)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\io.py\", line 917, in load_persistables\r\n    filename=filename)\r\n  File \"d:/paddle/PaddleVideo/train.py\", line 172, in train\r\n    exe, '', main_program=train_prog, filename=args.resume)\r\n  File \"d:/paddle/PaddleVideo/train.py\", line 265, in <module>\r\n    train(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Cannot parse tensor desc\r\n  [Hint: Expected desc.ParseFromArray(buf.get(), size) == true, but received desc.ParseFromArray(buf.get(), size):0 != true:1.] at (D:/1.7.0/paddle/paddle/fluid/framework/.tensor_util.cu:527)\r\n  [operator < load_combine > error]",
        "state": "closed",
        "user": "davidwhite-www",
        "closed_by": "davidwhite-www",
        "created_at": "2020-02-27T06:02:25+00:00",
        "updated_at": "2020-02-27T14:09:57+00:00",
        "closed_at": "2020-02-27T14:09:57+00:00",
        "comments_count": [
            "SunGaofeng",
            "davidwhite-www",
            "davidwhite-www"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4355,
        "title": "图片分类出错了",
        "body": "![image](https://user-images.githubusercontent.com/27176468/75430075-c0e55980-5985-11ea-938c-6dc80599ebbb.png)\r\n",
        "state": "open",
        "user": "Airyzf",
        "closed_by": null,
        "created_at": "2020-02-27T09:23:12+00:00",
        "updated_at": "2020-03-19T09:17:54+00:00",
        "closed_at": null,
        "comments_count": [
            "JepsonWong",
            "Qzgfather"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4356,
        "title": "ocr 识别的那个没有dict_map，预测的时候不知道是什么文字呀",
        "body": "ocr 识别的那个没有dict_map，预测的时候不知道是什么文字呀",
        "state": "open",
        "user": "cisco08",
        "closed_by": null,
        "created_at": "2020-02-27T12:42:13+00:00",
        "updated_at": "2020-05-09T00:36:35+00:00",
        "closed_at": null,
        "comments_count": [
            "JepsonWong",
            "lishiyu93",
            "lishiyu93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4358,
        "title": "用TSN视频分类模型进行finetune时的问题",
        "body": "我想利用paddle提供的已经训练好的TSN等视频模型，对自己的数据集进行finetune并分类。\r\n有两个个问题：\r\n1、在执行train.py时，能否冻结预训练模型的部分或全部卷积层，只训练剩下的卷积层和自己定制的全连接层。\r\n2、在执行predict.py时，如何获得预训练模型的某一层的输出，或者获得输出层的特征向量。",
        "state": "closed",
        "user": "davidwhite-www",
        "closed_by": "huangjun12",
        "created_at": "2020-02-28T03:22:41+00:00",
        "updated_at": "2020-04-15T03:01:50+00:00",
        "closed_at": "2020-04-15T03:01:50+00:00",
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4361,
        "title": "exe.run(startup_prog) show errors in   train.py  PaddleCv/face_detection",
        "body": "### i debug it show erros in line code: exe.run(startup_prog)\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport shutil\r\nimport numpy as np\r\nimport time\r\nimport argparse\r\nimport functools\r\n\r\n\r\ndef set_paddle_flags(**kwargs):\r\n    for key, value in kwargs.items():\r\n        if os.environ.get(key, None) is None:\r\n            os.environ[key] = str(value)\r\n\r\n\r\n# NOTE(paddle-dev): All of these flags should be\r\n# set before `import paddle`. Otherwise, it would\r\n# not take any effect. \r\nset_paddle_flags(\r\n    FLAGS_eager_delete_tensor_gb=0,  # enable GC to save memory\r\n)\r\n\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nfrom pyramidbox import PyramidBox\r\nimport reader\r\nfrom utility import add_arguments, print_arguments, check_cuda\r\n\r\nparser = argparse.ArgumentParser(description=__doc__)\r\nadd_arg = functools.partial(add_arguments, argparser=parser)\r\n\r\n# yapf: disable\r\nadd_arg('parallel',         bool,  True,            \"Whether use multi-GPU/threads or not.\")\r\nadd_arg('learning_rate',    float, 0.001,           \"The start learning rate.\")\r\nadd_arg('batch_size',       int,   16,              \"Minibatch size.\")\r\nadd_arg('epoc_num',         int,   160,             \"Epoch number.\")\r\nadd_arg('use_gpu',          bool,  True,            \"Whether use GPU.\")\r\nadd_arg('use_pyramidbox',   bool,  True,            \"Whether use PyramidBox model.\")\r\nadd_arg('model_save_dir',   str,   'output',        \"The path to save model.\")\r\nadd_arg('resize_h',         int,   640,             \"The resized image height.\")\r\nadd_arg('resize_w',         int,   640,             \"The resized image width.\")\r\nadd_arg('mean_BGR',         str,   '104., 117., 123.', \"Mean value for B,G,R channel which will be subtracted.\")\r\nadd_arg('pretrained_model', str,   './vgg_ilsvrc_16_fc_reduced/', \"The init model path.\")\r\nadd_arg('data_dir',         str,   'data',          \"The base dir of dataset\")\r\nadd_arg('use_multiprocess', bool,  False,            \"Whether use multi-process for data preprocessing.\")\r\nparser.add_argument('--enable_ce', action='store_true', help='If set, run the task with continuous evaluation logs.')\r\nparser.add_argument('--batch_num', type=int, help=\"batch num for ce\")\r\nparser.add_argument('--num_devices', type=int, default=1, help='Number of GPU devices')\r\n#yapf: enable\r\n\r\ntrain_parameters = {\r\n    \"train_images\": 12880,\r\n    \"image_shape\": [3, 640, 640],\r\n    \"class_num\": 2,\r\n    \"batch_size\": 16,\r\n    \"lr\": 0.001,\r\n    \"lr_epochs\": [99, 124, 149],\r\n    \"lr_decay\": [1, 0.1, 0.01, 0.001],\r\n    \"epoc_num\": 160,\r\n    \"optimizer_method\": \"momentum\",\r\n    \"use_pyramidbox\": True\r\n}\r\n\r\ndef optimizer_setting(train_params):\r\n    batch_size = train_params[\"batch_size\"]\r\n    iters = train_params[\"train_images\"] // batch_size\r\n    lr = train_params[\"lr\"]\r\n    optimizer_method = train_params[\"optimizer_method\"]\r\n    boundaries = [i * iters for i in train_params[\"lr_epochs\"]]\r\n    values = [i * lr for i in train_params[\"lr_decay\"]]\r\n\r\n    if optimizer_method == \"momentum\":\r\n        optimizer = fluid.optimizer.Momentum(\r\n            learning_rate=fluid.layers.piecewise_decay(boundaries, values),\r\n            momentum=0.9,\r\n            regularization=fluid.regularizer.L2Decay(0.0005),\r\n        )\r\n    else:\r\n        optimizer = fluid.optimizer.RMSProp(\r\n            learning_rate=fluid.layers.piecewise_decay(boundaries, values),\r\n            regularization=fluid.regularizer.L2Decay(0.0005),\r\n        )\r\n    return optimizer\r\n\r\n\r\ndef build_program(train_params, main_prog, startup_prog, args):\r\n    use_pyramidbox = train_params[\"use_pyramidbox\"]\r\n    image_shape = train_params[\"image_shape\"]\r\n    class_num = train_params[\"class_num\"]\r\n    with fluid.program_guard(main_prog, startup_prog):\r\n        py_reader = fluid.layers.py_reader(\r\n            capacity=8,\r\n            shapes=[[-1] + image_shape, [-1, 4], [-1, 4], [-1, 1]],\r\n            lod_levels=[0, 1, 1, 1],\r\n            dtypes=[\"float32\", \"float32\", \"float32\", \"int32\"],\r\n            use_double_buffer=True)\r\n        with fluid.unique_name.guard():\r\n            image, face_box, head_box, gt_label = fluid.layers.read_file(py_reader)\r\n            fetches = []\r\n            network = PyramidBox(image=image,\r\n                                 face_box=face_box,\r\n                                 head_box=head_box,\r\n                                 gt_label=gt_label,\r\n                                 sub_network=use_pyramidbox)\r\n            if use_pyramidbox:\r\n                face_loss, head_loss, loss = network.train()\r\n                fetches = [face_loss, head_loss]\r\n            else:\r\n                loss = network.vgg_ssd_loss()\r\n                fetches = [loss]\r\n            optimizer = optimizer_setting(train_params)\r\n            optimizer.minimize(loss)\r\n    return py_reader, fetches, loss\r\n\r\ndef train(args, config, train_params, train_file_list):\r\n    batch_size = train_params[\"batch_size\"]\r\n    epoc_num = train_params[\"epoc_num\"]\r\n    optimizer_method = train_params[\"optimizer_method\"]\r\n    use_pyramidbox = train_params[\"use_pyramidbox\"]\r\n\r\n    use_gpu = args.use_gpu\r\n    model_save_dir = args.model_save_dir\r\n    pretrained_model = args.pretrained_model\r\n\r\n    devices = os.getenv(\"CUDA_VISIBLE_DEVICES\") or \"\"\r\n    devices_num = len(devices.split(\",\"))\r\n    batch_size_per_device = batch_size // devices_num\r\n    iters_per_epoc = train_params[\"train_images\"] // batch_size\r\n    num_workers = 8\r\n    is_shuffle = True\r\n\r\n    startup_prog = fluid.Program()\r\n    train_prog = fluid.Program()\r\n\r\n    #only for ce\r\n    if args.enable_ce:\r\n        is_shuffle = False\r\n        SEED = 102\r\n        startup_prog.random_seed = SEED\r\n        train_prog.random_seed = SEED\r\n        num_workers = 1\r\n        pretrained_model = \"\"\r\n        if args.batch_num != None:\r\n            iters_per_epoc = args.batch_num\r\n\r\n    train_py_reader, fetches, loss = build_program(\r\n        train_params = train_params,\r\n        main_prog = train_prog,\r\n        startup_prog = startup_prog,\r\n        args=args)\r\n\r\n    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\r\n    print(place)\r\n    exe = fluid.Executor(place)\r\n    exe.run(startup_prog)  <---------------- here ---------------------\r\n    start_epoc = 0\r\n    if pretrained_model:\r\n        if pretrained_model.isdigit():\r\n            start_epoc = int(pretrained_model) + 1\r\n            pretrained_model = os.path.join(model_save_dir, pretrained_model)\r\n            print(\"Resume from %s \" %(pretrained_model))\r\n\r\n        if not os.path.exists(pretrained_model):\r\n            raise ValueError(\"The pre-trained model path [%s] does not exist.\" %\r\n                             (pretrained_model))\r\n        def if_exist(var):\r\n            return os.path.exists(os.path.join(pretrained_model, var.name))\r\n        fluid.io.load_vars(\r\n            exe, pretrained_model, main_program=train_prog, predicate=if_exist)\r\n    train_reader = reader.train(config,\r\n                                train_file_list,\r\n                                batch_size_per_device,\r\n                                shuffle = is_shuffle,\r\n                                use_multiprocess=args.use_multiprocess,\r\n                                num_workers=num_workers)\r\n    train_py_reader.decorate_paddle_reader(train_reader)\r\n\r\n    if args.parallel:\r\n        train_exe = fluid.ParallelExecutor(\r\n            main_program = train_prog,\r\n            use_cuda=use_gpu,\r\n            loss_name=loss.name)\r\n\r\n    def save_model(postfix, program):\r\n        model_path = os.path.join(model_save_dir, postfix)\r\n        if os.path.isdir(model_path):\r\n            shutil.rmtree(model_path)\r\n\r\n        print('save models to %s' % (model_path))\r\n        fluid.io.save_persistables(exe, model_path, main_program=program)\r\n\r\n    total_time = 0.0\r\n    epoch_idx = 0\r\n    face_loss = 0\r\n    head_loss = 0\r\n    for pass_id in range(start_epoc, epoc_num):\r\n        epoch_idx += 1\r\n        start_time = time.time()\r\n        prev_start_time = start_time\r\n        end_time = 0\r\n        batch_id = 0\r\n        train_py_reader.start()\r\n        while True:\r\n            try:\r\n                prev_start_time = start_time\r\n                start_time = time.time()\r\n                if args.parallel:\r\n                    fetch_vars = train_exe.run(fetch_list=\r\n                        [v.name for v in fetches])\r\n                else:\r\n                    fetch_vars = exe.run(train_prog, fetch_list=fetches)\r\n                end_time = time.time()\r\n                fetch_vars = [np.mean(np.array(v)) for v in fetch_vars]\r\n                face_loss = fetch_vars[0]\r\n                head_loss = fetch_vars[1]\r\n                if batch_id % 10 == 0:\r\n                    if not args.use_pyramidbox:\r\n                        print(\"Pass {:d}, batch {:d}, loss {:.6f}, time {:.5f}\".format(\r\n                            pass_id, batch_id, face_loss,\r\n                            start_time - prev_start_time))\r\n                    else:\r\n                        print(\"Pass {:d}, batch {:d}, face loss {:.6f}, \" \\\r\n                              \"head loss {:.6f}, \" \\\r\n                              \"time {:.5f}\".format(pass_id,\r\n                               batch_id, face_loss, head_loss,\r\n                               start_time - prev_start_time))\r\n                batch_id += 1\r\n            except (fluid.core.EOFException, StopIteration):\r\n                train_py_reader.reset()\r\n                break\r\n        epoch_end_time = time.time()\r\n        total_time += epoch_end_time - start_time\r\n        save_model(str(pass_id), train_prog)\r\n\r\n    # only for ce\r\n    if args.enable_ce:\r\n        gpu_num = get_cards(args)\r\n        print(\"kpis\\teach_pass_duration_card%s\\t%s\" %\r\n                (gpu_num, total_time / epoch_idx))\r\n        print(\"kpis\\ttrain_face_loss_card%s\\t%s\" %\r\n                (gpu_num, face_loss))\r\n        print(\"kpis\\ttrain_head_loss_card%s\\t%s\" %\r\n                (gpu_num, head_loss))\r\n\r\n\r\n\r\ndef get_cards(args):\r\n    if args.enable_ce:\r\n        cards = os.environ.get('CUDA_VISIBLE_DEVICES')\r\n        num = len(cards.split(\",\"))\r\n        return num\r\n    else:\r\n        return args.num_devices\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = parser.parse_args()\r\n    print_arguments(args)\r\n    check_cuda(args.use_gpu)\r\n\r\n    data_dir = os.path.join(args.data_dir, 'WIDER_train/images/')\r\n    train_file_list = os.path.join(args.data_dir,\r\n        'wider_face_split/wider_face_train_bbx_gt.txt')\r\n    mean_BGR = [float(m) for m in args.mean_BGR.split(\",\")]\r\n    image_shape = [3, int(args.resize_h), int(args.resize_w)]\r\n    train_parameters[\"image_shape\"] = image_shape\r\n    train_parameters[\"use_pyramidbox\"] = args.use_pyramidbox\r\n    train_parameters[\"batch_size\"] = args.batch_size\r\n    train_parameters[\"lr\"] = args.learning_rate\r\n    train_parameters[\"epoc_num\"] = args.epoc_num\r\n\r\n\r\n    config = reader.Settings(\r\n        data_dir=data_dir,\r\n        resize_h=image_shape[1],\r\n        resize_w=image_shape[2],\r\n        apply_distort=True,\r\n        apply_expand=False,\r\n        mean_value=mean_BGR,\r\n        ap_version='11point')\r\n    train(args, config, train_parameters, train_file_list)\r\n```\r\n### Here is errors:\r\n```\r\n-----------  Configuration Arguments -----------\r\nbatch_num: None\r\nbatch_size: 16\r\ndata_dir: data\r\nenable_ce: False\r\nepoc_num: 160\r\nlearning_rate: 0.001\r\nmean_BGR: 104., 117., 123.\r\nmodel_save_dir: output\r\nnum_devices: 1\r\nparallel: True\r\npretrained_model: ./vgg_ilsvrc_16_fc_reduced/\r\nresize_h: 640\r\nresize_w: 640\r\nuse_gpu: True\r\nuse_multiprocess: False\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\n2020-02-28 08:19:13,201-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\nCUDAPlace(0)\r\n/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"/root/.vscode-server/extensions/ms-python.python-2020.2.64397/pythonFiles/ptvsd_launcher.py\", line 48, in <module>\r\n    main(ptvsdArgs)\r\n  File \"/root/.vscode-server/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 432, in main\r\n    run()\r\n  File \"/root/.vscode-server/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 316, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/root/phamkhactu/face_detection/train.py\", line 285, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"/root/phamkhactu/face_detection/train.py\", line 158, in train\r\n    exe.run(startup_prog)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/.local/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\r\n3   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<paddle::platform::Place, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<paddle::platform::Place>, std::allocator<std::pair<paddle::platform::Place const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, paddle::platform::Place)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<paddle::platform::Place, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<paddle::platform::Place>, std::allocator<std::pair<paddle::platform::Place const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, paddle::platform::Place)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\r\n7   paddle::platform::DeviceContextPool::Get(paddle::platform::Place const&)\r\n8   paddle::framework::GarbageCollector::GarbageCollector(paddle::platform::Place const&, unsigned long)\r\n9   paddle::framework::UnsafeFastGPUGarbageCollector::UnsafeFastGPUGarbageCollector(paddle::platform::CUDAPlace const&, unsigned long)\r\n10  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n11  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Paddle internal Check failed. (Please help us create a new issue, here we need to find the developer to add a user friendly error message): out of memory at (/paddle/paddle/fluid/platform/device_context.cc:220)\r\n```\r\n### and nvidia-smi show 11GB not use\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 208...  On   | 00000000:01:00.0 Off |                  N/A |\r\n| 45%   56C    P2    41W / 260W |  10905MiB / 11019MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     23333      G   /usr/lib/xorg/Xorg                            46MiB |\r\n|    0     23412      G   /usr/bin/sddm-greeter                         48MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n```",
        "state": "open",
        "user": "phamkhactu",
        "closed_by": null,
        "created_at": "2020-02-28T08:26:34+00:00",
        "updated_at": "2020-10-30T03:01:22+00:00",
        "closed_at": null,
        "comments_count": [
            "zhangting2020",
            "phamkhactu",
            "zhangting2020",
            "qingqing01",
            "phamkhactu",
            "phamkhactu",
            "phamkhactu",
            "qingqing01",
            "zhangting2020",
            "phamkhactu",
            "JOYLINZQ",
            "zhangting2020"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4363,
        "title": "请您帮助下，对话情感分析的报错，预训练文件和数据以及文件都没错，按照操作步骤来的",
        "body": "对话情感分析时，使用sh run.sh所有命令都能运行，但是sh run_ernie.sh train的时候会出现报错，数据和预训练文件都来自github。报错内容为：\r\nError: The feeded Variable 1 should have dimensions = 3, shape = [-1, 64, 1], but received feeded shape [32, 23, 1]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:133)\r\n  [operator < read > error]\r\n\r\n更详细的报错如下：\r\nDevice count: 16\r\nNum train examples: 9655\r\nMax train steps: 57\r\nTheoretical memory usage in training: 7954.669 - 8333.463 MB\r\nLoad model from ./pretrain_models/ernie/params\r\n/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_ernie_classifier.py\", line 403, in <module>\r\n    main(args)\r\n  File \"run_ernie_classifier.py\", line 327, in main\r\n    outputs = train_exe.run(program=train_program, fetch_list=fetch_list, return_numpy=False)\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 831, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 905, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n5   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 733, in _init_non_iterable\r\n    outputs={'Out': self._feed_list})\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 646, in __init__\r\n    self._init_non_iterable()\r\n  File \"/root/env/emotion/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 280, in from_generator\r\n    iterable, return_list)\r\n  File \"../models/representation/ernie.py\", line 44, in ernie_pyreader\r\n    use_double_buffer=True)\r\n  File \"run_ernie_classifier.py\", line 217, in main\r\n    pyreader_name='train_reader')\r\n  File \"run_ernie_classifier.py\", line 403, in <module>\r\n    main(args)",
        "state": "closed",
        "user": "Igoslow",
        "closed_by": "zhangting2020",
        "created_at": "2020-02-28T10:33:53+00:00",
        "updated_at": "2020-03-31T11:39:16+00:00",
        "closed_at": "2020-03-03T12:42:37+00:00",
        "comments_count": [
            "Igoslow",
            "hengai"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4364,
        "title": "PaddleHub 情感分析教程运行错误",
        "body": "PaddleHub 情感分析教程运行如下错误：\r\n七、开始Finetune\r\n我们选择finetune_and_eval接口来进行模型训练，这个接口在finetune的过程中，会周期性的进行模型效果的评估，以便我们了解整个训练过程的性能变化。\r\nrun_states = cls_task.finetune_and_eval()\r\n[2020-03-01 16:25:06,188] [    INFO] - Strategy with scheduler: {'warmup': 0.1, 'linear_decay': {'start_point': 0.1, 'end_learning_rate': 0}, 'noam_decay': False, 'discriminative': {'blocks': 0, 'factor': 2.6}, 'gradual_unfreeze': 0, 'slanted_triangle': {'cut_fraction': 0.0, 'ratio': 32}}, regularization: {'L2': 0.0, 'L2SP': 0.0, 'weight_decay': 0.01} and clip: {'GlobalNorm': 1.0, 'Norm': 0.0}\r\n2020-03-01 16:25:06,315-WARNING: \r\n     You can try our memory optimize feature to save your memory usage:\r\n         # create a build_strategy variable to set memory optimize option\r\n         build_strategy = compiler.BuildStrategy()\r\n         build_strategy.enable_inplace = True\r\n         build_strategy.memory_optimize = True\r\n         \r\n         # pass the build_strategy to with_data_parallel API\r\n         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\r\n             loss_name=loss.name, build_strategy=build_strategy)\r\n      \r\n     !!! Memory optimize is our experimental feature !!!\r\n         some variables may be removed/reused internal to save memory usage, \r\n         in order to fetch the right value of the fetch_list, please set the \r\n         persistable property to true for each variable in fetch_list\r\n\r\n         # Sample\r\n         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \r\n         # if you need to fetch conv1, then:\r\n         conv1.persistable = True\r\n\r\n                 \r\n[2020-03-01 16:25:07,187] [    INFO] - Try loading checkpoint from nlp_senta_turtorial_demo/ckpt.meta\r\n[2020-03-01 16:25:07,189] [    INFO] - PaddleHub model checkpoint not found, start from scratch...\r\n[2020-03-01 16:25:07,221] [    INFO] - PaddleHub finetune start\r\n[2020-03-01 16:25:07,227] [    INFO] - 20 pretrained paramaters loaded by PaddleHub\r\n[2020-03-01 16:25:11,932] [   TRAIN] - step 10 / 300: loss=0.71818 acc=0.16562 [step/sec: 2.13]\r\n[2020-03-01 16:25:16,371] [   TRAIN] - step 20 / 300: loss=0.71554 acc=0.15937 [step/sec: 2.25]\r\n[2020-03-01 16:25:20,792] [   TRAIN] - step 30 / 300: loss=0.70258 acc=0.26250 [step/sec: 2.26]\r\n[2020-03-01 16:25:25,574] [   TRAIN] - step 40 / 300: loss=0.68916 acc=0.60313 [step/sec: 2.09]\r\n[2020-03-01 16:25:30,040] [   TRAIN] - step 50 / 300: loss=0.66774 acc=0.85000 [step/sec: 2.24]\r\n[2020-03-01 16:25:30,044] [    INFO] - Evaluation on dev dataset start\r\nException in thread Thread-7:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/io.py\", line 585, in __provider_thread__\r\n    raise ex\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/io.py\", line 567, in __provider_thread__\r\n    for tensors in func():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/io.py\", line 617, in __tensor_provider__\r\n    for slots in paddle_reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 326, in __reader_creator__\r\n    for item in reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/batch.py\", line 35, in batch_reader\r\n    for instance in r:\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/reader/nlp_reader.py\", line 1203, in _data_reader\r\n    text = preprocess(item.text_a)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/reader/nlp_reader.py\", line 1178, in preprocess\r\n    processed = self.lac.lexical_analysis(data=data_dict)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/module/module.py\", line 543, in __call__\r\n    return_numpy=False)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator mul error.\r\nPython Callstacks: \r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1654, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 323, in fc\r\n    \"y_num_col_dims\": 1})\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/classifier_task.py\", line 200, in _build_net\r\n    act=\"softmax\")\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 329, in _build_env\r\n    self.env.outputs = self._build_net()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 474, in main_program\r\n    self._build_env()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 826, in _run\r\n    with fluid.program_guard(self.main_program, self.startup_program):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 799, in eval\r\n    run_states = self._run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 688, in _default_eval_interval_event\r\n    self.eval(phase=\"dev\")\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 580, in hook_function\r\n    func(*args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 930, in _run_with_py_reader\r\n    self._eval_interval_event()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 828, in _run\r\n    return self._run_with_py_reader(do_eval=do_eval)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 775, in finetune\r\n    run_states = self._run(do_eval=do_eval)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\", line 763, in finetune_and_eval\r\n    return self.finetune(do_eval=True)\r\n  File \"<ipython-input-8-33eafd68b5ee>\", line 1, in <module>\r\n    run_states = cls_task.finetune_and_eval()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\r\n    if (yield from self.run_code(code, result)):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\r\n    return runner(coro)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1080, in __init__\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 346, in wrapper\r\n    runner = Runner(result, future, yielded)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\r\n    yield self.process_one()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\r\n    ret = callback()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n    self._context.run(self._callback, *self._args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\r\n    self.io_loop.start()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\r\n    app.start()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\nC++ Callstacks: \r\nInput X(0)is not initialized at [/paddle/paddle/fluid/framework/operator.cc:1109]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fdca7ea2d60p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7fdca7ea30d9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7fdca9b2f04fp paddle::framework::OperatorWithKernel::IndicateDataType(paddle::framework::ExecutionContext const&) const + 1343\r\n3       0x7fdca9b2f23fp paddle::framework::OperatorWithKernel::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 47\r\n4       0x7fdca9b322a3p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 243\r\n5       0x7fdca9b32bb4p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 292\r\n6       0x7fdca9b304dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n7       0x7fdca801541ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 222\r\n8       0x7fdca80162ffp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n9       0x7fdca7e9296ep\r\n10      0x7fdca7ed576ep\r\n11      0x55b857d62744p _PyMethodDef_RawFastCallKeywords + 596\r\n12      0x55b857d62861p _PyCFunction_FastCallKeywords + 33\r\n13      0x55b857dce6e8p _PyEval_EvalFrameDefault + 21240\r\n14      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n15      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n16      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n17      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n18      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n19      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n20      0x55b857d12d09p _PyEval_EvalCodeWithName + 2761\r\n21      0x55b857d13860p _PyFunction_FastCallDict + 1024\r\n22      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n23      0x55b857d24dbep PyObject_Call + 110\r\n24      0x55b857e21bc7p\r\n25      0x55b857d6a8fbp _PyObject_FastCallKeywords + 1179\r\n26      0x55b857dcea8fp _PyEval_EvalFrameDefault + 22175\r\n27      0x55b857d1281ap _PyEval_EvalCodeWithName + 1498\r\n28      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n29      0x55b857dc9806p _PyEval_EvalFrameDefault + 1046\r\n30      0x55b857d6ab31p\r\n31      0x55b857dc9e36p _PyEval_EvalFrameDefault + 2630\r\n32      0x55b857d6ab31p\r\n33      0x55b857dc9e36p _PyEval_EvalFrameDefault + 2630\r\n34      0x55b857d6ab31p\r\n35      0x55b857dc9e36p _PyEval_EvalFrameDefault + 2630\r\n36      0x55b857d6ab31p\r\n37      0x55b857dc9e36p _PyEval_EvalFrameDefault + 2630\r\n38      0x55b857d12d09p _PyEval_EvalCodeWithName + 2761\r\n39      0x55b857d13635p _PyFunction_FastCallDict + 469\r\n40      0x55b857dcb232p _PyEval_EvalFrameDefault + 7746\r\n41      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n42      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n43      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n44      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n45      0x55b857d1356bp _PyFunction_FastCallDict + 267\r\n46      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n47      0x55b857d24dbep PyObject_Call + 110\r\n48      0x55b857e21817p\r\n49      0x55b857ddc788p\r\n50      0x7fdd253e76bap\r\n51      0x7fdd2511d41dp clone + 109\r\n\r\n\r\n---------------------------------------------------------------------------EnforceNotMet                             Traceback (most recent call last)<ipython-input-8-33eafd68b5ee> in <module>\r\n----> 1 run_states = cls_task.finetune_and_eval()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in finetune_and_eval(self)\r\n    761 \r\n    762     def finetune_and_eval(self):\r\n--> 763         return self.finetune(do_eval=True)\r\n    764 \r\n    765     def finetune(self, do_eval=False):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in finetune(self, do_eval)\r\n    773                 while self.current_epoch <= self.config.num_epoch:\r\n    774                     self.config.strategy.step()\r\n--> 775                     run_states = self._run(do_eval=do_eval)\r\n    776                     self.env.current_epoch += 1\r\n    777 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in _run(self, do_eval)\r\n    826         with fluid.program_guard(self.main_program, self.startup_program):\r\n    827             if self.config.use_pyreader:\r\n--> 828                 return self._run_with_py_reader(do_eval=do_eval)\r\n    829             return self._run_with_data_feeder(do_eval=do_eval)\r\n    830 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in _run_with_py_reader(self, do_eval)\r\n    928 \r\n    929                         if do_eval and self.current_step % self.config.eval_interval == 0:\r\n--> 930                             self._eval_interval_event()\r\n    931 \r\n    932                     self._run_step_event(step_run_state)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in hook_function(self, *args)\r\n    578             for name, func in self._hooks[hook_type].items():\r\n    579                 if inspect.ismethod(func):\r\n--> 580                     func(*args)\r\n    581                 else:\r\n    582                     partial(func, self)(*args)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in _default_eval_interval_event(self)\r\n    686 \r\n    687     def _default_eval_interval_event(self):\r\n--> 688         self.eval(phase=\"dev\")\r\n    689 \r\n    690     def _default_run_step_event(self, run_state):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in eval(self, phase, load_best_model)\r\n    797                 self.init_if_necessary()\r\n    798             self._eval_start_event()\r\n--> 799             run_states = self._run()\r\n    800             self._eval_end_event(run_states)\r\n    801             return run_states\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in _run(self, do_eval)\r\n    824 \r\n    825     def _run(self, do_eval=False):\r\n--> 826         with fluid.program_guard(self.main_program, self.startup_program):\r\n    827             if self.config.use_pyreader:\r\n    828                 return self._run_with_py_reader(do_eval=do_eval)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in main_program(self)\r\n    472     def main_program(self):\r\n    473         if not self.env.is_inititalized:\r\n--> 474             self._build_env()\r\n    475         return self.env.main_program\r\n    476 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py in _build_env(self)\r\n    327                                  self._base_startup_program):\r\n    328             with fluid.unique_name.guard(self.env.UNG):\r\n--> 329                 self.env.outputs = self._build_net()\r\n    330                 if self.is_train_phase or self.is_test_phase:\r\n    331                     self.env.labels = self._add_label()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/classifier_task.py in _build_net(self)\r\n    198             bias_attr=fluid.ParamAttr(\r\n    199                 name=\"cls_out_b\", initializer=fluid.initializer.Constant(0.)),\r\n--> 200             act=\"softmax\")\r\n    201 \r\n    202         self.ret_infers = fluid.layers.reshape(\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py in fc(input, size, num_flatten_dims, param_attr, bias_attr, act, is_test, name)\r\n    321             outputs={\"Out\": tmp},\r\n    322             attrs={\"x_num_col_dims\": num_flatten_dims,\r\n--> 323                    \"y_num_col_dims\": 1})\r\n    324         mul_results.append(tmp)\r\n    325 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py in append_op(self, *args, **kwargs)\r\n     41 \r\n     42     def append_op(self, *args, **kwargs):\r\n---> 43         return self.main_program.current_block().append_op(*args, **kwargs)\r\n     44 \r\n     45     def multiple_input(self, input_param_name='input'):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in append_op(self, *args, **kwargs)\r\n   1652                 inputs=kwargs.get(\"inputs\", None),\r\n   1653                 outputs=kwargs.get(\"outputs\", None),\r\n-> 1654                 attrs=kwargs.get(\"attrs\", None))\r\n   1655 \r\n   1656             self.ops.append(op)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in __init__(***failed resolving arguments***)\r\n   1056             if self._has_kernel(type):\r\n   1057                 self.desc.infer_var_type(self.block.desc)\r\n-> 1058                 self.desc.infer_shape(self.block.desc)\r\n   1059 \r\n   1060     def _has_kernel(self, op_type):\r\nEnforceNotMet: Enforce failed. Expected x_dims.size() > x_num_col_dims, but received x_dims.size():1 <= x_num_col_dims:1.\r\nThe input tensor X's rank of MulOp should be larger than x_num_col_dims. at [/paddle/paddle/fluid/operators/mul_op.cc:48]\r\nPaddlePaddle Call Stacks: \r\n0       0x7fdca7ea3288p void paddle::platform::EnforceNotMet::Init<std::string>(std::string, char const*, int) + 360\r\n1       0x7fdca7ea35d7p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int) + 87\r\n2       0x7fdca857e417p paddle::operators::MulOp::InferShape(paddle::framework::InferShapeContext*) const + 3319\r\n3       0x7fdca7ffac6ep paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 862\r\n4       0x7fdca7f5225cp\r\n5       0x7fdca7ed576ep\r\n6       0x55b857d62744p _PyMethodDef_RawFastCallKeywords + 596\r\n7       0x55b857d62861p _PyCFunction_FastCallKeywords + 33\r\n8       0x55b857dce6e8p _PyEval_EvalFrameDefault + 21240\r\n9       0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n10      0x55b857d13860p _PyFunction_FastCallDict + 1024\r\n11      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n12      0x55b857d6997ap\r\n13      0x55b857d6a588p _PyObject_FastCallKeywords + 296\r\n14      0x55b857dcea8fp _PyEval_EvalFrameDefault + 22175\r\n15      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n16      0x55b857d13860p _PyFunction_FastCallDict + 1024\r\n17      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n18      0x55b857d24dbep PyObject_Call + 110\r\n19      0x55b857dcb232p _PyEval_EvalFrameDefault + 7746\r\n20      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n21      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n22      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n23      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n24      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n25      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n26      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n27      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n28      0x55b857d12d09p _PyEval_EvalCodeWithName + 2761\r\n29      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n30      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n31      0x55b857d1356bp _PyFunction_FastCallDict + 267\r\n32      0x55b857d76ed2p\r\n33      0x55b857d26fe1p _PyObject_GenericGetAttrWithDict + 257\r\n34      0x55b857dc9cdap _PyEval_EvalFrameDefault + 2282\r\n35      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n36      0x55b857d61ef5p _PyFunction_FastCallKeywords + 805\r\n37      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n38      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n39      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n40      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n41      0x55b857d1356bp _PyFunction_FastCallDict + 267\r\n42      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n43      0x55b857d24dbep PyObject_Call + 110\r\n44      0x55b857dcb232p _PyEval_EvalFrameDefault + 7746\r\n45      0x55b857d1281ap _PyEval_EvalCodeWithName + 1498\r\n46      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n47      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n48      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n49      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n50      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n51      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n52      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n53      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n54      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n55      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n56      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n57      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n58      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n59      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n60      0x55b857d13424p PyEval_EvalCodeEx + 68\r\n61      0x55b857d1344cp PyEval_EvalCode + 28\r\n62      0x55b857dd8f8dp\r\n63      0x55b857d625d9p _PyMethodDef_RawFastCallKeywords + 233\r\n64      0x55b857d62861p _PyCFunction_FastCallKeywords + 33\r\n65      0x55b857dcdb94p _PyEval_EvalFrameDefault + 18340\r\n66      0x55b857d6b592p _PyGen_Send + 674\r\n67      0x55b857dcae69p _PyEval_EvalFrameDefault + 6777\r\n68      0x55b857d6b592p _PyGen_Send + 674\r\n69      0x55b857dcae69p _PyEval_EvalFrameDefault + 6777\r\n70      0x55b857d6b592p _PyGen_Send + 674\r\n71      0x55b857d6257dp _PyMethodDef_RawFastCallKeywords + 141\r\n72      0x55b857d6a3cfp _PyMethodDescr_FastCallKeywords + 79\r\n73      0x55b857dce07cp _PyEval_EvalFrameDefault + 19596\r\n74      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n75      0x55b857dc9806p _PyEval_EvalFrameDefault + 1046\r\n76      0x55b857d61ccbp _PyFunction_FastCallKeywords + 251\r\n77      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n78      0x55b857d12539p _PyEval_EvalCodeWithName + 761\r\n79      0x55b857d13860p _PyFunction_FastCallDict + 1024\r\n80      0x55b857d31e53p _PyObject_Call_Prepend + 99\r\n81      0x55b857d24dbep PyObject_Call + 110\r\n82      0x55b857dcb232p _PyEval_EvalFrameDefault + 7746\r\n83      0x55b857d1281ap _PyEval_EvalCodeWithName + 1498\r\n84      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n85      0x55b857dca8ccp _PyEval_EvalFrameDefault + 5340\r\n86      0x55b857d6b059p\r\n87      0x55b857d625d9p _PyMethodDef_RawFastCallKeywords + 233\r\n88      0x55b857d62861p _PyCFunction_FastCallKeywords + 33\r\n89      0x55b857dcdb94p _PyEval_EvalFrameDefault + 18340\r\n90      0x55b857d12d09p _PyEval_EvalCodeWithName + 2761\r\n91      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n92      0x55b857dc9a93p _PyEval_EvalFrameDefault + 1699\r\n93      0x55b857d6b059p\r\n94      0x55b857d625d9p _PyMethodDef_RawFastCallKeywords + 233\r\n95      0x55b857d62861p _PyCFunction_FastCallKeywords + 33\r\n96      0x55b857dcdb94p _PyEval_EvalFrameDefault + 18340\r\n97      0x55b857d12d09p _PyEval_EvalCodeWithName + 2761\r\n98      0x55b857d61f57p _PyFunction_FastCallKeywords + 903\r\n99      0x55b857dc9806p _PyEval_EvalFrameDefault + 1046",
        "state": "open",
        "user": "githubusr2",
        "closed_by": null,
        "created_at": "2020-03-01T09:00:25+00:00",
        "updated_at": "2020-03-02T12:31:25+00:00",
        "closed_at": null,
        "comments_count": [
            "kinghuin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4367,
        "title": "微调nextvald的参数，如何加载部分参数呢",
        "body": "如果不需要最后一层参数，该怎么进行这种底层操作呢？有没有相关教程，感觉paddlepaddle的教程很少啊，好多都是高级封装好的了，很难进行定制化操作",
        "state": "closed",
        "user": "aiot-tech",
        "closed_by": "mapingshuo",
        "created_at": "2020-03-02T06:35:43+00:00",
        "updated_at": "2020-03-02T07:26:09+00:00",
        "closed_at": "2020-03-02T07:26:09+00:00",
        "comments_count": [
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4369,
        "title": "face_detection/train.py  training model bugs",
        "body": "### read some image failed\r\n```\r\nProcess Process-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/reader/decorator.py\", line 556, in _read_into_queue\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/.local/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/reader/decorator.py\", line 549, in _read_into_queue\r\n    for sample in reader():\r\n  File \"/root/phamkhactu/face_detection/reader.py\", line 270, in reader\r\n    image_path)\r\n  File \"/root/phamkhactu/face_detection/reader.py\", line 119, in preprocess\r\n    settings.min_face_size)\r\n  File \"/root/phamkhactu/face_detection/image_util.py\", line 437, in crop_image_sampling\r\n    sample_img = np.zeros((height, width, 3))\r\nMemoryError\r\n2020-03-02 15:47:38,957-WARNING: Your decorated reader has raised an exception!\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/layers/io.py\", line 491, in __provider_thread__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/.local/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/layers/io.py\", line 472, in __provider_thread__\r\n    for tensors in func():\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/layers/io.py\", line 523, in __tensor_provider__\r\n    for slots in paddle_reader():\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/data_feeder.py\", line 488, in __reader_creator__\r\n    for item in reader():\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/reader/decorator.py\", line 572, in queue_reader\r\n    raise ValueError(\"multiprocess reader raises an exception\")\r\nValueError: multiprocess reader raises an exception\r\n\r\nPass 0, batch 680, face loss 4.203463, head loss 4.551610, time 0.90225\r\n/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 284, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"train.py\", line 212, in train\r\n    [v.name for v in fetches])\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/parallel_executor.py\", line 311, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/.local/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 843, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py\", line 677, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/layers/io.py\", line 889, in read_file\r\n    type='read', inputs={'Reader': [reader]}, outputs={'Out': out})\r\n  File \"train.py\", line 101, in build_program\r\n    image, face_box, head_box, gt_label = fluid.layers.read_file(py_reader)\r\n  File \"train.py\", line 153, in train\r\n    args=args)\r\n  File \"train.py\", line 284, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\r\n  [operator < read > error]\r\n```",
        "state": "closed",
        "user": "phamkhactu",
        "closed_by": "mapingshuo",
        "created_at": "2020-03-02T16:02:58+00:00",
        "updated_at": "2020-10-31T15:20:06+00:00",
        "closed_at": "2020-10-31T15:20:06+00:00",
        "comments_count": [
            "mapingshuo",
            "qingqing01",
            "phamkhactu",
            "qingqing01",
            "phamkhactu",
            "phamkhactu",
            "qingqing01",
            "phamkhactu",
            "phamkhactu",
            "phamkhactu",
            "phamkhactu",
            "qingqing01",
            "phamkhactu",
            "qingqing01",
            "phamkhactu",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4374,
        "title": "在训练时报了CUDNN_STATUS_EXECUTION_FAILED错误",
        "body": "我用的是ubuntu16.04\r\n显卡是RTX2080Ti\r\n我是在anaconda的虚拟环境下跑的训练，网络为ResNet50_vd\r\npaddle1.7.0.post97 + cuda9.0 + cudnn7.3.1\r\n\r\n\r\n2020-03-05 14:27:22,808-INFO: -------------  Configuration Arguments -------------\r\n2020-03-05 14:27:22,808-INFO:                batch_size : 16\r\n2020-03-05 14:27:22,808-INFO:                checkpoint : None\r\n2020-03-05 14:27:22,808-INFO:                 class_dim : 2\r\n2020-03-05 14:27:22,808-INFO:                  data_dir : ./data/ILSVRC2012/\r\n2020-03-05 14:27:22,808-INFO:               data_format : NCHW\r\n2020-03-05 14:27:22,808-INFO:              decay_epochs : 2.4\r\n2020-03-05 14:27:22,808-INFO:                decay_rate : 0.97\r\n2020-03-05 14:27:22,808-INFO:         drop_connect_rate : 0.2\r\n2020-03-05 14:27:22,808-INFO:                 ema_decay : 0.9999\r\n2020-03-05 14:27:22,808-INFO:                 enable_ce : False\r\n2020-03-05 14:27:22,808-INFO: finetune_exclude_pretrained_params : None\r\n2020-03-05 14:27:22,808-INFO:           fuse_bn_act_ops : False\r\n2020-03-05 14:27:22,808-INFO:  fuse_elewise_add_act_ops : False\r\n2020-03-05 14:27:22,808-INFO:                image_mean : [0.485, 0.456, 0.406]\r\n2020-03-05 14:27:22,808-INFO:               image_shape : [3, 224, 224]\r\n2020-03-05 14:27:22,808-INFO:                 image_std : [0.229, 0.224, 0.225]\r\n2020-03-05 14:27:22,808-INFO:             interpolation : None\r\n2020-03-05 14:27:22,808-INFO:               is_profiler : False\r\n2020-03-05 14:27:22,808-INFO:                  l2_decay : 7e-05\r\n2020-03-05 14:27:22,808-INFO:   label_smoothing_epsilon : 0.1\r\n2020-03-05 14:27:22,808-INFO:               lower_ratio : 0.75\r\n2020-03-05 14:27:22,808-INFO:               lower_scale : 0.08\r\n2020-03-05 14:27:22,808-INFO:                        lr : 0.1\r\n2020-03-05 14:27:22,808-INFO:               lr_strategy : cosine_decay\r\n2020-03-05 14:27:22,808-INFO:                  max_iter : 0\r\n2020-03-05 14:27:22,808-INFO:               mixup_alpha : 0.2\r\n2020-03-05 14:27:22,808-INFO:                     model : ResNet50_vd\r\n2020-03-05 14:27:22,808-INFO:            model_save_dir : output/\r\n2020-03-05 14:27:22,808-INFO:             momentum_rate : 0.9\r\n2020-03-05 14:27:22,808-INFO:                num_epochs : 200\r\n2020-03-05 14:27:22,808-INFO:              padding_type : SAME\r\n2020-03-05 14:27:22,808-INFO:          pretrained_model : None\r\n2020-03-05 14:27:22,808-INFO:                print_step : 10\r\n2020-03-05 14:27:22,808-INFO:             profiler_path : ./profilier_files\r\n2020-03-05 14:27:22,808-INFO:               random_seed : None\r\n2020-03-05 14:27:22,808-INFO:           reader_buf_size : 2048\r\n2020-03-05 14:27:22,808-INFO:             reader_thread : 8\r\n2020-03-05 14:27:22,808-INFO:         resize_short_size : 256\r\n2020-03-05 14:27:22,808-INFO:                 same_feed : 0\r\n2020-03-05 14:27:22,808-INFO:                 save_step : 1\r\n2020-03-05 14:27:22,808-INFO:                scale_loss : 1.0\r\n2020-03-05 14:27:22,808-INFO:               step_epochs : [30, 60, 90]\r\n2020-03-05 14:27:22,808-INFO:           test_batch_size : 8\r\n2020-03-05 14:27:22,809-INFO:              total_images : 476\r\n2020-03-05 14:27:22,809-INFO:               upper_ratio : 1.3333333333333333\r\n2020-03-05 14:27:22,809-INFO:                    use_aa : False\r\n2020-03-05 14:27:22,809-INFO:                  use_dali : False\r\n2020-03-05 14:27:22,809-INFO:  use_dynamic_loss_scaling : True\r\n2020-03-05 14:27:22,809-INFO:                   use_ema : False\r\n2020-03-05 14:27:22,809-INFO:                  use_fp16 : False\r\n2020-03-05 14:27:22,809-INFO:                   use_gpu : True\r\n2020-03-05 14:27:22,809-INFO:       use_label_smoothing : 1\r\n2020-03-05 14:27:22,809-INFO:                 use_mixup : 1\r\n2020-03-05 14:27:22,809-INFO:                    use_se : True\r\n2020-03-05 14:27:22,809-INFO:                  validate : 1\r\n2020-03-05 14:27:22,809-INFO:            warm_up_epochs : 5.0\r\n2020-03-05 14:27:22,809-INFO: ----------------------------------------------------\r\nW0305 14:27:26.086107 23366 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0305 14:27:26.087620 23366 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\nI0305 14:27:26.850368 23366 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI0305 14:27:26.869619 23366 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0305 14:27:26.908351 23366 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0305 14:27:26.920976 23366 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n2020-03-05 14:27:27,033-INFO: [Pass 0, train batch 0]     loss 0.71246, lr 0.10000, elapse 0.2654 sec\r\n/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 304, in <module>\r\n    main()\r\n  File \"train.py\", line 300, in main\r\n    train(args)\r\n  File \"train.py\", line 250, in train\r\n    fetch_list=train_fetch_list)\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 843, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 677, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n8   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunTracedOps(std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> > const&)\r\n10  paddle::framework::details::FastThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n11  paddle::framework::details::ScopeBufferedMonitor::Apply(std::function<void ()> const&, bool)\r\n12  paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n13  paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/junc-lin/anaconda3/envs/paddle_test/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1405, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"/home/junc-lin/Downloads/models-develop/PaddleCV/image_classification/models/resnet_vd.py\", line 146, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/home/junc-lin/Downloads/models-develop/PaddleCV/image_classification/models/resnet_vd.py\", line 67, in net\r\n    name='conv1_1')\r\n  File \"/home/junc-lin/Downloads/models-develop/PaddleCV/image_classification/build_model.py\", line 98, in _mixup_model\r\n    net_out = model.net(input=image, class_dim=args.class_dim)\r\n  File \"/home/junc-lin/Downloads/models-develop/PaddleCV/image_classification/build_model.py\", line 125, in create_model\r\n    loss_out = _mixup_model(data, model, args, is_train)\r\n  File \"train.py\", line 65, in build_program\r\n    data_loader, loss_out = create_model(model, args, is_train)\r\n  File \"train.py\", line 166, in train\r\n    args=args)\r\n  File \"train.py\", line 300, in main\r\n    train(args)\r\n  File \"train.py\", line 304, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: An error occurred here. There is no accurate error hint for this error yet. We are continuously in the process of increasing hint for this kind of error check. It would be helpful if you could inform us of how this conversion went by opening a github issue. And we will resolve it with high priority.\r\n  - New issue link: https://github.com/PaddlePaddle/Paddle/issues/new\r\n  - Recommended issue content: all error stack information\r\n  [Hint: CUDNN_STATUS_EXECUTION_FAILED] at (/paddle/paddle/fluid/operators/conv_cudnn_op.cu:286)\r\n  [operator < conv2d > error]\r\n",
        "state": "closed",
        "user": "chaogehah",
        "closed_by": "luotao1",
        "created_at": "2020-03-05T06:52:58+00:00",
        "updated_at": "2020-06-19T11:05:04+00:00",
        "closed_at": "2020-06-19T11:05:04+00:00",
        "comments_count": [
            "JepsonWong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4379,
        "title": "lac大规模文本分词效率比较低",
        "body": "",
        "state": "closed",
        "user": "yudian931122",
        "closed_by": "yudian931122",
        "created_at": "2020-03-06T06:02:29+00:00",
        "updated_at": "2020-03-13T12:18:43+00:00",
        "closed_at": "2020-03-13T12:18:43+00:00",
        "comments_count": [
            "baiyfbupt",
            "yudian931122",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4380,
        "title": "AttributeError: module 'paddle.fluid.io' has no attribute 'batch'",
        "body": "这个问题是因为版本改吗了？还是什么问题？年前还可以正常运行现在一直报这个错",
        "state": "closed",
        "user": "yw1991",
        "closed_by": "baiyfbupt",
        "created_at": "2020-03-06T08:31:53+00:00",
        "updated_at": "2020-03-18T07:49:29+00:00",
        "closed_at": "2020-03-18T07:49:29+00:00",
        "comments_count": [
            "baiyfbupt",
            "yw1991"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4396,
        "title": "load模型checkpoint, 第二次预测出问题 ",
        "body": "https://github.com/PaddlePaddle/models/blob/v1.6/PaddleNLP/emotion_detection/run_classifier.py\r\n照这个改的预测代码，就是load模型checkpoints，我们想做成那种api形式的，load一次模型，多次预测，第二次预测出问题：\r\n\r\nLoad model from ../inference_model_v5/cnn/step_220000\r\n现 在 怎 么 办\r\n<paddle.fluid.reader.GeneratorLoader object at 0x7fda24345450>\r\nbb\r\n[array([[6.2673175e-01, 6.5273693e-04, 6.8719119e-02, ..., 2.0736305e-14,\r\n        1.4468053e-13, 1.3849883e-12]], dtype=float32)]\r\n{\"sentence\":\"现在怎么办\"}\r\n{\"topic\": \"DFT\", \"prob\": 0.626732}\r\n怎 么 办\r\n<paddle.fluid.reader.GeneratorLoader object at 0x7fda24345450>\r\nbb\r\nTraceback (most recent call last):\r\n  File \"topic_api_init.py\", line 326, in <module>\r\n    b = a.inference(input_json)\r\n  File \"topic_api_init.py\", line 308, in inference\r\n    [label_key, prob] = main(args, test_exe, test_prog, infer_loader, probs)\r\n  File \"topic_api_init.py\", line 203, in main\r\n    \"infer\")\r\nTypeError: 'NoneType' object is not iterable\r\n\r\n我们的预测代码可私聊。\r\n",
        "state": "open",
        "user": "xfyu1999",
        "closed_by": "xfyu1999",
        "created_at": "2020-03-10T09:34:38+00:00",
        "updated_at": "2020-03-11T13:52:26+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4381,
        "title": "关于image_classification输入图片尺寸的问题",
        "body": "```bash\r\n!python image_classification/train.py \\\r\n        --data_dir=breast/ \\\r\n        --total_images=6356 \\\r\n        --class_dim=8 \\\r\n        --validate=True \\\r\n        --model=HRNet_W32_C \\\r\n        --batch_size=16 \\\r\n        --lr_strategy=cosine_decay \\\r\n        --image_shape 3 700 460 \\\r\n        --lr=0.001 \\\r\n        --num_epochs=200 \\\r\n        --model_save_dir=output/ \\\r\n        --l2_decay=7e-5 \\\r\n        --use_mixup=True \\\r\n        --use_label_smoothing=True \\\r\n        --label_smoothing_epsilon=0.1 \\\r\n        --pretrained_model=best/HRNet_W32_C  \r\n```\r\n使用这个指令进行训练时 增加  --image_shape 3 700 460 \\ 报错结果如下：\r\nValueError: The feeded Variable 'feed_image' should have dimensions = 4, shape = (-1, 3, 700, 460), but received feeded shape [16, 3, 700, 700]\r\n请问在代码中如何设置此项，我在reader中没有找到？\r\n还有一个问题  \r\n我尝试不适用预训练模型 分别使用 --image_shape 3 700 460 / --image_shape 3 460 460 \r\n均报错，可否有解释，如何更改？\r\n-image_shape 3 460 460 报错结果如下：\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [16, 32, 115, 115] and the shape of Y = [16, 32, 116, 116]. Received [115] in X is not equal to [116] in Y\r\n  [Hint: Expected y_dims[i] == 1, but received y_dims[i]:116 != 1:1.] at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:79)\r\n  [operator < elementwise_add > error]",
        "state": "open",
        "user": "lxk767363331",
        "closed_by": null,
        "created_at": "2020-03-06T13:50:24+00:00",
        "updated_at": "2020-03-09T08:50:29+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4385,
        "title": "#--init_checkpoint ./pretrain_models/ernie",
        "body": "按着官网步骤来的  报错：run_ernie.sh: line 22: --init_checkpoint: command not found",
        "state": "open",
        "user": "yw1991",
        "closed_by": null,
        "created_at": "2020-03-09T09:44:53+00:00",
        "updated_at": "2024-02-26T05:12:44+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4398,
        "title": "这是否是pyramidbox代码问题？",
        "body": "widerface_eval里\r\n函数infer有这么一段代\r\nif image.mode == 'L':\r\n     image = img.convert('RGB')\r\nimg我没有找到上下文，个人怀疑应该是image，不知道是不是？",
        "state": "closed",
        "user": "sonic-github",
        "closed_by": "yghstill",
        "created_at": "2020-03-10T12:06:40+00:00",
        "updated_at": "2020-03-13T01:37:37+00:00",
        "closed_at": "2020-03-13T01:37:37+00:00",
        "comments_count": [
            "huangjun12",
            "sonic-github",
            "yghstill",
            "sonic-github"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4409,
        "title": "DeepVoice3 训练时AssertionError",
        "body": "执行python train.py --data-root=ljspeech --use-gpu --preset=../../dv3.single_frame/config.json  --train-seq2seq-only --checkpoint=model后报错\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 225, in <module>\r\n    model = make_deepvoice3_from_hparams(hparams)\r\n  File \"train.py\", line 110, in make_deepvoice3_from_hparams\r\n    hparams.key_projection, hparams.value_projection)\r\n  File \"/home/aistudio/work/DeepVoice3/deepvoice3_paddle/builder.py\", line 75, in deepvoice3\r\n    use_decoder_state_for_postnet_input, \"float32\")\r\n  File \"/home/aistudio/work/DeepVoice3/deepvoice3_paddle/deepvoice3.py\", line 1189, in __init__\r\n    window_range, key_projection, value_projection, dropout, dtype)\r\n  File \"/home/aistudio/work/DeepVoice3/deepvoice3_paddle/deepvoice3.py\", line 1385, in __init__\r\n    dtype=dtype)\r\n  File \"/home/aistudio/work/DeepVoice3/deepvoice3_paddle/deepvoice3.py\", line 132, in __init__\r\n    dtype=dtype)\r\n  File \"/home/aistudio/work/DeepVoice3/deepvoice3_paddle/modules.py\", line 119, in Embedding\r\n    dtype=dtype)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/nn.py\", line 1309, in __init__\r\n    assert self._is_sparse is True and self._is_distributed is False\r\nAssertionError",
        "state": "open",
        "user": "weak-fox",
        "closed_by": null,
        "created_at": "2020-03-12T08:22:23+00:00",
        "updated_at": "2024-02-26T05:12:42+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4410,
        "title": "paddle.fluid.layers.cross_entropy(input, label, soft_label=True) 运行后label被更改",
        "body": "loss 使用\r\nfluid.layers.cross_entropy(input=self.network_outputs[0], label=gt_label, soft_label=True)，\r\n\r\n输入：\r\ngt_label是我自己设定好的  [0.  0.  0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\r\n\r\n在train的run之后打印 fetch_out的gt_label变为：\r\n![F2D45D6252E53F5B661495BB63587376](https://user-images.githubusercontent.com/9814501/76505363-556eb200-6484-11ea-839b-393f72dab3a8.JPG)\r\n\r\nloss完整代码如下：\r\n        cost_cls = fluid.layers.cross_entropy(input=self.network_outputs[0], label=self.label_id_input, soft_label=True)\r\n        #cost_cls = fluid.layers.sigmoid_cross_entropy_with_logits(x=self.logit, label=self.label_id_input)\r\n        cost_cls = fluid.layers.reduce_sum(cost_cls, dim=-1)\r\n        sum_cost_cls = fluid.layers.reduce_sum(cost_cls)\r\n        self.loss_cls_ = fluid.layers.scale(sum_cost_cls, scale=self.num_gpus, bias_after_scale=False)\r\n\r\n\r\n尝试用 fluid.layers.sigmoid_cross_entropy_with_logits.  gt_label不变化\r\n",
        "state": "closed",
        "user": "linrjing",
        "closed_by": "linrjing",
        "created_at": "2020-03-12T09:11:34+00:00",
        "updated_at": "2020-03-12T10:41:53+00:00",
        "closed_at": "2020-03-12T10:41:53+00:00",
        "comments_count": [
            "Aurelius84",
            "linrjing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4426,
        "title": "models/PaddleNLP/sentiment_classification/   找不到 nets.py",
        "body": "我在用models/PaddleNLP/sentiment_classification/ 尝试做情感倾向分析，但出现错误：\r\nTraceback (most recent call last):\r\n  File \"run_ernie_classifier.py\", line 23, in <module>\r\n    from nets import bow_net\r\nImportError: No module named nets\r\n请问能提供一下nets.py，或者更新一下说明文档吗？\r\n",
        "state": "closed",
        "user": "lguowang",
        "closed_by": "lguowang",
        "created_at": "2020-03-13T12:13:02+00:00",
        "updated_at": "2020-03-13T12:24:41+00:00",
        "closed_at": "2020-03-13T12:24:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4411,
        "title": "关于BSN/BMN模型",
        "body": "BSN/BMN模型中好像只提供了动作提名的部分的实验步骤，请问一下后面动作分类部分的实验步骤是什么？谢谢",
        "state": "closed",
        "user": "li-900406",
        "closed_by": "huangjun12",
        "created_at": "2020-03-12T14:03:20+00:00",
        "updated_at": "2020-12-29T01:10:43+00:00",
        "closed_at": "2020-03-25T13:24:38+00:00",
        "comments_count": [
            "Chuckie-He",
            "huangjun12",
            "li-900406",
            "huangjun12",
            "xueyingliu",
            "huangjun12",
            "xueyingliu",
            "liu824",
            "wwdok"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4424,
        "title": "models/PaddleNLP/sentiment_classification/ 中找不到 net.py",
        "body": "",
        "state": "closed",
        "user": "lguowang",
        "closed_by": "lguowang",
        "created_at": "2020-03-13T12:00:13+00:00",
        "updated_at": "2020-03-13T12:05:33+00:00",
        "closed_at": "2020-03-13T12:02:39+00:00",
        "comments_count": [
            "lguowang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4427,
        "title": "word2vec_skipgram Fine-tune问题",
        "body": "小白求助，我想直接使用word2vec_skipgram里边的词向量，但是里面有些业务名词没有，看介绍上说word2vec_skipgram是可以进行Fine-tune的，那么我可以使用自己的语料进行增量训练吗？如果可以的话，我该怎么做，没找到帮助文档，还请各位大佬帮忙！",
        "state": "open",
        "user": "yudian931122",
        "closed_by": null,
        "created_at": "2020-03-13T12:22:20+00:00",
        "updated_at": "2024-02-26T05:12:41+00:00",
        "closed_at": null,
        "comments_count": [
            "LDOUBLEV",
            "yudian931122",
            "kuke",
            "yudian931122",
            "yudian931122"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4432,
        "title": "关于xlnet",
        "body": "请问是否有xlnet的中文预训练模型，或将tensorflow的xlnet预训模型转换为paddle模型的方法？谢谢！",
        "state": "closed",
        "user": "chicleee",
        "closed_by": "chicleee",
        "created_at": "2020-03-14T13:11:33+00:00",
        "updated_at": "2020-05-31T02:42:02+00:00",
        "closed_at": "2020-05-31T02:42:02+00:00",
        "comments_count": [
            "123malin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4434,
        "title": "python ppdet/modeling/tests/test_architectures.py报错",
        "body": "快速安装后，运行python ppdet/modeling/tests/test_architectures.py，下边是运行结果\r\nEE....EE....\r\n\r\n```\r\n======================================================================\r\nERROR: test_test (__main__.TestCascadeRCNN)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 50, in test_test\r\n    test_fetches = model.eval(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 286, in eval\r\n    return self.build(feed_vars, 'test')\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 105, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1880, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::GetBroadcastDimsArrays(paddle::framework::DDim const&, paddle::framework::DDim const&, int*, int*, int*, int, int)\r\n3   paddle::operators::ElementwiseOp::InferShape(paddle::framework::InferShapeContext*) const\r\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 105, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 286, in eval\r\n    return self.build(feed_vars, 'test')\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 50, in test_test\r\n    test_fetches = model.eval(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run\r\n    testMethod()\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 648, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/runner.py\", line 176, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 255, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 94, in __init__\r\n    self.runTests()\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 79, in <module>\r\n    unittest.main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [-1, 256, 100, 167] and the shape of Y = [-1, 256, 100, 168]. Received [167] in X is not equal to [168] in Y at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:145)\r\n  [operator < elementwise_add > error]\r\n\r\n======================================================================\r\nERROR: test_train (__main__.TestCascadeRCNN)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 43, in test_train\r\n    train_fetches = model.train(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 281, in train\r\n    return self.build(feed_vars, 'train')\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 105, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1880, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::GetBroadcastDimsArrays(paddle::framework::DDim const&, paddle::framework::DDim const&, int*, int*, int*, int, int)\r\n3   paddle::operators::ElementwiseOp::InferShape(paddle::framework::InferShapeContext*) const\r\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 105, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/cascade_rcnn.py\", line 281, in train\r\n    return self.build(feed_vars, 'train')\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 43, in test_train\r\n    train_fetches = model.train(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run\r\n    testMethod()\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 648, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/runner.py\", line 176, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 255, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 94, in __init__\r\n    self.runTests()\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 79, in <module>\r\n    unittest.main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [-1, 256, 100, 167] and the shape of Y = [-1, 256, 100, 168]. Received [167] in X is not equal to [168] in Y at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:145)\r\n  [operator < elementwise_add > error]\r\n\r\n======================================================================\r\nERROR: test_test (__main__.TestRetinaNet)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 50, in test_test\r\n    test_fetches = model.eval(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 89, in eval\r\n    return self.build(feed_vars, 'test')\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 71, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1880, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::GetBroadcastDimsArrays(paddle::framework::DDim const&, paddle::framework::DDim const&, int*, int*, int*, int, int)\r\n3   paddle::operators::ElementwiseOp::InferShape(paddle::framework::InferShapeContext*) const\r\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 71, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 89, in eval\r\n    return self.build(feed_vars, 'test')\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 50, in test_test\r\n    test_fetches = model.eval(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run\r\n    testMethod()\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 648, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/runner.py\", line 176, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 255, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 94, in __init__\r\n    self.runTests()\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 79, in <module>\r\n    unittest.main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [-1, 256, 100, 167] and the shape of Y = [-1, 256, 100, 168]. Received [167] in X is not equal to [168] in Y at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:145)\r\n  [operator < elementwise_add > error]\r\n\r\n======================================================================\r\nERROR: test_train (__main__.TestRetinaNet)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 43, in test_train\r\n    train_fetches = model.train(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 86, in train\r\n    return self.build(feed_vars, 'train')\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 71, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 1880, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::GetBroadcastDimsArrays(paddle::framework::DDim const&, paddle::framework::DDim const&, int*, int*, int*, int, int)\r\n3   paddle::operators::ElementwiseOp::InferShape(paddle::framework::InferShapeContext*) const\r\n4   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/gta/.local/virtualenvs/pd_1/lib/python3.5/site-packages/paddle/fluid/layers/math_op_patch.py\", line 243, in __impl__\r\n    attrs={'axis': axis})\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 93, in _add_topdown_lateral\r\n    return lateral + topdown\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/backbones/fpn.py\", line 144, in get_output\r\n    top_output)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 71, in build\r\n    body_feats, spatial_scale = self.fpn.get_output(body_feats)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/architectures/retinanet.py\", line 86, in train\r\n    return self.build(feed_vars, 'train')\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 43, in test_train\r\n    train_fetches = model.train(feed_vars)\r\n  File \"/home/gta/MaskDetection/objdetection/models/PaddleCV/PaddleDetection/ppdet/modeling/tests/decorator_helper.py\", line 29, in __fn__\r\n    fn(*args, **kwargs)\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run\r\n    testMethod()\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 648, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python3.5/unittest/runner.py\", line 176, in run\r\n    test(result)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 255, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 94, in __init__\r\n    self.runTests()\r\n  File \"ppdet/modeling/tests/test_architectures.py\", line 79, in <module>\r\n    unittest.main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: ShapeError: broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [-1, 256, 100, 167] and the shape of Y = [-1, 256, 100, 168]. Received [167] in X is not equal to [168] in Y at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:145)\r\n  [operator < elementwise_add > error]\r\n\r\n----------------------------------------------------------------------\r\nRan 12 tests in 3.053s\r\n\r\nFAILED (errors=4)\r\n\r\n```\r\n\r\n测试都没通过，，，，什么问题？？？\r\n",
        "state": "closed",
        "user": "Suyn",
        "closed_by": "qingqing01",
        "created_at": "2020-03-16T06:13:00+00:00",
        "updated_at": "2020-03-17T03:02:14+00:00",
        "closed_at": "2020-03-17T03:02:13+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4438,
        "title": "如果下载simnet其他预训练模型？",
        "body": "download_pretrained_model.sh 文件中，只提供了simnet_bow-pairwise模型下载。\r\n请问，如果下载其他模型文件？ 比如simnet lstm pairwis预训练模型。 ",
        "state": "open",
        "user": "bluelml",
        "closed_by": null,
        "created_at": "2020-03-17T08:22:46+00:00",
        "updated_at": "2024-02-26T05:12:39+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4440,
        "title": "Paddle里面的Detection什么时候能够支持DALI？",
        "body": "我们这边期望训练速度能够更快一点，想问下paddle的检测什么时候能够支持dali？",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2020-03-17T08:54:35+00:00",
        "updated_at": "2024-02-26T05:12:38+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4441,
        "title": "运行tools/eval.py报错",
        "body": "模型成功使用tools/train.py训练，\r\n但是运行tools/eval.py报错。\r\n运行代码：\r\n```\r\n‘%cd ~\r\n%cd PaddleDetection/\r\n!export CUDA_VISIBLE_DEVICES=0\r\n!python -u tools/eval.py -c configs/yolov3_darknet_voc.yml \\\r\n                    -o weights=output/yolov3_darknet_voc/model_final/model_final \\’\r\n```\r\n\r\n出错信息如下：\r\n```\r\n/home/aistudio\r\n/home/aistudio/PaddleDetection\r\n2020-03-17 19:17:51,257-INFO: 555 samples in file dataset/underwater_data/val.txt\r\n2020-03-17 19:17:51,258-INFO: places would be ommited when DataLoader is not iterable\r\nW0317 19:17:52.077756   559 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0317 19:17:52.081887   559 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\n2020-03-17 19:17:53,552-INFO: Loading parameters from output/yolov3_darknet_voc/model_final/model_final...\r\nI0317 19:17:56.293087   559 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI0317 19:17:56.304033   559 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0317 19:17:56.312638   559 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0317 19:17:56.318989   559 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\n2020-03-17 19:17:56,902-INFO: Test iter 0\r\n2020-03-17 19:18:03,758-INFO: Test finish iter 69\r\n2020-03-17 19:18:03,759-INFO: Total number of images: 546, inference time: 73.04237257565066 fps.\r\n2020-03-17 19:18:03,759-INFO: Start evaluate...\r\n2020-03-17 19:18:04,487-INFO: Accumulating evaluatation results...\r\n2020-03-17 19:18:04,535-INFO: mAP(0.50, 11point) = 24.81\r\nterminate called without an active exception\r\nW0317 19:18:04.659145   628 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0317 19:18:04.659191   628 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0317 19:18:04.659196   628 init.cc:214] The detail failure signal is:\r\n\r\nW0317 19:18:04.659202   628 init.cc:217] *** Aborted at 1584443884 (unix time) try \"date -d @1584443884\" if you are using GNU date ***\r\nW0317 19:18:04.661578   628 init.cc:217] PC: @                0x0 (unknown)\r\nW0317 19:18:04.661710   628 init.cc:217] *** SIGABRT (@0x3e80000022f) received by PID 559 (TID 0x7f7e2d7fe700) from PID 559; stack trace: ***\r\nW0317 19:18:04.663616   628 init.cc:217]     @     0x7f7f12139390 (unknown)\r\nW0317 19:18:04.665478   628 init.cc:217]     @     0x7f7f11d93428 gsignal\r\nW0317 19:18:04.667274   628 init.cc:217]     @     0x7f7f11d9502a abort\r\nW0317 19:18:04.668453   628 init.cc:217]     @     0x7f7ed2d0084a __gnu_cxx::__verbose_terminate_handler()\r\nW0317 19:18:04.669427   628 init.cc:217]     @     0x7f7ed2cfef47 __cxxabiv1::__terminate()\r\nW0317 19:18:04.670521   628 init.cc:217]     @     0x7f7ed2cfef7d std::terminate()\r\nW0317 19:18:04.671491   628 init.cc:217]     @     0x7f7ed2cfec5a __gxx_personality_v0\r\nW0317 19:18:04.672348   628 init.cc:217]     @     0x7f7ed2ff1b97 _Unwind_ForcedUnwind_Phase2\r\nW0317 19:18:04.673223   628 init.cc:217]     @     0x7f7ed2ff1e7d _Unwind_ForcedUnwind\r\nW0317 19:18:04.674988   628 init.cc:217]     @     0x7f7f12138070 __GI___pthread_unwind\r\nW0317 19:18:04.676718   628 init.cc:217]     @     0x7f7f12130845 __pthread_exit\r\nW0317 19:18:04.677220   628 init.cc:217]     @     0x55b12b95be59 PyThread_exit_thread\r\nW0317 19:18:04.677367   628 init.cc:217]     @     0x55b12b7e1c17 PyEval_RestoreThread.cold.798\r\nW0317 19:18:04.677793   628 init.cc:217]     @     0x7f7ec7b8008d (unknown)\r\nW0317 19:18:04.678279   628 init.cc:217]     @     0x55b12b8dd7e6 _PyMethodDef_RawFastCallKeywords\r\nW0317 19:18:04.678741   628 init.cc:217]     @     0x55b12b8dd861 _PyCFunction_FastCallKeywords\r\nW0317 19:18:04.679210   628 init.cc:217]     @     0x55b12b9497cc _PyEval_EvalFrameDefault\r\nW0317 19:18:04.679639   628 init.cc:217]     @     0x55b12b88d539 _PyEval_EvalCodeWithName\r\nW0317 19:18:04.680107   628 init.cc:217]     @     0x55b12b88e635 _PyFunction_FastCallDict\r\nW0317 19:18:04.680549   628 init.cc:217]     @     0x55b12b8ace53 _PyObject_Call_Prepend\r\nW0317 19:18:04.680773   628 init.cc:217]     @     0x55b12b8e4a3a slot_tp_call\r\nW0317 19:18:04.681227   628 init.cc:217]     @     0x55b12b8e58fb _PyObject_FastCallKeywords\r\nW0317 19:18:04.681691   628 init.cc:217]     @     0x55b12b948e86 _PyEval_EvalFrameDefault\r\nW0317 19:18:04.682130   628 init.cc:217]     @     0x55b12b88e56b _PyFunction_FastCallDict\r\nW0317 19:18:04.682551   628 init.cc:217]     @     0x55b12b8ace53 _PyObject_Call_Prepend\r\nW0317 19:18:04.682771   628 init.cc:217]     @     0x55b12b8e4a3a slot_tp_call\r\nW0317 19:18:04.683207   628 init.cc:217]     @     0x55b12b8e58fb _PyObject_FastCallKeywords\r\nW0317 19:18:04.683665   628 init.cc:217]     @     0x55b12b9496e8 _PyEval_EvalFrameDefault\r\nW0317 19:18:04.684094   628 init.cc:217]     @     0x55b12b88d539 _PyEval_EvalCodeWithName\r\nW0317 19:18:04.684522   628 init.cc:217]     @     0x55b12b88e635 _PyFunction_FastCallDict\r\nW0317 19:18:04.684940   628 init.cc:217]     @     0x55b12b8ace53 _PyObject_Call_Prepend\r\nW0317 19:18:04.685431   628 init.cc:217]     @     0x55b12b89fdbe PyObject_Call\r\nAborted (core dumped)\r\n```",
        "state": "open",
        "user": "COST-97",
        "closed_by": null,
        "created_at": "2020-03-17T11:27:23+00:00",
        "updated_at": "2024-02-26T05:12:37+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "COST-97"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4445,
        "title": "DQN model找不到在哪？",
        "body": null,
        "state": "open",
        "user": "hp-cuiwb",
        "closed_by": null,
        "created_at": "2020-03-18T07:38:40+00:00",
        "updated_at": "2024-02-26T05:12:34+00:00",
        "closed_at": null,
        "comments_count": [
            "kuke"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4442,
        "title": "yml文件里面模型超参数配置",
        "body": "可否把yml文件里面模型的超参数的设计原则，设计方案阐述一下（可以使用yolov3或faster r-cnn建立一个demo，详细说明各个参数的**作用，取值范围，实际取值对模型的影响**等等）。",
        "state": "open",
        "user": "COST-97",
        "closed_by": null,
        "created_at": "2020-03-17T11:32:20+00:00",
        "updated_at": "2024-02-26T05:12:36+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "COST-97"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4446,
        "title": "Pyramidbox中并没有body部分处理？",
        "body": "论文中有半监督的head和body引入，但是代码中只看到head，是我看漏了吗？",
        "state": "open",
        "user": "heiheiya",
        "closed_by": null,
        "created_at": "2020-03-18T08:31:31+00:00",
        "updated_at": "2020-03-20T06:20:02+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "heiheiya"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4449,
        "title": "动态图预训练模型",
        "body": "我在[这里](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/README.md#%E5%B7%B2%E5%8F%91%E5%B8%83%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E6%80%A7%E8%83%BD),下载了vgg16的预训练模型,请问能否转化使得它能导入动态图里进行预训练",
        "state": "open",
        "user": "Quan-zzx",
        "closed_by": null,
        "created_at": "2020-03-19T04:18:06+00:00",
        "updated_at": "2020-03-23T13:00:31+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain",
            "Quan-zzx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4474,
        "title": "KT-NET训练报错，显存不足",
        "body": "KT-NET训练同时使用WordNet和nell，directly fine-tuning ，报错，错误如下：\r\n![1](https://user-images.githubusercontent.com/14139827/77328863-1c71ef80-6d58-11ea-84d7-51c155f0bde1.png)\r\n![image](https://user-images.githubusercontent.com/14139827/77329257-b5086f80-6d58-11ea-8946-3b6975d524a7.png)\r\n\r\n已将类似issues提到的解决方法均尝试了一遍，无果：\r\n环境变量FLAGS_fraction_of_gpu_memory_to_use从0一直到1都尝试过；\r\nbatch_size已设为1；\r\nFLAGS_eager_delete_tensor_gb以及FLAGS_fast_eager_deletion_mode均已经设置；\r\n\r\n以下是机器基本情况\r\n![2](https://user-images.githubusercontent.com/14139827/77329217-a621bd00-6d58-11ea-8891-61621470d1d9.png)\r\n多谢各位！",
        "state": "open",
        "user": "callmeivy",
        "closed_by": null,
        "created_at": "2020-03-23T14:51:32+00:00",
        "updated_at": "2024-02-26T05:12:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4452,
        "title": "使用关键点检测human_pose_estimation模型时val和test脚本报数据方面的错误",
        "body": "### 环境：\r\n\r\nUbuntu18.04\r\nCUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\ncuDNN Version: 7.3\r\nRTX2080TI\r\npaddle.1.6.1\r\npython3.7\r\npaddel.models版本为develop\r\n数据集用的https://aistudio.baidu.com/aistudio/projectDetail/122271这里提供的数据集\r\n==================================\r\n\r\n### 问题1\r\n\r\n将mpii的标注下载下来后只有.mat文件，如何转换成lib/mpii_reader.py支持的格式。\r\n\r\n### 问题2\r\n\r\n使用上述数据集执行test.py和val.py报错。\r\n\r\n执行val.py\r\n\r\n`CUDA_VISIBLE_DEVICES=1 python val.py --dataset coco --checkpoint output/simplebase-coco/90 --data_root data/coco`\r\n\r\n报错\r\n\r\n`-----------  Configuration Arguments -----------\r\nbatch_size: 128\r\ncheckpoint: output/simplebase-coco/90\r\ndata_root: data/coco\r\ndataset: coco\r\nflip_test: True\r\nkp_dim: 17\r\nlr: 0.001\r\nlr_strategy: piecewise_decay\r\nnum_epochs: 140\r\npost_process: True\r\npretrained_model: None\r\nshift_heatmap: True\r\ntotal_images: 6108\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0320 02:40:14.122923 20034 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0320 02:40:14.125887 20034 device_context.cc:243] device: 0, cuDNN Version: 7.3.\r\nW0320 02:40:14.125910 20034 device_context.cc:269] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.4, but CUDNN version in your machine is 7.3, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nloading annotations into memory...\r\nDone (t=0.02s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'person']\r\n=> num_images: 500\r\ngenerating coco gt_db...\r\n=> num db: 430\r\n=> num selected db: 416\r\nTraceback (most recent call last):\r\n  File \"val.py\", line 229, in <module>\r\n    valid(args)\r\n  File \"val.py\", line 135, in valid\r\n    for batch_id, meta in enumerate(valid_reader()):\r\n  File \"/home/ldk/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/batch.py\", line 58, in batch_reader\r\n    for instance in r:\r\n  File \"/home/ldk/myProjects/human_pose_estimation/lib/coco_reader.py\", line 352, in pop\r\n    yield mapper(x)\r\n  File \"/home/ldk/myProjects/human_pose_estimation/lib/coco_reader.py\", line 255, in data_augmentation\r\n    flags=cv2.INTER_LINEAR)\r\ncv2.error: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/imgwarp.cpp:2610: error: (-215:Assertion failed) src.cols > 0 && src.rows > 0 in function 'warpAffine'`\r\n\r\n执行test.py\r\n\r\n`CUDA_VISIBLE_DEVICES=1 python test.py --dataset coco --checkpoint output/simplebase-coco/90`\r\n\r\n报错\r\n\r\n`-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ncheckpoint: output/simplebase-coco/90\r\ndataset: coco\r\nflip_test: True\r\nkp_dim: 17\r\nshift_heatmap: True\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0320 02:44:44.987195 21398 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0320 02:44:44.990037 21398 device_context.cc:243] device: 0, cuDNN Version: 7.3.\r\nW0320 02:44:44.990063 21398 device_context.cc:269] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.4, but CUDNN version in your machine is 7.3, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nloading annotations into memory...\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 132, in <module>\r\n    test(args)\r\n  File \"test.py\", line 94, in test\r\n    for batch_id, data in enumerate(test_reader()):\r\n  File \"/home/ldk/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/batch.py\", line 58, in batch_reader\r\n    for instance in r:\r\n  File \"/home/ldk/myProjects/human_pose_estimation/lib/coco_reader.py\", line 362, in pop\r\n    for i, x in enumerate(reader()):\r\n  File \"/home/ldk/myProjects/human_pose_estimation/lib/coco_reader.py\", line 297, in reader\r\n    coco = COCO(file_name)\r\n  File \"/home/ldk/.local/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg/pycocotools/coco.py\", line 84, in __init__\r\n    dataset = json.load(open(annotation_file, 'r'))\r\nFileNotFoundError: [Errno 2] No such file or directory: 'data/coco/annotations/image_info_test2017.json'`\r\n\r\n",
        "state": "open",
        "user": "lidingke",
        "closed_by": null,
        "created_at": "2020-03-20T07:00:38+00:00",
        "updated_at": "2024-02-26T05:12:31+00:00",
        "closed_at": null,
        "comments_count": [
            "JiaXiao243",
            "lzp1317",
            "lidingke",
            "qingqing01",
            "a310694487"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4453,
        "title": "关于metric learning中的reader.py",
        "body": "版本、环境信息：\r\n1）PaddlePaddle版本：1.6\r\n2）CPU：CPU\r\n3）GPU：无\r\n4）系统环境：Linux python2.7\r\nmetric learning中的reader.py源码如下：createreader中的keep_order\r\n`\r\ndef createreader(settings, mode):\r\n    def metric_reader():\r\n        if mode == 'train':\r\n            train_data, train_image_list = init_sop('train')\r\n            loss_name = settings.loss_name\r\n            if loss_name in [\"softmax\", \"arcmargin\"]:\r\n                return arcmargin_iterator(train_image_list, settings)()\r\n            elif loss_name == 'triplet':\r\n                return triplet_iterator(train_data, settings)()\r\n            else:\r\n                return common_iterator(train_data, settings)()\r\n        elif mode == 'val':\r\n            val_data, val_image_list = init_sop('val')\r\n            return image_iterator(val_image_list, 'val')()\r\n        else:\r\n            test_image_list = init_sop('test')\r\n            return image_iterator(test_image_list, 'test')()\r\n\r\n    image_shape = settings.image_shape.split(',')\r\n    assert(image_shape[1] == image_shape[2])\r\n    image_size = int(image_shape[2])\r\n    keep_order = False if mode != 'train' or settings.loss_name in ['softmax', 'arcmargin'] else True\r\n    image_mapper = functools.partial(process_image,\r\n            mode=mode, color_jitter=False, rotate=False, crop_size=image_size)\r\n    reader = paddle.reader.xmap_readers(\r\n            image_mapper, metric_reader, 8, 1000, order=keep_order)\r\n    return reader                                                                              \r\n`\r\n问题描述：\r\nkeep_order = False if mode != 'train' or settings.loss_name in ['softmax', 'arcmargin'] else True中当非训练模式置keep_order为False的作用是什么？",
        "state": "open",
        "user": "linshufei",
        "closed_by": null,
        "created_at": "2020-03-20T07:07:43+00:00",
        "updated_at": "2024-02-26T05:12:30+00:00",
        "closed_at": null,
        "comments_count": [
            "kebinC",
            "linshufei",
            "linshufei",
            "kebinC"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4477,
        "title": "OCR 中数据的label为什么不是从0开始标记的？",
        "body": "在 https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/ocr_recognition \r\n在这个OCR模型中，提供的数据集的标签是从15开始标记的，而且一共就只有62个类别，但是模型设置却是95个类别，这是为什么呢？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-03-25T06:38:50+00:00",
        "updated_at": "2020-03-26T07:41:14+00:00",
        "closed_at": "2020-03-26T07:41:14+00:00",
        "comments_count": [
            "LDOUBLEV",
            "yeyupiaoling",
            "LDOUBLEV",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4481,
        "title": "我想问问paddle训练好的模型可以用部署在java生产环境中吗？",
        "body": null,
        "state": "open",
        "user": "yw1991",
        "closed_by": null,
        "created_at": "2020-03-26T02:41:36+00:00",
        "updated_at": "2024-02-26T05:12:27+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4483,
        "title": "想在AI studio上跑pointnet，但是环境里没有nvcc，无法编译动态库",
        "body": "pointnet++里有几个自定义op需要将c++和cuda代码编译成动态库，需要通过g++/nvcc编译，但是aistudio环境里没有nvcc，求解。",
        "state": "open",
        "user": "LLChocolate",
        "closed_by": null,
        "created_at": "2020-03-26T05:30:10+00:00",
        "updated_at": "2024-02-26T05:12:26+00:00",
        "closed_at": null,
        "comments_count": [
            "alfredtorres",
            "NHZlX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4486,
        "title": "Compiled with WITH_GPU, but no GPU found in runtime",
        "body": "基于paddlepaddle/paddle:1.5.2-gpu-cuda9.0-cudnn7镜像构建的新镜像，\r\n<img width=\"958\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/34512369/77643648-b6c17580-6f9a-11ea-8575-7aab50149e65.png\">\r\n系统信息：\r\n<img width=\"537\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/34512369/77643867-0f910e00-6f9b-11ea-956e-8fd622cd3019.png\">\r\n\r\n[work@yq01-gpu-yq-adu-1-28 paddleflow]$ uname -a\r\nLinux yq01-gpu-yq-adu-1-28.epc.baidu.com 3.10.0_3-0-0-15 #1 SMP Fri Jan 12 18:18:11 CST 2018 x86_64 GNU/Linux\r\n<img width=\"1300\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/34512369/77645706-22f1a880-6f9e-11ea-97e0-10d375e53ff8.png\">\r\n",
        "state": "open",
        "user": "HaozhengAN",
        "closed_by": null,
        "created_at": "2020-03-26T11:48:27+00:00",
        "updated_at": "2024-02-26T05:12:25+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "HaozhengAN",
            "JepsonWong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4488,
        "title": "PaddleNLP的sentiment_classification官方例程报错",
        "body": "按照例程运行，报错。\r\naistudio@jupyter-256968-332689:~/models/PaddleNLP/sentiment_classification$ sh run_ernie.sh train\r\n['/home/aistudio/models/PaddleNLP/sentiment_classification', '/opt/conda/envs/python35-paddle120-env/lib/python37.zip', '/opt/conda/envs/python35-paddle120-env/lib/python3.7', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/lib-dynload', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages', '../shared_modules/models/classification/', '../shared_modules/']\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 4\r\ncheckpoints: ./save_models\r\ndata_dir: None\r\ndev_set: ./senta_data/dev.tsv\r\ndo_infer: False\r\ndo_lower_case: True\r\ndo_save_inference_model: True\r\ndo_train: True\r\ndo_val: True\r\nenable_ce: False\r\nepoch: 2\r\nernie_config_path: ./senta_model/ernie_pretrain_model/ernie_config.json\r\ninference_model_dir: None\r\ninit_checkpoint: ./senta_model/ernie_pretrain_model/params\r\nlabel_map_config: None\r\nlr: 5e-05\r\nmax_seq_len: 256\r\nmodel_type: ernie_bilstm\r\nnum_labels: 2\r\nrandom_seed: 1\r\nsave_steps: 5000\r\nsenta_config_path: None\r\nskip_steps: 10\r\ntask_name: None\r\ntest_set: ./senta_data/test.tsv\r\ntrain_set: ./senta_data/train.tsv\r\nuse_cuda: True\r\nuse_paddle_hub: False\r\nvalidation_steps: 5000\r\nverbose: True\r\nvocab_path: ./senta_model/ernie_pretrain_model/vocab.txt\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\nhidden_act: relu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nmax_position_embeddings: 513\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\ntype_vocab_size: 2\r\nvocab_size: 18000\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 9600\r\nMax train steps: 4800\r\nTheoretical memory usage in training: 5728.860 - 6001.662 MB\r\nW0327 11:31:43.733820 27852 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0327 11:31:43.737951 27852 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\nW0327 11:31:43.738011 27852 device_context.cc:271] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.3, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\n2020-03-27 11:31:45,428-WARNING: ./senta_model/ernie_pretrain_model/params/checkpoint.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-27 11:31:45,428-WARNING: ./senta_model/ernie_pretrain_model/params/checkpoint.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-27 11:31:45,432-WARNING: ./senta_model/ernie_pretrain_model/params.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-27 11:31:45,432-WARNING: ./senta_model/ernie_pretrain_model/params.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-27 11:31:45,443-WARNING: variable file [ ./senta_model/ernie_pretrain_model/params/mask_lm_out_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@sent_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pos_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pre_encoder_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pooled_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/reduce_mean_0.tmp_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/mask_lm_trans_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/tmp_51 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pre_encoder_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@word_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/next_sent_3cls_fc.w_0 ./senta_model/ernie_pretrain_model/params/next_sent_3cls_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/mask_lm_trans_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pooled_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/__model__ ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/mask_lm_trans_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/mask_lm_trans_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@LR_DECAY_COUNTER@ ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_0.b_0 ] not used\r\n2020-03-27 11:31:45,443-WARNING: variable file [ ./senta_model/ernie_pretrain_model/params/mask_lm_out_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@sent_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pos_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pre_encoder_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pooled_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/reduce_mean_0.tmp_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/mask_lm_trans_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/tmp_51 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pre_encoder_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@word_embedding ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/next_sent_3cls_fc.w_0 ./senta_model/ernie_pretrain_model/params/next_sent_3cls_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/mask_lm_trans_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@pooled_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/__model__ ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/mask_lm_trans_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/mask_lm_trans_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@LR_DECAY_COUNTER@ ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_multi_head_att_value_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_5_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_key_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_9_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_post_ffn_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_key_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_1.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_2_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_post_att_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_0_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_multi_head_att_value_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_6_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_ffn_fc_1.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_8_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_11_ffn_fc_0.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_output_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_ffn_fc_0.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_3_post_ffn_layer_norm_bias ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_10_post_att_layer_norm_scale ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_query_fc.w_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_4_multi_head_att_output_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_1_multi_head_att_query_fc.b_0 ./senta_model/ernie_pretrain_model/params/@HUB_ernie-stable@encoder_layer_7_ffn_fc_0.b_0 ] not used\r\nLoad model from ./senta_model/ernie_pretrain_model/params\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_ernie_classifier.py\", line 379, in <module>\r\n    main(args)\r\n  File \"run_ernie_classifier.py\", line 318, in main\r\n    return_numpy=False)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 831, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 905, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n5   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 733, in _init_non_iterable\r\n    outputs={'Out': self._feed_list})\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 646, in __init__\r\n    self._init_non_iterable()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 280, in from_generator\r\n    iterable, return_list)\r\n  File \"run_ernie_classifier.py\", line 56, in ernie_pyreader\r\n    use_double_buffer=False)\r\n  File \"run_ernie_classifier.py\", line 196, in main\r\n    args, pyreader_name='train_pyreader')\r\n  File \"run_ernie_classifier.py\", line 379, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: The feeded Variable src_ids should have dimensions = 3, shape = [-1, 256, 1], but received feeded shape [4, 191, 1]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:133)\r\n  [operator < read > error]\r\nterminate called without an active exception\r\nW0327 11:31:46.799196 27948 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0327 11:31:46.799240 27948 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0327 11:31:46.799247 27948 init.cc:214] The detail failure signal is:\r\n\r\nW0327 11:31:46.799260 27948 init.cc:217] *** Aborted at 1585279906 (unix time) try \"date -d @1585279906\" if you are using GNU date ***\r\nW0327 11:31:46.800933 27948 init.cc:217] PC: @                0x0 (unknown)\r\nW0327 11:31:46.801038 27948 init.cc:217] *** SIGABRT (@0x3e800006ccc) received by PID 27852 (TID 0x7f493d145700) from PID 27852; stack trace: ***\r\nW0327 11:31:46.802203 27948 init.cc:217]     @     0x7f4959f91390 (unknown)\r\nW0327 11:31:46.803315 27948 init.cc:217]     @     0x7f4959beb428 gsignal\r\nW0327 11:31:46.804404 27948 init.cc:217]     @     0x7f4959bed02a abort\r\nW0327 11:31:46.805187 27948 init.cc:217]     @     0x7f491ab1984a __gnu_cxx::__verbose_terminate_handler()\r\nW0327 11:31:46.805850 27948 init.cc:217]     @     0x7f491ab17f47 __cxxabiv1::__terminate()\r\nW0327 11:31:46.806664 27948 init.cc:217]     @     0x7f491ab17f7d std::terminate()\r\nW0327 11:31:46.807369 27948 init.cc:217]     @     0x7f491ab17c5a __gxx_personality_v0\r\nW0327 11:31:46.808004 27948 init.cc:217]     @     0x7f491ae4ab97 _Unwind_ForcedUnwind_Phase2\r\nW0327 11:31:46.808630 27948 init.cc:217]     @     0x7f491ae4ae7d _Unwind_ForcedUnwind\r\nW0327 11:31:46.809741 27948 init.cc:217]     @     0x7f4959f90070 __GI___pthread_unwind\r\nW0327 11:31:46.810840 27948 init.cc:217]     @     0x7f4959f88845 __pthread_exit\r\nW0327 11:31:46.811084 27948 init.cc:217]     @     0x560d80438e59 PyThread_exit_thread\r\nW0327 11:31:46.811159 27948 init.cc:217]     @     0x560d802bec17 PyEval_RestoreThread.cold.798\r\nW0327 11:31:46.812208 27948 init.cc:217]     @     0x7f48f1492d49 pybind11::gil_scoped_release::~gil_scoped_release()\r\nW0327 11:31:46.812541 27948 init.cc:217]     @     0x7f48f143f704 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL22pybind11_init_core_avxERNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE60_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESY_\r\nW0327 11:31:46.813469 27948 init.cc:217]     @     0x7f48f14b10f1 pybind11::cpp_function::dispatcher()\r\nW0327 11:31:46.813761 27948 init.cc:217]     @     0x560d803ba744 _PyMethodDef_RawFastCallKeywords\r\nW0327 11:31:46.814002 27948 init.cc:217]     @     0x560d803ba861 _PyCFunction_FastCallKeywords\r\nW0327 11:31:46.814231 27948 init.cc:217]     @     0x560d804266e8 _PyEval_EvalFrameDefault\r\nW0327 11:31:46.814442 27948 init.cc:217]     @     0x560d8036a81a _PyEval_EvalCodeWithName\r\nW0327 11:31:46.814661 27948 init.cc:217]     @     0x560d8036b635 _PyFunction_FastCallDict\r\nW0327 11:31:46.814884 27948 init.cc:217]     @     0x560d80423232 _PyEval_EvalFrameDefault\r\nW0327 11:31:46.815078 27948 init.cc:217]     @     0x560d803b9ccb _PyFunction_FastCallKeywords\r\nW0327 11:31:46.815299 27948 init.cc:217]     @     0x560d80421a93 _PyEval_EvalFrameDefault\r\nW0327 11:31:46.815492 27948 init.cc:217]     @     0x560d803b9ccb _PyFunction_FastCallKeywords\r\nW0327 11:31:46.815721 27948 init.cc:217]     @     0x560d80421a93 _PyEval_EvalFrameDefault\r\nW0327 11:31:46.815929 27948 init.cc:217]     @     0x560d8036b56b _PyFunction_FastCallDict\r\nW0327 11:31:46.816131 27948 init.cc:217]     @     0x560d80389e53 _PyObject_Call_Prepend\r\nW0327 11:31:46.816356 27948 init.cc:217]     @     0x560d8037cdbe PyObject_Call\r\nW0327 11:31:46.816448 27948 init.cc:217]     @     0x560d80479817 t_bootstrap\r\nW0327 11:31:46.816498 27948 init.cc:217]     @     0x560d80434788 pythread_wrapper\r\nW0327 11:31:46.817675 27948 init.cc:217]     @     0x7f4959f876ba start_thread\r\nAborted (core dumped)",
        "state": "open",
        "user": "CVsaber",
        "closed_by": null,
        "created_at": "2020-03-27T03:40:37+00:00",
        "updated_at": "2020-03-30T14:40:28+00:00",
        "closed_at": null,
        "comments_count": [
            "IEnglishBad",
            "IEnglishBad"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4490,
        "title": "PointNet++编译失败",
        "body": "您好，我想在ai studio平台复现PointNet++，在编译自定义OP时失败。输出如下：\r\n```\r\naistudio@jupyter-259415-338227:~/work/PointNet2/ext_op/src$ sh make.sh\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/libs\r\ngather_point_op.cc:97:14: error: ‘GradOpPtr’ has not been declared\r\n   void Apply(GradOpPtr<T> op) const override {\r\n              ^\r\ngather_point_op.cc:97:23: error: expected ‘,’ or ‘...’ before ‘<’ token\r\n   void Apply(GradOpPtr<T> op) const override {\r\n                       ^\r\ngather_point_op.cc: In member function ‘void paddle::operators::GatherPointGradDescMaker<T>::Apply(int) const’:\r\ngather_point_op.cc:98:5: error: ‘op’ was not declared in this scope\r\n     op->SetType(\"gather_point_grad\");\r\n     ^\r\ngather_point_op.cc: In instantiation of ‘class paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>’:\r\n/usr/include/c++/5/type_traits:1459:12:   required from ‘struct std::is_base_of<paddle::framework::OperatorBase, paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc> >’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:74:25:   required from ‘constexpr const bool paddle::framework::details::internal::IsMatchedBaseTypeImpl<paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>, 0, true>::kValue’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:86:63:   required from ‘constexpr bool paddle::framework::details::internal::IsMatchedBaseType() [with T = paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>; int kPos = 0]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:118:53:   required by substitution of ‘template<class T> using OpInfoFillTypeGetter = paddle::framework::details::internal::OpInfoFillTypeGetterImpl<T, 0, 8, false, IsMatchedBaseType<T, 0>()> [with T = paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:125:47:   required from ‘static constexpr paddle::framework::details::OpInfoFillType paddle::framework::details::OpInfoFillTypeID<T>::ID() [with T = paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   recursively required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 1ul; ARGS = {paddle::operators::GatherPointOp, paddle::operators::GatherPointOpMaker, paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GatherPointGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 0ul; ARGS = {paddle::operators::GatherPointOp, paddle::operators::GatherPointOpMaker, paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GatherPointGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/op_registry.h:63:5:   required from ‘paddle::framework::OperatorRegistrar<ARGS>::OperatorRegistrar(const char*) [with ARGS = {paddle::operators::GatherPointOp, paddle::operators::GatherPointOpMaker, paddle::operators::GatherPointGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GatherPointGradDescMaker<paddle::imperative::OpBase>}]’\r\ngather_point_op.cc:111:1:   required from here\r\ngather_point_op.cc:97:8: error: ‘void paddle::operators::GatherPointGradDescMaker<T>::Apply(int) const [with T = paddle::framework::OpDesc]’ marked ‘override’, but does not override\r\n   void Apply(GradOpPtr<T> op) const override {\r\n        ^\r\ngroup_points_op.cc:105:14: error: ‘GradOpPtr’ has not been declared\r\n   void Apply(GradOpPtr<T> op) const override {\r\n              ^\r\ngroup_points_op.cc:105:23: error: expected ‘,’ or ‘...’ before ‘<’ token\r\n   void Apply(GradOpPtr<T> op) const override {\r\n                       ^\r\ngroup_points_op.cc: In member function ‘void paddle::operators::GroupPointsGradDescMaker<T>::Apply(int) const’:\r\ngroup_points_op.cc:106:5: error: ‘op’ was not declared in this scope\r\n     op->SetType(\"group_points_grad\");\r\n     ^\r\ngroup_points_op.cc: In instantiation of ‘class paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>’:\r\n/usr/include/c++/5/type_traits:1459:12:   required from ‘struct std::is_base_of<paddle::framework::OperatorBase, paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc> >’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:74:25:   required from ‘constexpr const bool paddle::framework::details::internal::IsMatchedBaseTypeImpl<paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>, 0, true>::kValue’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:86:63:   required from ‘constexpr bool paddle::framework::details::internal::IsMatchedBaseType() [with T = paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>; int kPos = 0]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:118:53:   required by substitution of ‘template<class T> using OpInfoFillTypeGetter = paddle::framework::details::internal::OpInfoFillTypeGetterImpl<T, 0, 8, false, IsMatchedBaseType<T, 0>()> [with T = paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:125:47:   required from ‘static constexpr paddle::framework::details::OpInfoFillType paddle::framework::details::OpInfoFillTypeID<T>::ID() [with T = paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   recursively required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 1ul; ARGS = {paddle::operators::GroupPointsOp, paddle::operators::GroupPointsOpMaker, paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GroupPointsGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 0ul; ARGS = {paddle::operators::GroupPointsOp, paddle::operators::GroupPointsOpMaker, paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GroupPointsGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/op_registry.h:63:5:   required from ‘paddle::framework::OperatorRegistrar<ARGS>::OperatorRegistrar(const char*) [with ARGS = {paddle::operators::GroupPointsOp, paddle::operators::GroupPointsOpMaker, paddle::operators::GroupPointsGradDescMaker<paddle::framework::OpDesc>, paddle::operators::GroupPointsGradDescMaker<paddle::imperative::OpBase>}]’\r\ngroup_points_op.cc:119:1:   required from here\r\ngroup_points_op.cc:105:8: error: ‘void paddle::operators::GroupPointsGradDescMaker<T>::Apply(int) const [with T = paddle::framework::OpDesc]’ marked ‘override’, but does not override\r\n   void Apply(GradOpPtr<T> op) const override {\r\n        ^\r\nthree_interp_op.cc:120:14: error: ‘GradOpPtr’ has not been declared\r\n   void Apply(GradOpPtr<T> op) const override {\r\n              ^\r\nthree_interp_op.cc:120:23: error: expected ‘,’ or ‘...’ before ‘<’ token\r\n   void Apply(GradOpPtr<T> op) const override {\r\n                       ^\r\nthree_interp_op.cc: In member function ‘void paddle::operators::ThreeInterpGradDescMaker<T>::Apply(int) const’:\r\nthree_interp_op.cc:121:5: error: ‘op’ was not declared in this scope\r\n     op->SetType(\"three_interp_grad\");\r\n     ^\r\nthree_interp_op.cc: In instantiation of ‘class paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>’:\r\n/usr/include/c++/5/type_traits:1459:12:   required from ‘struct std::is_base_of<paddle::framework::OperatorBase, paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc> >’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:74:25:   required from ‘constexpr const bool paddle::framework::details::internal::IsMatchedBaseTypeImpl<paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>, 0, true>::kValue’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:86:63:   required from ‘constexpr bool paddle::framework::details::internal::IsMatchedBaseType() [with T = paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>; int kPos = 0]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:118:53:   required by substitution of ‘template<class T> using OpInfoFillTypeGetter = paddle::framework::details::internal::OpInfoFillTypeGetterImpl<T, 0, 8, false, IsMatchedBaseType<T, 0>()> [with T = paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:125:47:   required from ‘static constexpr paddle::framework::details::OpInfoFillType paddle::framework::details::OpInfoFillTypeID<T>::ID() [with T = paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   recursively required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 1ul; ARGS = {paddle::operators::ThreeInterpOp, paddle::operators::ThreeInterpOpMaker, paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>, paddle::operators::ThreeInterpGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/details/op_registry.h:144:71:   required from ‘paddle::framework::details::OperatorRegistrarRecursive<I, false, ARGS ...>::OperatorRegistrarRecursive(const char*, paddle::framework::OpInfo*) [with long unsigned int I = 0ul; ARGS = {paddle::operators::ThreeInterpOp, paddle::operators::ThreeInterpOpMaker, paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>, paddle::operators::ThreeInterpGradDescMaker<paddle::imperative::OpBase>}]’\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/include/paddle/fluid/framework/op_registry.h:63:5:   required from ‘paddle::framework::OperatorRegistrar<ARGS>::OperatorRegistrar(const char*) [with ARGS = {paddle::operators::ThreeInterpOp, paddle::operators::ThreeInterpOpMaker, paddle::operators::ThreeInterpGradDescMaker<paddle::framework::OpDesc>, paddle::operators::ThreeInterpGradDescMaker<paddle::imperative::OpBase>}]’\r\nthree_interp_op.cc:135:1:   required from here\r\nthree_interp_op.cc:120:8: error: ‘void paddle::operators::ThreeInterpGradDescMaker<T>::Apply(int) const [with T = paddle::framework::OpDesc]’ marked ‘override’, but does not override\r\n   void Apply(GradOpPtr<T> op) const override {\r\n```\r\n我发现错误是因为下面这句\r\n```\r\ng++ farthest_point_sampling_op.cc farthest_point_sampling_op.cu.o gather_point_op.cc gather_point_op.cu.o group_points_op.cc group_points_op.cu.o query_ball_op.cu.o query_ball_op.cc three_interp_op.cu.o three_interp_op.cc three_nn_op.cu.o three_nn_op.cc -o pointnet_lib.so -DPADDLE_WITH_MKLDNN -shared -fPIC -std=c++11 -O0 -g \\\r\n  -I ${include_dir}/third_party/ \\\r\n  -I ${include_dir} \\\r\n  -L ${lib_dir} \\\r\n  -L /usr/local/cuda/lib64 -lpaddle_framework -lcudart\r\n```\r\n是不能在ai studio上编译吗？",
        "state": "closed",
        "user": "alfredtorres",
        "closed_by": "alfredtorres",
        "created_at": "2020-03-27T14:28:40+00:00",
        "updated_at": "2020-03-28T18:11:50+00:00",
        "closed_at": "2020-03-28T18:11:50+00:00",
        "comments_count": [
            "heavengate"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4492,
        "title": "Is the backbone frozen in yolov3 training?",
        "body": "I download the pre-trained models from [https://github.com/PaddlePaddle/models/blob/v1.4/PaddleCV/yolov3/weights/download.sh](https://github.com/PaddlePaddle/models/blob/v1.4/PaddleCV/yolov3/weights/download.sh).\r\n\r\nThe backbone part in yolov3.tar.gz has almost the same weights in darknet53.tar.gz. So I wonder whether the backbone part is frozen during the yolov3 training process. If so, is it helpful to better converge or achieve higher accuracy?\r\n",
        "state": "closed",
        "user": "jcdubron",
        "closed_by": "jcdubron",
        "created_at": "2020-03-30T08:59:55+00:00",
        "updated_at": "2020-04-30T14:50:17+00:00",
        "closed_at": "2020-04-30T14:50:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4487,
        "title": "文档错误",
        "body": "执行该脚本的理想输出为：\r\n```bash\r\n> sh get_data.sh\r\n\r\n上面脚本的名应该是sh download_data.sh",
        "state": "open",
        "user": "wanubias",
        "closed_by": null,
        "created_at": "2020-03-26T13:28:55+00:00",
        "updated_at": "2024-02-26T05:12:24+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX",
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4491,
        "title": "human_pose_estimation C++预测接口",
        "body": "你好，human_pose_estimation模型有C++预测接口吗",
        "state": "open",
        "user": "pele228",
        "closed_by": null,
        "created_at": "2020-03-30T01:46:21+00:00",
        "updated_at": "2024-02-26T05:12:21+00:00",
        "closed_at": null,
        "comments_count": [
            "ruyijidan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4496,
        "title": "pointnet++训练出了模型，怎么预测自己的数据 啊。",
        "body": "大佬们，pointnet++训练出了模型，怎么预测自己的数据 啊。哪位大佬救救我，有偿，qq：857832956",
        "state": "open",
        "user": "honggesmile",
        "closed_by": null,
        "created_at": "2020-03-31T06:24:43+00:00",
        "updated_at": "2024-02-26T05:12:19+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4494,
        "title": "Lac 词性分析无法处理包含 '/'的文本",
        "body": "lac.lexical_analysis(data={'text': ['胆囊结石/胆囊炎']})\r\n返回[{'word': ['胆囊结石', '/胆囊炎'], 'tag': ['nz', '胆囊炎']}]\r\n\r\nlac.lexical_analysis(data={'text': ['胆囊结石//胆囊炎']})\r\n返回[{'word': ['胆囊结石', '//胆囊炎'], 'tag': ['nz', '']}]\r\n\r\nlac.lexical_analysis(data={'text': ['胆囊结石/ 胆囊炎']})\r\n返回[{'word': ['胆囊结石', '/', ' ', '胆囊炎'], 'tag': ['nz', '', 'w', 'nz']}]",
        "state": "open",
        "user": "RickDYang",
        "closed_by": null,
        "created_at": "2020-03-31T02:27:10+00:00",
        "updated_at": "2020-03-31T06:04:58+00:00",
        "closed_at": null,
        "comments_count": [
            "RickDYang",
            "luotao1",
            "RickDYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4504,
        "title": "类BIM攻击中每次的迭代应该不更新模型参数，但是我们的实现是不是会更新参数？",
        "body": "```\r\n\r\nclass GradientMethodAttack(Attack):\r\n    \"\"\"\r\n    This class implements gradient attack method, and is the base of FGSM, BIM,\r\n    ILCM, etc.\r\n    \"\"\"\r\n\r\n    def __init__(self, model, support_targeted=True):\r\n        \"\"\"\r\n        :param model(model): The model to be attacked.\r\n        :param support_targeted(bool): Does this attack method support targeted.\r\n        \"\"\"\r\n        super(GradientMethodAttack, self).__init__(model)\r\n        self.support_targeted = support_targeted\r\n\r\n    def _apply(self,\r\n               adversary,\r\n               norm_ord=np.inf,\r\n               epsilons=0.01,\r\n               steps=1,\r\n               epsilon_steps=100):\r\n        \"\"\"\r\n        Apply the gradient attack method.\r\n        :param adversary(Adversary):\r\n            The Adversary object.\r\n        :param norm_ord(int):\r\n            Order of the norm, such as np.inf, 1, 2, etc. It can't be 0.\r\n        :param epsilons(list|tuple|int):\r\n            Attack step size (input variation).\r\n            Largest step size if epsilons is not iterable.\r\n        :param steps:\r\n            The number of attack iteration.\r\n        :param epsilon_steps:\r\n            The number of Epsilons' iteration for each attack iteration.\r\n        :return:\r\n            adversary(Adversary): The Adversary object.\r\n        \"\"\"\r\n        if norm_ord == 0:\r\n            raise ValueError(\"L0 norm is not supported!\")\r\n\r\n        if not self.support_targeted:\r\n            if adversary.is_targeted_attack:\r\n                raise ValueError(\r\n                    \"This attack method doesn't support targeted attack!\")\r\n\r\n        if not isinstance(epsilons, Iterable):\r\n            epsilons = np.linspace(0, epsilons, num=epsilon_steps)\r\n\r\n        pre_label = adversary.original_label\r\n        min_, max_ = self.model.bounds()\r\n\r\n        assert self.model.channel_axis() == adversary.original.ndim\r\n        assert (self.model.channel_axis() == 1 or\r\n                self.model.channel_axis() == adversary.original.shape[0] or\r\n                self.model.channel_axis() == adversary.original.shape[-1])\r\n\r\n        for epsilon in epsilons[:]:\r\n            step = 1\r\n            adv_img = adversary.original\r\n            if epsilon == 0.0:\r\n                continue\r\n            for i in range(steps):\r\n                if adversary.is_targeted_attack:\r\n                    gradient = -self.model.gradient(adv_img,\r\n                                                    adversary.target_label)\r\n                else:\r\n                    gradient = self.model.gradient(adv_img,\r\n                                                   adversary.original_label)\r\n                if norm_ord == np.inf:\r\n                    gradient_norm = np.sign(gradient)\r\n                else:\r\n                    gradient_norm = gradient / self._norm(\r\n                        gradient, ord=norm_ord)\r\n\r\n                adv_img = adv_img + epsilon * gradient_norm * (max_ - min_)\r\n                adv_img = np.clip(adv_img, min_, max_)\r\n                adv_label = np.argmax(self.model.predict(adv_img))\r\n                logging.info('step={}, epsilon = {:.5f}, pre_label = {}, '\r\n                             'adv_label={}'.format(step, epsilon, pre_label,\r\n                                                   adv_label))\r\n                if adversary.try_accept_the_example(adv_img, adv_label):\r\n                    return adversary\r\n                step += 1\r\n        return adversary\r\n\r\n```\r\n\r\n\r\n```\r\n    def gradient(self, data, label):\r\n        \"\"\"\r\n        Calculate the gradient of the cross-entropy loss w.r.t the image.\r\n\r\n        Args:\r\n            data(numpy.ndarray): input data with shape (size, height, width,\r\n            channels).\r\n            label(int): Label used to calculate the gradient.\r\n\r\n        Return:\r\n            numpy.ndarray: gradient of the cross-entropy loss w.r.t the image\r\n                with the shape (height, width, channel).\r\n        \"\"\"\r\n        scaled_data = self._process_input(data)\r\n\r\n        feeder = fluid.DataFeeder(\r\n            feed_list=[self._input_name, self._logits_name],\r\n            place=self._place,\r\n            program=self._program)\r\n\r\n        grad, = self._exe.run(self._program,\r\n                              feed=feeder.feed([(scaled_data, label)]),\r\n                              fetch_list=[self._gradient])\r\n        return grad.reshape(data.shape)\r\n```\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/adversarial/advbox/attacks/gradient_method.py#L95\r\n\r\n在多迭代攻击的算法中， 假设攻击迭代次数是20，那么这20次迭代中，模型的参数是不接受梯度更新的，只有输入的样本接收梯度，以形成攻击样本。\r\n但是我们的实现中， \r\n\r\n```self.model.gradient``` 会调用 ```self._exe.run```函数，即会更新模型参数，这样的实现是正确的吗？\r\n",
        "state": "open",
        "user": "OleNet",
        "closed_by": null,
        "created_at": "2020-04-01T08:51:55+00:00",
        "updated_at": "2024-02-26T05:12:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4493,
        "title": "使用ParallelExecutor单机多核训练，除速度外等价于加大batchsize么？",
        "body": "比如，`batchsize = 128`，`CPU_NUM = 8` 时，使用 `ParallelExecutor` 单机训练，除训练速度外，是否等价于 `batchsize = 128 * 8`，`CPU_NUM = 1` 的单机单核训练？",
        "state": "closed",
        "user": "bkseastone",
        "closed_by": "luotao1",
        "created_at": "2020-03-30T16:17:01+00:00",
        "updated_at": "2020-04-01T02:48:09+00:00",
        "closed_at": "2020-04-01T02:48:09+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4499,
        "title": "在ai studio编译好了pointnet_lib.so，但是提示说路径不在LD_LIBRARY_PATH里",
        "body": "在ai studio编译好了pointnet_lib.so，但是提示说路径不在LD_LIBRARY_PATH里，想问一下ai studio里的哪个路径在LD_LIBRARY_PATH里，或者如何添加LD_LIBRARY_PATH路径。",
        "state": "open",
        "user": "LLChocolate",
        "closed_by": null,
        "created_at": "2020-04-01T03:12:11+00:00",
        "updated_at": "2020-04-07T05:03:47+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "LLChocolate",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4500,
        "title": "the focal loss impletation for PaddleCV/image_classification",
        "body": "使用PaddleCV/image_classification时候，复现了一个可用于图像分类任务的focal loss\r\n\r\nhttps://github.com/zimoqingfeng/focal_loss_paddle/blob/master/focal_loss_paddle.py\r\n\r\n望采纳，有问题随时联系。",
        "state": "closed",
        "user": "zimoqingfeng",
        "closed_by": "zimoqingfeng",
        "created_at": "2020-04-01T03:38:23+00:00",
        "updated_at": "2020-04-02T10:18:31+00:00",
        "closed_at": "2020-04-02T10:18:31+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4501,
        "title": "No such  txt file",
        "body": "hi,dear\r\nthat's the [code](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/predict.py#L51)\r\nand do not find the file.\r\nShould be the [yaml file ](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/configs/attention_cluster.yaml)?\r\n\r\nthx\r\n",
        "state": "closed",
        "user": "ucas010",
        "closed_by": "ucas010",
        "created_at": "2020-04-01T07:56:12+00:00",
        "updated_at": "2020-04-03T08:29:31+00:00",
        "closed_at": "2020-04-03T08:29:31+00:00",
        "comments_count": [
            "ucas010",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4503,
        "title": "ocr_recognition预测如何获得每个字符识别的得分？",
        "body": "ocr_recognition预测结果是字符的识别的类别，是否可以获得每个字符识别的得分？另外是否能获得每个字符的位置，用给的训练集训练，在自己的数据集预测，发现有预测少字符的情况，不清楚是那个字符没有找到，是否能返回每个字符对应的位置？",
        "state": "open",
        "user": "prettyocean85",
        "closed_by": null,
        "created_at": "2020-04-01T08:16:11+00:00",
        "updated_at": "2024-02-26T05:12:15+00:00",
        "closed_at": null,
        "comments_count": [
            "BeyondYourself"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4502,
        "title": "The NeXtVLAD final model couldn't be used ???",
        "body": "hi,dear\r\nthe nextvlad_final file can't be load ???\r\n```\r\n[INFO: predict.py:  185]: Namespace(batch_size=1, config='configs/attention_cluster.txt', filelist=None, infer_topk=20, log_interval=1, model_name='AttentionCluster', save_dir='data\\\\predict_results', use_gpu=False, video_path=None, weights='./NEXTVLAD_final.pdparams')\r\n[INFO: config_utils.py:   56]: ---------------- Infer Arguments ----------------\r\n[INFO: config_utils.py:   58]: MODEL:\r\n[INFO: config_utils.py:   60]:     name:AttentionCluster\r\n[INFO: config_utils.py:   60]:     dataset:YouTube-8M\r\n[INFO: config_utils.py:   60]:     bone_network:None\r\n[INFO: config_utils.py:   60]:     drop_rate:0.5\r\n[INFO: config_utils.py:   60]:     feature_num:2\r\n[INFO: config_utils.py:   60]:     feature_names:['rgb', 'audio']\r\n[INFO: config_utils.py:   60]:     feature_dims:[1024, 128]\r\n[INFO: config_utils.py:   60]:     seg_num:100\r\n[INFO: config_utils.py:   60]:     cluster_nums:[32, 32]\r\n[INFO: config_utils.py:   60]:     num_classes:3862\r\n[INFO: config_utils.py:   60]:     topk:20\r\n[INFO: config_utils.py:   60]:     UNIQUE:{'good': 20, 'bad': 30}\r\n[INFO: config_utils.py:   58]: TRAIN:\r\n[INFO: config_utils.py:   60]:     epoch:5\r\n[INFO: config_utils.py:   60]:     learning_rate:0.001\r\n[INFO: config_utils.py:   60]:     pretrain_base:None\r\n[INFO: config_utils.py:   60]:     batch_size:2048\r\n[INFO: config_utils.py:   60]:     use_gpu:True\r\n[INFO: config_utils.py:   60]:     num_gpus:8\r\n[INFO: config_utils.py:   60]:     filelist:data/dataset/youtube8m/train.list\r\n[INFO: config_utils.py:   58]: VALID:\r\n[INFO: config_utils.py:   60]:     batch_size:2048\r\n[INFO: config_utils.py:   60]:     filelist:data/dataset/youtube8m/val.list\r\n[INFO: config_utils.py:   58]: TEST:\r\n[INFO: config_utils.py:   60]:     batch_size:256\r\n[INFO: config_utils.py:   60]:     filelist:data/dataset/youtube8m/test.list\r\n[INFO: config_utils.py:   58]: INFER:\r\n[INFO: config_utils.py:   60]:     batch_size:1\r\n[INFO: config_utils.py:   60]:     filelist:data/dataset/youtube8m/infer.list\r\n[INFO: config_utils.py:   61]: -------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"D:\\python36\\new\\rcdnn\\image\\predict.py\", line 187, in <module>\r\n    infer(args)\r\n  File \"D:\\python36\\new\\rcdnn\\image\\predict.py\", line 90, in infer\r\n    infer_model = models.get_model(args.model_name, infer_config, mode='infer')\r\n  File \"D:\\python36\\new\\rcdnn\\image\\models\\model.py\", line 191, in get_model\r\n    return model_zoo.get(name, cfg, mode)\r\n  File \"D:\\python36\\new\\rcdnn\\image\\models\\model.py\", line 179, in get\r\n    raise ModelNotFoundError(name, self.model_zoo.keys())\r\nmodels.model.ModelNotFoundError: Model AttentionCluster Not Found.\r\nAvailiable models:\r\n  NEXTVLAD\r\n```\r\nExcept specified the final model path, no other modified.\r\nSO how to solve the problem?\r\nthx",
        "state": "open",
        "user": "ucas010",
        "closed_by": null,
        "created_at": "2020-04-01T08:06:36+00:00",
        "updated_at": "2020-04-07T05:50:30+00:00",
        "closed_at": null,
        "comments_count": [
            "ucas010",
            "ucas010",
            "ucas010",
            "ucas010",
            "ucas010",
            "huangjun12",
            "huangjun12",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4506,
        "title": "谁有这个yt8m 的tfrecord？",
        "body": "hi,dear\r\n[这个里面](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/data/dataset)的数据集太多了，挨个下载到狗年了。谷歌的那个链接也打不开，\r\n谁有下载好的，麻烦分享一下啊？\r\n多谢\r\n\r\nthx",
        "state": "open",
        "user": "ucas010",
        "closed_by": null,
        "created_at": "2020-04-01T12:43:11+00:00",
        "updated_at": "2020-04-03T08:24:51+00:00",
        "closed_at": null,
        "comments_count": [
            "ucas010",
            "SunGaofeng",
            "SunGaofeng",
            "ucas010"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4514,
        "title": "跑官方的PointNet++训练模型时Warning: PaddlePaddle catches a failure signal, it may not work properly",
        "body": "  1）PaddlePaddle版本：1.7.1\r\n   2）CUDA:9.0\r\n   3）cuDNN：7.3\r\n   4）系统环境：Linux16.4、Python版本2.7\r\n安装方式信息：\r\n1）pip安装\r\n2）models:release/1.7\r\n问题：在跑跑官方的PointNet++训练模型时，按官方步骤操作到运行 sh scripts/train_cls.sh 后输出以下报错信息，然后程序停止，小白一个，完全没看懂报的是什么错以及怎么解决\r\n报错信息：\r\n(tensorflow) xz@xz:~/models-release-1.7/PaddleCV/3d_vision/PointNet++$ sh scripts/train_cls.sh\r\n2020-04-03 15:10:47,093-INFO: -----------  Configuration Arguments -----------\r\n2020-04-03 15:10:47,093-INFO: batch_size: 4\r\n2020-04-03 15:10:47,093-INFO: bn_momentum: 0.99\r\n2020-04-03 15:10:47,094-INFO: data_dir: dataset/ModelNet40/modelnet40_ply_hdf5_2048\r\n2020-04-03 15:10:47,094-INFO: decay_steps: 12500\r\n2020-04-03 15:10:47,094-INFO: enable_ce: False\r\n2020-04-03 15:10:47,094-INFO: epoch: 10\r\n2020-04-03 15:10:47,094-INFO: log_interval: 1\r\n2020-04-03 15:10:47,094-INFO: lr: 0.01\r\n2020-04-03 15:10:47,094-INFO: lr_decay: 0.7\r\n2020-04-03 15:10:47,094-INFO: model: MSG\r\n2020-04-03 15:10:47,094-INFO: num_classes: 40\r\n2020-04-03 15:10:47,094-INFO: num_points: 4096\r\n2020-04-03 15:10:47,094-INFO: resume: None\r\n2020-04-03 15:10:47,094-INFO: save_dir: checkpoints_cls\r\n2020-04-03 15:10:47,094-INFO: use_gpu: True\r\n2020-04-03 15:10:47,094-INFO: weight_decay: 1e-05\r\n2020-04-03 15:10:47,094-INFO: ------------------------------------------------\r\nW0403 15:10:47.322461  3862 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0403 15:10:47.322497  3862 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0403 15:10:47.322506  3862 init.cc:214] The detail failure signal is:\r\n\r\nW0403 15:10:47.322515  3862 init.cc:217] *** Aborted at 1585897847 (unix time) try \"date -d @1585897847\" if you are using GNU date ***\r\nW0403 15:10:47.324349  3862 init.cc:217] PC: @                0x0 (unknown)\r\nW0403 15:10:47.324578  3862 init.cc:217] *** SIGILL (@0x7eff833e1b35) received by PID 3862 (TID 0x7effc1f9d740) from PID 18446744071616469813; stack trace: ***\r\nW0403 15:10:47.326310  3862 init.cc:217]     @     0x7effc1d52330 (unknown)\r\nW0403 15:10:47.327126  3862 init.cc:217]     @     0x7eff833e1b35 paddle::framework::OpDesc::SetAttrMap()\r\nW0403 15:10:47.327630  3862 init.cc:217]     @     0x7eff841e8a04 paddle::operators::GroupPointsGradDescMaker<>::Apply()\r\nW0403 15:10:47.328037  3862 init.cc:217]     @     0x7eff841c57e3 paddle::framework::SingleGradOpMaker<>::operator()()\r\nW0403 15:10:47.328611  3862 init.cc:217]     @     0x7eff841e6313 _ZZNK6paddle9framework7details12OpInfoFillerINS_9operators24GroupPointsGradDescMakerINS0_6OpDescEEELNS1_14OpInfoFillTypeE2EEclEPKcPNS0_6OpInfoEENKUlRKS5_RKSt13unordered_setISsSt4hashISsESt8equal_toISsESaISsEEPSt13unordered_mapISsSsSH_SJ_SaISt4pairIKSsSsEEERKSt6vectorIPNS0_9BlockDescESaISX_EEE_clESE_SN_SU_S11_\r\nW0403 15:10:47.329150  3862 init.cc:217]     @     0x7eff841e7b2e _ZNSt17_Function_handlerIFSt6vectorISt10unique_ptrIN6paddle9framework6OpDescESt14default_deleteIS4_EESaIS7_EERKS4_RKSt13unordered_setISsSt4hashISsESt8equal_toISsESaISsEEPSt13unordered_mapISsSsSE_SG_SaISt4pairIKSsSsEEERKS0_IPNS3_9BlockDescESaIST_EEEZNKS3_7details12OpInfoFillerINS2_9operators24GroupPointsGradDescMakerIS4_EELNSZ_14OpInfoFillTypeE2EEclEPKcPNS3_6OpInfoEEUlSB_SK_SR_SX_E_E9_M_invokeERKSt9_Any_dataSB_SK_SR_SX_\r\nW0403 15:10:47.329793  3862 init.cc:217]     @     0x7eff833a85a0 PD_GetGradOpDescStrs\r\nW0403 15:10:47.330160  3862 init.cc:217]     @     0x7eff88a20e0f _ZNSt17_Function_handlerIFSt6vectorISt10unique_ptrIN6paddle9framework6OpDescESt14default_deleteIS4_EESaIS7_EERKS4_RKSt13unordered_setISsSt4hashISsESt8equal_toISsESaISsEEPSt13unordered_mapISsSsSE_SG_SaISt4pairIKSsSsEEERKS0_IPNS3_9BlockDescESaIST_EEEZNS3_9LoadOpLibERSN_EUlSB_SK_SR_SX_E_E9_M_invokeERKSt9_Any_dataSB_SK_SR_SX_\r\nW0403 15:10:47.330523  3862 init.cc:217]     @     0x7eff88a208bc _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL24pybind11_init_core_noavxERNS_6moduleEEUlRKNS2_9framework6OpDescERKSt13unordered_setISsSt4hashISsESt8equal_toISsESaISsEERKSt6vectorIPNS6_9BlockDescESaISL_EEE68_St4pairISJ_IPS7_SaISS_EESt13unordered_mapISsSsSC_SE_SaISR_IKSsSsEEEEIS9_SI_SP_EINS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES1H_\r\nW0403 15:10:47.332165  3862 init.cc:217]     @     0x7eff88a67d8e pybind11::cpp_function::dispatcher()\r\nW0403 15:10:47.334061  3862 init.cc:217]     @     0x7effc20862f4 PyEval_EvalFrameEx\r\nW0403 15:10:47.336364  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.338436  3862 init.cc:217]     @     0x7effc2084fe8 PyEval_EvalFrameEx\r\nW0403 15:10:47.340397  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.342281  3862 init.cc:217]     @     0x7effc2084fe8 PyEval_EvalFrameEx\r\nW0403 15:10:47.344147  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.346045  3862 init.cc:217]     @     0x7effc2084fe8 PyEval_EvalFrameEx\r\nW0403 15:10:47.347934  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.349687  3862 init.cc:217]     @     0x7effc20107d7 function_call\r\nW0403 15:10:47.351596  3862 init.cc:217]     @     0x7effc1febb83 PyObject_Call\r\nW0403 15:10:47.353756  3862 init.cc:217]     @     0x7effc2080aee PyEval_EvalFrameEx\r\nW0403 15:10:47.355752  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.357581  3862 init.cc:217]     @     0x7effc20107d7 function_call\r\nW0403 15:10:47.359529  3862 init.cc:217]     @     0x7effc1febb83 PyObject_Call\r\nW0403 15:10:47.361403  3862 init.cc:217]     @     0x7effc2080aee PyEval_EvalFrameEx\r\nW0403 15:10:47.363319  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.365209  3862 init.cc:217]     @     0x7effc2084fe8 PyEval_EvalFrameEx\r\nW0403 15:10:47.367069  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.368911  3862 init.cc:217]     @     0x7effc2084fe8 PyEval_EvalFrameEx\r\nW0403 15:10:47.370736  3862 init.cc:217]     @     0x7effc20865ce PyEval_EvalFrameEx\r\nW0403 15:10:47.372582  3862 init.cc:217]     @     0x7effc2087b19 PyEval_EvalCodeEx\r\nW0403 15:10:47.374399  3862 init.cc:217]     @     0x7effc2087d3a PyEval_EvalCode\r\nIllegal instruction (core dumped)\r\n",
        "state": "open",
        "user": "a178052771",
        "closed_by": null,
        "created_at": "2020-04-03T07:54:04+00:00",
        "updated_at": "2024-02-26T05:12:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4508,
        "title": "有关CTCN视频动作定位的问题",
        "body": "谢谢作者的棒棒的成果,更谢谢作者分享您的代码.佩服佩服!\r\n\r\n阅读了您的2018夺冠文章后,有两个问题请教,不知可否赐教?\r\n您文章中说: BSN has a higher mAP than our C-TCN with the threshold of 0.95, however, it uses additional video classification results of [65] which are fused by multiple models, while our model only uses a two-stream model.\r\n1. 您是否尝试过也用[65]的video classification results 替代您pipeline中two-stream model, mAP会提高吗?\r\n2. 我阅读了[65]  \"Y. Zhao, et al., Cuhk & ethz & siat submission to activitynet challenge 2017\", 发现这篇文章中介绍了好几个方法针对好几个问题.您说的video classification results究竟是哪种方法得到的?哪里可以下載its video classification results?\r\n\r\n如果您能回覆, 就太感谢了!\r\n\r\n",
        "state": "open",
        "user": "happyCodingSusan",
        "closed_by": null,
        "created_at": "2020-04-01T15:01:32+00:00",
        "updated_at": "2024-02-26T05:12:12+00:00",
        "closed_at": null,
        "comments_count": [
            "HUSTLX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4513,
        "title": "如何得到预训练模型的某一层输出结果？",
        "body": "hi,dear\r\n预训练模型[NeXtVLAD](https://paddlemodels.bj.bcebos.com/video_classification/NEXTVLAD.pdparams)的某一层输出结果怎么得到啊？\r\n具体情况请看[这个](https://github.com/PaddlePaddle/models/issues/4510)\r\n\r\n多谢\r\n",
        "state": "closed",
        "user": "ucas010",
        "closed_by": "heavengate",
        "created_at": "2020-04-02T09:43:14+00:00",
        "updated_at": "2020-04-03T03:20:32+00:00",
        "closed_at": "2020-04-03T03:20:32+00:00",
        "comments_count": [
            "heavengate",
            "ucas010",
            "heavengate",
            "ucas010",
            "heavengate",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4510,
        "title": "video_path is what ?",
        "body": "hi,dear\r\nin the [predict.py](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/predict.py#L93),\r\nwhat's the meaning ?\r\n```\r\n    parser.add_argument(\r\n        '--save_dir',\r\n        type=str,\r\n        default=os.path.join('data', 'predict_results'),\r\n        help='directory to store results')\r\n    parser.add_argument(\r\n        '--video_path',\r\n        type=str,\r\n        default=None,\r\n        help='directory to store results')\r\n```\r\nvideo_path is the video what I want to test/infer ?\r\n\r\nthx",
        "state": "closed",
        "user": "ucas010",
        "closed_by": "ucas010",
        "created_at": "2020-04-01T16:08:24+00:00",
        "updated_at": "2020-04-03T08:27:37+00:00",
        "closed_at": "2020-04-03T08:27:37+00:00",
        "comments_count": [
            "ucas010",
            "heavengate",
            "ucas010",
            "SunGaofeng",
            "ucas010",
            "SunGaofeng",
            "ucas010",
            "ucas010",
            "SunGaofeng",
            "ucas010"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4512,
        "title": "TypeError: load() got an unexpected keyword argument 'var_list'",
        "body": "## 1.错误\r\n你好,我在使用NeXtVLAD预训练权重预测的时候出现下面错误:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 200, in <module>\r\n    infer(args)\r\n  File \"predict.py\", line 131, in infer\r\n    fluid.default_main_program(), place)\r\n  File \"E:\\20200328_img_text\\NeXtVLAD\\models-develop\\PaddleCV\\video\\models\\model.py\", line 158, in load_test_weights\r\n    fluid.load(prog, weights, executor=exe, var_list=params_list)\r\nTypeError: load() got an unexpected keyword argument 'var_list'\r\n```\r\n## 2.运行及版本情况\r\n1. 目前使用paddle的版本: \r\n```\r\npaddlepaddle-gpu 1.6.3.post97\r\n```\r\n\r\n2. 运行代码来自:[链接](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video)\r\n\r\n3. 运行命令如下:\r\n```\r\npython predict.py --model_name=NEXTVLAD --config=configs/nextvlad.yaml --log_interval=1 --weights=./data/model/NEXTVLAD.pdparams --filelist=./data/dataset/youtube8m/infer.list --use_gpu=True\r\n```\r\n## 3问题\r\n想问一下是什么原因导致的?\r\n\r\n## PS\r\n查看了源代码\r\n[model文件](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/model.py)\r\n```\r\n    def load_test_weights(self, exe, weights, prog, place):\r\n        params_list = list(filter(is_parameter, prog.list_vars()))\r\n        fluid.load(prog, weights, executor=exe, var_list=params_list)\r\n```\r\n源代码: Anaconda4.2\\envs\\Python36\\Lib\\site-packages\\paddle\\fluid\\io.py\r\n```\r\ndef load(program, model_path, executor=None):\r\n```\r\n需要哪个版本的paddle才能兼容?\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Mintcat10",
        "closed_by": "heavengate",
        "created_at": "2020-04-02T09:23:35+00:00",
        "updated_at": "2020-04-03T03:23:00+00:00",
        "closed_at": "2020-04-03T03:23:00+00:00",
        "comments_count": [
            "heavengate",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4516,
        "title": "dygraph的ocr_recognition有没有更新beam_search()?",
        "body": "dygraph的ocr_recognition没有看到采用beam_search()",
        "state": "open",
        "user": "wenston2006",
        "closed_by": null,
        "created_at": "2020-04-07T06:05:36+00:00",
        "updated_at": "2020-04-07T13:22:58+00:00",
        "closed_at": null,
        "comments_count": [
            "LielinJiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4522,
        "title": "文字识别模型 ocr_recognition 变长输入出错",
        "body": "ocr_recognition 模型：https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/ocr_recognition\r\n\r\n在最新的代码下，使用的是输入接口是：\r\n```python\r\n    images = fluid.data(name='pixel', shape=data_shape, dtype='float32')\r\n    label = fluid.data(name='label', shape=[None, 1], dtype='int32', lod_level=1)\r\n```\r\n\r\n该接口好像不支持变长输入，为什么不使用`fluid.layers.data()`接口呢？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-04-09T08:05:03+00:00",
        "updated_at": "2020-04-09T09:33:52+00:00",
        "closed_at": "2020-04-09T09:33:51+00:00",
        "comments_count": [
            "BeyondYourself",
            "yeyupiaoling",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4520,
        "title": "不显示图片，",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/bmn/README.md\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/39516551/78782067-f7c27c80-79d3-11ea-8c02-102a4fb2a408.png)\r\n",
        "state": "open",
        "user": "DavidFangx",
        "closed_by": null,
        "created_at": "2020-04-08T12:03:47+00:00",
        "updated_at": "2024-02-26T05:12:08+00:00",
        "closed_at": null,
        "comments_count": [
            "llxxxll",
            "qingqing01",
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4523,
        "title": "Parakeet model does not work",
        "body": "PaddlePaddle official [pretrained model](https://github.com/PaddlePaddle/Parakeet#pre-trained-models-and-audio-samples) can't generate sound. This pre-trained [WaveFlow model](https://paddlespeech.bj.bcebos.com/Parakeet/waveflow_res128_ljspeech_ckpt_1.0.zip) should convert a mel spectrogram of a sound to `wav` file, but it generates only noise.\r\nYou can reproduce it by copypasting this code to Colab:\r\n\r\n```\r\n!wget -qqq https://paddlespeech.bj.bcebos.com/Parakeet/waveflow_res128_ljspeech_ckpt_1.0.zip > /dev/null\r\n!mkdir -p /content/downloads\r\n!unzip -qqq /content/waveflow_res128_ljspeech_ckpt_1.0.zip -d /content/downloads > /dev/null\r\n!rm -rf /content/sample_data /content/waveflow_res128_ljspeech_ckpt_1.0.zip\r\n!sudo apt-get update -y -qqq --fix-missing && apt-get install -y -qqq libsndfile1 > /dev/null\r\n!pip install -U -qqq imgaug scipy albumentations paddlepaddle-gpu > /dev/null\r\n!git clone -qqq https://github.com/PaddlePaddle/Parakeet > /dev/null\r\n%cd /content/Parakeet\r\n!pip install -qqq -e . > /dev/null\r\n\r\nimport os, pathlib, nltk, sys\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nnltk.download(\"punkt\")\r\nnltk.download(\"cmudict\")\r\n\r\npth_1 = \"/content/Parakeet\"\r\nif pth_1 not in sys.path: sys.path.insert(0, pth_1)\r\n\r\npth_2 = \"/content/Parakeet/examples/waveflow\"\r\nif pth_2 not in sys.path: sys.path.insert(0, pth_2)\r\n\r\n%cd /content/downloads\r\n\r\n!curl -Ls https://dl.dropboxusercontent.com/s/jj78665lrhiod97/LJ001-0001.wav -o LJ001-0001.wav\r\naudio_pth = \"/content/downloads/LJ001-0001.wav\"\r\n\r\n!export CUDA_VISIBLE_DEVICES=0\r\nfrom parakeet.models.waveflow import waveflow_modules\r\nfrom parakeet.modules import weight_norm\r\nfrom parakeet.utils import io\r\nimport paddle.fluid.dygraph as dg\r\nfrom paddle import fluid\r\nfrom scipy.io.wavfile import read\r\nfrom scipy.io.wavfile import write\r\nfrom ruamel import yaml\r\nimport random, librosa\r\n\r\nclass Config():\r\n  def __init__(self, **entries):\r\n    self.__dict__.update(entries)\r\n\r\nclass WaveFlow():\r\n  def __init__(self,\r\n               config,\r\n               parallel=False,\r\n               rank=0,\r\n               nranks=1,\r\n               tb_logger=None):\r\n    self.config = config\r\n    self.checkpoint_dir = config.checkpoint_dir\r\n    self.parallel = parallel\r\n    self.rank = rank\r\n    self.nranks = nranks\r\n    self.tb_logger = tb_logger\r\n    self.dtype = \"float16\" if config.use_fp16 else \"float32\"\r\n\r\n  def build(self):\r\n    config = self.config\r\n\r\n    waveflow = waveflow_modules.WaveFlowModule(config)\r\n\r\n    # Dry run once to create and initalize all necessary parameters.\r\n    audio = dg.to_variable(np.random.randn(1, 16000).astype(self.dtype))\r\n    mel = dg.to_variable(\r\n        np.random.randn(1, config.mel_bands, 63).astype(self.dtype))\r\n    waveflow(audio, mel)\r\n\r\n    iteration = io.load_parameters(waveflow, checkpoint_dir=self.checkpoint_dir)\r\n\r\n    for layer in waveflow.sublayers():\r\n      if isinstance(layer, weight_norm.WeightNormWrapper):\r\n        layer.remove_weight_norm()    \r\n    self.waveflow = waveflow\r\n    \r\n    return iteration\r\n\r\n  @dg.no_grad\r\n  def infer(self, mel):\r\n    self.waveflow.eval()\r\n    config = self.config\r\n    print(mel.shape, 'mel.shape')\r\n    audio = self.waveflow.synthesize(mel, sigma=self.config.sigma)\r\n    audio = audio[0]\r\n\r\n    # Denormalize audio from [-1, 1] to [-32768, 32768] int16 range.\r\n    audio = audio.numpy().astype(\"float32\") * 32768.0\r\n    audio = audio.astype('int16')\r\n    filename = 'test.wav'\r\n    print(audio.shape, 'audio.shape')\r\n    write(filename, config.sample_rate, audio)\r\n\r\ndef get_mel(audio):\r\n  spectrogram = librosa.core.stft(\r\n      audio,\r\n      n_fft=config.fft_size,\r\n      hop_length=config.fft_window_shift,\r\n      win_length=config.fft_window_size)\r\n  spectrogram_magnitude = np.abs(spectrogram)\r\n\r\n  # mel_filter_bank shape: [n_mels, 1 + n_fft/2]\r\n  mel_filter_bank = librosa.filters.mel(sr=config.sample_rate,\r\n                                        n_fft=config.fft_size,\r\n                                        n_mels=config.mel_bands,\r\n                                        fmin=config.mel_fmin,\r\n                                        fmax=config.mel_fmax)\r\n  # mel shape: [n_mels, num_frames]\r\n  mel = np.dot(mel_filter_bank, spectrogram_magnitude)\r\n\r\n  # Normalize mel.\r\n  clip_val = 1e-5\r\n  ref_constant = 1\r\n  mel = np.log(np.clip(mel, a_min=clip_val, a_max=None) * ref_constant)\r\n\r\n  return mel\r\n\r\ndef get_config(pth=\"/content/Parakeet/examples/waveflow/configs/waveflow_ljspeech.yaml\"):\r\n  with open(pth) as f:\r\n    config = yaml.load(f, Loader=yaml.Loader)\r\n\r\n  config['checkpoint'] = None\r\n  config['checkpoint_dir'] = \"/content/downloads/waveflow_res128_ljspeech_ckpt_1.0\"\r\n  config['iteration'] = None\r\n  config['name'] = ''\r\n  config['output'] = './syn_audios'\r\n  config['sample'] = 0\r\n  config['use_fp16'] = True\r\n  config['use_gpu'] = True\r\n  return Config(**config)\r\n\r\nconfig = get_config()\r\nprint(config.__dict__)\r\n\r\nplace = fluid.CUDAPlace(0) if config.use_gpu else fluid.CPUPlace()\r\nwith dg.guard(place):\r\n  # Fix random seed.\r\n  seed = config.seed\r\n  random.seed(seed)\r\n  np.random.seed(seed)\r\n  fluid.default_startup_program().random_seed = seed\r\n  fluid.default_main_program().random_seed = seed\r\n\r\n  # Build model.\r\n  model = WaveFlow(config)\r\n  iteration = model.build()\r\n  print(iteration, \"iteration\")\r\n  # Obtain the current iteration.\r\n  if config.checkpoint is None:\r\n    if config.iteration is None:\r\n      print(\"_load_latest_checkpoint\")\r\n      iteration = io._load_latest_checkpoint(config.checkpoint_dir)\r\n    else:\r\n      iteration = config.iteration\r\n  else:\r\n    iteration = int(config.checkpoint.split('/')[-1].split('-')[-1])\r\n  print(config.checkpoint_dir, iteration)\r\n  loaded_sr, audio = read(audio_pth)\r\n  mel = dg.to_variable(np.expand_dims(get_mel(np.asarray(audio, dtype=np.float32)), axis=0))\r\n  model.infer(mel)\r\n\r\n{'valid_size': 16, 'segment_length': 16000, 'sample_rate': 22050, 'fft_window_shift': 256, 'fft_window_size': 1024, 'fft_size': 1024, 'mel_bands': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'seed': 1234, 'learning_rate': 0.0002, 'batch_size': 8, 'test_every': 2000, 'save_every': 10000, 'max_iterations': 3000000, 'sigma': 1.0, 'n_flows': 8, 'n_group': 16, 'n_layers': 8, 'n_channels': 64, 'kernel_h': 3, 'kernel_w': 3, 'checkpoint': None, 'checkpoint_dir': '/content/downloads/waveflow_res128_ljspeech_ckpt_1.0', 'iteration': None, 'name': '', 'output': './syn_audios', 'sample': 0, 'use_fp16': True, 'use_gpu': True}\r\n/usr/local/lib/python3.6/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'input' in assign only support float16 in GPU now. (When the type of input in assign is Variable.)\r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python3.6/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'x' in cast only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n/usr/local/lib/python3.6/dist-packages/paddle/fluid/data_feeder.py:93: UserWarning: The data type of 'input' in squeeze only support float16 in GPU now. \r\n  (input_name, op_name, extra_message))\r\n0 iteration\r\n_load_latest_checkpoint\r\n/content/downloads/waveflow_res128_ljspeech_ckpt_1.0 0\r\n[1, 80, 832] mel.shape\r\n(212720,) audio.shape\r\n```",
        "state": "closed",
        "user": "qo4on",
        "closed_by": "qo4on",
        "created_at": "2020-04-09T14:07:13+00:00",
        "updated_at": "2020-04-15T15:35:14+00:00",
        "closed_at": "2020-04-15T15:35:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4524,
        "title": "tagspace中text2paddle.py代码错误",
        "body": "PaddleRec/tagspace/text2paddle.py中代码有错，返回值比文档说明的要少一个，而且生成的csv文件格式也不对。\r\n改回python2.7时的版本text2paddle.py可以正常训练。\r\npython2.7版本：\r\n```\r\nimport sys\r\nimport six\r\nimport collections\r\nimport os\r\nimport csv \r\nimport re\r\n\r\ndef word_count(column_num, input_file, word_freq=None):\r\n    \"\"\"\r\n    compute word count from corpus\r\n    \"\"\"\r\n    if word_freq is None:\r\n        word_freq = collections.defaultdict(int)\r\n    data_file = csv.reader(input_file)\r\n    for row in data_file:\r\n        for w in re.split(r'\\W+',row[column_num].strip()):\r\n            word_freq[w]+= 1\r\n    return word_freq\r\n\r\ndef build_dict(column_num=2, min_word_freq=0, train_dir=\"\", test_dir=\"\"):\r\n    \"\"\"\r\n    Build a word dictionary from the corpus,  Keys of the dictionary are words,\r\n    and values are zero-based IDs of these words.\r\n    \"\"\"\r\n    word_freq = collections.defaultdict(int)\r\n    files = os.listdir(train_dir)\r\n    for fi in files:\r\n        with open(train_dir + '/' + fi, \"r\") as f:\r\n            word_freq = word_count(column_num, f, word_freq)\r\n    files = os.listdir(test_dir)\r\n    for fi in files:\r\n        with open(test_dir + '/' + fi, \"r\") as f:\r\n            word_freq = word_count(column_num, f, word_freq)\r\n\r\n    word_freq = [x for x in six.iteritems(word_freq) if x[1] > min_word_freq]\r\n    word_freq_sorted = sorted(word_freq, key=lambda x: (-x[1], x[0]))\r\n    words, _ = list(zip(*word_freq_sorted))\r\n    word_idx = dict(list(zip(words, six.moves.range(len(words)))))\r\n    return word_idx\r\n\r\n\r\ndef write_paddle(text_idx, tag_idx, train_dir, test_dir, output_train_dir, output_test_dir):\r\n    files = os.listdir(train_dir)\r\n    if not os.path.exists(output_train_dir):\r\n        os.mkdir(output_train_dir)\r\n    for fi in files:\r\n        with open(train_dir + '/' + fi, \"r\") as f:\r\n            with open(output_train_dir + '/' + fi, \"w\") as wf:\r\n                data_file = csv.reader(f)\r\n                for row in data_file:\r\n                    tag_raw = re.split(r'\\W+', row[0].strip())\r\n                    pos_index = tag_idx.get(tag_raw[0])\r\n                    wf.write(str(pos_index) + \",\")\r\n                    text_raw = re.split(r'\\W+', row[2].strip())\r\n                    l = [text_idx.get(w) for w in text_raw]\r\n                    for w in l:\r\n                        wf.write(str(w) + \" \")\r\n                    wf.write(\"\\n\")\r\n\r\n    files = os.listdir(test_dir)\r\n    if not os.path.exists(output_test_dir):\r\n        os.mkdir(output_test_dir)\r\n    for fi in files:\r\n        with open(test_dir + '/' + fi, \"r\") as f:\r\n            with open(output_test_dir + '/' + fi, \"w\") as wf:\r\n                data_file = csv.reader(f)\r\n                for row in data_file:\r\n                    tag_raw = re.split(r'\\W+', row[0].strip())\r\n                    pos_index = tag_idx.get(tag_raw[0])\r\n                    wf.write(str(pos_index) + \",\")\r\n                    text_raw = re.split(r'\\W+', row[2].strip())\r\n                    l = [text_idx.get(w) for w in text_raw]\r\n                    for w in l:\r\n                        wf.write(str(w) + \" \")\r\n                    wf.write(\"\\n\")\r\n\r\ndef text2paddle(train_dir, test_dir, output_train_dir, output_test_dir, output_vocab_text, output_vocab_tag):\r\n    print(\"start constuct word dict\")\r\n    vocab_text = build_dict(2, 0, train_dir, test_dir)\r\n    with open(output_vocab_text, \"w\") as wf:\r\n        wf.write(str(len(vocab_text)) + \"\\n\")\r\n\r\n    vocab_tag = build_dict(0, 0, train_dir, test_dir)\r\n    with open(output_vocab_tag, \"w\") as wf:\r\n        wf.write(str(len(vocab_tag)) + \"\\n\")\r\n\r\n    print(\"construct word dict done\\n\")\r\n    write_paddle(vocab_text, vocab_tag, train_dir, test_dir, output_train_dir, output_test_dir)\r\n\r\n\r\ntrain_dir = sys.argv[1]\r\ntest_dir = sys.argv[2]\r\noutput_train_dir = sys.argv[3]\r\noutput_test_dir = sys.argv[4]\r\noutput_vocab_text = sys.argv[5]\r\noutput_vocab_tag = sys.argv[6]\r\ntext2paddle(train_dir, test_dir, output_train_dir, output_test_dir, output_vocab_text, output_vocab_tag)\r\n```",
        "state": "closed",
        "user": "edencfc",
        "closed_by": "mmglove",
        "created_at": "2020-04-10T08:56:33+00:00",
        "updated_at": "2020-09-25T06:04:58+00:00",
        "closed_at": "2020-09-25T06:04:58+00:00",
        "comments_count": [
            "frankwhzhang",
            "edencfc",
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4526,
        "title": "使用已有预训练模型来训练新模型，若已有预训练模型的分类为80 ，在训练新模型时，能否增加新分类，若能增加，请问怎么增加？",
        "body": "使用已有预训练模型来训练新模型，若已有预训练模型的分类为80 ，在训练新模型时，能否增加新分类，若能增加，请问怎么增加？\r\n\r\n比如：使用这个 https://paddle-imagenet-models-name.bj.bcebos.com/DarkNet53_pretrained.tar 模型\r\n，该模型不包含头盔分类，可以使用这个模型来训练头盔识别？",
        "state": "open",
        "user": "DavidFangx",
        "closed_by": null,
        "created_at": "2020-04-13T08:29:32+00:00",
        "updated_at": "2024-02-26T05:12:06+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4525,
        "title": "stargan的问题",
        "body": "1.StarGAN.py的build_model函数:\r\n这两个标签是什么意思，self.cfg.c_dim=5，这个为什么是5维？  \r\n label_org = fluid.data(\r\n            name='label_org', shape=[None, self.cfg.c_dim], dtype='float32')\r\nlabel_trg = fluid.data(\r\n            name='label_trg', shape=[None, self.cfg.c_dim], dtype='float32')\r\n\r\n2.StarGAN.py的DTrainer函数:\r\nD网络有2个输出，这两个输出参数没有看到说明，照说明文档不是输出真假即可？\r\nself.pred_real, self.cls_real = model.network_D(image_real, cfg, name=\"d_main\")\r\n\r\n3.整体思路能大概描述一下，特别是输入输出相关方面？",
        "state": "open",
        "user": "sonic-github",
        "closed_by": null,
        "created_at": "2020-04-11T09:46:36+00:00",
        "updated_at": "2020-04-14T03:10:13+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4528,
        "title": "bsn model is missing python training script - train.py",
        "body": "bsn model is missing python training script - train.py\r\n(only has bmn training script in dygraph/bmn/train.py)\r\n\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/models/bsn\r\n\r\n![image](https://user-images.githubusercontent.com/35629974/79119802-cc6cd280-7dc3-11ea-9a61-94596a2e4b7f.png)\r\n@qingqing01 @SunGaofeng @huangjun12 \r\n",
        "state": "closed",
        "user": "UCC-team",
        "closed_by": "UCC-team",
        "created_at": "2020-04-13T12:21:48+00:00",
        "updated_at": "2020-04-15T08:27:52+00:00",
        "closed_at": "2020-04-15T08:27:52+00:00",
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4527,
        "title": "读取数据除了问题",
        "body": "我是用自定义数据的，但是我的标签从来就没有float类型，但是它在训练两轮后缺报了`Error: D:/1.7.1/paddle\\paddle/fluid/operators/cross_entropy_op.h:173 Assertion `label >= 0 && label < feature_size_` failed. Variable value (label) of OP(fluid.layers.cross_entropy) expected >= 0 and < 5335, but got 0. Please check label value.`这是为什么呀？麻烦您帮帮我解决一下",
        "state": "open",
        "user": "Fighter-zzp",
        "closed_by": null,
        "created_at": "2020-04-13T11:49:50+00:00",
        "updated_at": "2024-02-26T05:12:04+00:00",
        "closed_at": null,
        "comments_count": [
            "Fighter-zzp",
            "SunGaofeng",
            "Fighter-zzp",
            "Fighter-zzp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4529,
        "title": "训练stnet读取kinetics数据集时出线错误 求解决",
        "body": "![QQ图片20200414093238](https://user-images.githubusercontent.com/55325034/79176483-eabde700-7e32-11ea-8763-da456262bb26.png)\r\n![QQ图片20200414093322](https://user-images.githubusercontent.com/55325034/79176515-03c69800-7e33-11ea-9748-9a7a30d28323.png)\r\n应该不是路径问题，添加pythonpath也是一样的error",
        "state": "open",
        "user": "jia6214876",
        "closed_by": null,
        "created_at": "2020-04-14T01:34:22+00:00",
        "updated_at": "2024-02-26T05:12:03+00:00",
        "closed_at": null,
        "comments_count": [
            "ysh329",
            "ysh329",
            "jia6214876",
            "jia6214876",
            "xiegegege",
            "jia6214876",
            "xiegegege",
            "jia6214876",
            "xiegegege",
            "jia6214876",
            "jia6214876",
            "xiegegege",
            "jia6214876",
            "tosonw",
            "xiegegege",
            "tosonw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4532,
        "title": "README链接失效",
        "body": "## Model下README的“基于动态图实现的模型”部分链接失效\r\nhttps://github.com/PaddlePaddle/models\r\n![图片](https://user-images.githubusercontent.com/46156734/79337787-c2300d00-7f58-11ea-8cc9-e7b968e7e295.png)\r\n![图片](https://user-images.githubusercontent.com/46156734/79337888-ec81ca80-7f58-11ea-8802-a035b0a6c6c4.png)\r\n",
        "state": "closed",
        "user": "GT-ZhangAcer",
        "closed_by": "GT-ZhangAcer",
        "created_at": "2020-04-15T12:38:10+00:00",
        "updated_at": "2020-04-18T06:04:23+00:00",
        "closed_at": "2020-04-18T06:04:23+00:00",
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4534,
        "title": "PaddlePredictor预测ocr_recognition模型问题",
        "body": "ocr_recognition，CRNN模型保存为fluid.io.save_inference_model(dirname=args.freeze_model_path,\r\n                                      feeded_var_names=['pixel'],\r\n                                      target_vars=[ids],\r\n                                      main_program=test_program,\r\n                                      executor=exe,\r\n                                      model_filename='_model_',\r\n                                      params_filename='_params_')\r\n采用PaddlePredictor进行预测，输出结果为\r\n[[14]\r\n [26]]\r\n采用infer.py预测结果正确，输出为[ 3  2  4  8  7 21 31 14 31 36 35]\r\n不知道是什么原因，是模型保存问题还是预测问题。预测输入查看了和infer.py的输入数据是一致的",
        "state": "closed",
        "user": "prettyocean85",
        "closed_by": "prettyocean85",
        "created_at": "2020-04-16T09:01:29+00:00",
        "updated_at": "2020-04-17T06:18:15+00:00",
        "closed_at": "2020-04-17T06:18:15+00:00",
        "comments_count": [
            "prettyocean85"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4550,
        "title": "cpu下ocr_recognition预测结果错误",
        "body": "使用PaddlePaddle\\models\\PaddleCV\\ocr_recognition训练好的模型预测，模型重新保存为固化模型。使用 AnalysisPredictor 方式预测，并使用zerocopytensor。在GPU下预测结果正确，CPU结果错误，请问可能是什么原因。\r\nGPU预测结果\r\n[[ 3]\r\n [ 2]\r\n [ 4]\r\n [ 8]\r\n [ 7]\r\n [21]\r\n [31]\r\n [14]\r\n [31]\r\n [36]\r\n [35]]\r\n改为CPU预测结果\r\n[[ 2]\r\n [ 2]\r\n [ 4]\r\n [ 4]\r\n [ 4]\r\n [ 5]\r\n [ 4]\r\n [ 5]\r\n [ 1]\r\n [ 4]\r\n [ 5]\r\n [ 4]\r\n [31]\r\n [ 2]\r\n [ 4]\r\n [ 5]\r\n [ 9]\r\n [ 2]\r\n [34]\r\n [34]\r\n [ 4]]\r\n",
        "state": "closed",
        "user": "prettyocean85",
        "closed_by": "prettyocean85",
        "created_at": "2020-04-20T05:47:52+00:00",
        "updated_at": "2020-04-21T03:05:40+00:00",
        "closed_at": "2020-04-21T03:05:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4545,
        "title": "emotion_detection服务部署出现问题，命令行可以 运行，pycharm运行就报错，请帮助！",
        "body": "emotion_detection服务部署出现问题，命令行可以 运行，pycharm运行就报错\r\n![image](https://user-images.githubusercontent.com/33630730/79593033-6eb2f000-810d-11ea-9518-fb0fa765caa7.png)\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "27182812",
        "closed_by": null,
        "created_at": "2020-04-17T16:43:41+00:00",
        "updated_at": "2020-04-18T14:23:08+00:00",
        "closed_at": null,
        "comments_count": [
            "hong19860320",
            "27182812",
            "hong19860320",
            "27182812"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4551,
        "title": "基于视频码流的目标检测，然后推流到流媒体服务器，但性能较卡，请问可好的解决思路或方案",
        "body": "具体问题：\r\n我们基于 YOLOv3 DarkNet53 模型，对视频码流进行目标实时检测，并把识别结果叠加到视频上去，并以 ffmpeg 方式 推流 stmp 到流媒体服务器，但是效果不理想，在流媒体上服务器看最后的视频，非常的卡，请问可好的解决思路或方案?\r\n\r\n谢谢。",
        "state": "closed",
        "user": "DavidFangx",
        "closed_by": "DavidFangx",
        "created_at": "2020-04-20T09:23:33+00:00",
        "updated_at": "2020-04-24T01:09:34+00:00",
        "closed_at": "2020-04-24T01:09:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4548,
        "title": "推荐算法SR-GNN中建立有向图中np.divide()建议改成np.true_divide()",
        "body": "![image](https://user-images.githubusercontent.com/58713995/79696003-e88eca80-822e-11ea-9f95-29ba597bee7c.png)\r\n有向图adj_in和adj_out归一化时官方对应python版本使用了np.divide(),可能会出现adj_in和adj_out全是0矩阵的情况，改成np.true_divide()会使用浮点数除法，才能达到归一化的效果。不知道是否正确？",
        "state": "closed",
        "user": "jaykay233",
        "closed_by": "jaykay233",
        "created_at": "2020-04-19T18:18:24+00:00",
        "updated_at": "2020-04-22T01:24:25+00:00",
        "closed_at": "2020-04-22T01:24:25+00:00",
        "comments_count": [
            "hutuxian",
            "jaykay233"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4564,
        "title": "度量学习项目难以收敛",
        "body": "近日，我测试用了models的度量学习（metric_learning）项目，但是数据我替换成了人脸数据，其他代码在基本未改的情况下，我训练项目时的loss非常大，recall仍旧很小。请问一下我在这里需要调整什么代码吗，还是参数需要调一下，怎么才能让它快速收敛？\r\n\r\n> 我微调训练（batch size为50，其他基本不变）其了几万轮，loss还是很大如下\r\n`[2020-04-22 17:51:47] trainbatch 30000, lr 0.000100, loss 0.983684, recall 0.1835, time 0.22 sec`",
        "state": "open",
        "user": "Fighter-zzp",
        "closed_by": null,
        "created_at": "2020-04-22T09:52:21+00:00",
        "updated_at": "2024-02-26T05:12:01+00:00",
        "closed_at": null,
        "comments_count": [
            "MyPandaShaoxiang",
            "Fighter-zzp",
            "MyPandaShaoxiang",
            "Fighter-zzp",
            "cuicheng01",
            "Fighter-zzp",
            "xiaoran-xr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4565,
        "title": "使用最新develop版Paddle动态图多卡训练跑不起来",
        "body": "使用最新develop版Paddle，https://github.com/PaddlePaddle/models/tree/develop/dygraph/resnet#%E8%AE%AD%E7%BB%83%E6%B5%8B%E8%AF%95residual-network 这里的多卡训练demo跑不起来，请问是什么原因？报错信息如下：\r\n```bash\r\nstart data reader (trainers_num: 2, trainer_id: 0)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 389, in <module>\r\n    train_resnet()\r\n  File \"train.py\", line 340, in train_resnet\r\n    out = resnet(img)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 460, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/parallel.py\", line 288, in forward\r\n    return self._layers(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 460, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"train.py\", line 226, in forward\r\n    y = self.conv(inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 460, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"train.py\", line 108, in forward\r\n    y = self._conv(inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 457, in __call__\r\n    self._parameters.values())\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/parallel_helper.py\", line 43, in _broadcast_parameters\r\n    collective._broadcast(param, 0, sync_mode=True)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/layers/collective.py\", line 60, in _broadcast\r\n    \"root\": root})\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2552, in append_op\r\n    kwargs.get(\"stop_gradient\", False))\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\", line 43, in trace_op\r\n    not stop_gradient)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > paddle::platform::GetTraceBackString<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*, int)\r\n1   paddle::framework::OpRegistry::CreateOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > > > const&, std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > > > const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, boost::variant<boost::blank, int, float, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, boost::variant<boost::blank, int, float, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Operator broadcast has not been registered\r\n  [Hint: op_info_ptr should not be null.] at (/baiyifan/Paddle/paddle/fluid/framework/op_info.h:140)\r\n```",
        "state": "closed",
        "user": "baiyfbupt",
        "closed_by": "baiyfbupt",
        "created_at": "2020-04-22T09:57:15+00:00",
        "updated_at": "2020-04-23T07:25:57+00:00",
        "closed_at": "2020-04-23T07:25:57+00:00",
        "comments_count": [
            "MyPandaShaoxiang",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4567,
        "title": "OCR 用attention 训练后，用模型预测报错AssertionError: Can not find [conv2d_0.b_0] in model file ",
        "body": "Traceback (most recent call last):\r\n  File \"infer.py\", line 170, in <module>\r\n    main()\r\n  File \"infer.py\", line 166, in main\r\n    inference(args)\r\n  File \"infer.py\", line 91, in inference\r\n    var_list=fluid.io.get_program_parameter(fluid.default_main_program()))\r\n  File \"/opt/anaconda3/bin/anaconda/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1740, in load\r\n    v.name, parameter_file_name)\r\nAssertionError: Can not find [conv2d_0.b_0] in model file [models/ocr_ctc_attention/model_15000.pdparams]",
        "state": "closed",
        "user": "MrTsien",
        "closed_by": "MrTsien",
        "created_at": "2020-04-23T05:42:57+00:00",
        "updated_at": "2020-04-25T12:38:40+00:00",
        "closed_at": "2020-04-25T12:38:40+00:00",
        "comments_count": [
            "zhupengyang",
            "MrTsien"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4572,
        "title": "PP实现的googLeNet模型中，这个每一层的输出shape，不符合googLeNet的网络结构",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/models/googlenet.py\r\n\r\nPP实现的`googLeNet`模型中，这个每一层的输出`shape`，不符合googLeNet的网络结构\r\n```\r\ngoogLeNet论文中，前几层的输出是：\r\n112 * 112 * 64\r\n56 * 56 * 64\r\n56 * 56 * 192\r\n28 * 28 * 256\r\n28 * 28* 480\r\n```\r\n而PP实现是：\r\n```\r\n112 * 112 * 64\r\n55* 55* 64\r\n55* 55* 192\r\n55* 55* 256\r\n27* 27* 480\r\n```\r\n\r\n在PP中，3*3/2的`pool`操作，并不能使shape刚好为原来的1/4",
        "state": "open",
        "user": "DrRyanHuang",
        "closed_by": null,
        "created_at": "2020-04-24T08:49:59+00:00",
        "updated_at": "2020-04-26T03:30:19+00:00",
        "closed_at": null,
        "comments_count": [
            "willthefrog",
            "DrRyanHuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4573,
        "title": "OCR 用attention 训练，infer 的字符长度最长为20 个",
        "body": "OCR 用attention 训练，infer 的字符长度最长为20 ，但我有的图片不止20个。请问如何调",
        "state": "closed",
        "user": "MrTsien",
        "closed_by": "MrTsien",
        "created_at": "2020-04-25T12:31:24+00:00",
        "updated_at": "2020-04-25T13:54:34+00:00",
        "closed_at": "2020-04-25T13:54:33+00:00",
        "comments_count": [
            "MrTsien"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4574,
        "title": "请问有senta情感分类的数据集吗？谢谢",
        "body": null,
        "state": "open",
        "user": "yw1991",
        "closed_by": null,
        "created_at": "2020-04-27T05:28:12+00:00",
        "updated_at": "2024-02-26T05:11:58+00:00",
        "closed_at": null,
        "comments_count": [
            "xyzhou-puck",
            "yw1991",
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4577,
        "title": "PaddleNlp下的simnet模型，是基于<query,query>训练的吗？",
        "body": "",
        "state": "closed",
        "user": "fengmiaomiao",
        "closed_by": "fengmiaomiao",
        "created_at": "2020-04-27T07:38:11+00:00",
        "updated_at": "2020-05-07T03:48:32+00:00",
        "closed_at": "2020-05-07T03:48:32+00:00",
        "comments_count": [
            "xyzhou-puck",
            "fengmiaomiao",
            "xyzhou-puck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4578,
        "title": "PaddlePaddle七日打卡 心得",
        "body": "      深度学习PaddlePaddle深度学习七日打卡营给我的学习带来了新的方向。\r\n      我报名了这门课。通过这几天的学习，我们了解了一些关于深度学习方面的知识。没想到这门课真的是出乎我的想象。Paddle功能很强大，尤其是PaddleHub，可以让0基础的人轻松上手，并且只需要fine tune，使得低配的机器也能跑得起深度学习。\r\n      课上，老师知识点总结得十分到位，讲的也很细致，答疑区也非常活跃。虽然这几天我们并没有自己写代码来实现一个完整的项目，只是在老师提供的代码上进行添加。但是我们在这些添加的过程中，我们对深度学习有了一定的了解。同时在老师的讲解下，我们对paddle Hub也有一些了解了。总之，这次课程让我对深度学习有了一些的概念。在对这次课程使用的平台上，我觉得AI Studio真的挺好用的，与我们之前自己租的服务器相比，确实方便许多。AI Studio能图形化地进行操作，而不是仅仅使用终端进行操作，上传下载文件也挺方便的。\r\n      PaddleHub提供了众多前沿的模型，包括口罩人脸识别等，助力疫情期间企业的打卡问题，解决了企业的痛点，paddle团队真的是又快又准。\r\n      在未来的学习中，我会利用paddle参加一些比赛。感谢班主任老师，助教老师和AIstudio后台开发的劳动人员的辛苦劳动。我会好好利用这个平台，不断学习，不断充实自己！\r\n",
        "state": "open",
        "user": "tm-eng22",
        "closed_by": null,
        "created_at": "2020-04-28T02:42:09+00:00",
        "updated_at": "2024-02-26T05:11:57+00:00",
        "closed_at": null,
        "comments_count": [
            "yiicy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4579,
        "title": "异步数据读取和处理效率不高，导致GPU利用率较低",
        "body": "### 问题描述：\r\n\r\n- 试用的代码是paddlepaddle开源的deepspeech2: https://github.com/PaddlePaddle/DeepSpeech\r\n\r\n- 硬件环境：paddlepaddle-1.6, 4块GPU-v100, CPU 32core\r\n\r\n- 代码里面使用的是异步数据读取：\r\n\r\n reader = fluid.io.DataLoader.from_generator(\r\n                feed_list=inputs,\r\n                capacity=64,\r\n                iterable=False,\r\n                use_double_buffer=True)\r\n\r\n- 遇到的问题：\r\nbatch_size=64, 4块GPU-v100训练的时候，gpu利用率不到1%\r\n自己排查了io利用率不到20%，磁盘为SSD，cpu只有1-2个core用起来了，其它的30个cpu core都是空闲。\r\n\r\n根据paddlepaddle文档 \r\n (https://www.paddlepaddle.org.cn/documentation/docs/en//advanced_guide/performance_improving/singlenode_training_improving/training_best_practice.html)    提示设置FLAGS_reader_queue_speed_test_mode，关闭数据读取和预处理，纯测试GPU利用率稳定在90%以上，自行排查下来瓶颈应该在异步数据读取和预处理\r\n\r\n求帮忙解答。",
        "state": "closed",
        "user": "yangyangHu",
        "closed_by": "chenwhql",
        "created_at": "2020-04-28T03:41:31+00:00",
        "updated_at": "2021-03-03T09:30:00+00:00",
        "closed_at": "2021-03-03T09:30:00+00:00",
        "comments_count": [
            "chenwhql",
            "yangyangHu",
            "chenwhql",
            "yangyangHu",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4582,
        "title": "transformer模型中英数据集",
        "body": "想要一份适用于transformer模型的中译英数据集...自己有一份中英数据集但是规模太小感觉训练不出理想的效果。",
        "state": "open",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2020-04-28T13:23:35+00:00",
        "updated_at": "2020-04-30T08:01:17+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4583,
        "title": "seq2seq模型翻译效果问题",
        "body": "我用了官方文档-经典案例-自然语言处理-机器翻译-seq2seq模型（单一的seq2seq.py文件），换成了自己的数据集：\r\n‘’‘\r\n中英语句对25w条，中文词典9w+，英文词典8w+，训练70个轮次左右，loss值在3.7左右浮动\r\n‘’’\r\n然而，中译英效果并不好，最多只能翻译一个句子里的几个词。请问是数据集的问题还是模型的问题，还是说这个训练得要好久，loss值要收敛到多少模型才基本可用？",
        "state": "open",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2020-04-28T13:26:20+00:00",
        "updated_at": "2020-04-29T09:58:53+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4584,
        "title": "请问ernie-lac在对新句子进行infer的时候，可以不先标注么？这块有实现的逻辑么？感谢",
        "body": null,
        "state": "open",
        "user": "shiztong",
        "closed_by": null,
        "created_at": "2020-04-29T06:33:43+00:00",
        "updated_at": "2024-02-26T05:11:54+00:00",
        "closed_at": null,
        "comments_count": [
            "gfwm2013",
            "shiztong",
            "Bond-H",
            "shiztong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4586,
        "title": "similarity_net/nets/lstm.py在batch输入情况下的词向量学习问题",
        "body": "请问下在similarity_net/nets/lstm.py中，如果输入的是批量的文本，内部的lstm_layer会不会把整个batch的sentence拼接在一起，然后作为整个长句子输入到LSTM模型里面，学习每个词的表示，我看代码里的好像是这样做的，是不是有问题呀？还是我哪里没有注意到？求指教。",
        "state": "open",
        "user": "renke2",
        "closed_by": "renke2",
        "created_at": "2020-04-30T07:38:57+00:00",
        "updated_at": "2020-05-07T02:13:41+00:00",
        "closed_at": null,
        "comments_count": [
            "DannyIsFunny",
            "renke2",
            "renke2",
            "DannyIsFunny",
            "renke2",
            "DannyIsFunny",
            "renke2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4587,
        "title": "关于dcgan data列表下的数据格式问题？",
        "body": "请问使用gan模块时dcgan的数据格式应该是什么样的，我的data下的数据列表是如下形式的：\r\n![image](https://user-images.githubusercontent.com/38516795/80855741-3adfda80-8c76-11ea-80f5-6324eab216fe.png)\r\ntrain.txt的文件格式如下：\r\n![image](https://user-images.githubusercontent.com/38516795/80855760-54812200-8c76-11ea-944b-345f232bc527.png)\r\n\r\n额外的问题是测试数据我应该如何划分，望解答，感谢",
        "state": "open",
        "user": "lxk767363331",
        "closed_by": null,
        "created_at": "2020-05-02T05:11:15+00:00",
        "updated_at": "2020-05-06T09:14:20+00:00",
        "closed_at": null,
        "comments_count": [
            "liym27",
            "lxk767363331",
            "liym27",
            "ceci3",
            "lxk767363331",
            "ceci3",
            "lxk767363331",
            "ceci3",
            "lxk767363331",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4588,
        "title": "请问simnet有python3的版本吗？或者说转成Python3的环境可以正常运行吗",
        "body": "",
        "state": "closed",
        "user": "lerry-lee",
        "closed_by": "cryoco",
        "created_at": "2020-05-04T01:38:15+00:00",
        "updated_at": "2020-05-06T04:53:07+00:00",
        "closed_at": "2020-05-06T04:53:07+00:00",
        "comments_count": [
            "cryoco",
            "lerry-lee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4608,
        "title": "STNET跑模型推断，显卡显存充足，提示显存不足",
        "body": "模型运行语句如下\r\n![QQ截图20200512105638](https://user-images.githubusercontent.com/22005432/81633499-7b421400-943f-11ea-9b9e-ff291c145976.jpg)\r\n\r\n报错截图：\r\n![QQ截图20200512105919](https://user-images.githubusercontent.com/22005432/81633607-b6dcde00-943f-11ea-98af-6b4c4a05d0ee.jpg)\r\n\r\n显存占用：\r\n![image](https://user-images.githubusercontent.com/22005432/81633655-d247e900-943f-11ea-891d-fb87c3b1d9c1.png)\r\n\r\n\r\n",
        "state": "open",
        "user": "vincentpengpeng",
        "closed_by": null,
        "created_at": "2020-05-12T03:00:51+00:00",
        "updated_at": "2024-02-26T05:11:49+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4600,
        "title": "tf2pkl.py中tensorflow 使用的版本是多少能透露一下吗",
        "body": null,
        "state": "open",
        "user": "haoyijiang",
        "closed_by": null,
        "created_at": "2020-05-11T01:14:10+00:00",
        "updated_at": "2024-02-26T05:11:50+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4624,
        "title": "使用paddler serving保存simnet可服务模型问题",
        "body": "`\r\nimport paddle_serving_client.io as serving_io   \r\n \r\nmodel_dir = 'bow_pairwise/simnet'\r\nserving_model = 'simnet_model'\r\nserving_client = 'simnet_client'\r\ndata=?\r\nsimilarity=?\r\nserving_io.save_model(serving_model, serving_client,{'data': data}, {'similarity':similarity},model_dir)\r\n`\r\n我看了下bert保存为可服务模型的示例，但是我还是不明白如何写simnet的输入和输出，有知道的可以指教一下吗",
        "state": "open",
        "user": "lerry-lee",
        "closed_by": null,
        "created_at": "2020-05-14T13:12:00+00:00",
        "updated_at": "2020-12-08T09:43:53+00:00",
        "closed_at": null,
        "comments_count": [
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "lerry-lee",
            "lerry-lee",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee",
            "MRXLT",
            "lerry-lee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4627,
        "title": "调用动态图实现的Linear_chain_crf的问题",
        "body": "实现该接口的文件如下：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/dygraph/lac/sequence_labeling.py\r\n运行的环境是aistudio高级版，paddlepaddle 1.7.1, python 3.7\r\n我调用的代码如下：\r\n```\r\nlinear_chain_crf = Linear_chain_crf(\r\n        param_attr=fluid.ParamAttr(\r\n            name='linear_chain_crfw', learning_rate=LR),\r\n        size=num_labels)\r\ncrf_cost = linear_chain_crf(emission, label=label, length=MAX_SEQLEN)\r\n```\r\nemission.shape和label.shape均为[16, 400, 5]。其中16是batch_size，400是序列最大长度，5是序列标注的类别数量。\r\n执行之后报错，没有找到该接口对输入参数的具体要求，因而想咨询一下这是出现这个问题的原因。报错信息如下：\r\n\r\n```bash\r\n> ---------------------------------------EnforceNotMet                             Traceback (most recent call last)<ipython-input-36-85157a21fed9> in <module>\r\n> ----> 1 linear_chain_crf(emission, label=label, length=128)\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n>     302             self._built = True\r\n>     303 \r\n> --> 304         outputs = self.forward(*inputs, **kwargs)\r\n>     305         return outputs\r\n>     306 \r\n> ~/ernie/sequence_labeling.py in forward(self, input, label, length)\r\n>     177                         },\r\n>     178                         attrs={\r\n> --> 179                             \"is_test\": self._is_test,\r\n>     180                         })\r\n>     181         return log_likelihood\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layer_object_helper.py in append_op(self, type, inputs, outputs, attrs, stop_gradient)\r\n>      50             outputs=outputs,\r\n>      51             attrs=attrs,\r\n> ---> 52             stop_gradient=stop_gradient)\r\n>      53 \r\n>      54     def _multiple_input(self, inputs_in):\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in append_op(self, *args, **kwargs)\r\n>    2514                                        kwargs.get(\"outputs\", {}), attrs\r\n>    2515                                        if attrs else {},\r\n> -> 2516                                        kwargs.get(\"stop_gradient\", False))\r\n>    2517         else:\r\n>    2518             op_desc = self.desc.append_op()\r\n> /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py in trace_op(self, type, inputs, outputs, attrs, stop_gradient)\r\n>      37         self.trace(type, inputs, outputs, attrs,\r\n>      38                    framework._current_expected_place(), self._train_mode and\r\n> ---> 39                    not stop_gradient)\r\n>      40 \r\n>      41     def train_mode(self):\r\n> EnforceNotMet: \r\n> \r\n> --------------------------------------------\r\n> C++ Call Stacks (More useful to developers):\r\n> --------------------------------------------\r\n> 0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n> 1   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n> \r\n> ----------------------\r\n> Error Message Summary:\r\n> ----------------------\r\n> Error: Python object is not type of St10shared_ptrIN6paddle10imperative7VarBaseEE at (/paddle/paddle/fluid/pybind/imperative.cc:158)\r\n```",
        "state": "open",
        "user": "yaweisun",
        "closed_by": null,
        "created_at": "2020-05-14T15:22:08+00:00",
        "updated_at": "2020-05-15T08:07:27+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "yaweisun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4634,
        "title": "How can I get access to the Reddit and Twitter corpora used for pretraining?",
        "body": "Could you please provides download links for these two datasets? Thanks a lot!",
        "state": "open",
        "user": "JiaQiSJTU",
        "closed_by": null,
        "created_at": "2020-05-17T05:56:34+00:00",
        "updated_at": "2024-02-26T05:11:45+00:00",
        "closed_at": null,
        "comments_count": [
            "kirayummy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4637,
        "title": "Paddle1.6 模型库 paddleNlp/sentiment_classification   这个怎么单机多卡训练啊",
        "body": "Paddle1.6 模型库 paddleNlp/sentiment_classification   \r\nrun_ernie.sh   设置了环境变量\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5\r\n但是实际跑起来只有0在跑，其他的都没有跑\r\n这个怎么单机多卡训练啊",
        "state": "open",
        "user": "huoyuming",
        "closed_by": null,
        "created_at": "2020-05-18T13:04:25+00:00",
        "updated_at": "2024-02-26T05:11:43+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "huoyuming"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4641,
        "title": "请问分词工具tokenizer如何提高某个词的词频使其能够分成一个词？",
        "body": "如题",
        "state": "closed",
        "user": "lerry-lee",
        "closed_by": "lerry-lee",
        "created_at": "2020-05-19T01:58:21+00:00",
        "updated_at": "2020-05-24T14:28:16+00:00",
        "closed_at": "2020-05-24T14:28:16+00:00",
        "comments_count": [
            "1024er",
            "lerry-lee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4640,
        "title": "使用resnet网络出错",
        "body": "使用paddle官方给的resnet50模型训练数据，出现错误，TypeError: fc() got an unexpected keyword argument 'is_test'，请问是什么问题。b站别人视频同样运行没有出错",
        "state": "open",
        "user": "hwx724221178",
        "closed_by": null,
        "created_at": "2020-05-18T15:31:16+00:00",
        "updated_at": "2024-02-26T05:11:42+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4645,
        "title": "paddle推理时在python脚本中如何设置GPU的显存比例",
        "body": "通过以下方式，设置无效：   \r\n```\r\n        os.environ['FLAGS_selected_gpus']=“1”\r\n        os.environ['FLAGS_fraction_of_gpu_memory_to_use']=“0.5”\r\n        os.environ['FLAGS_enable_parallel_graph']=\"1\"\r\n        os.environ['FLAGS_sync_nccl_allreduce']=\"1\"\r\n```\r\n",
        "state": "open",
        "user": "ninghongbo123",
        "closed_by": null,
        "created_at": "2020-05-19T06:54:15+00:00",
        "updated_at": "2024-02-26T05:11:41+00:00",
        "closed_at": null,
        "comments_count": [
            "cryoco"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4647,
        "title": "sequence_pool meet LoD Level  unmatch error",
        "body": "my code was like:\r\n\r\npyreader = fluid.layers.py_reader(\r\n            capacity=50,\r\n            shapes=[[-1, max_seq_len, 1], [-1, max_seq_len, 1],\r\n                    [-1, max_seq_len, 1], [-1, max_seq_len, 1],\r\n                    [-1, max_seq_len, 1], [-1, 1], [-1, 1]],\r\n            dtypes=[\r\n                'int64', 'int64', 'int64', 'int64', 'float32', 'int64', 'int64'\r\n            ],\r\n            lod_levels=[0, 0, 0, 0, 0, 0, 0],\r\n            name=task_name + \"_\" + pyreader_name,\r\n            use_double_buffer=True)\r\n(src_ids, sent_ids, pos_ids, task_ids, input_mask, labels,\r\n     qids) = fluid.layers.read_file(pyreader)\r\n\r\nqt_emb = fluid.layers.embedding(\r\n    input=src_ids,\r\n    is_sparse=False,\r\n    size=[18000, 16],\r\n    param_attr=fluid.ParamAttr(name='vocab_embedding',\r\n                               initializer=fluid.initializer.Uniform()))\r\nqt_embed_sum = fluid.layers.sequence_pool(qt_emb, pool_type='sum')\r\n\r\nwhen i run it, i have these error message:\r\n\r\nError: The LoD level Input(X) of sequence_pool should be larger than 0.\r\n  [Hint: Expected in_lod_level > 0, but received in_lod_level:0 <= 0:0.] at (/home/teamcity/buildAgent/work/1ec40e2d88fa641/paddle/fluid/operators/sequence_ops/sequence_pool_op.cc:37)\r\n  [operator < sequence_pool > error]\r\n\r\n",
        "state": "open",
        "user": "alz95",
        "closed_by": null,
        "created_at": "2020-05-19T10:51:41+00:00",
        "updated_at": "2024-02-26T05:11:39+00:00",
        "closed_at": null,
        "comments_count": [
            "1024er"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4654,
        "title": "生成一个跟其他矩阵shape一致的对角矩阵",
        "body": "尝试eye实现一个矩阵，但是shape需要事先指定好，不支持动态；比如生成一个batch_size*batch_size的对角矩阵，batch_size配置为32，但是实际运行中样本没有32条，只有6条，这时候我需要的对角矩阵其实是6*6的 而不是32*32的，目前没有找到比较好的办法实现一个shape动态的对角矩阵,如下图error：\r\n![image](https://user-images.githubusercontent.com/8426657/82402876-136b7900-9a90-11ea-8192-9c929e96753f.png)\r\n![image](https://user-images.githubusercontent.com/8426657/82402930-3eee6380-9a90-11ea-9c6a-0348bc7253da.png)\r\n",
        "state": "open",
        "user": "lxwzju",
        "closed_by": null,
        "created_at": "2020-05-20T03:51:35+00:00",
        "updated_at": "2024-02-26T05:11:38+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84",
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4655,
        "title": "在训练的时候这几个参数['reduce_sum_0.tmp_0', 'reduce_sum_2.tmp_0', 'elementwise_sub_0']其中第一个参数的值为nan这是为什么",
        "body": "在训练的时候这几个参数['reduce_sum_0.tmp_0', 'reduce_sum_2.tmp_0', 'elementwise_sub_0']对应的值为 [nan, 4.791813, 5]，其中第一个参数reduce_sum_0.tmp_0的值为nan这是为什么？之前的训练都是正常的，在executor执行run后输出的结果中出现Nan，求解答",
        "state": "closed",
        "user": "BeyondYourself",
        "closed_by": "BeyondYourself",
        "created_at": "2020-05-20T06:28:01+00:00",
        "updated_at": "2020-05-21T00:58:45+00:00",
        "closed_at": "2020-05-21T00:58:45+00:00",
        "comments_count": [
            "Aurelius84",
            "BeyondYourself",
            "LDOUBLEV",
            "BeyondYourself",
            "LDOUBLEV",
            "BeyondYourself",
            "LDOUBLEV",
            "LDOUBLEV",
            "BeyondYourself"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4665,
        "title": "Figure 10 of PaddleSlim tutorial is missing",
        "body": "Figure 10 of PaddleSlim tutorial is missing\r\n\r\nthis path:\r\n./PaddleSlim/docs/images/tutorial/light-nas-block.png",
        "state": "closed",
        "user": "keosu",
        "closed_by": "keosu",
        "created_at": "2020-05-27T06:26:50+00:00",
        "updated_at": "2020-05-27T06:48:17+00:00",
        "closed_at": "2020-05-27T06:48:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4660,
        "title": "请问paddle模型如何一次初始化，多次预测",
        "body": "意思是，一次将模型初始化到内存中，后续多次送入不同的预测数据.\r\n目前是每次预测都要重新加载一次模型文件.",
        "state": "closed",
        "user": "lerry-lee",
        "closed_by": "lerry-lee",
        "created_at": "2020-05-24T14:31:18+00:00",
        "updated_at": "2020-06-27T06:51:13+00:00",
        "closed_at": "2020-06-27T06:51:13+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4663,
        "title": "PLATO执行训练时报错",
        "body": "我在PaddlePaddle 1.6.3的版本上， 运行PLATO的\r\nhttps://github.com/PaddlePaddle/Research/tree/master/NLP/Dialogue-PLATO\r\nDATASET=DailyDialog\r\nsh scripts/${DATASET}/train.sh\r\n\r\n命令时，报如下的错误：\r\n----------------------\r\n\r\nError Message Summary:\r\n\r\n----------------------\r\n\r\nError: ShapeError: The last dimensions of the 'Ids' tensor must be 1. But received Ids's last dimensions = 173, Ids's shape = [4, 173].\r\n\r\n  [Hint: Expected ids_dims[ids_rank - 1] == 1, but received ids_dims[ids_rank - 1]:173 != 1:1.] at (/paddle/paddle/fluid/operators/lookup_table_op.cc:51)\r\n\r\n+ [[ false = true ]]\r\n\r\nscripts/PersonaChat/train.sh: 47: scripts/PersonaChat/train.sh: [[: not found\r\n请帮忙看看是什么原因，使用的是CPUPlace，没有使用GPU。\r\n",
        "state": "open",
        "user": "MartinKUNGGitHub",
        "closed_by": null,
        "created_at": "2020-05-26T04:57:13+00:00",
        "updated_at": "2024-02-26T05:11:37+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4667,
        "title": "训练管理工具",
        "body": "最近在反复跑一个分割的模型炼丹，发现管理不同配置实验的结果十分复杂。想提问大佬们管理这么多模型，这么多实验，有没有好的工具或经验分享。",
        "state": "closed",
        "user": "linhandev",
        "closed_by": "gongweibao",
        "created_at": "2020-05-27T15:56:19+00:00",
        "updated_at": "2020-05-28T07:24:14+00:00",
        "closed_at": "2020-05-28T07:24:14+00:00",
        "comments_count": [
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4664,
        "title": "个性化推荐-DeepCTR  paddleserving 报  Illegal instruction     (core dumped) 问题",
        "body": "通过 kubectl get pod 查看状态，paddleserving一直处于CrashLoopBackOff\r\npaddleserving                         0/1     CrashLoopBackOff   259        21h\r\n\r\n查看日志，kubectl logs paddleserving -n recommendation-paddle 显示\r\nrun.sh: line 6:    12 Illegal instruction     (core dumped) ./bin/elastic_serving\r\n\r\n",
        "state": "open",
        "user": "HankPeng03",
        "closed_by": null,
        "created_at": "2020-05-27T02:04:19+00:00",
        "updated_at": "2024-02-26T05:11:36+00:00",
        "closed_at": null,
        "comments_count": [
            "gongweibao",
            "HankPeng03",
            "gongweibao",
            "HankPeng03"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4668,
        "title": "lexical_analysis中eval为何特别慢",
        "body": "从源码中读，看不出问题。一个短句、抽4个类型、大概得1s。直接在原始数据集测试也是。",
        "state": "open",
        "user": "AltenLi",
        "closed_by": null,
        "created_at": "2020-05-27T15:56:51+00:00",
        "updated_at": "2024-02-26T05:11:35+00:00",
        "closed_at": null,
        "comments_count": [
            "1024er",
            "AltenLi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4670,
        "title": "lexical_analysis中代码有bug",
        "body": "optimizer = fluid.optimizer.Adam(\r\n                learning_rate=args.base_learning_rate, \r\n                grad_clip=clip)\r\noptimizer.minimize(train_ret[\"avg_cost\"])\r\n\r\n-------应该为--------\r\n\r\noptimizer = fluid.optimizer.Adam(\r\n                learning_rate=args.base_learning_rate)\r\noptimizer.minimize(train_ret[\"avg_cost\"], \r\n                grad_clip=clip)",
        "state": "closed",
        "user": "AltenLi",
        "closed_by": "AltenLi",
        "created_at": "2020-05-28T14:22:25+00:00",
        "updated_at": "2020-06-08T12:12:36+00:00",
        "closed_at": "2020-06-08T12:12:36+00:00",
        "comments_count": [
            "guoshengCS",
            "AltenLi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4669,
        "title": "请问paddle的度量学习这一块能部署到c++下么？",
        "body": "paddle中的度量学习这一块是否可以部署到c++下？\r\n谢谢",
        "state": "open",
        "user": "baigang666",
        "closed_by": null,
        "created_at": "2020-05-28T06:42:54+00:00",
        "updated_at": "2024-02-26T05:11:33+00:00",
        "closed_at": null,
        "comments_count": [
            "baigang666",
            "guoshengCS",
            "baigang666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4677,
        "title": "undefined symbol: when trying PointNet++",
        "body": "Hi\r\n\r\nI follow the following process to do the test.\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleCV/3d_vision/PointNet++\r\n\r\nBut I tried with the following paddle version, and get the same error.\r\n\r\n- pip paddle gpu v1.8.1 with models tag v1.8.0\r\n- conda paddle gpu v1.8.1 with models tag v1.8.0\r\n- docker paddle gpu v1.8.1 with models tag v1.8.0\r\n- docker paddle gpu v1.7.1 with models tag v1.7.0\r\n\r\nI have set the LD_LIBRARY_PATH, and from the log, pointnet_lib.so is found.\r\nBut failed due to link issue.\r\nDid I miss anything?\r\n\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src# ls\r\nfarthest_point_sampling_op.cc  gather_point_op.cu  make.sh           query_ball_op.cu    three_nn_op.cc\r\nfarthest_point_sampling_op.cu  group_points_op.cc  pointnet_lib.so   three_interp_op.cc  three_nn_op.cu\r\ngather_point_op.cc             group_points_op.cu  query_ball_op.cc  three_interp_op.cu  util.cu.h\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src# bash make.sh\r\n/usr/local/lib/python2.7/dist-packages/paddle/include\r\n/usr/local/lib/python2.7/dist-packages/paddle/libs\r\n\r\n\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src#\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src#\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:`python -c 'import paddle; print(paddle.sysconfig.get_lib())'`\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src# cd ..\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op# export PYTHONPATH=$PYTHONPATH:`pwd`\r\nroot@907039411a82:/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op# python tests/test_farthest_point_sampling_op.py\r\nW0531 08:31:49.706547   225 dynamic_loader.cc:120] Can not find library: /paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src/pointnet_lib.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\n  File \"tests/test_farthest_point_sampling_op.py\", line 20, in <module>\r\n    import pointnet_lib\r\n  File \"/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/pointnet_lib.py\", line 19, in <module>\r\n    fluid.load_op_library(os.path.join(file_dir, 'src/pointnet_lib.so'))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 5035, in load_op_library\r\n    core.load_op_library(lib_filename)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::dynload::GetOpDsoHandle(std::string const&)\r\n3   paddle::framework::LoadOpLib(std::string const&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Failed to find dynamic library: /paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src/pointnet_lib.so ( /paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src/pointnet_lib.so: undefined symbol: _ZNK6paddle9framework12OperatorBase13DebugStringExB5cxx11EPKNS0_5ScopeE )\r\n Please specify its path correctly using following ways:\r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\n For instance, issue command: export LD_LIBRARY_PATH=...\r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at (/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177)",
        "state": "open",
        "user": "MiiViiDynamics",
        "closed_by": null,
        "created_at": "2020-05-31T08:39:14+00:00",
        "updated_at": "2024-02-26T05:11:32+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "MiiViiDynamics",
            "zhufeng888",
            "XiaXingLuo",
            "zhufeng888",
            "zhufeng888",
            "XiaXingLuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4679,
        "title": "想要训练tensorflow模型，但是却报了paddle的错",
        "body": "在训练tensorflow nonlocal的模型时加载了paddle nonlocal的imageNet上的预训练模型。遇到了如下报错：\r\n\r\n2020-06-02 11:34:12.696932: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this Te\r\nnsorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-06-02 11:34:13.135866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \r\nname: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\npciBusID: 0000:3e:00.0\r\ntotalMemory: 31.72GiB freeMemory: 26.64GiB\r\n2020-06-02 11:34:13.135905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n2020-06-02 11:34:13.989357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with \r\nstrength 1 edge matrix:\r\n2020-06-02 11:34:13.989401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n2020-06-02 11:34:13.989410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n2020-06-02 11:34:13.991195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localho\r\nst/replica:0/task:0/device:GPU:0 with 25848 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0\r\n000:3e:00.0, compute capability: 7.0)\r\nrun ini time is 1.33219480515\r\n2020-06-02 11:34:35.715417: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\n2020-06-02 11:34:35.716288: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nW0602 11:34:35.716351 87921 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0602 11:34:35.716372 87921 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or repo\r\nrt the case to PaddlePaddle\r\nW0602 11:34:35.716377 87921 init.cc:214] The detail failure signal is:\r\n\r\nW0602 11:34:35.716383 87921 init.cc:217] *** Aborted at 1591068875 (unix time) try \"date -d @1591068875\" if you are using GN\r\nU date ***\r\n2020-06-02 11:34:35.718102: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\n2020-06-02 11:34:35.718838: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nW0602 11:34:35.718925 87921 init.cc:217] PC: @                0x0 (unknown)\r\nW0602 11:34:35.719225 87921 init.cc:217] *** SIGABRT (@0x155ce) received by PID 87502 (TID 0x7fd3cdffb700) from PID 87502; s\r\ntack trace: ***\r\n2020-06-02 11:34:35.720662: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\nW0602 11:34:35.721504 87921 init.cc:217]     @     0x7fd5c20f25e0 (unknown)\r\n2020-06-02 11:34:35.722468: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nW0602 11:34:35.723459 87921 init.cc:217]     @     0x7fd5c164b1f7 __GI_raise\r\n2020-06-02 11:34:35.725009: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\nW0602 11:34:35.725256 87921 init.cc:217]     @     0x7fd5c164c8e8 __GI_abort\r\n2020-06-02 11:34:35.726091: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\n2020-06-02 11:34:35.728042: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\n2020-06-02 11:34:35.728924: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nW0602 11:34:35.730231 87921 init.cc:217]     @     0x7fd4fbbcc374 tensorflow::internal::LogMessageFatal::~LogMessageFatal()\r\n2020-06-02 11:34:35.730621: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7605 (compatibi\r\nlity version 7600) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your \r\nCuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version spec\r\nified during compile configuration.\r\n2020-06-02 11:34:35.731292: F tensorflow/core/kernels/conv_ops_3d.cc:399] Check failed: stream->parent()->GetConvolveAlgorit\r\nhms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nW0602 11:34:35.733728 87921 init.cc:217]     @     0x7fd4fb8cdc47 tensorflow::LaunchConvOp<>::launch()\r\nW0602 11:34:35.738135 87921 init.cc:217]     @     0x7fd4fb8ce019 tensorflow::Conv3DOp<>::Compute()\r\nW0602 11:34:35.739372 87921 init.cc:217]     @     0x7fd4f6e36289 tensorflow::BaseGPUDevice::ComputeHelper()\r\nW0602 11:34:35.740073 87921 init.cc:217]     @     0x7fd4f6e36750 tensorflow::BaseGPUDevice::Compute()\r\nW0602 11:34:35.740639 87921 init.cc:217]     @     0x7fd4f6e70365 tensorflow::(anonymous namespace)::ExecutorState::Process(\r\n)\r\nW0602 11:34:35.741199 87921 init.cc:217]     @     0x7fd4f6e70b7a _ZNSt17_Function_handlerIFvvEZN10tensorflow12_GLOBAL__N_11\r\n3ExecutorState13ScheduleReadyERKNS1_3gtl13InlinedVectorINS3_10TaggedNodeELi8EEEPNS3_20TaggedNodeReadyQueueEEUlvE_E9_M_in 49 \r\nvokeERKSt9_Any_data\r\nW0602 11:34:35.742094 87921 init.cc:217]     @     0x7fd4f6ae18ba Eigen::NonBlockingThreadPoolTempl<>::WorkerLoop()\r\nW0602 11:34:35.742883 87921 init.cc:217]     @     0x7fd4f6ae0962 _ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenE\r\nnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\nW0602 11:34:35.743469 87921 init.cc:217]     @     0x7fd4ed435070 (unknown)\r\nW0602 11:34:35.744760 87921 init.cc:217]     @     0x7fd5c20eae25 start_thread\r\nW0602 11:34:35.746145 87921 init.cc:217]     @     0x7fd5c170e35d __clone\r\nW0602 11:34:35.747447 87921 init.cc:217]     @                0x0 (unknown)\r\n",
        "state": "open",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2020-06-02T03:53:20+00:00",
        "updated_at": "2020-06-03T11:41:55+00:00",
        "closed_at": null,
        "comments_count": [
            "NHZlX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4678,
        "title": "生成模型的时候出现cannot import name init_on_cpu的错",
        "body": "root@fae-Z370-HD3P:/paddle/models-1.6/PaddleCV/image_classification# ./scripts/train/ResNet50.sh\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 41, in <module>\r\n    import reader\r\n  File \"/paddle/models-1.6/PaddleCV/image_classification/reader.py\", line 24, in <module>\r\n    from utils.autoaugment import ImageNetPolicy\r\n  File \"/paddle/models-1.6/PaddleCV/image_classification/utils/__init__.py\", line 14, in <module>\r\n    from .optimizer import cosine_decay, lr_warmup, cosine_decay_with_warmup, exponential_decay_with_warmup, Optimizer, create_optimizer\r\n  File \"/paddle/models-1.6/PaddleCV/image_classification/utils/optimizer.py\", line 23, in <module>\r\n    from paddle.fluid.initializer import init_on_cpu\r\nImportError: cannot import name init_on_cpu\r\n",
        "state": "open",
        "user": "BaronChiao",
        "closed_by": null,
        "created_at": "2020-06-01T08:32:22+00:00",
        "updated_at": "2024-02-26T05:11:31+00:00",
        "closed_at": null,
        "comments_count": [
            "BaronChiao",
            "phlrain",
            "BaronChiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4688,
        "title": "BERT 使用问题",
        "body": "BERT的github介绍中没有做Token级别分类的相关示例，可否提供以下利用Paddle中BERT做token级别分类的示例",
        "state": "closed",
        "user": "liu0haha123",
        "closed_by": "liu0haha123",
        "created_at": "2020-06-06T11:14:16+00:00",
        "updated_at": "2020-06-07T02:24:14+00:00",
        "closed_at": "2020-06-07T02:24:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4680,
        "title": "动态图resnet的分布式训练卡住跑不动",
        "body": "## 问题\r\n按照模型库中[resnet动态图](https://github.com/PaddlePaddle/models/tree/release/1.8/dygraph/resnet)的README进行分布式训练，执行了`python -m paddle.distributed.launch --selected_gpus=0,5,6,7  --log_dir ./mylog train.py --use_data_parallel 1`命令后，就一直卡在`start data reader`，没有再输出任何内容。  \r\n\r\n## 输出结果\r\n![image](https://user-images.githubusercontent.com/11596165/83506107-48001b80-a4f9-11ea-85f5-649a88321ccd.png)\r\n\r\n各个节点的输出\r\n![image](https://user-images.githubusercontent.com/11596165/83506138-55b5a100-a4f9-11ea-8cc4-739a7984f7a5.png)\r\n\r\n## 环境\r\n分别尝试了两套环境\r\n1. 物理机环境：\r\nPaddlePaddle-gpu：1.8.1-post107\r\ncuda：9.0\r\ncudnn：7.6.5\r\nnccl：2.5.6\r\n\r\n2. docker环境\r\ndocker版本：1.8.1-gpu-cuda10.0-cudnn7",
        "state": "open",
        "user": "LKKlein",
        "closed_by": null,
        "created_at": "2020-06-02T09:54:27+00:00",
        "updated_at": "2020-08-08T16:26:16+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain",
            "LKKlein"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4686,
        "title": "paddleseg",
        "body": "你好，能出一个遥感影像语义分割的项目",
        "state": "open",
        "user": "chang-png",
        "closed_by": null,
        "created_at": "2020-06-04T00:35:48+00:00",
        "updated_at": "2024-02-26T05:11:27+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4689,
        "title": "simnet训练时如何打印训练集上的loss，看了下打印的是验证集上的loss",
        "body": "`valid_loss: 0.886467`\r\n如题，因为有时候想知道有没有拟合训练集",
        "state": "closed",
        "user": "lerry-lee",
        "closed_by": "lerry-lee",
        "created_at": "2020-06-07T11:05:02+00:00",
        "updated_at": "2020-06-09T09:24:59+00:00",
        "closed_at": "2020-06-09T09:24:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4690,
        "title": "请问视频分类ATTENTION LSTM里的评价指标分别是什么意思？",
        "body": "我在做视频分类模型的时候训练LOSS后面有这三个指标，我只想知道分类的准确率，可是好像没有一个是准去率，请问Hit@1 = 0.50, PERR = 0.92, GAP = 0.98这三个指标分别指什么？",
        "state": "closed",
        "user": "Derek-Kun",
        "closed_by": "Derek-Kun",
        "created_at": "2020-06-08T09:54:33+00:00",
        "updated_at": "2020-06-09T13:13:59+00:00",
        "closed_at": "2020-06-09T13:13:59+00:00",
        "comments_count": [
            "huangjun12",
            "Derek-Kun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4691,
        "title": "feed_vars 和fetch_targets for using save_model on blazeface",
        "body": "请问我要用save_model来保存blazeface模型，以便在serving上运行，我应该使用什么作为feed_vars 和fetch_targets?\r\n\r\n谢谢！",
        "state": "closed",
        "user": "kgkzhiwen",
        "closed_by": "kgkzhiwen",
        "created_at": "2020-06-08T11:28:00+00:00",
        "updated_at": "2020-08-10T16:05:49+00:00",
        "closed_at": "2020-08-10T16:05:49+00:00",
        "comments_count": [
            "heavengate",
            "kgkzhiwen",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4693,
        "title": "是否支持直接将pytorch模型转换为Paddle Fluid 模型？",
        "body": "目标是将[spanbert](https://github.com/facebookresearch/SpanBERT) 中开源的pytorch 版模型转换为paddle fluid 模型用于fine-tune，类似repo中[bert](https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/pretrain_language_models/BERT)\r\n\r\n已尝试过的方案：\r\n\r\n* 利用X2paddle转换模型，但得到的模型不能直接用于fine-tune\r\n* 先将pytorch模型转换为TensorFlow，再利用脚本[convert_params.py](https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleNLP/pretrain_language_models/BERT/convert_params.py)转换为paddle模型，加载转换后的模型未报错，但fine-tune时不收敛",
        "state": "closed",
        "user": "Akeepers",
        "closed_by": "Akeepers",
        "created_at": "2020-06-08T13:01:49+00:00",
        "updated_at": "2020-06-09T09:27:23+00:00",
        "closed_at": "2020-06-09T09:27:23+00:00",
        "comments_count": [
            "heavengate",
            "Akeepers",
            "heavengate",
            "Akeepers",
            "heavengate",
            "Akeepers",
            "heavengate",
            "Akeepers",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4692,
        "title": "lexical_analysis中eval的结果和我人工评估的效果不一致。",
        "body": "在2个自建数据集测试了，人工评估f1均比自动评估低0.15左右。\r\n辛苦看下是代码问题还是fluid.layers.chunk_eval的问题\r\n",
        "state": "open",
        "user": "AltenLi",
        "closed_by": null,
        "created_at": "2020-06-08T12:15:14+00:00",
        "updated_at": "2024-02-26T05:11:26+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4697,
        "title": "paddle-slim提供的所有量化的模型下载链接都失效了",
        "body": "请问，啥时候可以修复一哈？",
        "state": "closed",
        "user": "ArtyZe",
        "closed_by": "ArtyZe",
        "created_at": "2020-06-11T03:26:02+00:00",
        "updated_at": "2020-06-12T02:36:39+00:00",
        "closed_at": "2020-06-12T02:36:39+00:00",
        "comments_count": [
            "sandyhouse",
            "ArtyZe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4694,
        "title": "emotion_detection多线程调用模型预测，返回结果为空",
        "body": "PaddleNLP\\emotion_detection 模型预测封装为服务类，多线程调用，当超过3个线程以上运行时，\r\npred = exe.run(infer_program,\r\n                   feed={feed_names[0]: data,\r\n                             feed_names[1]: seq_lens},\r\n                   fetch_list=fetch_targets,\r\n                   return_numpy=True)  返回的pred是个空列表，没有情感预测的三个概率数值，有一定几率出现",
        "state": "open",
        "user": "Veipin",
        "closed_by": null,
        "created_at": "2020-06-10T09:48:30+00:00",
        "updated_at": "2020-06-12T07:17:04+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian",
            "Veipin",
            "Veipin",
            "hutuxian",
            "Veipin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4698,
        "title": "报一个video_tag的BUG",
        "body": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/application/video_tag/metrics/metrics_util.py#L125\r\n\r\n这里应该是：\r\nf.write(json.dumps(res_list, ensure_ascii=False))",
        "state": "open",
        "user": "chizhizhen",
        "closed_by": null,
        "created_at": "2020-06-11T04:47:13+00:00",
        "updated_at": "2020-10-27T07:23:13+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "TerryBryant",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4702,
        "title": "dssm 给出的demo疑问",
        "body": "models/PaddleRec/dssm/ 下给出的demo中\r\ndssm.py 为什么使用随机生成的数据可以收敛\r\ninfer.py中随机生成的数据为什么相似性接近1，那是不是随便给query和doc的相似性都是1，这是有问题的吧",
        "state": "open",
        "user": "lixingtao",
        "closed_by": null,
        "created_at": "2020-06-12T09:34:36+00:00",
        "updated_at": "2024-02-26T05:11:21+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4701,
        "title": "关于deepFM中embedding处理变长ids的问题",
        "body": "请问 paddle embedding 是否支持变长 ids 的查找和聚合，类似 tf 的 https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse\r\n我已经实现了官网的deepFM_dygraph，但是面对有的用户的兴趣是多样的，比如A 喜欢历史，权重0.6，喜欢音乐，权重0.3， 喜欢汽车，权重0.1，B喜欢体育，权重0.2，喜欢情感，权重0.5， 这个是否可以通过embedding解决，最好提供demo参考",
        "state": "open",
        "user": "leidaxia",
        "closed_by": null,
        "created_at": "2020-06-12T06:24:45+00:00",
        "updated_at": "2024-02-26T05:11:23+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "leidaxia",
            "ceci3",
            "leidaxia",
            "ceci3",
            "leidaxia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4703,
        "title": "PointNet++ Windows C++ Inference is not supported",
        "body": "Hi,\r\n\r\n### **问题:**\r\n![pointnet++_paddle](https://user-images.githubusercontent.com/5748897/84624995-fa31dd00-af14-11ea-8cc4-fc4650d08868.png)\r\nPointNet++现在无法支持Windows C++部署, 有支持的计划吗? 如果官方没有支持, 那可以提供一个Workaround的思路吗? 另外, 如果我后续想用PaddleServing做云端部署, custom_op会影响部署吗? 有相应的部署例子吗? 谢谢!\r\n\r\n\r\n",
        "state": "open",
        "user": "jakeju92",
        "closed_by": null,
        "created_at": "2020-06-15T06:37:21+00:00",
        "updated_at": "2024-03-07T05:46:19+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "ZiqiXiong0603",
            "jakeju92",
            "ZiqiXiong0603",
            "jakeju92",
            "ZiqiXiong0603",
            "ScarRipper",
            "ScarRipper"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4704,
        "title": "config中init_model和gan_mode的说明都一样，是不是错了",
        "body": "https://github.com/PaddlePaddle/models/blob/08316fb833602f26d718defe2f40b81c1b8bc27a/PaddleCV/gan/util/config.py#L100\r\n\r\n这个地方init_model和gan_mode的注释都一样，是不是错了\r\n   add_arg('init_model', str, None, \"The init model file of directory.\")\r\n   add_arg('gan_mode', str, \"vanilla\", \"The init model file of directory.\")",
        "state": "closed",
        "user": "wzy-99",
        "closed_by": "ceci3",
        "created_at": "2020-06-15T10:51:48+00:00",
        "updated_at": "2020-06-19T06:01:12+00:00",
        "closed_at": "2020-06-19T06:01:11+00:00",
        "comments_count": [
            "ceci3",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4709,
        "title": "Add MobileDets and RegNet into model pool",
        "body": "Hi,\r\nWe have found MobileDets and RegNet have better performance on edge devices, please consider when to add these two models into model pool\r\nMobileDets:https://arxiv.org/abs/2004.14525?context=cs.CV\r\nRegNet: https://medium.com/analytics-vidhya/regnet-or-how-to-methodologically-design-effective-networks-c3560c1cf436\r\n",
        "state": "open",
        "user": "hi-bigcat",
        "closed_by": null,
        "created_at": "2020-06-19T07:29:26+00:00",
        "updated_at": "2020-06-22T06:17:59+00:00",
        "closed_at": null,
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4711,
        "title": "关于PyramidBox论文中CPM模块的一些疑问",
        "body": "在论文中的Fig3里面，画了一个CPM模块，即背景感知模块，下面是他的图示\r\n![image](https://user-images.githubusercontent.com/42901638/85221637-e50eef80-b3e7-11ea-8d4c-6da33a13d341.png)\r\n\r\n在代码里面，也有对应的实现\r\n![image](https://user-images.githubusercontent.com/42901638/85221623-cdd00200-b3e7-11ea-958c-eacba5369004.png)\r\n\r\n方法里的cpm方法是构造CPM模块的，但我自己画图发现它的形式应该如下\r\n![image](https://user-images.githubusercontent.com/42901638/85221627-d294b600-b3e7-11ea-8529-6db10f4ca13f.png)\r\n\r\n\r\n\r\n它前面采用的应该是DSSD模块中的一个形式\r\n![image](https://user-images.githubusercontent.com/42901638/85221628-d7596a00-b3e7-11ea-8e15-9d1480d79b9e.png)\r\n\r\n后面使用的是人脸检测SSH的上下文模块\r\n![image](https://user-images.githubusercontent.com/42901638/85221631-daecf100-b3e7-11ea-85f1-c15794a12034.png)\r\n\r\n与论文里的模块示意图完全不符合。。。希望官方能看下给我回复，谢谢！",
        "state": "closed",
        "user": "MARD1NO",
        "closed_by": "MARD1NO",
        "created_at": "2020-06-21T09:52:08+00:00",
        "updated_at": "2020-06-22T03:04:45+00:00",
        "closed_at": "2020-06-22T03:04:45+00:00",
        "comments_count": [
            "qingqing01",
            "MARD1NO"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4710,
        "title": "图片分类训练报错",
        "body": "![image](https://user-images.githubusercontent.com/62418900/85121945-56b83380-b258-11ea-973c-c71c4b55746d.png)\r\n使用上面的命令报错如下：\r\n[root@72b2d0dbbbe6 image_classification]# python3 train.py --data_dir=./data/mask/ --total_images=186 --class_dim=2 --validate=True --model=ResNet50_vd --batch_size=8 --lr_strategy=cosine_decay --lr=0.1 --num_epochs=200 --model_save_dir=output/ --l2_decay=7e-5 --use_mixup=True --use_label_smoothing=True --label_smoothing_epsilon=0.1\r\n2020-06-19 10:08:37,855-INFO: -------------  Configuration Arguments -------------\r\n2020-06-19 10:08:37,855-INFO:                batch_size : 8\r\n2020-06-19 10:08:37,855-INFO:                checkpoint : None\r\n2020-06-19 10:08:37,855-INFO:                 class_dim : 2\r\n2020-06-19 10:08:37,855-INFO:                  data_dir : ./data/mask/\r\n2020-06-19 10:08:37,855-INFO:               data_format : NCHW\r\n2020-06-19 10:08:37,855-INFO:              decay_epochs : 2.4\r\n2020-06-19 10:08:37,855-INFO:                decay_rate : 0.97\r\n2020-06-19 10:08:37,855-INFO:         drop_connect_rate : 0.2\r\n2020-06-19 10:08:37,855-INFO:                 ema_decay : 0.9999\r\n2020-06-19 10:08:37,855-INFO:                 enable_ce : False\r\n2020-06-19 10:08:37,855-INFO: finetune_exclude_pretrained_params : None\r\n2020-06-19 10:08:37,856-INFO:           fuse_bn_act_ops : False\r\n2020-06-19 10:08:37,856-INFO:  fuse_elewise_add_act_ops : False\r\n2020-06-19 10:08:37,856-INFO:                image_mean : [0.485, 0.456, 0.406]\r\n2020-06-19 10:08:37,856-INFO:               image_shape : [3, 224, 224]\r\n2020-06-19 10:08:37,856-INFO:                 image_std : [0.229, 0.224, 0.225]\r\n2020-06-19 10:08:37,856-INFO:             interpolation : None\r\n2020-06-19 10:08:37,856-INFO:               is_profiler : False\r\n2020-06-19 10:08:37,856-INFO:                  l2_decay : 7e-05\r\n2020-06-19 10:08:37,856-INFO:   label_smoothing_epsilon : 0.1\r\n2020-06-19 10:08:37,856-INFO:               lower_ratio : 0.75\r\n2020-06-19 10:08:37,856-INFO:               lower_scale : 0.08\r\n2020-06-19 10:08:37,856-INFO:                        lr : 0.1\r\n2020-06-19 10:08:37,856-INFO:               lr_strategy : cosine_decay\r\n2020-06-19 10:08:37,856-INFO:                  max_iter : 0\r\n2020-06-19 10:08:37,856-INFO:               mixup_alpha : 0.2\r\n2020-06-19 10:08:37,856-INFO:                     model : ResNet50_vd\r\n2020-06-19 10:08:37,856-INFO:            model_save_dir : output/\r\n2020-06-19 10:08:37,856-INFO:             momentum_rate : 0.9\r\n2020-06-19 10:08:37,856-INFO:                num_epochs : 200\r\n2020-06-19 10:08:37,857-INFO:              padding_type : SAME\r\n2020-06-19 10:08:37,857-INFO:          pretrained_model : None\r\n2020-06-19 10:08:37,857-INFO:                print_step : 10\r\n2020-06-19 10:08:37,857-INFO:             profiler_path : ./profilier_files\r\n2020-06-19 10:08:37,857-INFO:               random_seed : None\r\n2020-06-19 10:08:37,857-INFO:           reader_buf_size : 8\r\n2020-06-19 10:08:37,857-INFO:             reader_thread : 8\r\n2020-06-19 10:08:37,857-INFO:         resize_short_size : 256\r\n2020-06-19 10:08:37,857-INFO:                 same_feed : 0\r\n2020-06-19 10:08:37,857-INFO:                 save_step : 1\r\n2020-06-19 10:08:37,857-INFO:                scale_loss : 1.0\r\n2020-06-19 10:08:37,857-INFO:               step_epochs : [30, 60, 90]\r\n2020-06-19 10:08:37,857-INFO:           test_batch_size : 8\r\n2020-06-19 10:08:37,857-INFO:              total_images : 186\r\n2020-06-19 10:08:37,857-INFO:               upper_ratio : 1.3333333333333333\r\n2020-06-19 10:08:37,857-INFO:                    use_aa : False\r\n2020-06-19 10:08:37,857-INFO:                  use_dali : False\r\n2020-06-19 10:08:37,857-INFO:  use_dynamic_loss_scaling : True\r\n2020-06-19 10:08:37,857-INFO:                   use_ema : False\r\n2020-06-19 10:08:37,857-INFO:                  use_fp16 : False\r\n2020-06-19 10:08:37,857-INFO:                   use_gpu : True\r\n2020-06-19 10:08:37,858-INFO:       use_label_smoothing : 1\r\n2020-06-19 10:08:37,858-INFO:                 use_mixup : 1\r\n2020-06-19 10:08:37,858-INFO:                    use_se : True\r\n2020-06-19 10:08:37,858-INFO:                  validate : 1\r\n2020-06-19 10:08:37,858-INFO:            warm_up_epochs : 5.0\r\n2020-06-19 10:08:37,858-INFO: ----------------------------------------------------\r\nW0619 10:08:39.362601  5105 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0619 10:08:39.366940  5105 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n2020-06-19 10:08:41,431-WARNING: img(./data/mask/train/0/aada8594b5c91353a100d936490ecd3d.jpg) is None, pass it.\r\n2020-06-19 10:08:41,884-INFO: [Pass 0, train batch 0]   loss 0.65583, lr 0.10000, elapse 0.4723 sec\r\n/usr/local/lib64/python3.6/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 304, in <module>\r\n    main()\r\n  File \"train.py\", line 300, in main\r\n    train(args)\r\n  File \"train.py\", line 250, in train\r\n    fetch_list=train_fetch_list)\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n8   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunTracedOps(std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> > const&)\r\n10  paddle::framework::details::FastThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n11  paddle::framework::details::ScopeBufferedMonitor::Apply(std::function<void ()> const&, bool)\r\n12  paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n13  paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib64/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 2933, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"/host/Documents/models-release-1.8/models-release-1.8/PaddleCV/image_classification/models/resnet_vd.py\", line 146, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/host/Documents/models-release-1.8/models-release-1.8/PaddleCV/image_classification/models/resnet_vd.py\", line 67, in net\r\n    name='conv1_1')\r\n  File \"/host/Documents/models-release-1.8/models-release-1.8/PaddleCV/image_classification/build_model.py\", line 98, in _mixup_model\r\n    net_out = model.net(input=image, class_dim=args.class_dim)\r\n  File \"/host/Documents/models-release-1.8/models-release-1.8/PaddleCV/image_classification/build_model.py\", line 125, in create_model\r\n    loss_out = _mixup_model(data, model, args, is_train)\r\n  File \"train.py\", line 65, in build_program\r\n    data_loader, loss_out = create_model(model, args, is_train)\r\n  File \"train.py\", line 166, in train\r\n    args=args)\r\n  File \"train.py\", line 300, in main\r\n    train(args)\r\n  File \"train.py\", line 304, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  Cudnn error, CUDNN_STATUS_EXECUTION_FAILED  at (/paddle/paddle/fluid/operators/conv_cudnn_op.cu:300)\r\n  [operator < conv2d > error]\r\n\r\n然后使用\r\n![image](https://user-images.githubusercontent.com/62418900/85122199-c0384200-b258-11ea-8215-906509ea4ec0.png)\r\n检测了环境，没有报错，数据集使用的口罩分类的图片。求解决！\r\n",
        "state": "open",
        "user": "mcl-stone",
        "closed_by": null,
        "created_at": "2020-06-19T10:15:29+00:00",
        "updated_at": "2024-02-26T05:11:17+00:00",
        "closed_at": null,
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4712,
        "title": "PointNet++ ext_op cannot be loaded",
        "body": "## Background info\r\n\r\n- OS version: Ubuntu 20.04\r\n- Paddle version: paddlepaddle-gpu 1.8.1.post107\r\n\r\n## Issue\r\n\r\nHi,\r\n\r\nI'm trying to run pointnet++ on my PC. I have compiled the pointnet_lib.so and added the path into the LD_LIBRARY_PATH. However, I'm not able to load the so file when running the test script. The error msg is listed down below:\r\n\r\n```\r\nW0621 23:53:27.860921 21639 dynamic_loader.cc:120] Can not find library: /home/jake/Documents/paddle/pointnet2_paddle/ext_op/src/pointnet_lib.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\n  File \"tests/test_farthest_point_sampling_op.py\", line 20, in <module>\r\n    import pointnet_lib\r\n  File \"/home/jake/Documents/paddle/pointnet2_paddle/ext_op/pointnet_lib.py\", line 19, in <module>\r\n    fluid.load_op_library(os.path.join(file_dir, 'src/pointnet_lib.so'))\r\n  File \"/home/jake/anaconda3/envs/paddle-dev/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 5162, in load_op_library\r\n    core.load_op_library(lib_filename)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::dynload::GetOpDsoHandle(std::string const&)\r\n3   paddle::framework::LoadOpLib(std::string const&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Failed to find dynamic library: /home/jake/Documents/paddle/pointnet2_paddle/ext_op/src/pointnet_lib.so ( /home/jake/Documents/paddle/pointnet2_paddle/ext_op/src/pointnet_lib.so: undefined symbol: _ZNK6paddle9framework12OperatorBase13DebugStringExB5cxx11EPKNS0_5ScopeE ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at (/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177)\r\n```\r\n\r\nSeems like there is a linking error with the c++ lib. The compiled `pointnet_lib.so` is inside the src folder.\r\n\r\n```\r\ndrwxrwxr-x 2 jake jake     4096 6月  21 23:10 ./\r\ndrwxrwxr-x 5 jake jake     4096 6月  21 22:44 ../\r\n-rw-rw-r-- 1 jake jake     2502 6月  13 00:14 farthest_point_sampling_op.cc\r\n-rw-rw-r-- 1 jake jake     5366 6月  13 00:14 farthest_point_sampling_op.cu\r\n-rw-rw-r-- 1 jake jake     4251 6月  13 00:14 gather_point_op.cc\r\n-rw-rw-r-- 1 jake jake     4800 6月  13 00:14 gather_point_op.cu\r\n-rw-rw-r-- 1 jake jake     4531 6月  13 00:14 group_points_op.cc\r\n-rw-rw-r-- 1 jake jake     5448 6月  13 00:14 group_points_op.cu\r\n-rw-rw-r-- 1 jake jake     1054 6月  13 00:14 make.sh\r\n-rwxrwxr-x 1 jake jake 16741600 6月  21 23:10 pointnet_lib.so*\r\n-rw-rw-r-- 1 jake jake     3292 6月  13 00:14 query_ball_op.cc\r\n-rw-rw-r-- 1 jake jake     4097 6月  13 00:14 query_ball_op.cu\r\n-rw-rw-r-- 1 jake jake     5258 6月  13 00:14 three_interp_op.cc\r\n-rw-rw-r-- 1 jake jake     5817 6月  13 00:14 three_interp_op.cu\r\n-rw-rw-r-- 1 jake jake     3576 6月  13 00:14 three_nn_op.cc\r\n-rw-rw-r-- 1 jake jake     4074 6月  13 00:14 three_nn_op.cu\r\n-rw-rw-r-- 1 jake jake      810 6月  13 00:14 util.cu.h\r\n(paddle-dev) jake@jake-pc:~/Documents/paddle/pointnet2_paddle/ext_op/src$ \r\n```\r\nPlease help, thx!",
        "state": "closed",
        "user": "jakeju92",
        "closed_by": "jakeju92",
        "created_at": "2020-06-21T16:00:20+00:00",
        "updated_at": "2022-04-10T04:41:06+00:00",
        "closed_at": "2020-06-22T17:37:07+00:00",
        "comments_count": [
            "jakeju92"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4714,
        "title": "请问度量学习怎么用啊，使用infer.py得到的输出是啥意思呢",
        "body": "看了看infer.py的源码，是把测试集txt里面的图片预测了一下，得到的result是一个一维向量，有些不明白，是需要自己拿两张图的result向量做个比较，计算他的余弦相似度吗？我理解的是输入两张图片，然后输出图片的相似度，希望百度的人能帮忙解答一下，谢谢了。",
        "state": "open",
        "user": "xiaozhaxie777",
        "closed_by": null,
        "created_at": "2020-06-22T08:24:41+00:00",
        "updated_at": "2024-02-26T05:11:14+00:00",
        "closed_at": null,
        "comments_count": [
            "hong19860320",
            "xiaozhaxie777",
            "hong19860320",
            "xiaozhaxie777",
            "a123b12cd",
            "821029883"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4713,
        "title": "想问一下关于senet中reduction_ratio的设置问题",
        "body": "HRNET中senet的reduction_ratio为什么设置为16 ，另外代码如下hrnet中的代码size=num_channels / reduction_ratio使用的是/ 而不是// 是否是错误？\r\n        squeeze = fluid.layers.fc(input=pool,\r\n                                  size=num_channels / reduction_ratio,\r\n                                  act='relu',\r\n                                  param_attr=fluid.param_attr.ParamAttr(\r\n                                      initializer=fluid.initializer.Uniform(\r\n                                          -stdv, stdv),name=name+'_sqz_weights'),\r\n                                 bias_attr=ParamAttr(name=name+'_sqz_offset'))",
        "state": "open",
        "user": "lxk767363331",
        "closed_by": null,
        "created_at": "2020-06-22T06:20:38+00:00",
        "updated_at": "2020-06-23T10:37:44+00:00",
        "closed_at": null,
        "comments_count": [
            "hong19860320",
            "hong19860320",
            "lxk767363331",
            "hong19860320",
            "cuicheng01",
            "lxk767363331",
            "cuicheng01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4715,
        "title": "can you share data for  PaddleRec gnn",
        "body": "can you share data for  PaddleRec gnn\r\nfor\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleRec/gnn\r\n\r\nsince link to data \r\nhttps://cikm2016.cs.iupui.edu/cikm-cup\r\n\r\nis broken",
        "state": "closed",
        "user": "Sandy4321",
        "closed_by": "wangchaochaohu",
        "created_at": "2020-06-22T18:35:36+00:00",
        "updated_at": "2020-06-24T15:16:34+00:00",
        "closed_at": "2020-06-24T12:44:41+00:00",
        "comments_count": [
            "wangchaochaohu",
            "Sandy4321",
            "hutuxian",
            "Sandy4321"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4719,
        "title": "PaddleCV-video-ctcn 训练到Epoch21，iter1365停止不动",
        "body": "你好，我在训练CTCN的时候，发现训到Epoch21，iter1365时程序会停止不动，但同时程序仍然在使用GPU和CPU资源。\r\n详情如图。\r\n![image](https://user-images.githubusercontent.com/12699033/85503959-8763e880-b61d-11ea-8830-b234e6e3e661.png)\r\n![image](https://user-images.githubusercontent.com/12699033/85503914-656a6600-b61d-11ea-8dfb-194037bf770b.png)\r\n希望能够获得帮助解决这个问题，谢谢。\r\n\r\n",
        "state": "open",
        "user": "Fordacre",
        "closed_by": null,
        "created_at": "2020-06-24T05:21:56+00:00",
        "updated_at": "2024-02-26T05:11:12+00:00",
        "closed_at": null,
        "comments_count": [
            "chenwhql",
            "Fordacre",
            "huangjun12",
            "Fordacre",
            "huangjun12",
            "Fordacre",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4716,
        "title": "关于Youtube召回的评价指标",
        "body": "hi,dear大佬\r\n在[飞桨实现的Youtube](https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleRec/youtube_dnn)中，没有发现啥评价指标啊？\r\n能不能来个recall,precision,F1啊\r\n多谢大佬。\r\n",
        "state": "open",
        "user": "ucasiggcas",
        "closed_by": null,
        "created_at": "2020-06-23T02:28:10+00:00",
        "updated_at": "2024-02-26T05:11:13+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "ucasiggcas",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4722,
        "title": "No such file or directory: './data/vangogh2photo/trainB/2014-05-23'",
        "body": "在 `trainA` 文件夹中，文件格式为 **数字.jpg** ，例如 **00454.jpg**\r\n\r\n在 `trainB` 文件夹中，文件格式为 **日期 时间.jpg** ，例如 **2016-01-20 08:00:45.jpg**\r\n\r\n可是 `data_reader.py` 中的代码对于 `trainB` 中的图片只取了 **日期.jpg** 这种格式，导致报错\r\n![image](https://user-images.githubusercontent.com/45918719/85943045-0cbe0480-b960-11ea-9f72-fcd7f478804b.png)\r\n\r\n而我将代码中的\r\n```python\r\nif len(line) > 1:\r\n    self.with_label = True\r\n    batch_out_label.append(line[1])\r\n    file = line[0]\r\n```\r\n改成\r\n```python\r\nif len(line) > 1:\r\n    self.with_label = True\r\n    batch_out_label.append(line[1])\r\n    file = line[0] + \" \" + line[1]\r\n```\r\n后，新的错误又发生了\r\n\r\n![image](https://user-images.githubusercontent.com/45918719/85943177-e8165c80-b960-11ea-84b6-edf866cecd67.png)\r\n\r\n我不明白是我改动有误还是我一开始理解的不对？\r\n\r\n我在AI Studio公开了项目，方便的话可以直接运行复现：https://aistudio.baidu.com/aistudio/projectdetail/597606\r\n\r\n期待你们的回复~\r\n",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-06-28T09:09:19+00:00",
        "updated_at": "2020-06-29T03:08:33+00:00",
        "closed_at": "2020-06-29T03:08:33+00:00",
        "comments_count": [
            "willthefrog",
            "shaunhurryup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4720,
        "title": "ACL2020 文章Towards Conversational Recommendation over Multi-Type Dialogs咨询",
        "body": "请问Towards Conversational Recommendation over Multi-Type Dialogs这篇文章的code和dataset路径在哪里？",
        "state": "closed",
        "user": "mengyuanhuang1212",
        "closed_by": "chenwhql",
        "created_at": "2020-06-24T08:30:32+00:00",
        "updated_at": "2021-03-14T07:42:10+00:00",
        "closed_at": "2021-03-03T09:15:00+00:00",
        "comments_count": [
            "chenwhql",
            "mengyuanhuang1212",
            "liuzeming01",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4721,
        "title": "No such file or directory: './data/vangogh2photo/trainA.txt'",
        "body": "这个trainA.txt文件该去哪里找呢？下载过来的数据集只有4个图像文件\r\n\r\n![image](https://user-images.githubusercontent.com/45918719/85940123-1d18b400-b94d-11ea-8129-3fa6a6316427.png)\r\n\r\n",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-06-28T06:39:12+00:00",
        "updated_at": "2020-06-28T07:28:50+00:00",
        "closed_at": "2020-06-28T07:28:50+00:00",
        "comments_count": [
            "shaunhurryup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4723,
        "title": "GRU model under dygraph can't work now!",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 105, in <module>\r\n    epoch_num=args.epoch_num)\r\n  File \"train.py\", line 58, in train_without_distill\r\n    _, logits_s = model(ids_student)\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 461, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/go/src/github.com/paddlepaddle/edl/example/distill/nlp/nets.py\", line 215, in forward\r\n    emb = emb * mask_emb\r\n  File \"/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\", line 198, in __impl__\r\n    return math_op(self, other_var, 'axis', axis)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [16, 122, 128] and the shape of Y = [1952, 128]. Received [122] in X is not equal to [1952] in Y at i:1.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:157)\r\n```",
        "state": "open",
        "user": "gongweibao",
        "closed_by": null,
        "created_at": "2020-06-28T13:38:06+00:00",
        "updated_at": "2020-06-29T01:56:03+00:00",
        "closed_at": null,
        "comments_count": [
            "willthefrog"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4724,
        "title": "BMN的输入问题",
        "body": "在教程中有提到BMN的输入是TSN已经处理好的特征，具体是那一层输出的结果？\r\n我注意到飞桨模型库中已经有TSN模型，但是在BMN中的TSN链接是caffee的https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleCV/video/data/dataset/bmn/README.md，请问有没有飞桨的使用TSN进行特征提取并保存为.npy文件的案例？",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-06-29T07:43:39+00:00",
        "updated_at": "2021-01-15T10:48:03+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12",
            "chajchaj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4726,
        "title": "bmn的输入形状是否可以是其他的值",
        "body": "当我使用我的特征进行训练时，出现了下面的错误，我猜测是由于我的输入（433,1024）的.npy文件，与例子中的(100,400)不相同：\r\n[INFO: train.py:  249]: Namespace(batch_size=None, config='models-1.6/PaddleCV/PaddleVideo/configs/bmn.yaml', epoch=None, fix_random_seed=False, learning_rate=None, log_interval=10, model_name='BMN', no_memory_optimize=False, pretrain=None, resume=None, save_dir='./data/checkpoints', use_gpu=True, valid_interval=1)\r\n[INFO: config_utils.py:   70]: ---------------- Train Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:100\r\n[INFO: config_utils.py:   74]:     dscale:100\r\n[INFO: config_utils.py:   74]:     feat_dim:400\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:32\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:train.json\r\n[INFO: config_utils.py:   74]:     feat_path:work/train/videofeature\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:9\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW0629 21:27:22.091398 18762 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0629 21:27:22.095041 18762 device_context.cc:260] device: 0, cuDNN Version: 7.3.\r\ntrain subset video numbers: 200\r\nvalidation subset video numbers: 0\r\n[INFO: bmn_proposal_metrics.py:   62]: Resetting train metrics...\r\n[INFO: bmn_proposal_metrics.py:   62]: Resetting valid metrics...\r\n[INFO: train_utils.py:   45]: ------- learning rate [0.], learning rate counter [-1] -----\r\n[WARNING: reader.py: 1155]: Your reader has raised an exception!\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1156, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1136, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1206, in __tensor_reader_impl__\r\n    for slots in paddle_reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 506, in __reader_creator__\r\n    yield self.feed(item)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 347, in feed\r\n    ret_dict[each_name] = each_converter.done()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 156, in done\r\n    arr = np.array(self.data, dtype=self.dtype)\r\nValueError: could not broadcast input array from shape (1024,379) into shape (1024)\r\n\r\nTraceback (most recent call last):\r\n  File \"models-1.6/PaddleCV/PaddleVideo/train.py\", line 254, in <module>\r\n    train(args)\r\n  File \"models-1.6/PaddleCV/PaddleVideo/train.py\", line 241, in train\r\n    test_metrics=valid_metrics)\r\n  File \"/home/aistudio/models-1.6/PaddleCV/PaddleVideo/utils/train_utils.py\", line 90, in train_with_dataloader\r\n    for data in train_dataloader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1102, in __next__\r\n    return self._reader.read_next()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)",
        "state": "closed",
        "user": "liu824",
        "closed_by": "liu824",
        "created_at": "2020-06-29T14:00:56+00:00",
        "updated_at": "2020-12-16T07:07:53+00:00",
        "closed_at": "2020-07-01T08:11:55+00:00",
        "comments_count": [
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "PromiseXu1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4727,
        "title": "时间序列预测设备故障",
        "body": "",
        "state": "closed",
        "user": "mmmahhhhe",
        "closed_by": "mmmahhhhe",
        "created_at": "2020-06-30T01:48:38+00:00",
        "updated_at": "2020-07-04T11:59:36+00:00",
        "closed_at": "2020-07-04T11:59:36+00:00",
        "comments_count": [
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4728,
        "title": "face_detection里的NMS的过程代码是在哪里呀？希望告知一下",
        "body": "",
        "state": "closed",
        "user": "QxGeng",
        "closed_by": "QxGeng",
        "created_at": "2020-06-30T02:18:57+00:00",
        "updated_at": "2020-06-30T02:45:37+00:00",
        "closed_at": "2020-06-30T02:45:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4729,
        "title": "GAN有继续训练的方法吗？",
        "body": "用了下面的代码开始训练\r\n```python\r\n%cd /home/aistudio/gan\r\n!python train.py \\\r\n  --model_net=\"CycleGAN\" \\\r\n  --dataset=\"vangogh2photo\" \\\r\n  --data_dir=\"data\" \\\r\n  --epoch=100 \\\r\n  --batch_size=14\r\n```\r\n最后checkpoints存了第100次的参数，但是效果不太好。我把前面99次存的都删掉后想继续训练，不过找不到相关的参数设置...",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-06-30T07:00:51+00:00",
        "updated_at": "2020-06-30T12:38:46+00:00",
        "closed_at": "2020-06-30T12:38:46+00:00",
        "comments_count": [
            "ceci3",
            "shaunhurryup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4730,
        "title": "请问百度双塔模型有实现的源码吗，或者论文都行",
        "body": null,
        "state": "open",
        "user": "leidaxia",
        "closed_by": null,
        "created_at": "2020-06-30T09:03:26+00:00",
        "updated_at": "2024-02-26T05:11:08+00:00",
        "closed_at": null,
        "comments_count": [
            "zhiqiu",
            "leidaxia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4731,
        "title": "No iteration was executed, please check the data reader",
        "body": "训练时我遇到下面的问题：\r\n[INFO: train.py:  249]: Namespace(batch_size=None, config='models-1.6/PaddleCV/PaddleVideo/configs/bmn.yaml', epoch=None, fix_random_seed=False, learning_rate=None, log_interval=10, model_name='BMN', no_memory_optimize=False, pretrain=None, resume=None, save_dir='./data/checkpoints', use_gpu=True, valid_interval=1)\r\n[INFO: config_utils.py:   70]: ---------------- Train Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:551\r\n[INFO: config_utils.py:   74]:     dscale:551\r\n[INFO: config_utils.py:   74]:     feat_dim:1024\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:2\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:trainnew.json\r\n[INFO: config_utils.py:   74]:     feat_path:work/trainnew/videofeature\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:9\r\n[INFO: config_utils.py:   74]:     batch_size:2\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW0701 10:13:39.680063   368 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0701 10:13:39.683766   368 device_context.cc:260] device: 0, cuDNN Version: 7.3.\r\ntrain subset video numbers: 3500\r\nvalidation subset video numbers: 0\r\n[INFO: bmn_proposal_metrics.py:   62]: Resetting train metrics...\r\n[INFO: bmn_proposal_metrics.py:   62]: Resetting valid metrics...\r\n[INFO: train_utils.py:   45]: ------- learning rate [0.], learning rate counter [-1] -----\r\n[INFO: train_utils.py:  104]: No iteration was executed, please check the data reader\r\n我的配置文件如下：\r\nMODEL:\r\n    name: \"BMN\"\r\n    tscale: 551\r\n    dscale: 551\r\n    feat_dim: 1024\r\n    prop_boundary_ratio: 0.5\r\n    num_sample: 2\r\n    num_sample_perbin: 3\r\n    anno_file: \"trainnew.json\"\r\n    feat_path: 'work/trainnew/videofeature'\r\n\r\nTRAIN:\r\n    subset: \"train\"\r\n    epoch: 9\r\n    batch_size: 2\r\n    num_threads: 8\r\n    use_gpu: True\r\n    num_gpus: 4\r\n    learning_rate: 0.001\r\n    learning_rate_decay: 0.1\r\n    lr_decay_iter: 4200\r\n    l2_weight_decay: 1e-4\r\n其他没有变化",
        "state": "closed",
        "user": "liu824",
        "closed_by": "liu824",
        "created_at": "2020-07-01T02:18:16+00:00",
        "updated_at": "2020-07-06T10:52:35+00:00",
        "closed_at": "2020-07-06T10:52:35+00:00",
        "comments_count": [
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "liu824",
            "huangjun12",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4732,
        "title": "度量学习模块改变图像大小",
        "body": "您好，大神。我将度量学习中的图像大小做了改变。由原先的（224，224）改为（64，128）。相应的图像预处理部分也做修改，但是运行到train_exe.run()的时候报错：\r\nValueError: The fed Variable 'image' should have dimensions = 4, shape = (-1, 3, 64, 128), but received fed shape [256, 3, 128, 64] on each device\r\n请问一下，这个应该如何修改？谢谢",
        "state": "open",
        "user": "baigang666",
        "closed_by": null,
        "created_at": "2020-07-01T02:48:18+00:00",
        "updated_at": "2024-02-26T05:11:07+00:00",
        "closed_at": null,
        "comments_count": [
            "littletomatodonkey",
            "baigang666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4733,
        "title": "请问有多语言翻译相关的模型吗？",
        "body": "将中文翻译成多种语言的~",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-07-01T03:26:00+00:00",
        "updated_at": "2020-07-01T13:32:17+00:00",
        "closed_at": "2020-07-01T13:32:17+00:00",
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4738,
        "title": "BMN模型batch_size调小之后loss为nan",
        "body": "在我把BMN的batch_size由16调成8时，训练loss会出现nan,继续调为2之后，启动训练会报错。下面为使用batch_size为8时的结果。使用的训练集是官方的示例\r\n![image](https://user-images.githubusercontent.com/55372277/86448079-d8c05600-bd48-11ea-95c3-9a7b20ccb17f.png)\r\n",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-03T08:20:02+00:00",
        "updated_at": "2020-07-06T10:36:00+00:00",
        "closed_at": null,
        "comments_count": [
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4736,
        "title": "请问何时可以上阿里新出的pyconv？",
        "body": null,
        "state": "open",
        "user": "lxk767363331",
        "closed_by": null,
        "created_at": "2020-07-02T15:11:31+00:00",
        "updated_at": "2024-02-26T05:11:06+00:00",
        "closed_at": null,
        "comments_count": [
            "gfwm2013"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4740,
        "title": "关于se+resnet vd的问题",
        "body": "请问 re_resnet_vd中我找到的是这个位置。先经过一个2*2的池化 ，再经过一个1*1的卷积 与原来的131结构add。可以解释一下这样做的原因么，有什么可解释性么？ 为什么不能用1*1卷积 s=2 完成2*2池化+1*1卷积呢  谢谢\r\nhttps://github.com/PaddlePaddle/models/blob/365fe58a0afdfd038350a718e92684503918900b/PaddleCV/image_classification/models/se_resnet_vd.py#L145",
        "state": "open",
        "user": "lxk767363331",
        "closed_by": null,
        "created_at": "2020-07-05T23:54:34+00:00",
        "updated_at": "2024-02-26T05:11:03+00:00",
        "closed_at": null,
        "comments_count": [
            "cuicheng01",
            "lxk767363331"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4741,
        "title": "统计AUC指标时，遇到NaN",
        "body": "![image](https://user-images.githubusercontent.com/20982126/86556009-a26f1a80-bf84-11ea-84c1-22c89da9d1a0.png)\r\n这是个二分类的问题，通过计算cos_sim(usr_vec, channel_vec),  然后接sigmoid，然后统计AUC，但是却报错了，检查了数据集没有空值，网络结构也是对的，不知道怎么办了\r\n\r\n![image](https://user-images.githubusercontent.com/20982126/86556109-efeb8780-bf84-11ea-9ea1-90462026c4a8.png)\r\n",
        "state": "open",
        "user": "leidaxia",
        "closed_by": null,
        "created_at": "2020-07-06T04:31:46+00:00",
        "updated_at": "2020-07-07T03:18:16+00:00",
        "closed_at": null,
        "comments_count": [
            "FrostML"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4742,
        "title": "PaddleNLP的lac分词baseline模型保存为serving的预测模型出错",
        "body": "保存模型：\r\n\r\n```\r\n# baseline model\r\nexport PYTHONIOENCODING=UTF-8   # 模型输出为Unicode编码，Python2若无此设置容易报错\r\npython3.7 inference_model.py \\\r\n\t\t--init_checkpoint ./model_baseline \\\r\n\t\t--inference_save_dir ./inference_model\r\n```\r\n\r\n保存为serving预测模型：\r\n\r\n```\r\nimport paddle_serving_client.io as serving_io\r\n\r\nserving_io.inference_model_to_serving('./inference_model', serving_server=\"serving_server\", serving_client=\"serving_client\",  model_filename='model.pdmodel', params_filename='params.pdparams')\r\n```\r\n\r\n最后生成的serving_server_conf.prototxt有错误，导致请求时返回`{\"result\":\"Request Value Error\"}`\r\n\r\n```\r\nfeed_var {\r\n  name: \"words\"\r\n  alias_name: \"words\"\r\n  is_lod_tensor: true\r\n  feed_type: 0\r\n  shape: -1\r\n}\r\nfetch_var {\r\n  name: \"crf_decoding_0.tmp_0\"\r\n  alias_name: \"crf_decoding_0.tmp_0\"\r\n  is_lod_tensor: true\r\n  fetch_type: 1             <---   这里应该是0。0代表int，1代表float\r\n  shape: -1\r\n}\r\n```\r\n",
        "state": "closed",
        "user": "levinxo",
        "closed_by": "bjjwwang",
        "created_at": "2020-07-06T08:14:18+00:00",
        "updated_at": "2020-07-13T10:52:18+00:00",
        "closed_at": "2020-07-13T10:52:18+00:00",
        "comments_count": [
            "levinxo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4744,
        "title": "ERNIE_PRETRAIN  in the `run_ernie.sh` for sentiment classification & expected dimensions",
        "body": "On develop branch, the path to ERNIE_PRETRAIN \r\nin the `run_ernie.sh` for sentiment classification does not seem to be correct. \r\n(PaddleNLP/sentiment_classification)\r\nIt should be `ERNIE_PRETRAIN=./models/senta_model/ernie_pretrain_model/` and not only `./ernie_pretrain_model/ `as it is in the `run_ernie.sh`.\r\nHowever, even changing it, if launch `./run_ernie.sh train` I get the following:\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The fed Variable src_ids should have dimensions = 3, shape = [-1, 256, 1], but received fed shape [4, 191, 1]\r\n\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/data/azanetti/Paddle/paddle/fluid/operators/reader/read_op.cc:137)\r\n\r\n  [operator < read > error]\r\n\r\nFull log here:\r\n[loglog.txt](https://github.com/PaddlePaddle/models/files/4886982/loglog.txt)\r\n",
        "state": "closed",
        "user": "andreazanetti",
        "closed_by": "luotao1",
        "created_at": "2020-07-07T20:25:50+00:00",
        "updated_at": "2020-08-06T10:24:25+00:00",
        "closed_at": "2020-08-06T10:24:25+00:00",
        "comments_count": [
            "lidanqing-intel",
            "GaoWei8",
            "andreazanetti",
            "GaoWei8"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4743,
        "title": "使用BMN训练的模型进行预测 时报错",
        "body": "![image](https://user-images.githubusercontent.com/55372277/86751854-885f3600-c071-11ea-9c93-6070e1cbe33f.png)\r\n",
        "state": "closed",
        "user": "liu824",
        "closed_by": "liu824",
        "created_at": "2020-07-07T08:47:29+00:00",
        "updated_at": "2020-07-08T04:47:50+00:00",
        "closed_at": "2020-07-08T04:47:50+00:00",
        "comments_count": [
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4745,
        "title": "使用BMN进行预测时，输出的json文件 视频ID少了两个字符，所有的文件都是这样",
        "body": "![image](https://user-images.githubusercontent.com/55372277/86882608-1ba47400-c123-11ea-897a-3d1bb39d6ab0.png)\r\n![image](https://user-images.githubusercontent.com/55372277/86882803-66be8700-c123-11ea-8221-f9c50d0ad0c5.png)\r\n",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-08T06:01:02+00:00",
        "updated_at": "2020-07-13T03:19:43+00:00",
        "closed_at": null,
        "comments_count": [
            "juncaipeng",
            "liu824",
            "liu824",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4746,
        "title": "lookup_tablev2 and lookup_table difference",
        "body": "The Lac GRU model generated by [this page](https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/lexical_analysis) use lookup_tablev2, and it has 3 dimension output. While using lookup_table (v1) will have 2 dimension output. We think 2 dimension is more reasonable because it will be used as input of fc \r\n\r\nAlso the code is changed by this PR https://github.com/PaddlePaddle/models/pull/3823/files, we doubt if it is intended to use lookup_tablev2?\r\n\r\n`word_embedding = fluid.layers.embedding` \r\nwas changed to\r\n`word_embedding = fluid.embedding`\r\n",
        "state": "closed",
        "user": "lidanqing-intel",
        "closed_by": "lidanqing-intel",
        "created_at": "2020-07-08T08:00:58+00:00",
        "updated_at": "2020-09-10T09:59:20+00:00",
        "closed_at": "2020-09-10T09:59:20+00:00",
        "comments_count": [
            "lidanqing-intel",
            "juncaipeng",
            "Bond-H",
            "lidanqing-intel"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4748,
        "title": "代码死链问题反馈",
        "body": "“Enhancing Local Feature Extraction with Global Representation for Neural Text Classification”\r\n\r\n请问这篇文章提供的code路径不对呀，没有找到在哪里，可否提供一下呢？感激不尽！",
        "state": "closed",
        "user": "PearLion",
        "closed_by": "mapingshuo",
        "created_at": "2020-07-12T04:40:14+00:00",
        "updated_at": "2020-07-12T12:02:16+00:00",
        "closed_at": "2020-07-12T12:02:09+00:00",
        "comments_count": [
            "mapingshuo",
            "mapingshuo",
            "PearLion",
            "mapingshuo",
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4749,
        "title": "使用BMN预训练模型训练的时候报错",
        "body": "DALI is not installed, you can improve performance if use DALI\r\n[INFO: train.py:  254]: Namespace(batch_size=None, config='./configs/bmn.yaml', epoch=None, fix_random_seed=False, is_profiler=0, learning_rate=None, log_interval=10, model_name='BMN', no_memory_optimize=False, pretrain='data/dataset/bmn/BMN.pdparams', profiler_path='./', resume=None, save_dir='./data/checkpoints', use_gpu=True, valid_interval=1)\r\n[INFO: config_utils.py:   70]: ---------------- Train Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:100\r\n[INFO: config_utils.py:   74]:     dscale:100\r\n[INFO: config_utils.py:   74]:     feat_dim:400\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:32\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:data/dataset/bmn/trainlabel.json\r\n[INFO: config_utils.py:   74]:     feat_path:data/dataset/bmn/videofeature\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:10\r\n[INFO: config_utils.py:   74]:     batch_size:8\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:1\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:8\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:1\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer1.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW0713 13:21:17.239037 25735 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0713 13:21:17.242261 25735 device_context.cc:260] device: 0, cuDNN Version: 7.3.\r\n[INFO: model.py:  152]: Load pretrain weights from data/dataset/bmn/BMN.pdparams\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 259, in <module>\r\n    train(args)\r\n  File \"train.py\", line 174, in train\r\n    train_model.load_pretrain_params(exe, pretrain, train_prog, place)\r\n  File \"/home/aistudio/models-release-1.8/PaddleCV/video/models/model.py\", line 154, in load_pretrain_params\r\n    fluid.set_program_state(prog, state_dict)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1967, in set_program_state\r\n    .format(orig_para_np.shape, para.name, new_para_np.shape)\r\nAssertionError: Parameter's shape does not match, the Program requires a parameter with the shape of ((100, 32, 100, 100)), while the loaded parameter (namely [ sample_mask ]) has a shape of  ((100, 320000)).",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-13T05:29:31+00:00",
        "updated_at": "2024-02-26T05:11:00+00:00",
        "closed_at": null,
        "comments_count": [
            "ForFishes",
            "liu824",
            "ForFishes",
            "chajchaj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4750,
        "title": "ctcn的数据集.pkl文件的b'feats'和b'scores'是什么？我注意到ctcn_reader.py只用到了b'scores'，是否b'scores'才是需要的特征？还有对应的txt文件是什么？假设我需要把BMN的数据集转化为ctcn的数据集，该怎么做？",
        "body": null,
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-13T11:15:25+00:00",
        "updated_at": "2024-02-26T05:10:58+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4751,
        "title": "加载模型和模型预测操作分开",
        "body": "请问在fluid.dygraph.guard():下面，怎样实现把加载模型和预测给分开呢？我这样操作infer的时候会报错：\r\nclass model(object):\r\n    def __init__(self):\r\n        with fluid.dygraph.guard():\r\n            self.net = ResNet(\"resnet\", class_dim = train_parameters['class_dim'])\r\n            # load checkpoint\r\n            model_dict, _ = fluid.dygraph.load_dygraph(train_parameters[\"save_persistable_dir\"])\r\n            self.net.load_dict(model_dict)\r\n            print(\"checkpoint loaded\")\r\n            # start evaluate mode\r\n            self.net.eval()\r\n            self.label_dic = train_parameters[\"label_dict\"]\r\n            self.label_dic = {v: k for k, v in self.label_dic.items()}\r\n    def infer(self, image_path_pre, img_list):\r\n        result_dic = {}\r\n        for img_path in img_list:\r\n            img = read_img(os.path.join(image_path_pre, img_path))\r\n            results = self.net(fluid.dygraph.to_variable(img))\r\n            lab = np.argsort(results.numpy())\r\n            s = \"{} {}\\n\".format(img_path, self.label_dic[lab[0][-1]])\r\n            result_dic[img_path] = self.label_dic[lab[0][-1]]\r\n            print(s[:-1])\r\n        return result_dic\r\n![image](https://user-images.githubusercontent.com/54163016/87378583-b3d9a780-c5c0-11ea-9701-8f8eb3b1b8dc.png)\r\n",
        "state": "closed",
        "user": "legendxty",
        "closed_by": "legendxty",
        "created_at": "2020-07-14T02:56:54+00:00",
        "updated_at": "2020-07-14T03:32:33+00:00",
        "closed_at": "2020-07-14T03:31:47+00:00",
        "comments_count": [
            "legendxty"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4754,
        "title": "#face detection# Error: Blocking queue is killed because the data reader raises an exception",
        "body": "```bash\r\n2020-07-16 11:17:11,664-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n-----------  Configuration Arguments -----------\r\nbatch_num: None\r\nbatch_size: 16\r\ndata_dir: data\r\nenable_ce: False\r\nepoc_num: 160\r\nlearning_rate: 0.001\r\nmean_BGR: 104., 117., 123.\r\nmodel_save_dir: output\r\nnum_devices: 1\r\nparallel: True\r\npretrained_model: ./vgg_ilsvrc_16_fc_reduced/\r\nresize_h: 640\r\nresize_w: 640\r\nuse_gpu: True\r\nuse_multiprocess: False\r\nuse_pyramidbox: True\r\n------------------------------------------------\r\n2020-07-16 11:17:12,392-INFO: If regularizer of a Parameter has been set by 'fluid.ParamAttr' or 'fluid.WeightNormParamAttr' already. The Regularization[L2Decay, regularization_coeff=0.000500] in Optimizer will not take effect, and it will only be applied to other Parameters!\r\n2020-07-16 11:17:17,149-WARNING: Your decorated reader has raised an exception!\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\lib\\threading.py\", line 914, in _bootstrap_inner\r\n    self.run()\r\n  File \"D:\\Anaconda3\\lib\\threading.py\", line 862, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 496, in __provider_thread__\r\n    six.reraise(*sys.exc_info())\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\six.py\", line 686, in reraise\r\n    raise value\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 477, in __provider_thread__\r\n    for tensors in func():\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 528, in __tensor_provider__\r\n    for slots in paddle_reader():\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 506, in __reader_creator__\r\n    for item in reader():\r\n  File \"E:\\Sourcecode\\models-release-1.8\\PaddleCV\\face_detection\\reader.py\", line 270, in reader\r\n    image_path)\r\n  File \"E:\\Sourcecode\\models-release-1.8\\PaddleCV\\face_detection\\reader.py\", line 154, in preprocess\r\n    Image.BILINEAR, Image.HAMMING, Image.NEAREST, Image.BICUBIC,\r\nAttributeError: module 'PIL.Image' has no attribute 'HAMMING'\r\n\r\nD:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"E:/Sourcecode/models-release-1.8/PaddleCV/face_detection/train.py\", line 297, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n  File \"E:/Sourcecode/models-release-1.8/PaddleCV/face_detection/train.py\", line 225, in train\r\n    [v.name for v in fetches])\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\parallel_executor.py\", line 303, in run\r\n    return_numpy=return_numpy)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\six.py\", line 686, in reraise\r\n    raise value\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\nWindows not support stack backtrace yet.\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\layers\\io.py\", line 894, in read_file\r\n    type='read', inputs={'Reader': [reader]}, outputs={'Out': out})\r\n  File \"E:/Sourcecode/models-release-1.8/PaddleCV/face_detection/train.py\", line 114, in build_program\r\n    image, face_box, head_box, gt_label = fluid.layers.read_file(py_reader)\r\n  File \"E:/Sourcecode/models-release-1.8/PaddleCV/face_detection/train.py\", line 166, in train\r\n    args=args)\r\n  File \"E:/Sourcecode/models-release-1.8/PaddleCV/face_detection/train.py\", line 297, in <module>\r\n    train(args, config, train_parameters, train_file_list)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (D:\\1.8.2\\paddle\\paddle/fluid/operators/reader/blocking_queue.h:141)\r\n  [operator < read > error]\r\n```",
        "state": "open",
        "user": "ftraining",
        "closed_by": null,
        "created_at": "2020-07-16T03:27:40+00:00",
        "updated_at": "2024-02-26T05:10:57+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "baiyfbupt",
            "ftraining"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4756,
        "title": "CTCN 有没有使用I3D特征的demo",
        "body": null,
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-16T08:35:21+00:00",
        "updated_at": "2024-02-26T05:10:56+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824",
            "huangjun12",
            "liu824",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4758,
        "title": "有没有哥哥帮忙实现一下paddle版wgan-gp的demo",
        "body": "最近学习paddle,想实现一下gan的一些网络，并层层深入但是实现到了wgan-gp的时候，损失函数哪里出现了一些问题，可能由于对框架的静态图的一些东西了解的还不深入，希望可以帮我实现一下最简单的wgan-gp的demo, 简单能生成图像的，帮助我学习gan和paddle框架，万分感激",
        "state": "open",
        "user": "yxhpy",
        "closed_by": null,
        "created_at": "2020-07-17T00:45:46+00:00",
        "updated_at": "2020-07-17T02:33:55+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 222,
        "title": "models的PaddleNLP的bert，自有数据训练，生成训练数据。字典不匹配？？",
        "body": "https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/pretrain_language_models/BERT\r\n数据预处理部分\r\n![image](https://user-images.githubusercontent.com/26199465/87673833-b5b18f80-c7a7-11ea-8569-1f70127def5f.png)\r\nid化的例子 第一个token的id是1？你们用的是啥字典啊。\r\nbert-base 的字典，cls是102，sep是103才对吧\r\n\r\n或者你们能不能放出对应的create_train_data.py的代码，这也不麻烦吧",
        "state": "closed",
        "user": "waywaywayw",
        "closed_by": "ZeyuChen",
        "created_at": "2020-07-16T13:05:51+00:00",
        "updated_at": "2022-04-23T16:50:01+00:00",
        "closed_at": "2022-04-23T16:50:01+00:00",
        "comments_count": [
            "waywaywayw",
            "songzy12",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4760,
        "title": "按照例子我实现了WGAN-GP了，但是我调试了很久还是出问题",
        "body": "希望可以帮助我做一点修改，不知道具体问题出在哪，我参照了WGAN-GP其他框架的代码写的，但效果不好，由于我还是paddle框架的初学者，不能完美还原出来，希望可以帮助一下谢谢，这是公开有问题的项目地址：https://aistudio.baidu.com/aistudio/projectdetail/632252",
        "state": "open",
        "user": "yxhpy",
        "closed_by": null,
        "created_at": "2020-07-19T16:29:39+00:00",
        "updated_at": "2024-02-26T05:10:53+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84",
            "yxhpy",
            "Aurelius84",
            "yxhpy",
            "ceci3",
            "yxhpy",
            "yxhpy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4761,
        "title": "有没有使用I3D模型或是TSN模型提取视频的RGB和光流特征的例子",
        "body": "有没有使用I3D模型或是TSN模型提取视频的RGB和光流特征的例子",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-20T02:14:17+00:00",
        "updated_at": "2024-02-26T05:10:52+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4764,
        "title": "如果仅使用tsn进行特征提取，并输出提取的特征，该如何实现呢？ ",
        "body": "如果仅使用tsn进行特征提取，并输出提取的特征，该如何实现呢？ ",
        "state": "open",
        "user": "liu824",
        "closed_by": null,
        "created_at": "2020-07-23T06:47:48+00:00",
        "updated_at": "2020-07-27T03:22:23+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824",
            "huangjun12",
            "liu824"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4768,
        "title": "文件不支持windows",
        "body": "- 我在windows平台下跑rrpn的时候出现了dynamic_loader.cc不支持windows这个问题\r\n![微信图片_20200724164253](https://user-images.githubusercontent.com/31400928/88374820-068b3e80-cdcd-11ea-9b9e-e56f29789598.png)\r\n",
        "state": "open",
        "user": "dgl547437235",
        "closed_by": null,
        "created_at": "2020-07-24T08:47:14+00:00",
        "updated_at": "2024-02-26T05:10:50+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4767,
        "title": "Can not find library pointnet_lib.so pycharm ",
        "body": "OS: Ubuntu 16.04\r\ng++: 4.8\r\npaddle: 1.8.1.post107\r\nCUDA: 10.1\r\n\r\n你好，\r\n\r\n我在PointNet++成功编译pointnet_util.so动态库之后，termial中运行test也都通过的情况下，但是在pycharm中运行test会报错:\r\n```\r\nW0724 15:14:30.073087 1176505 dynamic_loader.cc:120] Can not find library: /home/jake/Documents/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src/pointnet_lib.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\nTraceback (most recent call last):\r\n  File \"/home/jake/Documents/paddle/models/PaddleCV/3d_vision/VoteNet/ext_op/tests/test_farthest_point_sampling_op.py\", line 23, in <module>\r\n    import pointnet_lib\r\n  File \"../pointnet_lib.py\", line 19, in <module>\r\n    fluid.load_op_library(os.path.join(file_dir, 'src/pointnet_lib.so'))\r\n  File \"/home/jake/anaconda3/envs/paddle-dev/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 5162, in load_op_library\r\n    core.load_op_library(lib_filename)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::dynload::GetOpDsoHandle(std::string const&)\r\n3   paddle::framework::LoadOpLib(std::string const&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Failed to find dynamic library: /home/jake/Documents/paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src/pointnet_lib.so ( libpaddle_framework.so: cannot open shared object file: No such file or directory ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at (/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177)\r\n```\r\n能帮忙看看是怎么回事吗？谢谢！",
        "state": "closed",
        "user": "jakeju92",
        "closed_by": "jakeju92",
        "created_at": "2020-07-24T07:34:46+00:00",
        "updated_at": "2020-08-06T02:36:53+00:00",
        "closed_at": "2020-08-06T02:36:53+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4770,
        "title": "文档中链接失效",
        "body": "文档地址：https://github.com/PaddlePaddle/models/blob/release/1.8/README.md#%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA\r\n\r\n链接：\r\n![image](https://user-images.githubusercontent.com/1263428/88503330-fb6e2380-d003-11ea-8794-26191fc9a7a6.png)\r\n",
        "state": "open",
        "user": "howl-anderson",
        "closed_by": null,
        "created_at": "2020-07-27T04:24:47+00:00",
        "updated_at": "2020-07-28T03:30:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4769,
        "title": "问题修复：PaddleCV/gan/data_reader.py",
        "body": "我在开始训练CycleGAN模型时项目报错，错误信息为：\r\n> FileNotFoundError: [Errno 2] No such file or directory: 'data/vangogh2photo/trainB/2015-05-18'\r\n\r\n后来发现在 [data_reader.py](https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleCV/gan/data_reader.py#L114) 中对文件名分割错误导致的。\r\n\r\n在 `trainB` 文件中，图片的格式为 **日期+时间** ，例如 **2016-01-20 08:00:45.jpg**，但是通过 `line = line.strip('\\n\\r\\t').split(' ')` 代码分割后，日期和时间被作为列表中两个独立的元素，在后来的 `img = Image.open(os.path.join(self.image_dir, file)).convert(` 代码中直接相连，导致无法找到图片。\r\n\r\n### 解决方案：\r\n将line = line.strip('\\n\\r\\t').split(' ')\r\n替换成line = line.strip('\\n\\r\\t').split('\\t')\r\n\r\n### 希望能早日修复",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-07-26T15:44:23+00:00",
        "updated_at": "2020-08-05T03:10:29+00:00",
        "closed_at": "2020-08-05T03:10:29+00:00",
        "comments_count": [
            "kuke",
            "shaunhurryup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4771,
        "title": "可以用来裁剪或优化TTS语音模型吗",
        "body": "可以用来裁剪或优化TTS语音模型吗，例如：pytorch版本的tacotron2",
        "state": "closed",
        "user": "chwbin",
        "closed_by": "chwbin",
        "created_at": "2020-07-27T06:00:08+00:00",
        "updated_at": "2020-08-10T01:30:27+00:00",
        "closed_at": "2020-08-10T01:30:27+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4775,
        "title": "AssertionError: Parameter file [./model_files/bow_pointwise/2000/.pdparams] not exits",
        "body": "用模型预测时报错    是什么原因呢 \r\n![image](https://user-images.githubusercontent.com/68848476/88771916-8725b280-d1b2-11ea-8de8-bcb0392ee096.png)\r\n     ",
        "state": "closed",
        "user": "fffyyy415",
        "closed_by": "fffyyy415",
        "created_at": "2020-07-29T07:45:54+00:00",
        "updated_at": "2020-07-29T07:58:15+00:00",
        "closed_at": "2020-07-29T07:58:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4772,
        "title": "请问能提供更多的动态图预训练的bert模型吗？或者静态图转动态图的脚本也行",
        "body": "https://github.com/PaddlePaddle/models/tree/release/1.8/dygraph/bert\r\n目前只有：\r\n![image](https://user-images.githubusercontent.com/26199465/88629546-f8496500-d0e1-11ea-9167-7a05bdb3d7ae.png)\r\n能正常加载使用，但是没有中文的bert\r\n能放出转换脚本吗？",
        "state": "open",
        "user": "waywaywayw",
        "closed_by": null,
        "created_at": "2020-07-28T06:53:06+00:00",
        "updated_at": "2024-02-26T05:10:48+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "guoshengCS",
            "waywaywayw",
            "waywaywayw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4773,
        "title": "Res2Net200_vd_26w_4s 模型使用报错 'UnicodeEncodeError: 'ascii' codec can't encode character '\\x90' in position 3: ordinal not in range(128)'",
        "body": "在使用 PaddleCV/image_classification/models/res2net_vd.py 里面的 Res2Net200_vd_26w_4s 模型是报错.\r\n`\r\nTraceback (most recent call last):\r\n  File \"classification/train_cls.py\", line 180, in <module>\r\n    train_cls(settings)\r\n  File \"classification/train_cls.py\", line 53, in train_cls\r\n    opt.minimize(avg_train_loss)\r\n  File \"<decorator-gen-66>\", line 2, in minimize\r\n  File \"/Users/ximinlin/Documents/AI-Insects-Challenge/env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 277, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/Users/ximinlin/Documents/AI-Insects-Challenge/env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 835, in minimize\r\n    no_grad_set=no_grad_set)\r\n  File \"/Users/ximinlin/Documents/AI-Insects-Challenge/env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 678, in backward\r\n    act_no_grad_set, callbacks)\r\n  File \"/Users/ximinlin/Documents/AI-Insects-Challenge/env/lib/python3.7/site-packages/paddle/fluid/backward.py\", line 1413, in append_backward\r\n    _rename_grad_(target_grad_block, fwd_op_num, grad_to_var, {})\r\n  File \"/Users/ximinlin/Documents/AI-Insects-Challenge/env/lib/python3.7/site-packages/paddle/fluid/backward.py\", line 1137, in _rename_grad_\r\n    if block.desc.find_var(name.encode(\"ascii\")):\r\nUnicodeEncodeError: 'ascii' codec can't encode character '\\x90' in position 3: ordinal not in range(128)\r\n`\r\n\r\n但是我能正常使用 Res2Net101_vd_26w_4s. 下面是代码:\r\n\r\n`def train_cls(args):\r\n    data_reader = DataReader(args[\"batch_size\"])\r\n\r\n    use_cuda = args[\"use_cuda\"] or fluid.core.is_compiled_with_cuda()\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n    # build program\r\n    startup_prog = fluid.Program()\r\n    train_prog = fluid.Program()\r\n    with fluid.program_guard(train_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            train_image = fluid.data(name='image', shape=[None] + args[\"image_shape\"],\r\n                                     dtype='float32')\r\n            train_label = fluid.data(name='label', shape=[None, 1], dtype='int64')\r\n            # model = SE_ResNet50_vd()\r\n            # model = SE_ResNeXt50_vd_32x4d()\r\n            # model = SENet154_vd()\r\n            # model = SE_ResNeXt50_32x4d()\r\n            model = Res2Net200_vd_26w_4s()\r\n            \r\n\r\n            net_out = model.net(train_image, class_dim=args[\"num_classes\"])\r\n\r\n            train_loss, train_pred = fluid.layers.softmax_with_cross_entropy(net_out, train_label,\r\n                                                                             return_softmax=True)\r\n            avg_train_loss = fluid.layers.mean(x=train_loss)\r\n            train_acc = fluid.layers.accuracy(input=train_pred, label=train_label, k=1)\r\n\r\n            opt = fluid.optimizer.AdamOptimizer(\r\n                learning_rate=fluid.layers.cosine_decay(args[\"lr\"], step_each_epoch=200, epochs=300),\r\n                regularization=fluid.regularizer.L2DecayRegularizer(regularization_coeff=args[\"l2_decay\"])\r\n            )\r\n            opt.minimize(avg_train_loss)\r\n\r\n            train_feeder = fluid.DataFeeder(place=place, feed_list=[train_image, train_label])\r\n\r\n    train_fetches = [avg_train_loss.name, train_acc.name]\r\n`\r\n",
        "state": "open",
        "user": "XiminLin",
        "closed_by": null,
        "created_at": "2020-07-29T01:15:26+00:00",
        "updated_at": "2024-02-26T05:10:46+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4774,
        "title": "AssertionError: Parameter file [pretrain_model/ResNet50_pretrained/.pdparams] not exits",
        "body": "在训练度量学习模型时，不使用ResNet50的预训练模型的话可以正常训练，如果使用的话就报如下错误：\r\n![image](https://user-images.githubusercontent.com/13143336/88768229-5a22d100-d1ad-11ea-9968-32c772bc23a8.png)\r\n麻烦帮忙看一下，多谢",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-07-29T07:08:45+00:00",
        "updated_at": "2020-07-30T11:58:48+00:00",
        "closed_at": "2020-07-30T11:58:48+00:00",
        "comments_count": [
            "fffyyy415",
            "Superjomn",
            "endy-see",
            "littletomatodonkey",
            "a123b12cd",
            "endy-see",
            "littletomatodonkey",
            "endy-see",
            "littletomatodonkey",
            "endy-see",
            "littletomatodonkey",
            "endy-see",
            "littletomatodonkey",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4778,
        "title": "PaddleCV/human_pose_estimation test.py报错The number of fields in data (7) does not match len(feed_list) (2)",
        "body": "ubuntu 16.04\r\npaddle 1.7.2\r\nGPU: Nvidia V100 16GB\r\npython:3.7\r\n\r\n```\r\naistudio@jupyter-78894-555912:~/work/models/PaddleCV/human_pose_estimation$ python test_squidtap.py  --dataset 'coco' --checkpoint 'output/simplebase-coco/0'\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ncheckpoint: output/simplebase-coco/0\r\ndataset: coco\r\nflip_test: True\r\nkp_dim: 7\r\nshift_heatmap: True\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0730 09:13:04.981681  4680 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0730 09:13:04.986066  4680 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'bottle']\r\n=> num_images: 138\r\ngenerating coco gt_db...\r\n=> num db: 138\r\n=> num selected db: 138\r\nProcessing batch #0\r\nTraceback (most recent call last):\r\n  File \"test_squidtap.py\", line 131, in <module>\r\n    test(args)\r\n  File \"test_squidtap.py\", line 102, in test\r\n    feed=feeder.feed(data))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 323, in feed\r\n    \"len(feed_list) (%d)\") % (len(each_sample), len(converter))\r\nAssertionError: The number of fields in data (7) does not match len(feed_list) (2)\r\n```",
        "state": "open",
        "user": "greatyang",
        "closed_by": null,
        "created_at": "2020-07-30T01:14:46+00:00",
        "updated_at": "2020-07-30T12:10:49+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4777,
        "title": "PaddleCV/human_pose_estimation/val.py 报错operands could not be broadcast together with shapes",
        "body": "OS：ubuntu 16.04\r\nPaddle: 1.7.0\r\nGPU:Nvidia V100 16GB\r\nPython:3.7\r\n\r\n```\r\naistudio@jupyter-78894-555912:~/work/models/PaddleCV/human_pose_estimation$ python val_squidtap.py --dataset 'coco' --checkpoint 'output/simplebase-coco/0' --data_root 'data/squidtap'\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 128\r\ncheckpoint: output/simplebase-coco/0\r\ndata_root: data/squidtap\r\ndataset: coco\r\nflip_test: True\r\nkp_dim: 7\r\nlr: 0.001\r\nlr_strategy: piecewise_decay\r\nnum_epochs: 140\r\npost_process: True\r\npretrained_model: None\r\nshift_heatmap: True\r\ntotal_images: 112\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0730 09:00:24.715301  3899 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\r\nW0730 09:00:24.719609  3899 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n=> classes: ['__background__', 'bottle']\r\n=> num_images: 112\r\ngenerating coco gt_db...\r\n=> num db: 112\r\n=> num selected db: 112\r\nI0730 09:00:27.523710  3899 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI0730 09:00:27.532135  3899 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0730 09:00:27.539041  3899 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0730 09:00:27.544224  3899 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\nEpoch [   0] Loss = 0.25711 Acc = 0.00000\r\nkp_dim  7\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n./results/keypoints_coco_results.json ./results\r\nLoading and preparing results...\r\nDONE (t=0.00s)\r\ncreating index...\r\nindex created!\r\nRunning per image evaluation...\r\nEvaluate annotation type *keypoints*\r\nTraceback (most recent call last):\r\n  File \"val_squidtap.py\", line 229, in <module>\r\n    valid(args)\r\n  File \"val_squidtap.py\", line 222, in valid\r\n    name_values, perf_indicator = evaluator.evaluate(all_preds, output_dir, all_boxes, image_path)\r\n  File \"/home/aistudio/work/models/PaddleCV/human_pose_estimation/utils/coco_evaluator.py\", line 114, in evaluate\r\n    info_str = self._do_python_keypoint_eval(res_file, res_folder)\r\n  File \"/home/aistudio/work/models/PaddleCV/human_pose_estimation/utils/coco_evaluator.py\", line 177, in _do_python_keypoint_eval\r\n    coco_eval.evaluate()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg/pycocotools/cocoeval.py\", line 149, in evaluate\r\n    for imgId in p.imgIds\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg/pycocotools/cocoeval.py\", line 150, in <dictcomp>\r\n    for catId in catIds}\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg/pycocotools/cocoeval.py\", line 229, in computeOks\r\n    e = (dx**2 + dy**2) / vars / (gt['area']+np.spacing(1)) / 2\r\nValueError: operands could not be broadcast together with shapes (7,) (17,) \r\n```",
        "state": "open",
        "user": "greatyang",
        "closed_by": null,
        "created_at": "2020-07-30T01:05:18+00:00",
        "updated_at": "2020-07-31T03:18:55+00:00",
        "closed_at": null,
        "comments_count": [
            "xiegegege",
            "greatyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4776,
        "title": "arcface loss",
        "body": "请问度量学习中的arcmargin loss是arcface loss么？？",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-07-29T14:14:35+00:00",
        "updated_at": "2020-07-30T02:36:21+00:00",
        "closed_at": "2020-07-30T02:36:21+00:00",
        "comments_count": [
            "wanghaoshuang",
            "endy-see"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4780,
        "title": "度量学习模块infer部分",
        "body": "度量学习模块中infer的最终输出是一个一维的向量，而且维度不是类别数目，个人理解应该是输出的是提取出来的图像特征。如果做人脸识别之类的任务，是否还需要自己构造一个样本库，然后将输入图片的特征与样本库进行距离的比对，进而判断类别？",
        "state": "open",
        "user": "a123b12cd",
        "closed_by": null,
        "created_at": "2020-07-30T07:58:45+00:00",
        "updated_at": "2024-02-26T05:10:42+00:00",
        "closed_at": null,
        "comments_count": [
            "littletomatodonkey",
            "a123b12cd",
            "xiaoran-xr",
            "yangy996"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4784,
        "title": "CycleGAN预测时argparse的部分参数无效",
        "body": "### 在AI Studio运行\r\n- 截图（无法运行）\r\n![image](https://user-images.githubusercontent.com/45918719/89035761-0ad7ce80-d36e-11ea-9215-55d5a2c48078.png)\r\n![image](https://user-images.githubusercontent.com/45918719/89035781-10cdaf80-d36e-11ea-9d29-8d4caf7d9bdf.png)\r\n![image](https://user-images.githubusercontent.com/45918719/89036049-95203280-d36e-11ea-8dc5-4dd4e613ff81.png)\r\n三个无法找到的参数在 `infer.py` 中都存在\r\n另一个相同的项目，相同的代码，是可以运行的\r\n我在想是不是平台的问题？\r\n\r\n",
        "state": "open",
        "user": "shaunhurryup",
        "closed_by": null,
        "created_at": "2020-07-31T12:49:26+00:00",
        "updated_at": "2024-02-26T05:10:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4785,
        "title": "Pix2Pix Paddle1.8下C++推断报错",
        "body": "Paddle1.8下，Pix2Pix使用C++进行预测，使用AnalysisConfig和NativeConfig来CreatePaddlePredictor，均报错如下：\r\n\r\n![image](https://user-images.githubusercontent.com/7035538/89271357-2ba26b80-d66f-11ea-9e32-17f3ba14f0d2.png)\r\n\r\n请问怎么解决，能给个GAN C++推断的例子参考下吗，谢谢",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2020-08-04T08:26:56+00:00",
        "updated_at": "2020-08-07T06:40:54+00:00",
        "closed_at": "2020-08-07T06:40:54+00:00",
        "comments_count": [
            "A1exy",
            "jerrywgz",
            "A1exy",
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4782,
        "title": "C-TCN模型数据集不支持MP4格式,MP4转为pickle文件格式需要提供相应处理工具脚本",
        "body": "C-TCN模型数据使用说明中明确说明了训练这个模型的时候，需要先对MP4源文件抽取RGB和FLOW 特征，再用训练好的TSN模型提取出抽象的特征数据并存储为pickle文件格式。现在问题是，贵司提供的训练数据集已经转换好了，用infer的时候，无法直接使用mp4文件，但是同时又无mp4转成pickle文件的脚本，需要提供一个解决方案，谢谢",
        "state": "open",
        "user": "fudameng",
        "closed_by": null,
        "created_at": "2020-07-31T03:31:38+00:00",
        "updated_at": "2024-02-26T05:10:41+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4786,
        "title": "emotion_detection教程中基于 ERNIE 进行 Finetune报错",
        "body": "执行这段代码后报错 前面都按照1.8的教程走下来了 不知道是哪里的问题 请指教\r\n\r\n#--init_checkpoint ./pretrain_models/ernie\r\nsh run_ernie.sh train\r\n\r\n报错内容：\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 32\r\ndata_dir: None\r\ndev_set: ./data/dev.tsv\r\ndo_infer: False\r\ndo_lower_case: True\r\ndo_train: True\r\ndo_val: True\r\nepoch: 3\r\nernie_config_path: ./pretrain_models/ernie//ernie_config.json\r\ninfer_set: None\r\ninit_checkpoint: ./pretrain_models/ernie//params\r\nlabel_map_config: None\r\nlr: 2e-05\r\nmax_seq_len: 64\r\nnum_labels: 3\r\nrandom_seed: 1\r\nsave_checkpoint_dir: ./save_models/ernie\r\nsave_steps: 500\r\nskip_steps: 50\r\ntask_name: None\r\ntest_set: None\r\ntrain_set: ./data/train.tsv\r\nuse_cuda: True\r\nuse_paddle_hub: False\r\nvalidation_steps: 50\r\nverbose: True\r\nvocab_path: ./pretrain_models/ernie//vocab.txt\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\nhidden_act: relu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nmax_position_embeddings: 513\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\ntype_vocab_size: 2\r\nvocab_size: 18000\r\n------------------------------------------------\r\nDevice count: 1\r\nNum train examples: 9655\r\nMax train steps: 906\r\nTheoretical memory usage in training: 7954.669 - 8333.463 MB\r\nW0804 18:40:22.526546 17467 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0804 18:40:22.530467 17467 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n2020-08-04 18:40:24,913-WARNING: ./pretrain_models/ernie//params.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-08-04 18:40:24,922-WARNING: variable file [ ./pretrain_models/ernie//params/mask_lm_trans_layer_norm_scale ./pretrain_models/ernie//params/tmp_51 ./pretrain_models/ernie//params/mask_lm_trans_layer_norm_bias ./pretrain_models/ernie//params/next_sent_3cls_fc.w_0 ./pretrain_models/ernie//params/@LR_DECAY_COUNTER@ ./pretrain_models/ernie//params/next_sent_3cls_fc.b_0 ./pretrain_models/ernie//params/mask_lm_trans_fc.w_0 ./pretrain_models/ernie//params/mask_lm_trans_fc.b_0 ./pretrain_models/ernie//params/reduce_mean_0.tmp_0 ./pretrain_models/ernie//params/mask_lm_out_fc.b_0 ] not used\r\n/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_ernie_classifier.py\", line 402, in <module>\r\n    main(args)\r\n  File \"run_ernie_classifier.py\", line 326, in main\r\n    outputs = train_exe.run(program=train_program, fetch_list=fetch_list, return_numpy=False)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n5   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n6   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 1079, in _init_non_iterable\r\n    attrs={'drop_last': self._drop_last})\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 977, in __init__\r\n    self._init_non_iterable()\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 608, in from_generator\r\n    iterable, return_list, drop_last)\r\n  File \"../shared_modules/models/representation/ernie.py\", line 48, in ernie_pyreader\r\n    use_double_buffer=True)\r\n  File \"run_ernie_classifier.py\", line 216, in main\r\n    pyreader_name='train_reader')\r\n  File \"run_ernie_classifier.py\", line 402, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The fed Variable 1 should have dimensions = 3, shape = [-1, 64, 1], but received fed shape [32, 23, 1]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:137)\r\n  [operator < read > error]\r\n",
        "state": "closed",
        "user": "ML-ZXF",
        "closed_by": "ML-ZXF",
        "created_at": "2020-08-04T10:55:51+00:00",
        "updated_at": "2021-07-20T07:06:50+00:00",
        "closed_at": "2020-08-11T05:44:43+00:00",
        "comments_count": [
            "jerrywgz",
            "ML-ZXF",
            "ML-ZXF",
            "darvincy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4791,
        "title": "models/PaddleRec/ctr/deepfm/ 这个实现的FM层在哪儿？",
        "body": "请问 当前的deepfm实现中， FM交叉在哪儿？ 而且目前没有看到对field的应用，feat_idx是把全部的field混在一起了？ 这样怎么明确的来完成域之间的交叉呢",
        "state": "open",
        "user": "Archimondecy",
        "closed_by": null,
        "created_at": "2020-08-06T13:26:44+00:00",
        "updated_at": "2024-02-26T05:10:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4787,
        "title": "请问如何推理与比较2张图片的相似度？",
        "body": "`python infer.py \\\r\n       --model=ResNet50 \\\r\n       --batch_size=1 \\         \r\n       --pretrained_model=${path_to_pretrain_model}`\r\n\r\n上述命令该如何输入图片，是【--image_shape】？\r\n接着如何比较2张图片的相似度？",
        "state": "open",
        "user": "670133189",
        "closed_by": null,
        "created_at": "2020-08-04T14:22:46+00:00",
        "updated_at": "2024-02-26T05:10:39+00:00",
        "closed_at": null,
        "comments_count": [
            "jerrywgz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4788,
        "title": "[论文复现]如何在动态图中导入静态图的预训练参数",
        "body": "我使用飞桨例子中dygraph文件夹下面的resnet模型，这个模型是用动态图方式实现的，参数名称与同一个模型在静态图下面的预训练参数不一样，怎么把这个静态图下面的预训练参数导入动态图中？\r\n静态图的预训练参数是：http://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_pretrained.tar\r\n",
        "state": "open",
        "user": "thrkingd",
        "closed_by": null,
        "created_at": "2020-08-04T16:42:20+00:00",
        "updated_at": "2021-03-18T11:16:21+00:00",
        "closed_at": null,
        "comments_count": [
            "AndersonZhangyq",
            "thrkingd",
            "littletomatodonkey",
            "thrkingd",
            "littletomatodonkey",
            "thrkingd",
            "shippingwang",
            "thrkingd",
            "littletomatodonkey",
            "Hsoms"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4789,
        "title": "CycleGAN推理无结果",
        "body": "## 在第一个项目中预测，这里训练时使用的是batch_norm\r\n```python\r\n%cd /home/aistudio/gan\r\n!python infer.py \\\r\n  --model_net=\"CycleGAN\" \\\r\n  --init_model=\"output/checkpoints/99\" \\\r\n  --input_style=\"B\" \\\r\n  --n_samples=1 \\\r\n  --dataset_dir=\"my_dataset\" \\\r\n  --test_list=\"my_dataset/labels.txt\" \\\r\n  --image_size=256 \\\r\n  --crop_size=256 \\\r\n  --output=\"my_dataset/output\" \\\r\n  --use_gpu=False\r\n```\r\n **最后几行输出结果：**\r\n \r\noutput/checkpoints/99/net_G\r\n\r\nload params done\r\n\r\nmy_dataset my_dataset/labels.txt\r\n\r\nread:  ['hiking.jpg']\r\n\r\n***\r\n\r\n## 第二个项目预测，训练使用的是instance_norm\r\n```python\r\n%cd /home/aistudio/gan\r\n!python infer.py \\\r\n    --model_net=\"CycleGAN\" \\\r\n    --init_model=\"output/checkpoints/30\" \\\r\n    --input_style=\"B\" \\\r\n    --output=\"my_dataset/output\" \\\r\n    --dataset_dir=\"my_dataset\" \\\r\n    --test_list=\"my_dataset/labels.txt\" \\\r\n    --norm_type=\"instance_norm\"\r\n```\r\n**最后几行输出结果：**\r\n\r\noutput/checkpoints/30/net_G\r\n\r\nload params done\r\n\r\nmy_dataset my_dataset/labels.txt\r\n\r\n***\r\n我把两个项目的地址公开在了AI Studio\r\n\r\n刚才用cpu测试了一下[第一个项目](https://aistudio.baidu.com/aistudio/projectdetail/597606)， `labels.txt` 中两张图片只能得到一张预测结果；\r\n\r\n用cpu测试了一下[第二个项目](https://aistudio.baidu.com/aistudio/projectdetail/684615)，没有出结果。",
        "state": "closed",
        "user": "shaunhurryup",
        "closed_by": "shaunhurryup",
        "created_at": "2020-08-05T03:52:02+00:00",
        "updated_at": "2020-08-05T11:11:40+00:00",
        "closed_at": "2020-08-05T11:11:40+00:00",
        "comments_count": [
            "shaunhurryup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4795,
        "title": "[功能请求]能实现可微光栅化吗？进而进行三维mesh的渲染",
        "body": "如题，具体可参考tf_mesh_renderer，pytorch3d，Nvidia/kaolin。\r\n建议实现后加入PaddleCV或者新立一则PaddleCG，目前PaddleCV里只有三维点云分类方面的模型。",
        "state": "open",
        "user": "HighCWu",
        "closed_by": null,
        "created_at": "2020-08-10T03:04:59+00:00",
        "updated_at": "2024-02-26T05:10:34+00:00",
        "closed_at": null,
        "comments_count": [
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4794,
        "title": "[论文复现]BIGGAN SA模块 grad报错",
        "body": "```python\r\nimport paddle.fluid as fluid\r\nimport paddle\r\nfrom paddle.fluid import layers\r\nimport paddle.fluid.dygraph as dg\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nclass SoftMax(dg.Layer):\r\n  def __init__(self, **kwargs):\r\n    super().__init__()\r\n    self.kwargs = kwargs\r\n  \r\n  def forward(self, x):\r\n    return layers.softmax(x, **self.kwargs)\r\nclass SpectralNorm(dg.SpectralNorm):\r\n  def __init__(self, module, weight_name='weight', power_iterations=1, **kwargs):\r\n    weight_shape = getattr(module, weight_name).shape\r\n    if 'dim' not in kwargs:\r\n      if isinstance(module, ( # dg.Conv1D, dg.Conv1DTranspose,\r\n                          dg.Conv2D, dg.Conv2DTranspose,\r\n                          dg.Conv3D, dg.Conv3DTranspose)):\r\n          kwargs['dim'] = 0\r\n      else:\r\n          kwargs['dim'] = 1\r\n    kwargs['power_iters'] = power_iterations\r\n    if 'weight_shape' in kwargs:\r\n      kwargs.pop('weight_shape')\r\n    super().__init__(weight_shape, **kwargs)\r\n    self.weight = getattr(module, weight_name)\r\n\r\n    del module._parameters[weight_name]\r\n    self.module = module\r\n    self.weight_name = weight_name\r\n  \r\n  def forward(self, *args, **kwargs):\r\n    weight_norm = super().forward(self.weight)\r\n    setattr(self.module, self.weight_name, weight_norm)\r\n    out = self.module(*args, **kwargs)\r\n    return out\r\nclass SelfAttention(dg.Layer):\r\n  def __init__(self, in_dim, activation=layers.relu):\r\n    super().__init__()\r\n    self.chanel_in = in_dim\r\n    self.activation = activation\r\n \r\n    self.theta = SpectralNorm(dg.Conv2D(in_dim, in_dim // 8, 1, bias_attr=False))\r\n    self.phi = SpectralNorm(dg.Conv2D(in_dim, in_dim // 8, 1, bias_attr=False))\r\n    self.pool = dg.Pool2D(2, 'max', 2)\r\n    self.g = SpectralNorm(dg.Conv2D(in_dim, in_dim // 2, 1, bias_attr=False))\r\n    self.o_conv = SpectralNorm(dg.Conv2D(in_dim // 2, in_dim, 1, bias_attr=False))\r\n    self.gamma = self.create_parameter([1,], default_initializer=fluid.initializer.Constant(0.0))\r\n \r\n    self.softmax = SoftMax(axis=-1)\r\n \r\n  def forward(self, x):\r\n    m_batchsize, C, width, height = x.shape\r\n    N = height * width\r\n \r\n    theta = self.theta(x)\r\n    phi = self.phi(x)\r\n    phi = self.pool(phi)\r\n    phi = layers.reshape(phi,(m_batchsize, -1, N // 4))\r\n    theta = layers.reshape(theta,(m_batchsize, -1, N))\r\n    theta = layers.transpose(theta,(0, 2, 1))\r\n    attention = self.softmax(layers.bmm(theta, phi))\r\n    g = layers.reshape(self.pool(self.g(x)),(m_batchsize, -1, N // 4))\r\n    attn_g = layers.reshape(layers.bmm(g, layers.transpose(attention,(0, 2, 1))),(m_batchsize, -1, width, height))\r\n    out = self.o_conv(attn_g)\r\n    return self.gamma * out + x\r\nwith fluid.dygraph.guard():\r\n    x = fluid.layers.uniform_random(shape=(10, 1024, 28 ,28))\r\n    x = fluid.dygraph.to_variable(x)\r\n    x.stop_gradient=False\r\n    y = SelfAttention(in_dim=1024)(x)\r\n    grads = fluid.dygraph.grad(y, [x])[0]\r\n    print(grads)\r\n\r\n---------------------------------------------------------------------------EnforceNotMet                             Traceback (most recent call last)<ipython-input-6-eb997cf843ba> in <module>\r\n      4     x.stop_gradient=False\r\n      5     y = SelfAttention(in_dim=1024)(x)\r\n----> 6     grads = fluid.dygraph.grad(y, [x])[0]\r\n      7     print(grads)\r\n</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-153> in grad(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, no_grad_vars, backward_strategy)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py in __impl__(func, *args, **kwargs)\r\n     23     def __impl__(func, *args, **kwargs):\r\n     24         wrapped_func = decorator_func(func)\r\n---> 25         return wrapped_func(*args, **kwargs)\r\n     26 \r\n     27     return __impl__\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in __impl__(*args, **kwargs)\r\n    214         assert in_dygraph_mode(\r\n    215         ), \"We Only support %s in imperative mode, please use fluid.dygraph.guard() as context to run it in imperative Mode\" % func.__name__\r\n--> 216         return func(*args, **kwargs)\r\n    217 \r\n    218     return __impl__\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in grad(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, no_grad_vars, backward_strategy)\r\n    487     return core.dygraph_partial_grad(\r\n    488         inputs, outputs, grad_outputs, no_grad_vars, place, backward_strategy,\r\n--> 489         create_graph, retain_graph, allow_unused, only_inputs)\r\n    490 \r\n    491 \r\nEnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::imperative::ReadyGradVarInfoMap::GetTarget(paddle::imperative::VariableWrapper const*) const\r\n3   paddle::imperative::PartialGradTask::CreateResult()\r\n4   paddle::imperative::PartialGradTask::Run()\r\n5   paddle::imperative::PartialGradEngine::Execute()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPermissionDeniedError: Target var tmp_0@GRAD should not be nullptr\r\n  [Hint: iter->second should not be null.] at (/paddle/paddle/fluid/imperative/partial_grad_engine.cc:501)\r\n```",
        "state": "open",
        "user": "yxhpy",
        "closed_by": null,
        "created_at": "2020-08-07T09:37:00+00:00",
        "updated_at": "2024-02-26T05:10:35+00:00",
        "closed_at": null,
        "comments_count": [
            "saxon-zh",
            "wzzju",
            "yxhpy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4796,
        "title": "[百度之星大赛]细分类训练时的bug",
        "body": "我试了七八次 每次都出现的一个错误\r\n![图片](https://user-images.githubusercontent.com/9131265/89749988-a3074d80-dafc-11ea-83d7-6dcee549bbcb.png)\r\n\r\n有时候训练到两千多轮、有时候训练到六千多七千多轮 还有的时候训练开始就会 我把batch已经调到非常小，这个问题也还会出现，改了好几次代码  也没起作用 运行七八个小时结果出错  这个错误成本太大了 这是框架问题吗？\r\nValuerror: could not broadcast input array from shape (3,64,64) into shape (3)\r\n完整的错误栈大概是下面这样\r\n2020-08-09 23:14:23,889-WARNING: Your reader has raised an exception!\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1156, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1136, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 203, in __call__\r\n    yield self._done()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 191, in _done\r\n    return [c.done() for c in self.converters]\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 191, in <listcomp>\r\n    return [c.done() for c in self.converters]\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 156, in done\r\n    arr = np.array(self.data, dtype=self.dtype)\r\nValueError: could not broadcast input array from shape (3,64,64) into shape (3)\r\n\r\nTraceback (most recent call last):\r\n  File \"train_elem.py\", line 243, in <module>\r\n    main()\r\n  File \"train_elem.py\", line 239, in main\r\n    train_async(args)\r\n  File \"train_elem.py\", line 188, in train_async\r\n    for train_batch in train_loader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1102, in __next__\r\n    return self._reader.read_next()\r\npaddle.fluid.core_avx.EnforceNotMet\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\r\n\r\nterminate called without an active exception\r\nW0809 23:14:24.456936  1279 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0809 23:14:24.456981  1279 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0809 23:14:24.456990  1279 init.cc:221] The detail failure signal is:\r\nW0809 23:14:24.456998  1279 init.cc:224] *** Aborted at 1596986064 (unix time) try \"date -d @1596986064\" if you are using GNU date ***\r\nW0809 23:14:24.459416  1279 init.cc:224] PC: @                0x0 (unknown)\r\nW0809 23:14:24.459564  1279 init.cc:224] *** SIGABRT (@0x3e8000004cc) received by PID 1228 (TID 0x7f1aa3fff700) from PID 1228; stack trace: ***\r\nW0809 23:14:24.462023  1279 init.cc:224]     @     0x7f1c7d1e9390 (unknown)\r\nW0809 23:14:24.464035  1279 init.cc:224]     @     0x7f1c7ce43428 gsignal\r\nW0809 23:14:24.465437  1279 init.cc:224]     @     0x7f1c7ce4502a abort\r\nW0809 23:14:24.469358  1279 init.cc:224]     @     0x7f1c51bc784a __gnu_cxx::__verbose_terminate_handler()\r\nW0809 23:14:24.470468  1279 init.cc:224]     @     0x7f1c51bc5f47 __cxxabiv1::__terminate()\r\nW0809 23:14:24.471663  1279 init.cc:224]     @     0x7f1c51bc5f7d std::terminate()\r\nW0809 23:14:24.472723  1279 init.cc:224]     @     0x7f1c51bc5c5a __gxx_personality_v0\r\nW0809 23:14:24.474215  1279 init.cc:224]     @     0x7f1c51eb8b97 _Unwind_ForcedUnwind_Phase2\r\nW0809 23:14:24.475225  1279 init.cc:224]     @     0x7f1c51eb8e7d _Unwind_ForcedUnwind\r\nW0809 23:14:24.477159  1279 init.cc:224]     @     0x7f1c7d1e8070 __GI___pthread_unwind\r\nW0809 23:14:24.479091  1279 init.cc:224]     @     0x7f1c7d1e0845 __pthread_exit\r\nW0809 23:14:24.479468  1279 init.cc:224]     @     0x55f638a8de59 PyThread_exit_thread\r\nW0809 23:14:24.479591  1279 init.cc:224]     @     0x55f638913c17 PyEval_RestoreThread.cold.798\r\nW0809 23:14:24.480059  1279 init.cc:224]     @     0x7f1c469487ba (unknown)\r\nW0809 23:14:24.480401  1279 init.cc:224]     @     0x55f638a0f744 _PyMethodDef_RawFastCallKeywords\r\nW0809 23:14:24.480726  1279 init.cc:224]     @     0x55f638a0f861 _PyCFunction_FastCallKeywords\r\nW0809 23:14:24.481055  1279 init.cc:224]     @     0x55f638a7b2bd _PyEval_EvalFrameDefault\r\nW0809 23:14:24.481350  1279 init.cc:224]     @     0x55f6389bf539 _PyEval_EvalCodeWithName\r\nW0809 23:14:24.481643  1279 init.cc:224]     @     0x55f6389c0860 _PyFunction_FastCallDict\r\nW0809 23:14:24.481848  1279 init.cc:224]     @     0x55f638aceb5b partial_call\r\nW0809 23:14:24.482152  1279 init.cc:224]     @     0x55f638a178fb _PyObject_FastCallKeywords\r\nW0809 23:14:24.482472  1279 init.cc:224]     @     0x55f638a7ae86 _PyEval_EvalFrameDefault\r\nW0809 23:14:24.482764  1279 init.cc:224]     @     0x55f6389bf81a _PyEval_EvalCodeWithName\r\nW0809 23:14:24.483067  1279 init.cc:224]     @     0x55f6389c0635 _PyFunction_FastCallDict\r\nW0809 23:14:24.483397  1279 init.cc:224]     @     0x55f638a78232 _PyEval_EvalFrameDefault\r\nW0809 23:14:24.483678  1279 init.cc:224]     @     0x55f638a0eccb _PyFunction_FastCallKeywords\r\nW0809 23:14:24.484002  1279 init.cc:224]     @     0x55f638a76a93 _PyEval_EvalFrameDefault\r\nW0809 23:14:24.484282  1279 init.cc:224]     @     0x55f638a0eccb _PyFunction_FastCallKeywords\r\nW0809 23:14:24.484601  1279 init.cc:224]     @     0x55f638a76a93 _PyEval_EvalFrameDefault\r\nW0809 23:14:24.484897  1279 init.cc:224]     @     0x55f6389c056b _PyFunction_FastCallDict\r\nW0809 23:14:24.485204  1279 init.cc:224]     @     0x55f6389dee53 _PyObject_Call_Prepend\r\nW0809 23:14:24.485523  1279 init.cc:224]     @     0x55f6389d1dbe PyObject_Call\r\nAborted (core dumped)",
        "state": "closed",
        "user": "zky001",
        "closed_by": "zky001",
        "created_at": "2020-08-10T03:36:48+00:00",
        "updated_at": "2020-08-12T05:36:18+00:00",
        "closed_at": "2020-08-12T05:36:18+00:00",
        "comments_count": [
            "zky001",
            "zky001",
            "zhengya01",
            "zky001",
            "zky001",
            "sandyhouse",
            "zky001",
            "zky001",
            "sandyhouse",
            "zky001",
            "zky001",
            "littletomatodonkey",
            "zky001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4797,
        "title": "[百度之星大赛]细分类微调时的bug",
        "body": "![图片](https://user-images.githubusercontent.com/9131265/89750586-3b9ecd00-daff-11ea-896d-ab1e784f91e8.png)\r\n训练了八千多轮  又遇到了一样的问题！\r\n\r\n训练的问题：\r\n[2020-08-10 11:33:10] trainbatch 8020, lr 0.000050, loss 0.178964, time 0.08 sec\r\n[2020-08-10 11:34:00] trainbatch 8030, lr 0.000050, loss 0.168911, time 0.10 sec\r\n[2020-08-10 11:34:49] trainbatch 8040, lr 0.000050, loss 0.192038, time 0.10 sec\r\n[2020-08-10 11:35:41] trainbatch 8050, lr 0.000050, loss 0.196493, time 0.08 sec\r\n[2020-08-10 11:36:30] trainbatch 8060, lr 0.000050, loss 0.191304, time 0.08 sec\r\n[2020-08-10 11:37:18] trainbatch 8070, lr 0.000050, loss 0.193833, time 0.08 sec\r\n[2020-08-10 11:38:10] trainbatch 8080, lr 0.000050, loss 0.189738, time 0.08 sec\r\n[2020-08-10 11:39:00] trainbatch 8090, lr 0.000050, loss 0.204269, time 0.08 sec\r\n[2020-08-10 11:39:52] trainbatch 8100, lr 0.000050, loss 0.195286, time 0.09 sec\r\n2020-08-10 11:40:16,391-WARNING: Your reader has raised an exception!\r\nTraceback (most recent call last):\r\n  File \"train_pair.py\", line 238, in <module>\r\n    main()\r\n  File \"train_pair.py\", line 234, in main\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1156, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1136, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 203, in __call__\r\n    yield self._done()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 191, in _done\r\n    return [c.done() for c in self.converters]\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 191, in <listcomp>\r\n    return [c.done() for c in self.converters]\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 156, in done\r\n    arr = np.array(self.data, dtype=self.dtype)\r\nValueError: could not broadcast input array from shape (3,64,64) into shape (3)\r\n\r\n    train_async(args)\r\n  File \"train_pair.py\", line 187, in train_async\r\n    for train_batch in train_loader():\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1102, in __next__\r\n    return self._reader.read_next()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)",
        "state": "closed",
        "user": "zky001",
        "closed_by": "sandyhouse",
        "created_at": "2020-08-10T03:49:16+00:00",
        "updated_at": "2020-09-07T12:02:52+00:00",
        "closed_at": "2020-09-07T12:02:52+00:00",
        "comments_count": [
            "zky001",
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4801,
        "title": "[PointNet++] Group point op 注释有问题",
        "body": "Hi,\r\n\r\n我发现在pointnet++中的custom op group point，有一个小问题，在python wrapper中[line](https://github.com/PaddlePaddle/models/blob/b87761f8100a545e0015046dd55d886ce90c190e/PaddleCV/3d_vision/PointNet%2B%2B/ext_op/pointnet_lib.py#L237)，和在[c++代码](https://github.com/PaddlePaddle/models/blob/b87761f8100a545e0015046dd55d886ce90c190e/PaddleCV/3d_vision/PointNet%2B%2B/ext_op/src/group_points_op.cc#L35)中的input和output tensor shape comment不一致，请修改一下，避免歧义。",
        "state": "open",
        "user": "jakeju92",
        "closed_by": null,
        "created_at": "2020-08-12T16:47:05+00:00",
        "updated_at": "2024-02-26T05:10:30+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4799,
        "title": "models/PaddleNLP/sentiment_classification/ 模型保存问题",
        "body": "使用Ernie 训练模型后 执行模型部署保存的命令 sh run_ernie.sh save_inference_model  出现Tensor未初始化的错误 按照教程里的参数结合本地文件位置做了修改 还需要改什么地方吗？\r\n['/home/ubuntu/python3.6_Project/zxf_Project/models/PaddleNLP/sentiment_classification', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages', '../shared_modules/', '../shared_modules/models/classification', '../shared_modules/models/classification/', '../shared_modules/']\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 4\r\ncheckpoints: checkpoints\r\ndata_dir: None\r\ndev_set: None\r\ndo_infer: True\r\ndo_lower_case: True\r\ndo_save_inference_model: True\r\ndo_train: True\r\ndo_val: True\r\nenable_ce: False\r\nepoch: 10\r\nernie_config_path: ./pretrain_models/ernie/ernie_config.json\r\ninference_model_dir: ./inference_model\r\ninit_checkpoint: ./save_models/step_4801/\r\nlabel_map_config: None\r\nlr: 0.002\r\nmax_seq_len: 512\r\nmodel_type: ernie_base\r\nnum_labels: 2\r\nrandom_seed: 0\r\nsave_steps: 10000\r\nsenta_config_path: None\r\nskip_steps: 10\r\ntask_name: None\r\ntest_set: ./senta_data/test.tsv\r\ntrain_set: None\r\nuse_cuda: True\r\nuse_paddle_hub: False\r\nvalidation_steps: 1000\r\nverbose: False\r\nvocab_path: ./pretrain_models/ernie/vocab.txt\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\nhidden_act: relu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 768\r\ninitializer_range: 0.02\r\nmax_position_embeddings: 513\r\nnum_attention_heads: 12\r\nnum_hidden_layers: 12\r\ntype_vocab_size: 2\r\nvocab_size: 18000\r\n------------------------------------------------\r\nW0811 11:36:57.896898 10516 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0811 11:36:57.900704 10516 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n2020-08-11 11:37:03,045-WARNING: ./save_models/step_4801/.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-08-11 11:37:03,048-WARNING: variable file [ ./save_models/step_4801/checkpoint.pdmodel ./save_models/step_4801/checkpoint.pdparams ./save_models/step_4801/checkpoint.pdopt ] not used\r\n/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py:1093: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\nLoad model from ./save_models/step_4801/\r\n/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"inference_model_ernie.py\", line 153, in <module>\r\n    do_save_inference_model(args)\r\n  File \"inference_model_ernie.py\", line 71, in do_save_inference_model\r\n    params_filename=\"params.pdparams\")\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1270, in save_inference_model\r\n    save_persistables(executor, save_dirname, main_program, params_filename)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 647, in save_persistables\r\n    filename=filename)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 301, in save_vars\r\n    filename=filename)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 356, in save_vars\r\n    executor.run(save_program)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::SaveCombineOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::SaveCombineOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::SaveCombineOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::SaveCombineOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::SaveCombineOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n8   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n9   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 349, in save_vars\r\n    'save_to_memory': save_to_memory\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 301, in save_vars\r\n    filename=filename)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 647, in save_persistables\r\n    filename=filename)\r\n  File \"/home/ubuntu/.virtualenvs/zxf_env/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1270, in save_inference_model\r\n    save_persistables(executor, save_dirname, main_program, params_filename)\r\n  File \"inference_model_ernie.py\", line 71, in do_save_inference_model\r\n    params_filename=\"params.pdparams\")\r\n  File \"inference_model_ernie.py\", line 153, in <module>\r\n    do_save_inference_model(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Tensor not initialized yet when Tensor::type() is called.\r\n  [Hint: holder_ should not be null.] at (/paddle/paddle/fluid/framework/tensor.h:140)\r\n  [operator < save_combine > error]\r\n",
        "state": "open",
        "user": "ML-ZXF",
        "closed_by": null,
        "created_at": "2020-08-11T03:52:21+00:00",
        "updated_at": "2024-02-26T05:10:32+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "tangjie010101"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4798,
        "title": "如果github上的项目能够直接在ai studio提供的环境下跑通",
        "body": "希望github上这些复现的项目能够在ai studio上做一些适配。比如PointNet++，在ai studio就不能直接跑通，好像是要g++4.8版本，但是ai studio上g++是5.4版本的，无法编译成功，ai stuido提供的环境跟代码需要的环境不适配。而且ai studio上是没有root权限的，开发者就基本没办法了（只要是新的C++ OP都没办法跑，只能选择线下），如果这些优秀的顶会代码能够直接在ai studio上当成一个项目一创建就直接跑通，那对于开发者的学习和进一步的开发会便捷很多，当然这样很费人力，也或者可以对ai studio提供的环境进一步改善（能够匹配github提供的项目需求），让新的C++ OP类也可以在ai studio正常运行，这样开发者如果有需求时也可以在ai studio运行github上提供的代码，进行开发，并在ai studio公开别人也可以运行的更高质量的项目。",
        "state": "open",
        "user": "zhufeng888",
        "closed_by": null,
        "created_at": "2020-08-10T08:58:28+00:00",
        "updated_at": "2024-02-26T05:10:33+00:00",
        "closed_at": null,
        "comments_count": [
            "sandyhouse",
            "weiexcelpro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4800,
        "title": "度量学习finetune阶段训练出错",
        "body": "paddle版本1.8，目前已经完成了训练阶段，准备开始finetune，但是发现finetune无法训起来，finetune脚本：\r\npython train_pair.py  \\\r\n        --model=ResNet50 \\\r\n        --train_batch_size=160 \\\r\n        --test_batch_size=50 \\\r\n        --lr=0.0001 \\\r\n        --total_iter_num=100000 \\\r\n        --use_gpu=True \\\r\n        --pretrained_model=model_save/ResNet50/30000 \\\r\n        --model_save_dir=finetune_output \\\r\n        --loss_name=eml \\\r\n        --samples_each_class=2\r\n\r\n其中model_save/ResNet50/30000是第一阶段训练好的模型，测试其Recall为0.78174，但是启动finetune脚本后，出现如下错误：\r\n![image](https://user-images.githubusercontent.com/13143336/89866990-11264000-dbe3-11ea-9670-99936d9784a9.png)\r\n麻烦帮忙看一下",
        "state": "open",
        "user": "endy-see",
        "closed_by": null,
        "created_at": "2020-08-11T06:58:16+00:00",
        "updated_at": "2024-02-26T05:10:31+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "endy-see",
            "ceci3",
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4802,
        "title": "AI Studio环境CUDA出错",
        "body": "训练的模型是SimNet，无任何改动，报下面错误\r\n\r\nExternalError:  Cuda error(38), no CUDA-capable device is detected.\r\n  [Advise: This indicates that no CUDA-capable devices were detected by the installed CUDA driver. ] at (/paddle/paddle/fluid/platform/gpu_info.cc:65)",
        "state": "closed",
        "user": "hlzonWang",
        "closed_by": "hlzonWang",
        "created_at": "2020-08-16T10:26:26+00:00",
        "updated_at": "2020-08-18T01:15:31+00:00",
        "closed_at": "2020-08-18T01:15:31+00:00",
        "comments_count": [
            "MRXLT"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4805,
        "title": "dygraph动态图模型中中seq2seq任务的数据读取部分的问题",
        "body": "models/dygraph/seq2seq/reader.py的第207行\r\n` if len(b_src) == batch_size * cache_num or mode == 'infer':`\r\n是否应该为：\r\n` if len(b_src) <= batch_size * cache_num or mode == 'infer':`\r\n否则数据最后不满足bsz大小的部分将无法被读取",
        "state": "open",
        "user": "elevenofji",
        "closed_by": null,
        "created_at": "2020-08-17T05:07:47+00:00",
        "updated_at": "2020-08-18T09:45:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4806,
        "title": "Bert fp16 加载checkpoint出错",
        "body": "models/nlp/pretrain中的静态图Bert，fp16训练后读取检查点，报opt文件中找不到[word_embededing_master]的错误，这与模型readme.md中支持混合精度训练的描述不符。",
        "state": "open",
        "user": "hlzonWang",
        "closed_by": null,
        "created_at": "2020-08-18T01:24:26+00:00",
        "updated_at": "2020-08-19T09:36:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4803,
        "title": "DCGAN的自定义数据集应该做成什么样的格式",
        "body": null,
        "state": "open",
        "user": "xiaolifeimianbao",
        "closed_by": null,
        "created_at": "2020-08-16T11:52:38+00:00",
        "updated_at": "2024-02-26T05:10:28+00:00",
        "closed_at": null,
        "comments_count": [
            "MRXLT",
            "xiaolifeimianbao",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4804,
        "title": "[论文复现]请问paddle.dygraph应该如何可视化",
        "body": "请问是否有类似pytorch中print(model)类似的，打印模型各层的输出方法；或者像tensorboard，graphviz一样图形化模型的方法",
        "state": "open",
        "user": "huilin16",
        "closed_by": null,
        "created_at": "2020-08-17T00:37:47+00:00",
        "updated_at": "2020-08-18T10:48:35+00:00",
        "closed_at": null,
        "comments_count": [
            "lijianshe02",
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4810,
        "title": "加载roberta模型进行二次预训练, 但未能成功加载参数",
        "body": "已解决",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2020-08-21T05:21:55+00:00",
        "updated_at": "2020-08-21T05:56:31+00:00",
        "closed_at": "2020-08-21T05:56:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4807,
        "title": "metric learning中的eml loss指的是什么loss？",
        "body": "请问metric learning中的eml loss指的是什么loss？有对应的论文推荐嘛？",
        "state": "closed",
        "user": "endy-see",
        "closed_by": "endy-see",
        "created_at": "2020-08-18T10:04:02+00:00",
        "updated_at": "2020-08-19T12:04:39+00:00",
        "closed_at": "2020-08-19T12:04:39+00:00",
        "comments_count": [
            "shippingwang",
            "endy-see",
            "littletomatodonkey",
            "endy-see"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 221,
        "title": "怎么使用LAC扩展实体识别标签",
        "body": "请问对于特定领域的命名实体识别任务，怎么训练模型使其针对人名地名机构名时间之外的类别标签呢？尝试修改了tag.dic和训练数据进行非增量的训练，但是模型训练的时候P/R/F1一直是0。",
        "state": "closed",
        "user": "xbc0112",
        "closed_by": "chenxiaozeng",
        "created_at": "2020-08-25T03:02:40+00:00",
        "updated_at": "2021-04-02T06:05:31+00:00",
        "closed_at": "2021-04-02T06:05:31+00:00",
        "comments_count": [
            "xiaojiangsi",
            "LielinJiang",
            "xbc0112"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4813,
        "title": "预测的时候出现问题",
        "body": "RuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((1833, 100)), while the loaded parameter (namely [ word_emb ]) has a shape of  ((20941, 128)).\r\n自行建立了一个字典共1833个键值对，后来预测的时候出现这样的问题",
        "state": "open",
        "user": "xiaojiangsi",
        "closed_by": null,
        "created_at": "2020-08-25T03:15:41+00:00",
        "updated_at": "2024-02-26T05:10:24+00:00",
        "closed_at": null,
        "comments_count": [
            "mmglove",
            "LielinJiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4814,
        "title": "训练nextvlad模型，Hit@1不会变化",
        "body": "用models/PaddleCV/video/里的代码和youtube8m数据集训练nextvlad模型，为啥Hit@1上不去？\r\n\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:54:35] Epoch 10, iter 41910, time 0.24196863174438477,  , loss = 2.364186, Hit@1 = 0.08, PERR = 0.88, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:54:37] Epoch 10, iter 41920, time 0.23306751251220703,  , loss = 2.527951, Hit@1 = 0.05, PERR = 0.91, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:54:45] Epoch 10, iter 41930, time 0.25219297409057617,  , loss = 2.148221, Hit@1 = 0.05, PERR = 0.89, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:54:54] Epoch 10, iter 41940, time 0.23409438133239746,  , loss = 2.436858, Hit@1 = 0.05, PERR = 0.90, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:55:02] Epoch 10, iter 41950, time 0.2435312271118164,  , loss = 2.446642, Hit@1 = 0.06, PERR = 0.88, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:55:11] Epoch 10, iter 41960, time 6.53504204750061,  , loss = 1.978944, Hit@1 = 0.05, PERR = 0.90, GAP = 0.95\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:55:14] Epoch 10, iter 41970, time 0.2472538948059082,  , loss = 2.467091, Hit@1 = 0.05, PERR = 0.93, GAP = 0.93\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-08-26 07:55:24] Epoch 10, iter 41980, time 0.24446415901184082,  , loss = 2.176183, Hit@1 = 0.04, PERR = 0.90, GAP = 0.94\r\n",
        "state": "closed",
        "user": "lale314",
        "closed_by": "huangjun12",
        "created_at": "2020-08-26T03:44:37+00:00",
        "updated_at": "2020-10-30T02:17:37+00:00",
        "closed_at": "2020-10-30T02:17:37+00:00",
        "comments_count": [
            "huangjun12",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4816,
        "title": "AssertionError: Can not find [conv2d_8.w_0] in model file [models/model_02000.pdparams]",
        "body": "采用Flask做成api调用的形式，第一次能识别成功，第二次就失败了",
        "state": "open",
        "user": "zhenzi0322",
        "closed_by": null,
        "created_at": "2020-08-26T08:43:23+00:00",
        "updated_at": "2024-02-26T05:10:23+00:00",
        "closed_at": null,
        "comments_count": [
            "zhiqiu",
            "Lanme",
            "guochen2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4823,
        "title": "多元回归",
        "body": "我想写一个多元回归，输入是8个特征，输出也是8维度\r\n`\r\nX = fluid.data(name='X', shape=[None, 8], dtype='float32')\r\nY = fluid.data(name='Y', shape=[None, 8], dtype='float32')\r\n\r\nh1 = fluid.layers.fc(input=X, size=100, act='tanh')\r\nh2 = fluid.layers.fc(input=h1, size=100, act='tanh')\r\nh3 = fluid.layers.fc(input=h2, size=100, act='tanh')\r\npred = fluid.layers.fc(input=h3, size=8, act='tanh')\r\n\r\ncost = fluid.layers.cross_entropy(input=pred, label=Y)\r\navg_cost = fluid.layers.mean(cost)\r\n\r\nadam_opt = fluid.optimizer.Adam(learning_rate=0.0003)\r\nadam_opt.minimize(avg_cost)\r\n`\r\n但是一直报错：\r\nInvalidArgumentError: the last dimension of Input(Label) should be 1.But received: the last dimension of Input(Label) is [8],the last dimension is [1]\r\n  [Hint: Expected label_dims[rank - 1] == 1UL, but received label_dims[rank - 1]:8 != 1UL:1.] at (D:\\1.8.4\\paddle\\paddle\\fluid\\operators\\cross_entropy_op.cc:87)\r\n  [operator < cross_entropy2 > error]\r\n",
        "state": "closed",
        "user": "wjwalpha",
        "closed_by": "wjwalpha",
        "created_at": "2020-08-31T10:32:27+00:00",
        "updated_at": "2020-08-31T11:22:56+00:00",
        "closed_at": "2020-08-31T11:22:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4820,
        "title": "请问为什么这么写auc会是0.5呀",
        "body": "两种写法，第一种auc正常，可以训练到0.9+；第二种auc自始自终都是0.5，求解原因啊\r\n\r\n第一种(auc正常)：\r\nbinary_predict = fluid.layers.fc(\r\n            input=fc3,\r\n            size=2,\r\n            act=\"softmax\",\r\n            param_attr=fluid.ParamAttr(initializer=fluid.initializer.Normal(\r\n                scale=1 / math.sqrt(fc3.shape[1]))),\r\n        )\r\ncost = fluid.layers.cross_entropy(input=binary_predict, label=inputs[1])\r\navg_cost = fluid.layers.mean(cost)\r\n\r\nauc_var, batch_auc_var, auc_stat_list = fluid.layers.auc(input=binary_predict, label=inputs[1])\r\noptimizer.minimize(avg_cost)\r\n#-----------------------------------------\r\n\r\n第二种写法(auc恒为0.5):\r\nfc4 = fluid.layers.fc(\r\n            input=fc3,\r\n            size=1,\r\n            act=None,\r\n            param_attr=fluid.ParamAttr(initializer=fluid.initializer.Normal(\r\n                scale=1 / math.sqrt(fc3.shape[1]))),\r\n        )\r\npredict = fluid.layers.sigmoid(fc4)\r\ncast_label = fluid.layers.cast(inputs[1], dtype='float32')\r\ncost = fluid.layers.log_loss(input=predict, label=cast_label)\r\navg_cost = fluid.layers.mean(cost)\r\nbinary_predict = fluid.layers.concat(\r\n          input=[fluid.layers.elementwise_sub(fluid.layers.ceil(predict), predict), predict], axis=1)\r\n\r\nauc_var, batch_auc_var, auc_stat_list = fluid.layers.auc(input=binary_predict, label=inputs[1])\r\noptimizer.minimize(avg_cost)\r\n#-----------------------------------------\r\n\r\n\r\n哪里不对呢？感觉这两种计算binary_predict的方式是一样的，而且第二种比第一种自然。第一种还得再去取出binary_predict的第2列来作为预测的ctr保存起来（顺便问一句怎么取呢。。。)\r\npaddle1.8.3, train_from_dataset, cpu异步训练",
        "state": "closed",
        "user": "starsblinking",
        "closed_by": "starsblinking",
        "created_at": "2020-08-27T12:48:05+00:00",
        "updated_at": "2020-08-28T10:50:40+00:00",
        "closed_at": "2020-08-28T10:50:40+00:00",
        "comments_count": [
            "GaoWei8",
            "starsblinking",
            "GaoWei8",
            "starsblinking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4818,
        "title": "resnet50单卡训练参数",
        "body": "Hi，我们目前正在用paddle做一些测试，请问可以提供单卡收敛的参数设置参考吗？我们在测试的时候发现在中途30几个epoch的时候会出现梯度爆炸的情况，loss变大\r\n我们需要测试如下网络：resnet50，数据集: imagenet，epoch=90，mixup=false，单卡\r\n\r\n谢谢 :)",
        "state": "open",
        "user": "learner321",
        "closed_by": null,
        "created_at": "2020-08-27T03:46:07+00:00",
        "updated_at": "2024-02-26T05:10:21+00:00",
        "closed_at": null,
        "comments_count": [
            "GaoWei8",
            "learner321",
            "GaoWei8",
            "learner321",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4821,
        "title": "度量学习 预测时结果每次不一样",
        "body": "按照度量学习的教程训练完后，进行预测，输入的图片没有改变过，只执行预测脚本，发现每次预测的结果不一样\r\n![QQ图片20200831110611](https://user-images.githubusercontent.com/62418900/91679126-03c4fb80-eb7a-11ea-9721-40df97b8b8fe.png)\r\n![QQ图片20200831110620](https://user-images.githubusercontent.com/62418900/91679132-06275580-eb7a-11ea-945c-13579184c659.png)\r\n求解答",
        "state": "open",
        "user": "mcl-stone",
        "closed_by": null,
        "created_at": "2020-08-31T03:06:51+00:00",
        "updated_at": "2024-02-26T05:10:20+00:00",
        "closed_at": null,
        "comments_count": [
            "liym27",
            "mcl-stone",
            "littletomatodonkey",
            "mcl-stone",
            "mcl-stone",
            "yangy996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4825,
        "title": "预训练模型加载问题",
        "body": "https://paddle-imagenet-models-name.bj.bcebos.com/VGG19_pretrained.tar\r\n这个预训练模型下载出来后的文件名和我 `var.name` 出来的文件名不一样，加载不进去，一直在报错，后来去找了模型库里的VGG19的代码（看到SPADE那个模型是用的 `load_vars`，我拿过来用，读出来的变量就不一致），加载也是报错，我几个load都试过了，从我的代码中读出的变量文件都带有后缀，和预训练模型不一样\r\n，请问应该用哪个api来加载这个形式的VGG19的预训练模型呢\r\n![image](https://user-images.githubusercontent.com/48123846/91743248-1b3bcd00-ebea-11ea-9c98-72680da57e61.png)\r\n\r\n",
        "state": "open",
        "user": "JixuH",
        "closed_by": null,
        "created_at": "2020-08-31T16:34:38+00:00",
        "updated_at": "2024-02-26T05:10:18+00:00",
        "closed_at": null,
        "comments_count": [
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4833,
        "title": "已解决",
        "body": "",
        "state": "closed",
        "user": "kyuer",
        "closed_by": "kyuer",
        "created_at": "2020-09-03T03:12:17+00:00",
        "updated_at": "2020-09-03T07:32:16+00:00",
        "closed_at": "2020-09-03T07:29:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4826,
        "title": "关于HAMBox(face detector)",
        "body": "请问HAMBox还会如论文中说的开源吗?",
        "state": "open",
        "user": "StetchPlane",
        "closed_by": null,
        "created_at": "2020-09-01T01:44:03+00:00",
        "updated_at": "2024-02-26T05:10:17+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01",
            "JohannesTK",
            "zehuichen123",
            "zehuichen123",
            "hujunchao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4841,
        "title": "paddleNLP下情感分析模型infer报错",
        "body": "使用下载的ernie_bilstm模型执行save_inference_model报错，\r\n\r\n![image](https://user-images.githubusercontent.com/33422503/92571120-4c389380-f2b5-11ea-84d6-776d8e2c8e0d.png)\r\n\r\n\r\n与[#4799](https://github.com/PaddlePaddle/models/issues/4799) 问题相同，在[#4799](https://github.com/PaddlePaddle/models/issues/4799) 下未找到解决方案。麻烦看一下是否bug",
        "state": "open",
        "user": "KaiyuanGao",
        "closed_by": null,
        "created_at": "2020-09-09T07:58:59+00:00",
        "updated_at": "2024-02-26T05:10:16+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFormers",
        "number": 1346,
        "title": "开启lac 不成功",
        "body": "`AttributeError: module 'paddle.fluid.core_avx' has no attribute 'is_compiled_with_ngraph'`\r\npy是3.7 其他的hub 都是最新。但进行hub install lac==2.2.0  时就是不成功  windows cpu 下",
        "state": "closed",
        "user": "hdyzhuxun",
        "closed_by": "WYB27",
        "created_at": "2020-09-04T04:25:44+00:00",
        "updated_at": "2025-06-30T07:23:44+00:00",
        "closed_at": "2025-06-30T07:23:44+00:00",
        "comments_count": [
            "zhangting2020",
            "hdyzhuxun",
            "zhangting2020"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4839,
        "title": "静态图单机多卡训练",
        "body": "请教大佬，静态图训练时如何进行单机多卡训练。",
        "state": "closed",
        "user": "zhudibo",
        "closed_by": "ForFishes",
        "created_at": "2020-09-08T01:27:18+00:00",
        "updated_at": "2020-09-17T04:54:31+00:00",
        "closed_at": "2020-09-17T04:54:31+00:00",
        "comments_count": [
            "ForFishes",
            "zhudibo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4840,
        "title": "训练小尺寸的分类,比如  3,32,32  这种小图片,程序是否会出错,",
        "body": "训练小尺寸的分类,比如  3,32,32  这种小图片,程序是否会出错,\r\n因为我看默认的 crop是 224  不知道在哪里修改或者说 要是训练3.32.32的分类器(小于224) 是不是有一些参数是要修改的 ?\r\n因为我按照默认参数训练了一次是不成功的",
        "state": "closed",
        "user": "zjutlzt",
        "closed_by": "zjutlzt",
        "created_at": "2020-09-08T02:58:46+00:00",
        "updated_at": "2020-09-09T07:36:34+00:00",
        "closed_at": "2020-09-09T07:36:34+00:00",
        "comments_count": [
            "ForFishes",
            "zjutlzt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4842,
        "title": "image classfication里的可视化问题",
        "body": "请问一下如何在训练过程中使其acc和loss可视化。\r\n\r\n请问有自带的吗？\r\n\r\n如果没有的话，能不能给一个visualdl的教程，谢谢",
        "state": "open",
        "user": "chaogehah",
        "closed_by": null,
        "created_at": "2020-09-09T08:23:15+00:00",
        "updated_at": "2024-02-26T05:10:15+00:00",
        "closed_at": null,
        "comments_count": [
            "littletomatodonkey",
            "chaogehah",
            "littletomatodonkey",
            "chaogehah"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4844,
        "title": "PaddleNLP/sentiment_classification中senta_data中word_dict.txt如何生成",
        "body": "![图片](https://user-images.githubusercontent.com/32992310/92679193-56609d80-f35a-11ea-931e-b420f15915e9.png)\r\n你好，想问一下senta_data中word_dict.txt是如何生成，我的理解是每个训练集都要有自己配套的word_dict.txt，但是我这里用自己的训练集分词后，求集合，生成word_dict.txt，一直显示维度问题，因为nets中的embedding_size只能小于34907？被这个问题困扰了好久，之前一直是删词，删到小于34907为止\r\n期待回复，谢谢！",
        "state": "closed",
        "user": "Twinkle123321",
        "closed_by": "Twinkle123321",
        "created_at": "2020-09-10T03:43:52+00:00",
        "updated_at": "2020-09-11T03:50:31+00:00",
        "closed_at": "2020-09-11T03:50:31+00:00",
        "comments_count": [
            "Twinkle123321"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4846,
        "title": "请问使用LAC分词，怎么返回词语在原句子中的位置信息？（tokenize）",
        "body": "例如在jieba分词中可以这么用：\r\njieba.tokenize(u'永和服装饰品有限公司', mode='search')\r\n\r\nword 永和                start: 0                end:2\r\nword 服装                start: 2                end:4\r\nword 饰品                start: 4                end:6\r\nword 有限                start: 6                end:8\r\nword 公司                start: 8                end:10\r\nword 有限公司            start: 6                end:10\r\n\r\n请问LAC中有没有这种接口？如果没有，请问哪里可以用？",
        "state": "open",
        "user": "LeeYongchao",
        "closed_by": null,
        "created_at": "2020-09-11T08:27:52+00:00",
        "updated_at": "2024-02-26T05:10:12+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4845,
        "title": "请教一下：在Aistudio中通过Paddlehub Finetune一个模型，将Model文件下载到了本地，如何调用它进行预测",
        "body": "请教一下：在Aistudio中通过Paddlehub Finetune一个模型，将Model文件下载到了本地，如何调用它进行预测\r\n有没有示例代码，麻烦发一个，谢谢了。",
        "state": "open",
        "user": "thailand88",
        "closed_by": null,
        "created_at": "2020-09-11T02:49:23+00:00",
        "updated_at": "2024-02-26T05:10:13+00:00",
        "closed_at": null,
        "comments_count": [
            "baiyfbupt",
            "thailand88",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4848,
        "title": "PaddleNLP/shared_modules/preprocess/tokenizer.py句子过长无法分词？",
        "body": "![图片](https://user-images.githubusercontent.com/32992310/92926854-41296300-f46f-11ea-9a25-7657d88366c4.png)\r\n![图片](https://user-images.githubusercontent.com/32992310/92927244-e6dcd200-f46f-11ea-84f0-9077f06c0ecb.png)\r\n请问，这里单独可以对string分词，当内容过长时，将该内容放到文件进行读取，部分内容无法进行分词，这是咋回事呢\r\n期待回复，谢谢！",
        "state": "open",
        "user": "Twinkle123321",
        "closed_by": null,
        "created_at": "2020-09-11T12:48:35+00:00",
        "updated_at": "2024-02-26T05:10:11+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "Twinkle123321"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4849,
        "title": "Can you add flowers dataset to DyGraph Mobilenet training?",
        "body": "We were trying to run CPU training of DyGraph Mobilenet using the default Imagenet dataset but it takes a lot of time. Do you think it's possible that you could add smaller flowers dataset as an option just like it's already done in DyGraph Resnet model ?",
        "state": "open",
        "user": "arlesniak",
        "closed_by": null,
        "created_at": "2020-09-11T13:06:50+00:00",
        "updated_at": "2020-09-14T13:51:25+00:00",
        "closed_at": null,
        "comments_count": [
            "shippingwang",
            "luotao1"
        ],
        "labels": [
            "intel"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4852,
        "title": "models/PaddleNLP/seq2seq/seq2seq/base_model.py /里的base class 里的 def embedding 可能拼错了。",
        "body": "class BaseModel(object):\r\n    def __init__(self,\r\n                 hidden_size,\r\n                 src_vocab_size,\r\n                 tar_vocab_size,\r\n                 batch_size,\r\n                 num_layers=1,\r\n                 init_scale=0.1,\r\n                 dropout=None,\r\n                 beam_start_token=1,\r\n                 beam_end_token=2,\r\n                 beam_max_step_num=100):\r\n\r\n        self.hidden_size = hidden_size\r\n        self.src_vocab_size = src_vocab_size\r\n        self.tar_vocab_size = tar_vocab_size\r\n        self.batch_size = batch_size\r\n        self.num_layers = num_layers\r\n        self.init_scale = init_scale\r\n        self.dropout = dropout\r\n        self.beam_start_token = beam_start_token\r\n        self.beam_end_token = beam_end_token\r\n        self.beam_max_step_num = beam_max_step_num\r\n        self.src_embeder = lambda x: fluid.embedding(\r\n            input=x,\r\n            size=[self.src_vocab_size, self.hidden_size],\r\n            dtype='float32',\r\n            is_sparse=False,\r\n            param_attr=fluid.ParamAttr(\r\n                name='source_embedding',\r\n                initializer=uniform_initializer(init_scale)))\r\n\r\n        self.tar_embeder = lambda x: fluid.embedding(\r\n            input=x,\r\n            size=[self.tar_vocab_size, self.hidden_size],\r\n            dtype='float32',\r\n            is_sparse=False,\r\n            param_attr=fluid.ParamAttr(\r\n                name='target_embedding',\r\n                initializer=uniform_initializer(init_scale)))\r\n\r\n    def _build_data(self):\r\n        self.src = fluid.data(name=\"src\", shape=[None, None], dtype='int64')\r\n        self.src_sequence_length = fluid.data(\r\n            name=\"src_sequence_length\", shape=[None], dtype='int32')\r\n\r\n        self.tar = fluid.data(name=\"tar\", shape=[None, None], dtype='int64')\r\n        self.tar_sequence_length = fluid.data(\r\n            name=\"tar_sequence_length\", shape=[None], dtype='int32')\r\n        self.label = fluid.data(\r\n            name=\"label\", shape=[None, None, 1], dtype='int64')\r\n\r\n    _**### def _emebdding(self):\r\n        self.src_emb = self.src_embeder(self.src)\r\n        self.tar_emb = self.tar_embeder(self.tar)**_",
        "state": "open",
        "user": "peterzsj6",
        "closed_by": null,
        "created_at": "2020-09-14T02:13:27+00:00",
        "updated_at": "2024-02-26T05:10:09+00:00",
        "closed_at": null,
        "comments_count": [
            "peterzsj6",
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4857,
        "title": "image_classfication中多卡训练报错",
        "body": "您好，我在使用老版本的图像分类时，使用python -m paddle.distributed.launch调用train.py时提示如图错误，请问这是什么原因啊？老版本支持多卡训练吗？\r\n![image](https://user-images.githubusercontent.com/38464417/93335312-ce4a2e80-f858-11ea-82c6-8af3e9ca2c9b.png)\r\n\r\n",
        "state": "open",
        "user": "duanyaohui",
        "closed_by": null,
        "created_at": "2020-09-16T12:11:56+00:00",
        "updated_at": "2024-02-26T05:10:07+00:00",
        "closed_at": null,
        "comments_count": [
            "lfchener",
            "duanyaohui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4855,
        "title": "ppl去掉两行注释代码后计算为负值",
        "body": "语言模型的IPython Notebook：https://aistudio.baidu.com/aistudio/projectDetail/122290\r\n提到\r\n![image](https://user-images.githubusercontent.com/68889682/93316254-8d452080-f83e-11ea-9b14-a669318a6f7a.png)\r\n句子无关联后，把代码注释\r\ninit_hidden = np.array(fetch_outs[1])\r\ninit_cell = np.array(fetch_outs[2])\r\n注释后重新训练，再infer.py时，算出来是\r\nppl: -3059.441162109375。\r\n这是正常的么？\r\n之前的ppl:\r\n![image](https://user-images.githubusercontent.com/68889682/93316606-05abe180-f83f-11ea-8833-3e299c379525.png)\r\n1736.609130859375\r\n",
        "state": "closed",
        "user": "igfuns",
        "closed_by": "igfuns",
        "created_at": "2020-09-16T09:12:55+00:00",
        "updated_at": "2020-09-17T08:01:35+00:00",
        "closed_at": "2020-09-17T08:00:51+00:00",
        "comments_count": [
            "igfuns"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4859,
        "title": "PaddleCV/human_pose_estimation test.py代码中的一些问题",
        "body": "操作系统: win10\r\npython版本: 3.6.10\r\n问题文件: https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleCV/human_pose_estimation/lib/mpii_reader.py\r\n问题描述:\r\nhuman_pose_estimation使用mpii数据集test的时候一直没有运行结果。在问题文件186行\r\n`fold = ‘test’`\r\n修改为\r\n`fold = cfg.DATAROOT + '/' + cfg.IMAGEDIR + '/test'`\r\n之后可以运行，因为下一行os.listdir(fold)读取的路径不对，一直没读取到文件。",
        "state": "closed",
        "user": "a2824256",
        "closed_by": "a2824256",
        "created_at": "2020-09-18T03:30:01+00:00",
        "updated_at": "2020-09-18T07:09:29+00:00",
        "closed_at": "2020-09-18T06:29:08+00:00",
        "comments_count": [
            "wangxicoding",
            "a2824256",
            "a2824256"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4863,
        "title": "从字符串，直接进行推理问题",
        "body": "官方使用run_ernie_sequence_labeling.py 文件进行推理，发现推理过程是从硬盘读取数据，并封装成数据迭代器实现的，\r\n请问有没有 可以直接从内存上把字符串接过来，直接进行推理呢？\r\n\r\n我在内存中的字符串是列表格式的 ['字符串1' ,'字符串2', '字符串3']， 想直接进行推理，分词并返回词性标注，\r\n\r\n谢谢！！\r\n\r\n",
        "state": "closed",
        "user": "LeeYongchao",
        "closed_by": "gongweibao",
        "created_at": "2020-09-21T04:14:42+00:00",
        "updated_at": "2020-09-22T07:03:31+00:00",
        "closed_at": "2020-09-22T07:03:31+00:00",
        "comments_count": [
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4881,
        "title": "BMN模型推理出现错误",
        "body": "使用BMN模型推理动作识别，输入命令后出现错误\r\npython predict.py --model_name=BMN --config=./configs/bmn.yaml --log_interval=1 --weights=./models/bmn/BMN.pdparams --filelist=./data/dataset/bmn/infer.list --use_gpu=False\r\n出现错误提示：\r\nOptimizer file [./models/bmn/BMN.pdopt] not exits。\r\n请问是怎么回事？",
        "state": "closed",
        "user": "upenggod",
        "closed_by": "upenggod",
        "created_at": "2020-09-24T11:30:56+00:00",
        "updated_at": "2021-02-04T14:20:15+00:00",
        "closed_at": "2021-02-04T14:20:15+00:00",
        "comments_count": [
            "huangjun12",
            "upenggod",
            "upenggod",
            "upenggod",
            "upenggod",
            "huangjun12",
            "upenggod",
            "upenggod",
            "thuansb",
            "huangjun12"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4884,
        "title": "测试阶段　从dataloader读入数据和直接feed，结果不一致",
        "body": "训练阶段，用的dataloader读入数据，模型存储\r\n\r\n测试阶段，导入模型，dataloader读入数据测试正常，但直接feed array形式的数据，结果不一致，想问下是什么原因？\r\n\r\n还有同时加载两个模型，有没有样例",
        "state": "open",
        "user": "chaojiewang94",
        "closed_by": null,
        "created_at": "2020-09-25T00:32:27+00:00",
        "updated_at": "2024-02-26T05:10:06+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4890,
        "title": "TSM 模型对视频分类时，如何传入一个文件夹路径",
        "body": "",
        "state": "closed",
        "user": "yy2yy",
        "closed_by": "yy2yy",
        "created_at": "2020-09-28T08:32:16+00:00",
        "updated_at": "2020-09-28T09:06:17+00:00",
        "closed_at": "2020-09-28T09:05:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4885,
        "title": "Seq2Seq 案例里的 Basemodel class BaseModel(object): 里的_build_data里面的label是啥意思啊",
        "body": "class BaseModel(object):\r\n    def __init__(self,\r\n                 hidden_size,\r\n                 src_vocab_size,\r\n                 tar_vocab_size,\r\n                 batch_size,\r\n                 num_layers=1,\r\n                 init_scale=0.1,\r\n                 dropout=None,\r\n                 beam_start_token=1,\r\n                 beam_end_token=2,\r\n                 beam_max_step_num=100):\r\n\r\n        self.hidden_size = hidden_size\r\n        self.src_vocab_size = VOCAB_SIZE\r\n        self.tar_vocab_size = VOCAB_SIZE\r\n        self.batch_size = batch_size\r\n        self.num_layers = num_layers\r\n        self.init_scale = init_scale\r\n        self.dropout = dropout\r\n        self.beam_start_token = beam_start_token\r\n        self.beam_end_token = beam_end_token\r\n        self.beam_max_step_num = beam_max_step_num\r\n        self.src_embeder = lambda x: fluid.embedding(\r\n            input=x,\r\n            size=[self.src_vocab_size, self.hidden_size],\r\n            dtype='float32',\r\n            is_sparse=False,\r\n            param_attr=fluid.ParamAttr(\r\n                name='source_embedding',\r\n                initializer=uniform_initializer(init_scale)))\r\n\r\n        self.tar_embeder = lambda x: fluid.embedding(\r\n            input=x,\r\n            size=[self.tar_vocab_size, self.hidden_size],\r\n            dtype='float32',\r\n            is_sparse=False,\r\n            param_attr=fluid.ParamAttr(\r\n                name='target_embedding',\r\n                initializer=uniform_initializer(init_scale)))\r\n\r\n    def _build_data(self):\r\n        self.src = fluid.data(name=\"src\", shape=[None, None], dtype='int64')\r\n        self.src_sequence_length = fluid.data(\r\n            name=\"src_sequence_length\", shape=[None], dtype='int32')\r\n\r\n        self.tar = fluid.data(name=\"tar\", shape=[None, None], dtype='int64')\r\n        self.tar_sequence_length = fluid.data(\r\n            name=\"tar_sequence_length\", shape=[None], dtype='int32')\r\n        \r\n\r\n         self.label = fluid.data(\r\n            name=\"label\", shape=[None, None, 1], dtype='int64')\r\n",
        "state": "open",
        "user": "peterzsj6",
        "closed_by": null,
        "created_at": "2020-09-25T03:25:45+00:00",
        "updated_at": "2024-02-26T05:10:05+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4894,
        "title": "run_ernie.sh infer 进行预测，数据格式问题",
        "body": "训练了模型之后，`bash run_ernie.sh infer` 进行预测，预测的数据格式不应该是未标注的数据吗？你这里为什么只能用标注过的数据做预测\r\n```bash\r\nfunction run_infer() {\r\n    echo \"infering\"\r\n    python run_ernie_sequence_labeling.py \\\r\n        --mode infer \\\r\n        --ernie_config_path \"${ERNIE_PRETRAINED_MODEL_PATH}/ernie_config.json\" \\\r\n        # --init_checkpoint \"${ERNIE_FINETUNED_MODEL_PATH}\" \\\r\n        --init_checkpoint \"./ernie_models/step_620\"\r\n        --init_bound 0.1 \\\r\n        --vocab_path \"${ERNIE_PRETRAINED_MODEL_PATH}/vocab.txt\" \\\r\n        --batch_size 64 \\\r\n        --random_seed 0 \\\r\n        --num_labels 57 \\\r\n        --max_seq_len 128 \\\r\n        **--test_data \"${DATA_PATH}/test.tsv\" \\**\r\n        --label_map_config \"./conf/label_map.json\" \\\r\n        --do_lower_case true \\\r\n        --use_cuda false\r\n\r\n}\r\n```\r\n用未标注过的语料训练就报错",
        "state": "open",
        "user": "Adrian-Yan16",
        "closed_by": null,
        "created_at": "2020-09-30T03:30:08+00:00",
        "updated_at": "2020-12-16T06:34:02+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "Adrian-Yan16",
            "dancinghui",
            "aliendaniel"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4892,
        "title": "3d_vision",
        "body": "我在用3d_vision的PointRCNN模型时，编译出现错误。请问是什么原因。\r\n报错截图方便发到你们的邮箱里吗",
        "state": "open",
        "user": "Sqhttwl",
        "closed_by": null,
        "created_at": "2020-09-29T04:21:53+00:00",
        "updated_at": "2024-02-26T05:10:03+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4895,
        "title": "why deepfm use reduce_sum in loss?",
        "body": "why deepfm use reduce_sum in loss?  The loss is large, while the model could converge, it is strange. \r\n\r\nhttps://github.com/PaddlePaddle/models/blob/release/1.8/PaddleRec/ctr/deepfm_dygraph/train.py#L108",
        "state": "closed",
        "user": "chengmengli06",
        "closed_by": "hutuxian",
        "created_at": "2020-10-03T02:41:00+00:00",
        "updated_at": "2020-10-13T06:06:19+00:00",
        "closed_at": "2020-10-13T06:06:19+00:00",
        "comments_count": [
            "hutuxian",
            "chengmengli06",
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4896,
        "title": "The pretrained params do not exist，没找到可以直接用的checkpoint/step_final，不训练不可以直接用模型吗？",
        "body": "The pretrained params do not exist，没找到可以直接用的checkpoint/step_final，不训练不可以直接用模型吗？",
        "state": "open",
        "user": "huit3826",
        "closed_by": null,
        "created_at": "2020-10-10T01:10:58+00:00",
        "updated_at": "2024-02-26T05:10:01+00:00",
        "closed_at": null,
        "comments_count": [
            "lijianshe02"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 220,
        "title": "paddleNLP lexical_analysis的使用问题",
        "body": "> 我完全按照github的文档做的，什么都没改动，但在运行 sh run.sh train_single_gpu 时，报错 run.sh: 7: run.sh: Syntax error: \"(\" unexpected ，我在aistudio上面运行的",
        "state": "closed",
        "user": "Adrian-Yan16",
        "closed_by": "ZeyuChen",
        "created_at": "2020-09-29T03:24:36+00:00",
        "updated_at": "2021-09-16T11:33:01+00:00",
        "closed_at": "2021-09-16T11:33:01+00:00",
        "comments_count": [
            "Adrian-Yan16",
            "songzy12",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4898,
        "title": "language model 里面的模型定义文件怎么找不到",
        "body": ".\r\n├── README.md            # 文档\r\n├── run.sh               # 启动脚本\r\n├── train.py             # 训练代码\r\n├── reader.py            # 数据读取\r\n├── args.py              # 参数读取\r\n└── data                 # 数据下载\r\n../\r\n└── models\r\n    └── language_model\r\n        └── lm_model.py  # 模型定义文件\r\n\r\n\r\n如上所示的位置并没有找到这个文件",
        "state": "closed",
        "user": "peterzsj6",
        "closed_by": "peterzsj6",
        "created_at": "2020-10-10T07:10:35+00:00",
        "updated_at": "2020-10-16T02:02:41+00:00",
        "closed_at": "2020-10-16T02:02:41+00:00",
        "comments_count": [
            "lijianshe02",
            "peterzsj6"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4906,
        "title": "将两个用同一预训练网络的模型放在不同线程预测报错",
        "body": "我训了两个图像分类网络（6分类网络和1000分类网络），骨架网络都是用的ResNet200_vd,我将这两个网络分别放在不同线程运行，\r\n单独运行的时候都没问题，两个线程同时运行就会报错：\r\n![图片](https://user-images.githubusercontent.com/57475881/95972808-785fab00-0e45-11eb-8f23-0c32a3829fc3.png)\r\n![图片](https://user-images.githubusercontent.com/57475881/95972882-90372f00-0e45-11eb-9cc0-98f27069e14c.png)\r\n两个模型用的infer.py代码都一样，只是class_dim和pretraind_model参数不一样，报错的位置是这行代码：\r\n![图片](https://user-images.githubusercontent.com/57475881/95973022-beb50a00-0e45-11eb-93af-87bbfcbd725d.png)\r\n\r\n应该是两个线程之间的指令相互干扰造成的，请问如何处理？",
        "state": "open",
        "user": "Derek-Kun",
        "closed_by": null,
        "created_at": "2020-10-14T09:50:58+00:00",
        "updated_at": "2024-02-26T05:10:00+00:00",
        "closed_at": null,
        "comments_count": [
            "chenwhql",
            "Derek-Kun",
            "Derek-Kun",
            "chenwhql",
            "Derek-Kun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4907,
        "title": "关于main_program和startup_program",
        "body": "PaddleNLP/emotion_detection/run_classifier.py\r\n178-184行：\r\n\r\n        with fluid.program_guard(train_program, startup_prog):\r\n            with fluid.unique_name.guard():\r\n                train_loader, loss, accuracy, num_seqs = create_model(\r\n                    args, num_labels=num_labels, is_prediction=False)\r\n\r\n                sgd_optimizer = fluid.optimizer.Adagrad(learning_rate=args.lr)\r\n                sgd_optimizer.minimize(loss)\r\n\r\n请问下，训练完成后，startup_prog是不是拥有和train_program一样的参数？",
        "state": "open",
        "user": "zhangxuanaj",
        "closed_by": null,
        "created_at": "2020-10-15T04:30:22+00:00",
        "updated_at": "2020-10-15T12:28:37+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4908,
        "title": "the issue when use the sentiment_classification to paddlelite",
        "body": "I use the `sentiment_classification` in my project. It's ok to train, but when I transform it to paddlelite. It seems that the 'sequence_unpad' is not support in th arm platform.\r\n![image](https://user-images.githubusercontent.com/3112825/96208072-4e220080-0f9f-11eb-9fd7-322c83f2c22b.png)\r\n\r\nSo I want to change the code here [cnn_net](https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleNLP/shared_modules/models/classification/nets.py#L55)\r\nremove the `sequence_unpad`, and use the [max_seq_len, dim] to be the emb,  but I can't use the `sequence_conv_pool`.\r\nHow can I use some conv function here ?\r\n\r\nBy the way, `sequence_unpad` is not supported in paddle lite, could anyone help implement a version with paddle lite ?",
        "state": "closed",
        "user": "burness",
        "closed_by": "burness",
        "created_at": "2020-10-16T03:09:30+00:00",
        "updated_at": "2020-10-20T01:41:33+00:00",
        "closed_at": "2020-10-20T01:41:33+00:00",
        "comments_count": [
            "zhupengyang",
            "burness"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4910,
        "title": "Seq2Seq 模型库案例里的reader案例为啥给 target language ID加上【1】，【2】",
        "body": "Seq2Seq 模型库案例里的reader 有几个看不懂的地方求助。\r\n\r\n> def read_all_line(filenam):\r\n> \r\n>   data = []\r\n> \r\n>   with io.open(filename, \"r\", encoding='utf-8') as f:\r\n> \r\n>   for line in f.readlines():\r\n> \r\n>   data.append(line.strip())\r\n\r\nfilename 好像写错了。\r\n\r\n且在 para file to id 中：\r\n\r\ndef _para_file_to_ids(src_file, tar_file, src_vocab, tar_vocab):\r\n\r\n \r\n\r\n  src_data = []\r\n\r\n  with io.open(src_file, \"r\", encoding='utf-8') as f_src:\r\n\r\n    for line in f_src.readlines():\r\n\r\n    arra = line.strip().split()\r\n\r\n    ids = [src_vocab[w] if w in src_vocab else UNK_ID for w in arra]\r\n\r\n    ids = ids\r\n\r\n \r\n\r\n    src_data.append(ids)\r\n\r\n \r\n\r\n  tar_data = []\r\n\r\n with io.open(tar_file, \"r\", encoding='utf-8') as f_tar:\r\n\r\n   for line in f_tar.readlines():\r\n\r\n   arra = line.strip().split()\r\n\r\n   ids = [tar_vocab[w] if w in tar_vocab else UNK_ID for w in arra]\r\n\r\n \r\n\r\n   ids = [1] + ids + [2]\r\n\r\n \r\n\r\n   tar_data.append(ids)\r\n\r\n \r\n\r\n return src_data, tar_data\r\n\r\n\r\n**tar_data的ids=[1]+ ids+[2]**\r\n\r\n这里的1和2是什么意思啊，1 和2 不是已经在_build_vocab里分给了两个词了吗\r\n\r\ngithub连接：https://github.com/PaddlePaddle/models/blob/release/1.8/dygraph/seq2seq/reader.py",
        "state": "closed",
        "user": "peterzsj6",
        "closed_by": "willthefrog",
        "created_at": "2020-10-17T03:28:21+00:00",
        "updated_at": "2020-11-04T01:35:31+00:00",
        "closed_at": "2020-10-19T09:33:48+00:00",
        "comments_count": [
            "willthefrog",
            "peterzsj6",
            "guoshengCS",
            "peterzsj6"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4924,
        "title": "emotion_detection/utils.py代码错误",
        "body": "utils.py第62行：seq_len = max_seq_len  是缩进错误吧？应该包括在else内，否则seq_len不能表示sequence的真实长度",
        "state": "closed",
        "user": "zhangxuanaj",
        "closed_by": "ZeyuChen",
        "created_at": "2020-10-30T12:13:36+00:00",
        "updated_at": "2020-12-24T14:23:07+00:00",
        "closed_at": "2020-12-24T14:23:07+00:00",
        "comments_count": [
            "ForFishes",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 128,
        "title": "simnet mmdnn报错",
        "body": "paddle版本1.8.0\r\nsimnet 采用模型config/mmdnn_pointwise.json\r\n使用pointwise模型，数据格式为：text_a text_b label形式\r\n\r\n模型报错：\r\n![image](https://user-images.githubusercontent.com/20043808/97671834-f4075c00-1ac3-11eb-8f43-fb09ae220d98.png)\r\n",
        "state": "closed",
        "user": "barry2025",
        "closed_by": "github-actions[bot]",
        "created_at": "2020-10-30T07:25:16+00:00",
        "updated_at": "2023-03-15T00:17:32+00:00",
        "closed_at": "2023-03-15T00:17:32+00:00",
        "comments_count": [
            "ForFishes",
            "barry2025",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 125,
        "title": "bert模型可以用cpu训练吗？",
        "body": "",
        "state": "closed",
        "user": "JoyeeL",
        "closed_by": "chenxiaozeng",
        "created_at": "2020-11-02T12:24:36+00:00",
        "updated_at": "2021-04-02T09:42:06+00:00",
        "closed_at": "2021-04-02T09:42:06+00:00",
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4934,
        "title": "Arpa file for common crawl",
        "body": "Hi,\r\n\r\nPlease suggest from where i can get \"arpa\" file for top 400,000 most frequent words of file en.00 from \"common crawl repository\", which was used to generate \"trie\" file for English LM.",
        "state": "open",
        "user": "pallav11",
        "closed_by": null,
        "created_at": "2020-11-04T10:17:18+00:00",
        "updated_at": "2020-11-24T06:46:14+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "Pallav56"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4942,
        "title": "Detailed Settings in HAMBox",
        "body": "Hi, I am trying to reimplement HAMBox with Pytorch. However, there are some details that I am not sure based on the description in the paper. Could you help me with the following questions? Thanks a lot!\r\n1. The paper says it trains Widerface with 140k iteration. So the iteration here refers to one GPU or four? If refers to one, the total epoch based on settings in the paper(4GPU, batch_size=7) is about 61(140_000 * 7 / 12881), otherwise 244. \r\n2. The paper says it only uses P2-P6, however, the anchor generator outputs 6 anchor_size: [16, 32, 64, 128, 256, 512]. So which level holds two different anchor sizes?\r\n3. Is multi-scale testing used in the paper when reporting performance? If used, what scales do you choose?\r\n",
        "state": "closed",
        "user": "zehuichen123",
        "closed_by": "zehuichen123",
        "created_at": "2020-11-09T12:05:50+00:00",
        "updated_at": "2021-07-05T08:07:05+00:00",
        "closed_at": "2021-07-05T08:07:05+00:00",
        "comments_count": [
            "zehuichen123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 127,
        "title": "ernie_pyreader数据维度和padding方式不一致",
        "body": "ernie_pyreader读取数据要求batch内均为max_seq_len长，但是调用的padding.py是按照batch内最大长度进行padding的。\r\n\r\nernie_pyreader： PaddleNLP/shared_modules/models/representation/ernie.py\r\npadding.py：PaddleNLP/shared_modules/preprocess/padding.py",
        "state": "closed",
        "user": "zhangxuanaj",
        "closed_by": "ZeyuChen",
        "created_at": "2020-11-11T07:34:15+00:00",
        "updated_at": "2021-09-04T08:04:39+00:00",
        "closed_at": "2021-09-04T08:04:39+00:00",
        "comments_count": [
            "wangxicoding",
            "zhangxuanaj",
            "wangxicoding",
            "zhangxuanaj",
            "wangxicoding",
            "songzy12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4955,
        "title": "DCGAN中infer.py问题：：",
        "body": "在DCGAN中运行infer.py，\r\n![image](https://user-images.githubusercontent.com/63913709/99250623-f0efc800-2846-11eb-8084-6b8621e86db6.png)\r\ndata中只有mnist，怎么还是加载的celeba?\r\n![image](https://user-images.githubusercontent.com/63913709/99250750-285e7480-2847-11eb-9d6d-7b396f596dd5.png)\r\n![image](https://user-images.githubusercontent.com/63913709/99250828-462bd980-2847-11eb-940c-963bc3234e5e.png)\r\n\r\n",
        "state": "open",
        "user": "jackie8310",
        "closed_by": null,
        "created_at": "2020-11-16T12:06:59+00:00",
        "updated_at": "2024-02-26T05:09:54+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "jackie8310"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4957,
        "title": "ETS模型的数据处理",
        "body": "我在使用ETS模型时，根据模型说明数据文档从ActivityNet下载页面下载了~89G数据，下载之后发现文件是.hdf5格式的，因此，根据后续的处理方法处理数据时，发现不能正常处理。请问这种情况有什么解决方法吗？",
        "state": "open",
        "user": "mc261670164",
        "closed_by": null,
        "created_at": "2020-11-17T02:48:42+00:00",
        "updated_at": "2024-02-26T05:09:53+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4959,
        "title": "动态图导入静态图模型报错",
        "body": "![image](https://user-images.githubusercontent.com/48643490/99468982-ce5fcb00-297c-11eb-9ed2-db7f75a42e9c.png)\r\n这个[ conv1._conv.weight]在name_space并没有使用，是paddle内置的必须有的参数吗？",
        "state": "open",
        "user": "knightning",
        "closed_by": null,
        "created_at": "2020-11-18T01:03:41+00:00",
        "updated_at": "2024-02-26T05:09:52+00:00",
        "closed_at": null,
        "comments_count": [
            "knightning",
            "TeslaZhao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4962,
        "title": "我在用自己数据集调试video tag的attention lstm模型时遇到点问题...",
        "body": "我的数据集有8类，也就是8个标签，我想利用你们开源的模型进行预训练，当我把configs/attention_lstm-single.yaml中MODEL下面的num_classes改成8的时候，报错如下：\r\nAssertionError: Parameter's shape does not match, the Program requires a parameter with the shape of ((4096, 8)), while the loaded parameter (namely [ output.w_0 ]) has a shape of  ((4096, 3396)).\r\n如果不使用预训练模型，可以跑完训练。请问我想是用你们的预训练模型的话，怎么解决？",
        "state": "closed",
        "user": "dl-lengyan",
        "closed_by": "dl-lengyan",
        "created_at": "2020-11-19T11:51:54+00:00",
        "updated_at": "2020-11-20T07:02:06+00:00",
        "closed_at": "2020-11-20T07:02:06+00:00",
        "comments_count": [
            "huangjun12",
            "dl-lengyan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4966,
        "title": "paddlecv/yolov3模型",
        "body": "paddlecv/yolov3模型是每次需要预测的时候都要重新训练吗？不能够再训练后保存模型，预测的时候直接用吗？\r\n\r\nDoes the Paddlecv/Yolov3 model have to be retrained every time it needs to be predicted? Can't it save the model after training and use it directly for prediction?",
        "state": "closed",
        "user": "B18090229",
        "closed_by": "qingqing01",
        "created_at": "2020-11-20T15:17:03+00:00",
        "updated_at": "2020-11-23T10:32:31+00:00",
        "closed_at": "2020-11-23T10:32:31+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4969,
        "title": "Do I need to convert the video to the pickle format when I use the TSN net?",
        "body": "Hi,\r\n\r\nI would like to train and predict the TSN net. I would like to know do I need to convert the .mp4 video to the pickle format? \r\n\r\nIt seems that the training and evaluation need the pickle format, and the prediction needs the mp4 video?\r\n\r\nMany thanks.",
        "state": "closed",
        "user": "p1n0cch10",
        "closed_by": "qili93",
        "created_at": "2020-11-23T13:19:14+00:00",
        "updated_at": "2020-11-26T02:51:31+00:00",
        "closed_at": "2020-11-26T02:51:31+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 219,
        "title": "simnet的预训练模型支持迁移学习吗",
        "body": "有一些专业词汇不在词典里，导致某些短语匹配的效果差点，用已有数据全新训练的效果不好，怎么用预训练的模型训练呢",
        "state": "closed",
        "user": "ly303550688",
        "closed_by": "github-actions[bot]",
        "created_at": "2020-10-20T08:48:36+00:00",
        "updated_at": "2023-03-15T00:17:34+00:00",
        "closed_at": "2023-03-15T00:17:34+00:00",
        "comments_count": [
            "GaoWei8",
            "guoshengCS",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 126,
        "title": "paddleNLP模型运行次数多以后，打印的日志相互矛盾",
        "body": "2020-11-01 05:27:32,566-WARNING: ./Good_models/step_5600/.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-11-01 05:27:32,567-WARNING: variable file [ ./Good_models/step_5600/checkpoint.pdopt ./Good_models/step_5600/checkpoint.pdparams ./Good_models/step_5600/checkpoint.pdmodel ] not used\r\n2020-11-01 05:27:32,567-WARNING: variable file [ ./Good_models/step_5600/checkpoint.pdopt ./Good_models/step_5600/checkpoint.pdparams ./Good_models/step_5600/checkpoint.pdmodel ] not used\r\n\r\n开发者们好：\r\n                请问程序在前半段执行的没有问题，后半段程序运行的时候同时出现『参数没有被找到』、『参数没有被使用』两种相互矛盾的日志是什么原因导致的呢？",
        "state": "closed",
        "user": "Twinkle123321",
        "closed_by": "chenxiaozeng",
        "created_at": "2020-11-01T09:04:31+00:00",
        "updated_at": "2021-04-02T09:40:37+00:00",
        "closed_at": "2021-04-02T09:40:37+00:00",
        "comments_count": [
            "danleifeng",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4965,
        "title": "【BUG】padding代码有问题",
        "body": "https://github.com/PaddlePaddle/models/blob/f80b766295e4c686d3d6d00858656d8239cea87f/PaddleNLP/shared_modules/preprocess/padding.py#L37\r\n\r\n运行PaddleNLP的情感分析ernie模型，会导致以下问题。\r\n![image](https://user-images.githubusercontent.com/33422503/99798578-358fa200-2b6c-11eb-805a-963498b1c615.png)\r\n\r\n原因是padding与定义的max_len不一致导致",
        "state": "closed",
        "user": "KaiyuanGao",
        "closed_by": "KaiyuanGao",
        "created_at": "2020-11-20T12:09:36+00:00",
        "updated_at": "2020-11-20T12:57:21+00:00",
        "closed_at": "2020-11-20T12:57:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 124,
        "title": "文本情感分类，为什么没有三分类的预训练模型",
        "body": "在实际中大部分都是三分类吧，积极中性消极？sentiment_classfiy都是积极和消极两个分类，也就是比如说一句话要么积极要么消极，在现实或者工业中不实际吧，请问是怎么考虑的。或者单纯是没有这样的语料？",
        "state": "closed",
        "user": "liuchenbaidu",
        "closed_by": "chenxiaozeng",
        "created_at": "2020-11-09T07:42:32+00:00",
        "updated_at": "2021-04-02T09:43:03+00:00",
        "closed_at": "2021-04-02T09:43:03+00:00",
        "comments_count": [
            "ZeyuChen",
            "Steffy-zxf"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4967,
        "title": "PaddleNLP情感分析infer结果每次都不一致",
        "body": "paddle版本：1.8.3\r\npython版本：3.7.1\r\n\r\n按照[Readme](https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/sentiment_classification) 下载ernie预训练模型与数据进行infer，可以成功运行，同一份测试数据但每次infer的结果不一致，请问是什么问题？\r\n![image](https://user-images.githubusercontent.com/33422503/99939683-9655ef00-2da5-11eb-8e9c-f50d1d39c515.png)\r\n![image](https://user-images.githubusercontent.com/33422503/99939694-99e97600-2da5-11eb-8655-caf313631877.png)\r\n",
        "state": "closed",
        "user": "KaiyuanGao",
        "closed_by": "KaiyuanGao",
        "created_at": "2020-11-23T08:05:08+00:00",
        "updated_at": "2020-12-03T09:30:01+00:00",
        "closed_at": "2020-12-03T09:30:01+00:00",
        "comments_count": [
            "qili93",
            "KaiyuanGao",
            "Steffy-zxf",
            "KaiyuanGao",
            "Steffy-zxf",
            "KaiyuanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4968,
        "title": "使用ETS模型时，如何使用自己的视频来准备数据集",
        "body": "您好，\r\n      我想请教一下，在跑ETS模型时，如何将自己的视频数据生成ETS模型能够使用的数据集？谢谢！",
        "state": "closed",
        "user": "mc261670164",
        "closed_by": "qili93",
        "created_at": "2020-11-23T09:40:42+00:00",
        "updated_at": "2020-11-26T02:51:26+00:00",
        "closed_at": "2020-11-26T02:51:26+00:00",
        "comments_count": [
            "mc261670164",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4954,
        "title": "dcgan如何加载自己的数据集？？？",
        "body": "例程中给的是mnist数据集，如果用自己的数据集，数据集格式该如何？是否支持读入自己的数据集训练",
        "state": "open",
        "user": "jackie8310",
        "closed_by": null,
        "created_at": "2020-11-16T09:25:56+00:00",
        "updated_at": "2024-02-26T05:09:56+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 123,
        "title": "emotion_detection 运行ernie evaluate报错",
        "body": "models/PaddleNLP/emotion_detection/run_ernie.sh   train完成后，运行eval报错，看报错信息，应该是在fluid.load(main_program, init_checkpoint_path, exe) 的时候出错了，error信息：\r\n\r\nError: When calling this method, the Tensor's numel must be equal or larger than zero. Please check Tensor::dims, or Tensor::Resize has been called first. The Tensor's shape is [-1, 768] now\r\n  [Hint: Expected numel() >= 0, but received numel():-768 < 0:0.] at (/paddle/paddle/fluid/framework/tensor.cc:45)",
        "state": "closed",
        "user": "zhangxuanaj",
        "closed_by": "chenxiaozeng",
        "created_at": "2020-11-17T11:13:07+00:00",
        "updated_at": "2021-04-02T09:45:01+00:00",
        "closed_at": "2021-04-02T09:45:01+00:00",
        "comments_count": [
            "Joejiong",
            "Joejiong",
            "zhangxuanaj",
            "Joejiong",
            "zhangxuanaj",
            "xiaosheng123XIAO",
            "chenxiaozeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4970,
        "title": "Data Anchor Sampling in Pyramidbox",
        "body": "Thanks for your code. I have some problems with the code pyramidbox. In the paper, the sampling is using the data anchor sampling, however in the code, it uses a probality that\r\n```python \r\nif prob>data_anchor_sampling_prob:\r\n      data_anchor_sampling\r\nelse:\r\n      using sampling methods in s3fd\r\n```\r\nSo why do you design this, and if the result in the paper is with the same set\r\nThanks very much3",
        "state": "open",
        "user": "XDUSPONGE",
        "closed_by": null,
        "created_at": "2020-11-24T07:08:37+00:00",
        "updated_at": "2024-02-26T05:09:51+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4972,
        "title": "How can I load a pretrained model in AttentionCluster to train my own data?",
        "body": "Hi,\r\n\r\nI am using the AttentionCluster to train my model, linked here.\r\n\r\nI download the released model for finetuning. The model only has an AttentionCluster.pdparams file, but no AttentionCluster.pdopt. \r\n\r\nAnd it shows \r\n`AssertionError: Optimizer file [./AttentionCluster.pdopt] not exits`\r\n\r\nWhen I set pretrain=\"AttentionCluster.pdparams\", it shows the shape does not match, because my class num is 12.\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_shenfen.py\", line 259, in <module>\r\n    train(args)\r\n  File \"train_shenfen.py\", line 174, in train\r\n    train_model.load_pretrain_params(exe, pretrain, train_prog, place)\r\n  File \".../models/model.py\", line 154, in load_pretrain_params\r\n    fluid.set_program_state(prog, state_dict)\r\n  File \".../python3.6/site-packages/paddle/fluid/io.py\", line 1968, in set_program_state\r\n    .format(orig_para_np.shape, para.name, new_para_np.shape)\r\nAssertionError: Parameter's shape does not match, the Program requires a parameter with the shape of ((4096, 12)), while the loaded parameter (namely [ logistic.weights ]) has a shape of  ((4096, 3862)).\r\n```\r\n\r\nSo.. When I want to resume a model for finetuning, I do not have a pdopt file, and when I want to load a pretrained model, the shape does not match..",
        "state": "open",
        "user": "p1n0cch10",
        "closed_by": null,
        "created_at": "2020-11-24T15:57:47+00:00",
        "updated_at": "2024-02-26T05:09:50+00:00",
        "closed_at": null,
        "comments_count": [
            "p1n0cch10",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4978,
        "title": "paddle.fluid.layers.lstm权重赋值",
        "body": "请问有没有为LSTM的权重进行赋值的AP，就是讲numpy数组赋值到lstm，如果有的话权重的维度是什么样的呢，四个门的顺序又是如何呢？",
        "state": "open",
        "user": "Jorsen0",
        "closed_by": null,
        "created_at": "2020-12-03T05:52:40+00:00",
        "updated_at": "2024-02-26T05:09:45+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4973,
        "title": "The avg losses are not same for training and validation when the same data are used.",
        "body": "Hi,\r\n\r\nI am training a AttentionCluster for video classification by using my own data, followed here\r\nhttps://github.com/PaddlePaddle/models/blob/release/1.8/PaddleCV/video/models/attention_cluster/README.md\r\n\r\nI used the same data for training, validation, testing, and inference. In the training phrase, the avg losses for training and validation are different. The avg loss for training is about 0.002, but that for validation is 0.1.\r\n\r\nMy config file is something like this.\r\n\r\nMODEL:\r\n    name: \"AttentionCluster\"\r\n    dataset: \"YouTube-8M\"\r\n    bone_network: None\r\n    drop_rate: 0.5 \r\n    feature_num: 2\r\n    feature_names: ['rgb', 'audio']\r\n    feature_dims: [1024, 128]\r\n    seg_num: 100 \r\n    cluster_nums: [32, 32] \r\n    num_classes: 12\r\n    topk: 20\r\n    UNIQUE:\r\n        good: 20\r\n        bad: 30\r\n\r\nTRAIN:\r\n    epoch: 100 \r\n    learning_rate: 0.001\r\n    pretrain_base: None\r\n    #batch_size: 2048\r\n    batch_size: 128 \r\n    use_gpu: True\r\n    #num_gpus: 8\r\n    num_gpus: 1\r\n    filelist: \"data/dataset/youtube8m/train.list\"\r\n\r\nVALID:\r\n    #batch_size: 2048\r\n    batch_size: 128 \r\n    filelist: \"data/dataset/youtube8m/train.list\"\r\n\r\nTEST:\r\n    #batch_size: 256\r\n    batch_size: 128 \r\n    filelist: \"data/dataset/youtube8m/train.list\"\r\n\r\nINFER:\r\n    batch_size: 1\r\n    filelist: \"data/dataset/youtube8m/train.list\"\r\n\r\n\r\nHere is a piece of log of the last epoch.\r\n[INFO: train_utils.py:   46]: ------- learning rate [0.001], learning rate counter [-] ----- \r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:49] Epoch 99, iter 0, time 0.34092283248901367,  , loss = 0.001345, Hit@1 = 0.40, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:49] Epoch 99, iter 1, time 0.18329644203186035,  , loss = 0.028296, Hit@1 = 0.41, PERR = 0.99, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:49] Epoch 99, iter 2, time 0.1722731590270996,  , loss = 0.001181, Hit@1 = 0.47, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:50] Epoch 99, iter 3, time 0.17226123809814453,  , loss = 0.002051, Hit@1 = 0.43, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:50] Epoch 99, iter 4, time 0.17180728912353516,  , loss = 0.001143, Hit@1 = 0.42, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:50] Epoch 99, iter 5, time 0.17211627960205078,  , loss = 0.002029, Hit@1 = 0.45, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:50] Epoch 99, iter 6, time 0.171461820602417,  , loss = 0.002691, Hit@1 = 0.46, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TRAIN 2020-11-25 00:59:50] Epoch 99, iter 7, time 0.1721813678741455,  , loss = 0.001076, Hit@1 = 0.44, PERR = 1.00, GAP = 1.00\r\n[INFO: train_utils.py:  122]: [TRAIN] Epoch 99 training finished, average time: 0.17362822805132186\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 0  , loss = 0.474687, Hit@1 = 0.76, PERR = 0.98, GAP = 0.98\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 1  , loss = 0.015227, Hit@1 = 1.00, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 2  , loss = 0.113151, Hit@1 = 0.98, PERR = 0.98, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 3  , loss = 0.117705, Hit@1 = 0.99, PERR = 0.99, GAP = 0.99\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 4  , loss = 0.105678, Hit@1 = 0.46, PERR = 0.98, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 5  , loss = 0.105103, Hit@1 = 0.98, PERR = 0.99, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 6  , loss = 0.004947, Hit@1 = 1.00, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:   79]: [TEST] test_iter 7  , loss = 0.013899, Hit@1 = 1.00, PERR = 1.00, GAP = 1.00\r\n[INFO: metrics_util.py:  112]: [TEST] Finish    avg_hit_at_one: 0.896331787109375,  avg_perr: 0.9912109375, avg_loss :0.1187995703658089,   aps: [0.9961657036415631, 0, 0, 0, 0, 0, 1.0000000000000002, 0, 0.9999999999999999, 1.0, 0, 0.9981928818589554],    gap:0.9960663751614023\r\nshare_vars_from is set, scope is ignored.",
        "state": "open",
        "user": "p1n0cch10",
        "closed_by": null,
        "created_at": "2020-11-25T04:20:57+00:00",
        "updated_at": "2024-02-26T05:09:49+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "p1n0cch10"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4976,
        "title": "using 2.0rc with CUDA10.1, install correctly but cannot find GPU",
        "body": "**Enviorment**: win10+CUDA10.1+cuDNN+PaddlePaddle_2.0rc\r\n**nvidia-smi**: NVIDIA-SMI 431.94       Driver Version: 431.94       CUDA Version: 10.1\r\n**nvcc --version**: Cuda compilation tools, release 10.1, V10.1.105\r\n**cudnn version**: cudnn-10.1-windows10-x64-v8.0.5.39\r\n**python --version**: Python 3.6.1\r\n**python -m pip --version** : pip 20.2.4\r\ninstalling by \"python -m pip install paddlepaddle-gpu==2.0.0rc0.post101 -f https://paddlepaddle.org.cn/whl/stable.html\"\r\n\r\nusing **import paddle.fluid as fluid** to check, returns:\r\n_W1129 09:52:00.254734 16436 init.cc:157] Compiled with WITH_GPU, but no GPU found in runtime.\r\nC:\\Users\\X1\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\paddle\\fluid\\framework.py:295: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  \"You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\"_\r\n\r\ninstalled and unistalled for muitlple times, any thoughts?\r\n",
        "state": "open",
        "user": "0mao0",
        "closed_by": null,
        "created_at": "2020-11-29T01:53:02+00:00",
        "updated_at": "2022-05-13T14:50:56+00:00",
        "closed_at": null,
        "comments_count": [
            "MissPenguin",
            "0mao0",
            "abhay-kum",
            "pangyoki"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4977,
        "title": "Make gru_compute.cc.o Error!!!",
        "body": "What's wrong with this and how can I fix it?\r\n\r\nHW: Jetson Nano\r\nPlatform: Ubuntu 18.04 image from NVIDIA official site.\r\n\r\nBased on Step 2-6 of the guideline I got below error again and again.\r\n\r\n[ 41%] Building CXX object paddle/fluid/operators/math/CMakeFiles/gru_compute.dir/gru_compute.cc.o\r\n/home/.../paddle/paddle/fluid/operators/math/gru_compute.cc: In instantiation of ‘static void paddle::operators::math::GRUUnitFunctor<paddle::platform::CPUDeviceContext, T>::compute(const paddle::platform::CPUDeviceContext&, paddle::operators::math::GRUMetaValue<T>, int, int, paddle::operators::math::detail::ActivationType, paddle::operators::math::detail::ActivationType, bool) [with T = float]’:\r\n/home/.../paddle/paddle/fluid/operators/math/gru_compute.cc:197:17:   required from here\r\n/home/.../paddle/paddle/fluid/operators/math/gru_compute.cc:55:33: error: the compiler can assume that the address of ‘context’ will never be NULL [-Werror=address]\r\n     detail::forward_final_output(detail::forward::gru_finalOutput<T>(), value,\r\n     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                                  frame_size, batch_size, active_node,\r\n                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                                  origin_mode, &context);\r\n                                  ~~~~~~~~~~~~~~~~~~~~~~\r\n......\r\ncc1plus: all warnings being treated as errors\r\npaddle/fluid/operators/math/CMakeFiles/gru_compute.dir/build.make:81: recipe for target 'paddle/fluid/operators/math/CMakeFiles/gru_compute.dir/gru_compute.cc.o' failed\r\nmake[2]: *** [paddle/fluid/operators/math/CMakeFiles/gru_compute.dir/gru_compute.cc.o] Error 1\r\nCMakeFiles/Makefile2:62115: recipe for target 'paddle/fluid/operators/math/CMakeFiles/gru_compute.dir/all' failed\r\nmake[1]: *** [paddle/fluid/operators/math/CMakeFiles/gru_compute.dir/all] Error 2\r\nMakefile:148: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n...@...-desktop:~/paddle/build$ \r\n",
        "state": "open",
        "user": "Noboru-Chen",
        "closed_by": null,
        "created_at": "2020-11-29T06:31:17+00:00",
        "updated_at": "2024-02-26T05:09:46+00:00",
        "closed_at": null,
        "comments_count": [
            "MissPenguin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4980,
        "title": "度量学习test的时候卡住不动了",
        "body": "度量学习官方例子\r\n运行到26000次的时候，在测试集的时候就卡住不动了，也不报错\r\n![QQ图片20201205121546](https://user-images.githubusercontent.com/63537268/101233449-ef058000-36f3-11eb-816f-853da27025df.png)\r\n强制停止的时候发现卡在这里了\r\n![QQ图片20201205121553](https://user-images.githubusercontent.com/63537268/101233607-fe84c900-36f3-11eb-9121-8c3510c2144e.png)\r\n",
        "state": "open",
        "user": "wengooooo",
        "closed_by": null,
        "created_at": "2020-12-05T04:19:20+00:00",
        "updated_at": "2024-02-26T05:09:44+00:00",
        "closed_at": null,
        "comments_count": [
            "luotao1",
            "wengooooo",
            "Intsigstephon",
            "wengooooo",
            "Intsigstephon",
            "xgyyao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4981,
        "title": "PaddlePaddleNLP issue",
        "body": "How to use the underlying model of the model to train their own data and predict, but only need to label proper terms.\r\nIn addition, can incremental training be continued on the basis of the underlying model?model is   https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/lexical_analysis。  Thanks！",
        "state": "closed",
        "user": "FYF1997",
        "closed_by": "FYF1997",
        "created_at": "2020-12-06T09:35:37+00:00",
        "updated_at": "2020-12-09T11:05:40+00:00",
        "closed_at": "2020-12-08T06:30:08+00:00",
        "comments_count": [
            "gongweibao",
            "kinghuin",
            "FYF1997",
            "kinghuin"
        ],
        "labels": [
            "paddlenlp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4993,
        "title": "进程被杀",
        "body": "您好，我在paddlepaddle1.8.4编译时进程被杀掉了，具体什么原因\r\n![image](https://user-images.githubusercontent.com/68497831/101439119-ccbb6e80-394e-11eb-9322-1422c16f87fd.png)\r\n",
        "state": "open",
        "user": "qdd1234",
        "closed_by": null,
        "created_at": "2020-12-08T04:13:41+00:00",
        "updated_at": "2020-12-09T09:13:28+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 4994,
        "title": "Thanks for your help！In addition, I would like to ask whether new proper nouns can be identified after incremental training if a new proper name tag is added during incremental training. When I conduct incremental training on the interface of Lac, I find that it can not recognize new proper nouns, so I turn to hope that I can get the results I want through the training of the underlying model. Meanwhile I‘m waitting for the better LAC！",
        "body": "Hi, \r\n\r\nyou can organize your data into the structures : https://github.com/PaddlePaddle/models/tree/release/1.8/PaddleNLP/lexical_analysis#%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F\r\nthe dataset demo can be see in https://baidu-nlp.bj.bcebos.com/lexical_analysis-2.0.0.tar.gz\r\nthen modify the `train_data`, `test_data `, `word_dict_path`, `label_dict_path `, `word_rep_dict_path ` to your real path in https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleNLP/lexical_analysis/run.sh#L10\r\n\r\nyes, you can incremental training by setting `--init_checkpoint`, it will load the model in https://github.com/PaddlePaddle/models/blob/release/1.8/PaddleNLP/lexical_analysis/train.py#L90\r\n\r\nBTW, The LAC model will be upgrade in Dec.20 which is easier to use, welcome to use!\r\n\r\n_Originally posted by @kinghuin in https://github.com/PaddlePaddle/models/issues/4981#issuecomment-740358928_",
        "state": "closed",
        "user": "FYF1997",
        "closed_by": "ZeyuChen",
        "created_at": "2020-12-08T06:43:12+00:00",
        "updated_at": "2021-01-23T16:25:15+00:00",
        "closed_at": "2021-01-23T16:25:15+00:00",
        "comments_count": [
            "ZeyuChen",
            "ZeyuChen",
            "ZeyuChen"
        ],
        "labels": [
            "paddlenlp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5005,
        "title": "请问稳重提到的preprocess文件在哪里？",
        "body": "![image](https://user-images.githubusercontent.com/26118845/101714475-9f98c880-3ad4-11eb-9184-2963db2df911.png)\r\n",
        "state": "closed",
        "user": "PhenixZhang",
        "closed_by": "PhenixZhang",
        "created_at": "2020-12-10T02:44:28+00:00",
        "updated_at": "2020-12-19T02:24:12+00:00",
        "closed_at": "2020-12-19T02:24:12+00:00",
        "comments_count": [
            "phlrain",
            "PhenixZhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5042,
        "title": "module 'paddle' has no attribute 'enable_static' ",
        "body": "Traceback (most recent call last):\r\n  File \"train.py\", line 252, in <module>\r\n    paddle.enable_static()\r\nAttributeError: module 'paddle' has no attribute 'enable_static'",
        "state": "closed",
        "user": "JonyJiang123",
        "closed_by": "JonyJiang123",
        "created_at": "2020-12-14T03:27:52+00:00",
        "updated_at": "2020-12-22T07:41:49+00:00",
        "closed_at": "2020-12-22T07:41:49+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5009,
        "title": "Conv2D中的padding无法设置padding类型",
        "body": "想要设置padding的类型为 零填充，镜像填充，边缘填充\r\n但是Conv2D的API中，没有设置这一类型的参数。\r\n\r\n另，请教，默认的padding类型，是以零填充吗？",
        "state": "open",
        "user": "herb711",
        "closed_by": null,
        "created_at": "2020-12-10T08:05:48+00:00",
        "updated_at": "2024-02-26T05:09:41+00:00",
        "closed_at": null,
        "comments_count": [
            "phlrain"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5103,
        "title": "We only support '%s()' in static graph mode, please call 'paddle.enable_static()' to enter static graph mode.\" % func.__name__",
        "body": "我按照BMN的[README](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/bmn/README.md)教程做,到运行`bash run.sh predict BMN ./configs/bmn.yaml`时遇到如下报错,请问如何debug,谢谢!\r\n\r\n```\r\n(base) weidawang@weidawang-TUF-Gaming-FX506LU-FX506LU:~/Repo/PaddlePaddle/models/PaddleCV/video$ bash run.sh predict BMN ./configs/bmn.yaml\r\npredict BMN ./configs/bmn.yaml\r\nDALI is not installed, you can improve performance if use DALI\r\n[INFO: predict.py:  198]: Namespace(batch_size=1, config='./configs/bmn.yaml', filelist=None, infer_topk=20, log_interval=1, model_name='BMN', save_dir='data/predict_results', use_gpu=True, video_path='', weights=None)\r\n[INFO: config_utils.py:   70]: ---------------- Infer Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:100\r\n[INFO: config_utils.py:   74]:     dscale:100\r\n[INFO: config_utils.py:   74]:     feat_dim:400\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:32\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:data/dataset/bmn/activitynet_1.3_annotations.json\r\n[INFO: config_utils.py:   74]:     feat_path:/media/weidawang/DATA/dataset/ActionLocalization/bmn_feat\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:9\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 200, in <module>\r\n    infer(args)\r\n  File \"predict.py\", line 104, in infer\r\n    infer_model.build_input(use_dataloader=False)\r\n  File \"/home/weidawang/Repo/PaddlePaddle/models/PaddleCV/video/models/bmn/bmn.py\", line 69, in build_input\r\n    feat = fluid.data(name='feat', shape=feat_shape, dtype='float32')\r\n  File \"<decorator-gen-25>\", line 2, in data\r\n  File \"/home/weidawang/miniconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/weidawang/miniconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 232, in __impl__\r\n    ), \"We only support '%s()' in static graph mode, please call 'paddle.enable_static()' to enter static graph mode.\" % func.__name__\r\n```\r\n",
        "state": "closed",
        "user": "wwdok",
        "closed_by": "wwdok",
        "created_at": "2020-12-18T03:45:56+00:00",
        "updated_at": "2020-12-18T05:25:48+00:00",
        "closed_at": "2020-12-18T05:25:48+00:00",
        "comments_count": [
            "wwdok",
            "wwdok"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5107,
        "title": "TypeError: a bytes-like object is required, not 'str'",
        "body": "My python version is 3.7.7, I got following error :\r\n\r\n```\r\n(base) weidawang@weidawang-TUF-Gaming-FX506LU-FX506LU:~/Repo/PaddlePaddle/models/PaddleCV/video/data/dataset/tall$ python gen_infer.py\r\nTraceback (most recent call last):\r\n  File \"gen_infer.py\", line 37, in <module>\r\n    select_name = movies_sentence[0][0].split('.')[0]\r\nTypeError: a bytes-like object is required, not 'str'\r\n```\r\n",
        "state": "open",
        "user": "wwdok",
        "closed_by": null,
        "created_at": "2020-12-18T06:33:22+00:00",
        "updated_at": "2024-02-26T05:09:40+00:00",
        "closed_at": null,
        "comments_count": [
            "wwdok",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5115,
        "title": "Optimizer file [/home/weidawang/.paddle/weights/BMN.pdopt] not exits",
        "body": "I got error when i am getting started with BMN:\r\n\r\n```\r\n(base) weidawang@weidawang-TUF-Gaming-FX506LU-FX506LU:~/Repo/PaddlePaddle/models/PaddleCV/video$ bash run.sh predict BMN ./configs/bmn.yaml\r\npredict BMN ./configs/bmn.yaml\r\nDALI is not installed, you can improve performance if use DALI\r\n[INFO: predict.py:  199]: Namespace(batch_size=1, config='./configs/bmn.yaml', filelist=None, infer_topk=20, log_interval=1, model_name='BMN', save_dir='data/predict_results', use_gpu=True, video_path='', weights=None)\r\n[INFO: config_utils.py:   70]: ---------------- Infer Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:100\r\n[INFO: config_utils.py:   74]:     dscale:100\r\n[INFO: config_utils.py:   74]:     feat_dim:400\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:32\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:data/dataset/bmn/activitynet_1.3_annotations.json\r\n[INFO: config_utils.py:   74]:     feat_path:/media/weidawang/DATA/dataset/ActionLocalization/bmn_feat\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:9\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW1218 16:29:50.778240 31472 device_context.cc:338] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.2\r\nW1218 16:29:50.779249 31472 device_context.cc:346] device: 0, cuDNN Version: 8.0.\r\ntest subset video numbers: 5\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 201, in <module>\r\n    infer(args)\r\n  File \"predict.py\", line 132, in infer\r\n    fluid.default_main_program(), place)\r\n  File \"/home/weidawang/Repo/PaddlePaddle/models/PaddleCV/video/models/model.py\", line 158, in load_test_weights\r\n    fluid.load(prog, weights, executor=exe, var_list=params_list)\r\n  File \"<decorator-gen-76>\", line 2, in load\r\n  File \"/home/weidawang/miniconda3/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/weidawang/miniconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 215, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/weidawang/miniconda3/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1882, in load\r\n    \"Optimizer file [{}] not exits\".format(opt_file_name)\r\nAssertionError: Optimizer file [/home/weidawang/.paddle/weights/BMN.pdopt] not exits\r\n```\r\n",
        "state": "closed",
        "user": "wwdok",
        "closed_by": "wwdok",
        "created_at": "2020-12-18T08:37:09+00:00",
        "updated_at": "2020-12-22T05:34:56+00:00",
        "closed_at": "2020-12-22T05:34:56+00:00",
        "comments_count": [
            "sandyhouse",
            "wwdok",
            "sandyhouse",
            "wwdok",
            "sandyhouse",
            "wwdok",
            "sandyhouse",
            "wwdok",
            "wwdok",
            "huangjun12",
            "wwdok"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5131,
        "title": "FatalError: A serious error (Segmentation fault) is detected by the operating system. (at /paddle/paddle/fluid/platform/init.cc:303)",
        "body": "大家好,我在按照[这个教程](https://github.com/PaddlePaddle/models/blob/release/2.0-beta/PaddleCV/video/application/video_tag/Run.md)运行video_tag的样例代码时,遇到了如下报错,请问有谁知道什么原因吗?谢谢!\r\n```\r\n(base) user@user-TUF-Gaming-FX506LU-FX506LU:~/Repo/PaddlePaddle/models/PaddleCV/video/application/video_tag$ python videotag_test.py\r\nNamespace(extractor_config='configs/tsn.yaml', extractor_name='TSN', extractor_weights='weights/tsn', filelist='./data/VideoTag_test.list', label_file='label_3396.txt', predictor_config='configs/attention_lstm.yaml', predictor_name='AttentionLSTM', predictor_weights='weights/attention_lstm', save_dir='data/VideoTag_results', use_gpu=True)\r\n[INFO: videotag_test.py:  240]: Namespace(extractor_config='configs/tsn.yaml', extractor_name='TSN', extractor_weights='weights/tsn', filelist='./data/VideoTag_test.list', label_file='label_3396.txt', predictor_config='configs/attention_lstm.yaml', predictor_name='AttentionLSTM', predictor_weights='weights/attention_lstm', save_dir='data/VideoTag_results', use_gpu=True)\r\nW1222 17:25:32.329594 11924 device_context.cc:338] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.2\r\nW1222 17:25:32.357901 11924 device_context.cc:346] device: 0, cuDNN Version: 8.0.\r\n[INFO: videotag_test.py:  138]: load extractor weights from weights/tsn\r\n[INFO: tsn.py:  155]: Load pretrain weights from weights/tsn, exclude fc layer.\r\n===pretrain=== weights/tsn\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::SignalHandle(char const*, int)\r\n1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: A serious error (Segmentation fault) is detected by the operating system. (at /paddle/paddle/fluid/platform/init.cc:303)\r\n  [TimeInfo: *** Aborted at 1608629142 (unix time) try \"date -d @1608629142\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 11924 (TID 0x7f5a6801a740) from PID 0 ***]\r\n\r\n段错误 (核心已转储)\r\n```\r\n我的电脑系统是ubuntu18.04,paddlepaddle版本是2.0.0rc0\r\n\r\n",
        "state": "open",
        "user": "wwdok",
        "closed_by": null,
        "created_at": "2020-12-22T09:33:11+00:00",
        "updated_at": "2024-02-26T05:09:39+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang",
            "wwdok",
            "indrasweb",
            "indrasweb"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5136,
        "title": "有没有DeepASR的预训练模型，我只想先测试一下",
        "body": "如题",
        "state": "open",
        "user": "lbq779660843",
        "closed_by": null,
        "created_at": "2020-12-23T07:07:16+00:00",
        "updated_at": "2024-02-26T05:09:38+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang",
            "lbq779660843"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5141,
        "title": "请完善一下使用文档",
        "body": "paddlerec的文档都是介绍性的文档, 没有像飞桨那样的使用教程 入门示例等开发文档.\r\npaddlerec文档看完就能知道怎么样把程序跑起来, 但是完全不知道怎么去开发",
        "state": "open",
        "user": "mervyn81",
        "closed_by": null,
        "created_at": "2020-12-25T01:17:26+00:00",
        "updated_at": "2024-02-26T05:09:37+00:00",
        "closed_at": null,
        "comments_count": [
            "wangchaochaohu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5142,
        "title": "pre_ids_emb = fluid.layers.embedding（） error in c++",
        "body": "os:\r\nubuntu  with gpu\r\npaddle1.8\r\n\r\n转换paddle到c++运行，下面两种情况，pyhon运行均正常，c++运行报错。\r\n**attention.py中的def attention_infer（）函数：**\r\n\r\n情况1：\r\npre_ids_emb = fluid.layers.embedding（）\r\n转化的模型在c++环境下运行出现错误：\r\n\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::LookupTableOp::InferShape(paddle::framework::InferShapeContext*) const\r\n3   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n5   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n6   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n8   paddle::operators::WhileOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::NaiveExecutor::Run()\r\n11  paddle::AnalysisPredictor::ZeroCopyRun()\r\n\r\n\r\nError: ShapeError: The last dimensions of the 'Ids' tensor must be 1. But received Ids's last dimensions = 128, Ids's shape = [1, 128].\r\n  [Hint: Expected ids_dims[ids_rank - 1] == 1, but received ids_dims[ids_rank - 1]:128 != 1:1.] at (/home/george/paddle/paddle/fluid/operators/lookup_table_op.cc:51)\r\n  [operator < lookup_table > error\r\n\r\n情况2：\r\npre_ids_emb = fluid.layers.embedding（）改为pre_ids_emb = fluid.embedding（）\r\n转化的模型在c++环境下运行出现错误：\r\n\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   long const* paddle::framework::Tensor::data<long>() const\r\n3   paddle::operators::LookupTableV2CUDAKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LookupTableV2CUDAKernel<float>, paddle::operators::LookupTableV2CUDAKernel<double>, paddle::operators::LookupTableV2CUDAKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n9   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n10  paddle::operators::WhileOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n11  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n12  paddle::framework::NaiveExecutor::Run()\r\n13  paddle::AnalysisPredictor::ZeroCopyRun()\r\n\r\n\r\nInvalidArgumentError: Tensor holds the wrong type, it holds float, but desires to be int64_t.\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] at (/home/george/paddle/paddle/fluid/framework/tensor_impl.h:33)\r\n  [operator < lookup_table_v2 > error]\r\n\r\n",
        "state": "open",
        "user": "GeorgeBohw",
        "closed_by": null,
        "created_at": "2020-12-25T02:17:16+00:00",
        "updated_at": "2024-02-26T05:09:36+00:00",
        "closed_at": null,
        "comments_count": [
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5143,
        "title": "“covert to c++” occurs error about “pre_ids_emb = fluid.layers.embedding（）”",
        "body": "os:\r\nubuntu  with gpu\r\npaddle1.8\r\n\r\n转换paddle到c++运行，下面两种情况，pyhon运行均正常，c++运行报错。\r\n**attention.py中的def attention_infer（）函数：**\r\n\r\n情况1：\r\npre_ids_emb = fluid.layers.embedding（）\r\n转化的模型在c++环境下运行出现错误：\r\n\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::LookupTableOp::InferShape(paddle::framework::InferShapeContext*) const\r\n3   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n5   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n6   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n8   paddle::operators::WhileOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::NaiveExecutor::Run()\r\n11  paddle::AnalysisPredictor::ZeroCopyRun()\r\n\r\n\r\nError: ShapeError: The last dimensions of the 'Ids' tensor must be 1. But received Ids's last dimensions = 128, Ids's shape = [1, 128].\r\n  [Hint: Expected ids_dims[ids_rank - 1] == 1, but received ids_dims[ids_rank - 1]:128 != 1:1.] at (/home/george/paddle/paddle/fluid/operators/lookup_table_op.cc:51)\r\n  [operator < lookup_table > error\r\n\r\n情况2：\r\npre_ids_emb = fluid.layers.embedding（）改为pre_ids_emb = fluid.embedding（）\r\n转化的模型在c++环境下运行出现错误：\r\n\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   long const* paddle::framework::Tensor::data<long>() const\r\n3   paddle::operators::LookupTableV2CUDAKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LookupTableV2CUDAKernel<float>, paddle::operators::LookupTableV2CUDAKernel<double>, paddle::operators::LookupTableV2CUDAKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n9   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n10  paddle::operators::WhileOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n11  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n12  paddle::framework::NaiveExecutor::Run()\r\n13  paddle::AnalysisPredictor::ZeroCopyRun()\r\n\r\n\r\nInvalidArgumentError: Tensor holds the wrong type, it holds float, but desires to be int64_t.\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] at (/home/george/paddle/paddle/fluid/framework/tensor_impl.h:33)\r\n  [operator < lookup_table_v2 > error]\r\n\r\n",
        "state": "open",
        "user": "GeorgeBohw",
        "closed_by": null,
        "created_at": "2020-12-25T02:20:18+00:00",
        "updated_at": "2024-02-26T05:09:34+00:00",
        "closed_at": null,
        "comments_count": [
            "GeorgeBohw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5146,
        "title": "动态图多卡训练时 收集各梯度的函数apply_collective_grads运行出错",
        "body": "系统：CentOS release 6.3\r\npaddle版本：1.8.1.post107\r\npython版本: python2.7\r\n\r\n模型代码：\r\ntextcnn代码结构参数：\r\n![image](https://user-images.githubusercontent.com/7113823/103125593-8bed8480-46c6-11eb-80c5-7ccb57446e64.png)\r\n训练代码：\r\n![image](https://user-images.githubusercontent.com/7113823/103125565-74ae9700-46c6-11eb-9078-adfe2fcb81d4.png)\r\n\r\n出错信息：\r\n![image](https://user-images.githubusercontent.com/7113823/103125644-a9bae980-46c6-11eb-9687-d826123ed5a1.png)\r\n\r\n分析：\r\n出错信息中 X's shape是[17964, 512]， 这个应该是embedding层的参数大小，但另一个1409024不知道具体是什么。\r\n为此我查看了出错信息中的代码文件，发现调用paddle/fluid/dygraph/parallel.py中的apply_collective_grads时，遍历模型的参数，当遍历到embeding层时，param的形状为[17964, 512]，到该参数的g_var时，其形状为[2752,512]，恰好就是1409024。\r\n不太明白这其中到底哪里有问题。\r\n\r\n![image](https://user-images.githubusercontent.com/7113823/103125787-32398a00-46c7-11eb-9331-3c4266886b26.png)\r\n\r\n当去除多卡相关的代码时，该模型和训练代码是能正常单卡训练的。",
        "state": "closed",
        "user": "HawChang",
        "closed_by": "HawChang",
        "created_at": "2020-12-25T07:42:30+00:00",
        "updated_at": "2020-12-28T03:18:47+00:00",
        "closed_at": "2020-12-28T03:18:47+00:00",
        "comments_count": [
            "wangchaochaohu",
            "HawChang",
            "HawChang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5148,
        "title": "视频分类模型STNET训练问题",
        "body": "用自己的数据训练STNET模型，视频数据是两分类问题，报错信息如下：\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 262, in <module>\r\n    train(args)\r\n  File \"train.py\", line 247, in train\r\n    profiler_path=args.profiler_path)\r\n  File \"/home/aistudio/work/models/PaddleCV/video/utils/train_utils.py\", line 135, in train_with_dataloader\r\n    str_time, epoch, train_iter, time_info_str))\r\n  File \"/home/aistudio/work/models/PaddleCV/video/metrics/metrics_util.py\", line 141, in calculate_and_log_out\r\n    acc1, acc5 = self.calculator.calculate_metrics(loss, pred, label)\r\n  File \"/home/aistudio/work/models/PaddleCV/video/metrics/kinetics/accuracy_metrics.py\", line 54, in calculate_metrics\r\n    accuracy5 = compute_topk_accuracy(softmax, labels, top_k=5) * 100.\r\n  File \"/home/aistudio/work/models/PaddleCV/video/metrics/kinetics/accuracy_metrics.py\", line 101, in compute_topk_accuracy\r\n    aggr_top_k_correct_hits = compute_topk_correct_hits(top_k, softmax, labels)\r\n  File \"/home/aistudio/work/models/PaddleCV/video/metrics/kinetics/accuracy_metrics.py\", line 84, in compute_topk_correct_hits\r\n    top_k_preds[i, :] = np.argsort(-preds[i, :])[:top_k]\r\nValueError: could not broadcast input array from shape (2) into shape (5)",
        "state": "closed",
        "user": "pele228",
        "closed_by": "pele228",
        "created_at": "2020-12-28T02:02:47+00:00",
        "updated_at": "2020-12-28T04:05:38+00:00",
        "closed_at": "2020-12-28T04:05:38+00:00",
        "comments_count": [
            "pele228",
            "pele228"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 121,
        "title": "使用文本分类任务时自己的准备的样本在加载时被替换成官方样本(train.tsv, dev.tsv, dev.tev)怎么破,求指导",
        "body": "项目链接:https://github.com/PaddlePaddle/models/tree/4d87afd6480737b64b5974c9c40a5b1c5a4600b3/PaddleNLP/examples/text_classification/rnn\r\n\r\n加载的时候是从train.py的这里进去的(但是里面调的类有点复杂,就不知道怎么改了)\r\n    train_ds, dev_ds, test_ds = ChnSentiCorp.get_datasets(\r\n        ['train', 'dev', 'test'])\r\n\r\n![11](https://user-images.githubusercontent.com/65219051/103256610-d7ef4080-49c8-11eb-8a4f-a30256b4ef0f.png)\r\n",
        "state": "closed",
        "user": "yizhipipixia",
        "closed_by": "github-actions[bot]",
        "created_at": "2020-12-29T03:29:54+00:00",
        "updated_at": "2023-03-15T00:17:30+00:00",
        "closed_at": "2023-03-15T00:17:30+00:00",
        "comments_count": [
            "Steffy-zxf",
            "yizhipipixia",
            "yizhipipixia",
            "Steffy-zxf",
            "chenxiaozeng",
            "chenxiaozeng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5165,
        "title": "由于自定义数据集较大,引起报错,怎样修改代码?",
        "body": "项目链接:https://github.com/PaddlePaddle/models/tree/4d87afd6480737b64b5974c9c40a5b1c5a4600b3/PaddleNLP/examples/text_classification/rnn\r\n\r\n将C:\\Users\\Administrator.paddlenlp\\datasets\\chnsenticorp目录下的train.tsv 与dev.tsv和test.tsv替换成了自己的训练集,然后进行训练,发现当训练集总样本个数在3万左右时不会报错,可以进行训练得到模型,但超过了就会发生下面的错误,请问改怎样修改代码呢,摆脱大佬详细些哈 我这边东拼西凑32万个样本的数据集不容易啊!求助,求助!\r\n报错代码如下\r\n`step 30/47 - loss: 0.3494 - acc: 0.9693 - 290ms/step\r\n\r\nstep 40/47 - loss: 0.3437 - acc: 0.9691 - 301ms/step\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"train.py\", line 193, in <module>\r\n    save_dir=args.save_dir)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 1503, in fit\r\n    eval_logs = self._run_one_epoch(eval_loader, cbks, 'eval')\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 1799, in _run_one_epoch\r\n    data[len(self._inputs):])\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 991, in eval_batch\r\n    loss = self._adapter.eval_batch(inputs, labels)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 681, in eval_batch\r\n    outputs = self.model.network.forward(* [to_variable(x) for x in inputs])\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddlenlp\\models\\senta.py\", line 104, in forward\r\n    logits = self.model(text, seq_len)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 884, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddlenlp\\models\\senta.py\", line 186, in forward\r\n    embedded_text = self.embedder(text)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 884, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\nn\\layer\\common.py\", line 1289, in forward\r\n    name=self._name)\r\n\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\nn\\functional\\input.py\", line 202, in embedding\r\n    'remote_prefetch', False, 'padding_idx', padding_idx)\r\n\r\nValueError: (InvalidArgument) Variable value (input) of OP(fluid.layers.embedding) expected >= 0 and < 857580, but got 858325. Please check input value.\r\n\r\n  [Hint: Expected ids[i] < row_number, but received ids[i]:858325 >= row_number:857580.] (at D:\\2.0.0rc1\\paddle\\paddle/fluid/operators/lookup_table_v2_op.h:81)\r\n\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n\r\n  [operator < lookup_table_v2 > error]\r\n`",
        "state": "open",
        "user": "yizhipipixia",
        "closed_by": null,
        "created_at": "2020-12-30T16:53:28+00:00",
        "updated_at": "2024-02-26T05:09:33+00:00",
        "closed_at": null,
        "comments_count": [
            "GaoWei8",
            "yizhipipixia",
            "Steffy-zxf",
            "lightCraft2020",
            "Maydaytyh",
            "yanliangyy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 120,
        "title": "lac 模型fine-tune",
        "body": "一、现状\r\n目前使用lac模型提取文本中ORG信息作为公司或机构的名称返回给上层应用。\r\n对于一般的机构信息，模型可以正常识别，但是我们的文本中存在很多非标准的公司/机构数据，例如：“包店镇手机大卖场”、“李梅种子专营店”等，lac就很难正常识别。\r\n目前我们想到的办法是整理了大概10w条类似的数据：小勇手机专营店 /ORG 百姓大药房/ORG ....... 准备利用lac进行fine-tune\r\n二、问题\r\n\r\n目前按照这个思路操作的过程中，lac训练出来的模型最终将很多非ORG的数据识别成了ORG，准确率反而降低了很多。我们也观查到一个现象就是：一个句子的开头几个词很容易被识别为ORG，我们猜想这可能是训练样本中只含有ORG导致模型认为开头的词由很大概率是ORG，所以导致了误判（问题1：这个猜想是否合理/正确）。\r\n\r\n目前在思考一个解决思路（问题2）：是否需要在训练集中混入一些其他非ORG样本，或者以整个句子标注的形式作为样本 ，而不是只提供ORG形式的单词。\r\n\r\n\r\n",
        "state": "closed",
        "user": "stopit",
        "closed_by": "github-actions[bot]",
        "created_at": "2020-12-30T11:08:47+00:00",
        "updated_at": "2023-03-15T00:17:25+00:00",
        "closed_at": "2023-03-15T00:17:25+00:00",
        "comments_count": [
            "kinghuin",
            "stopit",
            "kinghuin",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 122,
        "title": "使用自己制作的tsv数据集进行文本分类,训练的过程中得到如下报错,怎么破,",
        "body": "项目链接:https://github.com/PaddlePaddle/models/tree/4d87afd6480737b64b5974c9c40a5b1c5a4600b3/PaddleNLP/examples/text_classification/rnn\r\n\r\n训练命令:python train.py  --use_gpu=False --network=bilstm --lr=5e-4 --batch_size=64 --epochs=5 --save_dir='./checkpoints'\r\n\r\n将C:\\Users\\Administrator\\.paddlenlp\\datasets\\chnsenticorp目录下的train.tsv 与dev.tsv和test.tsv进行了替换,然后进行训练\r\n训练了3步,然后就报错了,报错信息如下\r\nstep   10/4050 - loss: 0.6850 - acc: 0.5156 - 3s/step\r\nstep   20/4050 - loss: 0.6437 - acc: 0.5062 - 3s/step\r\nstep   30/4050 - loss: 0.5077 - acc: 0.5786 - 4s/step\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 193, in <module>\r\n    save_dir=args.save_dir)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 1492, in fit\r\n    logs = self._run_one_epoch(train_loader, cbks, 'train')\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 1799, in _run_one_epoch\r\n    data[len(self._inputs):])\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 940, in train_batch\r\n    loss = self._adapter.train_batch(inputs, labels)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\hapi\\model.py\", line 654, in train_batch\r\n    * [to_variable(x) for x in inputs])\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddlenlp\\models\\senta.py\", line 104, in forward\r\n    logits = self.model(text, seq_len)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 884, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddlenlp\\models\\senta.py\", line 186, in forward\r\n    embedded_text = self.embedder(text)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 884, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\nn\\layer\\common.py\", line 1289, in forward\r\n    name=self._name)\r\n  File \"F:\\aanaa\\lib\\site-packages\\paddle\\nn\\functional\\input.py\", line 202, in embedding\r\n    'remote_prefetch', False, 'padding_idx', padding_idx)\r\nValueError: (InvalidArgument) Variable value (input) of OP(fluid.layers.embedding) expected >= 0 and < 857580, but got 858057. Please check input value.\r\n  [Hint: Expected ids[i] < row_number, but received ids[i]:858057 >= row_number:857580.] (at D:\\2.0.0rc1\\paddle\\paddle/fluid/operators/lookup_table_v2_op.h:81)\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n  [operator < lookup_table_v2 > error]\r\n\r\n\r\n",
        "state": "closed",
        "user": "yizhipipixia",
        "closed_by": "github-actions[bot]",
        "created_at": "2020-12-30T02:55:14+00:00",
        "updated_at": "2023-03-15T00:17:27+00:00",
        "closed_at": "2023-03-15T00:17:27+00:00",
        "comments_count": [
            "Steffy-zxf",
            "yizhipipixia",
            "yizhipipixia",
            "Steffy-zxf",
            "doubleyuhang",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5167,
        "title": "DeepASR有python3版本的吗？",
        "body": "",
        "state": "closed",
        "user": "yuemengrui",
        "closed_by": "yuemengrui",
        "created_at": "2020-12-31T07:14:23+00:00",
        "updated_at": "2021-01-04T01:43:44+00:00",
        "closed_at": "2021-01-04T01:43:44+00:00",
        "comments_count": [
            "GaoWei8"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5174,
        "title": "编译自定义OP不成功",
        "body": "作者你好。在AIStuidio终端下运行链接中的项目，执行sh make.sh报错误，提示g++ error。\r\n![image](https://user-images.githubusercontent.com/62875177/103614694-3043b680-4f64-11eb-9f47-22ce96f0e531.png)\r\n![image](https://user-images.githubusercontent.com/62875177/103614796-62edaf00-4f64-11eb-917c-d645e5fc2cb0.png)\r\n(https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleCV/3d_vision/PointRCNN)",
        "state": "open",
        "user": "XiaXingLuo",
        "closed_by": null,
        "created_at": "2021-01-05T02:21:21+00:00",
        "updated_at": "2021-01-06T04:43:48+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5171,
        "title": "Attention LSTM/Attention Cluster  数据初始化问题",
        "body": "如果不使用youtobe8m 数据，只使用Kinetics类似的MP4格式的数据集，如何做训练数据的pkl包转换？ 可否给出类似Kinetics的pkl包(video-id,[frame1, frame2,...,frameN],label)的具体说明",
        "state": "closed",
        "user": "pele228",
        "closed_by": "pele228",
        "created_at": "2021-01-04T01:12:04+00:00",
        "updated_at": "2021-01-08T02:03:19+00:00",
        "closed_at": "2021-01-08T02:03:19+00:00",
        "comments_count": [
            "liym27",
            "pele228",
            "pele228",
            "chajchaj",
            "pele228"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5172,
        "title": "不太理解models/dygraph/transformer/model.py中position_encoding_init函数的逻辑",
        "body": "该函数是位置编码函数\r\n以位置长度为4，emb大小为6为例：\r\n原论文的位置编码应该是：\r\n![image](https://user-images.githubusercontent.com/7113823/103507715-c1e6f180-4e9a-11eb-8380-ca8a30e2420c.png)\r\n值为：\r\n![image](https://user-images.githubusercontent.com/7113823/103507886-12f6e580-4e9b-11eb-864b-8e7fddf888ba.png)\r\n\r\n但models/dygraph/transformer/model.py中的position_encoding_init函数\r\n输入n_position=4, d_pos_vec=6时，输入如下：\r\n![image](https://user-images.githubusercontent.com/7113823/103507932-3457d180-4e9b-11eb-837a-848c4a4bbd35.png)\r\n\r\n不知道为什么会有这种差别，且我看其中逻辑也不并是原transformer的位置编码逻辑，麻烦解读一下。",
        "state": "open",
        "user": "HawChang",
        "closed_by": null,
        "created_at": "2021-01-04T06:44:17+00:00",
        "updated_at": "2021-01-05T05:00:28+00:00",
        "closed_at": null,
        "comments_count": [
            "liym27",
            "FrostML",
            "HawChang",
            "FrostML"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 119,
        "title": "sh run_ernie.sh train 无法完成",
        "body": "换了自己只有几条数据的train.tsv，就卡着不动了，过了2小时了\r\n![image](https://user-images.githubusercontent.com/9248572/103479622-ee066200-4e09-11eb-96fd-6388a5f55283.png)\r\n",
        "state": "closed",
        "user": "Vvegetables",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-01-03T13:26:39+00:00",
        "updated_at": "2023-03-13T00:18:39+00:00",
        "closed_at": "2023-03-13T00:18:39+00:00",
        "comments_count": [
            "jiweibo",
            "ZeyuChen",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5176,
        "title": "metric_learning finetune部分训练，耗时过长",
        "body": "![image](https://user-images.githubusercontent.com/17264083/103637831-06e85200-4f87-11eb-873f-331c9f2cf1a5.png)\r\n",
        "state": "open",
        "user": "Intsigstephon",
        "closed_by": null,
        "created_at": "2021-01-05T10:51:41+00:00",
        "updated_at": "2024-02-26T05:09:30+00:00",
        "closed_at": null,
        "comments_count": [
            "Intsigstephon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5177,
        "title": "How to add flow attention cluster for the attention cluster model?",
        "body": "Hi, I am using the attention cluster model for video classification. The original paper shows that the model uses the rgb attention, the flow attention, and the audio attention. However, there are only the rgb attention and the audio attention in the code.\r\n\r\nCan anyone tell me how to add the flow attention cluster for the model? Many thanks.",
        "state": "open",
        "user": "p1n0cch10",
        "closed_by": null,
        "created_at": "2021-01-06T09:19:08+00:00",
        "updated_at": "2024-02-26T05:09:29+00:00",
        "closed_at": null,
        "comments_count": [
            "chajchaj",
            "chajchaj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5179,
        "title": "paddleclas初体验错误，求帮忙看看是哪里没有设置对?",
        "body": "参考的官方链接：https://github.com/PaddlePaddle/PaddleClas/blob/dygraph/docs/zh_CN/tutorials/quick_start.md\r\n使用3.1 零基础训练：不加载预训练模型的训练\r\n基于ResNet50_vd模型，训练脚本如下所示。\r\n\r\nexport CUDA_VISIBLE_DEVICES=0\r\npython -m paddle.distributed.launch \\\r\n    --gpus=\"0\" \\\r\n    tools/train.py \\\r\n        -c ./configs/quick_start/ResNet50_vd.yaml\r\n\r\n然后报出的错误如下\r\n\r\n`2021-01-07 01:55:54 INFO: valid_interval : 1\r\n2021-01-07 01:55:54 INFO: validate : True\r\nW0107 01:55:54.222257 19002 device_context.cc:320] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0107 01:55:54.225203 19002 device_context.cc:330] device: 0, cuDNN Version: 7.6.\r\n2021-01-07 01:55:56 ERROR: DataLoader reader thread raised an exception!\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 118, in <module>\r\n    main(args)\r\n  File \"tools/train.py\", line 90, in main\r\n    epoch_id, 'train')\r\n  File \"/home/ppx/Clas/PaddleClas/tools/program.py\", line 300, in run\r\n    for idx, batch in enumerate(dataloader()):\r\n  File \"/home/ppx/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 771, in __next__\r\n    data = self._reader.read_next_var_list()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154)\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n\r\nINFO 2021-01-07 01:56:02,351 launch_utils.py:308] terminate all the procs\r\nERROR 2021-01-07 01:56:02,352 launch_utils.py:546] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2021-01-07 01:56:05,355 launch_utils.py:308] terminate all the procs\r\n`\r\n总的运行记录如下\r\n[报错.txt](https://github.com/PaddlePaddle/models/files/5777391/default.txt)\r\n\r\n",
        "state": "closed",
        "user": "yizhipipixia",
        "closed_by": "juncaipeng",
        "created_at": "2021-01-06T18:00:16+00:00",
        "updated_at": "2021-01-07T12:43:47+00:00",
        "closed_at": "2021-01-07T12:43:47+00:00",
        "comments_count": [
            "littletomatodonkey",
            "yizhipipixia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 218,
        "title": "models-release-1.7/PaddleNLP/emotion_detection模型",
        "body": "将开源ernie模型进行sh run_ernie train微调，源码报错，这个修改了ernie函数中的fluid.data，改成fluid.layers.data就能成功进行train。可在进行sh run_ernie.sh infer时，出现如下错误，这个是哪里有问题呢\r\n\r\nTraceback (most recent call last):\r\n  File \"run_ernie_classifier.py\", line 402, in <module>\r\n    main(args)\r\n  File \"run_ernie_classifier.py\", line 303, in main\r\n    main_program=test_prog)\r\n  File \"/data/yuting/models-release-1.7/PaddleNLP/emotion_detection/utils.py\", line 37, in init_checkpoint\r\n    fluid.load(main_program, init_checkpoint_path, exe)\r\n  File \"/home/ant/.conda/envs/text_analysis/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1779, in load\r\n    optimizer_var_list, global_scope(), executor._default_executor)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::Tensor::mutable_data(paddle::platform::Place const&, paddle::framework::proto::VarType_Type, unsign\r\ned long)\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: When calling this method, the Tensor's numel must be equal or larger than zero. Please check Tensor::dims, or Tenso\r\nr::Resize has been called first. The Tensor's shape is [-1, 768] now  [Hint: Expected numel() >= 0, but received numel():-768 < 0:0.] at (/paddle/paddle/fluid/framework/tensor.cc:45)\r\n\r\n",
        "state": "closed",
        "user": "xiaosheng123XIAO",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-01-07T09:13:46+00:00",
        "updated_at": "2023-03-13T00:18:36+00:00",
        "closed_at": "2023-03-13T00:18:36+00:00",
        "comments_count": [
            "juncaipeng",
            "xiaosheng123XIAO",
            "xiaosheng123XIAO",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5197,
        "title": "关于paddle安装中的TensorRT问题",
        "body": "我是ubuntu18.04系统，显卡是1660ti，安装了CUDA10.0+cudnn7，安装的TensorRT是6.0.1.5，paddle版本是1.8.5\r\n但我安装完之后提示：（可是我已经安装了TensorRT，库目录也加到路径中去了）\r\nSuggestions:\r\n  1. Check if TensorRT is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure TensorRT dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX;>>> fluid.install_check.run_check()\r\n",
        "state": "open",
        "user": "ccbptm",
        "closed_by": null,
        "created_at": "2021-01-13T02:48:36+00:00",
        "updated_at": "2024-02-26T05:09:26+00:00",
        "closed_at": null,
        "comments_count": [
            "yaoxuefeng6"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 5208
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5189,
        "title": "PaddleCV image_classification训练过程中存在显存消耗递增的问题，最终显存溢出",
        "body": "使用GTX1080训练，用的GoogLeNet网络，开始训练过程中，显存消耗在5000M以内，训练10个epoch以后，显存开始增加，再训练10几轮后，显卡再次增加，最终导致显存不够，程序异常",
        "state": "open",
        "user": "HongChen123",
        "closed_by": null,
        "created_at": "2021-01-08T09:24:32+00:00",
        "updated_at": "2024-02-26T05:09:27+00:00",
        "closed_at": null,
        "comments_count": [
            "zhangting2020",
            "HongChen123",
            "zhangting2020"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5184,
        "title": "使用paddleclas进行模型预测得到的输出怎样理解？",
        "body": "参考的官方链接：https://github.com/PaddlePaddle/PaddleClas/blob/dygraph/docs/zh_CN/tutorials/getting_started.md\r\n\r\n自己制作的只有两个分类（0和1两个标签）的图形数据集进行训练得到的关于ResNet50_vd的预训练模型，然后根据手册调用模型进行预测，但是不怎么能理解输出结果top1,top2，top3，以及使用inference模型得到的top-1 class，top-1 score等等的含义，即我应该主要参考输出的什么参数，来判断输入的图片属于什么类型呢？希望能够得到解答。\r\n\r\n**1.自己数据集的标签结构（只有0，1两个类别）：**\r\n`photos/2kNifOOKx6HcVtfoskeZDQ.jpg 0\r\nphotos/2kOFbSSqFi_vSqWFB1Ukqw.jpg 1`\r\n\r\n**2.使用自己训练出的预训练模型进行模型预测**\r\n\r\n`python tools/infer/infer.py \\\r\n    --image_file ./dataset/yelp/photos/37Wz9h1CqMCPgudoWCmm3g.jpg\\\r\n    --model ResNet50_vd \\\r\n    --pretrained_model \"./output/ResNet50_vd/best_model/ppcls\" \\\r\n    --use_gpu True \\\r\n    --load_static_weights False`\r\n\r\n    **输出：**\r\n`/home/ppx/anaconda3/envs/paddle/lib/python3.7/site-packages/socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Callable\r\nW0108 02:58:56.253964  4775 device_context.cc:320] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0108 02:58:56.257138  4775 device_context.cc:330] device: 0, cuDNN Version: 7.6.\r\n/home/ppx/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1245: UserWarning: Skip loading for out.weight. out.weight receives a shape [2048, 102], but the expected shape is [2048, 1000].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n\r\n/home/ppx/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1245: UserWarning: Skip loading for out.bias. out.bias receives a shape [102], but the expected shape is [1000].\r\n\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n\r\nCurrent image file: ./dataset/yelp/photos/37Wz9h1CqMCPgudoWCmm3g.jpg\r\n\r\n        top1, class id: 196, probability: 0.0012\r\n        top2, class id: 96, probability: 0.0012\r\n        top3, class id: 772, probability: 0.0012\r\n        top4, class id: 504, probability: 0.0012\r\n        top5, class id: 467, probability: 0.0012\r\n`\r\n\r\n**3.使用预训练模型转换的inference模型进行模型推理：**\r\n\r\n`python tools/infer/predict.py \\\r\n    --image_file ./dataset/tu/_1AVl8QmfnDx1pmTxkFh7A.jpg \\\r\n    --model_file \"./inference/inference.pdmodel\" \\\r\n    --params_file \"./inference/inference.pdiparams\" \\\r\n    --use_gpu=True \\\r\n    --use_tensorrt=False`\r\n\r\n     **输出：**\r\n\r\n`/home/ppx/anaconda3/envs/paddle/lib/python3.7/site-packages/socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Callable\r\n\r\nCurrent image file: ./dataset/tu/_1AVl8QmfnDx1pmTxkFh7A.jpg\r\n\r\n        top-1 class: 409\r\n\r\n        top-1 score: 0.0014189358334988356\r\n`",
        "state": "closed",
        "user": "yizhipipixia",
        "closed_by": "zhangting2020",
        "created_at": "2021-01-07T19:12:22+00:00",
        "updated_at": "2021-01-11T07:50:35+00:00",
        "closed_at": "2021-01-11T07:50:35+00:00",
        "comments_count": [
            "littletomatodonkey",
            "littletomatodonkey",
            "yizhipipixia",
            "zhangting2020",
            "yizhipipixia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5204,
        "title": "DeepSpeech报错",
        "body": "在提供的容器内进行普通话的训练、预估、评价。\r\n进行推断sh run_infer_golden.sh时报错，应该是paddle.fluid问题。\r\n  File \"/DeepSpeech/model_utils/network.py\", line 62, in <module>\r\n    class RNNCell(fluid.layers.RNNCell):\r\nAttributeError: 'module' object has no attribute 'RNNCell'",
        "state": "closed",
        "user": "DemonWang555",
        "closed_by": "ZeyuChen",
        "created_at": "2021-01-15T01:36:02+00:00",
        "updated_at": "2021-03-11T14:01:28+00:00",
        "closed_at": "2021-03-11T14:01:28+00:00",
        "comments_count": [
            "iclementine",
            "ZeyuChen",
            "ZeyuChen"
        ],
        "labels": [
            "speech"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 118,
        "title": "怎么把自己的数据集换成paddleNLP内置的数据集格式",
        "body": "~\r\n原项目在这https://aistudio.baidu.com/aistudio/projectdetail/1294333?channelType=0&channel=0\r\n\r\n问题：我自己的数据集应该是什么格式的？\r\n\r\n例子中的数据集是PaddleNLP内置该数据集：\r\n\r\ntrain_ds, dev_ds, test_ds = ppnlp.datasets.ChnSentiCorp.get_datasets(['train', 'dev', 'test'])\r\n\r\ntrain_ds是'ChnSentiCorp' object\r\n长下面这样\r\n\r\n \r\n![image](https://user-images.githubusercontent.com/62973945/104553024-e26e3300-5674-11eb-88d4-82888f4534e7.png)\r\n\r\n\r\n\r\ntrain_ds需要apply\r\n\r\ntrain_ds.apply(trans_func, lazy=True)\r\n\r\n\r\n其中trans_func需要train_ds是list\r\nApply貌似只能用dataframe，因为我试过list、set都报错没有apply属性\r\n\r\n自定义数据集是（）包起来的，不能apply，内置数据集是【】包起来的。\r\n![image](https://user-images.githubusercontent.com/62973945/104558415-b99e6b80-567d-11eb-871f-818353eeac19.png)\r\n",
        "state": "closed",
        "user": "millywang516",
        "closed_by": "ZeyuChen",
        "created_at": "2021-01-14T06:29:40+00:00",
        "updated_at": "2021-05-23T10:01:32+00:00",
        "closed_at": "2021-05-23T10:01:31+00:00",
        "comments_count": [
            "baiyfbupt",
            "millywang516",
            "Steffy-zxf",
            "chenxiaozeng",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5207,
        "title": "variational_seq2seq inference error",
        "body": "in models/PaddleNLP/legacy/seq2seq/variational_seq2seq/\r\nrun sh infer.sh ptb\r\nit shows:\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Dims of all Inputs(X) must be the same, but received input 1 dim is:320096, 1 not equal to input 0 dim:32, 1.\r\n  [Hint: Expected input_dims[i] == input_dims[0], but received input_dims[i]:320096, 1 != input_dims[0]:32, 1.] at (/paddle/paddle/fluid/operators/stack_op.cc:46)\r\n  [operator < stack > error]\r\nin model.py             \r\noutputs, _ = dynamic_decode(\r\n                beam_search_decoder,\r\n                inits=dec_initial_states,\r\n                max_step_num=max_length)",
        "state": "closed",
        "user": "nickyoungforu",
        "closed_by": "nickyoungforu",
        "created_at": "2021-01-15T09:39:50+00:00",
        "updated_at": "2021-01-25T06:52:15+00:00",
        "closed_at": "2021-01-25T06:52:15+00:00",
        "comments_count": [
            "iclementine",
            "nickyoungforu",
            "iclementine",
            "nickyoungforu",
            "iclementine",
            "ZeyuChen",
            "LiuChiachi",
            "LiuChiachi",
            "nickyoungforu"
        ],
        "labels": [
            "paddlenlp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5210,
        "title": "PaddleOCR 2.0.2 is slower than 1.1 using CUDA11.2",
        "body": "I finally managed to get the latest version running without segfaults by doing the following:\r\n\r\n2) Update to cuda11.2 https://developer.nvidia.com/cuda-downloads\r\n3) sudo docker run --name ppocr --gpus all -v $PWD:/paddle --shm-size=32G --network=host -it paddlepaddle/paddle:2.0.0rc1-gpu-cuda11.0-cudnn8 /bin/bash\r\n4) python3.8 -m pip install paddleocr  (no need to install paddlepaddle-gpu because the docker already has it)\r\n\r\nHowever, inference speed is about 3x slower than using paddleocr==1.1 + paddlepaddle-gpu 1.8.5.post107\r\n+ CUDA10 (though this model is more accurate). Any ideas how I could speed it up?\r\n\r\nAlso, how could I install outside of docker? It seems that the version of paddlepaddle-gpu installed in paddle:2.0.0rc1-gpu-cuda11.0-cudnn8 docker is not available on pypi - I've lost the output now but it was a version with post110 at the end, I think.\r\n\r\n",
        "state": "open",
        "user": "indrasweb",
        "closed_by": null,
        "created_at": "2021-01-17T23:30:15+00:00",
        "updated_at": "2024-02-26T05:09:25+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "LDOUBLEV"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5219,
        "title": "单目标跟踪模型动态图转静态图失败",
        "body": "背景：\r\n\r\n  想导出https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleCV/tracking 这里面的atom_resnet18模型，用来部署推理验证，发现是只有动态图模型，所以想转成静态图。\r\n\r\n代码：\r\n\r\n  \r\n![1261611152403_ pic_hd](https://user-images.githubusercontent.com/49897975/105187371-ad2e7d00-5b6d-11eb-982f-1dcaf05fe531.jpg)\r\n\r\n\r\n\r\n在最后一步，  paddle.jit.save(model, 'inference_models/AtomNet')的时候失败，报下面的问题(参考文件的error [log)](url\r\n[error.txt](https://github.com/PaddlePaddle/models/files/5843038/error.txt)\r\n)\r\n\r\n\r\n这个可能是什么问题，请帮忙看一下，谢谢！是和模型在1.8版本训练的有关吗？我现在使用2.0版本的转静态图。",
        "state": "closed",
        "user": "AnBaolei1984",
        "closed_by": "AnBaolei1984",
        "created_at": "2021-01-20T14:24:21+00:00",
        "updated_at": "2021-01-22T12:38:45+00:00",
        "closed_at": "2021-01-22T12:38:45+00:00",
        "comments_count": [
            "AnBaolei1984"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5222,
        "title": "运行3d_version里面的pointrcnn模型编译自定义的op出错。",
        "body": "直接在ai  stuidio下运行，paddle版本2.0.0-rc.post101,gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~16.04),按照pointrcnn模型的GitHub教程来，运行 sh make.sh,报以下错误，\r\n![image](https://user-images.githubusercontent.com/62875177/105472912-707e9500-5cd7-11eb-87a1-1a032b93da40.png),网上百度过觉得是gcc 和g++版本不一致的问题，终端查看g++是这样子的\r\n![image](https://user-images.githubusercontent.com/62875177/105473081-a4f25100-5cd7-11eb-9bda-7e5b158c5b2a.png)\r\n和单独查看gcc版本是不一样的，降级安装gcc没有sudo 权限，pip 和apt都试过了没有用。\r\n![image](https://user-images.githubusercontent.com/62875177/105473972-b25c0b00-5cd8-11eb-85e1-59f33297d18f.png)\r\n\r\n",
        "state": "open",
        "user": "XiaXingLuo",
        "closed_by": null,
        "created_at": "2021-01-22T09:39:04+00:00",
        "updated_at": "2024-02-26T05:09:24+00:00",
        "closed_at": null,
        "comments_count": [
            "XiaXingLuo",
            "qingqing01",
            "XiaXingLuo",
            "Milalaa",
            "qingqing01",
            "Milalaa",
            "XiaXingLuo",
            "XiaXingLuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFormers",
        "number": 1345,
        "title": "paddlehub中的视频模型使用预测框架create_paddle_predictor运行闪退",
        "body": "env:\r\nwindows7\r\npython3.7\r\npaddle 1.8.5\r\n\r\n使用paddlehub中的视频流标签模型videotag_tsn_lstm本身运行正常，由于想用cpu部署，使用create_paddle_predictor开启mkldnn部署运行直接闪退，没有任何提示和错误，必现\r\n\r\n使用create_paddle_predictor的闪退代码（该代码运行其他paddle模型正常）：\r\nclass PaddleOCRBackend():\r\n    def init(self, model_path, model_filename, params_filename):\r\n        config = AnalysisConfig(model_filename, params_filename)\r\n\r\n        config.disable_gpu()\r\n        # config.set_cpu_math_library_num_threads(6)\r\n\r\n        # config.set_mkldnn_cache_capacity(10)\r\n        config.enable_mkldnn()\r\n\r\n        # config.enable_memory_optim()\r\n        config.disable_glog_info()\r\n\r\n        config.delete_pass(\"conv_transpose_eltwiseadd_bn_fuse_pass\")\r\n        config.switch_use_feed_fetch_ops(False)\r\n\r\n        self.predictor = create_paddle_predictor(config)\r\n        input_names = self.predictor.get_input_names()\r\n        for name in input_names:\r\n            self.input_tensor = self.predictor.get_input_tensor(name)\r\n        output_names = self.predictor.get_output_names()\r\n        self.output_tensors = []\r\n        for output_name in output_names:\r\n            output_tensor = self.predictor.get_output_tensor(output_name)\r\n            self.output_tensors.append(output_tensor)\r\n\r\n    def run(self, output_name, input_data):\r\n        input_data = list(input_data.values())[0]\r\n        # norm_img_batch = fluid.core.PaddleTensor(input_data)\r\n        # outs = self.predictor.run([norm_img_batch])\r\n        self.input_tensor.copy_from_cpu(input_data)\r\n        self.predictor.zero_copy_run()\r\n        outputs = []\r\n        for output_tensor in self.output_tensors:\r\n            output = output_tensor.copy_to_cpu()\r\n            outputs.append(output)\r\n\r\n        return outputs\r\n\r\n使用fluid.Executor运行正常，代码如下\r\nclass PaddleBackend():\r\n    def init(self, model_path, model_filename, params_filename):\r\n        self.extractor_scope = fluid.Scope()\r\n        with fluid.scope_guard(self.extractor_scope):\r\n            extractor_startup_prog = fluid.Program()\r\n            extractor_main_prog = fluid.Program()\r\n            with fluid.program_guard(extractor_main_prog, extractor_startup_prog):\r\n                self.place = fluid.CUDAPlace(0) if fluid.is_compiled_with_cuda() else fluid.CPUPlace()\r\n                # self.place = fluid.CPUPlace()\r\n                self.exe=fluid.Executor(self.place)\r\n                # self.exe.run(fluid.default_startup_program())\r\n                self.infer_program, self.feeded_var_names, self.target_var = fluid.io.load_inference_model(model_path, self.exe, model_filename, params_filename)\r\n                # self.feeder = fluid.DataFeeder(place=self.place, feed_list=self.feeded_var_names)\r\n\r\n    def run(self, output_name, input_data):\r\n        # input_data = list(input_data.values())[0]\r\n        result = self.exe.run(program=self.infer_program,feed=input_data,fetch_list=self.target_var, scope=self.extractor_scope)\r\n        return result\r\n\r\n\r\n",
        "state": "closed",
        "user": "whut09",
        "closed_by": "WYB27",
        "created_at": "2021-01-21T02:34:54+00:00",
        "updated_at": "2025-06-30T07:20:23+00:00",
        "closed_at": "2025-06-30T07:20:23+00:00",
        "comments_count": [
            "ZeyuChen",
            "whut09"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5233,
        "title": "BMN 推断失败",
        "body": "E:\\PythonProject\\models\\PaddleCV\\video> python predict.py --model_name BMN --config configs/bmn.yaml --log_interval 1 --weights .\\models\\bmn\\BMN\r\nDALI is not installed, you can improve performance if use DALI\r\n[INFO: predict.py:  199]: Namespace(batch_size=1, config='configs/bmn.yaml', filelist=None, infer_topk=20, log_interval=1, model_name='BMN', save_dir='data\\\\predict_results', use_gpu=True, video_path=None, weights='.\\\\models\\\\bmn\\\\BMN')\r\n[INFO: config_utils.py:   69]: ---------------- Infer Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:BMN\r\n[INFO: config_utils.py:   74]:     tscale:100\r\n[INFO: config_utils.py:   74]:     dscale:100\r\n[INFO: config_utils.py:   74]:     feat_dim:400\r\n[INFO: config_utils.py:   74]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   74]:     num_sample:32\r\n[INFO: config_utils.py:   74]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   74]:     anno_file:data/dataset/bmn/activitynet_1.3_annotations.json\r\n[INFO: config_utils.py:   74]:     feat_path:data/dataset/bmn/fix_feat_100\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     subset:train\r\n[INFO: config_utils.py:   74]:     epoch:9\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   74]:     learning_rate:0.001\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   74]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   74]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:16\r\n[INFO: config_utils.py:   74]:     num_threads:8\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:4\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     subset:validation\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     output_path:data/output/EVAL/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/evaluate_results\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     subset:test\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     num_threads:1\r\n[INFO: config_utils.py:   74]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   74]:     snms_t1:0.5\r\n[INFO: config_utils.py:   74]:     snms_t2:0.9\r\n[INFO: config_utils.py:   74]:     filelist:data/dataset/bmn/infer.list\r\n[INFO: config_utils.py:   74]:     output_path:data/output/INFER/BMN_results\r\n[INFO: config_utils.py:   74]:     result_path:data/predict_results\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW0126 21:49:35.488451 13780 device_context.cc:320] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.3, Runtime API Version: 10.1\r\nW0126 21:49:35.509438 13780 device_context.cc:330] device: 0, cuDNN Version: 7.6.\r\ntest subset video numbers: 5\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 201, in <module>\r\n    infer(args)\r\n  File \"predict.py\", line 125, in infer\r\n    assert os.path.exists(\r\nAssertionError: Given weight dir .\\models\\bmn\\BMN not exist.\r\n\r\n运行命令中的 --weights 加不加后缀都试过了",
        "state": "closed",
        "user": "jishixin",
        "closed_by": "jishixin",
        "created_at": "2021-01-26T13:51:40+00:00",
        "updated_at": "2021-10-23T07:42:43+00:00",
        "closed_at": "2021-10-23T07:42:43+00:00",
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5235,
        "title": "paddle2.0和paddlenlp loss.backward()错误",
        "body": "环境\r\npaddlecloudplatform    3.0.7\r\npaddlehub              1.8.3\r\npaddlenlp              2.0.0b3\r\npaddlepaddle-gpu       2.0.0rc1\r\npaddleslim             1.1.0\r\n![image](https://user-images.githubusercontent.com/6512760/105965697-b57f3e80-60be-11eb-99ab-f605ce238fc7.png)\r\n\r\n错误\r\n【dev】step: 0 - loss: 3.521899 precision: 0.000, recall: 0.009, f1: 0.001 current best 0.000\r\n==============================================save best model best performerence 0.000848\r\nTraceback (most recent call last):\r\n  File \"sequence_labeling.py\", line 235, in <module>\r\n    loss.backward()\r\n  File \"<decorator-gen-113>\", line 2, in backward\r\n  File \"/home/work/mnt/project/.local/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/work/mnt/project/.local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 223, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/work/mnt/project/.local/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 176, in backward\r\n    self._run_backward(framework._dygraph_tracer(), retain_graph)\r\nValueError: \r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::imperative::BasicEngine::Execute()\r\n1   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVariableWrapperMap const&, paddle::imperative::NameVariableWrapperMap const&, paddle::framework::AttributeMap const&)\r\n2   paddle::operators::DropoutOpGrad::InferShape(paddle::framework::InferShapeContext*) const\r\n3   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n4   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: GradOp is only callable when is_test is false\r\n  [Hint: Expected ctx->Attrs().Get<bool>(\"is_test\") == false, but received ctx->Attrs().Get<bool>(\"is_test\"):1 != false:0.] (at /paddle/paddle/fluid/operators/dropout_op.cc:122)",
        "state": "closed",
        "user": "littlepan0413",
        "closed_by": "Steffy-zxf",
        "created_at": "2021-01-27T08:43:03+00:00",
        "updated_at": "2021-01-28T02:50:09+00:00",
        "closed_at": "2021-01-28T02:50:09+00:00",
        "comments_count": [
            "ZeyuChen",
            "Steffy-zxf"
        ],
        "labels": [
            "paddlenlp"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5240,
        "title": "tracking 评估报错",
        "body": "地址：https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/tracking#%E5%BC%80%E5%A7%8B%E6%B5%8B%E8%AF%95\r\n\r\n执行代码：\r\n`!python eval_benchmark.py -d VOT2018 -tr ATOMnet_ep0040_models -te atom.default_vot -e 40`\r\n\r\n后报错：\r\n```\r\n=> Evaluating: ATOMnet_ep0040_models.epoch40\r\nloading VOT2018: 100%|██████████████████████████████████| 60/60 [00:00<00:00, 65.12it/s, zebrafish1]\r\n2021-01-28 09:20:00,429-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\r\n2021-01-28 09:20:00,818-INFO: generated new fontManager\r\n  0%|                                                    | 0/60 [00:00<?, ?it/s]W0128 09:20:00.959059  1191 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 11.0, Runtime API Version: 9.0\r\nW0128 09:20:00.963425  1191 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n  0%|                                                    | 0/60 [00:03<?, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"eval_benchmark.py\", line 315, in <module>\r\n    main()\r\n  File \"eval_benchmark.py\", line 308, in main\r\n    metrics = run_tracking_and_evaluate(params)\r\n  File \"eval_benchmark.py\", line 254, in run_tracking_and_evaluate\r\n    run_one_dataset(dataset, params)\r\n  File \"eval_benchmark.py\", line 204, in run_one_dataset\r\n    run_one_sequence(video, params, tracker=tracker)\r\n  File \"eval_benchmark.py\", line 167, in run_one_sequence\r\n    pred_bboxes = run_tracker(tracker, video, reset=True)\r\n  File \"eval_benchmark.py\", line 113, in run_tracker\r\n    tracker.initialize(image, init_bbox)\r\n  File \"../pytracking/tracker/atom/atom.py\", line 149, in initialize\r\n    self.init_optimization(train_x, init_y)\r\n  File \"../pytracking/tracker/atom/atom.py\", line 669, in init_optimization\r\n    fig_num=(12, 13, 14))\r\n  File \"../pytracking/libs/optimization.py\", line 411, in __init__\r\n    self._construct_graph()\r\n  File \"../pytracking/libs/optimization.py\", line 431, in _construct_graph\r\n    self.f0 = self.problem(self.x_ph, scope)\r\n  File \"../pytracking/tracker/atom/optim.py\", line 99, in __call__\r\n    training_samples, P).apply(self.projection_activation)\r\n  File \"../pytracking/libs/tensorlist.py\", line 258, in oplist\r\n    [op(a, b, *args[2:], **kwargs) for a, b in zip(*args[:2])])\r\n  File \"../pytracking/libs/tensorlist.py\", line 258, in <listcomp>\r\n    [op(a, b, *args[2:], **kwargs) for a, b in zip(*args[:2])])\r\n  File \"../pytracking/libs/operation.py\", line 59, in conv1x1\r\n    return FConv2D(input, weight)\r\n  File \"../pytracking/libs/Fconv2d.py\", line 96, in FConv2D\r\n    num_channels = input.shape[channel_dim]\r\nIndexError: tuple index out of range\r\n```",
        "state": "open",
        "user": "iceriver97",
        "closed_by": null,
        "created_at": "2021-01-28T01:25:35+00:00",
        "updated_at": "2021-11-05T03:54:56+00:00",
        "closed_at": null,
        "comments_count": [
            "iceriver97",
            "zhwesky2010"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 117,
        "title": "恳请大佬大神们赐教：如何使用自己的数据集训练MRC？",
        "body": "本人小白，想用Dureader robust的MRC训练一套自己的中文数据集，但是我没有id，只有 问句和文本。\r\n请问我改如何更改源数据集呢？\r\n恳请大佬大神们赐教",
        "state": "closed",
        "user": "Minjuner-97",
        "closed_by": "smallv0221",
        "created_at": "2021-01-22T17:13:07+00:00",
        "updated_at": "2021-03-12T07:40:49+00:00",
        "closed_at": "2021-03-12T07:40:49+00:00",
        "comments_count": [
            "smallv0221",
            "Minjuner-97",
            "smallv0221",
            "Minjuner-97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5245,
        "title": "PaddleCV/metric_learning 开发分支和1.8分支 finetuning 代码无法运行",
        "body": "执行环境paddle 1.7\r\n\r\n拉取metric_learning开发分支，执行 finetuning 代码，报告没有引入对应python包错误。\r\n拉取1.8分支，fluid.load报告错误。\r\n拉取1.7分支可以执行\r\n",
        "state": "open",
        "user": "linghaolu",
        "closed_by": null,
        "created_at": "2021-01-28T06:26:01+00:00",
        "updated_at": "2021-01-29T09:38:19+00:00",
        "closed_at": null,
        "comments_count": [
            "zhwesky2010"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5248,
        "title": "I can't find the model aboutface recognition",
        "body": "",
        "state": "closed",
        "user": "zgsxwsdxg",
        "closed_by": "zgsxwsdxg",
        "created_at": "2021-01-28T09:00:59+00:00",
        "updated_at": "2021-02-01T01:14:38+00:00",
        "closed_at": "2021-02-01T01:14:38+00:00",
        "comments_count": [
            "zgsxwsdxg",
            "zhwesky2010",
            "zgsxwsdxg",
            "zhwesky2010",
            "zgsxwsdxg"
        ],
        "labels": [
            "FAQ"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5250,
        "title": "能举个例子说明video tag项目训练attention lstm多标签怎么标注吗？",
        "body": "项目中只是说了使用多标签微调lstm 没有说明具体该怎么给视频标注多标签 标注几个 这个对于新手也比较难，能举个例子说明一下嘛，给没有经验的小菜一个标注的方向，万分感谢！谢谢！",
        "state": "open",
        "user": "wangxinzhe0617",
        "closed_by": null,
        "created_at": "2021-01-29T08:12:37+00:00",
        "updated_at": "2024-02-26T05:09:19+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5252,
        "title": "paddlenlp如何指定GPU训练？",
        "body": "在运行paddlenlp的mrc任务的时候出现设置CUDA_VISIBLE_DEVICES = 1，训练的时候仍然使用 gpu = 0来训练，请问如何彻底解决这个问题？",
        "state": "closed",
        "user": "Minjuner-97",
        "closed_by": "ZeyuChen",
        "created_at": "2021-01-31T15:15:43+00:00",
        "updated_at": "2021-03-11T14:02:24+00:00",
        "closed_at": "2021-03-11T14:02:24+00:00",
        "comments_count": [
            "joey12300",
            "Minjuner-97",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5246,
        "title": "ssd模型在jetson NX上推理时间不合理",
        "body": "利用1.6版本提供的ssd模型，在jetson上安装paddle后进行推理测试\r\n```\r\n    place = fluid.CUDAPlace(0) if args.use_gpu else fluid.CPUPlace()\r\n    #place = fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    # yapf: disable\r\n    if model_dir:\r\n        def if_exist(var):\r\n            return os.path.exists(os.path.join(model_dir, var.name))\r\n        fluid.io.load_vars(exe, model_dir, predicate=if_exist)\r\n    # yapf: enable\r\n    infer_reader = reader.infer(data_args, image_path)\r\n    feeder = fluid.DataFeeder(place=place, feed_list=[image])\r\n\r\n    data = infer_reader()\r\n\r\n    # switch network to test mode (i.e. batch norm test mode)\r\n    test_program = fluid.default_main_program().clone(for_test=True)\r\n    detect_time = []\r\n    t0 = time()\r\n    nmsed_out_v, = exe.run(test_program,\r\n                           feed=feeder.feed([[data]]),\r\n                           fetch_list=[nmsed_out],\r\n                           return_numpy=False)\r\n    detect_time.append((time() - t0) * 1000)\r\n    print('detect_time is {} ms'.format(np.average(np.asarray(detect_time))))\r\n```\r\n分了利用gpu和cpu进行推理，获取推理时间\r\n在gpu上推理：\r\n```\r\nW0128 15:40:08.554250  5453 device_context.cc:320] Please NOTE: device: 0, CUDA Capability: 72, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW0128 15:40:08.558723  5453 device_context.cc:328] device: 0, cuDNN Version: 8.0.\r\ndetect_time is 1125.3809928894043 ms\r\n```\r\n在cpu上推理：\r\n```\r\ndetect_time is 419.86751556396484 ms\r\n```\r\n可以看到cpu推理时间比gpu还短，感觉有点不太合理",
        "state": "open",
        "user": "Huihuihh",
        "closed_by": null,
        "created_at": "2021-01-28T08:24:06+00:00",
        "updated_at": "2021-03-18T12:26:15+00:00",
        "closed_at": null,
        "comments_count": [
            "OliverLPH",
            "Huihuihh",
            "OliverLPH",
            "Huihuihh",
            "OliverLPH",
            "Huihuihh",
            "OliverLPH",
            "Huihuihh",
            "shangzhizhou",
            "Huihuihh",
            "Huihuihh",
            "shangzhizhou",
            "Huihuihh",
            "shangzhizhou",
            "shangzhizhou",
            "Huihuihh",
            "shangzhizhou",
            "Huihuihh",
            "Huihuihh",
            "Huihuihh",
            "Huihuihh",
            "shangzhizhou",
            "wangye707",
            "Huihuihh",
            "tianhechao",
            "Huihuihh",
            "tianhechao",
            "Huihuihh",
            "OliverLPH",
            "tianhechao",
            "wangye707"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5254,
        "title": "PaddleCV模型库下的3D检测里的M3D-RPN模型文档有问题",
        "body": "这个目录下的文档\r\n快速开始目录下的cd M3D-RPN后\r\n运行ln -s  /path/to/kitti dataset/kitti提示：\r\nln:failed to create symbolic link \"dataset/kitti\":没有这个目录\r\n\r\n另外：本模型是在1.8下开发的，什么时候能提供个2.0的版本呢\r\n",
        "state": "open",
        "user": "Sqhttwl",
        "closed_by": null,
        "created_at": "2021-02-01T03:26:28+00:00",
        "updated_at": "2024-02-26T05:09:17+00:00",
        "closed_at": null,
        "comments_count": [
            "qili93",
            "lijianshe02"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 217,
        "title": "NER教程中发现bug",
        "body": "hi,\r\nhttps://aistudio.baidu.com/aistudio/projectdetail/1317771\r\n在这个NER任务中，主模型代码\r\n`\r\nclass BiGRUWithCRF2(nn.Layer):\r\n    def __init__(self, emb_size, hidden_size, word_num, label_num):\r\n        super(BiGRUWithCRF2, self).__init__()\r\n        self.word_emb = TokenEmbedding(extended_vocab_path='./conf/word.dic', unknown_token='OOV') #EMB\r\n`\r\nTokenEmbedding的利用有误\r\n\r\n我查看了源码，extended_vocab_path的参数会作为读取字典，经过_read_vocab_list_from_file取出词表\r\n`   \r\ndef _read_vocab_list_from_file(self, extended_vocab_path):\r\n        # load new vocab table from file\r\n        vocab_list = []\r\n        with open(extended_vocab_path, \"r\", encoding=\"utf-8\") as f:\r\n            for line in f.readlines():\r\n                vocab = line.rstrip(\"\\n\").split(\"\\t\")[0]\r\n                vocab_list.append(vocab)\r\n        return vocab_list\r\n`\r\n该任务对应的字典word.dic ，第一列是索引id，不是vocab\r\n\r\n所以TokenEmbedding无法正确加载pretrain的权重",
        "state": "closed",
        "user": "cocoa0409",
        "closed_by": "ZeyuChen",
        "created_at": "2021-01-31T16:38:28+00:00",
        "updated_at": "2021-05-11T12:35:16+00:00",
        "closed_at": "2021-05-11T12:35:16+00:00",
        "comments_count": [
            "chenxiaozeng",
            "ZeyuChen"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5262,
        "title": "[问题咨询]PaddleCV/metric_learning/utility.py recall_topk_ori 实现",
        "body": "想咨询一下 PaddleCV/metric_learning/utility.py recall_topk_ori 实现是根据什么公式算的，有点没看明白。谢谢\r\n\r\n    def recall_topk_ori(fea, lab, k):\r\n        fea = np.array(fea)\r\n        fea = fea.reshape(fea.shape[0], -1)\r\n        n = np.sqrt(np.sum(fea**2, 1)).reshape(-1, 1)\r\n        fea = fea / n\r\n        a = np.sum(fea**2, 1).reshape(-1, 1)\r\n        b = a.T\r\n        ab = np.dot(fea, fea.T)\r\n        d = a + b - 2 * ab\r\n        d = d + np.eye(len(fea)) * 1e8\r\n        sorted_index = np.argsort(d, 1)\r\n        res = 0\r\n        for i in range(len(fea)):\r\n            for j in range(k):\r\n                pred = lab[sorted_index[i][j]]\r\n                if lab[i] == pred:\r\n                    res += 1.0\r\n                    break\r\n        res = res / len(fea)\r\n        return res\r\n",
        "state": "closed",
        "user": "linghaolu",
        "closed_by": "linghaolu",
        "created_at": "2021-02-02T09:47:13+00:00",
        "updated_at": "2021-02-03T11:35:48+00:00",
        "closed_at": "2021-02-03T11:35:39+00:00",
        "comments_count": [
            "linghaolu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5260,
        "title": "3d_vision PointNet++分类训练报错UnavailableError: There are no kernels which are registered in the fill_constant operator.",
        "body": "刚入门小白，遇到了问题恳请各位大神帮忙！谢谢\r\nAI Studio \r\nPaddlePaddle2.0.0\r\n3d_vision PointNet++分类训练报错UnavailableError: There are no kernels which are registered in the fill_constant operator.具体如下\r\naistudio@jupyter-622623-1481923:~/PointNet++$ python train_cls.py --model=MSG --batch_size=16 --save_dir=checkpoints_msg_cls\r\n2021-02-02 16:17:38,539-INFO: -----------  Configuration Arguments -----------\r\n2021-02-02 16:17:38,539-INFO: batch_size: 16\r\n2021-02-02 16:17:38,539-INFO: bn_momentum: 0.99\r\n2021-02-02 16:17:38,539-INFO: data_dir: dataset/ModelNet40/modelnet40_ply_hdf5_2048\r\n2021-02-02 16:17:38,539-INFO: decay_steps: 12500\r\n2021-02-02 16:17:38,540-INFO: enable_ce: False\r\n2021-02-02 16:17:38,540-INFO: epoch: 201\r\n2021-02-02 16:17:38,540-INFO: log_interval: 1\r\n2021-02-02 16:17:38,540-INFO: lr: 0.01\r\n2021-02-02 16:17:38,540-INFO: lr_decay: 0.7\r\n2021-02-02 16:17:38,540-INFO: model: MSG\r\n2021-02-02 16:17:38,540-INFO: num_classes: 40\r\n2021-02-02 16:17:38,540-INFO: num_points: 2048\r\n2021-02-02 16:17:38,540-INFO: resume: None\r\n2021-02-02 16:17:38,540-INFO: save_dir: checkpoints_msg_cls\r\n2021-02-02 16:17:38,540-INFO: use_gpu: True\r\n2021-02-02 16:17:38,540-INFO: weight_decay: 1e-05\r\n2021-02-02 16:17:38,540-INFO: ------------------------------------------------\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/PointNet++/models/pointnet2_modules.py:53\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\nW0202 16:17:39.180770  1631 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\r\nW0202 16:17:39.185834  1631 device_context.cc:372] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"train_cls.py\", line 308, in <module>\r\n    train()\r\n  File \"train_cls.py\", line 184, in train\r\n    exe.run(startup)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1328, in _run_program\r\n    [fetch_var_name])\r\nRuntimeError: In user code:\r\n\r\n    File \"train_cls.py\", line 308, in <module>\r\n      train()\r\n    File \"train_cls.py\", line 166, in train\r\n      optimizer.minimize(train_loss, parameter_list=params)\r\n    File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-104>\", line 2, in minimize\r\n      \r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 260, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 951, in minimize\r\n      loss, startup_program=startup_program, params_grads=params_grads)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 862, in apply_optimize\r\n      optimize_ops = self.apply_gradients(params_grads)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 836, in apply_gradients\r\n      optimize_ops = self._create_optimization_pass(params_grads)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 664, in _create_optimization_pass\r\n      [p[0] for p in parameters_and_grads if p[0].trainable])\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 2048, in _create_accumulators\r\n      type=core.VarDesc.VarType.LOD_TENSOR, device='cpu')\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py\", line 577, in _add_accumulator\r\n      var, initializer=Constant(value=float(fill_value)))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper_base.py\", line 448, in set_variable_initializer\r\n      initializer=initializer)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2851, in create_var\r\n      kwargs['initializer'](var, self)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/initializer.py\", line 165, in __call__\r\n      stop_gradient=True)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3104, in _prepend_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2102, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    UnavailableError: There are no kernels which are registered in the fill_constant operator.\r\n      [Hint: Expected kernels_iter != all_op_kernels.end(), but received kernels_iter == all_op_kernels.end().] (at /paddle/paddle/fluid/framework/operator.cc:1179)\r\n      [operator < fill_constant > error]\r\naistudio@jupyter-622623-1481923:~/PointNet++$ ",
        "state": "open",
        "user": "Milalaa",
        "closed_by": null,
        "created_at": "2021-02-02T08:26:33+00:00",
        "updated_at": "2024-02-26T05:09:16+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "milala1235",
            "gg22mm",
            "gg22mm",
            "JackonLiu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5264,
        "title": "KeyError: b'nframes'",
        "body": "https://github.com/PaddlePaddle/models/blob/release/2.0-beta/PaddleCV/video/models/nextvlad/README.md\r\n按照官网的教程，在cpu上进行nextvlad的模型评估的时候，\r\n出现：    \r\nnframes = record[b'nframes']\r\nKeyError: b'nframes'",
        "state": "open",
        "user": "nasaweimao",
        "closed_by": null,
        "created_at": "2021-02-02T11:55:34+00:00",
        "updated_at": "2024-02-26T05:09:15+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5265,
        "title": "如何修改部分网络参数",
        "body": null,
        "state": "open",
        "user": "18810580125",
        "closed_by": null,
        "created_at": "2021-02-02T13:05:19+00:00",
        "updated_at": "2024-02-26T05:09:14+00:00",
        "closed_at": null,
        "comments_count": [
            "18810580125"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5267,
        "title": "paddle2.0不同层参数，不同学习率如何实现？",
        "body": "我看Optimizer基类有个learning_rate参数，貌似是全聚德，请问如果我用Optimizer对网络不同部分设置不同的学习率，应该如何实现呢？",
        "state": "open",
        "user": "cocoa0409",
        "closed_by": null,
        "created_at": "2021-02-03T07:52:23+00:00",
        "updated_at": "2024-02-26T05:09:12+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "cocoa0409",
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5269,
        "title": "video-tag特征提取模型tsm权重",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/application/video_tag\r\n请问video-tag的视频特征提取是否有tsm模型，有的话里可以提供一下tsm的预训练权重，学习一下，谢谢",
        "state": "open",
        "user": "xzhoubb",
        "closed_by": null,
        "created_at": "2021-02-03T12:03:20+00:00",
        "updated_at": "2024-02-26T05:09:11+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5275,
        "title": "一个死链接，请修复",
        "body": "死链接：\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleNLP/examples/examples/named_entity_recognition/express_ner\r\n\r\n位置：\r\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/examples\r\n\r\n模型 | 简介\r\n-- | --\r\nBiGRU-CRF\r\n\r\n",
        "state": "closed",
        "user": "guojiahuiEmily",
        "closed_by": "guojiahuiEmily",
        "created_at": "2021-02-07T10:02:33+00:00",
        "updated_at": "2021-02-20T09:47:20+00:00",
        "closed_at": "2021-02-20T09:47:20+00:00",
        "comments_count": [
            "ZHUI",
            "guojiahuiEmily"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 115,
        "title": "paddlenlp实体识别模型服务器部署问题",
        "body": "paddlenlp训练的模型只能通过save_pretrained保存，通过from_pretrained来加载吗？\r\n这样的话工业化部署，只有cpu的情况下很慢，请问如何工业化如果部署，性能怎么提升？",
        "state": "closed",
        "user": "geekChinaMaster",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-02-05T08:56:27+00:00",
        "updated_at": "2023-03-13T00:18:34+00:00",
        "closed_at": "2023-03-13T00:18:34+00:00",
        "comments_count": [
            "MissPenguin",
            "geekChinaMaster",
            "MissPenguin",
            "geekChinaMaster",
            "ZeyuChen",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5281,
        "title": "how to use paddlepaddle vit(vision transformer) to video classfication",
        "body": null,
        "state": "open",
        "user": "dotsonliu",
        "closed_by": null,
        "created_at": "2021-02-23T10:58:03+00:00",
        "updated_at": "2024-02-26T05:09:10+00:00",
        "closed_at": null,
        "comments_count": [
            "bjjwwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 116,
        "title": "在lstm语言模型中为什么要先把全部数据读进来？",
        "body": "https://github.com/PaddlePaddle/models/blob/release/1.7/PaddleNLP/language_model/train.py 文件第212行，直接在reader.get_data_iter()里边读文件边yield感觉也可以吧？",
        "state": "closed",
        "user": "HaodaY",
        "closed_by": "chenxiaozeng",
        "created_at": "2021-02-24T05:06:34+00:00",
        "updated_at": "2021-04-02T09:51:32+00:00",
        "closed_at": "2021-04-02T09:51:32+00:00",
        "comments_count": [
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5288,
        "title": "metric_learning 项目 tripletloss 实现疑问",
        "body": "在metric learning 项目中，tripletloss 实现采用 fluid.layers.split 对batch输入数据分成anchor, positive, negative。\r\n我在 reader.py 中查看 tripletreader 输出的数据格式为[anchor, pos, neg, anchor, pos, neg, anchor, pos, neg, anchor, pos, neg,....]\r\n如果采用 fluid.layers.split 对输入数据进行split，这个split是间隔的对输入采样切分，还是直接进行三等分？\r\n如果是三等分，好像tripletloss 实现貌似有些问题\r\n\r\n不知道我理解的对不对，帮忙确认 fluid.layers.split  和 tripletreaer 两个实现是不是匹配的\r\n\r\n谢谢",
        "state": "closed",
        "user": "linghaolu",
        "closed_by": "linghaolu",
        "created_at": "2021-03-16T02:41:25+00:00",
        "updated_at": "2021-03-16T02:56:16+00:00",
        "closed_at": "2021-03-16T02:56:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 114,
        "title": "使用paddlenlp训练模型后使用paddle.jit.save()保存模型，使用paddle.jit.load()加载后无法使用",
        "body": "### 使用paddlenlp训练模型后使用paddle.jit.save()保存模型，使用paddle.jit.load()加载后无法使用\r\n在使用PaddleNLP语义预训练模型ERNIE完成快递单信息抽取的项目中，使用自定义数据集训练模型并保存，加载后无法使用：\r\n环境：ai studio，paddlenlp2.0b\r\n代码如下：\r\n`\r\nfrom utils import evaluate\r\nimport paddle\r\nglobal_step = 0\r\nfor epoch in range(1, epochs+1):\r\n    for step, (input_ids, segment_ids, seq_lens, labels) in enumerate(train_loader, start=1):\r\n        logits = model(input_ids, segment_ids)\r\n        preds = paddle.argmax(logits, axis=-1)\r\n        n_infer, n_label, n_correct = metric.compute(None, seq_lens, preds, labels)\r\n        metric.update(n_infer.numpy(), n_label.numpy(), n_correct.numpy())\r\n        precision, recall, f1_score = metric.accumulate()\r\n        loss = paddle.mean(criterion(logits.reshape([-1, train_ds.num_label]), labels.reshape([-1])))\r\n\r\n        global_step += 1\r\n        if global_step % 10 == 0 :\r\n            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, precision: %.5f, recall: %.5f, f1: %.5f\" % (global_step, epoch, step, loss, precision, recall, f1_score))\r\n        loss.backward()\r\n        optimizer.step()\r\n        lr_scheduler.step()\r\n        optimizer.clear_grad()\r\n    evaluate(model, metric, dev_loader)\r\n\r\nmodel.save_pretrained('./checkpoint')\r\ntokenizer.save_pretrained('./checkpoint')\r\nfrom paddle.static import InputSpec\r\n# save\r\npath = \"example.dy_model/linear\"\r\npaddle.jit.save(\r\n    layer=model,\r\n    path=path,\r\n    input_spec=[InputSpec(shape=[None, 768], dtype='int64')])\r\n\r\n# load\r\npath = \"example.dy_model/linear\"\r\nloaded_layer = paddle.jit.load(path)\r\n# inference\r\nloaded_layer.eval()\r\nx = paddle.randn([1, 768], 'int64')\r\npred = loaded_layer(x)\r\n`\r\n### 报错结果：\r\n---------------------------------------------------------------------------RuntimeError                              Traceback (most recent call last)<ipython-input-10-8db6a378e7a7> in <module>\r\n      4 # inference\r\n      5 loaded_layer.eval()\r\n----> 6 x = paddle.randn([1, 768], 'int64')\r\n      7 pred = loaded_layer(x)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/random.py in randn(shape, dtype, name)\r\n    331             #  [-0.3761474, -1.044801  ,  1.1870178 ]]  # random\r\n    332     \"\"\"\r\n--> 333     return standard_normal(shape, dtype, name)\r\n    334 \r\n    335 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/random.py in standard_normal(shape, dtype, name)\r\n    277 \r\n    278     \"\"\"\r\n--> 279     return gaussian(shape=shape, mean=0.0, std=1.0, dtype=dtype, name=name)\r\n    280 \r\n    281 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/random.py in gaussian(shape, mean, std, dtype, name)\r\n    198                                         float(mean), 'std',\r\n    199                                         float(std), 'seed', seed, 'dtype',\r\n--> 200                                         dtype)\r\n    201 \r\n    202     check_shape(shape, op_type_for_check)\r\nRuntimeError: (NotFound) Operator gaussian_random does not have kernel for data_type[int64_t]:data_layout[ANY_LAYOUT]:place[CUDAPlace(0)]:library_type[PLAIN].\r\n  [Hint: Expected kernel_iter != kernels.end(), but received kernel_iter == kernels.end().] (at /paddle/paddle/fluid/imperative/prepared_operator.cc:127)\r\n  [operator < gaussian_random > error]\r\n\r\n![图片](https://user-images.githubusercontent.com/44657953/108991518-30923f80-76d3-11eb-8479-c427f7cbc815.png)\r\n![图片](https://user-images.githubusercontent.com/44657953/108991565-3c7e0180-76d3-11eb-9ca1-762415d7ca1c.png)\r\n![图片](https://user-images.githubusercontent.com/44657953/108991631-4d2e7780-76d3-11eb-8dbc-b925473c577c.png)\r\n",
        "state": "closed",
        "user": "geekChinaMaster",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-02-24T11:06:24+00:00",
        "updated_at": "2023-03-13T00:18:32+00:00",
        "closed_at": "2023-03-13T00:18:32+00:00",
        "comments_count": [
            "jeff41404",
            "geekChinaMaster",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5286,
        "title": "如何直接调用模型？",
        "body": "如何像pytorch一样能直接调用各种模型，比如像\r\ntorchvision.models.detection.fasterrcnn_resnet_fpn(pretrained=true)，model.eval()\r\n这样很方便\r\n",
        "state": "open",
        "user": "lao-xu",
        "closed_by": null,
        "created_at": "2021-03-13T07:51:38+00:00",
        "updated_at": "2024-02-26T05:09:08+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng",
            "zhijiejia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5287,
        "title": "infer预测结果理解，和度量学习生成向量的应用问题",
        "body": "已经通过训练生成了模型，通过infer做了预测，经过预测显示的是各张图片对应的五维向量。想问，是否可理解为：每张图片的特征已被抽象为一个特征向量？然后想问：如果要实现多张图片的相识度比对，如何处理这些向量？是否有运用paddle做图像相识度度量的案例？\r\n![2021-03-15 10-15-28 的屏幕截图 - 2](https://user-images.githubusercontent.com/44991938/111095338-2b107280-8578-11eb-9f5f-f7bf1ab67474.png)\r\n",
        "state": "open",
        "user": "Hsoms",
        "closed_by": null,
        "created_at": "2021-03-15T02:21:24+00:00",
        "updated_at": "2024-02-26T05:09:07+00:00",
        "closed_at": null,
        "comments_count": [
            "Hsoms"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 216,
        "title": "球各位大佬帮忙解答一下，关于MRC的问题。使用自己的数据集，预测结果出现单个字的情况？",
        "body": "球各位大佬帮忙解答一下~\r\n在使用paddlepaddle的MRC代码的时候，出现以下迷惑情况。\r\n之前使用自带数据集，预测结果是正常的；使用自己的数据集（2151个），也是正常的，预测结果还不错的；\r\n正常结果如下：\r\n    \"1612\": \"张国荣\",\r\n    \"1206\": \"张火丁\",\r\n    \"2025\": \"罗密欧\",\r\n    \"372\": \"刘霓娜\",\r\n    \"2885\": \"中井贵惠\",\r\n    \"2768\": \"鲁桓公\",\r\n    \"1969\": \"也遂皇后\",\r\n    \"4026\": \"钱韵玲\",\r\n    \"1451\": \"蒋友青\",\r\n\r\n后来使用自己的另外一个数据集（17199个），出现了一下情况：\r\n    \"0\": \"唐\",\r\n    \"1\": \"作\",\r\n    \"2\": \"丁\",\r\n    \"3\": \"诺\",\r\n    \"4\": \"令\",\r\n    \"5\": \"沙\",\r\n    \"6\": \"穆\",\r\n    \"7\": \"周\",\r\n    \"8\": \"唐\",\r\n    \"9\": \"弟\",\r\n\r\n但其实，预测的是不对的，应该是正常的人名，且训练过程中，epoch = 1，batchsize = 12，在第509个batch之后，loss出现nan的情况；\r\n目前尝试过的方法：\r\n1、调小学习率，无用；\r\n2、使用小数据集，不会出现loss为nan的情况。\r\n\r\n\r\n球球各位大佬帮忙解答一下~",
        "state": "closed",
        "user": "Minjuner-97",
        "closed_by": "ZeyuChen",
        "created_at": "2021-03-17T01:48:49+00:00",
        "updated_at": "2021-04-02T04:06:59+00:00",
        "closed_at": "2021-04-02T04:06:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5290,
        "title": "复现度量学习时，做微调再训练时，导入预训练模型报错",
        "body": "报错信息：\r\n![SharedScreenshot](https://user-images.githubusercontent.com/44991938/111423061-aade3e80-872a-11eb-851c-114805e9312e.jpg)\r\n\r\n没有微调时，训练生成的模型格式如下：\r\n![SharedScreenshot1](https://user-images.githubusercontent.com/44991938/111423817-c9910500-872b-11eb-94e1-cb141d59af8c.jpg)\r\n没有微调时，模型保存部分代码：\r\n![t](https://user-images.githubusercontent.com/44991938/111424057-30162300-872c-11eb-80e8-7564ea841db6.jpg)\r\n\r\n\r\n",
        "state": "open",
        "user": "Hsoms",
        "closed_by": null,
        "created_at": "2021-03-17T06:22:35+00:00",
        "updated_at": "2024-02-26T05:09:06+00:00",
        "closed_at": null,
        "comments_count": [
            "iclementine",
            "Hsoms",
            "iclementine",
            "Hsoms"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5291,
        "title": "https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/video/models/nextvlad/README.md",
        "body": "NeXtVLAD模型是第二届Youtube-8M视频理解竞赛中效果最好的单模型，在参数量小于80M的情况下，能得到高于0.87的GAP指标。该模型提供了一种将桢级别的视频特征转化并压缩成特征向量，以适用于大尺寸视频文件的分类的方法。其基本出发点是在NetVLAD模型的基础上，将高维度的特征先进行分组，通过引入attention机制聚合提取时间维度的信息，这样既可以获得较高的准确率，又可以使用更少的参数量。详细内容请参考[NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification](https://arxiv.org/abs/1811.05014)。\r\n\r\n\r\n该模型提供了一种将桢级别的视频特征转化并压缩成特征向量->帧级别\r\n",
        "state": "closed",
        "user": "NEUdeep",
        "closed_by": "huangjun12",
        "created_at": "2021-03-18T03:50:00+00:00",
        "updated_at": "2021-04-12T07:01:09+00:00",
        "closed_at": "2021-04-12T07:01:09+00:00",
        "comments_count": [
            "huangjun12",
            "huangjun12",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5292,
        "title": "PyramidBox无法下载",
        "body": "https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleCV/face_detection\r\n模型发布部分 Pyramidbox-v1-SSD 640x640 点击链接无法下载",
        "state": "open",
        "user": "vincentpengpeng",
        "closed_by": null,
        "created_at": "2021-03-19T09:28:53+00:00",
        "updated_at": "2024-02-26T05:09:04+00:00",
        "closed_at": null,
        "comments_count": [
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5293,
        "title": "paddlepaddle2.0.0、paddlehub2.0.0版本ocr接口疑似存在内存泄漏",
        "body": "ocr接口疑似存在内存泄漏请看一下问题出现在什么地方，谢谢。\r\n\r\n1、版本：\r\npaddlepaddle2.0.0、\r\npaddlehub2.0.0\r\n运行的为cpu版本\r\n服务器内存16G\r\n\r\n2、问题现象\r\n     a、python单进程调用ocr.recognize_text接口读取指定目录下的100张不同图片进行图片文字识别，每识别一张图片，占用内存增加200M以上，随着识别图片数的增加，内存持续增长，直到内存被耗尽被操作系统kill掉\r\n     b、如果只是反复识别同一张图片的话，内存增长的一定数后不再增长\r\n     \r\n3、导致内存泄漏的疑似代码\r\n    通过代码调用链的分析最终定位到c++库中的PD_PredictorZeroCopyRun函数疑似存在内存泄漏，内存泄漏语句\r\n    output_i.shape = new int[output_shape.size()];\r\n    此处new分配的内存没有释放\r\n    包含PD_PredictorZeroCopyRun函数的源码文件：Paddle/paddle/fluid/inference/capi/pd_predictor.cc\r\n\r\n    函数调用链:ocr.recognize_text->self._recognize_text->self.rec_predictor.zero_copy_run()->PD_PredictorRun\r\n\r\n   ocr.recognize_text函数所在文件：.paddlehub/modules/chinese_ocr_db_crnn_server/module.py\r\n   self._recognize_text函数所在文件：.paddlehub/modules/chinese_ocr_db_crnn_server/module.py\r\n   zero_copy_run函数所在文件：Paddle/paddle/fluid/inference/tests/api/analyzer_capi_tester.cc\r\n   PD_PredictorZeroCopyRun函数所在文件：Paddle/paddle/fluid/inference/capi/pd_predictor.cc\r\n\r\n4、出现问题的测试代码\r\nimport paddlehub as hub\r\nimport cv2\r\nimport os, sys\r\n\r\nocr = hub.Module(name=\"chinese_ocr_db_crnn_server\")\r\nfor i in range(100):\r\n    rootdir = '/home/test/img'\r\n    list = os.listdir(rootdir)\r\n    for i in range(0, len(list)):\r\n        f = os.path.join(rootdir, list[i])\r\n        res = ocr.recognize_text(images=[cv2.imread(f)])\r\n\r\n\r\n\r\n  ",
        "state": "closed",
        "user": "weihyemail",
        "closed_by": "weihyemail",
        "created_at": "2021-03-20T02:46:24+00:00",
        "updated_at": "2021-03-22T02:31:38+00:00",
        "closed_at": "2021-03-22T02:31:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5295,
        "title": "请问阅读理解模型的代码实现的模型论文能提供吗？",
        "body": "",
        "state": "closed",
        "user": "Minjuner-97",
        "closed_by": "Minjuner-97",
        "created_at": "2021-04-04T02:37:46+00:00",
        "updated_at": "2021-04-05T11:17:26+00:00",
        "closed_at": "2021-04-05T11:17:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5296,
        "title": "CV video_tag中，3000个标签是什么及模型训练的AUC和准确率是什么",
        "body": "想用一下飞桨的视频标签模型，有些疑惑的地方：\r\nhttps://github.com/PaddlePaddle/PaddleHub/tree/release/v1.7/hub_module/modules/video/classification/videotag_tsn_lstm\r\n![Uploading image.png…]()\r\n需要的是：\r\n1. 3000个标签是哪些\r\n2. 模型训练的AUC和准确率是什么",
        "state": "closed",
        "user": "zhangweijiqn",
        "closed_by": "zhangweijiqn",
        "created_at": "2021-04-06T07:44:13+00:00",
        "updated_at": "2021-04-07T06:55:09+00:00",
        "closed_at": "2021-04-07T06:55:09+00:00",
        "comments_count": [
            "huangjun12",
            "zhangweijiqn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 301,
        "title": "distinct评价指标 的合理范围",
        "body": "引用了您的distinct的计算方式，得到的inter distinct2的值大约在0.24 inter distinct1大约在0.08， 请问这种值是正确且有意义的吗，因为与一些论文里的值有一些不同",
        "state": "closed",
        "user": "zhunipingan",
        "closed_by": "ZeyuChen",
        "created_at": "2021-04-02T07:18:11+00:00",
        "updated_at": "2021-05-14T04:04:09+00:00",
        "closed_at": "2021-05-14T04:04:08+00:00",
        "comments_count": [
            "qili93",
            "xiemoyuan",
            "xiemoyuan",
            "zhunipingan",
            "xiemoyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5301,
        "title": "我想在调试video_tag时，在原有的3396个label上，新增200个关label，此时我只准备对应200个label的视频数据，可以吗？",
        "body": "假设我新增label3397~label3597，而我的自定义视频训练集仅针对新增的200个label，比如每个label下2000个视频，这样可以吗？",
        "state": "open",
        "user": "hongyuzlx",
        "closed_by": null,
        "created_at": "2021-04-28T05:55:54+00:00",
        "updated_at": "2024-02-26T05:09:03+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 241,
        "title": "基于 LambdaDecay 实现的 LinearDecayWithWarmup，训练中途挂掉后热启动继续训练，学习率还是按 step = 0 开始迭代",
        "body": "ci 见 https://github.com/PaddlePaddle/models/commit/fee616e868262a7b791f3801bd0d1380f56d0e36\r\n\r\n",
        "state": "closed",
        "user": "nbcc",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-04-08T02:34:51+00:00",
        "updated_at": "2023-03-13T00:18:07+00:00",
        "closed_at": "2023-03-13T00:18:07+00:00",
        "comments_count": [
            "guoshengCS",
            "LiuChiachi",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5304,
        "title": " `Segmentation fault` is detected by the operating system.",
        "body": "I have seen the same issue previously by different users but no solution is provided if you have found a solution please let me know. \r\n\r\nW0430 06:54:48.080085  1245 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0430 06:54:48.083513  1245 device_context.cc:372] device: 0, cuDNN Version: 8.0.\r\n[04/30 06:54:53] ppdet.utils.checkpoint INFO: Finish loading model weights: /root/.cache/paddle/weights/ResNet50_vd_ssld_pretrained.pdparams\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::SignalHandle(char const*, int)\r\n1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1619765694 (unix time) try \"date -d @1619765694\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 1245 (TID 0x7ff4baebf740) from PID 0 ***]\r\n",
        "state": "open",
        "user": "nataliyah123",
        "closed_by": null,
        "created_at": "2021-04-30T07:01:08+00:00",
        "updated_at": "2021-05-14T05:18:24+00:00",
        "closed_at": null,
        "comments_count": [
            "jiweibo",
            "nataliyah123",
            "nataliyah123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5306,
        "title": "  https://gitee.com/paddlepaddle/models/tree/develop/PaddleCV/video/application/video_tag运行test失败啊啊啊啊",
        "body": "\r\n\r\n\r\n\r\nhttps://gitee.com/paddlepaddle/models/tree/develop/PaddleCV/video/application/video_tag运行test失败啊啊啊啊\r\n`%cd ~/video_tag/\r\n!python videotag_test.py\r\n/home/aistudio/video_tag\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  def convert_to_list(value, n, name, dtype=np.int):\r\nNamespace(extractor_config='configs/tsn.yaml', extractor_name='TSN', extractor_weights='weights/tsn', filelist='./data/VideoTag_test.list.txt', label_file='label_3396.txt', predictor_config='configs/attention_lstm.yaml', predictor_name='AttentionLSTM', predictor_weights='weights/attention_lstm', save_dir='data/VideoTag_results', use_gpu=True)\r\n[INFO: videotag_test.py:  239]: Namespace(extractor_config='configs/tsn.yaml', extractor_name='TSN', extractor_weights='weights/tsn', filelist='./data/VideoTag_test.list.txt', label_file='label_3396.txt', predictor_config='configs/attention_lstm.yaml', predictor_name='AttentionLSTM', predictor_weights='weights/attention_lstm', save_dir='data/VideoTag_results', use_gpu=True)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:1150: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\nW0501 18:28:51.170547  4107 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\r\nW0501 18:28:51.176075  4107 device_context.cc:372] device: 0, cuDNN Version: 7.6.\r\n[INFO: videotag_test.py:  137]: load extractor weights from weights/tsn\r\n[INFO: tsn.py:  157]: Load pretrain weights from weights/tsn, exclude fc layer.\r\n===pretrain=== weights/tsn\r\nTraceback (most recent call last):\r\n  File \"videotag_test.py\", line 240, in <module>\r\n    main()\r\n  File \"videotag_test.py\", line 154, in main\r\n    feed=extractor_feeder.feed(feed_data))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1328, in _run_program\r\n    [fetch_var_name])\r\nRuntimeError: In user code:\r\n\r\n    File \"videotag_test.py\", line 240, in <module>\r\n      main()\r\n    File \"videotag_test.py\", line 127, in main\r\n      extractor_model.build_model()\r\n    File \"/home/aistudio/video_tag/models/tsn/tsn.py\", line 94, in build_model\r\n      class_dim=cfg['class_dim'])\r\n    File \"/home/aistudio/video_tag/models/tsn/tsn_res_model.py\", line 125, in net\r\n      name='conv1')\r\n    File \"/home/aistudio/video_tag/models/tsn/tsn_res_model.py\", line 50, in conv_bn_layer\r\n      bias_attr=False)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1622, in conv2d\r\n      \"data_format\": data_format,\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3027, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2107, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    PreconditionNotMetError: Tensor not initialized yet when Tensor::type() is called.\r\n      [Hint: holder_ should not be null.] (at /paddle/paddle/fluid/framework/tensor.h:202)\r\n      [operator < conv2d > error]`",
        "state": "open",
        "user": "livingbody",
        "closed_by": null,
        "created_at": "2021-05-01T13:38:50+00:00",
        "updated_at": "2021-11-25T13:48:13+00:00",
        "closed_at": null,
        "comments_count": [
            "liym27",
            "huangjun12",
            "Interesting6",
            "Interesting6",
            "ZhongkaiZ",
            "CLIsVeryOK",
            "CLIsVeryOK"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5310,
        "title": "paddle复现BMN结果很差",
        "body": "我在复现BMN的过程中，数据集以及任何参数都未修改，得到的AR@1：5%，这种情况是我还需要调整那些参数吗？",
        "state": "open",
        "user": "Wazxcvb",
        "closed_by": null,
        "created_at": "2021-05-18T08:10:27+00:00",
        "updated_at": "2024-02-26T05:08:58+00:00",
        "closed_at": null,
        "comments_count": [
            "pangyoki",
            "huangjun12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5309,
        "title": "video_tag Out of memory error",
        "body": "1.运行此代码时\r\n![image](https://user-images.githubusercontent.com/31821866/118598731-20c15d80-b7e1-11eb-8fb4-d95cb52a59f2.png)\r\n\r\n2.报了以下错误\r\n[2021-05-18 13:49:17,554] [ WARNING] - The _initialize method in HubModule will soon be deprecated, you can use the __init__() to handle the initialization of the object\r\n2021-05-18 13:49:24,454 - INFO - load extractor weights from C:\\Users\\Administrator\\.paddlehub\\modules\\videotag_tsn_lstm\\weights\\tsn\r\n[INFO 2021-05-18 13:49:24,454 module.py:87] load extractor weights from C:\\Users\\Administrator\\.paddlehub\\modules\\videotag_tsn_lstm\\weights\\tsn\r\n2021-05-18 13:49:25,316 - INFO - load lstm weights from C:\\Users\\Administrator\\.paddlehub\\modules\\videotag_tsn_lstm\\weights\\attention_lstm\r\n[INFO 2021-05-18 13:49:25,316 module.py:117] load lstm weights from C:\\Users\\Administrator\\.paddlehub\\modules\\videotag_tsn_lstm\\weights\\attention_lstm\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Administrator/Desktop/douyin/1.py\", line 9, in <module>\r\n    top_k=10)  # 返回预测结果的前k个，默认为10\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\paddlehub\\compat\\paddle_utils.py\", line 220, in runner\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Administrator\\.paddlehub\\modules\\videotag_tsn_lstm\\module.py\", line 188, in classify\r\n    scope=self.extractor_scope)\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\", line 719, in reraise\r\n    raise value\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1328, in _run_program\r\n    [fetch_var_name])\r\nRuntimeError: ResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 918.750244MB memory on GPU 0, available memory is only 594.612109MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\n\r\n (at D:\\v2.0.2\\paddle\\paddle\\fluid\\memory\\allocation\\cuda_allocator.cc:69)\r\n\r\nW0518 13:49:20.264742 11740 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.0, Runtime API Version: 10.0\r\nW0518 13:49:20.280762 11740 device_context.cc:372] device: 0, cuDNN Version: 7.4.\r\nW0518 13:49:39.900574 11740 operator.cc:206] batch_norm raises an exception struct paddle::memory::allocation::BadAlloc, ResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 918.750244MB memory on GPU 0, available memory is only 594.612109MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\n\r\n (at D:\\v2.0.2\\paddle\\paddle\\fluid\\memory\\allocation\\cuda_allocator.cc:69)",
        "state": "open",
        "user": "Jasonxgw",
        "closed_by": null,
        "created_at": "2021-05-18T06:00:00+00:00",
        "updated_at": "2024-02-26T05:08:59+00:00",
        "closed_at": null,
        "comments_count": [
            "Jasonxgw",
            "pangyoki",
            "Jasonxgw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 381,
        "title": "有关dialogue-plato的metric.py",
        "body": "想问一下其中intra-distinct和inter-distinct的区别是？",
        "state": "closed",
        "user": "ruolanyang",
        "closed_by": "ZeyuChen",
        "created_at": "2021-05-12T05:35:55+00:00",
        "updated_at": "2021-05-14T04:03:24+00:00",
        "closed_at": "2021-05-14T04:03:23+00:00",
        "comments_count": [
            "xiemoyuan",
            "ZeyuChen"
        ],
        "labels": [
            "question"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5314,
        "title": "paddle该怎么实现类似pytorch中对上下文的局部参数禁止求梯度的功能呢？比如torch._C.set_grad_enabled(False)",
        "body": "",
        "state": "closed",
        "user": "aiot-tech",
        "closed_by": "aiot-tech",
        "created_at": "2021-06-04T06:54:52+00:00",
        "updated_at": "2021-06-09T07:35:51+00:00",
        "closed_at": "2021-06-09T07:35:51+00:00",
        "comments_count": [
            "saxon-zh",
            "saxon-zh"
        ],
        "labels": [
            "question",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5315,
        "title": "no have kpi.py",
        "body": "PaddleNLP\\pretrain_language_models\\BERT \r\nrun ./_run_ce.sh\r\n![image](https://user-images.githubusercontent.com/40634721/120807710-cf53f500-c57a-11eb-9dca-e596754afffe.png)\r\nno share all the code",
        "state": "closed",
        "user": "zhihuashan",
        "closed_by": "ZeyuChen",
        "created_at": "2021-06-04T13:22:35+00:00",
        "updated_at": "2021-06-14T08:45:19+00:00",
        "closed_at": "2021-06-14T08:45:19+00:00",
        "comments_count": [
            "chenxiaozeng",
            "ZeyuChen"
        ],
        "labels": [
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5317,
        "title": "3D_version中的pointRCNN 编译自定义的op 出现缺少头文件错误",
        "body": "![image](https://user-images.githubusercontent.com/57033962/122357671-85114180-cf86-11eb-94ad-773c6a70250e.png)\r\n按照官方教程一步步走的，还是存在这些问题。",
        "state": "open",
        "user": "Meroke",
        "closed_by": null,
        "created_at": "2021-06-17T08:11:53+00:00",
        "updated_at": "2021-07-15T10:18:01+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "Meroke",
            "yiakwy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5318,
        "title": "[BUG] 3d vision external static operator compilation is out of date",
        "body": "# Compiilation is out of date\r\nThe latest success compilation for 3d vision models is using Paddle 1.8.5:\r\n\r\n```\r\n# packages in environment at /home/yiakwy/anaconda3/envs/py36-paddle-pointpillar:\r\n#\r\n# Name                    Version                   Build  Channel\r\npaddlepaddle              1.8.5                    pypi_0    pypi\r\n(py36-paddle-pointpillar) yiakwy@yiakwy-System-Product-Name:~/WorkSpace/Github/Paddle/models/PaddleCV/3d_vision/PointNet++/ext_op/src$ bash make.sh\r\n/home/yiakwy/anaconda3/envs/py36-paddle-pointpillar/lib/python3.6/site-packages/paddle/include\r\n/home/yiakwy/anaconda3/envs/py36-paddle-pointpillar/lib/python3.6/site-packages/paddle/libs\r\n```\r\n\r\nHowever, since the recent update of Paddle (v 2.0.1 ) removes previous external static operator compilation method, many projects including PointNet++ won't compile correctly and they didn't make it clear which version it uses in compilation and creates conflicts in latest compilation.\r\n\r\n## compile shared library in 2.0.1\r\nFor example, in PointNet++, to compile successfully, you have add some headers and libraries manually like this:\r\n\r\n```shell\r\nset -e\r\n\r\ninclude_dir=$( python -c 'import paddle; print(paddle.sysconfig.get_include())' )\r\nlib_dir=$( python -c 'import paddle; print(paddle.sysconfig.get_lib())' )\r\n\r\necho $include_dir\r\necho $lib_dir\r\n\r\nOPS='farthest_point_sampling_op gather_point_op group_points_op query_ball_op three_interp_op three_nn_op'\r\nfor op in ${OPS}\r\ndo\r\nnvcc ${op}.cu -c -o ${op}.cu.o -ccbin cc -DPADDLE_WITH_CUDA -DEIGEN_USE_GPU -DPADDLE_USE_DSO -DPADDLE_WITH_MKLDNN -Xcompiler -fPIC -std=c++14 -Xcompiler -fPIC -w --expt-relaxed-constexpr -O0 -g -DNVCC \\\r\n    -I ${include_dir}/third_party/ \\\r\n    -I ${include_dir} \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/mkldnn/include \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/protobuf/include \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/xxhash/include \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/threadpool/src/extern_threadpool \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/eigen3/src/extern_eigen3 \\\r\n    -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/dlpack/src/extern_dlpack/include\r\ndone\r\n\r\n/usr/local/gcc-8.2/bin/g++ farthest_point_sampling_op.cc farthest_point_sampling_op.cu.o gather_point_op.cc gather_point_op.cu.o group_points_op.cc group_points_op.cu.o query_ball_op.cu.o query_ball_op.cc three_interp_op.cu.o three_interp_op.cc three_nn_op.cu.o three_nn_op.cc -o pointnet_lib.so -DPADDLE_WITH_MKLDNN -shared -fPIC -std=c++14 -O0 -g \\\r\n  -I ${include_dir}/third_party/ \\\r\n  -I ${include_dir} \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/mkldnn/include \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/protobuf/include \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/xxhash/include \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/threadpool/src/extern_threadpool \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/eigen3/src/extern_eigen3 \\\r\n  -I /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/dlpack/src/extern_dlpack/include \\\r\n  -L ${lib_dir} \\\r\n  -L /usr/local/cuda/lib64 \\\r\n  -L /home/yiakwy/WorkSpace/Github/Paddle/build/paddle/fluid/framework/ \\\r\n  -L /home/yiakwy/WorkSpace/Github/Paddle/build/third_party/install/xxhash/lib \\\r\n  -lcudart -lxxhash\r\n\r\nrm *.cu.o\r\n\r\n```\r\n\r\nThis is an old problem because header only libraries won't be exported in python path. Here is an another PointNet operator implementation example for education purpose I wrote recently:\r\n\r\nhttps://github.com/yiakwy/paddle_cpp_backend/blob/feature_add_pp_3d_ops/modules/ops/sampling/farthest_point_sampling_op_test.cc\r\n\r\nWhich has a valid test output:\r\n\r\n```\r\n(py36) ➜  paddle_cpp_backend git:(feature_add_pp_3d_ops) ✗ bash scripts/run_farthest_sampling_op.sh \r\nI0618 01:43:13.997464 13857 farthest_point_sampling_op_impl.hpp:83] ==Batch 0===\r\nI0618 01:43:13.998387 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 0, index: 0\r\nI0618 01:43:13.998754 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 1, index: 111938\r\nI0618 01:43:13.999190 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 2, index: 116431\r\nI0618 01:43:13.999765 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 3, index: 109208\r\nI0618 01:43:14.000416 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 4, index: 49938\r\nI0618 01:43:14.001201 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 5, index: 54574\r\nI0618 01:43:14.002121 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 6, index: 109199\r\nI0618 01:43:14.003240 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 7, index: 54545\r\nI0618 01:43:14.004410 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 8, index: 79971\r\nI0618 01:43:14.005683 13857 farthest_point_sampling_op_impl.hpp:116] Add sample point 9, index: 115541\r\n...\r\n```\r\nTo compile it correctly, you have many thing to do.\r\n\r\n## register shared library in 2.0.1\r\nNote, in 2.0.1, \"load_op_library\" is removed. A shared library, according to documentation should be reigstered through\r\n\r\n```python\r\npaddle.utils.cpp_extension.load_op_meta_info_and_register_op(\"Your shared lib path\") # otherwise, even if you loaded the shared lib into python, the operator will not be seen by paddle.\r\n```\r\n\r\n## register helper\r\nOf course, you have to use static declaration because they are not default now.\r\n\r\n@heavengate @qingqing01 @LutaoChu ",
        "state": "open",
        "user": "yiakwy",
        "closed_by": null,
        "created_at": "2021-06-17T17:49:25+00:00",
        "updated_at": "2024-02-26T05:08:56+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "yiakwy-mapping-team"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5320,
        "title": "求BMN在THUMOS的实验代码",
        "body": "跪求BMN在THUMOS上的代码。自己复现实在达不到论文的效果。跪求相关小组大佬放一下代码吧。或者有其他大佬实现了可以支援一波。万分感谢",
        "state": "open",
        "user": "pengjinqiang",
        "closed_by": null,
        "created_at": "2021-06-29T15:21:52+00:00",
        "updated_at": "2024-02-26T05:08:55+00:00",
        "closed_at": null,
        "comments_count": [
            "huangjun12",
            "pengjinqiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5321,
        "title": "pix2pix训练结束后，为什么用save_inference_model重新保存的模型性能下降？",
        "body": "    model_name = 'net_G'\r\n    print(args.init_model + '/' + model_name)\r\n\r\n    place = fluid.CPUPlace()\r\n    if args.use_gpu:\r\n        place = fluid.CUDAPlace(0)\r\n    exe = fluid.Executor(place)\r\n\r\n    startup_prog = fluid.Program()\r\n    infer_prog = fluid.Program()\r\n\r\n    with fluid.program_guard(main_program=infer_prog, startup_program=startup_prog):\r\n        data_shape = [None, 3, args.image_size, args.image_size]\r\n        input = fluid.data(name='input', shape=data_shape, dtype='float32')\r\n        from network.Pix2pix_network import Pix2pix_model\r\n        model = Pix2pix_model()\r\n        fake = model.network_G(input, \"generator\", cfg=args)\r\n\r\n    exe.run(startup_prog)\r\n    fluid.load(infer_prog, os.path.join(args.init_model, model_name), exe)\r\n    print('load params done')\r\n\r\n    infer_prog = infer_prog.clone(for_test=True)\r\n\r\n    if not os.path.exists(args.output_dir):\r\n        os.makedirs(args.output_dir)\r\n    fluid.io.save_inference_model(\r\n        args.output_dir,\r\n        feeded_var_names=['input'],\r\n        target_vars=[fake],\r\n        executor=exe,\r\n        main_program=infer_prog,\r\n        model_filename='__model__',\r\n        params_filename='__params__'\r\n    )",
        "state": "open",
        "user": "ursular86",
        "closed_by": null,
        "created_at": "2021-07-02T03:06:59+00:00",
        "updated_at": "2021-07-28T03:09:34+00:00",
        "closed_at": null,
        "comments_count": [
            "wangxicoding",
            "ursular86",
            "wangxicoding",
            "ursular86"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5323,
        "title": "安装过程中出错，Python.h: no such file or directory",
        "body": "setup.sh 编译过程中出错，Python.h: no such file or directory",
        "state": "open",
        "user": "WindBlowDickCool",
        "closed_by": null,
        "created_at": "2021-07-09T03:17:36+00:00",
        "updated_at": "2024-02-26T05:08:52+00:00",
        "closed_at": null,
        "comments_count": [
            "WindBlowDickCool",
            "chenjiaoAngel"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5325,
        "title": "release 1.8 下 度量学习无法训练",
        "body": "机器： mac book pro\r\n环境：\r\n docker 安装 hub.baidubce.com/paddlepaddle/paddle:1.8.0\r\n\r\n数据集：Stanford_Online_Products\r\n\r\n命令： \r\n`export CPU_NUM=4`\r\n`python3 train_elem.py --model=ResNet50 --train_batch_size=256  --test_batch_size=4  --lr=0.01  --total_iter_num=30000   --use_gpu=False  --model_save_dir=save_model   --loss_name=arcmargin  --arc_scale=80.0`\r\n\r\n\r\n报错信息：\r\n\r\nroot@509278317f3f:/paddle# python3 train_elem.py --model=ResNet50 --train_batch_size=256  --test_batch_size=4  --lr=0.01  --total_iter_num=30000   --use_gpu=False  --model_save_dir=save_model   --loss_name=arcmargin  --arc_scale=80.0\r\n-----------  Configuration Arguments -----------\r\narc_easy_margin: False\r\narc_margin: 0.15\r\narc_scale: 80.0\r\ncheckpoint: None\r\nclass_dim: 11318\r\ndisplay_iter_step: 10\r\nembedding_size: 0\r\nenable_ce: False\r\nimage_shape: 3,224,224\r\nloss_name: arcmargin\r\nlr: 0.01\r\nlr_steps: 15000,25000\r\nlr_strategy: piecewise_decay\r\nmodel: ResNet50\r\nmodel_save_dir: save_model\r\npretrained_model: None\r\nsave_iter_step: 1000\r\ntest_batch_size: 4\r\ntest_iter_step: 1000\r\ntotal_iter_num: 30000\r\ntrain_batch_size: 256\r\nuse_gpu: 0\r\n------------------------------------------------\r\ntrain dataset size: 11318\r\nW0716 02:53:18.506563  2099 build_strategy.cc:170] fusion_group is not enabled for Windows/MacOS now, and only effective when running with CUDA GPU.\r\nW0716 02:53:19.158396  2099 fuse_all_reduce_op_pass.cc:74] Find all_reduce operators: 160. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 160.\r\n/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train_elem.py\", line 317, in <module>\r\n    main()\r\n  File \"train_elem.py\", line 313, in main\r\n    train_async(args)\r\n  File \"train_elem.py\", line 233, in train_async\r\n    lr, loss, acc1, acc5 = train_exe.run(feed=train_batch,fetch_list=train_fetch_list)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py\", line 876, in _run_parallel\r\n    exe.feed_tensors_into_local_scopes(res)\r\npaddle.fluid.core_noavx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::ParallelExecutor::FeedTensorsIntoLocalScopes(std::vector<std::unordered_map<std::string, paddle::framework::LoDTensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, paddle::framework::LoDTensor> > >, std::allocator<std::unordered_map<std::string, paddle::framework::LoDTensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, paddle::framework::LoDTensor> > > > > const&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nUnimplementedError: The feed data number 1 does not match the device number 4. If you are using DataLoader to feed data, this may be because you set drop_last=False in training network. Currently, drop_last=False for DataLoader is not supported for training network. Please set drop_last=True when defining DataLoader.\r\n  [Hint: Expected tensors.size() == member_->local_scopes_.size(), but received tensors.size():1 != member_->local_scopes_.size():4.] at (/paddle/paddle/fluid/framework/parallel_executor.cc:852)\r\n\r\nterminate called recursively\r\nterminate called recursively\r\nterminate called recursively\r\nterminate called without an active exception\r\nW0716 02:53:23.828729  2136 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0716 02:53:23.829792  2136 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0716 02:53:23.829843  2136 init.cc:221] The detail failure signal is:\r\n\r\nW0716 02:53:23.831596  2136 init.cc:224] *** Aborted at 1626404003 (unix time) try \"date -d @1626404003\" if you are using GNU date ***\r\nW0716 02:53:23.931061  2136 init.cc:224] PC: @                0x0 (unknown)\r\nqemu: uncaught target signal 11 (Segmentation fault) - core dumped\r\nSegmentation fault\r\n\r\n\r\n代码没有修改，使用的原始代码",
        "state": "closed",
        "user": "Bobo-y",
        "closed_by": "Bobo-y",
        "created_at": "2021-07-16T02:56:40+00:00",
        "updated_at": "2021-07-19T09:07:12+00:00",
        "closed_at": "2021-07-19T08:58:13+00:00",
        "comments_count": [
            "zhwesky2010",
            "Bobo-y",
            "zhwesky2010"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5329,
        "title": "如何实现添加热词功能？",
        "body": "如何在源码的基础上修改，自定义自己的热词，来提高识别这些词语的权重？",
        "state": "open",
        "user": "shanmon110",
        "closed_by": null,
        "created_at": "2021-07-20T15:36:24+00:00",
        "updated_at": "2021-07-25T03:55:04+00:00",
        "closed_at": null,
        "comments_count": [
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5332,
        "title": "GAN预训练模型下载地址失效",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/gan\r\nGAN预训练模型下载地址失效\r\n![image](https://user-images.githubusercontent.com/38368353/126740014-afc49767-8315-4abb-8cee-97aca6b73c38.png)\r\n",
        "state": "open",
        "user": "msxfXF",
        "closed_by": null,
        "created_at": "2021-07-23T05:16:11+00:00",
        "updated_at": "2024-02-26T05:08:50+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5333,
        "title": "图像分类是否有热力图可视化呢？",
        "body": "",
        "state": "closed",
        "user": "Bobo-y",
        "closed_by": "Bobo-y",
        "created_at": "2021-07-23T11:01:38+00:00",
        "updated_at": "2021-07-26T03:35:27+00:00",
        "closed_at": "2021-07-26T03:35:27+00:00",
        "comments_count": [
            "ceci3",
            "Bobo-y"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5340,
        "title": "PointRCNN多卡训练报错",
        "body": null,
        "state": "closed",
        "user": "ZeaZoM",
        "closed_by": "ZeaZoM",
        "created_at": "2021-09-02T03:29:21+00:00",
        "updated_at": "2021-09-02T03:40:43+00:00",
        "closed_at": "2021-09-02T03:40:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 883,
        "title": "LAC训练数据集在哪里可以下载呢",
        "body": null,
        "state": "closed",
        "user": "adeagle",
        "closed_by": "ZeyuChen",
        "created_at": "2021-08-09T06:01:53+00:00",
        "updated_at": "2021-08-15T13:41:25+00:00",
        "closed_at": "2021-08-15T13:41:25+00:00",
        "comments_count": [
            "joey12300",
            "adeagle",
            "joey12300",
            "adeagle"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5336,
        "title": "metric_learning train报错",
        "body": "在获取get_gpu_num()函数中报错\r\n![image](https://user-images.githubusercontent.com/63645468/128801342-cd94bbf0-c6bf-4038-9d1f-00e649fe5d1a.png)\r\n报错信息：\r\nTypeError: a bytes-like object is required, not 'str'\r\n这个问题该怎么解决",
        "state": "open",
        "user": "Enn29",
        "closed_by": null,
        "created_at": "2021-08-10T02:56:26+00:00",
        "updated_at": "2024-02-26T05:08:49+00:00",
        "closed_at": null,
        "comments_count": [
            "Enn29"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5343,
        "title": "resource unavailable",
        "body": "the following resource is no longer available,\r\n\r\nhttps://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/data/ILSVRC2012/download_imagenet2012.sh",
        "state": "closed",
        "user": "kuizhiqing",
        "closed_by": "kuizhiqing",
        "created_at": "2021-09-15T09:10:07+00:00",
        "updated_at": "2022-06-24T02:17:34+00:00",
        "closed_at": "2022-06-24T02:17:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5339,
        "title": "NEXTVLAD.pdopt not exits",
        "body": "I am finetune the nextvlad on my dataset, but occur error: AssertionError: Optimizer file [./nextvlad/model_weights/NEXTVLAD.pdopt] not exits！need to help!",
        "state": "open",
        "user": "yuxulingche",
        "closed_by": null,
        "created_at": "2021-08-31T09:50:19+00:00",
        "updated_at": "2024-02-26T05:08:47+00:00",
        "closed_at": null,
        "comments_count": [
            "yuxulingche"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5341,
        "title": "PointRCNN多卡训练报错",
        "body": "PointRCNN单卡训练RPN和RCNN都没问题。\r\n\r\n切到多卡训练会报错：\r\n![image](https://user-images.githubusercontent.com/46807404/131778290-3646ed12-2c9b-4b30-bca7-e87d20aa0d32.png)\r\n",
        "state": "open",
        "user": "ZeaZoM",
        "closed_by": null,
        "created_at": "2021-09-02T03:41:51+00:00",
        "updated_at": "2024-02-26T05:08:46+00:00",
        "closed_at": null,
        "comments_count": [
            "wawltor",
            "ZeaZoM"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 1027,
        "title": "bart-base模型精度问题",
        "body": "在复现Pegasus时候，我参考了bart,这2个模型很相似。但是对齐bart精度时候，发现误差很大。麻烦你看看。\r\nmean difference: tensor(1.0486, grad_fn=<MeanBackward0>)\r\nmax difference: tensor(11.2015, grad_fn=<MaxBackward1>)\r\nhuggingface facebook/bart-base vs paddle bart-base\r\n----------------------------------------------------------\r\nfrom paddlenlp.transformers import BartTokenizer as PDBartTokenizer, BartModel as PDBartModel\r\nfrom transformers import BartTokenizer, BartModel\r\nfrom transformers import BartModel as PTBartModel\r\nimport paddle\r\nimport torch\r\nimport os,sys\r\nbase_dir=os.path.dirname(__file__)\r\n\r\nsys.path.append(os.path.join(base_dir,'paddlenlp'))  #临时修改环境变量\r\npaddle.set_device(\"cpu\")\r\n\r\nmodel_list = [\r\n    (\"facebook/bart-base\", \"bart-base\")\r\n    # (\"google/Bart-xsum\", \"ErnieForGeneration\")\r\n]\r\ntext = \"Welcome to use paddle paddle and paddlenlp!\"\r\n\r\nfor model in model_list:\r\n    bart_tokenizer = BartTokenizer.from_pretrained(model[0])\r\n    pt_decoder_input_ids = bart_tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids\r\n    pt_input_ids = bart_tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\").input_ids\r\n    #\r\n    pt_model = PTBartModel.from_pretrained(model[0])\r\n    outputs = pt_model(input_ids=pt_input_ids, decoder_input_ids=pt_decoder_input_ids)\r\n    pt_outputs = outputs.last_hidden_state\r\n    #paddle\r\n    pd_model = PDBartModel.from_pretrained(model[1])\r\n\r\n    with paddle.no_grad():\r\n        tokenizer = PDBartTokenizer.from_pretrained(model[1])\r\n        inputs = tokenizer(\"Studies have been shown that owning a dog is good for you\")[\"input_ids\"]\r\n        decoder_input_ids = tokenizer(\"Studies show that\")[\"input_ids\"]\r\n        pd_decoder_input_ids = paddle.to_tensor([decoder_input_ids])\r\n        pd_input_ids = paddle.to_tensor([inputs])\r\n        pd_outputs = torch.from_numpy(pd_model(input_ids=pd_input_ids, decoder_input_ids=pd_decoder_input_ids).numpy())\r\n    print(\"mean difference:\", (pt_outputs - pd_outputs).abs().mean())\r\n    print(\"max difference:\", (pt_outputs - pd_outputs).abs().max())\r\n    print(f\"huggingface {model[0]} vs paddle {model[1]}\")",
        "state": "closed",
        "user": "myboyliu",
        "closed_by": "gongel",
        "created_at": "2021-09-14T02:49:42+00:00",
        "updated_at": "2021-09-15T08:27:47+00:00",
        "closed_at": "2021-09-15T08:27:47+00:00",
        "comments_count": [
            "myboyliu",
            "gongel"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5345,
        "title": "stnet加载resnet50参数",
        "body": "stnet加载的resnet50是只加载一开始的conv1吗，而不加载哪些bottleneck_block的参数吗",
        "state": "closed",
        "user": "shiyuan680",
        "closed_by": "shiyuan680",
        "created_at": "2021-09-16T01:47:43+00:00",
        "updated_at": "2021-09-16T01:52:49+00:00",
        "closed_at": "2021-09-16T01:52:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5348,
        "title": "对话情绪识别中的models模块在哪里找到？",
        "body": "你好，我在使用https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/emotion_detection中的run_classifier.py时，\r\n`from models.classification import nets` 无法从models中引入相关的类，请问下models这个模块在哪里可以找到？谢谢！",
        "state": "open",
        "user": "gongshaojie12",
        "closed_by": null,
        "created_at": "2021-09-22T06:38:48+00:00",
        "updated_at": "2024-02-26T05:08:42+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5344,
        "title": "PointNet++ ext_op 算子编译报错",
        "body": "基于 Docker 编译源码：\r\n\r\n基础镜像：registry.baidubce.com/paddlepaddle/paddle:2.1.2-gpu-cuda11.2-cudnn8\r\n\r\nPaddle 源码编译通过，但是在编译算子时报错，ext_op/src \r\n\r\n报错关联对象：\r\n\r\n> paddle/fluid/platform/complex.h(115): error: explicit type is missing (\"int\" assumed)\r\n>\r\n>paddle/fluid/platform/complex.h(115): error: qualified name is not allowed\r\n>\r\n>paddle/fluid/platform/complex.h(115): error: expected a \")\"\r\n>\r\n>paddle/fluid/platform/complex.h(123): error: explicit type is missing (\"int\" assumed)\r\n>\r\n>paddle/fluid/platform/complex.h(123): error: qualified name is not allowed\r\n>\r\n>paddle/fluid/platform/complex.h(123): error: expected a \")\"\r\n>\r\n>paddle/fluid/platform/complex.h(122): error: invalid redeclaration of member function template >\"paddle::platform::complex<T>::complex(int)\"\r\n>(114): here",
        "state": "open",
        "user": "zjuncd",
        "closed_by": null,
        "created_at": "2021-09-16T01:28:38+00:00",
        "updated_at": "2024-02-26T05:08:44+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5346,
        "title": "PointNet++ 测试运行失败",
        "body": "基础Docker镜像： paddlepaddle/paddle:1.8.0-gpu-cuda10.0-cudnn7\r\n\r\n1. 调整 ext_op/src/make.sh 代码，在 g++  编译指令中加上 -D_GLIBCXX_USE_CXX11_ABI=0\r\n```bash\r\n# make.sh\r\ninclude_dir=$( python -c 'import paddle; print(paddle.sysconfig.get_include())' )\r\nlib_dir=$( python -c 'import paddle; print(paddle.sysconfig.get_lib())' )\r\n\r\necho $include_dir\r\necho $lib_dir\r\n\r\nOPS='farthest_point_sampling_op gather_point_op group_points_op query_ball_op three_interp_op three_nn_op'\r\nfor op in ${OPS}\r\ndo\r\nnvcc ${op}.cu -c -o ${op}.cu.o -ccbin cc -DPADDLE_WITH_CUDA -DEIGEN_USE_GPU -DPADDLE_USE_DSO -DPADDLE_WITH_MKLDNN -Xcompiler -fPIC -std=c++11 -Xcompiler -fPIC -w --expt-relaxed-constexpr -O0 -g -DNVCC \\\r\n    -I ${include_dir}/third_party/ \\\r\n    -I ${include_dir}\r\ndone\r\n\r\ng++ farthest_point_sampling_op.cc farthest_point_sampling_op.cu.o gather_point_op.cc gather_point_op.cu.o group_points_op.cc group_points_op.cu.o query_ball_op.cu.o query_ball_op.cc three_interp_op.cu.o three_interp_op.cc three_nn_op.cu.o three_nn_op.cc -o pointnet_lib.so -DPADDLE_WITH_MKLDNN -shared -fPIC -std=c++11 -O0 -g \\\r\n  -I ${include_dir}/third_party/ \\\r\n  -I ${include_dir} \\\r\n  -L ${lib_dir} \\\r\n  -L /usr/local/cuda/lib64 -lpaddle_framework -lcudart\\\r\n  -D_GLIBCXX_USE_CXX11_ABI=0\r\n\r\nrm *.cu.o\r\n\r\n```\r\n2. 运行 make.sh 编译通过\r\n3. 执行测试\r\n```bash\r\nexport CUDA_VISIBLE_DEVICES=0\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:`python -c 'import paddle; print(paddle.sysconfig.get_lib())'`\r\nexport PYTHONPATH=$PYTHONPATH:`pwd`\r\npython tests/test_three_nn_op.py\r\n```\r\n报错信息如下：\r\n```\r\nW0916 10:55:57.921620   376 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0916 10:55:57.921661   376 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0916 10:55:57.921666   376 init.cc:221] The detail failure signal is:\r\n\r\nW0916 10:55:57.921671   376 init.cc:224] *** Aborted at 1631789757 (unix time) try \"date -d @1631789757\" if you are using GNU date ***\r\nW0916 10:55:57.923035   376 init.cc:224] PC: @                0x0 (unknown)\r\nW0916 10:55:57.923224   376 init.cc:224] *** SIGFPE (@0x7f1e088ed83b) received by PID 376 (TID 0x7f1e0e650700) from PID 143579195; stack trace: ***\r\nW0916 10:55:57.924304   376 init.cc:224]     @     0x7f1e0e22e390 (unknown)\r\nW0916 10:55:57.925643   376 init.cc:224]     @     0x7f1e088ed83b std::__detail::_Mod_range_hashing::operator()()\r\nW0916 10:55:57.926782   376 init.cc:224]     @     0x7f1e089104b2 std::__detail::_Hash_code_base<>::_M_bucket_index()\r\nW0916 10:55:57.927825   376 init.cc:224]     @     0x7f1e0890f5d0 std::_Hashtable<>::_M_bucket_index()\r\nW0916 10:55:57.928773   376 init.cc:224]     @     0x7f1e089119bb std::__detail::_Map_base<>::operator[]()\r\nW0916 10:55:57.929697   376 init.cc:224]     @     0x7f1e08910992 std::unordered_map<>::operator[]()\r\nW0916 10:55:57.930344   376 init.cc:224]     @     0x7f1e0890fe46 _ZN6paddle9framework19RegisterKernelClassINS_8platform9CUDAPlaceEfZNKS0_24OpKernelRegistrarFunctorIS3_Lb0ELm0EINS_9operators33FarthestPointSamplingOpCUDAKernelIfEENS6_IdEEEEclEPKcSB_iEUlRKNS0_16ExecutionContextEE_EEvSB_SB_iT1_\r\nW0916 10:55:57.931105   376 init.cc:224]     @     0x7f1e0890f2e4 paddle::framework::OpKernelRegistrarFunctor<>::operator()()\r\nW0916 10:55:57.931761   376 init.cc:224]     @     0x7f1e0890e799 _ZN6paddle9framework17OpKernelRegistrarINS_8platform9CUDAPlaceEJNS_9operators33FarthestPointSamplingOpCUDAKernelIfEENS5_IdEEEEC2EPKcSA_i\r\nW0916 10:55:57.932322   376 init.cc:224]     @     0x7f1e0890af49 __static_initialization_and_destruction_0()\r\nW0916 10:55:57.932822   376 init.cc:224]     @     0x7f1e0890af77 _GLOBAL__sub_I_tmpxft_000000df_00000000_5_farthest_point_sampling_op.cudafe1.cpp\r\nW0916 10:55:57.933336   376 init.cc:224]     @     0x7f1e0e44a6ca (unknown)\r\nW0916 10:55:57.933843   376 init.cc:224]     @     0x7f1e0e44a7db (unknown)\r\nW0916 10:55:57.934345   376 init.cc:224]     @     0x7f1e0e44f8f2 (unknown)\r\nW0916 10:55:57.934846   376 init.cc:224]     @     0x7f1e0e44a574 (unknown)\r\nW0916 10:55:57.935348   376 init.cc:224]     @     0x7f1e0e44edb9 (unknown)\r\nW0916 10:55:57.935863   376 init.cc:224]     @     0x7f1e0dc4ff09 (unknown)\r\nW0916 10:55:57.936401   376 init.cc:224]     @     0x7f1e0e44a574 (unknown)\r\nW0916 10:55:57.936937   376 init.cc:224]     @     0x7f1e0dc50571 (unknown)\r\nW0916 10:55:57.937688   376 init.cc:224]     @     0x7f1e0dc4ffa1 dlopen\r\nW0916 10:55:57.945061   376 init.cc:224]     @     0x7f1da08da6d3 paddle::platform::dynload::GetOpDsoHandle()\r\nW0916 10:55:57.950942   376 init.cc:224]     @     0x7f1d9cfbe71d paddle::framework::LoadOpLib()\r\nW0916 10:55:57.953336   376 init.cc:224]     @     0x7f1d9d0239ed _ZZN8pybind1112cpp_function10initializeIRPFvRKSsEvIS3_EINS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESN_\r\nW0916 10:55:57.955534   376 init.cc:224]     @     0x7f1d9d048b39 pybind11::cpp_function::dispatcher()\r\nW0916 10:55:57.955688   376 init.cc:224]     @           0x4bc9ba PyEval_EvalFrameEx\r\nW0916 10:55:57.955794   376 init.cc:224]     @           0x4ba036 PyEval_EvalCodeEx\r\nW0916 10:55:57.955926   376 init.cc:224]     @           0x4c237b PyEval_EvalFrameEx\r\nW0916 10:55:57.956028   376 init.cc:224]     @           0x4ba036 PyEval_EvalCodeEx\r\nW0916 10:55:57.956147   376 init.cc:224]     @           0x4b9d26 PyEval_EvalCode\r\nW0916 10:55:57.956218   376 init.cc:224]     @           0x4b9c5f PyImport_ExecCodeModuleEx\r\nW0916 10:55:57.956341   376 init.cc:224]     @           0x4b2f86 (unknown)\r\nW0916 10:55:57.956454   376 init.cc:224]     @           0x4a4d21 (unknown)\r\nFloating point exception (core dumped)\r\n\r\n```",
        "state": "open",
        "user": "zjuncd",
        "closed_by": null,
        "created_at": "2021-09-16T11:35:20+00:00",
        "updated_at": "2024-02-26T05:08:43+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5351,
        "title": "CRNN-CTC可以识别英文字符+数字字符的文本么？",
        "body": "像下面图中所示的\r\n![烟草32位码](https://user-images.githubusercontent.com/34160512/134862893-a67453c8-d12f-4ad5-81c3-b0cf51c292a5.jpg)\r\n",
        "state": "open",
        "user": "chenmonster",
        "closed_by": null,
        "created_at": "2021-09-27T07:25:46+00:00",
        "updated_at": "2024-02-26T05:08:38+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5349,
        "title": "度量模型提取特征的时候如何找到对应图片地址?",
        "body": "由于原模型提取特征时输出只有特征无法和图片对应，如果将keeporder改为True则预测速度大幅下降，目前尝试了下改动reader中的processImg处理方法，增加了图片地址返回值，但报错（显示reader读取越界），同时也不知道对于str的返回值fluid.data应该选什么dtype类型",
        "state": "open",
        "user": "kkpssr",
        "closed_by": null,
        "created_at": "2021-09-23T08:59:20+00:00",
        "updated_at": "2024-02-26T05:08:41+00:00",
        "closed_at": null,
        "comments_count": [
            "kkpssr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5350,
        "title": "core_avx.so 如何动态链接到 libcudart.so",
        "body": "环境： ubuntu18.04，自己编译paddlepaddle\r\n\r\n按照前辈的做法：https://github.com/PaddlePaddle/Paddle/issues/20765\r\n\r\nlibwarpctc.so 确实可以动态链接 libcudart.so\r\n\r\n但是 core_avx.so 这个还是静态链接，请问有什么cmake文件，我没有添加什么条件再编译吗？",
        "state": "open",
        "user": "chensusu11",
        "closed_by": null,
        "created_at": "2021-09-27T01:33:54+00:00",
        "updated_at": "2024-02-26T05:08:39+00:00",
        "closed_at": null,
        "comments_count": [
            "chensusu11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5357,
        "title": "获取训练相关信息问题",
        "body": "请问在Paddle/image_classification文件夹下的分类模型里面如何设定参数保存查看训练日志？",
        "state": "open",
        "user": "SumFunction",
        "closed_by": null,
        "created_at": "2021-10-14T01:38:53+00:00",
        "updated_at": "2024-02-26T05:08:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5353,
        "title": "models/docs/ThesisReproduction_CV.md 文档错误",
        "body": "第 5 章 5.1 中部分内容存在错误，如下图所示：\r\n![image](https://user-images.githubusercontent.com/34644177/135592825-4a552c7d-8ec6-42d9-81c4-af25f1f928a9.png)\r\n",
        "state": "closed",
        "user": "lazyn1997",
        "closed_by": "lazyn1997",
        "created_at": "2021-10-01T08:52:15+00:00",
        "updated_at": "2021-12-16T04:36:13+00:00",
        "closed_at": "2021-12-16T04:36:13+00:00",
        "comments_count": [
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5361,
        "title": "stnet  训练时的验证集精度",
        "body": "同标题，想知道下，训练时最后验证集能达到的精度",
        "state": "open",
        "user": "shiyuan680",
        "closed_by": null,
        "created_at": "2021-10-25T03:05:44+00:00",
        "updated_at": "2024-02-26T05:08:35+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5362,
        "title": "stnet  kinetics400数据如果从原视频抽帧直接处理 怎么进行数据处理",
        "body": "同标题",
        "state": "open",
        "user": "shiyuan680",
        "closed_by": null,
        "created_at": "2021-10-25T14:12:03+00:00",
        "updated_at": "2024-02-26T05:08:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5360,
        "title": "paddle.utils.run_check() 报错",
        "body": "cuda版本是10.1， cudnn是7.6.5，paddle 安装的是2.1.3。\r\n\r\n使用 paddle.utils.run_check() 验证安装是否成功时，报错。不知道问题出在哪里了，麻烦帮看下。\r\n\r\n具体报错如下：\r\n\r\n`\r\nRunning verify PaddlePaddle program ...\r\nW1023 17:00:07.024209  6741 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 10.1, Runtime API Version: 10.1\r\nW1023 17:00:07.032667  6741 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\nPaddlePaddle works well on 1 GPU.\r\nW1023 17:00:11.081976  6741 parallel_executor.cc:601] Cannot enable P2P access from 0 to 4\r\nW1023 17:00:11.082031  6741 parallel_executor.cc:601] Cannot enable P2P access from 0 to 5\r\nW1023 17:00:11.082046  6741 parallel_executor.cc:601] Cannot enable P2P access from 0 to 6\r\nW1023 17:00:11.082060  6741 parallel_executor.cc:601] Cannot enable P2P access from 0 to 7\r\nW1023 17:00:12.972504  6741 parallel_executor.cc:601] Cannot enable P2P access from 1 to 4\r\nW1023 17:00:12.972553  6741 parallel_executor.cc:601] Cannot enable P2P access from 1 to 5\r\nW1023 17:00:12.972563  6741 parallel_executor.cc:601] Cannot enable P2P access from 1 to 6\r\nW1023 17:00:12.972571  6741 parallel_executor.cc:601] Cannot enable P2P access from 1 to 7\r\nW1023 17:00:14.508332  6741 parallel_executor.cc:601] Cannot enable P2P access from 2 to 4\r\nW1023 17:00:14.508384  6741 parallel_executor.cc:601] Cannot enable P2P access from 2 to 5\r\nW1023 17:00:14.508422  6741 parallel_executor.cc:601] Cannot enable P2P access from 2 to 6\r\nW1023 17:00:14.508442  6741 parallel_executor.cc:601] Cannot enable P2P access from 2 to 7\r\nW1023 17:00:16.406250  6741 parallel_executor.cc:601] Cannot enable P2P access from 3 to 4\r\nW1023 17:00:16.406316  6741 parallel_executor.cc:601] Cannot enable P2P access from 3 to 5\r\nW1023 17:00:16.406330  6741 parallel_executor.cc:601] Cannot enable P2P access from 3 to 6\r\nW1023 17:00:16.406342  6741 parallel_executor.cc:601] Cannot enable P2P access from 3 to 7\r\nW1023 17:00:16.406355  6741 parallel_executor.cc:601] Cannot enable P2P access from 4 to 0\r\nW1023 17:00:16.406368  6741 parallel_executor.cc:601] Cannot enable P2P access from 4 to 1\r\nW1023 17:00:16.406388  6741 parallel_executor.cc:601] Cannot enable P2P access from 4 to 2\r\nW1023 17:00:16.406400  6741 parallel_executor.cc:601] Cannot enable P2P access from 4 to 3\r\nW1023 17:00:18.666070  6741 parallel_executor.cc:601] Cannot enable P2P access from 5 to 0\r\nW1023 17:00:18.666117  6741 parallel_executor.cc:601] Cannot enable P2P access from 5 to 1\r\nW1023 17:00:18.666129  6741 parallel_executor.cc:601] Cannot enable P2P access from 5 to 2\r\nW1023 17:00:18.666141  6741 parallel_executor.cc:601] Cannot enable P2P access from 5 to 3\r\nW1023 17:00:20.616923  6741 parallel_executor.cc:601] Cannot enable P2P access from 6 to 0\r\nW1023 17:00:20.616972  6741 parallel_executor.cc:601] Cannot enable P2P access from 6 to 1\r\nW1023 17:00:20.616983  6741 parallel_executor.cc:601] Cannot enable P2P access from 6 to 2\r\nW1023 17:00:20.616993  6741 parallel_executor.cc:601] Cannot enable P2P access from 6 to 3\r\nW1023 17:00:22.165275  6741 parallel_executor.cc:601] Cannot enable P2P access from 7 to 0\r\nW1023 17:00:22.165328  6741 parallel_executor.cc:601] Cannot enable P2P access from 7 to 1\r\nW1023 17:00:22.165338  6741 parallel_executor.cc:601] Cannot enable P2P access from 7 to 2\r\nW1023 17:00:22.165349  6741 parallel_executor.cc:601] Cannot enable P2P access from 7 to 3\r\n\r\n\r\n\r\nC++ Traceback (most recent call last):\r\n0   paddle::framework::SignalHandle(char const*, int)\r\n1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n\r\nError Message Summary:\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1634979634 (unix time) try \"date -d @1634979634\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 6741 (TID 0x7f117c717700) from PID 0 ***]\r\n\r\nSegmentation fault (core dumped)\r\n`\r\n",
        "state": "open",
        "user": "128ve900",
        "closed_by": null,
        "created_at": "2021-10-23T09:36:43+00:00",
        "updated_at": "2024-02-26T05:08:36+00:00",
        "closed_at": null,
        "comments_count": [
            "chunniunai220ml"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5364,
        "title": "【菁英计划】实现库einops的类Rearrange报错",
        "body": "论文复现，第62篇论文**《CvT: Introducing Convolutions to Vision Transformers》**\r\n\r\n参考的github repo在models/cls_cvt.py中引入了einops库，使用了该库的函数rearrang进行数据重排，在模型的层里面使用了类Rearrange。使用paddle实现该类，前向报错。\r\n\r\n\r\n![WechatIMG53](https://user-images.githubusercontent.com/38393385/139624120-74ac15df-0cb5-415b-af1b-c33003ecb187.png)\r\n\r\n\r\ngithub项目链接：[https://github.com/vcowwy/CvT_paddle]\r\n\r\n\r\n",
        "state": "closed",
        "user": "vcowwy",
        "closed_by": "vcowwy",
        "created_at": "2021-11-01T05:05:30+00:00",
        "updated_at": "2021-11-01T05:07:40+00:00",
        "closed_at": "2021-11-01T05:07:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5363,
        "title": "nextVlad读数据错误请教 [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)",
        "body": "完全参考https://github.com/PaddlePaddle/models/blob/release/1.7/PaddleCV/video/models/nextvlad/README.md的指引\r\n使用的分支是1.7\r\n数据集训练集和测试集各自下了100个数据\r\n检验过转换成pkl后，相关文件的配置地址是没问题的。生成的pkl文件使用pickle读取验证过，内容应该是正确的。\r\n为什么会训练的时候会出现这个错误呢？试过调整batch_size到4，也没用。\r\n\r\n其他：\r\nnum_gpus设置为1\r\n\r\n且在train.py加入了：\r\nimport paddle\r\npaddle.enable_static()\r\n\r\n\r\n$python train.py --model_name=NEXTVLAD  --config=./configs/nextvlad.yaml --log_interval=10 --valid_interval=1 --use_gpu=True --save_dir=./data/checkpoints --fix_random_seed=False\r\n[INFO: train.py:  257]: Namespace(batch_size=None, config='./configs/nextvlad.yaml', epoch=None, fix_random_seed=False, is_profiler=0, learning_rate=None, log_interval=10, model_name='NEXTVLAD', no_memory_optimize=False, pretrain=None, profiler_path='./', resume=None, save_dir='./data/checkpoints', use_gpu=True, valid_interval=1)\r\n[INFO: config_utils.py:   70]: ---------------- Train Arguments ----------------\r\n[INFO: config_utils.py:   72]: MODEL:\r\n[INFO: config_utils.py:   74]:     name:NEXTVLAD\r\n[INFO: config_utils.py:   74]:     num_classes:3862\r\n[INFO: config_utils.py:   74]:     topk:20\r\n[INFO: config_utils.py:   74]:     video_feature_size:1024\r\n[INFO: config_utils.py:   74]:     audio_feature_size:128\r\n[INFO: config_utils.py:   74]:     cluster_size:128\r\n[INFO: config_utils.py:   74]:     hidden_size:2048\r\n[INFO: config_utils.py:   74]:     groups:8\r\n[INFO: config_utils.py:   74]:     expansion:2\r\n[INFO: config_utils.py:   74]:     drop_rate:0.5\r\n[INFO: config_utils.py:   74]:     gating_reduction:8\r\n[INFO: config_utils.py:   74]:     eigen_file:./data/dataset/youtube8m/yt8m_pca/eigenvals.npy\r\n[INFO: config_utils.py:   72]: TRAIN:\r\n[INFO: config_utils.py:   74]:     epoch:6\r\n[INFO: config_utils.py:   74]:     learning_rate:0.0002\r\n[INFO: config_utils.py:   74]:     lr_boundary_examples:2000000\r\n[INFO: config_utils.py:   74]:     max_iter:700000\r\n[INFO: config_utils.py:   74]:     learning_rate_decay:0.8\r\n[INFO: config_utils.py:   74]:     l2_penalty:1e-05\r\n[INFO: config_utils.py:   74]:     gradient_clip_norm:1.0\r\n[INFO: config_utils.py:   74]:     use_gpu:True\r\n[INFO: config_utils.py:   74]:     num_gpus:1\r\n[INFO: config_utils.py:   74]:     batch_size:4\r\n[INFO: config_utils.py:   74]:     filelist:./data/dataset/youtube8m/train.list\r\n[INFO: config_utils.py:   72]: VALID:\r\n[INFO: config_utils.py:   74]:     batch_size:4\r\n[INFO: config_utils.py:   74]:     filelist:./data/dataset/youtube8m/val.list\r\n[INFO: config_utils.py:   72]: TEST:\r\n[INFO: config_utils.py:   74]:     batch_size:4\r\n[INFO: config_utils.py:   74]:     filelist:./data/dataset/youtube8m/test.list\r\n[INFO: config_utils.py:   72]: INFER:\r\n[INFO: config_utils.py:   74]:     batch_size:1\r\n[INFO: config_utils.py:   74]:     filelist:./data/dataset/youtube8m/infer.list\r\n[INFO: config_utils.py:   75]: -------------------------------------------------\r\nW1029 15:37:22.192792 36029 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW1029 15:37:22.200862 36029 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\n[INFO: train_utils.py:   46]: ------- learning rate [0.], learning rate counter [-1] -----\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 262, in <module>\r\n    train(args)\r\n  File \"train.py\", line 249, in train\r\n    profiler_path=args.profiler_path)\r\n  File \"/ProjectRoot/python_workspace/video_topic/paddle/models-release-1.7/PaddleCV/video/utils/train_utils.py\", line 92, in train_with_dataloader\r\n    for data in train_dataloader():\r\n  File \"/UserData/software/anaconda3/envs/python3.6_paddle/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 1251, in __next__\r\n    return self._reader.read_next()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n\r\n/UserData/software/anaconda3/envs/python3.6_paddle/lib/python3.6/site-packages/paddle/fluid/reader.py:1294: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\r\n  logging.warn('Your reader has raised an exception!')\r\n[WARNING: reader.py: 1294]: Your reader has raised an exception!",
        "state": "open",
        "user": "yezhanglang",
        "closed_by": null,
        "created_at": "2021-10-29T07:45:43+00:00",
        "updated_at": "2024-02-26T05:08:32+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5366,
        "title": "videotag更改label数量",
        "body": "默认给的3396的label，我直接指定新的包含10个类别的label_file训练会报错，显示和3396不匹配，请问我该成自己的label_file对应还需要改哪些地方啊",
        "state": "open",
        "user": "Skye2099",
        "closed_by": null,
        "created_at": "2021-11-04T06:49:02+00:00",
        "updated_at": "2024-02-26T05:08:30+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5368,
        "title": "下载不了pix2pix模型",
        "body": "https://paddle-gan-models.bj.bcebos.com/pix2pix_G.tar.gz\r\n\r\nhttps://www.paddlepaddle.org.cn/modelbasedetail/pix2pix",
        "state": "open",
        "user": "zhenzi0322",
        "closed_by": null,
        "created_at": "2021-11-10T02:03:24+00:00",
        "updated_at": "2024-02-26T05:08:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5375,
        "title": "Hi，尊敬的开发者们，请教一个问题，cascade-rcnn模型是否指定了模型输入图片的尺寸，还有模型的实现源码请问在哪里可以看呢？",
        "body": "我现在遇到一个问题，在训练模型的时候，因为采集图片的设备多种多样，采集图片的尺寸也就不一样。\r\n使用的是cascade-rcnn\r\n我看配置文件里，\r\n训练时，可以随机增强成5种尺寸的输入大小\r\n评估和预测时只有1种尺寸大小。\r\n我的问题是：\r\n1，cascade-rcnn网络要求的输入图片尺寸是多少呢？是固定大小还是不固定呢？如果不固定是因为全卷积吗？如果算法里使用了全链接层就必须固定对吗？\r\n2，预测不一样尺寸的图片，最后会resize到配置文件中设置的尺寸上输入，那么模型网络的输入是不是还要resize到固定inputsize的呢？比如我设置的输入图片大小是1600*800，我拍到的图片是4000*2000，训练/预测时，先resize到1600*800，再resize到网络需要的输入（比如说684*684）才送入网络训练/预测。\r\n3，在原始图片上对锚框聚类后，配置文件里的锚框尺寸是以原始图片为基准，还是以resize到网络输入的尺寸大小为准。\r\n4，预测/训练不同大小的图片时，比如尺寸从（500X500）到（2000X2000）按步长200尺寸均匀分布。怎样处理不同尺寸的训练和预测比较合适呢？",
        "state": "open",
        "user": "MatrixLyz0623",
        "closed_by": null,
        "created_at": "2021-11-17T05:43:23+00:00",
        "updated_at": "2024-02-26T05:08:28+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5365,
        "title": "请问可以cpu-ps方式运行吗",
        "body": "请问可以cpu-ps方式运行吗",
        "state": "open",
        "user": "ftgreat",
        "closed_by": null,
        "created_at": "2021-11-02T02:49:14+00:00",
        "updated_at": "2024-02-26T05:08:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5387,
        "title": "STGAN预训练模型地址消失",
        "body": "https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleCV/gan地址里面的STGAN预训练模型下载地址（https://paddle-gan-models.bj.bcebos.com/stgan_G.tar.gz）消失不见\r\n![image](https://user-images.githubusercontent.com/17585343/143212909-504dad52-6f49-45b9-a512-553a849beb68.png)\r\n",
        "state": "open",
        "user": "webYFDT",
        "closed_by": null,
        "created_at": "2021-11-24T09:37:07+00:00",
        "updated_at": "2024-02-26T05:08:26+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5414,
        "title": "fluid版本的resnet预训练权重还能下载吗",
        "body": "https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification",
        "state": "open",
        "user": "renmada",
        "closed_by": null,
        "created_at": "2021-12-10T04:39:02+00:00",
        "updated_at": "2024-02-26T05:08:22+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5394,
        "title": "SMOKE static model export to ONNX",
        "body": "Dear Author.\r\nHello! I have encountered a problem. I am using the SMOKE model and following the instructions in README.MD to export the model as a static diagram model. However, the following error occurs when converting the static diagram model to ONNX model.\r\n```\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:45: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/home/lee/.conda/envs/paddle/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/command.py\", line 148, in main\r\n    program2onnx(\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 79, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker, operator_export_type)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 33, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, operator_export_type, verbose)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n    onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n    self.update_opset_version()\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 127, in get_recommend_opset_version\r\n    recommend_opset_version = OpMapper.check_support_status(node_map, opset_version, True)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 168, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 9 ops are not supported yet\r\n=========== while ===========\r\n=========== set_value ===========\r\n=========== crop_tensor ===========\r\n=========== logical_not ===========\r\n=========== less_than ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== index_select ===========\r\n=========== atan ===========\r\n```\r\nThis error indicates that nine operators are not supported. After checking the list of operators, I found only 'conditional-block', 'set-value', and 'while', 'select-input' and 'crop-tensor' are not available. Here are the commands I used for the conversion.\r\n`paddle2onnx \r\n--model_dir /media/lee/DATA/project/gitproject/models/PaddleCV/3d_vision/SMOKE/inference_model             \r\n--model_filename inference.pdmodel             \r\n--params_filename inference.pdiparams             \r\n--opset_version 11            \r\n--save_file smoke.onnx\r\n`\r\nHow should I solve such a situation? I look forward to your reply!",
        "state": "open",
        "user": "Gewaihir",
        "closed_by": null,
        "created_at": "2021-11-26T00:50:54+00:00",
        "updated_at": "2024-02-26T05:08:25+00:00",
        "closed_at": null,
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5406,
        "title": "模型导出出现Tensor' object has no attribute 'get",
        "body": "        paddlepaddle-gpu==2.1.3\r\n\r\n       state_dict = paddle.load(resume_model_path)\r\n        model.set_state_dict(state_dict)\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/dnf/PPASR/export_model.py\", line 24, in <module>\r\n    trainer.export(save_model_path=args.save_model, resume_model=args.resume_model)\r\n  File \"D:\\dnf\\PPASR\\ppasr\\trainer.py\", line 493, in export\r\n    base_model.set_state_dict(state_dict)\r\n  File \"C:\\Users\\qiegewala\\anaconda3\\envs\\rrr\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 274, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\qiegewala\\anaconda3\\envs\\rrr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 1298, in set_state_dict\r\n    match_res = _check_match(key_name, param)\r\n  File \"C:\\Users\\qiegewala\\anaconda3\\envs\\rrr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 1282, in _check_match\r\n    state = state_dict.get(key, None)\r\nAttributeError: 'Tensor' object has no attribute 'get'\r\n\r\n\r\n",
        "state": "open",
        "user": "skyriver1",
        "closed_by": null,
        "created_at": "2021-12-08T11:38:59+00:00",
        "updated_at": "2024-02-26T05:08:24+00:00",
        "closed_at": null,
        "comments_count": [
            "greatsuuny"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5432,
        "title": "有没有c++版本部署环境呀？",
        "body": null,
        "state": "open",
        "user": "xiaogao22",
        "closed_by": null,
        "created_at": "2021-12-22T01:08:34+00:00",
        "updated_at": "2024-02-26T05:08:21+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5420,
        "title": "【无需回复】用户群二维码链接生成",
        "body": "![61a1bd92c94181c39759251010e8cc2a](https://user-images.githubusercontent.com/23690325/165911212-cda07629-1bab-4cc3-8228-e5b69320fe4d.jpg)\r\n\r\n",
        "state": "closed",
        "user": "D-DanielYang",
        "closed_by": "D-DanielYang",
        "created_at": "2021-12-11T17:11:23+00:00",
        "updated_at": "2022-11-29T05:10:50+00:00",
        "closed_at": "2022-11-29T05:10:50+00:00",
        "comments_count": [
            "thgpddl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5458,
        "title": "为什么LSTM中使用 delattr 删除属性，会生成一个其他的属性",
        "body": "    class MyLayer(paddle.nn.Layer):\r\n        def __init__(self):\r\n            super(MyLayer, self).__init__()\r\n            self.lstm1 = paddle.nn.LSTM(400, 200)\r\n            self.lstm2 = paddle.nn.LSTM(600, 300)\r\n            delattr(self.lstm1, 'bias_hh_l0')\r\n    \r\n        def forward(self, input):\r\n            pass\r\n    \r\n    mylayer = MyLayer()\r\n    for name, param in mylayer.named_parameters():\r\n        print(name)\r\n\r\n结果删除了'bias_hh_l0'属性，但是却生成一个’lstm1.0.cell.bias_hh ‘\r\n\r\n    lstm1.weight_ih_l0\r\n    lstm1.weight_hh_l0\r\n    lstm1.bias_ih_l0\r\n    lstm1.0.cell.bias_hh\r\n    lstm2.weight_ih_l0\r\n    lstm2.weight_hh_l0\r\n    lstm2.bias_ih_l0\r\n    lstm2.bias_hh_l0",
        "state": "open",
        "user": "FightingFrogg",
        "closed_by": null,
        "created_at": "2022-01-05T11:29:17+00:00",
        "updated_at": "2024-02-26T05:08:20+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5465,
        "title": "按照步骤youtube8m数据转pkl失败",
        "body": "我想测试一下NeXtVLAD，结果在转tfrecord为pkl遇到下面的错误：\r\nInvalid argument: Feature: mean_audio (data type: float) is required but could not be found.\r\n看起来是数据缺少该字段，不知道是官方数据变了还是现在的代码不适用了",
        "state": "open",
        "user": "garspace",
        "closed_by": null,
        "created_at": "2022-01-28T04:00:22+00:00",
        "updated_at": "2024-02-26T05:08:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5466,
        "title": "ImageNet数据集处理报错--ClassificationPresetTrain无法在静态图模式下使用",
        "body": "需求：借用此教程ImageNet预处理方式，在静态图模式下对模型进行训练\r\n\r\n使用：使用的是这个教程里的 ImageNet数据集预处理方法 \r\nhttps://github.com/PaddlePaddle/models/tree/release/2.2/tutorials/mobilenetv3_prod/Step6\r\n\r\n问题：\r\nClassificationPresetTrain无法在静态图模式下使用 （拿来train静态图模型报错）\r\nClassificationPresetEval 则可以在静态图模式下使用（可以拿来eval静态图模型）\r\n\r\n错误：paddlevision的transform.py中，@staticmethod def get_params函数中，使用了一个paddle.to_tensor(ratio)，此操作只在动态图中支持.\r\n\r\n\r\n详细错误如下:\r\nPlease NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.1\r\nW0130 12:03:35.088925 11028 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 212, in _thread_loop\r\n    batch = self._dataset_fetcher.fetch(indices,\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/dataloader/fetcher.py\", line 121, in fetch\r\n    data.append(self.dataset[idx])\r\n  File \"/home/xieyunyao/Desktop/MasterProject/PP_other/my_ImageNet/paddlevision/datasets/folder.py\", line 247, in __getitem__\r\n    sample = self.transform(sample)\r\n  File \"/home/xieyunyao/Desktop/MasterProject/PP_other/my_ImageNet/presets.py\", line 26, in __call__\r\n    return self.transforms(img)\r\n  File \"/home/xieyunyao/Desktop/MasterProject/PP_other/my_ImageNet/paddlevision/transforms/transforms.py\", line 47, in __call__\r\n    img = t(img)\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xieyunyao/Desktop/MasterProject/PP_other/my_ImageNet/paddlevision/transforms/transforms.py\", line 354, in forward\r\n    i, j, h, w = self.get_params(img, self.scale, self.ratio)\r\n  File \"/home/xieyunyao/Desktop/MasterProject/PP_other/my_ImageNet/paddlevision/transforms/transforms.py\", line 312, in get_params\r\n    log_ratio = paddle.log(paddle.to_tensor(ratio))\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 227, in __impl__\r\n    assert in_dygraph_mode(\r\nAssertionError: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\r\n",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2022-01-30T11:43:46+00:00",
        "updated_at": "2022-02-08T10:06:47+00:00",
        "closed_at": "2022-02-08T10:06:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5477,
        "title": "用x2paddle转换onnx2paddle得到的模型如何处理得到支持量化的模型",
        "body": "x2paddle转换onnx2paddle得到模型`model.pdiparams  model.pdiparams.info  model.pdmodel model.pdparams`这几个模型文件。请问如何操作可以得到可以做离线量化的模型呢？谢谢",
        "state": "open",
        "user": "vicwer",
        "closed_by": null,
        "created_at": "2022-03-02T09:27:52+00:00",
        "updated_at": "2024-02-26T05:08:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5498,
        "title": "如何在自己的视频上使用nextvlad？",
        "body": "先感谢一下辛苦的开发人员~\r\n我想在自己的视频上跑一下nextvlad，但是我发现这个需要读取一个.pickle文件，这个文件应该是百度自己把youtube8m测试集转码的格式吧？\r\n想问问如果想在自己的视频上跑一下，我要怎么做呢？（版本，code什么的都已经ready了）",
        "state": "open",
        "user": "YilanWang",
        "closed_by": null,
        "created_at": "2022-04-07T10:50:57+00:00",
        "updated_at": "2024-02-26T05:08:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5500,
        "title": "face_detection training经常出现loss=nan",
        "body": "face_detection training经常出现loss=nan，我上载了cpu 模式, batch_size=1的log，gpu模式也碰到过loss=nan\r\n[Paddle-models-train.log](https://github.com/PaddlePaddle/models/files/8493465/Paddle-models-train.log)\r\n",
        "state": "open",
        "user": "lishu2016",
        "closed_by": null,
        "created_at": "2022-04-15T02:30:23+00:00",
        "updated_at": "2024-02-26T05:08:09+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5485,
        "title": "Human Pose Estimation 项目中 wget 连接失效 ",
        "body": "\r\n问题现象：\r\n对应的项目连接：[Human Pose Estimation](https://github.com/PaddlePaddle/models/tree/v1.8.0/PaddleCV/human_pose_estimation#prepare-datasets-and-pretrained-models)\r\n\r\n执行 wget 错误效果如下：\r\n`wget http://paddle-imagenet-models.bj.bcebos.com/resnet_50_model.tar`\r\n\r\n![277cfa49dd7e9e645891f74aee83a7e](https://user-images.githubusercontent.com/30424804/157226669-27301832-ecc3-4179-afa6-40c772166fb4.png)\r\n\r\n期望结果：提供正确的 url 地址",
        "state": "open",
        "user": "leaf0412",
        "closed_by": null,
        "created_at": "2022-03-08T11:10:08+00:00",
        "updated_at": "2024-02-26T05:08:12+00:00",
        "closed_at": null,
        "comments_count": [
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5512,
        "title": "有没有独立于框架的FCEnet的复现？",
        "body": null,
        "state": "open",
        "user": "Contincode",
        "closed_by": null,
        "created_at": "2022-05-08T07:21:02+00:00",
        "updated_at": "2024-02-26T05:08:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5508,
        "title": "AssertionError: Given weight dir /home/b308/hao/models-develop/dygraph/bmn/checkpoint/bmn.pdparams not exist.",
        "body": "(czk) b308@b308:~/hao/models-develop/dygraph/bmn$ python eval.py --weights=checkpoint/bmn.pdparams\r\n[INFO: config_utils.py:   80]: ----------------  Test Arguments ----------------\r\n[INFO: config_utils.py:   82]: MODEL:\r\n[INFO: config_utils.py:   84]:     name:BMN\r\n[INFO: config_utils.py:   84]:     tscale:100\r\n[INFO: config_utils.py:   84]:     dscale:100\r\n[INFO: config_utils.py:   84]:     feat_dim:400\r\n[INFO: config_utils.py:   84]:     prop_boundary_ratio:0.5\r\n[INFO: config_utils.py:   84]:     num_sample:32\r\n[INFO: config_utils.py:   84]:     num_sample_perbin:3\r\n[INFO: config_utils.py:   84]:     anno_file:./activitynet_1.3_annotations.json\r\n[INFO: config_utils.py:   84]:     feat_path:./fix_feat_100\r\n[INFO: config_utils.py:   82]: TRAIN:\r\n[INFO: config_utils.py:   84]:     subset:train\r\n[INFO: config_utils.py:   84]:     epoch:9\r\n[INFO: config_utils.py:   84]:     batch_size:16\r\n[INFO: config_utils.py:   84]:     num_threads:8\r\n[INFO: config_utils.py:   84]:     use_gpu:True\r\n[INFO: config_utils.py:   84]:     num_gpus:4\r\n[INFO: config_utils.py:   84]:     learning_rate:0.001\r\n[INFO: config_utils.py:   84]:     learning_rate_decay:0.1\r\n[INFO: config_utils.py:   84]:     lr_decay_iter:4200\r\n[INFO: config_utils.py:   84]:     l2_weight_decay:0.0001\r\n[INFO: config_utils.py:   82]: VALID:\r\n[INFO: config_utils.py:   84]:     subset:validation\r\n[INFO: config_utils.py:   84]:     batch_size:16\r\n[INFO: config_utils.py:   84]:     num_threads:8\r\n[INFO: config_utils.py:   84]:     use_gpu:True\r\n[INFO: config_utils.py:   84]:     num_gpus:4\r\n[INFO: config_utils.py:   82]: TEST:\r\n[INFO: config_utils.py:   84]:     subset:validation\r\n[INFO: config_utils.py:   84]:     batch_size:1\r\n[INFO: config_utils.py:   84]:     num_threads:1\r\n[INFO: config_utils.py:   84]:     snms_alpha:0.001\r\n[INFO: config_utils.py:   84]:     snms_t1:0.5\r\n[INFO: config_utils.py:   84]:     snms_t2:0.9\r\n[INFO: config_utils.py:   84]:     output_path:output/EVAL/BMN_results\r\n[INFO: config_utils.py:   84]:     result_path:evaluate_results\r\n[INFO: config_utils.py:   82]: INFER:\r\n[INFO: config_utils.py:   84]:     subset:test\r\n[INFO: config_utils.py:   84]:     batch_size:1\r\n[INFO: config_utils.py:   84]:     num_threads:1\r\n[INFO: config_utils.py:   84]:     snms_alpha:0.4\r\n[INFO: config_utils.py:   84]:     snms_t1:0.5\r\n[INFO: config_utils.py:   84]:     snms_t2:0.9\r\n[INFO: config_utils.py:   84]:     filelist:./infer.list\r\n[INFO: config_utils.py:   84]:     output_path:output/INFER/BMN_results\r\n[INFO: config_utils.py:   84]:     result_path:predict_results\r\n[INFO: config_utils.py:   85]: -------------------------------------------------\r\nW0427 14:50:08.213558  6388 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW0427 14:50:08.214612  6388 device_context.cc:465] device: 0, cuDNN Version: 8.0.\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 220, in <module>\r\n    test_bmn(args)\r\n  File \"eval.py\", line 143, in test_bmn\r\n    args.weights)\r\nAssertionError: Given weight dir checkpoint/bmn.pdparams not exist.\r\n\r\n使用的是动态图进行验证，我可以确定权重文件夹存在，权重文件夹放在/models-develop/dygraph/bmn/checkpoint中，但运行之后系统报给的文件夹不存在。想询问下我这个是哪里除了问题？",
        "state": "open",
        "user": "haohaichao",
        "closed_by": null,
        "created_at": "2022-04-27T08:52:09+00:00",
        "updated_at": "2024-02-26T05:08:08+00:00",
        "closed_at": null,
        "comments_count": [
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5501,
        "title": "首页飞桨模型库技术交流群二维码已经过期",
        "body": "请更新；\r\n另外，请注明是微信还是QQ群，方便用户加群。",
        "state": "closed",
        "user": "onecatcn",
        "closed_by": "D-DanielYang",
        "created_at": "2022-04-18T05:32:32+00:00",
        "updated_at": "2022-11-29T05:11:04+00:00",
        "closed_at": "2022-11-29T05:11:04+00:00",
        "comments_count": [
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5514,
        "title": "comparision bewteen Nextvlad and TSM",
        "body": "我好奇Nextvlad在其他数据集上的表现，但是网上只有youtube的，请问有哪位大神比较过nexvlad和TSM在相同数据集上的表现嘛\r\n感谢",
        "state": "open",
        "user": "bendanzzc",
        "closed_by": null,
        "created_at": "2022-05-09T14:27:53+00:00",
        "updated_at": "2024-02-26T05:08:04+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5510,
        "title": "compat tf2pkl.py  to tensorflow2.x",
        "body": null,
        "state": "open",
        "user": "Hanson-Chan",
        "closed_by": null,
        "created_at": "2022-05-06T02:33:38+00:00",
        "updated_at": "2024-02-26T05:08:06+00:00",
        "closed_at": null,
        "comments_count": [
            "Hanson-Chan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5537,
        "title": "The pre-trained dataset of DeepASR cannot be downloaded.",
        "body": "The urls in 'DeepASR/examples/aishell/prepare_data.sh' are invalid, is there any other way to download the model?",
        "state": "open",
        "user": "Zsongyuan",
        "closed_by": null,
        "created_at": "2022-07-04T08:47:21+00:00",
        "updated_at": "2024-02-26T05:08:02+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5515,
        "title": "Optimizer file [/.paddle/weights/BMN.pdopt] not exits",
        "body": "predict运行过程中，优化器文件不存在",
        "state": "open",
        "user": "wkIDFCK",
        "closed_by": null,
        "created_at": "2022-05-10T09:19:12+00:00",
        "updated_at": "2024-02-26T05:08:03+00:00",
        "closed_at": null,
        "comments_count": [
            "Chaxigo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5538,
        "title": "在nuscenes上训练SMOKE模型",
        "body": "在nuscenes数据集上训练smoke模型 我做了如下修改：\r\n在train_val_kitti.yaml中修改depth_ref和dim_ref（平均和std的深度、每个类别的长宽高都进行了修改）：\r\n![image](https://user-images.githubusercontent.com/67692069/179715831-b265e213-1e4f-428b-8497-650135e3dc94.png)\r\n在kitti.py文件中：\r\n![image](https://user-images.githubusercontent.com/67692069/179716160-e2468087-44c5-4fb1-bc03-a36d1f6a137a.png)\r\n![image](https://user-images.githubusercontent.com/67692069/179716247-4cd6520e-23fa-4345-9380-e8a46deba75b.png)\r\n![image](https://user-images.githubusercontent.com/67692069/179716414-09758963-4df8-4587-8216-5525e7ef16f1.png)\r\n但是检测的效果并不好 车辆离得很近的时候 朝向角会明显偏的厉害 \r\n如下图所示：\r\n![image](https://user-images.githubusercontent.com/67692069/179716952-9c907d30-8849-463e-ad0b-6e4f21e6f3e9.png)\r\n![image](https://user-images.githubusercontent.com/67692069/179717541-22363e4c-2dd3-4ac9-af3e-a70d5b01f845.png)\r\n![image](https://user-images.githubusercontent.com/67692069/179717634-f548517b-d9cb-4897-985e-d85f7cb16ab3.png)\r\n想请教一下  \r\n1这样的情况可能是什么导致的呢 \r\n2 训练自定义数据集 除了我上面提到的地方 还有什么要修改的地方吗\r\n",
        "state": "open",
        "user": "tong1311",
        "closed_by": null,
        "created_at": "2022-07-19T09:32:07+00:00",
        "updated_at": "2025-03-14T08:19:07+00:00",
        "closed_at": null,
        "comments_count": [
            "clw5180",
            "rlczddl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5539,
        "title": "【提问】关于使用PaddlePaddle SMOKE模型进行对象检测时的cam_info参数的疑惑",
        "body": "大家好：\r\n\r\n如题，在使用PaddlePaddle SMOKE进行物体识别时，除了需要传入`img`外，还需要传入一个`cam_info`参数，从代码中可以看到，`cam_info`包含了一个硬编码的矩阵`K`。\r\nhttps://github.com/PaddlePaddle/models/blob/0173b12c3974de44b0bdeb06802d6f27cb66dc65/PaddleCV/3d_vision/SMOKE/test.py#L66-L75\r\n\r\n我的疑惑是，这个K矩阵是如何计算出的？使用SMOKE的[官方实现](https://github.com/lzccccc/SMOKE/blob/bc5d2bba66e2d66fa56b7b599d55457cb1a05b33/smoke/engine/inference.py#L11-L29)进行物体识别时并不需要传入这样的一个矩阵。\r\n\r\n目前，我猜测这是为了兼容不同数据集而引入的一个特定于数据集的坐标转换矩阵，但从维度和数值来看，和训练PaddlePaddle SMOKE时使用的KITTI的数值标定矩阵似乎也并不相符？\r\n\r\n请教 @michaelowenliu  :)",
        "state": "open",
        "user": "Creling",
        "closed_by": null,
        "created_at": "2022-07-22T14:48:18+00:00",
        "updated_at": "2024-02-26T05:07:59+00:00",
        "closed_at": null,
        "comments_count": [
            "mikasazgx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5541,
        "title": " generate_sequence_by_rnn_lm",
        "body": "这个模型要求的paddle版本是0.10.0，都没下载资源了== ",
        "state": "open",
        "user": "WaterLemonade",
        "closed_by": null,
        "created_at": "2022-08-20T09:36:37+00:00",
        "updated_at": "2024-02-26T05:07:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5544,
        "title": "train_val_kitti.yaml中的dim_ref是什么含义？",
        "body": "train_val_kitti.yaml中的dim_ref是什么含义，各项数值是怎么来的？如果换成其他数据集，应该怎样填写数值？",
        "state": "open",
        "user": "Bingoang",
        "closed_by": null,
        "created_at": "2022-09-25T00:15:59+00:00",
        "updated_at": "2024-02-26T05:07:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5540,
        "title": "提供的这几个预训练模型链接全部失效了",
        "body": "![image](https://user-images.githubusercontent.com/85534457/183591546-120482e2-d18b-4d24-867d-8249c6667113.png)\r\n",
        "state": "open",
        "user": "caidou05",
        "closed_by": null,
        "created_at": "2022-08-09T07:35:32+00:00",
        "updated_at": "2024-02-26T05:07:58+00:00",
        "closed_at": null,
        "comments_count": [
            "caidou05",
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5542,
        "title": "ocr 竖排文本 和长文本",
        "body": "我不想要竖排文本和长文本识别怎么设置! 目前用的paddlehub 的chpp ocrv3\r\n![image](https://user-images.githubusercontent.com/47367844/187620724-658aef50-5d9c-4831-a32b-e3d8ad3c43ee.png)\r\n",
        "state": "open",
        "user": "Geralt02",
        "closed_by": null,
        "created_at": "2022-08-31T07:38:42+00:00",
        "updated_at": "2024-02-26T05:07:55+00:00",
        "closed_at": null,
        "comments_count": [
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5545,
        "title": "导出模型时，发现有些维数是？号",
        "body": "使用下面指令导出模型\r\n`\r\nexport PYTHONPATH=\"$PWD\"\r\npython deploy/export.py --config configs/test_export.yaml --model_path model_export/model_kitti.pdparams\r\n`\r\n得到的模型如图所示，有些维数没有指定，是？号，是什么原因？\r\n![Screenshot from 2022-09-26 19-25-27](https://user-images.githubusercontent.com/10301777/192265993-7c18049b-e9e9-49f6-aaed-d4cd648d5b18.png)\r\n\r\n\r\n这个模型应该不能使用吧？",
        "state": "open",
        "user": "hitbuyi",
        "closed_by": null,
        "created_at": "2022-09-26T11:32:15+00:00",
        "updated_at": "2024-02-26T05:07:53+00:00",
        "closed_at": null,
        "comments_count": [
            "lugimzzz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5551,
        "title": " 【笔误】models/tutorials/reprod_log/README.md ",
        "body": "models/tutorials/reprod_log/README.md 的文件中 \"compare_forward 用于对比网络的反向过程，其参数为\" 这句话中应该是“前向过程” 吧？ 偶然看到了，这里提交一个issue",
        "state": "open",
        "user": "arrayofstar",
        "closed_by": null,
        "created_at": "2022-11-01T14:04:51+00:00",
        "updated_at": "2024-02-26T05:07:52+00:00",
        "closed_at": null,
        "comments_count": [
            "D-DanielYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5680,
        "title": "NULL",
        "body": "![DeepCFD 模型@3x](https://user-images.githubusercontent.com/23690325/204209896-75ce0e7a-591a-45b6-8c71-cf9ec1a7fd8e.png)\r\n![ERNIE 3 0@3x](https://user-images.githubusercontent.com/23690325/204210074-797eb581-adb6-4239-9b4f-81c53ef84fe8.png)\r\n![ERNIE 3 0 Zeus@3x](https://user-images.githubusercontent.com/23690325/204210223-7f861d21-8d91-492b-9e27-ba1075105ae1.png)\r\n![ERNIE-Layout@3x](https://user-images.githubusercontent.com/23690325/204210234-3e0ad7d5-7387-4e74-a295-07181ebb77dd.png)\r\n![ERNIE-M@3x](https://user-images.githubusercontent.com/23690325/204210256-19abcc56-a2e6-41ae-8df7-4d27e2a76711.png)\r\n![ERNIE-UIE@3x](https://user-images.githubusercontent.com/23690325/204210272-85def4db-a543-4344-b07f-94c2e3a154c0.png)\r\n![ERNIE-ViLG@3x](https://user-images.githubusercontent.com/23690325/204210290-43058fd2-898c-4ef4-a5d3-fdcc62c8efc2.png)\r\n![PINN_CFD@3x](https://user-images.githubusercontent.com/23690325/204210395-b8c1f5ff-cfea-4e3c-8e41-cd9bcf6acd56.png)\r\n![PP-ASR@3x](https://user-images.githubusercontent.com/23690325/204210409-7b66c4a3-dbee-46e9-a688-335da427c060.png)\r\n![PP-HelixFold@3x](https://user-images.githubusercontent.com/23690325/204210442-86e39d43-ecda-4a72-b035-b912e6eb9b9e.png)\r\n============10==============\r\n![PP-HGNet@3x](https://user-images.githubusercontent.com/23690325/204210516-da473832-6872-4e5a-a871-b280ee62975d.png)\r\n![PP-HumanSegV2@3x](https://user-images.githubusercontent.com/23690325/204210529-35d7087a-8b81-48f7-9ad0-d95cbb88babf.png)\r\n![PP-HumanV2@3x](https://user-images.githubusercontent.com/23690325/204210545-e0df3d2f-e10d-45b6-aace-81ba9eed6bad.png)\r\n![PP-LCNet@3x](https://user-images.githubusercontent.com/23690325/204210567-ca028af1-ba4c-4232-b046-8dd8cad444eb.png)\r\n![PP-LCNetv2@3x](https://user-images.githubusercontent.com/23690325/204210580-d529f9cc-7dbd-4622-9b78-fe5e2b3e5f4a.png)\r\n![PP-LiteSeg@3x](https://user-images.githubusercontent.com/23690325/204210611-510b46fa-cebd-4020-91ce-b4cb0ce07bee.png)\r\n![PP-Matting@3x](https://user-images.githubusercontent.com/23690325/204210637-bb5bfdad-e280-4d87-8fff-c0b264e7f1d3.png)\r\n![PP-MSVSR@3x](https://user-images.githubusercontent.com/23690325/204210648-afac71eb-e86c-41bb-8288-39e887ba71f0.png)\r\n![PP-OCRv2@3x](https://user-images.githubusercontent.com/23690325/204210676-6bc7a5c3-bc4b-4129-ac5c-5cdf7edd7dc8.png)\r\n![PP-OCRv3@3x](https://user-images.githubusercontent.com/23690325/204210696-ef11e601-87fe-4b2d-9df0-42aa4050fda1.png)\r\n===============20=====================\r\n![PP-Picodet@3x](https://user-images.githubusercontent.com/23690325/204210764-257ab080-273e-470a-baf4-a0e924242f1a.png)\r\n![PP-shiTu@3x](https://user-images.githubusercontent.com/23690325/204210779-12ff299e-b8f4-48f3-83ba-d8f3d10cab4e.png)\r\n![PP-ShiTuV2@3x](https://user-images.githubusercontent.com/23690325/204210790-4f6ea5d2-89dc-4c28-b044-418cc2199db9.png)\r\n![PP-StructureV2@3x](https://user-images.githubusercontent.com/23690325/204210800-976f5d12-714d-4171-b54e-14bd39bab89f.png)\r\n![PP-TinyPose@3x](https://user-images.githubusercontent.com/23690325/204210827-acc0c23c-fa01-43c1-b260-d7daf2ffeae4.png)\r\n![PP-TSM@3x](https://user-images.githubusercontent.com/23690325/204210847-18a4dc67-b1ab-445e-8b84-e8ac61638375.png)\r\n![PP-TTS@3x](https://user-images.githubusercontent.com/23690325/204210890-e341d784-529d-47a1-8014-026bbf45114f.png)\r\n![PP-Vehicle@3x](https://user-images.githubusercontent.com/23690325/204210913-b0abfd94-1d7a-474a-b012-7ba06ca3590f.png)\r\n![PP-YOLO@3x](https://user-images.githubusercontent.com/23690325/204210935-61e990cc-2bb0-4578-bace-bdb31e0fc287.png)\r\n![PP-YOLOE@3x](https://user-images.githubusercontent.com/23690325/204210957-b79603db-1406-4e0b-afa9-3745e9e69ff1.png)\r\n================30===============\r\n![PP-YOLOE+@3x](https://user-images.githubusercontent.com/23690325/204210973-2d21766d-04e0-46c8-8c9d-439ac203b05d.png)\r\n![PP-YOLOv2@3x](https://user-images.githubusercontent.com/23690325/204210980-9ee0f09b-f5bc-4515-b0f8-86450d2b3498.png)\r\n![PQ-VSDL@3x](https://user-images.githubusercontent.com/23690325/204210998-f3e40918-6654-4780-98f4-58eb8353b33b.png)\r\n![VIMER-CAE1 0@3x](https://user-images.githubusercontent.com/23690325/204211143-852a7bae-8fe4-47d2-a465-c16167745efa.png)\r\n![VIMER-UFO2 0@3x](https://user-images.githubusercontent.com/23690325/204211162-a49335b0-e15b-4dcd-9aa1-729c4b7959cf.png)\r\n===============35==================\r\n![z-community@3x](https://user-images.githubusercontent.com/23690325/204211315-240bfe30-51fb-4f96-9797-12dcc36d10d3.png)\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "D-DanielYang",
        "closed_by": "D-DanielYang",
        "created_at": "2022-11-28T06:46:53+00:00",
        "updated_at": "2022-11-28T06:47:15+00:00",
        "closed_at": "2022-11-28T06:47:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5694,
        "title": "说明文档和下载的代码不一样",
        "body": "遇见过好几次了，文档和下载的代码完全不一样，文档都不更新吗？？？",
        "state": "open",
        "user": "tai960519073",
        "closed_by": null,
        "created_at": "2022-12-24T12:12:48+00:00",
        "updated_at": "2024-02-26T05:07:49+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5696,
        "title": "希望能够给这个页面加一个目录，要不然从上往下翻非常不方便",
        "body": "https://github.com/PaddlePaddle/models/blob/release/2.4/docs/official/README.md\r\n\r\n祝好~",
        "state": "open",
        "user": "we-enjoy-today",
        "closed_by": null,
        "created_at": "2023-01-03T06:37:34+00:00",
        "updated_at": "2024-02-26T05:07:48+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle3D",
        "number": 162,
        "title": "About training SMOKE on waymo.",
        "body": "Hi, Can you give some information about the training configuration(total_epoch, data agumentation, lr schedule) of smoke model on the waymo dataset? Many Thanks.",
        "state": "closed",
        "user": "JiSuanJiDaWang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-17T08:43:30+00:00",
        "updated_at": "2025-02-04T06:39:54+00:00",
        "closed_at": "2025-02-04T06:39:54+00:00",
        "comments_count": [
            "thinkthinking",
            "JiSuanJiDaWang",
            "Lyric0620",
            "nepeplwu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5638,
        "title": "pr",
        "body": "怎么 一个pr 同时修改多个文件",
        "state": "open",
        "user": "cinderellaTiger",
        "closed_by": null,
        "created_at": "2022-11-22T05:28:07+00:00",
        "updated_at": "2024-02-26T05:07:50+00:00",
        "closed_at": null,
        "comments_count": [
            "thinkthinking",
            "cinderellaTiger"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5715,
        "title": "win10-paddleSpeech，语音识别报错 ImportError: cannot import name 'load' from 'paddleaudio.backends'",
        "body": "环境win10，python 3.10.9（anaconda）\r\n执行语音识别的测试代码如下：\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\n \r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\n\r\n报错信息如下：\r\nPS C:\\Users\\Administrator> & D:/ProgramData/Anaconda3/envs/ftn/python.exe c:/Users/Administrator/padddleSpeech.py\r\nD:\\ProgramData\\Anaconda3\\envs\\ftn\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\n  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\n[nltk_data] Error loading averaged_perceptron_tagger: Remote end\r\n[nltk_data]     closed connection without response\r\n[nltk_data] Downloading package cmudict to\r\n[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\r\n[nltk_data]   Unzipping corpora\\cmudict.zip.\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\Administrator\\padddleSpeech.py\", line 1, in <module>\r\n    from paddlespeech.cli.asr.infer import ASRExecutor\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\ftn\\lib\\site-packages\\paddlespeech\\cli\\__init__.py\", line 24, in <module>\r\n    from .vector import VectorExecutor\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\ftn\\lib\\site-packages\\paddlespeech\\cli\\vector\\__init__.py\", line 14, in <module>\r\n    from .infer import VectorExecutor\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\ftn\\lib\\site-packages\\paddlespeech\\cli\\vector\\infer.py\", line 25, in <module>\r\n    from paddleaudio.backends import load as load_audio\r\nImportError: cannot import name 'load' from 'paddleaudio.backends' (D:\\ProgramData\\Anaconda3\\envs\\ftn\\lib\\site-packages\\paddleaudio\\backends\\__init__.py)",
        "state": "open",
        "user": "jiaozn",
        "closed_by": null,
        "created_at": "2023-02-02T02:29:23+00:00",
        "updated_at": "2024-02-26T05:07:46+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5713,
        "title": "在跑官方教程手写数字识别任务时，loss全为0",
        "body": "![image](https://user-images.githubusercontent.com/109579348/213447914-11af4b9f-f528-4729-ba34-23e35e00832f.png)\r\n",
        "state": "open",
        "user": "hhhqqqhhhqqq",
        "closed_by": null,
        "created_at": "2023-01-19T12:53:27+00:00",
        "updated_at": "2024-02-26T05:07:47+00:00",
        "closed_at": null,
        "comments_count": [
            "hhhqqqhhhqqq"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleNLP",
        "number": 4146,
        "title": "阅读理解数据预处理，cpu版本正常，GPU出现 AttributeError: 'DataLoader' object has no attribute 'prefetch_factor'",
        "body": "阅读理解数据预处理，cpu2.3.2版本正常，paddle-GPU2.3.2出现 AttributeError: 'DataLoader' object has no attribute 'prefetch_factor'\r\n由于输入数据是dict类型，所以数据导入用的是datasets.Dataset.from_dict(res_dict)\r\n    res_dict = {\r\n        \"id\": [\"0\", \"1\", \"2\"],\r\n        \"question\": [\"崂山在哪\", \"崂山在哪\", \"崂山在哪\"],\r\n        \"context\": [\r\n            \"东、南濒黄海，西邻青岛市市南区、市北区，西北邻李沧区，北接青岛市城阳区和即墨区。辖区陆域面积395.8平方公里，海域面积3700平方公里，海岸线长103.7公里【摘要】崂山在青岛哪里【提问】您好！崂山区是山东省青岛市辖区...\",\r\n            \"1994年2月，被列为全国15个副省级城市之一（其中省会十个，非省会五个）。2008年末全市户籍总人口为761.56万人，其中市区1159平方公里，人口276.25万人；五市（县级）485.3万人。 特产：崂山石、\\\"西施舌\\\"海贝、胶州湾...\",\r\n            \"崂山景区为国家级风景名胜区、国家AAAAA级旅游景区、国家级森林公园、爱国主义教育基地。崂山古称牢山、劳山。坐落在山东半岛的东南，西靠青岛，东南两面濒临黄海。面积386平方公里，崂顶巨峰，海拔1，133米。既是中国道教名山，...\"]\r\n    }\r\n请问我是否该修改数据加载的方法，用何种方法合适？",
        "state": "closed",
        "user": "0sxw0",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-01T11:15:10+00:00",
        "updated_at": "2024-09-17T06:36:13+00:00",
        "closed_at": "2024-09-17T06:36:13+00:00",
        "comments_count": [
            "Eason-zz"
        ],
        "labels": [
            "triage"
        ]
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5734,
        "title": "模型滤波器问题",
        "body": "您好，我在替换某个卷积模块之后，出现了下面的报错，实在解决不出来\r\nValueError: (InvalidArgument) The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 704, the input's shape is [4, 704, 168, 168]; the filter's channels is 448, the filter's shape is [64, 448, 1, 1]; the groups is 1, the data_format is NCHW. The error may come from wrong data_format setting.\r\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:704 != filter_dims[1] * groups:448.] (at ../paddle/phi/infermeta/binary.cc:534)",
        "state": "open",
        "user": "todesti2",
        "closed_by": null,
        "created_at": "2023-08-09T08:41:53+00:00",
        "updated_at": "2024-02-26T05:07:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5729,
        "title": "问一下resnet50_vd_ssld的教师模型和学生模型分别是哪个",
        "body": "问一下resnet50_vd_ssld的教师模型和学生模型分别是哪个",
        "state": "open",
        "user": "linxiaodan-bit",
        "closed_by": null,
        "created_at": "2023-03-03T14:12:03+00:00",
        "updated_at": "2024-02-26T05:07:44+00:00",
        "closed_at": null,
        "comments_count": [
            "linxiaodan-bit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5735,
        "title": "paddle LAC模型输出模型报告问题。",
        "body": "您好，我在使用LAC实体提取模型，训练后像输出模型报告遇到了问题，他的真实序列和预测序列好像和训练模型的标签不太一致，有什么好的建议么？\r\n![964b1ea4dab66cda01dbd100fea9d21](https://github.com/PaddlePaddle/models/assets/110172520/624ce3c9-1bdc-40e0-8294-0cf46feaa857)\r\n",
        "state": "closed",
        "user": "rap8",
        "closed_by": "rap8",
        "created_at": "2023-08-15T03:17:55+00:00",
        "updated_at": "2023-08-15T06:41:21+00:00",
        "closed_at": "2023-08-15T06:41:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5737,
        "title": "Compiled with WITH_GPU, but no GPU found in runtime",
        "body": "![image](https://github.com/PaddlePaddle/models/assets/107621428/42f9c736-e79a-4ac3-aea0-2370c3afcb36)\r\nFROM paddlepaddle/paddle:2.4.2-gpu-cuda11.7-cudnn8.4-trt8.4\r\nI have used above image as base image.\r\n\r\nRUN python -m pip install --no-cache-dir paddlepaddle-gpu==2.4.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\r\n\r\nI am using above versionof paddle only because I get error during export to onnx with other versions. https://github.com/PaddlePaddle/Paddle2ONNX/issues/1147\r\n\r\nThe code runs fine while running on my local gpu but in ml.p2.xlarge instance with aws docker sagemaker i get the above error, tried with many combinations of images still same issue, can you help me with this?",
        "state": "open",
        "user": "mahesh11T",
        "closed_by": null,
        "created_at": "2023-09-11T06:15:40+00:00",
        "updated_at": "2024-02-26T05:07:42+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5739,
        "title": "自定义切词错误",
        "body": "from LAC import LAC, custom\r\n\r\nlac = LAC()\r\nlac.model.custom = custom.Customization()\r\n\r\nlac.model.custom.add_word('中华人民共和国/国家')\r\nlac.model.custom.add_word('国2/标准')\r\nprint(lac.run('中华人民共和国2008年奥运会'))\r\n\r\n// 返回 [['中华人民共和', '国2', '008年', '奥运会'], ['国家', '标准', 'TIME', 'nz']]",
        "state": "open",
        "user": "guoandzhong",
        "closed_by": null,
        "created_at": "2023-11-09T09:20:01+00:00",
        "updated_at": "2024-02-26T05:07:39+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5738,
        "title": "paddle fleet分布式框架 设置参数不同学习率时报错",
        "body": "paddle版本： 2.2.1.\r\n背景： 多任务学习中，同一个backbone模型有不同的头学习不同的任务， 期望各个头fc层的学习率可以不一样，但是设置的时候会有如下错误：\r\n错误信息如下：\r\nTraceback (most recent call last):\r\n  File \"run_batch_fine_grained.py\", line 466, in <module>\r\n    train(args)\r\n  File \"run_batch_fine_grained.py\", line 283, in train\r\n    optimizer.minimize(loss)\r\n  File \"/py37/lib/python3.7/site-packages/paddle/distributed/fleet/base/fleet_base.py\", line 1501, in minimize\r\n    loss, startup_program, parameter_list, no_grad_set=no_grad_set)\r\n  File \"/py37/lib/python3.7/site-packages/paddle/distributed/fleet/meta_optimizers/meta_optimizer_base.py\", line 95, in minimize\r\n    loss, startup_program, parameter_list, no_grad_set)\r\n  File \"/py37/lib/python3.7/site-packages/paddle/distributed/fleet/meta_optimizers/sharding_optimizer.py\", line 516, in minimize_impl\r\n    self._apply_sharding_pass(params_grads)\r\n  File \"/py37/lib/python3.7/site-packages/paddle/distributed/fleet/meta_optimizers/sharding_optimizer.py\", line 295, in _apply_sharding_pass\r\n    self._split_program(main_block)\r\n  File \"/py37/lib/python3.7/site-packages/paddle/distributed/fleet/meta_optimizers/sharding_optimizer.py\", line 746, in _split_program\r\n    assert (int(op.attr('op_role')) != int(OpRole.Optimize))\r\nAssertionError\r\n",
        "state": "open",
        "user": "lwgkzl",
        "closed_by": null,
        "created_at": "2023-09-14T07:01:46+00:00",
        "updated_at": "2024-02-26T05:07:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5740,
        "title": "paddle.where not support auto-broad-casting like tensorflow",
        "body": "ref: https://github.com/google-research/google-research/blob/master/dselect_k_moe/dselect_k_moe.py#L254",
        "state": "open",
        "user": "fooSynaptic",
        "closed_by": null,
        "created_at": "2023-12-20T15:51:05+00:00",
        "updated_at": "2024-02-26T05:07:38+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5742,
        "title": "怎么批量处理视频文件",
        "body": "怎么批量处理视频文件，在输入video_dir时，总是识别不了文件夹中的文件 \r\n(PaddleDetection) PS D:\\03data analysis\\05pedtest2\\PaddleDetection-release-2.6> python deploy/pipeline/pipeline.py --config deploy/pipeline/config/infer_cfg_pphuman.yml --video_dir=in --device=gpu --draw_center_traj --do_break_in_counting --region_type=custom --region_polygon 0 680 1920 680 1920 1080 0 1080\r\nD:\\01software\\04tech\\Anaconda\\envs\\PaddleDetection\\lib\\site-packages\\setuptools\\sandbox.py:13: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n  import pkg_resources\r\nD:\\01software\\04tech\\Anaconda\\envs\\PaddleDetection\\lib\\site-packages\\pkg_resources\\__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nD:\\01software\\04tech\\Anaconda\\envs\\PaddleDetection\\lib\\site-packages\\pkg_resources\\__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nArgsParser(prog='pipeline.py', usage=None, description=None, formatter_class=<class 'argparse.RawDescriptionHelpFormatter'>, conflict_handler='error', add_help=True)\r\n-----------  Running Arguments -----------\r\nATTR:\r\n  batch_size: 8\r\n  enable: false\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/PPLCNet_x1_0_person_attribute_945_infer.zip\r\nDET:\r\n  batch_size: 1\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip\r\nID_BASED_CLSACTION:\r\n  batch_size: 8\r\n  display_frames: 80\r\n  enable: false\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_tiny_calling_halfbody.zip\r\n  skip_frame_num: 2\r\n  threshold: 0.8\r\nID_BASED_DETACTION:\r\n  batch_size: 8\r\n  display_frames: 80\r\n  enable: false\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/ppyoloe_crn_s_80e_smoking_visdrone.zip\r\n  skip_frame_num: 2\r\n  threshold: 0.6\r\nKPT:\r\n  batch_size: 8\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip\r\nMOT:\r\n  batch_size: 1\r\n  enable: true\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip\r\n  skip_frame_num: 0\r\n  tracker_config: deploy/pipeline/config/tracker_config.yml\r\nREID:\r\n  batch_size: 16\r\n  enable: false\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/reid_model.zip\r\nSKELETON_ACTION:\r\n  batch_size: 1\r\n  coord_size:\r\n  - 384\r\n  - 512\r\n  display_frames: 80\r\n  enable: false\r\n  max_frames: 50\r\n  model_dir: https://bj.bcebos.com/v1/paddledet/models/pipeline/STGCN.zip\r\nVIDEO_ACTION:\r\n  batch_size: 1\r\n  enable: false\r\n  frame_len: 8\r\n  model_dir: https://videotag.bj.bcebos.com/PaddleVideo-release2.3/ppTSM_fight.zip\r\n  sample_freq: 7\r\n  short_size: 340\r\n  target_size: 320\r\nattr_thresh: 0.5\r\ncrop_thresh: 0.5\r\nkpt_thresh: 0.2\r\nvisual: true\r\nwarmup_frame: 50\r\n\r\n------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"deploy/pipeline/pipeline.py\", line 1396, in <module>\r\n    main()\r\n  File \"deploy/pipeline/pipeline.py\", line 1380, in main\r\n    pipeline = Pipeline(FLAGS, cfg)\r\n  File \"deploy/pipeline/pipeline.py\", line 87, in __init__\r\n    self.input = self._parse_input(args.image_file, args.image_dir,\r\n  File \"deploy/pipeline/pipeline.py\", line 114, in _parse_input\r\n    assert os.path.exists(\r\nAssertionError: video_file not exists and not an rtsp site.\r\n",
        "state": "open",
        "user": "qxfoxin",
        "closed_by": null,
        "created_at": "2024-04-21T07:30:13+00:00",
        "updated_at": "2024-04-21T07:30:17+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5746,
        "title": "hi help is needed with my cross platform audio upscaller project{mit license }",
        "body": "https://github.com/rajasekarnp1/neural-audio-upscaler",
        "state": "open",
        "user": "rajasekarnp1",
        "closed_by": null,
        "created_at": "2025-05-26T14:03:47+00:00",
        "updated_at": "2025-05-26T14:03:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/models",
        "number": 5741,
        "title": "如何使用模型",
        "body": "fastspeech2_mix_ckpt_0.2.0下载到电脑怎么用？",
        "state": "open",
        "user": "20246688",
        "closed_by": null,
        "created_at": "2024-04-17T02:04:09+00:00",
        "updated_at": "2024-04-17T08:51:13+00:00",
        "closed_at": null,
        "comments_count": [
            "sijunhe"
        ],
        "labels": []
    }
]