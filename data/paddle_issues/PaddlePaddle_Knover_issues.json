[
    {
        "repo": "PaddlePaddle/Knover",
        "number": 15,
        "title": "sh ./scripts/24L_plato_training.sh报错，请帮忙看看是什么原因",
        "body": "我装的paddle版本是1.8.2.post107 paddlehub版本是1.5.3，错误信息如下：\r\nERROR 2020-07-21 14:44:20,106 utils.py:422] ABORT!!! Out of all 2 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nTraceback (most recent call last):\r\n  File \"/home/li.ma/anaconda3/lib/python3.7/site-packages/paddle/distributed/utils.py\", line 406, in watch_local_trainers\r\n    terminate_local_procs(procs)\r\n  File \"/home/li.ma/anaconda3/lib/python3.7/site-packages/paddle/distributed/utils.py\", line 257, in terminate_local_procs\r\n    p.proc.join(timeout=1)\r\nAttributeError: 'Popen' object has no attribute 'join'\r\n\r\n\r\n",
        "state": "closed",
        "user": "mali19064",
        "closed_by": "sserdoubleh",
        "created_at": "2020-07-21T07:00:57+00:00",
        "updated_at": "2020-07-21T09:19:12+00:00",
        "closed_at": "2020-07-21T09:19:12+00:00",
        "comments_count": [
            "sserdoubleh",
            "mali19064",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 7,
        "title": "Undefined name do_test",
        "body": "Hello, \r\n\r\nIn `dialog_reader` found followoing error:\r\n`/Knover/readers/dialog_reader.py:374:73: F821 undefined name 'do_test'`",
        "state": "closed",
        "user": "l3str4nge",
        "closed_by": "sserdoubleh",
        "created_at": "2020-07-12T06:29:11+00:00",
        "updated_at": "2020-07-13T09:06:06+00:00",
        "closed_at": "2020-07-13T09:06:06+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 14,
        "title": "方便透露一下数据的来源吗？",
        "body": "中文数据不开源我可以理解，但透露一下数据的来源没问题吧？\r\n\r\n论文只是简单的提了一下中文数据来自中文的社交媒体，能否具体一点呢？\r\n微博，豆瓣小组，还是百度贴吧？\r\n\r\n不同的来源上文谈话的内容风格和话题差异还是比较大的，希望可以提供一下。\r\n谢谢",
        "state": "open",
        "user": "MashiMaroLjc",
        "closed_by": null,
        "created_at": "2020-07-19T14:48:16+00:00",
        "updated_at": "2021-11-18T03:42:29+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026",
            "DvHuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 11,
        "title": "Cublas Error - CUBLAS_STATUS_EXECUTION_FAILED with interact scipt",
        "body": "Hi, while running the interactive script for both the 24L and 32L models, I faced the following CUBLAS error.\r\nI'm running the script on Ubuntu 18.04 with 4 Tesla T4 16GB GPUs on GCP. \r\n\r\n```shell\r\nW0715 13:57:42.359799 16069 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.0, Runtime API Version: 10.0\r\nW0715 13:57:42.362675 16069 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\nLoad pretraining parameters from ./24L/Plato.\r\nEnter [EXIT] to quit the interaction, [NEXT] to start a new conversation.\r\n[Human]: hey\r\n/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"./interaction.py\", line 83, in <module>\r\n    interact(args)\r\n  File \"./interaction.py\", line 72, in interact\r\n    pred = task.infer_step(model, data)[0]\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/tasks/task_base.py\", line 46, in infer_step\r\n    predictions = model.infer_step(inputs)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/plato.py\", line 243, in infer_step\r\n    return super(Plato, self).infer_step(inputs)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/unified_transformer.py\", line 506, in infer_step\r\n    return self._run_generation(inputs)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/unified_transformer.py\", line 462, in _run_generation\r\n    return_numpy=False)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/model_base.py\", line 258, in _execute\r\n    fetch_vars = self.exe.run(program, feed, fetch_list, return_numpy=return_numpy)\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::GEMM<float>(CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, float, float const*, float const*, float, float*) const\r\n3   void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<float>(paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, float, paddle::framework::Tensor*, float) const\r\n4   paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n5   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n8   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n9   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n10  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n11  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/bakht/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 6414, in matmul\r\n    attrs=attrs)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/plato.py\", line 194, in forward\r\n    latent_emb = layers.matmul(x=weights, y=latent_embeddings, transpose_y=True)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/model_base.py\", line 90, in _build_programs\r\n    outputs = self.forward(inputs, is_infer=True)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/model_base.py\", line 74, in __init__\r\n    self._build_programs()\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/unified_transformer.py\", line 98, in __init__\r\n    super(UnifiedTransformer, self).__init__(args, place)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/plato.py\", line 50, in __init__\r\n    super(Plato, self).__init__(args, place)\r\n  File \"/mnt/disks/disk-huge/bakht/Knover/models/__init__.py\", line 49, in create_model\r\n    return MODEL_REGISTRY[args.model](args, place)\r\n  File \"./interaction.py\", line 54, in interact\r\n    model = models.create_model(args, place)\r\n  File \"./interaction.py\", line 83, in <module>\r\n    interact(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  Cublas error, CUBLAS_STATUS_EXECUTION_FAILED  at (/paddle/paddle/fluid/operators/math/blas_impl.cu.h:34)\r\n  [operator < matmul > error]\r\n```\r\n\r\n",
        "state": "closed",
        "user": "bakszero",
        "closed_by": "sserdoubleh",
        "created_at": "2020-07-15T14:01:01+00:00",
        "updated_at": "2020-07-29T07:13:34+00:00",
        "closed_at": "2020-07-29T07:13:33+00:00",
        "comments_count": [
            "sserdoubleh",
            "bakszero",
            "sserdoubleh",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 21,
        "title": "请问有提供中文的预训练数据模型吗？",
        "body": "你好 非常感谢工作的开源。\r\nPaper里有提到有中文和英文模型，但似乎只在github上找到了英文的开源模型(EN) 所以中文预训练模型会开源吗请问",
        "state": "open",
        "user": "ChenYutongTHU",
        "closed_by": null,
        "created_at": "2020-08-11T13:27:58+00:00",
        "updated_at": "2020-08-13T07:40:52+00:00",
        "closed_at": null,
        "comments_count": [
            "WorldEditors"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 20,
        "title": "没有预训练模型weight吗？",
        "body": "没看懂，模型是英文，还是中文",
        "state": "open",
        "user": "luyifanlu",
        "closed_by": null,
        "created_at": "2020-08-10T13:18:57+00:00",
        "updated_at": "2020-08-13T07:39:53+00:00",
        "closed_at": null,
        "comments_count": [
            "WorldEditors"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 12,
        "title": "Low download speeds for the pretrained models",
        "body": "Hi, first of all, thanks for the really nice work!\r\nI'm facing very low download speeds for the 24L model -- close to 20-30 KB/s using `wget`. Could you please help with an alternative mirror link? Thanks!",
        "state": "closed",
        "user": "bakszero",
        "closed_by": "bakszero",
        "created_at": "2020-07-15T14:10:09+00:00",
        "updated_at": "2020-07-16T07:57:28+00:00",
        "closed_at": "2020-07-16T07:57:28+00:00",
        "comments_count": [
            "portia1026",
            "bakszero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 3,
        "title": "期待更新中文模型",
        "body": "",
        "state": "closed",
        "user": "AnShengqiang",
        "closed_by": "AnShengqiang",
        "created_at": "2020-07-08T05:32:39+00:00",
        "updated_at": "2020-08-10T12:24:03+00:00",
        "closed_at": "2020-07-13T05:52:43+00:00",
        "comments_count": [
            "bojone",
            "Jeff654",
            "terrifyzhao",
            "codelast",
            "bladetornado",
            "bojone",
            "Jeff654",
            "portia1026",
            "portia1026",
            "AnShengqiang",
            "bojone",
            "AnShengqiang",
            "luyifanlu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 17,
        "title": "*_plato_interact.sh bug",
        "body": "https://github.com/PaddlePaddle/Knover/blob/master/plato-2/scripts/24L_plato_interact.sh#L18\r\n这个地方的文件名和使用方式已经修改了，但是这里没有改。\r\n为什么不能提供包含__model__的ckpt下载呢？",
        "state": "closed",
        "user": "kinghuin",
        "closed_by": "sserdoubleh",
        "created_at": "2020-07-31T07:47:15+00:00",
        "updated_at": "2020-08-04T11:25:12+00:00",
        "closed_at": "2020-08-04T11:25:12+00:00",
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 26,
        "title": "We are hiring! Come and join us!",
        "body": "We are looking for interns and motivated researchers & engineers in dialogue systems.\r\nSend your resume to wang.fan@baidu.com if you are interested.",
        "state": "open",
        "user": "WorldEditors",
        "closed_by": null,
        "created_at": "2020-08-13T07:36:07+00:00",
        "updated_at": "2020-08-13T07:36:07+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 25,
        "title": "该plato代码怎么去训练中文模型呢",
        "body": "",
        "state": "open",
        "user": "ShengXiaoXiao",
        "closed_by": null,
        "created_at": "2020-08-13T07:17:06+00:00",
        "updated_at": "2020-08-13T08:24:36+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 22,
        "title": "可以用CPU运行interact吗？",
        "body": "用gpu运行plato-2/scripts/24L_plato_interact.sh是可以的，但是我在没有gpu的机器上安装了cpu版本的paddlepaddle运行时出现问题：\r\nE0811 21:28:37.228886 20545 pybind.cc:1277] Cannot use GPU because you have installed CPU version PaddlePaddle.\r\nIf you want to use GPU, please try to install GPU version PaddlePaddle by: pip install paddlepaddle-gpu\r\nIf you only have CPU, please change CUDAPlace(0) to be CPUPlace().\r\n\r\n我已经尝试把所有的CUDAPlace(0)都替换成了CPUPlace()，请问还有哪不对吗？。\r\n这是git diff的结果：\r\n\r\nhttps://gist.github.com/fancyerii/fa04cea4e94cf9408c5d6091697fd9fa\r\n",
        "state": "closed",
        "user": "fancyerii",
        "closed_by": "fancyerii",
        "created_at": "2020-08-11T13:35:35+00:00",
        "updated_at": "2020-08-14T01:13:32+00:00",
        "closed_at": "2020-08-14T01:13:32+00:00",
        "comments_count": [
            "sserdoubleh",
            "fancyerii"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 24,
        "title": "Context to a conversation in PLATO-2",
        "body": "Is it possible to give a context to the conversation, so that the setting description/persona can be given to the pretrained models beforehand? \r\n\r\nIf not, is there a possibility of incorporating something like this with the pretrained models?",
        "state": "open",
        "user": "bakszero",
        "closed_by": null,
        "created_at": "2020-08-12T14:24:15+00:00",
        "updated_at": "2020-08-13T08:33:58+00:00",
        "closed_at": null,
        "comments_count": [
            "WorldEditors",
            "bakszero",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 27,
        "title": "请问一下论文中的L_{BOW}",
        "body": "根据论文：\r\n![图片](https://user-images.githubusercontent.com/5372812/90515822-c46bd780-e195-11ea-8f07-dd7500e254f8.png)\r\n\r\n我的理解是：topic隐变量z对于的向量h_z乘以W_2，W_2 \\in R^{V \\times D}为每一个词的向量，这样就可以一次计算z和所有词的内积，然后softmax变成概率。然后我们优化的目标是target里出现的词对应的logits大，从而loss小。如果是这样的话，为什么又对f_{r_t}再计算一次softmax呢？\r\n\r\n",
        "state": "closed",
        "user": "fancyerii",
        "closed_by": "fancyerii",
        "created_at": "2020-08-18T13:03:53+00:00",
        "updated_at": "2020-10-30T03:17:59+00:00",
        "closed_at": "2020-08-27T11:52:57+00:00",
        "comments_count": [
            "portia1026",
            "LLLLLLoki",
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 23,
        "title": "Context to a conversation",
        "body": "Is it possible to give a context to the conversation, so that the setting description/persona can be given to the pretrained models beforehand? \r\n\r\nIf not, is there a possibility of incorporating something like this with the pretrained models?",
        "state": "closed",
        "user": "bakszero",
        "closed_by": "bakszero",
        "created_at": "2020-08-12T14:24:00+00:00",
        "updated_at": "2020-08-12T14:25:25+00:00",
        "closed_at": "2020-08-12T14:24:49+00:00",
        "comments_count": [
            "bakszero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 30,
        "title": "NSP任务的代码应该是有问题的，是不是该修复一下了",
        "body": "\r\nmetrics = {}\r\n--\r\n74 | fc_out = self._calc_logits(outputs[\"enc_out\"], inputs[\"tgt_pos\"])\r\n75 | lm_loss = layers.softmax_with_cross_entropy(logits=fc_out, label=inputs[\"tgt_pos\"])\r\n\r\nmodels/nsp_model.py的74行应该是有问题的\r\n参数错误，中间应该还有一个checkpoints参数\r\n然后nsp的forward函数应该和UnifiedTransformer一样有个存checkpoints数据的操作\r\n\r\n另外能给出plato2更具体的训练demo吗\r\n比如给出如何先只训练UnifiedTransformer，如何后续训练nsp和隐状态那个",
        "state": "closed",
        "user": "onewaymyway",
        "closed_by": "sserdoubleh",
        "created_at": "2020-11-04T11:43:54+00:00",
        "updated_at": "2020-11-20T06:13:30+00:00",
        "closed_at": "2020-11-20T06:13:30+00:00",
        "comments_count": [
            "sserdoubleh",
            "onewaymyway",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 29,
        "title": "运行convert_data_to_numerical时需要\"sentence_piece_model\"",
        "body": "请问这个sentence_piece_model是需要自己准备的吗？另外如何使用这个模型的文档可以详细点吗，或者说可能是我自己没找到详细说明的地方。工作很好，不过作为一个新手上手有点困难欸，麻烦解答了，谢谢。",
        "state": "closed",
        "user": "27182812",
        "closed_by": "sserdoubleh",
        "created_at": "2020-10-26T13:40:14+00:00",
        "updated_at": "2020-11-20T06:13:43+00:00",
        "closed_at": "2020-11-20T06:13:43+00:00",
        "comments_count": [
            "sserdoubleh",
            "27182812"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 28,
        "title": "建议把如何从check_point继续训练的方式也在文档里写一下",
        "body": "这个训练一般会持续很久，很可能会断了之后继续训练，所以继续训练也是个刚需。建议把如何继续训练写到文档里面。\r\n\r\n还有就是现在要继续训练要自己在参数里填check_point路径和当前的start_step，这样还是太麻烦了，建议在保存check_point的时候把这个信息保存一下，这样继续训练的时候先检测这个信息，然后自动从上次最后的step开始训练\r\n",
        "state": "closed",
        "user": "onewaymyway",
        "closed_by": "sserdoubleh",
        "created_at": "2020-10-22T02:24:19+00:00",
        "updated_at": "2020-11-20T06:13:22+00:00",
        "closed_at": "2020-11-20T06:13:22+00:00",
        "comments_count": [
            "sserdoubleh",
            "onewaymyway",
            "sserdoubleh",
            "onewaymyway",
            "smartmark-pro",
            "sserdoubleh",
            "sserdoubleh"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 32,
        "title": "the missing full source code of plato-2",
        "body": "Hi thanks for your great work! I explore the plato-2 directory and just found there are .sh files, may I ask where is the .py files? so I could try the chatbot interaction, thanks for your help!",
        "state": "closed",
        "user": "chikiuso",
        "closed_by": "chikiuso",
        "created_at": "2020-11-20T04:22:55+00:00",
        "updated_at": "2020-11-24T09:09:44+00:00",
        "closed_at": "2020-11-24T09:09:44+00:00",
        "comments_count": [
            "sserdoubleh",
            "chikiuso",
            "sserdoubleh",
            "sserdoubleh",
            "chikiuso",
            "sserdoubleh",
            "chikiuso",
            "sserdoubleh",
            "chikiuso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 33,
        "title": "请问NSPModel是如何训练的？",
        "body": "",
        "state": "closed",
        "user": "zhiyingf",
        "closed_by": "zhiyingf",
        "created_at": "2020-11-25T08:39:00+00:00",
        "updated_at": "2021-02-04T02:41:45+00:00",
        "closed_at": "2021-02-04T02:41:45+00:00",
        "comments_count": [
            "fiyen",
            "sserdoubleh",
            "fiyen",
            "zhiyingf",
            "fiyen",
            "zhiyingf",
            "zhiyingf",
            "fiyen",
            "fiyen",
            "zhiyingf",
            "zhiyingf",
            "fiyen",
            "zhiyingf",
            "fiyen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 34,
        "title": "请问use_amp中的amp是什么意思？",
        "body": "",
        "state": "open",
        "user": "fiyen",
        "closed_by": null,
        "created_at": "2020-11-25T15:33:13+00:00",
        "updated_at": "2020-11-26T02:42:25+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 37,
        "title": "请问train.py中是不是只有stage2.1的训练过程？没有看到三个训练过程",
        "body": "![image](https://user-images.githubusercontent.com/49787234/103600663-ea2a2b00-4f42-11eb-9a00-4c90b5eaa420.png)\r\n",
        "state": "open",
        "user": "zhizeng8",
        "closed_by": null,
        "created_at": "2021-01-05T02:44:37+00:00",
        "updated_at": "2021-01-06T03:44:04+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 44,
        "title": "Exception: 'feed_targets' does not have label_pos variable",
        "body": "Traceback (most recent call last):\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/perfectworld/gx/Knover/knover/scripts/interact.py\", line 83, in <module>\r\n    interact(args)\r\n  File \"/home/perfectworld/gx/Knover/knover/scripts/interact.py\", line 70, in interact\r\n    pred = task.infer_step(model, data)[0]\r\n  File \"/home/perfectworld/gx/Knover/knover/core/task.py\", line 46, in infer_step\r\n    outputs = self._post_process_infer_output(predictions)\r\n  File \"/home/perfectworld/gx/Knover/knover/tasks/dialog_generation.py\", line 162, in _post_process_infer_output\r\n    return self._post_process_generation_output(predictions)\r\n  File \"/home/perfectworld/gx/Knover/knover/tasks/dialog_generation.py\", line 91, in _post_process_generation_output\r\n    get_nsp_score_batch(self.nsp_predictor, predictions)\r\n  File \"/home/perfectworld/gx/Knover/knover/tasks/dialog_generation.py\", line 404, in get_nsp_score_batch\r\n    outputs = nsp_predictor(data)\r\n  File \"/home/perfectworld/gx/Knover/knover/utils/inference_utils.py\", line 44, in __predict__\r\n    return_numpy=True)\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1313, in _run_program\r\n    fetch_var_name=fetch_var_name)\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 624, in _add_feed_fetch_ops\r\n    if not has_feed_operators(global_block, feed, feed_var_name):\r\n  File \"/home/perfectworld/anaconda3/envs/dialogue/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 280, in has_feed_operators\r\n    format(feed_target_name))\r\nException: 'feed_targets' does not have label_pos variable\r\n\r\nDear sir, do you meet this problem? How to fix it?",
        "state": "closed",
        "user": "aszxnm",
        "closed_by": "sserdoubleh",
        "created_at": "2021-03-25T07:33:09+00:00",
        "updated_at": "2022-04-21T16:18:28+00:00",
        "closed_at": "2022-04-21T16:18:28+00:00",
        "comments_count": [
            "sserdoubleh",
            "aszxnm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 39,
        "title": "refactor Knover",
        "body": "",
        "state": "closed",
        "user": "sserdoubleh",
        "closed_by": "sserdoubleh",
        "created_at": "2021-02-01T03:55:54+00:00",
        "updated_at": "2021-02-08T07:30:21+00:00",
        "closed_at": "2021-02-08T07:30:21+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 36,
        "title": "为什么train.py比infer.py快的多？",
        "body": "在调用train.py时，batch_size可以设为8000左右，且一步用时在200s左右，而调用infer.py时，batch_size只能设的很小，4，12或更小，超过32就可能爆显存。这与平时的直观经验不一致啊。平时eval模式下应该比train模式下更快，占用内存也更小才对啊。请问是什么原因呢？",
        "state": "open",
        "user": "fiyen",
        "closed_by": null,
        "created_at": "2020-11-30T13:29:59+00:00",
        "updated_at": "2020-12-01T03:01:02+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "fiyen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 45,
        "title": "Plato model infers error!!! The same config for train process is OK, but it fails for inferrence. ",
        "body": "```\r\naistudio@jupyter-208728-1765888:~/Knover$ git branch -av\r\n  develop                      dcf05a0 Support PaddlePaddle 2.0.\r\n* master                       4bad22c Fix checkpoints and add document for continuous training (#31)\r\n  remotes/origin/HEAD          -> origin/develop\r\n  remotes/origin/develop       dcf05a0 Support PaddlePaddle 2.0.\r\n  remotes/origin/dygraph       5a2fbec Support dygraph in PaddlePaddle 2.0 and add lic2021 baseline\r\n  remotes/origin/luge-dialogue 1b03ac1 update score\r\n  remotes/origin/master        4bad22c Fix checkpoints and add document for continuous training (#31)\r\n  remotes/origin/plato-2       4bad22c Fix checkpoints and add document for continuous training (#31)\r\naistudio@jupyter-208728-1765888:~/Knover$ python infer.py --model Plato --task DialogGeneration --vocab_path ./projects/lic2021/conf/vocab.txt --spm_model_file ./projects/lic2021/conf/spm.model --infer_file ./data/lic2021/test.txt --data_format numerical --file_format file --config_path ./projects/lic2021/conf/12L_P.json --init_pretraining_params Plato --batch_size 2 --max_src_len 384 --max_tgt_len 128 --max_seq_len 512 --output_name response --decoding_strategy topk_sampling --do_generation True --num_samples 4 --topk 5 --is_cn True --do_generation true --save_path ./projects/lic2021/infer/output --log_step 10 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n{\r\n  \"is_distributed\": false,\r\n  \"save_path\": \"./projects/lic2021/infer/output\",\r\n  \"infer_file\": \"./data/lic2021/test.txt\",\r\n  \"output_name\": \"response\",\r\n  \"log_steps\": 10,\r\n  \"Model\": {\r\n    \"model\": \"Plato\",\r\n    \"config_path\": \"./projects/lic2021/conf/12L_P.json\",\r\n    \"init_checkpoint\": \"\",\r\n    \"init_pretraining_params\": \"Plato\",\r\n    \"learning_rate\": 1e-05,\r\n    \"warmup_steps\": 0,\r\n    \"weight_decay\": 0.0,\r\n    \"max_grad_norm\": 0.1,\r\n    \"use_recompute\": false,\r\n    \"use_amp\": false,\r\n    \"amp_loss_scaling\": 12800,\r\n    \"max_seq_len\": 512,\r\n    \"weight_sharing\": true,\r\n    \"mem_efficient\": false,\r\n    \"use_bow\": true,\r\n    \"use_entropy\": false,\r\n    \"pre_encoder_cmd\": \"d\",\r\n    \"preprocess_cmd\": \"n\",\r\n    \"postprocess_cmd\": \"da\",\r\n    \"post_cls_cmd\": \"n\",\r\n    \"cls_bias\": true,\r\n    \"attention_probs_dropout_prob\": 0.1,\r\n    \"hidden_act\": \"gelu\",\r\n    \"hidden_dropout_prob\": 0.1,\r\n    \"hidden_size\": 768,\r\n    \"initializer_range\": 0.02,\r\n    \"max_position_embeddings\": 512,\r\n    \"latent_type_size\": 20,\r\n    \"num_attention_heads\": 12,\r\n    \"num_hidden_layers\": 12,\r\n    \"type_vocab_size\": 2,\r\n    \"role_type_size\": 32,\r\n    \"vocab_size\": 30004\r\n  },\r\n  \"Generator\": {\r\n    \"min_dec_len\": 1,\r\n    \"max_dec_len\": 64,\r\n    \"decoding_strategy\": \"topk_sampling\",\r\n    \"temperature\": 1.0,\r\n    \"ignore_unk\": true,\r\n    \"num_samples\": 4,\r\n    \"topk\": 5,\r\n    \"topp\": 0.9,\r\n    \"beam_size\": 10,\r\n    \"length_average\": true,\r\n    \"length_penalty\": 0.0\r\n  },\r\n  \"Task\": {\r\n    \"task\": \"DialogGeneration\",\r\n    \"do_generation\": true,\r\n    \"is_cn\": true,\r\n    \"nsp_inference_model_path\": null,\r\n    \"nsp_attention_style\": \"bidirectional\",\r\n    \"ranking_score\": \"decode_score\"\r\n  },\r\n  \"Reader\": {\r\n    \"max_src_len\": 384,\r\n    \"max_tgt_len\": 128,\r\n    \"truncate_first_turn\": false,\r\n    \"file_format\": \"file\",\r\n    \"data_format\": \"numerical\",\r\n    \"in_tokens\": false,\r\n    \"batch_size\": 2,\r\n    \"continuous_position\": true,\r\n    \"random_seed\": 11,\r\n    \"sort_pool_size\": 65536\r\n  },\r\n  \"Tokenizer\": {\r\n    \"tokenizer\": \"SentencePieceTokenizer\",\r\n    \"vocab_path\": \"./projects/lic2021/conf/vocab.txt\",\r\n    \"do_lower_case\": false,\r\n    \"spm_model_file\": \"./projects/lic2021/conf/spm.model\"\r\n  },\r\n  \"run_infer\": true\r\n}\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/unified_transformer.py:119\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/transformer_block.py:116\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/transformer_block.py:217\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/generator.py:161\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  return (isinstance(seq, collections.Sequence) and\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/generator.py:209\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/generator.py:209\r\nThe behavior of expression A / B has been unified with elementwise_div(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_div(X, Y, axis=0) instead of A / B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/generator.py:239\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/Knover/models/generator.py:239\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\nW0412 19:20:59.318835  4704 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\r\nW0412 19:20:59.322726  4704 device_context.cc:372] device: 0, cuDNN Version: 7.6.\r\nLoad pretraining parameters from Plato.\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 139, in <module>\r\n    infer(args)\r\n  File \"infer.py\", line 86, in infer\r\n    predictions = task.infer_step(model, data)\r\n  File \"/home/aistudio/Knover/tasks/task_base.py\", line 43, in infer_step\r\n    predictions = model.infer_step(inputs)\r\n  File \"/home/aistudio/Knover/models/plato.py\", line 280, in infer_step\r\n    return super(Plato, self).infer_step(inputs)\r\n  File \"/home/aistudio/Knover/models/unified_transformer.py\", line 439, in infer_step\r\n    predictions = self._run_generation(inputs)\r\n  File \"/home/aistudio/Knover/models/unified_transformer.py\", line 394, in _run_generation\r\n    return_numpy=False)\r\n  File \"/home/aistudio/Knover/models/model_base.py\", line 266, in _execute\r\n    fetch_vars = self.exe.run(program, feed, fetch_list, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1328, in _run_program\r\n    [fetch_var_name])\r\nValueError: In user code:\r\n\r\n    File \"infer.py\", line 139, in <module>\r\n      infer(args)\r\n    File \"infer.py\", line 72, in infer\r\n      model = models.create_model(args, place)\r\n    File \"/home/aistudio/Knover/models/__init__.py\", line 49, in create_model\r\n      return MODEL_REGISTRY[args.model](args, place)\r\n    File \"/home/aistudio/Knover/models/plato.py\", line 49, in __init__\r\n      super(Plato, self).__init__(args, place)\r\n    File \"/home/aistudio/Knover/models/unified_transformer.py\", line 93, in __init__\r\n      super(UnifiedTransformer, self).__init__(args, place)\r\n    File \"/home/aistudio/Knover/models/model_base.py\", line 74, in __init__\r\n      self._build_programs()\r\n    File \"/home/aistudio/Knover/models/model_base.py\", line 91, in _build_programs\r\n      predictions = self.infer(inputs, outputs)\r\n    File \"/home/aistudio/Knover/models/unified_transformer.py\", line 380, in infer\r\n      return self.generator.inference(self, inputs, outputs)\r\n    File \"/home/aistudio/Knover/models/generator.py\", line 175, in inference\r\n      gather_idx=parent_idx)\r\n    File \"/home/aistudio/Knover/models/unified_transformer.py\", line 178, in _generation_network\r\n      gather_idx=gather_idx)\r\n    File \"/home/aistudio/Knover/models/unified_transformer.py\", line 202, in _encode\r\n      store=caches is not None\r\n    File \"/home/aistudio/Knover/models/transformer_block.py\", line 376, in encoder\r\n      store=store)\r\n    File \"/home/aistudio/Knover/models/transformer_block.py\", line 288, in encoder_layer\r\n      store=store)\r\n    File \"/home/aistudio/Knover/models/transformer_block.py\", line 158, in multi_head_attention\r\n      dropout_rate)\r\n    File \"/home/aistudio/Knover/models/transformer_block.py\", line 116, in scaled_dot_product_attention\r\n      product += attn_bias\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py\", line 304, in __impl__\r\n      attrs={'axis': axis})\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3023, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2107, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [160, 12, 160, 427] and the shape of Y = [160, 12, 1, 268]. Received [427] in X is not equal to [268] in Y at i:3.\r\n      [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:160)\r\n      [operator < elementwise_add > error]\r\naistudio@jupyter-208728-1765888:~/Knover$ \r\n```",
        "state": "open",
        "user": "nanzhao",
        "closed_by": null,
        "created_at": "2021-04-12T11:24:50+00:00",
        "updated_at": "2021-04-14T09:34:57+00:00",
        "closed_at": null,
        "comments_count": [
            "nanzhao",
            "sserdoubleh",
            "nanzhao",
            "nanzhao",
            "nanzhao",
            "nanzhao",
            "sserdoubleh",
            "sserdoubleh",
            "nanzhao",
            "nanzhao",
            "sserdoubleh",
            "nanzhao",
            "sserdoubleh",
            "nanzhao",
            "sserdoubleh",
            "sserdoubleh",
            "nanzhao",
            "sserdoubleh",
            "nanzhao",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 46,
        "title": "An PLATO-2 inference error for data pre-process???",
        "body": "I try to use plato to infer a example data with the instrunction of https://github.com/PaddlePaddle/Knover/tree/develop/projects/PLATO-2.\r\n\r\nBut I encounter an error below. And my code branch is develop and paddle is 2.0.1.\r\n\r\ncould you give me some help for this issue?\r\n\r\naistudio@jupyter-208728-1765888:~/develop/Knover$ git branch\r\n* develop\r\naistudio@jupyter-208728-1765888:~/develop/Knover$ pip list | grep paddle\r\npaddlehub              2.0.4                          \r\npaddlenlp              2.0.0rc7                       \r\npaddlepaddle-gpu       2.0.1.post101                  \r\ntb-paddle              0.3.6                          \r\naistudio@jupyter-208728-1765888:~/develop/Knover$ ./scripts/local/job.sh ./projects/PLATO-2/pretrain/24L_infer.conf\r\n+ [[ 1 == 1 ]]\r\n+ job_conf=./projects/PLATO-2/pretrain/24L_infer.conf\r\n+ source ./projects/PLATO-2/pretrain/24L_infer.conf\r\n++ job_script=./scripts/distributed/infer.sh\r\n++ model=Plato\r\n++ task=DialogGeneration\r\n++ vocab_path=./package/dialog_en/vocab.txt\r\n++ spm_model_file=./package/dialog_en/spm.model\r\n++ infer_file=./data/dailydialog_test_60.tsv\r\n++ data_format=raw\r\n++ file_format=file\r\n++ config_path=./projects/PLATO-2/24L.json\r\n++ init_params=./24L/Plato\r\n++ nsp_init_params=./24L/NSP\r\n++ in_tokens=false\r\n++ batch_size=5\r\n++ log_steps=1\r\n++ log_dir=./log\r\n++ save_path=./output\r\n++ output_name=response\r\n++ infer_args='--ranking_score nsp_score'\r\n+ export FLAGS_sync_nccl_allreduce=1\r\n+ FLAGS_sync_nccl_allreduce=1\r\n+ export FLAGS_fuse_parameter_memory_size=64\r\n+ FLAGS_fuse_parameter_memory_size=64\r\n+ mkdir -p ./output\r\n+ [[ ./log != '' ]]\r\n+ distributed_args=' --log_dir ./log'\r\n+ [[ ./24L/NSP != '' ]]\r\n+ [[ ! -e ./24L/NSP/__model__ ]]\r\n+ infer_args='--ranking_score nsp_score --nsp_inference_model_path ./24L/NSP'\r\n+ python -m paddle.distributed.launch --log_dir ./log ./knover/scripts/infer.py --is_distributed true --model Plato --task DialogGeneration --vocab_path ./package/dialog_en/vocab.txt --do_lower_case false --spm_model_file ./package/dialog_en/spm.model --init_pretraining_params ./24L/Plato --infer_file ./data/dailydialog_test_60.tsv --data_format raw --file_format file --config_path ./projects/PLATO-2/24L.json --output_name response --ranking_score nsp_score --nsp_inference_model_path ./24L/NSP --in_tokens false --batch_size 5 --save_path ./output\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n-----------  Configuration Arguments -----------\r\ngpus: None\r\nheter_worker_num: None\r\nheter_workers: \r\nhttp_port: None\r\nips: 127.0.0.1\r\nlog_dir: ./log\r\nnproc_per_node: None\r\nserver_num: None\r\nservers: \r\ntraining_script: ./knover/scripts/infer.py\r\ntraining_script_args: ['--is_distributed', 'true', '--model', 'Plato', '--task', 'DialogGeneration', '--vocab_path', './package/dialog_en/vocab.txt', '--do_lower_case', 'false', '--spm_model_file', './package/dialog_en/spm.model', '--init_pretraining_params', './24L/Plato', '--infer_file', './data/dailydialog_test_60.tsv', '--data_format', 'raw', '--file_format', 'file', '--config_path', './projects/PLATO-2/24L.json', '--output_name', 'response', '--ranking_score', 'nsp_score', '--nsp_inference_model_path', './24L/NSP', '--in_tokens', 'false', '--batch_size', '5', '--save_path', './output']\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nWARNING 2021-04-14 12:08:40,192 launch.py:316] Not found distinct arguments and compiled with cuda. Default use collective mode\r\nlaunch train in GPU mode\r\nINFO 2021-04-14 12:08:40,193 launch_utils.py:471] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:56451               |\r\n    |                     PADDLE_TRAINERS_NUM                        1                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:56451               |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2021-04-14 12:08:40,193 launch_utils.py:475] details abouts PADDLE_TRAINER_ENDPOINTS can be found in ./log/endpoints.log, and detail running logs maybe found in ./log/workerlog.0\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n{\r\n  \"is_distributed\": true,\r\n  \"save_path\": \"./output\",\r\n  \"infer_file\": \"./data/dailydialog_test_60.tsv\",\r\n  \"output_name\": \"response\",\r\n  \"log_steps\": 1,\r\n  \"Model\": {\r\n    \"model\": \"Plato\",\r\n    \"config_path\": \"./projects/PLATO-2/24L.json\",\r\n    \"init_checkpoint\": \"\",\r\n    \"init_pretraining_params\": \"./24L/Plato\",\r\n    \"optimizer\": \"AdamW\",\r\n    \"learning_rate\": 1e-05,\r\n    \"warmup_steps\": 0,\r\n    \"lr_scheduler\": \"noam\",\r\n    \"max_training_steps\": 2000,\r\n    \"min_learning_rate\": 0,\r\n    \"weight_decay\": 0.0,\r\n    \"max_grad_norm\": 0.1,\r\n    \"use_recompute\": false,\r\n    \"use_amp\": false,\r\n    \"amp_loss_scaling\": 32768.0,\r\n    \"weight_sharing\": true,\r\n    \"mem_efficient\": false,\r\n    \"use_role\": false,\r\n    \"use_bow\": true,\r\n    \"use_entropy\": false,\r\n    \"pre_encoder_cmd\": \"d\",\r\n    \"preprocess_cmd\": \"n\",\r\n    \"postprocess_cmd\": \"da\",\r\n    \"post_cls_cmd\": \"n\",\r\n    \"cls_bias\": true,\r\n    \"attention_probs_dropout_prob\": 0.1,\r\n    \"hidden_act\": \"gelu\",\r\n    \"hidden_dropout_prob\": 0.1,\r\n    \"hidden_size\": 1024,\r\n    \"initializer_range\": 0.02,\r\n    \"max_position_embeddings\": 256,\r\n    \"latent_type_size\": 20,\r\n    \"num_attention_heads\": 16,\r\n    \"num_hidden_layers\": 24,\r\n    \"type_vocab_size\": 2,\r\n    \"vocab_size\": 8001\r\n  },\r\n  \"Generator\": {\r\n    \"min_dec_len\": 1,\r\n    \"max_dec_len\": 64,\r\n    \"decoding_strategy\": \"topk_sampling\",\r\n    \"temperature\": 1.0,\r\n    \"ignore_unk\": true,\r\n    \"num_samples\": null,\r\n    \"topk\": 10,\r\n    \"topp\": 0.9,\r\n    \"beam_size\": 10,\r\n    \"length_average\": true,\r\n    \"length_penalty\": 0.0\r\n  },\r\n  \"Task\": {\r\n    \"task\": \"DialogGeneration\",\r\n    \"do_generation\": true,\r\n    \"is_cn\": false,\r\n    \"filter_cross_repetition\": true,\r\n    \"nsp_inference_model_path\": \"./24L/NSP\",\r\n    \"ranking_score\": \"nsp_score\"\r\n  },\r\n  \"Reader\": {\r\n    \"max_src_len\": 128,\r\n    \"max_tgt_len\": 128,\r\n    \"max_seq_len\": 256,\r\n    \"max_knowledge_len\": 0,\r\n    \"knowledge_position\": \"post_src\",\r\n    \"knowledge_style\": \"original\",\r\n    \"truncate_first_turn\": false,\r\n    \"file_format\": \"file\",\r\n    \"data_format\": \"raw\",\r\n    \"in_tokens\": false,\r\n    \"batch_size\": 5,\r\n    \"position_style\": \"continuous\",\r\n    \"random_seed\": 11,\r\n    \"shuffle_pool_size\": 0,\r\n    \"sort_pool_size\": 65536\r\n  },\r\n  \"Tokenizer\": {\r\n    \"tokenizer\": \"SentencePieceTokenizer\",\r\n    \"vocab_path\": \"./package/dialog_en/vocab.txt\",\r\n    \"specials_path\": \"\",\r\n    \"do_lower_case\": false,\r\n    \"spm_model_file\": \"./package/dialog_en/spm.model\"\r\n  },\r\n  \"run_infer\": true\r\n}\r\nW0414 12:08:41.338814  1234 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\r\nW0414 12:08:41.343097  1234 device_context.cc:372] device: 0, cuDNN Version: 7.6.\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/models/unified_transformer.py:140\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/transformer_block.py:113\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/transformer_block.py:213\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  return (isinstance(seq, collections.Sequence) and\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/generator.py:225\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/generator.py:225\r\nThe behavior of expression A / B has been unified with elementwise_div(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_div(X, Y, axis=0) instead of A / B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/generator.py:255\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/develop/Knover/knover/modules/generator.py:255\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\nLoading model from ./24L/Plato.\r\nLoad pretraining parameters from ./24L/Plato\r\nTraceback (most recent call last):\r\n  File \"./knover/scripts/infer.py\", line 140, in <module>\r\n    infer(args)\r\n  File \"./knover/scripts/infer.py\", line 81, in infer\r\n    predictions = task.infer_step(model, data)\r\n  File \"/home/aistudio/develop/Knover/knover/core/task.py\", line 46, in infer_step\r\n    outputs = self._post_process_infer_output(predictions)\r\n  File \"/home/aistudio/develop/Knover/knover/tasks/dialog_generation.py\", line 162, in _post_process_infer_output\r\n    return self._post_process_generation_output(predictions)\r\n  File \"/home/aistudio/develop/Knover/knover/tasks/dialog_generation.py\", line 91, in _post_process_generation_output\r\n    get_nsp_score_batch(self.nsp_predictor, predictions)\r\n  File \"/home/aistudio/develop/Knover/knover/tasks/dialog_generation.py\", line 404, in get_nsp_score_batch\r\n    outputs = nsp_predictor(data)\r\n  File \"/home/aistudio/develop/Knover/knover/utils/inference_utils.py\", line 44, in __predict__\r\n    return_numpy=True)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1313, in _run_program\r\n    fetch_var_name=fetch_var_name)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 624, in _add_feed_fetch_ops\r\n    if not has_feed_operators(global_block, feed, feed_var_name):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 280, in has_feed_operators\r\n    format(feed_target_name))\r\nException: 'feed_targets' does not have label_pos variable\r\nINFO 2021-04-14 12:08:55,230 launch_utils.py:307] terminate all the procs\r\nERROR 2021-04-14 12:08:55,230 launch_utils.py:545] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2021-04-14 12:08:58,233 launch_utils.py:307] terminate all the procs\r\n+ exit_code=1\r\n+ [[ 1 != 0 ]]\r\n+ rm './output/*.finish'\r\nrm: cannot remove './output/*.finish': No such file or directory\r\n+ exit 1\r\naistudio@jupyter-208728-1765888:~/develop/Knover$ ",
        "state": "closed",
        "user": "nanzhao",
        "closed_by": "nanzhao",
        "created_at": "2021-04-14T04:15:53+00:00",
        "updated_at": "2021-04-14T05:51:05+00:00",
        "closed_at": "2021-04-14T05:51:04+00:00",
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh",
            "nanzhao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 49,
        "title": "多轮对话训练数据的组织",
        "body": "有关多轮对话训练数据组织，我有个疑问。\r\n比如 a, b , c， d  是一段对话。\r\n应该生成 a,b ,c ->d一个pair的数据，还是枚举所有上文生成下文 a b,  a b ->c, abc->d 呢。\r\n\r\n第一种方式好像会损失一些tgt，只学最后一句；\r\n第二种方式又显得有些冗余。",
        "state": "closed",
        "user": "lonelydancer",
        "closed_by": "lonelydancer",
        "created_at": "2021-04-25T03:06:28+00:00",
        "updated_at": "2021-04-26T07:35:48+00:00",
        "closed_at": "2021-04-26T07:35:48+00:00",
        "comments_count": [
            "sserdoubleh",
            "lonelydancer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 52,
        "title": "有关NSPModel训练",
        "body": "1）我看paper中的NSPModel，“To select the most appropriate responses generated by the fine-grained generation model, the evaluation model is trained to estimate the coherence of the responses.” \r\n理解为用stage 2.1生成的候选 + label 做分类model\r\n而代码中的 mix_negative_sample 实现是随机替换tgt做负例，感觉不一致。\r\n2）最后上线的模型是 用2.1 先生成候选 再用2.2 排序么？\r\n\r\n",
        "state": "open",
        "user": "lonelydancer",
        "closed_by": null,
        "created_at": "2021-04-27T08:41:47+00:00",
        "updated_at": "2022-12-01T11:45:52+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "lonelydancer",
            "lonelydancer",
            "sserdoubleh",
            "jjj9china",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 50,
        "title": "NSP reader中的mask策略有时会使tgt_label采样为空，导致报错（paddle1.8版本）",
        "body": "你好，我在一些数据上重训nsp model，发现mask策略会使tgt_label采样为空。\r\n具体在nsp_reader.py 的_pad_batch_records函数中\r\n        batch_mask_token_ids, tgt_label, tgt_pos, label_pos = mask(\r\n                    batch_tokens=batch_token_ids,\r\n                    vocab_size=self.vocab_size,\r\n                    bos_id=self.bos_id,\r\n                    eos_id=self.eos_id,\r\n                    mask_id=self.mask_id,\r\n                    sent_b_starts=batch_tgt_start_idx,\r\n                    labels=batch_label,\r\n                    is_unidirectional=False)\r\n\r\n而mask策略，多次采样有时候prob 均> 0.15 ，导致mask_label、mask_pos都为空。\r\n\r\n我在这块多次采样直到非空，暂时解决了这个问题。\r\n",
        "state": "open",
        "user": "lonelydancer",
        "closed_by": null,
        "created_at": "2021-04-26T07:40:23+00:00",
        "updated_at": "2021-04-26T09:57:06+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "lonelydancer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 54,
        "title": "关于plato-2论文的一个问题",
        "body": "最近在拜读plato-2,有个疑问\r\n\r\n在stage1.1 粗训的时候,生成1to1的mapping,这里使用的NLL损失,可是公式前面的`E`指的是什么呢?\r\n![image](https://user-images.githubusercontent.com/5136418/121141460-8c8d6800-c86d-11eb-9590-99515ed78dac.png)\r\n\r\nstage2.1中代指的是从z的分布中取样得出一个z,这个能理解,可是stage1.1里面的E就不太懂了\r\n![image](https://user-images.githubusercontent.com/5136418/121141592-bba3d980-c86d-11eb-9fc0-95e70951ac8e.png)\r\n\r\n",
        "state": "open",
        "user": "qishibo",
        "closed_by": null,
        "created_at": "2021-06-08T07:26:42+00:00",
        "updated_at": "2021-06-09T05:04:58+00:00",
        "closed_at": null,
        "comments_count": [
            "qishibo",
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 55,
        "title": "why there is no __model__ in model file 24L/Plato",
        "body": "There is no __model__ in model file 24L/Plato, so it can not be translated into onnx. While NSP have __model__, why?",
        "state": "open",
        "user": "ifromeast",
        "closed_by": null,
        "created_at": "2021-06-23T02:37:38+00:00",
        "updated_at": "2021-07-03T17:55:25+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 56,
        "title": "CPU版本paddleHub居然要配置CUDA_HOME什么鬼",
        "body": "![image](https://user-images.githubusercontent.com/43203333/123193337-30fee380-d4d7-11eb-9411-33457e389e37.png)\r\n",
        "state": "open",
        "user": "xzkzdx",
        "closed_by": null,
        "created_at": "2021-06-24T02:31:18+00:00",
        "updated_at": "2021-06-24T03:55:57+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 57,
        "title": "为什么vocab中有很多带下划线的单词",
        "body": "感谢开源这么好的对话训练工具。最近学习过程中，发现示例的英语字典vacab.txt中有很多带下划线的单词，同时也有对应不带下划线的单词。不理解这些带下划线单词的作用，它增加了vacab长度，同时也会增加模型的收敛难度，那为什么会存在呢？下面是几个字典中的例子：\r\n▁of\t50\r\n▁be\t51\r\nbe\t408\r\nof\t2530",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-06-28T10:08:30+00:00",
        "updated_at": "2021-06-29T02:10:09+00:00",
        "closed_at": "2021-06-29T02:10:09+00:00",
        "comments_count": [
            "guijuzhejiang",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 53,
        "title": "有关训练效果",
        "body": "530w数据，从头训stage1, stage2.1 。仍然明显有safe response&重复的现象，请问是我训练的不够充分吗？\r\nstage1 batch_size=16 训练了320000 step，stage2.1训练了batch_size=1024 18000step\r\n\r\n![image](https://user-images.githubusercontent.com/548443/117535483-8d419d00-b028-11eb-8155-a89a11c8261a.png)\r\n\r\n改成选随机的候选感觉好一些。\r\n![image](https://user-images.githubusercontent.com/548443/117536265-aa786a80-b02c-11eb-8b1e-88595bdc9e6a.png)\r\n",
        "state": "closed",
        "user": "lonelydancer",
        "closed_by": "sserdoubleh",
        "created_at": "2021-05-08T10:09:42+00:00",
        "updated_at": "2021-12-23T09:33:59+00:00",
        "closed_at": "2021-07-02T18:38:09+00:00",
        "comments_count": [
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "zhanghaoie",
            "sserdoubleh",
            "lonelydancer",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "portia1026",
            "sserdoubleh",
            "lonelydancer",
            "lonelydancer",
            "lonelydancer",
            "sserdoubleh",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sserdoubleh",
            "lonelydancer",
            "sxmafei",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 58,
        "title": "关于vocab字典格式错误",
        "body": "我用sentencepiece生成了vocab字典，model type是unigram。字典中第二列不是index整数，而是float的概率，所以运行训练时报错：ValueError: invalid literal for int() with base 10:\r\n代码位置是vocab[token] = int(index)\r\n因为index是浮点数，所以转换失败。\r\n请问这里我要改字典还是代码呢？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-06-30T03:10:30+00:00",
        "updated_at": "2021-06-30T10:46:18+00:00",
        "closed_at": "2021-06-30T10:46:17+00:00",
        "comments_count": [
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 59,
        "title": "AttributeError: 'Plato' object has no attribute 'args'",
        "body": "训练plato模型时报错：\r\nFile \"/home/zzg/workspace/pycharm/Knover/knover/core/model.py\", line 225, in load\r\n    self.args.start_step = start_step[0]\r\nAttributeError: 'Plato' object has no attribute 'args'\r\n查看model.py代码如下：\r\n        if is_checkpoint:\r\n            print(f\"Load model from checkpoint: {model_path}\")\r\n            start_step = get_tensor(\"@LR_DECAY_COUNTER@\")\r\n            if start_step is not None:\r\n                self.args.start_step = start_step[0]\r\n原因：初始化init时确实没有初始化args。\r\n疑问：需要在init中加上self.args=args吗？感觉好像没用到self.args吧",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-02T08:33:38+00:00",
        "updated_at": "2021-07-03T02:52:00+00:00",
        "closed_at": "2021-07-03T02:52:00+00:00",
        "comments_count": [
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 60,
        "title": "为什么vocab里必须既有[UNK]又有<unk>呢？",
        "body": "看代码的规则，vocab里既要有[UNK]又要有\\<unk>，否则会报错，这两个token都代表未知词吧，有什么区别吗？\r\n另外我看例子中英语的vocab有些token的ids重复了，如下，不明白为什么，重复的id不会被覆盖吗？自己做vocab的时候也要改成重复的吗？\r\n\\<unk>\t0\r\n\\<s>\t1\r\n\\</s>\t2\r\n[UNK]\t0\r\n[PAD]\t0\r\n[CLS]\t1\r\n[SEP]\t2",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-03T02:59:23+00:00",
        "updated_at": "2021-07-04T09:08:41+00:00",
        "closed_at": "2021-07-04T09:08:40+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 61,
        "title": "用NSP做infer的时候报错",
        "body": "按着文档做infer时报了下面的错误：\r\nUnavailableError: Load operator fail to open file output/NSP/infer_model/encoder_layer_0_multi_head_att_key_fc.b_0, please check whether the model file is complete or damaged.\r\n      [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] (at /paddle/paddle/fluid/operators/load_op.h:41)\r\n      [operator < load > error]\r\n是NSP模型有问题吗？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-08T02:23:22+00:00",
        "updated_at": "2021-07-08T04:33:47+00:00",
        "closed_at": "2021-07-08T04:33:47+00:00",
        "comments_count": [
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 62,
        "title": "多伦对话的max_src_len是不是要设置长一些？",
        "body": "我理解的max_src_len是包括了人设，历史信息，本轮对话的上一句，这三部分加和后的最大长度，max_tgt_len是本轮对话的下一句的最大长度，max_seq_len是max_src_len+max_tgt_len的最大长度，这样理解对吗？如果对的话是不是要把max_src_len设置的长一些？中文对话训练里一个文字是2个字节，所以我设置的max_src_len=1600，这样对训练有什么影响呢？\r\n",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-08T04:58:50+00:00",
        "updated_at": "2021-07-08T06:17:02+00:00",
        "closed_at": "2021-07-08T06:16:49+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 69,
        "title": "请问作者在使用Knover做DSTC9任务时的训练脚本可以提供一下么",
        "body": "想通过训练脚本学习一下整个流程",
        "state": "open",
        "user": "AdamFocus",
        "closed_by": null,
        "created_at": "2021-08-01T08:23:58+00:00",
        "updated_at": "2021-08-01T08:23:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 63,
        "title": "训练代码中对角色信息是怎么处理的",
        "body": "百度的预训练模型很强大，推理时可以将角色放在上下文中做出响应。我想用自己的数据做加入自己设定的角色进行训练，参照了数据example/train.tsv中加入your persona:的做法，但查看代码dialog_reader.py中，里面并没有针对\"your persona:\"字段做特殊处理，请问百度训练时，对带有\"your persona:\"的信息是怎么处理的？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-09T00:22:53+00:00",
        "updated_at": "2021-07-10T04:19:42+00:00",
        "closed_at": "2021-07-10T04:19:42+00:00",
        "comments_count": [
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 64,
        "title": "请问use_role参数是怎么用的",
        "body": "请问use_role参数是标记什么的？是对话中的A和B吗？要怎么使用呢？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-12T09:00:07+00:00",
        "updated_at": "2021-07-14T09:32:32+00:00",
        "closed_at": "2021-07-14T09:32:31+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 65,
        "title": "在预测中num_samples和topk的关系",
        "body": "我看文档里给出的预测参数里默认是--num_samples 20 --topk 5.不太理解num_samples和topk的关系。\r\ntopk5的话，是说按概率大小排序后，从前5个里面采样一个作为输出token。\r\n那num_samples 20是做什么用的呢？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-07-16T02:55:32+00:00",
        "updated_at": "2021-07-18T05:34:47+00:00",
        "closed_at": "2021-07-18T05:34:47+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 67,
        "title": "请问有没有做过数据增强",
        "body": "做情感分类时做过随机mask和ngram的数据增强，请问对话任务，使用这种增强方式效果会好吗？还有其他有效的数据增强方式吗？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2021-07-22T01:27:43+00:00",
        "updated_at": "2021-07-26T06:38:18+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 70,
        "title": "UnifiedTransformerTokenizer' object has no attribute 'dialogue_encode'",
        "body": "'msg': \"'UnifiedTransformerTokenizer' object has no attribute 'dialogue_encode'\", 'results': '', 'status': '101'",
        "state": "open",
        "user": "shadowcz007",
        "closed_by": null,
        "created_at": "2021-08-07T15:43:11+00:00",
        "updated_at": "2021-08-20T05:07:40+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 71,
        "title": "关于paddle的docker image问题",
        "body": "下载paddle的2.1.0镜像创建容器后按照步骤install了所需要的包，再运行plato-2的interact的时候会报这个错误\r\n![1](https://user-images.githubusercontent.com/26245903/129464276-494433e0-4181-4328-baff-addf87bad646.png)\r\n![2](https://user-images.githubusercontent.com/26245903/129464278-d2e9fdd9-b85e-46ae-a5e5-deae2696c533.png)\r\n\r\n源代码只在interaction.py中添加了\r\n\"import paddle\r\npaddle.enable_static()\"\r\n这俩行代码\r\n\r\n想知道可能的原因是什么",
        "state": "closed",
        "user": "CristianYuuKi",
        "closed_by": "CristianYuuKi",
        "created_at": "2021-08-15T01:42:44+00:00",
        "updated_at": "2021-08-17T03:41:19+00:00",
        "closed_at": "2021-08-17T03:40:32+00:00",
        "comments_count": [
            "sserdoubleh",
            "CristianYuuKi",
            "sserdoubleh",
            "CristianYuuKi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 72,
        "title": "运行interact.py问题",
        "body": "运行interact进行多伦问答时，发现第2，3...轮的回答还是针对第一轮的问题的，没有对后面的问题作回答。\r\n请问这是为什么？\r\n源码把所有历史信息和当前的问题连起来作为输入token_ids，并且type_ids都为0，不知道训练是不是也是这样的。",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2021-08-20T03:53:46+00:00",
        "updated_at": "2021-08-24T07:01:28+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 74,
        "title": "Incorrect arguments in bash scripts",
        "body": "This line in projects/Plato-2/README.md:\r\n\r\nbash ./scripts/local/job.sh ./project/PLATO-2/pretrain/24L_inference.conf\r\n\r\nshould be:\r\n\r\nbash ./scripts/local/job.sh **./projecst/PLATO-2/pretrain/24L_infer.conf**\r\n\r\n\r\nSame for all similar lines...",
        "state": "closed",
        "user": "Evraa",
        "closed_by": "sserdoubleh",
        "created_at": "2021-08-25T20:47:21+00:00",
        "updated_at": "2021-10-20T08:29:48+00:00",
        "closed_at": "2021-10-20T08:29:48+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 73,
        "title": "PLATO-2 中文模型",
        "body": "想请问目前有开源中文模型参数吗？谢谢！",
        "state": "open",
        "user": "tobytyx",
        "closed_by": null,
        "created_at": "2021-08-25T12:27:45+00:00",
        "updated_at": "2021-09-02T03:37:13+00:00",
        "closed_at": null,
        "comments_count": [
            "tobytyx",
            "portia1026",
            "tobytyx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 75,
        "title": "Defining knowledge based document.",
        "body": "Using PLATO-2 project, how to define knowledge-based documents, to test the model based on? Or is there's a persona for the Bot that we may define?\r\n\r\nThank you",
        "state": "open",
        "user": "Evraa",
        "closed_by": null,
        "created_at": "2021-08-26T08:24:37+00:00",
        "updated_at": "2021-08-26T09:44:57+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "Evraa",
            "sserdoubleh",
            "Evraa"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 77,
        "title": "关于使用finetune Knover进行infer时，同一个语料库的infer结果每次都不一样",
        "body": "你好，我使用自己的数据对Knover Classfier进行finetune后保存checkpoint （我们发现保存的checkpoint有2612个参数文件比提供的[SOP-32L-Context](https://dialogue.bj.bcebos.com/Knover/projects/DSTC9-Track1/SOP-32L-Context.tar)模型的522个多了近4倍），然后基于这个checkpoint使用infer.sh进行预测，但是同一个数据集的预测结果每次都不一致，请问这种情况正常么？该如何解决？",
        "state": "closed",
        "user": "xcluo",
        "closed_by": "xcluo",
        "created_at": "2021-09-01T03:33:59+00:00",
        "updated_at": "2021-09-01T06:49:23+00:00",
        "closed_at": "2021-09-01T06:49:23+00:00",
        "comments_count": [
            "xcluo",
            "sserdoubleh",
            "xcluo",
            "sserdoubleh",
            "xcluo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 76,
        "title": "有没有使用对抗训练？",
        "body": "请问有没有测试用对抗训练的效果？如果要加入对抗训练，在哪里加入好？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2021-08-28T07:26:47+00:00",
        "updated_at": "2021-09-06T03:13:32+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 78,
        "title": "plato-2支持背景，人设的配置吗",
        "body": "1. plato-2支持背景，任务性格的配置吗？比如这个Bot的个人履历，性格相关等，然后回答能和其履历，性格相匹配。",
        "state": "open",
        "user": "kev1876",
        "closed_by": null,
        "created_at": "2021-09-02T07:24:50+00:00",
        "updated_at": "2021-09-11T02:35:47+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "kev1876",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 79,
        "title": "中文plato2，单机单卡可以训练，单机多卡跑到一定步数就退出，无有用报错信息",
        "body": "中文对话数据，数据量400w，单卡可以跑完整个epoch，单机4卡运行到一定步数就退出\r\n\r\n环境：\r\npaddlepaddle-gpu==2.0.1\r\ncuda==11.0\r\ncudnn==8.0\r\n\r\n\r\n终端报错是：\r\n\r\nINFO 2021-09-05 21:51:40,245 launch_utils.py:327] terminate all the procs\r\nERROR 2021-09-05  21:51:40,245 launch_utils.py:584] ABORT!!! Out of all 4 trainers, the trainer process with rank=[3] was aborted. Please check its log.\r\nINFO 2021-09-05  21:51:43,248 launch_utils.py:327] terminate all the procs`\r\n\r\n\r\nwork_log.3里面报错如下：\r\n```\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)\r\n1   paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)\r\n2   paddle::framework::details::FastThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)\r\n3   paddle::framework::BlockingQueue<unsigned long>::Pop()\r\n4   paddle::framework::SignalHandle(char const*, int)\r\n5   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Termination signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1630683022 (unix time) try \"date -d @1630683022\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGTERM (@0x3e800000a5e) received by PID 2812 (TID 0x7f718f576b80) from PID 2654 ***]\r\n```",
        "state": "closed",
        "user": "jidlin",
        "closed_by": "jidlin",
        "created_at": "2021-09-05T14:42:21+00:00",
        "updated_at": "2021-09-08T07:11:32+00:00",
        "closed_at": "2021-09-08T07:11:32+00:00",
        "comments_count": [
            "jidlin",
            "sserdoubleh",
            "jidlin",
            "jidlin",
            "jidlin",
            "sserdoubleh",
            "jidlin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 86,
        "title": "Data Preprocessing",
        "body": "Hi, \r\n\r\nThanks for your awesome job. Will you share the part of the code for Reddit data preprocessing? Looking forward to your reply.",
        "state": "open",
        "user": "goodbai-nlp",
        "closed_by": null,
        "created_at": "2021-10-04T03:01:30+00:00",
        "updated_at": "2021-10-04T03:01:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 82,
        "title": "想问下分布式训练有什么特殊设置吗，单机多卡可以跑通，多机多卡可以建立通信但是不报错也不训练",
        "body": "配置里按照paddle分布式教程设置为：distributed_args=\"--ips 10.130.19.203,10.130.17.157 --selected_gpus 0,1\"，两台机器可以建立通信但是不开始训练，GPU每张卡有2g内存占用，\r\n下面这种配置可以正常训练：distributed_args=\"--ips 10.130.19.203 --selected_gpus 0,1\"，",
        "state": "closed",
        "user": "jidlin",
        "closed_by": "jidlin",
        "created_at": "2021-09-22T06:20:36+00:00",
        "updated_at": "2021-10-26T03:07:00+00:00",
        "closed_at": "2021-10-26T03:07:00+00:00",
        "comments_count": [
            "sserdoubleh",
            "jidlin",
            "jidlin",
            "sserdoubleh",
            "jidlin",
            "jidlin",
            "jidlin",
            "sserdoubleh",
            "jidlin",
            "jidlin",
            "sserdoubleh",
            "jidlin",
            "jidlin",
            "jidlin",
            "jidlin",
            "sserdoubleh",
            "jidlin",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 81,
        "title": "dygraph分支只有第一步训练可以跑通，第二步很多代码缺失",
        "body": null,
        "state": "closed",
        "user": "jidlin",
        "closed_by": "jidlin",
        "created_at": "2021-09-08T05:02:44+00:00",
        "updated_at": "2021-09-09T09:10:50+00:00",
        "closed_at": "2021-09-09T09:10:50+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 80,
        "title": "infer的时候latent_id为什么指定为0，这个ID怎么发挥引导回复多样性的作用",
        "body": "如题，测试的时候发现latent_id是指定为0的，所以在使用的时候是需要人工指定latent_id吗，怎么确定每一步使用什么ID",
        "state": "closed",
        "user": "jidlin",
        "closed_by": "jidlin",
        "created_at": "2021-09-07T14:04:06+00:00",
        "updated_at": "2021-09-08T07:11:50+00:00",
        "closed_at": "2021-09-08T07:11:50+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 83,
        "title": "PLATO-XL",
        "body": "昨天看到百度发布了PLATO-XL，对话效果挺好。只知道模型参数扩大到了110亿，还有什么细节变化能多透露一些吗？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2021-09-23T01:34:52+00:00",
        "updated_at": "2021-09-23T12:17:53+00:00",
        "closed_at": null,
        "comments_count": [
            "LangDaoAI"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 84,
        "title": "plato-2优化函数为AdamW，我看lr有对应的衰减策略，但是weight_decay则没有",
        "body": " plato-2优化函数为AdamW，我看lr有对应的衰减策略，但是weight_decay则没有，是不需要吗？同时我看layer_norm相关参数，是没有用到weight_decay策略的，是有什么考虑吗?\r\n![image](https://user-images.githubusercontent.com/11463123/134842240-65e64d27-616f-4f30-8bf7-f3520a940f69.png)\r\n",
        "state": "open",
        "user": "kev1876",
        "closed_by": null,
        "created_at": "2021-09-27T03:54:57+00:00",
        "updated_at": "2021-10-08T09:40:22+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh",
            "kev1876",
            "kev1876"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 85,
        "title": "运行bash ./scripts/local/job.sh ./project/PLATO-2/pretrain/24L_inference.conf该命令时出现Exception: 'feed_targets' does not have label_pos variable",
        "body": "运行bash ./scripts/local/job.sh ./project/PLATO-2/pretrain/24L_inference.conf该命令时出现异常：\r\n![image](https://user-images.githubusercontent.com/65451118/135756271-d789f090-b455-42dd-886e-d4d092397967.png)\r\n进入到inference_utils.py文件中查看__predict__函数里面打印了inputs发现里面确实没有label_pos但是有一个label_idx不知道是不是改变量名了？",
        "state": "closed",
        "user": "lichade-son",
        "closed_by": "sserdoubleh",
        "created_at": "2021-10-03T13:47:05+00:00",
        "updated_at": "2022-04-21T16:16:59+00:00",
        "closed_at": "2022-04-21T16:16:59+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 87,
        "title": "训练数据的组织形式",
        "body": "Hi，我想请问下，中文模型训练的时候大部分都是多轮数据吗？还有单轮的比较多呀",
        "state": "open",
        "user": "zhanghaoie",
        "closed_by": null,
        "created_at": "2021-10-08T12:40:12+00:00",
        "updated_at": "2021-10-20T08:11:08+00:00",
        "closed_at": null,
        "comments_count": [
            "zhanghaoie",
            "guijuzhejiang",
            "kev1876",
            "guijuzhejiang",
            "kev1876",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 95
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 88,
        "title": "Stage2.1训练时报错 ",
        "body": "<img width=\"1739\" alt=\"截屏2021-10-09 下午6 35 53\" src=\"https://user-images.githubusercontent.com/22286006/136654613-4274017c-fcc1-4ed5-b018-57a5268526ee.png\">\r\n检查代码时发现未实现_get_feed_dict()\r\n<img width=\"395\" alt=\"截屏2021-10-09 下午6 36 59\" src=\"https://user-images.githubusercontent.com/22286006/136654636-f19f1c96-83d9-44b9-802c-b6b03c33cfb2.png\">\r\n<img width=\"899\" alt=\"截屏2021-10-09 下午6 38 13\" src=\"https://user-images.githubusercontent.com/22286006/136654663-2ae6cd2d-0bb2-4ca0-b269-a4cdb34ed414.png\">\r\n\r\n",
        "state": "open",
        "user": "misska1",
        "closed_by": null,
        "created_at": "2021-10-09T10:38:29+00:00",
        "updated_at": "2021-10-10T13:05:27+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 90,
        "title": "推理模型的文件大小",
        "body": "对比了你提供的预训练模型和自己生成的训练模型，发现自己生成的模型有4.1G，比你的大很多，多了一些文件，请问推理时是否要把带有'_beta1_pow_acc_0','_beta2_pow_acc_0','_moment1_0','_moment2_0'这四个后缀的文件从模型文件中删除？\r\n",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-10-19T11:09:22+00:00",
        "updated_at": "2021-10-20T00:48:51+00:00",
        "closed_at": "2021-10-20T00:48:51+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 89,
        "title": "knover/data/dialog_reader.py里_gen_self_attn_mask函数对unidirecional的情况处理是不是不全",
        "body": "正在学习plato-2的代码，发现_gen_self_attn_mask函数对is_unidirecional为真时的操作是不是对input_mask_data不起作用？\r\n通过这个参数对attention网络实现单边或双边的吧？\r\n ",
        "state": "open",
        "user": "wfeagle",
        "closed_by": null,
        "created_at": "2021-10-12T12:32:31+00:00",
        "updated_at": "2021-10-12T13:25:54+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 93,
        "title": "lantent参数对推理的影响",
        "body": "请问latent参数的大小对产生对话的具体影响是什么。现在用的默认值20，如果改成50的话，会怎么样？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2021-10-26T08:27:26+00:00",
        "updated_at": "2021-11-01T07:42:27+00:00",
        "closed_at": "2021-11-01T07:42:27+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 100,
        "title": "Plato-XL inference.sh runs, but output appears to be garbage",
        "body": "Greetings, I am attempting to run the Plato-XL 11B model.  I have been successful installing PaddlePaddle, Knover, etc and have been able to run the interact.sh demo, but the output is garbage:\r\n\r\n```\r\nLoading model from ./projects/PLATO-XL/models/11B-mp4.\r\n/home/zeus/anaconda3/envs/pytorch-env2/lib/python3.9/site-packages/paddle/fluid/executor.py:1307: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\nLoad pretraining parameters from ./projects/PLATO-XL/models/11B-mp4\r\nEnter [EXIT] to quit the interaction, [NEXT] to start a new conversation.\r\n[Human]:\r\nhello\r\n[Bot]:\r\nfreeones mattersacing measureacing matters lead 21amiote aw yaami :) awlineamilinelineote fem aw :)line CPU CPU measure CPU fem fem CPU awline limits femuuuuline awuuuu fem fem femamiriendline fem]line from fromline developerslineami developersline madeline from reachedizelineize\r\n[Human]:\r\n```\r\n\r\nMy only deviation from the repository instructions is that I am running the example on 4 V100 GPUs with 16GB RAM each, instead of 2 GPUs with 32GB RAM.\r\n\r\nAny thoughts as to what I could be doing wrong?  Any help would be appreciated, thanks.",
        "state": "open",
        "user": "hyperia-zeus",
        "closed_by": null,
        "created_at": "2021-12-03T21:03:01+00:00",
        "updated_at": "2021-12-06T13:11:14+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 98,
        "title": "能分享一下24L版本中文模型的一些训练情况吗",
        "body": "从配置文件来看，1、2-1和2-2三个阶段的learning rate分别是1e-3、4e-5、和1e-4，warmup steps是4000。三个stage总的训练步数分别是多少呢？阶段1和阶段2-1的NLL loss大概收敛到什么水平？多谢啦",
        "state": "open",
        "user": "JesseYang",
        "closed_by": null,
        "created_at": "2021-11-13T09:37:29+00:00",
        "updated_at": "2022-01-14T04:06:15+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 101,
        "title": "`entropy_loss` 在训练过程中几乎不变，都是 -3.0 左右",
        "body": "您好。请问 `entroy_loss` 训练过程中几乎不变，可能是哪个方面有问题？其他两个`loss`都会缓慢下降。\r\n非常期待得到回复。\r\n谢谢~",
        "state": "closed",
        "user": "cingtiye",
        "closed_by": "cingtiye",
        "created_at": "2021-12-10T02:14:20+00:00",
        "updated_at": "2021-12-23T03:03:03+00:00",
        "closed_at": "2021-12-23T03:03:03+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 103,
        "title": "百度为啥只开源英文的模型，不开源中文的，就不能为国内生态做点贡献吗？",
        "body": null,
        "state": "open",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2022-01-05T08:11:39+00:00",
        "updated_at": "2023-04-07T10:02:50+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026",
            "zhangxu999",
            "shuaijiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 104,
        "title": "损失函数entropy_loss和bow_loss",
        "body": "请问entropy_loss和bow_loss具体评估的是什么？\r\n我训练过程中entropy_loss变为nan，bow_loss降到5左右就不下降了，这样正常吗？\r\n什么情况下要使用这两个损失，也就是设置use_entropy，use_bow为true呢？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": "sserdoubleh",
        "created_at": "2022-01-05T10:52:28+00:00",
        "updated_at": "2022-01-12T08:41:21+00:00",
        "closed_at": null,
        "comments_count": [
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 105,
        "title": "如何从hugging face的模型作迁移",
        "body": "感谢您开源的工作。如果手上没有大规模的训练数据，而又想利用已有模型的知识，是否能利用hugging face上transformer模型做微调？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2022-01-09T07:01:16+00:00",
        "updated_at": "2022-01-26T13:29:57+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 109,
        "title": "请问有PLATO-XL的预训练conf吗",
        "body": null,
        "state": "open",
        "user": "Anery",
        "closed_by": null,
        "created_at": "2022-01-18T12:30:56+00:00",
        "updated_at": "2022-01-22T13:50:11+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 108,
        "title": "关于中文多轮对话训练预料的构造",
        "body": "您好！\r\n        我想构造**多轮的训练预料**，比如我爬取了某个微博的所有评论，但是这些评论都是针对这个微博的不同的评论。类似这样的数据可以按照**时间顺序**作为多轮对话预料吗？还是说需要经过一些怎样的清洗和处理才可以？\r\n非常期望得到您的回复~",
        "state": "closed",
        "user": "cingtiye",
        "closed_by": "cingtiye",
        "created_at": "2022-01-13T09:29:56+00:00",
        "updated_at": "2022-01-14T05:59:02+00:00",
        "closed_at": "2022-01-14T05:59:02+00:00",
        "comments_count": [
            "portia1026"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 106,
        "title": "Convert PLATO-2 model to ONNX format",
        "body": "Hello everyone,\r\n\r\nI'm currently trying to convert PLATO-2 model into ONNX format using Paddle2ONNX. However, when I try to convert the NSP model, I got this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 184, in main\r\n    input_shape_dict=input_shape_dict)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 148, in program2onnx\r\n    operator_export_type=operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 84, in program2onnx\r\n    enable_onnx_checker, operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 34, in export_onnx\r\n    operator_export_type, verbose)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n    onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n    self.update_opset_version()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 129, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 1 ops are not supported yet\r\n=========== gather_nd ===========\r\n```\r\nIs this Paddle2ONNX's issue?\r\n\r\nAlso, Is there anyone who had successfully converted PLATO-2 model to ONNX format with Paddle2ONNX or other alternative methods and does not mind to share how to do it?\r\n\r\nThank you very much in advance!",
        "state": "open",
        "user": "fadelma",
        "closed_by": null,
        "created_at": "2022-01-10T09:53:47+00:00",
        "updated_at": "2022-01-11T07:37:10+00:00",
        "closed_at": null,
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "fadelma",
            "jiangjiajun",
            "fadelma",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 107,
        "title": "Does dygraph branch support plato2's interact mode?",
        "body": null,
        "state": "open",
        "user": "zhanghaoie",
        "closed_by": null,
        "created_at": "2022-01-13T07:04:48+00:00",
        "updated_at": "2022-03-09T02:57:59+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "zhanghaoie",
            "sserdoubleh",
            "zhanghaoie",
            "zhanghaoie",
            "sserdoubleh",
            "zhanghaoie",
            "sserdoubleh",
            "zhanghaoie"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 110,
        "title": "请问模型参数量怎么统计",
        "body": "如题，请问提供统计模型参数量的工具吗",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-01-19T02:45:52+00:00",
        "updated_at": "2022-01-25T08:39:56+00:00",
        "closed_at": "2022-01-25T08:39:56+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 111,
        "title": "关于plato2的persona定制",
        "body": "您好，我看了issue #24，尝试在24L的plato-2上使用persona定制，修改代码如下：\r\n\r\nhttps://github.com/PaddlePaddle/Knover/blob/9d0db786dca9c575b40eb5776c6620bbd6657070/knover/scripts/interact.py#L84\r\n改成：\r\n\r\n```python\r\npersonas = [\"your persona: i have three cats.\", \"your persona: i am 20 years old.\", \"your persona: i like eggs.\"]\r\nexample = Example(src=\" [SEP] \".join(personas + data.decode(\"utf8\")), data_id=0)\r\n```\r\n\r\nhttps://github.com/PaddlePaddle/Knover/blob/9d0db786dca9c575b40eb5776c6620bbd6657070/knover/scripts/interact.py#L127\r\n改成：\r\n\r\n```python\r\npersonas = [\"your persona: i have three cats.\", \"your persona: i am 20 years old.\", \"your persona: i like eggs.\"]\r\nsrc = \" [SEP] \".join(personas + context)\r\n```\r\n\r\n执行interact后结果混乱，如下：\r\n![image](https://user-images.githubusercontent.com/20638961/150108952-a22aa6bf-02f4-41d3-b332-bba3575a6ae9.png)\r\n\r\n能否帮忙看下，是哪里使用不对吗？",
        "state": "open",
        "user": "Anery",
        "closed_by": null,
        "created_at": "2022-01-19T10:07:36+00:00",
        "updated_at": "2022-03-01T03:01:00+00:00",
        "closed_at": null,
        "comments_count": [
            "Anery",
            "sserdoubleh",
            "Anery",
            "sserdoubleh",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 112,
        "title": "关于`role_ids`",
        "body": "非常感谢百度开源代码！\r\n想请教一下关于`role_ids`的设置。\r\n\r\n我现在有多组多轮对话的数据，每组多轮对话有多个角色，请问我是否需要为每一组的每个角色都设置一个唯一的`role_id`，还是只需要设置`n`个`role_id`（远小于角色数），依次分配到每一组中。\r\n\r\n非常期待能得到回复！\r\n元宵节快乐~",
        "state": "closed",
        "user": "cingtiye",
        "closed_by": "cingtiye",
        "created_at": "2022-02-15T06:50:42+00:00",
        "updated_at": "2022-02-22T10:37:12+00:00",
        "closed_at": "2022-02-22T10:37:12+00:00",
        "comments_count": [
            "sserdoubleh",
            "cingtiye",
            "sserdoubleh",
            "cingtiye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 113,
        "title": "PLATO-XL Perplexity",
        "body": "Hello, Can you suggest how to get the perplexity of a target response using your model? What is the score in the [prediction](https://github.com/PaddlePaddle/Knover/blob/9d0db786dca9c575b40eb5776c6620bbd6657070/knover/scripts/infer.py#L87) about? Thanks!",
        "state": "open",
        "user": "jasonwu0731",
        "closed_by": null,
        "created_at": "2022-02-25T23:40:55+00:00",
        "updated_at": "2022-03-01T00:05:18+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "jasonwu0731",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 125,
        "title": "plato2多机多卡分布式训练卡住",
        "body": null,
        "state": "closed",
        "user": "leelinglin",
        "closed_by": "leelinglin",
        "created_at": "2022-04-02T08:27:43+00:00",
        "updated_at": "2022-04-02T08:30:18+00:00",
        "closed_at": "2022-04-02T08:30:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 122,
        "title": "模型怎么固定",
        "body": "请问推理生成对话时，模型权重要怎么固定？有类似model.eval()的方法吗？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-03-17T12:32:15+00:00",
        "updated_at": "2022-03-24T14:26:57+00:00",
        "closed_at": "2022-03-24T14:26:57+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 119,
        "title": "关于PLATO-XL的训练",
        "body": "非常感谢您开源的XL模型。我尝试用8个A100（每块40G显存）训练自己的XL模型，但因参数过大，显存还是不够。看plato-XL论文里面提到：Given the limited memory of each device, vanilla data parallelism cannot support the training of such a model with up to 11 billion parameters.As such, we adopt the sharded data parallelism (Rajbhandari et al., 2020) to eliminate memory redundancies, by partitioning the optimizer states, gradients and parameters across multiple devices. \r\n请问论文里提到的这种模型参数跨多个显卡的训练方法要如何实现？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-03-04T05:19:36+00:00",
        "updated_at": "2022-03-30T04:58:09+00:00",
        "closed_at": "2022-03-30T04:58:09+00:00",
        "comments_count": [
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 120,
        "title": "请问用plato-2跑中文模型，loss一般下降到多少？",
        "body": "您好，我用plato-2跑中文模型（目前跑的是第一阶段），我感觉我的学习率是不是设置小了，我设置的为1e-5，跑了1.8M个步长（batch_size=32），loss下降到2.66，尽管loss一直在下降，但是我觉得太慢了。我是不是应该把学习率设置大一点，5e-4或者2e-5。另外，我想咨询一下第一阶段的loss一般下降到多少左右就可以了？\r\n\r\n非常期望得到回复~",
        "state": "open",
        "user": "cingtiye",
        "closed_by": null,
        "created_at": "2022-03-14T03:23:49+00:00",
        "updated_at": "2022-07-12T02:46:52+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "ZeyuTeng96",
            "cingtiye",
            "ZeyuTeng96",
            "cingtiye",
            "ZeyuTeng96",
            "cingtiye",
            "ZeyuTeng96"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 124,
        "title": "Speech Disfluency Simulator and Phoneme-level Simulator In TOD-DA",
        "body": "Hello\r\n\r\nDoes this github include the code for the Speech Disfluency Simulator and Phoneme-level Simulator used in TOD-DA?",
        "state": "open",
        "user": "yeonheuiyeon",
        "closed_by": null,
        "created_at": "2022-03-25T06:39:58+00:00",
        "updated_at": "2022-03-25T09:13:38+00:00",
        "closed_at": null,
        "comments_count": [
            "ShaneTian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 126,
        "title": "plato2源码有开源吗",
        "body": "源码有开源吗",
        "state": "open",
        "user": "jiuyanyufei",
        "closed_by": null,
        "created_at": "2022-04-11T05:52:34+00:00",
        "updated_at": "2022-04-11T06:46:36+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 127,
        "title": "Fine-tune PLATO-2",
        "body": "1) I download the 24L model, and run the finetune script `bash ./scripts/local/job.sh ./projects/PLATO-2/finetune/24L_train.conf`. I got nan for my loss at the very beginning of the fine-tuning. Am I missing any stages? \r\n\r\n2) If I do the pre-train script, the pretrain stage 1 does not store anything in the output/. I assume stage 2.1, and stage 2.2, requires stage 1's output right? How do I store stage 1? Thanks\r\n\r\nThanks!",
        "state": "open",
        "user": "sdai654416",
        "closed_by": null,
        "created_at": "2022-04-12T21:21:32+00:00",
        "updated_at": "2022-05-03T10:16:09+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "py703703"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 128,
        "title": "About PLATO-KAG",
        "body": "First of all thank you very much for your work. When I run the code of PLATO-KAG as instructed, there is a problem.\r\n![problem](https://user-images.githubusercontent.com/96398485/163391312-305b3c1d-78ff-40ed-baf6-753bcb93ee59.png)\r\nWould you mind answering this question？thank you very much.",
        "state": "closed",
        "user": "bingfeiz",
        "closed_by": "sserdoubleh",
        "created_at": "2022-04-14T12:34:23+00:00",
        "updated_at": "2022-05-06T04:11:42+00:00",
        "closed_at": "2022-05-06T04:11:42+00:00",
        "comments_count": [
            "Vonderland",
            "bingfeiz",
            "Vonderland",
            "bingfeiz",
            "Vonderland",
            "bingfeiz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 129,
        "title": "运行train.py时出现以下错误",
        "body": "E:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEARE\r\nST or Dither.NONE instead.\r\n  'nearest': Image.NEAREST,\r\nE:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILI\r\nNEAR instead.\r\n  'bilinear': Image.BILINEAR,\r\nE:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUB\r\nIC instead.\r\n  'bicubic': Image.BICUBIC,\r\nE:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:39: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX inste\r\nad.\r\n  'box': Image.BOX,\r\nE:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:40: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZ\r\nOS instead.\r\n  'lanczos': Image.LANCZOS,\r\nE:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:41: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMI\r\nNG instead.\r\n  'hamming': Image.HAMMING\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 29, in <module>\r\n    import knover.models as models\r\nModuleNotFoundError: No module named 'knover'\r\n\r\n没有找到模块knover，但是打开对应文件第29行，编辑器在导入knover时并没有提示有错？",
        "state": "closed",
        "user": "chikin-lau",
        "closed_by": "chikin-lau",
        "created_at": "2022-04-17T10:56:44+00:00",
        "updated_at": "2022-04-17T11:18:03+00:00",
        "closed_at": "2022-04-17T11:18:03+00:00",
        "comments_count": [
            "chikin-lau",
            "chikin-lau",
            "chikin-lau"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 136,
        "title": "请问下plato系列后续会不会开源一些中文预训练模型呢",
        "body": null,
        "state": "open",
        "user": "yinnxinn",
        "closed_by": null,
        "created_at": "2022-05-09T02:32:45+00:00",
        "updated_at": "2022-05-09T02:32:45+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 132,
        "title": "ValueError: (InvalidArgument) Tensor holds the wrong type, it holds int, but desires to be int64_t.",
        "body": "### Lic2022的baseline源码，在AIStudio可以正常跑，本地跑时train_query，infer_dial，infer_dial均无错误，只在infer_query时出现以下错误\r\npaddlepaddle：2.2.2\r\ncuda：11.2\r\ncudnn：8.2\r\n\r\n$ sh ./scripts/local/job.sh ./projects/lic2022/conf/query_infer.conf\r\n\r\n2022-04-18 15:40:25,456-INFO: [topology.py:169:init] HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 1, mp_group: [0], sharding_group: [0], pp_group: [0], dp_gr\r\noup: [0], check/clip group: [0]\r\nW0418 15:40:25.456908 14688 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.6, Runtime API Version: 11.2\r\nW0418 15:40:25.472528 14688 device_context.cc:465] device: 0, cuDNN Version: 8.2.\r\n[WARN] Using constant learning rate because of warmup_steps is not positive while using NoamScheduler.\r\nLoading parameters from ./projects/lic2022/model_zoo/query_finetune.pdparams.\r\nLoading has done!\r\nTraceback (most recent call last):\r\nFile \"./knover/scripts/infer.py\", line 140, in\r\ninfer(args)\r\nFile \"./knover/scripts/infer.py\", line 83, in infer\r\npredictions = task.infer_step(model, data)\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\core\\task.py\", line 46, in infer_step\r\npredictions = model.infer_step(inputs)\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\core\\model.py\", line 508, in infer_step\r\npredictions = self._model(*inputs, mode=\"infer\")\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\core\\model.py\", line 180, in call\r\noutputs = self.infer_step(inputs)\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\core\\model.py\", line 170, in infer_step\r\npredictions = self.infer(inputs, outputs)\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\models\\unified_transformer.py\", line 297, in infer\r\noutputs = self.generator(self, inputs, outputs)\r\nFile \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\modules\\generator.py\", line 163, in call\r\nstate = self._update_state(state, probs)\r\n**File \"e:\\jupyternotebookproject\\lic2022\\knover\\knover\\modules\\generator.py\", line 390, in _update_state\r\nstate[\"predictions\"] = paddle.concat([state[\"predictions\"], pred], axis=1)\r\nFile \"E:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\tensor\\manipulation.py\", line 345, in concat\r\nreturn paddle.fluid.layers.concat(input=x, axis=axis, name=name)\r\nFile \"E:\\software\\Anaconda3\\envs\\Knover\\lib\\site-packages\\paddle\\fluid\\layers\\tensor.py\", line 327, in concat\r\nreturn _C_ops.concat(input, 'axis', axis)\r\nValueError: (InvalidArgument) Tensor holds the wrong type, it holds int, but desires to be int64_t.\r\n[Hint: Expected valid == true, but received valid:0 != true:1.] (at ../paddle/fluid/framework/tensor_impl.h:33)\r\n[operator < concat > error]**\r\nINFO 2022-04-18 15:40:36,201 launch_utils.py:341] terminate all the procs\r\nERROR 2022-04-18 15:40:36,201 launch_utils.py:604] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2022-04-18 15:40:39,210 launch_utils.py:341] terminate all the procs\r\nINFO 2022-04-18 15:40:39,210 launch.py:311] Local processes completed.\r\n\r\nexit_code=0\r\n[[ 0 != 0 ]]\r\nexit 0",
        "state": "closed",
        "user": "chikin-lau",
        "closed_by": "chikin-lau",
        "created_at": "2022-04-18T07:49:58+00:00",
        "updated_at": "2022-04-19T04:21:20+00:00",
        "closed_at": "2022-04-18T08:29:38+00:00",
        "comments_count": [
            "chikin-lau",
            "chikin-lau",
            "sserdoubleh",
            "sserdoubleh",
            "chikin-lau",
            "chikin-lau"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 135,
        "title": "关于distinct-1/2的计算，用了多少句子/conversations？",
        "body": "is:issue is:open 你好，我想问一下，在计算distinct-1/2的时候，用了多少句子和多少词汇，是全部test 数据吗，还是选择了top 10？ 50？200？我们想知道这个分母是基于多少数据计算的。我们主要是为了做对照实验，想知道这个重要的数据信息。谢谢",
        "state": "open",
        "user": "ZenzenDatabase",
        "closed_by": null,
        "created_at": "2022-05-06T08:38:40+00:00",
        "updated_at": "2022-05-10T11:44:31+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 138,
        "title": "For the error of running the command 'bash ./scripts/local/job.sh ./projects/PLATO-2/pretrain/24L_infer.conf'",
        "body": "For the following parameters in the config of https://github.com/PaddlePaddle/Knover/blob/develop/projects/PLATO-2/pretrain/24L_infer.conf:\r\n```\r\n16 init_params=\"./24L/Plato\"\r\n17 nsp_init_params=\"./24L/NSP\"\r\n```\r\nHow can I get these two models? Do I need transform from the model https://dialogue.bj.bcebos.com/Knover/projects/PLATO-2/24L.tar to get them by myself.",
        "state": "open",
        "user": "kiseliu",
        "closed_by": null,
        "created_at": "2022-05-18T14:18:15+00:00",
        "updated_at": "2022-06-09T12:15:54+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh",
            "kiseliu",
            "sserdoubleh",
            "kiseliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 139,
        "title": "分布式训练性能BUG",
        "body": "1、python train.py 单卡 训练速度9.0step/s\r\n2、fleetrun train.py 单卡 use_amp = False 训练速度 9.0step/s use_amp=True 训练速度3.9step/s\r\n3、fleetrun train.py 多卡(6卡) use_amp = False 训练速度3.0step/s use_amp=True 训练速度1.8step/s\r\n问题1、使用use_amp后性能下降严重\r\n2、使用fleetrun 分布式训练较单卡性能下降严重，使用3张卡才相当于之前一张卡，没有体现分布式加速训练的效果",
        "state": "open",
        "user": "leelinglin",
        "closed_by": null,
        "created_at": "2022-05-26T09:16:48+00:00",
        "updated_at": "2022-05-28T18:26:44+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 140,
        "title": "请问plato2能够运行在CPU服务器上吗？16核，64G内存",
        "body": null,
        "state": "open",
        "user": "zhaoyiyong",
        "closed_by": null,
        "created_at": "2022-06-03T10:04:46+00:00",
        "updated_at": "2022-06-21T07:07:58+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 143,
        "title": "关于 Stage 2.2 NSP模型 的 实现问题",
        "body": "论文中 context 前面使用的是 CLS token，猜测是想 和 MLM 任务对齐；\r\n<img width=\"534\" alt=\"image\" src=\"https://user-images.githubusercontent.com/15831043/172858610-af393baa-3ad8-490b-ae01-cbe7ca1cf0fd.png\">\r\n但是 plato-1 里面画的是 MASK token，所以这里实现的时候，用的是 CLS token 还是 MASK token？似乎在代码里面看不太出来。",
        "state": "closed",
        "user": "kiseliu",
        "closed_by": "kiseliu",
        "created_at": "2022-06-09T13:33:35+00:00",
        "updated_at": "2022-06-10T14:09:50+00:00",
        "closed_at": "2022-06-10T14:08:58+00:00",
        "comments_count": [
            "sserdoubleh",
            "kiseliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 151,
        "title": "plato-mini 可以微调吗？",
        "body": "plato-mini  可以定制数据进行微调吗",
        "state": "open",
        "user": "daozhi0921",
        "closed_by": null,
        "created_at": "2022-06-30T07:52:33+00:00",
        "updated_at": "2022-06-30T07:52:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 150,
        "title": "plato闲聊对话服务，多人请求，历史对话是否会出现交叉？",
        "body": "您好， 对于plato闲聊对话模型，如果在不同机器上部署了uwsgi服务， 同时多人请求闲聊， 那么怎么保证历史对话之间不会交叉呢？",
        "state": "open",
        "user": "daozhi0921",
        "closed_by": null,
        "created_at": "2022-06-28T11:44:57+00:00",
        "updated_at": "2022-06-28T11:44:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 141,
        "title": "关于./scripts/single_gpu的训练参数保存问题（paddle-2.2.2）",
        "body": "你好，我在使用./scripts/single_gpu/train.sh时，会报出\r\n\r\n`Traceback (most recent call last):\r\n  File \"./knover/scripts/train.py\", line 250, in <module>\r\n    train(args)\r\n  File \"./knover/scripts/train.py\", line 170, in train\r\n    save_model(model, args.save_path, \"best\", args)\r\n  File \"./knover/scripts/train.py\", line 242, in save_model\r\n    model.save(path, is_checkpoint=args.save_checkpoint)\r\n  File \"/home/aistudio/work/Knover/knover/core/model.py\", line 541, in save\r\n    paddle.save(self._dist_model.state_dict(), params_path)\r\nAttributeError: 'ModelInterface' object has no attribute '_dist_model'`\r\n\r\n的错误，而在使用./scripts/destributed/train.sh时，就不会出现，请问可以解决吗？",
        "state": "open",
        "user": "M-aterialism",
        "closed_by": null,
        "created_at": "2022-06-08T18:05:30+00:00",
        "updated_at": "2022-06-09T07:36:08+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 144,
        "title": "关于 PLATO-2 和 PLATO 的模型区别",
        "body": "除了论文中提到的 pre-norm 和 post-norm 的区别，以及 tokenizer 的区别，\r\n\r\n我对比了下 plato 的网络结构 和 plato-2 (stage 2.1 PLATO模型) 的网络结构，发现也有细微区别：\r\n\r\n1、在预测 latent variable 的时候，plato 1 中的实现的是 mask token 的 final hidden state 经过 post_network；而plato-2 中，我理解 recognition_fc 这一层 是为了 取出 mask token 的 final hidden state，然后 post_network 用 (latent_embedding, recognition_bias) 给替代了；\r\n\r\n2、plato 1 中，计算 NLL loss 的时候(generation network)，response 中所有 token 的 final hidden states，上面没有接分类器，而是和 word embedding 共享参数；而 plato 2 中，response 中所有 token 的 final hidden states，还要经过 一层 mask_lm_trans_fc 和 一层 layer norm，然后 和 word embedding 共享参数时，还多了个偏置 mask_lm_out_fc.b_0；\r\n\r\n3、计算 bow loss 的时候，和 计算 NLL loss 的改动一样，多了 一层 bow_trans_fc  和 一层 layer norm，以及偏置 bow_out_fc.b_0；\r\n\r\n我不知道上述理解是否正确，以及这种改动上的设计是为了？",
        "state": "open",
        "user": "kiseliu",
        "closed_by": null,
        "created_at": "2022-06-09T14:14:16+00:00",
        "updated_at": "2022-06-10T13:25:18+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 145,
        "title": "use_role? missing role_type_size parameter？",
        "body": "when training UnifiedTransformer model, if set use_role=True, it will raise following exception; \r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\\\Miniconda3\\envs\\python37\\lib\\contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"C:\\Users\\\\Miniconda3\\envs\\python37\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 6854, in program_guard\r\n    yield\r\n  File \"e:\\chatbot\\git_code\\knover\\knover\\core\\model.py\", line 228, in _build_programs\r\n    outputs = self.forward(inputs)\r\n  File \"e:\\chatbot\\git_code\\knover\\knover\\models\\unified_transformer.py\", line 435, in forward\r\n    gather_idx=inputs.get(\"parent_idx\", None)\r\n  File \"e:\\chatbot\\git_code\\knover\\knover\\models\\unified_transformer.py\", line 261, in _generation_network\r\n    name=name)\r\n  File \"e:\\chatbot\\git_code\\knover\\knover\\models\\unified_transformer.py\", line 154, in _gen_input\r\n    name=name + self.role_emb_name, initializer=self.param_initializer))\r\n  File \"C:\\Users\\\\Miniconda3\\envs\\python37\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 509, in embedding\r\n    attr=helper.param_attr, shape=size, dtype=dtype, is_bias=False)\r\n  File \"C:\\Users\\\\Miniconda3\\envs\\python37\\lib\\site-packages\\paddle\\fluid\\layer_helper_base.py\", line 319, in create_parameter\r\n    assert size > 0, (\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\npython-BaseException\r\n",
        "state": "closed",
        "user": "shanekong",
        "closed_by": "shanekong",
        "created_at": "2022-06-15T03:45:09+00:00",
        "updated_at": "2022-06-21T06:14:37+00:00",
        "closed_at": "2022-06-21T06:14:36+00:00",
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh",
            "shanekong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 155,
        "title": "如何基于现有的开源英文plato-2模型，搭建一个中文多轮对话机器人",
        "body": "各位大佬，\r\n\r\n请问如何基于现有的开源英文plato-2模型，搭建一个中文多轮对话机器人？本人看了下面的链接，但还是对如何使用英文的plato-2搭建适用于中文多轮对话任务的plato-2模型表示不太了解。能否请各位大佬提供一些更详细的细节？还能否请各位已经实现的大佬共享一些代码供小弟参考，谢谢。\r\n\r\n链接：\r\nhttps://github.com/PaddlePaddle/Knover/issues/25",
        "state": "open",
        "user": "ZeyuTeng96",
        "closed_by": null,
        "created_at": "2022-07-11T10:04:01+00:00",
        "updated_at": "2022-07-11T10:04:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 152,
        "title": "DSTC10-Track2/task2 inference code: Error while running the command 'bash ./submission_0_infer.sh'",
        "body": "When running DSTC10-Track2/task2 (Knowledge-grounded Dialogue Modeling), I got error message like this. \r\nPlease help me to fix the following error.\r\n\r\nthe error message:\r\n```\r\nLoad pretraining parameters from /home/Knover/projects/DSTC10-Track2/task2/models/SOP-32L-Detection\r\nTraceback (most recent call last):\r\n  File \"/home/Knover/knover/data/dialog_reader.py\", line 578, in __wrapper__\r\n    for batch in batch_reader():\r\n  File \"/home/Knover/knover/data/dialog_reader.py\", line 517, in __wrapper__\r\n    for batch in batch_reader():\r\n  File \"/home/Knover/knover/data/dialog_reader.py\", line 432, in __wrapper__\r\n    for record in reader():\r\n  File \"/home/Knover/knover/data/dialog_reader.py\", line 369, in __wrapper__\r\n    yield from self._read_numerical_file(fp, phase, is_infer)\r\nTypeError: _read_numerical_file() takes from 2 to 3 positional arguments but 4 were given\r\nWARNING:root:Your reader has raised an exception!\r\nTraceback (most recent call last):\r\nException in thread   File \"./knover/scripts/infer.py\", line 145, in <module>\r\nThread-1:\r\nTraceback (most recent call last):\r\n      File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\ninfer(args)\r\n    for step, data in enumerate(infer_generator(), 1):\r\n  File \"/home/Knover/myenv/lib/python3.8/site-packages/paddle/fluid/reader.py\", line 1392, in __next__\r\n        return self._reader.read_next()self.run()\r\n\r\nSystemError:   File \"/usr/lib/python3.8/threading.py\", line 870, in run\r\n(Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n```\r\n\r\nThank you for taking the time to review this. ",
        "state": "closed",
        "user": "JH-debug",
        "closed_by": "JH-debug",
        "created_at": "2022-07-05T10:24:23+00:00",
        "updated_at": "2022-07-07T15:10:52+00:00",
        "closed_at": "2022-07-07T15:10:52+00:00",
        "comments_count": [
            "sserdoubleh",
            "JH-debug",
            "sserdoubleh",
            "sserdoubleh",
            "JH-debug"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 157,
        "title": "XLarge模型部署需要多大显存",
        "body": "感谢分享的XLarge模型，请问部署一个11B参数的XLarge模型至少需要大多显存？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-09-27T03:11:09+00:00",
        "updated_at": "2022-09-30T08:45:18+00:00",
        "closed_at": "2022-09-30T08:45:18+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 156,
        "title": "Diamante的模型怎么没有",
        "body": "看到Diamante的论文里说训练代码已开放，但是链接过来没找到代码",
        "state": "open",
        "user": "LinglingGreat",
        "closed_by": null,
        "created_at": "2022-09-08T03:44:36+00:00",
        "updated_at": "2022-11-17T03:06:20+00:00",
        "closed_at": null,
        "comments_count": [
            "what-is-perfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 161,
        "title": "Plato-KAG部署环境下如何输入topic和knowledge",
        "body": "你好，关于Plato-KAG部署场景有几个疑问，Plato-KAG预测模型的输入是topic，knowledge，src。请问Plato-KAG模型部署后，topic和knowledge是随便选定输入吗？如果对方提问，如何选择相应的topic和knowledge呢？",
        "state": "open",
        "user": "guijuzhejiang",
        "closed_by": null,
        "created_at": "2022-10-10T08:18:55+00:00",
        "updated_at": "2022-10-10T08:18:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 162,
        "title": "请问Link theWorld这个论文中2.1节Service Information的service API是如何构建的",
        "body": "感谢百度一直以来在中文对话上的工作~\r\n\r\n我想咨询一下论文《Link theWorld: Improving Open-domain Conversation with Dynamic Spatiotemporal-aware Knowledge》中2.1节Service Information第一段中的service API具体是如何构建的。\r\n我看了论文，觉得全文最重要的就是这个service API的构建，假若构造的足够好的话，确实可以大大提高人机交互体验。但是论文似乎并没有细说这部分的工作以及相关开源的代码/数据。确实非常好奇~\r\n\r\n非常期待能得到您的回复！\r\n谢谢~",
        "state": "open",
        "user": "cingtiye",
        "closed_by": null,
        "created_at": "2022-10-10T12:19:55+00:00",
        "updated_at": "2022-10-10T12:19:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 158,
        "title": "如何使用Plato-KAG训练自己的数据",
        "body": "非常感谢你们开源的工作，去年我用了plato2训练了自己的模型，但不基于知识回答的很随意。请问如果使用Plato-KAG训练自己的模型，有没有相关的指导文档，比如数据处理，训练步骤等。提前致谢",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-09-27T09:36:57+00:00",
        "updated_at": "2022-09-30T04:35:37+00:00",
        "closed_at": "2022-09-30T04:35:37+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 159,
        "title": "ValueError: (InvalidArgument) for PLATO-XL's interact.sh",
        "body": "Hi, thanks for your very nice work.\r\nI have an error when running interact.sh for PLATO-XL.\r\nI'm running the script on Ubuntu 18.04 with 3 RTX 3090 24GB GPUs.\r\npython version: 3.7.12\r\nknover             0.0.6\r\npaddlepaddle-gpu   2.3.2.post111\r\nCUDA Version: 11.1\r\ncudnn: 8.0\r\n# Error information\r\n\r\n```\r\n(plato) tsq@Sakura32:/data/tsq/xiaomu/baselines/Knover/projects/PLATO-XL$ bash ./interact.sh\r\nmodels/11B is exist.\r\n+ [[ 1 != 1 ]]\r\n+ job_conf=./projects/PLATO-XL/interact.conf\r\n+ source ./projects/PLATO-XL/interact.conf\r\n++ job_script=./scripts/distributed/interact.sh\r\n++ model=UnifiedTransformer\r\n++ task=DialogGeneration\r\n++ vocab_path=./package/dialog_en/vocab.txt\r\n++ spm_model_file=./package/dialog_en/spm.model\r\n++ config_path=./projects/PLATO-XL/11B.json\r\n++ init_params=./projects/PLATO-XL/models/11B\r\n++ log_dir=./projects/PLATO-XL/log\r\n++ export CUDA_VISIBLE_DEVICES=2,5,7\r\n++ CUDA_VISIBLE_DEVICES=2,5,7\r\n++ infer_args='\r\n--use_role true\r\n--position_style relative\r\n--decoding_strategy topk_sampling\r\n--topk 10\r\n--num_samples 20\r\n--use_sharding true\r\n'\r\n+ [[ ./projects/PLATO-XL/log != '' ]]\r\n+ rm './projects/PLATO-XL/log/workerlog.*'\r\nrm: cannot remove './projects/PLATO-XL/log/workerlog.*': No such file or directory\r\n++ dirname ./scripts/local/job.sh\r\n+ export PYTHONPATH=./scripts/local/../..:/data/tsq/xiaomu/baselines/Knover:\r\n+ PYTHONPATH=./scripts/local/../..:/data/tsq/xiaomu/baselines/Knover:\r\n+ ./scripts/distributed/interact.sh ./projects/PLATO-XL/interact.conf\r\n+ [[ 1 == 1 ]]\r\n+ job_conf=./projects/PLATO-XL/interact.conf\r\n+ source ./projects/PLATO-XL/interact.conf\r\n++ job_script=./scripts/distributed/interact.sh\r\n++ model=UnifiedTransformer\r\n++ task=DialogGeneration\r\n++ vocab_path=./package/dialog_en/vocab.txt\r\n++ spm_model_file=./package/dialog_en/spm.model\r\n++ config_path=./projects/PLATO-XL/11B.json\r\n++ init_params=./projects/PLATO-XL/models/11B\r\n++ log_dir=./projects/PLATO-XL/log\r\n++ export CUDA_VISIBLE_DEVICES=2,5,7\r\n++ CUDA_VISIBLE_DEVICES=2,5,7\r\n++ infer_args='\r\n--use_role true\r\n--position_style relative\r\n--decoding_strategy topk_sampling\r\n--topk 10\r\n--num_samples 20\r\n--use_sharding true\r\n'\r\n+ export FLAGS_sync_nccl_allreduce=1\r\n+ FLAGS_sync_nccl_allreduce=1\r\n+ export FLAGS_fuse_parameter_memory_size=64\r\n+ FLAGS_fuse_parameter_memory_size=64\r\n+ [[ ./package/dialog_en/spm.model != '' ]]\r\n+ save_args='--spm_model_file ./package/dialog_en/spm.model '\r\n+ infer_args='--spm_model_file ./package/dialog_en/spm.model \r\n--use_role true\r\n--position_style relative\r\n--decoding_strategy topk_sampling\r\n--topk 10\r\n--num_samples 20\r\n--use_sharding true\r\n'\r\n+ [[ '' != '' ]]\r\n+ [[ --spm_model_file ./package/dialog_en/spm.model \r\n--use_role true\r\n--position_style relative\r\n--decoding_strategy topk_sampling\r\n--topk 10\r\n--num_samples 20\r\n--use_sharding true\r\n =~ --use_sharding true ]]\r\n+ [[ 2,5,7 != '' ]]\r\n+ CUDA_VISIBLE_DEVICE_ARRAY=(${CUDA_VISIBLE_DEVICES//,/ })\r\n+ MP_DEGREE=3\r\n+ infer_args='--spm_model_file ./package/dialog_en/spm.model \r\n--use_role true\r\n--position_style relative\r\n--decoding_strategy topk_sampling\r\n--topk 10\r\n--num_samples 20\r\n--use_sharding true\r\n --mp_degree 3'\r\n+ [[ ! -d ./projects/PLATO-XL/models/11B-mp3 ]]\r\n+ init_params=./projects/PLATO-XL/models/11B-mp3\r\n+ fleetrun ./knover/scripts/interact.py --is_distributed true --model UnifiedTransformer --vocab_path ./package/dialog_en/vocab.txt --config_path ./projects/PLATO-XL/11B.json --init_pretraining_params ./projects/PLATO-XL/models/11B-mp3 --spm_model_file ./package/dialog_en/spm.model --use_role true --position_style relative --decoding_strategy topk_sampling --topk 10 --num_samples 20 --use_sharding true --mp_degree 3\r\nLAUNCH INFO 2022-10-02 16:05:44,163 -----------  Configuration  ----------------------\r\nLAUNCH INFO 2022-10-02 16:05:44,163 devices: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 elastic_level: -1\r\nLAUNCH INFO 2022-10-02 16:05:44,164 elastic_timeout: 30\r\nLAUNCH INFO 2022-10-02 16:05:44,164 gloo_port: 6767\r\nLAUNCH INFO 2022-10-02 16:05:44,164 host: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 job_id: default\r\nLAUNCH INFO 2022-10-02 16:05:44,164 legacy: False\r\nLAUNCH INFO 2022-10-02 16:05:44,164 log_dir: log\r\nLAUNCH INFO 2022-10-02 16:05:44,164 log_level: INFO\r\nLAUNCH INFO 2022-10-02 16:05:44,164 master: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 max_restart: 3\r\nLAUNCH INFO 2022-10-02 16:05:44,164 nnodes: 1\r\nLAUNCH INFO 2022-10-02 16:05:44,164 nproc_per_node: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 rank: -1\r\nLAUNCH INFO 2022-10-02 16:05:44,164 run_mode: collective\r\nLAUNCH INFO 2022-10-02 16:05:44,164 server_num: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 servers: \r\nLAUNCH INFO 2022-10-02 16:05:44,164 trainer_num: None\r\nLAUNCH INFO 2022-10-02 16:05:44,164 trainers: \r\nLAUNCH INFO 2022-10-02 16:05:44,164 training_script: ./knover/scripts/interact.py\r\nLAUNCH INFO 2022-10-02 16:05:44,164 training_script_args: ['--is_distributed', 'true', '--model', 'UnifiedTransformer', '--vocab_path', './package/dialog_en/vocab.txt', '--config_path', './projects/PLATO-XL/11B.json', '--init_pretraining_params', './projects/PLATO-XL/models/11B-mp3', '--spm_model_file', './package/dialog_en/spm.model', '--use_role', 'true', '--position_style', 'relative', '--decoding_strategy', 'topk_sampling', '--topk', '10', '--num_samples', '20', '--use_sharding', 'true', '--mp_degree', '3']\r\nLAUNCH INFO 2022-10-02 16:05:44,164 with_gloo: 0\r\nLAUNCH INFO 2022-10-02 16:05:44,164 --------------------------------------------------\r\nLAUNCH INFO 2022-10-02 16:05:44,172 Job: default, mode collective, replicas 1[1:1], elastic False\r\nLAUNCH INFO 2022-10-02 16:05:44,173 Run Pod: izcvrd, replicas 3, status ready\r\nLAUNCH INFO 2022-10-02 16:05:44,198 Watching Pod: izcvrd, replicas 3, status running\r\n{\r\n  \"is_distributed\": true,\r\n  \"port\": 18123,\r\n  \"Model\": {\r\n    \"model\": \"UnifiedTransformer\",\r\n    \"config_path\": \"./projects/PLATO-XL/11B.json\",\r\n    \"init_checkpoint\": \"\",\r\n    \"init_pretraining_params\": \"./projects/PLATO-XL/models/11B-mp3\",\r\n    \"optimizer\": \"AdamW\",\r\n    \"learning_rate\": 1e-05,\r\n    \"beta1\": 0.9,\r\n    \"beta2\": 0.999,\r\n    \"warmup_steps\": 0,\r\n    \"lr_scheduler\": \"noam\",\r\n    \"max_training_steps\": 2000,\r\n    \"min_learning_rate\": 0,\r\n    \"weight_decay\": 0.0,\r\n    \"max_grad_norm\": 0.1,\r\n    \"use_recompute\": false,\r\n    \"checkpointing_every_n_layers\": 1,\r\n    \"use_amp\": false,\r\n    \"amp_loss_scaling\": 32768.0,\r\n    \"use_sharding\": true,\r\n    \"dp_degree\": 1,\r\n    \"sharding_degree\": 1,\r\n    \"mp_degree\": 3,\r\n    \"pp_degree\": 1,\r\n    \"weight_sharing\": true,\r\n    \"mem_efficient\": false,\r\n    \"use_role\": true,\r\n    \"pre_encoder_cmd\": \"d\",\r\n    \"preprocess_cmd\": \"n\",\r\n    \"postprocess_cmd\": \"da\",\r\n    \"post_cls_cmd\": \"n\",\r\n    \"cls_bias\": true,\r\n    \"attention_probs_dropout_prob\": 0.1,\r\n    \"hidden_act\": \"gelu\",\r\n    \"hidden_dropout_prob\": 0.1,\r\n    \"hidden_size\": 3072,\r\n    \"inner_hidden_size\": 18432,\r\n    \"initializer_range\": 0.01,\r\n    \"max_position_embeddings\": 1024,\r\n    \"num_attention_heads\": 32,\r\n    \"num_hidden_layers\": 72,\r\n    \"type_vocab_size\": 3,\r\n    \"role_type_size\": 128,\r\n    \"vocab_size\": 8001\r\n  },\r\n  \"Generator\": {\r\n    \"min_dec_len\": 1,\r\n    \"max_dec_len\": 64,\r\n    \"decoding_strategy\": \"topk_sampling\",\r\n    \"temperature\": 1.0,\r\n    \"ignore_unk\": true,\r\n    \"num_samples\": 20,\r\n    \"topk\": 10,\r\n    \"topp\": 0.9,\r\n    \"beam_size\": 10,\r\n    \"length_average\": true,\r\n    \"length_penalty\": 0.0\r\n  },\r\n  \"Task\": {\r\n    \"do_generation\": true,\r\n    \"is_cn\": false,\r\n    \"filter_cross_repetition\": true,\r\n    \"nsp_inference_model_path\": null,\r\n    \"ranking_score\": \"decode_score\",\r\n    \"generate_seed\": 11\r\n  },\r\n  \"Reader\": {\r\n    \"max_src_len\": 128,\r\n    \"max_tgt_len\": 128,\r\n    \"max_seq_len\": 256,\r\n    \"max_knowledge_len\": 0,\r\n    \"knowledge_position\": \"post_src\",\r\n    \"knowledge_style\": \"original\",\r\n    \"truncate_first_turn\": false,\r\n    \"file_format\": \"file\",\r\n    \"data_format\": \"raw\",\r\n    \"in_tokens\": false,\r\n    \"batch_size\": 16,\r\n    \"position_style\": \"relative\",\r\n    \"random_seed\": 11,\r\n    \"shuffle_pool_size\": 0,\r\n    \"sort_pool_size\": 65536\r\n  },\r\n  \"Tokenizer\": {\r\n    \"tokenizer\": \"SentencePieceTokenizer\",\r\n    \"vocab_path\": \"./package/dialog_en/vocab.txt\",\r\n    \"specials_path\": \"\",\r\n    \"do_lower_case\": false,\r\n    \"spm_model_file\": \"./package/dialog_en/spm.model\"\r\n  },\r\n  \"run_infer\": true\r\n}\r\n/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/executor.py:400: UserWarning: do not use standalone executor in fleet by default\r\n  warnings.warn(\"do not use standalone executor in fleet by default\")\r\nI1002 16:05:45.244711 32810 nccl_context.cc:83] init nccl context nranks: 3 local rank: 0 gpu id: 0 ring id: 0\r\nW1002 16:05:45.914779 32810 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.1, Runtime API Version: 11.1\r\nW1002 16:05:45.919350 32810 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\r\n/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py:146\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:341: UserWarning: /data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py:155\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\nTraceback (most recent call last):\r\n  File \"./knover/scripts/interact.py\", line 164, in <module>\r\n    interact(args)\r\n  File \"./knover/scripts/interact.py\", line 61, in interact\r\n    model = models.create_model(args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/__init__.py\", line 46, in create_model\r\n    return MODEL_REGISTRY[args.model](args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 101, in __init__\r\n    super(UnifiedTransformer, self).__init__(args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/core/model.py\", line 146, in __init__\r\n    self._build_programs()\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/core/model.py\", line 212, in _build_programs\r\n    outputs = self.forward(inputs, is_infer=True)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 435, in forward\r\n    gather_idx=inputs.get(\"parent_idx\", None)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 268, in _generation_network\r\n    name=\"encoder\" if name == \"\" else name)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 310, in _encode\r\n    topo=self.topo\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 478, in encoder\r\n    topo=topo)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 379, in encoder_layer\r\n    topo=topo)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 190, in multi_head_attention\r\n    k = layers.concat([select_k, k], axis=1) \r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layers/tensor.py\", line 393, in concat\r\n    type='concat', inputs=inputs, outputs={'Out': [out]}, attrs=attrs)\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 44, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3621, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2764, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\nValueError: (InvalidArgument) The 2-th dimension of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [-1, 0, 960], input[1]'s shape = [-1, 256, 1024].\r\n  [Hint: Expected inputs_dims[0][j] == inputs_dims[i][j], but received inputs_dims[0][j]:960 != inputs_dims[i][j]:1024.] (at /paddle/paddle/phi/kernels/funcs/concat_funcs.h:83)\r\n  [operator < concat > error]\r\nLAUNCH INFO 2022-10-02 16:05:47,203 Pod failed\r\nLAUNCH ERROR 2022-10-02 16:05:47,204 Container failed !!!\r\nContainer rank 0 status failed cmd ['/home/tsq/miniconda3/envs/plato/bin/python', '-u', './knover/scripts/interact.py', '--is_distributed', 'true', '--model', 'UnifiedTransformer', '--vocab_path', './package/dialog_en/vocab.txt', '--config_path', './projects/PLATO-XL/11B.json', '--init_pretraining_params', './projects/PLATO-XL/models/11B-mp3', '--spm_model_file', './package/dialog_en/spm.model', '--use_role', 'true', '--position_style', 'relative', '--decoding_strategy', 'topk_sampling', '--topk', '10', '--num_samples', '20', '--use_sharding', 'true', '--mp_degree', '3'] code 1 log log/default.izcvrd.0.log \r\nenv {'CONDA_SHLVL': '2', 'LD_LIBRARY_PATH': '/home/user/cuda/lib64/:/usr/local/cuda/lib64', 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'CONDA_EXE': '/home/tsq/miniconda3/bin/conda', 'SSH_CONNECTION': '166.111.68.66 2395 103.238.162.32 22', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LANG': 'en_US.UTF-8', 'OLDPWD': '/data/tsq/xiaomu/baselines/Knover/projects/PLATO-XL', 'CONDA_PREFIX': '/home/tsq/miniconda3/envs/plato', 'FLAGS_sync_nccl_allreduce': '1', 'S_COLORS': 'auto', '_CE_M': '', 'XDG_SESSION_ID': '63791', 'USER': 'tsq', 'CONDA_PREFIX_1': '/home/tsq/miniconda3', 'CORENLP_HOME': '/data/tsq/corenlp/stanford-corenlp-4.4.0', 'PWD': '/data/tsq/xiaomu/baselines/Knover', 'HOME': '/home/tsq', 'CONDA_PYTHON_EXE': '/home/tsq/miniconda3/bin/python', 'SSH_CLIENT': '166.111.68.66 2395 22', 'CUDA_HOME': '/usr/local/cuda', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', '_CE_CONDA': '', 'FLAGS_fuse_parameter_memory_size': '64', 'CONDA_PROMPT_MODIFIER': '(plato) ', 'SSH_TTY': '/dev/pts/133', 'MAIL': '/var/mail/tsq', 'SHELL': '/bin/bash', 'TERM': 'xterm-256color', 'CUDA_VISIBLE_DEVICES': '2,5,7', 'SHLVL': '4', 'LANGUAGE': 'en_HK:en', 'PYTHONPATH': './scripts/local/../..:/data/tsq/xiaomu/baselines/Knover:', 'data_dir': '/data/tsq/coref', 'LOGNAME': 'tsq', 'XDG_RUNTIME_DIR': '/run/user/1016', 'PATH': '/home/tsq/mongodb/bin:/home/tsq/miniconda3/envs/plato/bin:/home/tsq/miniconda3/condabin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin', 'CONDA_DEFAULT_ENV': 'plato', 'LESSOPEN': '| /usr/bin/lesspipe %s', '_': '/home/tsq/miniconda3/envs/plato/bin/fleetrun', 'CUSTOM_DEVICE_ROOT': '', 'OMP_NUM_THREADS': '1', 'PADDLE_MASTER': '103.238.162.32:44617', 'PADDLE_GLOBAL_SIZE': '3', 'PADDLE_LOCAL_SIZE': '3', 'PADDLE_GLOBAL_RANK': '0', 'PADDLE_LOCAL_RANK': '0', 'PADDLE_TRAINER_ENDPOINTS': '103.238.162.32:54031,103.238.162.32:48471,103.238.162.32:53953', 'PADDLE_CURRENT_ENDPOINT': '103.238.162.32:54031', 'PADDLE_TRAINER_ID': '0', 'PADDLE_TRAINERS_NUM': '3', 'PADDLE_RANK_IN_NODE': '0', 'FLAGS_selected_gpus': '0'}\r\nified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\nTraceback (most recent call last):\r\n  File \"./knover/scripts/interact.py\", line 164, in <module>\r\n    interact(args)\r\n  File \"./knover/scripts/interact.py\", line 61, in interact\r\n    model = models.create_model(args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/__init__.py\", line 46, in create_model\r\n    return MODEL_REGISTRY[args.model](args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 101, in __init__\r\n    super(UnifiedTransformer, self).__init__(args, place)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/core/model.py\", line 146, in __init__\r\n    self._build_programs()\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/core/model.py\", line 212, in _build_programs\r\n    outputs = self.forward(inputs, is_infer=True)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 435, in forward\r\n    gather_idx=inputs.get(\"parent_idx\", None)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 268, in _generation_network\r\n    name=\"encoder\" if name == \"\" else name)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/models/unified_transformer.py\", line 310, in _encode\r\n    topo=self.topo\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 478, in encoder\r\n    topo=topo)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 379, in encoder_layer\r\n    topo=topo)\r\n  File \"/data/tsq/xiaomu/baselines/Knover/knover/modules/transformer_block.py\", line 190, in multi_head_attention\r\n    k = layers.concat([select_k, k], axis=1) \r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layers/tensor.py\", line 393, in concat\r\n    type='concat', inputs=inputs, outputs={'Out': [out]}, attrs=attrs)\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 44, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3621, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/tsq/miniconda3/envs/plato/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2764, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\nValueError: (InvalidArgument) The 2-th dimension of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [-1, 0, 960], input[1]'s shape = [-1, 256, 1024].\r\n  [Hint: Expected inputs_dims[0][j] == inputs_dims[i][j], but received inputs_dims[0][j]:960 != inputs_dims[i][j]:1024.] (at /paddle/paddle/phi/kernels/funcs/concat_funcs.h:83)\r\n  [operator < concat > error]\r\nLAUNCH INFO 2022-10-02 16:05:47,204 Exit code 1\r\n+ exit_code=1\r\n+ exit 1\r\n```",
        "state": "closed",
        "user": "ShangQingTu",
        "closed_by": "ShangQingTu",
        "created_at": "2022-10-02T08:25:33+00:00",
        "updated_at": "2022-10-04T02:45:14+00:00",
        "closed_at": "2022-10-04T02:45:13+00:00",
        "comments_count": [
            "sserdoubleh",
            "ShangQingTu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 160,
        "title": "PLATO-KAG不需要三步训练了吗？",
        "body": "感谢你们的工作，以前训练plato2时分了UT，plato2，NSP三个任务的训练。PLATO-KAG貌似只训练一次，脚本中也没有latent隐变量了。是这样吗？除了运用了wiki知识外，PLATO-KAG与Plato2相比，还有其他区别吗？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-10-08T10:25:14+00:00",
        "updated_at": "2023-01-08T06:45:22+00:00",
        "closed_at": "2023-01-08T06:45:22+00:00",
        "comments_count": [
            "portia1026",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 167,
        "title": "Plato-KAG文档",
        "body": "最近在学习Plato-KAG，除了kag的论文和readme之外没找到其他文档，请问还有其他相关的帮助文档可以指导训练自己模型的吗？",
        "state": "open",
        "user": "aguang1201",
        "closed_by": null,
        "created_at": "2022-10-21T01:32:48+00:00",
        "updated_at": "2022-10-21T08:57:11+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 169,
        "title": "加载数据时发现报错[WARN] Invalid example: context too long / no context - Example",
        "body": "您好，我最近在使用Knover，试图训练一个24L的中文模型，我在完成数据收集，开始训练24L_train_stage-1.conf 时发现训练前的日志中出现警告。警告信息样式如下：\r\n\r\n[WARN] Invalid example: context too long / no context - Example(src='松子是上面撒的东西……难道我的已经化掉了？我打开杯子看没有撒的东西……那他可能没有给你撒松子上面应该有奶油吗，我打开奶油都木有……废话……绿奶油！这款是我觉得打开来最好看的一款了绿奶油？！！！我没有！！！生气气！！！为什么我没有！要特地说吗？', tgt='不用..只有去奶油才要特地说你喝了一个假的星巴克吧', data_id=64905)\r\n\r\n我明白这段对话中history似乎过长，但我的max_src_len设置为384，上述文本满足长度要求，因此或许不是输入数据过长的原因。\r\n我集中检查no context的问题，在找到这个异常地抛出位置（Knover/knover/data/dialog_reader.py : line-289）后，我按程序执行顺序模拟了tokenize的流程，现在还没有找到原因。请问有人可以帮我找到触发警告的原因和解决办法吗？\r\n我使用的一些信息：\r\n    job.sh来自single_gpu目录\r\n    24L_train_stage-1.conf 参数：\r\n        model=UnifiedTransformer\r\n        task=DialogGeneration\r\n        tokenize : 默认方式\r\n        spm.model : luge-dialogue baseline model\r\n        vocab.txt : 同取自luge-dialogue\r\n        datatype : raw\r\n        file_format : filelist\r\n谢谢！！！\r\n\r\n\r\n",
        "state": "closed",
        "user": "what-is-perfect",
        "closed_by": "what-is-perfect",
        "created_at": "2022-11-16T10:25:35+00:00",
        "updated_at": "2022-11-17T02:55:34+00:00",
        "closed_at": "2022-11-17T02:55:24+00:00",
        "comments_count": [
            "sserdoubleh",
            "what-is-perfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 170,
        "title": "WARN，读数据时显示context过长或无content",
        "body": "该问题被我误删除，这里重复一下：\r\n由于我在训练stage1时在相应conf中声明max_src_len，导致实际训练未能使参数生效，目前该参数正确的声明方式是在Knover/scripts/**/train.sh中按 train_args=\"--max_src_len 384 --max_seq_len 512\"格式自行声明，或在编写自己的train.sh时按相同方式声明。\r\n感谢之前回复的朋友，在他的提示下解决了这个问题！！！",
        "state": "closed",
        "user": "what-is-perfect",
        "closed_by": "what-is-perfect",
        "created_at": "2022-11-17T03:01:51+00:00",
        "updated_at": "2022-11-17T03:03:07+00:00",
        "closed_at": "2022-11-17T03:03:07+00:00",
        "comments_count": [
            "what-is-perfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 171,
        "title": "使用single_gpu训练报错TypeError: __new__() got multiple values for argument data_id",
        "body": "我只有一张显卡，因此我是用Knover/scripts/single_gpu/train.sh进行训练。\r\n训练时发现在训练epoch1时训练顺利进行，但在某个阶段，读数据时报错其显示使用Tread1读取数据时发现data_id有多个值。\r\n读数据程序位于“Knover/knover/data/dialog_reader.py”\r\n报错信息如下：\r\n[train][1] progress: 1/1 step: 6524, time: 0.753, queue size: 64, speed: 1.327 steps/sException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/reader.py\", line 1442, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/reader.py\", line 1422, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/root/Knover/knover/core/model.py\", line 382, in __wrapper__\r\n    for batch in generator():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 578, in __wrapper__\r\n    for batch in batch_reader():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 517, in __wrapper__\r\n    for batch in batch_reader():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 483, in __wrapper__\r\n    for record in reader():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 397, in __wrapper__\r\n    for record in file_reader():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 372, in __wrapper__\r\n    for example in gen_examples():\r\n  File \"/root/Knover/knover/data/dialog_reader.py\", line 339, in __wrapper__\r\n    example = Example(*line, data_id=self.data_id)\r\nTypeError: __new__() got multiple values for argument 'data_id'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/root/Knover/knover/scripts/train.py\", line 319, in <module>\r\n    train(args)\r\n  File \"/root/Knover/knover/scripts/train.py\", line 146, in train\r\n    for step, data in enumerate(train_generator(), args.start_step + 1):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/reader.py\", line 1398, in __next__\r\n    return self._reader.read_next()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n\r\n        current lr: 0.0000392\r\n        lm_loss: 3.1958, ppl: 24.4298, loss: 3.1958\r\n[train][1] progress: 1/1 step: 6525, time: 0.824, queue size: 64, speed: 1.214 steps/s\r\n        current lr: 0.0000392\r\n        lm_loss: 3.2496, ppl: 25.7806, loss: 3.2496\r\n+ exit_code=1\r\n+ exit 1\r\n\r\n目前我修改使用distuributed/train.sh做训练。这是因为我之前使用finetune时，使用single_gpu脚本报错，使用distuributed脚本则完成finetune，现在还没有发现报错。\r\n\r\n请问谁知道这个问题是怎样引起的以及怎样解决啊？",
        "state": "closed",
        "user": "what-is-perfect",
        "closed_by": "what-is-perfect",
        "created_at": "2022-11-17T06:41:34+00:00",
        "updated_at": "2022-11-18T05:21:04+00:00",
        "closed_at": "2022-11-18T05:21:04+00:00",
        "comments_count": [
            "what-is-perfect",
            "what-is-perfect",
            "sserdoubleh",
            "what-is-perfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 172,
        "title": "PLATO stage-1训练之后output里没有输出",
        "body": "运行 bash ./scripts/local/job.sh ./projects/PLATO-2/pretrain/24L_train_stage-1.conf 训练样例数据之后，output文件夹里没有任何输出是怎么回事呢",
        "state": "open",
        "user": "mjy0012",
        "closed_by": null,
        "created_at": "2022-11-28T11:38:29+00:00",
        "updated_at": "2022-11-28T12:05:01+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 175,
        "title": "PLATO stage1训练发现内存一直在增长，训练到9w步后，出现内存溢出，这是什么原因？",
        "body": "使用中文的的语料训练plato，但是发现训练到一定步数后，内存就被消耗完了，这是什么原因？",
        "state": "closed",
        "user": "yiyele",
        "closed_by": "yiyele",
        "created_at": "2022-12-19T11:18:59+00:00",
        "updated_at": "2022-12-21T01:56:12+00:00",
        "closed_at": "2022-12-21T01:56:12+00:00",
        "comments_count": [
            "sserdoubleh",
            "yiyele",
            "sserdoubleh",
            "yiyele"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 177,
        "title": "PLATO-KAG生成的回复能否使用NSP模型的score排序",
        "body": "请问在知识应答PLATO-KAG生成应答后，能否使用plato2的stage2.2的NSP任务模型的输出score作排序？尝试设置--ranking_score nsp_score，运行失败了",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-12-24T05:58:48+00:00",
        "updated_at": "2022-12-26T07:39:49+00:00",
        "closed_at": "2022-12-26T07:39:49+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 173,
        "title": "InvalidArgumentError: Broadcast dimension mismatch",
        "body": "您好，我使用Knover训练了一个Plato2模型，但在使用hub serving start部署到我的后台后，使用jmeter测试，jmeter客户端报错。\r\n报错内容如下：\r\n InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [20, 16, 20, 27] and the shape of Y = [20, 16, 1, 8]. Received [27] in X is not equal to [8] in Y at i:3.\r\n[Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n[operator < elementwise_add > error]\",\"results\":\"\",\"status\":\"101\"}\r\n我的环境如下：\r\n服务部署平台：paddlepaddle-gpu容器。容器版本：paddlepaddle/paddle   2.3.2-gpu-cuda11.2-cudnn8\r\nKnover版本：0.0.6\r\nGPU数量：1\r\npaddlehub版本：2.3.0\r\n我完成了以下方案的测试：\r\n1、export CUDA_VISIBLE_DEVICES=0\r\n2、因为本地运行interact.py对应脚本成功，因此我将AIstudio上一位开发者的开源项目中的module.py中关于数据加载的部分按照Knover/knover/core/model.py中对应的部分重写了一次，但仍然报错。对比两步骤发现：本地调用时，将数据转换为tensor的部分shape恒定为20，但hub部署的服务过程中的tensor的shape会随着文本分词后的长度而变化。我不太清楚应该修改哪个部分，请问是否有这方面的方案，或者在该版本下的plato2_en_base的部署教程啊？\r\n2中的开源作者的AIStudio的链接为：https://aistudio.baidu.com/aistudio/projectdetail/1197592\r\n谢谢",
        "state": "open",
        "user": "what-is-perfect",
        "closed_by": null,
        "created_at": "2022-12-06T09:49:37+00:00",
        "updated_at": "2022-12-06T19:43:27+00:00",
        "closed_at": null,
        "comments_count": [
            "what-is-perfect",
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 178,
        "title": "关于PLATO-KAG模型部署后的回答生成",
        "body": "学习了./scripts/single_gpu/infer.sh脚本，里面有build data，eval ppl，generation，eval F1等几个脚本组成。如果我只想根据输入数据和知识生成回答的话，是否只要跑infer_generation.conf这一个脚本就够了？我看论文里是分知识排序选择和根据选择的知识来生成回复两步，KAG模型部署后，是否也需要先运行一次选择知识，再运行第二次生成回复两步呢？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2022-12-26T09:57:50+00:00",
        "updated_at": "2022-12-27T07:44:38+00:00",
        "closed_at": "2022-12-27T07:44:38+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 181,
        "title": "KAG训练中mean_mlm_ce指标的意义是什么",
        "body": null,
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2023-01-09T07:57:35+00:00",
        "updated_at": "2023-01-09T07:59:19+00:00",
        "closed_at": "2023-01-09T07:59:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 179,
        "title": "Release of training code for QKConv",
        "body": "@christineaa Thanks for sharing nice work !\r\n\r\nDo you have any plans to release the training code ?",
        "state": "open",
        "user": "robinsongh381",
        "closed_by": null,
        "created_at": "2022-12-28T05:06:34+00:00",
        "updated_at": "2023-09-11T08:02:02+00:00",
        "closed_at": null,
        "comments_count": [
            "christineaa",
            "robinsongh381",
            "christineaa",
            "dhx20150812",
            "christineaa",
            "dhx20150812",
            "robinsongh381",
            "robinsongh381",
            "christineaa",
            "robinsongh381",
            "christineaa"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 180,
        "title": "KAG训练中mean_mlm_ce指标的意义是什么",
        "body": "在plato2-KAG模型的训练过程中有两个评价指标：loss和mean_mlm_ce，猜测loss是生成的回答和训练数据中tgt之间的损失，mean_mlm_ce是否衡量知识选择的正确概率？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2023-01-09T07:57:28+00:00",
        "updated_at": "2023-01-10T10:23:32+00:00",
        "closed_at": "2023-01-10T04:30:07+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 182,
        "title": "lr scheduler参数设置",
        "body": "看到有关lr scheduler设置的代码：group.add_argument(\"--lr_scheduler\", type=str, default=\"noam\", choices=[\"linear\", \"noam\", \"constant\", \"cosine\"],是否可以在训练的conf中设置--lr_scheduler？",
        "state": "closed",
        "user": "guijuzhejiang",
        "closed_by": "guijuzhejiang",
        "created_at": "2023-02-11T10:49:37+00:00",
        "updated_at": "2023-02-13T10:40:46+00:00",
        "closed_at": "2023-02-13T10:40:46+00:00",
        "comments_count": [
            "sserdoubleh",
            "guijuzhejiang",
            "sserdoubleh",
            "guijuzhejiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 186,
        "title": "训练plato2.2L",
        "body": "需要多少的GPU\r\n\r\n训练集示例样本，一般需要多少条，我想通过GPT生成，是否能行\r\n\r\n训练后部署占用多少推理GPU RAM",
        "state": "open",
        "user": "ChuXNobody",
        "closed_by": null,
        "created_at": "2023-09-15T00:04:52+00:00",
        "updated_at": "2023-09-15T00:04:52+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 185,
        "title": "Methods of PLATO-KAG pre-training for other languages",
        "body": "In README.md, the methods of fine-tuning is based on the Chinese and English pretrain models.\r\nIf we want to generate a pretrain model in other language, how should we train it?\r\n\r\nhttps://github.com/PaddlePaddle/Knover/blob/develop/projects/PLATO-KAG/README.md",
        "state": "open",
        "user": "ak-sakamoto",
        "closed_by": null,
        "created_at": "2023-05-17T09:49:09+00:00",
        "updated_at": "2023-05-17T10:29:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 183,
        "title": "Changing the allowed maximum conversation length in Plato-2",
        "body": "Plato-2 removes all the conversation data points which exceed its constraint of conversation length. **How can I increase this allowed conversation length** so as to incorporate context lengths? \r\n\r\nPlease do help, I have been trying to do this for a while now. But everytime it seems like the pretrained weights that is being downloaded for the 24L model has a fixed unique vocabulary size, which leads to the training to not happen.\r\n\r\nThank you.",
        "state": "open",
        "user": "Sidx-sys",
        "closed_by": null,
        "created_at": "2023-03-06T09:30:39+00:00",
        "updated_at": "2023-03-07T05:53:47+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 184,
        "title": "Using PLATO-XL for inference on 3 or more GPUs",
        "body": "Hi, thanks for you impressive work.\r\n\r\nI'm currently trying to deploy PLATO-XL service on RTX3090. The deployment is successful, however, I'm only able to input no more than 3 rounds as RTX3090 only has 24GB memory. I also try to use args \"--mem_efficient true\" or change the embedding size to 512, but they are not very useful.\r\n\r\nIs there any way to run PLATO-XL on 3 or more GPUs instead of 2? I notice that when setting cuda visible device to 3 in config file(e.g., interact.conf), the script will split the checkpoint to 3. However, I got this error while running interact.sh. Is there any way to solve it?\r\n\r\nLooking forward for your reply.\r\n\r\n<img width=\"1323\" alt=\"截屏2023-04-21 15 06 10\" src=\"https://user-images.githubusercontent.com/58215584/233565541-6bd4fc18-e811-4c03-8ebd-4e945d4a1a15.png\">\r\n\r\n",
        "state": "closed",
        "user": "Kaka23333",
        "closed_by": "Kaka23333",
        "created_at": "2023-04-21T07:07:19+00:00",
        "updated_at": "2023-04-21T14:19:04+00:00",
        "closed_at": "2023-04-21T14:19:04+00:00",
        "comments_count": [
            "sserdoubleh",
            "Kaka23333"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Knover",
        "number": 187,
        "title": "AG-DST模型开源了吗",
        "body": "只找到了项目的使用代码，没有找到模型的开源代码，请问AG-DST的模型源码开园了吗",
        "state": "open",
        "user": "mirrorball799",
        "closed_by": null,
        "created_at": "2024-02-27T08:44:33+00:00",
        "updated_at": "2024-03-04T15:43:29+00:00",
        "closed_at": null,
        "comments_count": [
            "ShaneTian"
        ],
        "labels": []
    }
]