[
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 52,
        "title": "dnn 数据预处理问题、py3兼容问题及文档问题",
        "body": "模型：https://github.com/PaddlePaddle/PaddleRec/tree/master/models/rank/dnn\r\n\r\n1：dataset_generator.py中zip(feature_name, [dense_feature] + sparse_feature + [label])在py3中不兼容，需要修改为list(zip(feature_name, [dense_feature] + sparse_feature + [label]))\r\n\r\n2：get_slot_data.py文件64行print及strip()方法不兼容py3，需修改为print(s.strip(b''))\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dnn/data/get_slot_data.py#L64\r\n\r\n3：文档中的network_conf.py需要修改为代码目录中的model.py\r\n\r\n4. dnn 文档修复",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-08T05:12:39+00:00",
        "updated_at": "2020-06-12T06:28:49+00:00",
        "closed_at": "2020-06-12T06:28:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 59,
        "title": "rank/fgcnn训练预测速度有些慢，希望后期可以优化一下。",
        "body": "修改fgcnn/model.py模型文件中的循环次数，与其它rank下其它模型对比速度仍很慢。",
        "state": "open",
        "user": "gentelyang",
        "closed_by": null,
        "created_at": "2020-06-09T09:44:13+00:00",
        "updated_at": "2020-06-09T09:44:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 65,
        "title": "single_infer报错",
        "body": "配置dataset type=DataLoader的infer报错:  save_path  找不到\r\n\r\nsingle_infer的时候在runner 下不配置epochs报错",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-10T13:06:03+00:00",
        "updated_at": "2020-06-11T03:02:16+00:00",
        "closed_at": "2020-06-11T03:02:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 57,
        "title": "models/recall召回任务中，基于python3.6环境下，只有w2v不报错，ssr，youtube_dnn，gru4rec，gnn，ncf均报如下错",
        "body": "复现代码地址：https://github.com/PaddlePaddle/PaddleRec/tree/master/models/recall\r\n\r\n分别执行如下命令：\r\npython -m paddlerec.run -m paddlerec.models.recall.ssr # ssr\r\npython -m paddlerec.run -m paddlerec.models.recall.gru4rec # gru4rec\r\npython -m paddlerec.run -m paddlerec.models.recall.gnn # gnn\r\npython -m paddlerec.run -m paddlerec.models.recall.ncf # ncf\r\npython -m paddlerec.run -m paddlerec.models.recall.youtube_dnn #",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-08T15:51:36+00:00",
        "updated_at": "2020-06-12T06:28:49+00:00",
        "closed_at": "2020-06-12T06:28:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 61,
        "title": "try except error in python3",
        "body": "![image](https://user-images.githubusercontent.com/12492564/84223525-b69e3400-ab0c-11ea-855e-3c8443248bf0.png)\r\n",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-10T03:22:55+00:00",
        "updated_at": "2020-06-10T05:37:34+00:00",
        "closed_at": "2020-06-10T05:37:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 56,
        "title": "dnn模型dense参数不起作用",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dnn/model.py#L39\r\n\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dnn/model.py#L56\r\n\r\n\r\n把dense_input加上就可以",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-08T15:50:36+00:00",
        "updated_at": "2020-06-09T09:05:46+00:00",
        "closed_at": "2020-06-09T09:05:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 63,
        "title": "PaddleRec/core/trainers/single_trainer.py中cudaplace设置不灵活",
        "body": "        device = envs.get_global_env(\"device\")\r\n        if device == 'gpu':\r\n            self._place = fluid.CUDAPlace(0)\r\n        elif device == 'cpu':\r\n            self._place = fluid.CPUPlace()",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-10T04:24:41+00:00",
        "updated_at": "2020-06-12T06:44:20+00:00",
        "closed_at": "2020-06-12T06:44:20+00:00",
        "comments_count": [
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 45,
        "title": "代码风格，以及执行报错",
        "body": "参数未定义：\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/core/utils/validation.py#L23 \r\n\r\n不要使用python 内建函数作为参数：\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/core/utils/validation.py#L19\r\n\r\n执行报错：\r\n![image](https://user-images.githubusercontent.com/12492564/83935093-c35b1900-a7e8-11ea-90d2-ae67dc1a6374.png)\r\n\r\n",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "xjqbest",
        "created_at": "2020-06-06T03:28:10+00:00",
        "updated_at": "2020-06-08T15:52:08+00:00",
        "closed_at": "2020-06-08T15:52:07+00:00",
        "comments_count": [
            "xjqbest"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 30,
        "title": "NameError: name 'reduce' is not defined",
        "body": "官方代码 clone 下来，安装好后跑python -m paddlerec.run -m paddlerec.models.rank.dnn 报错；\r\nNameError: name 'reduce' is not defined",
        "state": "closed",
        "user": "YangYangL",
        "closed_by": "fuyinno4",
        "created_at": "2020-06-02T08:57:55+00:00",
        "updated_at": "2020-06-03T10:45:28+00:00",
        "closed_at": "2020-06-03T10:45:28+00:00",
        "comments_count": [
            "seiriosPlus",
            "YangYangL",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 73,
        "title": "rank下dnn\\dcn\\deepfm\\fnn等大部分模型，支持py3.6+QueueDataset训练（single_train）",
        "body": "拉取https://github.com/PaddlePaddle/PaddleRec/pull/71 兼容py3的pr后，本地测试发现py3+paddle1.7.2可支持QueueDataset训练。",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-11T11:39:20+00:00",
        "updated_at": "2020-06-12T05:11:06+00:00",
        "closed_at": "2020-06-12T05:11:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 75,
        "title": "debug选项没起作用",
        "body": "![image](https://user-images.githubusercontent.com/12492564/84472708-43d2bb80-acba-11ea-9ba0-193acf2d0bc7.png)\r\n",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "fuyinno4",
        "created_at": "2020-06-12T06:37:47+00:00",
        "updated_at": "2020-06-12T07:00:23+00:00",
        "closed_at": "2020-06-12T07:00:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 76,
        "title": "afm不兼容py3",
        "body": "Traceback (most recent call last):\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainer.py\", line 196, in context_process\r\n    self._status_processor[context['status']](context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/general_trainer.py\", line 98, in network\r\n    network_class.build_network(context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/framework/network.py\", line 87, in build_network\r\n    model.net(model._data_var, context[\"is_infer\"])\r\n  File \"/ssd2/liyang/paddlerec/PaddleRec/models/rank/afm/model.py\", line 140, in net\r\n    1])  # batch_size * (num_field*(num_field-1)/2) * 1\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layers/nn.py\", line 5674, in reshape\r\n    \"XShape\": x_shape})\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1877, in __init__\r\n    self.desc.check_attrs()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n2   paddle::framework::ExtractAttribute<std::vector<int, std::allocator<int> > >::operator()(boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>&) const\r\n3   std::_Function_handler<void ()(std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool), paddle::framework::TypedAttrChecker<std::vector<int, std::allocator<int> > > >::_M_invoke(std::_Any_data const&, std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool)\r\n4   paddle::framework::OpDesc::CheckAttrs()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot get attribute shape by type std::vector<int, std::allocator<int> >, its type is std::vector<float, std::allocator<float> > at (/paddle/paddle/fluid/framework/attribute.h:42)\r\n\r\nCatch Exception:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n2   paddle::framework::ExtractAttribute<std::vector<int, std::allocator<int> > >::operator()(boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>&) const\r\n3   std::_Function_handler<void ()(std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool), paddle::framework::TypedAttrChecker<std::vector<int, std::allocator<int> > > >::_M_invoke(std::_Any_data const&, std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool)\r\n4   paddle::framework::OpDesc::CheckAttrs()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot get attribute shape by type std::vector<int, std::allocator<int> >, its type is std::vector<float, std::allocator<float> > at (/paddle/paddle/fluid/framework/attribute.h:42)\r\n\r\nExit app. catch exception in precoss status:network_pass, except:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n2   paddle::framework::ExtractAttribute<std::vector<int, std::allocator<int> > >::operator()(boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>&) const\r\n3   std::_Function_handler<void ()(std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool), paddle::framework::TypedAttrChecker<std::vector<int, std::allocator<int> > > >::_M_invoke(std::_Any_data const&, std::unordered_map<std::string, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, boost::variant<boost::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string> >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >*, bool)\r\n4   paddle::framework::OpDesc::CheckAttrs()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot get attribute shape by type std::vector<int, std::allocator<int> >, its type is std::vector<float, std::allocator<float> > at (/paddle/paddle/fluid/framework/attribute.h:42)\r\n",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-12T07:32:18+00:00",
        "updated_at": "2020-08-10T06:09:37+00:00",
        "closed_at": "2020-08-10T06:09:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 77,
        "title": "（建议）paddlerec添加version",
        "body": "print(paddlerec. __ version __)没有version这个attr，建议添加。(输出0.02）",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-12T07:35:05+00:00",
        "updated_at": "2020-08-10T06:10:40+00:00",
        "closed_at": "2020-08-10T06:10:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 69,
        "title": "文档需要更新",
        "body": "![image](https://user-images.githubusercontent.com/29789135/84341114-edd81800-abd4-11ea-8853-c9bda18c0eae.png)\r\n\r\n![image](https://user-images.githubusercontent.com/29789135/84341142-fd576100-abd4-11ea-89ef-fff6412b9566.png)\r\n\r\n![image](https://user-images.githubusercontent.com/29789135/84341128-f597bc80-abd4-11ea-863d-a5782a311d8c.png)\r\n",
        "state": "closed",
        "user": "MrChengmo",
        "closed_by": "MrChengmo",
        "created_at": "2020-06-11T03:16:48+00:00",
        "updated_at": "2020-06-12T07:09:36+00:00",
        "closed_at": "2020-06-12T07:09:36+00:00",
        "comments_count": [
            "MrChengmo",
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 82,
        "title": "GPU selected gpus 设置不生效",
        "body": "`run.py`中 selected gpus 是list",
        "state": "closed",
        "user": "MrChengmo",
        "closed_by": "MrChengmo",
        "created_at": "2020-06-13T08:49:27+00:00",
        "updated_at": "2020-07-10T12:12:09+00:00",
        "closed_at": "2020-07-10T12:12:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 78,
        "title": "local_cluster本地模拟分布式训练，不兼容py3",
        "body": "server端正常启动，worker端爆粗如下：\r\n\r\n\r\nI0612 09:03:26.418155  3451 communicator.h:252] AsyncCommunicator Initialized\r\nTraceback (most recent call last):\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainer.py\", line 246, in run\r\n    self.context_process(self._context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainer.py\", line 207, in context_process\r\n    self._status_processor[context['status']](context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/general_trainer.py\", line 95, in network\r\n    network_class.build_network(context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/framework/network.py\", line 165, in build_network\r\n    dataset[\"name\"], context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/framework/dataset.py\", line 90, in create_dataset\r\n    return self._get_dataset(dataset_name, context)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle_rec-0.0.2-py3.6.egg/paddlerec/core/trainers/framework/dataset.py\", line 126, in _get_dataset\r\n    file_list = context[\"fleet\"].split_files(file_list)\r\n  File \"/opt/_internal/cpython-3.6.0/lib/python3.6/site-packages/paddle/fluid/incubate/fleet/base/fleet_base.py\", line 179, in split_files\r\n    trainer_files[i] = files[begin:begin + blocks[i]]\r\nTypeError: slice indices must be integers or None or have an __index__ method\r\nCatch Exception:slice indices must be integers or None or have an __index__ method\r\n\r\n--------------------------------\r\nPaddleRec Error Message Summary:\r\n--------------------------------\r\n\r\nExit PaddleRec. catch exception in precoss status: [network_pass], except: slice indices must be integers or None or have an __index__ method\r\nTypeError",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-12T09:11:02+00:00",
        "updated_at": "2020-08-10T06:10:22+00:00",
        "closed_at": "2020-08-10T06:10:22+00:00",
        "comments_count": [
            "seiriosPlus",
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 107,
        "title": "（建议）使用DataLoader的时候，是否可以加个判单去掉QueueDataset can not support PY3, change to DataLoader提示。",
        "body": "![image](https://user-images.githubusercontent.com/25795827/84891398-63108500-b0ce-11ea-8be2-7c04d5ea5141.png)\r\n",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-06-17T11:12:08+00:00",
        "updated_at": "2020-08-10T06:10:01+00:00",
        "closed_at": "2020-08-10T06:10:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 89,
        "title": "mac下contentunderstanding.tagspace报错 ，linux下正常",
        "body": "python -m paddlerec.run -m paddlerec.models.contentunderstanding.tagspace\r\n\r\n```\r\nRuntimeError: Some of your fetched tensors hold LoD information.             They can not be completely cast to Python ndarray.             Please set the parameter 'return_numpy' as 'False' to             return LoDTensor itself directly.\r\n\r\nCatch Exception:Some of your fetched tensors hold LoD information.             They can not be completely cast to Python ndarray.             Please set the parameter 'return_numpy' as 'False' to             return LoDTensor itself directly.\r\n\r\n\r\n\r\n--------------------------------\r\n\r\nPaddleRec Error Message Summary:\r\n\r\n--------------------------------\r\n\r\n\r\n\r\nExit PaddleRec. catch exception in precoss status: [train_pass], except: Some of your fetched tensors hold LoD information.             They can not be completely cast to Python ndarray.             Please set the parameter 'return_numpy' as 'False' to             return LoDTensor itself directly.\r\n\r\nRuntimeError\r\n\r\n\r\n```",
        "state": "closed",
        "user": "xjqbest",
        "closed_by": "seiriosPlus",
        "created_at": "2020-06-16T03:42:41+00:00",
        "updated_at": "2020-08-10T07:21:49+00:00",
        "closed_at": "2020-08-10T07:21:49+00:00",
        "comments_count": [
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 121,
        "title": "tools目录下面是否可添加几个编译镜像用的dockerfile（ubuntu、centos、window、mac、py2、py3）",
        "body": "![image](https://user-images.githubusercontent.com/25795827/86318440-7c840600-bc64-11ea-9b07-142add1d28aa.png)\r\n\r\n效率云加CI需要dockerfile\r\n![image](https://user-images.githubusercontent.com/25795827/86326158-ddffa100-bc73-11ea-8c30-8916ec679259.png)\r\n\r\n缺少Dockerfile，效率云 CI 构建镜像会构建失败。",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-07-02T05:04:02+00:00",
        "updated_at": "2020-08-10T06:11:21+00:00",
        "closed_at": "2020-08-10T06:11:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 157,
        "title": "利用脚本下载的大数据安装遇到的问题，mark一下",
        "body": "python setup.py install 安装的时候会把目录下面提前下载好的大数据也cp一份数据，这个问题需要解决，这里记录一下",
        "state": "closed",
        "user": "frankwhzhang",
        "closed_by": "seiriosPlus",
        "created_at": "2020-07-24T03:51:50+00:00",
        "updated_at": "2020-08-13T05:10:03+00:00",
        "closed_at": "2020-08-13T05:10:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 135,
        "title": "Error while finding module specification for 'paddlerec.run' (ModuleNotFoundError: No module named 'paddlerec')",
        "body": "hi,dear\r\n没有这个东西啊，直接运行下面的\r\n```\r\npython -m paddlerec.run -m ./config.yaml\r\n#or\r\npython -m paddlerec.run -m paddlerec.models.recall.gnn\r\n```\r\n`Error while finding module specification for 'paddlerec.run' (ModuleNotFoundError: No module named 'paddlerec')`\r\n\r\n咋解决啊，大佬\r\n",
        "state": "closed",
        "user": "ucasiggcas",
        "closed_by": "seiriosPlus",
        "created_at": "2020-07-08T03:36:24+00:00",
        "updated_at": "2020-08-10T06:07:52+00:00",
        "closed_at": "2020-08-10T06:07:52+00:00",
        "comments_count": [
            "ucasiggcas",
            "MrChengmo",
            "ucasiggcas",
            "MrChengmo",
            "ucasiggcas",
            "123malin",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "123malin",
            "123malin",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 137,
        "title": "PaddleRec新增评价指标P，R, F1",
        "body": "如题~",
        "state": "open",
        "user": "123malin",
        "closed_by": null,
        "created_at": "2020-07-09T06:08:40+00:00",
        "updated_at": "2020-07-09T06:50:25+00:00",
        "closed_at": null,
        "comments_count": [
            "ucasiggcas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 140,
        "title": "非百度的员工可以参与开发这个项目吗？",
        "body": "对这个项目非常感兴趣，自己本身也是做推荐的，想参与到这个项目中，给推荐领域的开源工具添砖加瓦！",
        "state": "open",
        "user": "tcandzq",
        "closed_by": null,
        "created_at": "2020-07-11T02:18:14+00:00",
        "updated_at": "2020-07-13T08:55:46+00:00",
        "closed_at": null,
        "comments_count": [
            "guru4elephant",
            "tcandzq"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 153,
        "title": "分布式任务提交中遇到若干问题",
        "body": "1：文档只给出MPI_CPU的submit demo，未给出K8S_CPU\\K8S_GPU的submit demo。\r\n\r\n2:pip install paddlepaddle-gpu==1.7.2 --index-url=http://pip.baidu.com/pypi/simple --trusted-host pip.baidu.com mpi_cpu模式不需要gpu\r\n\r\n3：如何在paddlecloud运行py3未给出说明，有两种方式：①：通过添加一个run.sh,在里面配置PATH\r\n和执行python -m paddlerec.run -m config.yaml②：通过在config.ini中添加use_python3=1\r\n\r\n4:FLAGS_communicator_max_merge_var_num: 5这个Flags说明一下，在sync和half_async时，需要和cpu_num个数相同。\r\n\r\n5：个人感觉可以将backend.yaml文件中的内容全部放到config.yaml中，backend.yaml中重要是一个配置config和summit提交job作业，没有必要单独弄一个backend.yaml,只留一个config.yaml文档说明清楚如何配置提交到cloud的config和summit即可，这样从单机单卡、单机多卡、local_cluster\\cluster都可以只用config.yaml，简洁明了；\r\n\r\n6：现在cluster模式，只能支持train，未添加infer相关功能。\r\n需求：PaddleRec分布式预测功能添加。\r\n\r\n7：config.ini中的cpu_num默认等于1，如何通过backend.yaml控制cpu_num的值？文档需给出明确说明。",
        "state": "open",
        "user": "MrChengmo",
        "closed_by": null,
        "created_at": "2020-07-22T05:48:06+00:00",
        "updated_at": "2020-07-22T05:49:12+00:00",
        "closed_at": null,
        "comments_count": [
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 148,
        "title": "listwise不支持dataset？",
        "body": "raceback (most recent call last):\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainer.py\", line 246, in run\r\n    self.context_process(self._context)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainer.py\", line 207, in context_process\r\n    self._status_processor[context['status']](context)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainers/general_trainer.py\", line 90, in network\r\n    network_class.build_network(context)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainers/framework/network.py\", line 106, in build_network\r\n    context)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainers/framework/dataset.py\", line 90, in create_dataset\r\n    return self._get_dataset(dataset_name, context)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainers/framework/dataset.py\", line 118, in _get_dataset\r\n    dataset.set_batch_size(batch_size)\r\n  File \"/opt/_internal/cpython-2.7.11-ucs4/lib/python2.7/site-packages/paddle/fluid/dataset.py\", line 155, in set_batch_size\r\n    self.proto_desc.batch_size = batch_size\r\nTypeError: None has type NoneType, but expected one of: int, long\r\nCatch Exception:None has type NoneType, but expected one of: int, long\r\n\r\n--------------------------------\r\nPaddleRec Error Message Summary:\r\n--------------------------------\r\n\r\nExit PaddleRec. catch exception in precoss status: [network_pass], except: None has type NoneType, but expected one of: int, long\r\nTypeError",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-07-16T06:39:57+00:00",
        "updated_at": "2020-07-16T10:20:11+00:00",
        "closed_at": "2020-07-16T10:20:11+00:00",
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 168,
        "title": "【用户使用问题】数据读取异常报错，原因是隐藏文件导致",
        "body": "如题，config.yaml 记录的data_path路径下有未知文件或者隐藏文件导致数据读取异常",
        "state": "open",
        "user": "frankwhzhang",
        "closed_by": null,
        "created_at": "2020-08-07T03:20:53+00:00",
        "updated_at": "2020-09-04T09:19:18+00:00",
        "closed_at": null,
        "comments_count": [
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 169,
        "title": "【用户使用问题】save_inference_model的fetch_var使用不友好，需要修复",
        "body": "如题，现在用户使用save_inference_model保存完整模型结构需要配置save_inference_path,  save_inference_feed_varnames, save_inference_fetch_varnames的接口， 其中fetch_var_names需要用户在组网中指导对应变量的var_names而不是自己指定的变量。目前建议的使用方式：ctcvr_prop_one = fluid.layers.elementwise_mul(ctr_prop_one,cvr_prop_one,name=\"fetch_name_ctcvr\")",
        "state": "open",
        "user": "frankwhzhang",
        "closed_by": null,
        "created_at": "2020-08-07T03:30:50+00:00",
        "updated_at": "2020-08-07T03:30:50+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 193,
        "title": "【用户使用问题】建议支持每个epoch文件级别的shuffle",
        "body": "",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-08-28T03:26:52+00:00",
        "updated_at": "2020-08-28T03:26:52+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 180,
        "title": "esmm训练样本格式",
        "body": "你好，请问原始训练集经过处理后（reader.py）样本格式是 index，click_label，conversion_label，field_index:feature_index...   此处并没有用到特征具体的value值。可参照PaddleRec/models/multitask/esmm/data/train/small.txt目录下的测试样本。为什么没有特征的val，此处是把所有的特征都当做了离散特征所以只记录了index吗？\r\n",
        "state": "open",
        "user": "come-come",
        "closed_by": null,
        "created_at": "2020-08-18T08:44:41+00:00",
        "updated_at": "2020-09-15T03:12:43+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 194,
        "title": "【用户使用问题】建议支持组batch的功能",
        "body": "增加配置， 可以自己在reader里面组完batch后训练直接用，dien模型下有这个配置，貌似还不通用",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-08-28T03:29:58+00:00",
        "updated_at": "2020-08-28T03:29:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 195,
        "title": "【用户使用问题】支持reader.py debug",
        "body": "RT~",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-08-28T03:30:41+00:00",
        "updated_at": "2020-08-28T03:30:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 196,
        "title": "【用户使用问题】save按batch个数存储",
        "body": "SAVE按batch个数存储\r\nsave按batch只有dataloader可以做\r\npaddlerec还不支持对batch进行save",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-08-28T06:25:33+00:00",
        "updated_at": "2020-08-28T06:25:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 192,
        "title": "ESMM, python reader.py文件不存在",
        "body": "不太清楚这个 reader.py是怎么实现的\r\nPaddleRec/models/multitask/esmm/data/run.sh",
        "state": "open",
        "user": "jxlijunhao",
        "closed_by": null,
        "created_at": "2020-08-26T12:31:59+00:00",
        "updated_at": "2020-08-27T01:50:25+00:00",
        "closed_at": null,
        "comments_count": [
            "mmglove"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 202,
        "title": "AIStudio安装PaddleRec 时出错，黄埔学员有两位出错",
        "body": "执行教程的时候\r\n# 环境部署\r\n# 安装PaddleRec\r\n!cd PaddleRec/ && python setup.py install \r\n在第一步遇到了错误，错误如下：\r\n[Errno -3] Temporary failure in name resolution  的问题\r\n![image](https://user-images.githubusercontent.com/11599059/91822620-9fce3000-ec6a-11ea-93af-ab3e330c70fe.png)\r\n\r\n请问是否下载地址需要换一个了？ ",
        "state": "open",
        "user": "chaoshong",
        "closed_by": null,
        "created_at": "2020-09-01T07:51:15+00:00",
        "updated_at": "2020-09-01T07:51:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 201,
        "title": "【用户使用问题】cluster training下默认0号GPU的卡冲突问题",
        "body": "cluster-trainer模式下，默认select_gpus是0，在集群上是有问题的，会导致卡冲突。",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-08-31T15:19:23+00:00",
        "updated_at": "2020-08-31T15:19:23+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 200,
        "title": "【用户使用问题】目前PaddleRec在提交PaddleCloud分布式任务时，不支持多机多卡",
        "body": "RT，目前仅支持多机单卡，或多机多卡（伪，使用Parallel Executor 龟速运行），应该在每个分布式节点上使用 fleet.run 或 paddle.distributed.launch方法启动多机多卡训练。",
        "state": "open",
        "user": "MrChengmo",
        "closed_by": null,
        "created_at": "2020-08-31T08:26:04+00:00",
        "updated_at": "2020-08-31T08:47:11+00:00",
        "closed_at": null,
        "comments_count": [
            "fuyinno4"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 209,
        "title": "【用户使用问题】dataloader按照step保存模型",
        "body": "支持Collective、PS、单机模式",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-09-07T07:46:55+00:00",
        "updated_at": "2020-09-07T07:46:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 211,
        "title": "【文档】主页缺乏onlinetraining文档",
        "body": "",
        "state": "open",
        "user": "fuyinno4",
        "closed_by": null,
        "created_at": "2020-09-08T01:45:21+00:00",
        "updated_at": "2020-09-08T01:45:21+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 212,
        "title": "【用户使用问题】demo跑不通，aistudio可跑通，两者存在不一致",
        "body": "",
        "state": "open",
        "user": "fuyinno4",
        "closed_by": null,
        "created_at": "2020-09-08T01:45:54+00:00",
        "updated_at": "2020-09-08T01:45:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 215,
        "title": "Windows上 GPU paddle跑CPU模型时报WITH_NCCL的错 ",
        "body": "Windows上 GPU paddle跑CPU模型时报WITH_NCCL的错 \r\npaddle=1.8.4.post107\r\npython=3.6\\2.7\r\n报错模型\r\nfibinet\\flen  \\word2vec\r\npython -m paddlerec.run -m models/rank/word2vec/config.yaml\r\n使用gpu 版本的paddle跑CPUmode 的时候会报下面的错，如果修改mode为gpu，则正常\r\n![image](https://user-images.githubusercontent.com/38800877/92709839-d81bef80-f389-11ea-96ed-1678673223be.png)\r\n",
        "state": "open",
        "user": "mmglove",
        "closed_by": null,
        "created_at": "2020-09-10T09:20:25+00:00",
        "updated_at": "2020-09-10T09:20:25+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 203,
        "title": "文档：自定义reader 失效了",
        "body": "",
        "state": "closed",
        "user": "wangsiji",
        "closed_by": "wangsiji",
        "created_at": "2020-09-02T07:53:04+00:00",
        "updated_at": "2020-10-13T03:06:54+00:00",
        "closed_at": "2020-10-13T03:06:46+00:00",
        "comments_count": [
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 218,
        "title": "有尝试把deepfm模型的fm侧换成afm模型吗",
        "body": "",
        "state": "open",
        "user": "sitongchen",
        "closed_by": null,
        "created_at": "2020-09-15T03:06:11+00:00",
        "updated_at": "2020-09-15T03:06:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 216,
        "title": "windows单机cpu下跑word2vec报错，麻烦看一下",
        "body": "![image](https://user-images.githubusercontent.com/67900310/92714586-fe905980-f38e-11ea-8ec6-44bdb7210bd7.png)\r\n",
        "state": "open",
        "user": "atizz",
        "closed_by": null,
        "created_at": "2020-09-10T09:56:56+00:00",
        "updated_at": "2020-09-23T13:55:11+00:00",
        "closed_at": null,
        "comments_count": [
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 224,
        "title": "【用户使用问题】升级支持paddle的版本",
        "body": "目前6月底的v0.1.0只支持1.7.2，建议支持>=1.7.2 ＜=1.8.5 ",
        "state": "open",
        "user": "vslyu",
        "closed_by": null,
        "created_at": "2020-09-16T02:01:39+00:00",
        "updated_at": "2020-09-18T13:02:37+00:00",
        "closed_at": null,
        "comments_count": [
            "cheerser",
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 219,
        "title": "【用户使用问题】SR-GNN训练速度及推理速度不及预期",
        "body": "<img width=\"529\" alt=\"image\" src=\"https://user-images.githubusercontent.com/29789135/93161261-c9945600-f744-11ea-82e3-a7d56f559435.png\">\r\n",
        "state": "open",
        "user": "MrChengmo",
        "closed_by": null,
        "created_at": "2020-09-15T03:17:14+00:00",
        "updated_at": "2020-10-21T09:31:45+00:00",
        "closed_at": null,
        "comments_count": [
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas",
            "ucasiggcas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 232,
        "title": "runner里不配置phase，需要check",
        "body": "",
        "state": "open",
        "user": "fuyinno4",
        "closed_by": null,
        "created_at": "2020-09-24T01:48:34+00:00",
        "updated_at": "2020-09-24T01:48:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 237,
        "title": "Aborted at 1601178025 (unix time) try \"date -d @1601178025\" if you are using GNU date",
        "body": "Traceback (most recent call last):\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/trainers/framework/../../utils/dataset_instance.py\", line 47, in <module>\r\n    reader.run_from_stdin()\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/incubate/data_generator/__init__.py\", line 128, in run_from_stdin\r\n    for user_parsed_line in line_iter():\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle_rec-0.1.0-py2.7.egg/paddlerec/core/reader.py\", line 83, in reader\r\n    feasign = int(slot_feasign[1])\r\nIndexError: list index out of range\r\nW0927 11:46:20.432853  1311 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0927 11:46:20.432900  1311 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0927 11:46:20.432905  1311 init.cc:214] The detail failure signal is:\r\n\r\nW0927 11:46:20.432910  1311 init.cc:217] *** Aborted at 1601178380 (unix time) try \"date -d @1601178380\" if you are using GNU date ***\r\nW0927 11:46:20.434149  1311 init.cc:217] PC: @                0x0 (unknown)\r\nW0927 11:46:20.434366  1311 init.cc:217] *** SIGSEGV (@0x0) received by PID 1290 (TID 0x7f0ceeafd700) from PID 0; stack trace: ***\r\nW0927 11:46:20.435386  1311 init.cc:217]     @     0x7f0d376ac390 (unknown)\r\nW0927 11:46:20.435848  1311 init.cc:217]     @     0x7f0d134b3d16 _ZNSt19_Sp_counted_deleterIP8_IO_FILEZN6paddle9framework11shell_popenERKSsS5_PiEUlS1_E_SaIiELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv\r\nW0927 11:46:20.436623  1311 init.cc:217]     @     0x7f0d11807b59 std::_Sp_counted_base<>::_M_release()\r\nPython error: <stdin> is a directory, cannot continue\r\nW0927 11:46:20.437424  1311 init.cc:217]     @     0x7f0d11b80efd paddle::framework::MultiSlotDataFeed::ReadThread()\r\nW0927 11:46:20.438167  1311 init.cc:217]     @     0x7f0d29fa1c5c execute_native_thread_routine_compat\r\nW0927 11:46:20.439100  1311 init.cc:217]     @     0x7f0d376a26ba start_thread\r\nW0927 11:46:20.440027  1311 init.cc:217]     @     0x7f0d36cc841d clone\r\nW0927 11:46:20.440940  1311 init.cc:217]     @                0x0 (unknown)\r\nSegmentation fault (core dumped)",
        "state": "open",
        "user": "zbp-xxxp",
        "closed_by": null,
        "created_at": "2020-09-27T03:46:37+00:00",
        "updated_at": "2020-09-27T03:46:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 245,
        "title": "loopup_table_v2_op报错",
        "body": "paddlpaddle: 1.8.4\r\ncuda: 10.0\r\nmodel: multiview-simnet\r\n使用50w词表，数据格式按照标准转化方式转化如下：\r\n![image](https://user-images.githubusercontent.com/20043808/96855390-3e1e8b00-148f-11eb-9224-45a8ecdd5266.png)\r\n\r\n训练时报错：\r\n![image](https://user-images.githubusercontent.com/20043808/96855204-fc8de000-148e-11eb-9833-76407587fb79.png)\r\n",
        "state": "closed",
        "user": "barry2025",
        "closed_by": "barry2025",
        "created_at": "2020-10-22T09:51:53+00:00",
        "updated_at": "2020-10-22T09:52:48+00:00",
        "closed_at": "2020-10-22T09:52:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 233,
        "title": "【Error】windows下跑demo，train阶段报错， config.yaml为默认参数",
        "body": "报错信息如下：\r\nError Message Summary:\r\n----------------------\r\nError: Cannot open increment_recall\\0\\fc_1.w_0_moment1_0 to write at (D:\\1.7.2\\paddle\\paddle/fluid/operators/save_op.h:82)\r\n  [operator < save > error]\r\nEnforceNotMet\r\n![1](https://user-images.githubusercontent.com/22476573/94139769-c9126280-fe9c-11ea-8657-55a9db1bb8f3.png)\r\n",
        "state": "open",
        "user": "Energy9502",
        "closed_by": null,
        "created_at": "2020-09-24T11:33:16+00:00",
        "updated_at": "2020-09-26T14:38:26+00:00",
        "closed_at": null,
        "comments_count": [
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 242,
        "title": "请问新训练数据需要生成新的feat_dict_10.pkl2文件吗？",
        "body": "刚使用这个库在新数据上用没什么效果，请问是需要根据新的训练数据生成feat_dict_10.pkl2吗？还是说用已下载的就可以了。",
        "state": "open",
        "user": "jqsl2012",
        "closed_by": null,
        "created_at": "2020-10-04T13:39:24+00:00",
        "updated_at": "2020-10-15T05:17:48+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "jqsl2012",
            "yinhaofeng",
            "jqsl2012"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 249,
        "title": "【使用问题】如何安装最新版本的paddlerec",
        "body": "用 \r\nhttps://github.com/PaddlePaddle/PaddleRec\r\n介绍的方法，只能安装 0.1.0 版本",
        "state": "open",
        "user": "xmuyong",
        "closed_by": null,
        "created_at": "2020-10-28T05:43:36+00:00",
        "updated_at": "2020-10-28T08:20:57+00:00",
        "closed_at": null,
        "comments_count": [
            "vslyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 251,
        "title": "直接pip 安装 paddlepaddle 和paddle-rec 执行gru4rec报错,源码编译安装不报错",
        "body": "",
        "state": "open",
        "user": "zhiweilin",
        "closed_by": null,
        "created_at": "2020-10-28T08:06:48+00:00",
        "updated_at": "2020-11-23T05:34:50+00:00",
        "closed_at": null,
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 252,
        "title": "[安装问题] ImportError: dlopen: cannot load any more object with static TLS",
        "body": "python -m pip install paddle-rec -i https://mirror.baidu.com/pypi/simple\r\n\r\nBuilding wheels for collected packages: pathlib\r\n  Building wheel for pathlib (setup.py) ... done\r\n  Created wheel for pathlib: filename=pathlib-1.0.1-py3-none-any.whl size=14348 sha256=1a742bbaae9155c36eefeaa0b66852843bdb4242f4b650bb96cf9b7887819ff6\r\n  Stored in directory: /home/work/.cache/pip/wheels/ea/c2/62/0ae2836c6f4c45d02165aa3ae1e864f91b774dadc8ec9ec3ee\r\nSuccessfully built pathlib\r\nInstalling collected packages: astor, numpy, opencv-python, graphviz, objgraph, Pillow, pyparsing, kiwisolver, six, python-dateutil, cycler, matplotlib, decorator, protobuf, funcsigs, pathlib, click, joblib, tqdm, regex, nltk, PyYAML, rarfile, wcwidth, prettytable, idna, urllib3, chardet, requests, gast, scipy, paddlepaddle, paddle-rec\r\nSuccessfully installed Pillow-8.0.1 PyYAML-5.3.1 astor-0.8.1 chardet-3.0.4 click-7.1.2 cycler-0.10.0 decorator-4.4.2 funcsigs-1.0.2 gast-0.3.3 graphviz-0.14.2 idna-2.10 joblib-0.17.0 kiwisolver-1.3.0 matplotlib-3.3.2 nltk-3.5 numpy-1.19.2 objgraph-3.5.0 opencv-python-4.2.0.32 paddle-rec-1.8.5.1 paddlepaddle-1.8.5 pathlib-1.0.1 prettytable-1.0.1 protobuf-3.13.0 pyparsing-2.4.7 python-dateutil-2.8.1 rarfile-4.0 regex-2020.10.23 requests-2.24.0 scipy-1.5.3 six-1.15.0 tqdm-4.51.0 urllib3-1.25.11 wcwidth-0.2.5\r\n\r\n\r\n\r\npython\r\nPython 3.7.9 (default, Aug 31 2020, 12:42:55)\r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddle\r\n/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/core.py:194: UserWarning: Load /usr/lib64/libgomp.so.1 failed\r\n  warnings.warn(\"Load {} failed\".format(dso_absolute_path))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/__init__.py\", line 37, in <module>\r\n    import paddle.complex\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/complex/__init__.py\", line 15, in <module>\r\n    from . import tensor\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/complex/tensor/__init__.py\", line 15, in <module>\r\n    from . import math\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/complex/tensor/math.py\", line 15, in <module>\r\n    from paddle.common_ops_import import *\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/common_ops_import.py\", line 15, in <module>\r\n    from paddle.fluid.layer_helper import LayerHelper\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 35, in <module>\r\n    from . import framework\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/core.py\", line 273, in <module>\r\n    raise e\r\n  File \"/home/work/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/core.py\", line 243, in <module>\r\n    from .core_avx import *\r\nImportError: dlopen: cannot load any more object with static TLS\r\n\r\n\r\n【miniconda3 安装的 python3.7】",
        "state": "open",
        "user": "xmuyong",
        "closed_by": null,
        "created_at": "2020-10-28T10:46:09+00:00",
        "updated_at": "2020-11-23T05:29:20+00:00",
        "closed_at": null,
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 258,
        "title": "[使用问题] paddlecloud分布式训练报错",
        "body": "**问题概述**：参照distributed_train.md教程提交paddlecloud训练任务。demo和配置同教程所述，配置采用`K8S集群的Collective模式配置`。任务运行没有输出，日志有报错。\r\n\r\n**任务详情**\r\n\r\n安装paddle-rec（run.log显示安装成功）\r\n\r\n```\r\n# before_hook.sh\r\npip install paddle-rec==1.8.5.1\r\npip uninstall -y paddlepaddle\r\npython -m pip install paddlepaddle-gpu==1.8.5.post107 -i https://mirror.baidu.com/pypi/simple\r\n```\r\n\r\n\r\n报错信息(workerlog)\r\n```\r\n# /env_run/logs/workerlog.0\r\n...\r\n/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: Deprec\r\nationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses           \r\n  import imp                                                                                                                     \r\nTensorRT dynamic library (libnvinfer.so) that Paddle depends on is not configured correctly. (error code is libnvinfer.so: cannot\r\n open shared object file: No such file or directory)                                                                             \r\n  Suggestions:                                                                                                                   \r\n  1. Check if TensorRT is installed correctly and its version is matched with paddlepaddle you installed.                        \r\n  2. Configure TensorRT dynamic library environment variables as follows:                                                        \r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`                                                                   \r\n  - Windows: set PATH by `set PATH=XXX;PaddleRec: Runner collective_cluster Begin                                                \r\nPADDLEREC_CLUSTER_TYPE: K8S                                                                                                      \r\nPaddleRec run on device GPU: 0                                                                                                   \r\nExecutor Mode: train                                                                                                             \r\nprocessor_register begin                                                                                                         \r\nRunning CollectiveInstance.                                                                                                      \r\nRunning CollectiveNetwork.                                                                                                       \r\nTraceback (most recent call last):                                                                                               \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainer.py\", line 255, in run                    \r\n    self.context_process(self._context)                                                                                          \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainer.py\", line 216, in context_process        \r\n    self._status_processor[context['status']](context)                                                                           \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/general_trainer.py\", line 90, in network\r\n    network_class.build_network(context)                                                                                         \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/framework/network.py\", line 392, in buil\r\nd_network                                                                                                                        \r\n    model._data_loader)                                                                                                          \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/framework/dataset.py\", line 67, in get_d\r\nataloader\r\n    \"\", dataset_name, context[\"config_yaml\"], context)                                                                           \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/utils/dataloader_instance.py\", line 115, in slotd\r\nataloader_by_name                                                                                                                \r\n    hidden_file_list=[], data_file_list=[], train_data_path=data_path)                                                           \r\nTypeError: cannot unpack non-iterable NoneType object                                                                            \r\nCatch Exception:cannot unpack non-iterable NoneType object                                                                       \r\n                                                                                                                                 \r\n--------------------------------                                                                                                 \r\nPaddleRec Error Message Summary:                                                                                                 \r\n--------------------------------                                                                                                 \r\n                                                                                                                                 \r\nExit PaddleRec. catch exception in precoss status: [network_pass], except: cannot unpack non-iterable NoneType object            \r\nTypeError\r\n```\r\n\r\nrun.log日志\r\n```\r\nselected_gpus:range(0, 1)                                                                                                        \r\nuse_paddlecloud_flag:True                                                                                                        \r\nnode_ips:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724,job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b5\r\n8f-a0369f713724                                                                                                                  \r\nnode_ip:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724                                                      \r\nnode_rank:0                                                                                                                      \r\nnum_nodes: 2                                                                                                                     \r\ncluster:job_server:None pods:[\"rank:0 id:None addr:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None \r\nvisible_gpu:[] trainers:['gpu:[0] endpoint:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:0']\", \"\r\nrank:1 id:None addr:job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None visible_gpu:[] trainers:['gpu:[\r\n0] endpoint:job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:1']\"] job_stage_flag:None hdfs:None   \r\npod:rank:0 id:None addr:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None visible_gpu:[] trainers:['g\r\npu:[0] endpoint:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:0']                               \r\n~/paddlejob/workspace                                                                                                            \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/run.sh: 251] [start_user_end_hook_process] end_hook start ...                        \r\n~/paddlejob/workspace/env_run ~/paddlejob/workspace                                                                              \r\nRun before_hook.sh ...                                                                                                           \r\n~/paddlejob/workspace                                                                                                            \r\n~/paddlejob/workspace ~/paddlejob/workspace                                                                                      \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 14] [start_umount_afs] starting umount afs                        \r\nno need umount afs                                                                                                               \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 21] [start_umount_afs] finished umount afs                        \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 30] [data_clean] data_clear start ...                             \r\n~/paddlejob/workspace                                                                                                            \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/run.sh: 554] [taks_allreduce_mode] trainer successed.                                \r\nk8s job finished\r\n```",
        "state": "closed",
        "user": "tjufc",
        "closed_by": "tjufc",
        "created_at": "2020-11-11T05:05:14+00:00",
        "updated_at": "2020-11-11T05:09:13+00:00",
        "closed_at": "2020-11-11T05:09:13+00:00",
        "comments_count": [
            "tjufc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 259,
        "title": "[使用问题] paddlecloud分布式训练demo报错",
        "body": "**问题概述**：参照distributed_train.md教程提交paddlecloud训练任务。demo和配置同教程所述，配置采用`K8S集群的Collective模式配置`。任务运行没有输出，日志有报错。\r\n\r\n**任务详情**\r\n\r\n安装paddle-rec（run.log显示安装成功）\r\n\r\n```\r\n# before_hook.sh\r\npip install paddle-rec==1.8.5.1\r\npip uninstall -y paddlepaddle\r\npython -m pip install paddlepaddle-gpu==1.8.5.post107 -i https://mirror.baidu.com/pypi/simple\r\n```\r\n\r\n\r\n报错信息(workerlog)\r\n```\r\n# /env_run/logs/workerlog.0\r\n...\r\n/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: Deprec\r\nationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses           \r\n  import imp                                                                                                                     \r\nTensorRT dynamic library (libnvinfer.so) that Paddle depends on is not configured correctly. (error code is libnvinfer.so: cannot\r\n open shared object file: No such file or directory)                                                                             \r\n  Suggestions:                                                                                                                   \r\n  1. Check if TensorRT is installed correctly and its version is matched with paddlepaddle you installed.                        \r\n  2. Configure TensorRT dynamic library environment variables as follows:                                                        \r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`                                                                   \r\n  - Windows: set PATH by `set PATH=XXX;PaddleRec: Runner collective_cluster Begin                                                \r\nPADDLEREC_CLUSTER_TYPE: K8S                                                                                                      \r\nPaddleRec run on device GPU: 0                                                                                                   \r\nExecutor Mode: train                                                                                                             \r\nprocessor_register begin                                                                                                         \r\nRunning CollectiveInstance.                                                                                                      \r\nRunning CollectiveNetwork.                                                                                                       \r\nTraceback (most recent call last):                                                                                               \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainer.py\", line 255, in run                    \r\n    self.context_process(self._context)                                                                                          \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainer.py\", line 216, in context_process        \r\n    self._status_processor[context['status']](context)                                                                           \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/general_trainer.py\", line 90, in network\r\n    network_class.build_network(context)                                                                                         \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/framework/network.py\", line 392, in buil\r\nd_network                                                                                                                        \r\n    model._data_loader)                                                                                                          \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/trainers/framework/dataset.py\", line 67, in get_d\r\nataloader\r\n    \"\", dataset_name, context[\"config_yaml\"], context)                                                                           \r\n  File \"/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddlerec/core/utils/dataloader_instance.py\", line 115, in slotd\r\nataloader_by_name                                                                                                                \r\n    hidden_file_list=[], data_file_list=[], train_data_path=data_path)                                                           \r\nTypeError: cannot unpack non-iterable NoneType object                                                                            \r\nCatch Exception:cannot unpack non-iterable NoneType object                                                                       \r\n                                                                                                                                 \r\n--------------------------------                                                                                                 \r\nPaddleRec Error Message Summary:                                                                                                 \r\n--------------------------------                                                                                                 \r\n                                                                                                                                 \r\nExit PaddleRec. catch exception in precoss status: [network_pass], except: cannot unpack non-iterable NoneType object            \r\nTypeError\r\n```\r\n\r\nrun.log日志\r\n```\r\nselected_gpus:range(0, 1)                                                                                                        \r\nuse_paddlecloud_flag:True                                                                                                        \r\nnode_ips:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724,job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b5\r\n8f-a0369f713724                                                                                                                  \r\nnode_ip:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724                                                      \r\nnode_rank:0                                                                                                                      \r\nnum_nodes: 2                                                                                                                     \r\ncluster:job_server:None pods:[\"rank:0 id:None addr:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None \r\nvisible_gpu:[] trainers:['gpu:[0] endpoint:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:0']\", \"\r\nrank:1 id:None addr:job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None visible_gpu:[] trainers:['gpu:[\r\n0] endpoint:job-0bb5fab60b346c8c-trainer-1.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:1']\"] job_stage_flag:None hdfs:None   \r\npod:rank:0 id:None addr:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724 port:None visible_gpu:[] trainers:['g\r\npu:[0] endpoint:job-0bb5fab60b346c8c-trainer-0.e22e0c50-d2e3-11e9-b58f-a0369f713724:35024 rank:0']                               \r\n~/paddlejob/workspace                                                                                                            \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/run.sh: 251] [start_user_end_hook_process] end_hook start ...                        \r\n~/paddlejob/workspace/env_run ~/paddlejob/workspace                                                                              \r\nRun before_hook.sh ...                                                                                                           \r\n~/paddlejob/workspace                                                                                                            \r\n~/paddlejob/workspace ~/paddlejob/workspace                                                                                      \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 14] [start_umount_afs] starting umount afs                        \r\nno need umount afs                                                                                                               \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 21] [start_umount_afs] finished umount afs                        \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/tools/end_hook.sh: 30] [data_clean] data_clear start ...                             \r\n~/paddlejob/workspace                                                                                                            \r\n2020-11-11 12:02:00 [INFO] [/root/paddlejob/run.sh: 554] [taks_allreduce_mode] trainer successed.                                \r\nk8s job finished\r\n```",
        "state": "open",
        "user": "tjufc",
        "closed_by": null,
        "created_at": "2020-11-11T05:06:11+00:00",
        "updated_at": "2020-11-23T09:22:23+00:00",
        "closed_at": null,
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 266,
        "title": "排序模型BST里面multi-head attention的实现，没有实现positional_embedding 呢 ？？ ",
        "body": "我看到训练样本里面是有position特征，请问这个position特征代表的什么意思 ？？ ",
        "state": "open",
        "user": "FanWan",
        "closed_by": null,
        "created_at": "2020-11-24T11:30:08+00:00",
        "updated_at": "2020-11-24T11:30:08+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 261,
        "title": "models/demo 可不可以换成python3版本的",
        "body": "models/demo 可不可以换成python3版本的",
        "state": "open",
        "user": "q4323636",
        "closed_by": null,
        "created_at": "2020-11-14T02:27:31+00:00",
        "updated_at": "2020-12-03T07:43:56+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 270,
        "title": "在linux环境使用python3.7.3执行一键数据处理脚本data_prepare.sh报UnicodeDecodeError",
        "body": "用python3.7.3执行一键数据处理脚本data_prepare.sh，已将reload(sys)和sys.setdefaultencoding('utf-8')注释，print该加括号的已加，还是报以下错误：\r\n`Traceback (most recent call last):\r\n  File \"process_ml_1m.py\", line 137, in <module>\r\n    process(sys.argv[2])\r\n  File \"process_ml_1m.py\", line 17, in process\r\n    movie_dict = parse_movie_data(data_path + \"/movies.dat\", movie_fea)\r\n  File \"process_ml_1m.py\", line 45, in parse_movie_data\r\n    for line in open(file_name):\r\n  File \"/home/11102517/anaconda3/lib/python3.7/codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 3114: invalid continuation byte`",
        "state": "open",
        "user": "imitn",
        "closed_by": null,
        "created_at": "2020-12-03T11:58:14+00:00",
        "updated_at": "2020-12-03T11:58:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 262,
        "title": "能不能保存一下训练过程中的最佳模型",
        "body": "在paddleOCR中，训练的时候可以配置测试集，在测试集上的最佳模型会自动转存为best model。PaddleRec是否可以引入这个功能。避免训练过拟合，方便使用。谢谢",
        "state": "open",
        "user": "peterz3g",
        "closed_by": null,
        "created_at": "2020-11-17T08:10:27+00:00",
        "updated_at": "2020-12-31T03:11:17+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "peterz3g"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 296,
        "title": "请问现在发布版本1.8.5适配paddlepaddle2.0.0rc嘛",
        "body": "如题，支持的paddlepaddle2.0.0rc版本的paddleRec啥时候发布呢",
        "state": "open",
        "user": "wanghao19970205",
        "closed_by": null,
        "created_at": "2020-12-29T06:00:26+00:00",
        "updated_at": "2021-01-05T04:19:18+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghao19970205"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 316,
        "title": "Why do you need slice_end? Isn't this the same as the value of batch_size?",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/5cd4ae7e8da86262bc379b253d9f6cf83c4a7786/models/match/dssm/config_bigdata.yaml#L50",
        "state": "open",
        "user": "JepsonWong",
        "closed_by": null,
        "created_at": "2021-01-17T11:52:02+00:00",
        "updated_at": "2021-01-17T11:52:02+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 314,
        "title": "PaddleCloud训练配置修改问题",
        "body": "PaddleRec/doc/source/paddlerec/distributed_train.md\r\n\r\nPaddleCloud拷贝workspace目录下的output到最终的输出集群目录，这个说明文档中 save_checkpoint_path 需要改为 output/increment output/inference",
        "state": "open",
        "user": "zeronorm",
        "closed_by": null,
        "created_at": "2021-01-15T11:56:55+00:00",
        "updated_at": "2021-01-15T11:56:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 298,
        "title": "【文档】建议文档中把`快速开始`放在最上面",
        "body": "如题~",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "frankwhzhang",
        "created_at": "2020-12-30T02:00:59+00:00",
        "updated_at": "2021-12-08T09:27:55+00:00",
        "closed_at": "2021-12-08T09:27:55+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 361,
        "title": "paddle如何对接pyspark？",
        "body": "希望给个demo",
        "state": "open",
        "user": "forrestneo",
        "closed_by": null,
        "created_at": "2021-01-29T02:21:55+00:00",
        "updated_at": "2021-01-29T02:21:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 303,
        "title": "目前更新的动态图模型，能不能加上动转静保存整个模型，而不是分别保存模型参数和op参数，这样每次预测还得先重建网络结构",
        "body": "",
        "state": "closed",
        "user": "wanghao19970205",
        "closed_by": "frankwhzhang",
        "created_at": "2021-01-06T06:37:45+00:00",
        "updated_at": "2021-12-09T06:07:06+00:00",
        "closed_at": "2021-12-09T06:07:06+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 309,
        "title": "deepfm、xdeepfm run.sh error No module named paddlerec.tools.tools",
        "body": "![image](https://user-images.githubusercontent.com/16204466/104162179-13f5bd00-542f-11eb-9e40-65ba9bb1d3f7.png)\r\n",
        "state": "closed",
        "user": "wangheng19900315",
        "closed_by": "frankwhzhang",
        "created_at": "2021-01-11T09:04:48+00:00",
        "updated_at": "2021-12-09T06:07:27+00:00",
        "closed_at": "2021-12-09T06:07:27+00:00",
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 317,
        "title": "about dssm loss",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/5cd4ae7e8da86262bc379b253d9f6cf83c4a7786/models/match/dssm/train.py#L53\r\n\r\n感觉这里应该改为下面的代码：如果不加`axis`参数，后续的`paddle.mean`函数将没有任何意义，而且得到的`avg_cost`将会是一个batch中每条样本的`损失之和`，而不是`损失平均`。\r\n\r\n```\r\nloss = -paddle.sum(paddle.log(hit_prob), axis=-1)\r\navg_cost = paddle.mean(x=loss)\r\n```",
        "state": "closed",
        "user": "JepsonWong",
        "closed_by": "JepsonWong",
        "created_at": "2021-01-17T12:02:54+00:00",
        "updated_at": "2021-03-23T11:16:55+00:00",
        "closed_at": "2021-03-23T11:16:55+00:00",
        "comments_count": [
            "JepsonWong",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 375,
        "title": "模型版本",
        "body": "1.8.5 下面的所有模型会不会全部升级到2.0.0以上呢？",
        "state": "open",
        "user": "wangduan023",
        "closed_by": null,
        "created_at": "2021-02-04T09:55:05+00:00",
        "updated_at": "2021-07-20T06:18:16+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 418,
        "title": "runner参数不统一之[model_init_path, init_model_path]",
        "body": "有些地方写的是init_model_path，有些地方写的又是model_init_path，建议统一一下",
        "state": "open",
        "user": "thinkall",
        "closed_by": null,
        "created_at": "2021-04-19T01:49:25+00:00",
        "updated_at": "2021-04-19T01:49:25+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 429,
        "title": "add_sublayer的使用",
        "body": "当组网时，如果将网络层定义到自己的成员函数中，比如\r\n`self.fm = FM(sparse_feature_number, sparse_feature_dim)`\r\n使用时，需要通过add_sublayer函数添加到模型中，如\r\n`self.add_sublayer('cnn_%d' % i, _conv)`\r\n其中_conv为FM类中定义的网络层。\r\n\r\nPS：如果没有add_sublayer这一步，可能会导致动态图和静态图精度不一致的情况",
        "state": "closed",
        "user": "wangzhen38",
        "closed_by": "wangzhen38",
        "created_at": "2021-05-13T06:44:40+00:00",
        "updated_at": "2021-08-10T03:26:52+00:00",
        "closed_at": "2021-08-10T03:26:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 416,
        "title": "fm模型特征处理方法",
        "body": "使用fm模型需要将连续性特征值离散化后再输入模型吗？离散型特征值要one-hot转换再输入模型吗？",
        "state": "open",
        "user": "monkeyshichi",
        "closed_by": "monkeyshichi",
        "created_at": "2021-04-15T07:56:37+00:00",
        "updated_at": "2021-12-22T08:28:00+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "monkeyshichi",
            "DXQer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 451,
        "title": "DSSM模型实现有问题",
        "body": "针对models/match/dssm目录下实现的DSSM模型我们发现以下几个问题：\r\n\r\n1. 在net.py中，DSSM对于给定query的positive document和negative document使用了两个不同的编码器（self._pos_layers, self._neg_layers），这是不对的，所有的documents应该使用同一个编码器。\r\n这一问题会导致所有pairs的预测similarity都很高。在修改这个问题之后，我们得到了91.38的正序率，远高于项目中报告的79的正序率。\r\n\r\n2. 根据dygrapy_model.py中的loss定义函数定义，模型将最大化所有net.py返回的hit_prob的值（概率）。 目前，因为实验中只选择了一个negative样本且使用了slice函数进行切片, 所以对当前实验没有问题。但是如果negative样本数目大于1的话，hit_prob中将会返回negative样本的预测概率，导致模型最大化negative样本的预测概率。为了保证模型的适用性，建议将net.py中的slice切片实现修改为：hit_prob = paddle.slice( prob, axes=[0, 1], starts=[0, 0], ends=[self.slice_end, 1]) 。\r\n\r\n另外提一个改进建议，在cosine similarity 的基础上做softmax是不合适的，因为cosine similarity的值域为[-1, 1], 在此基础上做softmax, 正样本的概率最大为：exp(1)/(exp(1) +  N_n exp(-1)), 其中N_n为negative样本数目，会导致较大的损失。应该直接把内积输入到softmax层，这一做法可以进一步将上面的91.38提高到93.96.",
        "state": "closed",
        "user": "v-mipeng",
        "closed_by": "seemingwang",
        "created_at": "2021-05-21T03:12:48+00:00",
        "updated_at": "2021-06-18T03:11:39+00:00",
        "closed_at": "2021-06-18T03:11:39+00:00",
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 454,
        "title": "benchmark文件夹中小word2vec 模型，最少需要训练几个epoches可以观察收敛曲线",
        "body": "首先，我们发现PaddleRec中存在两个word2vec模型。[官方word2vec模型（大模型）](https://github.com/PaddlePaddle/PaddleRec/tree/master/models/recall/word2vec)，[benchmark word2vec模型（小模型，少一些op）](https://github.com/PaddlePaddle/PaddleRec/tree/master/models/recall/word2vec/benchmark)\r\n\r\n第一季度以来，Intel在帮助实现word2vec BF16训练版本，以benchmark word2vec模型做POC， 目前大部分功能已实现，正在精度测试。但是由于在官网只看到了大模型的精度参考值，如下[PaddleRec/models/recall/word2vec readme](https://github.com/PaddlePaddle/PaddleRec/tree/master/models/recall/word2vec)：\r\n![image](https://user-images.githubusercontent.com/47151829/120732187-78690400-c517-11eb-8d54-259d2b4dddde.png)\r\n\r\n官网文档没有提供 benchmark 小模型精度日志或者所需epoch及精度参考。\r\n\r\n问题：\r\n1. 如果想获得 benchmark 小模型 FP32的精度值，作为BF16训练的精度调整的参考，最少需要训练几个epoch可以？我们发现yaml 中默认值是15 epoches, 但是15个epoch 太久了，5个 epoches能说明收敛吗。\r\n2. 如果百度已经有 benchmark 小模型的训练日志或者精度记录，请发给我们，我们就不重新训练了，谢谢！\r\n3. 如果训练的话，能否可以多线程训练，设置CPU_NUM=12 可行吗？\r\n\r\nReproduction steps:\r\n```\r\npip install paddlepaddle==2.1.0\r\n\r\ngit clone https://github.com/PaddlePaddle/PaddleRec.git\r\ncd models/recall/word2vec/benchmark\r\n\r\n# Download the test data\r\n./benchmark_data.sh\r\n\r\n# Run FP32 training\r\npython -u ../../../../tools/static_ps_trainer.py -m benchmark.yaml\r\n\r\n```",
        "state": "open",
        "user": "lidanqing-intel",
        "closed_by": "lidanqing-intel",
        "created_at": "2021-06-04T01:21:01+00:00",
        "updated_at": "2021-12-22T08:28:10+00:00",
        "closed_at": null,
        "comments_count": [
            "lidanqing-intel",
            "frankwhzhang",
            "lidanqing-intel",
            "lidanqing-intel"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 468,
        "title": "https://github.com/PaddlePaddle/PaddleRec/blob/release/2.1.0/models/rank/wide_deep/net.py  wide 写错了吧",
        "body": "<img width=\"687\" alt=\"efab1d610cf101ac3739cf4aa13b1884\" src=\"https://user-images.githubusercontent.com/16644339/122723169-38d74180-d2a5-11eb-8cff-36bad996f776.png\">\r\n\r\n按照原来论文，wide deep model中wide的输入应该是spare 类别特征吧",
        "state": "open",
        "user": "zle1992",
        "closed_by": null,
        "created_at": "2021-06-21T07:28:25+00:00",
        "updated_at": "2021-06-22T03:57:02+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 470,
        "title": "Wide&Deep代码中对所有sparse特征只用一个embedding",
        "body": "wide deep代码里对sparse特征先做embedding，查看代码发现是直接统计所有sparse特征取值不同的数值，作为sparse_feature_number，来初始化一个embedding layer的，那这样子做岂不是不同sparse feature有同个值，embedding后的结果是一样的，比如A字段也有数值2，B字段也有数值2，这样子是不是没有区分度了\r\n![image](https://user-images.githubusercontent.com/33123730/123033875-12d3ad80-d41b-11eb-9504-b4d2a88ded46.png)\r\n![image](https://user-images.githubusercontent.com/33123730/123033895-1f580600-d41b-11eb-9be5-7f9897dab527.png)\r\n",
        "state": "closed",
        "user": "lhbrichard",
        "closed_by": "frankwhzhang",
        "created_at": "2021-06-23T04:04:30+00:00",
        "updated_at": "2021-12-08T09:27:09+00:00",
        "closed_at": "2021-12-08T09:27:09+00:00",
        "comments_count": [
            "frankwhzhang",
            "lhbrichard"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 493
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 472,
        "title": "1.8.5分支ESMM demo运行失败",
        "body": "厂内机器，paddle信息：\r\n![image](https://user-images.githubusercontent.com/30000773/124103296-b8c68e00-da93-11eb-9251-700ab50078d5.png)\r\n\r\n\r\n报错信息：\r\n\r\n`====================================================================================================\r\n                Runtime Envs                      Value\r\n----------------------------------------------------------------------------------------------------\r\ntrain.trainer.platform                            LINUX\r\ntrain.trainer.executor_mode                       train\r\ntrain.trainer.trainer                             GeneralTrainer\r\ntrain.trainer.engine                              single\r\ntrain.trainer.threads                             2\r\n====================================================================================================\r\n\r\n\r\n====================================================================================================\r\n            paddlerec Global Envs                 Value\r\n----------------------------------------------------------------------------------------------------\r\nhyper_parameters.optimizer.class                  adam\r\ndataset.dataset_infer.type                        QueueDataset\r\nrunner.train_runner.epochs                        3\r\nrunner.infer_runner.name                          infer_runner\r\nphase.infer.dataset_name                          dataset_infer\r\nphase.infer.thread_num                            1\r\nrunner.infer_runner.phases                        ['infer']\r\ndataset.dataset_train.name                        dataset_train\r\ndataset.dataset_train.batch_size                  5\r\nrunner.train_runner.save_checkpoint_interval      1\r\nhyper_parameters.vocab_size                       737946\r\nrunner.infer_runner.selected_gpus                 0\r\nrunner.infer_runner.device                        gpu\r\ndataset.dataset_train.type                        QueueDataset\r\nphase.train.thread_num                            1\r\ndataset.dataset_infer.name                        dataset_infer\r\nrunner.infer_runner.init_model_path               increment_esmm/1\r\nhyper_parameters.embed_size                       12\r\ndataset.dataset_infer.data_converter              models/multitask/esmm/esmm_reader.py\r\nrunner.train_runner.print_interval                10\r\ndataset.dataset_train.data_path                   models/multitask/esmm/data/train\r\nrunner.train_runner.phases                        ['train']\r\nhyper_parameters.optimizer.learning_rate          0.001\r\nphase.train.model                                 models/multitask/esmm/model.py\r\nphase.infer.name                                  infer\r\nrunner.infer_runner.print_interval                1\r\ndataset.dataset_train.data_converter              models/multitask/esmm/esmm_reader.py\r\nhyper_parameters.optimizer.strategy               async\r\nrunner.train_runner.selected_gpus                 0\r\ndataset.dataset_infer.batch_size                  5\r\nphase.infer.model                                 models/multitask/esmm/model.py\r\nrunner.train_runner.save_inference_path           inference\r\nrunner.train_runner.name                          train_runner\r\nphase.train.name                                  train\r\nrunner.infer_runner.class                         infer\r\nrunner.train_runner.save_inference_interval       4\r\ndataset.dataset_infer.data_path                   models/multitask/esmm/data/test\r\nphase.train.dataset_name                          dataset_train\r\nrunner.train_runner.device                        gpu\r\nrunner.train_runner.class                         train\r\nmode                                              ['train_runner', 'infer_runner']\r\nworkspace                                         models/multitask/esmm\r\nrunner.train_runner.save_checkpoint_path          increment_esmm\r\n====================================================================================================\r\n\r\nPaddleRec: Runner train_runner Begin\r\nPaddleRec run on device GPU: 0\r\nExecutor Mode: train\r\nprocessor_register begin\r\nRunning SingleInstance.\r\nRunning SingleNetwork.\r\nWarning:please make sure there are no hidden files in the dataset folder and check these hidden files:[]\r\nFile_list: ['models/multitask/esmm/data/train/small.txt']\r\nWarning:please make sure there are no hidden files in the dataset folder and check these hidden files:[]\r\nFile_list: ['models/multitask/esmm/data/test/small.txt']\r\nRunning SingleStartup.\r\nW0701 17:38:54.887231 58053 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0701 17:38:54.893249 58053 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\nRunning SingleRunner.\r\nTraceback (most recent call last):\r\n  File \"/home/work/niuyuhang/tools/python_paddle185_gpu/python/lib/python2.7/site-packages/paddle_rec-1.8.5-py2.7.egg/paddlerec/core/trainers/framework/../../utils/dataset_instance.py\", line 21, in <module>\r\n    **from paddlerec.core.utils.envs import lazy_instance_by_fliename**\r\nImportError: No module named paddlerec.core.utils.envs\r\nW0701 17:38:58.462741 58053 init.cc:226] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0701 17:38:58.462769 58053 init.cc:228] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0701 17:38:58.462775 58053 init.cc:231] The detail failure signal is:\r\n\r\nW0701 17:38:58.462781 58053 init.cc:234] *** Aborted at 1625132338 (unix time) try \"date -d @1625132338\" if you are using GNU date ***\r\nW0701 17:38:58.464403 58053 init.cc:234] PC: @                0x0 (unknown)\r\nW0701 17:38:58.464587 58053 init.cc:234] *** SIGSEGV (@0x0) received by PID 58053 (TID 0x7f57f4528700) from PID 0; stack trace: ***\r\nW0701 17:38:58.465903 58053 init.cc:234]     @     0x7f57f3ce0160 (unknown)\r\nW0701 17:38:58.467234 58053 init.cc:234]     @     0x7f572085ee46 _ZNSt19_Sp_counted_deleterIP8_IO_FILEZN6paddle9framework11shell_popenERKSsS5_PiEUlS1_E_SaIiELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv\r\nW0701 17:38:58.469238 58053 init.cc:234]     @     0x7f571d0744a9 std::_Sp_counted_base<>::_M_release()\r\nW0701 17:38:58.473094 58053 init.cc:234]     @     0x7f571d3c1258 paddle::framework::MultiSlotDataFeed::~MultiSlotDataFeed()\r\nW0701 17:38:58.474995 58053 init.cc:234]     @     0x7f571d0744a9 std::_Sp_counted_base<>::_M_release()\r\nW0701 17:38:58.476524 58053 init.cc:234]     @     0x7f571d390895 paddle::framework::DatasetImpl<>::DestroyReaders()\r\nW0701 17:38:58.477910 58053 init.cc:234]     @     0x7f571d1bb518 _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework7DatasetEJEJNS_4nameENS_9is_methodENS_7siblingENS_10call_guardIJNS_18gil_scoped_releaseEEEEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_E_vJSM_EJS6_S7_S8_SB_EEEvOSD_PFSC_SF_ESL_ENUlRNS_6detail13function_callEE1_4_FUNEST_\r\nW0701 17:38:58.479228 58053 init.cc:234]     @     0x7f571d0b40b9 pybind11::cpp_function::dispatcher()\r\nW0701 17:38:58.480751 58053 init.cc:234]     @     0x7f57f3ff9bb8 PyEval_EvalFrameEx\r\nW0701 17:38:58.482113 58053 init.cc:234]     @     0x7f57f3ffa460 PyEval_EvalFrameEx\r\nW0701 17:38:58.483494 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.484843 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.486197 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.487534 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.488898 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.490255 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.491608 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.492956 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.494313 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.495658 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.497013 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.498359 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.499702 58053 init.cc:234]     @     0x7f57f3ffa460 PyEval_EvalFrameEx\r\nW0701 17:38:58.501044 58053 init.cc:234]     @     0x7f57f3ffa460 PyEval_EvalFrameEx\r\nW0701 17:38:58.502399 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.503741 58053 init.cc:234]     @     0x7f57f3ffd1f2 PyEval_EvalCode\r\nW0701 17:38:58.505081 58053 init.cc:234]     @     0x7f57f3ffc858 PyEval_EvalFrameEx\r\nW0701 17:38:58.506446 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.507776 58053 init.cc:234]     @     0x7f57f3ffa345 PyEval_EvalFrameEx\r\nW0701 17:38:58.509127 58053 init.cc:234]     @     0x7f57f3ffd0bd PyEval_EvalCodeEx\r\nW0701 17:38:58.510396 58053 init.cc:234]     @     0x7f57f3f73eb0 function_call\r\nW0701 17:38:58.511759 58053 init.cc:234]     @     0x7f57f3f41df3 PyObject_Call\r\ntrain.sh: line 3: 58053 Segmentation fault      (core dumped) /home/work/niuyuhang/tools/python_paddle185_gpu/python/bin/python -m paddlerec.run -m models/multitask/esmm/config.yaml`\r\n\r\n由于执行用的命令是paddlepython185 -m paddlerec.run -m models/multitask/esmm/config.yaml，而非python -m paddlerec.run -m models/multitask/esmm/config.yaml尝试在出错文件/home/work/niuyuhang/tools/python_paddle185_gpu/python/lib/python2.7/site-packages/paddle_rec-1.8.5-py2.7.egg/paddlerec/core/trainers/framework/../../utils/dataset_instance.py中，import paddle，依然报相同错，怀疑是强行调用了python导致。但在运行前加入alias python=\"/home/work/niuyuhang/tools/python_paddle185_gpu/python/bin/python\"，无效，依然报错。",
        "state": "closed",
        "user": "Niuyuhang03",
        "closed_by": "Niuyuhang03",
        "created_at": "2021-07-01T09:46:34+00:00",
        "updated_at": "2021-07-01T13:15:08+00:00",
        "closed_at": "2021-07-01T13:15:08+00:00",
        "comments_count": [
            "Niuyuhang03",
            "Niuyuhang03"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 494
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 479,
        "title": "din 模型这个地方应该是乘号吧",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/9761b4d458c0f59314aaa29ca3926e5704091b9c/models/rank/din/model.py#L100",
        "state": "open",
        "user": "zle1992",
        "closed_by": null,
        "created_at": "2021-07-11T10:07:49+00:00",
        "updated_at": "2021-07-25T10:22:36+00:00",
        "closed_at": null,
        "comments_count": [
            "inpiredhss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 485,
        "title": "缺少reader.py",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/release/2.1.0/datasets/ali-ccp/data_process.sh\r\n\r\n缺少reader.py\r\n\r\n```\r\necho \"preprocessing data......\"\r\npython reader.py --train_data_path ${train_target_path} \\\r\n                 --test_data_path ${test_target_path} \\\r\n                 --vocab_path vocab/vocab_size.txt \\\r\n                 --train_sample_size 6400 \\\r\n                 --test_sample_size 6400 \\\r\n```",
        "state": "open",
        "user": "w5688414",
        "closed_by": null,
        "created_at": "2021-07-18T02:16:53+00:00",
        "updated_at": "2022-05-13T03:49:07+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "w5688414",
            "frankwhzhang",
            "jxlijunhao",
            "Helafeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 545,
        "title": "对于有专利保护的第三方算法比如Wide&Deep，实现并开源会侵犯知识产权吗？",
        "body": null,
        "state": "open",
        "user": "zhujiem",
        "closed_by": null,
        "created_at": "2021-09-10T13:43:22+00:00",
        "updated_at": "2021-09-10T13:43:22+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 504,
        "title": "关于DeepFM模型的Embedding层问题",
        "body": "请教下[deepfm/net.py](https://github.com/PaddlePaddle/PaddleRec/blob/release/2.1.0/models/rank/deepfm/net.py)里的FM layer里为何只总共只有一个embedding layer（`self.embedding`）?  \r\n实际上对于不同的categorical feature应该是各有一个不同的embedding层。不同特征共享同一个embedding层是没有意义也行不通的吧。\r\n另外，即使在FM框架下，各个embedding的`embedding_dim`（嵌入向量维度）是相同的，`num_embeddings`（ 嵌入字典的大小）也可能是不同的，但模型`__init__`部分并没有对各个特征分别输入`num_embeddings`，可能可以用，但感觉是有些问题的吧。\r\n\r\n不知是否理解有误，期待解答。",
        "state": "open",
        "user": "Mr-maoge",
        "closed_by": null,
        "created_at": "2021-08-02T03:36:14+00:00",
        "updated_at": "2021-08-07T04:50:23+00:00",
        "closed_at": null,
        "comments_count": [
            "Mr-maoge",
            "rogeroyer",
            "yinhaofeng",
            "yinhaofeng",
            "rogeroyer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 510,
        "title": "Request for a demo of large-scare recommendation. How to solve the problem about item vocabulary is too large to put a single machine.",
        "body": "Sorry to trouble. I met a question about the item vocabulary is too large to put a single machine. I couldn’t find the solution in PaddleRec project, may anyone give a few pointers for it?  ",
        "state": "open",
        "user": "xinyi-code",
        "closed_by": null,
        "created_at": "2021-08-09T07:26:40+00:00",
        "updated_at": "2021-08-10T03:25:54+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 533,
        "title": "Word2vec benchmark crashes when saving dump file",
        "body": "Word2vec benchmark crashes when saving dump file after an epoch with the following info:\r\n\r\n> ValueError: The feeded_var_names[0]: 'analogy_a' doesn't exist in pruned inference program. Please check whether 'analogy_a' is a valid feed_var name, or remove it from feeded_var_names if 'analogy_a' is not involved in the target_vars calculation.\r\n\r\nIt looks like caused by #506 \r\n\r\nreproduction steps:\r\nrun on local machine, CPU only\r\n```\r\ncd models/recall/word2vec/benchmark\r\npython -u ../../../../tools/static_ps_trainer.py -m benchmark.yaml\r\n```",
        "state": "open",
        "user": "arlesniak",
        "closed_by": null,
        "created_at": "2021-08-31T13:37:50+00:00",
        "updated_at": "2021-09-02T14:22:32+00:00",
        "closed_at": null,
        "comments_count": [
            "seemingwang",
            "arlesniak"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 534,
        "title": "PLE Loss 没有优化",
        "body": "多任务模型的 ple 中是否没有按照原文实现 Joint Loss Optimization for MTL？",
        "state": "open",
        "user": "kris-yangjs",
        "closed_by": "frankwhzhang",
        "created_at": "2021-09-01T05:04:55+00:00",
        "updated_at": "2021-12-22T08:27:49+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 539,
        "title": "drop_last=False not working",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/df31a2d9c63e900039a28e2f278de0c51e19570f/tools/paddle_infer.py#L112",
        "state": "open",
        "user": "simwiki",
        "closed_by": null,
        "created_at": "2021-09-06T11:29:12+00:00",
        "updated_at": "2021-09-07T07:37:51+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 549,
        "title": "python -m paddlerec.run -m models/rank/fm/config.yaml",
        "body": "这个命令为什么运行不起来了，会报错。\r\nError while finding module specification for 'paddlerec.run' (ModuleNotFoundError: No module named 'paddlerec')\r\n怎么解决？",
        "state": "open",
        "user": "huliangtian",
        "closed_by": null,
        "created_at": "2021-09-13T07:26:43+00:00",
        "updated_at": "2021-09-13T08:13:15+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 565
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 552,
        "title": "Convert mind model met the problem",
        "body": "Hi, when i used paddle_serving_client to convert the trained model, met the error, how can i fix the problem.\r\n\r\nThe two methods give the same result.\r\n\r\n`python3 -m paddle_serving_client.convert --dirname model --model_filename model/rec_static.pdmodel --params_filename model/rec_static.pdparams\r\n\r\nimport paddle_serving_client.io as serving_io\r\nserving_io.inference_model_to_serving('model', serving_server=\"serving_server\", serving_client=\"serving_client\",  model_filename='model/rec_static.pdmodel', params_filename='model/rec_static.pdparams')`\r\n\r\nInvalidArgumentError: Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 2459239552 found).\r\n      [Hint: Expected version == 0U, but received version:2459239552 != 0U:0.] (at /paddle/paddle/fluid/framework/lod_tensor.cc:329)\r\n      [operator < load_combine > error]\r\n\r\n",
        "state": "closed",
        "user": "linWujl",
        "closed_by": "frankwhzhang",
        "created_at": "2021-09-14T05:09:56+00:00",
        "updated_at": "2021-12-08T09:25:50+00:00",
        "closed_at": "2021-12-08T09:25:50+00:00",
        "comments_count": [
            "bjjwwang",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 561,
        "title": "剩下的只有paddle1.8的模型有计划时间升级到2.1版本吗？",
        "body": "剩下的paddle1.8的模型有计划时间升级到2.1版本吗？\r\n比如 Deep crossing， DCN， DIN， DIEN等等",
        "state": "closed",
        "user": "JoshonSmith",
        "closed_by": "JoshonSmith",
        "created_at": "2021-09-26T13:20:26+00:00",
        "updated_at": "2021-09-27T03:13:59+00:00",
        "closed_at": "2021-09-27T03:13:59+00:00",
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 573
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 588
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 571,
        "title": "Found a possible security concern",
        "body": "Hey there!\n\nI belong to an open source security research community, and a member (@ajdumanhug) has found an issue, but doesn’t know the best way to disclose it.\n\nIf not a hassle, might you kindly add a `SECURITY.md` file with an email, or another contact method? GitHub [recommends](https://docs.github.com/en/code-security/getting-started/adding-a-security-policy-to-your-repository) this best practice to ensure security issues are responsibly disclosed, and it would serve as a simple instruction for security researchers in the future.\n\nThank you for your consideration, and I look forward to hearing from you!\n\n(cc @huntr-helper)",
        "state": "closed",
        "user": "zidingz",
        "closed_by": "frankwhzhang",
        "created_at": "2021-10-20T23:30:48+00:00",
        "updated_at": "2021-11-23T06:50:03+00:00",
        "closed_at": "2021-11-23T06:50:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 570,
        "title": "fm net.py部分bug",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/bcddcf46e5cd8d4e6b2c5ee8d0d5521e292a2a81/models/rank/fm/net.py#L40\r\nfm模型这个地方代码是不是写错了？应该是self.fm.forward(sparse_inputs, dense_inputs)吧",
        "state": "closed",
        "user": "tz28",
        "closed_by": "tz28",
        "created_at": "2021-10-16T11:45:06+00:00",
        "updated_at": "2022-03-08T07:00:28+00:00",
        "closed_at": "2022-03-08T07:00:28+00:00",
        "comments_count": [
            "tz28",
            "frankwhzhang",
            "tz28",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 572,
        "title": "帮你们发现一个紧急bug，有密码泄露风险，赶紧处理吧",
        "body": "你们不小心把系统密码泄露了，-Dhadoop.job.ugi=paddle,*** ，pr链接如下                https://github.com/PaddlePaddle/PaddleRec/pull/565",
        "state": "closed",
        "user": "coderstevenprc",
        "closed_by": "fuyinno4",
        "created_at": "2021-10-22T09:32:54+00:00",
        "updated_at": "2021-11-23T00:53:30+00:00",
        "closed_at": "2021-11-23T00:53:30+00:00",
        "comments_count": [
            "fuyinno4"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 585,
        "title": "建议输出log中加上eta",
        "body": null,
        "state": "open",
        "user": "zouhan6806504",
        "closed_by": null,
        "created_at": "2021-11-11T11:53:48+00:00",
        "updated_at": "2021-11-23T02:32:03+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 586,
        "title": "召回mind不支持边训练边预测的？",
        "body": null,
        "state": "open",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-12T01:58:09+00:00",
        "updated_at": "2021-12-22T08:28:27+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 589,
        "title": "使用排序模型xdeepfm，如何得到数据之间的前后顺序？",
        "body": "目前infer.py没有做相关的输出",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-15T12:29:57+00:00",
        "updated_at": "2021-11-23T05:14:33+00:00",
        "closed_at": "2021-11-23T05:14:33+00:00",
        "comments_count": [
            "yinhaofeng",
            "zouhan6806504",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 593,
        "title": " No such file or directory: 'sample_data/feat_dict_10.pkl2'",
        "body": "在下载数据集criteo并使用sh data_process.sh进行数据处理时，报错信息 No such file or directory: 'sample_data/feat_dict_10.pkl2'，请问可以在哪里得到相应的文件？",
        "state": "open",
        "user": "DXQer",
        "closed_by": null,
        "created_at": "2021-11-17T05:13:18+00:00",
        "updated_at": "2021-11-18T07:51:40+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 595,
        "title": "mind的eval阶段，数据读取会droplast，导致预测的数据会少一部分",
        "body": null,
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-18T01:16:54+00:00",
        "updated_at": "2021-11-19T02:18:15+00:00",
        "closed_at": "2021-11-19T02:18:15+00:00",
        "comments_count": [
            "zouhan6806504",
            "zouhan6806504",
            "yinhaofeng",
            "zouhan6806504"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 598,
        "title": "PS异步训练模式下server出现core",
        "body": "当DistributedStrategy的a_sync=True时，server会core dump，a_sync=False时就正常\r\n2server、3worker，CPU模式，Adam和SGD都会在如图位置core，请问是什么问题呢\r\n![image](https://user-images.githubusercontent.com/35255760/142409724-0b983ee2-b055-4b2d-ad39-88a0076d07b7.png)\r\n",
        "state": "open",
        "user": "Li-Jiajie",
        "closed_by": null,
        "created_at": "2021-11-18T11:48:56+00:00",
        "updated_at": "2021-11-26T11:29:17+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "Li-Jiajie",
            "Li-Jiajie",
            "yinhaofeng",
            "Li-Jiajie",
            "yinhaofeng",
            "Li-Jiajie",
            "yinhaofeng",
            "Li-Jiajie",
            "yinhaofeng",
            "Li-Jiajie",
            "esythan",
            "Li-Jiajie",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 597,
        "title": "xdeepfm 配置文件中的一些疑问",
        "body": "hyper_parameters:\r\n  sparse_inputs_slots: 27\r\n  sparse_feature_number: 1000001\r\n  sparse_feature_dim: 9\r\n  dense_input_dim: 13\r\n\r\nsparse_inputs_slots是离散特征的数目吧，数据里有26个，这里是26+1？\r\nsparse_feature_number和sparse_feature_dim是以什么标准来确定的？",
        "state": "open",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-18T07:40:17+00:00",
        "updated_at": "2021-12-22T08:27:34+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "zouhan6806504",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 604,
        "title": "static_ps_trainer.py is throwing an exception ",
        "body": "\r\n\r\nMy command line:\r\n```\r\npython -u ../../../../tools/static_ps_trainer.py -m benchmark.yaml -bf16=True\r\n\r\n```\r\nI have an error:\r\n\r\n```\r\nINFO:__main__:Run Worker Begin\r\nTraceback (most recent call last):\r\n  File \"../../../../tools/static_ps_trainer.py\", line 351, in <module>\r\n    benchmark_main.run()\r\n  File \"../../../../tools/static_ps_trainer.py\", line 81, in run\r\n    self.run_worker()\r\n  File \"../../../../tools/static_ps_trainer.py\", line 116, in run_worker\r\n    self.model.optimizer.amp_init(self.exe.place)\r\nAttributeError: 'SGDOptimizer' object has no attribute 'amp_init'\r\n```\r\n\r\nbut .. If you use version below it works fine:\r\n\r\n```\r\ncommit e8c61ec375c6d1407e7d74d75ecbe1e2bd1b68eb\r\nMerge: e1224448 296a1ea9\r\nAuthor: zhang wenhui <frankwhzhang@126.com>\r\nDate:   Wed Oct 13 15:17:49 2021 +0800\r\n\r\n    Merge pull request #568 from seemingwang/master\r\n    \r\n    fix name error\r\n\r\n```\r\n\r\nDetails:\r\n```\r\nPython 3.8.12 (default, Oct 12 2021, 13:49:34) \r\n[GCC 7.5.0] :: Anaconda, Inc. on linux\r\n\r\n```\r\n\r\n",
        "state": "open",
        "user": "pawelpiotrowicz",
        "closed_by": null,
        "created_at": "2021-11-24T10:12:20+00:00",
        "updated_at": "2021-11-26T17:04:20+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang",
            "pawelpiotrowicz",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 615,
        "title": "更换数据集",
        "body": "麻烦问下，能否更换每个模型的数据集，比如说MIND使用movielens数据集进行测试？能做到吗？",
        "state": "open",
        "user": "Bradyzzhang",
        "closed_by": null,
        "created_at": "2021-11-29T07:52:38+00:00",
        "updated_at": "2021-11-29T14:14:43+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 628,
        "title": "关于criteo_reader.py修改的问题",
        "body": "您好，注意到在sample_data里给出的样本数据中，dense_features的名字都是一样的，所以在数据处理是会有相应的reshape的过程，如果dense_features的名字都不一样呢，要如何修改，有修改样例吗？我尝试对dense_features的获取方式修改成与sparse_features的获取方式一样，但似乎会造成内存泄漏😢，即程序运行过程中所申请虚拟内存一直增加，最后被killed。。",
        "state": "open",
        "user": "DXQer",
        "closed_by": null,
        "created_at": "2021-12-07T13:18:12+00:00",
        "updated_at": "2021-12-08T09:22:23+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 629,
        "title": "train_thread_num=1时如何提高多核CPU利用率",
        "body": "分布式训练时，配置文件中可以通过train_thread_num来控制训练线程数，但是train_thread_num是样本并行的程度，相当于有多个reader并行去读取+训练。由于batchsize很大，且是hdfs样本，内存有限，我不能将train_thread_num设置得很大，但是当train_thread_num设置较小比如=1时，只能由1核被充分利用\r\n尝试了下设置OMP_NUM_THREADS、MKL_NUM_THREADS等方式似乎可以提高CPU占用，但是训练速度差不多（比如原本把1核占满，把这两个设置大了，96核可以几乎占满，但是速度提升不明显）\r\n看文档说通过CPU_NUM环境变量来配置，不设置则使用所有CPU，我没有配置CPU_NUM，但是CPU占用不满，基本都在compute阶段耗时，感觉是op里的计算没有并行起来，请问有方法可以设置吗\r\n（OMP_NUM_THREADS、MKL_NUM_THREADS这两个环境变量也是我摸出来的，感觉官方文档里并没有人让配置这两个参数）",
        "state": "open",
        "user": "Li-Jiajie",
        "closed_by": null,
        "created_at": "2021-12-08T04:15:17+00:00",
        "updated_at": "2021-12-09T08:21:29+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "Li-Jiajie",
            "esythan",
            "Li-Jiajie",
            "esythan",
            "Li-Jiajie",
            "esythan",
            "Li-Jiajie",
            "Li-Jiajie",
            "Li-Jiajie",
            "Li-Jiajie",
            "Li-Jiajie"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 643,
        "title": "在运行paddle_infer.py时发现auto_log模块缺失",
        "body": "![截屏2021-12-14 上午12 08 58](https://user-images.githubusercontent.com/66515297/145847049-04dfc172-eb67-4b2c-951d-1a56805ffe43.png)\r\n",
        "state": "closed",
        "user": "gouzil",
        "closed_by": "gouzil",
        "created_at": "2021-12-13T16:09:54+00:00",
        "updated_at": "2021-12-15T00:44:35+00:00",
        "closed_at": "2021-12-15T00:44:35+00:00",
        "comments_count": [
            "yinhaofeng",
            "gouzil"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 630,
        "title": "使用教程中已经训练好的 movie_model的压缩文件进行静态图训练recall模型出错",
        "body": "教程地址：https://aistudio.baidu.com/aistudio/projectdetail/1816335?channelType=0&channel=0\r\n\r\npaddlepaddle : 2.2.1\r\npaddleRec: 2.2.0\r\n\r\n已将models/demo/movie_recommand/recall/movie.yaml里的use_gpu改成False\r\n\r\n运行命令\r\n\r\n```bash\r\ncd PaddleRec/models/demo/movie_recommand && python -u ../../../tools/static_trainer.py -m recall/movie.yaml\r\n```\r\n\r\n报错信息如下\r\n\r\n```bash\r\nLenovo@DESKTOP-91MGDB0 MINGW64 /c/workspace/github/PaddleRec/models/demo/movie_recommand (release/2.2.0)\r\n$ python -u ../../../tools/static_trainer.py -m recall/movie.yaml\r\nC:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:341: UserWarning: C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\nn\\functional\\common.py:1423\r\nThe behavior of expression A / B has been unified with elementwise_div(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_div(X, Y, axis=0) instead of A / B. This transitional warning will be dropped in the future.\r\n  op_type, op_type, EXPRESSION_MAP[method_name]))\r\n2021-12-08 16:24:39,401 - INFO - cpu_num: None\r\n2021-12-08 16:24:39,402 - INFO - **************common.configs**********\r\n2021-12-08 16:24:39,402 - INFO - use_gpu: False, use_xpu: False, use_visual: False, train_batch_size: 1, train_data_dir: ../data/train, epochs: 5, print_interval: 20, model_save_path: movie_model\r\n2021-12-08 16:24:39,402 - INFO - **************common.configs**********\r\n2021-12-08 16:24:39,860 - INFO - reader path:reader\r\nTraceback (most recent call last):\r\n  File \"../../../tools/static_trainer.py\", line 282, in <module>\r\n    main(args)\r\n  File \"../../../tools/static_trainer.py\", line 149, in main\r\n    config, use_visual, log_visual, step_num)\r\n  File \"../../../tools/static_trainer.py\", line 249, in dataloader_train\r\n    fetch_list=[var for _, var in fetch_vars.items()])\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1262, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\six.py\", line 719, in reraise\r\n    raise value\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1260, in run\r\n    return_merged=return_merged)\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1402, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1479, in _run_program\r\n    self._feed_data(program, feed, feed_var_name, scope)\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 800, in _feed_data\r\n    check_feed_shape_type(var, cur_feed)\r\n  File \"C:\\workspace\\github\\PaddleRec\\venv\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 247, in check_feed_shape_type\r\n    (var.name, var_dtype_format, feed_dtype_format))\r\nValueError: The data type of fed Variable 'label' must be 'int64', but received 'int32'\r\n```",
        "state": "open",
        "user": "Chgocn",
        "closed_by": null,
        "created_at": "2021-12-08T08:28:27+00:00",
        "updated_at": "2021-12-10T09:03:48+00:00",
        "closed_at": null,
        "comments_count": [
            "Chgocn",
            "yinhaofeng",
            "Chgocn",
            "yinhaofeng",
            "Chgocn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 653,
        "title": "[QUES]: Multi-core",
        "body": "How to train it in parallel !",
        "state": "open",
        "user": "Data-Designer",
        "closed_by": null,
        "created_at": "2021-12-18T09:42:15+00:00",
        "updated_at": "2021-12-20T02:54:27+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 657,
        "title": "使用paddle serving预测时返回结果都为1",
        "body": "![截屏2021-12-27 下午3 16 56](https://user-images.githubusercontent.com/66515297/147445980-b3826ca3-8522-44cf-887d-b83102f50da5.png)\r\n",
        "state": "closed",
        "user": "gouzil",
        "closed_by": "gouzil",
        "created_at": "2021-12-27T07:22:23+00:00",
        "updated_at": "2022-05-07T01:03:28+00:00",
        "closed_at": "2022-05-07T01:03:28+00:00",
        "comments_count": [
            "gouzil",
            "yinhaofeng",
            "gouzil",
            "yinhaofeng",
            "gouzil",
            "TeslaZhao",
            "gouzil",
            "gouzil",
            "yinhaofeng",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 675,
        "title": "使用paddle_infer.py预测naml模型失败",
        "body": "将naml模型导出为Paddle Inference模型后，使用paddle_infer.py脚本进行预测，但不能正确运行。\r\n这是我的执行命令：\r\n`python3 ../../../tools/paddle_infer.py --model_file=PaddleRec_model/naml/model.pdmodel --params_file=PaddleRec_model/naml/model.pdiparams --use_gpu=False --data_dir=data/sample_data/train/ --reader_file=NAMLDataReader.py --batchsize=1 --benchmark=False`\r\n\r\n但由于NAMLDataReader.py里缺少config的读取，因此我在里面也加了下列代码。\r\n`config = load_yaml(\"/Work/PaddleRec/models/rank/naml/config.yaml\")`\r\n\r\n但还是会报输入shape不匹配的问题：\r\n    InvalidArgumentError: The shape of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [1, 10], input[1]'s shape = [1, 5, 10].\r\n      [Hint: Expected inputs_dims[i].size() == out_dims.size(), but received inputs_dims[i].size():3 != out_dims.size():2.] (at /paddle/paddle/fluid/operators/concat_op.h:40)\r\n      [operator < concat > error]\r\n\r\n\r\n有什么办法可以让我使用Paddle Inference来推理naml吗？",
        "state": "closed",
        "user": "shentanyue",
        "closed_by": "shentanyue",
        "created_at": "2022-01-12T03:26:57+00:00",
        "updated_at": "2022-01-12T07:36:31+00:00",
        "closed_at": "2022-01-12T07:36:31+00:00",
        "comments_count": [
            "yinhaofeng",
            "shentanyue"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 691
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 678,
        "title": "静态图训练自定义数据报错",
        "body": "错误信息如下：\r\n![image](https://user-images.githubusercontent.com/24427182/149295924-b26d4b79-a75b-44d1-95e2-3c97d4163108.png)\r\n数据格式如下：\r\nlogid:100073418 time:976419420 companyid:257360 A01:331948 A02:277013 A03:206218 A04:206218 policyid:367294 B01:254421 B01:143746 B01:454433 B01:569806 B02:118344 B02:0 B02:0 label:4\r\nread.y代码修改如下：\r\n![image](https://user-images.githubusercontent.com/24427182/149296980-807b2e12-f54c-48d8-8a6b-00bb918c0392.png)\r\nstatic_model.py代码如下：\r\n![image](https://user-images.githubusercontent.com/24427182/149297119-d6652acb-2091-44c8-a83d-ba51e742f8da.png)\r\nconfig.ymal如下：\r\n![image](https://user-images.githubusercontent.com/24427182/149297179-e3aba5ce-35ab-42b4-b34c-fec83d14cc03.png)\r\n",
        "state": "open",
        "user": "jiangxianqiang",
        "closed_by": null,
        "created_at": "2022-01-13T08:51:41+00:00",
        "updated_at": "2022-01-17T03:56:15+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "jiangxianqiang",
            "yinhaofeng",
            "jiangxianqiang",
            "yinhaofeng",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 680,
        "title": "models/rank/dnn/criteo_reader.py的67行有bug",
        "body": "```\r\nif not self.visit[slot]:  # 对空缺值进行填充\r\n    if i in self.dense_slots:\r\n        output[self.slot2index[i]][1].extend(\r\n            [self.padding] *\r\n            self.dense_slots_shape[self.slot2index[i]])   # 这里有风险\r\n```\r\n从63行到67行是用于处于dense特征的空缺值的，本意是填充对应数量的0，但实际这里有out of range风险\r\n代码运行逻辑是当dense特征都不存在时，此时dense_feature的visit为false，进入此逻辑，但此时将self.slot2index[i]作为索引传给self.dense_slots_shape会导致“index out of range”，因为slot2index[i]此时肯定为27，而dense_slots_shape列表只有一个初始值13，索引为0，任何大于0的索引都会导致报错。",
        "state": "open",
        "user": "kaohao",
        "closed_by": null,
        "created_at": "2022-01-14T14:25:18+00:00",
        "updated_at": "2022-01-17T03:38:29+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 682,
        "title": "models/rank/xdeepfm/net.py的223-225行有bug",
        "body": "```\r\nself.add_sublayer('linear_%d' % i, linear)\r\nself._mlp_layers.append(linear)  # 实际前馈传递时，从这里列表里读取layer信息，此时只有linear，缺失act\r\nif acts[i] == 'relu':\r\n    act = paddle.nn.ReLU()\r\n    self.add_sublayer('act_%d' % i, act)\r\n```\r\n在排序模型xdeepfm的dnn部分的初始化里面，本意是每做一次linear，就使用一次relu激活，但代码这里未将act加入_mlp_layers，导致在实际的forward过程中，就是普通的全连接神经网络，而没有用到relu激活了\r\n参考dnn/net.py，应该在225行下再加上`self._mlp_layers.append(act)`",
        "state": "open",
        "user": "kaohao",
        "closed_by": null,
        "created_at": "2022-01-17T09:13:45+00:00",
        "updated_at": "2022-01-18T06:19:06+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "kaohao",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 692
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 686,
        "title": "设置train_batch_size导致读取数据报错",
        "body": "训练自定义数据的时候，如果将config.ymal中train_batch_size设置为6且训练数据是11条，可以正常训练。如果将训练数据data.txt设置为12条数据或者将train_batch_size设置为7都会提示错误。\r\n数据如下：\r\n`logid:100002243 companyid:125099 A01:267979 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:83157 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100021262 companyid:392093 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:75628 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100022699 companyid:357181 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:493890 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100026891 companyid:330324 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:230042 B01:199323 B01:0 B01:0 B01:0 B02:352070 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100039170 companyid:294552 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:303095 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100064368 companyid:369090 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:110558 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100066291 companyid:62190 A01:6181 A01:0 A01:0 A01:0 A02:371158 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:228800 A05:466273 A05:0 A05:0 A06:313660 A06:237193 A06:150094 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:84963 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:351309 A10:0 A10:0 A10:0 A11:597211 A11:556730 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:70889 A13:415356 A13:494498 A13:211574 A13:34101 policyid:429079 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100068622 companyid:222229 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:447215 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100073405 companyid:151899 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:265933 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100073998 companyid:130268 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:383584 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100087482 companyid:181675 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:493043 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\nlogid:100093814 companyid:171407 A01:340427 A01:0 A01:0 A01:0 A02:334554 A02:0 A02:0 A02:0 A03:30833 A03:0 A03:0 A03:0 A04:73144 A04:0 A04:0 A04:0 A05:386087 A05:0 A05:0 A05:0 A06:15382 A06:0 A06:0 A06:0 A07:160093 A07:0 A07:0 A07:0 A08:478020 A08:0 A08:0 A08:0 A09:237811 A09:0 A09:0 A09:0 A10:138661 A10:0 A10:0 A10:0 A11:42878 A11:0 A11:0 A11:0 A12:109071 A12:0 A12:0 A12:0 A13:375456 A13:0 A13:0 A13:0 policyid:232488 B01:248146 B01:0 B01:0 B01:0 B02:306595 B02:0 B02:0 B02:0 B03:45492 B03:0 B03:0 B03:0 B04:482965 B04:0 B04:0 B04:0 B05:577326 B05:0 B05:0 B05:0 B06:158335 B06:0 B06:0 B06:0 B07:559376 B07:0 B07:0 B07:0 B08:233889 B08:0 B08:0 B08:0 B09:90954 B09:0 B09:0 B09:0 B10:61456 B10:0 B10:0 B10:0 B11:242431 B11:0 B11:0 B11:0 B12:199086 B12:0 B12:0 B12:0 B13:193685 B13:0 B13:0 B13:0\r\n`\r\n配置信息如下：\r\n`runner:\r\n  train_data_dir: \"../data/train\"\r\n  train_reader_path: \"reader1\"\r\n  train_batch_size: 1\r\n  model_save_path: \"output_model_recall\"\r\n\r\n  use_gpu: False\r\n  epochs: 5\r\n  print_interval: 20\r\n  \r\n  test_data_dir: \"../data/test\"\r\n  infer_reader_path: \"reader\"  # importlib format\r\n  infer_batch_size: 5\r\n  infer_load_path: \"output_model_recall\"\r\n  infer_start_epoch: 4\r\n  infer_end_epoch: 5\r\n\r\n  runner_result_dump_path: \"recall_infer_result\"\r\n\r\nhyper_parameters:\r\n  optimizer:\r\n    class: Adam\r\n    learning_rate: 0.001\r\n  sparse_feature_number: 600000\r\n  sparse_feature_dim: 9\r\n  dense_input_dim: 13\r\n  fc_sizes: [512, 256, 128, 32]`\r\n错误信息：\r\n![image](https://user-images.githubusercontent.com/24427182/150071506-445c4b59-a8de-44ce-89a3-c1adcfef9c27.png)\r\n",
        "state": "open",
        "user": "jiangxianqiang",
        "closed_by": null,
        "created_at": "2022-01-19T05:44:12+00:00",
        "updated_at": "2022-01-20T09:21:32+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 690,
        "title": "【Help】关于运行PaddleRec中的模型显存利用率低的问题",
        "body": "![image](https://user-images.githubusercontent.com/31981876/150338030-7f38c075-3259-44c3-afa8-de7bd893253c.png)\r\n\r\n如图，我在ai studio跑rec的模型，当用全量数据集(4kw)训练时，显存利用率往往只有10几%，我尝试了将batch_size从512调到10000，但没什么变化。\r\n这个问题，我在使用实验室的自建服务器或者谷歌的colab时也存在，也尝试过一些方法去提高利用率和训练速度，现在换到paddle也出现了这个问题，想问问，有遇到过的前辈，可以大概告诉个解决思路吗？感谢！",
        "state": "open",
        "user": "kaohao",
        "closed_by": null,
        "created_at": "2022-01-20T12:27:17+00:00",
        "updated_at": "2022-01-20T12:47:33+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 693,
        "title": "代码规范性问题",
        "body": "dcn模型中，链接：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dcn/net.py#L73，\r\n请把注释掉的代码清理，因为这个无关代码中shape=[100004]就是个错的，极易误导人，让人以为layer_w的shape为100004。实际上layer_w的shape为13+26*9。如果这段代码不用了请删除，更别提是错的带有误导性的注释代码，更应该删除。",
        "state": "closed",
        "user": "tz28",
        "closed_by": "tz28",
        "created_at": "2022-01-24T14:13:19+00:00",
        "updated_at": "2022-03-08T07:01:01+00:00",
        "closed_at": "2022-03-08T07:01:01+00:00",
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 702,
        "title": "关于DCN代码中的一些疑惑",
        "body": "DCN代码中的cross网络部分：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dcn/net.py#L112\r\n\r\n    def _cross_layer(self, input_0, input_x):\r\n        input_w = paddle.multiply(input_x, self.layer_w)\r\n        input_w1 = paddle.sum(input_w, axis=1, keepdim=True)\r\n        input_ww = paddle.multiply(input_0, input_w1)\r\n        input_layer_0 = paddle.add(input_ww, self.layer_b)\r\n        input_layer = paddle.add(input_layer_0, input_x)\r\n        return input_layer, input_w\r\n\r\n这段代码，每一层cross的参数w都是共享的self.layer_w，是否与原论文中不一致？看愿论文中的公式\r\n$$x_{l+1} = x_0x_l^Tw_l + b_l + x_l$$\r\n每一层的w是独立的而不是共享的。",
        "state": "open",
        "user": "tz28",
        "closed_by": null,
        "created_at": "2022-01-28T09:51:34+00:00",
        "updated_at": "2022-01-29T03:44:21+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "tz28"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 706,
        "title": "欢迎大家加入PaddleRec社区！",
        "body": "## PaddleRec社区\r\n哈喽，大家好！首先感谢大家对PaddleRec的关注与支持，并且在大家的反馈中，PaddleRec也在茁壮成长！\r\n### 背景说明\r\n为了能和各位进一步并肩作战，共同维护PaddleRec，我们欢迎大家在以下情况时积极提PR：\r\n\r\n- 文档书写错误\r\n- 代码规范问题\r\n- 套件bug\r\n- 新增模型｜功能\r\n\r\n### 提交规范\r\nPaddleRec套件的准则基本和主Paddle的一致，请参考[官网文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/10_contribution/local_dev_guide_cn.html)\r\n### 奖励说明\r\n对于成功合入的同学，我们设置了如下奖励：\r\n\r\n- 该同学的贡献将被记录到主页的主页的贡献者列表中\r\n- 定期选取表现优秀的同学赠送百度纪念品\r\n\r\n### 写在最后\r\n我相信在我们的共同努力下，PaddlRec将越来越完善，国产深度学习平台在全球的影响力也会越来越强！",
        "state": "open",
        "user": "wangzhen38",
        "closed_by": null,
        "created_at": "2022-02-09T10:21:43+00:00",
        "updated_at": "2022-02-09T10:21:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 700,
        "title": "将训练模型转为paddle serving时提示_model_文件不存在，但是训练模型中没有这个_model_文件",
        "body": "我按照README.md中离线部分操作步骤，将训练好的user_model转为可部署使用的paddle Serving模型时，提示找不到_model文件，训练的模型中不存在这个文件，自己手动建了文件后也还是错误。\r\n![image](https://user-images.githubusercontent.com/24427182/151136635-ce6bbab8-dd35-483a-99ee-4d5c934033d8.png)\r\n错误如下：\r\n![image](https://user-images.githubusercontent.com/24427182/151136065-be0f82eb-5d97-45f8-a129-fe2979f1a26b.png)\r\n",
        "state": "open",
        "user": "jiangxianqiang",
        "closed_by": null,
        "created_at": "2022-01-26T09:22:29+00:00",
        "updated_at": "2022-05-13T09:01:16+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "yinhaofeng",
            "jiangxianqiang",
            "hongenge"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 704,
        "title": "关于xdeepfm代码中的一些疑惑",
        "body": "hi，\r\nxdeepfm代码在实现CIN网络结构（代码：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/xdeepfm/net.py#L130）\r\n时，卷积部分Conv2D中的in_channels参数设置是否和原论文不太一致？\r\n原论文如下图所示：\r\n![image](https://user-images.githubusercontent.com/9672354/152763535-f2b84a72-4c5e-4c6f-964e-def7571d87f5.png)\r\n\r\n以下为个人对原论文中（b）部分的示意图理解，经过（a）得到的Z^{k+1}的维度为m * H_k * D，在（b）中为了压缩，使用了H_{k+1}个大小为​H_k*m的向量（矩阵）做了一波点乘内积，此时得到是H_{k+1}个向量的第一个元素，因为Z^{k+1}的channel为D，因此最终得到的x^{k+1}为H_{k+1}个D维向量。\r\n\r\n如上所述，卷积in_channels应该为D，即embedding维度，而不是paddle版本实现xdeepfm中的last_s * self.num_field，请确认。",
        "state": "open",
        "user": "tz28",
        "closed_by": null,
        "created_at": "2022-02-07T09:50:49+00:00",
        "updated_at": "2022-02-08T06:13:59+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 705,
        "title": "BST代码的一个bug",
        "body": "paddleRec/models/rank/bst/net.py\r\n\r\n第435行\r\nitem_sequence = paddle.concat( [hist_item_emb, hist_item_emb,  hist_position_emb], axis=2)\r\n应该是\r\nitem_sequence = paddle.concat( [hist_item_emb, hist_cat_emb,  hist_position_emb], axis=2)",
        "state": "open",
        "user": "starspringcloud",
        "closed_by": null,
        "created_at": "2022-02-07T13:52:06+00:00",
        "updated_at": "2022-02-08T03:28:11+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 708,
        "title": "recall/tisas 静态图训练异常",
        "body": "1. 执行训练\r\n\r\n`python -u ../../../tools/static_trainer.py -m config_bigdata.yaml`\r\n\r\n2. 异常信息如下 \r\n\r\n![image](https://user-images.githubusercontent.com/16534871/153386563-d01bc10a-253a-4621-9133-9bd951827793.png)\r\n\r\n\r\n3.版本信息\r\n\r\npaddle: paddlepaddle:2.2.2\r\n机器：mac m1\r\n\r\n",
        "state": "open",
        "user": "lrtz-v",
        "closed_by": null,
        "created_at": "2022-02-10T10:17:13+00:00",
        "updated_at": "2022-02-14T07:27:55+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 709,
        "title": "wide&deep输入",
        "body": "wide&deep模型中，forward中sparse_inputs, dense_inputs的shape是什么",
        "state": "open",
        "user": "ZTurboX",
        "closed_by": null,
        "created_at": "2022-02-14T08:12:33+00:00",
        "updated_at": "2022-02-16T03:16:23+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "ZTurboX",
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 710,
        "title": "wide&deep输出",
        "body": "wide&deep预测想输出得分概率值，但输出的是1或0",
        "state": "open",
        "user": "ZTurboX",
        "closed_by": null,
        "created_at": "2022-02-15T04:24:30+00:00",
        "updated_at": "2022-02-15T06:58:12+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 721,
        "title": "关于MMoe网络一些疑问",
        "body": "1. 当前现状\r\npaddle在实现MMoe时，在每个expert权重初始化时用了常量初始化，weight_attr=nn.initializer.Constant(value=0.1),\r\nbias_attr=nn.initializer.Constant(value=0.1), 详情参见https://github.com/PaddlePaddle/PaddleRec/blob/master/models/multitask/mmoe/net.py#L37\r\n\r\n2. 存在的问题\r\n因为在mmoe中每个expert喂入的样本（特征）是一样的，之所以每个expert可以学到不同的东西，核心原因在于数据存在multi-view，但这是有前提条件的，即每个expert的权重初始化是要不一样的，可以随机可以其他，总之不能相同。而paddle在实现时恰恰犯了这个致命错误，paddle把每个expert权重都初始化成了1，这样会导致每个expert最终学到的网络参数趋向一样，也就意味着每个expert失去了difference，导致最终失去了ensemble的意义，gate的初始化也有问题，但问题没有expert严重。\r\n\r\n3.  验证\r\n我基于paddle公布的代码和数据，训练完成后，把每个expert的权重打出来，结果证实了2中陈述的问题，详情参见：\r\n('net.state_dict(): ', OrderedDict([('expert_0.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_0.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_1.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_1.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_2.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_2.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_3.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_3.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_4.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_4.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_5.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_5.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_6.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_6.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('expert_7.weight', Parameter containing:\r\nTensor(shape=[499, 16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08814958, 0.08814958, 0.08814958, ..., 0.08814958, 0.08814958, 0.08814958],\r\n        [0.09953024, 0.09953024, 0.09953024, ..., 0.09953024, 0.09953024, 0.09953024],\r\n        [0.09432000, 0.09432000, 0.09432000, ..., 0.09432000, 0.09432000, 0.09432000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.08475424, 0.08475424, 0.08475424, ..., 0.08475424, 0.08475424, 0.08475424],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('expert_7.bias', Parameter containing:\r\nTensor(shape=[16], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424, 0.08475424])), ('gate_0.weight', Parameter containing:\r\nTensor(shape=[499, 8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('gate_0.bias', Parameter containing:\r\nTensor(shape=[8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000])), ('tower_0.weight', Parameter containing:\r\nTensor(shape=[16, 8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330],\r\n        [0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330, 0.10692330]])), ('tower_0.bias', Parameter containing:\r\nTensor(shape=[8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.10714810, 0.10714810, 0.10714810, 0.10714810, 0.10714810, 0.10714810, 0.10714810, 0.10714810])), ('tower_out_0.weight', Parameter containing:\r\nTensor(shape=[8, 2], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131],\r\n        [0.10613869, 0.09386131]])), ('tower_out_0.bias', Parameter containing:\r\nTensor(shape=[2], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.10621535, 0.09378465])), ('gate_1.weight', Parameter containing:\r\nTensor(shape=[499, 8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        ...,\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000],\r\n        [0.10000000, 0.10000000, 0.10000000, ..., 0.10000000, 0.10000000, 0.10000000]])), ('gate_1.bias', Parameter containing:\r\nTensor(shape=[8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000])), ('tower_1.weight', Parameter containing:\r\nTensor(shape=[16, 8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549],\r\n        [0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549, 0.08482549]])), ('tower_1.bias', Parameter containing:\r\nTensor(shape=[8], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08414954, 0.08414954, 0.08414954, 0.08414954, 0.08414954, 0.08414954, 0.08414954, 0.08414954])), ('tower_out_1.weight', Parameter containing:\r\nTensor(shape=[8, 2], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [[0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940],\r\n        [0.10030183, 0.09969940]])), ('tower_out_1.bias', Parameter containing:\r\nTensor(shape=[2], dtype=float32, place=CPUPlace, stop_gradient=False,\r\n       [0.08894448, 0.11105615]))]))\r\n\r\n\r\n请验证是否存在此问题，若存在请修复。",
        "state": "open",
        "user": "tz28",
        "closed_by": null,
        "created_at": "2022-03-08T06:50:56+00:00",
        "updated_at": "2022-03-10T08:35:22+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 725,
        "title": "关于pgl模型在paddlerec中的使用以及在文档中的自定义reader实现问题",
        "body": "1，我在models/recall/deepwalk/deepwalk_train/static_model.py中看见deepwalk的代码是使用静态图实现的，请问在paddlerec的框架下，图神经网络都建议使用静态图吗，其中的考虑是怎么样的？\r\n\r\n2，在models/recall/deepwalk/randwalk_reader.py中并没有按照paddlerec文档要求使用DataLoader或者QueueDataset，我在做graphGan方向的研究，请问在reader的设计上推荐使用paddlerec的DataLoader或者QueueDataset还是pgl的Dataset？\r\n\r\n3，在文档中自定义reader下，参照models/rank/dnn 目录下的criteo_reader.py的实现方式中，在第64行到第67行当中的操作我理解应该是在判断如果当前slot没有使用且为dense_slot时，就填充dense_slot所对应的dense_slots_shape个数的0在列表output[self.slot2index[i]][1]中，但是在第33行定义的self.dense_slots_shape = [13]是一个长度只有1的list，经过67行的self.dense_slots_shape[self.slot2index[i]]时，如果此时的i不是第一个slot即此时的self.slot2index[i]>0,就会产生越界错误，这个问题困扰了我，希望可以得到请教，谢谢",
        "state": "open",
        "user": "luoyoucode",
        "closed_by": null,
        "created_at": "2022-03-13T17:14:08+00:00",
        "updated_at": "2022-03-14T03:41:24+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 713,
        "title": "DIEN组网代码一点疑惑",
        "body": "DIEN组网代码中，下面这两行调用的add_sublayer()函数【self.add_sublayer('linear_%d' % i, linear)】，在传入的name都是'linear_%d' % i的情况下，是否会后面即L144里的覆盖L123里的，如果会覆盖，这么操作两遍add_sublayer()的目的是什么？\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dien/net.py#L123\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dien/net.py#L144",
        "state": "closed",
        "user": "tz28",
        "closed_by": "tz28",
        "created_at": "2022-02-23T03:26:59+00:00",
        "updated_at": "2022-03-08T07:01:47+00:00",
        "closed_at": "2022-03-08T07:01:47+00:00",
        "comments_count": [
            "wangzhen38",
            "tz28",
            "tz28"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 723,
        "title": "esmm模型保存模型而不是模型参数遇到问题",
        "body": "部署服务需要用到模型而不是模型参数，所以想要保存模型\r\n使用paddle.save(net, model_prefix + \".pdmodel\")\r\n显示报错\r\nValueError: paddle do not support saving `paddle.nn.Layer` object.\r\n\r\n使用 paddle.jit.save(net, model_prefix + \".pdmodel\",input_spec=None)\r\n显示报错\r\nValueError: No valid transformed program for function: forward(inputs), input_spec: None.\r\n\t    Please specific `input_spec` in `@paddle.jit.to_static` or feed input tensor to call the decorated function at once.\r\n\r\n请问这个该怎么解决呢",
        "state": "open",
        "user": "FelixLiu1996",
        "closed_by": null,
        "created_at": "2022-03-09T04:51:05+00:00",
        "updated_at": "2022-03-10T08:39:20+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 726,
        "title": "paddlerec如何读取fc、embedding等的权重",
        "body": "如题，paddlerec如何读取fc、embedding等的权重，并print出来",
        "state": "open",
        "user": "NealRichardRui",
        "closed_by": null,
        "created_at": "2022-03-14T11:49:39+00:00",
        "updated_at": "2022-03-15T02:56:06+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 728,
        "title": "logic_regression模型save_inference_model的时候报错dense_input参数不存在",
        "body": "经过调试发现是函数def _prune_with_input(self, feeded_var_names, targets)保存的模型里面把一些变量都移除了.原因未知,dll无法调试\r\n只剩下了两个变量\r\nvar label : LOD_TENSOR.shape(-1, 1).dtype(int64).stop_gradient(True)\r\nvar save_infer_model/scale_0.tmp_0 : LOD_TENSOR.shape(-1, 1).dtype(int64).stop_gradient(False)\r\n下面是堆栈\r\nTraceback (most recent call last):\r\n  File \".\\PaddleRec-master\\tools\\static_trainer.py\", line 288, in <module>\r\n    main(args)\r\n  File \".\\PaddleRec-master\\tools\\static_trainer.py\", line 220, in main\r\n    fetchvars, exe)\r\n  File \"D:\\workspace_cm\\MagicCubeServer\\kibana\\stat\\PaddleRec-master\\tools\\utils\\save_load.py\", line 81, in save_inference_model\r\n    executor=exe)\r\n  File \"<decorator-gen-207>\", line 2, in save_inference_model\r\n  File \"D:\\Program Files\\Python37\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Python37\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 238, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Python37\\lib\\site-packages\\paddle\\static\\io.py\", line 514, in save_inference_model\r\n    program = normalize_program(program, feed_vars, fetch_vars)\r\n  File \"D:\\Program Files\\Python37\\lib\\site-packages\\paddle\\static\\io.py\", line 218, in normalize_program\r\n    prepend_feed_ops(copy_program, feed_var_names)\r\n  File \"D:\\Program Files\\Python37\\lib\\site-packages\\paddle\\fluid\\io.py\", line 1218, in prepend_feed_ops\r\n    i=i, name=name))\r\nValueError: The feeded_var_names[0]: 'dense_input' doesn't exist in pruned inference program. Please check whether 'dense_input' is a valid feed_var name, or remove it from feeded_var_names if 'dense_input' is not involved in the target_vars calculation.",
        "state": "open",
        "user": "tfft2126",
        "closed_by": null,
        "created_at": "2022-03-17T09:14:57+00:00",
        "updated_at": "2022-10-28T06:01:08+00:00",
        "closed_at": null,
        "comments_count": [
            "tfft2126",
            "yinhaofeng",
            "tfft2126",
            "yinhaofeng",
            "yinhaofeng",
            "tfft2126",
            "yinhaofeng",
            "tfft2126",
            "Hoonly"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 729,
        "title": "关于rank目录下所有涉及DNN组网的一个bug",
        "body": "rank目录下涉及到DNN组装的模型全部存在一个bug，在dnn组网中激活函数没有加入到网络中，如下所示：\r\n```python\r\n        acts = [\"relu\" for _ in range(len(self.layer_sizes))] + [None]\r\n        self._mlp_layers = []\r\n        for i in range(len(self.layer_sizes)):  # + 1):\r\n            linear = paddle.nn.Linear(\r\n                in_features=sizes[i],\r\n                out_features=sizes[i + 1],\r\n                weight_attr=paddle.ParamAttr(\r\n                    initializer=paddle.nn.initializer.Normal(\r\n                        std=1.0 / math.sqrt(sizes[i]))))\r\n            self.add_sublayer('linear_%d' % i, linear)\r\n            self._mlp_layers.append(linear)\r\n            if acts[i] == 'relu':\r\n                act = paddle.nn.ReLU()\r\n                self.add_sublayer('act_%d' % i, act)\r\n```\r\n\r\n**少了语句self._mlp_layers.append(act)**，导致后面在dnn forward时（如下所示代码），激活函数完全没有起作用。\r\n```python\r\n        for n_layer in self._mlp_layers:\r\n            dnn_feat = n_layer(dnn_feat)\r\n```\r\n\r\n存在此bug的模型有：\r\nDCN：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dcn/net.py#L90\r\nDCNV2：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/dcn_v2/net.py#L171\r\ndeepfefm：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/deepfefm/net.py#L226\r\ndeepfm：https://github.com/PaddlePaddle/PaddleRec/blob/master/models/rank/deepfm/net.py#L166\r\n\r\n太多了，你们查下吧，我不列举了。",
        "state": "open",
        "user": "tz28",
        "closed_by": null,
        "created_at": "2022-03-19T05:22:27+00:00",
        "updated_at": "2022-03-21T02:30:53+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 731,
        "title": "怎么下载criteo 1TB click数据集",
        "body": "想用paddlerec训练MLPerf中的DLRM任务，但是数据集很难下载，请问paddle团队是否有这个数据集，能否共享",
        "state": "open",
        "user": "xiwei777",
        "closed_by": null,
        "created_at": "2022-03-22T06:17:43+00:00",
        "updated_at": "2022-03-23T06:08:43+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "xiwei777",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 735,
        "title": "预测结果数据的输出在哪里？",
        "body": "按照 https://github.com/PaddlePaddle/PaddleRec/blob/master/tools/readme.md\r\npython -u tools/static_infer.py -m models/rank/dnn/config.yaml\r\n这个预测的是 test目录下的数据，但是输出在哪里目录？\r\n看来原代码里主要是AUC的数据，没有具体每行数据的预测结果",
        "state": "closed",
        "user": "veridone",
        "closed_by": "veridone",
        "created_at": "2022-03-28T06:08:09+00:00",
        "updated_at": "2022-03-29T07:28:45+00:00",
        "closed_at": "2022-03-29T07:28:45+00:00",
        "comments_count": [
            "yinhaofeng",
            "veridone",
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 737,
        "title": "AI Studio中mind模型inference_model_to_serving转换模型后使用client.predict预测报错",
        "body": "PaddlePaddle2.2.2\\paddle-serving-client 0.8.3\r\n1、在AI Studio中测试mind模型，在config.yaml中增加以下几行\r\n use_inference: True\r\n save_inference_feed_varnames: ['hist_item','seq_len']\r\n save_inference_fetch_varnames: [\"softmax_with_cross_entropy_0.tmp_0\"]\r\n2、使用python -u tools/static_trainer.py -m models/recall/mind/config.yaml命令生成模型。\r\n3、使用以下测试代码，serving转换之前生成的模型，再构造测试数据预测。\r\nimport os\r\nimport logging\r\nimport numpy as np\r\nimport paddle\r\nimport paddle_serving_client.io as serving_io\r\nfrom paddle_serving_app.local_predict import LocalPredictor\r\n\r\ndef serving(model_path, epoch_id):\r\n    serving_io.inference_model_to_serving(model_path+\"/\"+str(epoch_id),\r\n                                          serving_server=\"serving_server\",\r\n                                          serving_client=\"serving_client\",\r\n                                          model_filename=\"rec_inference.pdmodel\",\r\n                                          params_filename=\"rec_inference.pdiparams\")\r\n\r\n\r\ndef process_feed_dict(recall_result):\r\n    dic = {\"hist_item\": [2805, 2573], \"seq_len\": [2]}\r\n    for key in dic:\r\n        dic[key] = np.array(dic[key]).astype(np.int64).reshape(len(dic[key]), 1)\r\n    return dic\r\n\r\n\r\ndef rank_predict(recall_result):\r\n    client = LocalPredictor()\r\n    client.load_model_config(\"serving_server\")\r\n    dict = process_feed_dict(None)\r\n    print(dict)\r\n    fetch_map = client.predict(feed=dict, fetch=[\"save_infer_model/scale_0.tmp_1\"], batch=True)\r\n    return fetch_map\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    model_path = \"output_model_mind\"\r\n    epoch_id = 0\r\n    # serving(model_path, epoch_id)\r\n    fetch_map = rank_predict(None)\r\n    print(fetch_map)\r\n    for i in range(1):\r\n        list = fetch_map[\"save_infer_model/scale_0.tmp_1\"].tolist()[i]\r\n        print(list)\r\n        list1 = fetch_map[\"save_infer_model/scale_0.tmp_1\"][i][1]\r\n        print(\"cell\"+str(i)+\"=\"+str(list1))\r\n\r\n错误如下：\r\n{'hist_item': array([[2805],\r\n       [2573]]), 'seq_len': array([[2]])}\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 36, in <module>\r\n    fetch_map = rank_predict(None)\r\n  File \"predict.py\", line 28, in rank_predict\r\n    fetch_map = client.predict(feed=dict, fetch=[\"save_infer_model/scale_0.tmp_1\"], batch=True)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle_serving_app/local_predict.py\", line 393, in predict\r\n    self.predictor.run()\r\nValueError: In user code:\r\n\r\n    File \"tools/static_trainer.py\", line 296, in <module>\r\n      main(args)\r\n    File \"tools/static_trainer.py\", line 69, in main\r\n      fetch_vars = static_model_class.net(input_data)\r\n    File \"/home/aistudio/PaddleRec/models/recall/mind/static_model.py\", line 78, in net\r\n      hist_item, seqlen, labels)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/home/aistudio/PaddleRec/models/recall/mind/net.py\", line 287, in forward\r\n      seqlen)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/home/aistudio/PaddleRec/models/recall/mind/net.py\", line 197, in forward\r\n      B_mask = paddle.where(mask, B, pad)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/search.py\", line 532, in where\r\n      outputs={'Out': [out]})\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3184, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2224, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The dims of Inputs(Condition) and Inputs(X) should be same. But received Condition's shape is [1, 4, 20], X's shape is [2, 4, 20]\r\n      [Hint: Expected cond_dims == x_dims, but received cond_dims:1, 4, 20 != x_dims:2, 4, 20.] (at /paddle/paddle/fluid/operators/where_op.cc:38)\r\n      [operator < where > error]\r\n不知是构造测试数据有错还是框架本身的原因？",
        "state": "open",
        "user": "sjun",
        "closed_by": null,
        "created_at": "2022-03-31T13:01:50+00:00",
        "updated_at": "2022-04-01T12:06:00+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "sjun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 742,
        "title": "as for the recall ensfm ,  can you help to give some information about the format of the ensfm training dataset?",
        "body": "as for the recall ensfm ,  can you help to give some information about the format of the ensfm training dataset?\r\n\r\nfor the two part of the data,what does each stand for?\r\nthe first part of each column is the userid & itemid respectively? and the rest is the user's feature and item feature?\r\n\r\nthanks very much\r\n\r\n1-6041-6042-6043 3186-3711\r\n1-6041-6042-6043 1270-3709\r\n1-6041-6042-6043 1721-3711\r\n",
        "state": "open",
        "user": "jackyhawk",
        "closed_by": null,
        "created_at": "2022-04-08T11:49:06+00:00",
        "updated_at": "2022-04-12T08:18:55+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "jackyhawk",
            "jackyhawk",
            "wangzhen38",
            "yinhaofeng",
            "jackyhawk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 743,
        "title": "param_state_dict 里边的 \"item_emb.weight\" 是用索引（0,1,2，……）对所有的 特征进行编码（编号）的，对吗？",
        "body": "PaddleRec\\tools\\utils 里边的 save_load.py这个文件中，\r\nparam_state_dict 里边的 \"item_emb.weight\" 是用索引对所有的 特征进行编码（编号）的，对吗？\r\n所有特征的顺序-->对于特征的名称，这个在哪能取到？多谢\r\n\r\ndef load_model(model_path, net, prefix='rec'):\r\n    logger.info(\"start load model from {}\".format(model_path))\r\n    model_prefix = os.path.join(model_path, prefix)\r\n    **param_state_dict = paddle.load(model_prefix + \".pdparams\")**\r\n    net.set_dict(param_state_dict)",
        "state": "open",
        "user": "jackyhawk",
        "closed_by": null,
        "created_at": "2022-04-11T08:09:28+00:00",
        "updated_at": "2022-04-12T11:55:20+00:00",
        "closed_at": null,
        "comments_count": [
            "jackyhawk",
            "wangzhen38",
            "jackyhawk",
            "jackyhawk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 745,
        "title": "gru4rec 模型的动态图定义与训练",
        "body": "你好，在召回模型中gru4rec 在 release 2 实现被删除了，只在release 1.8 以静态图的形式实现了，请问有没有动态图版本的gru4rec?",
        "state": "open",
        "user": "yejiahaoye",
        "closed_by": null,
        "created_at": "2022-04-19T09:48:57+00:00",
        "updated_at": "2022-04-19T11:51:13+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 746,
        "title": "静态图训练时，每个epoch之后，内存累加",
        "body": "静态图训练时，每个epoch训练完成使用save_interface接口保存模型，内存会增加一些，导致无法进行多轮训练",
        "state": "closed",
        "user": "JingyibySUTsoftware",
        "closed_by": "JingyibySUTsoftware",
        "created_at": "2022-04-20T03:45:58+00:00",
        "updated_at": "2022-05-01T06:34:15+00:00",
        "closed_at": "2022-05-01T06:34:15+00:00",
        "comments_count": [
            "wangzhen38",
            "JingyibySUTsoftware",
            "wangzhen38",
            "JingyibySUTsoftware",
            "JingyibySUTsoftware"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 754,
        "title": "关于wide_deep model 的 TIPC 测试。",
        "body": "你好我在fork项目后按照test_tipc里的readme.md文件里的指示进行测试。执行一下两条代码：\r\n1.bash test_tipc/prepare.sh ./test_tipc/configs/wide_deep/train_infer_python.txt 'lite_train_lite_infer'\r\n2.bash test_tipc/test_train_inference_python.sh ./test_tipc/configs/wide_deep/train_infer_python.txt 'lite_train_lite_infer'\r\n再enable_tensorRT=True的情况下，测试失败，错误报告如下：\r\nW0504 20:43:30.999462  1664 analysis_predictor.cc:795] The one-time configuration of analysis predictor failed, which may be due to native predictor called first and its configurations taken effect.\r\nI0504 20:43:31.013504  1664 analysis_predictor.cc:576] TensorRT subgraph engine is enabled\r\n\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\r\n\u001b[1m\u001b[35m--- Running analysis [ir_graph_clean_pass]\u001b[0m\r\n\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\r\nTraceback (most recent call last):\r\n  File \"tools/paddle_infer.py\", line 169, in <module>\r\n    main(args)\r\n  File \"tools/paddle_infer.py\", line 115, in main\r\n    predictor, pred_config = init_predictor(args)\r\n  File \"tools/paddle_infer.py\", line 93, in init_predictor\r\n    predictor = create_predictor(config)\r\nValueError: (InvalidArgument) Pass tensorrt_subgraph_pass has not been registered. Please use the paddle inference library compiled with tensorrt or disable the tensorrt engine in inference configuration! \r\n  [Hint: Expected Has(pass_type) == true, but received Has(pass_type):0 != true:1.] (at /paddle/paddle/fluid/framework/ir/pass.h:236)\r\n\r\n运行环境是AI Studio经典版  V100 32GB。\r\n请问是因为环境的问题吗？",
        "state": "closed",
        "user": "Li-fAngyU",
        "closed_by": "Li-fAngyU",
        "created_at": "2022-05-04T12:49:17+00:00",
        "updated_at": "2022-05-06T07:10:28+00:00",
        "closed_at": "2022-05-06T07:10:28+00:00",
        "comments_count": [
            "wangzhen38",
            "Li-fAngyU",
            "Li-fAngyU",
            "wangzhen38",
            "Li-fAngyU"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 769,
        "title": "评估指标没有reset",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/8ce9dbdbc5d0149bfcdb57a06a183024cff21aa3/tools/infer.py#L176-L179",
        "state": "closed",
        "user": "renmada",
        "closed_by": "renmada",
        "created_at": "2022-05-13T03:49:04+00:00",
        "updated_at": "2022-05-13T03:49:57+00:00",
        "closed_at": "2022-05-13T03:49:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 764,
        "title": "PLE模型",
        "body": "PLE模型训练之后似乎auc_income一直是0.5多一点，是不是有问题？",
        "state": "open",
        "user": "toziki",
        "closed_by": null,
        "created_at": "2022-05-10T14:37:32+00:00",
        "updated_at": "2022-05-17T06:46:42+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 765,
        "title": "MIND模型效果复现",
        "body": "MIND模型按照步骤使用全量的AmazonBook数据集，实际测试并没有达到README里标称的效果，有什么需要注意的地方吗？实验环境为python=3.9.7, paddlepaddle=2.2.2, cuda=10.2。\r\n![image](https://user-images.githubusercontent.com/45687099/167773326-5275148c-80fa-4be3-bdcf-400e07bc8627.png)\r\n",
        "state": "open",
        "user": "ADCa97",
        "closed_by": null,
        "created_at": "2022-05-11T05:12:19+00:00",
        "updated_at": "2022-07-30T06:37:40+00:00",
        "closed_at": null,
        "comments_count": [
            "yinhaofeng",
            "yechenzhi",
            "yechenzhi",
            "AlbusWei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 770,
        "title": "PaddleRec/models/demo/movie_recommand 这个demo动态图训练和静态图训练均报错",
        "body": "# 动态图训练recall模型\r\n!cd PaddleRec/models/demo/movie_recommand && python -u ../../../tools/trainer.py -m recall/config.yaml\r\n执行这个命令报错\r\n![image](https://user-images.githubusercontent.com/15665995/168250324-d6ba31f7-9ed6-4fab-8d50-02b0c67b2224.png)\r\n",
        "state": "closed",
        "user": "hongenge",
        "closed_by": "hongenge",
        "created_at": "2022-05-13T09:11:48+00:00",
        "updated_at": "2022-05-13T09:35:33+00:00",
        "closed_at": "2022-05-13T09:35:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 778,
        "title": "ESMM只有10万条数据吗",
        "body": "请问ESMM 用的ali-ccp的全量数据34M的数据有放出来吗，现在放出的全量数据只有10万条，在上面训练很容易过拟合？",
        "state": "open",
        "user": "mojinyu123",
        "closed_by": null,
        "created_at": "2022-05-22T08:48:13+00:00",
        "updated_at": "2022-05-24T06:02:47+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 792,
        "title": "No module named 'paddle.inference'",
        "body": null,
        "state": "closed",
        "user": "wjy3326",
        "closed_by": "wjy3326",
        "created_at": "2022-06-09T02:01:11+00:00",
        "updated_at": "2023-11-15T02:43:13+00:00",
        "closed_at": "2022-06-09T09:07:30+00:00",
        "comments_count": [
            "jack00000"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 814,
        "title": "(models/recall/mind)MIND预测，怎么拿到iterm embedding对应的iterm id",
        "body": "<img width=\"932\" alt=\"image\" src=\"https://user-images.githubusercontent.com/19882987/179933847-db5f9057-6f49-42a0-a299-cde56458bb02.png\">\r\n",
        "state": "open",
        "user": "guoyangji",
        "closed_by": null,
        "created_at": "2022-07-20T08:24:56+00:00",
        "updated_at": "2022-07-20T08:25:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 815,
        "title": "PaddleRec DeepFM Demo 用Flask部署",
        "body": "[范例](https://www.paddlepaddle.org.cn/tutorials/projectdetail/4002682#anchor-27)提到用Flask部署服务进行inference，但git repo中并没有Falsk相应的文件，请问这块有参考吗？",
        "state": "open",
        "user": "syw2014",
        "closed_by": null,
        "created_at": "2022-07-22T07:22:36+00:00",
        "updated_at": "2022-07-22T07:22:36+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 793,
        "title": "grpc远程调用错误",
        "body": "在https://github.com/PaddlePaddle/PaddleRec/tree/master/recserving/movie_recommender 的test_client.py启动客户端过程中出现错误：\r\n(image_text_match_tf_1.15) [user@tianhu-worker-5 movie_recommender]$ python test_client.py as 5\r\nTraceback (most recent call last):\r\n  File \"test_client.py\", line 81, in <module>\r\n    print(get_as(req))\r\n  File \"test_client.py\", line 66, in get_as\r\n    response = stub.as_call(request)\r\n  File \"/home/user/anaconda3/envs/image_text_match_tf_1.15/lib/python3.6/site-packages/grpc/_channel.py\", line 923, in __call__\r\n    return _end_unary_response_blocking(state, call, False, None)\r\n  File \"/home/user/anaconda3/envs/image_text_match_tf_1.15/lib/python3.6/site-packages/grpc/_channel.py\", line 826, in _end_unary_response_blocking\r\n    raise _InactiveRpcError(state)\r\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\r\n        status = StatusCode.UNKNOWN\r\n        details = \"Exception calling application: <_InactiveRpcError of RPC that terminated with:\r\n        status = StatusCode.UNKNOWN\r\n        details = \"Exception calling application: Error 111 connecting to 172.17.0.1:6389. Connection refused.\"\r\n        debug_error_string = \"{\"created\":\"@1654828488.731180301\",\"description\":\"Error received from peer ipv4:127.0.0.1:8910\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1061,\"grpc_message\":\"Exception calling application: Error 111 connecting to 172.17.0.1:6389. Connection refused.\",\"grpc_status\":2}\"\r\n>\"\r\n        debug_error_string = \"{\"created\":\"@1654828488.732741464\",\"description\":\"Error received from peer ipv4:192.168.10.87:8930\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1061,\"grpc_message\":\"Exception calling application: <_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNKNOWN\\n\\tdetails = \"Exception calling application: Error 111 connecting to 172.17.0.1:6389. Connection refused.\"\\n\\tdebug_error_string = \"{\"created\":\"@1654828488.731180301\",\"description\":\"Error received from peer ipv4:127.0.0.1:8910\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1061,\"grpc_message\":\"Exception calling application: Error 111 connecting to 172.17.0.1:6389. Connection refused.\",\"grpc_status\":2}\"\\n>\",\"grpc_status\":2}\"\r\n>\r\n请问该怎么解决？",
        "state": "closed",
        "user": "wjy3326",
        "closed_by": "wjy3326",
        "created_at": "2022-06-10T03:02:42+00:00",
        "updated_at": "2023-08-21T10:23:24+00:00",
        "closed_at": "2022-06-13T11:51:56+00:00",
        "comments_count": [
            "LYuanLing",
            "husheng-liu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 816,
        "title": "DeepRec模型如何用分布式CPU训练",
        "body": "看支持模型列表写着DeepRec模型支持分布式CPU训练，但是我看DeepRec模型是用自身的trainer.py文件，没有用tools下的，应该怎么启动分布式CPU训练？",
        "state": "open",
        "user": "laigood",
        "closed_by": null,
        "created_at": "2022-07-25T09:58:29+00:00",
        "updated_at": "2022-07-25T09:58:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 804,
        "title": "essfm训练loss为负，且一直最小优化，咋处理",
        "body": "请问一下，使用ensfm训练优化loss为负数了，是因为非负采样太少吗？",
        "state": "open",
        "user": "snailfrying",
        "closed_by": null,
        "created_at": "2022-06-29T06:49:58+00:00",
        "updated_at": "2022-07-05T07:59:11+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 806,
        "title": "Error when runing DNN exampel ",
        "body": "Hi, when I run the example of DNN. The error AttributeError: module 'paddle' has no attribute 'is_compiled_with_npu' occured",
        "state": "open",
        "user": "justopit",
        "closed_by": null,
        "created_at": "2022-07-05T17:55:42+00:00",
        "updated_at": "2022-07-12T06:29:29+00:00",
        "closed_at": null,
        "comments_count": [
            "frankwhzhang"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 822
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 817,
        "title": "为什么训练如此慢，用criteo 20g数据集版本，一直内存才用几G ，一夜也训练不完",
        "body": null,
        "state": "open",
        "user": "ArtificialZeng",
        "closed_by": null,
        "created_at": "2022-07-29T05:46:43+00:00",
        "updated_at": "2022-07-29T11:57:49+00:00",
        "closed_at": null,
        "comments_count": [
            "ArtificialZeng",
            "iamWHTWD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 820,
        "title": "ESMM全量数据生成缺失reader.py文件",
        "body": "ali-ccp文件夹下，data_process.sh文件里面有一行\r\npython reader.py --train_data_path ${train_target_path} \\\r\n                 --test_data_path ${test_target_path} \\\r\n                 --vocab_path vocab/vocab_size.txt \\\r\n                 --train_sample_size 6400 \\\r\n                 --test_sample_size 6400 \\\r\n但是ali-ccp文件夹下没有reader.py文件，而使用run.sh下载的10m数据集复现不了文档中说的效果，auc停留在0.5x\r\n想要下载全量数据，但是没有reader，也无法反推数据处理的方式",
        "state": "closed",
        "user": "AlbusWei",
        "closed_by": "AlbusWei",
        "created_at": "2022-08-04T18:43:26+00:00",
        "updated_at": "2022-08-04T18:43:52+00:00",
        "closed_at": "2022-08-04T18:43:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 819,
        "title": "ESMM全量数据生成缺失reader.py文件",
        "body": "ali-ccp文件夹下，data_process.sh文件里面有一行\r\npython reader.py --train_data_path ${train_target_path} \\\r\n                 --test_data_path ${test_target_path} \\\r\n                 --vocab_path vocab/vocab_size.txt \\\r\n                 --train_sample_size 6400 \\\r\n                 --test_sample_size 6400 \\\r\n但是ali-ccp文件夹下没有reader.py文件，而使用run.sh下载的10m数据集复现不了文档中说的效果，auc停留在0.5x\r\n想要下载全量数据，但是没有reader，也无法反推数据处理的方式",
        "state": "open",
        "user": "AlbusWei",
        "closed_by": null,
        "created_at": "2022-08-04T18:43:02+00:00",
        "updated_at": "2022-08-10T11:49:06+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 834,
        "title": "wide&deep learning rate decay",
        "body": "请问wide&deep模型如何设置earning rate decay呢？",
        "state": "closed",
        "user": "flyingjohn",
        "closed_by": "flyingjohn",
        "created_at": "2022-09-14T12:40:27+00:00",
        "updated_at": "2022-10-18T09:44:07+00:00",
        "closed_at": "2022-10-18T09:44:07+00:00",
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 837,
        "title": "如何自定义优化器？",
        "body": "如题，如果想对已有模型如Shared-Bottom自定义优化器该怎么做呢？",
        "state": "closed",
        "user": "marcuswang6",
        "closed_by": "marcuswang6",
        "created_at": "2022-09-17T03:17:27+00:00",
        "updated_at": "2022-09-19T04:03:43+00:00",
        "closed_at": "2022-09-19T04:03:42+00:00",
        "comments_count": [
            "wangzhen38",
            "marcuswang6"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 821,
        "title": "Bug found in `Ali_Display_Ad_Click` dataset preprocessing, which has been used for DMR model reproduction.",
        "body": "数据集目录“Ali_Display_Ad_Click”中显示从以下路径直接获取预处理后的数据https://github.com/PaddlePaddle/PaddleRec/blob/master/datasets/Ali_Display_Ad_Click/run.sh#L3\r\n```\r\nwget https://paddlerec.bj.bcebos.com/datasets/dmr/dataset_full.zip\r\n```\r\n\r\n但该预处理数据的ID编码存在问题，具体表现为: 编码之后test set中仍包含未在train set中出现过的ID，可能原因为编码词典的统计不是只在train set中进行，导致test中出现的的新ID也在字典中。从而导致训练模型过程中，feature embedding的数量要比真实的要大，test阶段未训练到的ID embedding会以随机值的形式出现，会导致模型效果偏低。\r\n\r\n以brand为例，统计brand_his和brand两个字段(这两个字段是统一编码)，具体复现代码：\r\n```\r\n# 字段说明参看https://aistudio.baidu.com/aistudio/projectdetail/1805731 中“生成最终训练和测试数据集”标签页\r\ntrain = pd.read_csv(\"work/train_sorted.csv\", dtype=object)\r\ntrain.fillna(\"0\", inplace=True)\r\nbrand = train.iloc[:, 263].astype(int).values\r\nbrand_set = set(list(brand))\r\nbrand_his = train.iloc[:, 100:150].astype(int).values.flatten()\r\nbrand_his_set = set(list(brand_his))\r\nbrand_train = brand_set | brand_his_set\r\npd.DataFrame({\"brand\": sorted(list(brand_train))}).to_csv(\"train_brand.csv\", index=False)\r\n\r\ntest = pd.read_csv(\"work/test.csv\", dtype=object)\r\ntest.fillna(\"0\", inplace=True)\r\nbrand = test.iloc[:, 263].astype(int).values\r\nbrand_set = set(list(brand))\r\nbrand_his = test.iloc[:, 100:150].astype(int).values.flatten()\r\nbrand_his_set = set(list(brand_his))\r\nbrand_test = brand_set | brand_his_set\r\npd.DataFrame({\"brand\": sorted(list(brand_test))}).to_csv(\"test_brand.csv\", index=False)\r\n\r\nprint(\"Diff size:\", len(brand_test - brand_train))\r\nprint(list(brand_test - brand_train)[0:50])\r\n```\r\n执行结果：\r\n```\r\nDiff size: 8048  # 即test中包含8048个新的brand id，未在train中出现，但进行了编码，分配了embedding空间\r\n[163844, 32784, 360465, 65555, 360469, 426009, 26, 32795, 262171, 294941, 458783, 196646, 426022, 98345, 32814, 327727, 294971, 65599, 196672, 360511, 196682, 229457, 458846, 458851, 163940, 393317, 327783, 262250, 98414, 262255, 229489, 98422, 196727, 196729, 65665, 327809, 65667, 65676, 32909, 65678, 131215, 163983, 426126, 65682, 98457, 229539, 65700, 164008, 196776, 327848]\r\n```\r\n\r\n同样对cate_id和cate_his执行相同的代码得到:\r\n```\r\nDiff size: 101\r\n[4096, 11264, 5639, 4105, 1547, 4107, 11275, 2066, 4116, 12314, 4124, 12323, 12324, 2597, 11813, 5677, 558, 2045, 50, 8243, 52, 3646, 3137, 11329, 68, 4164, 9292, 2665, 10351, 3185, 114, 7795, 4236, 3213, 2190, 4246, 12450, 12467, 2740, 8394, 3288, 3291, 9952, 9441, 2823, 11532, 10511, 10002, 3867, 12581]\r\n```",
        "state": "open",
        "user": "zhujiem",
        "closed_by": null,
        "created_at": "2022-08-04T23:46:11+00:00",
        "updated_at": "2022-08-10T10:09:21+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 839,
        "title": "wide_deep/config_gpups.yaml的sparse_feature_number为什么是1024？",
        "body": "在wide_deep目录下运行：python -u ../../../tools/trainer.py config_gpups.yaml\r\n报错了：\r\nValueError: (InvalidArgument) Variable value (input) of OP(fluid.layers.embedding) expected >= 0 and < 1024, but got 737395. Please check input value.\r\n  [Hint: Expected ids[i] < row_number, but received ids[i]:737395 >= row_number:1024.] (at /paddle/paddle/phi/kernels/cpu/embedding_kernel.cc:63)\r\n  [operator < lookup_table_v2 > error]\r\n请问这里sparse_feature_number的值为什么是1024？",
        "state": "open",
        "user": "wintersurvival",
        "closed_by": null,
        "created_at": "2022-09-18T14:26:57+00:00",
        "updated_at": "2022-09-18T15:17:19+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 846,
        "title": "无法可视化梯度：参数的梯度是None",
        "body": "代码：\r\n```\r\nloss.backward(retain_graph=True)\r\noptimizer.step()\r\nfor name, param in dy_model.named_parameters():\r\n                if param.grad is not None:\r\n                # [499, 117]\r\n                    tag_name = \"train/\" + name + '/grad1'\r\n                    log_visual.add_histogram(\r\n                                tag=tag_name, \r\n                                values= param.grad.numpy(),\r\n                                step=step_num,)\r\noptimizer.clear_grad()\r\n```\r\n\r\n报错消息：\r\n```\r\nWarning:\r\ntensor.grad will return the tensor value of the gradient. This is an incompatible upgrade for tensor.grad API.  It's return type changes from numpy.ndarray in version 2.0 to paddle.Tensor in version 2.1.0.  If you want to get the numpy value of the gradient, you can use :code:`x.grad.numpy()` \r\n  warnings.warn(warning_msg)\r\n../../../tools/trainer.py:50: RuntimeWarning: divide by zero encountered in true_divide\r\n  similiarity = np.dot(a, b.T)/(a_norm * b_norm)\r\n../../../tools/trainer.py:50: RuntimeWarning: invalid value encountered in true_divide\r\n  similiarity = np.dot(a, b.T)/(a_norm * b_norm)\r\nTraceback (most recent call last):\r\n  File \"../../../tools/trainer.py\", line 284, in <module>\r\n    main(args)\r\n  File \"../../../tools/trainer.py\", line 204, in main\r\n    step=step_num,)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/visualdl/writer/writer.py\", line 435, in add_histogram\r\n    hist, bin_edges = np.histogram(values, bins=buckets)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/histograms.py\", line 780, in histogram\r\n    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/histograms.py\", line 417, in _get_bin_edges\r\n    first_edge, last_edge = _get_outer_edges(a, range)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/histograms.py\", line 315, in _get_outer_edges\r\n    \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\r\nValueError: autodetected range of [nan, nan] is not finite\r\n```\r\n求大神帮忙，蟹蟹！",
        "state": "closed",
        "user": "marcuswang6",
        "closed_by": "marcuswang6",
        "created_at": "2022-09-23T03:26:54+00:00",
        "updated_at": "2022-10-01T04:37:15+00:00",
        "closed_at": "2022-10-01T04:37:15+00:00",
        "comments_count": [
            "wangzhen38",
            "marcuswang6",
            "wangzhen38",
            "marcuswang6"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 847,
        "title": "UnboundLocalError: local variable 'tensor_print_dict' referenced before assignment",
        "body": "infer.py 推理的时候，测试数据不够一个batch的时候，报错。",
        "state": "closed",
        "user": "wcode-wzx",
        "closed_by": "wcode-wzx",
        "created_at": "2022-09-27T02:24:09+00:00",
        "updated_at": "2022-09-28T10:06:05+00:00",
        "closed_at": "2022-09-28T10:06:05+00:00",
        "comments_count": [
            "wangzhen38",
            "wcode-wzx",
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 859,
        "title": "youtube dnn是否能支持百万级的softmax？（论文原文自称使用了sampled softmax loss）",
        "body": "谢谢",
        "state": "closed",
        "user": "ralgond",
        "closed_by": "ralgond",
        "created_at": "2022-11-24T01:14:59+00:00",
        "updated_at": "2022-11-24T15:37:11+00:00",
        "closed_at": "2022-11-24T15:37:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 850,
        "title": "hash函数的问题",
        "body": "发现有些预处理脚本如：\r\nhttps://github.com/PaddlePaddle/PaddleRec/blob/master/datasets/criteo_lr/get_slot_data.py，\r\n在处理分类特征时使用到了python内置的hash函数，而这个函数在不同进程对同一值出来的哈希值不同。\r\n查询以往issue发现有个修复：https://github.com/PaddlePaddle/PaddleRec/pull/476/commits/a875c7b95d72ad7e6997312112ee246281f54660 \r\n但只修复了w&d和dnn的批量读脚本。应该都修复下以防踩坑",
        "state": "open",
        "user": "laigood",
        "closed_by": null,
        "created_at": "2022-10-14T06:40:54+00:00",
        "updated_at": "2022-10-17T06:22:18+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 856,
        "title": "推荐算法业务咨询",
        "body": "您好，请问PaddleRec团队老师们：有类似paddleNLP的流水线端到端，便于直接部署到业务中的推荐产品吗？\r\n（前段时间已经基于paddleNLP端到端搭建了一个规范查询系统https://mp.weixin.qq.com/s/zEHU_aDctre8e2DbJjhlfA\r\n现需结合实际查询业务实现规范条款的精准推荐）\r\n感谢~",
        "state": "open",
        "user": "bruce0210",
        "closed_by": null,
        "created_at": "2022-11-10T01:42:30+00:00",
        "updated_at": "2022-11-10T02:35:45+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 858,
        "title": "请问ple怎么使用ali-ccp数据集进行训练，我这边一直报不是tensor数据的错误",
        "body": null,
        "state": "open",
        "user": "FDASFADWE",
        "closed_by": null,
        "created_at": "2022-11-15T05:26:03+00:00",
        "updated_at": "2022-11-15T07:02:15+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 860,
        "title": "DCN 全量模型epoch_num参数的配置是否存在问题？",
        "body": "DCN的config_bigdata.yaml中将epochs配置为10，训练过程中auc指标超过给出的benchmrak 0.777很多，推理过程中auc却达不到训练的程度，后几个epoch生成的模型甚至达不到benchmark，怀疑出现了过拟合现象。所以想请教一下这个参数的配置是否有问题？\r\n另外看到有其他使用criteo数据集的模型的epoch参数设置为1，DCN是否也是配置为1比较好？\r\n这是训练精度：\r\n2022-11-24 23:10:42,973 - INFO - epoch: 0 done, auc: 0.797744, epoch time: 10259.33 s\r\n2022-11-25 01:56:55,257 - INFO - epoch: 1 done, auc: 0.813983, epoch time: 9972.15 s\r\n2022-11-25 04:42:34,678 - INFO - epoch: 2 done, auc: 0.824308, epoch time: 9939.29 s\r\n2022-11-25 07:27:25,202 - INFO - epoch: 3 done, auc: 0.832276, epoch time: 9890.38 s\r\n2022-11-25 10:09:49,307 - INFO - epoch: 4 done, auc: 0.838268, epoch time: 9743.98 s\r\n2022-11-25 12:52:43,571 - INFO - epoch: 5 done, auc: 0.842872, epoch time: 9774.13 s\r\n2022-11-25 15:36:14,327 - INFO - epoch: 6 done, auc: 0.846537, epoch time: 9810.63 s\r\n2022-11-25 18:24:26,853 - INFO - epoch: 7 done, auc: 0.849568, epoch time: 10092.39 s\r\n2022-11-25 21:05:38,557 - INFO - epoch: 8 done, auc: 0.852145, epoch time: 9671.57 s\r\n2022-11-25 23:49:26,100 - INFO - epoch: 9 done, auc: 0.854425, epoch time: 9827.41 s\r\n这是推理精度：\r\n2022-11-28 10:05:40,387 - INFO - epoch: 0 done, auc: 0.800802, epoch time: 407.88 s\r\n2022-11-28 10:12:20,827 - INFO - epoch: 1 done, auc: 0.801374, epoch time: 400.44 s\r\n2022-11-28 10:19:00,820 - INFO - epoch: 2 done, auc: 0.796485, epoch time: 399.99 s\r\n2022-11-28 10:25:47,121 - INFO - epoch: 3 done, auc: 0.790854, epoch time: 406.30 s\r\n2022-11-28 10:32:18,459 - INFO - epoch: 4 done, auc: 0.786025, epoch time: 391.34 s\r\n2022-11-28 10:38:54,057 - INFO - epoch: 5 done, auc: 0.782249, epoch time: 395.60 s\r\n2022-11-28 10:45:33,497 - INFO - epoch: 6 done, auc: 0.778672, epoch time: 399.44 s\r\n2022-11-28 10:52:11,217 - INFO - epoch: 7 done, auc: 0.775637, epoch time: 397.72 s\r\n2022-11-28 10:58:49,925 - INFO - epoch: 8 done, auc: 0.773437, epoch time: 398.71 s\r\n2022-11-28 11:05:31,881 - INFO - epoch: 9 done, auc: 0.770960, epoch time: 401.96 s",
        "state": "open",
        "user": "USTCKAY",
        "closed_by": null,
        "created_at": "2022-11-28T02:53:23+00:00",
        "updated_at": "2022-11-30T06:13:43+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "USTCKAY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 861,
        "title": "deeprec模型训练过程中没有输出实时精度",
        "body": "训练输出信息如下，没有精度信息。\r\n<img width=\"1301\" alt=\"c58fc0ad9994dbda511f982b33c443ff\" src=\"https://user-images.githubusercontent.com/50285351/204726178-0f35934a-ed60-4ad0-9aa6-4e7bd164a2e1.png\">\r\n查看deeprec目录下的dygraph_model.py，发现train_forward函数中更新评价指标的部分似乎没有实现。具体在这个地方：https://github.com/PaddlePaddle/PaddleRec/blob/24bea1bfb6110442f5ade28ec6ceba96aa8e455b/models/rank/deeprec/dygraph_model.py#L75\r\n<img width=\"823\" alt=\"a8258aed2579cd0f7d054321a7e573d3\" src=\"https://user-images.githubusercontent.com/50285351/204726497-21511b40-f00f-4f3f-b493-e56b8d70d43c.png\">\r\n希望可以修复一下",
        "state": "open",
        "user": "USTCKAY",
        "closed_by": null,
        "created_at": "2022-11-30T06:46:50+00:00",
        "updated_at": "2022-12-08T02:23:58+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 863,
        "title": "TDM模型快速开始部分运行失败: KeyError: '102489422'",
        "body": "@wangzhen38  我尝试参照README.md的教程运行实例，我使用的版本是stable 2.3，在参考[快速开始](https://github.com/PaddlePaddle/PaddleRec/tree/release/2.3.0/models/treebased#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B)部分运行时出现错误。我成功地完成了初次训练，并聚类生成树，但是当我再次完成训练(Step 2)后，却无法成功进行预测。报错如下：\r\n```python\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 295, in <module>\r\n    first_layer_set, config)\r\n  File \"infer.py\", line 210, in infer\r\n    for groudtruth, user_input in reader():\r\n  File \"infer.py\", line 60, in reader\r\n    groudtruth, output_list = self.line_process(line)\r\n  File \"infer.py\", line 49, in line_process\r\n    bidword_list = [self.id_code[s] for s in bidword_list]\r\n  File \"infer.py\", line 49, in <listcomp>\r\n    bidword_list = [self.id_code[s] for s in bidword_list]\r\nKeyError: '102489422'\r\n```\r\n经过调试，我发现再次建树生成的ids_id.txt与初次建树生成文件的key字段完全不一样，它们之间相差非常大。\r\n![Snipaste_2022-12-25_19-51-17](https://user-images.githubusercontent.com/102496108/209466850-31634c45-2416-4869-8abd-cf116cebd3f3.png)\r\n\r\n同时再次建树生成ids_id.txt中所有的id在 [测试数据](https://github.com/PaddlePaddle/PaddleRec/blob/release/2.3.0/models/treebased/data/demo_test_data/test_data)都不存在，正因如此才会出现KeyError。我确实不太清楚是哪一步出现了问题，感觉可能是生成的`epoch_0_item_embedding.txt` 的id号和原始数据对不上。 @wangzhen38  我是哪一步弄错了吗？\r\n\r\n",
        "state": "open",
        "user": "Jim59-Chen",
        "closed_by": null,
        "created_at": "2022-12-25T11:54:40+00:00",
        "updated_at": "2022-12-28T03:07:21+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "wangzhen38",
            "Jim59-Chen",
            "Jim59-Chen",
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 865,
        "title": "[Question] about: Solve user cold-start problems",
        "body": "Thanks for great repo.\r\nWhen I read the readme, it shows that: \"model can face with poor user\", but with your example, it contains the users - items and interaction\r\nwith my define:\r\n**User cold-start problems: When there is almost no information available about the user and all are new for system, the user cold-start problem arises.**\r\nHow to solve it if use Your Resys\r\nThank you",
        "state": "open",
        "user": "phamkhactu",
        "closed_by": null,
        "created_at": "2023-01-10T09:08:05+00:00",
        "updated_at": "2023-01-12T02:45:51+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 867,
        "title": "预测结果存放在哪里呀",
        "body": "<img width=\"1272\" alt=\"image\" src=\"https://user-images.githubusercontent.com/66876429/217170298-bed1213f-58a9-494c-8c0d-7a007bde8296.png\">\r\n我使用的是PaddleRec中的wide_deep模型，我在训练完后想要预测部分数据，但是我找不到预测的结果在哪里。。。\r\n<img width=\"1182\" alt=\"image\" src=\"https://user-images.githubusercontent.com/66876429/217170677-48acf395-d114-4efa-8f72-2490da22f96f.png\">\r\n这是我推理的部分数据的结果",
        "state": "open",
        "user": "btobab",
        "closed_by": null,
        "created_at": "2023-02-07T06:58:21+00:00",
        "updated_at": "2023-02-08T11:56:49+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 869,
        "title": "FFM模型Field-aware二阶项部分问题",
        "body": "在FFM模型net.py文件中，FFM实现的Field-aware二阶项部分field_aware_feat_embedding的shape是[-1,sparse_num_field,sparse_num_field,sparse_feature_dim],如果按照FFM算法应该是[-1,sparse_feature_number,sparse_num_field,sparse_feature_dim]吧，请问这里为什么是两个sparse_num_field呢？\r\n\r\n````\r\n        # -------------------Field-aware second order term  --------------------\r\n        sparse_embeddings = self.embedding(sparse_inputs_concat)\r\n        dense_inputs_re = paddle.unsqueeze(dense_inputs, axis=2)\r\n        dense_embeddings = paddle.multiply(dense_inputs_re, self.dense_w)\r\n        feat_embeddings = paddle.concat([sparse_embeddings, dense_embeddings],\r\n                                        1)\r\n        field_aware_feat_embedding = paddle.reshape(\r\n            feat_embeddings,\r\n            shape=[\r\n                -1, self.sparse_num_field, self.sparse_num_field,\r\n                self.sparse_feature_dim\r\n            ])\r\n        field_aware_interaction_list = []\r\n        for i in range(self.sparse_num_field):\r\n            for j in range(i + 1, self.sparse_num_field):\r\n                field_aware_interaction_list.append(\r\n                    paddle.sum(field_aware_feat_embedding[:, i, j, :] *\r\n                               field_aware_feat_embedding[:, j, i, :],\r\n                               1,\r\n                               keepdim=True))\r\n````",
        "state": "open",
        "user": "kj-wu",
        "closed_by": null,
        "created_at": "2023-02-10T04:50:28+00:00",
        "updated_at": "2023-02-13T02:29:00+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 868,
        "title": "paddlerec在推荐问答的时候，有什么可以用的模型？",
        "body": "我们的数据可以拆成“title+详解”的形式，用户以自然语言提问，我们推荐给他最正确的答案，这个可以套用什么模型？",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2023-02-08T02:59:07+00:00",
        "updated_at": "2023-02-10T10:00:55+00:00",
        "closed_at": "2023-02-10T10:00:55+00:00",
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 871,
        "title": "GPU Training Issue",
        "body": "Hi,\r\n\r\nWe are now trying GPU training on PaddleRec for [NCF example](https://paddlerec.readthedocs.io/en/latest/models/recall/ncf.html).\r\n\r\nWe enabled the GPU config in the `config.yaml` as: `use_gpu: True`\r\n\r\nHowever, If we turn on this config, we get an error as follows:\r\n```\r\nRuntimeError: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\r\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/fluid/platform/download/cudnn.cc:59)\r\n```\r\nWe installed CUDNN & CUDA via Ananconda like:\r\n```\r\ncudatoolkit               11.2.2              hbe64b41_10    conda-forge\r\ncudnn                     8.2.1.32             h86fa8c9_0    conda-forge\r\n```\r\nBut it doesn't work with it.\r\n\r\nHere is the paddlepaddle we used in the example:\r\n```\r\npaddlepaddle-gpu          2.2.2                    pypi_0    pypi\r\n```\r\n",
        "state": "closed",
        "user": "hqsiswiliam",
        "closed_by": "hqsiswiliam",
        "created_at": "2023-02-12T03:14:27+00:00",
        "updated_at": "2023-03-12T04:06:28+00:00",
        "closed_at": "2023-03-12T04:06:28+00:00",
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 873,
        "title": "字段的意义",
        "body": "我使用的是PaddleRec中的mind模型\r\n<img width=\"246\" alt=\"image\" src=\"https://user-images.githubusercontent.com/66876429/219551708-e65aaa12-73b2-4d6c-ac19-819c05f3f961.png\">\r\n这个是训练集的截图\r\n训练集的字段我的理解是用户id， 商品id，点击的顺序，这些文档里是有写的\r\n但是验证集以及测试集文档里没有写这些字段的意思\r\n<img width=\"733\" alt=\"image\" src=\"https://user-images.githubusercontent.com/66876429/219552341-0d6946de-4528-4703-b30a-8cf17a1d3974.png\">\r\n这个是验证集的截图\r\n我的理解是user_id指的是用户id，target_item则全是0，这个字段我没有理解，我目前的猜测是商品的种类，hist_item指的是用户过去点击的商品id，eval_item指的是用户实际点击的商品id\r\n",
        "state": "open",
        "user": "btobab",
        "closed_by": null,
        "created_at": "2023-02-17T04:56:50+00:00",
        "updated_at": "2023-02-17T05:20:17+00:00",
        "closed_at": null,
        "comments_count": [
            "btobab"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 878,
        "title": "数据集预处理问题",
        "body": "下载criteo原生数据后使用data_process.sh对数据进行处理但得出的结果与直接下载的paddle预处理过的数据不一样。\r\n\r\n![image](https://user-images.githubusercontent.com/38580985/223614751-f3a34ab1-a201-4300-a2a5-0deba94b3a0c.png)\r\n![image](https://user-images.githubusercontent.com/38580985/223614785-3eaf5e5a-4727-42b1-b7ed-ea6da79165c3.png)\r\n所以想知道原生数据到预处理数据之间的这一块是怎么做的。",
        "state": "open",
        "user": "T0L0ve",
        "closed_by": null,
        "created_at": "2023-03-08T03:49:05+00:00",
        "updated_at": "2023-03-08T03:49:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 879,
        "title": "麻烦更新一下paddle.distributed.fleet文档接口",
        "body": "import paddle.distributed.fleet as fleet\r\nfleet.MultiSlotDataGenerator\r\n最新2.4版本查不到这个模块或者类，希望能把文档也更新一下",
        "state": "open",
        "user": "Adam86546853",
        "closed_by": null,
        "created_at": "2023-03-12T03:13:33+00:00",
        "updated_at": "2023-03-12T03:13:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 875,
        "title": "请问在官网看到的的ERNIE-Search：围绕检索场景的多种任务，有开源地址嘛",
        "body": "请问在官网看到的的ERNIE-Search：围绕检索场景的多种任务，有开源地址嘛\r\n\r\nhttps://wenxin.baidu.com/wenxin/modelbasedetail/ernie_search\r\n\r\n模型概述\r\n为了提升 ERNIE 在检索领域的效果，ERNIE-Search 提出了使用预训练阶段细粒度交互向粗粒度交互蒸馏的策略。通过在训练过程中进行自蒸馏，在节省了传统方法中训练教师模型的开销之外，提高了 ERNIE-Search 的模型效果。",
        "state": "open",
        "user": "tingaicompass",
        "closed_by": null,
        "created_at": "2023-02-27T02:24:27+00:00",
        "updated_at": "2023-02-27T07:27:47+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 883,
        "title": "tdm的示例跑不通",
        "body": "快速开始的step1就出错了，提示\r\nImportError: cannot import name 'index_dataset_pb2' from 'paddle.distributed.fleet.proto' (/Users/xxx/miniforge3/envs/paddle_env/lib/python3.9/site-packages/paddle/distributed/fleet/proto/__init__.py)\r\n求帮忙看看@wangzhen38 ",
        "state": "open",
        "user": "duanlisheng",
        "closed_by": null,
        "created_at": "2023-03-14T07:56:05+00:00",
        "updated_at": "2023-03-25T09:18:11+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "duanlisheng",
            "wangzhen38",
            "duanlisheng",
            "wangzhen38",
            "MerrillLi",
            "whutbd",
            "MerrillLi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 887,
        "title": "slot_dnn示例跑不通",
        "body": null,
        "state": "open",
        "user": "13320017832",
        "closed_by": null,
        "created_at": "2023-03-16T04:26:53+00:00",
        "updated_at": "2023-03-22T11:39:03+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "13320017832",
            "Adam86546853",
            "wangzhen38",
            "wang-kangkang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 885,
        "title": "【用户使用问题】运行get_movie_vectors.py报错",
        "body": "failed to create predictor: Log_id: 0  Raise_msg: (NotFound) Cannot open file serving_server/__model__, please confirm whether the file is normal.\r\n  [Hint: Expected static_cast<bool>(fin.is_open()) == true, but received static_cast<bool>(fin.is_open()):0 != true:1.] (at /paddle/paddle/fluid/inference/api/analysis_predictor.cc:1500)\r\n  ClassName: LocalPredictor.load_model_config.<locals>.create_predictor_check  FunctionName: create_predictor_check\r\nKilled\r\n![图片](https://user-images.githubusercontent.com/26479246/225199067-03bc2af6-ceae-41e3-aaef-77356cb25e62.png)\r\n",
        "state": "open",
        "user": "danan0755",
        "closed_by": null,
        "created_at": "2023-03-15T03:31:22+00:00",
        "updated_at": "2023-03-16T08:05:57+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "danan0755",
            "danan0755",
            "danan0755",
            "danan0755",
            "danan0755",
            "danan0755"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 889,
        "title": "训练ensfm模型loss为负数",
        "body": "使用的文档里的ml-1m-ensfm的数据集，输出的loss一直为负数，且越来越小\r\n![image](https://user-images.githubusercontent.com/38580985/225843083-8c6719a6-fd1a-4660-aa6c-3e902b0323ce.png)\r\n",
        "state": "open",
        "user": "T0L0ve",
        "closed_by": null,
        "created_at": "2023-03-17T07:43:43+00:00",
        "updated_at": "2023-03-17T07:43:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 888,
        "title": "rank/dnn 的demo 使用dataset 读样例数据进行训练， 仿佛没有数据读入",
        "body": null,
        "state": "open",
        "user": "incoging",
        "closed_by": null,
        "created_at": "2023-03-17T03:40:22+00:00",
        "updated_at": "2023-03-20T03:29:13+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 890,
        "title": "在线实例运行需要注册，认证的话邮箱怎么发不了邮件啊，无法点击",
        "body": "在线实例运行需要注册，认证的话邮箱怎么发不了邮件啊，无法点击",
        "state": "closed",
        "user": "Junesui",
        "closed_by": "Junesui",
        "created_at": "2023-03-18T11:33:19+00:00",
        "updated_at": "2023-03-20T10:33:55+00:00",
        "closed_at": "2023-03-20T10:33:55+00:00",
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 892,
        "title": "metric监控",
        "body": "想问下paddle有没有类似auc那个接口可以输出pcoc指标的",
        "state": "open",
        "user": "13320017832",
        "closed_by": null,
        "created_at": "2023-03-20T08:55:42+00:00",
        "updated_at": "2023-03-23T06:23:27+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 899,
        "title": "MIND模型中最后一次路由迭代为什么不设置B.stop_gradient = False ?",
        "body": "代码文件路径：models/recall/mind/net.py\r\n\r\n第206-234行：\r\n```\r\n        B = paddle.tile(self.routing_logits,\r\n                        [paddle.shape(item_his_emb)[0], 1, 1])\r\n        B.stop_gradient = True\r\n        # 这里是前iter - 1次路由迭代\r\n        for i in range(self.iters - 1):\r\n            B_mask = paddle.where(mask, B, pad)\r\n            # print(B_mask)\r\n            W = F.softmax(B_mask, axis=1)\r\n            W = paddle.unsqueeze(W, axis=2)\r\n            high_capsule_tmp = paddle.matmul(W, low_capsule_new_nograd)\r\n            # print(low_capsule_new_nograd.shape)\r\n            high_capsule = self.squash(high_capsule_tmp)\r\n            B_delta = paddle.matmul(\r\n                low_capsule_new_nograd,\r\n                paddle.transpose(high_capsule, [0, 1, 3, 2]))\r\n            B_delta = paddle.reshape(\r\n                B_delta, shape=[-1, self.k_max, self.maxlen])\r\n            B += B_delta\r\n        # 这里是最后一次路由迭代\r\n        B_mask = paddle.where(mask, B, pad)\r\n        W = F.softmax(B_mask, axis=1)\r\n        W = paddle.unsqueeze(W, axis=2)\r\n        interest_capsule = paddle.matmul(W, low_capsule_new_tile)\r\n        interest_capsule = self.squash(interest_capsule)\r\n        high_capsule = paddle.reshape(interest_capsule,\r\n                                      [-1, self.k_max, self.output_units])\r\n\r\n        high_capsule = F.relu(self.relu_layer(high_capsule))\r\n        return high_capsule, W, seq_len\r\n```\r\n由于前self.iter - 1次路由迭代会修改B，因此要截断从B传给self.routing_logits的梯度。我理解最后一次路由要恢复这个梯度的传导[参考这里代码的forward函数](https://github.com/Ugenteraan/CapsNet-PyTorch/blob/master/CapsNet-PyTorch.ipynb)，但为什么没有手动设置`B.stop_gradient = False`？这样self.routing_logits不会无法更新吗？\r\n",
        "state": "closed",
        "user": "Wang-Yu-Qing",
        "closed_by": "Wang-Yu-Qing",
        "created_at": "2023-03-27T15:35:31+00:00",
        "updated_at": "2023-03-29T03:49:33+00:00",
        "closed_at": "2023-03-29T03:49:33+00:00",
        "comments_count": [
            "Wang-Yu-Qing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 903,
        "title": "训练wide_deep模型时，设置num_workers，epoch内迭代次数反而变多了。",
        "body": "训练方式为readme中的动态图训练方式，数据集也是从Paddle官方下载的已处理数据slot_train_data_full，只用了part0来做测试。其他训练参数均为默认。\r\nnum_workers=0时，一个epoch内的迭代总次数为390:\r\nbatch_id :  388\r\nbatch shape :  512\r\nbatch_id :  389\r\nbatch shape :  512\r\nnum_workers=2时，一个epoch内的迭代总次数为780:\r\nbatch_id :  778\r\nbatch shape :  512\r\nbatch_id :  779\r\nbatch shape :  512\r\nnum_workers=5时，一个epoch内的迭代总次数为1950:\r\nbatch_id :  3898\r\nbatch shape :  512\r\nbatch_id :  3899\r\nbatch shape :  512\r\nnum_workers=10时，一个epoch内的迭代次数为3900:\r\nbatch_id :  3898\r\nbatch shape :  512\r\nbatch_id :  3899\r\nbatch shape :  512\r\n单次迭代(1个batch数据)时间会变短，但迭代次数变多，整体训练时间会变长。\r\n请帮忙看下这个问题，感谢！",
        "state": "open",
        "user": "paynezhangpayne",
        "closed_by": null,
        "created_at": "2023-04-01T09:52:56+00:00",
        "updated_at": "2024-11-22T02:28:16+00:00",
        "closed_at": null,
        "comments_count": [
            "ibarbecue",
            "ibarbecue"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 908,
        "title": "KIM样例数据说明",
        "body": "您好，想请问一下针对KIM模型的样例数据（train、test）能否有一个简单的说明呀？样例数据有点看不懂",
        "state": "closed",
        "user": "magical-cao",
        "closed_by": "magical-cao",
        "created_at": "2023-04-03T09:46:16+00:00",
        "updated_at": "2023-04-09T06:32:33+00:00",
        "closed_at": "2023-04-09T06:32:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 920,
        "title": "静态图模型能否修改共享参数形状",
        "body": "我想共享embedding层和最后输出fc层的参数，但是两个shape不同，embedding的shape是[65555,256],fc的weight是[256,65555],需要将embedding做下转置，没有找到对应的API。网上有推荐用动态图的，我想知道静态图有解决方法吗？\r\n```\r\nshared_param_attrs = fluid.ParamAttr(name=\"programset_embedding\",initializer=paddle.nn.initializer.Uniform())\r\n\r\nemb = paddle.static.nn.sparse_embedding(\r\n                    input=input[1],\r\n                    size=[\r\n                        self.sparse_feature_number[i]+1, self.sparse_feature_dim[i]\r\n                    ],\r\n                    param_attr=paddle.ParamAttr(\r\n                        name=\"SparseFeatFactors\",\r\n                        initializer=paddle.nn.initializer.Uniform()))\r\n...\r\nfinal_layer = paddle.static.nn.fc(\r\n                x=cust_embdding,\r\n                size=65555,\r\n                weight_attr=shared_param_attrs)\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"tools/static_trainer.py\", line 315, in <module>\r\n    main(args)\r\n  File \"tools/static_trainer.py\", line 69, in main\r\n    fetch_vars = static_model_class.net(input_data)\r\n  File \"[E:\\PaddleRec\\PaddleRec\\models\\recall\\ha_youtube_dnn\\static_model.py](file:///E:/PaddleRec/PaddleRec/models/recall/ha_youtube_dnn/static_model.py)\", line 110, in net\r\n    weight_attr=shared_param_attrs)\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\decorator.py](file:///D:/Anaconda/envs/py37/lib/site-packages/decorator.py)\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/wrapped_decorator.py)\", line 26, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\framework.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/framework.py)\", line 558, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\static\\nn\\common.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/static/nn/common.py)\", line 166, in fc\r\n    name=name,\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/layers/nn.py)\", line 398, in fc\r\n    attr=param_attr, shape=param_shape, dtype=dtype, is_bias=False\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\layer_helper_base.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/layer_helper_base.py)\", line 385, in create_parameter\r\n    **attr._to_kwargs(with_initializer=True))\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\framework.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/framework.py)\", line 3953, in create_parameter\r\n    param = Parameter(global_block, *args, **kwargs)\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\framework.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/framework.py)\", line 6926, in __init__\r\n    **kwargs\r\n  File \"[d:\\Anaconda\\envs\\py37\\lib\\site-packages\\paddle\\fluid\\framework.py](file:///D:/Anaconda/envs/py37/lib/site-packages/paddle/fluid/framework.py)\", line 1461, in __init__\r\n    \"matched.\".format(self.name, old_shape, shape)\r\nValueError: Variable 'programset_embedding' has been created before. The previous shape is (65345, 256), the new shape is (256, 65345). They are not matched.",
        "state": "closed",
        "user": "arbitraryking",
        "closed_by": "arbitraryking",
        "created_at": "2023-05-09T02:33:39+00:00",
        "updated_at": "2023-05-11T03:30:29+00:00",
        "closed_at": "2023-05-11T03:30:29+00:00",
        "comments_count": [
            "wangzhen38",
            "arbitraryking",
            "arbitraryking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 914,
        "title": "maml 图像类别预测",
        "body": "我想用官方训练好的模型进行单张图像的预测，应该如何实现呢 @ZeyuChen @jacquesqiao @kuizhiqing @thinkall ",
        "state": "open",
        "user": "qiu-pinggaizi",
        "closed_by": null,
        "created_at": "2023-04-10T11:33:20+00:00",
        "updated_at": "2023-04-11T08:42:18+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 917,
        "title": "运行movie_recommand下的data_prepare.sh出现问题",
        "body": "运行bash data_prepare.sh出现如下错误\r\n```\r\n(Paddle)C:\\Users\\71400\\Desktop\\OmnicCrisis\\PaddleRec\\models\\demo\\movie_recommand>bash data_prepare.sh\r\nProcessing fstab with mount -a failed.\r\n\r\n<3>WSL (8) ERROR: CreateProcessEntryCommon:370: getpwuid(0) failed 2\r\n<3>WSL (8) ERROR: CreateProcessEntryCommon:374: getpwuid(0) failed 2\r\n<3>WSL (8) ERROR: CreateProcessEntryCommon:577: execvpe /bin/bash failed 2\r\n<3>WSL (8) ERROR: CreateProcessEntryCommon:586: Create process not expected to return\r\n```\r\nPython版本3.7.12\r\ngit version 2.40.0.windows.1",
        "state": "open",
        "user": "Paradox-Sin",
        "closed_by": null,
        "created_at": "2023-04-23T15:27:38+00:00",
        "updated_at": "2023-04-25T08:55:56+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 921,
        "title": "数据全部都是经过预处理的，无法进行实际业务测试",
        "body": "小白无从下手进行学习",
        "state": "open",
        "user": "AnitaSherry",
        "closed_by": null,
        "created_at": "2023-05-09T02:59:16+00:00",
        "updated_at": "2023-05-10T03:22:32+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 923,
        "title": "流式训练demo报错",
        "body": "按照doc/online_trainer.md执行命令\r\n```\r\n(py37) E:\\PaddleRec\\PaddleRec\\models\\rank\\slot_dnn>fleetrun --server_num=1 --worker_num=1 ../../../tools/static_ps_online_trainer.py -m config_online.yaml\r\n\r\nFatal error in launcher: Unable to create process using '\"C:\\ProgramData\\Anaconda3\\conda-bld\\paddlepaddle-gpu_1676544693779\\_h_env\\python.exe\"  \"D:\\Anacony37\\Scripts\\fleetrun.exe\" --server_num=1 --worker_num=1 ../../../tools/static_ps_online_trainer.py -m config_online.yaml': ???????????\r\n```\r\n我看了下C:\\ProgramData\\目录下没有Anaconda3，这个python路径没有看到哪里能配置呢",
        "state": "open",
        "user": "arbitraryking",
        "closed_by": null,
        "created_at": "2023-05-15T07:35:50+00:00",
        "updated_at": "2023-05-15T08:42:15+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38",
            "arbitraryking",
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 926,
        "title": "module 'paddle' has no attribute 'is_compiled_with_custom_device'",
        "body": "```\r\nλ 5fd09798794c /code/PaddleRec python -u ./tools/trainer.py -m ./models/rank/dlrm/config.yaml # 全量数据运行config_bigdata.yaml\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n2023-05-17 03:30:32,956 - INFO - **************common.configs**********\r\n2023-05-17 03:30:32,956 - INFO - use_gpu: True, use_xpu: False, use_npu: False, use_visual: False, train_batch_size: 2, train_data_dir: data/sample_data/train, epochs: 3, print_interval: 2, model_save_path: output_model_dlrm\r\n2023-05-17 03:30:32,956 - INFO - **************common.configs**********\r\nW0517 03:30:32.957670  1244 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.2\r\nW0517 03:30:32.962177  1244 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\nTraceback (most recent call last):\r\n  File \"./tools/trainer.py\", line 227, in <module>\r\n    main(args)\r\n  File \"./tools/trainer.py\", line 98, in main\r\n    dy_model = dy_model_class.create_model(config)\r\n  File \"/code/PaddleRec/models/rank/dlrm/dygraph_model.py\", line 41, in create_model\r\n    self_interaction=False)\r\n  File \"/code/PaddleRec/models/rank/dlrm/net.py\", line 65, in __init__\r\n    if paddle.is_compiled_with_custom_device('npu'):\r\nAttributeError: module 'paddle' has no attribute 'is_compiled_with_custom_device'\r\n```\r\nPaddle版本：(Docker: registry.baidubce.com/paddlepaddle/paddle:2.3.2-gpu-cuda11.2-cudnn8)\r\n```\r\nPaddlePaddle 2.3.2.post112, compiled with\r\n    with_avx: ON\r\n    with_gpu: ON\r\n    with_mkl: ON\r\n    with_mkldnn: ON\r\n    with_python: ON\r\n```",
        "state": "closed",
        "user": "Dominic-ZZ",
        "closed_by": "Dominic-ZZ",
        "created_at": "2023-05-17T03:32:31+00:00",
        "updated_at": "2023-08-04T06:10:01+00:00",
        "closed_at": "2023-08-04T06:10:01+00:00",
        "comments_count": [
            "wangzhen38",
            "wml1993",
            "wangzhen38",
            "huzuoliang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 930,
        "title": "如何保存某一层的输出",
        "body": "我自己写的模型想要在训练时将网络某一层的输出保存到本地作为用户的表征，config.yaml有配置吗?是静态图模型，用static_trainer.py训练。",
        "state": "closed",
        "user": "arbitraryking",
        "closed_by": "arbitraryking",
        "created_at": "2023-06-01T00:57:34+00:00",
        "updated_at": "2023-06-05T07:58:28+00:00",
        "closed_at": "2023-06-05T07:58:28+00:00",
        "comments_count": [
            "wangzhen38",
            "arbitraryking",
            "wangzhen38",
            "arbitraryking",
            "wangzhen38",
            "arbitraryking",
            "arbitraryking",
            "arbitraryking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 931,
        "title": "DeepRec模型训练报错",
        "body": "运行训练指令`python -u trainer.py -m config_bigdata.yaml`即报错，报错信息如下：\r\n![image](https://github.com/PaddlePaddle/PaddleRec/assets/50285351/4b31684b-f08a-40a1-8dd8-db89d6ad39a7)\r\npaddle版本：0.0.0.post102(daily build的develop版本)",
        "state": "open",
        "user": "USTCKAY",
        "closed_by": null,
        "created_at": "2023-06-07T03:09:28+00:00",
        "updated_at": "2023-07-07T03:00:53+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 933,
        "title": "In the MOE method does expert have to learn and can the frozen model be used as an expert?like gpt3 bert",
        "body": "\r\n\r\n**Describe the question(问题描述)**\r\nModeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts\r\n\r\nIn the MOE method does expert have to learn and can the frozen model be used as an expert?like gpt3 bert\r\n\r\nthank you very much！！\r\n",
        "state": "open",
        "user": "Harzva",
        "closed_by": null,
        "created_at": "2023-06-14T01:57:39+00:00",
        "updated_at": "2023-06-14T02:25:19+00:00",
        "closed_at": null,
        "comments_count": [
            "wangzhen38"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 936,
        "title": "paddle.concat函数有问题",
        "body": "`Traceback (most recent call last):\r\n  File \"/home/heyiheng/competition/vipshop/src/vip_train.py\", line 43, in <module>\r\n    pred = model.forward(sparse_tensor, dense_tensor)\r\n  File \"/home/heyiheng/competition/vipshop/src/net.py\", line 43, in forward\r\n    y_first_order, y_second_order, feat_embeddings = self.fm.forward(\r\n  File \"/home/heyiheng/competition/vipshop/src/net.py\", line 107, in forward\r\n    sparse_inputs_concat = paddle.concat(sparse_inputs, axis=1)\r\n  File \"/home/young/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/tensor/manipulation.py\", line 1140, in concat\r\n    return _C_ops.concat(input, axis)\r\nValueError: (InvalidArgument) The axis is expected to be in range of [-1, 1), but got 1\r\n  [Hint: Expected axis >= -rank && axis < rank == true, but received axis >= -rank && axis < rank:0 != true:1.] (at /paddle/paddle/phi/infermeta/multiary.cc:897)\r\n`\r\nmodels/rank/deepfm/net.py\r\n107行 sparse_inputs_concat = paddle.concat(sparse_inputs, axis=1)",
        "state": "closed",
        "user": "AnitaSherry",
        "closed_by": "AnitaSherry",
        "created_at": "2023-07-07T03:04:36+00:00",
        "updated_at": "2023-07-07T06:10:41+00:00",
        "closed_at": "2023-07-07T06:10:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 938,
        "title": "wide_deep如何跑单机多卡？",
        "body": "wide_deep如何跑单机多卡？用一台单机八卡， 怎么训练wide_deep呢",
        "state": "open",
        "user": "Sooguo",
        "closed_by": null,
        "created_at": "2023-07-20T08:45:37+00:00",
        "updated_at": "2023-07-20T08:45:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 940,
        "title": "Dependencies in `requirements.txt` have module conflicts.",
        "body": "## Background\r\nDependencies in `requirements.txt` have module conflicts.\r\n \r\n## Description\r\nThere are two dependencies mentioned in the `requirements.txt` file: `faiss-cpu` and `faiss-gpu`. Based on my knowledge, these two packages have module conflicts. \r\nThis is mainly because when packages are installed using pip, they are by default installed in the `site-packages` directory without any isolation between different packages. This means that when both `faiss-cpu` and `faiss-gpu` are installed, both of them having the same module name ‘faiss’, they would both be installed in the `faiss` folder. Therefore, modules present in both packages would conflict and get overridden (with the later installed module overriding the earlier one, depending on the installation order and dependency declaration order). This behavior is the default for pip and there are no warnings.\r\n\r\nIf the contents of the overridden files are the same, there won’t be any problems. But if the contents of these files differ, conflicts may arise. There could potentially be functional errors present. For instance, certain functions require the invocation of the `faiss-cpu`'s module, but `faiss-gpu` overrides the `faiss-cpu`'s module. As a result, the Python interpreter mistakenly identifies the `faiss-gpu`'s module as the `faiss-cpu`'s module, leading to some functional errors.\r\n\r\n## Steps to Reproduce\r\n`pip install -r requirements.txt`\r\n\r\n## Desired Change\r\nIndeed, it is not an ideal behavior for modules to be overwritten, even if they are not actively used or if the overwritten module is the one being called. It introduces uncertainty and can cause issues in the long run, especially if there are changes or updates to the overwritten modules in future development. It is generally recommended to avoid such conflicts and ensure that only the necessary and compatible dependencies are declared in the requirements to maintain a stable and predictable environment for the project. \r\n\r\nWe believe that although this project can only modify direct dependencies and indirect dependencies are a black box, it is possible to add additional explanations rather than directly declaring both conflicting packages in the requirements.txt file.\r\n\r\nAdding extra explanations or documentation about the potential conflicts and the need to choose only one of the conflicting packages can help developers understand the issue and make informed decisions. Including a clear instruction or warning in the project’s documentation can guide users to choose the appropriate package based on their specific requirements.\r\n",
        "state": "open",
        "user": "unsatisfying",
        "closed_by": null,
        "created_at": "2023-07-27T15:08:54+00:00",
        "updated_at": "2023-07-27T15:08:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 934,
        "title": "esmm推理只有0.52的auc",
        "body": "train\r\n![image](https://github.com/PaddlePaddle/PaddleRec/assets/28783826/9dcb8e7e-f49f-41cf-add3-fb2e038b99c7)\r\n\r\ninfer\r\n![image](https://github.com/PaddlePaddle/PaddleRec/assets/28783826/389e154b-4375-4960-b762-f5d14bcddaf8)\r\n",
        "state": "open",
        "user": "JJplane",
        "closed_by": null,
        "created_at": "2023-06-14T12:47:23+00:00",
        "updated_at": "2025-02-27T11:52:34+00:00",
        "closed_at": null,
        "comments_count": [
            "JJplane",
            "wangzhen38",
            "JJplane",
            "SSBCL-zjgsu",
            "JJplane",
            "magicleo",
            "YanranDeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 941,
        "title": "关于escm2算法的疑问",
        "body": "    def counterfact_ipw(self, loss_cvr, ctr_num, O, ctr_out_one):\r\n        PS = paddle.multiply(\r\n            ctr_out_one, paddle.cast(\r\n                ctr_num, dtype=\"float32\"))\r\n        min_v = paddle.full_like(PS, 0.000001)\r\n        PS = paddle.maximum(PS, min_v)\r\n        IPS = paddle.reciprocal(PS)\r\n        batch_shape = paddle.full_like(O, 1)\r\n        batch_size = paddle.sum(paddle.cast(\r\n            batch_shape, dtype=\"float32\"),\r\n                                axis=0)\r\n        #TODO this shoud be a hyparameter\r\n        IPS = paddle.clip(IPS, min=-15, max=15)  #online trick \r\n        IPS = paddle.multiply(IPS, batch_size)\r\n        IPS.stop_gradient = True\r\n        loss_cvr = paddle.multiply(loss_cvr, IPS)\r\n        loss_cvr = paddle.multiply(loss_cvr, O)\r\n        return paddle.mean(loss_cvr)\r\n\r\nIPW方法为什么要乘batch_size，论文中也没发现需要做这个操作？IPS = paddle.multiply(IPS, batch_size)",
        "state": "open",
        "user": "huzuoliang",
        "closed_by": null,
        "created_at": "2023-07-28T03:57:47+00:00",
        "updated_at": "2023-07-28T03:57:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 944,
        "title": "din 模型的网络实现有点小bug",
        "body": "din模型的网络定义，attention_layer以及con_layer两处定义，add_sublayer使用的layer name重复了。对于custom device，在eager mode模型下进行训练，会导致梯度计算出现异常。建议把这两处的layer name 调整一下",
        "state": "open",
        "user": "cqli0905",
        "closed_by": null,
        "created_at": "2023-08-15T12:59:40+00:00",
        "updated_at": "2023-08-15T12:59:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 954,
        "title": "关于MHCN代码的Loss function问题请教。",
        "body": "请问在计算自监督loss的时候，局部互信息的部分为何是local_loss = paddle.sum(-paddle.log(F.sigmoid(pos - neg1)) -paddle.log(F.sigmoid(**neg1** - neg2)))？为什么不是pos-neg2而是neg1-neg2？",
        "state": "open",
        "user": "shaitaiyangmie",
        "closed_by": null,
        "created_at": "2023-10-15T06:40:40+00:00",
        "updated_at": "2023-10-15T06:40:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 951,
        "title": "ValueError: The ``path`` (output_model_xdeepfm/0/rec.pdparams) to load model not exists.",
        "body": "2023-09-14 09:56:15,651 - INFO - start load model from output_model_xdeepfm/0\r\nTraceback (most recent call last):\r\n  File \"../../../tools/infer.py\", line 201, in <module>\r\n    main(args)\r\n  File \"../../../tools/infer.py\", line 120, in main\r\n    load_model(model_path, dy_model)\r\n  File \"/xjh_workspace/poc/yz_test/PaddleRec/tools/utils/save_load.py\", line 45, in load_model\r\n    param_state_dict = paddle.load(model_prefix + \".pdparams\")\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/framework/io.py\", line 358, in load\r\n    model_path, config = _build_load_path_and_config(path, config)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/framework/io.py\", line 158, in _build_load_path_and_config\r\n    raise ValueError(error_msg % path)\r\nValueError: The ``path`` (output_model_xdeepfm/0/rec.pdparams) to load model not exists.",
        "state": "open",
        "user": "roy699",
        "closed_by": null,
        "created_at": "2023-09-15T06:15:15+00:00",
        "updated_at": "2023-09-15T06:15:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 959,
        "title": "运行paddlerec报错OSError: (External) adam XDNN Error, XDNN_RUNTIME_ERROR  (at /data/paddle/Paddle/paddle/phi/kernels/selected_rows/xpu/adam_kernel.cc:318)",
        "body": "请问这个报错如何解决？\r\n\r\n\r\n\r\n2023-12-05 12:26:57,350 - INFO - epoch: 0, batch_id: 3308486, auc:0.755325, loss:0.2112919, avg_reader_cost: 0.00033 sec, avg_batch_cost: 0.01113 sec, avg_samples: 10.00000, ips: 894.39914 ins/s\r\n2023-12-05 12:26:57,389 - INFO - epoch: 0, batch_id: 3308488, auc:0.755325, loss:0.19263451, avg_reader_cost: 0.00188 sec, avg_batch_cost: 0.01226 sec, avg_samples: 10.00000, ips: 812.13010 ins/s\r\n2023-12-05 12:26:57,428 - INFO - epoch: 0, batch_id: 3308490, auc:0.755325, loss:0.6327275, avg_reader_cost: 0.00264 sec, avg_batch_cost: 0.01300 sec, avg_samples: 10.00000, ips: 766.06592 ins/s\r\n2023-12-05 12:26:57,477 - INFO - epoch: 0, batch_id: 3308492, auc:0.755325, loss:0.28639948, avg_reader_cost: 0.00215 sec, avg_batch_cost: 0.01766 sec, avg_samples: 10.00000, ips: 564.51145 ins/s\r\n[WARN][XPURT][xpu_llwait:675] ioctl() fail, (714) Exception in kernel execution\r\n[WARN][XPURT][xpu_lllaunch_async:543] ioctl() fail, (712) Operation not supported\r\n[WARN][XPURT][xpu_launch_async:327] fail on kernel ty=CLUSTER name='_ZN4xpu25scaleIfEEvPKT_PS1_xffi' ncl=8 nco=64\r\n[WARN][XPURT][xpu_llwait:675] ioctl() fail, (714) Exception in kernel execution\r\nTraceback (most recent call last):\r\n  File \"../../../tools/trainer.py\", line 227, in <module>\r\n    main(args)\r\n  File \"../../../tools/trainer.py\", line 151, in main\r\n    optimizer.step()\r\n  File \"/opt/conda/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 341, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 602, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    param_group_idx=0,\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 1214, in _apply_optimize\r\n    params_grads, param_group_idx=param_group_idx\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 996, in _create_optimization_pass\r\n    target_block, param_and_grad\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/adam.py\", line 337, in _append_optimize_op\r\n    False,\r\nOSError: (External) adam XDNN Error, XDNN_RUNTIME_ERROR  (at /data/paddle/Paddle/paddle/phi/kernels/selected_rows/xpu/adam_kernel.cc:318)",
        "state": "closed",
        "user": "hellokhj",
        "closed_by": "danleifeng",
        "created_at": "2023-12-05T11:28:23+00:00",
        "updated_at": "2024-02-21T12:06:48+00:00",
        "closed_at": "2024-02-21T12:06:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 956,
        "title": "同样是Session Based Recommendation算法，为什么GRU4Rec是用于召回，而BERT4Rec用于排序？",
        "body": "谢谢！",
        "state": "open",
        "user": "ralgond",
        "closed_by": null,
        "created_at": "2023-11-04T00:33:18+00:00",
        "updated_at": "2023-12-21T07:18:09+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 958,
        "title": "关于escm2中的操作",
        "body": "https://github.com/PaddlePaddle/PaddleRec/blob/22d28cf16830a4d871bd9c7a0be8eaec8349241a/models/multitask/escm2/dygraph_model.py#L124C1-L125C1\r\n我想问下这里乘以0是不是导致loss_cvr=0?\r\n",
        "state": "open",
        "user": "youyouhuo",
        "closed_by": null,
        "created_at": "2023-11-22T07:09:28+00:00",
        "updated_at": "2023-12-21T07:00:31+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 957,
        "title": "Ple模型获取数据时出错",
        "body": "![image](https://github.com/PaddlePaddle/PaddleRec/assets/48747626/71874f5e-cdc5-44a9-99f3-ba7755405ca9)\r\n这里出现了bug导致数据不能下载下来，也可能是网络进行了更换\r\n望能够告知应该如何处理\r\n\r\n在这个文件夹内datasets/census",
        "state": "open",
        "user": "challenger9911",
        "closed_by": null,
        "created_at": "2023-11-15T09:02:26+00:00",
        "updated_at": "2023-12-21T07:06:51+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 968,
        "title": "排序模型",
        "body": "请问老师，您这边有推荐的基于权威性和时效性的文本排序模型吗？",
        "state": "open",
        "user": "huangjianzuishuai",
        "closed_by": null,
        "created_at": "2023-12-26T08:08:52+00:00",
        "updated_at": "2023-12-26T08:08:52+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 960,
        "title": "运行paddlerec报错OSError: (External) adam XDNN Error, XDNN_RUNTIME_ERROR  (at /data/paddle/Paddle/paddle/phi/kernels/selected_rows/xpu/adam_kernel.cc:318)",
        "body": "请问这个报错如何解决？\r\n\r\n\r\n\r\n2023-12-05 12:26:57,350 - INFO - epoch: 0, batch_id: 3308486, auc:0.755325, loss:0.2112919, avg_reader_cost: 0.00033 sec, avg_batch_cost: 0.01113 sec, avg_samples: 10.00000, ips: 894.39914 ins/s\r\n2023-12-05 12:26:57,389 - INFO - epoch: 0, batch_id: 3308488, auc:0.755325, loss:0.19263451, avg_reader_cost: 0.00188 sec, avg_batch_cost: 0.01226 sec, avg_samples: 10.00000, ips: 812.13010 ins/s\r\n2023-12-05 12:26:57,428 - INFO - epoch: 0, batch_id: 3308490, auc:0.755325, loss:0.6327275, avg_reader_cost: 0.00264 sec, avg_batch_cost: 0.01300 sec, avg_samples: 10.00000, ips: 766.06592 ins/s\r\n2023-12-05 12:26:57,477 - INFO - epoch: 0, batch_id: 3308492, auc:0.755325, loss:0.28639948, avg_reader_cost: 0.00215 sec, avg_batch_cost: 0.01766 sec, avg_samples: 10.00000, ips: 564.51145 ins/s\r\n[WARN][XPURT][xpu_llwait:675] ioctl() fail, (714) Exception in kernel execution\r\n[WARN][XPURT][xpu_lllaunch_async:543] ioctl() fail, (712) Operation not supported\r\n[WARN][XPURT][xpu_launch_async:327] fail on kernel ty=CLUSTER name='_ZN4xpu25scaleIfEEvPKT_PS1_xffi' ncl=8 nco=64\r\n[WARN][XPURT][xpu_llwait:675] ioctl() fail, (714) Exception in kernel execution\r\nTraceback (most recent call last):\r\n  File \"../../../tools/trainer.py\", line 227, in <module>\r\n    main(args)\r\n  File \"../../../tools/trainer.py\", line 151, in main\r\n    optimizer.step()\r\n  File \"/opt/conda/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 341, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 602, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    param_group_idx=0,\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 1214, in _apply_optimize\r\n    params_grads, param_group_idx=param_group_idx\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 996, in _create_optimization_pass\r\n    target_block, param_and_grad\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/optimizer/adam.py\", line 337, in _append_optimize_op\r\n    False,\r\nOSError: (External) adam XDNN Error, XDNN_RUNTIME_ERROR  (at /data/paddle/Paddle/paddle/phi/kernels/selected_rows/xpu/adam_kernel.cc:318)",
        "state": "closed",
        "user": "hellokhj",
        "closed_by": "danleifeng",
        "created_at": "2023-12-05T11:28:32+00:00",
        "updated_at": "2024-02-21T12:06:56+00:00",
        "closed_at": "2024-02-21T12:06:56+00:00",
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 962,
        "title": "Implement Fastformer in the rank models for the experiments on MIND dataset",
        "body": "I referred to this [repository](https://github.com/wuch15/Fastformer) by the author of Fastformer, which was proposed in 2021, and reimplemented it in the PaddlePaddle framework. The exact layers were not officially implemented by the author, only the core of Fastformer attention was revealed. I inherited the architecture of NAML and replaced the attention layers with Fastformer. The final AUC score can almost reach the state-of-the-art (SOTA) performance, even without powerful language models like UniLM, MOKA, or word embeddings from GPT. The AUC score on the test dataset after training for 9 epochs is 0.729. Although there are still some tasks to complete, I aim to contribute the core Fastformer attention models to PaddleRec first. Here is a screenshot of the results:\r\n\r\n![Screenshot 2023-12-18 at 10 59 08 PM](https://github.com/PaddlePaddle/PaddleRec/assets/45786393/7735e2e7-4b6b-4ca4-b706-a841d44806e3)\r\n\r\n## To-do\r\n- Add metrics such as MRR, nDCG@5, nDCG@10 for evaluation.\r\n- Integrate strong word embedding features from pretrained language models like UniLM, MOKA,...\r\n- Make sure it works in the static modeling mode",
        "state": "closed",
        "user": "vic4code",
        "closed_by": "danleifeng",
        "created_at": "2023-12-18T15:08:19+00:00",
        "updated_at": "2024-02-21T12:05:46+00:00",
        "closed_at": "2024-02-21T12:05:46+00:00",
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 964,
        "title": "config.yaml文件中save_inference_fetch_varnames参数的问题",
        "body": "请问，我在使用wide_deep静态图训练保存模型中参数save_inference_fetch_varnames具体该如何确定\r\n\r\n我看了inference文档中写了“fetch参数输出的是auc，具体意义为static_model.py里def net（）函数中将auc使用cast转换为float32类型语句中的cast算子。”，具体到现实场景，请问，我该如何确定/找到这个参数是sigmoid_0.tmp_0？类似的，其他模型中的scale_0.tmp_0等。\r\n\r\n  use_inference: True\r\n  save_inference_feed_varnames: [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"dense_input\"]\r\n  save_inference_fetch_varnames: [\"sigmoid_0.tmp_0\"]\r\n\r\n**谢谢**",
        "state": "open",
        "user": "disheng34",
        "closed_by": null,
        "created_at": "2023-12-20T04:20:33+00:00",
        "updated_at": "2023-12-26T07:12:21+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng",
            "disheng34",
            "disheng34"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 966,
        "title": "Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . ",
        "body": "运行DCN-V2训练模型时报错:\r\n![微信图片_20231221135844](https://github.com/PaddlePaddle/PaddleRec/assets/114725104/3737ac37-f29b-461f-b66b-b7f86a7c5684)\r\n",
        "state": "open",
        "user": "Atopos111",
        "closed_by": null,
        "created_at": "2023-12-21T05:58:54+00:00",
        "updated_at": "2023-12-21T06:29:09+00:00",
        "closed_at": null,
        "comments_count": [
            "danleifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 975,
        "title": "运行paddle_infer.py报错",
        "body": "环境：\r\npython 3.9\r\npaddlepaddle-gpu\r\nubuntu 18.04\r\ncuda11.7\r\ntensorrt                                          8.5.3.1-1+cuda11.8                              amd64        Meta package for TensorRT\r\n\r\n1.修改models/rank/deepfm/config.yaml\r\n  use_inference: True\r\n\r\n2.执行\r\npython -u ../../../tools/static_trainer.py -m config.yaml\r\n3. 执行\r\npython -u ../../../tools/paddle_infer.py --model_file=output_model_deepfm/2/rec_inference.pdmodel --params_file=output_model_deepfm/2/rec_inference.pdiparams --use_gpu=True --data_dir=data/sample_data/train --reader_file=criteo_reader.py --batchsize=5 --enable_tensorRT=True\r\n\r\n报错\r\n\r\n`\r\nE0118 19:50:24.366691 13690 helper.h:131] 4: [graphShapeAnalyzer.cpp::analyzeShapes::1872] Error Code 4: Miscellaneous (IShuffleLayer (Unnamed Layer* 10) [Shuffle]: reshape changes volume to multiple of original volume. Reshaping [13,9] to [1,1].)\r\nTraceback (most recent call last):\r\n  File \"/data/ymtguest/liuxinglong/ymt/PaddleRec/models/rank/deepfm/../../../tools/paddle_infer.py\", line 188, in <module>\r\n    main(args)\r\n  File \"/data/ymtguest/liuxinglong/ymt/PaddleRec/models/rank/deepfm/../../../tools/paddle_infer.py\", line 126, in main\r\n    predictor, pred_config = init_predictor(args)\r\n  File \"/data/ymtguest/liuxinglong/ymt/PaddleRec/models/rank/deepfm/../../../tools/paddle_infer.py\", line 104, in init_predictor\r\n    predictor = create_predictor(config)\r\nValueError: (InvalidArgument) Errors occures in Paddle-TRT reshape2 op, try to use C++ Api config.Exp_DisableTensorRtOPs({\"reshape2\"})\r\n; or Python Api config.exp_disable_tensorrt_ops([\"reshape2\"]) to forbid reshape2 op into Paddle-TRT.\r\n  [Hint: Expected layer->getOutput(0)->getDimensions().nbDims >= 0, but received layer->getOutput(0)->getDimensions().nbDims:-1 < 0:0.] (at ../paddle/fluid/inference/tensorrt/convert/reshape_op.cc:74)\r\n`",
        "state": "closed",
        "user": "magicleo",
        "closed_by": "magicleo",
        "created_at": "2024-01-18T11:50:45+00:00",
        "updated_at": "2024-01-19T02:02:42+00:00",
        "closed_at": "2024-01-19T02:02:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 981,
        "title": "mmoe模型配置缺少auc_num导致AUC计算错误",
        "body": "RT\r\n默认的auc_num是1，mmoe等多任务模型没有改成2，\r\n在static_infer.py中，reset_auc 传参了1，\r\n        if use_auc:\r\n            reset_auc(use_fleet, auc_num)\r\n\r\n导致计算出来的第二个任务的AUC是错的！",
        "state": "open",
        "user": "magicleo",
        "closed_by": null,
        "created_at": "2024-02-28T07:05:29+00:00",
        "updated_at": "2024-02-28T07:13:36+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 979,
        "title": "PaddleRec的deepfm模型不明原因出core #61629",
        "body": "请提出你的问题 Please ask your question\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n2024-02-05 10:25:05,138 - INFO - ****common.configs\r\n2024-02-05 10:25:05,138 - INFO - use_gpu: False, use_xpu: False, use_npu: False, use_visual: False, train_batch_size: 2, train_data_dir: data/, epochs: 3, print_interval: 2, model_save_path: output_model_deepfm\r\n2024-02-05 10:25:05,138 - INFO - ****common.configs\r\n2024-02-05 10:25:05,157 - INFO - read data\r\n2024-02-05 10:25:05,157 - INFO - reader path:criteo_reader\r\n2024-02-05 10:25:05,276 - INFO - epoch: 0, batch_id: 0, auc:0.000000, loss:0.8438953, avg_reader_cost: 0.00402 sec, avg_batch_cost: 0.05622 sec, avg_samples: 1.00000, ips: 17.77118 ins/s\r\nC++ Traceback (most recent call last):\r\n0 embedding_ad_func(paddle::Tensor const&, paddle::Tensor const&, long, bool)\r\n1 paddle::experimental::embedding(paddle::Tensor const&, paddle::Tensor const&, long, bool)\r\n2 void phi::EmbeddingKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, long, phi::DenseTensor*)\r\n3 GOMP_parallel\r\n\r\nError Message Summary:\r\nFatalError: Process abort signal is detected by the operating system.\r\n[TimeInfo: *** Aborted at 1707128705 (unix time) try \"date -d @1707128705\" if you are using GNU date ***]\r\n[SignalInfo: *** SIGABRT (@0x8df) received by PID 2271 (TID 0x7f89f4145080) from PID 2271 ***]\r\n\r\n做了一些data的改动和代码微调后，刚训练一个batch就出core,帮忙看一下\r\n\r\n改动如下：\r\n1）reader的修改：\r\nsparse_slots = \"label all_rank city_line last_click_sem_time_days_ago first_reg_date_days_ago potential_corporate_user delete_pv_last_active_day_days_ago career is_aiqicha_user is_old_enterprise last_active_client all_revrank active_pcmac_cuidnum_in7days upload_doc_last_date_days_ago download_doc_last_date_days_ago rank is_history_pay categoryconsume income_level age married consumption_amount_last_year consumer_doc_last_date_days_ago edu tc ustage sexual product_name company_cert_page_last_day_days_ago enterprise_pc_pop_up_show_lastday_days_ago svip_overdue_date_days_ago doc_backup_last_date_days_ago province constellation vip_overdue_date_days_ago carlevel is_xinyun_user company_offical_web_last_day_days_ago consume asset enterprise_pc_pop_up_clk_lastday_days_ago vip_type accountnum cuid_num used_quota\"\r\nself.sparse_slots = sparse_slots.strip().split(\" \")\r\nself.dense_slots = [\"feat_value\"]\r\nself.dense_slots_shape = [1]\r\n\r\n2）data文件修改为：\r\nall_rank:81 city_line:169 last_click_sem_time_days_ago:266 first_reg_date_days_ago:157 potential_corporate_user:234 delete_pv_last_active_day_days_ago:225 career:233 is_aiqicha_user:36 is_old_enterprise:212 last_active_client:60 all_revrank:149 active_pcmac_cuidnum_in7days:27 upload_doc_last_date_days_ago:141 download_doc_last_date_days_ago:106 rank:267 is_history_pay:221 categoryconsume:131 income_level:195 age:184 married:250 consumption_amount_last_year:66 consumer_doc_last_date_days_ago:50 edu:150 tc:55 ustage:214 sexual:84 product_name:112 company_cert_page_last_day_days_ago:39 enterprise_pc_pop_up_show_lastday_days_ago:253 svip_overdue_date_days_ago:259 doc_backup_last_date_days_ago:105 province:48 constellation:21 vip_overdue_date_days_ago:12 carlevel:87 is_xinyun_user:193 company_offical_web_last_day_days_ago:73 consume:192 asset:38 enterprise_pc_pop_up_clk_lastday_days_ago:92 vip_type:227 accountnum:197 cuid_num:239 used_quota:76 feat_value:0.215693 label:0 uid:XXX\r\n配置中的相应变量也做了修改",
        "state": "open",
        "user": "xiuechen",
        "closed_by": null,
        "created_at": "2024-02-05T11:37:50+00:00",
        "updated_at": "2024-02-05T11:37:50+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 970,
        "title": "ModuleNotFoundError: No module named 'paddle.fluid'",
        "body": "In [2]: import paddle.fluid\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nCell In[2], line 1\r\n----> 1 import paddle.fluid\r\n\r\nModuleNotFoundError: No module named 'paddle.fluid'\r\n\r\n↑↑↑↑↑↑↑↑↑↑\r\n\r\n最新版paddle好像把fluid不知道移动到哪里去了，导致\r\nhttps://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/README.cn.md#%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E\r\n都跑不通",
        "state": "open",
        "user": "tigflanker",
        "closed_by": "tigflanker",
        "created_at": "2024-01-03T05:44:30+00:00",
        "updated_at": "2024-01-17T07:27:03+00:00",
        "closed_at": null,
        "comments_count": [
            "tigflanker",
            "tigflanker",
            "tigflanker",
            "danleifeng",
            "magicleo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 982,
        "title": "Word2Vec 负样本 id 没有做到单词的映射",
        "body": "\r\n[word2vec_reader.py 第 116 行左右](https://github.com/PaddlePaddle/PaddleRec/blob/master/models/recall/word2vec/word2vec_reader.py#L116)\r\n\r\n```\r\n  for i in range(self.neg_num):\r\n      tmp.append(random.random())\r\n  neg_array = self.cs.searchsorted(tmp)\r\n\r\n  output.append(\r\n      np.array([int(i)\r\n                for i in neg_array]).astype('int64'))\r\n\r\n  yield output\r\n```\r\n负采样得到的 id 用的是采样 list (self.cs) 的 index 值，并且直接作为了输出，没有映射到单词的 word_id，这可能导致模型的负采样逻辑完全出错。\r\n\r\n另外，在取 context 词的时候为什么要[对 window_size 的大小做随机](https://github.com/PaddlePaddle/PaddleRec/blob/master/models/recall/word2vec/word2vec_reader.py#L61)呢，是为了 demo 能快速运行吗？\r\n",
        "state": "open",
        "user": "KiraYeetar",
        "closed_by": null,
        "created_at": "2024-02-29T11:53:24+00:00",
        "updated_at": "2024-02-29T11:53:24+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 989,
        "title": "Requirement.parse Error",
        "body": "Apple M2 error\r\n\r\nSearching for faiss-gpu\r\nReading https://pypi.org/simple/faiss-gpu/\r\nNo local packages or working download links found for faiss-gpu\r\nerror: Could not find suitable distribution for Requirement.parse('faiss-gpu')",
        "state": "open",
        "user": "Adenc",
        "closed_by": null,
        "created_at": "2024-03-28T10:42:50+00:00",
        "updated_at": "2024-03-28T10:42:50+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 990,
        "title": "MMOE\\PLE模型sparse特征为什么没有转化为embedding啊？",
        "body": "RT\r\n请问是有什么特殊的考虑吗？",
        "state": "open",
        "user": "magicleo",
        "closed_by": null,
        "created_at": "2024-04-24T06:11:40+00:00",
        "updated_at": "2024-04-24T06:11:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 991,
        "title": "ESCM2模型的IPW代码",
        "body": "你好，我最近阅读了PaddlePaddle对ESCM2模型的代码实现，我对其中的 IPW 代码部分有点疑问：\r\n\r\n```\r\n    def counterfact_ipw(self, loss_cvr, ctr_num, O, ctr_out_one):\r\n        PS = paddle.multiply(\r\n            ctr_out_one, paddle.cast(\r\n                ctr_num, dtype=\"float32\"))\r\n        min_v = paddle.full_like(PS, 0.000001)\r\n        PS = paddle.maximum(PS, min_v)\r\n        IPS = paddle.reciprocal(PS)\r\n        batch_shape = paddle.full_like(O, 1)\r\n        batch_size = paddle.sum(paddle.cast(\r\n            batch_shape, dtype=\"float32\"),\r\n                                axis=0)\r\n        #TODO this shoud be a hyparameter\r\n        IPS = paddle.clip(IPS, min=-15, max=15)  #online trick \r\n        IPS = paddle.multiply(IPS, batch_size)\r\n        IPS.stop_gradient = True\r\n        loss_cvr = paddle.multiply(loss_cvr, IPS)\r\n        loss_cvr = paddle.multiply(loss_cvr, O)\r\n        return paddle.mean(loss_cvr)\r\n\r\n请问为什么需要乘 \"ctr_num\" 和 \"batch_size\" 呢？这跟ESCM2论文中描述的 IPW 公式不太一样？通常来说IPW不就是直接除以 CTR 的概率吗 ？",
        "state": "open",
        "user": "zhjcp",
        "closed_by": null,
        "created_at": "2024-06-03T06:16:31+00:00",
        "updated_at": "2024-06-03T06:16:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 992,
        "title": "config.yaml开启了use_inference: True，为什么执行静态图训练（static_trainer.py）保存的模型缺少rec_inference.pdiparams",
        "body": "只有以下这四个文件生成\r\n![QQ截图20240607182927](https://github.com/PaddlePaddle/PaddleRec/assets/59813522/e862aa50-1cf7-4ed8-ac26-90b12a3cfe0d)\r\n",
        "state": "open",
        "user": "kules-rara",
        "closed_by": null,
        "created_at": "2024-06-07T10:29:46+00:00",
        "updated_at": "2024-06-07T10:30:20+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 1012,
        "title": "如何进行增量训练",
        "body": "没有看到相关的文档，请指教，谢谢",
        "state": "open",
        "user": "itflash",
        "closed_by": null,
        "created_at": "2024-12-25T06:40:10+00:00",
        "updated_at": "2024-12-25T06:40:10+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 1014,
        "title": "在linux系统上上无法导入其他文件夹的模块",
        "body": "环境：魔塔云服务器，ubuntu20.04\n描述：1. 进入models/match/kim 执行 python -u trainer.py -m config.yaml -o mode=train 报错无法找到utils包。\n           2. 但在我的win10系统环境下是能够执行的。\n报错： root@123445:/mnt/workspace/PaddleRec/models/match/kim# python -u trainer.py -m config.yaml -o mode=train\n            Traceback (most recent call last):\n                 File \"trainer.py\", line 29, in <module>\n                from utils.utils_single import load_yaml, load_dy_model_class, get_abs_model, create_data_loader\n                ModuleNotFoundError: No module named 'utils.utils_single'",
        "state": "open",
        "user": "MirindaFrank",
        "closed_by": null,
        "created_at": "2025-01-20T08:48:09+00:00",
        "updated_at": "2025-01-20T08:48:09+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 1017,
        "title": "输入数据多个目录怎么设置",
        "body": "train_data_dir:“path1” ok\ntrain_data_dir:“path1，path2” 不可以\n不知道如何设置多个输入呢",
        "state": "open",
        "user": "pipipiapia",
        "closed_by": null,
        "created_at": "2025-03-25T12:45:57+00:00",
        "updated_at": "2025-03-25T12:45:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 1020,
        "title": "get_movie_vectors将电影特征转化为向量时报错",
        "body": "我的版本：paddle-serving-app        0.9.0\npaddle-serving-client     0.9.0\npaddle-serving-server-gpu 0.9.0.post1028\npaddlepaddle-gpu          2.4.2.post117\n\n我想要采用PaddleRec与Milvus深度结合，进行电影推荐。看到官方教程，走的步骤。\n首先执行python -m paddle_serving_client.convert --dirname ./movie_model/4/ --model_filename ./movie_model/4/rec_inference.pdmodel --params_filename  ./movie_model/4/rec_inference.pdiparams得到的模型，然后执行python get_movie_vectors.py就会报错了：\n\npython get_movie_vectors.py\n/home/jmt/anaconda3/envs/milvus/lib/python3.9/site-packages/setuptools/command/easy_install.py:41: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  import pkg_resources\n/home/jmt/anaconda3/envs/milvus/lib/python3.9/site-packages/pkg_resources/__init__.py:3147: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/home/jmt/anaconda3/envs/milvus/lib/python3.9/site-packages/paddle_serving_client/httpclient.py:22: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n  from collections import Iterable\nfailed to create predictor: Log_id: 0  Raise_msg: (NotFound) Cannot open file serving_server/__model__, please confirm whether the file is normal.\n  [Hint: Expected static_cast<bool>(fin.is_open()) == true, but received static_cast<bool>(fin.is_open()):0 != true:1.] (at /paddle/paddle/fluid/inference/api/analysis_predictor.cc:1901)\n  ClassName: LocalPredictor.load_model_config.<locals>.create_predictor_check  FunctionName: create_predictor_check\nKilled\n\n",
        "state": "open",
        "user": "aajingmingtao",
        "closed_by": null,
        "created_at": "2025-06-21T01:37:48+00:00",
        "updated_at": "2025-06-21T01:37:48+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleRec",
        "number": 1019,
        "title": "请问用这套本地化，推荐效果怎么样",
        "body": null,
        "state": "open",
        "user": "qingcaixin",
        "closed_by": null,
        "created_at": "2025-04-25T07:18:29+00:00",
        "updated_at": "2025-06-06T09:28:05+00:00",
        "closed_at": null,
        "comments_count": [
            "phpxiaobaiyihao",
            "qingcaixin",
            "phpxiaobaiyihao",
            "qingcaixin"
        ],
        "labels": []
    }
]