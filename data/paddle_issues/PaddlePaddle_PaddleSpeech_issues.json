[
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 14,
        "title": "Update released Aishell model",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-16T12:20:05+00:00",
        "updated_at": "2017-11-16T12:50:22+00:00",
        "closed_at": "2017-11-16T12:50:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 9,
        "title": "Need add script to prepare vox dataset.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-15T14:05:09+00:00",
        "updated_at": "2017-11-20T03:12:23+00:00",
        "closed_at": "2017-11-20T03:12:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 22,
        "title": "Need to remove doc deploy in travis-ci",
        "body": "It is unnecessary for DeepSpeech2",
        "state": "closed",
        "user": "kuke",
        "closed_by": "luotao1",
        "created_at": "2017-11-17T10:37:54+00:00",
        "updated_at": "2017-11-17T10:41:49+00:00",
        "closed_at": "2017-11-17T10:41:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 20,
        "title": "Fix some problems in the ctc beam search decoder",
        "body": "- [x] Make character's index in FST starting from one, otherwise wrong decoding results would be produced especially when space is the first character in the vocabulary;\r\n- [x] Add version check in the setup script;\r\n- [x] Remove unused code. \r\n",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-17T08:03:31+00:00",
        "updated_at": "2017-11-17T09:34:00+00:00",
        "closed_at": "2017-11-17T09:34:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 12,
        "title": "Need to update settings for Aishell demo",
        "body": "rnn_layer_size=1024\r\nuse_gru=True\r\nshare_rnn_weights=False\r\nlearning_rate=5e-4\r\nalpha=2.6\r\nbeta=5.0\r\n\r\nCER with small lm: 0.080241\r\nCER with large lm: 0.074366",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-16T08:09:32+00:00",
        "updated_at": "2017-11-16T08:32:46+00:00",
        "closed_at": "2017-11-16T08:32:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1,
        "title": "Need add CI",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-14T13:19:12+00:00",
        "updated_at": "2017-11-14T14:08:18+00:00",
        "closed_at": "2017-11-14T14:08:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 11,
        "title": "Need to rebuild the Docker image",
        "body": "Due to the latest modification in both this project and PaddlePaddle,  temporarily the Docker image ```paddlepaddle/models:deep-speech-2``` cannot work properly. And we will rebuild a new one soon. ",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-16T04:00:17+00:00",
        "updated_at": "2017-11-21T09:21:46+00:00",
        "closed_at": "2017-11-21T09:21:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 17,
        "title": "Need fix ci",
        "body": "1. set clang version to '3.9'\r\n2. remove convert to html\r\n3. fix exit code 0",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "kuke",
        "created_at": "2017-11-17T07:14:21+00:00",
        "updated_at": "2017-11-17T09:25:57+00:00",
        "closed_at": "2017-11-17T09:25:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4,
        "title": "Add download url for BaiduEN8k Model.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-15T03:34:50+00:00",
        "updated_at": "2017-11-17T06:57:14+00:00",
        "closed_at": "2017-11-15T08:51:15+00:00",
        "comments_count": [
            "pkuyym",
            "PES2g",
            "pkuyym",
            "PES2g"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 24,
        "title": "Need upload newest Libri model",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-20T09:26:10+00:00",
        "updated_at": "2017-11-20T12:22:39+00:00",
        "closed_at": "2017-11-20T12:22:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 31,
        "title": "Update the setup in readme",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-21T08:56:41+00:00",
        "updated_at": "2017-11-21T09:02:45+00:00",
        "closed_at": "2017-11-21T09:02:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 27,
        "title": "Need adapt demo_server.py",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-20T13:57:23+00:00",
        "updated_at": "2017-11-21T07:33:09+00:00",
        "closed_at": "2017-11-21T07:33:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 33,
        "title": "Upload the Docker image for users in China",
        "body": "For users in China, a Docker image that can be faster downloaded is provided: \r\n\r\n```shell\r\ndocker pull docker.paddlepaddle.org/deep_speech:latest-gpu\r\n```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "zh794390558",
        "created_at": "2017-11-28T15:14:40+00:00",
        "updated_at": "2021-02-03T07:23:26+00:00",
        "closed_at": "2021-02-03T07:23:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 30,
        "title": "aishell eval BaiduCN1.2k",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-21T07:12:10+00:00",
        "updated_at": "2017-12-21T03:03:52+00:00",
        "closed_at": "2017-12-21T03:03:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 23,
        "title": "Update bench mark data for Libri model and corresponding url",
        "body": "- [x] evaluate on libri-test.clean and libri-test.other\r\n- [x] evaluate on vox data",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-11-20T03:09:48+00:00",
        "updated_at": "2017-11-20T12:22:56+00:00",
        "closed_at": "2017-11-20T12:22:56+00:00",
        "comments_count": [
            "pkuyym",
            "kuke",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 25,
        "title": "非常感谢",
        "body": "我一直在寻找ctc加上语言模型的实现方式，虽然有苗亚杰博士的示范，但是shell脚本实在是艰涩，没想到找到了这个项目。非常感谢作者。在这里提个想法，不知道可以把解码文件转化为python文件吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "zh794390558",
        "created_at": "2017-11-20T10:12:31+00:00",
        "updated_at": "2021-02-03T07:22:44+00:00",
        "closed_at": "2021-02-03T07:22:44+00:00",
        "comments_count": [
            "pkuyym",
            "yyhlvdl",
            "kuke",
            "yyhlvdl",
            "kuke",
            "Lebron-Kun",
            "Lebron-Kun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 34,
        "title": "Build Docker image for cloud training",
        "body": "Access by ```docker pull docker.paddlepaddle.org/ds2cloud:latest-gpu```",
        "state": "closed",
        "user": "kuke",
        "closed_by": "zh794390558",
        "created_at": "2017-11-28T15:28:22+00:00",
        "updated_at": "2021-02-03T07:23:41+00:00",
        "closed_at": "2021-02-03T07:23:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 32,
        "title": "中文语言模型的衔接失效了吗？",
        "body": "英文的可以，中文的下不下来。",
        "state": "closed",
        "user": "ksellesk",
        "closed_by": "ksellesk",
        "created_at": "2017-11-22T02:17:01+00:00",
        "updated_at": "2017-11-22T07:03:16+00:00",
        "closed_at": "2017-11-22T07:03:16+00:00",
        "comments_count": [
            "pkuyym",
            "zh794390558",
            "pkuyym",
            "zh794390558",
            "ksellesk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 38,
        "title": "Add library boost to the dependency",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-11-29T13:33:42+00:00",
        "updated_at": "2017-11-30T04:18:57+00:00",
        "closed_at": "2017-11-30T04:18:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 39,
        "title": "stuck at [INFO 2017-11-29 18:42:07,933 model.py:230] begin to initialize the external scorer for decoding",
        "body": "demo server is stuck at [INFO 2017-11-29 18:42:07,933 model.py:230] begin to initialize the external scorer for decoding. No response on client side.\r\n\r\nvocab_path: data/librispeech/eng_vocab.txt\r\nwarmup_manifest: data/librispeech/manifest.test-clean\r\n------------------------------------------------\r\nI1129 18:41:38.429951 29571 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\n[INFO 2017-11-29 18:41:38,444 layers.py:2689] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-11-29 18:41:38,445 layers.py:3244] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-11-29 18:41:38,446 layers.py:7401] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-11-29 18:41:38,447 layers.py:2689] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-11-29 18:41:38,448 layers.py:3244] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-11-29 18:41:38,449 layers.py:7401] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n-----------------------------------------------------------\r\nWarming up ...\r\n-----------------------------------------------------------\r\nASR Server Started.\r\nReceived utterance[length=122880] from 10.40.0.206, saved to demo_cache/20171129184205_10.40.0.206.wav.\r\n[INFO 2017-11-29 18:42:07,933 model.py:230] begin to initialize the external scorer for decoding\r\n\r\n\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2017-11-29T18:43:41+00:00",
        "updated_at": "2017-12-11T11:51:45+00:00",
        "closed_at": "2017-11-29T18:54:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 35,
        "title": "Need update BaiduEN8k Model",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "kuke",
        "created_at": "2017-11-29T02:38:51+00:00",
        "updated_at": "2017-12-21T08:18:40+00:00",
        "closed_at": "2017-12-21T08:18:40+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 36,
        "title": "安装错误",
        "body": "你好，我今天发现，paddlepaddle可以用pip安装了，就在uabntu16.04上pip安装了它。然而，在git clone https://github.com/PaddlePaddle/models.git\r\ncd models/deep_speech_2\r\nsh setup.sh\r\n这一步安装setup.sh\r\n和swig的setup.sh时，都出现错误：openfst-1.6.3/src/include/fst/union.h:33:40: warning: typedef ‘using StateId = typename Arc::StateId’ locally defined but not used [-Wunused-local-typedefs]\r\n   using StateId = typename Arc::StateId;\r\n                                        ^\r\nerror: command 'gcc' failed with exit status 1\r\n请问，可以解决下吗？毕竟pip安装的paddlepaddle比docker安装的要便捷多了。",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "pkuyym",
        "created_at": "2017-11-29T10:26:00+00:00",
        "updated_at": "2017-12-07T12:09:10+00:00",
        "closed_at": "2017-12-05T07:50:08+00:00",
        "comments_count": [
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "kuke",
            "kuke",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 41,
        "title": "High WER",
        "body": "Each time after I ran 'run_infer.sh' or any of scripts in 'examples/', I can still see python process running when I type 'ps' in terminal. When I run 'nvidia-docker' the GPU memory are still being used. I had to manually 'kill -9' all the python processes. Is this a known issue? Any way of killing these python processes automatically?",
        "state": "closed",
        "user": "yangliu2",
        "closed_by": "yangliu2",
        "created_at": "2017-11-29T19:03:03+00:00",
        "updated_at": "2017-12-04T18:32:51+00:00",
        "closed_at": "2017-11-30T02:14:01+00:00",
        "comments_count": [
            "kuke",
            "yangliu2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 40,
        "title": "demo_server error ",
        "body": "Exception happened during processing of request from ('10.40.0.206', 54528)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\r\n    self.process_request(request, client_address)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 318, in process_request\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 331, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 652, in __init__\r\n    self.handle()\r\n  File \"demo_server.py\", line 102, in handle\r\n    transcript = self.server.audio_process_handler(filename)\r\n  File \"demo_server.py\", line 192, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/ubuntu/DeepSpeech/deploy/../model_utils/model.py\", line 207, in infer_batch\r\n    output_layer=self._log_probs, parameters=self._parameters)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/inference.py\", line 50, in __init__\r\n    val.copyFromNumpyArray(parameters.get(name).flatten())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 242, in get\r\n    return self.__getitem__(key=parameter_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n    return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 153, in __getter_inner\r\n    shape = self.get_shape(key)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 200, in get_shape\r\n    raise ValueError(\"No such parameter %s\" % key)\r\nValueError: No such parameter ___recurrent_layer_0__.w0",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2017-11-29T18:55:42+00:00",
        "updated_at": "2018-09-28T03:47:36+00:00",
        "closed_at": "2017-11-29T19:19:05+00:00",
        "comments_count": [
            "cogmeta",
            "18811737901"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 42,
        "title": "python process still running after 'run_infer.sh'",
        "body": "Each time after I ran 'run_infer.sh' or any of scripts in 'examples/', I can still see python process running when I type 'ps' in terminal. When I run 'nvidia-docker' the GPU memory are still being used. I had to manually 'kill -9' all the python processes. Is this a known issue? Any way of killing these python processes automatically?",
        "state": "closed",
        "user": "yangliu2",
        "closed_by": "pkuyym",
        "created_at": "2017-11-30T02:14:25+00:00",
        "updated_at": "2017-12-06T09:59:00+00:00",
        "closed_at": "2017-12-06T09:59:00+00:00",
        "comments_count": [
            "pkuyym",
            "yangliu2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 43,
        "title": "BaiduCN1.2k Model 显示 to-be added？",
        "body": "这个模型可以提供一下吗？谢谢啦！",
        "state": "closed",
        "user": "lezasantaizi",
        "closed_by": "zh794390558",
        "created_at": "2017-11-30T11:04:26+00:00",
        "updated_at": "2021-02-03T07:24:02+00:00",
        "closed_at": "2021-02-03T07:24:02+00:00",
        "comments_count": [
            "pkuyym",
            "lezasantaizi",
            "harold-yh",
            "pkuyym",
            "harold-yh",
            "iou2much",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 44,
        "title": "n best results",
        "body": "Is there to way to tell demo server to send n best recognition results rather than just one? thanks.",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2017-11-30T15:14:04+00:00",
        "updated_at": "2017-12-01T08:37:56+00:00",
        "closed_at": "2017-12-01T08:37:56+00:00",
        "comments_count": [
            "pkuyym",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 46,
        "title": "Should expose the distance in error_rate.py",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "kuke",
        "created_at": "2017-12-01T09:47:39+00:00",
        "updated_at": "2017-12-02T04:54:57+00:00",
        "closed_at": "2017-12-02T04:54:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 45,
        "title": "Wers computed diff from kaldi",
        "body": "https://github.com/PaddlePaddle/DeepSpeech/blob/edaed68f33b7fff2455c26b880340ba680621f5c/test.py#L110\r\n\r\nWhy the wers compute method is different from kaldi's method? Which one is correct?",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2017-12-01T06:40:18+00:00",
        "updated_at": "2021-02-03T07:23:04+00:00",
        "closed_at": "2021-02-03T07:23:04+00:00",
        "comments_count": [
            "kuke",
            "zh794390558",
            "pkuyym",
            "kuke",
            "zh794390558",
            "pkuyym",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 48,
        "title": "c/c++ decoder",
        "body": "Is there a way to create c/c++ decoder for production deployment?",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "zh794390558",
        "created_at": "2017-12-03T16:34:05+00:00",
        "updated_at": "2021-02-03T07:25:57+00:00",
        "closed_at": "2021-02-03T07:25:57+00:00",
        "comments_count": [
            "pkuyym",
            "cogmeta",
            "pkuyym",
            "cogmeta",
            "pkuyym"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 53,
        "title": "Add infer & test scripts for baidu_en8k model",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-04T06:04:30+00:00",
        "updated_at": "2017-12-04T06:37:57+00:00",
        "closed_at": "2017-12-04T06:37:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 56,
        "title": "The resources won't be released when program exited.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-12-04T10:13:05+00:00",
        "updated_at": "2017-12-06T09:59:00+00:00",
        "closed_at": "2017-12-06T09:59:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 54,
        "title": "Retune hyper-parameters for English models due to #50",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-04T06:10:18+00:00",
        "updated_at": "2017-12-06T04:10:45+00:00",
        "closed_at": "2017-12-06T04:10:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 50,
        "title": "Correct the error rate's computation for multiple sentences",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-04T05:41:00+00:00",
        "updated_at": "2017-12-04T12:30:42+00:00",
        "closed_at": "2017-12-04T12:30:42+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 49,
        "title": "switching language model at runtime",
        "body": "From deploy_demo_server.py ( def ds2_model.infer_batch), it looks like we can change and use different language model at runtime. Is that true?\r\n\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "zh794390558",
        "created_at": "2017-12-03T16:37:26+00:00",
        "updated_at": "2021-02-03T07:17:55+00:00",
        "closed_at": "2021-02-03T07:17:55+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 57,
        "title": "A mistake issue",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-04T13:24:08+00:00",
        "updated_at": "2017-12-04T13:27:49+00:00",
        "closed_at": "2017-12-04T13:24:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 59,
        "title": "aishell的deploy出现的错误",
        "body": "因为实验室硬件的问题，我实在是无法自己训练完aishell数据，那估计需要一个月。所以，我使用了你们发布的中文模型，来尝试识别我自己的语音。\r\nwarmup_manifest是使用aishell的test数据，然后出现这样的错误。\r\n```\r\nroot@70ae495f3c96:/DeepSpeech# python deploy/demo_server.py \r\n-----------  Configuration Arguments -----------\r\nalpha: 2.15\r\nbeam_size: 500\r\nbeta: 0.35\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: asset/preprocess/mean_std.npz\r\nmodel_path: asset/train/aishell_model .tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: False\r\nvocab_path: asset/preprocess/vocab.txt\r\nwarmup_manifest: asset/preprocess/test\r\n------------------------------------------------\r\nI1205 06:26:07.198161    93 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1 \r\n[INFO 2017-12-05 06:26:09,496 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 06:26:09,498 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 06:26:09,499 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 06:26:09,500 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-05 06:26:09,502 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-05 06:26:09,503 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'asset/data/aishell/wav/test/S0765/BAC009S0765W0205.wav')\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 219, in <module>\r\n    main()\r\n  File \"deploy/demo_server.py\", line 215, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 199, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 135, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 190, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/DeepSpeech/deploy/../model_utils/model.py\", line 207, in infer_batch\r\n    output_layer=self._log_probs, parameters=self._parameters)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/inference.py\", line 50, in __init__\r\n    val.copyFromNumpyArray(parameters.get(name).flatten())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 242, in get\r\n    return self.__getitem__(key=parameter_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n    return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 153, in __getter_inner\r\n    shape = self.get_shape(key)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 200, in get_shape\r\n    raise ValueError(\"No such parameter %s\" % key)\r\nValueError: No such parameter ___conv_0__.w0\r\n```",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-05T06:42:28+00:00",
        "updated_at": "2017-12-07T12:08:10+00:00",
        "closed_at": "2017-12-05T10:21:18+00:00",
        "comments_count": [
            "pkuyym",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 60,
        "title": "Illegal instruction (core dumped) when run sh run_train.sh",
        "body": "I follow the steps to do the test, but when run \"sh run_train.sh\", the application crashed.\r\nI set the GPU to False, and when I test by PythonCharm, this line cause the crash:\r\n\r\nimport py_paddle.swig_paddle as api\r\n",
        "state": "closed",
        "user": "gdfspy",
        "closed_by": "gdfspy",
        "created_at": "2017-12-05T07:24:01+00:00",
        "updated_at": "2019-08-23T12:45:59+00:00",
        "closed_at": "2017-12-07T02:23:55+00:00",
        "comments_count": [
            "pkuyym",
            "gdfspy",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "kuke",
            "gdfspy",
            "gdfspy",
            "hui001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 65,
        "title": "Decoupling network architecture from data provider",
        "body": "DataProvider 和 Model Structure 需要解耦合，以使得data provider的易于复用，代码结构更合理。\r\n\r\n请关注 https://github.com/PaddlePaddle/DeepSpeech/blob/develop/data_utils/data.py#L82\r\n\r\n这一行的增加使得二者完全耦合了，让人觉得很奇怪，请关注并改进。",
        "state": "closed",
        "user": "xinghai-sun",
        "closed_by": "pkuyym",
        "created_at": "2017-12-08T08:48:29+00:00",
        "updated_at": "2017-12-15T08:16:13+00:00",
        "closed_at": "2017-12-15T08:16:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 67,
        "title": "Update default hyper-params of scorer in python scripts",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-08T12:50:51+00:00",
        "updated_at": "2017-12-15T08:16:52+00:00",
        "closed_at": "2017-12-15T08:16:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 62,
        "title": "couldn't download the noise data",
        "body": "I have some noisy audio files and I'm trying to put noise in clean data (like librispeech) to generate a denoise autoencoder. The link for downloading noise data in '/data/noise/chime3_background.py' doesn't exist anymore. Wget return a 404. Do you guys still have that data?",
        "state": "closed",
        "user": "yangliu2",
        "closed_by": "yangliu2",
        "created_at": "2017-12-05T20:19:36+00:00",
        "updated_at": "2017-12-06T14:44:33+00:00",
        "closed_at": "2017-12-06T14:44:33+00:00",
        "comments_count": [
            "gdfspy",
            "gdfspy",
            "yangliu2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 69,
        "title": "'superimpose' method in 'data_utils/audio.py'",
        "body": "I'm trying to use 'superimpose' method in 'data_utils/audio.py' to combine two AudioSegment, clean audio segment and noise segment.  \r\nI'm getting the error \"TypeError: Cannot add segments of different type: <class 'data_utils.audio.AudioSegment'> and <class 'data_utils.audio.AudioSegment'>.\"\r\nThey are the same object type and same size, except the numbers are different. \r\nSo I'm not sure if I'm using it correctly. \r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/4bf526e78d8531551fce1f4d8bfb119e297812d7/data_utils/audio.py#L270\r\nIf I took out the 'if isinstance' statement on line 270 of source code, it seems to work fine. But don't want to modify your source code. ",
        "state": "closed",
        "user": "yangliu2",
        "closed_by": "zh794390558",
        "created_at": "2017-12-08T18:28:46+00:00",
        "updated_at": "2021-02-03T07:28:54+00:00",
        "closed_at": "2021-02-03T07:28:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 61,
        "title": "aishell的deploy的问题",
        "body": "我直接使用你们发布的aishell模型，执行python deploy/demo_server.py，然后出现了错误：\r\n```\r\nroot@095d9ada1b1d:/DeepSpeech# python deploy/demo_server.py\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.15\r\nbeam_size: 500\r\nbeta: 0.35\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: asset/preprocess/mean_std.npz\r\nmodel_path: asset/train/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: False\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: True\r\nvocab_path: asset/preprocess/vocab.txt\r\nwarmup_manifest: asset/preprocess/test\r\n------------------------------------------------\r\nI1205 10:14:34.175657    15 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1 \r\n[INFO 2017-12-05 10:14:35,626 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 10:14:35,626 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 10:14:35,627 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-05 10:14:35,627 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-05 10:14:35,628 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-05 10:14:35,628 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'asset/data/aishell/wav/test/S0765/BAC009S0765W0205.wav')\r\n[INFO 2017-12-05 10:14:42,337 model.py:230] begin to initialize the external scorer for decoding\r\n[INFO 2017-12-05 10:14:50,941 model.py:241] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2017-12-05 10:14:50,941 model.py:242] end initializing scorer. Start decoding ...\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 224, in <module>\r\n    main()\r\n  File \"deploy/demo_server.py\", line 220, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 204, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 143, in warm_up_test\r\n    (finish_time - start_time, transcript))\r\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 40-94: ordinal not in range(128)\r\n```\r\n于是，我将transcript注释掉，重新执行，然后可以继续了。只是\r\n```('Warm-up Test Case %d: %s', 0, u'asset/data/aishell/wav/test/S0765/BAC009S0765W0205.wav')\r\n[INFO 2017-12-05 10:46:41,054 model.py:230] begin to initialize the external scorer for decoding\r\n[INFO 2017-12-05 10:46:42,193 model.py:241] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2017-12-05 10:46:42,193 model.py:242] end initializing scorer. Start decoding ...\r\nResponse Time: 1174.020508\r\n('Warm-up Test Case %d: %s', 1, u'asset/data/aishell/wav/test/S0767/BAC009S0767W0141.wav')\r\n```\r\n一个文件就需要1174s，这么长的时间，请问，有办法可以提速吗？\r\n",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-05T11:10:34+00:00",
        "updated_at": "2018-02-05T09:30:07+00:00",
        "closed_at": "2017-12-07T08:46:11+00:00",
        "comments_count": [
            "yyhlvdl",
            "kuke",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "kuke",
            "pkuyym",
            "pkuyym",
            "Pelhans",
            "yyhlvdl",
            "Pelhans"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 64,
        "title": "/DeepSpeech/examples/tiny# sh run_train.sh 运行时出错",
        "body": "root@3328a2284d27:/DeepSpeech/examples/tiny# sh run_train.sh\r\n----------- Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 8\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n\r\nI1206 11:44:56.762332 47 Util.cpp:166] commandline: --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=8\r\nF1206 11:44:57.226635 47 hl_cuda_cublas.cc:137] Check failed: CUBLAS_STATUS_SUCCESS == g_cublasStat (0 vs. 1) Cublas Error: [cublas status]: not initialized [cublas init] Cublas create handle faild!\r\n*** Check failure stack trace: ***\r\n@ 0x7f7b10b7f04d google::LogMessage::Fail()\r\n@ 0x7f7b10b81398 google::LogMessage::SendToLog()\r\n@ 0x7f7b10b7eb5b google::LogMessage::Flush()\r\n@ 0x7f7b10b8226e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f7b10b1d7a1 hl_cublas_init()\r\n@ 0x7f7b10b2a6e4 hl_create_global_resources()\r\n@ 0x7f7b10b2b1a4 hl_specify_devices_start()\r\n@ 0x7f7b10b2b47d hl_start()\r\n@ 0x7f7b10aace7e paddle::initMain()\r\n@ 0x7f7b10b65621 initPaddle()\r\n@ 0x7f7b10601347 _wrap_initPaddle\r\n@ 0x4c468a PyEval_EvalFrameEx\r\n@ 0x4c9d8f PyEval_EvalFrameEx\r\n@ 0x4c2765 PyEval_EvalCodeEx\r\n@ 0x4de6fe (unknown)\r\n@ 0x4b0cb3 PyObject_Call\r\n@ 0x4c6ad1 PyEval_EvalFrameEx\r\n@ 0x4c2765 PyEval_EvalCodeEx\r\n@ 0x4ca8d1 PyEval_EvalFrameEx\r\n@ 0x4c2765 PyEval_EvalCodeEx\r\n@ 0x4ca8d1 PyEval_EvalFrameEx\r\n@ 0x4c2765 PyEval_EvalCodeEx\r\n@ 0x4c2509 PyEval_EvalCode\r\n@ 0x4f1def (unknown)\r\n@ 0x4ec652 PyRun_FileExFlags\r\n@ 0x4eae31 PyRun_SimpleFileExFlags\r\n@ 0x49e14a Py_Main\r\n@ 0x7f7b35555830 __libc_start_main\r\n@ 0x49d9d9 _start\r\n@ (nil) (unknown)\r\nAborted (core dumped)\r\nFail in training!",
        "state": "closed",
        "user": "JoeBlack220",
        "closed_by": "zh794390558",
        "created_at": "2017-12-07T12:08:50+00:00",
        "updated_at": "2021-02-03T07:27:39+00:00",
        "closed_at": "2021-02-03T07:27:39+00:00",
        "comments_count": [
            "yyhlvdl",
            "kuke",
            "JoeBlack220",
            "fangmingbnu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 63,
        "title": "Data augmentor problem",
        "body": "change_speed function changes tempo and pitch both. \r\nIs it reasonable? Is just changing tempo a better choice?\r\n\r\n[code here](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/data_utils/audio.py#L301)",
        "state": "closed",
        "user": "lispc",
        "closed_by": "zh794390558",
        "created_at": "2017-12-06T08:17:59+00:00",
        "updated_at": "2021-02-03T07:20:58+00:00",
        "closed_at": "2021-02-03T07:20:58+00:00",
        "comments_count": [
            "pkuyym",
            "lispc",
            "kuke",
            "lispc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 70,
        "title": "'slice_from_file' in 'data_util/audio.py'",
        "body": "The default behavior for the method is to get AudioSegment from begin to end if 'start' or 'end' is not provided. \r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/4bf526e78d8531551fce1f4d8bfb119e297812d7/data_utils/audio.py#L99\r\nOn line 99, 'end = 0. if end is None else end' should be 'end = duration if end is None else end'. \r\nPlease let me know if this is what was intended or I missed something. \r\n\r\nThanks. ",
        "state": "closed",
        "user": "yangliu2",
        "closed_by": "zh794390558",
        "created_at": "2017-12-08T19:43:51+00:00",
        "updated_at": "2021-02-03T07:13:11+00:00",
        "closed_at": "2021-02-03T07:13:11+00:00",
        "comments_count": [
            "pkuyym",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 78,
        "title": "Fix the link to cloud training in doc",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-13T02:25:41+00:00",
        "updated_at": "2017-12-15T08:17:34+00:00",
        "closed_at": "2017-12-15T08:17:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 79,
        "title": "lanaguge model 的blank id能从0 开始吗？",
        "body": "lanaguge model 的blank id能从0 开始吗？\r\n\r\n因为我训练出来的模型，其blank id是从0 开始的，有办法修正她，让她不是voc.size吗？",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2017-12-14T05:33:30+00:00",
        "updated_at": "2021-02-03T06:39:09+00:00",
        "closed_at": "2021-02-03T06:39:09+00:00",
        "comments_count": [
            "pkuyym",
            "ghost",
            "ghost",
            "pkuyym",
            "ghost",
            "ghost",
            "pkuyym",
            "ghost",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 74,
        "title": "中文语言模型无法下载，下了几十M之后就像断了，一直都这样",
        "body": "只要是这个地址的文件都是这样子的\r\nhttp://cloud.dlnel.org/filepub/?uuid=245d02bb-cd01-4ebe-b079-b97be864ec37",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "zh794390558",
        "created_at": "2017-12-11T10:38:24+00:00",
        "updated_at": "2021-02-03T06:39:29+00:00",
        "closed_at": "2021-02-03T06:39:29+00:00",
        "comments_count": [
            "pkuyym",
            "witkeyshare",
            "bliunlpr",
            "pkuyym",
            "bliunlpr",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 72,
        "title": "Problem about Librispeech data process and training params",
        "body": "The largest sample of LibriSpeech is about 40s, how do you use these data? Or the full data is used in your training process?  I see your batch size is 10, does it can be larger, e.g. 32?\r\n\r\nDoes rnn hidden size is sensitive to the result? Now you use 2048, does 1024 or other size is sensitive to the result?",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2017-12-11T01:49:02+00:00",
        "updated_at": "2021-02-03T07:06:37+00:00",
        "closed_at": "2021-02-03T07:06:37+00:00",
        "comments_count": [
            "pkuyym",
            "zh794390558",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 76,
        "title": "decoder_utils.h:55: Error: Syntax error in input(1).",
        "body": "compile decoders  find error：\r\n\r\ndecoder_utils.h:55: Error: Syntax error in input(1).\r\n\r\n\r\n",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "zh794390558",
        "created_at": "2017-12-12T05:02:37+00:00",
        "updated_at": "2021-05-12T06:24:18+00:00",
        "closed_at": "2021-05-12T06:24:18+00:00",
        "comments_count": [
            "witkeyshare",
            "pkuyym",
            "zy486at189cn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 75,
        "title": "run_train.sh出错",
        "body": "MAC OS 10.13.2\r\nPython版本：2.7.13\r\npaddle版本：使用pip安装，编译安装不过。\r\nPaddlePaddle 0.10.0, compiled with\r\n    with_avx: ON\r\n    with_gpu: OFF\r\n    with_double: OFF\r\n    with_python: ON\r\n    with_rdma: OFF\r\n    with_timer: OFF\r\n```\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 8\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 4\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI1212 09:08:28.942749 2570847040 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=4\r\n[INFO 2017-12-12 09:08:28,953 layers.py:2479] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 131, in <module>\r\n    main()\r\n  File \"train.py\", line 127, in main\r\n    train()\r\n  File \"train.py\", line 107, in train\r\n    share_rnn_weights=args.share_rnn_weights)\r\n  File \"/Volumes/DATA/git/paddlepaddle/DeepSpeech/model_utils/model.py\", line 46, in __init__\r\n    rnn_layer_size, use_gru, share_rnn_weights)\r\n  File \"/Volumes/DATA/git/paddlepaddle/DeepSpeech/model_utils/model.py\", line 307, in _create_network\r\n    share_rnn_weights=share_rnn_weights)\r\n  File \"/Volumes/DATA/git/paddlepaddle/DeepSpeech/model_utils/network.py\", line 263, in deep_speech_v2_network\r\n    index_range_datas=index_range_datas)\r\n  File \"/Volumes/DATA/git/paddlepaddle/DeepSpeech/model_utils/network.py\", line 165, in conv_group\r\n    index_range_data=index_range_datas[0])\r\n  File \"/Volumes/DATA/git/paddlepaddle/DeepSpeech/model_utils/network.py\", line 43, in conv_bn_layer\r\n    scale_sub_region = paddle.layer.scale_sub_region(\r\nAttributeError: 'module' object has no attribute 'scale_sub_region'\r\nFail in training!\r\n```",
        "state": "closed",
        "user": "harold-yh",
        "closed_by": "zh794390558",
        "created_at": "2017-12-12T01:14:11+00:00",
        "updated_at": "2021-02-03T06:37:56+00:00",
        "closed_at": "2021-02-03T06:37:56+00:00",
        "comments_count": [
            "kuke",
            "harold-yh",
            "kuke",
            "harold-yh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 80,
        "title": "有一个层不清楚",
        "body": "在network中有一个层paddle.layer.sub_seq，这个层我在百度的api中，实在是找不到，有人可以告诉我在哪里吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-17T12:54:11+00:00",
        "updated_at": "2017-12-21T07:51:33+00:00",
        "closed_at": "2017-12-21T07:51:33+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 73,
        "title": "中文的deploy问题",
        "body": "终于，我在docker中启动了服务器和客户端，然后说了一段中文，出现这样的错误：\r\nException happened during processing of request from ('127.0.0.1', 59312)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\r\n    self.process_request(request, client_address)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 318, in process_request\r\n    self.finish_request(request, client_address)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 331, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 652, in __init__\r\n    self.handle()\r\n  File \"deploy/demo_server.py\", line 108, in handle\r\n    (finish_time - start_time, transcript))\r\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 39-48: ordinal not in range(128)\r\n我个人觉得，可以把识别结果存储到一个文件中，没必要打印出来，当然，如果作者可以解决打印的问题，就更好了。",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "pkuyym",
        "created_at": "2017-12-11T04:34:41+00:00",
        "updated_at": "2018-08-16T00:44:11+00:00",
        "closed_at": "2017-12-11T12:36:48+00:00",
        "comments_count": [
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "yyhlvdl",
            "Pelhans",
            "yyhlvdl",
            "DmytroSytro",
            "Pelhans",
            "Pelhans",
            "Pelhans",
            "zhaoqxu97",
            "Pelhans"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 82,
        "title": "Abort while training",
        "body": "W1219 06:39:14.853305 35630 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:14.853649 35631 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:14.853781 35629 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:14.860672 35632 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:16.114899 35630 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:16.175866 35630 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:16.214041 35629 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nW1219 06:39:16.219384 35631 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\nThread [140650471823104] Forwarding __concat_0__,\r\n*** Aborted at 1513645756 (unix time) try \"date -d @1513645756\" if you are using GNU date ***\r\n\r\nPC: @                0x0 (unknown)\r\n\r\n*** SIGFPE (@0x7febe07e49fe) received by PID 35544 (TID 0x7febbd691700) from PID 18446744073180957182; stack trace: ***\r\n\r\n    @     0x7fec56ff1390 (unknown)\r\nW1219 06:39:16.236891 35632 MKLDNNBatchNormLayer.cpp:138] use_global_stats is invalid setting in training phase\r\n\r\n    @     0x7febe07e49fe paddle::MKLDNNConcatLayer::reshape()",
        "state": "closed",
        "user": "jayiind",
        "closed_by": "zh794390558",
        "created_at": "2017-12-19T01:17:07+00:00",
        "updated_at": "2021-02-03T06:37:32+00:00",
        "closed_at": "2021-02-03T06:37:32+00:00",
        "comments_count": [
            "luotao1",
            "jayiind",
            "luotao1",
            "jayiind",
            "luotao1",
            "jayiind"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 81,
        "title": "run deploy/demo_client.py error",
        "body": "ALSA lib pcm_dsnoop.c:618:(snd_pcm_dsnoop_open) unable to open slave\r\nALSA lib pcm_dmix.c:1052:(snd_pcm_dmix_open) unable to open slave\r\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\r\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\r\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\r\nALSA lib pcm_dmix.c:1052:(snd_pcm_dmix_open) unable to open slave\r\n\r\nStart Recording ...                                              Speech[length=110592] Sent.\r\nTraceback (most recent call last):\r\n  File \"/home/zxj/DeepSpeech/deploy/demo_client.py\", line 63, in callback\r\n    received = sock.recv(1024)\r\nsocket.error: [Errno 104] Connection reset by peer\r\n\r\n\r\nanyone know how to solve this error? ",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "zh794390558",
        "created_at": "2017-12-18T09:36:04+00:00",
        "updated_at": "2021-02-03T06:39:55+00:00",
        "closed_at": "2021-02-03T06:39:55+00:00",
        "comments_count": [
            "kuke",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 87,
        "title": "Need update baidu8k model to latest",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-12-20T12:44:42+00:00",
        "updated_at": "2017-12-20T13:16:19+00:00",
        "closed_at": "2017-12-20T13:16:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 89,
        "title": "Need upload Baidu1.2kCN model",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2017-12-20T13:05:10+00:00",
        "updated_at": "2017-12-20T13:50:35+00:00",
        "closed_at": "2017-12-20T13:50:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 83,
        "title": "DeepSpeech/examples/librispeech run_infer_golden.sh inference failed",
        "body": "I downloaded librispeech model and ran inference with run_infer_golden.sh. Inference failed with the following error\r\nF1219 07:07:20.167259 36066 MKLDNNConcatLayer.cpp:38] Check failed: (size_t)ic * ih * iw == inputLayers_[0]->getSize() (0 vs. 2048)\r\n*** Check failure stack trace: ***\r\n    @     0x7f46a4c0226d  google::LogMessage::Fail()\r\n    @     0x7f46a4c045b8  google::LogMessage::SendToLog()\r\n    @     0x7f46a4c01d7b  google::LogMessage::Flush()\r\n    @     0x7f46a4c0548e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f46a4a01d0d  paddle::MKLDNNConcatLayer::reshape()\r\n    @     0x7f46a48bfa25  paddle::MKLDNNLayer::forward()\r\n    @     0x7f46a486be77  paddle::NeuralNetwork::forward()\r\n    @     0x7f46a47cd816  _wrap_GradientMachine_forward\r\n    @           0x4c45fa  PyEval_EvalFrameEx\r\n    @           0x4c9d7f  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4ddd6a  (unknown)\r\n    @           0x4c4bdc  PyEval_EvalFrameEx\r\n    @           0x4ddd6a  (unknown)\r\n    @           0x4c4bdc  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca088  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4ca7df  PyEval_EvalFrameEx\r\n    @           0x4c2705  PyEval_EvalCodeEx\r\n    @           0x4c24a9  PyEval_EvalCode\r\n    @           0x4f19ef  (unknown)\r\n    @           0x4ec372  PyRun_FileExFlags\r\n    @           0x4eaaf1  PyRun_SimpleFileExFlags\r\n    @           0x49e208  Py_Main\r\n    @     0x7f471fe55830  __libc_start_main\r\n    @           0x49da59  _start\r\nAborted (core dumped)\r\nFailed in inference!\r\n",
        "state": "closed",
        "user": "jayiind",
        "closed_by": "luotao1",
        "created_at": "2017-12-19T01:37:32+00:00",
        "updated_at": "2018-01-10T14:15:02+00:00",
        "closed_at": "2018-01-10T14:15:02+00:00",
        "comments_count": [
            "kuke",
            "jayiind",
            "kuke",
            "jayiind",
            "luotao1",
            "jayiind",
            "luotao1",
            "jayiind"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 91,
        "title": "Update benchmark result for BaiduEN8K model due to #88",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2017-12-21T02:19:06+00:00",
        "updated_at": "2017-12-21T03:00:53+00:00",
        "closed_at": "2017-12-21T03:00:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 84,
        "title": "What language model do you use in the LibriSpeech benchmark?",
        "body": "We can not get a WER 6.85% with CommonCrawl(en.00) Language model.\r\n\r\nDo you use the CommonCrawl(en.00) Language model in the LibriSpeech benchmark?",
        "state": "closed",
        "user": "ksellesk",
        "closed_by": "zh794390558",
        "created_at": "2017-12-19T10:16:31+00:00",
        "updated_at": "2021-02-03T07:06:16+00:00",
        "closed_at": "2021-02-03T07:06:16+00:00",
        "comments_count": [
            "pkuyym",
            "sivagururaman",
            "sahilanguralla"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 86,
        "title": "bidirectional_gru_bn_layer问题",
        "body": "在 model_utils/network.py 107行 , 定义了 bidirectional_gru_bn_layer(name, input, size, act) 这个函数，做的是双向带bn的gru。在程序里，先做了一个线性变换层，应该是 输入乘以一个权重矩阵（代表了gru计算公式中的前半部分，也就是 W_z * X, W_r * X, W * X）。紧接着做了bn。但是在计算bn的时候，会先做一个 减均值除标准差 的操作，如果输入乘了权重矩阵，再进行 减均值除标准差的操作 的时候，结果是一样的。 换句话说，上面的线性变换层是不是就失去作用了？无论变换是什么，计算bn 的时候都抵消了。不知道我这样理解是不是有问题？诚心求教，谢谢！",
        "state": "closed",
        "user": "bliunlpr",
        "closed_by": "zh794390558",
        "created_at": "2017-12-19T14:04:29+00:00",
        "updated_at": "2021-02-03T06:36:38+00:00",
        "closed_at": "2021-02-03T06:36:38+00:00",
        "comments_count": [
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 85,
        "title": "batch-norm paramters",
        "body": "When I print the paramters of the model, I found:\r\n___batch_norm_2__.w0 (1, 3072)\r\n___batch_norm_2__.w1 (1, 3072)\r\n___batch_norm_2__.w2 (1, 3072)\r\n___batch_norm_2__.wbias (1, 3072).\r\nI wonder why batch-norm layer has four paramters(w0, w1, w2, wbias)?  I guess these are \\\\gamma, \\\\beta, running_average, running_var.  So what's the meaning for batch-norm paramters respectively? Thanks very much!\r\n",
        "state": "closed",
        "user": "bliunlpr",
        "closed_by": "zh794390558",
        "created_at": "2017-12-19T10:20:40+00:00",
        "updated_at": "2021-02-03T06:40:55+00:00",
        "closed_at": "2021-02-03T06:40:55+00:00",
        "comments_count": [
            "pkuyym",
            "bliunlpr",
            "pkuyym",
            "bliunlpr",
            "wudeshi",
            "wudeshi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 93,
        "title": "The WER comparison between current benchmark and  DS2 paper ",
        "body": "With [the latest update](https://github.com/PaddlePaddle/DeepSpeech/pull/88), the BaiduEN8K model has caught up with the original [Deep Speech 2](https://arxiv.org/abs/1512.02595) work in WER performance on some public test datasets. \r\n\r\n|         | On pubic LM (8.3G) |  On internal LM (260G)        |  DS2 paper|\r\n|:------------------------------:|:----------:|:----------:| :-----------:|\r\n| LibriSpeech Test-Clean            |  5.41          |  **5.28**   | 5.33            |\r\n| LibriSpeech Test-Other            |  13.85\t   |  13.49        |  **13.26**  |\r\n| VoxForge American-Canadian |  **7.13**   |  **6.96**   |  7.55            |\r\n| VoxForge Commonwealth         |  14.93\t   |  14.62         |  **13.56**  |\r\n| VoxForge European                   |  18.64\t   |  18.34        |  **17.55**   |\r\n| VoxForge Indian                         |  25.51\t   |  25.27        |  **22.44**  |\r\n\r\n- Training data set: **8628h** vs. **11940h**",
        "state": "closed",
        "user": "kuke",
        "closed_by": "zh794390558",
        "created_at": "2017-12-21T04:24:40+00:00",
        "updated_at": "2021-05-12T06:24:03+00:00",
        "closed_at": "2021-05-12T06:24:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 95,
        "title": "Installation issue on installing package - Install python dependencies failed !!!",
        "body": "The setup.py file contains this line \r\n`pip install package -r requirements.txt `, which outputs the following error.\r\n`\r\n\r\n>   Downloading/unpacking package\r\n>   Downloading package-0.1.1.tar.gz\r\n>   Running setup.py (path:/tmp/pip_build_root/package/setup.py) egg_info for package package\r\n>     \r\n>     Greetings!\r\n>     \r\n>     It looks like you are trying to install this package (called `package`). STOP!\r\n>     \r\n>     package` is a set of tools to make Python packages easier to write and\r\n>     maintain, and to make the resulting packages easier for their users to\r\n>     install.\r\n>     \r\n>     If you are not a (possibly aspiring) Python package author, you can stop\r\n>     \r\n>     ...\r\n>     \r\n>     I'm glad you are still reading. You must be a (possibly aspiring) Python\r\n>     package author. Good on you!\r\n>     \r\n>     To use this stuff either untar package-#.#.#.tar.gz (get it from\r\n>     http://pypi.python.org/pypi/package/) or get/git the development sources\r\n>     directly from http://github.com/ingydotnet/package-py. Put the `package`\r\n>     directory under your src directory, next to the Python packages you are\r\n>     authoring, and call it `package-py/`.\r\n>     \r\n>     Further instructions can be found at http://pypi.python.org/pypi/package/\r\n>     \r\n>     Enjoy!\r\n>     \r\n>     \r\n> Cleaning up...\r\n> No files/directories in /tmp/pip_build_root/package/pip-egg-info (from PKG-INFO)\r\n> Storing debug log for failure in /home/koki/.pip/pip.log\r\n> Install python dependencies failed !!!\r\n\r\n\r\nIt seems for the package _package_, we cannot install it via its setup.py, which causes `Install python dependencies failed !!!`. The [official doc](https://pypi.python.org/pypi/package/) said \r\n\r\n> DON’T INSTALL THIS PACKAGE (package)!!!\r\n> \r\n> package isn’t meant to be installed like normal Python packages. It is meant to be copied and distributed as a part of other Python packages.\r\n> \r\n> The best thing to do is to to git clone it from GitHub, and put it beside the other packages that you package for Python:\r\n> \r\n> git clone git://github.com/ingydotnet/package-py.git\r\n> \r\n> The second best thing to do is get the latest package-#.#.#.tar.gz from http://pypi.python.org/pypi/package/, untar it and rename the directory to package-py.\r\n\r\nI am wondering whether you guys also follow this guideline to use the package _package_.",
        "state": "closed",
        "user": "vucuong12",
        "closed_by": "vucuong12",
        "created_at": "2017-12-21T09:55:01+00:00",
        "updated_at": "2017-12-21T10:07:31+00:00",
        "closed_at": "2017-12-21T10:07:31+00:00",
        "comments_count": [
            "kuke",
            "vucuong12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 94,
        "title": "BaiduCN1.2k Model识别结果不对",
        "body": "使用deploy_server.py和deploy_client.py进行识别，声音来源麦克风，音频文件正常，识别结果不对\r\n语言模型使用：Mandarin LM Small     Speech Model使用：BaiduCN1.2k Model，参数按照BaiduCN1.2k Model的README设置，识别出来的结果完全不对，一句话只识别成一个字，并且还是错的，麻烦指导一下是我使用的不对吗？\r\n```\r\n-----------  Configuration Arguments -----------\r\nalpha: 1.15\r\nbeam_size: 500\r\nbeta: 0.15\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/MandarinLMSmall.klm\r\nmean_std_path: models/baidu_cn1.2k_model/mean_std.npz\r\nmodel_path: models/baidu_cn1.2k_model/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: models/baidu_cn1.2k_model/vocab.txt\r\n------------------------------------------------\r\n```\r\n结果全是下面这样的\r\nRecognition Results: 人\r\nRecognition Results: 在\r\nRecognition Results: 我",
        "state": "closed",
        "user": "harold-yh",
        "closed_by": "zh794390558",
        "created_at": "2017-12-21T07:59:23+00:00",
        "updated_at": "2021-05-12T06:23:56+00:00",
        "closed_at": "2021-05-12T06:23:56+00:00",
        "comments_count": [
            "pkuyym",
            "harold-yh",
            "pkuyym",
            "harold-yh",
            "pkuyym",
            "harold-yh",
            "fedoral",
            "pkuyym",
            "tangsipeng",
            "sunjunlishi",
            "sukibean163",
            "VegetableWithChicken"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 99,
        "title": "在network.py中对于数据的一些问题",
        "body": "在network.py中，conv_group_output这样的layerout格式的width,height,depth都是可以查看的，而在转化为序列后，我只可以查看 remove_padding_data的size,如果我想看它的时间步，可以做到吗？\r\n或者说，是这样的，数据在conv_group后，是c=32, h = 41, w = 54, size = 70848;那么在 paddle.layer.block_expand后，应该变成时间步54，每个时间步是1312的序列，size=54*1312,可是，我查看的数据在经过paddle.layer.block_expand后的size是1312，非常困惑这个问题。可以解答下吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-23T08:56:14+00:00",
        "updated_at": "2017-12-24T05:28:43+00:00",
        "closed_at": "2017-12-24T05:28:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 96,
        "title": " IOError: got end of file during message when  training with CPU",
        "body": "```\r\nroot@537527a1fed8:/DeepSpeech/examples/tiny# sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 2\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 10\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 4\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI1222 08:04:21.331934 17693 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=4\r\n[INFO 2017-12-22 08:04:21,345 layers.py:2696] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-22 08:04:21,347 layers.py:3264] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-22 08:04:21,347 layers.py:7436] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2017-12-22 08:04:21,348 layers.py:2696] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-22 08:04:21,348 layers.py:3264] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2017-12-22 08:04:21,349 layers.py:7436] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI1222 08:04:21.697677 17693 GradientMachine.cpp:94] Initing parameters..\r\nI1222 08:04:23.947732 17693 GradientMachine.cpp:101] Init parameters done.\r\n\r\n.Exception in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 153, in flush_worker\r\n    sample = in_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: got end of file during message\r\n```\r\n\r\nneed to set something ?",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "zh794390558",
        "created_at": "2017-12-22T08:15:09+00:00",
        "updated_at": "2021-05-12T06:23:50+00:00",
        "closed_at": "2021-05-12T06:23:50+00:00",
        "comments_count": [
            "kuke",
            "witkeyshare",
            "kuke",
            "fantasyoooo",
            "fantasyoooo",
            "wuqi930907"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 98,
        "title": "demo_client.py IOError: [Errno -9996] Invalid input device (no default output device)",
        "body": "/usr/bin/python2.7 /media/justin/新加卷1/deepspeech/DeepSpeech/deploy/demo_client.py\r\nTraceback (most recent call last):\r\n  File \"/media/justin/新加卷1/deepspeech/DeepSpeech/deploy/demo_client.py\", line 94, in <module>\r\n    main()\r\n  File \"/media/justin/新加卷1/deepspeech/DeepSpeech/deploy/demo_client.py\", line 79, in main\r\n    stream_callback=callback)\r\n  File \"build/bdist.linux-x86_64/egg/pyaudio.py\", line 750, in open\r\n    stream = Stream(self, *args, **kwargs)\r\n  File \"build/bdist.linux-x86_64/egg/pyaudio.py\", line 441, in __init__\r\n    self._stream = pa.open(**arguments)\r\nIOError: [Errno -9996] Invalid input device (no default output device)\r\n\r\nProcess finished with exit code 1\r\n\r\n\r\nimport _portaudio as pa\r\npa.get_version()\r\n1246720L\r\npa.get_version_text()\r\nu'PortAudio V19.6.0-devel, revision 396fe4b6699ae929d3a685b3ef8a7e97396139a4'\r\npa.get_device_count()\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\nIOError: [Errno -10000] PortAudio not initialized\r\npa.initialize()\r\npa.get_device_count()\r\n0L\r\n\r\nPyAudio  _version__ = \"0.2.11\"\r\n\r\nanyone tell me why?\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "zh794390558",
        "created_at": "2017-12-23T06:34:36+00:00",
        "updated_at": "2021-05-12T06:23:43+00:00",
        "closed_at": "2021-05-12T06:23:43+00:00",
        "comments_count": [
            "kuke",
            "Arch-gx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 100,
        "title": "BaiduEN8k Model Configuration",
        "body": "I was wondering if you could document what configuration of the network was used for training the released baidu 8k model?",
        "state": "closed",
        "user": "ryanleary",
        "closed_by": "zh794390558",
        "created_at": "2017-12-28T04:52:31+00:00",
        "updated_at": "2021-05-12T06:23:37+00:00",
        "closed_at": "2021-05-12T06:23:37+00:00",
        "comments_count": [
            "pkuyym",
            "kenyeung128",
            "pkuyym",
            "kenyeung128",
            "pkuyym",
            "ryanleary",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 97,
        "title": "DeepSpeech 交流QQ群，欢迎加入共同交流学习",
        "body": "",
        "state": "closed",
        "user": "witkeyshare",
        "closed_by": "kuke",
        "created_at": "2017-12-22T08:16:46+00:00",
        "updated_at": "2017-12-22T09:02:54+00:00",
        "closed_at": "2017-12-22T09:02:54+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 101,
        "title": "关于librispeech的数据",
        "body": "hi,以前我是使用你们发布的模型进行使用的，我注意到，librispeech的manifest是分类的，比如train分为manifest.train-clean-100,manifest.train-clean-360之类的。而train.py是使用manifest.train这个数据的，你们是把train的三种文件合一了吗？就是说，你们是使用librispeech的train-clean-100，train-clean-360，test-other三种数据共960小时的数据进行训练的吗？那么dev文件也是这样处理的吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-28T06:10:42+00:00",
        "updated_at": "2017-12-28T06:48:39+00:00",
        "closed_at": "2017-12-28T06:48:39+00:00",
        "comments_count": [
            "pkuyym",
            "yyhlvdl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 103,
        "title": "ubantu14.04下swig_decoder安装错误",
        "body": "",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-28T08:19:25+00:00",
        "updated_at": "2017-12-28T08:53:50+00:00",
        "closed_at": "2017-12-28T08:26:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 102,
        "title": "Live Demo - how does it process real-time audio.",
        "body": "I am wondering how the live demo works.\r\nIf I say \"Today I am going to the supermarket to buy some beer\", then does the live demo record the whole sentence then do the inference step (speech to text), or does it do that for smaller chunks (For example, \"Today I am\", then \"going to the supermarket\", and so on) ?",
        "state": "closed",
        "user": "vucuong12",
        "closed_by": "vucuong12",
        "created_at": "2017-12-28T06:11:52+00:00",
        "updated_at": "2017-12-28T06:26:56+00:00",
        "closed_at": "2017-12-28T06:26:56+00:00",
        "comments_count": [
            "yyhlvdl",
            "vucuong12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 106,
        "title": "Training details of the downloadable librispeech model",
        "body": "Hi, \r\n\r\nI am using the trained **librispeech model** from below link for inferencing. \r\nhttps://github.com/PaddlePaddle/DeepSpeech#speech-model-released  \r\n\r\nWhere can i get the training details for the model like \r\nhardware used for training the model,\r\nnumber of epochs trained,\r\ntime taken for training the model \r\n\r\nThanks\r\n",
        "state": "closed",
        "user": "jayiind",
        "closed_by": "zh794390558",
        "created_at": "2018-01-04T05:41:24+00:00",
        "updated_at": "2021-02-03T07:31:11+00:00",
        "closed_at": "2021-02-03T07:31:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 108,
        "title": "zhidao_giga.klm 与 zh_giga.no_cna_cmn.prune01244.klm、baidu_cn1.2k_model.tar.gz下载几十M后就失败了，有其他下载链接吗？",
        "body": "zhidao_giga.klm 与 zh_giga.no_cna_cmn.prune01244.klm、baidu_cn1.2k_model.tar.gz下载几十M后就失败了，有其他下载链接吗？",
        "state": "closed",
        "user": "ganzhong007",
        "closed_by": "ganzhong007",
        "created_at": "2018-01-05T02:55:51+00:00",
        "updated_at": "2018-01-05T03:29:08+00:00",
        "closed_at": "2018-01-05T03:29:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 104,
        "title": "寻求关于训练参数的建议",
        "body": "@pkuyym \r\n你好，我最近想自己训练下模型，就是用librispeech的数据。因为硬件关系，我只好把batchsize改成16，不是你们最初的256了，那么epoch和迭代率等参数应该改成多少，可以给我一些建议吗？因为实验室硬件稀缺，我不好多次调整参数，只好麻烦你们了。\r\n  ",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-03T09:59:06+00:00",
        "updated_at": "2018-01-03T12:36:25+00:00",
        "closed_at": "2018-01-03T12:36:25+00:00",
        "comments_count": [
            "pkuyym",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 105,
        "title": "询问一下关于硬件的信息",
        "body": "@pkuyym\r\n不好意思，再次打扰了。昨天，我开始训练，然而我只能让持续时间少于11s的librispeech的语音数据进入训练，这样的话，只有将近8万条语音进入训练，而不是你们使用的将近29万语音。我注意到，在readme中，你们是使用6-7s的语音来验证多gpu加速的性能。那么，可以告诉我，你们做librispeech的时候，使用的硬件的具体信息吗？最低配置就可以，因为实验室实在是没办法为我一个人就花费那么大的资金，更不可能去不断试不同的配置，只能向你们请求一下，我们可以一次性配置好。只要尽可能的让持续时间更长的语音数据进入训练，我就满足了，可以给我些建议吗？(深度学习果然首先是看硬件的)\r\n  ",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-04T02:18:42+00:00",
        "updated_at": "2018-01-04T07:17:50+00:00",
        "closed_at": "2018-01-04T07:17:50+00:00",
        "comments_count": [
            "kuke",
            "yyhlvdl",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl",
            "pkuyym",
            "yyhlvdl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 107,
        "title": "PaddlePaddle新年大礼！周边产品送不停！",
        "body": "各位亲爱的PaddlePaddle用户：\r\n\r\n2017年已经过去，感谢你们一直陪伴PaddlePaddle在深度学习领域共同成长，无论是应用、贡献、还是review、纠错；每一个人的付出对于PaddlePaddle都是至关重要的。**值此新年，PaddlePaddle准备了一批周边小礼物赠送给各位，与各位一同迎接更好的2018！PaddlePaddle，一起加油！**\r\n\r\n**周边礼物领取方式如下：**\r\n请各位使用者、贡献者将**如下信息**发到PaddlePaddle-TechWriter@baidu.com\r\n**【“姓名“+“github账号名” +“周边礼物快递邮寄地址”+”快递联系电话“+”定制卫衣号码（S：160，M：165，L：170，XL：175，xxL：180）“】** →发到PaddlePaddle-TechWriter@baidu.com\r\n我们会根据邮件中的地址为您送上PaddlePaddle周边礼物一份。\r\n您也可以同时回复此issue-”你对PaddlePaddle的祝福和嘱咐“或“PaddlePaddle，一起加油！”来提醒我们查收您的邮件。\r\n\r\n# 礼物内容如下：\r\n每位发送邮件的用户都能获得PaddlePaddle**礼袋一个，内置“LOGO卫衣+贴纸+纪念小徽章“**\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556980-9ed91f42-f173-11e7-974c-e0db65314868.png)\r\n\r\n\r\n# 重要贡献用户随机加发下列周边产品之一：\r\n## PaddlePaddle定制款-膳魔师保温水杯\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556983-a3bcbed8-f173-11e7-9c0c-7fe35348b0c7.png)\r\n\r\n## PaddlePaddle定制款-机械键盘\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556989-a9dc7c4a-f173-11e7-80d0-5af5ec9f2a20.png)\r\n\r\n\r\n## PaddlePaddle定制款-树莓派\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34557019-d4f113e6-f173-11e7-9489-265ac6ba207b.png)\r\n\r\n# 如有其他疑问，可以直接回复本issue~~感谢大家的支持！",
        "state": "closed",
        "user": "angelashane",
        "closed_by": "zh794390558",
        "created_at": "2018-01-04T09:25:34+00:00",
        "updated_at": "2021-02-03T07:30:40+00:00",
        "closed_at": "2021-02-03T07:30:40+00:00",
        "comments_count": [
            "gdfspy",
            "fedoral",
            "witkeyshare",
            "wanghaolw",
            "suBoMan",
            "qianlongchen",
            "Des-yangzi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 109,
        "title": "Error related to GPU when running example script for librispeech",
        "body": "Hi, I got the following error when running the librispeech examples.\r\n\r\nI use cuDNN v5.5\r\n\r\nCUDA_VISIBLE_DEVICES=0,1,2,3\r\n\r\n(paddle-env) alim@ctc3:~/paddle-deepspeech/examples/librispeech$ sh run_train.sh \r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/librispeech/manifest.dev-clean\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/librispeech/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/libri\r\nrnn_layer_size: 512\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/librispeech/manifest.train\r\ntrainer_count: 30\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/librispeech/vocab.txt\r\n------------------------------------------------\r\nI0105 17:36:05.526255 27647 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=30 \r\n[INFO 2018-01-05 17:36:10,822 layers.py:2689] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-05 17:36:10,824 layers.py:3251] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-05 17:36:10,825 layers.py:7409] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-05 17:36:10,826 layers.py:2689] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-05 17:36:10,827 layers.py:3251] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-05 17:36:10,828 layers.py:7409] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nF0105 17:36:10.859037 27647 hl_gpu_matrix_kernel.cuh:181] Check failed: cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed] CUDA error: invalid\r\n device function\r\n*** Check failure stack trace: ***\r\n    @     0x7fb7341cabcd  google::LogMessage::Fail()\r\n    @     0x7fb7341ce67c  google::LogMessage::SendToLog()\r\n    @     0x7fb7341ca6f3  google::LogMessage::Flush()\r\n    @     0x7fb7341cfb8e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fb73403f3eb  hl_gpu_apply_unary_op<>()\r\n    @     0x7fb73403f75d  paddle::BaseMatrixT<>::applyUnary<>()\r\n    @     0x7fb73403f9a3  paddle::BaseMatrixT<>::zero()\r\n    @     0x7fb733fde375  paddle::GpuMatrix::zeroMem()\r\n    @     0x7fb733ec8e72  paddle::BatchNormBaseLayer::init()\r\n    @     0x7fb733e820c1  paddle::CudnnBatchNormLayer::init()\r\n    @     0x7fb733ed3d7f  paddle::NeuralNetwork::init()\r\n    @     0x7fb733ef9506  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @     0x7fb733efdd7f  paddle::GradientMachine::create()\r\n    @     0x7fb7341a7495  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7fb7341a767f  GradientMachine::createByConfigProtoStr()\r\n    @     0x7fb733d84717  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x568b3a  (unknown)\r\n    @           0x4c2604  (unknown)\r\n    @           0x4d1c5c  (unknown)\r\n    @           0x55f6db  (unknown)\r\n    @           0x5244dd  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx    \r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\nrun_train.sh: line 33: 27647 Aborted                 (core dumped) CUDA_VISIBLE_DEVICES=0,1,2,3 python -u train.py --batch_size=16 --trainer_count=30 --num_passes=50 --num_proc_data=16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=512 --num_iter_print=100 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=True --is_local=True --share_rnn_weights=True --train_manifest='data/librispeech/manifest.train' --dev_manifest='data/librispeech/manifest.dev-clean' --mean_std_path='data/librispeech/mean_std.npz' --vocab_path='data/librispeech/vocab.txt' --output_model_dir='./checkpoints/libri' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training\r\n\r\n(paddle-env) alim@ctc3:~/paddle-deepspeech/examples/librispeech$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Sun_Sep__4_22:14:01_CDT_2016\r\nCuda compilation tools, release 8.0, V8.0.44\r\n\r\n(paddle-env) alim@ctc3:~/paddle-deepspeech/examples/librispeech$ nvidia-smi \r\nFri Jan  5 17:38:35 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 24%   45C    P2    44W / 180W |   1117MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 1080    Off  | 00000000:03:00.0 Off |                  N/A |\r\n| 24%   36C    P8     8W / 180W |     10MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 1080    Off  | 00000000:81:00.0 Off |                  N/A |\r\n| 24%   36C    P8     7W / 180W |     10MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 1080    Off  | 00000000:82:00.0 Off |                  N/A |\r\n| 24%   45C    P2   134W / 180W |   2438MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     27612      C   nnet3-chain-train                           1107MiB |\r\n|    3     27473      C   nnet3-chain-train                           1159MiB |\r\n|    3     27479      C   nnet3-chain-train                           1269MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\nAny suggestion?\r\n\r\nThanks,\r\nAlim",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "misbullah",
        "created_at": "2018-01-05T09:48:42+00:00",
        "updated_at": "2018-01-06T05:40:29+00:00",
        "closed_at": "2018-01-06T05:40:29+00:00",
        "comments_count": [
            "misbullah",
            "yyhlvdl",
            "misbullah"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 110,
        "title": "deepspeech或者paddle中的确存在内存泄露的问题",
        "body": "我的模型不是和deepspeech2完全一致，用了一些别的层，训练过程中，第一个epoch是按照语音文件持续时间从大到小来进入batch的，然而程序占用内存越来越大，最后崩溃。也许是deepspeech的问题，也许是paddle的问题，必须说的是，我是在deepspeech：latest-gpu的docker中运行的。\r\n  ",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-08T11:54:38+00:00",
        "updated_at": "2018-01-08T13:48:04+00:00",
        "closed_at": "2018-01-08T13:48:04+00:00",
        "comments_count": [
            "yyhlvdl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 111,
        "title": "Failed to download Mandarin LM",
        "body": "Hi,\r\n\r\nI tried to download the Mandarin LM from the following link:\r\n\r\nSmall: http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e \r\nLarger: http://cloud.dlnel.org/filepub/?uuid=245d02bb-cd01-4ebe-b079-b97be864ec37\r\n\r\nBut, it failed. I tried it many times from different network.\r\n\r\nIn the beginning, it can download well, but it will be stopped after a while or some MB of size. It always happened like that.\r\n \r\nDo you have any suggestion?\r\n\r\nThanks,\r\nAlim",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "misbullah",
        "created_at": "2018-01-08T14:30:16+00:00",
        "updated_at": "2018-01-11T09:18:20+00:00",
        "closed_at": "2018-01-11T09:18:20+00:00",
        "comments_count": [
            "yyhlvdl",
            "misbullah",
            "kuke",
            "BookGin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 112,
        "title": "epoch的问题",
        "body": "@pkuyym \r\ndeepspeech训练模型的第一个epoch是按照语音数据持续时间大小进行训练的。然而，在我进行亲自训练的时候出现了问题(我是按照readme中的docker模式进行的)，在第一个epoch结束后，程序并不会开始下一个epoch，事实上，它卡在那里不动了。然后把gpu内存撑爆，这就是前段时间我一直怀疑的内存泄露的问题。\r\nPass: 0, Batch: 1, TrainCost: 93.167046\r\nPass: 0, Batch: 2, TrainCost: 95.089401\r\nPass: 0, Batch: 3, TrainCost: 83.036194\r\nPass: 0, Batch: 4, TrainCost: 80.692101\r\nPass: 0, Batch: 5, TrainCost: 67.172005\r\nPass: 0, Batch: 6, TrainCost: 55.272041\r\nPass: 0, Batch: 7, TrainCost: 54.719227\r\nPass: 0, Batch: 8, TrainCost: 48.882935\r\nPass: 0, Batch: 9, TrainCost: 52.184387\r\nPass: 0, Batch: 10, TrainCost: 35.945839\r\nPass: 0, Batch: 11, TrainCost: 37.550327\r\nPass: 0, Batch: 12, TrainCost: 37.640144\r\nPass: 0, Batch: 13, TrainCost: 37.709978\r\nF0109 01:49:19.022586   845 hl_cuda_device.cc:273] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory\r\n*** Check failure stack trace: ***\r\n    @     0x7f9687cd504d  google::LogMessage::Fail()\r\n    @     0x7f9687cd7398  google::LogMessage::SendToLog()\r\n    @     0x7f9687cd4b5b  google::LogMessage::Flush()\r\n    @     0x7f9687cd826e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f9687c7da9f  hl_malloc_device()\r\n    @     0x7f9687ad17c7  paddle::GpuAllocator::alloc()\r\n    @     0x7f9687abe458  paddle::PoolAllocator::alloc()\r\n    @     0x7f9687abde33  paddle::GpuMemoryHandle::GpuMemoryHandle()\r\n    @     0x7f9687a1d30b  paddle::GemmConvFunction<>::calc()\r\n    @     0x7f96878b30f8  paddle::ExpandConvLayer::forward()\r\n    @     0x7f96879629ff  paddle::NeuralNetwork::forward()\r\n    @     0x7f968796f92c  paddle::TrainerThread::forward()\r\n    @     0x7f96879731c8  paddle::TrainerThread::computeThread()\r\n    @     0x7f96d6b5cc80  (unknown)\r\n    @     0x7f96dd17e6ba  start_thread\r\n    @     0x7f96dceb43dd  clone\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n要说明的是，我使用的是librispeech的0s到1.5s共103个数据，batch_size是8，在batch13后，理论上是应该进入下一个epoch的，然而出现上面的错误，程序卡住，直到让内存崩溃。\r\n  然后，我将data.py中的这段代码注释掉，   #if self._epoch == 0 and sortagrad:\r\n            #    manifest.sort(key=lambda x: x[\"duration\"])\r\n            #else:\r\n它依然出现了上面的问题。可以帮我解决一下吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-09T01:52:42+00:00",
        "updated_at": "2018-01-09T03:34:28+00:00",
        "closed_at": "2018-01-09T03:03:07+00:00",
        "comments_count": [
            "pkuyym",
            "yyhlvdl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 113,
        "title": "无法安装，一直提示ImportError: No module named swig_decoders",
        "body": "import swig_decoders\r\n后，一直提示\r\nImportError: No module named swig_decoders\r\n\r\n也没有说具体的原因",
        "state": "closed",
        "user": "angenge",
        "closed_by": "zh794390558",
        "created_at": "2018-01-09T10:16:40+00:00",
        "updated_at": "2022-07-05T10:42:08+00:00",
        "closed_at": "2021-02-03T07:26:33+00:00",
        "comments_count": [
            "kuke",
            "gdfspy",
            "harold-yh",
            "fantasyoooo",
            "fantasyoooo",
            "fantasyoooo",
            "beyondboy",
            "fantasyoooo",
            "kvinwang",
            "bolt163",
            "seiriosPlus",
            "kaijien",
            "sunjunlishi",
            "OttoOu",
            "ben-8878"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 114,
        "title": "Failed to train LibriSpeech using example script.",
        "body": "Hi, I tried to train model using all LibriSpeech dataset (960H) with data augmentation. I use 2 GPU GTX 1080. After Pass 10, I got the following error.\r\n\r\nI0110 17:18:34.314939 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_4__.w0 need clipping by local threshold=400, max grad\r\n=1.86242e+09, avg grad=7.7372e+07\r\nI0110 17:18:34.315071 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_4__.wbias need clipping by local threshold=400, max g\r\nrad=2.21661e+09, avg grad=7.25256e+07\r\nI0110 17:18:34.319563 47267 FirstOrderOptimizer.cpp:321] parameter=___recurrent_layer_4__.w0 need clipping by local threshold=400, max\r\n grad=4.5849e+09, avg grad=7.94203e+06\r\nI0110 17:18:34.319880 47267 FirstOrderOptimizer.cpp:321] parameter=___recurrent_layer_4__.wbias need clipping by local threshold=400,\r\nmax grad=2.21661e+09, avg grad=7.25256e+07\r\n.I0110 17:18:34.418779 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_0__.w0 need clipping by local threshold=400, max gra\r\nd=942.53, avg grad=156.387\r\nI0110 17:18:34.418969 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_0__.wbias need clipping by local threshold=400, max g\r\nrad=1613.23, avg grad=205.539\r\nI0110 17:18:34.419972 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_1__.w0 need clipping by local threshold=400, max grad\r\n=1028.06, avg grad=339.691\r\nI0110 17:18:34.420138 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_1__.wbias need clipping by local threshold=400, max g\r\nrad=1713.61, avg grad=505.019\r\nI0110 17:18:34.426007 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_2__.w0 need clipping by local threshold=400, max grad\r\n=905.969, avg grad=26.9515\r\nI0110 17:18:34.426167 47267 FirstOrderOptimizer.cpp:321] parameter=___batch_norm_2__.wbias need clipping by local threshold=400, max g\r\nrad=1077.66, avg grad=32.965\r\nI0110 17:18:34.430650 47267 FirstOrderOptimizer.cpp:321] parameter=___recurrent_layer_0__.w0 need clipping by local threshold=400, max\r\n grad=2006.8, avg grad=1.30195\r\nI0110 17:18:34.430976 47267 FirstOrderOptimizer.cpp:321] parameter=___recurrent_layer_0__.wbias need clipping by local threshold=400,\r\nmax grad=1071.72, avg grad=31.856\r\n.*** Aborted at 1515575915 (unix time) try \"date -d @1515575915\" if you are using GNU date ***                               [37/1957]\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7fc03283ad89) received by PID 47267 (TID 0x7fc0b121c740) from PID 847490441; stack trace: ***\r\n    @     0x7fc0b0e11330 (unknown)\r\n    @     0x7fc03283ad89 paddle::GpuVectorT<>::getAbsMax()\r\n    @     0x7fc032afbef6 paddle::OptimizerWithGradientClipping::update()\r\n    @     0x7fc032ae1ddd paddle::SgdThreadUpdater::updateImpl()\r\n    @     0x7fc03299ed51 ParameterUpdater::update()\r\n    @     0x7fc03257a336 _wrap_ParameterUpdater_update\r\n    @           0x52714b PyEval_EvalFrameEx\r\n    @           0x555551 PyEval_EvalCodeEx\r\n    @           0x525560 PyEval_EvalFrameEx\r\n    @           0x555551 PyEval_EvalCodeEx\r\n    @           0x524338 PyEval_EvalFrameEx\r\n    @           0x555551 PyEval_EvalCodeEx\r\n    @           0x524338 PyEval_EvalFrameEx\r\n    @           0x555551 PyEval_EvalCodeEx\r\n    @           0x525560 PyEval_EvalFrameEx\r\n    @           0x555551 PyEval_EvalCodeEx\r\n    @           0x525560 PyEval_EvalFrameEx\r\n    @           0x567d14 (unknown)\r\n    @           0x465bf4 PyRun_FileExFlags\r\n    @           0x46612d PyRun_SimpleFileExFlags\r\n    @           0x466d92 Py_Main\r\n    @     0x7fc0b0a59f45 __libc_start_main\r\n    @           0x577c2e (unknown)\r\n    @                0x0 (unknown)\r\nrun_train.sh: line 35: 47267 Floating point exception(core dumped) CUDA_VISIBLE_DEVICES=0,2 python -u train.py --init_model_path='/var\r\n/nlp/alim/paddle-deepspeech/checkpoints/libri/params.latest.tar.gz' --batch_size=16 --trainer_count=2 --num_passes=20 --num_proc_data=\r\n16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --learning_rate=5e-4 --max_duration=27.0 --min_du\r\nration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=True --is_local=True --share_rnn_weights=True --train_manif\r\nest='data/librispeech/manifest.train' --dev_manifest='data/librispeech/manifest.dev-clean' --mean_std_path='data/librispeech/mean_std.\r\nnpz' --vocab_path='data/librispeech/vocab.txt' --output_model_dir='./checkpoints/libri' --augment_conf_path='conf/augmentation.config'\r\n --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training!\r\n\r\nAny suggestion?\r\n\r\nThanks,\r\nAlim\r\n  ",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "zh794390558",
        "created_at": "2018-01-10T10:21:50+00:00",
        "updated_at": "2021-05-12T06:23:31+00:00",
        "closed_at": "2021-05-12T06:23:31+00:00",
        "comments_count": [
            "kuke",
            "misbullah",
            "kuke",
            "misbullah",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 115,
        "title": "试了en8k，识别率真不错！但有个问题...",
        "body": "params.tar.gz能继续训练其它语音数据吗？还是要等DeepSpeech3？\r\n",
        "state": "closed",
        "user": "gdfspy",
        "closed_by": "gdfspy",
        "created_at": "2018-01-11T02:21:53+00:00",
        "updated_at": "2018-01-11T06:31:53+00:00",
        "closed_at": "2018-01-11T06:31:53+00:00",
        "comments_count": [
            "kuke",
            "gdfspy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 116,
        "title": "demo_server用cn 1.2k推荐什么配置？",
        "body": "我用虚拟机 8G内存，预热那个步骤就非常慢，要10几分钟，还识别不出任何内容，是内存少吗？",
        "state": "closed",
        "user": "gdfspy",
        "closed_by": "zh794390558",
        "created_at": "2018-01-11T02:24:26+00:00",
        "updated_at": "2021-05-12T06:23:24+00:00",
        "closed_at": "2021-05-12T06:23:24+00:00",
        "comments_count": [
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "pkuyym",
            "gdfspy",
            "MrCuiHao",
            "Ckj409399",
            "sunjunlishi",
            "dxhgq-github",
            "ccbptm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 117,
        "title": "tools/tune.py感觉没有根据最新的data.py进行更新",
        "body": "在我用tune.py进行调节参数的时候，出现这样的错误：KeyError: u'sequence_offset'，于是我就自己修改了文件，运行。这里提醒一下这个bug,当然，也可能是我自己修改了太多东西，很可能哪里不协调，而官网的本来是协调的。\r\n",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-12T03:36:25+00:00",
        "updated_at": "2018-01-13T07:11:06+00:00",
        "closed_at": "2018-01-13T07:11:06+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 119,
        "title": "Mandarin LM  query speed is very slow",
        "body": "I have tried the chinese language Model (zh_giga.no_cna_cmn.prune01244.klm) in decoding process,but the speed is very slow,nearly 2 seconds per sample, how can i speed this?",
        "state": "closed",
        "user": "zhaoningning",
        "closed_by": "zh794390558",
        "created_at": "2018-01-12T11:38:20+00:00",
        "updated_at": "2021-05-12T06:23:11+00:00",
        "closed_at": "2021-05-12T06:23:11+00:00",
        "comments_count": [
            "pkuyym",
            "zhaoningning",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 118,
        "title": "Aishell testing data benchmark",
        "body": "Hi, \r\n\r\nToday, I did evaluation using different models (AM and LM). Plese see the following table.\r\n\r\n![image](https://user-images.githubusercontent.com/385009/34866348-48658200-f7b7-11e7-930a-a80fe8cb225b.png)\r\n\r\nI reduce sampling rate to be 8000 Hz when doing test for BaiduCN1.2k model because I think the model was trained using 8000 Hz dataset.\r\n\r\nQuestion:\r\n1. Why I get very worse result for BaiduCN1.2K? (As we know the model was trained using larger training data than AISHELL and the model parameter also larger than AISHELL model?\r\n2. How to use tune.py to find good tuning parameter for alpha and beta?\r\n   I cannot find any examples for the python code?\r\n\r\nThanks,\r\nAlim",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "zh794390558",
        "created_at": "2018-01-12T08:44:15+00:00",
        "updated_at": "2021-05-12T06:23:17+00:00",
        "closed_at": "2021-05-12T06:23:17+00:00",
        "comments_count": [
            "pkuyym",
            "misbullah",
            "zhaoningning",
            "misbullah",
            "DmytroSytro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 120,
        "title": "Missing num_conv_layers in data_generator (tune.py)",
        "body": "Hi,\r\n\r\nI found that there is an issue in tune.py when call DataGenerator function as shown in below.\r\n\r\n    data_generator = DataGenerator(\r\n        vocab_filepath=args.vocab_path,\r\n        mean_std_filepath=args.mean_std_path,\r\n        augmentation_config='{}',\r\n        specgram_type=args.specgram_type,\r\n        num_threads=args.num_proc_data,\r\n        keep_transcription_text=True,\r\n        num_conv_layers=args.num_conv_layers)\r\n\r\nThere is no argument for num_conv_layers in DataGenerator (data_utils/data.py)\r\n\r\nThanks,\r\nAlim",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "kuke",
        "created_at": "2018-01-12T11:55:24+00:00",
        "updated_at": "2018-01-15T06:42:14+00:00",
        "closed_at": "2018-01-15T06:42:14+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 123,
        "title": "Aborted at 1515694750 (unix time) try \"date -d @1515694750\" if you are using GNU date",
        "body": "系统环境：Ubuntu 16.04,使用的两块GTX 1080TI显卡，内存32G，SWAP：800G\r\n\r\n参照aishell脚本训练自己的语音和标注数据，训练结束时报错：\r\n...................................................................................................\r\nPass: 18, Batch: 100, TrainCost: 70.923850\r\n............................................................................\r\n------- Time: 759 sec,  Pass: 18, ValidationCost: 131.906596488\r\n...................................................................................................\r\nPass: 19, Batch: 100, TrainCost: 70.486890\r\n............................................................................\r\n------- Time: 754 sec,  Pass: 19, ValidationCost: 106.161569876\r\n*** Aborted at 1515694750 (unix time) try \"date -d @1515694750\" if you are using GNU date ***\r\n\r\n使用的参数如下：\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 8\r\ndev_manifest: data/numbers/manifest.dev\r\ninit_model_path: checkpoints/numbers/params.pass-19.tar.gz\r\nis_local: 1\r\nlearning_rate: 1e-06\r\nmax_duration: 27.0\r\nmean_std_path: data/numbers/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 5\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/numbers\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/numbers/manifest.train\r\ntrainer_count: 2\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/numbers/vocab.txt\r\n------------------------------------------------",
        "state": "closed",
        "user": "harold-yh",
        "closed_by": "zh794390558",
        "created_at": "2018-01-13T03:11:25+00:00",
        "updated_at": "2024-07-30T02:14:07+00:00",
        "closed_at": "2021-05-12T06:23:04+00:00",
        "comments_count": [
            "kuke",
            "harold-yh",
            "s11e22",
            "iamadog3333",
            "pkuyym",
            "xguo-prestolabs"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 121,
        "title": "Decouple ext scorer init & inference & decoding for the convenience of tuning",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-01-12T13:34:19+00:00",
        "updated_at": "2018-01-15T06:42:14+00:00",
        "closed_at": "2018-01-15T06:42:14+00:00",
        "comments_count": [
            "misbullah"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 124,
        "title": "inference in real time",
        "body": "There is any plans to publish a real time streaming code that performs like google api?\r\nDo you think I will able to use the pertained model and execute inference fast enough? \r\n\r\n\r\nThanks!",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-01-14T16:43:04+00:00",
        "updated_at": "2021-05-12T06:22:58+00:00",
        "closed_at": "2021-05-12T06:22:58+00:00",
        "comments_count": [
            "yyhlvdl",
            "alanbekker",
            "yyhlvdl",
            "kuke",
            "alanbekker",
            "kuke",
            "alanbekker",
            "kuke",
            "Slyne"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 127,
        "title": "Download the Docker image不了..",
        "body": "root@amax-SYS-7048GR-TR:/data# nvidia-docker pull paddlepaddle/deep_speech:latest-gpu\r\nError response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\r\n实验室服务器用的是移动的宽带,连接不了怎么办..\r\n是被墙了么..",
        "state": "closed",
        "user": "fantasyoooo",
        "closed_by": "fantasyoooo",
        "created_at": "2018-01-17T11:55:10+00:00",
        "updated_at": "2018-01-17T12:18:46+00:00",
        "closed_at": "2018-01-17T12:18:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 125,
        "title": "用docker编译paddlepaddle出错..",
        "body": "用docker编译paddlepaddle出错..\r\n错误是\r\n[ERROR]\tUpdate failed for golang.org/x/net: Cannot detect VCS\r\n[ERROR]\tUpdate failed for google.golang.org/grpc: Cannot detect VCS\r\n[ERROR]\tFailed to install: Cannot detect VCS\r\n.\r\n.\r\n.\r\n[ 63%] Linking CXX static library libexpand_op.a\r\ncpplint: Checking source code style\r\nDone processing expand_op.cc\r\nDone processing expand_op.cu\r\nDone processing /paddle/paddle/operators/expand_op.h\r\nTotal errors found: 0\r\n[ 63%] Built target expand_op\r\nmake: *** [all] Error 2\r\nMakefile:160: recipe for target 'all' failed",
        "state": "closed",
        "user": "fantasyoooo",
        "closed_by": "fantasyoooo",
        "created_at": "2018-01-16T12:29:00+00:00",
        "updated_at": "2018-01-17T11:55:59+00:00",
        "closed_at": "2018-01-17T11:55:59+00:00",
        "comments_count": [
            "pkuyym",
            "fantasyoooo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 129,
        "title": "指定gpu的使用",
        "body": "hi,我最近在训练模型。我们实验室有4个gpu，我只能使用其中的3个，然而，我在train.py中设置train counter为3后，它自动选择编码为0，1，2的gpu，然而，我只能使用1，2，3的gpu，有什么方法可以设置吗？",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2018-01-19T14:41:58+00:00",
        "updated_at": "2018-01-20T04:42:24+00:00",
        "closed_at": "2018-01-20T04:42:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 126,
        "title": "感谢，如果用DeepSpeech做孤立词识别，有没有比较好的建议，从数据准备到模型训练等",
        "body": "感谢百度对开源所作的贡献，我们现在尝试在做孤立词识别，用过CMU、HTK、Kaldi，也用过DNN等算法模型，都是自己准备数据，自己训练模型，但是效果却不是很理想，貌似现在的平台更擅长做连续语音识别，当然我们目前的研究依然十分浅薄，望能指点一二，谢谢！",
        "state": "closed",
        "user": "wanghaolw",
        "closed_by": "zh794390558",
        "created_at": "2018-01-17T02:12:43+00:00",
        "updated_at": "2021-05-12T06:22:51+00:00",
        "closed_at": "2021-05-12T06:22:51+00:00",
        "comments_count": [
            "kuke",
            "wanghaolw",
            "zhouyikang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 128,
        "title": "Context window width-  feed forward question",
        "body": "Let's assume my audio segment consists of 8000 samples at 16khz (0.5sec)\r\nIn the preprocessing stage using a sliding window of 20msec and stride of 10msec I receive 50 different spectrograms..you can reach this number by yourself (500msec/10msec=50)\r\n\r\nWhen I run prediction I can see that the softmax output consist of 17 distribution vectors.\r\n\r\nWhy 17? I assume this is a result of context window width of +-1 (and then 50/3=~17), but I have no reference that the context width indeed is +-1..can someone correct point out a reference for this or correct me?\r\n\r\nThanks in advance!\r\n\r\n",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-01-17T16:04:52+00:00",
        "updated_at": "2021-05-12T06:22:44+00:00",
        "closed_at": "2021-05-12T06:22:44+00:00",
        "comments_count": [
            "pkuyym",
            "alanbekker",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 130,
        "title": "demo server error -  ValueError: No such parameter ___recurrent_layer_0__.w0",
        "body": "I got this error when running CUDA_VISIBLE_DEVICES=0 python deploy/demo_server.py with baidu_en8k. Here is command output. Could someone help?\r\n\r\nml@tesla1a:~/Paddle/DeepSpeech$ CUDA_VISIBLE_DEVICES=0 python deploy/demo_server.py\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/baidu_en8k/mean_std.npz\r\nmodel_path: models/baidu_en8k/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: False\r\nvocab_path: models/baidu_en8k/vocab.txt\r\nwarmup_manifest: data/librispeech/manifest.test-clean\r\n------------------------------------------------\r\nI0119 13:57:54.665096 60035 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1\r\n[INFO 2018-01-19 13:57:59,480 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-19 13:57:59,482 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-19 13:57:59,483 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-19 13:57:59,484 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-19 13:57:59,485 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-19 13:57:59,486 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-19 13:58:04,793 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-01-19 13:58:17,973 model.py:253] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2018-01-19 13:58:18,154 model.py:254] end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'/home/ml/.cache/paddle/dataset/speech/libri/test-clean/LibriSpeech/test-clean/7176/92135/7176-92135-0025.flac')\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 217, in <module>\r\n    main()\r\n  File \"deploy/demo_server.py\", line 213, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 196, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 135, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 171, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/ml/Paddle/DeepSpeech/deploy/../model_utils/model.py\", line 193, in infer_batch_probs\r\n    output_layer=self._log_probs, parameters=self._parameters)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/inference.py\", line 63, in __init__\r\n    val.copyFromNumpyArray(parameters.get(name).flatten())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 242, in get\r\n    return self.__getitem__(key=parameter_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n    return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 153, in __getter_inner\r\n    shape = self.get_shape(key)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 200, in get_shape\r\n    raise ValueError(\"No such parameter %s\" % key)\r\nValueError: No such parameter ___recurrent_layer_0__.w0\r\n",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "lightsailpro",
        "created_at": "2018-01-19T18:59:15+00:00",
        "updated_at": "2018-09-27T11:56:05+00:00",
        "closed_at": "2018-01-22T12:53:24+00:00",
        "comments_count": [
            "yyhlvdl",
            "lightsailpro",
            "lightsailpro",
            "18811737901"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 131,
        "title": "log10(0) in rms_db(self)",
        "body": "in data_utils/audio.py  the method self.rms_db() computes:\r\n mean_square = np.mean(self._samples**2)\r\n return 10 * np.log10(mean_square)\r\n\r\nand at inference time in on elf my utterances: self._samples is a vector of zeros therefore the np.log10(mean_square)\r\nobviously cause a core dump..any ideas how to treat this?\r\n\r\n1.This makes sense receiving self._samples is a vector of zeros?\r\n2. which epsilon do you recommend to add in order to avoid this in  np.log10(mean_square+epsilon) and not harm the preprocessing stage?",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-01-21T16:04:00+00:00",
        "updated_at": "2021-02-03T07:30:19+00:00",
        "closed_at": "2021-02-03T07:30:19+00:00",
        "comments_count": [
            "pkuyym",
            "alanbekker"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 132,
        "title": "incorporate hints in the decoding phase",
        "body": "I'm trying to implement hints in the decoding phase..any ideas or suggestions how to implement this?\r\n\r\nThanks!",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-01-22T17:26:06+00:00",
        "updated_at": "2021-05-12T06:22:35+00:00",
        "closed_at": "2021-05-12T06:22:35+00:00",
        "comments_count": [
            "kuke",
            "alanbekker",
            "kuke",
            "alanbekker"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 135,
        "title": "changing the ctc_beam_search_decoder.cpp function",
        "body": "I wonder maybe you have a main.cpp function which you used to debug ctc_beam_search_decoder.cpp function.\r\n\r\nI would like to change thectc_beam_search_decoder.cpp and need ability to debug the changes with breakpoint...any ideas how to do so?",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-01-24T09:00:26+00:00",
        "updated_at": "2021-05-12T06:22:19+00:00",
        "closed_at": "2021-05-12T06:22:19+00:00",
        "comments_count": [
            "kuke",
            "alanbekker"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 133,
        "title": "maximum length of audio clip that can be transcribed using en8k model",
        "body": "I tested the en8k model using the demo server. For longer audio clips e.g. 28 seconds of wave file, it seems that only last 10 seconds or so of the wave file got transcribed. The 1st 18 seconds just got discarded. Does anyone know why?",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "zh794390558",
        "created_at": "2018-01-22T22:15:22+00:00",
        "updated_at": "2021-05-12T06:22:26+00:00",
        "closed_at": "2021-05-12T06:22:26+00:00",
        "comments_count": [
            "kuke",
            "viig99"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 134,
        "title": "something strange in aishell database downloading",
        "body": "Hi , i meet a mistake\r\ni try to run the aishell baseline,\r\nwhen it broke down like the reason of out of memory , i continue to run again,\r\nthe program shows the following error:\r\n\r\n[INFO 2018-01-23 08:08:02,503 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-01-23 08:08:02,666 model.py:253] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2018-01-23 08:08:02,667 model.py:254] end initializing scorer\r\n[INFO 2018-01-23 08:08:02,667 test.py:98] start evaluation ...\r\nProcess Process-3:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 134, in order_handle_worker\r\n    result = mapper(sample)\r\n  File \"/DeepSpeech/data_utils/data.py\", line 280, in <lambda>\r\n    lambda instance: self.process_utterance(instance[\"audio_filepath\"], instance[\"text\"]),\r\n  File \"/DeepSpeech/data_utils/data.py\", line 115, in process_utterance\r\n speech_segment = SpeechSegment.from_file(filename, transcript)\r\n  File \"/DeepSpeech/data_utils/speech.py\", line 50, in from_file\r\n    audio = AudioSegment.from_file(filepath)\r\n  File \"/DeepSpeech/data_utils/audio.py\", line 71, in from_file\r\n    samples, sample_rate = soundfile.read(file, dtype='float32')\r\n  File \"/usr/local/lib/python2.7/dist-packages/soundfile.py\", line 373, in read\r\n    subtype, endian, format, closefd) as f:\r\n  File \"/usr/local/lib/python2.7/dist-packages/soundfile.py\", line 740, in __init__\r\n self._file = self._open(file, mode_int, closefd)\r\n  File \"/usr/local/lib/python2.7/dist-packages/soundfile.py\", line 1265, in _open\r\n    \"Error opening {0!r}: \".format(self.name))\r\n  File \"/usr/local/lib/python2.7/dist-packages/soundfile.py\", line 1455, in _error_check\r\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\r\nRuntimeError: Error opening u'/root/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/train/S0002/BAC009S0002W0213.wav': System error.\r\nand so on ..\r\n\r\nif i want to  keep running the program, aishell database has to be re-downloaded..\r\nI have encountered this situation many times ..\r\nthe path i use is \r\n\r\nSaving to: '/root/.cache/paddle/dataset/speech/Aishell/data_aishell.tgz'\r\ndata_aishell.tgz    100%[===================>]  14.51G  2.16MB/s    in 2h 30m  \r\n\r\nIt costs a lot of time\r\nAt the same time , the libri/tiny do not have a similar situation..\r\nWhat is the cause of this problem? I am very confused..\r\n\r\n\r\n",
        "state": "closed",
        "user": "Willoiron",
        "closed_by": "Willoiron",
        "created_at": "2018-01-23T08:34:51+00:00",
        "updated_at": "2018-01-27T11:41:38+00:00",
        "closed_at": "2018-01-27T11:41:38+00:00",
        "comments_count": [
            "pkuyym",
            "Willoiron"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 137,
        "title": "aishell cn model, different results between warm test and demo client",
        "body": "I run the demo_server using aisheill model and test data. The demo_server.py has the following, basically save the uploaded wave file with sample rate 8000. But the \"Warm up test\" and demo client got different result with the exact same wave file ( \"以前我们国家一直提出保护艾滋病病人的隐私\" vs \"你们我们国家一直保护令病人的隐私\"). Is this because wave format conversion? What should I do in order to duplicate the warm test result?\r\n\r\n----------------------------------------------\r\n       # write to wav file\r\n        file = wave.open(out_filename, 'wb')\r\n        file.setnchannels(1)\r\n        file.setsampwidth(4)\r\n        file.setframerate(8000)\r\n--------------------------------- \r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'/home/ml/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/train/S0722/BAC009S0722W0187.wav')\r\nResponse Time: 0.691690, Transcript: 以前我们国家一直提出保护艾滋病病人的隐私\r\n\r\n----------------------------------------------------------------------------------\r\n\"\"\"test client\"\"\"\r\nimport struct\r\nimport socket\r\nimport sys\r\nimport argparse\r\nimport wave  \r\n\r\ndata_list = []\r\n\r\nwaveFile = wave.open('/home/ml/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/train/S0722/BAC009S0722W0187.wav', 'rb')\r\ndata = waveFile.readframes(waveFile.getnframes())\r\ndata_list.append(data)\r\n\r\nif len(data_list) > 0:\r\n        # Connect to server and send data\r\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\n        sock.connect((\"192.168.1.16\", 8086))\r\n        sent = ''.join(data_list)\r\n        sock.sendall(struct.pack('>i', len(sent)) + sent)\r\n        print('Speech[length=%d] Sent.' % len(sent))\r\n        # Receive data from the server and shut down\r\n        received = sock.recv(1024)\r\n        print \"Recognition Results: {}\".format(received)\r\n        sock.close()\r\n        data_list = []\r\n\r\n\r\nSpeech[length=146784] Sent.\r\nRecognition Results: 你们我们国家一直保护令病人的隐私\r\n---------------------------------------------------------",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "zh794390558",
        "created_at": "2018-01-24T16:52:45+00:00",
        "updated_at": "2021-05-12T06:22:06+00:00",
        "closed_at": "2021-05-12T06:22:06+00:00",
        "comments_count": [
            "pkuyym",
            "lightsailpro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 136,
        "title": "Floating point exception in ctc_beam_search_decoder",
        "body": "Error in \r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/edaed68f33b7fff2455c26b880340ba680621f5c/decoders/swig/ctc_beam_search_decoder.cpp#L137\r\nwhen decoding using beam search. \r\n\r\n[INFO 2018-01-24 14:29:35,342 model.py:244] begin to initialize the external scorer for decoding\r\n[INFO 2018-01-24 14:29:35,439 model.py:255] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2018-01-24 14:29:35,439 model.py:256] end initializing scorer. Start decoding ...\r\n*** Aborted at 1516804178 (unix time) try \"date -d @1516804178\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7fe13bdd2f36) received by PID 8361 (TID 0x7fe12114b700) from PID 1004351286; stack trace: ***\r\n    @     0x7fe16d7e4390 (unknown)\r\n    @     0x7fe13bdd2f36 PathTrie::iterate_to_vec()\r\n    @     0x7fe13bdd2ed8 PathTrie::iterate_to_vec()\r\n    @     0x7fe13bdc8992 ctc_beam_search_decoder()\r\n    @     0x7fe13bdc9bd7 std::_Function_handler<>::_M_invoke()\r\n    @     0x7fe13bdc9589 std::__future_base::_State_baseV2::_M_do_set()\r\n    @     0x7fe16d7e1a99 __pthread_once_slow\r\n    @     0x7fe13bdc98ef std::__future_base::_Task_state<>::_M_run()\r\n    @     0x7fe13bdcac11 _ZNSt6thread5_ImplISt12_Bind_simpleIFZN10ThreadPoolC4EmEUlvE_vEEE6_M_runEv\r\n    @     0x7fe14b51ac80 (unknown)\r\n    @     0x7fe16d7da6ba start_thread\r\n    @     0x7fe16d5103dd clone\r\n    @                0x0 (unknown)\r\n\r\nFloating point exception (core dumped)\r\n\r\nThe model is trained on an internal mandarin speech dataset.\r\n\r\n\r\ntrainer_count = 1\r\nbeam_size = 500\r\nnum_proc_bsearch = 8\r\nnum_proc_data = 8\r\nnum_conv_layers = 2\r\nnum_rnn_layers = 3\r\nrnn_layer_size = 2048\r\nalpha = 1.0\r\nbeta = 2.329\r\ncutoff_prob = 1.0\r\ncutoff_top_n = 40\r\nuse_gru = True\r\nuse_gpu = True\r\nshare_rnn_weights = False\r\nlang_model_path = '/mnt/models/lm/zh_giga.no_cna_cmn.prune01244.klm'\r\ndecoding_method = 'ctc_beam_search'\r\nerror_rate_type = 'cer'\r\nspecgram_type = 'linear'\r\n",
        "state": "closed",
        "user": "neozhangthe1",
        "closed_by": "zh794390558",
        "created_at": "2018-01-24T14:40:47+00:00",
        "updated_at": "2021-05-12T06:22:12+00:00",
        "closed_at": "2021-05-12T06:22:12+00:00",
        "comments_count": [
            "kuke",
            "fancyerii"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 138,
        "title": "What is the rtf(real time rate) of DS2 in paddle?",
        "body": "rt",
        "state": "closed",
        "user": "beyondboy",
        "closed_by": "beyondboy",
        "created_at": "2018-01-27T17:10:51+00:00",
        "updated_at": "2018-01-30T16:48:59+00:00",
        "closed_at": "2018-01-30T16:48:59+00:00",
        "comments_count": [
            "kuke",
            "beyondboy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 143,
        "title": "empty",
        "body": "rt",
        "state": "closed",
        "user": "brainbpe",
        "closed_by": "brainbpe",
        "created_at": "2018-01-31T09:23:37+00:00",
        "updated_at": "2018-01-31T12:02:31+00:00",
        "closed_at": "2018-01-31T12:02:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 139,
        "title": "mac下运行run_train.sh运行报错",
        "body": "paddle版本为当前最新，\r\nuse_gpu已经设置为0\r\n```\r\nsh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI0128 15:36:36.402436 2102243328 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=1\r\n[INFO 2018-01-28 15:36:36,413 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-28 15:36:36,414 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-28 15:36:36,414 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-01-28 15:36:36,415 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-28 15:36:36,416 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-01-28 15:36:36,417 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0128 15:36:36.737751 2102243328 GradientMachine.cpp:94] Initing parameters..\r\nI0128 15:36:37.935442 2102243328 GradientMachine.cpp:101] Init parameters done.\r\nF0128 15:36:42.101572 2102243328 DynamicLoader.cpp:104] Check failed: nullptr != *dso_handle Failed to find dynamic library: /usr/local/cuda/lib/libwarpctc.dylib (dlopen(/usr/local/cuda/lib/libwarpctc.dylib, 5): image not found)\r\nPlease specify its path correctly using following ways:\r\nMethod. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.\r\nFor instance, issue command: export LD_LIBRARY_PATH=...\r\nNote: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled.\r\n*** Check failure stack trace: ***\r\n    @        0x1082062cd  google::LogMessage::Flush()\r\n    @        0x10820a54f  google::LogMessageFatal::~LogMessageFatal()\r\n    @        0x108207189  google::LogMessageFatal::~LogMessageFatal()\r\n    @        0x1084ccaaf  GetDsoHandleFromSearchPath()\r\n    @        0x1084ccc1e  GetWarpCTCDsoHandle()\r\n    @     0x7fff8ce266e9  std::__1::__call_once()\r\n    @        0x10854b1e9  hl_warpctc_init()\r\n    @        0x108221383  paddle::WarpCTCLayer::forward()\r\n    @        0x1082e273e  paddle::NeuralNetwork::forward()\r\n    @        0x1082d5783  paddle::GradientMachine::forwardBackward()\r\n    @        0x10854e7d6  GradientMachine::forwardBackward()\r\n    @        0x1081e666e  _wrap_GradientMachine_forwardBackward()\r\n    @        0x101b11562  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\n    @        0x101b144ae  _PyEval_SliceIndex\r\n    @        0x101b1130c  PyEval_EvalFrameEx\r\n    @        0x101b0e3c1  PyEval_EvalCodeEx\r\nrun_train.sh: line 33: 61758 Abort trap: 6           python -u train.py --batch_size=16 --trainer_count=1 --num_passes=20 --num_proc_data=1 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --num_iter_print=100 --learning_rate=1e-5 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=False --is_local=True --share_rnn_weights=True --train_manifest='data/tiny/manifest.tiny' --dev_manifest='data/tiny/manifest.tiny' --mean_std_path='data/tiny/mean_std.npz' --vocab_path='data/tiny/vocab.txt' --output_model_dir='./checkpoints/tiny' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFail in training!\r\n```",
        "state": "closed",
        "user": "bushidonggua",
        "closed_by": "zh794390558",
        "created_at": "2018-01-28T07:41:51+00:00",
        "updated_at": "2021-05-12T06:22:00+00:00",
        "closed_at": "2021-05-12T06:22:00+00:00",
        "comments_count": [
            "pkuyym",
            "kuke",
            "bushidonggua",
            "kuke",
            "bushidonggua",
            "xiaolvtaomi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 141,
        "title": "Floaing point exception in demo_server.py",
        "body": "warmup_manifest: ../models/baidu_en8k/manifest.test-clean\r\n------------------------------------------------\r\n-----------------------------------------------------------\r\nWarming up ...\r\n-----------------------------------------------------------\r\nASR Server Started.\r\nReceived utterance[length=61440] from 14.143.40.242, saved to demo_cache/20180129074345_14.143.40.242.wav.\r\nResponse Time: 10.588990, Transcript:\r\nReceived utterance[length=196608] from 14.143.40.242, saved to demo_cache/20180129074401_14.143.40.242.wav.\r\n*** Aborted at 1517211841 (unix time) try \"date -d @1517211841\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7f407961fbc3) received by PID 29663 (TID 0x7f407a70a700) from PID 2036464579; stack trace: ***\r\n    @     0x7f407a2ed390 (unknown)\r\n    @     0x7f407961fbc3 log10f\r\n    @     0x7f406c7843a5 PyUFunc_f_f\r\n    @     0x7f406c8817dc trivial_two_operand_loop\r\n    @     0x7f406c889ec4 PyUFunc_GenericFunction\r\n    @     0x7f406c88a585 ufunc_generic_call\r\n    @           0x4b0c93 PyObject_Call\r\n    @           0x4c9f9f PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4de69e (unknown)\r\n    @           0x4b0c93 PyObject_Call\r\n    @           0x4b0901 PyObject_CallFunction\r\n    @           0x4b01bc _PyObject_GenericGetAttrWithDict\r\n    @           0x4c442c PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4ca088 PyEval_EvalFrameEx\r\n@           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4ca088 PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4ca7df PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4ca7df PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4ca7df PyEval_EvalFrameEx\r\n    @           0x4c9d7f PyEval_EvalFrameEx\r\n    @           0x4c2705 PyEval_EvalCodeEx\r\n    @           0x4de69e (unknown)\r\n    @           0x4b0c93 PyObject_Call\r\n    @           0x4f452e (unknown)\r\n    @           0x4b0c93 PyObject_Call\r\n    @           0x4ce540 PyEval_CallObjectWithKeywords\r\n    @           0x4e15b4 PyInstance_New\r\n\r\n\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "zh794390558",
        "created_at": "2018-01-29T07:47:35+00:00",
        "updated_at": "2021-05-12T06:21:54+00:00",
        "closed_at": "2021-05-12T06:21:54+00:00",
        "comments_count": [
            "pkuyym",
            "cogmeta",
            "philiptzou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 140,
        "title": "服务器跑aishell过程中存在的error",
        "body": "您好,我在单个NV M40 12GB 显卡上面跑aishell ,用的是nvidia-docker运行, batch_size从默认的64改成了24,连续两次试着跑aishell都在第15个epoch结束的时候出现了下面的这个问题:\r\nPass: 15, Batch: 4700, TrainCost: 0.866109\r\n...................................................................................................\r\nPass: 15, Batch: 4800, TrainCost: 0.982023\r\n...................................................................................................\r\nPass: 15, Batch: 4900, TrainCost: 0.861112\r\n...................................................................................................\r\nPass: 15, Batch: 5000, TrainCost: 0.930983\r\n...Exception in thread Thread-32:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 153, in flush_worker\r\n    sample = in_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: got end of file during message\r\n\r\nProcess Process-822:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-830:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-819:\r\nProcess Process-815:\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nProcess Process-828:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nIOError: [Errno 104] Connection reset by peer\r\n.\r\n.\r\n.\r\n请问这个问题是..?",
        "state": "closed",
        "user": "Willoiron",
        "closed_by": "Willoiron",
        "created_at": "2018-01-29T04:26:46+00:00",
        "updated_at": "2018-01-30T04:23:00+00:00",
        "closed_at": "2018-01-30T04:23:00+00:00",
        "comments_count": [
            "pkuyym",
            "Willoiron",
            "Willoiron"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 142,
        "title": "GPU memory leak with demo_server and demo_client?",
        "body": "I am testing the demo_server and demo_client with the en8k model. I noticed that the GPU (K40c with 12G ram) ram consumption kept increasing with each use of then client. Is this normal? I worry that GPU will run out ram after certain amount of calls.",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "lightsailpro",
        "created_at": "2018-01-29T13:53:01+00:00",
        "updated_at": "2018-01-31T15:02:01+00:00",
        "closed_at": "2018-01-31T15:02:01+00:00",
        "comments_count": [
            "kuke",
            "lightsailpro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 144,
        "title": "Process audio data directly from buffer instead of writing to file",
        "body": ">> feature = data_generator.process_utterance(filename, \"\")\r\n\r\nIs there a way to process utterance directly from the buffer without writing first to file and then passing the file as an argument?",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2018-02-01T01:36:45+00:00",
        "updated_at": "2018-02-05T14:42:13+00:00",
        "closed_at": "2018-02-01T16:12:43+00:00",
        "comments_count": [
            "cogmeta",
            "pkuyym",
            "cogmeta",
            "cogmeta",
            "cogmeta",
            "cogmeta",
            "lightsailpro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 145,
        "title": "Find a bug in data_utils/audio.py",
        "body": "    def superimpose(self, other):\r\n        if isinstance(other, type(self)):\r\n            raise TypeError(\"Cannot add segments of different types: %s \"\r\n                            \"and %s.\" % (type(self), type(other)))\r\n\r\nShould be \"if not isinstance(other, type(self)):\" ?",
        "state": "closed",
        "user": "cbtpkzm",
        "closed_by": "zh794390558",
        "created_at": "2018-02-01T09:04:32+00:00",
        "updated_at": "2021-05-12T06:21:47+00:00",
        "closed_at": "2021-05-12T06:21:47+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 147,
        "title": "can I enlarge the size of characters in the vocab.txt of the existing model?",
        "body": "I have tried  to use BaiduCN1.2k Model as initial  model to train model using Aishell Dataset(already coverted to 8k) , but there are some characters which are not included in the vocab.txt. I wonder how to enlarge the size of characters.",
        "state": "closed",
        "user": "onlywordding",
        "closed_by": "zh794390558",
        "created_at": "2018-02-02T12:49:10+00:00",
        "updated_at": "2021-05-12T06:21:41+00:00",
        "closed_at": "2021-05-12T06:21:41+00:00",
        "comments_count": [
            "pkuyym",
            "onlywordding"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 146,
        "title": "Check failed: mapGet(type, creatorMap_, &creator) ",
        "body": "probs_split = self.ds2_model.infer_batch_probs( ....  is throwing following error\r\n\r\nF0202 12:26:05.674350 28466 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: data\r\n*** Check failure stack trace: ***\r\n\r\nAny idea what is going wrong?",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2018-02-02T12:29:49+00:00",
        "updated_at": "2018-02-02T12:36:54+00:00",
        "closed_at": "2018-02-02T12:36:54+00:00",
        "comments_count": [
            "cogmeta",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 152,
        "title": "DataGenerator.process_utterance does not accept file object",
        "body": "The docstring says filename accepts `basestring` or `file`. But it do not accept `file` actually.\r\n```python\r\n    def process_utterance(self, filename, transcript):\r\n        \"\"\"Load, augment, featurize and normalize for speech data.\r\n\r\n        :param filename: Audio filepath\r\n        :type filename: basestring | file\r\n```",
        "state": "closed",
        "user": "kvinwang",
        "closed_by": "pkuyym",
        "created_at": "2018-02-06T08:52:11+00:00",
        "updated_at": "2018-02-07T12:53:15+00:00",
        "closed_at": "2018-02-07T12:53:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 148,
        "title": "mac下run_train.sh内存占用持续增加，有泄漏？",
        "body": "我想用自己的语料来训练DeepSpeech， 训练过程系统内存占用持续增高，直至交换文件把磁盘撑爆。\r\n但是python进程本身的内存占用又没有增加，不知道是哪里吃的内存。\r\n```\r\n(paddle)loong@MacBook-Pro:~/l/lab/py/ml/baidu/wav on master$ sh run_train.sh \r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: arg.config\r\nbatch_size: 4\r\ndev_manifest: data/manifest.train\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 5e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 40\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./models\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/manifest.train\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/vocab.txt\r\n------------------------------------------------\r\nI0202 21:40:14.468683 2907198400 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=1 \r\n[INFO 2018-02-02 21:40:14,484 layers.py:2689] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-02-02 21:40:14,485 layers.py:3251] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-02-02 21:40:14,487 layers.py:7409] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-02-02 21:40:14,488 layers.py:2689] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-02-02 21:40:14,490 layers.py:3251] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-02-02 21:40:14,493 layers.py:7409] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0202 21:40:14.751354 2907198400 GradientMachine.cpp:94] Initing parameters..\r\nI0202 21:40:15.287204 2907198400 GradientMachine.cpp:101] Init parameters done.\r\n```\r\n![1](https://loongw.github.io/assets/train-1.png)\r\n![2](https://loongw.github.io/assets/train-2.png)\r\n![3](https://loongw.github.io/assets/train-3.png)\r\n",
        "state": "closed",
        "user": "kvinwang",
        "closed_by": "pkuyym",
        "created_at": "2018-02-02T14:57:35+00:00",
        "updated_at": "2019-07-04T08:39:30+00:00",
        "closed_at": "2018-05-22T05:20:35+00:00",
        "comments_count": [
            "kuke",
            "kvinwang",
            "kuke",
            "kvinwang",
            "kvinwang",
            "kuke",
            "kvinwang",
            "kuke",
            "kvinwang",
            "kvinwang",
            "kenyeung128",
            "kuke",
            "kvinwang",
            "kvinwang",
            "kvinwang",
            "kvinwang",
            "fangmingbnu",
            "tai960519073",
            "tai960519073"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 155,
        "title": "greedy && beam search ",
        "body": "fixed",
        "state": "closed",
        "user": "mixcoder",
        "closed_by": "mixcoder",
        "created_at": "2018-02-08T10:31:07+00:00",
        "updated_at": "2018-02-09T03:16:32+00:00",
        "closed_at": "2018-02-09T03:16:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 149,
        "title": "nvidia-docker跑demo训练程序出错",
        "body": "我用nvidia-docker（sudo nvidia-docker run -it -v $(pwd)/DeepSpeech:/DeepSpeech paddlepaddle/deep_speech:latest-gpu /bin/bash）在8块显卡上跑训练程序DeepSpeech/aishell/run_train.sh，出错了，请问这是怎么回事？代码一点没有改\r\n\r\nPass: 9, Batch: 1500, TrainCost: 1.245488\r\n...................................................................................................\r\nPass: 9, Batch: 1600, TrainCost: 1.278968\r\n...................................................................................................\r\nPass: 9, Batch: 1700, TrainCost: 1.278138\r\n...................................................................................................\r\nPass: 9, Batch: 1800, TrainCost: 1.370887\r\n...........................................................................\r\n------- Time: 2829 sec, Pass: 9, ValidationCost: 1.88582897921\r\n...................................................................................................Exception in thread Thread-21:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\nself.run()\r\nFile \"/usr/lib/python2.7/threading.py\", line 754, in run\r\nself.__target(*self.__args, **self.__kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 153, in flush_worker\r\nsample = in_queue.get()\r\nFile \"\", line 2, in get\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n\r\nPass: 10, Batch: 100, TrainCost: 0.892535\r\n.....................................Process Process-376:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-373:\r\nProcess Process-372:\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nself.run()\r\nIOError: [Errno 104] Connection reset by peer\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nProcess Process-367:\r\nself._target(*self._args, **self._kwargs)\r\nTraceback (most recent call last):\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nProcess Process-371:\r\nTraceback (most recent call last):\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nEOFError\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nkind, result = conn.recv()\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nEOFError\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nEOFError\r\nProcess Process-374:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nProcess Process-368:\r\nTraceback (most recent call last):\r\nwhile order_id != out_order[0]:\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 138, in order_handle_worker\r\nkind, result = conn.recv()\r\nout_order[0] += 1\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nProcess Process-365:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nkind, result = conn.recv()\r\nEOFError\r\nProcess Process-375:\r\nIOError: [Errno 104] Connection reset by peer\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-364:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-369:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-370:\r\nProcess Process-377:\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself.run()\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-362:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 121, in order_read_worker\r\nin_queue.put((order_id, sample))\r\nFile \"\", line 2, in put\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nEOFError\r\nProcess Process-363:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-366:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nEOFError\r\nProcess Process-378:\r\nTraceback (most recent call last):\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nself.run()\r\nFile \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nself._target(*self._args, **self._kwargs)\r\nFile \"/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\nwhile order_id != out_order[0]:\r\nFile \"\", line 2, in getitem\r\nFile \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\nkind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer",
        "state": "closed",
        "user": "wuqi930907",
        "closed_by": "wuqi930907",
        "created_at": "2018-02-03T14:19:48+00:00",
        "updated_at": "2018-02-28T15:49:50+00:00",
        "closed_at": "2018-02-28T15:49:50+00:00",
        "comments_count": [
            "kuke",
            "wuqi930907",
            "kuke",
            "wuqi930907",
            "kvinwang",
            "wuqi930907",
            "kvinwang",
            "wuqi930907"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 151,
        "title": "Do I need to create my own Language Model if I generate a ASR model?",
        "body": "I used a data with 8000 Mandarin characters  to train a the DeepSpeech model. I wonder if I need to generate an own Language Model based on the data, or I can still use the baidu released Language Model?\r\n\r\nI also want to know what is the relationship between the 'vocab.txt' of the  DeepSpeech model and the Language Model?",
        "state": "closed",
        "user": "PHDZheng",
        "closed_by": "zh794390558",
        "created_at": "2018-02-05T04:52:00+00:00",
        "updated_at": "2021-05-12T06:21:28+00:00",
        "closed_at": "2021-05-12T06:21:28+00:00",
        "comments_count": [
            "kuke",
            "PHDZheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 150,
        "title": "improving location name (beijing, mumbai etc) recognition accuracy",
        "body": "The default model is horrible at recognising location names. Any idea how that can be improved? I tried with custom language models but the accuracy is not good. Any suggestions",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "zh794390558",
        "created_at": "2018-02-03T15:30:13+00:00",
        "updated_at": "2021-05-12T06:21:34+00:00",
        "closed_at": "2021-05-12T06:21:34+00:00",
        "comments_count": [
            "kuke",
            "cogmeta",
            "cogmeta",
            "kuke",
            "cogmeta",
            "cogmeta",
            "kuke",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 156,
        "title": "silence detection using cutoff on the acoustic probabilities",
        "body": "I'm using the recognizer for real time transcription and I've noticed that even when the user don't speak the recognizer outputs some gibberish characters...I assume I can fix it using some cutoff probability of the acoustic model right?\r\n\r\n",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-02-08T22:03:51+00:00",
        "updated_at": "2021-05-12T06:21:22+00:00",
        "closed_at": "2021-05-12T06:21:22+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 158,
        "title": "Is it possible to train from features file (MFCC) not wave files",
        "body": "Hi,\r\n\r\nHow to train the model in DeepSpeech if I only have the MFCC features from Kaldi Toolkit format?\r\nIs it possible?\r\n\r\nI can make the MFCC features to be readable.\r\n\r\nThanks.\r\nAlim",
        "state": "closed",
        "user": "misbullah",
        "closed_by": "zh794390558",
        "created_at": "2018-02-13T08:15:37+00:00",
        "updated_at": "2021-05-12T06:21:09+00:00",
        "closed_at": "2021-05-12T06:21:09+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 157,
        "title": "why low test WER on CHiME, training on librispeech Acoustic Model",
        "body": "Librispeech provides fairly large amounts of speech (960hour) which is recorded from various recording environment. So I expect training acoustic model on this corpus will also works for speech in another domain, such as CHiME-3.\r\n\r\nFor acoustic model, deepspeech model is trained with librispeech corpus.\r\nFor language model, 4-gram (from http://www.openslr.org/11/) is used.\r\n\r\nIt achieve 7.6% WER on test-clean, 24.8% WER on test-other.\r\n\r\nHowever, this model is not working to recognize CHiME-3 data.\r\n\r\nClean evaluation dataset got WER 64.2%, Cafe-noise evaluation dataset got 83.7% WER.\r\n\r\nWhat could be the possible reason for degradation?",
        "state": "closed",
        "user": "lifelongeek",
        "closed_by": "zh794390558",
        "created_at": "2018-02-13T02:53:23+00:00",
        "updated_at": "2021-05-12T06:21:15+00:00",
        "closed_at": "2021-05-12T06:21:15+00:00",
        "comments_count": [
            "kuke",
            "lifelongeek"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 159,
        "title": "send only audio features and not the audio data itself to the server for decoding ",
        "body": "We are wondering if it is possible to extract the audio features locally and then send only the features instead of audio data. Will that reduce the amount of data needed to send. In other end, is the feature data size significantly smaller than the audio data itself?\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2018-02-20T13:07:09+00:00",
        "updated_at": "2018-03-01T11:28:39+00:00",
        "closed_at": "2018-03-01T11:28:39+00:00",
        "comments_count": [
            "kuke",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 160,
        "title": "decoder giving partial transcripts",
        "body": "@kuke  Decoder gives partial transcripts once integrated with language model. While the greedy decoder gives full output . I used the scorer inside the swig wrapper . I suspect this is a common issue with decoder integrated with  lm. What can be the fix ??",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2018-02-22T15:59:54+00:00",
        "updated_at": "2021-05-12T06:17:08+00:00",
        "closed_at": "2021-05-12T06:17:08+00:00",
        "comments_count": [
            "kuke",
            "ghost",
            "ghost",
            "uzunovic"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 162,
        "title": "aishell预训练模型的结果糟糕",
        "body": "我使用 aishell的预训练模型做 python infer.py，超参数采用aishell/run_infer_golden.sh里面的值, 在aishell的数据集train, dev, test数据集上的平均 cer 各为  0.015873， 0.086128， 0.029167，识别结果比较好。但是当我使用自己的数据集进行测试的时候，识别结果非常糟糕，平均 cer 为 1.153333。 我使用的测试音频是 16k 采样率，16位的，\r\n[test_wavs_16k.zip](https://github.com/PaddlePaddle/DeepSpeech/files/1750830/test_wavs_16k.zip)\r\naishell 预训练模型的识别结果(lm 使用的zh_giga.no_cna_cmn.prune01244.klm)：\r\n        groundtruth label: 出租房屋的话收益如何\r\n        predict label: 澳洲房屋的话称如\r\n        Current error rate [cer] = 0.500000\r\n\r\n        groundtruth label: 我不太清楚地铁通吗\r\n        predict label: 偶然之后二十二日\r\n        Current error rate [cer] = 1.000000\r\n\r\n        groundtruth label: 有没有健身房之类的\r\n        predict label: 有的也不少一人的\r\n        Current error rate [cer] = 0.777778\r\n\r\n是有其他需要改动的地方吗？ 还是 aishell 模型不适用于该种数据集，finetune aishell的预训练模型会有帮助吗\r\n",
        "state": "closed",
        "user": "luweishuang",
        "closed_by": "zh794390558",
        "created_at": "2018-02-23T08:05:03+00:00",
        "updated_at": "2021-05-12T05:21:46+00:00",
        "closed_at": "2021-05-12T05:21:46+00:00",
        "comments_count": [
            "pkuyym",
            "luweishuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 161,
        "title": "How to create my own language model",
        "body": "I got issue to download Language mode\r\n ( http://cloud.dlnel.org/filepub/?uuid=d21861e4-4ed6-45bb-ad8e-ae417a43195e)\r\n as the file show its 2.x G in size, but i always can download file up to 1.x GB only,it didn't help even i add to hosts file.\r\n\r\n180.76.189.142  cloud.dlnel.org\r\n\r\nIs there any other alternative server i can download ?\r\n",
        "state": "closed",
        "user": "chesterkuo",
        "closed_by": "zh794390558",
        "created_at": "2018-02-23T07:23:14+00:00",
        "updated_at": "2021-05-12T06:17:01+00:00",
        "closed_at": "2021-05-12T06:17:01+00:00",
        "comments_count": [
            "chesterkuo",
            "kuke",
            "pkuyym",
            "chesterkuo",
            "chesterkuo",
            "chesterkuo",
            "chesterkuo",
            "chesterkuo",
            "pkuyym",
            "chesterkuo",
            "wujsy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 163,
        "title": "ctc_beam_search_decoder documentation",
        "body": "Do you have any documentation of ctc_beam_search_decoder.cpp?\r\n\r\nmore specifically: I wondering about score,ctc approx_ctc,log_prob_b_prev ,log_prob_nb_prev,log_prob_b_cur,log_prob_nb_cur parameters?\r\n\r\nCould you please explain each of them?\r\n\r\nThanks!",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-02-27T11:50:00+00:00",
        "updated_at": "2021-05-12T05:21:40+00:00",
        "closed_at": "2021-05-12T05:21:40+00:00",
        "comments_count": [
            "mrfox321"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 164,
        "title": "基于该项目可以构建一个纯c++的asr识别系统么？",
        "body": "项目需求，后续会有中文phoneme或者音节作为建模单元，需要引入wfst构图\r\n并且后面部署需要纯c++，有人能给些参考建议么？\r\n我目前的想法:\r\n1.声学模型inference部分,用paddle 的capi\r\n2.解码部分也方便可以换成c++的\r\n现在麻烦的是声学特征提取部分，都是基于python的，有等价的c++方案么？",
        "state": "closed",
        "user": "beyondboy",
        "closed_by": "beyondboy",
        "created_at": "2018-02-27T17:46:14+00:00",
        "updated_at": "2021-05-13T11:20:12+00:00",
        "closed_at": "2018-03-14T16:00:26+00:00",
        "comments_count": [
            "kuke",
            "Pelhans",
            "cogmeta",
            "zxk1995"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 167,
        "title": "TrainCost vs ValidationCost",
        "body": "Hi might i ask what's the TrainCost and ValidationCost during training, and what would be the optimal values for it?",
        "state": "closed",
        "user": "kenyeung128",
        "closed_by": "zh794390558",
        "created_at": "2018-03-04T14:54:58+00:00",
        "updated_at": "2021-05-12T05:21:26+00:00",
        "closed_at": "2021-05-12T05:21:26+00:00",
        "comments_count": [
            "luweishuang",
            "kenyeung128",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 166,
        "title": "训练集与测试集的音频时长需要严格相似？",
        "body": "我使用自己的数据集微调 baidu_cn1.2k中文模型， 训练音频是16k的采样率，训练集共7676个音频，平均时长为 3.01秒。测试集大小为56个，平均时长为 4.86秒。原始baidu_cn1.2k模型在该测试集上的 \r\n         Final error rate [cer] (56/56) = 0.148315，\r\n微调过后模型在同样测试集上的表现为：\r\n    groundtruth label: 他希望大家团结一致努力工作在新的一年里取得更大成绩\r\npredict label: 他是在家工作在一年期存款\r\nCurrent error rate [cer] = 18.000000\r\nError rate [cer] (10/56) = 0.857143\r\n\r\ngroundtruth label: 排在马路边的真假音像制品宣传牌引得过往行人驻足浏览\r\npredict label: 还在里边在今天工信息提前做\r\nCurrent error rate [cer] = 23.000000\r\nError rate [cer] (11/56) = 0.862963\r\n\r\ngroundtruth label: 据行家估计时下在欧美流行的苏格兰呢计有三十余种之多\r\npredict label: 今天在这里的人有多\r\nCurrent error rate [cer] = 21.000000\r\nFinal error rate [cer] (30/56) = 0.86101\r\n错误率显著上升且可以发现识别的文字结果变短了。是由于训练测试集数据集的音频时长不一致造成的吗? ",
        "state": "closed",
        "user": "luweishuang",
        "closed_by": "zh794390558",
        "created_at": "2018-02-28T06:43:51+00:00",
        "updated_at": "2021-05-12T05:21:33+00:00",
        "closed_at": "2021-05-12T05:21:33+00:00",
        "comments_count": [
            "pkuyym",
            "luweishuang",
            "pkuyym",
            "luweishuang",
            "sunjunlishi",
            "sunjunlishi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 168,
        "title": "only finetune last fc layer and other layers fixed",
        "body": "for leak of enough training data, I want to only finetune last fc layer params and other layers keep fixed by pretrained model. I do this by setting some layers in network.py, like this\r\n```\r\n     param_attr = paddle.attr.ParameterAttribute(is_static=True)\r\n\r\ndef conv_bn_layer(input, filter_size, num_channels_in, num_channels_out, stride,\r\n                  padding, act, index_range_data):\r\n   conv_layer = paddle.layer.img_conv(\r\n        input=input,\r\n        filter_size=filter_size,\r\n        num_channels=num_channels_in,\r\n        num_filters=num_channels_out,\r\n        stride=stride,\r\n        padding=padding,\r\n        act=paddle.activation.Linear(),\r\n        bias_attr=False,\r\n        param_attr=param_attr)\r\n    batch_norm = paddle.layer.batch_norm(input=conv_layer, act=act)\r\n    # reset padding part to 0\r\n    scale_sub_region = paddle.layer.scale_sub_region(batch_norm, index_range_data, value=0.0)\r\n    return scale_sub_region\r\n```\r\n\r\nbut when I run \"sh run_train.sh\"， I get the error\r\n![2018-03-06 13-54-22](https://user-images.githubusercontent.com/12368977/37016180-f001fa36-2145-11e8-948a-3293313c14e4.png)\r\nremove the is_static, the code will run successfully",
        "state": "closed",
        "user": "luweishuang",
        "closed_by": "zh794390558",
        "created_at": "2018-03-06T05:55:11+00:00",
        "updated_at": "2021-05-12T05:21:20+00:00",
        "closed_at": "2021-05-12T05:21:20+00:00",
        "comments_count": [
            "kuke",
            "viig99"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 172,
        "title": "Translation Plan-DeepSpeech2 on PaddlePaddle-英译汉",
        "body": "## 任务背景\r\n针对v2版本，目前我们已有很多中文使用文档，但仍有大量的汉译英工作及少量英译汉工作没有完成，我们希望将中英文版本补充完全，提升用户的阅读体验，也有益于国外用户在使用时查阅文档。\r\n此外，我们的模型库Models，仍有大部分英译汉和汉译英的工作，亟待完成。\r\n\r\n\r\n## 任务描述\r\n1. 需要做什么：\r\n把“DeepSpeech2 on PaddlePaddle”**英译汉**，中文名为“语音识别: DeepSpeech2”，请勿改动\r\n\r\n2. 地址\r\n- 英文地址： [Github地址](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/README.md)，网页地址暂无\r\n- 需要翻译的中文地址，暂无，可在英文版github下创建md文档\r\n\r\n\r\n## 如何认领\r\n我们欢迎大家积极认领，内部小伙伴请通过self assign的方式认领，外部小伙伴可通过在本issue下方comment认领。\r\n\r\n## 注意事项\r\n上交初稿的截止日期是2018年4月15日\r\n上交后，PaddlePaddle的RD会为大家review\r\n请于review后的5个工作日之内完成修改\r\n\r\n\r\n## 相关信息\r\n所有需要翻译的文档：\r\nV2使用文档：\r\nhttps://shimo.im/sheet/PqK407VYm80Ju3dw\r\nModels:\r\nhttps://shimo.im/sheet/6XTZnRQEUS0uC1Ut",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-03-13T02:05:17+00:00",
        "updated_at": "2018-06-04T02:20:54+00:00",
        "closed_at": "2018-06-04T02:20:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 169,
        "title": "memory leak ctc_beam_search_decoder",
        "body": "If I repeatedly call the swig decoder `ctc_beam_search_decoder,` I get a memory leak of around 10MB per iteration.\r\n```python\r\ndef score():\r\n\r\n    scorer = Scorer(alpha,beta,language_model_path,vocab)\r\n    best_path = ctc_beam_search_decoder(probs_seq2,vocab,beam_size,\r\n                                            cutoff_prob=cutoff_p,cutoff_top_n=cutoff_n,\r\n                                            ext_scoring_func=scorer)\r\n    print best_path[0][1]\r\n\r\nfor i in range(num_iter):\r\n    score()\r\n```\r\nHere is the memory profiler output after the first iteration:\r\n\r\n> Line     Mem usage    Increment   Line Contents\r\n================================================\r\n    21     35.6 MiB     35.6 MiB   @profile\r\n    22                                         def score():\r\n    23                             \r\n    24    878.4 MiB    842.7 MiB       scorer = Scorer(alpha,beta,language_model_path,vocab)\r\n    25    878.4 MiB      0.0 MiB       best_path = ctc_beam_search_decoder(probs_seq2,vocab,beam_size,\r\n    26    878.4 MiB      0.0 MiB                                               cutoff_prob=cutoff_p,cutoff_top_n=cutoff_n,\r\n    27    878.7 MiB      0.4 MiB                                               ext_scoring_func=scorer)\r\n    28    878.7 MiB      0.0 MiB       print best_path[0][1]\r\n\r\nand after N iterations:\r\n\r\n> Line #    Mem usage    Increment   Line Contents\r\n================================================\r\n    21   1446.4 MiB   1446.4 MiB   @profile\r\n    22                             def score():\r\n    23                             \r\n    24   2061.3 MiB    614.9 MiB       scorer = Scorer(alpha,beta,language_model_path,vocab)\r\n    25   2061.3 MiB      0.0 MiB       best_path = ctc_beam_search_decoder(probs_seq2,vocab,beam_size,\r\n    26   2061.3 MiB      0.0 MiB                                               cutoff_prob=cutoff_p,cutoff_top_n=cutoff_n,\r\n    27   2061.3 MiB      0.0 MiB                                               ext_scoring_func=scorer)\r\n    28   2061.3 MiB      0.0 MiB       print best_path[0][1]\r\n\r\nit seems that when I change the loop to:\r\n\r\n```python \r\nfor j in range(100):\r\n    scorer = Scorer(alpha,beta,language_model_path,vocab)\r\n    for i in range(num_iter):\r\n        score()\r\n\r\n    del scorer\r\n```\r\nThe memory leak occurs in the outer loop associated with the construction of the scorer.  The memory is roughly constant in each inner loop iteration.\r\n\r\nAdditionally, if I do not run `score(),` the construction of `scorer` does not leak.",
        "state": "closed",
        "user": "mrfox321",
        "closed_by": "zh794390558",
        "created_at": "2018-03-06T17:11:09+00:00",
        "updated_at": "2021-05-12T05:21:12+00:00",
        "closed_at": "2021-05-12T05:21:12+00:00",
        "comments_count": [
            "kuke",
            "mrfox321",
            "Engineering-Course",
            "mrfox321"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 171,
        "title": "a bug  in ctc beam search decoder",
        "body": "https://github.com/PaddlePaddle/DeepSpeech/blob/edaed68f33b7fff2455c26b880340ba680621f5c/decoders/swig/decoder_utils.cpp\r\nThe bug locates in line 30. It happens if you use **cutoff_top_n** but not **cutoff_prob** to prune log_probs of vocabulary. \r\nA correct version should be like this:\r\n`prob_idx = std::vector<std::pair<int, double>>(\r\n        prob_idx.begin(), prob_idx.begin() + (cutoff_top_n<cutoff_len)?cutoff_top_n:cutoff_len);` \r\n@kuke ",
        "state": "closed",
        "user": "kiddding",
        "closed_by": "zh794390558",
        "created_at": "2018-03-12T03:37:30+00:00",
        "updated_at": "2021-05-12T05:20:54+00:00",
        "closed_at": "2021-05-12T05:20:54+00:00",
        "comments_count": [
            "kuke",
            "kiddding"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 174,
        "title": "pip install  paddlepaddle-0.11.1a1-cp27-cp27mu-linux_x86_64.whl之后，找不到 Paddle，什么鬼。。。",
        "body": "",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "bolt163",
        "created_at": "2018-03-13T10:31:42+00:00",
        "updated_at": "2018-03-13T13:12:53+00:00",
        "closed_at": "2018-03-13T13:12:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 170,
        "title": "Ubuntu14.04 安装过程问题总结",
        "body": "",
        "state": "closed",
        "user": "seiriosPlus",
        "closed_by": "zh794390558",
        "created_at": "2018-03-12T03:04:07+00:00",
        "updated_at": "2021-05-12T05:21:02+00:00",
        "closed_at": "2021-05-12T05:21:02+00:00",
        "comments_count": [
            "seiriosPlus",
            "bolt163",
            "seiriosPlus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 173,
        "title": "Size of custom language model is very small compared to common_crawl_00.prune01111.trie.klm",
        "body": "Hi,\r\n\r\nI've created a language model using kenlm on common crawl data. The size of resultant output arpa is only 51Mb. The trained language model that you have provided is close to 8Gb in size which is also trained on common crawl dataset (common_crawl_00.prune01111.trie.klm). Could you tell why this could happen?\r\n\r\nCommand used to create the language model:\r\nbin/lmplz -o 5 --prune 01111 -T /datadrive/ -S 50% --text en.00.deduped --arpa en.00.deduped.arpa\r\n\r\nOutput:\r\n```\r\n=== 1/5 Counting and sorting n-grams ===\r\nReading /datadrive/speechexperiments/paddle/datasets/en.00.deduped.sadguru.processed\r\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n****************************************************************************************************\r\nUnigram tokens 9630074265 types 109380831\r\n=== 2/5 Calculating and sorting adjusted counts ===\r\nChain sizes: 1:1312569972 2:6413600768 3:12025502720 4:19240802304 5:28059504640\r\nStatistics:\r\n1 116081/109380831 D1=0.832246 D2=1.08381 D3+=1.25936\r\n2 641408/699725052 D1=0.817398 D2=1.02413 D3+=1.20664\r\n3 525936/2424418023 D1=0.843848 D2=1.08604 D3+=1.26471\r\n4 241171/4531878860 D1=0.894573 D2=1.15259 D3+=1.2933\r\n5 152819/5933461247 D1=0.898007 D2=1.2717 D3+=1.32749\r\nMemory estimate for binary LM:\r\ntype       kB\r\nprobing 38645 assuming -p 1.5\r\nprobing 47352 assuming -r models -p 1.5\r\ntrie    20622 without quantization\r\ntrie    12119 assuming -q 8 -b 8 quantization \r\ntrie    18450 assuming -a 22 array pointer compression\r\ntrie     9947 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n=== 3/5 Calculating and sorting initial probabilities ===\r\nChain sizes: 1:1392972 2:10262528 3:10518720 4:5788104 5:4278932\r\n=== 4/5 Calculating and writing order-interpolated probabilities ===\r\nChain sizes: 1:1392972 2:10262528 3:10518720 4:5788104 5:4278932\r\n=== 5/5 Writing ARPA model ===\r\nName:lmplz\tVmPeak:67678176 kB\tVmRSS:85464 kB\tRSSMax:67560500 kB\tuser:12830.9\tsys:2520.67\tCPU:15351.5\treal:15451.3\r\n\r\n```",
        "state": "closed",
        "user": "dalonlobo",
        "closed_by": "dalonlobo",
        "created_at": "2018-03-13T09:15:55+00:00",
        "updated_at": "2018-10-23T06:32:30+00:00",
        "closed_at": "2018-03-14T05:27:26+00:00",
        "comments_count": [
            "pkuyym",
            "dalonlobo",
            "dalonlobo",
            "sivagururaman"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 175,
        "title": "DeepSpeech 里面 setup.sh 安装swig_decoders报错的问题",
        "body": "https://github.com/PaddlePaddle/DeepSpeech\r\n参考这里  Paddle都安装好，包括相关的 c源码依赖包都已安好。。。执行  setup.sh的时候，\r\n\r\nkenlm/util/tokenize_piece.hh:8:46: fatal error: boost/iterator/iterator_facade.hpp: No such file or directory\r\n #include <boost/iterator/iterator_facade.hpp>\r\n                                              ^\r\ncompilation terminated.\r\nerror: command 'gcc' failed with exit status 1\r\n\r\nboost库安装了，在PATH里面也设定了 BOOST_ROOT\r\n手动进入  kenlm的安装目录下去make编译都能正常编过， 求大侠指点下这个问题\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "zh794390558",
        "created_at": "2018-03-14T06:29:24+00:00",
        "updated_at": "2021-05-12T05:20:42+00:00",
        "closed_at": "2021-05-12T05:20:42+00:00",
        "comments_count": [
            "kuke",
            "bolt163",
            "kuke",
            "bolt163",
            "bolt163",
            "kuke",
            "hui001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 176,
        "title": "examples目录下sh run_train.sh训练的时候，报这个错误是什么情况 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: cudnn_conv",
        "body": "机器上有GPU的， 是因为编译paddle的时候cmake传了   -DWITH_GPU=OFF的原因吗\r\n~/DeepSpeech/examples/aishell> sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 64\r\ndev_manifest: data/aishell/manifest.dev\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/aishell/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/aishell\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/aishell/manifest.train\r\ntrainer_count: 8\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\nI0314 21:29:46.475132 40531 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=8 \r\n[INFO 2018-03-14 21:29:46,487 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-14 21:29:46,488 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-14 21:29:46,489 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-14 21:29:46,490 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-14 21:29:46,490 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-14 21:29:46,491 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nF0314 21:29:46.509068 40531 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: cudnn_conv\r\n*** Check failure stack trace: ***\r\n    @     0x7f8b5119d99d  google::LogMessage::Fail()\r\n    @     0x7f8b511a1b5c  google::LogMessage::SendToLog()\r\n    @     0x7f8b5119d4c3  google::LogMessage::Flush()\r\n    @     0x7f8b511a25ae  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f8b50ec67cb  paddle::Layer::create()\r\n    @     0x7f8b50f6de48  _ZZN6paddle13NeuralNetwork4initERKNS_11ModelConfigESt8functionIFviPNS_9ParameterEEERKSt6vectorINS_19enumeration_wrapper13ParameterTypeESaISB_EEbENKUlRKNS_11LayerConfigEE_clESI_\r\n    @     0x7f8b50f6ed4f  paddle::NeuralNetwork::init()\r\n    @     0x7f8b50f7c7d9  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @     0x7f8b50f80f8f  paddle::GradientMachine::create()\r\n    @     0x7f8b5117a635  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7f8b5117a81f  GradientMachine::createByConfigProtoStr()\r\n    @     0x7f8b50e0a68d  _wrap_GradientMachine_createByConfigProtoStr\r\n    @     0x7f8ba5726412  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba57271f6  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba57271f6  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba56a38e8  function_call\r\n    @     0x7f8ba5673dc3  PyObject_Call\r\n    @     0x7f8ba568654f  instancemethod_call\r\n    @     0x7f8ba5673dc3  PyObject_Call\r\n    @     0x7f8ba56e0910  slot_tp_init\r\n    @     0x7f8ba56d7328  type_call\r\n    @     0x7f8ba5673dc3  PyObject_Call\r\n    @     0x7f8ba57256c7  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba57271f6  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba57271f6  PyEval_EvalFrameEx\r\n    @     0x7f8ba57281ce  PyEval_EvalCodeEx\r\n    @     0x7f8ba57271f6  PyEval_EvalFrameEx\r\nrun_train.sh: line 34: 40531 Aborted                 CUDA_VISIBLE_DEVICES=0,1,2,3 python -u train.py --batch_size=64 --trainer_count=8 --num_passes=50 --num_proc_data=16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True --share_rnn_weights=False --train_manifest='data/aishell/manifest.train' --dev_manifest='data/aishell/manifest.dev' --mean_std_path='data/aishell/mean_std.npz' --vocab_path='data/aishell/vocab.txt' --output_model_dir='./checkpoints/aishell' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training!\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "bolt163",
        "created_at": "2018-03-14T13:31:45+00:00",
        "updated_at": "2018-04-02T15:25:27+00:00",
        "closed_at": "2018-03-15T06:56:20+00:00",
        "comments_count": [
            "zy486at189cn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 177,
        "title": "GPU execution requested, but not compiled with GPU support **F0315 14:52:42.020200 70689 hl_warpctc_wrap.cc:131] Check failed: CTC_STATUS_SUCCESS == dynload::compute_ctc_loss(batchInput, batchGrad, cpuLabels, cpuLabelLengths, cpuInputLengths, numClasses, numSequences, cpuCosts, workspace, *options) (0 vs. 3) warp-ctc [version 2] Error: execution failed ",
        "body": "昨天的cudnn问题（https://github.com/PaddlePaddle/DeepSpeech/issues/176）\r\n已解决，编译的时候 GPU选项没有打开；\r\npaddle已开启gpu选项编译通过并重新安装，但是 swig_decoders沿用的是昨天编译通过的，下面这个错误不知是否 受swig_decoders 没有重新编译的影响,有点奇怪.....求大神解答.....\r\n/DeepSpeech/examples/aishell> sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 64\r\ndev_manifest: data/aishell/manifest.dev\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/aishell/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/aishell\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/aishell/manifest.train\r\ntrainer_count: 4\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\nI0315 14:52:31.625025 70572 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=4 \r\n[INFO 2018-03-15 14:52:33,805 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 14:52:33,806 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 14:52:33,807 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 14:52:33,808 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-15 14:52:33,808 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-15 14:52:33,809 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0315 14:52:33.829530 70572 MultiGradientMachine.cpp:99] numLogicalDevices=1 numThreads=4 numDevices=4\r\nI0315 14:52:33.940189 70572 GradientMachine.cpp:94] Initing parameters..\r\nI0315 14:52:37.948616 70572 GradientMachine.cpp:101] Init parameters done.\r\n**GPU execution requested, but not compiled with GPU support\r\nGPU execution requested, but not compiled with GPU support\r\n**F0315 14:52:42.020200 70689 hl_warpctc_wrap.cc:131] Check failed: CTC_STATUS_SUCCESS == dynload::compute_ctc_loss(batchInput, batchGrad, cpuLabels, cpuLabelLengths, cpuInputLengths, numClasses, numSequences, cpuCosts, workspace, *options) (0 vs. 3) warp-ctc [version 2] Error: execution failed \r\n*** Check failure stack trace: *******\r\n    @     0x7f28c1bd3dad  google::LogMessage::Fail()\r\n    @     0x7f28c1bd7f6c  google::LogMessage::SendToLog()\r\n    @     0x7f28c1bd38d3  google::LogMessage::Flush()\r\n    @     0x7f28c1bd89be  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f28c1b8bf91  hl_warpctc_compute_loss()\r\n    @     0x7f28c17fab9f  paddle::WarpCTCLayer::forward()\r\n    @     0x7f28c19410fd  paddle::NeuralNetwork::forward()\r\n    @     0x7f28c194c334  paddle::TrainerThread::forward()\r\n    @     0x7f28c194d625  paddle::TrainerThread::computeThread()\r\n    @     0x7f290b204870  (unknown)\r\n    @     0x7f291697bdc5  start_thread\r\n    @     0x7f2915fa029d  __clone\r\n    @              (nil)  (unknown)\r\nrun_train.sh: line 34: 70572 Aborted                 CUDA_VISIBLE_DEVICES=0,1,2,3 python -u train.py --batch_size=64 --trainer_count=4 --num_passes=50 --num_proc_data=16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True --share_rnn_weights=False --train_manifest='data/aishell/manifest.train' --dev_manifest='data/aishell/manifest.dev' --mean_std_path='data/aishell/mean_std.npz' --vocab_path='data/aishell/vocab.txt' --output_model_dir='./checkpoints/aishell' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training!\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "zh794390558",
        "created_at": "2018-03-15T06:57:44+00:00",
        "updated_at": "2021-05-12T05:20:35+00:00",
        "closed_at": "2021-05-12T05:20:35+00:00",
        "comments_count": [
            "bolt163",
            "kuke",
            "bolt163"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 178,
        "title": "运行过程中 CUDA out of memmory?",
        "body": "说一下我的情况，因为机器只有4块GPU，每个12GB内存，同时也对应修改了  run_train.sh脚本内容如下\r\n-------------------------------------------------------------------------------------\r\nCUDA_VISIBLE_DEVICES=0,1,2,3 \\\r\npython -u train.py \\\r\n--batch_size=64 \\\r\n--trainer_count=4 \\\r\n--num_passes=50 \\\r\n--num_proc_data=16 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--num_iter_print=100 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=27.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=False \\\r\n--train_manifest='data/aishell/manifest.train' \\\r\n--dev_manifest='data/aishell/manifest.dev' \\\r\n--mean_std_path='data/aishell/mean_std.npz' \\\r\n--vocab_path='data/aishell/vocab.txt' \\\r\n--output_model_dir='./checkpoints/aishell' \\\r\n--augment_conf_path='conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped'\r\n\r\nif [ $? -ne 0 ]; then\r\n    echo \"Failed in training!\"\r\n    exit 1\r\nfi\r\n\r\n\r\nexit 0\r\n~                                                                                                                                                                                               \r\n~                                                                                                                                                                                               \r\n~                                                                                                                                                                                               \r\n\"run_train.sh\" 43L, 1019C               \r\n\r\n—————————————————————————————————————————————\r\n~/DeepSpeech/examples/aishell> sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 64\r\ndev_manifest: data/aishell/manifest.dev\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/aishell/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/aishell\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/aishell/manifest.train\r\ntrainer_count: 4\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\nI0315 16:47:44.366181 11850 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=4 \r\n[INFO 2018-03-15 16:47:46,743 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 16:47:46,744 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 16:47:46,744 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-15 16:47:46,745 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-15 16:47:46,746 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-15 16:47:46,746 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0315 16:47:46.766090 11850 MultiGradientMachine.cpp:99] numLogicalDevices=1 numThreads=4 numDevices=4\r\nI0315 16:47:46.877454 11850 GradientMachine.cpp:94] Initing parameters..\r\nI0315 16:47:50.904826 11850 GradientMachine.cpp:101] Init parameters done.\r\n...................................................................................................\r\nPass: 0, Batch: 100, TrainCost: 63.639388\r\n...................................................................................................\r\nPass: 0, Batch: 200, TrainCost: 63.148882\r\n...................................................................................................\r\nPass: 0, Batch: 300, TrainCost: 64.747351\r\n...................................................................................................\r\nPass: 0, Batch: 400, TrainCost: 54.954166\r\n...................................................................................................\r\nPass: 0, Batch: 500, TrainCost: 38.613670\r\n...................................................................................................\r\nPass: 0, Batch: 600, TrainCost: 30.979173\r\n...................................................................................................\r\nPass: 0, Batch: 700, TrainCost: 26.576287\r\n...................................................................................................\r\nPass: 0, Batch: 800, TrainCost: 24.339529\r\n...................................................................................................\r\nPass: 0, Batch: 900, TrainCost: 22.288584\r\n...............................F0315 17:24:56.116675 11921 hl_cuda_device.cc:273] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory\r\n*** Check failure stack trace: ***\r\n    @     0x7fa000f5adad  google::LogMessage::Fail()\r\n    @     0x7fa000f5ef6c  google::LogMessage::SendToLog()\r\n    @     0x7fa000f5a8d3  google::LogMessage::Flush()\r\n    @     0x7fa000f5f9be  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fa000f1bf84  hl_malloc_device()\r\n    @     0x7fa000dd4a66  paddle::GpuAllocator::alloc()\r\n    @     0x7fa000dc85ff  paddle::PoolAllocator::alloc()\r\n    @     0x7fa000dc8004  paddle::GpuMemoryHandle::GpuMemoryHandle()\r\n    @     0x7fa000da05c4  paddle::GpuMatrix::resize()\r\n    @     0x7fa000db4839  paddle::Matrix::resizeOrCreate()\r\n    @     0x7fa000c15cb2  paddle::Layer::resetSpecifyOutput()\r\n    @     0x7fa000c15f64  paddle::Layer::resetOutput()\r\n    @     0x7fa000c5e384  paddle::CudnnBatchNormLayer::forward()\r\n    @     0x7fa000cc80fd  paddle::NeuralNetwork::forward()\r\n    @     0x7fa000cd3334  paddle::TrainerThread::forward()\r\n    @     0x7fa000cd4625  paddle::TrainerThread::computeThread()\r\n    @     0x7fa04a58b870  (unknown)\r\n    @     0x7fa055d02dc5  start_thread\r\n    @     0x7fa05532729d  __clone\r\n    @              (nil)  (unknown)\r\nrun_train.sh: line 35: 11850 Aborted                 CUDA_VISIBLE_DEVICES=0,1,2,3 python -u train.py --batch_size=64 --trainer_count=4 --num_passes=50 --num_proc_data=16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True --share_rnn_weights=False --train_manifest='data/aishell/manifest.train' --dev_manifest='data/aishell/manifest.dev' --mean_std_path='data/aishell/mean_std.npz' --vocab_path='data/aishell/vocab.txt' --output_model_dir='./checkpoints/aishell' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training!\r\n\r\n-------------------------------------------------------中途异常退出。。。GPU内存泄漏。。。\r\nThu Mar 15 17:26:56 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.20                 Driver Version: 375.20                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K40m          Off  | 0000:0D:00.0     Off |                    0 |\r\n| N/A   37C    P0    62W / 235W |   **3022MiB** / 11471MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K40m          Off  | 0000:0E:00.0     Off |                    0 |\r\n| N/A   36C    P0    62W / 235W |   **2967MiB** / 11471MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K40m          Off  | 0000:30:00.0     Off |                    0 |\r\n| N/A   39C    P0    62W / 235W |   **3032MiB** / 11471MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K40m          Off  | 0000:33:00.0     Off |                    0 |\r\n| N/A   35C    P0    62W / 235W |   **2966MiB** / 11471MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "zh794390558",
        "created_at": "2018-03-15T09:32:46+00:00",
        "updated_at": "2021-05-12T05:16:54+00:00",
        "closed_at": "2021-05-12T05:16:54+00:00",
        "comments_count": [
            "bolt163",
            "kuke",
            "bolt163",
            "bolt163",
            "kuke",
            "pkuyym",
            "bolt163",
            "bolt163",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 179,
        "title": "Noise file can't be downloaded",
        "body": "Hi! Thank you for your work! It is great project!\r\nBut I have trouble with noise emulation. Nose files from samples can't be downloaded, because the link from chime3_background.py was broken for now.\r\nCan you fix it please?",
        "state": "closed",
        "user": "Rai220",
        "closed_by": "Rai220",
        "created_at": "2018-03-16T12:49:39+00:00",
        "updated_at": "2018-03-21T10:09:39+00:00",
        "closed_at": "2018-03-21T10:09:39+00:00",
        "comments_count": [
            "kuke",
            "pkuyym",
            "Rai220"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 183,
        "title": "关于中文训练数据集AiShell标注文本的疑问",
        "body": "看到 AiShell的  transcript标注内容， 格式是下面这个样子, 引用其中若干条，也即看到各个字/词之间是有空格分割开来的（直接粘贴文本上来效果貌似不太明显），\r\n\"\r\nBAC009S0002W0122 而 对 楼市 成交 抑制 作用 最 大 的 限 购\r\nBAC009S0002W0123 也 成为 地方 政府 的 眼中 钉\r\nBAC009S0002W0124 自 六月 底 呼和浩特 市 率先 宣布 取消 限 购 后\r\nBAC009S0002W0125 各地 政府 便 纷纷 跟进\r\nBAC009S0002W0126 仅 一 个 多 月 的 时间 里\r\nBAC009S0002W0127 除了 北京 上海 广州 深圳 四 个 一 线 城市 和 三亚 之外\r\nBAC009S0002W0128 四十六 个 限 购 城市 当中\r\nBAC009S0002W0129 四十一 个 已 正式 取消 或 变相 放松 了 限 购\r\nBAC009S0002W0130 财政 金融 政策 紧随 其后 而来\r\nBAC009S0002W0131 显示 出 了 极 强 的 威力\r\n\"\r\n\r\n![_15215353325207](https://user-images.githubusercontent.com/25170435/37644134-c6c507d0-2c5d-11e8-8b68-0daf72753af4.png)\r\n\r\n——————————————————分割线—————————————————————\r\n现在我想用自己录制的语料来做训练，但是与语音对应的transtript标注文本内容是没有像上面那样把 字/词 用空格分割开来【如下所示】,  那么训练的时候是否会受这个的影响?  \r\n\r\n\"*/f001_25.wav\"\t\"嗯有时候学校的的工会也会组织一些活动\"\r\n\"*/f001_26.wav\"\t\"那么我们就参加学酗的组织的这些旅游的团体\"\r\n\"*/f001_26.wav\"\t\"那么我们就参加学酗的组织的这些旅游的团体\"\r\n\"*/f001_27.wav\"\t\"一起出去玩然后走了全国很多的地方\"\r\n\"*/f001_27.wav\"\t\"一起出去玩然后走了全国很多的地方\"\r\n\"*/f001_28.wav\"\t\"恩我家里呢还有很多的其他的一些亲戚\"\r\n\"*/f001_28.wav\"\t\"恩我家里呢还有很多的其他的一些亲戚\"\r\n\"*/f001_29.wav\"\t\"呃比如说我有一个姨妈现在在株洲\"\r\n\r\n【如果标注文本需去分割这些字/词，这是太麻烦的一件事情....】，\r\n\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "zh794390558",
        "created_at": "2018-03-20T08:49:32+00:00",
        "updated_at": "2021-05-12T05:20:06+00:00",
        "closed_at": "2021-05-12T05:20:06+00:00",
        "comments_count": [
            "pkuyym",
            "bolt163"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 180,
        "title": "write audio feature generator in c/c++",
        "body": "We want to write a complete c/c++ server. We have got a good hang of decoders. We were wondering whether it will be easy to write the feature generator code in c/c++. I think you are using third party library python_speech_features for that if i am not mistaken? Any points for generating those features in c/c++?",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "zh794390558",
        "created_at": "2018-03-17T13:42:42+00:00",
        "updated_at": "2021-05-12T05:20:28+00:00",
        "closed_at": "2021-05-12T05:20:28+00:00",
        "comments_count": [
            "kuke",
            "cogmeta",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 181,
        "title": "训练过程中 Connection reset by peer，“ managers.py\", line 759,  result = conn.recv() IOError: [Errno 104] Connection reset by peer",
        "body": "batch_size调成24 没有OOM， 第0个Pass训练正常，第1个Pass报 Connection reset by peer， 什么情况\r\n\r\n\r\n...................................................................................................\r\nPass: 1, Batch: 2100, TrainCost: 8.552184\r\n...................................................................................................\r\nPass: 1, Batch: 2200, TrainCost: 7.938597\r\n...................................................................................................\r\nPass: 1, Batch: 2300, TrainCost: 8.337096\r\n...................................................................................................\r\nPass: 1, Batch: 2400, TrainCost: 8.301428\r\n...................................................................................................\r\nPass: 1, Batch: 2500, TrainCost: 7.078673\r\n...................................................................................................\r\nPass: 1, Batch: 2600, TrainCost: 8.098217\r\n...................................................................................................\r\nPass: 1, Batch: 2700, TrainCost: 8.403698\r\n...................................................................................................\r\nPass: 1, Batch: 2800, TrainCost: 7.654552\r\n...................................................................................................\r\nPass: 1, Batch: 2900, TrainCost: 7.540778\r\n...................................................................................................\r\nPass: 1, Batch: 3000, TrainCost: 7.034502\r\n...................................................................................................\r\nPass: 1, Batch: 3100, TrainCost: 8.303614\r\n...................................................................................................\r\nPass: 1, Batch: 3200, TrainCost: 7.362420\r\n...................................................................................................\r\nPass: 1, Batch: 3300, TrainCost: 8.457884\r\n...................................................................................................\r\nPass: 1, Batch: 3400, TrainCost: 8.275194\r\n...................................................................................................\r\nPass: 1, Batch: 3500, TrainCost: 7.887627\r\n...................................................................................................\r\nPass: 1, Batch: 3600, TrainCost: 9.091355\r\n...................................................................................................\r\nPass: 1, Batch: 3700, TrainCost: 7.678354\r\n...................................................................................................\r\nPass: 1, Batch: 3800, TrainCost: 8.109676\r\n...................................................................................................\r\nPass: 1, Batch: 3900, TrainCost: 8.876282\r\n...................................................................................................\r\nPass: 1, Batch: 4000, TrainCost: 8.288002\r\n...................................................................................................\r\nPass: 1, Batch: 4100, TrainCost: 7.990575\r\n...................................................................................................\r\nPass: 1, Batch: 4200, TrainCost: 7.985103\r\n...................................................................................................\r\nPass: 1, Batch: 4300, TrainCost: 7.639118\r\n...................................................................................................\r\nPass: 1, Batch: 4400, TrainCost: 8.015420\r\n...................................................................................................\r\nPass: 1, Batch: 4500, TrainCost: 7.916594\r\n...................................................................................................\r\nPass: 1, Batch: 4600, TrainCost: 8.564386\r\n...................................................................................................\r\nPass: 1, Batch: 4700, TrainCost: 8.309537\r\n...................................................................................................\r\nPass: 1, Batch: 4800, TrainCost: 8.294658\r\n...Exception in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 153, in flush_worker\r\n    sample = in_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 758, in _callmethod\r\n    conn.send((self._id, methodname, args, kwds))\r\nIOError: [Errno 32] Broken pipe\r\n\r\n.....................Process Process-46:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nProcess Process-43:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\nProcess Process-51:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self.run()\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    while order_id != out_order[0]:\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nEOFError\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-53:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-42:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\nProcess Process-47:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\nProcess Process-49:\r\nTraceback (most recent call last):\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/data/offline/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/data1/bolt163/DeepSpeech/data_utils/utility.py\", line 135, in order_handle_worker\r\n",
        "state": "closed",
        "user": "bolt163",
        "closed_by": "zh794390558",
        "created_at": "2018-03-19T01:51:39+00:00",
        "updated_at": "2021-05-12T05:20:21+00:00",
        "closed_at": "2021-05-12T05:20:21+00:00",
        "comments_count": [
            "bolt163",
            "pkuyym",
            "bolt163",
            "pkuyym",
            "windowxiaoming"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 182,
        "title": "我用自己训练的中文语言模型做测试，提示如下：",
        "body": "我按照kenlm工具来做的中文语言模型，然后生成的二进制文件。\r\n\r\n在运行run_infer.sh时，提示如下：\r\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 23-41: ordinal not in range(128)\r\n\r\n在运行run_test.sh时，提示如下：\r\nError rate [cer] (128/?) = 0.795897\r\nError rate [cer] (256/?) = 0.806996\r\nError rate [cer] (384/?) = 0.803812\r\nError rate [cer] (512/?) = 0.798943\r\n......\r\n\r\n这里的问号？是什么含义呢？语言模型文件编码是哪种？",
        "state": "closed",
        "user": "angenge",
        "closed_by": "zh794390558",
        "created_at": "2018-03-19T07:55:26+00:00",
        "updated_at": "2021-05-12T05:20:13+00:00",
        "closed_at": "2021-05-12T05:20:13+00:00",
        "comments_count": [
            "pkuyym",
            "angenge",
            "Lebron-Kun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 184,
        "title": "URL to download zh_giga.no_cna_cmn.prune01244.klm is invalid",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-03-21T07:48:13+00:00",
        "updated_at": "2018-03-21T08:02:10+00:00",
        "closed_at": "2018-03-21T08:02:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 186,
        "title": "getting the loss of a audio file with a certain transcription",
        "body": "Any chance to get a guidance on hoe to receive the ctc_loss of a (audio,transcrption) pair via the python wrapper?\r\n\r\nThanks in advance!",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-03-21T12:21:17+00:00",
        "updated_at": "2021-05-12T05:19:59+00:00",
        "closed_at": "2021-05-12T05:19:59+00:00",
        "comments_count": [
            "kuke",
            "alanbekker",
            "hui001",
            "hui001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 187,
        "title": "Memory leak.",
        "body": "Hi! we have some problem with training own acoustic model. After each era, the consumption of RAM increases and, as a result, training stops. Could you help me?\r\nThanks.",
        "state": "closed",
        "user": "VictorBebnev",
        "closed_by": "zh794390558",
        "created_at": "2018-03-22T07:34:54+00:00",
        "updated_at": "2021-05-12T05:19:52+00:00",
        "closed_at": "2021-05-12T05:19:52+00:00",
        "comments_count": [
            "kuke",
            "VictorBebnev",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 189,
        "title": " preprocessing steps before training the LM",
        "body": "Do you have the code doing the preprocessing available?\r\n\r\nThanks!",
        "state": "closed",
        "user": "alanbekker",
        "closed_by": "zh794390558",
        "created_at": "2018-03-22T15:50:34+00:00",
        "updated_at": "2021-05-12T05:19:44+00:00",
        "closed_at": "2021-05-12T05:19:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 190,
        "title": "Inference using English model returns gibberish",
        "body": "The command we run:    \r\n```\r\nCUDA_VISIBLE_DEVICES=0 python infer.py --trainer_count 1 \\\r\n        --use_gru True \\\r\n        --mean_std_path ./models/baidu_en8k/mean_std.npz \\\r\n        --vocab_path ./models/baidu_en8k/vocab.txt \\\r\n        --infer_manifest manifest.json \\\r\n        --lang_model_path models/lm/common_crawl_00.prune01111.trie.klm \\\r\n        --model_path ./models/baidu_en8k/params.tar.gz\r\n```\r\n\r\nManifest:    \r\n```\r\n{\"audio_filepath\": \"./241757.wav\", \"duration\": 5, \"text\": \"If students today had more free time, they might show more interest in politics.\"}\r\n```\r\n\r\nThe file is this: [241757.zip](https://github.com/PaddlePaddle/DeepSpeech/files/1841443/241757.zip), it came from http://www.manythings.org/audio/sentences/126.html\r\n\r\nResult:    \r\n```\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: manifest.json\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: ./models/baidu_en8k/mean_std.npz\r\nmodel_path: ./models/baidu_en8k/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: True\r\nuse_gru: 1\r\nvocab_path: ./models/baidu_en8k/vocab.txt\r\n------------------------------------------------\r\nI0323 12:10:15.707188   820 Util.cpp:166] commandline:  --use_gpu=True --rnn_use_batch=True --trainer_count=1\r\n[INFO 2018-03-23 12:10:17,678 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-23 12:10:17,680 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-23 12:10:17,680 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-23 12:10:17,681 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-23 12:10:17,682 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-23 12:10:17,683 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-23 12:10:20,938 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-03-23 12:10:29,526 model.py:253] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2018-03-23 12:10:29,711 model.py:254] end initializing scorer\r\n[INFO 2018-03-23 12:10:29,711 infer.py:103] start inference ...\r\n\r\nTarget Transcription: If students today had more free time, they might show more interest in politics.\r\nOutput Transcription: eugenespringfield emergencies emergencies eyebrowraising\r\nCurrent error rate [wer] = 1.000000\r\n[INFO 2018-03-23 12:10:30,421 infer.py:124] finish inference\r\n```\r\n\r\nAny ideas?\r\n\r\n(It works well for sentences from librispeech, so the model is working)",
        "state": "closed",
        "user": "jrao1",
        "closed_by": "zh794390558",
        "created_at": "2018-03-23T12:19:46+00:00",
        "updated_at": "2021-05-12T05:19:38+00:00",
        "closed_at": "2021-05-12T05:19:38+00:00",
        "comments_count": [
            "ritesh-nitjsr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 192,
        "title": "Production Level DeepSpeech",
        "body": "Hi,\r\n\r\nAccording to my best understanding, the demo_server provided with does not implement any of the improvement discussed in section[7] (Deployment) of the DeepSpeech2 paper, right?\r\n\r\nI wanted to know, are the discussed deployment improvements i.e Batch Dispatch, half-precision matrix-matrix multiply kernel, Improved beam-search, row-convolution unidirectional model provided with this Repo? If yes, can you please share the details?\r\n\r\nThanks,\r\nRam",
        "state": "closed",
        "user": "rmalav15",
        "closed_by": "zh794390558",
        "created_at": "2018-03-26T12:27:36+00:00",
        "updated_at": "2021-05-12T05:19:19+00:00",
        "closed_at": "2021-05-12T05:19:19+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 193,
        "title": "求助：下载国语模型失败",
        "body": "求助！问题如下：\r\n1、Mandarin LM Small下载失败，报500服务器错误。\r\n![错误信息](https://user-images.githubusercontent.com/24585538/37955409-0963c416-3198-11e8-8e7b-423f70424a78.png)\r\n2、Mandarin LM Large总是下载不完整，一般下载到1~5G就完了，是否可以支持断点续传。",
        "state": "closed",
        "user": "Cxywzx",
        "closed_by": "Cxywzx",
        "created_at": "2018-03-27T08:33:01+00:00",
        "updated_at": "2019-02-20T12:24:10+00:00",
        "closed_at": "2018-03-28T11:53:55+00:00",
        "comments_count": [
            "pkuyym",
            "Cxywzx",
            "Cxywzx",
            "Cxywzx",
            "whaozl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 194,
        "title": "run_train.sh example failure",
        "body": "I kept getting cudnn errors on CUDA 9.1 and CUDNN 7.1 on Ubuntu 16.04\r\nTried reinstalling paddlepaddle and kept getting the follow erros\r\n\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 4\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI0327 16:29:22.122421 13135 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=4 \r\nF0327 16:29:22.784910 13135 DynamicLoader.cpp:104] Check failed: nullptr != *dso_handle Failed to find dynamic library: libcudnn.so (libcudnn.so: cannot open shared object file: No such file or directory) \r\nPlease specify its path correctly using following ways: \r\nMethod. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\nFor instance, issue command: export LD_LIBRARY_PATH=... \r\nNote: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled.\r\n*** Check failure stack trace: ***\r\n    @     0x7f4be2c74bcd  google::LogMessage::Fail()\r\n    @     0x7f4be2c7867c  google::LogMessage::SendToLog()\r\n    @     0x7f4be2c746f3  google::LogMessage::Flush()\r\n    @     0x7f4be2c79b8e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f4be2bb3bad  GetCudnnDsoHandle()\r\n    @     0x7f4c5a364a99  __pthread_once_slow\r\n    @     0x7f4be2c27372  hl_cudnn_init()\r\n    @     0x7f4be2c2fd3e  hl_create_global_resources()\r\n    @     0x7f4be2c30439  hl_specify_devices_start()\r\n    @     0x7f4be2c3085d  hl_start()\r\n    @     0x7f4be2bba55a  paddle::initMain()\r\n    @     0x7f4be2c5c5d1  initPaddle()\r\n    @     0x7f4be2803c29  _wrap_initPaddle\r\n    @           0x4c30ce  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d54b9  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n    @           0x4bed3d  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4eb30f  (unknown)\r\n    @           0x4e5422  PyRun_FileExFlags\r\n    @           0x4e3cd6  PyRun_SimpleFileExFlags\r\n    @           0x493ae2  Py_Main\r\n    @     0x7f4c59fac830  __libc_start_main\r\n    @           0x4933e9  _start\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\nFail in training!\r\n",
        "state": "closed",
        "user": "shaofushih",
        "closed_by": "zh794390558",
        "created_at": "2018-03-27T23:34:43+00:00",
        "updated_at": "2021-05-12T05:19:09+00:00",
        "closed_at": "2021-05-12T05:19:09+00:00",
        "comments_count": [
            "shaofushih",
            "pkuyym",
            "shaofushih",
            "shaofushih"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 191,
        "title": "下载Mandarin LM Small模型后端出现错误",
        "body": "已经尝试过 在/etc/hosts 添加 180.76.189.142 cloud.dlnel.org 并且重启了网卡服务，(mac/linux) \r\n但是仍然无法下载，提示 A server error occurred.  Please contact the administrator.\r\n\r\n请问如何解决？",
        "state": "closed",
        "user": "DLZSY",
        "closed_by": "zh794390558",
        "created_at": "2018-03-25T10:16:34+00:00",
        "updated_at": "2021-05-12T05:19:31+00:00",
        "closed_at": "2021-05-12T05:19:31+00:00",
        "comments_count": [
            "sailordiary",
            "Cxywzx",
            "frozenfires",
            "Lebron-Kun",
            "Cxywzx",
            "Cxywzx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 195,
        "title": "作者发布的aishell 模型无法去restore，retrain ",
        "body": "当我尝试去restore主页上的那个aishell模型的时候，出现错误。这是我的命令，CUDA_VISIBLE_DEVICES=0 python -u train.py --batch_size=16 --trainer_count=1 --num_passes=10 --num_proc_data=16 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --learning_rate=4e-5 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True --share_rnn_weights=False --train_manifest='data/aishell/manifest.train' --dev_manifest='data/aishell/manifest.dev' --mean_std_path='data/aishell/mean_std.npz' --vocab_path='data/aishell/vocab.txt' --output_model_dir='diymodel/aishell/' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped' --init_model_path='models/aishell/params.tar.gz'。\r\n\r\n错误提示如下：\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/aishell/manifest.dev\r\ninit_model_path: models/aishell/params.tar.gz\r\nis_local: 1\r\nlearning_rate: 4e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/aishell/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 10\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: diymodel/aishell/\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/aishell/manifest.train\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\nI0327 18:03:09.554020 23876 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=1 \r\n[INFO 2018-03-27 18:03:11,308 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-27 18:03:11,309 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-27 18:03:11,310 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-03-27 18:03:11,310 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-27 18:03:11,310 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-03-27 18:03:11,311 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0327 18:03:15.383965 23876 GradientMachine.cpp:94] Initing parameters..\r\nI0327 18:03:17.461269 23876 GradientMachine.cpp:101] Init parameters done.\r\nF0327 18:03:20.693872 23876 TensorApply.h:126] Check failed: lhs_.getWidth() == rhs_.getWidth() (8876032 vs. 8804352) \r\n*** Check failure stack trace: ***\r\n    @     0x7fc5aa6570bd  google::LogMessage::Fail()\r\n    @     0x7fc5aa659408  google::LogMessage::SendToLog()\r\n    @     0x7fc5aa656bcb  google::LogMessage::Flush()\r\n    @     0x7fc5aa65a2de  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc5aa7b49c8  paddle::adamApply()\r\n    @     0x7fc5aa7a3b59  paddle::AdamParameterOptimizer::update()\r\n    @     0x7fc5aa7a3f82  paddle::OptimizerWithGradientClipping::update()\r\n    @     0x7fc5aa78fe1e  paddle::SgdThreadUpdater::updateImpl()\r\n    @     0x7fc5aa62c7a1  ParameterUpdater::update()\r\n    @     0x7fc5aa0d5ff7  _wrap_ParameterUpdater_update\r\n    @           0x4bc3fa  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4eb30f  (unknown)\r\n    @           0x4e5422  PyRun_FileExFlags\r\n    @           0x4e3cd6  PyRun_SimpleFileExFlags\r\n    @           0x493ae2  Py_Main\r\n    @     0x7fc5e416e830  __libc_start_main\r\n    @           0x4933e9  _start\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n不知道是不是什么参数设置错了，请教大家，谢谢！",
        "state": "closed",
        "user": "fangmingbnu",
        "closed_by": "fangmingbnu",
        "created_at": "2018-03-28T01:06:57+00:00",
        "updated_at": "2018-03-28T17:30:16+00:00",
        "closed_at": "2018-03-28T17:30:16+00:00",
        "comments_count": [
            "fangmingbnu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 196,
        "title": "用自己的训练集训练报错",
        "body": "如题，我用自己的数据集制作了manifest数据，训练，run_train如下：\r\n```bash\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5 \\\r\npython -u train.py \\\r\n--batch_size=4 \\\r\n--trainer_count=6 \\\r\n--num_passes=5 \\\r\n--num_proc_data=16 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--num_iter_print=1 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=1000.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=False \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=True \\\r\n--train_manifest='/data/Paddle/DeepSpeech/demo/manifest.train' \\\r\n--dev_manifest='/data/Paddle/DeepSpeech/demo/manifest.dev' \\\r\n--mean_std_path='/data/Paddle/DeepSpeech/demo/mean_std.npz' \\\r\n--vocab_path='/data/Paddle/DeepSpeech/demo/vocab.txt' \\\r\n--output_model_dir='/data/Paddle/DeepSpeech/demo/log/' \\\r\n--augment_conf_path='conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped'\r\n```\r\n\r\n训练了好几次，都报如下错误，我调小了batch_size，减少了显卡数量，每次运行失败后也手动kill了，但还是报错，请问如何解决？\r\n```bash\r\nF0328 08:04:45.916014  5449 hl_warpctc_wrap.cc:131] Check failed: CTC_STATUS_SUCCESS == dynload::compute_ctc_loss(batchInput, batchGrad, cpuLabels, cpuLabelLengths, cpuInputLengths, numClasses, numSequences, cpuCosts, workspace, *options) (0 vs. 4) warp-ctc [version 2] Error: unknown error\r\n*** Check failure stack trace: ***\r\n    @     0x7febcd740bcd  google::LogMessage::Fail()\r\n    @     0x7febcd74467c  google::LogMessage::SendToLog()\r\n    @     0x7febcd7406f3  google::LogMessage::Flush()\r\n    @     0x7febcd745b8e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7febcd6f0e41  hl_warpctc_compute_loss()\r\n    @     0x7febcd3307f5  paddle::WarpCTCLayer::forward()\r\n    @     0x7febcd44af4d  paddle::NeuralNetwork::forward()\r\n    @     0x7febcd46d014  paddle::TrainerThread::forward()\r\n    @     0x7febcd46e315  paddle::TrainerThread::computeThread()\r\n    @     0x7febe8a93c80  (unknown)\r\n    @     0x7febeadfe6ba  start_thread\r\n    @     0x7febeab3482d  clone\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n```",
        "state": "closed",
        "user": "huxiaoman7",
        "closed_by": "zh794390558",
        "created_at": "2018-03-28T01:22:11+00:00",
        "updated_at": "2021-05-12T05:19:01+00:00",
        "closed_at": "2021-05-12T05:19:01+00:00",
        "comments_count": [
            "huxiaoman7",
            "pkuyym",
            "huxiaoman7"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 197,
        "title": "ValidationCost increases after each pass",
        "body": "Hi I tried to train a model but seems the validation cost increase after each pass as below, is it normal?\r\n\r\n[2018-03-21 00:00:10] ------- Time: 22227 sec,  Pass: 0, ValidationCost: 18.345830903\r\n[2018-03-21 06:10:07] ------- Time: 22185 sec,  Pass: 1, ValidationCost: 18.3184596212\r\n[2018-03-21 12:20:30] ------- Time: 22209 sec,  Pass: 2, ValidationCost: 17.5856525281\r\n[2018-03-21 18:27:57] ------- Time: 22034 sec,  Pass: 3, ValidationCost: 18.2304718057\r\n[2018-03-22 00:34:54] ------- Time: 22004 sec,  Pass: 4, ValidationCost: 17.9108289895\r\n[2018-03-22 06:42:42] ------- Time: 22056 sec,  Pass: 5, ValidationCost: 18.7010796109\r\n[2018-03-22 12:49:11] ------- Time: 21976 sec,  Pass: 6, ValidationCost: 19.2663258581\r\n[2018-03-22 18:57:12] ------- Time: 22070 sec,  Pass: 7, ValidationCost: 19.5299177824\r\n[2018-03-23 01:10:56] ------- Time: 22409 sec,  Pass: 8, ValidationCost: 20.5845607126\r\n[2018-03-23 07:20:32] ------- Time: 22163 sec,  Pass: 9, ValidationCost: 20.757628163\r\n[2018-03-23 13:28:11] ------- Time: 22045 sec,  Pass: 10, ValidationCost: 20.8393640953\r\n[2018-03-23 19:41:08] ------- Time: 22363 sec,  Pass: 11, ValidationCost: 21.0724439657\r\n[2018-03-24 01:53:30] ------- Time: 22327 sec,  Pass: 12, ValidationCost: 21.9896265413\r\n[2018-03-24 08:01:36] ------- Time: 22073 sec,  Pass: 13, ValidationCost: 22.531096637\r\n[2018-03-24 14:09:42] ------- Time: 22073 sec,  Pass: 14, ValidationCost: 22.3551265387\r\n[2018-03-24 20:21:39] ------- Time: 22303 sec,  Pass: 15, ValidationCost: 23.8237918068\r\n[2018-03-25 02:33:52] ------- Time: 22318 sec,  Pass: 16, ValidationCost: 24.2891556082\r\n[2018-03-25 08:41:56] ------- Time: 22072 sec,  Pass: 17, ValidationCost: 24.6508512178\r\n[2018-03-25 14:49:34] ------- Time: 22044 sec,  Pass: 18, ValidationCost: 25.2140230672\r\n[2018-03-25 21:01:05] ------- Time: 22276 sec,  Pass: 19, ValidationCost: 23.3633104355\r\n[2018-03-26 03:12:44] ------- Time: 22285 sec,  Pass: 20, ValidationCost: 27.1979689747\r\n[2018-03-26 09:23:12] ------- Time: 22214 sec,  Pass: 21, ValidationCost: 23.4449897665\r\n[2018-03-26 15:32:47] ------- Time: 22160 sec,  Pass: 22, ValidationCost: 24.0375935756\r\n[2018-03-26 21:42:57] ------- Time: 22197 sec,  Pass: 23, ValidationCost: 24.7978525064\r\n[2018-03-27 03:51:56] ------- Time: 22125 sec,  Pass: 24, ValidationCost: 24.6670613937\r\n[2018-03-27 10:01:58] ------- Time: 22187 sec,  Pass: 25, ValidationCost: 25.072318309\r\n[2018-03-27 16:17:09] ------- Time: 22496 sec,  Pass: 26, ValidationCost: 26.3841101534\r\n[2018-03-27 22:32:06] ------- Time: 22482 sec,  Pass: 27, ValidationCost: 26.4974455705\r\n[2018-03-28 04:45:17] ------- Time: 22377 sec,  Pass: 28, ValidationCost: 25.0781797638",
        "state": "closed",
        "user": "kenyeung128",
        "closed_by": "zh794390558",
        "created_at": "2018-03-28T06:39:17+00:00",
        "updated_at": "2021-05-12T05:18:54+00:00",
        "closed_at": "2021-05-12T05:18:54+00:00",
        "comments_count": [
            "pkuyym",
            "kenyeung128",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 198,
        "title": "paddle.layer.img_conv中的padding怎么计算得到的，不应该由上下左右四个变量么，为什么只有二维的",
        "body": "",
        "state": "closed",
        "user": "chenbblei",
        "closed_by": "chenbblei",
        "created_at": "2018-03-28T12:15:02+00:00",
        "updated_at": "2018-04-25T07:34:43+00:00",
        "closed_at": "2018-04-25T07:34:42+00:00",
        "comments_count": [
            "kuke",
            "chenbblei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 201,
        "title": "demo_server问题",
        "body": "我用mac去跑demo_server. 我的demo_server是可以跑出来，运行效果如下：\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'/Users/Desktop/DeepSpeech/data/aishell/wav/test/S0913/BAC009S0913W0364.wav')\r\nResponse Time: 3.273213, Transcript: 邀请专家学者等三十馀人组成志愿者培训导师\r\n('Warm-up Test Case %d: %s', 1, u'/Users/Desktop/DeepSpeech/data/aishell/wav/test/S0912/BAC009S0912W0384.wav')\r\nResponse Time: 1.695054, Transcript: 冰雪爱好者不得不选择出国\r\n('Warm-up Test Case %d: %s', 2, u'/Users/Desktop/DeepSpeech/data/aishell/wav/test/S0902/BAC009S0902W0467.wav')\r\nResponse Time: 1.467976, Transcript: 黄色渣土车一头撞进了路边的攻防\r\nASR Server Started.\r\n但是我的demo_client.py不知道有没有运行成功，我输入python -u deploy/demo_client.py --host_ip 'localhost' --host_port 8086， 也没有报错,只是没有任何反应。我是在同一台机子上跑的，不知道有什么问题，请教一下，谢谢！",
        "state": "closed",
        "user": "fangmingbnu",
        "closed_by": "fangmingbnu",
        "created_at": "2018-04-04T01:26:21+00:00",
        "updated_at": "2018-04-06T03:57:11+00:00",
        "closed_at": "2018-04-05T18:38:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 200,
        "title": "Floating point exception (core dumped): 跑大数据的时候(比如AISHELL数据) PaddlePaddle报错 ",
        "body": "跑自己的测试的几十个小音频的时候没什么问题，跑大数据的时候总会跳如下错误\r\n\r\n................*** Aborted at 1522777380 (unix time) try \"date -d @1522777380\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7f0b7f3cc7a4) received by PID 29812 (TID 0x7f0bb86c0700) from PID 2134689700; stack trace: ***\r\n    @     0x7f0bb82d0390 (unknown)\r\n    @     0x7f0b7f3cc7a4 paddle::GpuVectorT<>::getAbsMax()\r\n    @     0x7f0b7f74ddef paddle::OptimizerWithGradientClipping::update()\r\n    @     0x7f0b7f739e1e paddle::SgdThreadUpdater::updateImpl()\r\n    @     0x7f0b7f5d67a1 ParameterUpdater::update()\r\n    @     0x7f0b7f07fff7 _wrap_ParameterUpdater_update\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x7f0bb7f15830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @                0x0 (unknown)\r\n    Floating point exception (core dumped)",
        "state": "closed",
        "user": "xikunlun001",
        "closed_by": "xikunlun001",
        "created_at": "2018-04-03T18:02:06+00:00",
        "updated_at": "2019-12-03T09:09:43+00:00",
        "closed_at": "2018-06-01T17:53:16+00:00",
        "comments_count": [
            "frozenfires",
            "yana-xuyan",
            "fancyerii",
            "fancyerii",
            "xikunlun001",
            "shoegazerstella"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 199,
        "title": "Support FP16 calculation",
        "body": "Hi!\r\nDoes Deep Speech support calculations using FP16 ?\r\nWe are interested in this problem, because Nvidia v100 shows more TFLOPS with FP16 than FP32.\r\nThanks.",
        "state": "closed",
        "user": "VictorBebnev",
        "closed_by": "zh794390558",
        "created_at": "2018-03-29T15:40:45+00:00",
        "updated_at": "2021-05-12T05:18:33+00:00",
        "closed_at": "2021-05-12T05:18:33+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 202,
        "title": "中文声韵母建模",
        "body": "项目需要，用中文的声韵母来做建模单元，解码时需要wfst构图，请问这部分有代码参考吗，谢谢",
        "state": "closed",
        "user": "tao-githup",
        "closed_by": "zh794390558",
        "created_at": "2018-04-04T11:41:47+00:00",
        "updated_at": "2021-05-12T05:18:26+00:00",
        "closed_at": "2021-05-12T05:18:26+00:00",
        "comments_count": [
            "pkuyym",
            "tao-githup",
            "bolt163"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 203,
        "title": "Aborted when run Aishell example's run_infer_golden.sh",
        "body": "I cannot finish the baseline of aishell example for the following problem:\r\n  \r\n> root@a6a7c2f6ef28:/DeepSpeech/examples/aishell# sh run_infer_golden.sh \r\n-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/aishell/mean_std.npz\r\nmodel_path: models/aishell/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: models/aishell/vocab.txt\r\n------------------------------------------------\r\nI0410 03:30:05.007586    65 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=1 \r\n[INFO 2018-04-10 03:30:10,774 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-10 03:30:10,775 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-10 03:30:10,776 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-10 03:30:10,777 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-10 03:30:10,777 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-10 03:30:10,778 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-10 03:30:14,952 model.py:243] begin to initialize the external scorer for decoding\r\nterminate called after throwing an instance of 'lm::FormatLoadException'\r\n  what():  kenlm/lm/binary_format.cc:160 in void* lm::ngram::BinaryFormat::LoadBinary(std::size_t) threw FormatLoadException because `file_size != util::kBadSize && file_size < total_map'.\r\nBinary file has size 1087809998 but the headers say it should be at least 2953349384\r\n*** Aborted at 1523331015 (unix time) try \"date -d @1523331015\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x41) received by PID 65 (TID 0x7f7bf9cc6700) from PID 65; stack trace: ***\r\n    @     0x7f7bf98a2390 (unknown)\r\n    @     0x7f7bf94fc428 gsignal\r\n    @     0x7f7bf94fe02a abort\r\n    @     0x7f7bea3c484d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f7bea3c26b6 (unknown)\r\n    @     0x7f7bea3c2701 std::terminate()\r\n    @     0x7f7bea3c2919 __cxa_throw\r\n    @     0x7f7bdebd565f lm::ngram::BinaryFormat::LoadBinary()\r\n    @     0x7f7bdebe0605 lm::ngram::detail::GenericModel<>::GenericModel()\r\n    @     0x7f7bdebd73db lm::ngram::LoadVirtual()\r\n    @     0x7f7bded08a5f Scorer::load_lm()\r\n    @     0x7f7bded0c041 Scorer::setup()\r\n    @     0x7f7bded0c13d Scorer::Scorer()\r\n    @     0x7f7bdecc6f48 _wrap_new_Scorer\r\n    @           0x4c468a PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4de6fe (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f492e (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4c9faf PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4de6fe (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f492e (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f46a7 (unknown)\r\n    @           0x4b670c (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4c9faf PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\nAborted (core dumped)\r\nFailed in inference!\r\n\r\nand I'm running in the docker. Could you please help me solve it?",
        "state": "closed",
        "user": "zhaoqxu97",
        "closed_by": "zhaoqxu97",
        "created_at": "2018-04-10T03:40:30+00:00",
        "updated_at": "2018-04-19T07:03:30+00:00",
        "closed_at": "2018-04-19T07:03:30+00:00",
        "comments_count": [
            "gangyahaidao",
            "zhaoqxu97",
            "zhaoqxu97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 204,
        "title": "nvidia-docker中训练aishell模型出现CudnnBatchNormLayer::backward()失败问题",
        "body": "Thread [140347691067136] Forwarding __batch_norm_0__, \r\n*** Aborted at 1523453910 (unix time) try \"date -d @1523453910\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGSEGV (@0x0) received by PID 19 (TID 0x7fa53e456700) from PID 0; stack trace: ***\r\n    @     0x7fa53e032390 (unknown)\r\n    @     0x7fa518ea6c82 paddle::CudnnBatchNormLayer::backward()\r\n    @     0x7fa518f2e2bd paddle::NeuralNetwork::backward()\r\n    @     0x7fa519270bb0 GradientMachine::forwardBackward()\r\n    @     0x7fa518d295f4 _wrap_GradientMachine_forwardBackward\r\n    @           0x4cb45e PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca099 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4ca8d1 PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4c2509 PyEval_EvalCode\r\n    @           0x4f1def (unknown)\r\n    @           0x4ec652 PyRun_FileExFlags\r\n    @           0x4eae31 PyRun_SimpleFileExFlags\r\n    @           0x49e14a Py_Main\r\n    @     0x7fa53dc77830 __libc_start_main\r\n    @           0x49d9d9 _start\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\n\r\n\r\n模型配置：\r\nI0411 13:38:14.460194    19 Util.cpp:166] commandline:  --use_gpu=True --rnn_use_batch=False --log_clipping=True --trainer_count=1 \r\n[INFO 2018-04-11 13:38:17,982 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-11 13:38:17,983 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-11 13:38:17,985 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-11 13:38:17,986 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-11 13:38:17,987 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-11 13:38:17,988 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n\r\nadd_arg('batch_size',       int,    8,    \"Minibatch size.\")\r\nadd_arg('trainer_count',    int,    1,      \"# of Trainers (CPUs or GPUs).\")\r\nadd_arg('num_passes',       int,    200,    \"# of training epochs.\")\r\nadd_arg('num_proc_data',    int,    16,     \"# of CPUs for data preprocessing.\")\r\nadd_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\nadd_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\nadd_arg('rnn_layer_size',   int,    1024,   \"# of recurrent cells per layer.\")\r\nadd_arg('num_iter_print',   int,    100,    \"Every # iterations for printing \"\r\n                                            \"train cost.\")\r\nadd_arg('learning_rate',    float,  5e-4,   \"Learning rate.\")\r\nadd_arg('max_duration',     float,  60.0,   \"Longest audio duration allowed.\")\r\nadd_arg('min_duration',     float,  0.0,    \"Shortest audio duration allowed.\")\r\nadd_arg('test_off',         bool,   False,  \"Turn off testing.\")\r\nadd_arg('use_sortagrad',    bool,   True,   \"Use SortaGrad or not.\")\r\nadd_arg('use_gpu',          bool,   True,   \"Use GPU or not.\")\r\nadd_arg('use_gru',          bool,   True,  \"Use GRUs instead of simple RNNs.\")\r\nadd_arg('is_local',         bool,   True,   \"Use pserver or not.\")\r\nadd_arg('share_rnn_weights',bool,   False,   \"Share input-hidden weights across \"\r\n                                            \"bi-directional RNNs. Not for GRU.\")\r\n\r\n语言模型：Mandarin LM Small.\r\n\r\n环境： VGA compatible controller: NVIDIA Corporation GK110B [GeForce GTX TITAN Black] (rev a1)\r\n             ubuntu 16.04\r\n\r\n正常生成Manifest文件，均值方差文件，运用提供的词表。然后出现了这个问题，请问应该怎么解决？\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "DLZSY",
        "closed_by": "zh794390558",
        "created_at": "2018-04-11T14:28:38+00:00",
        "updated_at": "2021-05-12T05:18:47+00:00",
        "closed_at": "2021-05-12T05:18:47+00:00",
        "comments_count": [
            "kuke",
            "Lebhoryi",
            "Lebhoryi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 206,
        "title": "chinese",
        "body": "",
        "state": "closed",
        "user": "auzxb",
        "closed_by": "auzxb",
        "created_at": "2018-04-13T15:46:10+00:00",
        "updated_at": "2018-04-13T15:47:25+00:00",
        "closed_at": "2018-04-13T15:47:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 205,
        "title": "Why is there a constant score for OOV?",
        "body": "[This](https://github.com/PaddlePaddle/DeepSpeech/blob/e1013dc44f88746c95e3b49643cc156e54e6dfae/decoders/swig/scorer.cpp#L84) line gives a score of -1000 (which is declared [here](https://github.com/PaddlePaddle/DeepSpeech/blob/e1013dc44f88746c95e3b49643cc156e54e6dfae/decoders/swig/scorer.h#L16)), to any n-gram which contains an OOV. \r\nWhy have you used this approach instead of getting an OOV based score from the language model itself? My guess is because the LM used by you is developed using common_crawl dataset and is heavily pruned, so it makes sense to have a much stricter OOV check. Is the same approach necessary for a language model which is not built using Common_crawl and uses our own higher quality dataset?",
        "state": "closed",
        "user": "ankitmundada",
        "closed_by": "zh794390558",
        "created_at": "2018-04-13T13:25:55+00:00",
        "updated_at": "2021-05-12T05:18:40+00:00",
        "closed_at": "2021-05-12T05:18:40+00:00",
        "comments_count": [
            "pkuyym",
            "ankitmundada"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 211,
        "title": "导入DeepSpeech2Model出错",
        "body": "在docker里启动demo_server.py时报错：from model_utils.model import DeepSpeech2Model，但是在本地运行是没问题的。\r\n\r\n`Traceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 14, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"/deep/DeepSpeech-develop/deploy/../model_utils/model.py\", line 15, in <module>\r\n    from decoders.swig_wrapper import Scorer\r\n  File \"/deep/DeepSpeech-develop/deploy/../decoders/swig_wrapper.py\", line 6, in <module>\r\n    import swig_decoders\r\n  File \"/usr/local/lib/python2.7/dist-packages/swig_decoders-1.1-py2.7-linux-x86_64.egg/swig_decoders.py\", line 28, in <module>\r\n    _swig_decoders = swig_import_helper()\r\n  File \"/usr/local/lib/python2.7/dist-packages/swig_decoders-1.1-py2.7-linux-x86_64.egg/swig_decoders.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_swig_decoders', fp, pathname, description)\r\nImportError: /usr/local/lib/python2.7/dist-packages/swig_decoders-1.1-py2.7-linux-x86_64.egg/_swig_decoders.so: undefined symbol: FLAGS_fst_default_cache_gc\r\nFailed in starting demo server!\r\n`",
        "state": "closed",
        "user": "frozenfires",
        "closed_by": "frozenfires",
        "created_at": "2018-04-19T03:24:17+00:00",
        "updated_at": "2018-04-20T02:05:23+00:00",
        "closed_at": "2018-04-20T02:05:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 208,
        "title": "识别延时问题",
        "body": "你好，请问你们所说的识别一句话在1s以内是怎么做到的，我测试baidu12k模型反应时间都在10几秒，字数平均为5个字。",
        "state": "closed",
        "user": "pinweihelai",
        "closed_by": "zh794390558",
        "created_at": "2018-04-17T13:01:00+00:00",
        "updated_at": "2021-05-12T05:17:39+00:00",
        "closed_at": "2021-05-12T05:17:39+00:00",
        "comments_count": [
            "gangyahaidao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 210,
        "title": "run_data.sh中计算训练集mean_std错误",
        "body": "Aishell的run_data.sh 前2步成功（生成manifest文件和vocabulary文件），但生成mean and stddev 文件时报错，提示：\r\nFile \"tools/compute_mean_std.py\", line 47, in main\r\n    normalizer.write_to_file(args.output_path)\r\n  File \"/home/robot/paddle/DeepSpeech-develop/tools/../data_utils/normalizer.py\", line 68, in write_to_file\r\n    np.savez(filepath, mean=self._mean, std=self._std)\r\n  File \"/usr/lib64/python2.7/site-packages/numpy/lib/npyio.py\", line 595, in savez\r\n    _savez(file, args, kwds, False)\r\n  File \"/usr/lib64/python2.7/site-packages/numpy/lib/npyio.py\", line 716, in _savez\r\n    pickle_kwargs=pickle_kwargs)\r\n  File \"/usr/lib64/python2.7/site-packages/numpy/lib/format.py\", line 562, in write_array\r\n    version)\r\n  File \"/usr/lib64/python2.7/site-packages/numpy/lib/format.py\", line 308, in _write_array_header\r\n    header = asbytes(_filter_header(header))\r\n  File \"/usr/lib64/python2.7/site-packages/numpy/lib/format.py\", line 467, in _filter_header\r\n    return tokenize.untokenize(tokens)\r\n  File \"/usr/lib64/python2.7/tokenize.py\", line 262, in untokenize\r\n    return ut.untokenize(iterable)\r\n  File \"/usr/lib64/python2.7/tokenize.py\", line 198, in untokenize\r\n    self.add_whitespace(start)\r\n  File \"/usr/lib64/python2.7/tokenize.py\", line 187, in add_whitespace\r\n    assert row <= self.prev_row\r\nAssertionError\r\n\r\n请问下可能会是什么问题？ Thanks！",
        "state": "closed",
        "user": "crmlei",
        "closed_by": "zh794390558",
        "created_at": "2018-04-18T08:37:17+00:00",
        "updated_at": "2021-05-12T05:17:26+00:00",
        "closed_at": "2021-05-12T05:17:26+00:00",
        "comments_count": [
            "crmlei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 213,
        "title": "can not download capi from https://guest@paddleci.ngrok.io/repository/download/Manylinux1_CpuAvxCp27cp27mu/.lastSuccessful/paddle.tgz",
        "body": "I can not download this https://guest@paddleci.ngrok.io/repository/download/Manylinux1_CpuAvxCp27cp27mu/.lastSuccessful/paddle.tgz\r\n\r\n![image](https://user-images.githubusercontent.com/10062479/39001276-87818012-4413-11e8-9bbd-7b52e27f18f7.png)\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2018-04-19T15:22:18+00:00",
        "updated_at": "2018-04-19T17:24:49+00:00",
        "closed_at": "2018-04-19T17:12:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 212,
        "title": "Error report: Errors about run \"BaiduCN1.2k Model\" !",
        "body": "Hello guys, when i test Aishell, everything runs ok, except the high \"Word Error Rate\"!\r\n\r\nthen i begin to test \"BaiduCN1.2k Model\", something went wrong.\r\n\r\n1.i known that BaiduCN1.2k speech rate is 8khz, then I change the hz from file demo_server.py and demo_client.py  to 8000hz, when i speak from the mocrophone, i get some errors from demo_server.py, as follow:\r\n```\r\nReceived utterance[length=94208] from 127.0.0.1, saved to demo_cache/20180419073019_127.0.0.1.wav.\r\n/usr/local/lib/python2.7/dist-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n```\r\nand when the warmup file is 8000hz, got the same error:\r\n```\r\n('Warm-up Test Case %d: %s', 0, u'/home/train/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0913/BAC009S0913W0152.wav')\r\n/usr/local/lib/python2.7/dist-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n```\r\nI dont known why, please light me\r\n\r\n2.question two: I dont known how to run asr server by \"BaiduCN1.2k Model\", here is my config file run_zh_demo_server.sh```\r\n\r\n# start demo server\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython -u deploy/demo_server.py \\\r\n--host_ip='localhost' \\\r\n--host_port=8086 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--alpha=1.15 \\\r\n--beta=0.15 \\\r\n--cutoff_prob=1.0 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--share_rnn_weights=False \\\r\n--speech_save_dir='demo_cache' \\\r\n--warmup_manifest='data/aishell/manifest.test' \\\r\n--mean_std_path='models/baidu_zh12k/mean_std.npz' \\\r\n--vocab_path='models/baidu_zh12k/vocab.txt' \\\r\n--model_path='models/baidu_zh12k/params.tar.gz' \\\r\n--lang_model_path='models/lm/zh_giga.no_cna_cmn.prune01244.klm' \\\r\n--decoding_method='ctc_beam_search' \\\r\n--specgram_type='linear'\r\n```\r\nafter I startup the server, it cannot recognise wav file correct, what else I need to do?\r\n\r\nany help will be very appreciate, thank you ",
        "state": "closed",
        "user": "gangyahaidao",
        "closed_by": "gangyahaidao",
        "created_at": "2018-04-19T07:39:34+00:00",
        "updated_at": "2019-04-20T07:12:52+00:00",
        "closed_at": "2018-04-19T09:29:00+00:00",
        "comments_count": [
            "frozenfires",
            "gangyahaidao",
            "frozenfires",
            "frozenfires",
            "gangyahaidao",
            "frozenfires",
            "gangyahaidao",
            "gangyahaidao",
            "gangyahaidao",
            "blood0708",
            "blood0708",
            "sunjunlishi",
            "sunjunlishi",
            "code-R"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 214,
        "title": "Why I speend a whole night to load and initial the 70G file \"Mandarin LM Large\", it is not done yet ??",
        "body": "Hello, guys:\r\n\r\nNow i want to to load the file \"Mandarin LM Large\" which is 70G size for ASR, but I speed the whole last night to init it, it has not done yet, Here is my load info output:\r\n```\r\n-----------  Configuration Arguments -----------\r\nalpha: 1.15\r\nbeam_size: 500\r\nbeta: 0.15\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/zhidao_giga.klm\r\nmean_std_path: models/aishell/mean_std.npz\r\nmodel_path: models/aishell/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: models/aishell/vocab.txt\r\nwarmup_manifest: data/aishell/manifest.test\r\n------------------------------------------------\r\nI0420 00:18:23.264974  2271 Util.cpp:166] commandline:  --use_gpu=1 --trainer_count=1 \r\n[INFO 2018-04-20 00:18:24,713 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-20 00:18:24,714 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-20 00:18:24,715 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-04-20 00:18:24,715 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-20 00:18:24,716 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-20 00:18:24,716 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-04-20 00:18:28,632 model.py:243] begin to initialize the external scorer for decoding\r\n\r\n```\r\n\r\nI don't known why, any help will appreciate?\r\n\r\nthis is my computer hardware info:\r\n7.7 GiB\r\nIntel® Xeon(R) CPU E3-1231 v3 @ 3.40GHz × 8\r\nGeForce GTX 1070/PCIe/SSE2",
        "state": "closed",
        "user": "gangyahaidao",
        "closed_by": "gangyahaidao",
        "created_at": "2018-04-20T02:09:29+00:00",
        "updated_at": "2018-04-25T06:22:18+00:00",
        "closed_at": "2018-04-25T06:22:18+00:00",
        "comments_count": [
            "gangyahaidao",
            "kuke",
            "gangyahaidao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 215,
        "title": "我的docker镜像是基于paddlepaddle的，使用的是cpu，但是报cuda的错误",
        "body": "我自己制作的deepspeech2镜像，已经设置use_gpu=False，demo_server启动成功。但是，识别时会报Cuda Error。帮帮我！\r\n\r\nReceived utterance[length=98304] from 172.17.0.1, saved to demo_cache/20180419115913_172.17.0.1.wav.\r\nF0419 11:59:16.257073   178 hl_cuda_device.cc:565] Check failed: cudaSuccess == cudaStat (0 vs. 35) Cuda Error: CUDA driver version is insufficient for CUDA runtime version\r\n*** Check failure stack trace: ***\r\n    @     0x7f62e287927d  google::LogMessage::Fail()\r\n    @     0x7f62e287cd2c  google::LogMessage::SendToLog()\r\n    @     0x7f62e2878da3  google::LogMessage::Flush()\r\n    @     0x7f62e287e23e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f62e2833673  hl_stream_synchronize()\r\n    @     0x7f62e246bae7  paddle::SubSequenceLayer::forward()\r\n    @     0x7f62e259802d  paddle::NeuralNetwork::forward()\r\n    @     0x7f62e24235dd  _wrap_GradientMachine_forward\r\n    @           0x4c30ce  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d54b9  (unknown)\r\n    @           0x4eebee  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n    @           0x4d8f92  PyInstance_New\r\n    @           0x4c15bf  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\nAborted (core dumped)\r\nFailed in starting demo server!\r\n\r\n如果有cpu版本的镜像，那就更好了",
        "state": "closed",
        "user": "frozenfires",
        "closed_by": "zh794390558",
        "created_at": "2018-04-20T02:15:07+00:00",
        "updated_at": "2021-05-12T05:17:33+00:00",
        "closed_at": "2021-05-12T05:17:33+00:00",
        "comments_count": [
            "gangyahaidao",
            "frozenfires",
            "xueshang-liulp",
            "frozenfires",
            "xueshang-liulp",
            "hui001",
            "puti-flower"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 216,
        "title": "编译steup.sh时，出现c和c++转换错误",
        "body": "如题，使用win7系统编译setup.sh时，出现以下警告和错误：\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wimplicit-function-declaration’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wimplicit-function-declaration’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\nkenlm/util/exception.cc: 在构造函数‘util::ErrnoException::ErrnoException()’中:\r\nkenlm/util/exception.cc:78:62: 错误：‘strerror_r’在此作用域中尚未声明\r\n   const char *add = HandleStrerror(strerror_r(errno, buf, 200), buf);\r\n\r\n主要是因为c和c++转换的问题，是缺少了某个库吗，还是什么原因？",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-04-22T09:59:42+00:00",
        "updated_at": "2021-05-12T05:17:20+00:00",
        "closed_at": "2021-05-12T05:17:20+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 217,
        "title": "编译steup.sh时，出现c和c++转换错误",
        "body": "如题，使用win7系统编译setup.sh时，出现以下警告和错误：\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wimplicit-function-declaration’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wimplicit-function-declaration’ is valid for C/ObjC but not for C++\r\ncc1plus: 警告：command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\nkenlm/util/exception.cc: 在构造函数‘util::ErrnoException::ErrnoException()’中:\r\nkenlm/util/exception.cc:78:62: 错误：‘strerror_r’在此作用域中尚未声明\r\n   const char *add = HandleStrerror(strerror_r(errno, buf, 200), buf);\r\n\r\n主要是因为c和c++转换的问题，是缺少了某个库吗，还是什么原因？",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-04-22T09:59:47+00:00",
        "updated_at": "2021-05-12T05:17:14+00:00",
        "closed_at": "2021-05-12T05:17:14+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 218,
        "title": "can we use BaiduEN8k model as a checkpoint and continue training on our own data",
        "body": "can we use this python train.py --init_model_path CHECKPOINT_PATH_TO_RESUME_FROM command to train the BaiduEN8k model with our own data to further increase accuracy. @pkuyym \r\n",
        "state": "closed",
        "user": "saibharani",
        "closed_by": "zh794390558",
        "created_at": "2018-04-23T15:15:03+00:00",
        "updated_at": "2021-05-12T05:17:07+00:00",
        "closed_at": "2021-05-12T05:17:07+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 219,
        "title": "what are the tuning's required for far field recognition using BaiduEN8k model",
        "body": "I want to test the far field recognition accuracy of BaiduEN8k model can anyone suggest some hyper parameter tunings or any other tips for increasing the present poor accuracy levels for far-field recognition.\r\nThank you. @pkuyym ",
        "state": "closed",
        "user": "saibharani",
        "closed_by": "zh794390558",
        "created_at": "2018-04-24T15:42:54+00:00",
        "updated_at": "2021-05-12T05:17:00+00:00",
        "closed_at": "2021-05-12T05:17:00+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 220,
        "title": "如何识别自己的数据",
        "body": "看了一下评论，demo里的识别都是测试的时候及时拿麦克风录的，再进行在线识别。但我所在的课题组已经有了一些自己的语音数据，每条3-5min左右，是否可以用百度给出的已经训练好的模型来进行识别呢？",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-04-25T03:09:11+00:00",
        "updated_at": "2021-05-12T05:16:45+00:00",
        "closed_at": "2021-05-12T05:16:45+00:00",
        "comments_count": [
            "saibharani",
            "gangyahaidao",
            "jiaozhusos",
            "jiaozhusos"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 221,
        "title": "setup.sh编译",
        "body": "请教一个非常low的问题，因为之前一直是使用windows系统，但是各种报错，所以更改至centos6.9环境下，在安装依赖库（boost, ogg等）的时候有一点问题，比如安装boost时候，是否可以直接安装boost-devel？每次运行setup.sh时，总是显示依赖库版本不对，devel和dev都可以吗，还是必须要boost-dev？",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-04-26T05:57:40+00:00",
        "updated_at": "2021-05-12T05:16:32+00:00",
        "closed_at": "2021-05-12T05:16:32+00:00",
        "comments_count": [
            "jiaozhusos",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 222,
        "title": "soundfile问题",
        "body": "在运行examples/tiny里的run_data，出现以下错误：\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/hwja/anaconda3/envs/py2/lib/python2.7/site-packages/soundfile.py\", line 373, in read\r\n    subtype, endian, format, closefd) as f:\r\n  File \"/home/hwja/anaconda3/envs/py2/lib/python2.7/site-packages/soundfile.py\", line 740, in __init__\r\n    self._file = self._open(file, mode_int, closefd)\r\n  File \"/home/hwja/anaconda3/envs/py2/lib/python2.7/site-packages/soundfile.py\", line 1265, in _open\r\n    \"Error opening {0!r}: \".format(self.name))\r\n  File \"/home/hwja/anaconda3/envs/py2/lib/python2.7/site-packages/soundfile.py\", line 1455, in _error_check\r\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\r\nRuntimeError: Error opening '61-70968-0000.flac': File contains data in an unimplemented format.\r\n这一般是什么原因引起的呢？\r\n",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-04-28T03:13:39+00:00",
        "updated_at": "2021-05-12T05:16:38+00:00",
        "closed_at": "2021-05-12T05:16:38+00:00",
        "comments_count": [
            "kuke",
            "robin521111",
            "gekelly",
            "Aionrichman"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 223,
        "title": "在PASS:14时SWAP空间被占满",
        "body": "系统环境：CentOS7 64bit，1块GTX 1080TI，内存32G，SWAP：100G\r\n运行 aishell 训练脚本，在PASS: 14, Batch: 5000 ... 时 SWAP空间被占满，deepspeech或paddlepaddle不会自动释放空间吗？还是原本就需要很大的SWAP？那么SWAP大小设置多少比较合适？\r\n![_20180429155352](https://user-images.githubusercontent.com/24585538/39404763-04d1b6a8-4bcc-11e8-9199-c07e6108adba.png)\r\n![_20180429155406](https://user-images.githubusercontent.com/24585538/39404764-0514312c-4bcc-11e8-8fbe-aa1951f4e53a.png)\r\n\r\n",
        "state": "closed",
        "user": "Cxywzx",
        "closed_by": "Cxywzx",
        "created_at": "2018-04-29T08:44:15+00:00",
        "updated_at": "2018-05-09T00:33:07+00:00",
        "closed_at": "2018-05-09T00:33:07+00:00",
        "comments_count": [
            "Cxywzx",
            "Cxywzx",
            "kuke",
            "Cxywzx",
            "Cxywzx",
            "Cxywzx",
            "pkuyym",
            "Cxywzx",
            "VictorBebnev",
            "Cxywzx",
            "Cxywzx",
            "Cxywzx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 224,
        "title": "中文识别时间问题",
        "body": "使用aishell模型进行中文识别，感觉非常慢，而且效果也不好。\r\n另外，想基于baidu_1.2k_model进行识别，但是模型里没有vocab.text，此外，相应的warmup_manifest也没有，需要怎么进行设置呢?\r\n（待识别的数据本来是一条3-5min的，但是实在太慢，就换成aishell的其中一条wav数据了，只有几秒钟，还是非常慢，等了很久也没有最终的结果出来，是我的设置有问题吗还是参数需要调整一下？）\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/aishell/mean_std.npz\r\nmodel_path: models/aishell/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: my_data\r\nuse_gpu: False\r\nuse_gru: 1\r\nvocab_path: data/aishell/vocab.txt\r\nwarmup_manifest: data/aishell/manifest.test\r\n------------------------------------------------\r\nI0506 15:04:53.478561  3892 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\n[INFO 2018-05-06 15:04:53,587 layers.py:2689] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-06 15:04:53,588 layers.py:3251] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-06 15:04:53,589 layers.py:7409] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-06 15:04:53,590 layers.py:2689] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-05-06 15:04:53,591 layers.py:3251] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-05-06 15:04:53,591 layers.py:7409] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-05-06 15:05:00,766 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-05-06 15:05:06,010 model.py:253] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2018-05-06 15:05:06,010 model.py:254] end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'/home/hwja/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0913/BAC009S0913W0441.wav')\r\nResponse Time: 51.677608, Transcript: 篮\r\n('Warm-up Test Case %d: %s', 1, u'/home/hwja/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0912/BAC009S0912W0243.wav')\r\nResponse Time: 46.002436, Transcript: 篮\r\n('Warm-up Test Case %d: %s', 2, u'/home/hwja/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0902/BAC009S0902W0189.wav')\r\nResponse Time: 40.113678, Transcript: 篮\r\n-----------------------------------------------------------\r\nASR Server Started.\r\n",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-05-02T07:32:00+00:00",
        "updated_at": "2021-05-12T05:16:26+00:00",
        "closed_at": "2021-05-12T05:16:26+00:00",
        "comments_count": [
            "jiaozhusos",
            "wuzong19",
            "Ckj409399",
            "sunjunlishi",
            "whaozl",
            "sunjunlishi",
            "whaozl",
            "sunjunlishi",
            "whaozl",
            "liuborama",
            "whaozl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 226,
        "title": "model infer时infer_results中出现nan",
        "body": "使用自有数据训练的模型，在预测过程中时常报以下错误\r\n*** Aborted at 1516804178 (unix time) try \"date -d @1516804178\" if you are using GNU date ***\r\nPC: @ 0x0 (unknown)\r\n*** SIGFPE (@0x7fe13bdd2f36) received by PID 8361 (TID 0x7fe12114b700) from PID 1004351286; stack trace: ***\r\n\r\n经过debug发现问题出在https://github.com/PaddlePaddle/DeepSpeech/blob/dad1c2727e375beb05dd747b06b04d0438e4a78d/model_utils/model.py#L197\r\n\r\n对于特定的utterance，infer_results中会出现nan，具体表现是infer得到的向量值随着time step减小，最终变成nan\r\n\r\n例子如下\r\n![35201525813754_ pic_hd](https://user-images.githubusercontent.com/1272486/39784768-2d9a8a38-534c-11e8-962d-1117b310eeac.jpg)\r\n\r\n![35171525813706_ pic_hd](https://user-images.githubusercontent.com/1272486/39784751-1fa2841c-534c-11e8-9f0f-730657da6b7b.jpg)\r\n\r\n其中每行为time step以及对应的向量\r\n\r\n",
        "state": "closed",
        "user": "neozhangthe1",
        "closed_by": "zh794390558",
        "created_at": "2018-05-08T21:46:21+00:00",
        "updated_at": "2021-05-12T05:16:19+00:00",
        "closed_at": "2021-05-12T05:16:19+00:00",
        "comments_count": [
            "pkuyym",
            "neozhangthe1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 225,
        "title": "Segmentation fault in using JNI_CreateJavaVM with paddle",
        "body": "Hey,\r\n\r\nWe are using DeepSpeech in our project using provided docker image. First of all, terrific work in both PaddlePaddle and DeepSpeech.\r\n\r\nTo reproduce the error, we made a sample [github repo](https://github.com/rmalav15/swig_wrapper). For the project requirement we need to use [JNI_CreateJavaVM](https://github.com/rmalav15/swig_wrapper/blob/4cd328a755c5f77ffba34b87805b2799b97d0b9d/gfg.cpp#L45) to use java jar classes in our c++ code, which is in turn will be used in DeepSpeech python code using swig wrapper.\r\n\r\nWhen we run demo [test.py](https://github.com/rmalav15/swig_wrapper/blob/master/test.py) (which doesn't import paddle), it runs prefectly. But when we add import paddle:\r\n```\r\nimport gfg\r\nimport paddle.v2 as paddle\r\n\r\nprint gfg.fact(5)\r\nprint gfg.my_mod(3,4)\r\n#gfg.vm()\r\ngfg.main()\r\n```\r\n\r\nand run it, we get:\r\n```\r\n120\r\n3\r\nusing pool:)\r\nSegmentation fault (core dumped)\r\n```\r\n\r\n\r\nThe stack trace is this (When we used JNI_CreateJavaVM in DeepSpeech Code):\r\n\r\n> Received utterance[length=245760] from 10.158.19.119, saved to demo_cache/20180504155105_10.158.19.119.wav.\r\n> *** Aborted at 1525449065 (unix time) try \"date -d @1525449065\" if you are using GNU date ***\r\n> PC: @ 0x0 (unknown)\r\n> *** SIGSEGV (@0x50) received by PID 7060 (TID 0x7fde57e0a700) from PID 80; stack trace: ***\r\n> @ 0x7fde579e6390 (unknown)\r\n> @ 0x7fde57bfe73c (unknown)\r\n> @ 0x7fde57c07851 (unknown)\r\n> @ 0x7fde57c02564 (unknown)\r\n> @ 0x7fde57c06da9 (unknown)\r\n> @ 0x7fde57407f09 (unknown)\r\n> @ 0x7fde57c02564 (unknown)\r\n> @ 0x7fde57408571 (unknown)\r\n> @ 0x7fde57407fa1 dlopen\r\n> @ 0x7fde133fce75 os::Linux::clock_init()\r\n> @ 0x7fde13400049 os::init()\r\n> @ 0x7fde1354cca2 Threads::create_vm()\r\n> @ 0x7fde131aae64 JNI_CreateJavaVM\r\n> @ 0x7fde13daf06e create_vm()\r\n> @ 0x7fde13daf2dc main_fn()\r\n> @ 0x7fde13d46af8 _wrap_main_fn\r\n> @ 0x4c468a PyEval_EvalFrameEx\r\n> @ 0x4c2765 PyEval_EvalCodeEx\r\n> @ 0x4ca099 PyEval_EvalFrameEx\r\n> @ 0x4c2765 PyEval_EvalCodeEx\r\n> @ 0x4ca8d1 PyEval_EvalFrameEx\r\n> @ 0x4c2765 PyEval_EvalCodeEx\r\n> @ 0x4ca8d1 PyEval_EvalFrameEx\r\n> @ 0x4c9d8f PyEval_EvalFrameEx\r\n> @ 0x4c2765 PyEval_EvalCodeEx\r\n> @ 0x4de6fe (unknown)\r\n> @ 0x4b0cb3 PyObject_Call\r\n> @ 0x4f492e (unknown)\r\n> @ 0x4b0cb3 PyObject_Call\r\n> @ 0x4ce5d0 PyEval_CallObjectWithKeywords\r\n> @ 0x4e17e4 PyInstance_New\r\n> @ 0x4b0cb3 PyObject_Call\r\n> Segmentation fault (core dumped)\r\n\r\nThis sounds weird, but its actually happening. \r\n\r\nIt looks like there is some problem in using threads. The[ JNI_CreateJavaVM](https://www.cis.upenn.edu/~bcpierce/courses/629/jdkdocs/guide/jni/spec/invocation.doc.html) function description  says that it \"Loads and initializes a Java VM. The current thread becomes the main thread.\" Which is I think causing the problem. (I am not sure, I may be completely wrong).\r\n\r\nPlease let us know why its happening, It will be huge help.\r\n\r\nMuch Thanks\r\n",
        "state": "closed",
        "user": "rmalav15",
        "closed_by": "rmalav15",
        "created_at": "2018-05-07T10:43:39+00:00",
        "updated_at": "2018-05-19T12:43:52+00:00",
        "closed_at": "2018-05-19T12:43:52+00:00",
        "comments_count": [
            "kuke",
            "rmalav15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 227,
        "title": "安装paddlepaddle报错",
        "body": "你好，我再机器上执行（pip install paddlepaddle）装paddlepaddle的时候，报以下错误：\r\n[xxxxxx@l22-240-81 DeepSpeech]$ pip install paddlepaddle\r\nCollecting paddlepaddle\r\n  Using cached https://files.pythonhosted.org/packages/9c/bf/5f466741befa8b27a36cb8b224912f7fd7b0c4af58d6cdbb7b47bb366ae7/paddlepaddle-0.11.0-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting graphviz (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/84/44/21a7fdd50841aaaef224b943f7d10df87e476e181bb926ccf859bcb53d48/graphviz-0.8.3-py2.py3-none-any.whl\r\nCollecting scipy>=0.19.0 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/2a/f3/de9c1bd16311982711209edaa8c6caa962db30ebb6a8cc6f1dcd2d3ef616/scipy-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting nltk>=3.2.2 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip\r\nCollecting opencv-python (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/57/81/0a678c3f457f880c26ab4bd32c4bdcd3fb6fa5d335e9e8683798d290c9b3/opencv_python-3.4.0.12-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting numpy>=1.12 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/c0/e7/08f059a00367fd613e4f2875a16c70b6237268a1d6d166c6d36acada8301/numpy-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting Pillow (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/00/49/a0483e7308b4b04b5a898789911dbb876d9fea54e7df0453915e47744cfd/Pillow-5.1.0-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting matplotlib (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/33/da/6409d32c46778ed20308e83bc501ff2ff8a9cbda5dd7b26362c5e99a6149/matplotlib-2.2.2-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting recordio>=0.1.0 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/01/29/ee510d487bb2665e53b0171a6473531a3df86341ade7ab68d879cc6a2ac4/recordio-0.1.5-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting requests==2.9.2 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/8b/e7/229a428b8eb9a7f925ef16ff09ab25856efe789410d661f10157919f2ae2/requests-2.9.2-py2.py3-none-any.whl\r\nCollecting rarfile (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/de/a4/8b4abc72310da6fa53b6de8de1019e0516885d05369d6c91cba23476abe5/rarfile-3.0.tar.gz\r\nCollecting protobuf==3.1 (from paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/b2/30/ab593c6ae73b45a5ef0b0af24908e8aec27f79efcda2e64a3df7af0b92a2/protobuf-3.1.0-py2.py3-none-any.whl\r\nRequirement already satisfied: six in /usr/lib/python2.7/site-packages (from nltk>=3.2.2->paddlepaddle) (1.9.0)\r\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/6a/8a/718fd7d3458f9fab8e67186b00abdd345b639976bc7fb3ae722e1b026a50/pyparsing-2.2.0-py2.py3-none-any.whl\r\nCollecting backports.functools-lru-cache (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\r\nCollecting subprocess32 (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/b8/2f/49e53b0d0e94611a2dc624a1ad24d41b6d94d0f1b0a078443407ea2214c2/subprocess32-3.2.7.tar.gz\r\nRequirement already satisfied: pytz in /usr/lib/python2.7/site-packages (from matplotlib->paddlepaddle) (2018.4)\r\nCollecting python-dateutil>=2.1 (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/0c/57/19f3a65bcf6d5be570ee8c35a5398496e10a0ddcbc95393b2d17f86aaaf8/python_dateutil-2.7.2-py2.py3-none-any.whl\r\nCollecting kiwisolver>=1.0.1 (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/3a/62/a8c9bef3059d55ab38e41fe9cba4fad773bfc04e47290bab84db1c18262e/kiwisolver-1.0.1-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting cycler>=0.10 (from matplotlib->paddlepaddle)\r\n  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\r\nRequirement already satisfied: setuptools in /usr/lib/python2.7/site-packages (from protobuf==3.1->paddlepaddle) (0.9.8)\r\nrtslib-fb 2.1.63 has requirement pyudev>=0.16.1, but you'll have pyudev 0.15 which is incompatible.\r\nmatplotlib 2.2.2 has requirement six>=1.10, but you'll have six 1.9.0 which is incompatible.\r\nInstalling collected packages: graphviz, numpy, scipy, nltk, opencv-python, Pillow, pyparsing, backports.functools-lru-cache, subprocess32, python-dateutil, kiwisolver, cycler, matplotlib, recordio, requests, rarfile, protobuf, paddlepaddle\r\nCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/lib/python2.7/site-packages/graphviz'\r\nConsider using the `--user` option or check the permissions.\r\n\r\n=======================================================\r\n系统版本 ： Linux version 4.9.0 (root@localhost.localdomain) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) ) #1 SMP Wed May 2 11:23:23 CST 2018\r\nPython版本：2.7\r\n\r\n请教有什么办法吗？\r\n",
        "state": "closed",
        "user": "songxia928",
        "closed_by": "zh794390558",
        "created_at": "2018-05-09T08:30:30+00:00",
        "updated_at": "2021-05-12T05:16:05+00:00",
        "closed_at": "2021-05-12T05:16:05+00:00",
        "comments_count": [
            "pkuyym",
            "gdfspy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 229,
        "title": "Illegal instruction (core dumped) Failed in evaluation!",
        "body": "Hi,\r\n\r\nI am facing a below-mentioned problem when evaluating pretrained models. Any help would be appreciated. Also, Thank you for providing DeepSpeech Pretrained Models.\r\n\r\nOperating System : AWS Ubuntu 16.04\r\n\r\n```\r\nDeepSpeech/examples/tiny$ sudo sh run_test_golden.sh\r\nDownload language model ...\r\ndownload_lm_en.sh: 8: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n--2018-05-13 22:32:15--  http://paddlepaddle.bj.bcebos.com/model_zoo/speech/common_crawl_00.prune01111.trie.klm\r\nResolving paddlepaddle.bj.bcebos.com (paddlepaddle.bj.bcebos.com)... 103.235.46.61\r\nConnecting to paddlepaddle.bj.bcebos.com (paddlepaddle.bj.bcebos.com)|103.235.46.61|:80... connected.\r\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\r\n\r\n    The file is already fully retrieved; nothing to do.\r\n\r\ndownload_lm_en.sh: 20: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\nDownload LibriSpeech model ...\r\ndownload_model.sh: 8: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\n--2018-05-13 22:32:50--  http://cloud.dlnel.org/filepub/?uuid=117cde63-cd59-4948-8b80-df782555f7d6\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 202.108.23.203\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|202.108.23.203|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\nLength: unspecified [application/x-tar]\r\nSaving to: ‘./librispeech_model.tar.gz’\r\n\r\n./librispeech_model.ta     [                    <=>   ] 159.29M  4.54MB/s    in 62s\r\n\r\n2018-05-13 22:33:54 (2.58 MB/s) - ‘./librispeech_model.tar.gz’ saved [167029229]\r\n\r\ndownload_model.sh: 20: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\nmean_std.npz\r\nparams.tar.gz\r\nREADME.md\r\nvocab.txt\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbatch_size: 8\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/librispeech/mean_std.npz\r\nmodel_path: models/librispeech/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_proc_data: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntest_manifest: data/tiny/manifest.test-clean\r\ntrainer_count: 8\r\nuse_gpu: 0\r\nuse_gru: 0\r\nvocab_path: models/librispeech/vocab.txt\r\n------------------------------------------------\r\nIllegal instruction (core dumped)\r\nFailed in evaluation!\r\n\r\n```\r\nrun_test_golden.sh file\r\n\r\n```\r\nDeepSpeech/examples/tiny$ cat run_test_golden.sh \r\n#! /usr/bin/env bash\r\n\r\ncd ../.. > /dev/null\r\n\r\n# download language model\r\ncd models/lm > /dev/null\r\nsh download_lm_en.sh\r\nif [ $? -ne 0 ]; then\r\n    exit 1\r\nfi\r\ncd - > /dev/null\r\n\r\n\r\n# download well-trained model\r\ncd models/librispeech > /dev/null\r\nsh download_model.sh\r\nif [ $? -ne 0 ]; then\r\n    exit 1\r\nfi\r\ncd - > /dev/null\r\n\r\n\r\n# evaluate model\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\r\npython -u test.py \\\r\n--batch_size=8 \\\r\n--trainer_count=8 \\\r\n--beam_size=500 \\\r\n--num_proc_bsearch=8 \\\r\n--num_proc_data=8 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--alpha=2.5 \\\r\n--beta=0.3 \\\r\n--cutoff_prob=1.0 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=False \\\r\n--use_gpu=False \\\r\n--share_rnn_weights=True \\\r\n--test_manifest='data/tiny/manifest.test-clean' \\\r\n--mean_std_path='models/librispeech/mean_std.npz' \\\r\n--vocab_path='models/librispeech/vocab.txt' \\\r\n--model_path='models/librispeech/params.tar.gz' \\\r\n--lang_model_path='models/lm/common_crawl_00.prune01111.trie.klm' \\\r\n--decoding_method='ctc_beam_search' \\\r\n--error_rate_type='wer' \\\r\n--specgram_type='linear'\r\n\r\nif [ $? -ne 0 ]; then\r\n    echo \"Failed in evaluation!\"\r\n    exit 1\r\nfi\r\n\r\n\r\nexit 0\r\n```\r\nSwig Decoders\r\n\r\n```\r\nDeepSpeech/examples/tiny$ pip show swig-decoders\r\n---\r\nMetadata-Version: 1.0\r\nName: swig-decoders\r\nVersion: 1.1\r\nSummary: CTC decoders\r\nHome-page: UNKNOWN\r\nAuthor: UNKNOWN\r\nAuthor-email: UNKNOWN\r\nLicense: UNKNOWN\r\nLocation: /usr/local/lib/python2.7/dist-packages/swig_decoders-1.1-py2.7-linux-x86_64.egg\r\nRequires: \r\nClassifiers:\r\nYou are using pip version 8.1.1, however version 10.0.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n```\r\n\r\n\r\n",
        "state": "closed",
        "user": "thumarrushik",
        "closed_by": "thumarrushik",
        "created_at": "2018-05-13T22:36:55+00:00",
        "updated_at": "2018-12-13T03:50:54+00:00",
        "closed_at": "2018-05-14T12:28:42+00:00",
        "comments_count": [
            "gdfspy",
            "thumarrushik",
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 228,
        "title": "请问一下是什么原因导致识别效果很差呢？",
        "body": "测试了2个模型，aishell和baidu_cn1.2k，在warm_up阶段看起来效果都很好，在实际使用中效果则非常差，请问可能是什么原因呢？谢谢！\r\n\r\n我采用的是android平板进行录音，16000 sample rate，16bit signed PCM转32 bit signed PCM的wav。\r\n\r\n听了一下，感觉会有一些背景噪声。\r\n\r\n日志如下：\r\n```\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5 \r\nbeam_size: 500 \r\nbeta: 0.3 \r\ncutoff_prob: 1.0 \r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: 0.0.0.0\r\nhost_port: 8086\r\nlang_model_path: ./models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: ./models/aishell/mean_std.npz\r\nmodel_path: ./models/aishell/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: True\r\nvocab_path: ./models/aishell/vocab.txt\r\nwarmup_manifest: data/aishell/manifest.test\r\n------------------------------------------------\r\nI0511 17:51:47.988626 26012 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1 \r\n[INFO 2018-05-11 17:51:55,003 layers.py:2714] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-11 17:51:55,004 layers.py:3282] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-11 17:51:55,005 layers.py:7454] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-11 17:51:55,005 layers.py:2714] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-05-11 17:51:55,006 layers.py:3282] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848 \r\n[INFO 2018-05-11 17:51:55,007 layers.py:7454] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848 \r\n[INFO 2018-05-11 17:52:00,335 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-05-11 17:52:00,453 model.py:253] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2018-05-11 17:52:00,453 model.py:254] end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ... \r\n('Warm-up Test Case %d: %s', 0, u'/home/xxx/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0913/BAC009S0913W0265.wav')\r\nResponse Time: 2.252022, Transcript: 导致技术支持世界超过了预期分配时间\r\n('Warm-up Test Case %d: %s', 1, u'/home/xxx/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0912/BAC009S0912W0378.wav')\r\nResponse Time: 1.892228, Transcript: 早在申办北京冬奥会的时候\r\n('Warm-up Test Case %d: %s', 2, u'/home/xxx/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0902/BAC009S0902W0485.wav')\r\n```",
        "state": "closed",
        "user": "xylcbd",
        "closed_by": "xylcbd",
        "created_at": "2018-05-11T09:59:08+00:00",
        "updated_at": "2020-07-29T02:42:07+00:00",
        "closed_at": "2018-05-11T11:44:49+00:00",
        "comments_count": [
            "pkuyym",
            "xylcbd",
            "pkuyym",
            "xylcbd",
            "pkuyym",
            "xylcbd",
            "sunjunlishi",
            "YanqiangWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 231,
        "title": "How to port the model to PyTorch?",
        "body": "Is it possible to port this model to pytorch. I am planning to use it Cuda 9 and cudnn 7, which is not supported by PaddlePaddle. \r\nI can think of following things at an upper level. What other steps should be there?\r\n1. Create a network similar to https://github.com/PaddlePaddle/DeepSpeech/blob/develop/model_utils/network.py\r\n2. Load params from param.tgz \r\n\r\nHas anyone tried doing this before?",
        "state": "closed",
        "user": "ankitmundada",
        "closed_by": "zh794390558",
        "created_at": "2018-05-15T12:12:26+00:00",
        "updated_at": "2021-05-12T05:15:58+00:00",
        "closed_at": "2021-05-12T05:15:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 230,
        "title": "Has anyone tried without Docker?",
        "body": "OS: Ubuntu 16.04\r\nCUDA: 8.0\r\ncudnn: 7.0.1\r\npaddlepaddle whl: https://paddleci.ngrok.io/viewLog.html?buildId=35434&buildTypeId=Manylinux1_Cuda8cudnn7cp27cp27mu&tab=artifacts\r\n**NOT USING DOCKER**\r\n\r\nI am trying to run infer using Baidu's 8k hours model, but I keep getting the following error:\r\n\r\n```\r\nINFO 2018-05-14 06:47:52,296 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nF0514 06:47:52.311513 23044 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_,&creator) Unknown class type: cudnn_conv\r\n*** Check failure stack trace: ***\r\n    @     0x7ff7576f00ad  google::LogMessage::Fail()\r\n    @     0x7ff7576f3b5c  google::LogMessage::SendToLog()\r\n    @     0x7ff7576efbd3  google::LogMessage::Flush()\r\n    @     0x7ff7576f506e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7ff75743101b  paddle::Layer::create()\r\n    @     0x7ff757500388  _ZZN6paddle13NeuralNetwork4initERKNS_11ModelConfigESt8functionIFviPNS_9ParameterEEERKSt6vectorINS_19enumeration_wrapper13ParameterTypeESaISB_EEbENKUlRKNS_11LayerConfigEE_clESI_\r\n    @     0x7ff7575012af  paddle::NeuralNetwork::init()\r\n    @     0x7ff7574fa169  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @     0x7ff7574dd0df  paddle::GradientMachine::create()\r\n    @     0x7ff7576cc9c5  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7ff7576ccbaf  GradientMachine::createByConfigProtoStr()\r\n    @     0x7ff757359477  _wrap_GradientMachine_createByConfigProtoStr\r\n    @     0x7ff79030d210  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff79030d9b8  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff79030d9b8  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff790299377  function_call\r\n    @     0x7ff7902747a3  PyObject_Call\r\n    @     0x7ff79028363d  instancemethod_call\r\n    @     0x7ff7902747a3  PyObject_Call\r\n    @     0x7ff7902cd584  slot_tp_init\r\n    @     0x7ff7902c9e3b  type_call\r\n    @     0x7ff7902747a3  PyObject_Call\r\n    @     0x7ff79030ab69  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff79030d9b8  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff79030d9b8  PyEval_EvalFrameEx\r\n    @     0x7ff7903104e9  PyEval_EvalCodeEx\r\n    @     0x7ff79030d9b8  PyEval_EvalFrameEx\r\nAborted (core dumped)\r\nFail in training!\r\n```\r\n\r\nHas anyone else got this error too and successfully resolved it?",
        "state": "closed",
        "user": "ankitmundada",
        "closed_by": "zh794390558",
        "created_at": "2018-05-15T12:07:28+00:00",
        "updated_at": "2021-05-12T05:16:12+00:00",
        "closed_at": "2021-05-12T05:16:12+00:00",
        "comments_count": [
            "thumarrushik"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 233,
        "title": "Fail to download the language model!(下载中文语言模型失败)",
        "body": "I failed to download language model twice. Both are interrupted when reaching 1.01G. Is there any problem about the URL or it is just my personal problem?\r\n\r\nHere's the running detail:\r\n\r\n> $ sh run_infer_golden.sh\r\n> Download language model ...\r\n> --2018-05-21 01:13:51--  http://cloud.dlnel.org/filepub/?uuid=5cd1688e-78d9-4b9e-9c2f-6f104bd5b518\r\n> Resolving cloud.dlnel.org... 115.239.210.226\r\n> Connecting to cloud.dlnel.org|115.239.210.226|:80... connected.\r\n> HTTP request sent, awaiting response... 200 OK\r\n> Cookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\n> Length: unspecified [text/html]\r\n> Saving to: './zh_giga.no_cna_cmn.prune01244.klm'\r\n> \r\n> ./zh_giga.no_cna_cmn.prune01244.klm              [                                                                                 <=>           ]   1.01G  3.28MB/s    in 5m 50s  \r\n> \r\n> 2018-05-21 01:19:41 (2.96 MB/s) - './zh_giga.no_cna_cmn.prune01244.klm' saved [1087762436]\r\n> \r\n> Fail to download the language model!",
        "state": "closed",
        "user": "CynthiaSuwi",
        "closed_by": "zh794390558",
        "created_at": "2018-05-20T17:27:35+00:00",
        "updated_at": "2021-05-12T05:15:46+00:00",
        "closed_at": "2021-05-12T05:15:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 235,
        "title": "error occurs when training model on my own dataset",
        "body": "Hi, I tried to train a Mandarin model on my own dataset(200h), used 6 gpus(K80c) in docker with ubuntu16.04,  but i got the following error:\r\n\r\n...................................................................................................\r\nPass: 0, Batch: 100, TrainCost: 43.864211\r\n...................................................................................................\r\nPass: 0, Batch: 200, TrainCost: 46.124234\r\n...................................................................................................\r\nPass: 0, Batch: 300, TrainCost: 60.454348\r\n...................................................................................................\r\nPass: 0, Batch: 400, TrainCost: 50.351969\r\n...................................................................................................\r\nPass: 0, Batch: 500, TrainCost: 60.703720\r\n...................................................................................................\r\nPass: 0, Batch: 600, TrainCost: 65.057645\r\n...................................................................................................\r\nPass: 0, Batch: 700, TrainCost: 45.140548\r\n...................................................................................................\r\nPass: 0, Batch: 800, TrainCost: 61.789109\r\n...................................................................................................\r\nPass: 0, Batch: 900, TrainCost: 54.016421\r\n...................................................................................................\r\nPass: 0, Batch: 1000, TrainCost: 41.392280\r\n...................................................................................................\r\nPass: 0, Batch: 1100, TrainCost: 37.685595\r\n...................................................................................................\r\nPass: 0, Batch: 1200, TrainCost: 27.951182\r\n...................................................................................................\r\nPass: 0, Batch: 1300, TrainCost: 34.722017\r\n...................................................................................................\r\nPass: 0, Batch: 1400, TrainCost: 34.317093\r\n..............................................................Traceback (most recent call last):\r\n  File \"train.py\", line 129, in <module>\r\n    main()\r\n  File \"train.py\", line 125, in main\r\n    train()\r\n  File \"train.py\", line 116, in train\r\n    test_off=args.test_off)\r\n  File \"/data/wjx/workspace/DeepSpeech/model_utils/model.py\", line 155, in train\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 201, in train\r\n    gm=self.__gradient_machine__))\r\n  File \"/data/wjx/workspace/DeepSpeech/model_utils/model.py\", line 140, in event_handler\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 234, in test\r\n    evaluator=evaluator, cost=total_cost / num_samples)\r\nZeroDivisionError: float division by zero\r\nFailed in training!\r\n\r\nany one can help me?\r\nthanks!\r\n\r\n",
        "state": "closed",
        "user": "wujsy",
        "closed_by": "wujsy",
        "created_at": "2018-05-25T02:58:33+00:00",
        "updated_at": "2018-06-19T07:50:25+00:00",
        "closed_at": "2018-06-19T07:50:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 232,
        "title": "I cann't find impulse audio data and noise data !!!!!!!! how to find impulse data or download impulse audio data?!!!!",
        "body": "",
        "state": "closed",
        "user": "amin-aa",
        "closed_by": "zh794390558",
        "created_at": "2018-05-20T06:50:15+00:00",
        "updated_at": "2021-05-12T05:15:52+00:00",
        "closed_at": "2021-05-12T05:15:52+00:00",
        "comments_count": [
            "whaozl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 236,
        "title": "有没有完整的中文教程，能让我这种傻瓜都会使用！",
        "body": "我研究了两天了，还是没有搞明白，但是现在公司项目又需要自己做语音识别！\r\n而且很急的那种········\r\n而我又很菜，英文不好！！！\r\n不知道有没有哪位大神有完整的操作教程！\r\n有经验的大神笔记给抄一下也好！留个联系方式，我加你！",
        "state": "closed",
        "user": "wuzong19",
        "closed_by": "luotao1",
        "created_at": "2018-05-27T02:34:45+00:00",
        "updated_at": "2018-06-06T02:34:09+00:00",
        "closed_at": "2018-06-06T02:34:08+00:00",
        "comments_count": [
            "frozenfires",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 238,
        "title": "这是什么原因呢？",
        "body": "-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 10\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 2\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI0527 03:22:21.053562   433 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_ba\r\ntch=True --log_clipping=True --trainer_count=2\r\n[INFO 2018-05-27 03:22:21,071 layers.py:2606] output for __conv_0__: c = 32, h =\r\n 81, w = 54, size = 139968\r\n[INFO 2018-05-27 03:22:21,074 layers.py:3133] output for __batch_norm_0__: c = 3\r\n2, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-27 03:22:21,077 layers.py:7224] output for __scale_sub_region_0__:\r\n c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-05-27 03:22:21,079 layers.py:2606] output for __conv_1__: c = 32, h =\r\n 41, w = 54, size = 70848\r\n[INFO 2018-05-27 03:22:21,082 layers.py:3133] output for __batch_norm_1__: c = 3\r\n2, h = 41, w = 54, size = 70848\r\n[INFO 2018-05-27 03:22:21,085 layers.py:7224] output for __scale_sub_region_1__:\r\n c = 32, h = 41, w = 54, size = 70848\r\nI0527 03:22:21.739264   433 GradientMachine.cpp:94] Initing parameters..\r\nI0527 03:22:25.073403   433 GradientMachine.cpp:101] Init parameters done.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 129, in <module>\r\n    main()\r\n  File \"train.py\", line 125, in main\r\n    train()\r\n  File \"train.py\", line 116, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 155, in train\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 162,\r\nin train\r\n    for batch_id, data_batch in enumerate(reader()):\r\n  File \"/DeepSpeech/model_utils/model.py\", line 391, in adapted_reader\r\n    for instance in data():\r\n  File \"/DeepSpeech/data_utils/data.py\", line 199, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 178, in xreader\r\n    manager = Manager()\r\n  File \"/usr/lib/python2.7/multiprocessing/__init__.py\", line 99, in Manager\r\n    m.start()\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 524, in start\r\n    self._process.start()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 130, in start\r\n    self._popen = Popen(self)\r\n  File \"/usr/lib/python2.7/multiprocessing/forking.py\", line 121, in __init__\r\n    self.pid = os.fork()\r\nOSError: [Errno 12] Cannot allocate memory\r\nFail in training!",
        "state": "closed",
        "user": "wuzong19",
        "closed_by": "zh794390558",
        "created_at": "2018-05-27T03:24:09+00:00",
        "updated_at": "2021-05-12T05:15:14+00:00",
        "closed_at": "2021-05-12T05:15:14+00:00",
        "comments_count": [
            "frozenfires",
            "jiangliuer-beep"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 237,
        "title": "manifest 文件语音文件可以使用wav吗？默认的是flac，请问怎么设置？",
        "body": "因为我有自己的语音，然而格式是wav的",
        "state": "closed",
        "user": "wuzong19",
        "closed_by": "zh794390558",
        "created_at": "2018-05-27T03:06:46+00:00",
        "updated_at": "2021-05-12T05:15:33+00:00",
        "closed_at": "2021-05-12T05:15:33+00:00",
        "comments_count": [
            "thumarrushik"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 241,
        "title": "我用Aishell训练中文的几个问题. ",
        "body": "1. Training无法收敛. 如果RNN只有一层就可以. \r\n2. 用网上下载的model, 在docker上infer_golden, 报错退出. \r\n3. wav是转为多少pin的mfcc 或者 spectrum, 作为输入的呢? \r\n\r\n谢谢. ",
        "state": "closed",
        "user": "bjtommychen",
        "closed_by": "zh794390558",
        "created_at": "2018-06-01T16:30:27+00:00",
        "updated_at": "2021-05-12T05:15:26+00:00",
        "closed_at": "2021-05-12T05:15:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 239,
        "title": "我训练一个汉语模型，将aishell的数据集降采样为8k的，结果不能收敛，最左还报错了。",
        "body": "...................................................................................................\r\nPass: 0, Batch: 100, TrainCost: 68.859889\r\n...................................................................................................\r\nPass: 0, Batch: 200, TrainCost: 68.140386\r\n...................................................................................................\r\nPass: 0, Batch: 300, TrainCost: 73.981499\r\n...................................................................................................\r\nPass: 0, Batch: 400, TrainCost: 79.325998\r\n...................................................................................................\r\nPass: 0, Batch: 500, TrainCost: 84.907326\r\n...................................................................................................\r\nPass: 0, Batch: 600, TrainCost: 91.324884\r\n...................................................................................................\r\nPass: 0, Batch: 700, TrainCost: 98.817860\r\n...................................................................................................\r\nPass: 0, Batch: 800, TrainCost: 106.118329\r\n...................................................................................................\r\nPass: 0, Batch: 900, TrainCost: 111.627918\r\n...................................................................................................\r\nPass: 0, Batch: 1000, TrainCost: 85.846820\r\n........................................................................Traceback (most recent call last):\r\n  File \"train.py\", line 129, in <module>\r\n    main()\r\n  File \"train.py\", line 125, in main\r\n    train()\r\n  File \"train.py\", line 116, in train\r\n    test_off=args.test_off)\r\n  File \"/data/chensong/code/20180522_deepspeech/DeepSpeech/model_utils/model.py\", line 155, in train\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 201, in train\r\n    gm=self.__gradient_machine__))\r\n  File \"/data/chensong/code/20180522_deepspeech/DeepSpeech/model_utils/model.py\", line 140, in event_handler\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 234, in test\r\n    evaluator=evaluator, cost=total_cost / num_samples)\r\nZeroDivisionError: float division by zero\r\nFailed in training!\r\n\r\n\r\n原始的16k的数据可以正常训练，并收敛。但降采样为8k就不行了。还有自己准备的其他8k数据也不行。\r\n求指教！！！\r\n",
        "state": "closed",
        "user": "songxia928",
        "closed_by": "zh794390558",
        "created_at": "2018-05-29T01:46:48+00:00",
        "updated_at": "2021-05-12T05:15:39+00:00",
        "closed_at": "2021-05-12T05:15:39+00:00",
        "comments_count": [
            "songxia928",
            "liufei1656",
            "zongweiLi",
            "songxia928",
            "songxia928",
            "zongweiLi",
            "songxia928",
            "zongweiLi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 240,
        "title": "Inference script hang there",
        "body": "Hi @kuke ,\r\n\r\nHad you experienced with case run with infer script , but it stop there without any response, but if i change to use run_test script , everything good here.\r\n\r\n======<br />\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 2\r\nnum_rnn_layers: 5\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntrainer_count: 2\r\nuse_gpu: 1\r\nuse_gru: 1\r\n------------------------------------------------\r\nI0601 12:33:21.749088   258 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=2\r\n\r\n<br />",
        "state": "closed",
        "user": "chesterkuo",
        "closed_by": "chesterkuo",
        "created_at": "2018-06-01T04:43:10+00:00",
        "updated_at": "2018-06-15T07:04:46+00:00",
        "closed_at": "2018-06-15T07:04:46+00:00",
        "comments_count": [
            "chesterkuo",
            "chesterkuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 243,
        "title": "train.py Error",
        "body": "",
        "state": "closed",
        "user": "thumarrushik",
        "closed_by": "thumarrushik",
        "created_at": "2018-06-02T04:56:01+00:00",
        "updated_at": "2018-06-08T00:08:54+00:00",
        "closed_at": "2018-06-08T00:08:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 242,
        "title": "Not logging in tune.py",
        "body": "Hi @cs2be @reyoung \r\n\r\nI need help to resolve my issue. During tune.py, It stops generating log after that (wait for 3 hours)\r\n\r\n```\r\n[INFO 2018-06-02 04:42:49,663 layers.py:2716] output for __con\r\nv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-06-02 04:42:49,664 layers.py:3361] output for __bat\r\nch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-06-02 04:42:49,665 layers.py:7533] output for __sca\r\nle_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-06-02 04:42:49,666 layers.py:2716] output for __con\r\nv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-06-02 04:42:49,666 layers.py:3361] output for __bat\r\nch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-06-02 04:42:49,667 layers.py:7533] output for __sca\r\nle_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-06-02 04:42:54,934 model.py:243] begin to initializ\r\ne the external scorer for decoding\r\n[INFO 2018-06-02 04:44:17,487 model.py:253] language model: is\r\n_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2018-06-02 04:44:17,746 model.py:254] end initializing s\r\ncorer\r\n[INFO 2018-06-02 04:44:17,747 tune.py:119] start tuning ...\r\n```\r\n\r\nUsed Cuda v8, Cudann V7, Ubuntu 16.04, GPU Tesla P100.\r\n\r\nIt's working totally in good condition with test.py\r\n\r\n\r\nThank You for any help",
        "state": "closed",
        "user": "thumarrushik",
        "closed_by": "thumarrushik",
        "created_at": "2018-06-02T04:50:24+00:00",
        "updated_at": "2018-09-11T01:42:44+00:00",
        "closed_at": "2018-06-03T04:48:40+00:00",
        "comments_count": [
            "WIll-Xu35"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 244,
        "title": "Why the output of the CTC decoder is not seperated by space?",
        "body": "Hi,\r\n\r\nI used logits from another model (Wav2Letter) to test the CTC decoder, however, I can't get correct results from the decoder, for example,\r\nI got :\"sometimemesttheeultbotthfehinatetwhorkhasreallygod\" from the decoder while the greedy decoder gave me \"sometimd es the ou but of fan at work is really god\".\r\nI am wondering why the CTC decoder will concatenate all the characters?\r\n\r\nThanks,",
        "state": "closed",
        "user": "dreamibor",
        "closed_by": "dreamibor",
        "created_at": "2018-06-03T17:40:24+00:00",
        "updated_at": "2018-06-05T13:57:29+00:00",
        "closed_at": "2018-06-03T19:31:29+00:00",
        "comments_count": [
            "dreamibor"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 249,
        "title": "Do we have to split our data into pieces ?",
        "body": "Hi, I need to convert some wav files to text, each with 30 minutes. Do I have to split them into one or two sentences and if so, how could I do that? Thanks!",
        "state": "closed",
        "user": "zhaoqxu97",
        "closed_by": "zh794390558",
        "created_at": "2018-06-04T12:40:45+00:00",
        "updated_at": "2021-05-12T05:15:20+00:00",
        "closed_at": "2021-05-12T05:15:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 250,
        "title": "2 GPU is not working in tune.py",
        "body": "",
        "state": "closed",
        "user": "thumarrushik",
        "closed_by": "thumarrushik",
        "created_at": "2018-06-05T12:50:05+00:00",
        "updated_at": "2018-06-08T00:09:27+00:00",
        "closed_at": "2018-06-05T16:33:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 245,
        "title": "Incorrect output from CTC decoder",
        "body": "Hi,\r\n\r\nWhat's the input shape of the CTC decoder, is it (time_setps, num_classes)? The output from the CTC decoder is like \"(nan, \"ud rkn z ob elm c bi c vb wpx usr bg wr tok r weu ktt ty f ' pk ej stj w qe pd ayu gbs r jnl gc h bli po ggc h w j roi qk s e ech esf b wnm siba qa fu\")\" while it will be okay to use greedy decoder. I am using Python 3 and compile the CTC decoder for Python 3.5. Is that relevant?\r\n\r\nThanks in advance!",
        "state": "closed",
        "user": "dreamibor",
        "closed_by": "dreamibor",
        "created_at": "2018-06-03T19:31:22+00:00",
        "updated_at": "2019-02-01T09:56:18+00:00",
        "closed_at": "2018-06-04T13:09:24+00:00",
        "comments_count": [
            "dreamibor",
            "sruteesh-pivot"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 251,
        "title": "use  Paddlepaddle  to train deepspeech  show: Cannot allocate memory",
        "body": "============================================================ \r\n## ***    Print content:\r\n============================================================\r\n...................................................................................................\r\nPass: 25, Batch: 3100, TrainCost: 2.208693\r\n...............................\r\n------- Time: 7017 sec,  Pass: 25, ValidationCost: 52.2345577601\r\n...................................................................................................\r\nPass: 26, Batch: 100, TrainCost: 1.603295\r\n...................................................................................................\r\nPass: 26, Batch: 200, TrainCost: 1.676432\r\n...................................................................................................\r\nPass: 26, Batch: 300, TrainCost: 1.612143\r\n...................................................................................................\r\nPass: 26, Batch: 400, TrainCost: 1.353869\r\n...................................................................................................\r\nPass: 26, Batch: 500, TrainCost: 1.482893\r\n...................................................................................................\r\nPass: 26, Batch: 600, TrainCost: 1.687072\r\n...................................................................................................\r\nPass: 26, Batch: 700, TrainCost: 1.966297\r\n...................................................................................................\r\nPass: 26, Batch: 800, TrainCost: 1.420656\r\n...................................................................................................\r\nPass: 26, Batch: 900, TrainCost: 1.590458\r\n...................................................................................................\r\nPass: 26, Batch: 1000, TrainCost: 2.041432\r\n...................................................................................................\r\nPass: 26, Batch: 1100, TrainCost: 1.333077\r\n...................................................................................................\r\nPass: 26, Batch: 1200, TrainCost: 1.839570\r\n...................................................................................................\r\nPass: 26, Batch: 1300, TrainCost: 1.614656\r\n...................................................................................................\r\nPass: 26, Batch: 1400, TrainCost: 1.606205\r\n...................................................................................................\r\nPass: 26, Batch: 1500, TrainCost: 2.410910\r\n...................................................................................................\r\nPass: 26, Batch: 1600, TrainCost: 1.942313\r\n...................................................................................................\r\nPass: 26, Batch: 1700, TrainCost: 2.099164\r\n...................................................................................................\r\nPass: 26, Batch: 1800, TrainCost: 1.974127\r\n...................................................................................................\r\nPass: 26, Batch: 1900, TrainCost: 2.180515\r\n...................................................................................................\r\nPass: 26, Batch: 2000, TrainCost: 2.120815\r\n...................................................................................................\r\nPass: 26, Batch: 2100, TrainCost: 2.503351\r\n...................................................................................................\r\nPass: 26, Batch: 2200, TrainCost: 2.302993\r\n...................................................................................................\r\nPass: 26, Batch: 2300, TrainCost: 2.194658\r\n...................................................................................................\r\nPass: 26, Batch: 2400, TrainCost: 2.364214\r\n...................................................................................................\r\nPass: 26, Batch: 2500, TrainCost: 2.714264\r\n...................................................................................................\r\nPass: 26, Batch: 2600, TrainCost: 2.205300\r\n...................................................................................................\r\nPass: 26, Batch: 2700, TrainCost: 2.671229\r\n...................................................................................................\r\nPass: 26, Batch: 2800, TrainCost: 2.073756\r\n...................................................................................................\r\nPass: 26, Batch: 2900, TrainCost: 2.087103\r\n...................................................................................................\r\nPass: 26, Batch: 3000, TrainCost: 2.158531\r\n...................................................................................................\r\nPass: 26, Batch: 3100, TrainCost: 2.519216\r\n................................\r\n------- Time: 6982 sec,  Pass: 26, ValidationCost: 53.4873382121\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 129, in <module>\r\n    main()\r\n  File \"train.py\", line 125, in main\r\n    train()\r\n  File \"train.py\", line 116, in train\r\n    test_off=args.test_off)\r\n  File \"/data1/chensong/code/20180523_deepspeech/DeepSpeech/model_utils/model.py\", line 155, in train\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py\", line 162, in train\r\n    for batch_id, data_batch in enumerate(reader()):\r\n  File \"/data1/chensong/code/20180523_deepspeech/DeepSpeech/model_utils/model.py\", line 391, in adapted_reader\r\n    for instance in data():\r\n  File \"/data1/chensong/code/20180523_deepspeech/DeepSpeech/data_utils/data.py\", line 199, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/data1/chensong/code/20180523_deepspeech/DeepSpeech/data_utils/utility.py\", line 198, in xreader\r\n    w.start()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 130, in start\r\n    self._popen = Popen(self)\r\n  File \"/usr/lib/python2.7/multiprocessing/forking.py\", line 121, in __init__\r\n    self.pid = os.fork()\r\nOSError: [Errno 12] Cannot allocate memory\r\n\r\n\r\n\r\n============================================================ \r\n## ***    my machine state:  \r\n============================================================\r\n\r\nroot@2f9aebc64ff:/data1/code/20180523_deepspeech/DeepSpeech# nvidia-smi\r\nSun Jun 10 15:10:15 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 0000:05:00.0     Off |                    0 |\r\n| N/A   23C    P8    27W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |\r\n| N/A   25C    P8    27W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           Off  | 0000:09:00.0     Off |                    0 |\r\n| N/A   26C    P8    27W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |\r\n| N/A   27C    P8    30W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |\r\n| N/A   32C    P0    54W / 149W |   6569MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla K80           Off  | 0000:85:00.0     Off |                    0 |\r\n| N/A   37C    P0    70W / 149W |   6351MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |\r\n| N/A   33C    P0    55W / 149W |   6830MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  Tesla K80           Off  | 0000:89:00.0     Off |                    0 |\r\n| N/A   37C    P0    69W / 149W |   6542MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\nroot@2f9aebc64ff:/data1/code/20180523_deepspeech/DeepSpeech# free -w\r\n              total        used        free      shared     buffers       cache   available\r\nMem:      264057556   241080888     3589964    14154876     2435984    16950720     6184440\r\nSwap:      16777212    16452236      324976\r\n\r\n\r\n\r\n============================================================ \r\n## ***    the training parameters I set:  \r\n============================================================\r\nCUDA_VISIBLE_DEVICES=4,5,6,7 \\\r\npython -u train.py \\\r\n--batch_size=32 \\\r\n--trainer_count=4 \\\r\n--num_passes=50 \\\r\n--num_proc_data=16 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--num_iter_print=100 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=20.0 \\\r\n--min_duration=1.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=False \\\r\n--train_manifest='data_mangguo_2/aishell/manifest.train' \\\r\n--dev_manifest='data_mangguo_2/aishell/manifest.dev' \\\r\n--mean_std_path='data_mangguo_2/aishell/mean_std.npz' \\\r\n--vocab_path='data_mangguo_2/aishell/vocab.txt' \\\r\n--output_model_dir='./checkpoints/mangguo_2' \\\r\n--augment_conf_path='conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped'\r\n\r\n\r\n\r\nHi, I used PaddlePaddle to train a Chinese model based on Deepspeech. I can finish training a model with the data of aishell .  when I add more audio data to train , it will show this wrong.  From the machine state ， I guess the CPU' memory is not enough. But I don't know how to solve it .  Anyone could tell me , thanks !\r\n（我用PaddlePaddle训练一个基于Deepspeech的汉语模型。我能使用aishell的数据完成一轮训练，但是当语言数据增加时就会出现内存无法分配的错误提示，请问，有谁能知道怎么解决吗？）\r\n",
        "state": "closed",
        "user": "songxia928",
        "closed_by": "zh794390558",
        "created_at": "2018-06-10T08:00:08+00:00",
        "updated_at": "2021-05-12T05:15:06+00:00",
        "closed_at": "2021-05-12T05:15:06+00:00",
        "comments_count": [
            "kuke",
            "songxia928",
            "songxia928",
            "kuke",
            "songxia928",
            "kuke",
            "songxia928",
            "mp-lu",
            "songxia928"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 253,
        "title": "百度SDK",
        "body": "请问百度AI开放平台中的中文语音识别SDK,是采用deepspeech2的框架吗？多谢",
        "state": "closed",
        "user": "Sundy1219",
        "closed_by": "zh794390558",
        "created_at": "2018-06-12T03:16:18+00:00",
        "updated_at": "2021-05-12T05:14:36+00:00",
        "closed_at": "2021-05-12T05:14:36+00:00",
        "comments_count": [
            "pkuyym",
            "Sundy1219",
            "pkuyym",
            "Sundy1219",
            "pkuyym",
            "Sundy1219",
            "nashannashui",
            "Sundy1219"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 255,
        "title": "<space> characters before the first word in beam_search",
        "body": "If my ground truth is `word1 word2...`, does the beam search over the `space` character before the first word?\r\n\r\nIn other words, how is the prefix `space`, e.g. `blank blank space blank`, scored if there are no alphabetic characters in the prefix?  I assume this gets scored as zero (or `oov`) by the external scorer.  This leads me to believe that the only possible characters before the first word are `alphabet` and `blank` chars.",
        "state": "closed",
        "user": "mrfox321",
        "closed_by": "zh794390558",
        "created_at": "2018-06-16T12:37:39+00:00",
        "updated_at": "2021-05-12T05:14:28+00:00",
        "closed_at": "2021-05-12T05:14:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 252,
        "title": "BaiduCN1.2k Model  调参问题",
        "body": "中文识别，\r\n模型为：BaiduCN1.2k Model \r\n语言模型为：Mandarin LM Large\r\n识别效果不理想，想对alpha和beta进行调参，但是tools\\tune.py里的tune_manifest参数只有英文的，中文的数据没有，如何进行调整呢？\r\n",
        "state": "closed",
        "user": "jiaozhusos",
        "closed_by": "zh794390558",
        "created_at": "2018-06-12T02:53:15+00:00",
        "updated_at": "2021-05-12T05:14:49+00:00",
        "closed_at": "2021-05-12T05:14:49+00:00",
        "comments_count": [
            "zhaoqxu97",
            "liuborama",
            "wuliuqii"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 254,
        "title": "hl_cuda_cudnn.cc:251] Check failed: CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 3) Cudnn Error: CUDNN_STATUS_BAD_PARAM",
        "body": "When use_gpu is False issue is not observed.\r\nBut when use_gpu is True below issue is observed.\r\nCan you please tell me why this is happening.\r\n\r\nIssue summary:\r\nF0613 11:34:18.334713  1145 hl_cuda_cudnn.cc:251] Check failed: CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 3) Cudnn Error: CUDNN_STATUS_BAD_PARAM\r\n*** Check failure stack trace: ***\r\n    @     0x7f184d74304d  google::LogMessage::Fail()\r\n    @     0x7f184d745398  google::LogMessage::SendToLog()\r\n    @     0x7f184d742b5b  google::LogMessage::Flush()\r\n    @     0x7f184d74626e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f184d6e4290  hl_conv_workspace()\r\n    @     0x7f184d37b6e7  paddle::ConvBaseProjection::reshape()\r\n    @     0x7f184d37960b  paddle::ConvProjection::forward()\r\n    @     0x7f184d345df9  paddle::CudnnConvBaseLayer::forward()\r\n    @     0x7f184d3d09ff  paddle::NeuralNetwork::forward()\r\n    @     0x7f184d1caf46  _wrap_GradientMachine_forward\r\n    @           0x4bc3fa  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d54b9  (unknown)\r\n    @           0x4eebee  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n    @           0x4c5e10  PyEval_CallObjectWithKeywords\r\nDuring startup program terminated with signal SIGABRT, Aborted.",
        "state": "closed",
        "user": "krishnamohan191",
        "closed_by": "zh794390558",
        "created_at": "2018-06-13T11:46:46+00:00",
        "updated_at": "2021-05-12T05:14:56+00:00",
        "closed_at": "2021-05-12T05:14:56+00:00",
        "comments_count": [
            "krishnamohan191",
            "kuke",
            "krishnamohan191"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 258,
        "title": "Language model interpolation",
        "body": "I am planning on modifying the decoder to allow for language model interpolation (multiple scorers).  I was wondering if there is any plan on extending the decoder to allow for this.  I am going to start working on it this week.  \r\n\r\nI currently plan on allowing for 2 scorers and an interpolation parameter.  Although this can be extended for a set of language models and a set of parameters, I am not entirely sure if the SWIG python interface allows for std::vector<Scorer> (currently accepts a pointer to a Scorer).\r\n\r\nI am also considering log-linear interpolation (papers have shown it to be more performant than linear).",
        "state": "closed",
        "user": "mrfox321",
        "closed_by": "zh794390558",
        "created_at": "2018-07-04T17:43:13+00:00",
        "updated_at": "2021-05-12T05:14:21+00:00",
        "closed_at": "2021-05-12T05:14:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 259,
        "title": "CPU not support AVX",
        "body": "I use the gpu-latest version of PaddlePaddle. I have CUDA8.0 and cuDNN5.1, but my CPU doesn't support AVX. Can I use the gpu docker image? If not, could anyone provide a feasible solution for me?",
        "state": "closed",
        "user": "CynthiaSuwi",
        "closed_by": "CynthiaSuwi",
        "created_at": "2018-07-10T04:53:55+00:00",
        "updated_at": "2018-07-12T08:39:38+00:00",
        "closed_at": "2018-07-12T08:39:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 256,
        "title": "is Transfer Learning possible with Baidu En model",
        "body": "Can we use Transfer Learning on Baidu English model and make speech recognition for other languages.\r\nThank you.",
        "state": "closed",
        "user": "saibharani",
        "closed_by": "saibharani",
        "created_at": "2018-06-26T12:35:53+00:00",
        "updated_at": "2019-04-01T19:02:24+00:00",
        "closed_at": "2019-03-06T13:52:48+00:00",
        "comments_count": [
            "kuke",
            "viig99",
            "saibharani",
            "rhamnett"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 260,
        "title": "error occured  when inferenced using my own generated language model?",
        "body": "Hi, considering of speical area, I trained and generated a binary language model using kenlm tool, but errors occured when inferenced in deepspeech:\r\nI0720 14:15:50.371575  9838 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=8 \r\n[INFO 2018-07-20 14:15:57,485 layers.py:2689] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-07-20 14:15:57,486 layers.py:3251] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-07-20 14:15:57,487 layers.py:7409] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-07-20 14:15:57,488 layers.py:2689] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-07-20 14:15:57,488 layers.py:3251] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-07-20 14:15:57,489 layers.py:7409] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-07-20 14:16:02,241 model.py:243] begin to initialize the external scorer for decoding\r\nLoading the LM will be faster if you build a binary file.\r\nReading /data/chensong/lm_arpa/words_forum_o5.arpa\r\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n****************************************************************************************************\r\n[INFO 2018-07-20 14:25:22,499 model.py:253] language model: is_character_based = 0, max_order = 3, dict_size = 6950728\r\n[INFO 2018-07-20 14:25:22,500 model.py:254] end initializing scorer\r\n[INFO 2018-07-20 14:25:22,501 test.py:98] start evaluation ...\r\nI0720 14:25:27.228785  9838 MultiGradientMachine.cpp:99] numLogicalDevices=1 numThreads=8 numDevices=8\r\nF0720 14:25:27.982380  9991 Vector.cpp:266] Check failed: src.getSize() == this->getSize() (4596 vs. 4712) \r\n*** Check failure stack trace: ***\r\nF0720 14:25:27.984078  9987 Vector.cpp:266] Check failed: src.getSize() == this->getSize() (9412608 vs. 9650176) \r\n*** Check failure stack trace: ***\r\n    @     0x7fc11dc5927d  google::LogMessage::Fail()\r\n    @     0x7fc11dc5927d  google::LogMessage::Fail()\r\n    @     0x7fc11dc5cd2c  google::LogMessage::SendToLog()\r\n    @     0x7fc11dc5cd2c  google::LogMessage::SendToLog()\r\n    @     0x7fc11dc58da3  google::LogMessage::Flush()\r\n    @     0x7fc11dc58da3  google::LogMessage::Flush()\r\n    @     0x7fc11dc5e23e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc11da5e17a  paddle::GpuVectorT<>::copyFrom()\r\n    @     0x7fc11d9801f9  paddle::TrainerThread::valueDispatchThread()\r\n    @     0x7fc11dc5e23e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fc1861f7c80  (unknown)\r\n    @     0x7fc11da5e17a  paddle::GpuVectorT<>::copyFrom()\r\n    @     0x7fc18eeda6ba  start_thread\r\n    @     0x7fc18ec103dd  clone\r\n    @     0x7fc11d9801f9  paddle::TrainerThread::valueDispatchThread()\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n\r\nAs @kuke said in issue #161, \"The decoder supports language model both in binary and arpa format.\" ,the same error happened when used arpa format.\r\n\r\ndo anyone have ideas? I'll appreciated.\r\n",
        "state": "closed",
        "user": "wujsy",
        "closed_by": "zh794390558",
        "created_at": "2018-07-20T06:52:40+00:00",
        "updated_at": "2021-05-12T05:14:42+00:00",
        "closed_at": "2021-05-12T05:14:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 257,
        "title": "error during training (tiny example)",
        "body": "------ Time: 43 sec,  Pass: 5, ValidationCost: 253.10401535\r\n...\r\n------- Time: 43 sec,  Pass: 6, ValidationCost: 248.755771637\r\n...\r\n------- Time: 109 sec,  Pass: 7, ValidationCost: 246.753059387\r\n...\r\n------- Time: 108 sec,  Pass: 8, ValidationCost: 245.458805084\r\n...\r\n------- Time: 105 sec,  Pass: 9, ValidationCost: 242.365924835\r\n...\r\n------- Time: 107 sec,  Pass: 10, ValidationCost: 237.124584198\r\n...\r\n------- Time: 105 sec,  Pass: 11, ValidationCost: 233.543140411\r\n.Exception in thread Thread-25:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/utility.py\", line 153, in flush_worker\r\n    sample = in_queue.get()\r\n  File \"<string>\", line 2, in get\r\n  File \"/usr/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nIOError: got end of file during message\r\n\r\n",
        "state": "closed",
        "user": "cogmeta",
        "closed_by": "cogmeta",
        "created_at": "2018-06-30T14:53:12+00:00",
        "updated_at": "2018-07-01T15:32:29+00:00",
        "closed_at": "2018-07-01T15:32:29+00:00",
        "comments_count": [
            "cogmeta"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 261,
        "title": "Where is our own model?",
        "body": "I wonder whether we will get models that end with tar.gz if we train our own model. Because I only get 20 files in checkpoint directory that end with .tar.gz instead of .klm.",
        "state": "closed",
        "user": "RongerSnow",
        "closed_by": "RongerSnow",
        "created_at": "2018-07-21T12:39:46+00:00",
        "updated_at": "2018-07-26T10:17:56+00:00",
        "closed_at": "2018-07-26T10:17:56+00:00",
        "comments_count": [
            "frozenfires",
            "RongerSnow"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 263,
        "title": "下载 BaiduCN1.2k Model 直接报 502 错误，跟#301那个错误不一样",
        "body": "网页直接点击链接，会直接502。\r\n如果是执行 models/aishell/download_model.sh  的话会报如下错误 ，IP可以ping通，下面也显示connected。 跟#301那个错误不一样，我添加之后也还是一样的错误。比较着急用，麻烦各位大佬回复一下。\r\n--2018-07-23 12:18:01--  http://cloud.dlnel.org/filepub/?uuid=499569a6-0025-4f40-83e6-1c99527431a6\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 180.76.189.142\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|180.76.189.142|:80... connected.\r\nHTTP request sent, awaiting response... 502 Bad Gateway\r\n2018-07-23 12:18:01 ERROR 502: Bad Gateway.\r\n",
        "state": "closed",
        "user": "JinmingZhao",
        "closed_by": "JinmingZhao",
        "created_at": "2018-07-23T12:32:45+00:00",
        "updated_at": "2019-04-12T06:49:24+00:00",
        "closed_at": "2018-07-25T07:31:30+00:00",
        "comments_count": [
            "mp-lu",
            "JinmingZhao",
            "huntzhan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 262,
        "title": "Fail to download LibriSpeech Model",
        "body": "While running the command `sh run_infer_golden.sh`, I get the following error:\r\n```\r\ndownload_lm_en.sh: 20: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\nDownload LibriSpeech model ...\r\ndownload_model.sh: 8: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\n--2018-07-23 11:29:44--  http://cloud.dlnel.org/filepub/?uuid=117cde63-cd59-4948-8b80-df782555f7d6\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 202.108.23.203\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|202.108.23.203|:80... connected.\r\nHTTP request sent, awaiting response... 502 Bad Gateway\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\n2018-07-23 11:29:45 ERROR 502: Bad Gateway.\r\n\r\nFail to download LibriSpeech model!\r\n```",
        "state": "closed",
        "user": "zaffnet",
        "closed_by": "zaffnet",
        "created_at": "2018-07-23T06:04:01+00:00",
        "updated_at": "2019-05-13T06:36:50+00:00",
        "closed_at": "2018-07-25T11:29:14+00:00",
        "comments_count": [
            "zaffnet",
            "YasinZhao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 265,
        "title": "unable to use 3 or 4-gram models ",
        "body": "I tried to use 3 or 4-gram models generated using kenlm with baidu8k model. but is giving gnu time error and works fine with the 5-gram model. can you please tell how to use 3 or 4-gram models or what is the tool that should be used to preprocess our own data for custom language model.",
        "state": "closed",
        "user": "saibharani",
        "closed_by": "saibharani",
        "created_at": "2018-07-30T14:10:12+00:00",
        "updated_at": "2018-08-24T11:13:00+00:00",
        "closed_at": "2018-08-24T11:13:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 266,
        "title": "Training gets hung while using multiple GPU's",
        "body": "Hi,\r\n\r\nI'm training on a custom dataset of approx 1000hrs of data. The training starts and after completion of some batches (In this case after completion of 5397batch), the training just hangs. It does not progress to next batch. The training is using 4 GPU's on azure VM. All 4 GPU's are only ~40% utilized, so the problem is not with memory. Batch size used is 32. GPU used is K80. There is no error message nor does the program exit.\r\n\r\nIs there a problem with using multiple GPU's, does data read/write between them cause any error? Is there a way to debug this? \r\n\r\nPlease help!\r\n\r\n**Configuration:**\r\n![image](https://user-images.githubusercontent.com/12654849/43530910-4669624c-95cc-11e8-9cea-644b85073de8.png)\r\n\r\n\r\n**Screenshot of output:**\r\n![image](https://user-images.githubusercontent.com/12654849/43530762-fadd389e-95cb-11e8-804b-97cf254050ba.png)\r\n",
        "state": "closed",
        "user": "dalonlobo",
        "closed_by": "dalonlobo",
        "created_at": "2018-08-01T14:47:31+00:00",
        "updated_at": "2018-08-20T05:27:58+00:00",
        "closed_at": "2018-08-20T05:27:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 264,
        "title": "pretrained model links outdated - error 404 Unable to download",
        "body": "It seems that the links for downloading the pretrained models are dead/outdated or models where removed/moved:\r\n\r\n* clicking on the README.md Released Models links, you get:\r\nHTTP Error 404. The requested resource is not found.\r\n\r\n* same with wget/curl and download script.",
        "state": "closed",
        "user": "timotheev",
        "closed_by": "timotheev",
        "created_at": "2018-07-24T09:03:52+00:00",
        "updated_at": "2018-07-25T16:20:45+00:00",
        "closed_at": "2018-07-25T16:20:45+00:00",
        "comments_count": [
            "zaffnet",
            "timotheev"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 267,
        "title": "Deep Peak2",
        "body": "我想问下，Deep Peak2有相关的论文发出来了吗？谢谢",
        "state": "closed",
        "user": "Sundy1219",
        "closed_by": "zh794390558",
        "created_at": "2018-08-03T06:14:59+00:00",
        "updated_at": "2021-05-12T05:13:43+00:00",
        "closed_at": "2021-05-12T05:13:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 269,
        "title": "How to use original .arpa file as lm",
        "body": "Since the lm used here is a binary file(klm) but I hope to use this lm in Kaldi which only accepts .arpa file. So I'm wondering if the developer can offer the orignial file.\r\nThank you!  ",
        "state": "closed",
        "user": "yangxueruivs",
        "closed_by": "zh794390558",
        "created_at": "2018-08-09T05:58:12+00:00",
        "updated_at": "2021-05-12T05:14:05+00:00",
        "closed_at": "2021-05-12T05:14:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 268,
        "title": "download_lm_en.sh broken",
        "body": "Hi all,\r\n\r\nGot error when trying run `/models/lm/download_lm_en.sh` to download http://paddlepaddle.bj.bcebos.com/model_zoo/speech/common_crawl_00.prune01111.trie.klm\r\n\r\n```\r\n{\r\n\"code\": \"AccountOverdue\",\r\n\"message\": \"Your request is denied because there is an overdue bill of your account.\",\r\n\"requestId\": \"4b684141-1175-4691-a9cd-52c458a94845\"\r\n}\r\n```",
        "state": "closed",
        "user": "haoqiang",
        "closed_by": "zh794390558",
        "created_at": "2018-08-06T13:59:17+00:00",
        "updated_at": "2021-05-12T05:14:14+00:00",
        "closed_at": "2021-05-12T05:14:14+00:00",
        "comments_count": [
            "olegakbarov",
            "nikita-smetanin",
            "derekpankaew",
            "ashwan1",
            "tarashakhurana",
            "dileep1996",
            "qianghuang84",
            "1973Blunt",
            "sahilanguralla",
            "in03ng",
            "Ywz2018",
            "seethagithub",
            "mehercharan",
            "NeerajGulia",
            "wudeshi",
            "ces-bertino",
            "bkmgit",
            "NeerajGulia",
            "ces-bertino",
            "kuhanw",
            "lagon",
            "mtbadakhshan",
            "diegocardozo167",
            "rhamnett",
            "aaronlyt",
            "rhamnett",
            "code-R",
            "ces-bertino",
            "haowang5128",
            "Shashank112"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 270,
        "title": "Some questions about the vocab",
        "body": "Hello, I noticed that the order of characters is different in different vocabs generated by different datasets.  I am quite confused about what the vocabulary represents and how the vocabulary is used. \r\nCan you explain it to me?\r\n\r\nLook forward and many thanks.",
        "state": "closed",
        "user": "RongerSnow",
        "closed_by": "RongerSnow",
        "created_at": "2018-08-12T23:40:32+00:00",
        "updated_at": "2020-06-04T02:05:14+00:00",
        "closed_at": "2020-06-04T02:05:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 272,
        "title": "Floating point exception",
        "body": "I tried to write a script to record my voice and stop recording when I finished, but didn't work because when the script run `feature = data_generator.process_utterance(filename, \"\")` in test.py, I got Floating point exception. However, when I run the demo_server.py and the demo_cilent.py, it work prefectly. Please help!!!!\r\nUpdate: I found my speech_segment.samples only contain 0.0s. what is the problem???\r\nUpdate2: I found it is because my record2.py cannot record anything. any suggestions?\r\nhere's my code:\r\n\r\n> record2.py\r\n```python\r\nfrom sys import byteorder\r\nfrom array import array\r\nfrom struct import pack\r\n\r\nimport pyaudio\r\nimport wave\r\n\r\nTHRESHOLD = 1000000000\r\nCHUNK_SIZE = 1024\r\nFORMAT = pyaudio.paInt32\r\nRATE = 16000\r\n\r\ndef is_silent(snd_data):\r\n    \"Returns 'True' if below the 'silent' threshold\"\r\n    return max(snd_data) < THRESHOLD\r\n\r\ndef normalize(snd_data):\r\n    \"Average the volume out\"\r\n    MAXIMUM = 2147483648\r\n    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\r\n\r\n    r = array('i')\r\n    for i in snd_data:\r\n        r.append(int(i*times))\r\n    return r\r\n\r\ndef trim(snd_data):\r\n    \"Trim the blank spots at the start and end\"\r\n    def _trim(snd_data):\r\n        snd_started = False\r\n        r = array('i')\r\n\r\n        for i in snd_data:\r\n            if not snd_started and abs(i)>THRESHOLD:\r\n                snd_started = True\r\n                r.append(i)\r\n\r\n            elif snd_started:\r\n                r.append(i)\r\n        return r\r\n\r\n    # Trim to the left\r\n    snd_data = _trim(snd_data)\r\n\r\n    # Trim to the right\r\n    snd_data.reverse()\r\n    snd_data = _trim(snd_data)\r\n    snd_data.reverse()\r\n    return snd_data\r\n\r\ndef add_silence(snd_data, seconds):\r\n    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\r\n    r = array('i', [0 for i in xrange(int(seconds*RATE))])\r\n    r.extend(snd_data)\r\n    r.extend([0 for i in xrange(int(seconds*RATE))])\r\n    return r\r\n\r\ndef record():\r\n    \"\"\"\r\n    Record a word or words from the microphone and\r\n    return the data as an array of signed shorts.\r\n\r\n    Normalizes the audio, trims silence from the\r\n    start and end, and pads with 0.5 seconds of\r\n    blank sound to make sure VLC et al can play\r\n    it without getting chopped off.\r\n    \"\"\"\r\n    p = pyaudio.PyAudio()\r\n    stream = p.open(format=FORMAT, channels=1, rate=RATE,\r\n        input=True, output=True,\r\n        frames_per_buffer=CHUNK_SIZE)\r\n\r\n    num_silent = 0\r\n    snd_started = False\r\n\r\n    r = array('i')\r\n    print('listening')\r\n    while 1:\r\n        # little endian, signed short\r\n        snd_data = array('i', stream.read(CHUNK_SIZE))\r\n        print max(snd_data)\r\n        if byteorder == 'big':\r\n            snd_data.byteswap()\r\n        r.extend(snd_data)\r\n        silent = is_silent(snd_data)\r\n\r\n        if silent and snd_started:\r\n            num_silent += 1\r\n        elif not silent and not snd_started:\r\n            snd_started = True\r\n\r\n        if snd_started and num_silent > 10:\r\n            break\r\n\r\n    sample_width = p.get_sample_size(FORMAT)\r\n    stream.stop_stream()\r\n    stream.close()\r\n    p.terminate()\r\n\r\n    r = normalize(r)\r\n    r = trim(r)\r\n    r = add_silence(r, 0.5)\r\n    return sample_width, r\r\n\r\ndef record_to_file(path):\r\n    \"Records from the microphone and outputs the resulting data to 'path'\"\r\n    sample_width, data = record()\r\n    data = pack('<' + ('i'*len(data)), *data)\r\n\r\n    wf = wave.open(path, 'wb')\r\n    wf.setnchannels(1)\r\n    wf.setsampwidth(sample_width)\r\n    wf.setframerate(RATE)\r\n    wf.writeframes(data)\r\n    wf.close()\r\n\r\nif __name__ == '__main__':\r\n    print(\"please speak a word into the microphone\")\r\n    record_to_file('demo.wav')\r\n    print(\"done - result written to demo.wav\")\r\n```\r\n\r\n> test.py\r\n```python\r\nfrom record2 import record_to_file\r\n\r\n\"\"\"Server-end for the ASR demo.\"\"\"\r\nimport os\r\nimport time\r\nimport random\r\nimport argparse\r\nimport functools\r\nfrom time import gmtime, strftime\r\nimport SocketServer\r\nimport struct\r\nimport wave\r\nimport paddle.v2 as paddle\r\nimport _init_paths\r\nfrom data_utils.data import DataGenerator\r\nfrom model_utils.model import DeepSpeech2Model\r\nfrom data_utils.utility import read_manifest\r\nfrom utils.utility import add_arguments, print_arguments\r\n\r\nparser = argparse.ArgumentParser(description=__doc__)\r\nadd_arg = functools.partial(add_arguments, argparser=parser)\r\n# yapf: disable\r\nadd_arg('host_port',        int,    8086,    \"Server's IP port.\")\r\nadd_arg('beam_size',        int,    300,    \"Beam search width.\")\r\nadd_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\nadd_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\nadd_arg('rnn_layer_size',   int,    1024,   \"# of recurrent cells per layer.\")\r\nadd_arg('alpha',            float,  2.6,   \"Coef of LM for beam search.\")\r\nadd_arg('beta',             float,  5.0,   \"Coef of WC for beam search.\")\r\nadd_arg('cutoff_prob',      float,  0.99,    \"Cutoff probability for pruning.\")\r\nadd_arg('cutoff_top_n',     int,    40,     \"Cutoff number for pruning.\")\r\nadd_arg('use_gru',          bool,   True,  \"Use GRUs instead of simple RNNs.\")\r\nadd_arg('use_gpu',          bool,   False,   \"Use GPU or not.\")\r\nadd_arg('share_rnn_weights',bool,   False,   \"Share input-hidden weights across \"\r\n                                            \"bi-directional RNNs. Not for GRU.\")\r\nadd_arg('host_ip',          str,\r\n        'localhost',\r\n        \"Server's IP address.\")\r\nadd_arg('speech_save_dir',  str,\r\n        'demo_cache',\r\n        \"Directory to save demo audios.\")\r\nadd_arg('warmup_manifest',  str,\r\n        'data/aishell/manifest.test',\r\n        \"Filepath of manifest to warm up.\")\r\nadd_arg('mean_std_path',    str,\r\n        'models/aishell/mean_std.npz',\r\n        \"Filepath of normalizer's mean & std.\")\r\nadd_arg('vocab_path',       str,\r\n        'models/aishell/vocab.txt',\r\n        \"Filepath of vocabulary.\")\r\nadd_arg('model_path',       str,\r\n        'models/aishell/params.tar.gz',\r\n        \"If None, the training starts from scratch, \"\r\n        \"otherwise, it resumes from the pre-trained model.\")\r\nadd_arg('lang_model_path',  str,\r\n        'models/lm/zh_giga.no_cna_cmn.prune01244.klm',\r\n        \"Filepath for language model.\")\r\nadd_arg('decoding_method',  str,\r\n        'ctc_beam_search',\r\n        \"Decoding method. Options: ctc_beam_search, ctc_greedy\",\r\n        choices = ['ctc_beam_search', 'ctc_greedy'])\r\nadd_arg('specgram_type',    str,\r\n        'linear',\r\n        \"Audio feature type. Options: linear, mfcc.\",\r\n        choices=['linear', 'mfcc'])\r\n# yapf: disable\r\nargs = parser.parse_args()\r\n\r\n# prepare data generator\r\ndata_generator = DataGenerator(\r\n    vocab_filepath=args.vocab_path,\r\n    mean_std_filepath=args.mean_std_path,\r\n    augmentation_config='{}',\r\n    specgram_type=args.specgram_type,\r\n    num_threads=1,\r\n    keep_transcription_text=True)\r\n\r\n# prepare ASR model\r\nds2_model = DeepSpeech2Model(\r\n    vocab_size=data_generator.vocab_size,\r\n    num_conv_layers=args.num_conv_layers,\r\n    num_rnn_layers=args.num_rnn_layers,\r\n    rnn_layer_size=args.rnn_layer_size,\r\n    use_gru=args.use_gru,\r\n    pretrained_model_path=args.model_path,\r\n    share_rnn_weights=args.share_rnn_weights)\r\n\r\nvocab_list = [chars.encode(\"utf-8\") for chars in data_generator.vocab_list]\r\n\r\nif args.decoding_method == \"ctc_beam_search\":\r\n    ds2_model.init_ext_scorer(args.alpha, args.beta, args.lang_model_path,\r\n                              vocab_list)\r\n\r\n# prepare ASR inference handler\r\ndef file_to_transcript(filename):\r\n    feature = data_generator.process_utterance(filename, \"\")\r\n    probs_split = ds2_model.infer_batch_probs(\r\n        infer_data=[feature],\r\n        feeding_dict=data_generator.feeding)\r\n\r\n    if args.decoding_method == \"ctc_greedy\":\r\n        result_transcript = ds2_model.decode_batch_greedy(\r\n            probs_split=probs_split,\r\n            vocab_list=vocab_list)\r\n    else:\r\n        result_transcript = ds2_model.decode_batch_beam_search(\r\n            probs_split=probs_split,\r\n            beam_alpha=args.alpha,\r\n            beam_beta=args.beta,\r\n            beam_size=args.beam_size,\r\n            cutoff_prob=args.cutoff_prob,\r\n            cutoff_top_n=args.cutoff_top_n,\r\n            vocab_list=vocab_list,\r\n            num_processes=1)\r\n    return result_transcript[0]\r\n\r\npaddle.init(use_gpu=args.use_gpu, trainer_count=1)\r\n\r\nif __name__ == '__main__':\r\n    record_to_file('demo.wav')\r\n    print file_to_transcript('demo.wav')\r\n```\r\nand I got this:\r\n```bash\r\n*** Aborted at 1534487245 (unix time) try \"date -d @1534487245\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7f2329804bc3) received by PID 30608 (TID 0x7f232a8bc700) from PID 696273859; stack trace: ***\r\n    @     0x7f232a4d2390 (unknown)\r\n    @     0x7f2329804bc3 log10f\r\n    @     0x7f231599225a (unknown)\r\n    @     0x7f2315aa550c (unknown)\r\n    @     0x7f2315aaed62 (unknown)\r\n    @     0x7f2315aaf46e (unknown)\r\n    @           0x4c15bf PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d54b9 (unknown)\r\n    @           0x4a5371 PyObject_CallFunction\r\n    @           0x41cdd7 _PyObject_GenericGetAttrWithDict\r\n    @           0x4bc24b PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4c136f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x7f232a117830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @                0x0 (unknown)\r\nFloating point exception (core dumped)\r\n\r\n```",
        "state": "closed",
        "user": "johntyty912",
        "closed_by": "johntyty912",
        "created_at": "2018-08-17T06:55:10+00:00",
        "updated_at": "2018-08-20T06:02:14+00:00",
        "closed_at": "2018-08-20T06:02:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 271,
        "title": "output meaningless Chinese words",
        "body": "I have a dataset  with no  transcripts available, so I need to infer them. I followed the run_infer_golden.sh but got the results like this:\r\n\r\n> Output Transcription: 捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞\r\n> \r\n> Output Transcription: 捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞\r\n> \r\n> Output Transcription: 捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞呀捞\r\n\r\nCould any of you have some ideas why it got so terrible? Thanks a lot !\r\n\r\nMy configuration is as follows:\r\n```\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython -u infer.py \\\r\n--num_samples=10 \\\r\n--trainer_count=1 \\\r\n--beam_size=300 \\\r\n--num_proc_bsearch=2 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--alpha=2.4 \\\r\n--beta=5.0 \\\r\n--cutoff_prob=0.99 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--share_rnn_weights=False \\\r\n--infer_manifest='manifest.ex' \\\r\n--mean_std_path='mean_std.npz' \\\r\n--vocab_path='vocab.txt' \\\r\n--model_path='params.tar.gz' \\\r\n--lang_model_path='zhidao_giga.klm' \\\r\n--decoding_method='ctc_beam_search' \\\r\n--error_rate_type='cer' \\\r\n--specgram_type='linear'\r\n```\r\nI used the larger language model here and tried the mean_std both generated ourselves and from aishell dataset by executing run_data.sh(someone say it may work).  \r\n ",
        "state": "closed",
        "user": "zhaoqxu97",
        "closed_by": "zhaoqxu97",
        "created_at": "2018-08-13T12:18:06+00:00",
        "updated_at": "2018-08-17T17:17:50+00:00",
        "closed_at": "2018-08-17T17:17:50+00:00",
        "comments_count": [
            "zhaoqxu97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 275,
        "title": "训练自己的模型识别问题",
        "body": "大家好，最近自己训练了一个模型，训练数据相关说明：\r\n1.GPU型号：GeForce GTX 1070\r\n\r\n2.训练文件6500个，每个文件都是1到3秒钟，wav格式8000hz\r\n\r\n3.基于音频文件对应的文本使用kenlm自己生成了一个语言模型\r\n\r\n4.然后进行训练，训练参数如下：\r\n`CUDA_VISIBLE_DEVICES=0 \\\r\npython -u train.py \\\r\n--batch_size=32 \\\r\n--trainer_count=1 \\\r\n--num_passes=50 \\\r\n--num_proc_data=16 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--num_iter_print=100 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=27.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=False \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=False \\\r\n--train_manifest='data/mywavs/manifest' \\\r\n--dev_manifest='data/mywavs/manifest' \\\r\n--mean_std_path='data/mywavs/mean_std.npz' \\\r\n--vocab_path='data/mywavs/vocab.txt' \\\r\n--output_model_dir='./checkpoints/mywavs' \\\r\n--augment_conf_path='conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped'`\r\n其中--num_passes只有50，50次之后得到的结果cerr差不多是十几\r\n\r\n5.然后我将训练的模型进行实时识别，但是不管我输入的语音是什么识别的结果一直都是同一句话，或者是没有结果，想问一下这种情况是什么原因引起的呢？\r\n是需要增加数据量？ 还是需要增加训练次数？还是调参数呢？\r\n\r\n顺便介绍一下我的应用场景，我不是追求那种大而全的语音识别，我进行训练的数据只有两种，一种是用户各种肯定意向的回答，另一种是各种否定的回答，所以文件相对都比较短，前期是先用6500条进行基本的尝试看看效果",
        "state": "closed",
        "user": "gangyahaidao",
        "closed_by": "zh794390558",
        "created_at": "2018-08-29T05:16:33+00:00",
        "updated_at": "2021-05-12T05:12:45+00:00",
        "closed_at": "2021-05-12T05:12:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 276,
        "title": "speech features ",
        "body": "I want to change speech features using mfcc, but met a problem。How to change the input layer to solve this problem",
        "state": "closed",
        "user": "luoyujiaye",
        "closed_by": "luoyujiaye",
        "created_at": "2018-09-04T05:35:07+00:00",
        "updated_at": "2018-09-04T22:09:30+00:00",
        "closed_at": "2018-09-04T22:09:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 273,
        "title": "识别aishell中test语音文件正常,识别自己的wav文件就完全不对",
        "body": "文件我看都是16khz和16位的,  我自己的文件基本识别不出来\r\n\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbeam_size: 500\r\nbeta: 5.0\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: 0.0.0.0\r\nhost_port: 8086\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: data/aishell/mean_std.npz\r\nmodel_path: checkpoints/aishell/params.latest.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: False\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: True\r\nvocab_path: data/aishell/vocab.txt\r\nwarmup_manifest: data/aishell/manifest.test\r\n------------------------------------------------\r\n",
        "state": "closed",
        "user": "zhouyikang",
        "closed_by": "zhouyikang",
        "created_at": "2018-08-17T10:28:52+00:00",
        "updated_at": "2019-08-21T06:24:45+00:00",
        "closed_at": "2018-09-03T03:16:36+00:00",
        "comments_count": [
            "sunjunlishi",
            "sunjunlishi",
            "sunjunlishi",
            "sunjunlishi",
            "hui001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 274,
        "title": "语言模型Mandarin LM Small\t下载失败",
        "body": "文件名：zh_giga.no_cna_cmn.prune01244.klm\r\n文件大小2.8G，每次执行\r\n`sh run_infer.sh`\r\n都只能下载400多M\r\n\r\n网页访问下载链接结果如下\r\n![image](https://user-images.githubusercontent.com/18738958/44502451-1fac8180-a6c4-11e8-955b-0ff2cd12b0fe.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "orrorcol",
        "closed_by": "zh794390558",
        "created_at": "2018-08-23T03:03:43+00:00",
        "updated_at": "2021-05-12T05:12:52+00:00",
        "closed_at": "2021-05-12T05:12:52+00:00",
        "comments_count": [
            "zhouyikang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 277,
        "title": "Failed in inference ",
        "body": "Hello, when I tried to run the run_infer_golden.sh file, I met with the following problem. Error information is attached below.\r\n\r\n`\r\nterminate called after throwing an instance of 'lm::FormatLoadException'\r\n  what():  kenlm/lm/vocab.cc:43 in void lm::ngram::{anonymous}::ReadWords(int, lm::EnumerateVocab*, lm::WordIndex, uint64_t) threw FormatLoadException because `memcmp(check_unk, \"<unk>\", 6)'.\r\nVocabulary words are in the wrong place.  This could be because the binary file was built with stale gcc and old kenlm.  Stale gcc, including the gcc distributed with RedHat and OS X, has a bug that ignores pragma pack for template-dependent types.  New kenlm works around this, so you'll save memory but have to rebuild any binary files using the probing data structure.\r\n`\r\nI have no idea about what this problem is about and how to solve this. Have you ever encountered this kind of issue and successfully solved it? Thanks so much~~\r\n",
        "state": "closed",
        "user": "daiannan1993",
        "closed_by": "daiannan1993",
        "created_at": "2018-09-06T01:26:24+00:00",
        "updated_at": "2021-01-26T13:17:11+00:00",
        "closed_at": "2018-09-11T07:21:04+00:00",
        "comments_count": [
            "wangheng666",
            "daiannan1993"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 280,
        "title": "sh train.sh 报错",
        "body": "我的参数\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 2\r\ndev_manifest: data/aishell/manifest.dev\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.05\r\nmax_duration: 27.0\r\nmean_std_path: data/aishell/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 3\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/aishell\r\nrnn_layer_size: 128\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/aishell/manifest.train\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/aishell/vocab.txt\r\n运行结果：\r\nI0921 16:48:21.802156  1551 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=1 \r\nW0921 16:48:21.802270  1551 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON\r\n[INFO 2018-09-21 16:48:21,821 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-21 16:48:21,822 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-21 16:48:21,823 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-21 16:48:21,825 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-09-21 16:48:21,827 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-09-21 16:48:21,829 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0921 16:48:22.006682  1551 GradientMachine.cpp:94] Initing parameters..\r\nI0921 16:48:22.224419  1551 GradientMachine.cpp:101] Init parameters done.\r\nF0921 16:48:27.090147  1551 hl_cuda_device.cc:565] Check failed: cudaSuccess == cudaStat (0 vs. 35) Cuda Error: CUDA driver version is insufficient for CUDA runtime version\r\n*** Check failure stack trace: ***\r\n    @     0x7f385e536f8d  google::LogMessage::Fail()\r\n    @     0x7f385e53aa3c  google::LogMessage::SendToLog()\r\n    @     0x7f385e536ab3  google::LogMessage::Flush()\r\n    @     0x7f385e53bf4e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f385e4f48a7  hl_stream_synchronize()\r\n    @     0x7f385e268a5e  paddle::SubSequenceLayer::forward()\r\n    @     0x7f385e134d59  paddle::NeuralNetwork::forward()\r\n    @     0x7f385e1359f3  paddle::GradientMachine::forwardBackward()\r\n    @     0x7f385e513449  GradientMachine::forwardBackward()\r\n    @     0x7f385e0e28cc  _wrap_GradientMachine_forwardBackward\r\n    @           0x4c30ce  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4eb30f  (unknown)\r\n    @           0x4e5422  PyRun_FileExFlags\r\n    @           0x4e3cd6  PyRun_SimpleFileExFlags\r\n    @           0x493ae2  Py_Main\r\n    @     0x7f3884d42830  __libc_start_main\r\n    @           0x4933e9  _start\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\nFailed in training!\r\n调小了参数依然报错，且用的是CPU为什么还会有Cuda Error: CUDA driver version is insufficient for CUDA runtime version，求大神们解答下",
        "state": "closed",
        "user": "18811737901",
        "closed_by": "18811737901",
        "created_at": "2018-09-21T08:54:19+00:00",
        "updated_at": "2018-10-15T16:06:17+00:00",
        "closed_at": "2018-09-27T11:45:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 278,
        "title": "gradient exploding issue when using rnn",
        "body": "\r\n\r\nHi, I'm not sure if  this is normal. Here's the configuration and log:\r\n==================\r\n```\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 160\r\ndev_manifest: data/librispeech/manifest.dev-clean\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/librispeech/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 3\r\nnum_iter_print: 100\r\nnum_passes: 50\r\nnum_proc_data: 16\r\nnum_rnn_layers: 7\r\noutput_model_dir: ./checkpoints/libri_complex\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/librispeech/manifest.train\r\ntrainer_count: 8\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/librispeech/vocab.txt\r\n```\r\n=======================\r\n...................................................................................................\r\nPass: 0, Batch: 100, TrainCost: 125.596261\r\n...................................................................................................\r\nPass: 0, Batch: 200, TrainCost: 204.322346\r\n...................................................................................................\r\nPass: 0, Batch: 300, TrainCost: 279.806530\r\n...................................................................................................\r\nPass: 0, Batch: 400, TrainCost: 360.684450\r\n...................................................................................................\r\nPass: 0, Batch: 500, TrainCost: 399.957560\r\n...................................................................................................\r\nPass: 0, Batch: 600, TrainCost: 440.331799\r\n...................................................................................................\r\nPass: 0, Batch: 700, TrainCost: 466.695379\r\n...................................................................................................\r\nPass: 0, Batch: 800, TrainCost: 485.230144\r\n...................................................................................................\r\nPass: 0, Batch: 900, TrainCost: 499.748687\r\n...................................................................................................\r\nPass: 0, Batch: 1000, TrainCost: 512.164312\r\n...................................................................................................\r\nPass: 0, Batch: 1100, TrainCost: 523.656208\r\n...................................................................................................\r\nPass: 0, Batch: 1200, TrainCost: 533.018596\r\n...................................................................................................\r\nPass: 0, Batch: 1300, TrainCost: 541.667011\r\n...................................................................................................\r\nPass: 0, Batch: 1400, TrainCost: 552.249161\r\n...................................................................................................\r\nPass: 0, Batch: 1500, TrainCost: 561.308075\r\n...................................................................................................\r\nPass: 0, Batch: 1600, TrainCost: 572.026342\r\n...................................................................................................\r\nPass: 0, Batch: 1700, TrainCost: 583.196865\r\n..........................................................\r\n------- Time: 6633 sec,  Pass: 0, ValidationCost: 1524.97344964\r\n...................................................................................................\r\nPass: 1, Batch: 100, TrainCost: 569.899187\r\n...................................................................................................\r\nPass: 1, Batch: 200, TrainCost: 455.813797\r\n...................................................................................................\r\nPass: 1, Batch: 300, TrainCost: 459.514104\r\n...................................................................................................\r\nPass: 1, Batch: 400, TrainCost: 468.573062\r\n\r\n",
        "state": "closed",
        "user": "Slyne",
        "closed_by": "zh794390558",
        "created_at": "2018-09-17T07:36:09+00:00",
        "updated_at": "2021-05-12T05:13:58+00:00",
        "closed_at": "2021-05-12T05:13:58+00:00",
        "comments_count": [
            "Slyne",
            "gaozheyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 281,
        "title": "IOError: [Errno 104] Connection reset by peer",
        "body": "训练 librispeech  Pass: 15 \r\n报错\r\n    kind, result = conn.recv()\r\nIOError: [Errno 104] Connection reset by peer\r\n    kind, result = conn.recv()\r\nEOFError\r\nEOFError\r\n\r\n这是什么原因？\r\n",
        "state": "closed",
        "user": "moyan2016",
        "closed_by": "zh794390558",
        "created_at": "2018-09-25T01:26:32+00:00",
        "updated_at": "2021-05-12T05:13:51+00:00",
        "closed_at": "2021-05-12T05:13:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 279,
        "title": "failed to download LibriSpeech model",
        "body": "I was running the tiny example, using run_infer_golden.sh. While downloading the pre-trained LibriSpeech model, the download ends prematurely and I end up with a corrupted gz file.\r\n\r\nI have tried adding \"180.76.189.142  cloud.dlnel.org\" to etc/hosts but this problem persists.\r\n\r\nAdditionally, can I know what is the expected size of the pre-trained model? So far I've failed at last 10 times, the furthest I got was a 127 mb file.\r\n\r\nBelow is the error message.\r\n\r\nDownload LibriSpeech model ...\r\ndownload_model.sh: 8: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\n--2018-09-21 06:37:20--  http://cloud.dlnel.org/filepub/?uuid=117cde63-cd59-4948-8b80-df782555f7d6\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 202.108.23.203\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|202.108.23.203|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\nLength: unspecified [application/x-tar]\r\nSaving to: './librispeech_model.tar.gz'\r\n\r\n./librispeech_model.tar.gz            [                                       <=>                 ]  33.94M  41.4KB/s    in 11m 17s \r\n\r\n2018-09-21 06:48:37 (51.3 KB/s) - './librispeech_model.tar.gz' saved [127453508]\r\n\r\ndownload_model.sh: 20: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\nmean_std.npz\r\nparams.tar.gz\r\n\r\ngzip: stdin: unexpected end of file\r\ntar: Unexpected EOF in archive\r\ntar: Unexpected EOF in archive\r\ntar: Error is not recoverable: exiting now\r\n-----------  Configuration Arguments -----------\r\n",
        "state": "closed",
        "user": "wuisiong",
        "closed_by": "wuisiong",
        "created_at": "2018-09-21T07:03:48+00:00",
        "updated_at": "2018-09-25T07:10:50+00:00",
        "closed_at": "2018-09-25T07:10:50+00:00",
        "comments_count": [
            "wuisiong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 282,
        "title": "Manifest text in Mandarin English mixed sentence",
        "body": "How to arrange manifest text in Mandarin English mixed sentence?\r\nIn the DS2 paper, Mandarin chars in sentence do needn't space, but English words need space.\r\nSome mandarin corpus, there is some English words in sentence.\r\nHow to arrange such Mandarin English mix sentence for manifest text?\r\n",
        "state": "closed",
        "user": "kckao",
        "closed_by": "zh794390558",
        "created_at": "2018-09-25T01:48:05+00:00",
        "updated_at": "2021-05-12T05:13:27+00:00",
        "closed_at": "2021-05-12T05:13:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 285,
        "title": "安装报错：运行根目录下的setup.sh报错",
        "body": "运行根目录下的setup.sh报的错误，如下：\r\nCollecting scipy==0.13.1 (from -r requirements.txt (line 1))\r\n  Using cached https://files.pythonhosted.org/packages/83/7c/5ba1ca301c3b1ddd8d097778fea2ecc3c34f5c5fb9e95f562d55082aa5f1/scipy-0.13.1-cp27-cp27m-manylinux1_x86_64.whl\r\nRequirement already satisfied: resampy==0.1.5 in /usr/local/lib/python2.7/site-packages (from -r requirements.txt (line 2)) (0.1.5)\r\nRequirement already satisfied: SoundFile==0.9.0.post1 in /usr/local/lib/python2.7/site-packages (from -r requirements.txt (line 3)) (0.9.0.post1)\r\nRequirement already satisfied: python_speech_features in /usr/local/lib/python2.7/site-packages (from -r requirements.txt (line 4)) (0.6)\r\nRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python2.7/site-packages (from resampy==0.1.5->-r requirements.txt (line 2)) (1.14.0)\r\nRequirement already satisfied: six>=1.3 in /usr/local/lib/python2.7/site-packages (from resampy==0.1.5->-r requirements.txt (line 2)) (1.11.0)\r\nRequirement already satisfied: Cython>=0.23 in /usr/local/lib/python2.7/site-packages (from resampy==0.1.5->-r requirements.txt (line 2)) (0.28.5)\r\nRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python2.7/site-packages (from SoundFile==0.9.0.post1->-r requirements.txt (line 3)) (1.11.5)\r\nRequirement already satisfied: pycparser in /usr/local/lib/python2.7/site-packages (from cffi>=0.6->SoundFile==0.9.0.post1->-r requirements.txt (line 3)) (2.19)\r\npaddlepaddle 0.15.0 has requirement scipy>=0.19.0, but you'll have scipy 0.13.1 which is incompatible.\r\nInstalling collected packages: scipy\r\n  Found existing installation: scipy 1.1.0\r\n    Uninstalling scipy-1.1.0:\r\n      Successfully uninstalled scipy-1.1.0\r\nSuccessfully installed scipy-0.13.1\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"build/bdist.linux-x86_64/egg/pkg_resources/__init__.py\", line 963, in require\r\n  File \"build/bdist.linux-x86_64/egg/pkg_resources/__init__.py\", line 849, in resolve\r\npkg_resources.DistributionNotFound: The 'swig_decoders==1.1' distribution was not found and is required by the application\r\nInstall decoders ...\r\nscorer.h:22: Warning 401: Nothing known about base class 'lm::EnumerateVocab'. Ignored.\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\nwriting swig_decoders.egg-info/PKG-INFO\r\nwriting top-level names to swig_decoders.egg-info/top_level.txt\r\nwriting dependency_links to swig_decoders.egg-info/dependency_links.txt\r\nreading manifest file 'swig_decoders.egg-info/SOURCES.txt'\r\nwriting manifest file 'swig_decoders.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.linux-x86_64/egg\r\nrunning install_lib\r\nrunning build_py\r\ncopying swig_decoders.py -> build/lib.linux-x86_64-2.7\r\nrunning build_ext\r\nbuilding '_swig_decoders' extension\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/parallel_read.cc -o build/temp.linux-x86_64-2.7/kenlm/util/parallel_read.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/ersatz_progress.cc -o build/temp.linux-x86_64-2.7/kenlm/util/ersatz_progress.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/usage.cc -o build/temp.linux-x86_64-2.7/kenlm/util/usage.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/bit_packing.cc -o build/temp.linux-x86_64-2.7/kenlm/util/bit_packing.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/murmur_hash.cc -o build/temp.linux-x86_64-2.7/kenlm/util/murmur_hash.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/string_piece.cc -o build/temp.linux-x86_64-2.7/kenlm/util/string_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ngcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/file_piece.cc -o build/temp.linux-x86_64-2.7/kenlm/util/file_piece.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\nerror: command 'gcc' failed with exit status 1gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/local/include/python2.7 -c kenlm/util/float_to_string.cc -o build/temp.linux-x86_64-2.7/kenlm/util/float_to_string.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\n\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\ncc1plus: 警告：命令行选项“-Wstrict-prototypes”对 Ada/C/ObjC 是有效的，但对 C++ 无效\r\ncc1plus: 错误：无法识别的命令行选项“-std=c++11”\r\nInstall all dependencies successfully.",
        "state": "closed",
        "user": "xueshang-liulp",
        "closed_by": "xueshang-liulp",
        "created_at": "2018-10-15T06:07:46+00:00",
        "updated_at": "2018-10-17T02:29:55+00:00",
        "closed_at": "2018-10-17T02:29:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 283,
        "title": "demo_server.py默认换成Aishell后执行报错",
        "body": "/data/DeepSpeech2/deploy$ CUDA_VISIBLE_DEVICES=0 python2 demo_server.py --host_ip localhost --host_port 8086 --use_gpu False\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: /data/DeepSpeech2/models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: /data/DeepSpeech2/models/aishell/mean_std.npz\r\nmodel_path: /data/DeepSpeech2/checkpoints/aishell/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: /data/DeepSpeech2/gintong\r\nuse_gpu: 0\r\nuse_gru: False\r\nvocab_path: /data/DeepSpeech2/models/aishell/vocab.txt\r\nwarmup_manifest: /data/DeepSpeech2/data/aishell/manifest.test\r\n------------------------------------------------\r\nI0927 15:58:18.889097  2591 Util.cpp:166] commandline:  --use_gpu=0 --trainer_count=1 \r\nW0927 15:58:18.889184  2591 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON\r\n[INFO 2018-09-27 15:58:18,964 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-27 15:58:18,966 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-27 15:58:18,967 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-09-27 15:58:18,968 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-09-27 15:58:18,969 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-09-27 15:58:18,971 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-09-27 15:58:26,537 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-09-27 15:58:26,657 model.py:253] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2018-09-27 15:58:26,657 model.py:254] end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'/data/.cache/paddle/dataset/speech/Aishell/data_aishell/wav/test/S0913/BAC009S0913W0419.wav')\r\nTraceback (most recent call last):\r\n  File \"demo_server.py\", line 215, in <module>\r\n    main()\r\n  File \"demo_server.py\", line 211, in main\r\n    start_server()\r\n  File \"demo_server.py\", line 195, in start_server\r\n    num_test_cases=3)\r\n  File \"demo_server.py\", line 135, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"demo_server.py\", line 171, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/data/DeepSpeech2/deploy/../model_utils/model.py\", line 193, in infer_batch_probs\r\n    output_layer=self._log_probs, parameters=self._parameters)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/inference.py\", line 64, in __init__\r\n    val.copyFromNumpyArray(parameters.get(name).flatten())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 242, in get\r\n    return self.__getitem__(key=parameter_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n    return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 153, in __getter_inner\r\n    shape = self.get_shape(key)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py\", line 200, in get_shape\r\n    raise ValueError(\"No such parameter %s\" % key)\r\nValueError: No such parameter ___recurrent_layer_0__.w0",
        "state": "closed",
        "user": "18811737901",
        "closed_by": "zh794390558",
        "created_at": "2018-09-27T08:34:09+00:00",
        "updated_at": "2021-05-12T05:13:00+00:00",
        "closed_at": "2021-05-12T05:13:00+00:00",
        "comments_count": [
            "Slyne",
            "liuborama"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 284,
        "title": "Fail in example/tiny run_infer_golden.sh",
        "body": "After reading LM model (successfully), then error occurs. \r\n\r\nroot@7a87c4436d18:~/DeepSpeech/examples/tiny# sh run_infer_golden.sh \r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/tiny/manifest.test-clean\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/librispeech/mean_std.npz\r\nmodel_path: models/librispeech/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: 0\r\nvocab_path: models/librispeech/vocab.txt\r\n------------------------------------------------\r\nI1009 19:13:51.660266   442 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --trainer_count=1 \r\n[INFO 2018-10-09 19:13:51,872 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-09 19:13:51,873 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-09 19:13:51,874 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-09 19:13:51,874 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-09 19:13:51,875 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-09 19:13:51,875 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-09 19:13:54,459 model.py:243] begin to initialize the external scorer for decoding\r\nLoading the LM will be faster if you build a binary file.\r\nReading models/lm/common_crawl_00.prune01111.trie.klm\r\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\nterminate called after throwing an instance of 'util::EndOfFileException'\r\n  what():  End of file Byte: 0\r\n*** Aborted at 1539112434 (unix time) try \"date -d @1539112434\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x1ba) received by PID 442 (TID 0x7f704cc49700) from PID 442; stack trace: ***\r\n    @     0x7f704c826390 (unknown)\r\n    @     0x7f704c480428 gsignal\r\n    @     0x7f704c48202a abort\r\n    @     0x7f703388684d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7f70338846b6 (unknown)\r\n    @     0x7f7033884701 std::terminate()\r\n    @     0x7f7033884969 __cxa_rethrow\r\n    @     0x7f702102d2f8 lm::ngram::detail::GenericModel<>::InitializeFromARPA()\r\n    @     0x7f702102f0eb lm::ngram::detail::GenericModel<>::GenericModel()\r\n    @     0x7f7021026aab lm::ngram::LoadVirtual()\r\n    @     0x7f702113ecbf Scorer::load_lm()\r\n    @     0x7f70211422a1 Scorer::setup()\r\n    @     0x7f702114239d Scorer::Scorer()\r\n    @     0x7f70210fd1a8 _wrap_new_Scorer\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d54b9 (unknown)\r\n    @           0x4eebee (unknown)\r\n    @           0x4c15bf PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4d54b9 (unknown)\r\n    @           0x4eebee (unknown)\r\n    @           0x4ee7f6 (unknown)\r\n    @           0x4aa9ab (unknown)\r\n    @           0x4c15bf PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\nAborted (core dumped)\r\nFailed in inference!\r\n",
        "state": "closed",
        "user": "Nathan-zh",
        "closed_by": "Nathan-zh",
        "created_at": "2018-10-09T19:36:17+00:00",
        "updated_at": "2019-07-10T08:12:56+00:00",
        "closed_at": "2018-10-10T14:42:26+00:00",
        "comments_count": [
            "Laxmikant04"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 287,
        "title": "about    sh run_train.sh",
        "body": "my gpu is GT730, the gpu is not very good .so when I sh run_train.sh  .Only a toy example with a tiny sampled subset of LibriSpeech. \r\n\r\nAborted (core dumped)\r\nFail in training!\r\n   \r\nhow to solve it  thanks\r\n![2018-10-16 11-57-34](https://user-images.githubusercontent.com/43053983/46991986-b03e9580-d13a-11e8-93af-9163e2fb3810.png)\r\n\r\n",
        "state": "closed",
        "user": "smallsnailrunning",
        "closed_by": "zh794390558",
        "created_at": "2018-10-16T03:58:36+00:00",
        "updated_at": "2021-05-12T05:13:14+00:00",
        "closed_at": "2021-05-12T05:13:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 288,
        "title": "run_infer fails to get language model",
        "body": "I tried running the run_infer.sh from the tiny/\r\nAnd I get the following error:\r\nHTTP request sent, awaiting response... 404 Not Found\r\n2018-10-17 08:20:23 ERROR 404: Not Found.\r\n\r\nFail to download the language model!\r\n\r\nCan you help me with this?\r\n\r\nThanks!",
        "state": "closed",
        "user": "sivagururaman",
        "closed_by": "zh794390558",
        "created_at": "2018-10-17T02:55:15+00:00",
        "updated_at": "2021-05-12T05:13:21+00:00",
        "closed_at": "2021-05-12T05:13:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 286,
        "title": "Tamil Vocabulary produces circles.",
        "body": "When trying to build the vocabulary for Tamil. I am getting circles as some of the alphabets. Please tell the reason for this.\r\n[tamil_vocab.txt](https://github.com/PaddlePaddle/DeepSpeech/files/2478484/tamil_vocab.txt)\r\n",
        "state": "closed",
        "user": "akashravichandran",
        "closed_by": "akashravichandran",
        "created_at": "2018-10-15T11:15:27+00:00",
        "updated_at": "2020-06-21T18:14:51+00:00",
        "closed_at": "2020-06-21T18:14:51+00:00",
        "comments_count": [
            "vikrantsharma7"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 289,
        "title": "Could not run inference with tiny set",
        "body": "When running the inferernce, the following error shows up:\r\nDownload language model ...\r\ndownload_lm_en.sh: 8: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n--2018-10-18 19:16:48--  http://paddlepaddle.bj.bcebos.com/model_zoo/speech/common_crawl_00.prune01111.trie.klm\r\nResolving paddlepaddle.bj.bcebos.com (paddlepaddle.bj.bcebos.com)... 103.235.46.61\r\nConnecting to paddlepaddle.bj.bcebos.com (paddlepaddle.bj.bcebos.com)|103.235.46.61|:80... connected.\r\nHTTP request sent, awaiting response... 404 Not Found\r\n2018-10-18 19:16:49 ERROR 404: Not Found.\r\n\r\n\r\nLooks like the file is not present at the mentioned folder. Can you let me know how I can download the pre-trained network for me to run inference?\r\n ",
        "state": "closed",
        "user": "sivagururaman",
        "closed_by": "zh794390558",
        "created_at": "2018-10-18T13:49:29+00:00",
        "updated_at": "2021-05-12T05:13:07+00:00",
        "closed_at": "2021-05-12T05:13:07+00:00",
        "comments_count": [
            "sivagururaman"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 290,
        "title": "Training aborted due to the presence of an empty audio . ",
        "body": "Audio which has **no word spoken in it can disrupt the training process**. So before training ensure that the empty audios are removed. I used the below piece of code to identify the empty audios..\r\n\r\nimport soundfile as sf\r\ndata, samplerate = sf.read('any_file.wav')\r\n\r\nif sum(data) == 0:\r\n    remove the audio from the training sample\r\n\r\n",
        "state": "closed",
        "user": "praveenjune17",
        "closed_by": "zh794390558",
        "created_at": "2018-10-22T17:26:00+00:00",
        "updated_at": "2021-05-12T05:12:35+00:00",
        "closed_at": "2021-05-12T05:12:35+00:00",
        "comments_count": [
            "sivagururaman",
            "praveenjune17",
            "sivagururaman",
            "praveenjune17"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 293,
        "title": "Confused about adjustment to return score",
        "body": "https://github.com/PaddlePaddle/DeepSpeech/blob/develop/decoders/swig/ctc_beam_search_decoder.cpp#L170\r\n\r\n// compute aproximate ctc score as the return score, without affecting the\r\n// return order of decoding result. To delete when decoder gets stable.\r\n\r\nWhat is the use of this adjustment to the return score? And what is \"unstable\" about the decoder? Haven't been able to figure it out.\r\nThanks!",
        "state": "closed",
        "user": "PCerles",
        "closed_by": "zh794390558",
        "created_at": "2018-11-15T00:46:30+00:00",
        "updated_at": "2021-05-12T05:12:15+00:00",
        "closed_at": "2021-05-12T05:12:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 291,
        "title": "运行infer.py时报错: ValueError: No such parameter ___conv_0__.w0",
        "body": "运行infer.py时报错，不知道是否与自制的语言模型有关。从输出中看，好像语言模型已经被成功读入了，谢谢。\r\npython infer.py --use_gpu False --trainer_count 1\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: /home/xio/Baidu/BDeepSpeech2/amol.manifest\r\nlang_model_path: /home/xio/Baidu/BDeepSpeech2/speech_model/lm3.binary\r\nmean_std_path: /home/xio/Baidu/BDeepSpeech2/speech_model/mean_std.npz\r\nmodel_path: /home/xio/Baidu/BDeepSpeech2/speech_model/baidu_en8k_model.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 1\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: False\r\nvocab_path: /home/xio/Baidu/BDeepSpeech2/speech_model/vocab.txt\r\n------------------------------------------------\r\nI1029 20:57:05.445317  6422 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --trainer_count=1\r\n[INFO 2018-10-29 20:57:05,494 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-29 20:57:05,495 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-29 20:57:05,495 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2018-10-29 20:57:05,496 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-29 20:57:05,497 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-29 20:57:05,497 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2018-10-29 20:57:06,238 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2018-10-29 20:57:06,571 model.py:253] language model: is_character_based = 0, max_order = 5, dict_size = 23264\r\n[INFO 2018-10-29 20:57:06,571 model.py:254] end initializing scorer\r\n[INFO 2018-10-29 20:57:06,571 infer_jay.py:103] start inference ...\r\nTraceback (most recent call last):\r\n File \"infer_jay.py\", line 135, in <module>\r\n   main()\r\n File \"infer_jay.py\", line 131, in main\r\n   infer()\r\n File \"infer_jay.py\", line 105, in infer\r\n   feeding_dict=data_generator.feeding)\r\n File \"/home/xio/Baidu/BDeepSpeech2/DeepSpeech/model_utils/model.py\", line 193, in infer_batch_probs\r\n   output_layer=self._log_probs, parameters=self._parameters)\r\n File \"/home/xio/venv/py27/local/lib/python2.7/site-packages/paddle/v2/inference.py\", line 64, in __init__\r\n   val.copyFromNumpyArray(parameters.get(name).flatten())\r\n File \"/home/xio/venv/py27/local/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 242, in get\r\n   return self.__getitem__(key=parameter_name)\r\n File \"/home/xio/venv/py27/local/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n   return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n File \"/home/xio/venv/py27/local/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 153, in __getter_inner\r\n   shape = self.get_shape(key)\r\n File \"/home/xio/venv/py27/local/lib/python2.7/site-packages/paddle/v2/parameters.py\", line 200, in get_shape\r\n   raise ValueError(\"No such parameter %s\" % key)\r\nValueError: No such parameter ___conv_0__.w0",
        "state": "closed",
        "user": "jayxioresearch",
        "closed_by": "zh794390558",
        "created_at": "2018-10-30T01:09:41+00:00",
        "updated_at": "2021-05-12T05:12:29+00:00",
        "closed_at": "2021-05-12T05:12:29+00:00",
        "comments_count": [
            "ericput",
            "sruteesh-pivot",
            "jayxioresearch",
            "nicole-zhao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 294,
        "title": "What is the range of Q(y) in inference?",
        "body": "Hi Team,\r\n\r\nI'm trying to make use of the inference probabilities to show the confidence of the output transcription. I understand that equation[ (12)](https://arxiv.org/pdf/1512.02595.pdf#equation.3.12) is used to pick the transcription (y) that maximizes Q(y).\r\n\r\nI'm unable to generalize the scale in which this Q(y) is measured. Which is the range of Q(y) in which the confidence in prediction considered high? Can you tell me if there are minimum and maximum values of Q(y)?\r\n\r\nThanks in advance.",
        "state": "closed",
        "user": "dalonlobo",
        "closed_by": "zh794390558",
        "created_at": "2018-11-29T11:04:51+00:00",
        "updated_at": "2021-05-12T05:12:09+00:00",
        "closed_at": "2021-05-12T05:12:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 292,
        "title": "在docker image中运行examples/tiny/run_train.sh报错:terminate called after throwing an instance of 'Xbyak::Error'",
        "body": "按照“Installation->Running in Docker Container\"中步骤安装了Docker image. 按照“Getting Started“ 中的步骤一步步运行，“sh run_data.sh” 成功，在运行“sh run_train.sh”报错。\r\n\r\n**全部的报错信息：**\r\nterminate called after throwing an instance of 'Xbyak::Error'\r\n what():  internal error\r\nAborted (core dumped)\r\nFail in training!\r\n\r\n\r\n**全部输出如下：**\r\nroot@1ade2c36fbac:/DeepSpeech# cd examples/tiny/\r\nroot@1ade2c36fbac:/DeepSpeech/examples/tiny# sh run_data.sh\r\nSkip downloading and unpacking. Data already exists in /root/.cache/paddle/dataset/speech/libri/test-clean.\r\nCreating manifest data/tiny/manifest.test-clean ...\r\nSkip downloading and unpacking. Data already exists in /root/.cache/paddle/dataset/speech/libri/dev-clean.\r\nCreating manifest data/tiny/manifest.dev-clean ...\r\n-----------  Configuration Arguments -----------\r\ncount_threshold: 0\r\nmanifest_paths: ['data/tiny/manifest.dev-clean']\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\nmanifest_path: data/tiny/manifest.tiny\r\nnum_samples: 64\r\noutput_path: data/tiny/mean_std.npz\r\nspecgram_type: linear\r\n------------------------------------------------\r\nTiny data preparation done.\r\nroot@1ade2c36fbac:/DeepSpeech/examples/tiny# sh run_train.sh\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 4\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nterminate called after throwing an instance of 'Xbyak::Error'\r\n what():  internal error\r\nAborted (core dumped)\r\nFail in training!\r\nroot@1ade2c36fbac:/DeepSpeech/examples/tiny#\r\n\r\n**nvidia-docker信息 (nvidia GPU: 1080TI GTX) ：**\r\njay@tweed:~$ sudo docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi\r\nWed Oct 31 20:07:40 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n|  8%   53C    P0    55W / 250W |      0MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:41:00.0 Off |                  N/A |\r\n| 10%   54C    P0    53W / 250W |      0MiB / 11176MiB |      2%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n",
        "state": "closed",
        "user": "jayxioresearch",
        "closed_by": "zh794390558",
        "created_at": "2018-10-31T20:18:11+00:00",
        "updated_at": "2021-05-12T05:12:22+00:00",
        "closed_at": "2021-05-12T05:12:22+00:00",
        "comments_count": [
            "onmywei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 295,
        "title": "中文语言模型下载1.01G就停止下载了，在/etc/hosts添加180.76.189.142 cloud.dlnel.org也尝试了，还是不行，可以解决一下吗？非常感谢",
        "body": "sh download_lm_ch.sh\r\nDownload language model ...\r\ndownload_lm_ch.sh: 8: [: 29e02312deb2e59b3c8686c7966d4fe3: unexpected operator\r\n--2018-12-24 23:30:49--  http://cloud.dlnel.org/filepub/?uuid=245d02bb-cd01-4ebe-b079-b97be864ec37\r\nConnecting to 127.0.0.1:8118... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\nLength: unspecified [text/html]\r\nSaving to: ‘./zh_giga.no_cna_cmn.prune01244.klm’\r\n\r\n./zh_giga.no_cna_cm     [       <=>          ]   1.01G  2.74MB/s    in 7m 19s  \r\n\r\n2018-12-24 23:38:23 (2.36 MB/s) - ‘./zh_giga.no_cna_cmn.prune01244.klm’ saved [1087364578]\r\n\r\ndownload_lm_ch.sh: 20: [: 29e02312deb2e59b3c8686c7966d4fe3: unexpected operator\r\n",
        "state": "closed",
        "user": "MrCuiHao",
        "closed_by": "zh794390558",
        "created_at": "2018-12-25T07:56:31+00:00",
        "updated_at": "2021-05-12T05:12:03+00:00",
        "closed_at": "2021-05-12T05:12:03+00:00",
        "comments_count": [
            "MrCuiHao",
            "blood0708",
            "blood0708",
            "MrCuiHao",
            "blood0708",
            "whaozl",
            "aaronlyt",
            "huntzhan",
            "whaozl",
            "huntzhan",
            "whaozl",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 296,
        "title": "Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory  郁闷死了，费了半天劲",
        "body": "I1228 01:28:25.300649   173 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=1 \r\nF1228 01:28:25.392861   173 hl_cuda_device.cc:399] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory\r\n*** Check failure stack trace: ***\r\n    @     0x7febaa61804d  google::LogMessage::Fail()\r\n    @     0x7febaa61a398  google::LogMessage::SendToLog()\r\n    @     0x7febaa617b5b  google::LogMessage::Flush()\r\n    @     0x7febaa61b26e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7febaa5c39f1  hl_create_global_resources()\r\n    @     0x7febaa5c41a4  hl_specify_devices_start()\r\n    @     0x7febaa5c447d  hl_start()\r\n    @     0x7febaa545e7e  paddle::initMain()\r\n    @     0x7febaa5fe621  initPaddle()\r\n    @     0x7febaa09a347  _wrap_initPaddle\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4de6fe  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4c6ad1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7febd7056830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\n./run_train.sh: line 33:   173 Aborted                 (core dumped) CUDA_VISIBLE_DEVICES=0 python -u train.py --batch_size=1 --trainer_count=1 --num_passes=20 --num_proc_data=1 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --num_iter_print=100 --learning_rate=1e-5 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=True --is_local=True --share_rnn_weights=True --train_manifest='data/tiny/manifest.tiny' --dev_manifest='data/tiny/manifest.tiny' --mean_std_path='data/tiny/mean_std.npz' --vocab_path='data/tiny/vocab.txt' --output_model_dir='./checkpoints/tiny' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFail in training!\r\n",
        "state": "closed",
        "user": "blood0708",
        "closed_by": "blood0708",
        "created_at": "2018-12-28T01:34:48+00:00",
        "updated_at": "2018-12-28T09:42:05+00:00",
        "closed_at": "2018-12-28T09:42:05+00:00",
        "comments_count": [
            "blood0708"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 298,
        "title": "infer",
        "body": "",
        "state": "closed",
        "user": "MrCuiHao",
        "closed_by": "MrCuiHao",
        "created_at": "2018-12-29T02:17:32+00:00",
        "updated_at": "2018-12-29T02:18:00+00:00",
        "closed_at": "2018-12-29T02:18:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 297,
        "title": "有谁实验过，识别的效果怎么样阿？",
        "body": "",
        "state": "closed",
        "user": "blood0708",
        "closed_by": "zh794390558",
        "created_at": "2018-12-28T08:57:02+00:00",
        "updated_at": "2021-05-12T05:11:55+00:00",
        "closed_at": "2021-05-12T05:11:55+00:00",
        "comments_count": [
            "blood0708",
            "liuborama",
            "tai960519073",
            "YanqiangWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 301,
        "title": "DeepSpeech 和 fluid 中的 DeepASR 有什么区别？",
        "body": "在 fluid 中同样存在一个 [DeepASR](  https://github.com/PaddlePaddle/models/tree/develop/fluid/DeepASR)\r\n\r\n请问他们两者有什么区别？推荐使用哪个？\r\n\r\n多谢",
        "state": "closed",
        "user": "gnever",
        "closed_by": "zh794390558",
        "created_at": "2019-01-09T14:47:05+00:00",
        "updated_at": "2021-05-12T05:11:30+00:00",
        "closed_at": "2021-05-12T05:11:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 300,
        "title": "tune",
        "body": "",
        "state": "closed",
        "user": "chenjunweii",
        "closed_by": "chenjunweii",
        "created_at": "2019-01-07T13:30:18+00:00",
        "updated_at": "2019-01-07T13:30:26+00:00",
        "closed_at": "2019-01-07T13:30:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 299,
        "title": "demo_client运行报错？",
        "body": "root@b766672fd554:/DeepSpeech/examples/deploy_demo# ./run_demo_client.sh \r\nTraceback (most recent call last):\r\n  File \"deploy/demo_client.py\", line 2, in <module>\r\n    from pynput import keyboard\r\n  File \"/usr/local/lib/python2.7/dist-packages/pynput/__init__.py\", line 23, in <module>\r\n    from . import keyboard\r\n  File \"/usr/local/lib/python2.7/dist-packages/pynput/keyboard/__init__.py\", line 49, in <module>\r\n    from ._xorg import KeyCode, Key, Controller, Listener\r\n  File \"/usr/local/lib/python2.7/dist-packages/pynput/keyboard/_xorg.py\", line 39, in <module>\r\n    from pynput._util.xorg import (\r\n  File \"/usr/local/lib/python2.7/dist-packages/pynput/_util/xorg.py\", line 40, in <module>\r\n    _check()\r\n  File \"/usr/local/lib/python2.7/dist-packages/pynput/_util/xorg.py\", line 38, in _check\r\n    display = Xlib.display.Display()\r\n  File \"/usr/local/lib/python2.7/dist-packages/Xlib/display.py\", line 89, in __init__\r\n    self.display = _BaseDisplay(display)\r\n  File \"/usr/local/lib/python2.7/dist-packages/Xlib/display.py\", line 71, in __init__\r\n    protocol_display.Display.__init__(self, *args, **keys)\r\n  File \"/usr/local/lib/python2.7/dist-packages/Xlib/protocol/display.py\", line 85, in __init__\r\n    name, protocol, host, displayno, screenno = connect.get_display(display)\r\n  File \"/usr/local/lib/python2.7/dist-packages/Xlib/support/connect.py\", line 73, in get_display\r\n    return mod.get_display(display)\r\n  File \"/usr/local/lib/python2.7/dist-packages/Xlib/support/unix_connect.py\", line 61, in get_display\r\n    raise error.DisplayNameError(display)\r\nXlib.error.DisplayNameError: Bad display name \"\"\r\nFailed in starting demo client!\r\n",
        "state": "closed",
        "user": "blood0708",
        "closed_by": "zh794390558",
        "created_at": "2018-12-29T04:54:26+00:00",
        "updated_at": "2021-05-12T05:11:37+00:00",
        "closed_at": "2021-05-12T05:11:37+00:00",
        "comments_count": [
            "WiliiamBryant",
            "blood0708",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 302,
        "title": "使用docker训练时报错Check failed: cudaSuccess == err (0 vs. 8)",
        "body": "F0123 11:55:36.803860    19 hl_gpu_matrix_kernel.cuh:181] Check failed: cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed] CUDA error: invalid device function\r\n*** Check failure stack trace: ***\r\n    @     0x7fbf82b2a04d  google::LogMessage::Fail()\r\n    @     0x7fbf82b2c398  google::LogMessage::SendToLog()\r\n    @     0x7fbf82b29b5b  google::LogMessage::Flush()\r\n    @     0x7fbf82b2d26e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fbf8296d9df  hl_gpu_apply_unary_op<>()\r\n    @     0x7fbf8296de1f  paddle::BaseMatrixT<>::applyUnary<>()\r\n    @     0x7fbf8296e0e8  paddle::BaseMatrixT<>::zero()\r\n    @     0x7fbf828de8b4  paddle::GpuMatrix::zeroMem()\r\n    @     0x7fbf8278e421  paddle::BatchNormBaseLayer::init()\r\n    @     0x7fbf8272fa62  paddle::CudnnBatchNormLayer::init()\r\n    @     0x7fbf827b5d78  paddle::NeuralNetwork::init()\r\n    @     0x7fbf827c938a  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @     0x7fbf827ce1de  paddle::GradientMachine::create()\r\n    @     0x7fbf82afa8bb  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7fbf82afb4ce  GradientMachine::createByConfigProtoStr()\r\n    @     0x7fbf825e23aa  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4cb45e  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4de8b8  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4f492e  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4f46a7  (unknown)\r\n    @           0x4b670c  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4c9faf  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\nAborted (core dumped)\r\nFailed in training!\r\n",
        "state": "closed",
        "user": "zongweiLi",
        "closed_by": "zh794390558",
        "created_at": "2019-01-23T11:57:36+00:00",
        "updated_at": "2021-05-12T05:11:22+00:00",
        "closed_at": "2021-05-12T05:11:22+00:00",
        "comments_count": [
            "SunlerZRY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 303,
        "title": "use_gpu",
        "body": "",
        "state": "closed",
        "user": "piyush101",
        "closed_by": "piyush101",
        "created_at": "2019-02-01T18:12:50+00:00",
        "updated_at": "2019-02-01T18:13:21+00:00",
        "closed_at": "2019-02-01T18:13:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 304,
        "title": "运行infer.py报错IOError: [Errno 32] Broken pipe",
        "body": "-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: data/aishell/mean_std.npz\r\nmodel_path: checkpoints/aishell/params.latest.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 512\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\nI0203 15:48:53.821841 16114 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --trainer_count=1 \r\nProcess Process-2:\r\nTraceback (most recent call last):\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\r\n    self.run()\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/storage/workspace/zhujieenv/DeepSpeech/data_utils/utility.py\", line 120, in order_read_worker\r\n    in_queue.put((order_id, sample))\r\n  File \"<string>\", line 2, in put\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/managers.py\", line 759, in _callmethod\r\n    kind, result = conn.recv()\r\nEOFError\r\nProcess Process-3:\r\nTraceback (most recent call last):\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\r\n    self.run()\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/storage/workspace/zhujieenv/DeepSpeech/data_utils/utility.py\", line 134, in order_handle_worker\r\n    while order_id != out_order[0]:\r\n  File \"<string>\", line 2, in __getitem__\r\n  File \"/home/hoge/anaconda2/envs/py27/lib/python2.7/multiprocessing/managers.py\", line 758, in _callmethod\r\n    conn.send((self._id, methodname, args, kwds))\r\nIOError: [Errno 32] Broken pipe\r\n[INFO 2019-02-03 15:48:53,996 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-02-03 15:48:53,997 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-02-03 15:48:53,997 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-02-03 15:48:53,998 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-02-03 15:48:53,998 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-02-03 15:48:53,999 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-02-03 15:48:55,270 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2019-02-03 15:48:55,341 model.py:253] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2019-02-03 15:48:55,341 model.py:254] end initializing scorer\r\n[INFO 2019-02-03 15:48:55,341 infer.py:103] start inference ...\r\n\r\nTarget Transcription: 由于近期销售模式的调整\r\nOutput Transcription: 由于近期销售模式的调整\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 她表示最重要的就是诚恳\r\nOutput Transcription: 她表示虽重要的就是乘客\r\nCurrent error rate [cer] = 0.272727\r\n\r\nTarget Transcription: 也助推了土地市场的火爆\r\nOutput Transcription: 也助推了土地市场的火爆\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 已经花费了一定的资源和成本\r\nOutput Transcription: 已经花费了一定的资源和成本\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 安徽铜陵结束了当地契税补贴政策\r\nOutput Transcription: 安徽同龄结束了当地契税补贴政策\r\nCurrent error rate [cer] = 0.133333\r\n\r\nTarget Transcription: 研究者们希望年龄大的跑者能够注意脚踝的锻炼\r\nOutput Transcription: 研究者们希望也令大的跑者都能够注意脚踝的锻炼\r\nCurrent error rate [cer] = 0.142857\r\n\r\nTarget Transcription: 但目前还存在服务架构不完善\r\nOutput Transcription: 但目前还存在服务价构不完善\r\nCurrent error rate [cer] = 0.076923\r\n\r\nTarget Transcription: 可供客户为特定任务重新编程\r\nOutput Transcription: 可供客户为特定任务重新编程\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 脚踝的能力损失了大约百分之四十八\r\nOutput Transcription: 脚踝的能力损失了大约百分之四十八\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 稳增长措施需更全面地考虑化解楼市风险问题\r\nOutput Transcription: 为增长措施需更全面地考虑化解楼市风险问题\r\nCurrent error rate [cer] = 0.050000\r\n[INFO 2019-02-03 15:48:58,111 infer.py:124] finish inference",
        "state": "closed",
        "user": "windowxiaoming",
        "closed_by": "zh794390558",
        "created_at": "2019-02-03T07:52:24+00:00",
        "updated_at": "2021-05-12T05:11:15+00:00",
        "closed_at": "2021-05-12T05:11:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 306,
        "title": "英文语言模型高频词汇标音问题",
        "body": "> Top 400,000 most frequent words are selected to build the vocabulary and the rest are replaced with 'UNKNOWNWORD'.\r\n\r\n\r\n您好，我看英文语料处理的方法是选择文本中出现次数最多的 400, 000 个词，请问，那么这些词的发音该如何标注呢？ 使用 G2P 吗？ ",
        "state": "closed",
        "user": "asr-pub",
        "closed_by": "asr-pub",
        "created_at": "2019-02-21T13:00:12+00:00",
        "updated_at": "2019-02-22T10:34:05+00:00",
        "closed_at": "2019-02-22T10:34:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 307,
        "title": "Can i use both .wav and .flac file to training?",
        "body": "",
        "state": "closed",
        "user": "smallDrea",
        "closed_by": "zh794390558",
        "created_at": "2019-03-01T13:13:47+00:00",
        "updated_at": "2021-05-12T05:11:10+00:00",
        "closed_at": "2021-05-12T05:11:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 309,
        "title": "Alwasy oom problem, even if bath_size==1",
        "body": "python3 -u ./DeepSpeech.py --train_files /home/sky-ai/xwt/DeepSpeech/data/train/train.csv --dev_files /home/sky-ai/xwt/DeepSpeech/data/cv/cv.csv --test_files /home/sky/sky-ai/xwt/DeepSpeech/data/test/test.csv --train_batch_size 24 --dev_batch_size 15 --test_batch_size 20 --epoch 20 --display_step 1 \\ --validation_step 1 \\ --dropout_rate 0.30 \\ --default_stddev 0.046875 \\ --learning_rate 0.0001 \\ --log_level 0 \r\n\r\n_________________________________________________________________________________\r\n2019-03-08 16:25:17.113383: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-03-08 16:25:17.213002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:17:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.77GiB\r\n2019-03-08 16:25:17.274068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:65:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.57GiB\r\n2019-03-08 16:25:17.274882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2019-03-08 16:25:17.936644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-08 16:25:17.936675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 1\r\n2019-03-08 16:25:17.936680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N Y\r\n2019-03-08 16:25:17.936683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1: Y N\r\n2019-03-08 16:25:17.937213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 10419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\r\n2019-03-08 16:25:17.937478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:1 with 10226 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\nD Starting coordinator…\r\nD Coordinator started. Thread id 140459615708928\r\nPreprocessing [’/home/sky-ai/xwt/DeepSpeech/data/train/train.csv’]\r\nPreprocessing done\r\nPreprocessing [’/home/sky-ai/xwt/DeepSpeech/data/cv/cv.csv’]\r\nPreprocessing done\r\nW Parameter --validation_step needs to be >0 for early stopping to work\r\n2019-03-08 16:26:26.961329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2019-03-08 16:26:26.961413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-08 16:26:26.961419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 1\r\n2019-03-08 16:26:26.961424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N Y\r\n2019-03-08 16:26:26.961428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1: Y N\r\n2019-03-08 16:26:26.961956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10419 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\r\n2019-03-08 16:26:26.962068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10226 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\n2019-03-08 16:26:28.980208: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 8589934592 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980297: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 8589934592\r\n2019-03-08 16:26:28.980344: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 7730940928 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980353: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 7730940928\r\n2019-03-08 16:26:28.980392: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 6957846528 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980402: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 6957846528\r\n2019-03-08 16:26:28.980433: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 6262061568 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980440: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 6262061568\r\n2019-03-08 16:26:28.980464: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 5635855360 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980471: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 5635855360\r\n2019-03-08 16:26:28.980494: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 5072269824 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980501: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 5072269824\r\n2019-03-08 16:26:28.980526: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 4565042688 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980532: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 4565042688\r\n2019-03-08 16:26:28.980551: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 4108538368 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980556: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 4108538368\r\n2019-03-08 16:26:28.980572: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 3697684480 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980577: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 3697684480\r\n2019-03-08 16:26:28.980602: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 8589934592 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:28.980607: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 8589934592\r\n2019-03-08 16:26:38.980783: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 8589934592 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:38.980838: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 8589934592\r\n2019-03-08 16:26:38.980875: E tensorflow/stream_executor/cuda/cuda_driver.cc:868] failed to alloc 8589934592 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2019-03-08 16:26:38.980886: W ./tensorflow/core/common_runtime/gpu/cuda_host_allocator.h:44] could not allocate pinned host memory of size: 8589934592\r\n2019-03-08 16:26:38.980901: W tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (cuda_host_bfc) ran out of memory trying to allocate 3.33GiB. Current allocation summary follows.\r\n2019-03-08 16:26:38.980918: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (256): Total Chunks: 3, Chunks in use: 3. 768B allocated for chunks. 768B in use in bin. 12B client-requested in use in bin.\r\n2019-03-08 16:26:38.980931: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (512): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.980942: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1024): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.980954: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2048): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.980964: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4096): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.980979: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8192): Total Chunks: 12, Chunks in use: 12. 96.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.\r\n2019-03-08 16:26:38.980990: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16384): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981003: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (32768): Total Chunks: 3, Chunks in use: 3. 96.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981014: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (65536): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981025: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (131072): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981036: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (262144): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981049: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (524288): Total Chunks: 1, Chunks in use: 0. 831.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981061: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1048576): Total Chunks: 3, Chunks in use: 3. 5.00MiB allocated for chunks. 5.00MiB in use in bin. 5.00MiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981075: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2097152): Total Chunks: 3, Chunks in use: 3. 11.58MiB allocated for chunks. 11.58MiB in use in bin. 11.58MiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981086: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4194304): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981097: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8388608): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981110: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16777216): Total Chunks: 9, Chunks in use: 9. 144.00MiB allocated for chunks. 144.00MiB in use in bin. 144.00MiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981122: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (33554432): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981132: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (67108864): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2019-03-08 16:26:38.981146: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (134217728): Total Chunks: 4, Chunks in use: 3. 524.24MiB allocated for chunks. 384.00MiB in use in bin. 384.00MiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981158: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (268435456): Total Chunks: 3, Chunks in use: 2. 7.33GiB allocated for chunks. 6.66GiB in use in bin. 6.66GiB client-requested in use in bin.\r\n2019-03-08 16:26:38.981171: I tensorflow/core/common_runtime/bfc_allocator.cc:613] Bin for 3.33GiB was 256.00MiB, Chunk State:\r\n2019-03-08 16:26:38.981186: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 684.82MiB | Requested Size: 0B | in_use: 0, prev: Size: 3.33GiB | Requested Size: 3.33GiB | in_use: 1\r\n2019-03-08 16:26:38.981198: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fb956000000 of size 3576881152\r\n2019-03-08 16:26:38.981207: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Free at 0x7fba2b32e000 of size 718086144\r\n2019-03-08 16:26:38.981215: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fba74000000 of size 3576881152\r\n2019-03-08 16:26:38.981224: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb4932e000 of size 134217728\r\n2019-03-08 16:26:38.981232: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb5132e000 of size 134217728\r\n2019-03-08 16:26:38.981240: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb5932e000 of size 134217728\r\n2019-03-08 16:26:38.981248: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb6132e000 of size 1746688\r\n2019-03-08 16:26:38.981256: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb614d8700 of size 1746688\r\n2019-03-08 16:26:38.981264: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb61682e00 of size 1746688\r\n2019-03-08 16:26:38.981273: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb6182d500 of size 4046848\r\n2019-03-08 16:26:38.981281: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb61c09500 of size 4046848\r\n2019-03-08 16:26:38.981289: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb61fe5500 of size 4046848\r\n2019-03-08 16:26:38.981297: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb623c1500 of size 16777216\r\n2019-03-08 16:26:38.981305: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb633c1500 of size 16777216\r\n2019-03-08 16:26:38.981313: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb643c1500 of size 16777216\r\n2019-03-08 16:26:38.981321: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb653c1500 of size 16777216\r\n2019-03-08 16:26:38.981329: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb663c1500 of size 16777216\r\n2019-03-08 16:26:38.981337: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb673c1500 of size 16777216\r\n2019-03-08 16:26:38.981345: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb683c1500 of size 16777216\r\n2019-03-08 16:26:38.981353: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb693c1500 of size 16777216\r\n2019-03-08 16:26:38.981361: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbb6a3c1500 of size 16777216\r\n2019-03-08 16:26:38.981369: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Free at 0x7fbb6b3c1500 of size 147057408\r\n2019-03-08 16:26:38.981378: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14800000 of size 8192\r\n2019-03-08 16:26:38.981386: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14802000 of size 256\r\n2019-03-08 16:26:38.981394: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14802100 of size 8192\r\n2019-03-08 16:26:38.981402: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14804100 of size 8192\r\n2019-03-08 16:26:38.981410: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14806100 of size 8192\r\n2019-03-08 16:26:38.981418: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14808100 of size 8192\r\n2019-03-08 16:26:38.981426: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf1480a100 of size 8192\r\n2019-03-08 16:26:38.981434: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf1480c100 of size 8192\r\n2019-03-08 16:26:38.981442: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf1480e100 of size 8192\r\n2019-03-08 16:26:38.981450: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14810100 of size 8192\r\n2019-03-08 16:26:38.981458: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14812100 of size 8192\r\n2019-03-08 16:26:38.981466: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14814100 of size 8192\r\n2019-03-08 16:26:38.981474: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14816100 of size 8192\r\n2019-03-08 16:26:38.981485: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14818100 of size 256\r\n2019-03-08 16:26:38.981493: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14818200 of size 256\r\n2019-03-08 16:26:38.981501: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14818300 of size 32768\r\n2019-03-08 16:26:38.981509: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14820300 of size 32768\r\n2019-03-08 16:26:38.981517: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7fbf14828300 of size 32768\r\n2019-03-08 16:26:38.981525: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Free at 0x7fbf14830300 of size 851200\r\n2019-03-08 16:26:38.981533: I tensorflow/core/common_runtime/bfc_allocator.cc:638] Summary of in-use Chunks by size:\r\n2019-03-08 16:26:38.981543: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 256 totalling 768B\r\n2019-03-08 16:26:38.981553: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 12 Chunks of size 8192 totalling 96.0KiB\r\n2019-03-08 16:26:38.981562: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 32768 totalling 96.0KiB\r\n2019-03-08 16:26:38.981571: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 1746688 totalling 5.00MiB\r\n2019-03-08 16:26:38.981581: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 4046848 totalling 11.58MiB\r\n2019-03-08 16:26:38.981590: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 9 Chunks of size 16777216 totalling 144.00MiB\r\n2019-03-08 16:26:38.981599: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 134217728 totalling 384.00MiB\r\n2019-03-08 16:26:38.981608: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 3576881152 totalling 6.66GiB\r\n2019-03-08 16:26:38.981617: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 7.19GiB\r\n2019-03-08 16:26:38.981629: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats:\r\nLimit: 68719476736\r\nInUse: 7724988416\r\nMaxInUse: 7724988416\r\nNumAllocs: 38\r\nMaxAllocSize: 3576881152\r\n\r\n2019-03-08 16:26:38.981646: W tensorflow/core/common_runtime/bfc_allocator.cc:271] _______*********\r\n2019-03-08 16:26:38.982719: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Resource exhausted: OOM when allocating tensor with shape[2048,436631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\r\nTraceback (most recent call last):\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1334, in _do_call\r\nreturn fn(*args)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1319, in _run_fn\r\noptions, feed_dict, fetch_list, target_list, run_metadata)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1407, in _call_tf_sessionrun\r\nrun_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2048,436631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\r\n[[{{node save_1/RestoreV2_1}} = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, …, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n [[{{node save_1/RestoreV2_1/_43}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_save_1/RestoreV2_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile “./DeepSpeech.py”, line 964, in\r\ntf.app.run(main)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py”, line 125, in run\r\n_sys.exit(main(argv))\r\nFile “./DeepSpeech.py”, line 916, in main\r\ntrain()\r\nFile “./DeepSpeech.py”, line 549, in train\r\nconfig=Config.session_config) as session:\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 504, in MonitoredTrainingSession\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 921, in init\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 643, in init\r\nself._sess = _RecoverableSession(self._coordinated_creator)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 1107, in init\r\n_WrappedSession.init(self, self._create_session())\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 1112, in _create_session\r\nreturn self._sess_creator.create_session()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 800, in create_session\r\nself.tf_sess = self._session_creator.create_session()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 566, in create_session\r\ninit_fn=self._scaffold.init_fn)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py”, line 288, in prepare_session\r\nconfig=config)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py”, line 218, in _restore_checkpoint\r\nsaver.restore(sess, ckpt.model_checkpoint_path)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 1546, in restore\r\n{self.saver_def.filename_tensor_name: save_path})\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 929, in run\r\nrun_metadata_ptr)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1152, in _run\r\nfeed_dict_tensor, options, run_metadata)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1328, in _do_run\r\nrun_metadata)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py”, line 1348, in _do_call\r\nraise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2048,436631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\r\n[[node save_1/RestoreV2_1 (defined at ./DeepSpeech.py:549) = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, …, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n [[{{node save_1/RestoreV2_1/_43}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_save_1/RestoreV2_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nCaused by op ‘save_1/RestoreV2_1’, defined at:\r\nFile “./DeepSpeech.py”, line 964, in\r\ntf.app.run(main)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py”, line 125, in run\r\n_sys.exit(main(argv))\r\nFile “./DeepSpeech.py”, line 916, in main\r\ntrain()\r\nFile “./DeepSpeech.py”, line 549, in train\r\nconfig=Config.session_config) as session:\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 504, in MonitoredTrainingSession\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 921, in init\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 643, in init\r\nself._sess = _RecoverableSession(self._coordinated_creator)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 1107, in init\r\n_WrappedSession.init(self, self._create_session())\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 1112, in _create_session\r\nreturn self._sess_creator.create_session()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 800, in create_session\r\nself.tf_sess = self._session_creator.create_session()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 557, in create_session\r\nself._scaffold.finalize()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py”, line 213, in finalize\r\nself._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 886, in _get_saver_or_default\r\nsaver = Saver(sharded=True, allow_empty=True)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 1102, in init\r\nself.build()\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 1114, in build\r\nself._build(self._filename, build_save=True, build_restore=True)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 1151, in _build\r\nbuild_save=build_save, build_restore=build_restore)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 789, in _build_internal\r\nrestore_sequentially, reshape)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 459, in _AddShardedRestoreOps\r\nname=“restore_shard”))\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 406, in _AddRestoreOps\r\nrestore_sequentially)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py”, line 862, in bulk_restore\r\nreturn io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py”, line 1466, in restore_v2\r\nshape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py”, line 787, in _apply_op_helper\r\nop_def=op_def)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py”, line 488, in new_func\r\nreturn func(*args, **kwargs)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py”, line 3274, in create_op\r\nop_def=op_def)\r\nFile “/home/sky-ai/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py”, line 1770, in init\r\nself._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,436631] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\r\n[[node save_1/RestoreV2_1 (defined at ./DeepSpeech.py:549) = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, …, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_1/tensor_names, save_1/RestoreV2_1/shape_and_slices)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n [[{{node save_1/RestoreV2_1/_43}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_save_1/RestoreV2_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n________________________________________________________________________________\r\n\r\nNo matter how I reduced the train and CV data compatibility, it always said this OMM problem. I’ve tried batch_size 1 but all the same. I used 16GB memory, 2*1080Ti,i7. No other program was running.",
        "state": "closed",
        "user": "myrainbowandsky",
        "closed_by": "zh794390558",
        "created_at": "2019-03-08T08:41:34+00:00",
        "updated_at": "2021-05-12T05:10:57+00:00",
        "closed_at": "2021-05-12T05:10:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 305,
        "title": "new_char == ' '适应英文情况，中文没有空格作为label,请教中文加LM解码时是每次都计算LM概率吗？",
        "body": "\r\n\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/a76fc692123e97e5f183c3a00e30b7f2e2d3f07c/decoders/decoders_deprecated.py\r\n\r\n```python\r\nelif new_char == ' ':\r\n                        if (ext_scoring_func is None) or (len(l) == 1):\r\n                            score = 1.0\r\n                        else:\r\n                            prefix = l[1:]\r\n                            score = ext_scoring_func(prefix)\r\n                        probs_nb_cur[l_plus] += score * prob_c * (\r\n                            probs_b_prev[l] + probs_nb_prev[l])\r\n```",
        "state": "closed",
        "user": "whaozl",
        "closed_by": "whaozl",
        "created_at": "2019-02-21T06:02:34+00:00",
        "updated_at": "2019-02-22T08:56:09+00:00",
        "closed_at": "2019-02-22T08:56:09+00:00",
        "comments_count": [
            "Slyne",
            "whaozl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 310,
        "title": "中文預測無空格及結合詞語言模型問題",
        "body": "請問一下，中文系統中辨識空格機率是0沒錯嗎？\r\n因為查看中文的vocab都沒有空格，辨識出句子同樣不含空格\r\n若是要使用word-basd LM需要有空格機率\r\n我看了英文的vocab是以字母為單位且包含空格\r\n辨識結果中就有包含空格這個字\r\n\r\n有修改過中文訓練集使得辨識可以輸出為含有空格句子\r\n但是在使用word-basd LM上的結果極差\r\n是否是解碼過程中導致多數word在LM中的機率和辨識label不符合？\r\n\r\n",
        "state": "closed",
        "user": "mp-lu",
        "closed_by": "zh794390558",
        "created_at": "2019-03-12T04:08:23+00:00",
        "updated_at": "2021-05-12T05:10:51+00:00",
        "closed_at": "2021-05-12T05:10:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 308,
        "title": "Test pre-trained EN model on a .wav file ",
        "body": "Hi there,\r\n\r\nI just finished installing the DeepSpeech and I'm very curious about BaiduEN8k Model's performance versus Google STT on some of my test .wav files. How do I use this model to decode/transcribe a wavfile named \"test.wav\" ? \r\n\r\nThank you ",
        "state": "closed",
        "user": "Cloud299",
        "closed_by": "zh794390558",
        "created_at": "2019-03-07T07:58:07+00:00",
        "updated_at": "2021-05-12T05:11:04+00:00",
        "closed_at": "2021-05-12T05:11:04+00:00",
        "comments_count": [
            "rhamnett",
            "Cloud299",
            "rhamnett",
            "Cloud299",
            "Cloud299",
            "rhamnett",
            "rhamnett",
            "Cloud299",
            "rhamnett",
            "Cloud299"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 311,
        "title": "'datasets/manifest.noise'这个文件 在哪里哈？",
        "body": "",
        "state": "closed",
        "user": "whaozl",
        "closed_by": "zh794390558",
        "created_at": "2019-03-12T13:27:37+00:00",
        "updated_at": "2021-05-12T05:10:44+00:00",
        "closed_at": "2021-05-12T05:10:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 312,
        "title": "Where is Impulse Response (need impulse audio files)? can you provide a download link?",
        "body": "",
        "state": "closed",
        "user": "whaozl",
        "closed_by": "zh794390558",
        "created_at": "2019-03-14T01:35:04+00:00",
        "updated_at": "2021-05-12T05:10:38+00:00",
        "closed_at": "2021-05-12T05:10:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 314,
        "title": "How should I compile swig myself?",
        "body": "I want to change the file decoders/swig/ctc_beam_search_decoder.cpp\r\n\r\nHow do I re-compile it and apply the new library ?",
        "state": "closed",
        "user": "yflin1",
        "closed_by": "zh794390558",
        "created_at": "2019-03-28T03:23:06+00:00",
        "updated_at": "2021-05-12T05:10:32+00:00",
        "closed_at": "2021-05-12T05:10:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 313,
        "title": "请问，在执行数据准备run_data.sh计算mean_std.npz这一步时，直接killed是什么原因？",
        "body": "root@dbcf49f7de8d:~/DeepSpeech# python tools/compute_mean_std.py --manifest_path='data/librispeech/manifest.train' --num_samples=2000 --specgram_type='linear' --output_path='data/librispeech/mean_std.npz'\r\n-----------  Configuration Arguments -----------\r\nmanifest_path: data/librispeech/manifest.train\r\nnum_samples: 2000\r\noutput_path: data/librispeech/mean_std.npz\r\nspecgram_type: linear\r\n------------------------------------------------\r\nKilled",
        "state": "closed",
        "user": "wshhja",
        "closed_by": "wshhja",
        "created_at": "2019-03-19T05:48:33+00:00",
        "updated_at": "2019-03-19T09:06:34+00:00",
        "closed_at": "2019-03-19T09:06:33+00:00",
        "comments_count": [
            "wshhja"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 315,
        "title": "How to build Mandarin LM ?",
        "body": "我自己训练了语言模型，且在 python 下使用 kenlm 模块测试正常，\r\nI trained my own language model and tested it with kenlm under python. No problem so far.\r\n\r\n但当我把它应用到 DeepSpeech-1 项目下，语音识别时，识别结果都是空字串，而如果用项目里提供的\r\n预训练语言模型又是正常的，我不知道我哪一步做错了。\r\nbut when I applied it to DeepSpeech-1 project for sound recognition, the output showed only blank string. However, if I use the pre-trained model came with the project, it worked just fine. I don't know which step went wrong.\r\n\r\n输入语料处理包括:\r\n1. 去除空白和非中文字符\r\n2. 所有字符之间都插入一个空白字符\r\n处理后的文件(train.txt，共254万行)，如下：\r\nI processed the input text with the following methods:\r\n1. delete blank and non-Chinese characters\r\n2. insert a blank character between the characters\r\nthe processed text (train.txt，2.54 million lines in total) is as below:\r\n\r\n<pre>\r\n在 苏 黎 世 主 宰 的 瑞 士 金 融 界 来 自 巴 塞 尔 的 奥 斯 佩 尔 迄 今 仍 然 是 局 外 人\r\n位 于 前 五 名 的 另 外 三 个 城 市 为 哥 本 哈 根 苏 黎 世 和 东 京 纽 约 名 列 全 球 第 七\r\n但 是 在 苏 黎 世 的 公 寓 里 他 很 快 就 恢 复 了 过 去 的 秩 序 和 旧 礼 节\r\n此 外 巴 赫 家 族 的 音 乐 将 贯 穿 整 个 艺 术 节 尤 见 于 苏 黎 世 芭 蕾 舞 团 以 至 安 洁 拉 休 伊 特 与 欧 洲 嘉 兰 乐 团 的 节 目\r\n...\r\n</pre>\r\n\r\n训练使用如下命令：\r\nI used these command to train the model\r\n<pre>\r\n./kenlm_asr/build/bin/lmplz -o 5 --prune 0 1 2 4 4 -T . < train.txt > train.arpa\r\n./kenlm_asr/build/bin/build_binary train.arpa train.klm\r\n</pre>\r\n\r\n生成的 .arpa 文件如下：\r\nthe generated .arpa file is as below:\r\n<pre>\r\n[yflin@p100 4_3ngram]$ head train.arpa -n 15\r\n\\data\\\r\nngram 1=4834\r\nngram 2=1108956\r\nngram 3=2311307\r\nngram 4=962852\r\nngram 5=467075\r\n\r\n\\1-grams:\r\n-6.0460653      <unk>   0\r\n0       <s>     -2.6255522\r\n-2.5958326      </s>    0\r\n-2.791055       而      -1.0586245\r\n-2.831564       对      -1.2137116\r\n-3.3869455      楼      -0.5979735\r\n-3.1091366      市      -0.7209683\r\n...\r\n</pre>\r\n\r\nPython 下测试语言模型：\r\nI tested my language model under python:\r\n<pre>\r\n>>> import kenlm\r\n>>> model=kenlm.Model(\"train.klm\")\r\n>>> model.score('这 是 一 个 测 试',bos = True,eos = True)\r\n-8.183526992797852\r\n</pre>\r\n\r\n使用该语言模型，语音识别时的输出如下：\r\nThe result of sound recognition using my model:\r\n<pre>\r\n[INFO 2019-03-27 14:18:25,014 server.py:122] start inference ...\r\n\r\nOutput Transcription:\r\n[INFO 2019-03-27 14:18:25,150 server.py:146] finish inference\r\n</pre>\r\n\r\n而改用项目里预训练的语言模型，语音识别的结果如下(识别正确)：\r\nAnd if I use the pre-trained language model came with the project, the result is like this:\r\n<pre>\r\n[INFO 2019-03-27 14:19:47,514 server.py:122] start inference ...\r\n\r\nOutput Transcription: 这是一个测试\r\n[INFO 2019-03-27 14:19:47,799 server.py:146] finish inference\r\n</pre>",
        "state": "closed",
        "user": "yflin1",
        "closed_by": "zh794390558",
        "created_at": "2019-03-28T03:25:12+00:00",
        "updated_at": "2021-05-12T05:10:26+00:00",
        "closed_at": "2021-05-12T05:10:26+00:00",
        "comments_count": [
            "ritesh-nitjsr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 316,
        "title": "model download url not accesible",
        "body": "```\r\nDownload language model ...\r\ndownload_lm_ch.sh: 8: [: 29e02312deb2e59b3c8686c7966d4fe3: unexpected operator\r\n--2019-03-31 05:24:42--  http://cloud.dlnel.org/filepub/?uuid=5cd1688e-78d9-4b9e-9c2f-6f104bd5b518\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 180.76.189.142\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|180.76.189.142|:80... connected.\r\nHTTP request sent, awaiting response... 302 Moved Temporarily\r\nLocation: http://domainwall.cloud.baidu.com/block.html [following]\r\n--2019-03-31 05:24:42--  http://domainwall.cloud.baidu.com/block.html\r\nResolving domainwall.cloud.baidu.com (domainwall.cloud.baidu.com)... 180.149.133.169\r\nConnecting to domainwall.cloud.baidu.com (domainwall.cloud.baidu.com)|180.149.133.169|:80... connected.\r\nHTTP request sent, awaiting response... 403 Forbidden\r\n2019-03-31 05:24:42 ERROR 403: Forbidden.\r\n```",
        "state": "closed",
        "user": "nobody132",
        "closed_by": "zh794390558",
        "created_at": "2019-03-31T05:27:45+00:00",
        "updated_at": "2021-05-12T05:10:19+00:00",
        "closed_at": "2021-05-12T05:10:19+00:00",
        "comments_count": [
            "aaronlyt",
            "huntzhan",
            "code-R",
            "kuke",
            "huntzhan",
            "code-R",
            "huntzhan",
            "code-R",
            "huntzhan",
            "code-R",
            "wshhja",
            "huntzhan",
            "wshhja",
            "nijil",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 319,
        "title": "would you like to build a model for hebrew.",
        "body": "Hello there!\r\n\r\nI'm looking to create a model for recognizing Hebrew in phone recordings. What would be the way to go about this?\r\n",
        "state": "closed",
        "user": "sivang",
        "closed_by": "zh794390558",
        "created_at": "2019-04-13T12:11:43+00:00",
        "updated_at": "2021-05-12T05:10:05+00:00",
        "closed_at": "2021-05-12T05:10:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 317,
        "title": "语言模型下载链接出问题",
        "body": "网站未备案，暂时无法访问\r\n该网站可能未进行备案或未完成转入百度云备案。根据工信部相关法规要求进行阻断显示。\r\n\r\n请网站管理员尽快登录 百度云备案系统 根据法规要求完成备案。\r\n\r\n",
        "state": "closed",
        "user": "aaronlyt",
        "closed_by": "zh794390558",
        "created_at": "2019-04-02T05:52:22+00:00",
        "updated_at": "2021-05-12T05:10:12+00:00",
        "closed_at": "2021-05-12T05:10:12+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 318,
        "title": "Transfer learning for different language",
        "body": "Hello, \r\nI want to create a ASR system to recognise Persian speech. I can train a model from scratch, but I want to resumes my training from a pre-trained model (such as LibriSpeech Model or BaiduEN8k Model). so I set the value of **\"--init_model_path\"** argument to the directory of  LibriSpeech Model parameters (models/librispeech/params.tar.gz). \r\nbut I got the following output:\r\n\r\n```\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: /home/DeepSpeech2-PaddlePaddle/train-persian/manifest.persian\r\ninit_model_path: models/librispeech/params.tar.gz\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: /home/DeepSpeech2-PaddlePaddle/train-persian/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: /home/DeepSpeech2-PaddlePaddle/train-persian/checkpoints/libri-based\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: /home/DeepSpeech2-PaddlePaddle/train-persian/manifest.persian\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: /home/DeepSpeech2-PaddlePaddle/train-persian/vocab.txt\r\n------------------------------------------------\r\nI0408 13:50:13.156404  6138 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=1 \r\n[INFO 2019-04-08 13:50:13,723 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-04-08 13:50:13,724 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-04-08 13:50:13,724 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-04-08 13:50:13,725 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-04-08 13:50:13,725 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-04-08 13:50:13,726 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nI0408 13:50:16.769909  6138 GradientMachine.cpp:94] Initing parameters..\r\nI0408 13:50:18.651311  6138 GradientMachine.cpp:101] Init parameters done.\r\nF0408 13:50:22.542716  6138 TensorApply.h:126] Check failed: lhs_.getWidth() == rhs_.getWidth() (118784 vs. 139264) \r\n*** Check failure stack trace: ***\r\n    @     0x7feb1472b04d  google::LogMessage::Fail()\r\n    @     0x7feb1472d398  google::LogMessage::SendToLog()\r\n    @     0x7feb1472ab5b  google::LogMessage::Flush()\r\n    @     0x7feb1472e26e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7feb148969c8  paddle::adamApply()\r\n    @     0x7feb1488f8c9  paddle::AdamParameterOptimizer::update()\r\n    @     0x7feb1488fcf2  paddle::OptimizerWithGradientClipping::update()\r\n    @     0x7feb14871e7e  paddle::SgdThreadUpdater::updateImpl()\r\n    @     0x7feb14700731  ParameterUpdater::update()\r\n    @     0x7feb141b3e87  _wrap_ParameterUpdater_update\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7feb308f2830  __libc_start_main\r\n    @           0x49d9d9  _start\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\nFail in training!\r\n\r\n```\r\nthe error Individually:\r\n\r\n```\r\nF0408 13:50:22.542716  6138 TensorApply.h:126] Check failed: lhs_.getWidth() == rhs_.getWidth() (118784 vs. 139264) \r\n```\r\n\r\nP.S. \r\nIt is necessary to mention that if I continue my training from checkpoints that they were created while I was training from scratch,  I will not get any errors. \r\nP.P.S\r\nI am pretty sure that using different vocabulary causes this problem, but I have no idea how to fix it.\r\n",
        "state": "closed",
        "user": "mtbadakhshan",
        "closed_by": "mtbadakhshan",
        "created_at": "2019-04-08T14:00:09+00:00",
        "updated_at": "2019-05-12T15:00:36+00:00",
        "closed_at": "2019-05-12T15:00:36+00:00",
        "comments_count": [
            "rhamnett",
            "mtbadakhshan",
            "mtbadakhshan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 320,
        "title": "Librispeech AM and LM download link",
        "body": "Hi,\r\n Can you fix please the AM and LM download link for Librispeech models? \r\n\r\nThank you!\r\n",
        "state": "closed",
        "user": "lucgeo",
        "closed_by": "zh794390558",
        "created_at": "2019-04-16T10:45:42+00:00",
        "updated_at": "2021-05-12T05:09:58+00:00",
        "closed_at": "2021-05-12T05:09:58+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 321,
        "title": "Downloading URL Don't working,get a 502 Error",
        "body": "Speech Model's url don't work.",
        "state": "closed",
        "user": "wshhja",
        "closed_by": "wshhja",
        "created_at": "2019-04-21T08:55:52+00:00",
        "updated_at": "2019-04-23T10:39:49+00:00",
        "closed_at": "2019-04-23T10:39:49+00:00",
        "comments_count": [
            "nijil",
            "kuke",
            "wshhja"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 323,
        "title": "How to run infer.py?",
        "body": "I ran the infer.py as follow:\r\npython -u infer.py \\\r\n--use_gru=True \\\r\n--use_gpu=False \\\r\n--share_rnn_weights=False \\\r\n--infer_manifest='data/aishell/manifest.test' \\\r\n--mean_std_path='mean_std.npz' \\\r\n--vocab_path='vocab.txt' \\\r\n--model_path='params.tar.gz' \\\r\n--lang_model_path='zh_giga.no_cna_cmn.prune01244.klm' \\\r\n\r\nThe params above are:\r\n--infer_manifest='data/aishell/manifest.test' \\   --------created by run example/aishell/run_data.sh\r\n--mean_std_path='mean_std.npz' \\  -------unzip from the speech model's compressed package(baidu_cn1.2k_model.tar.gz).\r\n--vocab_path='vocab.txt' \\   -------unzip from the speech model's compressed package(baidu_cn1.2k_model.tar.gz).\r\n--model_path='params.tar.gz' \\   -------unzip from the speech model's compressed package(baidu_cn1.2k_model.tar.gz).\r\n--lang_model_path='zh_giga.no_cna_cmn.prune01244.klm' \\`   -------the downloading language model\r\n\r\nBut it doesn't work and the console output remains as follow:\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: mean_std.npz\r\nmodel_path: params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntrainer_count: 8\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: vocab.txt\r\n------------------------------------------------\r\nI0423 22:42:26.985620 154393 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --trainer_count=8 \r\n\r\nHow can i fixed this problems?Thanks.",
        "state": "closed",
        "user": "wshhja",
        "closed_by": "zh794390558",
        "created_at": "2019-04-23T15:29:26+00:00",
        "updated_at": "2021-05-12T05:09:52+00:00",
        "closed_at": "2021-05-12T05:09:52+00:00",
        "comments_count": [
            "wshhja",
            "wshhja",
            "AshishKarel"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 324,
        "title": "ctc beam search: python version is not correct",
        "body": "hi , \r\n\r\nThe following python version ctc beam search result is not correct for mandarin with and without LM scorer.(https://github.com/PaddlePaddle/DeepSpeech/blob/develop/decoders/decoders_deprecated.py)\r\n\r\nI found this code is for English word based LM which can explain the result with LM is not correct for mandarin.  But result without LM is not correct either.\r\nC++ version is correct.\r\n\r\nCan you give some idea why the python version is not correct. thanks in advance.\r\n",
        "state": "closed",
        "user": "lixx0105",
        "closed_by": "zh794390558",
        "created_at": "2019-04-28T09:16:43+00:00",
        "updated_at": "2021-05-12T05:09:45+00:00",
        "closed_at": "2021-05-12T05:09:45+00:00",
        "comments_count": [
            "lixx0105"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 325,
        "title": "调用GPU训练的时候，有大量的context-switch",
        "body": "top会发现cpu idle 85%，基本是空闲。与此同时，nvidia-smi发现gpu大部分时间空闲。vmstat观察，CS值大约为三万。CPU核数要远大于python进程数。因为我把num_proc_data设置为1. 是什么原因导致如此大量的上下文切换呢？",
        "state": "closed",
        "user": "nemo9903",
        "closed_by": "zh794390558",
        "created_at": "2019-05-01T15:23:35+00:00",
        "updated_at": "2021-05-12T05:09:33+00:00",
        "closed_at": "2021-05-12T05:09:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 327,
        "title": "paddle related errors paddle.v2 and paddle.init",
        "body": "I fount the paddle has updated a lot.  we can't import paddle.v2 now .\r\nIf I change from paddle.v2 to paddle, then we will find the paddle.init \r\ncan't find too.\r\nWe can't use train.py and infer.py because of this.\r\nDoes anyone find the solution for this paddle upgrade issue? Can anyone help?",
        "state": "closed",
        "user": "liuborama",
        "closed_by": "zh794390558",
        "created_at": "2019-05-09T05:24:44+00:00",
        "updated_at": "2021-05-12T05:09:39+00:00",
        "closed_at": "2021-05-12T05:09:39+00:00",
        "comments_count": [
            "saibharani",
            "ulimmeh",
            "tcollins590",
            "fizzafarooq08"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 326,
        "title": "terminate called after throwing an instance of 'util::CompressedException'",
        "body": "通过docker配置的环境，执行到sh run_infer.sh 报错，模型下载路径已经修改了\r\n[English LM](https://deepspeech.bj.bcebos.com/en_lm/common_crawl_00.prune01111.trie.klm) \r\n[LibriSpeech Model](https://deepspeech.bj.bcebos.com/eng_models/librispeech_model.tar.gz)\r\n\r\n\r\nroot@6c5480fbb525:/DeepSpeech/examples/tiny# sh run_infer.sh \r\nDownload language model ...\r\ndownload_lm_en.sh: 8: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n--2019-05-08 10:25:03--  https://deepspeech.bj.bcebos.com/en_lm/common_crawl_00.prune01111.trie.klm\r\nResolving deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)... 180.149.142.214, 220.181.33.43\r\nConnecting to deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)|180.149.142.214|:443... connected.\r\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\r\n\r\n    The file is already fully retrieved; nothing to do.\r\n\r\ndownload_lm_en.sh: 20: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/tiny/manifest.tiny\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: data/tiny/mean_std.npz\r\nmodel_path: checkpoints/tiny/params.pass-19.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI0508 10:25:22.147784    89 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=1 \r\n[INFO 2019-05-08 10:25:26,183 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-05-08 10:25:26,184 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-05-08 10:25:26,185 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-05-08 10:25:26,186 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-05-08 10:25:26,187 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-05-08 10:25:26,187 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-05-08 10:25:30,907 model.py:243] begin to initialize the external scorer for decoding\r\nLoading the LM will be faster if you build a binary file.\r\nReading models/lm/common_crawl_00.prune01111.trie.klm\r\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\nterminate called after throwing an instance of 'util::CompressedException'\r\n  what():  kenlm/util/read_compressed.cc:376 in util::ReadBase* util::{anonymous}::ReadFactory(int, uint64_t&, const void*, std::size_t, bool) threw CompressedException.\r\nThis looks like a gzip file but gzip support was not compiled in. in file models/lm/common_crawl_00.prune01111.trie.klm\r\n*** Aborted at 1557311130 (unix time) try \"date -d @1557311130\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGABRT (@0x59) received by PID 89 (TID 0x7fc83aaa1700) from PID 89; stack trace: ***\r\n    @     0x7fc83a67d390 (unknown)\r\n    @     0x7fc83a2d7428 gsignal\r\n    @     0x7fc83a2d902a abort\r\n    @     0x7fc8227d084d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7fc8227ce6b6 (unknown)\r\n    @     0x7fc8227ce701 std::terminate()\r\n    @     0x7fc8227ce969 __cxa_rethrow\r\n    @     0x7fc817195c24 util::FilePiece::TransitionToRead()\r\n    @     0x7fc8171966f9 util::FilePiece::FilePiece()\r\n    @     0x7fc8171a9ee1 lm::ngram::detail::GenericModel<>::InitializeFromARPA()\r\n    @     0x7fc8171ac13b lm::ngram::detail::GenericModel<>::GenericModel()\r\n    @     0x7fc8171a33db lm::ngram::LoadVirtual()\r\n    @     0x7fc8172d4a5f Scorer::load_lm()\r\n    @     0x7fc8172d8041 Scorer::setup()\r\n    @     0x7fc8172d813d Scorer::Scorer()\r\n    @     0x7fc817292f48 _wrap_new_Scorer\r\n    @           0x4c468a PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4de6fe (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f492e (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4c9faf PyEval_EvalFrameEx\r\n    @           0x4c2765 PyEval_EvalCodeEx\r\n    @           0x4de6fe (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f492e (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4f46a7 (unknown)\r\n    @           0x4b670c (unknown)\r\n    @           0x4b0cb3 PyObject_Call\r\n    @           0x4c9faf PyEval_EvalFrameEx\r\nAborted (core dumped)\r\nFailed in inference!",
        "state": "closed",
        "user": "aslily1234",
        "closed_by": "aslily1234",
        "created_at": "2019-05-08T10:38:42+00:00",
        "updated_at": "2019-05-08T10:50:19+00:00",
        "closed_at": "2019-05-08T10:50:19+00:00",
        "comments_count": [
            "aslily1234"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 328,
        "title": "下载预训练模型失败，502问题",
        "body": "你好，查看issue时有见到说下载链接问题已经解决了，但是我这里还是存在502问题，可以烦请官方人员帮忙看看吗，谢谢~\r\n\r\nDownload LibriSpeech model ...\r\ndownload_model.sh: 8: [: 1f72d0c5591f453362f0caa09dd57618: unexpected operator\r\n--2019-05-13 08:31:58--  http://cloud.dlnel.org/filepub/?uuid=117cde63-cd59-4948-8b80-df782555f7d6\r\nResolving cloud.dlnel.org (cloud.dlnel.org)... 115.239.210.226\r\nConnecting to cloud.dlnel.org (cloud.dlnel.org)|115.239.210.226|:80... connected.\r\nHTTP request sent, awaiting response... 502 Bad Gateway\r\nCookie coming from cloud.dlnel.org attempted to set domain to baidu.com\r\n2019-05-13 08:32:01 ERROR 502: Bad Gateway.\r\n\r\nFail to download LibriSpeech model!",
        "state": "closed",
        "user": "YasinZhao",
        "closed_by": "zh794390558",
        "created_at": "2019-05-13T08:34:46+00:00",
        "updated_at": "2021-05-12T05:09:21+00:00",
        "closed_at": "2021-05-12T05:09:21+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 329,
        "title": "Fail to download resource from http://cloud.dlnel.org/filepub/",
        "body": "Models/aishell\r\ndownload_model.sh\r\nhttp://cloud.dlnel.org/filepub/?uuid=61de63b9-6904-4809-ad95-0cc5104ab973\r\nI get 502 Bad Gateway. Anyone can help?",
        "state": "closed",
        "user": "liuborama",
        "closed_by": "liuborama",
        "created_at": "2019-05-17T09:45:06+00:00",
        "updated_at": "2019-05-17T09:49:04+00:00",
        "closed_at": "2019-05-17T09:48:05+00:00",
        "comments_count": [
            "liuborama"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 330,
        "title": "how to solve cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed]",
        "body": "I run the examples/tiny from the docker image. My machine is equipped with 4 GTX 2080Ti gpu",
        "state": "closed",
        "user": "wegamekinglc",
        "closed_by": "zh794390558",
        "created_at": "2019-05-27T11:28:18+00:00",
        "updated_at": "2021-05-12T05:09:27+00:00",
        "closed_at": "2021-05-12T05:09:27+00:00",
        "comments_count": [
            "ghost",
            "roywangtj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 335,
        "title": "why size=dict_size+1, is it for the blank?",
        "body": "in network.py:\r\n    fc = paddle.layer.fc(\r\n        input=rnn_group_output,\r\n        size=dict_size + 1,\r\n        act=paddle.activation.Linear(),\r\n        bias_attr=True)\r\nis it for the blank? thanks a lot.",
        "state": "closed",
        "user": "mtxing69",
        "closed_by": "mtxing69",
        "created_at": "2019-06-21T06:58:07+00:00",
        "updated_at": "2019-06-21T08:09:47+00:00",
        "closed_at": "2019-06-21T08:09:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 331,
        "title": "cannot import name md5file",
        "body": "from paddle.v2.dataset.common import md5file\r\n导入报错，查看官网，老版本文档api没法看，新版本没找到 md5file。请问，最新的版本中怎么导入？",
        "state": "closed",
        "user": "tai960519073",
        "closed_by": "zh794390558",
        "created_at": "2019-05-30T14:59:21+00:00",
        "updated_at": "2021-05-12T05:09:07+00:00",
        "closed_at": "2021-05-12T05:09:07+00:00",
        "comments_count": [
            "SunlerZRY",
            "hsauod"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 332,
        "title": "BaiduCN1.2k Model的音频采样率、位深度、声道是什么啊",
        "body": "百度提供的BaiduCN1.2k Model所使用的音频采样率、位深度、声道是什么啊\r\n\r\n![image](https://user-images.githubusercontent.com/50564800/59178674-3f992d00-8b92-11e9-9bcc-97ee3576eff3.png)\r\n",
        "state": "closed",
        "user": "QAQ1551QAQ",
        "closed_by": "zh794390558",
        "created_at": "2019-06-10T07:13:30+00:00",
        "updated_at": "2021-05-12T05:09:14+00:00",
        "closed_at": "2021-05-12T05:09:14+00:00",
        "comments_count": [
            "tai960519073",
            "wegamekinglc",
            "tai960519073",
            "QAQ1551QAQ",
            "dxhgq-github",
            "tai960519073",
            "dxhgq-github",
            "nicole-zhao",
            "wegamekinglc",
            "tai960519073",
            "jasonlbx13",
            "wuitson",
            "ccbptm",
            "ccbptm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 336,
        "title": "Any plan to upgrade Baddle depency?",
        "body": "Is there any plan to upgrade the paddle dependecy? Currently the project depends on a very old paddle version and python 2.7.",
        "state": "closed",
        "user": "wegamekinglc",
        "closed_by": "kuke",
        "created_at": "2019-06-24T02:16:02+00:00",
        "updated_at": "2019-11-18T03:38:52+00:00",
        "closed_at": "2019-11-01T06:51:34+00:00",
        "comments_count": [
            "nemo9903",
            "kuke",
            "wegamekinglc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 338,
        "title": "BaiduCN1.2k Model数据集",
        "body": "请问咱们BaiduCN1.2k Model模型采用的数据集是什么样的，比如什么环境，能公开一点数据看看吗",
        "state": "closed",
        "user": "tai960519073",
        "closed_by": "zh794390558",
        "created_at": "2019-06-27T01:42:24+00:00",
        "updated_at": "2021-05-12T05:09:00+00:00",
        "closed_at": "2021-05-12T05:09:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 337,
        "title": "Error in training with predefined model",
        "body": "Hi, \r\nI am newbie to this. I just went through the ReadMe and started to follow it. \r\nWhen I start training the predefined model with tiny data via **\"sh run_train.py\"**,  I found the below error.\r\n\r\nF0624 17:24:26.961547 14845 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: cudnn_conv\r\n*** Check failure stack trace: ***\r\n    @     0x7f4b04212eed  google::LogMessage::Fail()\r\n    @     0x7f4b0421699c  google::LogMessage::SendToLog()\r\n    @     0x7f4b04212a13  google::LogMessage::Flush()\r\n    @     0x7f4b04217eae  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f4b03fd853b  paddle::Layer::create()\r\n    @     0x7f4b03e99cd8  _ZZN6paddle13NeuralNetwork4initERKNS_11ModelConfigESt8functionIFviPNS_9ParameterEEERKSt6vectorINS_19enumeration_wrapper13ParameterTypeESaISB_EEbENKUlRKNS_11LayerConfigEE_clESI_\r\n    @     0x7f4b03e9abff  paddle::NeuralNetwork::init()\r\n    @     0x7f4b03e8f6c6  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @     0x7f4b03e94f1f  paddle::GradientMachine::create()\r\n    @     0x7f4b041ef935  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7f4b041efb1f  GradientMachine::createByConfigProtoStr()\r\n    @     0x7f4b03e4c857  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4c2e1e  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c17c6  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4d57a3  (unknown)\r\n    @           0x4eef5e  (unknown)\r\n    @           0x4eeb66  (unknown)\r\n    @           0x4aaafb  (unknown)\r\n    @           0x4c166d  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c17c6  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4eb69f  (unknown)\r\n    @           0x4e58f2  PyRun_FileExFlags\r\nAborted (core dumped)\r\nFail in training!\r\n\r\nPlease help me!",
        "state": "closed",
        "user": "artinegi1607",
        "closed_by": "artinegi1607",
        "created_at": "2019-06-24T12:06:39+00:00",
        "updated_at": "2019-07-17T06:41:52+00:00",
        "closed_at": "2019-07-17T06:41:52+00:00",
        "comments_count": [
            "QAQ1551QAQ",
            "artinegi1607"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 339,
        "title": "在百度的BaiduCN1.2k Model基础上继续训练，出现错误 Check failed: src.getSize() == this->getSize() (8060928 vs. 4030464)",
        "body": "我也是加载预训练模型训练的时候出错，--init_model_path = 'models/baiduCN/params.tar.gz'\r\n\r\nI0626 07:27:05.990948 1586 Util.cpp:166] commandline: --use_gpu=1 --rnn_use_batch=True --log_clipping=True --trainer_count=2\r\n[INFO 2019-06-26 07:27:07,147 layers.py:2606] output for conv_0: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-06-26 07:27:07,148 layers.py:3133] output for batch_norm_0: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-06-26 07:27:07,148 layers.py:7224] output for scale_sub_region_0: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-06-26 07:27:07,149 layers.py:2606] output for conv_1: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-06-26 07:27:07,150 layers.py:3133] output for batch_norm_1: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-06-26 07:27:07,150 layers.py:7224] output for scale_sub_region_1: c = 32, h = 41, w = 54, size = 70848\r\nI0626 07:27:26.776872 1586 MultiGradientMachine.cpp:99] numLogicalDevices=1 numThreads=2 numDevices=2\r\nI0626 07:27:26.796452 1586 GradientMachine.cpp:94] Initing parameters..\r\nI0626 07:27:29.301322 1586 GradientMachine.cpp:101] Init parameters done.\r\nF0626 07:27:31.709532 1663 Vector.cpp:266] Check failed: src.getSize() == this->getSize() (8060928 vs. 4030464)\r\n*** Check failure stack trace: ***\r\nF0626 07:27:31.712079 1659 Vector.cpp:266] Check failed: src.getSize() == this->getSize() (8060928 vs. 4030464)\r\n*** Check failure stack trace: ***\r\n@ 0x7f30387ce04d google::LogMessage::Fail()\r\n@ 0x7f30387d0398 google::LogMessage::SendToLog()\r\n@ 0x7f30387ce04d google::LogMessage::Fail()\r\n@ 0x7f30387d0398 google::LogMessage::SendToLog()\r\n@ 0x7f30387cdb5b google::LogMessage::Flush()\r\n@ 0x7f30387d126e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f30387cdb5b google::LogMessage::Flush()\r\n@ 0x7f30385d3e3e paddle::GpuVectorT<>::copyFrom()\r\n@ 0x7f30387d126e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f303846aae4 paddle::TrainerThread::valueDispatchThread()\r\n@ 0x7f30385d3e3e paddle::GpuVectorT<>::copyFrom()\r\n@ 0x7f30bf26bc80 (unknown)\r\n@ 0x7f303846aae4 paddle::TrainerThread::valueDispatchThread()\r\n@ 0x7f30c9a5b6ba start_thread\r\n@ 0x7f30c97913dd clone\r\n@ 0x7f30bf26bc80 (unknown)\r\n@ 0x7f30c9a5b6ba start_thread\r\n@ (nil) (unknown)\r\nAborted (core dumped)\r\nFailed in training!",
        "state": "closed",
        "user": "QAQ1551QAQ",
        "closed_by": "zh794390558",
        "created_at": "2019-06-27T06:08:26+00:00",
        "updated_at": "2021-05-12T05:08:41+00:00",
        "closed_at": "2021-05-12T05:08:41+00:00",
        "comments_count": [
            "Re-bin",
            "QAQ1551QAQ",
            "suntingfeng",
            "jchua127",
            "xueshang-liulp",
            "springminhcm",
            "xueshang-liulp",
            "springminhcm",
            "xueshang-liulp",
            "springminhcm",
            "xueshang-liulp",
            "springminhcm",
            "xueshang-liulp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 343,
        "title": "Time consumption and data size for tuning",
        "body": "How many dataset are needed for tuning? I have tried about only 200 data and it took me so much time about 10 hours to tune, and I didn't see the result for the gpu is limited. Is that normal? Does this consume so much time?",
        "state": "closed",
        "user": "liuziyi219",
        "closed_by": "zh794390558",
        "created_at": "2019-07-27T15:37:20+00:00",
        "updated_at": "2021-05-12T05:08:25+00:00",
        "closed_at": "2021-05-12T05:08:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 340,
        "title": "请问输入的audio，该采用那一种格式呢？",
        "body": "pocketsphinx的要求是\r\n\r\n\"single-channel (monaural), little-endian, unheadered 16-bit signed PCM audio file sampled at 16000 Hz\". \r\n\r\n那么DeepSpeech的要求呢?谢谢",
        "state": "closed",
        "user": "stereomatchingkiss",
        "closed_by": "zh794390558",
        "created_at": "2019-06-29T07:08:18+00:00",
        "updated_at": "2021-05-12T05:08:32+00:00",
        "closed_at": "2021-05-12T05:08:32+00:00",
        "comments_count": [
            "jchua127"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 342,
        "title": "run_train.sh error, Fatal Python error: PyThreadState_Get: no current thread",
        "body": "```\r\ncekhwang@cekhwangdeMacBook-Air tiny % sh run_train.sh \r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 0\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nFatal Python error: PyThreadState_Get: no current thread\r\nrun_train.sh: line 33:  1295 Abort trap: 6           \r\nCUDA_VISIBLE_DEVICES=0 \r\npython -u train.py \r\n--batch_size=16 \r\n--trainer_count=0 \r\n--num_passes=20 \r\n--num_proc_data=1 \r\n--num_conv_layers=2 \r\n--num_rnn_layers=3 \r\n--rnn_layer_size=2048 \r\n--num_iter_print=100 \r\n--learning_rate=1e-5 \r\n--max_duration=27.0 \r\n--min_duration=0.0 \r\n--test_off=False \r\n--use_sortagrad=True \r\n--use_gru=False \r\n--use_gpu=False \r\n--is_local=True \r\n--share_rnn_weights=True \r\n--train_manifest='data/tiny/manifest.tiny' \r\n--dev_manifest='data/tiny/manifest.tiny' \r\n--mean_std_path='data/tiny/mean_std.npz' \r\n--vocab_path='data/tiny/vocab.txt' \r\n--output_model_dir='./checkpoints/tiny' \r\n--augment_conf_path='conf/augmentation.config' \r\n--specgram_type='linear' \r\n--shuffle_method='batch_shuffle_clipped'\r\nFail in training!\r\n```\r\nI am not using gpu, so I set all use_gpu=False, trainer_count=0 and CUDA_VISIBLE_DEVICES=0, others setting are default. But when I run sh run_train.sh, it shows this problem. Did anyone encounter this problem?",
        "state": "closed",
        "user": "iekhwang",
        "closed_by": "zh794390558",
        "created_at": "2019-07-24T14:29:40+00:00",
        "updated_at": "2021-05-12T05:08:48+00:00",
        "closed_at": "2021-05-12T05:08:48+00:00",
        "comments_count": [
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 341,
        "title": "error when executing small, Aborted (core dumped)",
        "body": "hello tried to run deepspeech with docker, it downloaded from docker hub, but I could not configure it correctly to only use CPUs.\r\nI would appreciate knowing the complete configuration to only use CPU.\r\n\r\n> run_train configuration\r\n`\r\n***********  Configuration Arguments **********\r\naugment_conf_path: conf/augmentation.config \r\nbatch_size: 8\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_model_path: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 20\r\nnum_proc_data: 1\r\nnum_rnn_layers: 3\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\ntrainer_count: 0\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n`\r\n\r\nerror:\r\nI0717 19:07:04.436843   647 Util.cpp:166] commandline:  --use_gpu=0 --rnn_use_batch=True --log_clipping=True --trainer_count=0 \r\n[INFO 2019-07-17 19:07:04,477 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-07-17 19:07:04,479 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-07-17 19:07:04,479 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-07-17 19:07:04,480 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-07-17 19:07:04,482 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-07-17 19:07:04,483 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\nF0717 19:07:04.529284   647 GradientMachine.cpp:67] Unknown model type: nn\r\n*** Check failure stack trace: ***\r\n    @     0x7f9818ed004d  google::LogMessage::Fail()\r\n    @     0x7f9818ed2398  google::LogMessage::SendToLog()\r\n    @     0x7f9818ecfb5b  google::LogMessage::Flush()\r\n    @     0x7f9818ed326e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f9818b74c0c  paddle::GradientMachine::create()\r\n    @     0x7f9818ea08bb  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7f9818ea14ce  GradientMachine::createByConfigProtoStr()\r\n    @     0x7f98189883aa  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4c2e1e  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c17c6  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4d57a3  (unknown)\r\n    @           0x4eef5e  (unknown)\r\n    @           0x4eeb66  (unknown)\r\n    @           0x4aaafb  (unknown)\r\n    @           0x4c166d  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c17c6  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4c1f56  PyEval_EvalFrameEx\r\n    @           0x4b9b66  PyEval_EvalCodeEx\r\n    @           0x4eb69f  (unknown)\r\n    @           0x4e58f2  PyRun_FileExFlags\r\n    @           0x4e41a6  PyRun_SimpleFileExFlags\r\n    @           0x4938ce  Py_Main\r\n    @     0x7f9835098830  __libc_start_main\r\n    @           0x493299  _start\r\nAborted (core dumped)\r\nFail in training!\r\n",
        "state": "closed",
        "user": "DemonPrince",
        "closed_by": "zh794390558",
        "created_at": "2019-07-17T19:51:44+00:00",
        "updated_at": "2021-05-12T05:08:54+00:00",
        "closed_at": "2021-05-12T05:08:54+00:00",
        "comments_count": [
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 345,
        "title": "infer.py raise StopIteration Exception",
        "body": "I got this error when i tried to run sh run_infer_golden.sh in tiny examples folder \r\ni even tried to make try and catch but it didn't work\r\nis there any other suggestion ? \r\n\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/tiny/manifest.test-clean\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/librispeech/mean_std.npz\r\nmodel_path: models/librispeech/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 1\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: models/librispeech/vocab.txt\r\n------------------------------------------------\r\nI0801 10:23:59.024675 27241 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=1 \r\nW0801 10:23:59.524929 27241 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 135, in <module>\r\n    main()\r\n  File \"infer.py\", line 131, in main\r\n    infer()\r\n  File \"infer.py\", line 79, in infer\r\n    infer_data = batch_reader().next()\r\nStopIteration\r\nFailed in inference!",
        "state": "closed",
        "user": "mohamedITworx",
        "closed_by": "zh794390558",
        "created_at": "2019-08-01T08:27:03+00:00",
        "updated_at": "2021-05-12T05:05:20+00:00",
        "closed_at": "2021-05-12T05:05:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 344,
        "title": "如何将DeepSpeech的weights转换成onnx格式，或者任何能被tensorflow读取的格式。",
        "body": "如题。 我对paddlepaddle了解很肤浅。。 我想用pytorch加载预训练的百度模型。 但在我到处理模型权重时，我发现每个conv layer 权重都是都被squeeze成了一个list。例如， 第一层的conv layer 参数应该是 32个kernel，每个kernel是一个shape应该是（1，11，41）的tensor。但预训练模型的第一层权重是一个shape为（1，14432）的list。因为32\\*11\\*41=14432， 所以我猜测这个list中的每个element对应该layer中的一个weight。根据paddle.v2.parameter.Parameters的帮助信息，一个list中的每一个element是protobuf struct。 它记录了每个weight的信息。 \r\n\r\n我对protobuf完全不熟悉。 不知道应该如何正确映射每一个element的权重信息到该layer的对应权重位置上去。即将 （1，14431） 复原为 32 个shape为（1，11，14）的kernel。  deepspeech必须要用0.13或者更早的paddlepaddle， 我很难找到相关的权重导出的信息。\r\n\r\n有人能教教我应该怎么根据protobuf的信息做权重映射吗？只要能够将这个模型转换成onnx格式或者tensorflow的可读格式即可。  或者给点提示我应该去哪查找protobuf的更多相关资料。",
        "state": "closed",
        "user": "SamChen",
        "closed_by": "zh794390558",
        "created_at": "2019-07-31T18:48:42+00:00",
        "updated_at": "2021-05-12T05:08:16+00:00",
        "closed_at": "2021-05-12T05:08:16+00:00",
        "comments_count": [
            "zhangzhenyuyu",
            "SamChen",
            "shoegazerstella",
            "SamChen",
            "yangyangHu",
            "SamChen",
            "yangyangHu",
            "SamChen",
            "yangyangHu",
            "SamChen",
            "yangyangHu",
            "SamChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 346,
        "title": "Which version of cuda is sutible for this project?",
        "body": "",
        "state": "closed",
        "user": "SunlerZRY",
        "closed_by": "zh794390558",
        "created_at": "2019-08-07T08:19:41+00:00",
        "updated_at": "2021-05-12T05:08:09+00:00",
        "closed_at": "2021-05-12T05:08:09+00:00",
        "comments_count": [
            "SunlerZRY",
            "ghost",
            "SunlerZRY",
            "SunlerZRY",
            "ghost",
            "shoegazerstella"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 347,
        "title": "ModuleNotFoundError: No module named 'swig_decoders'",
        "body": "你好，安装swig已经成功安装，在pip list中也能看见，但是当使用python import swig_decoders的时候会报ModuleNotFoundError: No module named 'swig_decoders'错误，这个是什么原因导致的啊？ 谢谢！！！",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "suntingfeng",
        "created_at": "2019-08-12T01:56:26+00:00",
        "updated_at": "2025-04-01T07:42:27+00:00",
        "closed_at": "2019-08-12T05:11:28+00:00",
        "comments_count": [
            "suntingfeng",
            "blackstrawlstm",
            "ExpressGit",
            "suntingfeng",
            "zhangyifei1",
            "tongtongking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 349,
        "title": "vocab.txt文件位置",
        "body": "你好，\r\ntest.py文件中\r\nadd_arg('vocab_path',       str,\r\n        'data/librispeech/vocab.txt',\r\n        \"Filepath of vocabulary.\")\r\n我想问一下此文件在哪啊，哪里下载可以得到啊？",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "suntingfeng",
        "created_at": "2019-08-12T11:15:17+00:00",
        "updated_at": "2019-08-14T09:42:50+00:00",
        "closed_at": "2019-08-14T09:42:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 352,
        "title": "预测为空",
        "body": "",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "zh794390558",
        "created_at": "2019-08-17T08:14:47+00:00",
        "updated_at": "2021-05-12T05:07:55+00:00",
        "closed_at": "2021-05-12T05:07:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 356,
        "title": "预测语句时长",
        "body": "你好，我想咨询一下，预测语句最大的时长大概是多长时间呢？",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "zh794390558",
        "created_at": "2019-08-22T01:00:27+00:00",
        "updated_at": "2021-05-12T05:07:42+00:00",
        "closed_at": "2021-05-12T05:07:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 353,
        "title": "预测为空",
        "body": "",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "suntingfeng",
        "created_at": "2019-08-17T08:14:49+00:00",
        "updated_at": "2019-08-17T08:14:56+00:00",
        "closed_at": "2019-08-17T08:14:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 348,
        "title": "Why lookahead convolution is not implemented?",
        "body": "In the original paper of [DeepSpeech2](https://arxiv.org/abs/1512.02595), **lookahead convolution** is introduced for unidirectional model to keep accuracy, lower the latency compared to bidirectional model. And the best English models in the paper is 3 layers of unidirectional GRU with lookahead convolution. So, it seems that lookahead convolution is great for real-time deploy, but why lookahead convolution is not implemented in this repository?\r\n\r\nThanks!",
        "state": "closed",
        "user": "jfan0",
        "closed_by": "zh794390558",
        "created_at": "2019-08-12T03:17:21+00:00",
        "updated_at": "2021-05-12T05:08:02+00:00",
        "closed_at": "2021-05-12T05:08:02+00:00",
        "comments_count": [
            "gbxu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 357,
        "title": "请问什么时候会发布fluid的版本？谢谢",
        "body": "@kuke 您好，请问什么时候会发布fluid版本的deepspeech？谢谢",
        "state": "closed",
        "user": "hui001",
        "closed_by": "zh794390558",
        "created_at": "2019-08-29T08:02:38+00:00",
        "updated_at": "2021-05-12T05:07:29+00:00",
        "closed_at": "2021-05-12T05:07:29+00:00",
        "comments_count": [
            "onmywei",
            "lfchener",
            "hui001",
            "tai960519073",
            "tai960519073",
            "springminhcm",
            "springminhcm",
            "suntingfeng",
            "springminhcm",
            "springminhcm",
            "hui001",
            "kuke",
            "xueshang-liulp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 358,
        "title": "请问 BaiduCN1.2k Model 模型要怎么调用",
        "body": "请问 BaiduCN1.2k Model 模型要怎么调用，谢谢了。",
        "state": "closed",
        "user": "Re-bin",
        "closed_by": "Re-bin",
        "created_at": "2019-08-31T12:57:50+00:00",
        "updated_at": "2021-01-21T01:20:07+00:00",
        "closed_at": "2019-11-30T15:27:19+00:00",
        "comments_count": [
            "a2741432",
            "tai960519073",
            "Re-bin",
            "ccbptm",
            "ccbptm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 360,
        "title": "Timestamp",
        "body": "Is it possible to get the timestamp of each word? ",
        "state": "closed",
        "user": "tcollins590",
        "closed_by": "zh794390558",
        "created_at": "2019-09-09T23:18:14+00:00",
        "updated_at": "2021-05-12T05:07:37+00:00",
        "closed_at": "2021-05-12T05:07:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 359,
        "title": "terminate called after throwing an instance of 'Xbyak::Error'",
        "body": "`Download language model ...\r\ndownload_lm_en.sh: 8: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n--2019-09-03 14:23:04--  https://deepspeech.bj.bcebos.com/en_lm/common_crawl_00.prune01111.trie.klm\r\n正在解析主机 deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)... 111.206.47.194, 202.106.5.21\r\n正在连接 deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)|111.206.47.194|:443... 已连接。\r\n已发出 HTTP 请求，正在等待回应... 416 Requested Range Not Satisfiable\r\n\r\n    文件已下载完成；不会进行任何操作。\r\n\r\ndownload_lm_en.sh: 20: [: 099a601759d467cd0a8523ff939819c5: unexpected operator\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/tiny/manifest.tiny\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: data/tiny/mean_std.npz\r\nmodel_path: checkpoints/tiny/params.pass-19.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nterminate called after throwing an instance of 'Xbyak::Error'\r\n  what():  internal error\r\nAborted (core dumped)\r\nFailed in inference!\r\n`",
        "state": "closed",
        "user": "onmywei",
        "closed_by": "zh794390558",
        "created_at": "2019-09-03T06:27:19+00:00",
        "updated_at": "2021-05-12T05:07:48+00:00",
        "closed_at": "2021-05-12T05:07:48+00:00",
        "comments_count": [
            "onmywei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 364,
        "title": "punctuation",
        "body": "why we get rid of punctuation？When we add the comma and full stop ，what‘s the problem？",
        "state": "closed",
        "user": "windowxiaoming",
        "closed_by": "zh794390558",
        "created_at": "2019-09-23T01:35:48+00:00",
        "updated_at": "2021-05-12T05:05:51+00:00",
        "closed_at": "2021-05-12T05:05:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 361,
        "title": "Client启动失败求助，缺乏包pynput",
        "body": "```\r\nroot@34657c994c1d:/DeepSpeech# CUDA_VISIBLE_DEVICES=0 python -u deploy/demo_client.py --host_ip 'localhost' --host_port 8086\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_client.py\", line 2, in <module>\r\n    from pynput import keyboard\r\nImportError: No module named pynput\r\n\r\n```",
        "state": "closed",
        "user": "Re-bin",
        "closed_by": "Re-bin",
        "created_at": "2019-09-10T03:29:23+00:00",
        "updated_at": "2021-03-16T03:12:45+00:00",
        "closed_at": "2019-09-22T03:12:22+00:00",
        "comments_count": [
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 362,
        "title": "Export the trained model",
        "body": "Hello Team,\r\n\r\nI have trained a model and now I want to export the trained model. Is there is any way to achieve it (apart from the checkpoint directory)?\r\n\r\n",
        "state": "closed",
        "user": "AASHISHAG",
        "closed_by": "AASHISHAG",
        "created_at": "2019-09-11T16:50:20+00:00",
        "updated_at": "2019-09-11T16:52:20+00:00",
        "closed_at": "2019-09-11T16:52:20+00:00",
        "comments_count": [
            "AASHISHAG"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 365,
        "title": "当我在docker中运行run_infer_golden.sh时，报了如下错误，请问什么原因导致的？",
        "body": "运行时只使用了一个显卡，１张GTX 1080TI ，显存11GB\r\n\r\nroot@1e103b8c3b19:/DeepSpeech/examples/tiny# sh run_infer_golden.sh \r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/tiny/manifest.test-clean\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/librispeech/mean_std.npz\r\nmodel_path: models/librispeech/params.tar.gz\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 1\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: models/librispeech/vocab.txt\r\n------------------------------------------------\r\nI0923 13:29:14.188905    36 Util.cpp:166] commandline:  --use_gpu=1 --rnn_use_batch=True --trainer_count=1 \r\n[INFO 2019-09-23 13:29:20,204 layers.py:2606] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-09-23 13:29:20,207 layers.py:3133] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-09-23 13:29:20,209 layers.py:7224] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-09-23 13:29:20,211 layers.py:2606] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-09-23 13:29:20,214 layers.py:3133] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-09-23 13:29:20,215 layers.py:7224] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-09-23 13:29:24,914 model.py:243] begin to initialize the external scorer for decoding\r\n[INFO 2019-09-23 13:33:51,108 model.py:253] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2019-09-23 13:33:51,589 model.py:254] end initializing scorer\r\n[INFO 2019-09-23 13:33:51,589 infer.py:103] start inference ...\r\nF0923 13:33:57.753219    36 hl_cuda_device.cc:273] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory\r\n*** Check failure stack trace: ***\r\n    @     0x7f475d89b04d  google::LogMessage::Fail()\r\n    @     0x7f475d89d398  google::LogMessage::SendToLog()\r\n    @     0x7f475d89ab5b  google::LogMessage::Flush()\r\n    @     0x7f475d89e26e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f475d843a9f  hl_malloc_device()\r\n    @     0x7f475d6977c7  paddle::GpuAllocator::alloc()\r\n    @     0x7f475d684458  paddle::PoolAllocator::alloc()\r\n    @     0x7f475d683e33  paddle::GpuMemoryHandle::GpuMemoryHandle()\r\n    @     0x7f475d69efef  paddle::GpuVectorT<>::GpuVectorT()\r\n    @     0x7f475d69f388  paddle::VectorT<>::create()\r\n    @     0x7f475d69f3f8  paddle::VectorT<>::createParallelVector()\r\n    @     0x7f475d53de84  _ZNSt17_Function_handlerIFviPN6paddle9ParameterEEZNS0_15GradientMachine6createERKNS0_11ModelConfigEiRKSt6vectorINS0_19enumeration_wrapper13ParameterTypeESaISA_EEEUliS2_E_E9_M_invokeERKSt9_Any_dataOiOS2_\r\n    @     0x7f475d527933  paddle::NeuralNetwork::init()\r\n    @     0x7f475d53f331  paddle::GradientMachine::create()\r\n    @     0x7f475d86b8bb  GradientMachine::createFromPaddleModelPtr()\r\n    @     0x7f475d86c4ce  GradientMachine::createByConfigProtoStr()\r\n    @     0x7f475d3533aa  _wrap_GradientMachine_createByConfigProtoStr\r\n    @           0x4cb45e  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4de8b8  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4f492e  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4f46a7  (unknown)\r\n    @           0x4b670c  (unknown)\r\n    @           0x4b0cb3  PyObject_Call\r\n    @           0x4c9faf  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\nAborted (core dumped)\r\nFailed in inference!\r\n",
        "state": "closed",
        "user": "MrCuiHao",
        "closed_by": "zh794390558",
        "created_at": "2019-09-23T14:03:29+00:00",
        "updated_at": "2021-05-12T05:06:59+00:00",
        "closed_at": "2021-05-12T05:06:59+00:00",
        "comments_count": [
            "GC-Tom"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 363,
        "title": "基于Mandarin LM Large的剪枝",
        "body": "Mandarin LM Large下载的文件zhidao_giga.klm，能不能通过\r\n` bin/lmplz -o5 --prune 0 1 1 2 2 -S 80% -T ./ zhidao_giga.klm `进行剪枝,",
        "state": "closed",
        "user": "Chen1399",
        "closed_by": "heavengate",
        "created_at": "2019-09-19T06:46:12+00:00",
        "updated_at": "2019-09-20T03:32:54+00:00",
        "closed_at": "2019-09-20T03:32:54+00:00",
        "comments_count": [
            "Chen1399",
            "heavengate",
            "Chen1399",
            "heavengate",
            "Chen1399",
            "heavengate",
            "Chen1399",
            "Chen1399",
            "heavengate",
            "Chen1399"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 368,
        "title": "运行train.py的时候报ValueError: No such parameter错误",
        "body": "你好，我在进行模型训练的时候出现了以下的错误，请问这是什么原因引起的呢？该如何解决呢？谢谢！！！\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.configbatch_size: 256dev_manifest: ../test_manifest/manifest.dev\r\ninit_model_path: ../resource/params.tar.gz\r\nis_local: True\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: ../resource/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_iter_print: 100\r\nnum_passes: 200\r\nnum_proc_data: 16\r\nnum_rnn_layers: 3\r\noutput_model_dir: ../output\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: False\r\ntrain_manifest: ../test_manifest/manifest.train\r\ntrainer_count: 1\r\nuse_gpu: True\r\nuse_gru: False\r\nuse_sortagrad: True\r\nvocab_path: ../resource/vocab.txt\r\n------------------------------------------------\r\nI1014 19:49:58.496965 127202 Util.cpp:166] commandline:  --use_gpu=True --rnn_use_batch=True --log_clipping=True --trainer_count=1\r\n[INFO 2019-10-14 19:50:00,083 layers.py:2716] output for __conv_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-10-14 19:50:00,085 layers.py:3361] output for __batch_norm_0__: c = 32, h = 81, w = 54, size = 139968\r\n[INFO 2019-10-14 19:50:00,086 layers.py:7533] output for __scale_sub_region_0__: c = 32, h = 81, w = 54, size =139968\r\n[INFO 2019-10-14 19:50:00,088 layers.py:2716] output for __conv_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-10-14 19:50:00,089 layers.py:3361] output for __batch_norm_1__: c = 32, h = 41, w = 54, size = 70848\r\n[INFO 2019-10-14 19:50:00,090 layers.py:7533] output for __scale_sub_region_1__: c = 32, h = 41, w = 54, size =70848\r\nI1014 19:50:21.294397 127202 GradientMachine.cpp:94] Initing parameters..\r\nI1014 19:50:25.766219 127202 GradientMachine.cpp:101] Init parameters done.\r\n/usr/lib64/python2.7/site-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n/usr/lib64/python2.7/site-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n/usr/lib64/python2.7/site-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n\r\n------- Time: 1 sec,  Pass: 0, ValidationCost: 2138.80664062\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 133, in <module>\r\n    main()\r\n  File \"train.py\", line 129, in main\r\n    train()\r\n  File \"train.py\", line 120, in train\r\n    test_off=args.test_off)\r\n  File \"/home/rec/local_disk/template/stf/items/deepspeech2/src/model.py\", line 156, in train\r\n    feeding=adapted_feeding_dict)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/trainer.py\", line 214, in train\r\n    gm=self.__gradient_machine__))\r\n  File \"/home/rec/local_disk/template/stf/items/deepspeech2/src/model.py\", line 149, in event_handler\r\n    trainer.save_parameter_to_tar(f)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/trainer.py\", line 134, in save_parameter_to_tar\r\n    self.__parameters__.to_tar(f)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 343, in to_tar\r\n    self.serialize(nm, buf)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 304, in serialize\r\n    param = self.get(name)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 242, in get\r\n    return self.__getitem__(key=parameter_name)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 186, in __getitem__\r\n    return self.__getter_inner(key, api.PARAMETER_VALUE)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 164, in __getter_inner\r\n    each_gradient_machine, key)\r\n  File \"/usr/lib64/python2.7/site-packages/paddle/v2/parameters.py\", line 418, in __get_parameter_in_gradient_machine__\r\n    raise ValueError(\"No such parameter\")\r\nValueError: No such parameter",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "suntingfeng",
        "created_at": "2019-10-14T12:17:36+00:00",
        "updated_at": "2019-10-17T12:46:58+00:00",
        "closed_at": "2019-10-17T12:46:58+00:00",
        "comments_count": [
            "suntingfeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 370,
        "title": "Docker Image for non-gpu version ",
        "body": "The Docker Image mentioned in the ReadMe.md file talks about the image with GPU support (NVIDIA). Is there a docker image for non gpu support (CPU-only)?\r\n\r\nI do not have NVIDIA GPU nevertheless, would like to try out deepspeech, what are my options? ",
        "state": "closed",
        "user": "dhirajsuvarna",
        "closed_by": "zh794390558",
        "created_at": "2019-10-17T12:28:46+00:00",
        "updated_at": "2021-05-12T05:07:07+00:00",
        "closed_at": "2021-05-12T05:07:07+00:00",
        "comments_count": [
            "dhirajsuvarna",
            "ghost",
            "dhirajsuvarna",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 373,
        "title": "请问一下，如何使用已训练模型识别数据",
        "body": "使用脚本下载了\r\n`DeepSpeech/models/lm/zh_giga.no_cna_cmn.prune01244.klm`\r\n请教一下该如何使用，或者在example中哪个例子是使用的方法（通过脚本指定语音文件输出识别内容）？\r\n谢谢",
        "state": "closed",
        "user": "zhengyuelai-ctrl",
        "closed_by": "zh794390558",
        "created_at": "2019-10-28T08:21:20+00:00",
        "updated_at": "2021-05-12T05:02:56+00:00",
        "closed_at": "2021-05-12T05:02:56+00:00",
        "comments_count": [
            "lfchener",
            "tutan123",
            "duan348733684",
            "YanqiangWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 372,
        "title": "如果已训练好一个模型，若有新的资料，如何做训练后续部份呢？",
        "body": "拜托各位大神帮忙，如果在checkpoints下已做好了一个模型AAA.gz，这是经训练如100小时的语音，如果后续有新增新的20小时的训练资料时，请问要如何只针对那新的20小时训练呢？总不可能每次都要从头开始做学习吧？",
        "state": "closed",
        "user": "springminhcm",
        "closed_by": "zh794390558",
        "created_at": "2019-10-28T08:00:49+00:00",
        "updated_at": "2021-05-12T05:03:16+00:00",
        "closed_at": "2021-05-12T05:03:16+00:00",
        "comments_count": [
            "lfchener",
            "springminhcm",
            "jchua127",
            "springminhcm",
            "jchua127",
            "springminhcm",
            "jchua127",
            "sukibean163"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 378,
        "title": "Segmentation fault",
        "body": "各位好，我在WSL(Ubuntu 18.04)上配置了该项目，配置如下：\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython -u infer.py \\\r\n--num_samples=10 \\\r\n--beam_size=300 \\\r\n--num_proc_bsearch=8 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--alpha=2.6 \\\r\n--beta=5.0 \\\r\n--cutoff_prob=0.99 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=False \\\r\n--share_rnn_weights=False \\\r\n--infer_manifest='data/aishell/manifest.test' \\\r\n--mean_std_path='data/librispeech/mean_std.npz' \\\r\n--vocab_path='data/librispeech/vocab.txt' \\\r\n--model_path='data/librispeech/params.tar.gz' \\\r\n--lang_model_path='models/lm/zh_giga.no_cna_cmn.prune01244.klm' \\\r\n--decoding_method='ctc_beam_search' \\\r\n--error_rate_type='cer' \\\r\n--specgram_type='linear'\r\n图中路径有些乱，见谅。。",
        "state": "closed",
        "user": "dgai91",
        "closed_by": "dgai91",
        "created_at": "2019-10-31T03:56:09+00:00",
        "updated_at": "2020-04-21T13:03:19+00:00",
        "closed_at": "2019-11-13T07:40:26+00:00",
        "comments_count": [
            "dgai91",
            "purijs"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 377,
        "title": "BaiduCN1.2k Model download error",
        "body": "{\"code\":\"NoSuchKey\",\"message\":\"The specified key does not exist.\",\"requestId\":\"0b14fa2c-02db-4a35-8bf1-fd25147e2c45\"}\r\n",
        "state": "closed",
        "user": "sevenold",
        "closed_by": "zh794390558",
        "created_at": "2019-10-29T06:29:58+00:00",
        "updated_at": "2021-05-12T05:02:46+00:00",
        "closed_at": "2021-05-12T05:02:46+00:00",
        "comments_count": [
            "onmywei",
            "yeyupiaoling",
            "kuke",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 376,
        "title": "run_train.sh ERROR: unknown command line flag",
        "body": "I am getting the following output on running `sh run_train.sh` in the Docker image. I at least calls `train.py`  when I run it from outside the image.\r\n\r\n```\r\nERROR: unknown command line flag 'augment_conf_path'\r\nERROR: unknown command line flag 'batch_size'\r\nERROR: unknown command line flag 'dev_manifest'\r\nERROR: unknown command line flag 'is_local'\r\nERROR: unknown command line flag 'learning_rate'\r\nERROR: unknown command line flag 'max_duration'\r\nERROR: unknown command line flag 'mean_std_path'\r\nERROR: unknown command line flag 'min_duration'\r\nERROR: unknown command line flag 'num_conv_layers'\r\nERROR: unknown command line flag 'num_epoch'\r\nERROR: unknown command line flag 'num_iter_print'\r\nERROR: unknown command line flag 'num_rnn_layers'\r\nERROR: unknown command line flag 'num_samples'\r\nERROR: unknown command line flag 'output_model_dir'\r\nERROR: unknown command line flag 'rnn_layer_size'\r\nERROR: unknown command line flag 'save_epoch'\r\nERROR: unknown command line flag 'share_rnn_weights'\r\nERROR: unknown command line flag 'shuffle_method'\r\nERROR: unknown command line flag 'specgram_type'\r\nERROR: unknown command line flag 'test_off'\r\nERROR: unknown command line flag 'train_manifest'\r\nERROR: unknown command line flag 'use_gpu'\r\nERROR: unknown command line flag 'use_gru'\r\nERROR: unknown command line flag 'use_sortagrad'\r\nERROR: unknown command line flag 'vocab_path'\r\nFailed in training!\r\n```",
        "state": "closed",
        "user": "neonlight1203",
        "closed_by": "neonlight1203",
        "created_at": "2019-10-29T04:28:15+00:00",
        "updated_at": "2019-10-29T09:11:34+00:00",
        "closed_at": "2019-10-29T09:11:34+00:00",
        "comments_count": [
            "neonlight1203"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 379,
        "title": "swig_decoders==1.1' distribution was not found ",
        "body": "Hi,\r\n\r\nWhile running the setup.sh to install decoders, I got the below error.\r\nPlease help!\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/jay/GIT_HCL/NLP_Project_GIT/arti_branch_voice_recognition/dev_voice_recognition/voice_recognition/asr/venv2/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 900, in require\r\n    needed = self.resolve(parse_requirements(requirements))\r\n  File \"/home/jay/GIT_HCL/NLP_Project_GIT/arti_branch_voice_recognition/dev_voice_recognition/voice_recognition/asr/venv2/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 786, in resolve\r\n    raise DistributionNotFound(req, requirers)\r\npkg_resources.DistributionNotFound: The 'swig_decoders==1.1' distribution was not found and is required by the application\r\nInstall decoders ...\r\nscorer.h:22: Warning 401: Nothing known about base class 'lm::EnumerateVocab'. Ignored.\r\n....................\r\n..................\r\n.......\r\n\r\nopenfst-1.6.3/src/include/fst/vector-fst.h:149:53: warning: ‘dst’ may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n   Weight Final(StateId state) const { return states_[state]->Final(); }\r\n                                                     ^\r\ndecoder_utils.cpp:138:30: note: ‘dst’ was declared here\r\n   fst::StdVectorFst::StateId dst;\r\n                              ^\r\nerror: command 'x86_64-linux-gnu-gcc' failed with exit status 1\r\nInstall all dependencies successfully.",
        "state": "closed",
        "user": "artinegi1607",
        "closed_by": "zh794390558",
        "created_at": "2019-10-31T10:15:38+00:00",
        "updated_at": "2021-05-12T05:06:51+00:00",
        "closed_at": "2021-05-12T05:06:51+00:00",
        "comments_count": [
            "lfchener",
            "changweioy",
            "artinegi1607",
            "inishchith",
            "tuanphan09"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 380,
        "title": "训练中文模型，什么时候进行超参数调整？",
        "body": "训练中文模型，是训练结束之后就要进行超参数调整吗？还看要看情况而定的？\r\n\r\n```\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\r\npython tools/tune.py \\\r\n--alpha_from 1.0 \\\r\n--alpha_to 3.2 \\\r\n--num_alphas 45 \\\r\n--beta_from 0.1 \\\r\n--beta_to 0.45 \\\r\n--num_betas 8\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-01T08:11:54+00:00",
        "updated_at": "2019-11-28T02:48:03+00:00",
        "closed_at": "2019-11-28T02:48:03+00:00",
        "comments_count": [
            "xueshang-liulp",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 381,
        "title": "manifest.noise 这些数据是要自己生成的吗？还是训练过程中自动生成的？",
        "body": "我的训练数据太干净了，我想加点噪声，在配置文件中，manifest.noise 这些文件是要根据噪声音频生成的吗？还是说 train.py 代码在训练过程中自动帮我们生成？\r\n```\r\n    {\r\n        \"type\": \"noise\",\r\n        \"params\": {\"min_snr_dB\": 40,\r\n                   \"max_snr_dB\": 50,\r\n                   \"noise_manifest_path\": \"datasets/manifest.noise\"},\r\n        \"prob\": 0.6\r\n    },\r\n    {\r\n        \"type\": \"impulse\",\r\n        \"params\": {\"impulse_manifest_path\": \"datasets/manifest.impulse\"},\r\n        \"prob\": 0.5\r\n    },\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-01T08:47:08+00:00",
        "updated_at": "2020-02-25T17:22:00+00:00",
        "closed_at": "2019-12-10T07:46:38+00:00",
        "comments_count": [
            "lfchener",
            "yeyupiaoling",
            "yzcm1232"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 383,
        "title": "在计算均值 num_samples 多大合适？",
        "body": "我的训练数据大概有 50 万条，在计算均值 num_samples 多大合适？\r\n```\r\npython tools/compute_mean_std.py \\\r\n--num_samples 2000 \\\r\n--specgram_type linear \\\r\n--manifest_paths data/librispeech/manifest.train \\\r\n--output_path data/librispeech/mean_std.npz\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-02T03:09:05+00:00",
        "updated_at": "2019-11-28T02:48:27+00:00",
        "closed_at": "2019-11-28T02:48:27+00:00",
        "comments_count": [
            "kuke",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 384,
        "title": "在每一次训练估计是一轮之后就显存不足，batch size设置小也没有用",
        "body": "我的训练参数是：\r\n```\r\nexport FLAGS_sync_nccl_allreduce=0\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython -u train.py \\\r\n--batch_size=8 \\\r\n--num_epoch=50 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--num_iter_print=100 \\\r\n--save_epoch=2 \\\r\n--num_samples=120000 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=27.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=False \\\r\n--train_manifest='./dataset/manifest.train' \\\r\n--dev_manifest='./dataset/manifest.dev' \\\r\n--mean_std_path='./dataset/mean_std.npz' \\\r\n--vocab_path='./dataset/zh_vocab.txt' \\\r\n--output_model_dir='./models/checkpoints/' \\\r\n--augment_conf_path='./conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped' \\\r\n```\r\n\r\n我从batch size从原来的32设置到8还是报原来的错误，前面3万多的batch训练时正常的。\r\n```\r\n\r\n\r\nTrain [2019-11-06 04:35:06.863259] epoch: 0, batch: 35100, train loss: 13.707798\r\n\r\nTrain [2019-11-06 04:41:04.340795] epoch: 0, batch: 35200, train loss: 17.407038\r\n\r\nTrain [2019-11-06 04:47:09.349953] epoch: 0, batch: 35300, train loss: 12.541659\r\n\r\nTrain [2019-11-06 04:53:21.462351] epoch: 0, batch: 35400, train loss: 20.683529\r\n\r\nTrain [2019-11-06 04:59:41.506114] epoch: 0, batch: 35500, train loss: 21.854664\r\n\r\nTrain [2019-11-06 05:06:09.245898] epoch: 0, batch: 35600, train loss: 11.866036\r\n\r\nTrain [2019-11-06 05:12:48.686871] epoch: 0, batch: 35700, train loss: 17.497536\r\n\r\nTrain [2019-11-06 05:19:38.417454] epoch: 0, batch: 35800, train loss: 13.972732\r\n\r\n..........................................\r\n\r\nOut of memory error on GPU 0. Cannot allocate 68.156494MB memory on GPU 0, available memory is only 10.187500MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.92 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-06T06:13:58+00:00",
        "updated_at": "2020-12-09T03:41:38+00:00",
        "closed_at": "2019-12-10T07:46:06+00:00",
        "comments_count": [
            "zhaoyuchen2018",
            "yeyupiaoling",
            "yeyupiaoling",
            "yeyupiaoling",
            "zhaoyuchen2018",
            "yeyupiaoling",
            "zhaoyuchen2018",
            "yeyupiaoling",
            "zhaoyuchen2018",
            "yeyupiaoling",
            "yeyupiaoling",
            "NextGuido",
            "yeyupiaoling",
            "NextGuido"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 382,
        "title": "使用官方提供的模型作为预训练模型训练自己数据集报错",
        "body": "我使用如下的官方中文训练模型作为预训练模型训练自己的数据集，报错，\r\n![image](https://user-images.githubusercontent.com/26297768/68064516-924cce80-fd57-11e9-8922-9647577b30cb.png)\r\n\r\n错误信息如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 118, in <module>\r\n    main()\r\n  File \"train.py\", line 114, in main\r\n    train()\r\n  File \"train.py\", line 109, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 307, in train\r\n    pre_epoch = self.init_from_pretrained_model(exe, train_program)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 784, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 668, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 727, in load_vars\r\n    format(orig_shape, each_var.name, new_shape))\r\nRuntimeError: Shape not matching: the Program requires a parameter with a shape of ((1312L, 3072L)), while the loaded parameter (namely [ layer_2_forward_fc_weight ]) has a shape of  ((1312, 6144)).\r\nFailed in training!\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-02T02:01:09+00:00",
        "updated_at": "2020-05-13T08:27:08+00:00",
        "closed_at": "2020-02-25T03:55:40+00:00",
        "comments_count": [
            "lfchener",
            "yeyupiaoling",
            "yeyupiaoling",
            "xueshang-liulp",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "xueshang-liulp",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "yeyupiaoling",
            "xueshang-liulp",
            "yeyupiaoling",
            "jchua127",
            "yeyupiaoling",
            "jchua127",
            "AshishKarel",
            "yeyupiaoling",
            "AshishKarel",
            "yeyupiaoling",
            "yeyupiaoling",
            "AshishKarel",
            "yeyupiaoling",
            "gaozheyuan",
            "nemo9903",
            "chadlwm",
            "gezimonkey",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 385,
        "title": "使用官方的中文语音识别模型，不能正确识别语音",
        "body": "使用官方的中文语音识别模型，不能正确识别语音。输出都是空值\r\n\r\n```\r\nPYTHONPATH=.:$PYTHONPATH python -u deploy/server.py \\\r\n--host_ip=\"192.168.1.130\" \\\r\n--host_port=10086 \\\r\n--beam_size=500 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--alpha=2.5 \\\r\n--beta=0.3 \\\r\n--cutoff_prob=1.0 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--share_rnn_weights=True \\\r\n--speech_save_dir=\"./audios_cache\" \\\r\n--warmup_manifest=\"./dataset/manifest.test\" \\\r\n--mean_std_path=\"./models/baidu_cn1.2k_model_fluid/mean_std.npz\" \\\r\n--vocab_path=\"./models/baidu_cn1.2k_model_fluid/vocab.txt\" \\\r\n--model_path=\"./models/baidu_cn1.2k_model_fluid/\" \\\r\n--lang_model_path=\"./models/zhidao_giga.klm\" \\\r\n--decoding_method=\"ctc_beam_search\" \\\r\n--specgram_type=\"linear\"\r\n\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-06T11:55:22+00:00",
        "updated_at": "2020-09-09T09:43:17+00:00",
        "closed_at": "2019-12-10T08:23:45+00:00",
        "comments_count": [
            "yeyupiaoling",
            "jasonlbx13",
            "yeyupiaoling",
            "jasonlbx13",
            "yeyupiaoling",
            "ghost",
            "ghost",
            "yeyupiaoling",
            "ghost",
            "yeyupiaoling",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 390,
        "title": "Getting certainty along with transcription?",
        "body": "Is there any way to get the certainty of a transcription? The examples in ./deploy and ./examples show how to transcribe audio, but not how to get the certainty of that transcription.",
        "state": "closed",
        "user": "chrisspen",
        "closed_by": "zh794390558",
        "created_at": "2019-11-23T02:21:53+00:00",
        "updated_at": "2021-05-12T05:07:14+00:00",
        "closed_at": "2021-05-12T05:07:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 387,
        "title": "PaddleCheckError:not allowed to load partial data via load_combine_op",
        "body": "I am using docker to test my one audio, i change a little code from demo_server.py and found below error , is it due to paddle version ?\r\ni install paddle version: paddlepaddle-gpu= 1.6.1.post97\r\nPaddleCheckError: You are not allowed to load partial data via load_combine_op, use load_op instead. at [/paddle/paddle/fluid/operators/load_combine_op.h:105]",
        "state": "closed",
        "user": "lamudazh",
        "closed_by": "zh794390558",
        "created_at": "2019-11-12T13:58:18+00:00",
        "updated_at": "2021-05-12T05:07:21+00:00",
        "closed_at": "2021-05-12T05:07:21+00:00",
        "comments_count": [
            "lfchener",
            "gnaytx",
            "lfchener",
            "bigcash"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 386,
        "title": "AttributeError: 'module' object has no attribute 'RNNCell'",
        "body": "I user docker to run based on the guide, but when it failed when running examples, could you help ?\r\n\r\n/DeepSpeech/examples/tiny {develop} sh run_train.sh\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 9, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"/DeepSpeech/model_utils/model.py\", line 23, in <module>\r\n    from model_utils.network import deep_speech_v2_network\r\n  File \"/DeepSpeech/model_utils/network.py\", line 62, in <module>\r\n    class RNNCell(fluid.layers.RNNCell):\r\nAttributeError: 'module' object has no attribute 'RNNCell'\r\n",
        "state": "closed",
        "user": "lamudazh",
        "closed_by": "zh794390558",
        "created_at": "2019-11-11T04:47:40+00:00",
        "updated_at": "2021-05-12T05:05:30+00:00",
        "closed_at": "2021-05-12T05:05:30+00:00",
        "comments_count": [
            "lamudazh",
            "chadlwm",
            "lfchener",
            "jerrylususu",
            "ghost",
            "plseal",
            "vuvincent",
            "danielkope",
            "bigpo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 388,
        "title": "baidu_cn1.2K的模型的params.pdparams如何直接用来识别？",
        "body": "从官网下载下来的BaiduCN1.2K模型中的params.pdparams该如何使用？\r\ninfer.py中的model_path要求是params.tar.gz这种格式的，请问这个params.pdparams该如何使用呀，谢谢。\r\n\r\n![image](https://user-images.githubusercontent.com/26765635/69219622-2b7c4180-0bae-11ea-84bb-c792ef21d1f0.png)\r\n",
        "state": "closed",
        "user": "jchua127",
        "closed_by": "jchua127",
        "created_at": "2019-11-20T07:56:14+00:00",
        "updated_at": "2019-11-21T08:53:38+00:00",
        "closed_at": "2019-11-21T08:53:38+00:00",
        "comments_count": [
            "lfchener",
            "jchua127",
            "jchua127",
            "gnaytx",
            "jchua127",
            "jchua127"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 392,
        "title": "官方 baidu_cn1.2k_model_fluid 的音频参数是什么？",
        "body": "请问官方的baidu_cn1.2k_model_fluid 的下面的音频参数是什么呢，我使用`deploy`的程序也不能正确识别我的语音。\r\n```\r\nparams = f.getparams()\r\nnchannels, sampwidth, framerate, nframes = params[:4]\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-11-29T04:04:52+00:00",
        "updated_at": "2020-01-08T06:20:40+00:00",
        "closed_at": "2020-01-08T06:20:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 396,
        "title": "正常运行train.py 但是运行test.py和infer.py时使用gpu情况下报错",
        "body": "不使用gpu情况下 可正常使用，使用gpu时的报错信息如下：\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbatch_size: 128\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/librispeech/mean_std.npz\r\nmodel_path: checkpoints/libri/epoch_3\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\ntest_manifest: data/librispeech/manifest.test-clean\r\nuse_gpu: True\r\nuse_gru: False\r\nvocab_path: models/librispeech/vocab.txt\r\n------------------------------------------------\r\n[INFO 2019-12-07 11:40:57,547 model.py:475] begin to initialize the external scorer for decoding\r\n[INFO 2019-12-07 11:41:08,305 model.py:485] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2019-12-07 11:41:08,522 model.py:486] end initializing scorer\r\n[INFO 2019-12-07 11:41:08,522 test.py:109] start evaluation ...\r\nW1207 11:41:13.783799  9190 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1207 11:41:13.788204  9190 device_context.cc:243] device: 0, cuDNN Version: 7.5.\r\nfinish initing model from pretrained params from checkpoints/libri/epoch_3\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:774: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"/data/DeepSpeech/test.py\", line 149, in <module>\r\n    main()\r\n  File \"/data/DeepSpeech/test.py\", line 145, in main\r\n    evaluate()\r\n  File \"/data/DeepSpeech/test.py\", line 113, in evaluate\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/data/DeepSpeech/model_utils/model.py\", line 424, in infer_batch_probs\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 770, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 817, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 894, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\r\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n8   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2459, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 2803, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"/data/DeepSpeech/model_utils/network.py\", line 47, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/data/DeepSpeech/model_utils/network.py\", line 299, in conv_group\r\n    name='layer_0', )\r\n  File \"/data/DeepSpeech/model_utils/network.py\", line 408, in deep_speech_v2_network\r\n    masks=masks)\r\n  File \"/data/DeepSpeech/model_utils/model.py\", line 145, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/data/DeepSpeech/model_utils/model.py\", line 403, in infer_batch_probs\r\n    feeder, log_probs, _ = self.create_network(is_infer=True)\r\n  File \"/data/DeepSpeech/test.py\", line 113, in evaluate\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/data/DeepSpeech/test.py\", line 145, in main\r\n    evaluate()\r\n  File \"/data/DeepSpeech/test.py\", line 149, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPaddleCheckError: CUDNN_STATUS_EXECUTION_FAILED at [/paddle/paddle/fluid/operators/conv_cudnn_op.cu:288]\r\n  [operator < conv2d > error]\r\n\r\nProcess finished with exit code 1\r\n\r\n此外，请问为什么train.py可以正常使用gpu，test和infer就会报错误信息，如果train时也报错，那么基本原因就是cudnn版本问题，现在困惑的是train是正常的，麻烦告知下原因，谢谢",
        "state": "closed",
        "user": "GC-Tom",
        "closed_by": "zh794390558",
        "created_at": "2019-12-07T11:48:39+00:00",
        "updated_at": "2021-05-12T05:06:32+00:00",
        "closed_at": "2021-05-12T05:06:32+00:00",
        "comments_count": [
            "mhilmiasyrofi",
            "hawkcoder"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 398,
        "title": "在docker-GPU环境下训练的模型，在CPU自己安装的环境下如何进行识别？",
        "body": "我在docker GPU环境下训练好了模型（params.pass-49.tar.gz等49个文件），可以正常进行infer和test；在CPU环境下自己安装完成了DeepSpeech和Paddle，当我把训练好的模型拷贝到CPU环境下，进行infer识别时，报错如下：\r\nPaddleCheckError: OP(LoadCombine) fail to open file checkpoints/1120/params.pass-49.tar.gz/params.pdparams, please check whether the model file is complete or damaged. at [/paddle/paddle/fluid/operators/load_combine_op.h:46]\r\n  [operator < load_combine > error]\r\n\r\n麻烦各位帮忙看下是什么原因？",
        "state": "closed",
        "user": "jchua127",
        "closed_by": "jchua127",
        "created_at": "2019-12-10T11:25:42+00:00",
        "updated_at": "2019-12-17T09:58:11+00:00",
        "closed_at": "2019-12-17T09:57:58+00:00",
        "comments_count": [
            "jchua127"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 397,
        "title": "kenlm支持加载预训练语言模型进行语言模型的训练吗？",
        "body": "",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "zh794390558",
        "created_at": "2019-12-10T11:13:05+00:00",
        "updated_at": "2021-05-12T05:05:43+00:00",
        "closed_at": "2021-05-12T05:05:43+00:00",
        "comments_count": [
            "kuke",
            "suntingfeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 399,
        "title": "Unable to normalize segment",
        "body": "This error appears quite often during my training.\r\nAny idea on how to solve it? maybe doing some preprocessing on the audio?\r\n\r\n```\r\n[WARNING 2019-12-18 17:38:59,189 reader.py:487] Your reader has raised an exception!\r\nException in thread Thread-120:\r\nTraceback (most recent call last):\r\n  File \"/home/stella/.conda/envs/paddle/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/home/stella/.conda/envs/paddle/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/stella/.conda/envs/paddle/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 488, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/stella/.conda/envs/paddle/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 468, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/data.py\", line 200, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/data.py\", line 279, in reader\r\n    instance[\"text\"]),\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/data.py\", line 121, in process_utterance\r\n    speech_segment, self._keep_transcription_text)\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/featurizer/speech_featurizer.py\", line 76, in featurize\r\n    audio_feature = self._audio_featurizer.featurize(speech_segment)\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/featurizer/audio_featurizer.py\", line 86, in featurize\r\n    audio_segment.normalize(target_db=self._target_dB)\r\n  File \"/mnt/Data/stella/paddle/DeepSpeech/data_utils/audio.py\", line 345, in normalize\r\n    (target_db, max_gain_db))\r\nValueError: Unable to normalize segment to -20.000000 dB because the the probable gain have exceeds max_gain_db (300.000000 dB)\r\n```\r\n\r\nThanks!",
        "state": "closed",
        "user": "shoegazerstella",
        "closed_by": "shoegazerstella",
        "created_at": "2019-12-18T16:43:48+00:00",
        "updated_at": "2019-12-23T11:26:18+00:00",
        "closed_at": "2019-12-23T11:26:18+00:00",
        "comments_count": [
            "lfchener",
            "shoegazerstella",
            "shoegazerstella",
            "lfchener",
            "shoegazerstella",
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 400,
        "title": "加载预训练好的中文声学模型训练自己的模型，mean_std.npz该如何更新？",
        "body": "你好，加载预训练好的中文声学模型训练自己的模型，mean_std.npz该如何更新？因为提供的mean_std.npz包含的是你们预训练数据集样本特征的均值和标准差，现在我想包含我自己样本数据和你们数据的特征的均值和标准差。这个我该如何做呢？",
        "state": "closed",
        "user": "suntingfeng",
        "closed_by": "zh794390558",
        "created_at": "2019-12-19T11:14:44+00:00",
        "updated_at": "2021-05-12T05:06:13+00:00",
        "closed_at": "2021-05-12T05:06:13+00:00",
        "comments_count": [
            "suntingfeng",
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 401,
        "title": "fluid版本可以兼容V2版本的训练结果吗？",
        "body": "之前在V2版本上已经训练好的模型，模型后缀params.pass-49.tar.gz，但是新版本的fluid版本要求的模型是params.pdparams格式，fluid版本能有办法支持V2版本的模型吗？",
        "state": "closed",
        "user": "jchua127",
        "closed_by": "jchua127",
        "created_at": "2019-12-20T02:13:17+00:00",
        "updated_at": "2019-12-25T02:30:47+00:00",
        "closed_at": "2019-12-25T02:30:26+00:00",
        "comments_count": [
            "jchua127"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 404,
        "title": "按照readme 一步一步执行的， infer 时报错。",
        "body": "@lfchener 我看报错这行代码是您最近添加的，我是pip安装的环境， 并按照readme 一步步执行的，但执行到infer时报错，是readme过时了吗？谢谢。\r\nTraceback (most recent call last):\r\n  File \"/home/shenxz/.IdeaIC2019.2/config/plugins/python-ce/helpers/pydev/pydevd.py\", line 1415, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/home/shenxz/code/DeepSpeech/infer.py\", line 152, in <module>\r\n    main()\r\n  File \"/home/shenxz/code/DeepSpeech/infer.py\", line 148, in main\r\n    infer()\r\n  File \"/home/shenxz/code/DeepSpeech/infer.py\", line 94, in infer\r\n    infer_data = next(batch_reader())\r\n  File \"/home/shenxz/code/DeepSpeech/data_utils/data.py\", line 203, in batch_reader\r\n    yield self._padding_batch(batch, padding_to, flatten)\r\n  File \"/home/shenxz/code/DeepSpeech/data_utils/data.py\", line 333, in _padding_batch\r\n    texts = np.expand_dims(np.array(texts).astype('int32'), axis=-1)\r\nValueError: invalid literal for int() with base 10: 'he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fattened sauce'\r\n",
        "state": "closed",
        "user": "xinzheshen",
        "closed_by": "zh794390558",
        "created_at": "2019-12-25T09:12:29+00:00",
        "updated_at": "2021-05-12T05:05:59+00:00",
        "closed_at": "2021-05-12T05:05:59+00:00",
        "comments_count": [
            "jchua127",
            "WilliamEt",
            "xinzheshen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 405,
        "title": "按照docker一步一步装好，下载完data，sh run_train.sh就出错",
        "body": "在example/tiny目录下\r\nsh run_data.sh正常下载好librispeech的test-clean和dev-clean\r\n然后 sh run_train.sh就报错\r\n报错信息如下：\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 9, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"/DeepSpeech/model_utils/model.py\", line 23, in <module>\r\n    from model_utils.network import deep_speech_v2_network\r\n  File \"/DeepSpeech/model_utils/network.py\", line 62, in <module>\r\n    class RNNCell(fluid.layers.RNNCell):\r\nAttributeError: 'module' object has no attribute 'RNNCell'\r\nFailed in training!\r\n请问这是什么原因呢",
        "state": "closed",
        "user": "WilliamEt",
        "closed_by": "WilliamEt",
        "created_at": "2019-12-27T11:34:06+00:00",
        "updated_at": "2021-01-30T15:54:08+00:00",
        "closed_at": "2019-12-28T06:52:49+00:00",
        "comments_count": [
            "1003657663"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 406,
        "title": "使用多个CPU训练报错",
        "body": "为了可以使用多个CPU进行训练，因为我电脑有CPU有6核，我执行了\r\n```\r\nexport CPU_NUM=6\r\n```\r\n\r\n在docker训练，在执行训练时就报错了，\r\n```\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: ./conf/augmentation.config\r\nbatch_size: 32\r\ndev_manifest: ./dataset/manifest.dev\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: ./dataset/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 50\r\nnum_iter_print: 100\r\nnum_rnn_layers: 3\r\nnum_samples: 120000\r\noutput_model_dir: ./models/checkpoints/\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: ./dataset/manifest.train\r\nuse_gpu: 0\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: ./dataset/zh_vocab.txt\r\n------------------------------------------------\r\nI1228 04:08:01.524451   123 parallel_executor.cc:421] The number of CPUPlace, which is used in ParallelExecutor, is 6. And the Program will be copied 6 copies\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:774: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 118, in <module>\r\n    main()\r\n  File \"train.py\", line 114, in main\r\n    train()\r\n  File \"train.py\", line 109, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 332, in train\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 770, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 819, in _run_impl\r\n    program._compile(scope, self.place)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/compiler.py\", line 392, in _compile\r\n    places=self._places)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/compiler.py\", line 355, in _compile_data_parallel\r\n    self._exec_strategy, self._build_strategy, self._graph)\r\npaddle.fluid.core_avx.EnforceNotMet: 0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::memory::detail::AlignedMalloc(unsigned long)\r\n3   paddle::memory::detail::CPUAllocator::Alloc(unsigned long*, unsigned long)\r\n4   paddle::memory::detail::BuddyAllocator::RefillPool(unsigned long)\r\n5   paddle::memory::detail::BuddyAllocator::Alloc(unsigned long)\r\n6   void* paddle::memory::legacy::Alloc<paddle::platform::CPUPlace>(paddle::platform::CPUPlace const&, unsigned long)\r\n7   paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long)\r\n8   paddle::memory::allocation::AllocatorFacade::Alloc(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\r\n9   paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\r\n10  paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\r\n11  paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long)\r\n12  paddle::framework::ParallelExecutor::BCastParamsToDevices(std::vector<std::string, std::allocator<std::string> > const&, int) const\r\n13  paddle::framework::ParallelExecutor::ParallelExecutor(std::vector<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::allocator<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::string const&, paddle::framework::Scope*, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> > const&, paddle::framework::details::ExecutionStrategy const&, paddle::framework::details::BuildStrategy const&, paddle::framework::ir::Graph*)\r\nPaddleCheckError: Expected posix_memalign(&p, alignment, size) == 0, but received posix_memalign(&p, alignment, size):12 != 0:0.\r\nAlloc 522324864 error! at [/paddle/paddle/fluid/memory/detail/system_allocator.cc:59]\r\n\r\nFailed in training!\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2019-12-28T04:27:18+00:00",
        "updated_at": "2020-01-08T06:20:06+00:00",
        "closed_at": "2020-01-08T06:20:06+00:00",
        "comments_count": [
            "zhhsplendid",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 407,
        "title": "Error: OP(LoadCombine) fail to open file models/BaiduCN1.2k/baidu_cn1.2k_model_fluid.tar.gz/params.pdparams",
        "body": "我的目标是：使用baidu_cn1.2k的模型实现对语音文件转文字的调用测试，centos7，cpu环境，没有使用docker而是直接安装的。启动server时遇到以下错误：\r\n\r\n(baidu27) [lb@centos702 DeepSpeech]$ python deploy/demo_server.py --host_ip 172.16.1.190 --host_port 10010 --warmup_manifest data/aishell/manifest.test --mean_std_path models/BaiduCN1.2k/mean_std.npz --vocab_path models/BaiduCN1.2k/vocab.txt --model_path models/BaiduCN1.2k/baidu_cn1.2k_model_fluid.tar.gz --lang_model_path models/lm/zh_giga.no_cna_cmn.prune01244.klm --use_gpu False\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: 172.16.1.190\r\nhost_port: 10010\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/BaiduCN1.2k/mean_std.npz\r\nmodel_path: models/BaiduCN1.2k/baidu_cn1.2k_model_fluid.tar.gz\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: 0\r\nuse_gru: False\r\nvocab_path: models/BaiduCN1.2k/vocab.txt\r\nwarmup_manifest: data/aishell/manifest.test\r\n------------------------------------------------\r\n2019-12-31 10:16:49,765-INFO: begin to initialize the external scorer for decoding\r\n2019-12-31 10:16:56,318-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2019-12-31 10:16:56,318-INFO: end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'./dataset/aishell/data_aishell/wav/test/S0913/BAC009S0913W0464.wav')\r\n/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 238, in <module>\r\n    main()\r\n  File \"deploy/demo_server.py\", line 234, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 219, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 136, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/lingbao/work/DeepSpeech/deploy/../model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/home/lingbao/work/DeepSpeech/deploy/../model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 726, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n8   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 725, in load_vars\r\n    attrs={'file_path': os.path.join(load_dirname, filename)})\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/home/lingbao/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/home/lingbao/work/DeepSpeech/deploy/../model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/lingbao/work/DeepSpeech/deploy/../model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"deploy/demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"deploy/demo_server.py\", line 136, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 219, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 234, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 238, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: OP(LoadCombine) fail to open file models/BaiduCN1.2k/baidu_cn1.2k_model_fluid.tar.gz/params.pdparams, please check whether the model file is complete or damaged. at (/paddle/paddle/fluid/operators/load_combine_op.h:46)\r\n  [operator < load_combine > error]\r\n\r\n启动任务时报错，看提示是读取tar.gz中的模型文件出错，但是我是从github的readme中下载的模型文件，多次下载的字节数也相同的，应该没错了呀。另外，centos7上也安装了pkg-config, flac, ogg, vorbis, boost 和 swig。\r\n求助，这是我哪里出错了吗？",
        "state": "closed",
        "user": "bigcash",
        "closed_by": "bigcash",
        "created_at": "2019-12-31T03:27:09+00:00",
        "updated_at": "2020-01-03T03:42:32+00:00",
        "closed_at": "2020-01-03T03:42:31+00:00",
        "comments_count": [
            "lfchener",
            "bigcash",
            "lfchener",
            "bigcash"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 408,
        "title": "Error: You are not allowed to load partial data via load_combine_op, use load_op instead",
        "body": "λ 8aa2aa3cf875 /DeepSpeech/examples/tiny ./run_infer_golden.sh\r\nDownload language model ...\r\n./zh_giga.no_cna_cmn.prune01244.klm already exists, download skipped.\r\nDownload Aishell model ...\r\n./aishell_model_fluid.tar.gz already exists, download skipped.\r\nmean_std.npz\r\nREADME.md\r\nvocab.txt\r\nparams.pdparams\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/aishell/mean_std.npz\r\nmodel_path: models/aishell\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\nuse_gpu: 0\r\nuse_gru: 0\r\nvocab_path: models/aishell/vocab.txt\r\n------------------------------------------------\r\n2020-01-03 01:31:14,458-INFO: begin to initialize the external scorer for decoding\r\n2020-01-03 01:31:14,612-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-01-03 01:31:14,612-INFO: end initializing scorer\r\n2020-01-03 01:31:14,613-INFO: start inference ...\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 726, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, paddle::platform::Place const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const\r\n3   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n9   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 725, in load_vars\r\n    attrs={'file_path': os.path.join(load_dirname, filename)})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/DeepSpeech/model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: You are not allowed to load partial data via load_combine_op, use load_op instead. at (/paddle/paddle/fluid/operators/load_combine_op.h:105)\r\n  [operator < load_combine > error]\r\nFailed in inference!\r\n\r\nHow to solve this problem?thanks.",
        "state": "closed",
        "user": "wueching",
        "closed_by": "zh794390558",
        "created_at": "2020-01-03T01:44:45+00:00",
        "updated_at": "2021-05-12T05:06:23+00:00",
        "closed_at": "2021-05-12T05:06:23+00:00",
        "comments_count": [
            "lfchener",
            "wueching",
            "wueching",
            "wueching",
            "bigcash",
            "wueching",
            "wueching",
            "wueching",
            "bigcash",
            "duan348733684"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 409,
        "title": "Failed to find dynamic library: /usr/local/lib/python2.7/dist-packages/paddle/libs/libwarpctc.so",
        "body": "wueching@ubuntu:~/research/ai/DeepSpeech/examples/tiny$ ./run_train.sh-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 4\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 20\r\nnum_iter_print: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 64\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\nuse_gpu: 0\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nI0103 11:00:11.385960 15533 parallel_executor.cc:421] The number of CPUPlace, which is used in ParallelExecutor, is 4. And the Program will be copied 4 copies\r\nW0103 11:00:12.639942 15533 fuse_all_reduce_op_pass.cc:72] Find all_reduce operators: 29. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 29.\r\nI0103 11:00:12.644691 15533 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0103 11:00:12.784705 15533 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0103 11:00:12.845278 15533 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\r\nW0103 11:00:16.228854 15565 dynamic_loader.cc:151] Failed to find dynamic library: /usr/local/lib/python2.7/dist-packages/paddle/libs/libwarpctc.so (dlopen: cannot load any more object with static TLS)\r\nW0103 11:00:16.230798 15565 dynamic_loader.cc:120] Can not find library: libwarpctc.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/home/wueching/research/ai/DeepSpeech/model_utils/model.py\", line 337, in train\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 834, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 674, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::platform::dynload::GetWarpCTCDsoHandle()\r\n3   void std::__once_call_impl<std::_Bind_simple<decltype (get_warpctc_version({parm#1}...)) paddle::platform::dynload::DynLoad__get_warpctc_version::operator()<>()::{lambda()#1} ()> >()\r\n4   paddle::operators::WarpCTCFunctor<paddle::platform::CPUDeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*)\r\n5   paddle::operators::WarpCTCKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CPUDeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n8   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::details::ComputationOpHandle::RunImpl()\r\n11  paddle::framework::details::OpHandleBase::Run(bool)\r\n12  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n13  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n14  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n15  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n16  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 7557, in warpctc\r\n    'norm_by_times': norm_by_times,\r\n  File \"/home/wueching/research/ai/DeepSpeech/model_utils/network.py\", line 446, in deep_speech_v2_network\r\n    input=fc, label=text_data, blank=dict_size, norm_by_times=True)\r\n  File \"/home/wueching/research/ai/DeepSpeech/model_utils/model.py\", line 145, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/home/wueching/research/ai/DeepSpeech/model_utils/model.py\", line 281, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Failed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at (/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177)\r\n  [operator < warpctc > error]\r\nFailed in training!\r\n\r\nHow to fix this issue,thanks a lot.",
        "state": "closed",
        "user": "wueching",
        "closed_by": "zh794390558",
        "created_at": "2020-01-03T19:03:21+00:00",
        "updated_at": "2021-05-12T05:06:42+00:00",
        "closed_at": "2021-05-12T05:06:42+00:00",
        "comments_count": [
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 410,
        "title": "docker中paddlepaddle版本过低，无法运行",
        "body": "docker中paddlepaddle版本过低，无法运行，也无法下载软件包，无法联网，应该如何解决呢？",
        "state": "closed",
        "user": "wics1224",
        "closed_by": "zh794390558",
        "created_at": "2020-01-06T05:55:51+00:00",
        "updated_at": "2021-05-12T05:05:11+00:00",
        "closed_at": "2021-05-12T05:05:11+00:00",
        "comments_count": [
            "Cabchinoe",
            "WilliamEt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 412,
        "title": "模型部署后，对长语音是否支持？",
        "body": "您好，感谢开源！\r\n我部署启动了deploy/demo_server.py，测试大概40分钟的语音，wav文件8000rate的有38M的时候，报内存溢出错误：Out of memory error on GPU 0.  我使用的是2080Ti的单卡进行测试的，显存11019MiB，是不是这种长语音需要对音频进行切割，一般怎样切割可以使最终结果更加准确，是固定时长切割（如按每隔10s切割）还是按录音中没有语音信号时切割的？\r\n我也使用过百度云中提供的api进行语音转文字，是将40分钟录音文件直接提交的，是不是在服务端先进行了语音分割，然后再对所有结果合并，最后给出结果的？\r\n多谢解惑！！\r\n\r\nserver端报错如下（使用BaiduCN1.2k模型）：\r\nReceived utterance[length=40108716] from 172.16.1.18, saved to demo_cache/20200109031539_172.16.1.18.wav.\r\nfinish initing model from pretrained params from models/BaiduCN1.2k/\r\nW0109 11:16:28.406390 11887 operator.cc:179] mul raises an exception paddle::memory::allocation::BadAlloc, \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   paddle::memory::detail::GPUAllocator::Alloc(unsigned long*, unsigned long)\r\n1   paddle::memory::detail::BuddyAllocator::RefillPool(unsigned long)\r\n2   paddle::memory::detail::BuddyAllocator::Alloc(unsigned long)\r\n3   void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long)\r\n4   paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long)\r\n5   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n6   paddle::memory::allocation::RetryAllocator::AllocateImpl(unsigned long)\r\n7   paddle::memory::allocation::AllocatorFacade::Alloc(paddle::platform::Place const&, unsigned long)\r\n8   paddle::memory::allocation::AllocatorFacade::AllocShared(paddle::platform::Place const&, unsigned long)\r\n9   paddle::memory::AllocShared(paddle::platform::Place const&, unsigned long)\r\n10  paddle::framework::Tensor::mutable_data(paddle::platform::Place, paddle::framework::proto::VarType_Type, unsigned long)\r\n11  paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n12  std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n13  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n14  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n15  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n16  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n17  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\n\r\n\r\nOut of memory error on GPU 0. Cannot allocate 1.912537GB memory on GPU 0, available memory is only 381.125000MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.92 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n at (/paddle/paddle/fluid/memory/detail/system_allocator.cc:151)\r\n----------------------------------------\r\nException happened during processing of request from ('172.16.1.18', 55944)\r\nTraceback (most recent call last):\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/SocketServer.py\", line 293, in _handle_request_noblock\r\n    self.process_request(request, client_address)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/SocketServer.py\", line 321, in process_request\r\n    self.finish_request(request, client_address)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/SocketServer.py\", line 334, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/SocketServer.py\", line 655, in __init__\r\n    self.handle()\r\n  File \"deploy/demo_server.py\", line 101, in handle\r\n    transcript = self.server.audio_process_handler(filename)\r\n  File \"deploy/demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/lingbao/work/text/DeepSpeech/deploy/../model_utils/model.py\", line 424, in infer_batch_probs\r\n    return_numpy=False)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/lingbao/soft/anaconda3/envs/baidu27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\nRuntimeError: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   paddle::memory::detail::GPUAllocator::Alloc(unsigned long*, unsigned long)\r\n1   paddle::memory::detail::BuddyAllocator::RefillPool(unsigned long)\r\n2   paddle::memory::detail::BuddyAllocator::Alloc(unsigned long)\r\n3   void* paddle::memory::legacy::Alloc<paddle::platform::CUDAPlace>(paddle::platform::CUDAPlace const&, unsigned long)\r\n4   paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long)\r\n5   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n6   paddle::memory::allocation::RetryAllocator::AllocateImpl(unsigned long)\r\n7   paddle::memory::allocation::AllocatorFacade::Alloc(paddle::platform::Place const&, unsigned long)\r\n8   paddle::memory::allocation::AllocatorFacade::AllocShared(paddle::platform::Place const&, unsigned long)\r\n9   paddle::memory::AllocShared(paddle::platform::Place const&, unsigned long)\r\n10  paddle::framework::Tensor::mutable_data(paddle::platform::Place, paddle::framework::proto::VarType_Type, unsigned long)\r\n11  paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n12  std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n13  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n14  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n15  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n16  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n17  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\n\r\n\r\nOut of memory error on GPU 0. Cannot allocate 1.912537GB memory on GPU 0, available memory is only 381.125000MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.92 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n at (/paddle/paddle/fluid/memory/detail/system_allocator.cc:151)\r\n\r\n----------------------------------------",
        "state": "closed",
        "user": "bigcash",
        "closed_by": "zh794390558",
        "created_at": "2020-01-09T03:28:42+00:00",
        "updated_at": "2022-08-12T02:30:54+00:00",
        "closed_at": "2021-03-26T11:39:22+00:00",
        "comments_count": [
            "lfchener",
            "karlkao",
            "bigcash",
            "bigcash",
            "ccbptm",
            "zh794390558",
            "jkluo",
            "bigcash"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 413,
        "title": "ValueError: invalid literal for int() with base 10: ''",
        "body": "Getting the error on Ubuntu 18.04 Docker installation.\r\nRunning docker with \r\n`sudo docker run --gpus=all -it -v $(pwd)/DeepSpeech:/DeepSpeech hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu /bin/bash`\r\n\r\nUpdated the code to the latest develop branch.\r\n\r\nError happens on infer \r\n`CUDA_VISIBLE_DEVICES=0 python infer.py --infer_manifest test_deep_speech.txt`\r\n\r\nManifest I am trying to infer \r\n`{\"audio_filepath\": \"/DeepSpeech/test_deep_speech.wav\", \"duration\": 30.960, \"text\": \"\"}`\r\n\r\nSo it does not even goes to the infer, it fails on data read, because the code tried to convert text to int.\r\n\r\nUPDATE: sorry, this is in the DeepSpeech repo\r\n\r\n![image](https://user-images.githubusercontent.com/4475110/72521299-c2533a80-388d-11ea-817f-3fcd90fb08d9.png)\r\n\r\n",
        "state": "closed",
        "user": "ArtemiyFirsov",
        "closed_by": "zh794390558",
        "created_at": "2020-01-16T11:29:43+00:00",
        "updated_at": "2021-03-10T09:52:05+00:00",
        "closed_at": "2021-03-10T09:50:28+00:00",
        "comments_count": [
            "ArtemiyFirsov",
            "ArtemiyFirsov",
            "lfchener"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 411,
        "title": "use CN1.2K model do not have manifest_path",
        "body": "download 2.8g lm and baidu_cn1.2k_model_fluid.tar.gz but i can't find manifest_path when i extract file",
        "state": "closed",
        "user": "puti-flower",
        "closed_by": "zh794390558",
        "created_at": "2020-01-09T02:28:24+00:00",
        "updated_at": "2021-05-12T05:06:06+00:00",
        "closed_at": "2021-05-12T05:06:06+00:00",
        "comments_count": [
            "bigcash"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 414,
        "title": "aishell  run_test.sh时UnicodeEncodeError: 'decimal' codec can't encode characters in position 0-11: invalid decimal Unicode string",
        "body": "-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbatch_size: 128\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/aishell/mean_std.npz\r\nmodel_path: models/aishell\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntest_manifest: data/aishell/manifest.test\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: models/aishell/vocab.txt\r\n------------------------------------------------\r\n2020-01-20 01:43:38,386-INFO: begin to initialize the external scorer for decoding\r\n2020-01-20 01:43:38,501-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-01-20 01:43:38,501-INFO: end initializing scorer\r\n2020-01-20 01:43:38,502-INFO: start evaluation ...\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 149, in <module>\r\n    main()\r\n  File \"test.py\", line 145, in main\r\n    evaluate()\r\n  File \"test.py\", line 110, in evaluate\r\n    for infer_data in batch_reader():\r\n  File \"/media/zzzzzzk/HDD4T/zk/DeepSpeech/data_utils/data.py\", line 206, in batch_reader\r\n    yield self._padding_batch(batch, padding_to, flatten)\r\n  File \"/media/zzzzzzk/HDD4T/zk/DeepSpeech/data_utils/data.py\", line 336, in _padding_batch\r\n    texts = np.expand_dims(np.array(texts).astype('int32'), axis=-1)\r\nUnicodeEncodeError: 'decimal' codec can't encode characters in position 0-11: invalid decimal Unicode string\r\nFailed in evaluation!",
        "state": "closed",
        "user": "tianchaolangzi",
        "closed_by": "tianchaolangzi",
        "created_at": "2020-01-19T17:49:46+00:00",
        "updated_at": "2020-01-20T08:40:15+00:00",
        "closed_at": "2020-01-20T08:40:14+00:00",
        "comments_count": [
            "lfchener",
            "tianchaolangzi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 416,
        "title": "docker image for cpu",
        "body": "Is there a CPU version of docker image",
        "state": "closed",
        "user": "puti-flower",
        "closed_by": "zh794390558",
        "created_at": "2020-01-21T07:53:17+00:00",
        "updated_at": "2021-03-24T08:18:49+00:00",
        "closed_at": "2021-03-24T08:18:49+00:00",
        "comments_count": [
            "puti-flower",
            "loretoparisi",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 419,
        "title": "Training examples/librispeech - Segmentation fault",
        "body": "While it's training with examples/librispeech, right after test done with epoch 2, starting epoch 3.\r\nThe training failed with following message.\r\n\r\n----------Begin test...\r\n--------Time: 8828.566067 sec, epoch: 2, train loss: 55.043900, test loss: 823.349414\r\nsave parameters at ./checkpoints/libri/epoch_2\r\nW0123 04:51:52.655895  1282 init.cc:206] *** Aborted at 1579755112 (unix time) try \"date -d @1579755112\" if you are using GNU date ***\r\nW0123 04:51:52.658562  1282 init.cc:206] PC: @                0x0 (unknown)\r\nW0123 04:51:52.658725  1282 init.cc:206] *** SIGSEGV (@0x64) received by PID 1156 (TID 0x7f2532fed700) from PID 100; stack trace: ***\r\nW0123 04:51:52.660856  1282 init.cc:206]     @     0x7f4343178390 (unknown)\r\nW0123 04:51:52.663314  1282 init.cc:206]     @     0x7f4280d79d56 std::_Hashtable<>::_M_find_before_node()\r\nW0123 04:51:52.666824  1282 init.cc:206]     @     0x7f4280d77fb7 paddle::framework::Scope::FindVarLocally()\r\nW0123 04:51:52.668771  1282 init.cc:206]     @     0x7f4280d785be paddle::framework::Scope::VarInternal()\r\nW0123 04:51:52.670828  1282 init.cc:206]     @     0x7f4280d7873d paddle::framework::Scope::Var()\r\nW0123 04:51:52.673468  1282 init.cc:206]     @     0x7f427ee0dc7d paddle::operators::RecurrentGradOp::RunImpl()\r\nW0123 04:51:52.675822  1282 init.cc:206]     @     0x7f4280d0269c paddle::framework::OperatorBase::Run()\r\nW0123 04:51:52.677320  1282 init.cc:206]     @     0x7f4280ae4c8d _ZNSt17_Function_handlerIFvvEZN6paddle9framework7details12OpHandleBase17RunAndRecordEventERKSt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data\r\nW0123 04:51:52.680279  1282 init.cc:206]     @     0x7f4280ae44b5 paddle::framework::details::OpHandleBase::RunAndRecordEvent()\r\nW0123 04:51:52.683532  1282 init.cc:206]     @     0x7f4280ae78cb paddle::framework::details::ComputationOpHandle::RunImpl()\r\nW0123 04:51:52.686373  1282 init.cc:206]     @     0x7f4280a9eba6 paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync()\r\nW0123 04:51:52.689316  1282 init.cc:206]     @     0x7f4280a9d8ef paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp()\r\nW0123 04:51:52.690891  1282 init.cc:206]     @     0x7f4280a9dbb4 _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_Any_data\r\nW0123 04:51:52.694702  1282 init.cc:206]     @     0x7f427e5a0d13 std::_Function_handler<>::_M_invoke()\r\nW0123 04:51:52.698467  1282 init.cc:206]     @     0x7f427e3ece37 std::__future_base::_State_base::_M_do_set()\r\nW0123 04:51:52.700204  1282 init.cc:206]     @     0x7f4343175a99 __pthread_once_slow\r\nW0123 04:51:52.701709  1282 init.cc:206]     @     0x7f4280a99702 _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS4_12OpHandleBaseESt6atomicIiESt4hashIS8_ESt8equal_toIS8_ESaISt4pairIKS8_SA_EEES8_RKSt10shared_ptrINS3_13BlockingQueueImEEEEUlvE_vEESaIiEFvvEE6_M_runEv\r\nW0123 04:51:52.704826  1282 init.cc:206]     @     0x7f427e3ee5f4 _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\nW0123 04:51:52.706565  1282 init.cc:206]     @     0x7f4334da0c80 (unknown)\r\nW0123 04:51:52.708508  1282 init.cc:206]     @     0x7f434316e6ba start_thread\r\nW0123 04:51:52.710675  1282 init.cc:206]     @     0x7f4342ea441d clone\r\nW0123 04:51:52.712718  1282 init.cc:206]     @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\nFailed in training!",
        "state": "closed",
        "user": "karlkao",
        "closed_by": "zh794390558",
        "created_at": "2020-01-23T17:23:18+00:00",
        "updated_at": "2021-05-12T05:04:43+00:00",
        "closed_at": "2021-05-12T05:04:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 417,
        "title": "Docker image for CUDA 10.0",
        "body": "I am using the available docker image.\r\nAfter fixing [this issue ](https://github.com/PaddlePaddle/DeepSpeech/issues/386#issuecomment-566807071) I have this error when trying `sh run_train.sh`\r\n\r\n```\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 4\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 20\r\nnum_iter_print: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 64\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nE0121 09:57:47.763219    62 pybind.cc:1190] Cannot use GPU because there is no GPU detected on your machine.\r\nFailed in training!\r\n```\r\n\r\nIt seems starting from this docker image that i can't properly see the GPU, I am on a server with CUDA 10.2 but inside the docker there is CUDA 9 installed.\r\n\r\n```\r\nnvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n```\r\nWhat's another docker image I can pull from that works on CUDA 10?\r\nThanks!",
        "state": "closed",
        "user": "shoegazerstella",
        "closed_by": "zh794390558",
        "created_at": "2020-01-21T10:03:28+00:00",
        "updated_at": "2021-03-24T08:18:33+00:00",
        "closed_at": "2021-03-24T08:18:32+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 418,
        "title": "model init multiple times, slow inference",
        "body": "Hi Team,\r\n\r\nI was trying to run DeepSpeech on Libris dataset and noticed while doing inference. The model is initialized with every batch/loop. This makes the inference very slow, is there a way around that we don't initialize the model in every batch?\r\n\r\n\r\nComplete trace:\r\n`-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbatch_size: 16\r\nbeam_size: 128\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\nlang_model_path: pretrained_ds2/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: data/tiny/mean_std.npz\r\nmodel_path: pretrained_ds2/libris\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntest_manifest: data/tiny/manifest.sample\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: pretrained_ds2/libris/vocab.txt\r\n------------------------------------------------\r\n2020-01-23 17:04:50,840-INFO: begin to initialize the external scorer for decoding\r\n2020-01-23 17:07:10,592-INFO: language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n2020-01-23 17:07:10,596-INFO: end initializing scorer\r\n2020-01-23 17:07:10,597-INFO: start evaluation ...\r\n+++++++++++++++++++++++++++++++++\r\nProcessing Batch:  0\r\n+++++++++++++++++++++++++++++++++\r\nW0123 17:07:12.100998 28455 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.0, Runtime API Version: 10.0\r\nW0123 17:07:12.143882 28455 device_context.cc:244] device: 0, cuDNN Version: 7.6.\r\nfinish initing model from pretrained params from pretrained_ds2/libris\r\n\r\nTarget Transcription: he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fattened sauce\r\nOutput Transcription: he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flower fattened sauce\r\nError rate [wer] (16/?) = 0.050676\r\n+++++++++++++++++++++++++++++++++\r\nProcessing Batch:  1\r\n+++++++++++++++++++++++++++++++++\r\nfinish initing model from pretrained params from pretrained_ds2/libris\r\n\r\nTarget Transcription: then you can ask him questions on the catechism dedalus\r\nOutput Transcription: then you can ask him questions on the catechism daedalus\r\nError rate [wer] (32/?) = 0.031674\r\n+++++++++++++++++++++++++++++++++\r\nProcessing Batch:  2\r\n+++++++++++++++++++++++++++++++++\r\nfinish initing model from pretrained params from pretrained_ds2/libris\r\n\r\nTarget Transcription: he is called as you know the apostle of the indies\r\nOutput Transcription: he is called as you know the apostle of the indies\r\nError rate [wer] (48/?) = 0.027174\r\n+++++++++++++++++++++++++++++++++\r\nProcessing Batch:  3\r\n+++++++++++++++++++++++++++++++++\r\nfinish initing model from pretrained params from pretrained_ds2/libris\r\n\r\nTarget Transcription: brother mac ardle brother keogh\r\nOutput Transcription: brother mccardle brother key of\r\nError rate [wer] (64/?) = 0.040898\r\n+++++++++++++++++++++++++++++++++\r\nProcessing Batch:  4\r\n+++++++++++++++++++++++++++++++++\r\nfinish initing model from pretrained params from pretrained_ds2/libris\r\n\r\nTarget Transcription: you will find me continually speaking of four men titian holbein turner and tintoret in almost the same terms\r\nOutput Transcription: you will find me continually speaking of four men titan hobin turner and tenkara in almost the same terms\r\nError rate [wer] (80/?) = 0.056689\r\n`",
        "state": "closed",
        "user": "aayushkubb",
        "closed_by": "zh794390558",
        "created_at": "2020-01-23T11:48:30+00:00",
        "updated_at": "2021-05-12T05:04:52+00:00",
        "closed_at": "2021-05-12T05:04:52+00:00",
        "comments_count": [
            "nayanhalder"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 421,
        "title": "Facing problem with installation on python3i",
        "body": "I am facing problem in installation of DeepSpeech2 model in python3.5.2. \r\nSpeciallfically problem comes from DeepSpeech-develop/decoders/swig/swig_decoders.py\r\nwhich could not find _swig_decoders.py due to scorer.h:9:33: fatal error: lm/enumerate_vocab.hh: No such file or directory\r\n\r\nError messages as follows while doing setup from /DeepSpeech-develop/decoders/swig/setup.py:\r\nDeepSpeech-develop/decoders/swig$ sudo python3 setup.py install\r\nscorer.h:22: Warning 401: Nothing known about base class 'lm::EnumerateVocab'. Ignored.\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\ncreating swig_decoders.egg-info\r\nwriting top-level names to swig_decoders.egg-info/top_level.txt\r\nwriting dependency_links to swig_decoders.egg-info/dependency_links.txt\r\nwriting swig_decoders.egg-info/PKG-INFO\r\nwriting manifest file 'swig_decoders.egg-info/SOURCES.txt'\r\nreading manifest file 'swig_decoders.egg-info/SOURCES.txt'\r\nwriting manifest file 'swig_decoders.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.linux-x86_64/egg\r\nrunning install_lib\r\nrunning build_py\r\ncreating build\r\ncreating build/lib.linux-x86_64-3.5\r\ncopying swig_decoders.py -> build/lib.linux-x86_64-3.5\r\nrunning build_ext\r\nbuilding '_swig_decoders' extension\r\ncreating build/temp.linux-x86_64-3.5\r\nx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python3.5m -c decoders_wrap.cxx -o build/temp.linux-x86_64-3.5/decoders_wrap.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\ncc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\nIn file included from decoders_wrap.cxx:2806:0:\r\nscorer.h:9:33: fatal error: lm/enumerate_vocab.hh: No such file or directory\r\ncompilation terminated.\r\nx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python3.5m -c decoder_utils.cpp -o build/temp.linux-x86_64-3.5/decoder_utils.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11 -DHAVE_ZLIB -DHAVE_BZLIB -DHAVE_XZLIB\r\nerror: command 'x86_64-linux-gnu-gcc' failed with exit status 1\r\ncc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n\r\nWhen I am trying to run infer.py form python3 it is giving me following error:\r\npython3 infer.py \r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 14, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"<path>/DeepSpeech-develop/model_utils/model.py\", line 20, in <module>\r\n    from decoders.swig_wrapper import Scorer\r\n  File \"<path>/DeepSpeech-develop/decoders/swig_wrapper.py\", line 6, in <module>\r\n    from .swig import swig_decoders\r\n  File \"<path>/DeepSpeech-develop/decoders/swig/swig_decoders.py\", line 13, in <module>\r\n    from . import _swig_decoders\r\n",
        "state": "closed",
        "user": "vhiwase",
        "closed_by": "zh794390558",
        "created_at": "2020-01-30T13:18:57+00:00",
        "updated_at": "2022-01-15T19:19:04+00:00",
        "closed_at": "2021-02-03T07:15:47+00:00",
        "comments_count": [
            "vhiwase",
            "inishchith",
            "sungyihsun",
            "inishchith",
            "VaibhavAbhimanyooHiwase",
            "inishchith",
            "zh794390558",
            "detrin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 422,
        "title": "请问现在增加了python3的支持没？",
        "body": "",
        "state": "closed",
        "user": "ChenHuaYou",
        "closed_by": "zh794390558",
        "created_at": "2020-02-03T14:25:16+00:00",
        "updated_at": "2021-02-03T07:13:38+00:00",
        "closed_at": "2021-02-03T07:13:38+00:00",
        "comments_count": [
            "MRXLT",
            "ChenHuaYou",
            "Slyne",
            "inishchith",
            "Slyne",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 420,
        "title": "sh run_infer.sh ",
        "body": "sh run_infer.sh \r\n/usr/local/lib/python2.7/dist-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\r\n  warnings.warn(warning, RequestsDependencyWarning)\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 1\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 4\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/librispeech/manifest.dev-clean\r\nlang_model_path: models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: /home/vaibhav/speech/DeepSpeech-develop/models/librispeech/librispeech_model_fluid/mean_std.npz\r\nmodel_path: checkpoints/libri/step_final\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 1\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 0\r\nuse_gru: 0\r\nvocab_path: /home/vaibhav/speech/DeepSpeech-develop/models/librispeech/librispeech_model_fluid/vocab.txt\r\n------------------------------------------------\r\n2020-01-28 17:27:56,084-INFO: begin to initialize the external scorer for decoding\r\n2020-01-28 17:29:55,926-INFO: language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n2020-01-28 17:29:56,215-INFO: end initializing scorer\r\n2020-01-28 17:29:56,215-INFO: start inference ...\r\n[libprotobuf ERROR /paddle/build/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type \"paddle.framework.proto.VarType.TensorDesc\" because it is missing required fields: (cannot determine missing fields for lite message)\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/vaibhav/speech/DeepSpeech-develop/model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/home/vaibhav/speech/DeepSpeech-develop/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 726, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&)\r\n3   paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&)\r\n4   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, paddle::platform::Place const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const\r\n5   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n8   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n11  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 725, in load_vars\r\n    attrs={'file_path': os.path.join(load_dirname, filename)})\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 682, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 798, in load_params\r\n    filename=filename)\r\n  File \"/home/vaibhav/speech/DeepSpeech-develop/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/vaibhav/speech/DeepSpeech-develop/model_utils/model.py\", line 412, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot parse tensor desc at (/paddle/paddle/fluid/framework/tensor_util.cc:466)\r\n  [operator < load_combine > error]\r\nFailed in inference!\r\n",
        "state": "closed",
        "user": "vhiwase",
        "closed_by": "zh794390558",
        "created_at": "2020-01-28T12:46:17+00:00",
        "updated_at": "2021-05-12T05:04:23+00:00",
        "closed_at": "2021-05-12T05:04:23+00:00",
        "comments_count": [
            "ljssssss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 423,
        "title": "Inference output majorly incorrect with aishell test sample, using \"models/baidu_cn1.2k\" and \"models/lm/zhidao_giga.klm\"",
        "body": "sh run_infer_golden.sh\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: models/lm/zhidao_giga.klm\r\nmean_std_path: models/baidu_cn1.2k/mean_std.npz\r\nmodel_path: models/baidu_cn1.2k\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: models/baidu_cn1.2k/vocab.txt\r\n------------------------------------------------\r\n2020-02-04 23:59:20,513-INFO: begin to initialize the external scorer for decoding\r\n2020-02-04 23:59:23,525-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-02-04 23:59:23,525-INFO: end initializing scorer\r\n2020-02-04 23:59:23,525-INFO: start inference ...\r\nfinish initing model from pretrained params from models/baidu_cn1.2k\r\n\r\nTarget Transcription: 开发边界将作为城市发展的刚性约定\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 成交量环比大幅增加\r\nOutput Transcription: 啊\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 也有限购政策在控制需求规模\r\nOutput Transcription: 我\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 本月中下旬小行星撞地球\r\nOutput Transcription: 我\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 好莱坞当红明星之前曾被盛传将扮演斯诺登\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 公司已将原有的直销模式改为经销模式\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 制定了可再生能源电价附加补贴和配额交易方案\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 坚持违法零容忍和高限处理的执法态度\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 构建良好的旅游市场环境\r\nOutput Transcription: 我\r\nCurrent error rate [cer] = 1.000000\r\n\r\nTarget Transcription: 今年芯片行业并购交易额在八百亿美元以上\r\nOutput Transcription:\r\nCurrent error rate [cer] = 1.000000\r\n2020-02-05 00:00:18,121-INFO: finish inference",
        "state": "closed",
        "user": "karlkao",
        "closed_by": "zh794390558",
        "created_at": "2020-02-05T00:01:37+00:00",
        "updated_at": "2021-05-12T05:05:00+00:00",
        "closed_at": "2021-05-12T05:05:00+00:00",
        "comments_count": [
            "nerv3890",
            "ccbptm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 424,
        "title": "same response time in both 1 core(p2.xlarge) and 8 core(p2.8xlarge) AWS gpu",
        "body": "```\r\n\r\nI am getting same response time in both 1 core and 8 core gpu. \r\n\r\ni am using CUDA10.1 and cudnn7.6\r\n\r\nfor 8 core gpu. before running python program, i am running the following command in ubuntu\r\nexport CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\r\n\r\nam i missing any parameter to set.\r\nplease help.\r\ni am running with following settings:\r\n\r\nparser = argparse.ArgumentParser(description=__doc__)\r\nadd_arg = functools.partial(add_arguments, argparser=parser)\r\n# yapf: disable\r\nadd_arg('num_samples',      int,    1,     \"# of samples to infer.\")\r\nadd_arg('beam_size',        int,    500,    \"Beam search width.\")\r\nadd_arg('num_proc_bsearch', int,    8,      \"# of CPUs for beam search.\")\r\nadd_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\nadd_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\nadd_arg('rnn_layer_size',   int,    1024,   \"# of recurrent cells per layer.\")\r\nadd_arg('alpha',            float,  2.5,    \"Coef of LM for beam search.\")\r\nadd_arg('beta',             float,  0.3,    \"Coef of WC for beam search.\")\r\nadd_arg('cutoff_prob',      float,  1.0,    \"Cutoff probability for pruning.\")\r\nadd_arg('cutoff_top_n',     int,    40,     \"Cutoff number for pruning.\")\r\nadd_arg('use_gru',          bool,   True,  \"Use GRUs instead of simple RNNs.\")\r\nadd_arg('use_gpu',          bool,   True,   \"Use GPU or not.\")\r\nadd_arg('share_rnn_weights',bool,   False,   \"Share input-hidden weights across \"\r\n                                            \"bi-directional RNNs. Not for GRU.\")\r\n\r\n```",
        "state": "closed",
        "user": "nayanhalder",
        "closed_by": "zh794390558",
        "created_at": "2020-02-10T14:35:23+00:00",
        "updated_at": "2021-02-03T06:36:11+00:00",
        "closed_at": "2021-02-03T06:36:11+00:00",
        "comments_count": [
            "lfchener",
            "nayanhalder",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 425,
        "title": "运行 tune.py 时总是会中断",
        "body": "次次都会killed\r\npython tools/tune.py \r\n-----------  Configuration Arguments -----------\r\nalpha_from: 1.0\r\nalpha_to: 3.2\r\nbatch_size: 256\r\nbeam_size: 300\r\nbeta_from: 0.1\r\nbeta_to: 0.45\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\nerror_rate_type: wer\r\nlang_model_path: models/lm/zhidao_giga.klm\r\nmean_std_path: models/mean_std.npz\r\nmodel_path: models\r\nnum_alphas: 45\r\nnum_batches: -1\r\nnum_betas: 8\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\ntrainer_count: 8\r\ntune_manifest: data/aishell/manifest.dev\r\nuse_gpu: False\r\nuse_gru: True\r\nvocab_path: models/vocab.txt\r\n------------------------------------------------\r\n2020-02-13 20:14:27,192-INFO: begin to initialize the external scorer for decoding\r\n2020-02-13 20:25:17,093-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-02-13 20:25:17,159-INFO: end initializing scorer\r\n2020-02-13 20:25:17,160-INFO: start tuning ...\r\nfinish initing model from pretrained params from models\r\nKilled\r\n",
        "state": "closed",
        "user": "ChenHuaYou",
        "closed_by": "zh794390558",
        "created_at": "2020-02-13T13:28:53+00:00",
        "updated_at": "2021-02-03T06:34:46+00:00",
        "closed_at": "2021-02-03T06:34:46+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 426,
        "title": "同一份自己录制的语音，本人普通话不是很标准，但是科大讯飞的识别率几乎100%，百度这个的偏差也太大了。",
        "body": "如上描述，问题出在哪里呢？我用的是aishell",
        "state": "closed",
        "user": "ChenHuaYou",
        "closed_by": "zh794390558",
        "created_at": "2020-02-20T00:18:16+00:00",
        "updated_at": "2021-02-03T06:32:40+00:00",
        "closed_at": "2021-02-03T06:32:40+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 427,
        "title": "有一个70多G的语言模型，那个需要多大内存去加载？",
        "body": "有一个70多G的语言模型，那个需要多大内存去加载？",
        "state": "closed",
        "user": "ChenHuaYou",
        "closed_by": "zh794390558",
        "created_at": "2020-02-20T08:07:06+00:00",
        "updated_at": "2021-02-03T06:32:09+00:00",
        "closed_at": "2021-02-03T06:32:09+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 428,
        "title": "BaiduCN1.2k  准确率超级低",
        "body": "有没有官方demo?这么大的模型文件居然是这么偏差，不知道是不是参数没对，也没具体demo",
        "state": "closed",
        "user": "ChenHuaYou",
        "closed_by": "zh794390558",
        "created_at": "2020-02-21T02:26:24+00:00",
        "updated_at": "2021-05-12T05:02:24+00:00",
        "closed_at": "2021-05-12T05:02:24+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 430,
        "title": "paddlepaddle deepspeech2 on python3 ",
        "body": "Currently paddlepaddle deepspeech2 is supported only in python2.7.  is it also supported in python 3. ",
        "state": "closed",
        "user": "nayanhalder",
        "closed_by": "zh794390558",
        "created_at": "2020-02-22T15:16:43+00:00",
        "updated_at": "2021-02-03T06:31:19+00:00",
        "closed_at": "2021-02-03T06:31:19+00:00",
        "comments_count": [
            "lfchener",
            "loretoparisi",
            "nayanhalder",
            "shoegazerstella",
            "loretoparisi",
            "nayanhalder",
            "nayanhalder",
            "loretoparisi",
            "nayanhalder",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 431,
        "title": "Can the released models be used as checkpoints?",
        "body": "I was experimenting with adding new training data to the released models, specifically the BaiduEN8k model. I tried running a script that uses the BaiduEN8k as a checkpoint (borrowing from `examples/librispeech/run_train.sh`):\r\n\r\n```sh\r\nexport FLAGS_sync_nccl_allreduce=0\r\nexport CUDA_VISIBLE_DEVICES=0\r\n\r\npython -u train.py \\\r\n--batch_size=20 \\\r\n--num_epoch=50 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--num_iter_print=100 \\\r\n--save_epoch=1 \\\r\n--num_samples=280000 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=27.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=False \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=True \\\r\n--train_manifest='manifest.train-clean-100' \\\r\n--dev_manifest='manifest.dev-clean' \\\r\n--mean_std_path='mean_std.npz' \\\r\n--vocab_path='/code/models/deepspeech2/vocab.txt' \\\r\n--init_from_pretrained_model='/code/models/deepspeech2' \\\r\n--output_model_dir='/code/models/deepspeech2_new' \\\r\n--augment_conf_path='conf/augmentation.config' \\\r\n--specgram_type='linear' \\\r\n--shuffle_method='batch_shuffle_clipped'\r\n```\r\n\r\nThe directory `/code/models/deepspeech2` contains the BaiduEN8k models:\r\n```sh\r\n$ ls /code/models/deepspeech2\r\nREADME.md  mean_std.npz  params.pdparams  vocab.txt\r\n$ du -hs /code/models/deepspeech2/*\r\n4.0K    /code/models/deepspeech2/README.md\r\n4.0K    /code/models/deepspeech2/mean_std.npz\r\n201M    /code/models/deepspeech2/params.pdparams\r\n4.0K    /code/models/deepspeech2/vocab.txt\r\n```\r\n\r\nWhen I run the script, I get this segfault:\r\n```text\r\nW0224 02:04:07.079113   149 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0224 02:04:07.100364   149 device_context.cc:244] device: 0, cuDNN Version: 7.6.\r\nW0224 02:04:08.754072   149 init.cc:206] *** Aborted at 1582509848 (unix time) try \"date -d @1582509848\" if you are using GNU date ***\r\nW0224 02:04:08.756754   149 init.cc:206] PC: @                0x0 (unknown)\r\nW0224 02:04:08.757686   149 init.cc:206] *** SIGSEGV (@0x50) received by PID 149 (TID 0x7f0571ad1700) from PID 80; stack trace: ***\r\nW0224 02:04:08.760175   149 init.cc:206]     @     0x7f05716aa390 (unknown)\r\nW0224 02:04:08.762334   149 init.cc:206]     @     0x7f05718c275c (unknown)\r\nW0224 02:04:08.764492   149 init.cc:206]     @     0x7f05718cb861 (unknown)\r\nW0224 02:04:08.766629   149 init.cc:206]     @     0x7f05718c6574 (unknown)\r\nW0224 02:04:08.768791   149 init.cc:206]     @     0x7f05718cadb9 (unknown)\r\nW0224 02:04:08.771391   149 init.cc:206]     @     0x7f05714125ad (unknown)\r\nW0224 02:04:08.773540   149 init.cc:206]     @     0x7f05718c6574 (unknown)\r\nW0224 02:04:08.776126   149 init.cc:206]     @     0x7f0571412664 __libc_dlopen_mode\r\nW0224 02:04:08.778730   149 init.cc:206]     @     0x7f05713e4a85 (unknown)\r\nW0224 02:04:08.780908   149 init.cc:206]     @     0x7f05716a7a99 __pthread_once_slow\r\nW0224 02:04:08.782840   149 init.cc:206]     @     0x7f05713e4ba4 backtrace\r\nW0224 02:04:08.790917   149 init.cc:206]     @     0x7f0506158844 paddle::platform::GetTraceBackString<>()\r\nW0224 02:04:08.795003   149 init.cc:206]     @     0x7f0506158cfa paddle::platform::EnforceNotMet::EnforceNotMet()\r\nW0224 02:04:08.801776   149 init.cc:206]     @     0x7f0507554b35 paddle::operators::LoadCombineOpKernel<>::LoadParamsFromBuffer()\r\nW0224 02:04:08.807842   149 init.cc:206]     @     0x7f0507554ece paddle::operators::LoadCombineOpKernel<>::Compute()\r\nW0224 02:04:08.811461   149 init.cc:206]     @     0x7f0507555423 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform9CUDAPlaceELb0ELm0EJNS0_9operators19LoadCombineOpKernelINS7_17CUDADeviceContextEfEENSA_ISB_dEENSA_ISB_iEENSA_ISB_aEENSA_ISB_lEEEEclEPKcSJ_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\nW0224 02:04:08.816128   149 init.cc:206]     @     0x7f0508b4dd6b paddle::framework::OperatorWithKernel::RunImpl()\r\nW0224 02:04:08.822257   149 init.cc:206]     @     0x7f0508b4e361 paddle::framework::OperatorWithKernel::RunImpl()\r\nW0224 02:04:08.825278   149 init.cc:206]     @     0x7f0508b47fec paddle::framework::OperatorBase::Run()\r\nW0224 02:04:08.830551   149 init.cc:206]     @     0x7f0506308c86 paddle::framework::Executor::RunPreparedContext()\r\nW0224 02:04:08.833338   149 init.cc:206]     @     0x7f050630c4cf paddle::framework::Executor::Run()\r\nW0224 02:04:08.834825   149 init.cc:206]     @     0x7f0506145f1d _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL22pybind11_init_core_avxERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE103_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\nW0224 02:04:08.836560   149 init.cc:206]     @     0x7f050618f086 pybind11::cpp_function::dispatcher()\r\nW0224 02:04:08.836661   149 init.cc:206]     @           0x4c5cd6 PyEval_EvalFrameEx\r\nW0224 02:04:08.836764   149 init.cc:206]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0224 02:04:08.836939   149 init.cc:206]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0224 02:04:08.837083   149 init.cc:206]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0224 02:04:08.837195   149 init.cc:206]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0224 02:04:08.837280   149 init.cc:206]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0224 02:04:08.837378   149 init.cc:206]     @           0x4c1e32 PyEval_EvalFrameEx\r\nW0224 02:04:08.837463   149 init.cc:206]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0224 02:04:08.837559   149 init.cc:206]     @           0x4c1e32 PyEval_EvalFrameEx\r\n/code/code/deepspeech2/train.sh: line 35:   149 Segmentation fault      (core dumped) python -u train.py --batch_size=20 --num_epoch=50 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --num_iter_print=100 --save_epoch=1 --num_samples=280000 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=True --is_local=True --share_rnn_weights=True --train_manifest='manifest.train-clean-100' --dev_manifest='manifest.dev-clean' --mean_std_path='mean_std.npz' --vocab_path='/code/models/deepspeech2/vocab.txt' --init_from_pretrained_model='/code/models/deepspeech2_copy' --output_model_dir='/code/models/deepspeech2_new' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\n```\r\n\r\nIf using BaiduEN8k as a checkpoint is possible, am I doing it the right way? I understand some of those parameters in the train.py command may need to changed.\r\n",
        "state": "closed",
        "user": "DavidHuie",
        "closed_by": "DavidHuie",
        "created_at": "2020-02-24T02:15:46+00:00",
        "updated_at": "2020-02-24T04:54:45+00:00",
        "closed_at": "2020-02-24T04:54:45+00:00",
        "comments_count": [
            "lfchener",
            "DavidHuie",
            "DavidHuie"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 432,
        "title": "paddlepaddle 如何统计模型的参数量",
        "body": "如题，在用DEEPSPEECH2训练模型时，从哪里看网络总共的参数量？、\r\n\r\n谢谢！",
        "state": "closed",
        "user": "phecda-xu",
        "closed_by": "zh794390558",
        "created_at": "2020-03-10T10:06:52+00:00",
        "updated_at": "2021-02-03T06:30:10+00:00",
        "closed_at": "2021-02-03T06:30:10+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 433,
        "title": "Error: The fed Variable text_data should have dimensions = 2, shape = [-1, 1], but received fed shape [402]",
        "body": "I was tried training in CPU. i am facing shape mismatch error. how to resolve this issue.\r\n\r\ni was following step by step. comments below\r\n```\r\n\r\nvirtualenv --python=python2.7 env\r\nsource env/bin/activate\r\n\r\nsudo apt-get install -y pkg-config libflac-dev libogg-dev libvorbis-dev libboost-dev swig python2.7-dev\r\n\r\ngit clone https://github.com/PaddlePaddle/DeepSpeech.git\r\ncd DeepSpeech\r\n\r\npip install numpy\r\npip install -r requirements.txt\r\nsh setup.sh\r\n\r\npip install --upgrade 'setuptools<45.0.0'\r\n\r\npython -m pip install paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n\r\npython data/librispeech/librispeech.py\r\n\r\npython tools/compute_mean_std.py --num_samples 2000 --specgram_type linear --manifest_path manifest.train-clean-100 --output_path data/librispeech/mean_std.npz \r\n\r\npython tools/build_vocab.py --count_threshold 0 --vocab_path data/librispeech/eng_vocab.txt --manifest_paths manifest.train-clean-100\r\nsh ./examples/librispeech/run_train.sh\r\n```\r\n\r\n\r\n```\r\n/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/home/dell/Projects_module/STT/DeepSpeech/model_utils/model.py\", line 337, in train\r\n    return_numpy=False)\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 843, in _run_impl\r\n    return_numpy=return_numpy)\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 677, in _run_parallel\r\n    tensors = exe.run(fetch_var_names)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::ReadOp::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n5   paddle::framework::details::OpHandleBase::Run(bool)\r\n6   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n7   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n8   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n9   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n10  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 733, in _init_non_iterable\r\n    outputs={'Out': self._feed_list})\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 646, in __init__\r\n    self._init_non_iterable()\r\n  File \"/home/dell/Projects_module/STT/env/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 280, in from_generator\r\n    iterable, return_list)\r\n  File \"/home/dell/Projects_module/STT/DeepSpeech/model_utils/model.py\", line 112, in create_network\r\n    use_double_buffer=True)\r\n  File \"/home/dell/Projects_module/STT/DeepSpeech/model_utils/model.py\", line 281, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: The fed Variable text_data should have dimensions = 2, shape = [-1, 1], but received fed shape [402]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:133)\r\n  [operator < read > error]\r\nFailed in training!\r\n\r\n```",
        "state": "closed",
        "user": "MuruganR96",
        "closed_by": "zh794390558",
        "created_at": "2020-03-18T12:32:36+00:00",
        "updated_at": "2021-02-03T06:31:45+00:00",
        "closed_at": "2021-02-03T06:31:45+00:00",
        "comments_count": [
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 434,
        "title": "Model load fails in Tornado server",
        "body": "System information\r\n-PaddlePaddle version >= 1.6.0\r\n-OS Platform ubuntu 18.04\r\n-Python version: 3.7.4\r\n-Name of Model: DeepSpeech2\r\n\r\nI am trying to load a DeepSpeech2 model inside a tornado server using a SingletonMixin class and I have this error:\r\n```\r\nW0318 11:19:35.634687   150 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0318 11:19:35.634742   150 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0318 11:19:35.634757   150 init.cc:214] The detail failure signal is:\r\nW0318 11:19:35.634773   150 init.cc:217] *** Aborted at 1584530375 (unix time) try \"date -d @1584530375\" if you are using GNU date ***\r\nW0318 11:19:35.637790   150 init.cc:217] PC: @                0x0 (unknown)\r\nW0318 11:19:35.638175   150 init.cc:217] *** SIGSEGV (@0x130) received by PID 150 (TID 0x7fd82fb11f40) from PID 304; stack trace: ***\r\nW0318 11:19:35.640535   150 init.cc:217]     @     0x7fd830016730 (unknown)\r\nW0318 11:19:35.641213   150 init.cc:217]     @     0x7fd7e91a01aa pybind11::detail::make_new_python_type()\r\nW0318 11:19:35.642088   150 init.cc:217]     @     0x7fd7e91a27b8 pybind11::detail::generic_type::initialize()\r\nW0318 11:19:35.642894   150 init.cc:217]     @     0x7fd7e9316c94 _ZN8pybind115enum_IN10onnx_torch20TensorProto_DataTypeEEC1IJEEERKNS_6handleEPKcDpRKT_\r\nW0318 11:19:35.644227   150 init.cc:217]     @     0x7fd7e931029c torch::onnx::initONNXBindings()\r\nW0318 11:19:35.645166   150 init.cc:217]     @     0x7fd7e8fca218 initModule()\r\nW0318 11:19:35.647357   150 init.cc:217]     @     0x7fd830265042 _PyImport_LoadDynamicModuleWithSpec\r\nW0318 11:19:35.649078   150 init.cc:217]     @     0x7fd830264dc9 _imp_create_dynamic\r\nW0318 11:19:35.651010   150 init.cc:217]     @     0x7fd830176025 _PyMethodDef_RawFastCallDict\r\nW0318 11:19:35.652886   150 init.cc:217]     @     0x7fd830175d10 _PyCFunction_FastCallDict\r\nW0318 11:19:35.654853   150 init.cc:217]     @     0x7fd8301eb833 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.657164   150 init.cc:217]     @     0x7fd8301e5831 _PyEval_EvalCodeWithName\r\nW0318 11:19:35.659276   150 init.cc:217]     @     0x7fd830176982 _PyFunction_FastCallKeywords\r\nW0318 11:19:35.661051   150 init.cc:217]     @     0x7fd8301ea3b2 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.662883   150 init.cc:217]     @     0x7fd8301768da _PyFunction_FastCallKeywords\r\nW0318 11:19:35.664608   150 init.cc:217]     @     0x7fd8301e6992 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.666405   150 init.cc:217]     @     0x7fd8301768da _PyFunction_FastCallKeywords\r\nW0318 11:19:35.668154   150 init.cc:217]     @     0x7fd8301e6bb1 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.670182   150 init.cc:217]     @     0x7fd8301768da _PyFunction_FastCallKeywords\r\nW0318 11:19:35.672044   150 init.cc:217]     @     0x7fd8301e6bb1 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.674051   150 init.cc:217]     @     0x7fd8301768da _PyFunction_FastCallKeywords\r\nW0318 11:19:35.676153   150 init.cc:217]     @     0x7fd8301e6bb1 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.678510   150 init.cc:217]     @     0x7fd83017704a _PyFunction_FastCallDict\r\nW0318 11:19:35.679981   150 init.cc:217]     @     0x7fd8301765bd object_vacall\r\nW0318 11:19:35.681828   150 init.cc:217]     @     0x7fd830177dbb _PyObject_CallMethodIdObjArgs\r\nW0318 11:19:35.683385   150 init.cc:217]     @     0x7fd830200521 PyImport_ImportModuleLevelObject.localalias.22\r\nW0318 11:19:35.685279   150 init.cc:217]     @     0x7fd8301e9b39 _PyEval_EvalFrameDefault\r\nW0318 11:19:35.687129   150 init.cc:217]     @     0x7fd8301e5831 _PyEval_EvalCodeWithName\r\nW0318 11:19:35.689189   150 init.cc:217]     @     0x7fd8301e5539 PyEval_EvalCodeEx\r\nW0318 11:19:35.691130   150 init.cc:217]     @     0x7fd8301e54fb PyEval_EvalCode\r\nW0318 11:19:35.692857   150 init.cc:217]     @     0x7fd83025f114 builtin_exec\r\nW0318 11:19:35.695096   150 init.cc:217]     @     0x7fd830176025 _PyMethodDef_RawFastCallDict\r\nSegmentation fault\r\n```\r\n\r\nthe signleton class:\r\n```\r\nclass ResourceLoader(SingletonMixin):\r\n\r\n    def __init__(self):\r\n\r\n        self.deepspeech2_model = None\r\n\r\n    def load_ds2_model(self):\r\n        \"\"\"LOAD DeepSpeech2 model\"\"\"\r\n       self.deepspeech2_model = load_deepspeech2_model(DEEPSPEECH2_MODEL_PATH, vocab_path, mean_std_path)\r\n```\r\nI am executing this script which is the tornado run app:\r\n```\r\nclass WebServer(threading.Thread):\r\n    def run(self):\r\n        asyncio.set_event_loop_policy(AnyThreadEventLoopPolicy())\r\n        asyncio.get_event_loop().set_default_executor(ThreadPoolExecutor(max_workers=1))\r\n        app = application()\r\n        app.listen(PORT)\r\n        tornado.ioloop.IOLoop.instance().start()\r\n\r\nif __name__ == \"__main__\":\r\n      ResourceLoader.instance().load_ds2_model()\r\n      WebServer().start()\r\n```\r\n\r\nFrom inside the Docker container, the script that does load + inference alone works fine. The problem appears when I try to load it through the singleton inside tornado.\r\nThank you for your help!",
        "state": "closed",
        "user": "shoegazerstella",
        "closed_by": "shoegazerstella",
        "created_at": "2020-03-18T13:22:43+00:00",
        "updated_at": "2020-03-24T15:39:39+00:00",
        "closed_at": "2020-03-24T15:39:39+00:00",
        "comments_count": [
            "shoegazerstella"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 435,
        "title": "添加新的数据，怎么修改最后一层继续训练？",
        "body": "fluid版本，现在有新的数据，导致了vocab尺寸变大，想在已有的预训练模型上继续训练，怎么修改最后一层的尺寸大小？在其他问题里面，还没有看到解决方案。",
        "state": "closed",
        "user": "yzcm1232",
        "closed_by": "zh794390558",
        "created_at": "2020-03-21T14:08:11+00:00",
        "updated_at": "2021-02-03T06:26:09+00:00",
        "closed_at": "2021-02-03T06:26:09+00:00",
        "comments_count": [
            "lfchener",
            "yzcm1232",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 436,
        "title": "Unable to establish SSL connection.",
        "body": "在使用download_lm_ch.sh,出现了这个错误。但是在另外一台电脑上不会报错\r\n具体如下\r\n```\r\nλ e43130a8422a /DeepSpeech/models/lm {develop} sh download_lm_ch.sh\r\nDownload language model ...\r\ndownload_lm_ch.sh: 8: [: 29e02312deb2e59b3c8686c7966d4fe3: unexpected operator\r\n--2020-03-26 08:44:04--  https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm\r\nResolving deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)... 112.34.112.29, 39.156.69.23\r\nConnecting to deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)|112.34.112.29|:443... connected.\r\nUnable to establish SSL connection.\r\nFail to download the language model!\r\n```\r\n",
        "state": "closed",
        "user": "Jackie-zk",
        "closed_by": "zh794390558",
        "created_at": "2020-03-26T08:48:20+00:00",
        "updated_at": "2021-05-12T05:04:15+00:00",
        "closed_at": "2021-05-12T05:04:15+00:00",
        "comments_count": [
            "NHZlX"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 437,
        "title": "在docker中安装最新版1.7.1pandlepandle之后导入pandle包报错",
        "body": "导入包：import paddle.fluid\r\n\r\n报错：ImportError: No module named core_noavx\r\n",
        "state": "closed",
        "user": "hengai",
        "closed_by": "zh794390558",
        "created_at": "2020-04-01T04:59:21+00:00",
        "updated_at": "2021-02-03T06:21:31+00:00",
        "closed_at": "2021-02-03T06:21:30+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 438,
        "title": "How print pinyin using baidu_ch1.2k",
        "body": "",
        "state": "closed",
        "user": "GinaZhu",
        "closed_by": "zh794390558",
        "created_at": "2020-04-01T07:25:05+00:00",
        "updated_at": "2021-02-03T06:20:51+00:00",
        "closed_at": "2021-02-03T06:20:51+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 439,
        "title": "About decoders shared libraries",
        "body": "Hello, I have built a Docker image of DeepSpeech. I prefer to not install every time the swig wrappers since it should be enough to build once and then load at runtime.\r\nTherefore this is what I did\r\n\r\nI have built my library in the `lib/` folder within my `swig` folder, because I need the shared library (.so) to be there in the package without building it at install. \r\nWithout any modifications to `swig_import_helper` I got the error\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/MyProject/swig_wrapper.py\", line 6, in <module>\r\n    import swig_decoders\r\n  File \"/MyProject/swig/swig_decoders.py\", line 26, in <module>\r\n    _swig_decoders = swig_import_helper()\r\n  File \"/MyProject/swig/swig_decoders.py\", line 25, in swig_import_helper\r\n    return importlib.import_module('_swig_decoders')\r\n  File \"/usr/local/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_swig_decoders'\r\n``` \r\n\r\nI have thereforre modified `importlib` in order load the local library:\r\n\r\n```python\r\ndef swig_import_helper():\r\n        import importlib\r\n        pkg = __name__.rpartition('.')[0]\r\n        mname = '.'.join((pkg, '_swig_decoders')).lstrip('.')\r\n        try:\r\n            return importlib.import_module(mname)\r\n        except ImportError:\r\n            try:\r\n                import os\r\n                import importlib.util\r\n                BASE_PATH = os.path.join(os.path.dirname(os.path.realpath(__file__)))\r\n                spec = importlib.util.spec_from_file_location(\"module._swig_decoders\", os.path.join(BASE_PATH, 'lib'))\r\n                foo = importlib.util.module_from_spec(spec)\r\n                spec.loader.exec_module(foo)\r\n            except:\r\n                return importlib.import_module('_swig_decoders')\r\n    _swig_decoders = swig_import_helper()\r\n```\r\n\r\nthe libraries are located in the local path `swig/lib`:\r\n\r\n```\r\n.\r\n└── swig_decoders-1.1-py3.7-linux-x86_64.egg\r\n    ├── EGG-INFO\r\n    ├── __pycache__\r\n    ├── _swig_decoders.cpython-37m-x86_64-linux-gnu.so\r\n    ├── _swig_decoders.py\r\n    └── swig_decoders.py\r\n```\r\n\r\n\r\nAlso in the `swig/build` folder I have the static compiled libraries:\r\n\r\n```\r\n[17:24:43] ip-192-168-1-52:build loretoparisi$ tree -L 2\r\n.\r\n├── lib.linux-x86_64-3.7\r\n│   ├── _swig_decoders.cpython-37m-x86_64-linux-gnu.so\r\n│   └── swig_decoders.py\r\n└── temp.linux-x86_64-3.7\r\n    ├── ctc_beam_search_decoder.o\r\n    ├── ctc_greedy_decoder.o\r\n    ├── decoder_utils.o\r\n    ├── decoders_wrap.o\r\n    ├── kenlm\r\n    ├── openfst-1.6.3\r\n    ├── path_trie.o\r\n    └── scorer.o\r\n```\r\n\r\nI'm still getting an import error when I build:\r\n\r\n```\r\n  File \"MyProject/swig/swig_decoders.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"/usr/local/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named '_swig_decoders'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"MyProject/swig/swig_decoders.py\", line 21, in swig_import_helper\r\n    foo = importlib.util.module_from_spec(spec)\r\n  File \"<frozen importlib._bootstrap>\", line 580, in module_from_spec\r\nAttributeError: 'NoneType' object has no attribute 'loader'\r\n```\r\n\r\nIs this due to a library path error or to the importlib when using ` importlib.util.spec_from_file_location`?\r\n\r\n\r\n\r\n\r\nI have asked the same question here:\r\nhttps://stackoverflow.com/questions/60994100/swig-import-local-shared-library-in-python3",
        "state": "closed",
        "user": "loretoparisi",
        "closed_by": "zh794390558",
        "created_at": "2020-04-02T15:23:29+00:00",
        "updated_at": "2021-05-12T05:04:07+00:00",
        "closed_at": "2021-05-12T05:04:07+00:00",
        "comments_count": [
            "heavengate",
            "loretoparisi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 440,
        "title": "运行Test.py时出现错误OSError: cannot load library 'libsndfile.so.1': libsndfile.so.1: cannot open shared object file: No such file or directory",
        "body": "系统是CentOS 7.3，按照readMe里面来一步步操作的，但是测试时候出现了这个异常(运行examples/tiny/里面的也会,下面运行的是test.py):\r\n**configure: WARNING: *** One or more of the external libraries (ie libflac, libogg and\r\nconfigure: WARNING: *** libvorbis) is either missing (possibly only the development\r\nconfigure: WARNING: *** headers) or is of an unsupported version.\r\nconfigure: WARNING: ***\r\nconfigure: WARNING: *** Unfortunately, for ease of maintenance, the external libs\r\nconfigure: WARNING: *** are an all or nothing affair.\r\nconfigure: WARNING: Touching files in directory tests/.\r\nInstall all dependencies successfully.\r\n[root@iz4uregsg8u6ngz DeepSpeech]# test.py\r\n-bash: test.py: command not found\r\n[root@iz4uregsg8u6ngz DeepSpeech]# python test.py\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 9, in <module>\r\n    from data_utils.data import DataGenerator\r\n  File \"/root/DeepSpeech/data_utils/data.py\", line 15, in <module>\r\n    from data_utils.augmentor.augmentation import AugmentationPipeline\r\n  File \"/root/DeepSpeech/data_utils/augmentor/augmentation.py\", line 11, in <module>\r\n    from data_utils.augmentor.noise_perturb import NoisePerturbAugmentor\r\n  File \"/root/DeepSpeech/data_utils/augmentor/noise_perturb.py\", line 8, in <module>\r\n    from data_utils.audio import AudioSegment\r\n  File \"/root/DeepSpeech/data_utils/audio.py\", line 10, in <module>\r\n    import soundfile\r\n  File \"/usr/lib/python2.7/site-packages/soundfile.py\", line 267, in <module>\r\n    _snd = _ffi.dlopen('sndfile')\r\n  File \"/usr/lib64/python2.7/site-packages/cffi/api.py\", line 150, in dlopen\r\n    lib, function_cache = _make_ffi_library(self, name, flags)\r\n  File \"/usr/lib64/python2.7/site-packages/cffi/api.py\", line 832, in _make_ffi_library\r\n    backendlib = _load_backend_lib(backend, libname, flags)\r\n  File \"/usr/lib64/python2.7/site-packages/cffi/api.py\", line 828, in _load_backend_lib\r\n    return backend.load_library(path, flags)\r\nOSError: cannot load library 'libsndfile.so.1': libsndfile.so.1: cannot open shared object file: No such file or directory**\r\n安装时候他给我一个警告是可能是因为这个原因？求解，小白一个。",
        "state": "closed",
        "user": "DoraemonMiku",
        "closed_by": "zh794390558",
        "created_at": "2020-04-03T14:57:39+00:00",
        "updated_at": "2022-11-07T10:05:28+00:00",
        "closed_at": "2021-02-03T06:20:14+00:00",
        "comments_count": [
            "qili93",
            "yeyupiaoling",
            "zhangxiudan",
            "yeyupiaoling",
            "zhangxiudan",
            "zhangxiudan",
            "EzrealoveQXY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 441,
        "title": "关于语音识别的实时聊天",
        "body": "我为不相关的问题表示歉意，但是是否存在有关中文语音识别的实时聊天？ 微信或其他",
        "state": "closed",
        "user": "nshmyrev",
        "closed_by": "zh794390558",
        "created_at": "2020-04-05T19:23:27+00:00",
        "updated_at": "2021-02-03T06:19:14+00:00",
        "closed_at": "2021-02-03T06:19:13+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 442,
        "title": "感谢，在tiny目录下sh run_train.sh时报错",
        "body": "按照readme一步步来的，然后遇到了swig_decoders不存在的问题，按照issue解决后，继续执行train报如下错误：\r\nW0409 11:01:41.920228  2557 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0409 11:01:41.920295  2557 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0409 11:01:41.920307  2557 init.cc:214] The detail failure signal is:\r\n\r\nW0409 11:01:41.920320  2557 init.cc:217] *** Aborted at 1586401301 (unix time) try \"date -d @1586401301\" if you are using GNU date ***\r\nW0409 11:01:41.923130  2557 init.cc:217] PC: @                0x0 (unknown)\r\nrun_train.sh: 行 35:  2557 段错误               (吐核)CUDA_VISIBLE_DEVICES=0,1,2,3 python -u train.py --batch_size=4 --num_epoch=20 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --num_iter_print=1 --save_epoch=1 --num_samples=64 --learning_rate=1e-5 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=False --use_gpu=False --is_local=True --share_rnn_weights=True --train_manifest='data/tiny/manifest.tiny' --dev_manifest='data/tiny/manifest.tiny' --mean_std_path='data/tiny/mean_std.npz' --vocab_path='data/tiny/vocab.txt' --output_model_dir='./checkpoints/tiny' --augment_conf_path='conf/augmentation.config' --specgram_type='linear' --shuffle_method='batch_shuffle_clipped'\r\nFailed in training!\r\n\r\npaddlepaddle安装如下，安装的无GPU版本，非docker安装：\r\nPaddlePaddle 1.7.1, compiled with\r\n    with_avx: ON\r\n    with_gpu: OFF\r\n    with_mkl: ON\r\n    with_mkldnn: ON\r\n    with_python: ON\r\n\r\nDeepSpeech也是非Docker安装。\r\n\r\n现在解决不了这个问题，请大家指教。\r\n\r\n",
        "state": "closed",
        "user": "Kangzhiwen",
        "closed_by": "zh794390558",
        "created_at": "2020-04-09T03:25:39+00:00",
        "updated_at": "2021-02-03T06:18:30+00:00",
        "closed_at": "2021-02-03T06:18:30+00:00",
        "comments_count": [
            "Kangzhiwen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 444,
        "title": "[ERROR] SIGSEGV (@0x7f20ad805b40) received by PID 38 ",
        "body": "We report this error on a 32GB machine\r\n\r\n```\r\nW0411 14:10:19.744871    38 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0411 14:10:19.751854    38 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0411 14:10:19.751888    38 init.cc:214] The detail failure signal is:\r\nW0411 14:10:19.751909    38 init.cc:217] *** Aborted at 1586614219 (unix time) try \"date -d @1586614219\" if you are using GNU date ***\r\nW0411 14:10:19.872216    38 init.cc:217] PC: @                0x0 (unknown)\r\nW0411 14:10:20.248174    38 init.cc:217] *** SIGSEGV (@0x7f20ad805b40) received by PID 38 (TID 0x7f2907a4cf40) from PID 18446744072325454656; stack trace: ***\r\nW0411 14:10:20.251428    38 init.cc:217]     @     0x7f2907f51730 (unknown)\r\nW0411 14:10:20.324234    38 init.cc:217]     @     0x7f28c75be9e0 paddle::operators::math::Im2ColFunctor<>::operator()()\r\nW0411 14:10:20.356504    38 init.cc:217]     @     0x7f28c6ba5ee7 paddle::operators::GemmConvKernel<>::Compute()\r\nW0411 14:10:20.360272    38 init.cc:217]     @     0x7f28c6ba6563 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform8CPUPlaceELb0ELm0EINS0_9operators14GemmConvKernelINS7_16CPUDeviceContextEfEENSA_ISB_dEEEEclEPKcSG_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\nW0411 14:10:20.366858    38 init.cc:217]     @     0x7f28c794c1e6 paddle::framework::OperatorWithKernel::RunImpl()\r\nW0411 14:10:20.377954    38 init.cc:217]     @     0x7f28c794cd41 paddle::framework::OperatorWithKernel::RunImpl()\r\nW0411 14:10:20.380899    38 init.cc:217]     @     0x7f28c79481f4 paddle::framework::OperatorBase::Run()\r\nW0411 14:10:20.385221    38 init.cc:217]     @     0x7f28c5fc5646 paddle::framework::Executor::RunPreparedContext()\r\nW0411 14:10:20.387609    38 init.cc:217]     @     0x7f28c5fc8c5b paddle::framework::Executor::Run()\r\nW0411 14:10:20.387774    38 init.cc:217]     @     0x7f28c5c66fce _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL22pybind11_init_core_avxERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE107_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\nW0411 14:10:20.388813    38 init.cc:217]     @     0x7f28c5cba8c1 pybind11::cpp_function::dispatcher()\r\nW0411 14:10:20.392134    38 init.cc:217]     @     0x7f29080b09e4 _PyMethodDef_RawFastCallKeywords\r\nW0411 14:10:20.394524    38 init.cc:217]     @     0x7f29080b07b0 _PyCFunction_FastCallKeywords\r\nW0411 14:10:20.396335    38 init.cc:217]     @     0x7f2908125a5d _PyEval_EvalFrameDefault\r\nW0411 14:10:20.398545    38 init.cc:217]     @     0x7f2908120831 _PyEval_EvalCodeWithName\r\nW0411 14:10:20.400462    38 init.cc:217]     @     0x7f29080b1982 _PyFunction_FastCallKeywords\r\nW0411 14:10:20.402266    38 init.cc:217]     @     0x7f29081224a2 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.404166    38 init.cc:217]     @     0x7f2908120831 _PyEval_EvalCodeWithName\r\nW0411 14:10:20.406286    38 init.cc:217]     @     0x7f29080b1982 _PyFunction_FastCallKeywords\r\nW0411 14:10:20.408247    38 init.cc:217]     @     0x7f29081224a2 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.409994    38 init.cc:217]     @     0x7f2908120831 _PyEval_EvalCodeWithName\r\nW0411 14:10:20.411919    38 init.cc:217]     @     0x7f29080b1982 _PyFunction_FastCallKeywords\r\nW0411 14:10:20.413467    38 init.cc:217]     @     0x7f29081224a2 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.414943    38 init.cc:217]     @     0x7f2908120831 _PyEval_EvalCodeWithName\r\nW0411 14:10:20.416543    38 init.cc:217]     @     0x7f29080b1982 _PyFunction_FastCallKeywords\r\nW0411 14:10:20.418066    38 init.cc:217]     @     0x7f29081224a2 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.419690    38 init.cc:217]     @     0x7f29080b18da _PyFunction_FastCallKeywords\r\nW0411 14:10:20.421298    38 init.cc:217]     @     0x7f2908121bb1 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.422842    38 init.cc:217]     @     0x7f2908120831 _PyEval_EvalCodeWithName\r\nW0411 14:10:20.424589    38 init.cc:217]     @     0x7f29080b1982 _PyFunction_FastCallKeywords\r\nW0411 14:10:20.426334    38 init.cc:217]     @     0x7f29081224a2 _PyEval_EvalFrameDefault\r\nW0411 14:10:20.428069    38 init.cc:217]     @     0x7f29080b18da _PyFunction_FastCallKeywords\r\n```\r\n\r\nThe cpu is \r\n\r\n```\r\nprocessor       : 1\r\nvendor_id       : GenuineIntel\r\ncpu family      : 6\r\nmodel           : 79\r\nmodel name      : Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nstepping        : 1\r\nmicrocode       : 0xb000037\r\ncpu MHz         : 2300.086\r\ncache size      : 46080 KB\r\n```",
        "state": "closed",
        "user": "loretoparisi",
        "closed_by": "zh794390558",
        "created_at": "2020-04-14T08:37:16+00:00",
        "updated_at": "2021-02-03T06:11:49+00:00",
        "closed_at": "2021-02-03T06:11:49+00:00",
        "comments_count": [
            "ysh329",
            "loretoparisi",
            "ysh329",
            "shoegazerstella",
            "loretoparisi",
            "lfchener",
            "loretoparisi",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 443,
        "title": "设置CPU_NUM不起作用--自己的问题，泪目，不好意思，请删除",
        "body": "",
        "state": "closed",
        "user": "gezimonkey",
        "closed_by": "gezimonkey",
        "created_at": "2020-04-10T15:42:22+00:00",
        "updated_at": "2020-04-10T15:48:03+00:00",
        "closed_at": "2020-04-10T15:45:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 445,
        "title": "can we use .wav data to do the inference directly with a pre-trained model ?",
        "body": "",
        "state": "closed",
        "user": "juanlsss",
        "closed_by": "zh794390558",
        "created_at": "2020-04-19T14:49:06+00:00",
        "updated_at": "2021-02-03T06:19:53+00:00",
        "closed_at": "2021-02-03T06:19:53+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 448,
        "title": "[QUESTION] Support for ConvLM wav2letter Language models",
        "body": "Is it possibile to replace KenLM with ConvLM (wav2letter) pretrained models? They provide both new KenLM ngram based models (trained on WJS) and char based ConvLM models. Pretrained are in the w2l binary serialized format and are available [here](https://github.com/facebookresearch/wav2letter/blob/971e7befdc610d8e58faa2810886d395a12c1a46/recipes/models/lexicon_free/wsj/README.md)\r\n\r\nThank you.",
        "state": "closed",
        "user": "loretoparisi",
        "closed_by": "zh794390558",
        "created_at": "2020-05-05T10:27:37+00:00",
        "updated_at": "2021-05-12T05:04:34+00:00",
        "closed_at": "2021-05-12T05:04:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 446,
        "title": "Segmentation Fault error for large wav files",
        "body": "I'm testing wav files larger than 5 minutes, it fails with the following error:\r\n```\r\n\r\n python infer.py --lang_model_path models/common_crawl_00.prune01111.trie.klm \r\n--vocab_path models/baidu_en8k/vocab.txt --model_path models/baidu_en8k/ \r\n--mean_std_path models/baidu_en8k/mean_std.npz \r\n--use_gpu False --use_gru True --share_rnn_weights False --rnn_layer_size 1024\r\n\r\n\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: data/librispeech/manifest.dev-clean\r\nlang_model_path: models/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: models/baidu_en8k/mean_std.npz\r\nmodel_path: models/baidu_en8k/\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: models/baidu_en8k/vocab.txt\r\n------------------------------------------------\r\n/usr/local/lib/python2.7/dist-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n[INFO 2020-04-21 13:00:27,021 model.py:475] begin to initialize the external scorer for decoding\r\n[INFO 2020-04-21 13:00:43,513 model.py:485] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2020-04-21 13:00:43,813 model.py:486] end initializing scorer\r\n[INFO 2020-04-21 13:00:43,813 infer.py:121] start inference ...\r\nfinish initing model from pretrained params from models/baidu_en8k/\r\nW0421 13:00:54.503552 28983 init.cc:212] *** Aborted at 1587474054 (unix time) try \"date -d @1587474054\" if you are using GNU date ***\r\nW0421 13:00:54.505206 28983 init.cc:212] PC: @                0x0 (unknown)\r\nW0421 13:00:54.505419 28983 init.cc:212] *** SIGSEGV (@0x7f33d58814e0) received by PID 28983 (TID 0x7f3cb9e26700) from PID 18446744072997049568; stack trace: ***\r\nW0421 13:00:54.506572 28983 init.cc:212]     @     0x7f3cb9a05390 (unknown)\r\nW0421 13:00:54.509375 28983 init.cc:212]     @     0x7f3c7d28b850 paddle::operators::math::Im2ColFunctor<>::operator()()\r\nW0421 13:00:54.511279 28983 init.cc:212]     @     0x7f3c7c235e07 paddle::operators::GemmConvKernel<>::Compute()\r\nW0421 13:00:54.513412 28983 init.cc:212]     @     0x7f3c7c236483 _ZNSt17_Function_handlerIFvRKN6paddle9framework16ExecutionContextEEZNKS1_24OpKernelRegistrarFunctorINS0_8platform8CPUPlaceELb0ELm0EINS0_9operators14GemmConvKernelINS7_16CPUDeviceContextEfEENSA_ISB_dEEEEclEPKcSG_iEUlS4_E_E9_M_invokeERKSt9_Any_dataS4_\r\nW0421 13:00:54.516258 28983 init.cc:212]     @     0x7f3c7d5a653b paddle::framework::OperatorWithKernel::RunImpl()\r\nW0421 13:00:54.520184 28983 init.cc:212]     @     0x7f3c7d5a6ec1 paddle::framework::OperatorWithKernel::RunImpl()\r\nW0421 13:00:54.521590 28983 init.cc:212]     @     0x7f3c7d5a1a04 paddle::framework::OperatorBase::Run()\r\nW0421 13:00:54.525557 28983 init.cc:212]     @     0x7f3c7c007656 paddle::framework::Executor::RunPreparedContext()\r\nW0421 13:00:54.527557 28983 init.cc:212]     @     0x7f3c7c00a8ff paddle::framework::Executor::Run()\r\nW0421 13:00:54.527833 28983 init.cc:212]     @     0x7f3c7be5835d _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL22pybind11_init_core_avxERNS_6moduleEEUlRNS2_9framework8ExecutorERKNS6_11ProgramDescEPNS6_5ScopeEibbRKSt6vectorISsSaISsEEE101_vIS8_SB_SD_ibbSI_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES10_\r\nW0421 13:00:54.529031 28983 init.cc:212]     @     0x7f3c7be9cb36 pybind11::cpp_function::dispatcher()\r\nW0421 13:00:54.529223 28983 init.cc:212]     @           0x4c5cd6 PyEval_EvalFrameEx\r\nW0421 13:00:54.529346 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.529479 28983 init.cc:212]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0421 13:00:54.529592 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.529722 28983 init.cc:212]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0421 13:00:54.529836 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.529976 28983 init.cc:212]     @           0x4c1e32 PyEval_EvalFrameEx\r\nW0421 13:00:54.530107 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.530254 28983 init.cc:212]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0421 13:00:54.530375 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.530506 28983 init.cc:212]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0421 13:00:54.530620 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.530750 28983 init.cc:212]     @           0x4c2418 PyEval_EvalFrameEx\r\nW0421 13:00:54.530864 28983 init.cc:212]     @           0x4ba506 PyEval_EvalCodeEx\r\nW0421 13:00:54.531015 28983 init.cc:212]     @           0x4ea9ef (unknown)\r\nW0421 13:00:54.531126 28983 init.cc:212]     @           0x4e56a2 PyRun_FileExFlags\r\nW0421 13:00:54.531251 28983 init.cc:212]     @           0x4e3f56 PyRun_SimpleFileExFlags\r\nW0421 13:00:54.531373 28983 init.cc:212]     @           0x493abe Py_Main\r\nW0421 13:00:54.532829 28983 init.cc:212]     @     0x7f3cb964a830 __libc_start_main\r\nW0421 13:00:54.532968 28983 init.cc:212]     @           0x493489 _start\r\nW0421 13:00:54.534155 28983 init.cc:212]     @                0x0 (unknown)\r\nSegmentation fault\r\n\r\n```",
        "state": "closed",
        "user": "purijs",
        "closed_by": "zh794390558",
        "created_at": "2020-04-21T13:05:26+00:00",
        "updated_at": "2021-02-03T06:00:32+00:00",
        "closed_at": "2021-02-03T06:00:32+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 451,
        "title": "How to calculate FLOP count?",
        "body": "Hi,\r\n\r\nI am curious to know that how can we count the number of flops. Like TensorFlow has `tf.profiler.ProfileOptionBuilder.float_operation`, does there exists something similar here.",
        "state": "closed",
        "user": "guptakvgaurav",
        "closed_by": "zh794390558",
        "created_at": "2020-05-15T18:28:54+00:00",
        "updated_at": "2021-05-12T05:03:49+00:00",
        "closed_at": "2021-05-12T05:03:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 447,
        "title": "异步数据读取和处理效率不高，导致GPU利用率较低",
        "body": "问题描述：\r\n试用的代码是paddlepaddle开源的deepspeech2: https://github.com/PaddlePaddle/DeepSpeech\r\n\r\n硬件环境：paddlepaddle-1.6, 4块GPU-v100, CPU 32core\r\n\r\n代码里面使用的是异步数据读取：\r\n\r\nreader = fluid.io.DataLoader.from_generator(\r\nfeed_list=inputs,\r\ncapacity=64,\r\niterable=False,\r\nuse_double_buffer=True)\r\n\r\n遇到的问题：\r\nbatch_size=64, 4块GPU-v100训练的时候，gpu利用率不到1%\r\n自己排查了io利用率不到20%，磁盘为SSD，cpu只有1-2个core用起来了，其它的30个cpu core都是空闲。\r\n根据paddlepaddle文档\r\n(https://www.paddlepaddle.org.cn/documentation/docs/en//advanced_guide/performance_improving/singlenode_training_improving/training_best_practice.html) 提示设置FLAGS_reader_queue_speed_test_mode，关闭数据读取和预处理，纯测试GPU利用率稳定在90%以上，自行排查下来瓶颈应该在异步数据读取和预处理\r\n\r\n求帮忙解答。",
        "state": "closed",
        "user": "yangyangHu",
        "closed_by": "zh794390558",
        "created_at": "2020-04-28T03:45:54+00:00",
        "updated_at": "2021-02-03T06:24:30+00:00",
        "closed_at": "2021-02-03T06:24:29+00:00",
        "comments_count": [
            "AIpioneer",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 450,
        "title": "加载预训练模型后，报RuntimeError: Shape not matching",
        "body": "paddlepaddle版本：1.7\r\n使用baidu_cn1.2k_model_fluid作为预训练模型\r\n数据为16k的wav\r\nmean_std.npz和vocab.txt是为自己生成的\r\n\r\n参数：\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 16\r\ndev_manifest: data/swd/16k/manifest.dev\r\ninit_from_pretrained_model: models/baidu_cn1.2k_model_fluid/\r\nis_local: True\r\nlearning_rate: 0.0005\r\nmax_duration: 15.0\r\nmean_std_path: data/swd/16k/mean_std.npz\r\nmin_duration: 0.9\r\nnum_conv_layers: 2\r\nnum_epoch: 50\r\nnum_iter_print: 100\r\nnum_rnn_layers: 3\r\nnum_samples: 51000\r\noutput_model_dir: ./checkpoints/swd\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: False\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: False\r\ntrain_manifest: data/swd/16k/manifest.train\r\nuse_gpu: True\r\nuse_gru: True\r\nuse_sortagrad: True\r\nvocab_path: data/swd/16k/vocab.txt\r\n\r\n\r\n\r\n最后报：\r\nRuntimeError: Shape not matching: the Program requires a parameter with a shape of ((4096L, 1133L)), while the loaded parameter (namely [ layer_5_fc_weight ]) has a shape of  ((4096, 5304)).\r\n",
        "state": "closed",
        "user": "gezimonkey",
        "closed_by": "zh794390558",
        "created_at": "2020-05-13T08:33:23+00:00",
        "updated_at": "2021-02-03T06:26:52+00:00",
        "closed_at": "2021-02-03T06:26:52+00:00",
        "comments_count": [
            "lfchener",
            "gezimonkey",
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 452,
        "title": "请问如何直接预测自己的录音，将录音转成文本",
        "body": "请问如何直接预测自己的录音，将录音转成文本？谢谢解答，有提供相应的脚本吗？",
        "state": "closed",
        "user": "duan348733684",
        "closed_by": "zh794390558",
        "created_at": "2020-05-17T13:23:04+00:00",
        "updated_at": "2021-02-03T07:07:21+00:00",
        "closed_at": "2021-02-03T07:07:21+00:00",
        "comments_count": [
            "xixiaoyao",
            "lfchener",
            "duan348733684",
            "duan348733684",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 453,
        "title": "运行 python infer.py 时报C++的错?",
        "body": "Traceback (most recent call last):\r\n  File \"infer.py\", line 154, in <module>\r\n    main()\r\n  File \"infer.py\", line 150, in main\r\n    infer()\r\n  File \"infer.py\", line 122, in infer\r\n    vocab_list)\r\n  File \"/apps/users/dbc/workspace/DeepSpeech/model_utils/model.py\", line 478, in init_ext_scorer\r\n    language_model_path, vocab_list)\r\n  File \"/apps/users/dbc/workspace/DeepSpeech/decoders/swig_wrapper.py\", line 23, in __init__\r\n    swig_decoders.Scorer.__init__(self, alpha, beta, model_path, vocabulary)\r\n  File \"/apps/users/dbc/py3/lib/python3.7/site-packages/swig_decoders-1.1-py3.7-linux-x86_64.egg/swig_decoders.py\", line 1269, in __init__\r\n    this = _swig_decoders.new_Scorer(alpha, beta, lm_path, vocabulary)\r\nTypeError: in method 'new_Scorer', argument 4 of type 'std::vector< std::string,std::allocator< std::string > > const &'\r\n\r\n请问下在 运行 python infer.py 时报这个错是什么意思啊？完全看不懂",
        "state": "closed",
        "user": "duan348733684",
        "closed_by": "duan348733684",
        "created_at": "2020-05-18T06:09:48+00:00",
        "updated_at": "2020-08-10T14:10:27+00:00",
        "closed_at": "2020-05-20T06:09:19+00:00",
        "comments_count": [
            "artinegi1607",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 454,
        "title": "TypeError: The data type of 'length' in fluid.layers.sequence_unpad must be ['int64'], but received float32. ",
        "body": "运行 python infer.py 时，出现下面问题，请大佬们帮忙看下\r\n\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/duanchao/DeepSpeech/model_utils/model.py\", line 402, in infer_batch_probs\r\n    feeder, log_probs, _ = self.create_network(is_infer=True)\r\n  File \"/home/duanchao/DeepSpeech/model_utils/model.py\", line 145, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/home/duanchao/DeepSpeech/model_utils/network.py\", line 427, in deep_speech_v2_network\r\n    share_rnn_weights=share_rnn_weights)\r\n  File \"/home/duanchao/DeepSpeech/model_utils/network.py\", line 359, in rnn_group\r\n    share_weights=share_rnn_weights)\r\n  File \"/home/duanchao/DeepSpeech/model_utils/network.py\", line 196, in bidirectional_simple_rnn_bn_layer\r\n    forward_rnn = fluid.layers.sequence_unpad(x=forward_rnn, length=length)\r\n  File \"/home/duanchao/.local/lib/python2.7/site-packages/paddle/fluid/layers/sequence_lod.py\", line 1039, in sequence_unpad\r\n    'fluid.layers.sequence_unpad')\r\n  File \"/home/duanchao/.local/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 81, in check_variable_and_dtype\r\n    check_dtype(input.dtype, input_name, expected_dtype, op_name, extra_message)\r\n  File \"/home/duanchao/.local/lib/python2.7/site-packages/paddle/fluid/data_feeder.py\", line 116, in check_dtype\r\n    extra_message))\r\nTypeError: The data type of 'length' in fluid.layers.sequence_unpad must be ['int64'], but received float32.",
        "state": "closed",
        "user": "duan348733684",
        "closed_by": "zh794390558",
        "created_at": "2020-05-19T11:55:56+00:00",
        "updated_at": "2021-05-12T05:03:25+00:00",
        "closed_at": "2021-05-12T05:03:25+00:00",
        "comments_count": [
            "duan348733684",
            "lfchener",
            "shoegazerstella"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 457,
        "title": "examples/baidu_en8k/run_test_golden.sh 出錯",
        "body": "運行run_test_golden.sh會出現下列問題\r\n\r\ntest.py: error: unrecognized arguments: --num_proc_data=8\r\nFailed in evaluation!\r\n\r\n請問此問題要如何解決?感謝",
        "state": "closed",
        "user": "ssteven502tw",
        "closed_by": "zh794390558",
        "created_at": "2020-05-28T10:26:33+00:00",
        "updated_at": "2021-03-03T07:04:41+00:00",
        "closed_at": "2021-03-03T07:04:41+00:00",
        "comments_count": [
            "gekelly"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 456,
        "title": "请问大家都是怎么设置自己的参数的？遇到梯度爆炸大家都调整了什么呢？",
        "body": "",
        "state": "closed",
        "user": "ljssssss",
        "closed_by": "zh794390558",
        "created_at": "2020-05-28T09:08:51+00:00",
        "updated_at": "2021-03-03T07:05:30+00:00",
        "closed_at": "2021-03-03T07:05:29+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 458,
        "title": "operator < conv2d > error",
        "body": "when I try this example/tiny/run_train.py, I got this cuda error in the test stage, while it is ok in train stage, why? can somebody help me? \r\n\r\n\r\nPython2.7 \r\nPaddlePaddle=1.8.0.post107\r\n\r\n\r\n## The error was: \r\n\r\n3f93d4eb8892 /DeepSpeech/examples/tiny {develop} bash run_train.sh                                                                                                                                                                                                          \r\n\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script                                                                                                                                                                                                      \r\n\r\n\\\\-----------  Configuration Arguments -----------                                                                                                                                                                                                                              \r\n\r\naugment_conf_path: conf/augmentation.config                                                                                                                                                                                                                                   \r\nbatch_size: 4                                                                                                                                                                                                                                                                 \r\ndev_manifest: data/tiny/manifest.tiny                                                                                                                                                                                                                                         \r\ninit_from_pretrained_model: None                                                                                                                                                                                                                                              \r\nis_local: 1                                                                                                                                                                                                                                                                   \r\nlearning_rate: 1e-05                                                                                                                                                                                                                                                          \r\nmax_duration: 27.0                                                                                                                                                                                                                                                            \r\nmean_std_path: data/tiny/mean_std.npz                                                                                                                                                                                                                                         \r\nmin_duration: 0.0                                                                                                                                                                                                                                                             \r\nnum_conv_layers: 2                                                                                                                                                                                                                                                            \r\nnum_epoch: 20                                                                                                                                                                                                                                                                 \r\nnum_iter_print: 1                                                                                                                                                                                                                                                             \r\nnum_rnn_layers: 3                                                                                                                                                                                                                                                             \r\nnum_samples: 64                                                                                                                                                                                                                                                               \r\noutput_model_dir: ./checkpoints/tiny                                                                                                                                                                                                                                          \r\nrnn_layer_size: 2048                                                                                                                                                                                                                                                          \r\nsave_epoch: 1                                                                                                                                                                                                                                                                 \r\nshare_rnn_weights: 1                                                                                                                                                                                                                                                          \r\nshuffle_method: batch_shuffle_clipped                                                                                                                                                                                                                                         \r\nspecgram_type: linear                                                                                                                                                                                                                                                         \r\ntest_off: 0                                                                                                                                                                                                                                                                   \r\ntrain_manifest: data/tiny/manifest.tiny                                                                                                                                                                                                                                       \r\nuse_gpu: 1                                                                                                                                                                                                                                                                    \r\nuse_gru: 0                                                                                                                                                                                                                                                                    \r\nuse_sortagrad: 1                                                                                                                                                                                                                                                              \r\nvocab_path: data/tiny/vocab.txt                                                                                                                                                                                                                                               \r\n\\\\------------------------------------------------         \r\n                                                                                                                                                                                                                     \r\nW0602 03:40:12.703999   393 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0                                                                                                                           \r\nW0602 03:40:12.706190   393 device_context.cc:260] device: 0, cuDNN Version: 7.5.                                                                                                                                                                                             \r\nW0602 03:40:13.205840   393 device_context.h:155] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version$\r\nW0602 03:40:15.150069   393 fuse_all_reduce_op_pass.cc:74] Find all_reduce operators: 29. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 29.                                                          \r\nepoch: 0, batch: 0, train loss: 161.631409                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 1, train loss: 250.135147                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 2, train loss: 328.794434                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 3, train loss: 318.444031                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 4, train loss: 342.752563                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 5, train loss: 407.027008                                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                                                                              \r\nepoch: 0, batch: 6, train loss: 512.739380\r\n\r\nepoch: 0, batch: 7, train loss: 706.538940\r\n\r\n\r\n----------Begin test...\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 366, in train\r\n    fetch_list=[ctc_loss])\r\n  File \"/DeepSpeech/model_utils/model.py\", line 217, in test\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n7   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n8   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n9   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 2928, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"/DeepSpeech/model_utils/network.py\", line 47, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"/DeepSpeech/model_utils/network.py\", line 299, in conv_group\r\n    name='layer_0', )\r\n  File \"/DeepSpeech/model_utils/network.py\", line 408, in deep_speech_v2_network\r\n    masks=masks)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 145, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 296, in train\r\n    test_reader, _, ctc_loss = self.create_network()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  Cudnn error, CUDNN_STATUS_EXECUTION_FAILED  at (/paddle/paddle/fluid/operators/conv_cudnn_op.cu:300)\r\n  [operator < conv2d > error]\r\nFailed in training!",
        "state": "closed",
        "user": "hawkcoder",
        "closed_by": "zh794390558",
        "created_at": "2020-06-02T03:52:21+00:00",
        "updated_at": "2021-03-26T11:36:51+00:00",
        "closed_at": "2021-03-26T11:36:51+00:00",
        "comments_count": [
            "artinegi1607",
            "lfchener",
            "artinegi1607",
            "artinegi1607",
            "a01163125",
            "changhengyi",
            "changhengyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 455,
        "title": "InvalidArgumentError: Cannot parse tensor desc   [Hint: Expected desc.ParseFromArray(buf.get(), size) == true, but received desc.ParseFromArray(buf.get(), size):0 != true:1.] at (/paddle/paddle/fluid/framework/tensor_util.cc:527)   [operator < load_combine > error]",
        "body": "When i try to run `demo_server.py` or `infer.py` i get the above error. Here is the complete traceback. I am using `paddlepaddle==1.8.0` in CPU.\r\n\r\n`[libprotobuf ERROR /paddle/build/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type \"paddle.framework.proto.VarType.TensorDesc\" because it is missing required fields: data_type\r\n/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"demo_server.py\", line 238, in <module>\r\n    main()\r\n  File \"demo_server.py\", line 234, in main\r\n    start_server()\r\n  File \"demo_server.py\", line 219, in start_server\r\n    num_test_cases=1)\r\n  File \"demo_server.py\", line 136, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/Desktop/baidu/DeepSpeech/deploy/../model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/home/Desktop/baidu/DeepSpeech/deploy/../model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 876, in load_params\r\n    filename=filename)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 750, in load_vars\r\n    filename=filename)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 804, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&)\r\n3   paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&)\r\n4   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, paddle::platform::Place const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const\r\n5   paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CPUDeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n8   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n11  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n12  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 802, in load_vars\r\n    'model_from_memory': vars_from_memory\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 750, in load_vars\r\n    filename=filename)\r\n  File \"/home/miniconda3/envs/baidu/lib/python2.7/site-packages/paddle/fluid/io.py\", line 876, in load_params\r\n    filename=filename)\r\n  File \"/home/Desktop/baidu/DeepSpeech/deploy/../model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/Desktop/baidu/DeepSpeech/deploy/../model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"demo_server.py\", line 136, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"demo_server.py\", line 219, in start_server\r\n    num_test_cases=1)\r\n  File \"demo_server.py\", line 234, in main\r\n    start_server()\r\n  File \"demo_server.py\", line 238, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Cannot parse tensor desc\r\n  [Hint: Expected desc.ParseFromArray(buf.get(), size) == true, but received desc.ParseFromArray(buf.get(), size):0 != true:1.] at (/paddle/paddle/fluid/framework/tensor_util.cc:527)\r\n  [operator < load_combine > error]\r\n`",
        "state": "closed",
        "user": "libraster",
        "closed_by": "libraster",
        "created_at": "2020-05-25T15:04:26+00:00",
        "updated_at": "2020-12-08T19:11:19+00:00",
        "closed_at": "2020-05-26T06:40:05+00:00",
        "comments_count": [
            "tingyang01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 459,
        "title": "Japanese Language model is giving segmentation fault",
        "body": "Running a Japanese Language model is giving segmentation fault. I am getting the below error:-\r\n\r\nW0610 14:25:22.137501 24808 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0610 14:25:22.137524 24808 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0610 14:25:22.137532 24808 init.cc:221] The detail failure signal is:\r\n\r\nW0610 14:25:22.137540 24808 init.cc:224] *** Aborted at 1591779322 (unix time) try \"date -d @1591779322\" if you are using GNU date ***\r\nW0610 14:25:22.138669 24808 init.cc:224] PC: @                0x0 (unknown)\r\nW0610 14:25:22.138871 24808 init.cc:224] *** SIGSEGV (@0x10) received by PID 24795 (TID 0x7f4890e63700) from PID 16; stack trace: ***\r\nW0610 14:25:22.140156 24808 init.cc:224]     @     0x7f489931df20 (unknown)\r\nW0610 14:25:22.140625 24808 init.cc:224]     @     0x7f4863a76576 PathTrie::get_path_trie()\r\nW0610 14:25:22.140940 24808 init.cc:224]     @     0x7f48639b430d ctc_beam_search_decoder()\r\nW0610 14:25:22.141218 24808 init.cc:224]     @     0x7f48639b5cee _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultISt6vectorISt4pairIdNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEESaISG_EEEES3_EZNS1_11_Task_stateISt5_BindIFPFSI_RKS8_IS8_IdSaIdEESaISO_EERKS8_ISF_SaISF_EEmdmP6ScorerESQ_SU_mdmSY_EESaIiEFSI_vEE6_M_runEvEUlvE_SI_EEE9_M_invokeERKSt9_Any_data\r\nW0610 14:25:22.141551 24808 init.cc:224]     @     0x7f48639b5629 std::__future_base::_State_baseV2::_M_do_set()\r\nW0610 14:25:22.142618 24808 init.cc:224]     @     0x7f48990cf827 __pthread_once_slow\r\nW0610 14:25:22.142915 24808 init.cc:224]     @     0x7f48639b648c _ZNSt17_Function_handlerIFvvEZN10ThreadPool7enqueueIRFSt6vectorISt4pairIdNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEESaISB_EERKS3_IS3_IdSaIdEESaISF_EERKS3_ISA_SaISA_EEmdmP6ScorerEJSJ_SN_RmRdSS_RSP_EEESt6futureINSt9result_ofIFT_DpT0_EE4typeEEOSX_DpOSY_EUlvE_E9_M_invokeERKSt9_Any_data\r\nW0610 14:25:22.143095 24808 init.cc:224]     @     0x7f48639b60e0 _ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN10ThreadPoolC4EmEUlvE_EEEEE6_M_runEv\r\nW0610 14:25:22.144214 24808 init.cc:224]     @     0x7f48804ce6ef (unknown)\r\nW0610 14:25:22.145277 24808 init.cc:224]     @     0x7f48990c76db start_thread\r\nW0610 14:25:22.146253 24808 init.cc:224]     @     0x7f489940088f clone\r\nW0610 14:25:22.147152 24808 init.cc:224]     @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\n\r\n\r\nAm I missing anything. Any help would be appreciated.\r\n\r\n",
        "state": "closed",
        "user": "artinegi1607",
        "closed_by": "artinegi1607",
        "created_at": "2020-06-10T08:57:43+00:00",
        "updated_at": "2020-07-02T10:47:17+00:00",
        "closed_at": "2020-07-02T10:47:17+00:00",
        "comments_count": [
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 460,
        "title": "Multiple issues with the docker image, cuDNN, Failed in inference!: 'module' object has no attribute 'RNNCell'",
        "body": "Hi,\r\nAfter running the docker file i tried: \r\n``\r\n/DeepSpeech/examples/aishell {develop} ./sh run_infer.sh\r\n``\r\nWhich results in this error: \r\n``\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 14, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"/DeepSpeech/model_utils/model.py\", line 23, in <module>\r\n    from model_utils.network import deep_speech_v2_network\r\n  File \"/DeepSpeech/model_utils/network.py\", line 62, in <module>\r\n    class RNNCell(fluid.layers.RNNCell):\r\nAttributeError: 'module' object has no attribute 'RNNCell'\r\nFailed in inference!\r\n``\r\nThen I found that I have to upgrade paddle inside the docker file which is strange. So i did:\r\n``\r\nwget https://nero-mirror.stanford.edu/pypi/web/packages/5f/b0/769cd78f5fdc9de41d760512750e70ace87caea54502882d0818e4b3ce1d/paddlepaddle_gpu-1.6.2.post107-cp27-cp27mu-manylinux1_x86_64.whl#sha256=e09b0ccf009c14984676ea535b94e5bc1b05e6ce3f80c332c464fcd1474a6067\r\n\r\npip install paddlepaddle_gpu-1.6.2.post107-cp27-cp27mu-manylinux1_x86_64.whl\r\n``\r\nAfter updating paddle to the recommended version:\r\n``\r\nInstalling collected packages: paddlepaddle-gpu\r\n  Found existing installation: paddlepaddle-gpu 0.0.0\r\n    Uninstalling paddlepaddle-gpu-0.0.0:\r\n      Successfully uninstalled paddlepaddle-gpu-0.0.0\r\nSuccessfully installed paddlepaddle-gpu-1.6.2.post107\r\n``\r\nI run sh infer.sh (aishell):\r\n\r\n``\r\nλ e535b121260f /DeepSpeech/examples/aishell {develop} sh run_infer.sh\r\nDownload language model ...\r\n./zh_giga.no_cna_cmn.prune01244.klm already exists, download skipped.\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/aishell/manifest.test\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: data/aishell/mean_std.npz\r\nmodel_path: checkpoints/aishell/step_final\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\n2020-06-17 05:58:41,570-INFO: begin to initialize the external scorer for decoding\r\n2020-06-17 05:58:41,657-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-06-17 05:58:41,657-INFO: end initializing scorer\r\n2020-06-17 05:58:41,657-INFO: start inference ...\r\nW0617 05:58:43.268769   184 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0617 05:58:43.272881   184 device_context.cc:244] device: 0, cuDNN Version: 7.5.\r\nW0617 05:58:43.272904   184 device_context.cc:270] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\ncheckpoints/aishell/step_final\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 155, in init_from_pretrained_model\r\n    raise Warning(\"The pretrained params do not exist.\")\r\nWarning: The pretrained params do not exist.\r\nFailed in inference!\r\n``\r\n\r\nI do not understand, the docker is not working with the paddle version + cuDNN version that you recommended or is this another error?\r\n\r\nThanks! \r\n\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2020-06-17T06:00:39+00:00",
        "updated_at": "2021-05-12T05:03:57+00:00",
        "closed_at": "2021-05-12T05:03:57+00:00",
        "comments_count": [
            "lfchener",
            "danielkope"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 461,
        "title": " The pretrained params do not exist. Failed in inference!",
        "body": "Hi,\r\n\r\n``\r\n[INFO 2020-06-17 08:27:41,059 model.py:474] begin to initialize the external scorer for decoding\r\n[INFO 2020-06-17 08:27:51,392 model.py:484] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2020-06-17 08:27:51,616 model.py:485] end initializing scorer\r\n[INFO 2020-06-17 08:27:51,617 infer.py:121] start inference ...\r\nW0617 08:27:52.673171   330 device_context.cc:235] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0617 08:27:52.678908   330 device_context.cc:243] device: 0, cuDNN Version: 7.5.\r\n./checkpoints/tiny/step_final\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 155, in init_from_pretrained_model\r\n    raise Warning(\"The pretrained params do not exist.\")\r\nWarning: The pretrained params do not exist.\r\nFailed in inference!\r\n``\r\n\r\nWhat am I missing here? ",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2020-06-17T08:32:51+00:00",
        "updated_at": "2022-03-23T15:50:32+00:00",
        "closed_at": "2021-05-12T05:03:41+00:00",
        "comments_count": [
            "ParmpalSinghGill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 463,
        "title": "Infer for a single WAV file not using  data_generator.batch_reader_creator",
        "body": "Is there an example for loading a single WAV file and inferring on that? \r\n\r\nThanks ",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2020-06-17T11:37:07+00:00",
        "updated_at": "2021-05-12T05:03:33+00:00",
        "closed_at": "2021-05-12T05:03:33+00:00",
        "comments_count": [
            "lfchener",
            "YanqiangWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 462,
        "title": "tiny sh run_train.sh inside docker: TypeError: __init__() got an unexpected keyword argument 'grad_clip'",
        "body": "Hello,\r\nI updated paddle, but run_train.sh results in error:\r\nwget https://nero-mirror.stanford.edu/pypi/web/packages/5f/b0/769cd78f5fdc9de41d760512750e70ace87caea54502882d0818e4b3ce1d/paddlepaddle_gpu-1.6.2.post107-cp27-cp27mu-manyli$\r\n\r\npip install paddlepaddle_gpu-1.6.2.post107-cp27-cp27mu-manylinux1_x86_64.whl\r\n\r\n``\r\nλ 77050b25daa6 /DeepSpeech/examples/tiny {develop} sh run_train.sh\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 4\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 20\r\nnum_iter_print: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 64\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 290, in train\r\n    clip_norm=gradient_clipping))\r\nTypeError: __init__() got an unexpected keyword argument 'grad_clip'\r\nFailed in training!\r\n``\r\n\r\nThanks \r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": "zh794390558",
        "created_at": "2020-06-17T08:37:35+00:00",
        "updated_at": "2021-05-12T05:02:36+00:00",
        "closed_at": "2021-05-12T05:02:36+00:00",
        "comments_count": [
            "lfchener",
            "ghost",
            "lfchener",
            "ghost",
            "plseal"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 468,
        "title": "Error about “RuntimeError: MD5 checksum failed”",
        "body": "When I run examples/aishell/run_data.sh，some error happen,the error log is as follow\r\n\r\n> MD5 Chesksum ./dataset/aishell/data_aishell.tgz ...\r\nTraceback (most recent call last):\r\n  File \"data/aishell/aishell.py\", line 110, in <module>\r\n    main()\r\n  File \"data/aishell/aishell.py\", line 106, in main\r\n    manifest_path=args.manifest_prefix)\r\n  File \"data/aishell/aishell.py\", line 85, in prepare_dataset\r\n    filepath = download(url, md5sum, target_dir)\r\n  File \"/DeepSpeech/data_utils/utility.py\", line 73, in download\r\n    raise RuntimeError(\"MD5 checksum failed.\")\r\nRuntimeError: MD5 checksum failed.\r\nPrepare Aishell failed. Terminated.\r\n\r\nWhat should I do to solve this problem? Thanks",
        "state": "closed",
        "user": "ilove-Moretz",
        "closed_by": "ilove-Moretz",
        "created_at": "2020-06-28T08:16:08+00:00",
        "updated_at": "2020-07-02T02:16:12+00:00",
        "closed_at": "2020-07-02T02:16:12+00:00",
        "comments_count": [
            "willthefrog",
            "lfchener",
            "ilove-Moretz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 465,
        "title": "decoders/swig的 setup.sh下载 kenlm的git地址没了吗 ",
        "body": " https://github.com/luotao1/kenlm.git  我在家里访问这个地址 一直是404.。。。怎么办  本人新手，是作者删除了 还是我被墙了 ",
        "state": "closed",
        "user": "lgd123",
        "closed_by": "lfchener",
        "created_at": "2020-06-26T16:28:00+00:00",
        "updated_at": "2020-09-21T03:08:19+00:00",
        "closed_at": "2020-09-21T03:08:19+00:00",
        "comments_count": [
            "zhupengyang",
            "lgd123",
            "zhupengyang",
            "Aionrichman",
            "rinjac",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 466,
        "title": "安装报错了。。",
        "body": "In file included from scorer.h:14,\r\n                 from decoders_wrap.cxx:3171:\r\npath_trie.h:10:10: fatal error: fst/fstlib.h: No such file or directory\r\n   10 | #include \"fst/fstlib.h\"\r\n      |          ^~~~~~~~~~~~~~\r\ncompilation terminated.\r\nx86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-8kFkPd/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python2.7 -c decoder_utils.cpp -o build/temp.linux-x86_64-2.7/decoder_utils.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11\r\nIn file included from decoder_utils.cpp:1:\r\ndecoder_utils.h:5:10: fatal error: fst/log.h: No such file or directory\r\n    5 | #include \"fst/log.h\"\r\n      |          ^~~~~~~~~~~\r\ncompilation terminated.\r\nx86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-8kFkPd/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python2.7 -c path_trie.cpp -o build/temp.linux-x86_64-2.7/path_trie.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11\r\nIn file included from scorer.h:14,\r\n                 from scorer.cpp:1:\r\npath_trie.h:10:10: fatal error: fst/fstlib.h: No such file or directory\r\n   10 | #include \"fst/fstlib.h\"\r\n      |          ^~~~~~~~~~~~~~\r\ncompilation terminated.\r\nx86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-8kFkPd/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python2.7 -c ctc_beam_search_decoder.cpp -o build/temp.linux-x86_64-2.7/ctc_beam_search_decoder.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11\r\nIn file included from path_trie.cpp:1:\r\npath_trie.h:10:10: fatal error: fst/fstlib.h: No such file or directory\r\n   10 | #include \"fst/fstlib.h\"\r\n      |          ^~~~~~~~~~~~~~\r\ncompilation terminated.\r\nx86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-8kFkPd/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I. -Ikenlm -Iopenfst-1.6.3/src/include -IThreadPool -I/usr/include/python2.7 -c ctc_greedy_decoder.cpp -o build/temp.linux-x86_64-2.7/ctc_greedy_decoder.o -O3 -DNDEBUG -DKENLM_MAX_ORDER=6 -std=c++11\r\nIn file included from scorer.h:14,\r\n                 from ctc_beam_search_decoder.h:8,\r\n                 from ctc_beam_search_decoder.cpp:1:\r\npath_trie.h:10:10: fatal error: fst/fstlib.h: No such file or directory\r\n   10 | #include \"fst/fstlib.h\"\r\n      |          ^~~~~~~~~~~~~~\r\ncompilation terminated.\r\nIn file included from ctc_greedy_decoder.cpp:2:\r\ndecoder_utils.h:5:10: fatal error: fst/log.h: No such file or directory\r\n    5 | #include \"fst/log.h\"\r\n      |          ^~~~~~~~~~~\r\ncompilation terminated.\r\nerror: command 'x86_64-linux-gnu-gcc' failed with exit status 1\r\n",
        "state": "closed",
        "user": "lgd123",
        "closed_by": "lgd123",
        "created_at": "2020-06-26T16:41:52+00:00",
        "updated_at": "2021-04-22T12:23:28+00:00",
        "closed_at": "2020-06-28T01:13:58+00:00",
        "comments_count": [
            "lgd123",
            "ExpressGit",
            "yhz5256"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 469,
        "title": "Trying to install decoder package for language model in windows",
        "body": "Can anyone guide on how to install the python decoders package on windows!\r\nI am so confused how to do it!",
        "state": "closed",
        "user": "jainal09",
        "closed_by": "jainal09",
        "created_at": "2020-07-01T00:36:31+00:00",
        "updated_at": "2020-07-01T02:50:06+00:00",
        "closed_at": "2020-07-01T02:50:06+00:00",
        "comments_count": [
            "jainal09"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 470,
        "title": "Unable to train DeepSpeech from scratch on Indian Hinglish(Mixed Hindi_English) 8khz audio data.",
        "body": "Hi,\r\n\r\nI want to train Hinglish(Mixed Hindi_English) 8khz conversation audio data  from scratch.\r\nI am getting ValueError: Input signal length=0 is too small to resample from 8000->16000.\r\n\r\nTraining Command\r\n> CUDA_VISIBLE_DEVICES=0,1 python train.py\r\n\r\nTrainig Log:\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 256\r\ndev_manifest: data/audio_data/manifest.dev-clean\r\ninit_from_pretrained_model: None\r\nis_local: True\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/audio_data/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 200\r\nnum_iter_print: 100\r\nnum_rnn_layers: 3\r\nnum_samples: 489948\r\noutput_model_dir: checkpoint_dir\r\nrnn_layer_size: 2048\r\nsave_epoch: 10\r\nshare_rnn_weights: False\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: mfcc\r\ntest_off: False\r\ntrain_manifest: data/audio_data/manifest.train-clean\r\nuse_gpu: True\r\nuse_gru: True\r\nuse_sortagrad: True\r\nvocab_path: data/audio_data/eng_vocab.txt\r\n------------------------------------------------\r\nW0702 16:43:10.574574  7779 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0702 16:43:10.577214  7779 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\nW0702 16:43:14.229719  7779 fuse_all_reduce_op_pass.cc:74] Find all_reduce operators: 38. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 38.\r\n/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/resampy/core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  if not np.issubdtype(x.dtype, np.float):\r\n2020-07-02 16:43:19,910-WARNING: Your reader has raised an exception!\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1157, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1137, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/data.py\", line 200, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/data.py\", line 279, in reader\r\n    instance[\"text\"]),\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/data.py\", line 121, in process_utterance\r\n    speech_segment, self._keep_transcription_text)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/featurizer/speech_featurizer.py\", line 76, in featurize\r\n    audio_feature = self._audio_featurizer.featurize(speech_segment)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/featurizer/audio_featurizer.py\", line 80, in featurize\r\n    audio_segment.resample(self._target_sample_rate)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/data_utils/audio.py\", line 400, in resample\r\n    self.samples, self.sample_rate, target_sample_rate, filter=filter)\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/resampy/core.py\", line 102, in resample\r\n    'resample from {}->{}'.format(x.shape[axis], sr_orig, sr_new))\r\nValueError: Input signal length=0 is too small to resample from 8000->16000\r\n\r\n/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning:\r\n\"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 144, in <module>\r\n    main()\r\n  File \"train.py\", line 140, in main\r\n    train()\r\n  File \"train.py\", line 135, in train\r\n    test_off=args.test_off)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/model_utils/model.py\", line 336, in train\r\n    return_numpy=False)\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1079, in _init_non_iterable\r\n    attrs={'drop_last': self._drop_last})\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 977, in __init__\r\n    self._init_non_iterable()\r\n  File \"/home/ubuntu/tmp/deepspeech2-venv/local/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 608, in from_generator\r\n    iterable, return_list, drop_last)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/model_utils/model.py\", line 112, in create_network\r\n    use_double_buffer=True)\r\n  File \"/home/ubuntu/drive_a/Paddlepaddle_DeepSpeech/DeepSpeech/model_utils/model.py\", line 281, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"train.py\", line 135, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 140, in main\r\n    train()\r\n  File \"train.py\", line 144, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\r\n  [operator < read > error]\r\n\r\n\r\nAnyone can help me to resolve this issue.\r\nCan I run 8khz audio on training from scratch?\r\nI am able to infer an audio(8k sample_rate) using baidu_en8k model.\r\n\r\n\r\nThanks\r\nNasim\r\n",
        "state": "closed",
        "user": "alamnasim",
        "closed_by": "alamnasim",
        "created_at": "2020-07-02T11:35:50+00:00",
        "updated_at": "2020-09-17T02:51:51+00:00",
        "closed_at": "2020-07-13T11:10:04+00:00",
        "comments_count": [
            "lfchener",
            "alamnasim",
            "alamnasim",
            "alamnasim",
            "alamnasim",
            "hieuhv94"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 471,
        "title": "Baidu Internal English Dataset",
        "body": "Where can I find Baidu Internal English Dataset, and all these data sets are clean?",
        "state": "closed",
        "user": "ssteven502tw",
        "closed_by": "zh794390558",
        "created_at": "2020-07-03T08:47:00+00:00",
        "updated_at": "2021-04-09T02:34:50+00:00",
        "closed_at": "2021-04-09T02:34:50+00:00",
        "comments_count": [
            "DannyIsFunny",
            "ssteven502tw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 472,
        "title": "ModuleNotFoundError: No module named 'swig_decoders' ",
        "body": "Traceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'swig_decoders'\r\n\r\npip3 list\r\nswig-decoders (1.1)\r\n\r\n\r\npip3 下可以看见，但是import失败",
        "state": "closed",
        "user": "ExpressGit",
        "closed_by": "lfchener",
        "created_at": "2020-07-05T07:48:04+00:00",
        "updated_at": "2020-09-21T03:11:09+00:00",
        "closed_at": "2020-09-21T03:11:09+00:00",
        "comments_count": [
            "lfchener",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 473,
        "title": "unexpected EOF",
        "body": "When I downloaded the Docker image:\r\n\r\n<pre>$ sudo nvidia-docker pull hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu\r\n</pre>\r\n\r\nI got: \r\n\r\n<pre>unexpected EOF\r\n</pre>\r\n\r\nMay I ask how to take care of it? Thank you!\r\n",
        "state": "closed",
        "user": "ML6634",
        "closed_by": "zh794390558",
        "created_at": "2020-07-05T15:08:20+00:00",
        "updated_at": "2021-02-03T05:58:25+00:00",
        "closed_at": "2021-02-03T03:59:19+00:00",
        "comments_count": [
            "lfchener",
            "ML6634",
            "ML6634",
            "zh794390558",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 476,
        "title": "执行examples中的“sh run_train.sh”出现ImportError: No module named core_noavx....(用Docker)",
        "body": "大家好，我是下载使用Docker 来跑的，执行examples中的sh run_train.sh就出现异常如下： \r\n/DeepSpeech/examples/tiny {develop} sh run_train.sh\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 9, in <module>\r\n    from model_utils.model import DeepSpeech2Model\r\n  File \"/DeepSpeech/model_utils/model.py\", line 18, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/__init__.py\", line 35, in <module>\r\n    from . import framework\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 34, in <module>\r\n    from . import core\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/core.py\", line 214, in <module>\r\n    raise e\r\nImportError: No module named core_noavx\r\nFailed in training!\r\n\r\n请问有什么方式可以解决呢？",
        "state": "closed",
        "user": "springminhcm",
        "closed_by": "springminhcm",
        "created_at": "2020-07-17T04:48:56+00:00",
        "updated_at": "2020-09-03T07:18:21+00:00",
        "closed_at": "2020-09-03T07:18:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 475,
        "title": "Is Baidu Internal English Dataset clean voice?",
        "body": "Is Baidu Internal English Dataset clean voice?\r\nDo you use the following methods in paper?\r\n(Additionally, we dynamically augment the dataset by adding unique noise every epoch with an SNR between 0dB and 30dB)",
        "state": "closed",
        "user": "ssteven502tw",
        "closed_by": "zh794390558",
        "created_at": "2020-07-13T10:06:24+00:00",
        "updated_at": "2021-05-12T05:02:05+00:00",
        "closed_at": "2021-05-12T05:02:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 474,
        "title": "baiduCN1.2k模型部署运行test脚本报错Variable's shape does not match",
        "body": "部署方式：docker\r\n已经升级了CUDA 10.0和对应的cudnn版本，测试aishell数据模型，运行run_test.sh和run_infer.sh正常\r\n现在想部署测试一下baiduCN1.2k的模型，脚本仿照example/aishell/run_infer_golden.sh脚本进行修改，将模型防放置在对应的位置后运行报错，根据错误信息，参考了[issue #382 ](https://github.com/PaddlePaddle/DeepSpeech/issues/382) 和[issue #388](https://github.com/PaddlePaddle/DeepSpeech/issues/388)，按照上述的两个issue进行配置，没有解决问题，请各位指导一下解决方案，谢谢\r\n以下是错误信息：\r\n`\r\nTraceback (most recent call last):                                                                                \r\n  File \"test.py\", line 149, in <module>                                                                           \r\n    main()                                                                                                        \r\n  File \"test.py\", line 145, in main                                                                               \r\n    evaluate()                                                                                                    \r\n  File \"test.py\", line 113, in evaluate                                                                           \r\n    feeding_dict=data_generator.feeding)                                                                          \r\n  File \"/DeepSpeech/model_utils/model.py\", line 411, in infer_batch_probs                                         \r\n    self.init_from_pretrained_model(exe, infer_program)                                                           \r\n  File \"/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model                                \r\n    filename=\"params.pdparams\")                                                                                   \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 876, in load_params                      \r\n    filename=filename)                                                                                            \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 750, in load_vars                        \r\n    filename=filename)                                                                                            \r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 819, in load_vars                        \r\n    format(orig_shape, each_var.name, new_shape))                                                                 \r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((3072L,)), whil\r\ne the loaded parameter (namely [ layer_2_forward_batch_norm_moving_mean ]) has a shape of  ((6144,)).             \r\nFailed in evaluation!`\r\nissue #388 中提到的模型不同的问题，两种模型我都尝试了，更换另一种并没有解决问题。\r\n再此，粘贴一下两种模型的结构：\r\ngithub主页下载的模型\r\n![github_model](https://user-images.githubusercontent.com/36251986/86873980-096e0a00-c112-11ea-9424-1743e337e6c0.png)\r\ngithub issue #388 的下载模型\r\n![github_issue_model](https://user-images.githubusercontent.com/36251986/86874037-2b678c80-c112-11ea-97f7-1356c66bb198.png)\r\n请各位大神与老师指导，谢谢 \r\n\r\n",
        "state": "closed",
        "user": "lujx1024",
        "closed_by": "lujx1024",
        "created_at": "2020-07-08T03:57:48+00:00",
        "updated_at": "2020-07-13T02:53:57+00:00",
        "closed_at": "2020-07-13T02:53:57+00:00",
        "comments_count": [
            "lfchener",
            "lujx1024"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 477,
        "title": "Docker pull error",
        "body": "Hi,\r\n\r\nPlease help, while downloading the docker image on client machine it gives an error.\r\n\r\n**Command:** nvidia-docker pull hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu\r\n\r\n**Error**: Error response from daemon: error unmarshalling content: invalid character '<' looking for beginning of value\r\n\r\nPlease help to fix the issue.",
        "state": "closed",
        "user": "ngk512",
        "closed_by": "zh794390558",
        "created_at": "2020-07-17T05:36:44+00:00",
        "updated_at": "2021-02-03T03:56:10+00:00",
        "closed_at": "2021-02-03T03:56:09+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 478,
        "title": "支持实时的语音识别吗？",
        "body": "",
        "state": "closed",
        "user": "ZhangXinNan",
        "closed_by": "zh794390558",
        "created_at": "2020-07-23T06:54:01+00:00",
        "updated_at": "2021-02-03T03:46:07+00:00",
        "closed_at": "2021-02-03T03:46:07+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 480,
        "title": "aishell下执行sh run_data.sh生成的manifest文件都为空，且mean_std.npz文件未生成，怎么解决？",
        "body": "aishell$ sh run_data.sh \r\nSkip downloading and unpacking. Data already exists in ./dataset/aishell.\r\nCreating manifest data/aishell/manifest ...\r\n-----------  Configuration Arguments -----------\r\ncount_threshold: 0\r\nmanifest_paths: ['data/aishell/manifest.train', 'data/aishell/manifest.dev']\r\nvocab_path: data/aishell/vocab.txt\r\n------------------------------------------------\r\n-----------  Configuration Arguments -----------\r\nmanifest_path: data/aishell/manifest.train\r\nnum_samples: 2000\r\noutput_path: data/aishell/mean_std.npz\r\nspecgram_type: linear\r\n------------------------------------------------\r\n0 2000\r\nTraceback (most recent call last):\r\n  File \"tools/compute_mean_std.py\", line 51, in <module>\r\n    main()\r\n  File \"tools/compute_mean_std.py\", line 46, in main\r\n    num_samples=args.num_samples)\r\n  File \"/home/aistudio/DeepSpeech/tools/../data_utils/normalizer.py\", line 46, in __init__\r\n    self._compute_mean_std(manifest_path, featurize_func, num_samples)\r\n  File \"/home/aistudio/DeepSpeech/tools/../data_utils/normalizer.py\", line 80, in _compute_mean_std\r\n    sampled_manifest = self._rng.sample(manifest, num_samples)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/random.py\", line 325, in sample\r\n    raise ValueError(\"sample larger than population\")\r\nValueError: sample larger than population\r\nCompute mean and stddev failed. Terminated.",
        "state": "closed",
        "user": "YuHuasong123",
        "closed_by": "zh794390558",
        "created_at": "2020-07-24T06:46:26+00:00",
        "updated_at": "2021-02-03T03:50:26+00:00",
        "closed_at": "2021-02-03T03:50:26+00:00",
        "comments_count": [
            "ayayaya420",
            "ccbptm",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 479,
        "title": "运行demo_server.py时，提示gcc 和 kenlm版本问题，请问应该安装什么版本哪？",
        "body": "2020-07-24 11:54:44,195-INFO: begin to initialize the external scorer for decoding\r\nterminate called after throwing an instance of 'lm::FormatLoadException'\r\n  what():  kenlm/lm/vocab.cc:43 in void lm::ngram::{anonymous}::ReadWords(int, lm::EnumerateVocab*, lm::WordIndex, uint64_t) threw FormatLoadException because `memcmp(check_unk, \"<unk>\", 6)'.\r\nVocabulary words are in the wrong place.  This could be because the binary file was built with stale gcc and old kenlm.  Stale gcc, including the gcc distributed with RedHat and OS X, has a bug that ignores pragma pack for template-dependent types.  New kenlm works around this, so you'll save memory but have to rebuild any binary files using the probing data structure.\r\nW0724 11:54:44.449854 10056 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0724 11:54:44.449880 10056 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0724 11:54:44.449885 10056 init.cc:221] The detail failure signal is:\r\n\r\nW0724 11:54:44.449892 10056 init.cc:224] *** Aborted at 1595562884 (unix time) try \"date -d @1595562884\" if you are using GNU date ***\r\nW0724 11:54:44.451668 10056 init.cc:224] PC: @                0x0 (unknown)\r\nW0724 11:54:44.451771 10056 init.cc:224] *** SIGABRT (@0x32100002748) received by PID 10056 (TID 0x7f0dcab5f740) from PID 10056; stack trace: ***\r\nW0724 11:54:44.453256 10056 init.cc:224]     @     0x7f0dca9225f0 (unknown)\r\nW0724 11:54:44.454828 10056 init.cc:224]     @     0x7f0dc9e72337 __GI_raise\r\nW0724 11:54:44.456319 10056 init.cc:224]     @     0x7f0dc9e73a28 __GI_abort\r\nW0724 11:54:44.457363 10056 init.cc:224]     @     0x7f0d99d2084a __gnu_cxx::__verbose_terminate_handler()\r\nW0724 11:54:44.458148 10056 init.cc:224]     @     0x7f0d99d1ef47 __cxxabiv1::__terminate()\r\nW0724 11:54:44.459126 10056 init.cc:224]     @     0x7f0d99d1ef7d std::terminate()\r\nW0724 11:54:44.460006 10056 init.cc:224]     @     0x7f0d99d1f15a __cxa_throw\r\nW0724 11:54:44.460772 10056 init.cc:224]     @     0x7f0da34ef9f6 lm::ngram::(anonymous namespace)::ReadWords()\r\nW0724 11:54:44.461920 10056 init.cc:224]     @     0x7f0da34efe91 lm::ngram::ProbingVocabulary::LoadedBinary()\r\nW0724 11:54:44.462857 10056 init.cc:224]     @     0x7f0da34c7199 lm::ngram::detail::GenericModel<>::GenericModel()\r\nW0724 11:54:44.463752 10056 init.cc:224]     @     0x7f0da34beb0b lm::ngram::LoadVirtual()\r\nW0724 11:54:44.464592 10056 init.cc:224]     @     0x7f0da35d4ecc Scorer::load_lm()\r\nW0724 11:54:44.465605 10056 init.cc:224]     @     0x7f0da35db0f1 Scorer::setup()\r\nW0724 11:54:44.466466 10056 init.cc:224]     @     0x7f0da35db245 Scorer::Scorer()\r\nW0724 11:54:44.467242 10056 init.cc:224]     @     0x7f0da35905d0 _wrap_new_Scorer\r\nW0724 11:54:44.468819 10056 init.cc:224]     @     0x7f0dcac542f4 PyEval_EvalFrameEx\r\nW0724 11:54:44.470405 10056 init.cc:224]     @     0x7f0dcac55b19 PyEval_EvalCodeEx\r\nW0724 11:54:44.471848 10056 init.cc:224]     @     0x7f0dcabde6ea function_call\r\nW0724 11:54:44.473486 10056 init.cc:224]     @     0x7f0dcabb9b83 PyObject_Call\r\nW0724 11:54:44.475044 10056 init.cc:224]     @     0x7f0dcabc8a5d instancemethod_call\r\nW0724 11:54:44.476794 10056 init.cc:224]     @     0x7f0dcabb9b83 PyObject_Call\r\nW0724 11:54:44.478374 10056 init.cc:224]     @     0x7f0dcac50199 PyEval_EvalFrameEx\r\nW0724 11:54:44.480032 10056 init.cc:224]     @     0x7f0dcac55b19 PyEval_EvalCodeEx\r\nW0724 11:54:44.481617 10056 init.cc:224]     @     0x7f0dcabde6ea function_call\r\nW0724 11:54:44.483245 10056 init.cc:224]     @     0x7f0dcabb9b83 PyObject_Call\r\nW0724 11:54:44.484678 10056 init.cc:224]     @     0x7f0dcabc8a5d instancemethod_call\r\nW0724 11:54:44.486244 10056 init.cc:224]     @     0x7f0dcabb9b83 PyObject_Call\r\nW0724 11:54:44.487712 10056 init.cc:224]     @     0x7f0dcac12b04 slot_tp_init\r\nW0724 11:54:44.489179 10056 init.cc:224]     @     0x7f0dcac0f3bb type_call\r\nW0724 11:54:44.490762 10056 init.cc:224]     @     0x7f0dcabb9b83 PyObject_Call\r\nW0724 11:54:44.492444 10056 init.cc:224]     @     0x7f0dcac50199 PyEval_EvalFrameEx\r\nW0724 11:54:44.494045 10056 init.cc:224]     @     0x7f0dcac55b19 PyEval_EvalCodeEx\r\nAborted\r\n",
        "state": "closed",
        "user": "Ficery1",
        "closed_by": "zh794390558",
        "created_at": "2020-07-24T04:35:55+00:00",
        "updated_at": "2021-03-24T08:30:13+00:00",
        "closed_at": "2021-03-24T08:30:13+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 481,
        "title": "在docker下使用多卡训练报错",
        "body": "```\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: ./conf/augmentation.config\r\nbatch_size: 32\r\ndev_manifest: ./dataset/manifest.dev\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: ./dataset/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 50\r\nnum_iter_print: 100\r\nnum_rnn_layers: 3\r\nnum_samples: 120000\r\noutput_model_dir: ./models/checkpoints/\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 1\r\ntrain_manifest: ./dataset/manifest.train\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: ./dataset/zh_vocab.txt\r\n------------------------------------------------\r\nW0805 02:13:43.410346    69 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW0805 02:13:43.412559    69 device_context.cc:260] device: 0, cuDNN Version: 7.5.\r\nW0805 02:13:46.192203    69 device_context.h:155] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nW0805 02:13:50.619479    69 fuse_all_reduce_op_pass.cc:74] Find all_reduce operators: 38. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 38.\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 117, in <module>\r\n    main()\r\n  File \"train.py\", line 113, in main\r\n    train()\r\n  File \"train.py\", line 108, in train\r\n    test_off=args.test_off)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 311, in train\r\n    return_numpy=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*)\r\n3   paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n10  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n11  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n12  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n13  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/loss.py\", line 628, in warpctc\r\n    'norm_by_times': norm_by_times,\r\n  File \"/DeepSpeech/model_utils/network.py\", line 433, in deep_speech_v2_network\r\n    input=fc, label=text_data, blank=dict_size, norm_by_times=True)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 137, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 260, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"train.py\", line 108, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 113, in main\r\n    train()\r\n  File \"train.py\", line 117, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: warp-ctc [version 2] Error in compute_ctc_loss: execution failed\r\n  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] at (/paddle/paddle/fluid/operators/warpctc_op.h:94)\r\n  [operator < warpctc > error]\r\nFailed in training!\r\n\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-08-05T02:15:19+00:00",
        "updated_at": "2020-08-13T03:52:15+00:00",
        "closed_at": "2020-08-05T07:05:27+00:00",
        "comments_count": [
            "yeyupiaoling",
            "YanqiangWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 483,
        "title": "在训练中如何设置输入音频的帧率，通道数等参数",
        "body": "我们有几种不同帧率、通道数的音频数据集，按理来说应该是要统一帧率，如16k，通道数为1，我找了一番，没找到在哪里设置的。",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-08-05T07:31:57+00:00",
        "updated_at": "2020-08-28T09:51:44+00:00",
        "closed_at": "2020-08-28T09:51:44+00:00",
        "comments_count": [
            "lfchener",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 484,
        "title": "编译Python3环境成功，但是在运行时出现这种错误",
        "body": "```\r\n    swig_decoders.Scorer.__init__(self, alpha, beta, model_path, vocabulary)\r\n  File \"/home/fg007/anaconda3/envs/PaddlePaddle/lib/python3.7/site-packages/swig_decoders-1.1-py3.7-linux-x86_64.egg/swig_decoders.py\", line 1269, in __init__\r\n    this = _swig_decoders.new_Scorer(alpha, beta, lm_path, vocabulary)\r\nTypeError: in method 'new_Scorer', argument 4 of type 'std::vector< std::string,std::allocator< std::string > > const &'\r\n```\r\n\r\n应该如何修改swig中的源码呢？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-08-10T09:57:38+00:00",
        "updated_at": "2021-02-25T08:51:07+00:00",
        "closed_at": "2021-02-24T06:53:17+00:00",
        "comments_count": [
            "kiwen-lee",
            "yeyupiaoling",
            "yeyupiaoling",
            "111firelicaifeng",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 485,
        "title": "Speaker Diarilization",
        "body": " I want to perform speech to text on a wav file and get Multi speaker transcript with Speaker diarisation (who spoke what and when)\r\n\r\nBut, I am confused is this possible with Deep speech?",
        "state": "closed",
        "user": "jainal09",
        "closed_by": "zh794390558",
        "created_at": "2020-08-11T08:38:07+00:00",
        "updated_at": "2021-02-03T03:42:04+00:00",
        "closed_at": "2021-02-03T03:42:03+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 482,
        "title": "在训练过程中不断吃显存，直到显存不足",
        "body": "我使用的是docker进行训练，显存为11G，在训练过程中会出现不断吃显存，直到显存不足挂掉。设置小batch_size也没有用的。",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-08-05T07:26:32+00:00",
        "updated_at": "2020-08-13T01:52:49+00:00",
        "closed_at": "2020-08-13T01:52:49+00:00",
        "comments_count": [
            "yeyupiaoling",
            "yeyupiaoling",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 486,
        "title": "请问在训练时，对音频的处理方式使用linear好，还是mfcc好？",
        "body": "请问在训练时，对音频的处理方式使用linear好，还是mfcc好？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "zh794390558",
        "created_at": "2020-08-12T14:09:21+00:00",
        "updated_at": "2021-02-03T03:40:30+00:00",
        "closed_at": "2021-02-03T03:40:30+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 488,
        "title": "在多卡训练过程中出现cudaStreamSynchronize misaligned address错误",
        "body": " - 系统：Ubuntu 16.04\r\n - 显卡：2张 2080ti\r\n - 版本：PaddlePaddle-GPU 1.8.3.post107\r\n\r\n```\r\nF0823 14:54:47.975309 16507 all_reduce_op_handle.cc:192] cudaStreamSynchronize misaligned address\r\n*** Check failure stack trace: ***\r\n    @     0x7ff2ccc25d4d  google::LogMessage::Fail()\r\n    @     0x7ff2ccc297fc  google::LogMessage::SendToLog()\r\n    @     0x7ff2ccc25873  google::LogMessage::Flush()\r\n    @     0x7ff2ccc2ad0e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7ff2cfedb35c  paddle::framework::details::AllReduceOpHandle::SyncNCCLAllReduce()\r\n    @     0x7ff2cfedb3f4  paddle::framework::details::AllReduceOpHandle::NCCLAllReduceFunc()\r\n    @     0x7ff2cfedbf66  paddle::framework::details::AllReduceOpHandle::AllReduceFunc()\r\n    @     0x7ff2cfe3bf1c  paddle::framework::details::FusedAllReduceOpHandle::FusedAllReduceFunc()\r\n    @     0x7ff2cfe3d4fe  paddle::framework::details::FusedAllReduceOpHandle::RunImpl()\r\n    @     0x7ff2cfe77c31  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync()\r\n    @     0x7ff2cfe7572f  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp()\r\n    @     0x7ff2cfe759f4  _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_Any_data\r\n    @     0x7ff2ccc83213  std::_Function_handler<>::_M_invoke()\r\n    @     0x7ff2cca7ee67  std::__future_base::_State_base::_M_do_set()\r\n    @     0x7ff3105d8a99  __pthread_once_slow\r\n    @     0x7ff2cfe71bc2  _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS4_12OpHandleBaseESt6atomicIiESt4hashIS8_ESt8equal_toIS8_ESaISt4pairIKS8_SA_EEES8_RKSt10shared_ptrINS3_13BlockingQueueImEEEEUlvE_vEESaIiEFvvEE6_M_runEv\r\n    @     0x7ff2cca812c4  _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\n    @     0x7ff3011d7421  execute_native_thread_routine_compat\r\n    @     0x7ff3105d16ba  start_thread\r\n    @     0x7ff30fbf74dd  clone\r\n    @              (nil)  (unknown)\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-08-24T07:40:48+00:00",
        "updated_at": "2020-08-28T09:52:40+00:00",
        "closed_at": "2020-08-28T09:52:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 487,
        "title": "Error to run inference and test scripts in chinese",
        "body": "when i run scripts infer.sh or test.sh i get the following error:\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 152, in <module>\r\n    main()\r\n  File \"infer.py\", line 148, in main\r\n    infer()\r\n  File \"infer.py\", line 124, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 877, in load_params\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 751, in load_vars\r\n    filename=filename)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/io.py\", line 820, in load_vars\r\n    format(orig_shape, each_var.name, new_shape))\r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((4299L,)), while the loaded parameter (namely [ layer_5_fc_bias ]) has a shape of  ((4334,)).\r\nFailed in inference!\r\n",
        "state": "closed",
        "user": "andy311p",
        "closed_by": "zh794390558",
        "created_at": "2020-08-13T13:31:59+00:00",
        "updated_at": "2021-05-12T05:01:57+00:00",
        "closed_at": "2021-05-12T05:01:57+00:00",
        "comments_count": [
            "C4712",
            "Zolewit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 489,
        "title": "请问Paddle有可应用于音频分类的模型或框架吗？",
        "body": "",
        "state": "closed",
        "user": "mtz1992",
        "closed_by": "zh794390558",
        "created_at": "2020-09-02T02:21:25+00:00",
        "updated_at": "2021-02-03T03:43:07+00:00",
        "closed_at": "2021-02-03T03:43:06+00:00",
        "comments_count": [
            "yeyupiaoling",
            "mtz1992",
            "yeyupiaoling",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 494,
        "title": "您好，能提供预发布模型的manifest文件么？",
        "body": "您好，语音模型想要正常使用好像必须要manifest文件，说明文档中提供了生成的方式，但无奈下载数据集太慢了，而且不太清楚和预发布模型是否匹配，能够提供预发布中文模型的manifest文件么？",
        "state": "closed",
        "user": "happyBluebirds",
        "closed_by": "happyBluebirds",
        "created_at": "2020-09-18T08:44:25+00:00",
        "updated_at": "2020-09-23T02:12:45+00:00",
        "closed_at": "2020-09-23T02:12:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 490,
        "title": "How can we emit word confidence while decoding?",
        "body": "I am trying to estimate word confidence while doing CTC decoding, one of the simplest ways I could think of is just multiplying the associated character probabilities at that particular time step to get an approximation.\r\n\r\nHowever, a lot of people have been using the concept of posterior probabilities and lattice to get the word confidence.\r\n\r\nIs there a simplified way to have word confidence estimation during decoding?",
        "state": "closed",
        "user": "aayushkubb",
        "closed_by": "zh794390558",
        "created_at": "2020-09-05T08:31:16+00:00",
        "updated_at": "2021-03-26T11:38:28+00:00",
        "closed_at": "2021-03-26T11:38:28+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 491,
        "title": "load 官方的aishell_model_fluid时报错",
        "body": "`python ./deploy/demo_server.py --model_path='/root/DeepSpeech/deploy/aishell_model_fluid'  --host_ip='localhost'  --host_port=8086 --use_gpu=False --mean_std_path='/root/DeepSpeech/deploy/aishell_model_fluid/mean_std.npz'  --vocab_path='/root/DeepSpeech/deploy/aishell_model_fluid/vocab.txt' --lang_model_path='/root/DeepSpeech/deploy/zh_giga.no_cna_cmn.prune01244.klm' --rnn_layer_size=1024 --share_rnn_weights=False  --specgram_type='linear' --warmup_manifest='/root/DeepSpeech/data/tiny/manifest.test-clean' --num_conv_layers=2 --num_rnn_layers=3`\r\n时报错如下：\r\n2020-09-06 21:39:12,323-INFO: begin to initialize the external scorer for decoding\r\n2020-09-06 21:39:49,813-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2020-09-06 21:39:49,813-INFO: end initializing scorer\r\n-----------------------------------------------------------\r\nWarming up ...\r\n('Warm-up Test Case %d: %s', 0, u'./dataset/librispeech/test-clean/LibriSpeech/test-clean/7176/92135/7176-92135-0025.flac')\r\nTraceback (most recent call last):\r\n  File \"./deploy/demo_server.py\", line 238, in <module>\r\n    main()\r\n  File \"./deploy/demo_server.py\", line 234, in main\r\n    start_server()\r\n  File \"./deploy/demo_server.py\", line 219, in start_server\r\n    num_test_cases=3)\r\n  File \"./deploy/demo_server.py\", line 136, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"./deploy/demo_server.py\", line 195, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/root/anaconda3/envs/python27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 876, in load_params\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/python27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 750, in load_vars\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/python27/lib/python2.7/site-packages/paddle/fluid/io.py\", line 819, in load_vars\r\n    format(orig_shape, each_var.name, new_shape))\r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((1024L, 1024L)), while the loaded parameter (namely [ layer_3_forward_rnn_weight ]) has a shape of  ((1024, 3072)).\r\n请问这个是我哪里设置错误了吗？谢谢",
        "state": "closed",
        "user": "Mryangkaitong",
        "closed_by": "zh794390558",
        "created_at": "2020-09-06T05:46:40+00:00",
        "updated_at": "2021-03-03T07:03:13+00:00",
        "closed_at": "2021-03-03T07:03:13+00:00",
        "comments_count": [
            "lrsSpace"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 492,
        "title": "Error dimension mismatch when use specgram_type mfcc",
        "body": "I use specgram type but this error happended:\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The fed Variable audio_data should have dimensions = 3, shape = [-1, 161, -1], but received fed shape [20, 39, 200]\r\n  [Hint: Expected DimensionIsCompatibleWith(shapes[i], in_dims) == true, but received DimensionIsCompatibleWith(shapes[i], in_dims):0 != true:1.] at (/paddle/paddle/fluid/operators/reader/read_op.cc:137)\r\n  [operator < read > error]\r\nFailed in training!\r\n\r\nI don't understand why shape of audio_data is:\r\n`if not is_infer:\r\n            input_fields = {\r\n                'names': ['audio_data', 'text_data', 'seq_len_data', 'masks'],\r\n                'shapes':\r\n                [[None, 161, None], [None, 1], [None, 1], [None, 32, 81, None]],\r\n                'dtypes': ['float32', 'int32', 'int64', 'float32'],\r\n                'lod_levels': [0, 1, 0, 0]\r\n            }`\r\nHow do i resolve this issue?\r\nThanks",
        "state": "closed",
        "user": "hieuhv94",
        "closed_by": "zh794390558",
        "created_at": "2020-09-17T07:52:19+00:00",
        "updated_at": "2021-03-25T02:26:04+00:00",
        "closed_at": "2021-03-25T02:26:04+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 493,
        "title": "PaddlePaddle 1.8.0 installation fails",
        "body": "  Downloading https://mirror.baidu.com/pypi/packages/a1/d6/8422797e35f8814b1d9842530566a949d9b5850a466321a6c1d5a99055ee/opencv-python-4.3.0.38.tar.gz (88.0 MB)\r\n     |UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU| 88.0 MB 22 kB/s\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: 'C:\\Users\\Admin\\anaconda3\\envs\\speech\\python.exe' 'C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'c:\\users\\admin\\appdata\\local\\temp\\tmpmsjh7o'\r\n       cwd: c:\\users\\admin\\appdata\\local\\temp\\pip-install-ep_8ia\\opencv-python\r\n  Complete output (22 lines):\r\n  Traceback (most recent call last):\r\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 280, in <module>\r\n      main()\r\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 263, in main\r\n      json_out['return_val'] = hook(**hook_input['kwargs'])\r\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 114, in get_requires_for_build_wheel\r\n      return hook(config_settings)\r\n    File \"c:\\users\\admin\\appdata\\local\\temp\\pip-build-env-6a9hmw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 146, in get_requires_for_build_wheel\r\n      return self._get_build_requires(config_settings, requirements=['wheel'])\r\n    File \"c:\\users\\admin\\appdata\\local\\temp\\pip-build-env-6a9hmw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\r\n      self.run_setup()\r\n    File \"c:\\users\\admin\\appdata\\local\\temp\\pip-build-env-6a9hmw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 243, in run_setup\r\n      self).run_setup(setup_script=setup_script)\r\n    File \"c:\\users\\admin\\appdata\\local\\temp\\pip-build-env-6a9hmw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\r\n      exec(compile(code, __file__, 'exec'), locals())\r\n    File \"setup.py\", line 448, in <module>\r\n      main()\r\n    File \"setup.py\", line 99, in main\r\n      % {\"ext\": re.escape(sysconfig.get_config_var(\"EXT_SUFFIX\"))}\r\n    File \"C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\re.py\", line 210, in escape\r\n      s = list(pattern)\r\n  TypeError: 'NoneType' object is not iterable\r\n  ----------------------------------------\r\nERROR: Command errored out with exit status 1: 'C:\\Users\\Admin\\anaconda3\\envs\\speech\\python.exe' 'C:\\Users\\Admin\\anaconda3\\envs\\speech\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'c:\\users\\admin\\appdata\\local\\temp\\tmpmsjh7o' Check the logs for full command output.",
        "state": "closed",
        "user": "AshutoshDongare",
        "closed_by": "AshutoshDongare",
        "created_at": "2020-09-17T08:55:04+00:00",
        "updated_at": "2020-09-27T14:34:28+00:00",
        "closed_at": "2020-09-27T14:34:28+00:00",
        "comments_count": [
            "LeonKennedy",
            "LeonKennedy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 496,
        "title": "Speaker Diarization and Modify the Neural Network",
        "body": "I wonder if it is possible to modify this DeepSpeech Neural network to do speaker diarization, if it is possible could you give me some clue about this? I also want to train this neural network with Traditional Chinese, could you give me some clue about this? Thank you very much for your help.",
        "state": "closed",
        "user": "alexivaner",
        "closed_by": "zh794390558",
        "created_at": "2020-10-13T01:21:12+00:00",
        "updated_at": "2021-02-03T03:53:32+00:00",
        "closed_at": "2021-02-03T03:53:32+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 495,
        "title": "Downloaded the Docker image successfully? ",
        "body": "When I downloaded the Docker image:\r\n\r\n<pre>$ sudo nvidia-docker pull hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu</pre>\r\n\r\nit sounds that it might go through:\r\n\r\n<pre><font color=\"#4E9A06\"><b>ml@ml-Alienware-Aurora-Ryzen-Edition</b></font>:<font color=\"#3465A4\"><b>~</b></font>$ sudo nvidia-docker pull hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu\r\n[sudo] password for ml: \r\nlatest-gpu: Pulling from paddlepaddle/deep_speech_fluid\r\n3c21ebac6bec: Pulling fs layer \r\nad9e3a7075fe: Pulling fs layer \r\n4b1a464a2c0a: Pulling fs layer \r\n3a1d7eee827d: Pulling fs layer \r\n29d1b31ad169: Pulling fs layer \r\n9136047911d4: Pulling fs layer \r\nf1a4b0ab792e: Pulling fs layer \r\ne709e5219f58: Pulling fs layer \r\n3a1d7eee827d: Waiting \r\n3d8e005a1c36: Pulling fs layer \r\n4fc075736176: Pulling fs layer \r\n9136047911d4: Waiting \r\n7cc82bc7830b: Pulling fs layer \r\n21bbd44330d8: Pulling fs layer \r\ne7e99a532df2: Pulling fs layer \r\ne709e5219f58: Waiting \r\n09b927152200: Waiting \r\n21bbd44330d8: Waiting \r\n3d8e005a1c36: Waiting \r\ne7e99a532df2: Waiting \r\nf9daa39c1249: Pull complete \r\n023c7b718089: Pull complete \r\n3d35ffc25700: Pull complete \r\n6be655d28897: Pull complete \r\n9b30819d4d5e: Pull complete \r\nd6c4b765fb1b: Pull complete \r\ne3d45086c12c: Pull complete \r\n5acb8f7358ac: Pull complete \r\nd55e9aaab773: Pull complete \r\n77384f595cd2: Pull complete \r\n322b275d50cf: Pull complete \r\n4f37ca086c1d: Pull complete \r\n04ceb7100848: Pull complete \r\n2ed81ea9c480: Pull complete \r\nf3a6127b27f2: Pull complete \r\n6a3b4f6d134a: Pull complete \r\n74591c1e01a3: Pull complete \r\nae43c04823b6: Pull complete \r\n7683bf2504b7: Pull complete \r\n1a0cfa5c112a: Pull complete \r\n9f4205c52101: Pull complete \r\na545aeede71b: Pull complete \r\n6a7b1799822a: Pull complete \r\nDigest: sha256:aed16d3b3fabf64ca68e182c26dd3e0458ce09228696682963f1f39d63606b46\r\nStatus: Downloaded newer image for hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu\r\nhub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu\r\n<font color=\"#4E9A06\"><b>ml@ml-Alienware-Aurora-Ryzen-Edition</b></font>:<font color=\"#3465A4\"><b>~</b></font>$ git clone https://github.com/PaddlePaddle/DeepSpeech.git\r\nCloning into &apos;DeepSpeech&apos;...\r\nremote: Enumerating objects: 13, done.\r\nremote: Counting objects: 100% (13/13), done.\r\nremote: Compressing objects: 100% (11/11), done.\r\nremote: Total 2658 (delta 2), reused 5 (delta 2), pack-reused 2645\r\nReceiving objects: 100% (2658/2658), 1.16 MiB | 1001.00 KiB/s, done.\r\nResolving deltas: 100% (1717/1717), done.\r\n<font color=\"#4E9A06\"><b>ml@ml-Alienware-Aurora-Ryzen-Edition</b></font>:<font color=\"#3465A4\"><b>~</b></font>$ sudo nvidia-docker run -it -v $(pwd)/DeepSpeech:/DeepSpeech hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu /bin/bash\r\n[sudo] password for ml: \r\n<font color=\"#C4A000\"><b>λ </b></font><font color=\"#D3D7CF\"><b>bc95a51368df </b></font><font color=\"#4E9A06\"><b>/</b></font> \r\n</pre>\r\n\r\nHowever, for some lines, it still shows \"Waiting\".  May I ask whether I have downloaded the Docker image successfully? If not, how may I take care of this? Thanks.",
        "state": "closed",
        "user": "ML6634",
        "closed_by": "zh794390558",
        "created_at": "2020-10-09T08:55:56+00:00",
        "updated_at": "2021-02-03T03:44:59+00:00",
        "closed_at": "2021-02-03T03:44:59+00:00",
        "comments_count": [
            "slesinger",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 497,
        "title": "PreconditionNotMetError: warp-ctc [version 2] Error in get_workspace_size: Summary of this error.",
        "body": "I am trying to train an ASR model on from the pre-trained baidu-en8k.\r\n\r\nCommand Passed:\r\n```\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \r\npython -u train.py --batch_size=8 --num_epoch=50 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 \r\n--num_iter_print=100 --save_epoch=1 --num_samples=60000 --learning_rate=5e-3 --max_duration=45.0 \r\n--min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True \r\n--share_rnn_weights=False --init_from_pretrained_model='models/baidu_en8k' --train_manifest='data/dataset/manifest.train' \r\n--dev_manifest='data/dataset/manifest.val' --mean_std_path='data/dataset/mean_std.npz' \r\n--vocab_path='data/dataset/vocab.txt' --output_model_dir='./checkpoints/exp2' --specgram_type='linear'\r\n--shuffle_method='batch_shuffle_clipped'\r\n```\r\nError Got:\r\n```\r\nfinish initing model from pretrained params from models/baidu_en8k\r\nepoch: 0, batch: 0, train loss: 485.547302\r\n\r\nepoch: 0, batch: 100, train loss: 42.384502\r\n\r\n/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/home/ubuntu/DeepSpeech/model_utils/model.py\", line 348, in train\r\n    return_numpy=False)\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*)\r\n3   paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n9   paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n10  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n11  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n12  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n13  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/paddleDS2/lib/python2.7/site-packages/paddle/fluid/layers/loss.py\", line 638, in warpctc\r\n    'norm_by_times': norm_by_times,\r\n  File \"/home/ubuntu/DeepSpeech/model_utils/network.py\", line 446, in deep_speech_v2_network\r\n    input=fc, label=text_data, blank=dict_size, norm_by_times=True)\r\n  File \"/home/ubuntu/DeepSpeech/model_utils/model.py\", line 145, in create_network\r\n    share_rnn_weights=self._share_rnn_weights)\r\n  File \"/home/ubuntu/DeepSpeech/model_utils/model.py\", line 281, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPreconditionNotMetError: warp-ctc [version 2] Error in get_workspace_size: unknown error\r\n  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:4.] at (/paddle/paddle/fluid/operators/warpctc_op.h:101)\r\n  [operator < warpctc > error]\r\n```\r\n\r\n",
        "state": "closed",
        "user": "ashutosh486",
        "closed_by": "ashutosh486",
        "created_at": "2020-10-28T10:43:18+00:00",
        "updated_at": "2022-09-17T05:47:09+00:00",
        "closed_at": "2020-11-04T06:50:29+00:00",
        "comments_count": [
            "chai21b"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 498,
        "title": "Probability of output transcript word",
        "body": "Hi\r\n\r\n1. How can I check probability of correctness of individual transcribed words? \r\n2. Do we have timestamp of transcription w.r.t audio files?",
        "state": "closed",
        "user": "shahurvi84",
        "closed_by": "zh794390558",
        "created_at": "2020-11-02T07:34:57+00:00",
        "updated_at": "2021-02-03T03:47:56+00:00",
        "closed_at": "2021-02-03T03:47:56+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 501,
        "title": "nvidia-docker run error",
        "body": "nvidia-docker run -it -v $(pwd)/DeepSpeech:/DeepSpeech hub.baidubce.com/paddlepaddle/deep_speech_fluid:latest-gpu /bin/bash\r\n\r\ndocker: Error response from daemon: Unknown runtime specified nvidia.\r\nSee 'docker run --help'.",
        "state": "closed",
        "user": "zailushang2006",
        "closed_by": "zh794390558",
        "created_at": "2020-12-02T12:17:08+00:00",
        "updated_at": "2021-02-03T03:37:08+00:00",
        "closed_at": "2021-02-03T03:37:08+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 503,
        "title": "No such file or directory: 'data/librispeech/mean_std.npz'",
        "body": "我想利用预训练模型进行单条的语音转文字该怎么操作，我在文档中没有找到相关建议，可以帮帮我吗\r\n",
        "state": "closed",
        "user": "siyangbing",
        "closed_by": "zh794390558",
        "created_at": "2020-12-30T03:38:04+00:00",
        "updated_at": "2021-02-03T03:38:49+00:00",
        "closed_at": "2021-02-03T03:38:49+00:00",
        "comments_count": [
            "siyangbing",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 504,
        "title": "为什么我使用百度内部语料预训练的模型识别效果差呢 ",
        "body": "理论上来说大语料预训练模型识别效果会好(baidu-cn1.2k),识别效果差\r\n我的命令\r\npython -u infer.py \\\r\n--num_samples=10 \\\r\n--beam_size=300 \\\r\n--num_proc_bsearch=8 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=2048 \\\r\n--alpha=2.6 \\\r\n--beta=5.0 \\\r\n--cutoff_prob=0.99 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=False \\\r\n--share_rnn_weights=False \\\r\n--infer_manifest='data/aishell/test.test' \\\r\n--mean_std_path='models/bd18k/mean_std.npz' \\\r\n--vocab_path='models/bd18k/vocab.txt' \\\r\n--model_path='models/bd18k' \\\r\n--lang_model_path='/home/db/下载/zhidao_giga.klm' \\\r\n--specgram_type='linear'\r\n\r\n其中infer_manifest是自己的数据，模型是下载的预先训练的官方模型",
        "state": "closed",
        "user": "siyangbing",
        "closed_by": "zh794390558",
        "created_at": "2020-12-31T01:02:55+00:00",
        "updated_at": "2021-02-07T12:22:52+00:00",
        "closed_at": "2021-02-03T03:38:38+00:00",
        "comments_count": [
            "ccbptm",
            "fnhweiqs",
            "zh794390558",
            "ccbptm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 502,
        "title": "impulse manifest",
        "body": "Please provide me sample json to create impulse.manifest. \r\nAlso please guide how i can use it for training deepspeech model.",
        "state": "closed",
        "user": "Pallav56",
        "closed_by": "zh794390558",
        "created_at": "2020-12-18T06:35:43+00:00",
        "updated_at": "2021-02-03T03:39:27+00:00",
        "closed_at": "2021-02-03T03:39:27+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 505,
        "title": " pip install paddlepaddle-gpu==1.8.0.post107 -i https://mirrors.aliyun.com/pypi/simple  下载报错",
        "body": "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\nCollecting paddlepaddle-gpu==1.8.0.post107\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/77/54/e55c1484f0cc7af8a69a38e9e4722b4754be2130810984450761895a02c2/paddlepaddle_gpu-1.8.0.post107-cp27-cp27mu-manylinux1_x86_64.whl (405.7 MB)\r\nCollecting graphviz\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/86/86/89ba50ba65928001d3161f23bfa03945ed18ea13a1d1d44a772ff1fa4e7a/graphviz-0.16-py2.py3-none-any.whl (19 kB)\r\nCollecting opencv-python\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/a1/d6/8422797e35f8814b1d9842530566a949d9b5850a466321a6c1d5a99055ee/opencv-python-4.3.0.38.tar.gz (88.0 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /opt/Anaconda3/envs/py2/bin/python /opt/Anaconda3/envs/py2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmp07EPYa\r\n       cwd: /tmp/pip-install-U8NATZ/opencv-python\r\n  Complete output (22 lines):\r\n  Traceback (most recent call last):\r\n    File \"/opt/Anaconda3/envs/py2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py\", line 280, in <module>\r\n      main()\r\n    File \"/opt/Anaconda3/envs/py2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py\", line 263, in main\r\n      json_out['return_val'] = hook(**hook_input['kwargs'])\r\n    File \"/opt/Anaconda3/envs/py2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py\", line 114, in get_requires_for_build_wheel\r\n      return hook(config_settings)\r\n    File \"/tmp/pip-build-env-Md_yKd/overlay/lib/python2.7/site-packages/setuptools/build_meta.py\", line 146, in get_requires_for_build_wheel\r\n      return self._get_build_requires(config_settings, requirements=['wheel'])\r\n    File \"/tmp/pip-build-env-Md_yKd/overlay/lib/python2.7/site-packages/setuptools/build_meta.py\", line 127, in _get_build_requires\r\n      self.run_setup()\r\n    File \"/tmp/pip-build-env-Md_yKd/overlay/lib/python2.7/site-packages/setuptools/build_meta.py\", line 243, in run_setup\r\n      self).run_setup(setup_script=setup_script)\r\n    File \"/tmp/pip-build-env-Md_yKd/overlay/lib/python2.7/site-packages/setuptools/build_meta.py\", line 142, in run_setup\r\n      exec(compile(code, __file__, 'exec'), locals())\r\n    File \"setup.py\", line 448, in <module>\r\n      main()\r\n    File \"setup.py\", line 99, in main\r\n      % {\"ext\": re.escape(sysconfig.get_config_var(\"EXT_SUFFIX\"))}\r\n    File \"/opt/Anaconda3/envs/py2/lib/python2.7/re.py\", line 210, in escape\r\n      s = list(pattern)\r\n  TypeError: 'NoneType' object is not iterable\r\n  ----------------------------------------\r\nERROR: Command errored out with exit status 1: /opt/Anaconda3/envs/py2/bin/python /opt/Anaconda3/envs/py2/lib/python2.7/site-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmp07EPYa Check the logs for full command output.",
        "state": "closed",
        "user": "weiaoliu",
        "closed_by": "weiaoliu",
        "created_at": "2021-01-04T07:05:43+00:00",
        "updated_at": "2021-01-05T07:56:21+00:00",
        "closed_at": "2021-01-05T07:56:21+00:00",
        "comments_count": [
            "weiaoliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 506,
        "title": "AssertionError: In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and 'data()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.",
        "body": "Traceback (most recent call last):\r\n  File \"infer.py\", line 182, in <module>\r\n    show(audiopath)\r\n  File \"infer.py\", line 176, in show\r\n    result = infer()\r\n  File \"infer.py\", line 151, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/port/model_utils/model.py\", line 402, in infer_batch_probs\r\n    feeder, log_probs, _ = self.create_network(is_infer=True)\r\n  File \"/home/port/model_utils/model.py\", line 120, in create_network\r\n    lod_level=0)\r\n  File \"<decorator-gen-25>\", line 2, in data\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 231, in __impl__\r\n    ), \"In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and '%s()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.\" % func.__name__\r\nAssertionError: In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and 'data()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.",
        "state": "closed",
        "user": "weiaoliu",
        "closed_by": "weiaoliu",
        "created_at": "2021-01-04T09:06:22+00:00",
        "updated_at": "2021-03-23T10:48:32+00:00",
        "closed_at": "2021-01-05T07:56:35+00:00",
        "comments_count": [
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 507,
        "title": "关于cuda版本和cudnn版本问题",
        "body": "我是用docker容器运行的，机器的cuda版本是10.0，cudnn版本是7.6.0。而docker容器里的cuda版本是9.0，cudnn没有安装。在容器里运行train.py使用gpu的时候会报错\r\n`Cudnn error, CUDNN_STATUS_EXECUTION_FAILED`\r\n并且运行的时候，输出信息说我用的是cudnn 7.5\r\n请问容器里运行的时候使用的是容器外的cuda和cudnn还是容器内部的呐，我还需要升级容器内部的版本吗",
        "state": "closed",
        "user": "Rootian",
        "closed_by": "zh794390558",
        "created_at": "2021-01-06T08:24:09+00:00",
        "updated_at": "2021-02-03T03:38:22+00:00",
        "closed_at": "2021-02-03T03:38:22+00:00",
        "comments_count": [
            "1003657663",
            "Rootian",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 508,
        "title": "Train on Indian languages",
        "body": "How i can train/ use pretrained model for Indian languages (Hindi, Gujarati, Marathi etc.)",
        "state": "closed",
        "user": "Pallav56",
        "closed_by": "zh794390558",
        "created_at": "2021-01-08T04:56:34+00:00",
        "updated_at": "2021-02-03T03:39:18+00:00",
        "closed_at": "2021-02-03T03:39:18+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 509,
        "title": "训练好的模型部署效果很差",
        "body": "用自带的infer推理效果还挺好的，到server运行几乎识别不出来，运行过tune.py得到参数，还是没有什么效果，不知道具体问题出在哪里。",
        "state": "closed",
        "user": "ayayaya420",
        "closed_by": "zh794390558",
        "created_at": "2021-01-12T02:32:57+00:00",
        "updated_at": "2021-02-03T03:38:07+00:00",
        "closed_at": "2021-02-03T03:38:07+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 514,
        "title": "UnavailableError: Not allowed to load partial data via load_combine_op, please use load_op instead.",
        "body": "版本信息：\r\n```\r\nPaddle version: 1.8.5\r\nPaddle With CUDA: True\r\nOS: Ubuntu 18.04\r\nPython version: 2.7.17\r\nCUDA version: 10.0.130\r\ncuDNN version: 7.6.5\r\nNvidia driver version: 455.38\r\n```\r\n运行DeepSpeech/deploy/demo_server.py时错误提示：\r\n```\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nUnavailableError: Not allowed to load partial data via load_combine_op, please use load_op instead.\r\n  [Hint: Expected buffer->eof() == true, but received buffer->eof():0 != true:1.] at (/paddle/paddle/fluid/operators/load_combine_op.h:116)\r\n  [operator < load_combine > error]\r\n```\r\n\r\n我的运行配置为：\r\n\r\n```\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: /home/Myself/DeepSpeech/models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: /home/Myself/DeepSpeech/models/aishell/mean_std.npz\r\nmodel_path: /home/Myself/DeepSpeech/models/aishell\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: False\r\nvocab_path: /home/Myself/DeepSpeech/models/aishell/vocab.txt\r\nwarmup_manifest: /home/Myself/DeepSpeech/data/aishell/manifest.test\r\n------------------------------------------------\r\n[INFO 2021-01-19 19:20:15,922 model.py:474] begin to initialize the external scorer for decoding\r\n[INFO 2021-01-19 19:20:16,007 model.py:484] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2021-01-19 19:20:16,007 model.py:485] end initializing scorer\r\n-----------------------------------------------------------\r\n\r\n```",
        "state": "closed",
        "user": "ccbptm",
        "closed_by": "zh794390558",
        "created_at": "2021-01-19T11:25:56+00:00",
        "updated_at": "2021-03-24T08:29:18+00:00",
        "closed_at": "2021-03-24T08:29:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 511,
        "title": "关于使用tiny数据集在GPU上训练的问题",
        "body": "- 版本、环境信息：\r\n    1）PaddlePaddle版本：2.00 rc1\r\n    3）GPU：P4000，CUDA 10.1.243和CUDNN 7.6.0 nvdia driver :440.31 \r\n    4）系统环境：linux ubuntu 16.04LTS，Python 2.7.18\r\n\r\n- 模型信息\r\n    使用tiny数据集在gpu下进行训练\r\n- 复现信息：如为报错，请给出复现环境、复现步骤\r\n- 执行 sh run_train.sh发生错误\r\n- 问题描述：请详细描述您的问题，同步贴出报错信息、日志/代码关键片段\r\n- \r\n\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 4\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 20\r\nnum_iter_print: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 64\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/workspace/DeepSpeech/model_utils/model.py\", line 282, in train\r\n    train_reader, log_probs, ctc_loss = self.create_network()\r\n  File \"/workspace/DeepSpeech/model_utils/model.py\", line 106, in create_network\r\n    for i in range(len(input_fields['names']))\r\n  File \"<decorator-gen-25>\", line 2, in data\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 231, in __impl__\r\n    ), \"In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and '%s()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.\" % func.__name__\r\nAssertionError: In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and 'data()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.\r\nThank you for contributing to PaddlePaddle.\r\n按照提示修改后，发生如下错误\r\n-----------  Configuration Arguments -----------\r\naugment_conf_path: conf/augmentation.config\r\nbatch_size: 4\r\ndev_manifest: data/tiny/manifest.tiny\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 1e-05\r\nmax_duration: 27.0\r\nmean_std_path: data/tiny/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 20\r\nnum_iter_print: 1\r\nnum_rnn_layers: 3\r\nnum_samples: 64\r\noutput_model_dir: ./checkpoints/tiny\r\nrnn_layer_size: 2048\r\nsave_epoch: 1\r\nshare_rnn_weights: 1\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/tiny/manifest.tiny\r\nuse_gpu: 1\r\nuse_gru: 0\r\nuse_sortagrad: 1\r\nvocab_path: data/tiny/vocab.txt\r\n------------------------------------------------\r\nW0113 05:02:13.216773  5141 device_context.cc:320] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW0113 05:02:13.221822  5141 device_context.cc:330] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/workspace/DeepSpeech/model_utils/model.py\", line 337, in train\r\n    return_numpy=False)\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1106, in run\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1238, in _run_impl\r\n    program._compile(scope, self.place)\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/compiler.py\", line 454, in _compile\r\n    places=self._places)\r\n  File \"/root/miniconda3/envs/py27/lib/python2.7/site-packages/paddle/fluid/compiler.py\", line 407, in _compile_data_parallel\r\n    self._exec_strategy, self._build_strategy, self._graph)\r\nRuntimeError: (PreconditionNotMet) The graph doesn't have operators.\r\n  [Hint: Expected op_deps_.size() > 0, but received op_deps_.size():0 <= 0:0.] (at /paddle/paddle/fluid/framework/details/fast_threaded_ssa_graph_executor.cc:55)\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n\r\n",
        "state": "closed",
        "user": "SullivanJia",
        "closed_by": "zh794390558",
        "created_at": "2021-01-13T05:10:58+00:00",
        "updated_at": "2021-02-03T03:01:51+00:00",
        "closed_at": "2021-02-03T03:01:50+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 510,
        "title": "加载预训练模型报错",
        "body": "",
        "state": "closed",
        "user": "xiaoyu4122",
        "closed_by": "zh794390558",
        "created_at": "2021-01-12T09:47:27+00:00",
        "updated_at": "2021-02-03T03:37:39+00:00",
        "closed_at": "2021-02-03T03:37:39+00:00",
        "comments_count": [
            "xiaoyu4122",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 512,
        "title": "训练占用显存越来越高",
        "body": "你好，我在使用自己的数据进行训练的时候，设置的batch_size是16，最开始的几千个batch，基本可以几十秒完成100个batch的训练，而随着训练的进行，每100个batch的训练时间越来越长，现在进行到batch 20000左右的时候，100个batch需要7分钟的时间才能完成训练，而且train loss也是在缓慢增加的，请问这是正常现象吗？\r\n\r\n另外，最开始启动的时候占用的显存是4g，随着训练进行，每100个batch的训练速度越来越慢，占用的显存也越来越高，进行到batch 20000左右，显存的占用已经达到了7g，这种情况应该如何处理呢？",
        "state": "closed",
        "user": "Rootian",
        "closed_by": "zh794390558",
        "created_at": "2021-01-13T10:48:05+00:00",
        "updated_at": "2021-02-03T02:59:12+00:00",
        "closed_at": "2021-02-03T02:59:12+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 513,
        "title": "使用官方BaiduCN1.2k Model和Mandarin LM Small搭建语音识别报错",
        "body": "修改test.py并运行提示：\r\n```\r\nTensorRT dynamic library (libnvinfer.so) that Paddle depends on is not configured correctly. (error code is libnvinfer.so: cannot open shared object file: No such file or directory)\r\n  Suggestions:\r\n  1. Check if TensorRT is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure TensorRT dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX;-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbatch_size: 32\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: CER\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: models/baidu_ch1.2k/mean_std.npz\r\nmodel_path: /home/mocai/Graduation/DeepSpeech/models/aishell\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: False\r\nspecgram_type: linear\r\ntest_manifest: /home/mocai/Graduation/DeepSpeech/data/aishell/manifest.test\r\nuse_gpu: True\r\nuse_gru: True\r\nvocab_path: models/baidu_ch1.2k/vocab.txt\r\n------------------------------------------------\r\n[INFO 2021-01-13 19:20:17,509 model.py:474] begin to initialize the external scorer for decoding\r\n[INFO 2021-01-13 19:20:17,587 model.py:484] language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n[INFO 2021-01-13 19:20:17,587 model.py:485] end initializing scorer\r\n[INFO 2021-01-13 19:20:17,587 test.py:115] start evaluation ...\r\nW0113 19:20:17.922132 20528 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0113 19:20:17.924199 20528 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 155, in <module>\r\n    main()\r\n  File \"test.py\", line 151, in main\r\n    evaluate()\r\n  File \"test.py\", line 119, in evaluate\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/mocai/Graduation/DeepSpeech/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/home/mocai/Graduation/DeepSpeech/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/mocai/.local/lib/python2.7/site-packages/paddle/fluid/io.py\", line 877, in load_params\r\n    filename=filename)\r\n  File \"/home/mocai/.local/lib/python2.7/site-packages/paddle/fluid/io.py\", line 751, in load_vars\r\n    filename=filename)\r\n  File \"/home/mocai/.local/lib/python2.7/site-packages/paddle/fluid/io.py\", line 820, in load_vars\r\n    format(orig_shape, each_var.name, new_shape))\r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((6144L,)), while the loaded parameter (namely [ layer_2_forward_batch_norm_moving_mean ]) has a shape of  ((3072,)).\r\n\r\n```\r\n\r\n然后我的TensorRT也安装好了并且导入到LD_LIBARARY_PATH内了",
        "state": "closed",
        "user": "ccbptm",
        "closed_by": "zh794390558",
        "created_at": "2021-01-13T11:26:41+00:00",
        "updated_at": "2021-03-24T08:29:58+00:00",
        "closed_at": "2021-03-24T08:29:58+00:00",
        "comments_count": [
            "ccbptm",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 516,
        "title": "pip install swig_decoders没有找到相关包",
        "body": "python2.7，清华源",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-01-29T07:26:25+00:00",
        "updated_at": "2021-02-01T02:57:46+00:00",
        "closed_at": "2021-02-01T02:57:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 515,
        "title": "BaiduCN1.2k Model和AiShell Model使用问题",
        "body": "1.使用BaiduCN1.2k Model配置好test.py文件后，使用aishell的测试集测试显示cer=1.0000\r\n配置：\r\n```\r\n18 add_arg('batch_size',       int,    32,    \"Minibatch size.\")\r\n 19 add_arg('beam_size',        int,    500,    \"Beam search width.\")\r\n 20 add_arg('num_proc_bsearch', int,    8,      \"# of CPUs for beam search.\")\r\n 21 add_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\n 22 add_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\n 23 add_arg('rnn_layer_size',   int,    2048,   \"# of recurrent cells per layer.\")\r\n 24 add_arg('alpha',            float,  2.5,    \"Coef of LM for beam search.\")\r\n 25 add_arg('beta',             float,  0.3,    \"Coef of WC for beam search.\")\r\n 26 add_arg('cutoff_prob',      float,  0.99,    \"Cutoff probability for pruning.\")\r\n 27 add_arg('cutoff_top_n',     int,    40,     \"Cutoff number for pruning.\")\r\n 28 add_arg('use_gru',          bool,   True,  \"Use GRUs instead of simple RNNs.\")\r\n 29 add_arg('use_gpu',          bool,   True,   \"Use GPU or not.\")\r\n 30 add_arg('share_rnn_weights',bool,   False,   \"Share input-hidden weights across \"\r\n 31                                             \"bi-directional RNNs. Not for GRU.\")\r\n 32 add_arg('test_manifest',   str,\r\n 33         #'data/librispeech/manifest.test-clean',\r\n 34         '/home/DeepSpeech/data/aishell/manifest.test' ,\r\n 35         \"Filepath of manifest to evaluate.\")\r\n 36 add_arg('mean_std_path',    str,\r\n 37         #'data/librispeech/mean_std.npz',\r\n 38         '/home/DeepSpeech/models/baidu_ch1.2k/mean_std.npz' ,\r\n 39         \"Filepath of normalizer's mean & std.\")\r\n 40 add_arg('vocab_path',       str,\r\n 41         #'data/librispeech/vocab.txt',\r\n 42         '/home/DeepSpeech/models/baidu_ch1.2k/vocab.txt' ,\r\n 43         #'/home/DeepSpeech/models/aishell/vocab.txt' ,\r\n 44         \"Filepath of vocabulary.\")\r\n 45 add_arg('model_path',       str,\r\n 46         #'./checkpoints/libri/step_final',\r\n 47         '/home/DeepSpeech/models/baidu_ch1.2k/' ,\r\n 48         #'/home/DeepSpeech/models/baidu_ch1.2k/params.pdparams' ,\r\n 49         \"If None, the training starts from scratch, \"\r\n 50         \"otherwise, it resumes from the pre-trained model.\")\r\n 51 add_arg('lang_model_path',  str,\r\n 52         #'models/lm/common_crawl_00.prune01111.trie.klm',\r\n 53         '/home/DeepSpeech/models/lm/zh_giga.no_cna_cmn.prune01244.klm' ,\r\n 54         \"Filepath for language model.\")\r\n```\r\n\r\n2.参考./deploy和./example/deploy的做法，测试效果不好，然后有两个疑问：\r\n           2.1    对于BaiduCN1.2k Model的配置参数大家有什么建议么？（因为没有可用语料集，没办法去用./tools/tune.py进行参数的调整）\r\n           2.1    不知道有没有对麦克风的语音输入进行降噪和增强，大家能有什么方法提示么？\r\n\r\n3.使用Aishell Model配置好test.py文件后，使用aishell的测试集测试显示cer在0.1左右，但将Aishell Model使用./deploy和./example/deploy的做法后效果比用BaiduCN1.2k Model的./deploy/还差好多？这个有什么好的办法么？",
        "state": "closed",
        "user": "ccbptm",
        "closed_by": "zh794390558",
        "created_at": "2021-01-21T01:51:23+00:00",
        "updated_at": "2021-03-11T08:11:44+00:00",
        "closed_at": "2021-03-11T08:11:44+00:00",
        "comments_count": [
            "ccbptm",
            "zh794390558",
            "ccbptm"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 523,
        "title": "建议作者好好写一个demo",
        "body": "作为百度开源的框架，这是我使用体验感最糟糕的一个。\r\n1、demo写的模糊，照着做根本运行不起来，还需要大量的调整。\r\n2、即便有docker容器了，环境还是各种冲突。\r\n能不能提供一个可以直接运行的demo，哪怕体积很大、效率不高，能不能先让我运行起来，识别出第一个语音文本再说。这个年代，容器占用10G、20G、30G的空间，真的很重要吗？那些各种文件，运行的时候还不是要一个个去下载！paddle提供的各种模型，又搞了各自的容器环境，我就没见的拉取一个环境就能直接运行的，各种路径冲突，文件找不到，下载不了。paddle里面的项目结构是什么？各个文件、脚本的作用是什么？要是作者能够整理下，就真的完美了！",
        "state": "closed",
        "user": "jiangliuer-beep",
        "closed_by": "jiangliuer-beep",
        "created_at": "2021-02-09T02:38:51+00:00",
        "updated_at": "2021-02-25T06:02:46+00:00",
        "closed_at": "2021-02-23T01:21:02+00:00",
        "comments_count": [
            "monkeycc",
            "zh794390558",
            "jiangliuer-beep",
            "zh794390558",
            "111firelicaifeng"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 528,
        "title": "train.py脚本中的max_duration参数",
        "body": "想知道该参数是否是随意设置，还是根据数据集最大时长设置，我的数据集中有的句子时长能有20多秒，如果用默认参数27会导致oom,将max_duration修改成15可以顺利训练，但是训练结束后，test_loss很大，准确率也不行。@zh794390558",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "lfxx",
        "created_at": "2021-02-22T03:28:26+00:00",
        "updated_at": "2021-02-22T08:54:49+00:00",
        "closed_at": "2021-02-22T08:54:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 525,
        "title": "tiny和aishell，训练报错",
        "body": "### 一共两个报错信息，tiny和aishell，报错信息不一样\r\n\r\n###  no.1\r\n\r\n###  tiny：\r\n\r\n### bash run.sh\r\n\r\n============  Configuration Arguments ============\r\nalpha_from: 1.0\r\nalpha_to: 3.2\r\nbatch_size: 128\r\nbeam_size: 500\r\nbeta_from: 0.1\r\nbeta_to: 0.45\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\nerror_rate_type: wer\r\nlang_model_path: /root/DeepSpeech/examples/tiny/../..//models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: data/mean_std.npz\r\nmodel_path: /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\nnum_alphas: 45\r\nnum_batches: -1\r\nnum_betas: 8\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 12\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: 1\r\nspecgram_type: linear\r\ntrainer_count: 8\r\ntune_manifest: data/manifest.dev-clean\r\nuse_gpu: 1\r\nuse_gru: 0\r\nvocab_path: data/vocab.txt\r\n================================================----\r\n2021-02-18 12:11:32,090-INFO: begin to initialize the external scorer for decoding\r\n2021-02-18 12:11:39,547-INFO: language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n2021-02-18 12:11:39,620-INFO: end initializing scorer\r\n2021-02-18 12:11:39,621-INFO: start tuning ...\r\nW0218 12:11:45.212179 23717 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0218 12:11:45.224212 23717 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 0 [128/?], current opt (alpha, beta) = (3.200, 0.100),  min [wer] = 0.973516\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 1 [256/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.972130\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 2 [384/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.975304\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 3 [512/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.974737\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 4 [640/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.977027\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 5 [768/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.976478\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 6 [896/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.974615\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 7 [1024/?], current opt (alpha, beta) = (3.200, 0.150),  min [wer] = 0.974513\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 8 [1152/?], current opt (alpha, beta) = (3.200, 0.100),  min [wer] = 0.976047\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 9 [1280/?], current opt (alpha, beta) = (3.200, 0.100),  min [wer] = 0.975835\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/tiny/../..//models/librispeech\r\n....................................................................................................................................................................................\r\nBatch 10 [1408/?], current opt (alpha, beta) = (3.200, 0.100),  min [wer] = 0.975548\r\n./local/run_tune.sh: line 30: 23717 Killed                  CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -u $MAIN_ROOT/tools/tune.py --num_batches=-1 --batch_size=128 --beam_size=500 --num_proc_bsearch=12 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=2048 --num_alphas=45 --num_betas=8 --alpha_from=1.0 --alpha_to=3.2 --beta_from=0.1 --beta_to=0.45 --cutoff_prob=1.0 --cutoff_top_n=40 --use_gru=False --use_gpu=True --share_rnn_weights=True --tune_manifest=\"data/manifest.dev-clean\" --mean_std_path=\"data/mean_std.npz\" --vocab_path=\"data/vocab.txt\" --model_path=\"$MAIN_ROOT/models/librispeech\" --lang_model_path=\"$MAIN_ROOT/models/lm/common_crawl_00.prune01111.trie.klm\" --error_rate_type=\"wer\" --specgram_type=\"linear\"\r\nFailed in tuning!\r\n\r\n\r\n============\r\n\r\n\r\n###  no.2\r\n\r\n###  aishell：\r\n\r\n### bash run.sh\r\n\r\nUnpacking /root/DeepSpeech/examples/aishell/../..//dataset/aishell/data_aishell/wav/S0598.tar.gz ...\r\nCreating manifest data/manifest ...\r\n============  Configuration Arguments ============\r\ncount_threshold: 0\r\nmanifest_paths: ['data/manifest.train', 'data/manifest.dev']\r\nvocab_path: data/vocab.txt\r\n================================================----\r\n============  Configuration Arguments ============\r\nmanifest_path: data/manifest.train\r\nnum_samples: 2000\r\noutput_path: data/mean_std.npz\r\nspecgram_type: linear\r\n================================================----\r\nAishell data preparation done.\r\nDownload language model ...\r\n--2021-02-18 16:21:42--  https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm\r\nResolving deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)... 2409:8c00:6c21:10ad:0:ff:b00e:67d, 220.181.33.43, 220.181.33.44\r\nConnecting to deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)|2409:8c00:6c21:10ad:0:ff:b00e:67d|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 2953395058 (2.8G) [application/octet-stream]\r\nSaving to: './zh_giga.no_cna_cmn.prune01244.klm'\r\n\r\n./zh_giga.no_cna_cmn.prune01244. 100%[=======================================================>]   2.75G  27.7MB/s    in 1m 45s  \r\n\r\n2021-02-18 16:23:28 (26.7 MB/s) - './zh_giga.no_cna_cmn.prune01244.klm' saved [2953395058/2953395058]\r\n\r\nDownload Aishell model ...\r\n--2021-02-18 16:23:34--  https://deepspeech.bj.bcebos.com/mandarin_models/aishell_model_fluid.tar.gz\r\nResolving deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)... 2409:8c00:6c21:10ad:0:ff:b00e:67d, 220.181.33.44, 220.181.33.43\r\nConnecting to deepspeech.bj.bcebos.com (deepspeech.bj.bcebos.com)|2409:8c00:6c21:10ad:0:ff:b00e:67d|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 227293290 (217M) [application/x-gzip]\r\nSaving to: './aishell_model_fluid.tar.gz'\r\n\r\n./aishell_model_fluid.tar.gz     100%[=======================================================>] 216.76M  27.2MB/s    in 12s     \r\n\r\n2021-02-18 16:23:46 (18.7 MB/s) - './aishell_model_fluid.tar.gz' saved [227293290/227293290]\r\n\r\nmean_std.npz\r\nREADME.md\r\nvocab.txt\r\nparams.pdparams\r\n============  Configuration Arguments ============\r\nalpha: 2.6\r\nbatch_size: 128\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\nlang_model_path: /root/DeepSpeech/examples/aishell/../..//models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: /root/DeepSpeech/examples/aishell/../..//models/aishell/mean_std.npz\r\nmodel_path: /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntest_manifest: data/manifest.test\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: /root/DeepSpeech/examples/aishell/../..//models/aishell/vocab.txt\r\n================================================----\r\n2021-02-18 16:23:50,817-INFO: begin to initialize the external scorer for decoding\r\n2021-02-18 16:23:51,138-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2021-02-18 16:23:51,138-INFO: end initializing scorer\r\n2021-02-18 16:23:51,138-INFO: start evaluation ...\r\nW0218 16:23:55.017011  4562 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0218 16:23:55.025905  4562 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (128/?) = 0.055526\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (256/?) = 0.051899\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (384/?) = 0.052061\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (512/?) = 0.056111\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (640/?) = 0.053693\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (768/?) = 0.055531\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (896/?) = 0.056642\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1024/?) = 0.058581\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1152/?) = 0.058872\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1280/?) = 0.059066\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1408/?) = 0.060236\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1536/?) = 0.063794\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1664/?) = 0.067118\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1792/?) = 0.070420\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (1920/?) = 0.069857\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2048/?) = 0.068976\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2176/?) = 0.068703\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2304/?) = 0.068002\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2432/?) = 0.066791\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2560/?) = 0.066410\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2688/?) = 0.067141\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2816/?) = 0.067251\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (2944/?) = 0.068165\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3072/?) = 0.068429\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3200/?) = 0.068761\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3328/?) = 0.069398\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3456/?) = 0.070203\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3584/?) = 0.071271\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3712/?) = 0.073296\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3840/?) = 0.074478\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (3968/?) = 0.076443\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4096/?) = 0.075874\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4224/?) = 0.075810\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4352/?) = 0.075598\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4480/?) = 0.076835\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4608/?) = 0.078134\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4736/?) = 0.079075\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4864/?) = 0.078314\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (4992/?) = 0.077751\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5120/?) = 0.077168\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5248/?) = 0.076967\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5376/?) = 0.076557\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5504/?) = 0.075942\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5632/?) = 0.075414\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5760/?) = 0.075584\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (5888/?) = 0.076243\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6016/?) = 0.077038\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6144/?) = 0.078038\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6272/?) = 0.079831\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6400/?) = 0.081442\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6528/?) = 0.082090\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6656/?) = 0.081777\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6784/?) = 0.081388\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (6912/?) = 0.081175\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (7040/?) = 0.080895\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (7168/?) = 0.080448\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nError rate [cer] (7176/?) = 0.080447\r\nFinal error rate [cer] (7176/7176) = 0.080447\r\n2021-02-18 16:54:37,277-INFO: finish evaluation\r\nDownload language model ...\r\n./zh_giga.no_cna_cmn.prune01244.klm already exists, download skipped.\r\nDownload Aishell model ...\r\n./aishell_model_fluid.tar.gz already exists, download skipped.\r\nmean_std.npz\r\nREADME.md\r\nvocab.txt\r\nparams.pdparams\r\n============  Configuration Arguments ============\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/manifest.test\r\nlang_model_path: /root/DeepSpeech/examples/aishell/../..//models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: /root/DeepSpeech/examples/aishell/../..//models/aishell/mean_std.npz\r\nmodel_path: /root/DeepSpeech/examples/aishell/../..//models/aishell\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 0\r\nuse_gru: 1\r\nvocab_path: /root/DeepSpeech/examples/aishell/../..//models/aishell/vocab.txt\r\n================================================----\r\n2021-02-18 16:54:45,732-INFO: begin to initialize the external scorer for decoding\r\n2021-02-18 16:54:45,823-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2021-02-18 16:54:45,823-INFO: end initializing scorer\r\n2021-02-18 16:54:45,823-INFO: start inference ...\r\nfinish initing model from pretrained params from /root/DeepSpeech/examples/aishell/../..//models/aishell\r\n\r\nTarget Transcription: 维护正常的市场价格秩序\r\nOutput Transcription: 维护正常的市场价格秩序\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 研究者们选取了一些年龄大的跑者作为研究对象\r\nOutput Transcription: 研究者们选取了一些年龄大的跑者作为研究对象\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 在经济下行压力加大的背景下\r\nOutput Transcription: 在经济下行压力加大的背景下\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 公司已将原有的直销模式改为经销模式\r\nOutput Transcription: 公司已将原有的直销模式改为经销模式\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 记者从首都机场公安分局航站区派出所获悉\r\nOutput Transcription: 记者从首都机场公安分局行战区派出所获悉\r\nCurrent error rate [cer] = 0.105263\r\n\r\nTarget Transcription: 年龄大跑者的步幅明显短于年轻人\r\nOutput Transcription: 年龄大跑者的不服明显短于年轻人\r\nCurrent error rate [cer] = 0.133333\r\n\r\nTarget Transcription: 影片将在二零一五年一月在慕尼黑正式开机\r\nOutput Transcription: 影片将在二零一五年一月三目一黑正式开机\r\nCurrent error rate [cer] = 0.157895\r\n\r\nTarget Transcription: 在市场整体从高速增长进入中高速增长区间的同时\r\nOutput Transcription: 在市场整体从高速增长进入中高速增长区间的同时\r\nCurrent error rate [cer] = 0.000000\r\n\r\nTarget Transcription: 成功处置深航机上纵火事件\r\nOutput Transcription: 成功处置深航机上作火事件\r\nCurrent error rate [cer] = 0.083333\r\n\r\nTarget Transcription: 一线城市签约十七万套\r\nOutput Transcription: 一线城市签约十七万套\r\nCurrent error rate [cer] = 0.000000\r\n2021-02-18 16:54:57,788-INFO: finish inference\r\n============  Configuration Arguments ============\r\naugment_conf_path: /root/DeepSpeech/examples/aishell/../..//conf/augmentation.config\r\nbatch_size: 64\r\ndev_manifest: data/manifest.dev\r\ninit_from_pretrained_model: None\r\nis_local: 1\r\nlearning_rate: 0.0005\r\nmax_duration: 27.0\r\nmean_std_path: data/mean_std.npz\r\nmin_duration: 0.0\r\nnum_conv_layers: 2\r\nnum_epoch: 50\r\nnum_iter_print: 100\r\nnum_rnn_layers: 3\r\nnum_samples: 120000\r\noutput_model_dir: ./checkpoints\r\nrnn_layer_size: 1024\r\nsave_epoch: 1\r\nshare_rnn_weights: 0\r\nshuffle_method: batch_shuffle_clipped\r\nspecgram_type: linear\r\ntest_off: 0\r\ntrain_manifest: data/manifest.train\r\nuse_gpu: 1\r\nuse_gru: 1\r\nuse_sortagrad: 1\r\nvocab_path: data/vocab.txt\r\n================================================----\r\nW0218 16:54:59.143281 14427 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0218 16:54:59.152488 14427 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\nepoch: 0, batch: 0, train loss: 418.396118\r\n\r\nepoch: 0, batch: 100, train loss: 62.416603\r\n\r\nepoch: 0, batch: 200, train loss: 63.825356\r\n\r\nepoch: 0, batch: 300, train loss: 54.420654\r\n\r\nepoch: 0, batch: 400, train loss: 37.008553\r\n\r\nepoch: 0, batch: 500, train loss: 26.452053\r\n\r\nepoch: 0, batch: 600, train loss: 24.803284\r\n\r\nepoch: 0, batch: 700, train loss: 23.048244\r\n\r\nepoch: 0, batch: 800, train loss: 21.241261\r\n\r\nW0218 17:14:01.788877 14487 operator.cc:187] warpctc raises an exception paddle::memory::allocation::BadAlloc, \r\n\r\n================================================\r\nC++ Call Stacks (More useful to developers):\r\n================================================\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)\r\n2   paddle::memory::allocation::AlignedAllocator::AllocateImpl(unsigned long)\r\n3   paddle::memory::allocation::AutoGrowthBestFitAllocator::AllocateImpl(unsigned long)\r\n4   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n5   paddle::memory::allocation::RetryAllocator::AllocateImpl(unsigned long)\r\n6   paddle::memory::allocation::AllocatorFacade::Alloc(paddle::platform::Place const&, unsigned long)\r\n7   paddle::memory::Alloc(paddle::platform::Place const&, unsigned long)\r\n8   paddle::memory::Alloc(paddle::platform::DeviceContext const&, unsigned long)\r\n9   paddle::framework::Tensor paddle::framework::ExecutionContext::AllocateTmpTensor<float, paddle::platform::CUDADeviceContext>(paddle::framework::DDim const&, paddle::platform::CUDADeviceContext const&) const\r\n10  paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*)\r\n11  paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n12  std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n13  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n14  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n15  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n16  paddle::framework::details::ComputationOpHandle::RunImpl()\r\n17  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n18  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n19  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n20  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n21  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n========================\r\nError Message Summary:\r\n========================\r\nResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 142.958496MB memory on GPU 0, available memory is only 24.562500MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\n\r\n at (/paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:69)\r\nF0218 17:14:01.791173 14487 exception_holder.h:37] std::exception caught, \r\n\r\n================================================\r\nC++ Call Stacks (More useful to developers):\r\n================================================\r\n0   std::string paddle::platform::GetTraceBackString<std::string>(std::string&&, char const*, int)\r\n1   paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)\r\n2   paddle::memory::allocation::AlignedAllocator::AllocateImpl(unsigned long)\r\n3   paddle::memory::allocation::AutoGrowthBestFitAllocator::AllocateImpl(unsigned long)\r\n4   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n5   paddle::memory::allocation::RetryAllocator::AllocateImpl(unsigned long)\r\n6   paddle::memory::allocation::AllocatorFacade::Alloc(paddle::platform::Place const&, unsigned long)\r\n7   paddle::memory::Alloc(paddle::platform::Place const&, unsigned long)\r\n8   paddle::memory::Alloc(paddle::platform::DeviceContext const&, unsigned long)\r\n9   paddle::framework::Tensor paddle::framework::ExecutionContext::AllocateTmpTensor<float, paddle::platform::CUDADeviceContext>(paddle::framework::DDim const&, paddle::platform::CUDADeviceContext const&) const\r\n10  paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*)\r\n11  paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n12  std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n13  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n14  paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n15  paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n16  paddle::framework::details::ComputationOpHandle::RunImpl()\r\n17  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n18  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr<paddle::framework::BlockingQueue<unsigned long> > const&, unsigned long*)\r\n19  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n20  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n21  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n========================\r\nError Message Summary:\r\n========================\r\nResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 142.958496MB memory on GPU 0, available memory is only 24.562500MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\n\r\n at (/paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:69)\r\n*** Check failure stack trace: ***\r\n    @     0x7f0a4b55676d  google::LogMessage::Fail()\r\n    @     0x7f0a4b55a21c  google::LogMessage::SendToLog()\r\n    @     0x7f0a4b556293  google::LogMessage::Flush()\r\n    @     0x7f0a4b55b72e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f0a4e6acec8  paddle::framework::details::ExceptionHolder::Catch()\r\n    @     0x7f0a4e74808e  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync()\r\n    @     0x7f0a4e745a2f  paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp()\r\n    @     0x7f0a4e745cf4  _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_Any_data\r\n    @     0x7f0a4b5b3c33  std::_Function_handler<>::_M_invoke()\r\n    @     0x7f0a4b3b11b7  std::__future_base::_State_base::_M_do_set()\r\n    @     0x7f0b0ba3a997  __pthread_once_slow\r\n    @     0x7f0a4e741ec2  _ZNSt13__future_base11_Task_stateISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS4_12OpHandleBaseESt6atomicIiESt4hashIS8_ESt8equal_toIS8_ESaISt4pairIKS8_SA_EEES8_RKSt10shared_ptrINS3_13BlockingQueueImEEEEUlvE_vEESaIiEFvvEE6_M_runEv\r\n    @     0x7f0a4b3b3614  _ZZN10ThreadPoolC1EmENKUlvE_clEv\r\n    @     0x7f0a89db9421  execute_native_thread_routine_compat\r\n    @     0x7f0b0ba32fa3  start_thread\r\n    @     0x7f0b0b9634df  clone\r\n    @              (nil)  (unknown)\r\n./local/run_train.sh: line 33: 14427 Aborted                 CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python3 -u ${MAIN_ROOT}/train.py --batch_size=64 --num_epoch=50 --num_conv_layers=2 --num_rnn_layers=3 --rnn_layer_size=1024 --num_iter_print=100 --save_epoch=1 --num_samples=120000 --learning_rate=5e-4 --max_duration=27.0 --min_duration=0.0 --test_off=False --use_sortagrad=True --use_gru=True --use_gpu=True --is_local=True --share_rnn_weights=False --train_manifest=\"data/manifest.train\" --dev_manifest=\"data/manifest.dev\" --mean_std_path=\"data/mean_std.npz\" --vocab_path=\"data/vocab.txt\" --output_model_dir=\"./checkpoints\" --augment_conf_path=\"${MAIN_ROOT}/conf/augmentation.config\" --specgram_type=\"linear\" --shuffle_method=\"batch_shuffle_clipped\"\r\nFailed in training!\r\nDownload language model ...\r\n./zh_giga.no_cna_cmn.prune01244.klm already exists, download skipped.\r\n============  Configuration Arguments ============\r\nalpha: 2.6\r\nbatch_size: 128\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\nlang_model_path: /root/DeepSpeech/examples/aishell/../..//models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: data/mean_std.npz\r\nmodel_path: checkpoints/step_final\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\ntest_manifest: data/manifest.test\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: data/vocab.txt\r\n================================================----\r\n2021-02-18 17:14:08,242-INFO: begin to initialize the external scorer for decoding\r\n2021-02-18 17:14:08,423-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2021-02-18 17:14:08,423-INFO: end initializing scorer\r\n2021-02-18 17:14:08,423-INFO: start evaluation ...\r\nW0218 17:14:09.493114 19569 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0218 17:14:09.498034 19569 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\ncheckpoints/step_final\r\nTraceback (most recent call last):\r\n  File \"/root/DeepSpeech/examples/aishell/../..//test.py\", line 159, in <module>\r\n    main()\r\n  File \"/root/DeepSpeech/examples/aishell/../..//test.py\", line 155, in main\r\n    evaluate()\r\n  File \"/root/DeepSpeech/examples/aishell/../..//test.py\", line 123, in evaluate\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/root/DeepSpeech/model_utils/model.py\", line 420, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/root/DeepSpeech/model_utils/model.py\", line 164, in init_from_pretrained_model\r\n    raise Warning(\"The pretrained params do not exist.\")\r\nWarning: The pretrained params do not exist.\r\nFailed in evaluation!\r\nDownload language model ...\r\n./zh_giga.no_cna_cmn.prune01244.klm already exists, download skipped.\r\n============  Configuration Arguments ============\r\nalpha: 2.6\r\nbeam_size: 300\r\nbeta: 5.0\r\ncutoff_prob: 0.99\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: cer\r\ninfer_manifest: data/manifest.test\r\nlang_model_path: /root/DeepSpeech/examples/aishell/../..//models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: data/mean_std.npz\r\nmodel_path: checkpoints/step_final\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: 0\r\nspecgram_type: linear\r\nuse_gpu: 1\r\nuse_gru: 1\r\nvocab_path: data/vocab.txt\r\n================================================----\r\n2021-02-18 17:14:16,196-INFO: begin to initialize the external scorer for decoding\r\n2021-02-18 17:14:16,292-INFO: language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2021-02-18 17:14:16,292-INFO: end initializing scorer\r\n2021-02-18 17:14:16,292-INFO: start inference ...\r\nW0218 17:14:16.331327 19689 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0218 17:14:16.332828 19689 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\ncheckpoints/step_final\r\nTraceback (most recent call last):\r\n  File \"/root/DeepSpeech/examples/aishell/../..//infer.py\", line 159, in <module>\r\n    main()\r\n  File \"/root/DeepSpeech/examples/aishell/../..//infer.py\", line 155, in main\r\n    infer()\r\n  File \"/root/DeepSpeech/examples/aishell/../..//infer.py\", line 131, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/root/DeepSpeech/model_utils/model.py\", line 420, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/root/DeepSpeech/model_utils/model.py\", line 164, in init_from_pretrained_model\r\n    raise Warning(\"The pretrained params do not exist.\")\r\nWarning: The pretrained params do not exist.\r\nFailed in inference!\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-02-18T09:30:31+00:00",
        "updated_at": "2021-02-19T07:28:12+00:00",
        "closed_at": "2021-02-19T07:28:12+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "zh794390558",
            "monkeycc",
            "monkeycc",
            "monkeycc",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 527,
        "title": "examples里面的如何恢复训练",
        "body": "examples 目录源码\r\nbash ./local/run_train.sh\r\n\r\n-------------------------\r\n-# train model\r\n-# if you wish to resume from an exists model, uncomment --init_from_pretrained_model\r\nexport FLAGS_sync_nccl_allreduce=0\r\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\r\npython3 -u ${MAIN_ROOT}/train.py \\\r\n--batch_size=30 \\\r\n--num_epoch=50 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--num_iter_print=100 \\\r\n--save_epoch=1 \\\r\n--num_samples=120000 \\\r\n--learning_rate=5e-4 \\\r\n--max_duration=27.0 \\\r\n--min_duration=0.0 \\\r\n--test_off=False \\\r\n--use_sortagrad=True \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--is_local=True \\\r\n--share_rnn_weights=False \\\r\n--train_manifest=\"data/manifest.train\" \\\r\n--dev_manifest=\"data/manifest.dev\" \\\r\n--mean_std_path=\"data/mean_std.npz\" \\\r\n--vocab_path=\"data/vocab.txt\" \\\r\n--output_model_dir=\"./checkpoints\" \\\r\n--augment_conf_path=\"${MAIN_ROOT}/conf/augmentation.config\" \\\r\n--specgram_type=\"linear\" \\\r\n--shuffle_method=\"batch_shuffle_clipped\" \\\r\n\r\n-------------\r\n看了教程\r\n`python3 train.py \\\r\n--init_from_pretrained_model CHECKPOINT_PATH_TO_RESUME_FROM`\r\n\r\n那么这个\r\n--init_from_pretrained_model CHECKPOINT_PATH_TO_RESUME_FROM\r\n\r\n这个CHECKPOINT_PATH_TO_RESUME_FROM路径\r\n应该指的是哪里\r\n\r\n./local/run_train.sh\r\n直接在代码增加吗\r\n--init_from_pretrained_model = “？？？？？？？”\r\n\r\n\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-02-19T08:03:47+00:00",
        "updated_at": "2021-03-03T07:00:35+00:00",
        "closed_at": "2021-03-03T07:00:35+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 524,
        "title": "aishell的tune脚本",
        "body": "您好，我看librispeech文件下有run_tune.sh脚本，aishell没有对应的脚本，这两个一个是英文，一个是中文，run_tune.sh的参数配置应该是不一样的吧，希望可以补充该脚本",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "zh794390558",
        "created_at": "2021-02-09T03:29:18+00:00",
        "updated_at": "2021-03-03T07:00:23+00:00",
        "closed_at": "2021-03-03T07:00:23+00:00",
        "comments_count": [
            "zh794390558",
            "lfxx",
            "lfxx",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 526,
        "title": "DeepSpeech到底是python2还是python3",
        "body": "教程 写这 只支持 python2.7\r\n代码里面 却都是 python3\r\n\r\n就算教程没更新\r\n代码里面也有 SocketServer\r\npython2 中这个库叫SocketServer\r\npython3中这个库叫socketserver\r\n\r\n所以 感觉很乱",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "monkeycc",
        "created_at": "2021-02-18T13:30:25+00:00",
        "updated_at": "2021-02-25T06:14:26+00:00",
        "closed_at": "2021-02-19T08:10:21+00:00",
        "comments_count": [
            "zh794390558",
            "111firelicaifeng"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 529,
        "title": "利用预训练模型训练新的数据",
        "body": "如果想利用已有的预训练模型去训练新的语音数据，vocab.txt等配置文件是否需要修改？应该如何修改？",
        "state": "closed",
        "user": "xiaoyu4122",
        "closed_by": "zh794390558",
        "created_at": "2021-02-22T08:11:40+00:00",
        "updated_at": "2021-03-03T07:00:46+00:00",
        "closed_at": "2021-03-03T07:00:46+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 530,
        "title": "如何训练中英混杂的模型呢",
        "body": "",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "zh794390558",
        "created_at": "2021-02-22T10:49:13+00:00",
        "updated_at": "2021-03-11T08:12:00+00:00",
        "closed_at": "2021-03-11T08:12:00+00:00",
        "comments_count": [
            "zh794390558",
            "lfxx",
            "zh794390558",
            "lfxx",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 531,
        "title": "训练过程中，train loss : nan",
        "body": "aishell训练过程中，\r\nbash ./local/run_train.sh\r\n-------------------------------------------\r\nepoch: 0 , batch : 6700 ,  train loss : 64.74555\r\nepoch: 0 , batch : 6800 ,  train loss : nan\r\nepoch: 0 , batch : 6900 ,  train loss : nan\r\n.......\r\n------------------------------------------\r\ntrain loss : nan\r\n这个是什么问题导致的\r\n有没什么影响\r\n\r\nnvidia-smi 查看 一直正常",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-02-24T03:22:58+00:00",
        "updated_at": "2021-03-11T08:13:43+00:00",
        "closed_at": "2021-03-11T08:13:43+00:00",
        "comments_count": [
            "yeyupiaoling",
            "lfxx",
            "yeyupiaoling",
            "lfxx",
            "yeyupiaoling",
            "lfxx",
            "yeyupiaoling",
            "yeyupiaoling",
            "lfxx",
            "yeyupiaoling",
            "wuchaowei2012",
            "yeyupiaoling",
            "wuchaowei2012",
            "wuchaowei2012",
            "wuchaowei2012"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 532,
        "title": "预测中解码速度太慢",
        "body": "在预测中，单独的推理也就300ms，但这个解码就要11000ms，这个解码也太慢了。有没有加快解码速度的办法？\r\n \r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/054d795dc093e5063de1a02b23a6ac13d1cccef4/infer.py#L133-L141\r\n\r\n\r\n在沒有损坏准确率的情况下，有没有加快解码速度的办法？如果是修改`beam_size`，准确率会下降。我从`beam_size`为500改为5，错误率从7.6%升到8.5%\r\n ",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-02-24T09:37:40+00:00",
        "updated_at": "2021-03-02T07:55:59+00:00",
        "closed_at": "2021-03-02T07:55:59+00:00",
        "comments_count": [
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 533,
        "title": "Error in sh setup.sh,resampy",
        "body": "I have install paddlepaddle2.0.\r\nI also have \r\n`sudo apt-get install -y pkg-config libflac-dev libogg-dev libvorbis-dev libboost-dev swig python3-dev`\r\nbut when I run\r\n`python -m pip install -r requirements.txt`\r\nThe error occur,but I use\r\n`pip install resampy'\r\nThe are correct\r\n\r\nTheError\r\n```\r\nBuilding wheels for collected packages: resampy\r\n  Building wheel for resampy (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /home/mocai/.conda/envs/GraProPy37/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-5ezne7_7\r\n       cwd: /tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/\r\n  Complete output (123 lines):\r\n  /tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n    import imp\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/resampy\r\n  copying resampy/version.py -> build/lib.linux-x86_64-3.7/resampy\r\n  copying resampy/core.py -> build/lib.linux-x86_64-3.7/resampy\r\n  copying resampy/__init__.py -> build/lib.linux-x86_64-3.7/resampy\r\n  copying resampy/filters.py -> build/lib.linux-x86_64-3.7/resampy\r\n  creating build/lib.linux-x86_64-3.7/resampy/data\r\n  copying resampy/data/kaiser_best.npz -> build/lib.linux-x86_64-3.7/resampy/data\r\n  copying resampy/data/kaiser_fast.npz -> build/lib.linux-x86_64-3.7/resampy/data\r\n  running build_ext\r\n  building 'resampy.interp' extension\r\n  creating build/temp.linux-x86_64-3.7\r\n  creating build/temp.linux-x86_64-3.7/resampy\r\n  gcc -pthread -B /home/mocai/.conda/envs/GraProPy37/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include -I/home/mocai/.conda/envs/GraProPy37/include/python3.7m -c resampy/interp.c -o build/temp.linux-x86_64-3.7/resampy/interp.o\r\n  In file included from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1944:0,\r\n                   from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\r\n                   from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4,\r\n                   from resampy/interp.c:286:\r\n  /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\r\n   #warning \"Using deprecated NumPy API, disable it with \" \\\r\n    ^~~~~~~\r\n  resampy/interp.c: In function ‘__Pyx__ExceptionSave’:\r\n  resampy/interp.c:20816:21: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       *type = tstate->exc_type;\r\n                       ^~~~~~~~\r\n                       curexc_type\r\n  resampy/interp.c:20817:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       *value = tstate->exc_value;\r\n                        ^~~~~~~~~\r\n                        curexc_value\r\n  resampy/interp.c:20818:19: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       *tb = tstate->exc_traceback;\r\n                     ^~~~~~~~~~~~~\r\n                     curexc_traceback\r\n  resampy/interp.c: In function ‘__Pyx__ExceptionReset’:\r\n  resampy/interp.c:20825:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tmp_type = tstate->exc_type;\r\n                          ^~~~~~~~\r\n                          curexc_type\r\n  resampy/interp.c:20826:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tmp_value = tstate->exc_value;\r\n                           ^~~~~~~~~\r\n                           curexc_value\r\n  resampy/interp.c:20827:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tmp_tb = tstate->exc_traceback;\r\n                        ^~~~~~~~~~~~~\r\n                        curexc_traceback\r\n  resampy/interp.c:20828:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tstate->exc_type = type;\r\n               ^~~~~~~~\r\n               curexc_type\r\n  resampy/interp.c:20829:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tstate->exc_value = value;\r\n               ^~~~~~~~~\r\n               curexc_value\r\n  resampy/interp.c:20830:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tstate->exc_traceback = tb;\r\n               ^~~~~~~~~~~~~\r\n               curexc_traceback\r\n  resampy/interp.c: In function ‘__Pyx__GetException’:\r\n  resampy/interp.c:20885:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tmp_type = tstate->exc_type;\r\n                          ^~~~~~~~\r\n                          curexc_type\r\n  resampy/interp.c:20886:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tmp_value = tstate->exc_value;\r\n                           ^~~~~~~~~\r\n                           curexc_value\r\n  resampy/interp.c:20887:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tmp_tb = tstate->exc_traceback;\r\n                        ^~~~~~~~~~~~~\r\n                        curexc_traceback\r\n  resampy/interp.c:20888:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tstate->exc_type = local_type;\r\n               ^~~~~~~~\r\n               curexc_type\r\n  resampy/interp.c:20889:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tstate->exc_value = local_value;\r\n               ^~~~~~~~~\r\n               curexc_value\r\n  resampy/interp.c:20890:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tstate->exc_traceback = local_tb;\r\n               ^~~~~~~~~~~~~\r\n               curexc_traceback\r\n  resampy/interp.c: In function ‘__Pyx__ExceptionSwap’:\r\n  resampy/interp.c:22495:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tmp_type = tstate->exc_type;\r\n                          ^~~~~~~~\r\n                          curexc_type\r\n  resampy/interp.c:22496:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tmp_value = tstate->exc_value;\r\n                           ^~~~~~~~~\r\n                           curexc_value\r\n  resampy/interp.c:22497:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tmp_tb = tstate->exc_traceback;\r\n                        ^~~~~~~~~~~~~\r\n                        curexc_traceback\r\n  resampy/interp.c:22498:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n       tstate->exc_type = *type;\r\n               ^~~~~~~~\r\n               curexc_type\r\n  resampy/interp.c:22499:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n       tstate->exc_value = *value;\r\n               ^~~~~~~~~\r\n               curexc_value\r\n  resampy/interp.c:22500:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n       tstate->exc_traceback = *tb;\r\n               ^~~~~~~~~~~~~\r\n               curexc_traceback\r\n  In file included from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:21:0,\r\n                   from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4,\r\n                   from resampy/interp.c:286:\r\n  At top level:\r\n  /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/__multiarray_api.h:1464:1: warning: ‘_import_array’ defined but not used [-Wunused-function]\r\n   _import_array(void)\r\n   ^~~~~~~~~~~~~\r\n  error: command 'gcc' failed with exit status 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for resampy\r\n  Running setup.py clean for resampy\r\nFailed to build resampy\r\nInstalling collected packages: resampy, python-speech-features\r\n  Attempting uninstall: resampy\r\n    Found existing installation: resampy 0.2.2\r\n    Uninstalling resampy-0.2.2:\r\n      Successfully uninstalled resampy-0.2.2\r\n    Running setup.py install for resampy ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /home/mocai/.conda/envs/GraProPy37/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xhz6ua1b/install-record.txt --single-version-externally-managed --compile --install-headers /home/mocai/.conda/envs/GraProPy37/include/python3.7m/resampy\r\n         cwd: /tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/\r\n    Complete output (123 lines):\r\n    /tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n      import imp\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/resampy\r\n    copying resampy/version.py -> build/lib.linux-x86_64-3.7/resampy\r\n    copying resampy/core.py -> build/lib.linux-x86_64-3.7/resampy\r\n    copying resampy/__init__.py -> build/lib.linux-x86_64-3.7/resampy\r\n    copying resampy/filters.py -> build/lib.linux-x86_64-3.7/resampy\r\n    creating build/lib.linux-x86_64-3.7/resampy/data\r\n    copying resampy/data/kaiser_best.npz -> build/lib.linux-x86_64-3.7/resampy/data\r\n    copying resampy/data/kaiser_fast.npz -> build/lib.linux-x86_64-3.7/resampy/data\r\n    running build_ext\r\n    building 'resampy.interp' extension\r\n    creating build/temp.linux-x86_64-3.7\r\n    creating build/temp.linux-x86_64-3.7/resampy\r\n    gcc -pthread -B /home/mocai/.conda/envs/GraProPy37/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include -I/home/mocai/.conda/envs/GraProPy37/include/python3.7m -c resampy/interp.c -o build/temp.linux-x86_64-3.7/resampy/interp.o\r\n    In file included from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1944:0,\r\n                     from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\r\n                     from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4,\r\n                     from resampy/interp.c:286:\r\n    /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\r\n     #warning \"Using deprecated NumPy API, disable it with \" \\\r\n      ^~~~~~~\r\n    resampy/interp.c: In function ‘__Pyx__ExceptionSave’:\r\n    resampy/interp.c:20816:21: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         *type = tstate->exc_type;\r\n                         ^~~~~~~~\r\n                         curexc_type\r\n    resampy/interp.c:20817:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         *value = tstate->exc_value;\r\n                          ^~~~~~~~~\r\n                          curexc_value\r\n    resampy/interp.c:20818:19: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         *tb = tstate->exc_traceback;\r\n                       ^~~~~~~~~~~~~\r\n                       curexc_traceback\r\n    resampy/interp.c: In function ‘__Pyx__ExceptionReset’:\r\n    resampy/interp.c:20825:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tmp_type = tstate->exc_type;\r\n                            ^~~~~~~~\r\n                            curexc_type\r\n    resampy/interp.c:20826:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tmp_value = tstate->exc_value;\r\n                             ^~~~~~~~~\r\n                             curexc_value\r\n    resampy/interp.c:20827:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tmp_tb = tstate->exc_traceback;\r\n                          ^~~~~~~~~~~~~\r\n                          curexc_traceback\r\n    resampy/interp.c:20828:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tstate->exc_type = type;\r\n                 ^~~~~~~~\r\n                 curexc_type\r\n    resampy/interp.c:20829:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tstate->exc_value = value;\r\n                 ^~~~~~~~~\r\n                 curexc_value\r\n    resampy/interp.c:20830:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tstate->exc_traceback = tb;\r\n                 ^~~~~~~~~~~~~\r\n                 curexc_traceback\r\n    resampy/interp.c: In function ‘__Pyx__GetException’:\r\n    resampy/interp.c:20885:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tmp_type = tstate->exc_type;\r\n                            ^~~~~~~~\r\n                            curexc_type\r\n    resampy/interp.c:20886:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tmp_value = tstate->exc_value;\r\n                             ^~~~~~~~~\r\n                             curexc_value\r\n    resampy/interp.c:20887:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tmp_tb = tstate->exc_traceback;\r\n                          ^~~~~~~~~~~~~\r\n                          curexc_traceback\r\n    resampy/interp.c:20888:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tstate->exc_type = local_type;\r\n                 ^~~~~~~~\r\n                 curexc_type\r\n    resampy/interp.c:20889:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tstate->exc_value = local_value;\r\n                 ^~~~~~~~~\r\n                 curexc_value\r\n    resampy/interp.c:20890:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tstate->exc_traceback = local_tb;\r\n                 ^~~~~~~~~~~~~\r\n                 curexc_traceback\r\n    resampy/interp.c: In function ‘__Pyx__ExceptionSwap’:\r\n    resampy/interp.c:22495:24: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tmp_type = tstate->exc_type;\r\n                            ^~~~~~~~\r\n                            curexc_type\r\n    resampy/interp.c:22496:25: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tmp_value = tstate->exc_value;\r\n                             ^~~~~~~~~\r\n                             curexc_value\r\n    resampy/interp.c:22497:22: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tmp_tb = tstate->exc_traceback;\r\n                          ^~~~~~~~~~~~~\r\n                          curexc_traceback\r\n    resampy/interp.c:22498:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_type’; did you mean ‘curexc_type’?\r\n         tstate->exc_type = *type;\r\n                 ^~~~~~~~\r\n                 curexc_type\r\n    resampy/interp.c:22499:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_value’; did you mean ‘curexc_value’?\r\n         tstate->exc_value = *value;\r\n                 ^~~~~~~~~\r\n                 curexc_value\r\n    resampy/interp.c:22500:13: error: ‘PyThreadState {aka struct _ts}’ has no member named ‘exc_traceback’; did you mean ‘curexc_traceback’?\r\n         tstate->exc_traceback = *tb;\r\n                 ^~~~~~~~~~~~~\r\n                 curexc_traceback\r\n    In file included from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:21:0,\r\n                     from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4,\r\n                     from resampy/interp.c:286:\r\n    At top level:\r\n    /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/numpy/core/include/numpy/__multiarray_api.h:1464:1: warning: ‘_import_array’ defined but not used [-Wunused-function]\r\n     _import_array(void)\r\n     ^~~~~~~~~~~~~\r\n    error: command 'gcc' failed with exit status 1\r\n    ----------------------------------------\r\n  Rolling back uninstall of resampy\r\n  Moving to /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/resampy-0.2.2.dist-info/\r\n   from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/~esampy-0.2.2.dist-info\r\n  Moving to /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/resampy/\r\n   from /home/mocai/.conda/envs/GraProPy37/lib/python3.7/site-packages/~esampy\r\nERROR: Command errored out with exit status 1: /home/mocai/.conda/envs/GraProPy37/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_9d9_e87/resampy_23028cdbed534bb79ae27cfda3de1e78/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xhz6ua1b/install-record.txt --single-version-externally-managed --compile --install-headers /home/mocai/.conda/envs/GraProPy37/include/python3.7m/resampy Check the logs for full command output.\r\n```",
        "state": "closed",
        "user": "ccbptm",
        "closed_by": "zh794390558",
        "created_at": "2021-02-25T07:06:08+00:00",
        "updated_at": "2021-03-11T08:11:32+00:00",
        "closed_at": "2021-03-11T08:11:32+00:00",
        "comments_count": [
            "zh794390558",
            "ccbptm",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 534,
        "title": "用了aishell训练出来的模型，怎么测试自己的音频",
        "body": "用了aishell训练出来的模型，怎么测试自己的音频",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-02-27T15:33:21+00:00",
        "updated_at": "2021-03-11T08:11:20+00:00",
        "closed_at": "2021-03-11T08:11:20+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 535,
        "title": "用自己的声音尝试现场演示报错",
        "body": "我用了aishell的模型进行测试，结果报错\r\n\r\nCUDA_VISIBLE_DEVICES=0 python3 deploy/demo_server.py --host_ip localhost --host_port 8086\r\n‘-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nhost_ip: localhost\r\nhost_port: 8086\r\nlang_model_path: /root/DeepSpeech/models/lm/common_crawl_00.prune01111.trie.klm\r\nmean_std_path: /root/DeepSpeech/examples/aishell/data/mean_std.npz\r\nmodel_path: /root/DeepSpeech/examples/aishell/checkpoints/step_final\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 2048\r\nshare_rnn_weights: True\r\nspecgram_type: linear\r\nspeech_save_dir: demo_cache\r\nuse_gpu: True\r\nuse_gru: False\r\nvocab_path: /root/DeepSpeech/examples/aishell/data/vocab.txt\r\nwarmup_manifest: /root/DeepSpeech/examples/aishell/data/manifest.test-clean\r\n’------------------------------------------------\r\n2021-02-27 23:31:05,084-INFO: begin to initialize the external scorer for decoding\r\n2021-02-27 23:31:08,785-INFO: language model: is_character_based = 0, max_order = 5, dict_size = 0\r\n2021-02-27 23:31:08,785-INFO: end initializing scorer\r\n‘-----------------------------------------------------------\r\nWarming up ...\r\nWarm-up Test Case %d: %s 0 /root/DeepSpeech/examples/aishell/../..//dataset/aishell/data_aishell/wav/test/S0916/BAC009S0916W0385.wav\r\nW0227 23:31:08.934581  8325 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW0227 23:31:08.942637  8325 device_context.cc:260] device: 0, cuDNN Version: 8.0.\r\n/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"deploy/demo_server.py\", line 251, in <module>\r\n    main()\r\n  File \"deploy/demo_server.py\", line 247, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 232, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 149, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 208, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 420, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 170, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 876, in load_params\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 750, in load_vars\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 804, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n’--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n‘--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, paddle::platform::Place const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const\r\n3   paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n9   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n10  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n’------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n‘------------------------------------------\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 802, in load_vars\r\n    'model_from_memory': vars_from_memory\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 750, in load_vars\r\n    filename=filename)\r\n  File \"/root/anaconda3/envs/DeepSpeech36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 876, in load_params\r\n    filename=filename)\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 170, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/root/DeepSpeech/deploy/../model_utils/model.py\", line 420, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"deploy/demo_server.py\", line 208, in file_to_transcript\r\n    feeding_dict=data_generator.feeding)\r\n  File \"deploy/demo_server.py\", line 149, in warm_up_test\r\n    transcript = audio_process_handler(sample['audio_filepath'])\r\n  File \"deploy/demo_server.py\", line 232, in start_server\r\n    num_test_cases=3)\r\n  File \"deploy/demo_server.py\", line 247, in main\r\n    start_server()\r\n  File \"deploy/demo_server.py\", line 251, in <module>\r\n    main()\r\n\r\n’----------------------\r\nError Message Summary:\r\n‘----------------------\r\nUnavailableError: Not allowed to load partial data via load_combine_op, please use load_op instead.\r\n  [Hint: Expected buffer->eof() == true, but received buffer->eof():0 != true:1.] at (/paddle/paddle/fluid/operators/load_combine_op.h:115)\r\n  [operator < load_combine > error]\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-02-27T15:35:53+00:00",
        "updated_at": "2021-03-24T08:18:16+00:00",
        "closed_at": "2021-03-24T08:18:16+00:00",
        "comments_count": [
            "zh794390558",
            "monkeycc",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 536,
        "title": "baidu_cn1.2按照8000采样报错",
        "body": "我使用baidu_cn1.2模型进行测试,\r\n\r\ndemo_client:\r\ndata_dir='/home/audio/asr/wav/'\r\n#data_path=os.listdir(data_dir)\r\n#for audio_file in data_path:\r\naudio_file = \"chunk0.wav\"\r\nprint(audio_file) \r\n\r\n(HOST, PORT) = ('localhost', 8086)\r\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\ns.connect((HOST, PORT))\r\nw=wave.open(os.path.join(data_dir,audio_file), 'r')\r\nn = w.getnframes()\r\ndata = w.readframes(n)\r\ns.sendall(struct.pack('>i', len(data)) + data)\r\nreceived = s.recv(1024)\r\nprint(received.decode('utf-8'))\r\n\r\n\r\ndemo_server参数:\r\n\r\nadd_arg('host_port',        int,    8086,    \"Server's IP port.\")\r\nadd_arg('beam_size',        int,    500,    \"Beam search width.\")\r\nadd_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\nadd_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\nadd_arg('rnn_layer_size',   int,    2048,   \"# of recurrent cells per layer.\")\r\nadd_arg('alpha',            float,  2.5,   \"Coef of LM for beam search.\")\r\nadd_arg('beta',             float,  0.3,   \"Coef of WC for beam search.\")\r\nadd_arg('cutoff_prob',      float,  1,    \"Cutoff probability for pruning.\")\r\nadd_arg('cutoff_top_n',     int,    40,     \"Cutoff number for pruning.\")\r\nadd_arg('use_gru',          bool,   True,  \"Use GRUs instead of simple RNNs.\")\r\nadd_arg('use_gpu',          bool,   True,   \"Use GPU or not.\")\r\nadd_arg('share_rnn_weights',bool,   False,   \"Share input-hidden weights across \"\r\n                                            \"bi-directional RNNs. Not for GRU.\")\r\nadd_arg('host_ip',          str,\r\n        'localhost',\r\n        \"Server's IP address.\")\r\nadd_arg('speech_save_dir',  str,\r\n        '/home/audio/asr/temp_dir',\r\n        \"Directory to save demo audios.\")\r\nadd_arg('warmup_manifest',  str,\r\n        '/home/audio/asr/DeepSpeech/examples/aishell/data/manifest.test',\r\n        \"Filepath of manifest to warm up.\")\r\nadd_arg('mean_std_path',    str,\r\n        '/home/audio/asr/DeepSpeech/models/baidu_cn1.2k/mean_std.npz',\r\n        \"Filepath of normalizer's mean & std.\")\r\nadd_arg('vocab_path',       str,\r\n        '/home/audio/asr/DeepSpeech/models/baidu_cn1.2k/vocab.txt',\r\n        \"Filepath of vocabulary.\")\r\nadd_arg('model_path',       str,\r\n        '/home/audio/asr/DeepSpeech/models/baidu_cn1.2k/',\r\n        \"If None, the training starts from scratch, \"\r\n        \"otherwise, it resumes from the pre-trained model.\")\r\nadd_arg('lang_model_path',  str,\r\n        '/home/audio/asr/DeepSpeech/models/lm/zh_giga.no_cna_cmn.prune01244.klm',\r\n        \"Filepath for language model.\")\r\nadd_arg('decoding_method',  str,\r\n        'ctc_beam_search',\r\n        \"Decoding method. Options: ctc_beam_search, ctc_greedy\",\r\n        choices = ['ctc_beam_search', 'ctc_greedy'])\r\nadd_arg('specgram_type',    str,\r\n        'linear',\r\n        \"Audio feature type. Options: linear, mfcc.\",\r\n        choices=['linear', 'mfcc'])\r\n\r\n_write_to_file函数:\r\n        file = wave.open(out_filename, 'wb')\r\n        file.setnchannels(1)\r\n        file.setsampwidth(4)\r\n        file.setframerate(16000)\r\n        file.writeframes(data)\r\n\r\n当file.setframerate(16000) 改为 file.setframerate(8000)报错:\r\n\r\nException happened during processing of request from ('127.0.0.1', 60322)\r\nTraceback (most recent call last):\r\n  File \"/home/cs/anaconda3/envs/dp/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\r\n    self.process_request(request, client_address)\r\n  File \"/home/cs/anaconda3/envs/dp/lib/python3.6/socketserver.py\", line 351, in process_request\r\n    self.finish_request(request, client_address)\r\n  File \"/home/cs/anaconda3/envs/dp/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/home/cs/anaconda3/envs/dp/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"server_test.py\", line 114, in handle\r\n    transcript = self.server.audio_process_handler(filename)\r\n  File \"server_test.py\", line 196, in file_to_transcript\r\n    feature = data_generator.process_utterance(filename, \"\")\r\n  File \"/home/audio/asr/DeepSpeech/deploy/../data_utils/data.py\", line 131, in process_utterance\r\n    speech_segment, self._keep_transcription_text)\r\n  File \"/home/audio/asr/DeepSpeech/deploy/../data_utils/featurizer/speech_featurizer.py\", line 86, in featurize\r\n    audio_feature = self._audio_featurizer.featurize(speech_segment)\r\n  File \"/home/audio/asr/DeepSpeech/deploy/../data_utils/featurizer/audio_featurizer.py\", line 90, in featurize\r\n    audio_segment.resample(self._target_sample_rate)\r\n  File \"/home/audio/asr/DeepSpeech/deploy/../data_utils/audio.py\", line 410, in resample\r\n    self.samples, self.sample_rate, target_sample_rate, filter=filter)\r\n  File \"/home/cs/anaconda3/envs/dp/lib/python3.6/site-packages/resampy/core.py\", line 92, in resample\r\n    'Only floating-point types are supported.'.format(x.dtype))\r\nTypeError: Unable to resample signals of dtype=float32. Only floating-point types are supported.\r\n\r\n\r\n临时语音20210302075108_127.0.0.1.wav与原始语音不一样,感觉都是杂音",
        "state": "closed",
        "user": "chasemy",
        "closed_by": "zh794390558",
        "created_at": "2021-03-02T07:57:01+00:00",
        "updated_at": "2021-03-24T08:18:06+00:00",
        "closed_at": "2021-03-24T08:18:06+00:00",
        "comments_count": [
            "zh794390558",
            "DemoMoon",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 537,
        "title": "run on corol tpu",
        "body": "After converting the model to tflite format. Is it possible to use it with corol tpu ?",
        "state": "closed",
        "user": "roboticsai",
        "closed_by": "zh794390558",
        "created_at": "2021-03-03T13:15:41+00:00",
        "updated_at": "2021-03-17T03:13:09+00:00",
        "closed_at": "2021-03-17T03:13:09+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 539,
        "title": "什么时候搞个QQ群",
        "body": "什么时候搞个QQ群\r\n\r\n大家交流起来 也方便",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-03-05T02:45:13+00:00",
        "updated_at": "2021-03-11T08:11:11+00:00",
        "closed_at": "2021-03-11T08:11:11+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 540,
        "title": "Run infer.py时报错",
        "body": "以前example什么的跑的都是好的，然后想用自己的数据试试就下了几个flac文件，然后把那些文件的manifest做出来之后用infer.py跑就报这个错： \r\n-----------  Configuration Arguments -----------\r\nalpha: 2.5\r\nbeam_size: 500\r\nbeta: 0.3\r\ncutoff_prob: 1.0\r\ncutoff_top_n: 40\r\ndecoding_method: ctc_beam_search\r\nerror_rate_type: wer\r\ninfer_manifest: /home/ubuntu/DeepSpeech/data/aishell/testmani2\r\nlang_model_path: models/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nmean_std_path: /home/ubuntu/DeepSpeech/models/aishell/mean_std.npz\r\nmodel_path: checkpoints/aishell/step_final\r\nnum_conv_layers: 2\r\nnum_proc_bsearch: 8\r\nnum_rnn_layers: 3\r\nnum_samples: 10\r\nrnn_layer_size: 1024\r\nshare_rnn_weights: False\r\nspecgram_type: linear\r\nuse_gpu: True\r\nuse_gru: True\r\nvocab_path: /home/ubuntu/DeepSpeech/models/aishell/vocab.txt\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 146, in <module>\r\n    main()\r\n  File \"infer.py\", line 142, in main\r\n    infer()\r\n  File \"infer.py\", line 88, in infer\r\n    infer_data = next(batch_reader())\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/data.py\", line 197, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/data.py\", line 276, in reader\r\n    instance[\"text\"])\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/data.py\", line 118, in process_utterance\r\n    speech_segment, self._keep_transcription_text)\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/featurizer/speech_featurizer.py\", line 73, in featurize\r\n    audio_feature = self._audio_featurizer.featurize(speech_segment)\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/featurizer/audio_featurizer.py\", line 77, in featurize\r\n    audio_segment.resample(self._target_sample_rate)\r\n  File \"/home/ubuntu/DeepSpeech/data_utils/audio.py\", line 397, in resample\r\n    self.samples, self.sample_rate, target_sample_rate, filter=filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/resampy/core.py\", line 92, in resample\r\n    'Only floating-point types are supported.'.format(x.dtype))\r\nTypeError: Unable to resample signals of dtype=float32. Only floating-point types are supported.\r\n用的是python3.6.9和paddlepaddle-gpu1.8.5",
        "state": "closed",
        "user": "TyroneHe-0926",
        "closed_by": "TyroneHe-0926",
        "created_at": "2021-03-05T03:16:14+00:00",
        "updated_at": "2021-03-05T07:13:46+00:00",
        "closed_at": "2021-03-05T07:13:46+00:00",
        "comments_count": [
            "zh794390558",
            "TyroneHe-0926"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 541,
        "title": "train out of memmory ",
        "body": "显卡16G，8卡训练。\r\n训练例子都没有问题，但是训练自己的数据集总是报oom的错误。\r\nbatch-size 64  训练10000多个batch后oom\r\nbatch-size 32 训练20000多个batch后oom\r\nbatch-size16 训练50000多个batch后oom\r\n这是显存泄漏造的bug吗？请教该如何调试？",
        "state": "closed",
        "user": "wwj8837817",
        "closed_by": "zh794390558",
        "created_at": "2021-03-06T08:04:21+00:00",
        "updated_at": "2021-12-28T17:14:31+00:00",
        "closed_at": "2021-03-24T08:17:57+00:00",
        "comments_count": [
            "zh794390558",
            "wwj8837817",
            "zh794390558",
            "jeffzhengye"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 553,
        "title": "训练报错",
        "body": "----------Begin test...\r\n[WARNING 2021-03-12 17:08:54,584 reader.py:1144] Your reader has raised an exception!\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1145, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1125, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/home/weiao/DeepSpeech/data_utils/data.py\", line 200, in batch_reader\r\n    for instance in instance_reader():\r\n  File \"/home/weiao/DeepSpeech/data_utils/data.py\", line 279, in reader\r\n    instance[\"text\"]),\r\n  File \"/home/weiao/DeepSpeech/data_utils/data.py\", line 121, in process_utterance\r\n    speech_segment, self._keep_transcription_text)\r\n  File \"/home/weiao/DeepSpeech/data_utils/featurizer/speech_featurizer.py\", line 79, in featurize\r\n    text_ids = self._text_featurizer.featurize(speech_segment.transcript)\r\n  File \"/home/weiao/DeepSpeech/data_utils/featurizer/text_featurizer.py\", line 36, in featurize\r\n    return [self._vocab_dict[token] for token in tokens]\r\nKeyError: u'\\u80c1'\r\n\r\n/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"/home/weiao/DeepSpeech/model_utils/model.py\", line 366, in train\r\n    fetch_list=[ctc_loss])\r\n  File \"/home/weiao/DeepSpeech/model_utils/model.py\", line 217, in test\r\n    return_numpy=False)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 1080, in _init_non_iterable\r\n    attrs={'drop_last': self._drop_last})\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 978, in __init__\r\n    self._init_non_iterable()\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/reader.py\", line 620, in from_generator\r\n    iterable, return_list, drop_last)\r\n  File \"/home/weiao/DeepSpeech/model_utils/model.py\", line 112, in create_network\r\n    use_double_buffer=True)\r\n  File \"/home/weiao/DeepSpeech/model_utils/model.py\", line 296, in train\r\n    test_reader, _, ctc_loss = self.create_network()\r\n  File \"train.py\", line 133, in train\r\n    test_off=args.test_off)\r\n  File \"train.py\", line 138, in main\r\n    train()\r\n  File \"train.py\", line 142, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\r\n  [operator < read > error]\r\n\r\n",
        "state": "closed",
        "user": "weiaoliu",
        "closed_by": "weiaoliu",
        "created_at": "2021-03-12T09:13:07+00:00",
        "updated_at": "2021-03-12T14:17:43+00:00",
        "closed_at": "2021-03-12T14:17:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 542,
        "title": "No module named 'SocketServer'",
        "body": "根据官方 Trying Live Demo with Your Own Voice 教程\r\n\r\nTo start the demo's server, please run this in one console:\r\n\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython3 deploy/demo_server.py \\\r\n--host_ip localhost \\\r\n--host_port 8086\r\n\r\n报错 No module named 'SocketServer'\r\n----------------------------------------\r\n\r\nDeepSpeech/deploy/demo_server.py \r\n\r\nimport SocketServer\r\n\r\n这个 SocketServer 是在python2中使用\r\n\r\n应该改为 socketserver ",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "zh794390558",
        "created_at": "2021-03-06T10:25:40+00:00",
        "updated_at": "2021-03-24T08:17:49+00:00",
        "closed_at": "2021-03-24T08:17:49+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 543,
        "title": "release-v1.8.5版本使用cn1.2k预训练模型难以预测的问题",
        "body": "release-v1.8.5这个版本的cn1.2k模型，使用aishell的mean_std.npz\r\n```\r\nadd_arg('mean_std_path',    str,\r\n        'models/aishell/mean_std.npz',\r\n        \"Filepath of normalizer's mean & std.\")\r\n```\r\n做预测时，错字率20%-40%。\r\n\r\n但使用自带的baidu_cn1.2k_model_fluid/mean_std.npz\r\n```\r\nadd_arg('mean_std_path',    str,\r\n        'models/baidu_cn1.2k_model_fluid/mean_std.npz',\r\n        \"Filepath of normalizer's mean & std.\")\r\n```\r\n做预测时输出结果全是“我”、“得”。\r\n\r\n对此十分迷惑，希望得到解答。",
        "state": "closed",
        "user": "haoranchen06",
        "closed_by": "zh794390558",
        "created_at": "2021-03-08T11:02:42+00:00",
        "updated_at": "2021-03-24T08:17:41+00:00",
        "closed_at": "2021-03-24T08:17:41+00:00",
        "comments_count": [
            "zh794390558",
            "haoranchen06",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 551,
        "title": "预训练模型无法下载",
        "body": "您好，最近在使用deepspeech时发现无法下载已经训练好的libr声学模型，报错：\r\nERROR 502: Bad Gateway.\r\n\r\n看之前也有人提到这个问题，不知道怎么了",
        "state": "closed",
        "user": "RongerSnow",
        "closed_by": "zh794390558",
        "created_at": "2018-07-22T12:09:49+00:00",
        "updated_at": "2021-05-12T05:13:35+00:00",
        "closed_at": "2021-05-12T05:13:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 548,
        "title": "deepspeech中遇到了 ValueError: invalid literal for int() with base 10: 'params.pdparams'",
        "body": "您好，我在使用前天更新的开发版中遇到了此问题：\r\n采用的预训练模型aishell_model_fluid.tar.gz,语言模型zh_giga.no_cna_cmn.prune01244.klm,环境部署完成, 执行bash local/infer.sh 命令时出现下列错误。\r\n\r\n-----------  Configuration Arguments -----------\r\ncheckpoint_path: data/lm/zh_giga.no_cna_cmn.prune01244.klm\r\nconfig: conf/deepspeech2.yaml\r\ndevice: cpu\r\ndump_config: None\r\nexport_path: None\r\nnprocs: 1\r\nopts: []\r\noutput: None\r\n------------------------------------------------\r\ndata:\r\n  augmentation_config: conf/augmentation.config\r\n  batch_size: 64\r\n  dev_manifest: data/manifest.dev\r\n  keep_transcription_text: False\r\n  max_duration: 27.0\r\n  max_freq: None\r\n  mean_std_filepath: data/mean_std.npz\r\n  min_duration: 0.0\r\n  n_fft: None\r\n  num_workers: 0\r\n  random_seed: 0\r\n  shuffle_method: batch_shuffle\r\n  sortagrad: True\r\n  specgram_type: linear\r\n  stride_ms: 10.0\r\n  target_dB: -20\r\n  target_sample_rate: 16000\r\n  test_manifest: data/manifest.test\r\n  train_manifest: data/manifest.train\r\n  use_dB_normalization: True\r\n  vocab_filepath: data/vocab.txt\r\n  window_ms: 20.0\r\ndecoding:\r\n  alpha: 2.6\r\n  batch_size: 128\r\n  beam_size: 300\r\n  beta: 5.0\r\n  cutoff_prob: 0.99\r\n  cutoff_top_n: 40\r\n  decoding_method: ctc_beam_search\r\n  error_rate_type: cer\r\n  lang_model_path: data/lm/zh_giga.no_cna_cmn.prune01244.klm\r\n  num_proc_bsearch: 10\r\nmodel:\r\n  num_conv_layers: 2\r\n  num_rnn_layers: 3\r\n  rnn_layer_size: 1024\r\n  share_rnn_weights: False\r\n  use_gru: True\r\ntraining:\r\n  global_grad_clip: 5.0\r\n  lr: 0.0005\r\n  lr_decay: 0.83\r\n  n_epoch: 30\r\n  weight_decay: 1e-06\r\n2021-03-10 17:46:21,624 - INFO - Setup test Dataloader!\r\nTraceback (most recent call last):\r\n  File \"/home/lg/DeepSpeech-develop/examples/aishell/../..//deepspeech/exps/deepspeech2/bin/infer.py\", line 59, in <module>\r\n    main(config, args)\r\n  File \"/home/lg/DeepSpeech-develop/examples/aishell/../..//deepspeech/exps/deepspeech2/bin/infer.py\", line 39, in main\r\n    main_sp(config, args)\r\n  File \"/home/lg/DeepSpeech-develop/examples/aishell/../..//deepspeech/exps/deepspeech2/bin/infer.py\", line 34, in main_sp\r\n    exp.setup()\r\n  File \"/home/lg/DeepSpeech-develop/deepspeech/exps/deepspeech2/model.py\", line 337, in setup\r\n    self.setup_model()\r\n  File \"/home/lg/DeepSpeech-develop/deepspeech/exps/deepspeech2/model.py\", line 354, in setup_model\r\n    self.test_loader.dataset, config, self.args.checkpoint_path)\r\n  File \"/home/lg/DeepSpeech-develop/deepspeech/models/deepspeech2.py\", line 407, in from_pretrained\r\n    checkpoint.load_parameters(model, checkpoint_path=checkpoint_path)\r\n  File \"/home/lg/DeepSpeech-develop/deepspeech/utils/checkpoint.py\", line 84, in load_parameters\r\n    iteration = int(os.path.basename(checkpoint_path).split(\"-\")[-1])\r\nValueError: invalid literal for int() with base 10: 'zh_giga.no_cna_cmn.prune01244.klm'\r\nFailed in inference!\r\n\r\n\r\n在checkpoint.py   load_parameters函数中 预训练模型的处理的此步骤。 期待您的回复，感谢。",
        "state": "closed",
        "user": "zhihenan",
        "closed_by": "zh794390558",
        "created_at": "2021-03-10T09:55:00+00:00",
        "updated_at": "2021-03-24T08:17:32+00:00",
        "closed_at": "2021-03-24T08:17:32+00:00",
        "comments_count": [
            "zh794390558",
            "zhihenan",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 554,
        "title": "InvalidArgumentError: Cannot parse tensor desc",
        "body": "[libprotobuf ERROR /paddle/build/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type \"paddle.framework.proto.VarType.TensorDesc\" because it is missing required fields: data_type\r\n/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 120, in <module>\r\n    show(audiopath)\r\n  File \"infer.py\", line 114, in show\r\n    result = infer()\r\n  File \"infer.py\", line 91, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"/home/weiao/port/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"/home/weiao/port/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 877, in load_params\r\n    filename=filename)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 751, in load_vars\r\n    filename=filename)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 805, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::TensorFromStream(std::istream&, paddle::framework::Tensor*, paddle::platform::DeviceContext const&)\r\n3   paddle::framework::DeserializeFromStream(std::istream&, paddle::framework::LoDTensor*, paddle::platform::DeviceContext const&)\r\n4   paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::LoadParamsFromBuffer(paddle::framework::ExecutionContext const&, paddle::platform::Place const&, std::istream*, bool, std::vector<std::string, std::allocator<std::string> > const&) const\r\n5   paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, int>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, signed char>, paddle::operators::LoadCombineOpKernel<paddle::platform::CUDADeviceContext, long> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n8   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n9   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n10  paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n11  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n12  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 803, in load_vars\r\n    'model_from_memory': vars_from_memory\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 751, in load_vars\r\n    filename=filename)\r\n  File \"/home/weiao/anaconda3/envs/deep/lib/python2.7/site-packages/paddle/fluid/io.py\", line 877, in load_params\r\n    filename=filename)\r\n  File \"/home/weiao/port/model_utils/model.py\", line 161, in init_from_pretrained_model\r\n    filename=\"params.pdparams\")\r\n  File \"/home/weiao/port/model_utils/model.py\", line 411, in infer_batch_probs\r\n    self.init_from_pretrained_model(exe, infer_program)\r\n  File \"infer.py\", line 91, in infer\r\n    feeding_dict=data_generator.feeding)\r\n  File \"infer.py\", line 114, in show\r\n    result = infer()\r\n  File \"infer.py\", line 120, in <module>\r\n    show(audiopath)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Cannot parse tensor desc\r\n  [Hint: Expected desc.ParseFromArray(buf.get(), size) == true, but received desc.ParseFromArray(buf.get(), size):0 != true:1.] at (/paddle/paddle/fluid/framework/tensor_util.cu:527)\r\n  [operator < load_combine > error]",
        "state": "closed",
        "user": "weiaoliu",
        "closed_by": "weiaoliu",
        "created_at": "2021-03-12T14:18:38+00:00",
        "updated_at": "2021-03-19T05:17:18+00:00",
        "closed_at": "2021-03-13T07:10:29+00:00",
        "comments_count": [
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 555,
        "title": "develop分支docker使用的是3.5版本。会报错",
        "body": "develop分支默认是python3.5版本，安装指南运行代码时会报no model resampy,导致后面的无法运行。希望开发人员可以装配docker默认为python3.7+版本",
        "state": "closed",
        "user": "zhangyifei1",
        "closed_by": "zh794390558",
        "created_at": "2021-03-15T06:44:18+00:00",
        "updated_at": "2021-03-24T08:17:23+00:00",
        "closed_at": "2021-03-24T08:17:23+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 557,
        "title": "python -u deploy/demo_client.py --host_ip 'localhost' --host_port 8086 Segmentation fault: 11",
        "body": "(venv) demodeMacBook-Pro:DeepSpeech-release-v1.8.5 demo$ sudo python -u deploy/demo_client.py --host_ip 'xx.xx.xx.xx' --host_port 8086\r\nSegmentation fault: 11\r\n\r\n\r\npython 3.7.5\r\nmac os 10.14.6",
        "state": "closed",
        "user": "DemoMoon",
        "closed_by": "DemoMoon",
        "created_at": "2021-03-16T06:11:19+00:00",
        "updated_at": "2021-03-18T01:23:41+00:00",
        "closed_at": "2021-03-18T01:23:41+00:00",
        "comments_count": [
            "DemoMoon",
            "DemoMoon",
            "zh794390558",
            "DemoMoon"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 558,
        "title": "DeepSpeech识别性能问题",
        "body": "请问下\r\n1.现在识别一个单词需要2.3秒，请问如何提高识别效率，需要什么样的配置\r\n2.并发识别会报错，可以并发快速识别么？",
        "state": "closed",
        "user": "535495945",
        "closed_by": "zh794390558",
        "created_at": "2021-03-18T01:52:57+00:00",
        "updated_at": "2021-03-24T08:17:15+00:00",
        "closed_at": "2021-03-24T08:17:15+00:00",
        "comments_count": [
            "zh794390558",
            "535495945",
            "zh794390558",
            "535495945",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 560,
        "title": "运行aishell下的export.sh报错",
        "body": "报错如下：\r\nAttributeError: module 'gast' has no attribute 'Index'\r\n用的是develop分支最新版本\r\n我用的paddle版本如下：\r\npaddlepaddle-gpu：2.0.1.post100\r\ngast:0.4.0",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "zh794390558",
        "created_at": "2021-03-18T06:26:25+00:00",
        "updated_at": "2021-03-24T08:16:47+00:00",
        "closed_at": "2021-03-24T08:16:47+00:00",
        "comments_count": [
            "lfxx",
            "lfxx",
            "zh794390558",
            "lfxx",
            "zh794390558",
            "lfxx",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 559,
        "title": "引入噪声数据增强后 报错",
        "body": "Exception in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/DeepSpeech/DeepSpeech/deepspeech/frontend/augmentor/noise_perturb.py\", line 71, in transform_audio\r\n    audio_segment.add_noise(noise_segment, snr_dB, allow_downsampling=True, rng=self._rng)\r\n  File \"/DeepSpeech/DeepSpeech/deepspeech/frontend/audio.py\", line 597, in add_noise\r\n    if noise.sample_rate != self.sample_rate:\r\nAttributeError: 'NoneType' object has no attribute 'sample_rate'\r\n\r\n\r\n但是 实际检查的时候，发现噪声数据 存在，且长度正确。",
        "state": "closed",
        "user": "wuchaowei2012",
        "closed_by": "zh794390558",
        "created_at": "2021-03-18T05:01:51+00:00",
        "updated_at": "2021-03-24T08:16:55+00:00",
        "closed_at": "2021-03-24T08:16:55+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 561,
        "title": "docker 下运行bash run.sh 报错",
        "body": "你好，使用docker环境下，运行bash run.sh 脚本的时候，在导入数据后会报没有安装’resampy‘模块的错误。\r\npip3 install resampy  则会报以下错误，始终导不了包。请问是什么问题，如何解决。\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/28425091/111718595-3247c100-8895-11eb-8011-9d614f5819a0.png)\r\n",
        "state": "closed",
        "user": "zhangyifei1",
        "closed_by": "zh794390558",
        "created_at": "2021-03-19T01:26:40+00:00",
        "updated_at": "2021-03-24T08:16:34+00:00",
        "closed_at": "2021-03-24T08:16:33+00:00",
        "comments_count": [
            "lfxx",
            "zhangyifei1",
            "lfxx",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 562,
        "title": "训练的模型在语音识别的时候报错了",
        "body": "Python 3.7.6\r\n(venv) [root@bogon deploy_demo]# pip show paddlepaddle\r\nName: paddlepaddle\r\nVersion: 2.0.1\r\nSummary: Parallel Distributed Deep Learning\r\nHome-page: UNKNOWN\r\nAuthor: None\r\nAuthor-email: Paddle-better@baidu.com\r\nLicense: Apache Software License\r\nLocation: /home/DeepSpeech/tools/venv/lib/python3.7/site-packages\r\nRequires: decorator, numpy, requests, gast, Pillow, protobuf, six, astor\r\nRequired-by: \r\n\r\n python3 tools/compute_mean_std.py --num_samples 1 --specgram_type linear --manifest_path data/xm/manifest.test --output_path data/xm/mean_std.npz\r\n\r\n python3 tools/build_vocab.py \\\r\n--count_threshold 0 \\\r\n--vocab_path data/xm/vocab.txt \\\r\n--manifest_paths data/xm/manifest.train\r\n\r\nsh run_infer.sh\r\nTarget Transcription: 猫\r\nOutput Transcription: \r\nCurrent error rate [wer] = 1.000000\r\n2021-03-19 12:06:58,659 - INFO - finish inference\r\n\r\n\r\nsh run_test.sh \r\nfinish initing model from pretrained params from checkpoints/xm/step_final\r\nError rate [wer] (1/?) = 1.000000\r\nFinal error rate [wer] (1/1) = 1.000000\r\n2021-03-19 12:09:03,714 - INFO - finish evaluation\r\n\r\n以语音文件的来识别语音内容，报错如下，\r\n[libprotobuf ERROR /paddle/build.noavx/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type \"paddle.framework.proto.VarType.TensorDesc\" because it is missing required fields: data_type",
        "state": "closed",
        "user": "DemoMoon",
        "closed_by": "zh794390558",
        "created_at": "2021-03-19T04:46:23+00:00",
        "updated_at": "2021-03-24T08:16:21+00:00",
        "closed_at": "2021-03-24T08:16:21+00:00",
        "comments_count": [
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "zh794390558",
            "zh794390558",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "zh794390558",
            "DemoMoon",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 563,
        "title": "服务端推理的时候，收到的音频必须先保存然后再读取吗",
        "body": "应用在业务中，上述方法明显是不可靠的，可不可以直接保存在内存中推理？希望官方可以优化下server demo",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "lfxx",
        "created_at": "2021-03-19T07:22:09+00:00",
        "updated_at": "2021-03-19T07:42:23+00:00",
        "closed_at": "2021-03-19T07:42:23+00:00",
        "comments_count": [
            "lfxx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 564,
        "title": "项目中用到tensorrt了吗",
        "body": "如果没有，有计划加入该优化方法吗",
        "state": "closed",
        "user": "lfxx",
        "closed_by": "zh794390558",
        "created_at": "2021-03-19T07:43:33+00:00",
        "updated_at": "2021-03-24T08:16:02+00:00",
        "closed_at": "2021-03-24T08:16:01+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 565,
        "title": " UnavailableError: Not allowed to load partial data via load_combine_op, please use load_op instead.",
        "body": "运行sh run_test_golden.sh 时遇到该问题，请问怎么处理\r\n",
        "state": "closed",
        "user": "yinchunlin",
        "closed_by": "zh794390558",
        "created_at": "2021-03-21T08:46:41+00:00",
        "updated_at": "2021-03-24T08:15:48+00:00",
        "closed_at": "2021-03-24T08:15:48+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 566,
        "title": "lm_dict_size = self._ext_scorer.get_dict_size()，return 0,it shoud be the reason.",
        "body": "lm_dict_size = self._ext_scorer.get_dict_size()，return 0,it shoud be the reason.\r\n\r\n_Originally posted by @wueching in https://github.com/PaddlePaddle/DeepSpeech/issues/408#issuecomment-570598781_",
        "state": "closed",
        "user": "yinchunlin",
        "closed_by": "zh794390558",
        "created_at": "2021-03-21T09:25:35+00:00",
        "updated_at": "2021-03-24T08:15:39+00:00",
        "closed_at": "2021-03-24T08:15:39+00:00",
        "comments_count": [
            "yinchunlin",
            "zh794390558",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 572
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 574
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 575
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 568,
        "title": "File contains data in an unimplemented format.",
        "body": "linux同样的环境，\r\ndevelop 分支 训练时候报错了。\r\nrelease/v1.8.5 分支 可以正常训练。\r\n\r\n(venvnew) [root@bogon DeepSpeech]# sh setup.sh \r\nRequirement already satisfied: scipy==1.2.1 in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.2.1)\r\nRequirement already satisfied: resampy==0.2.2 in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.2.2)\r\nRequirement already satisfied: SoundFile==0.9.0.post1 in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (0.9.0.post1)\r\nRequirement already satisfied: python_speech_features in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.6)\r\nRequirement already satisfied: tensorboardX in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.1)\r\nRequirement already satisfied: yacs in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.1.8)\r\nRequirement already satisfied: typeguard in ./tools/venvnew/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (2.11.1)\r\nRequirement already satisfied: six>=1.3 in ./tools/venvnew/lib/python3.7/site-packages (from resampy==0.2.2->-r requirements.txt (line 2)) (1.15.0)\r\nRequirement already satisfied: numpy>=1.10 in ./tools/venvnew/lib/python3.7/site-packages (from resampy==0.2.2->-r requirements.txt (line 2)) (1.20.1)\r\nRequirement already satisfied: numba>=0.32 in ./tools/venvnew/lib/python3.7/site-packages (from resampy==0.2.2->-r requirements.txt (line 2)) (0.53.0)\r\nRequirement already satisfied: cffi>=0.6 in ./tools/venvnew/lib/python3.7/site-packages (from SoundFile==0.9.0.post1->-r requirements.txt (line 3)) (1.14.5)\r\nRequirement already satisfied: pycparser in ./tools/venvnew/lib/python3.7/site-packages (from cffi>=0.6->SoundFile==0.9.0.post1->-r requirements.txt (line 3)) (2.20)\r\nRequirement already satisfied: setuptools in ./tools/venvnew/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2->-r requirements.txt (line 2)) (53.0.0)\r\nRequirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in ./tools/venvnew/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.2->-r requirements.txt (line 2)) (0.36.0)\r\nRequirement already satisfied: protobuf>=3.8.0 in ./tools/venvnew/lib/python3.7/site-packages (from tensorboardX->-r requirements.txt (line 5)) (3.15.6)\r\nRequirement already satisfied: PyYAML in ./tools/venvnew/lib/python3.7/site-packages (from yacs->-r requirements.txt (line 6)) (5.4.1)\r\nInstall all dependencies successfully.\r\n\r\n(venvnew) [root@bogon xm_test]# sh run.sh                                \r\nWARNING: AVX is not support on your machine. Hence, no_avx core will be imported, It has much worse preformance than avx core.\r\n/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  def convert_to_list(value, n, name, dtype=np.int):\r\n-----------  Configuration Arguments -----------\r\ncount_threshold: 0\r\nmanifest_paths: ['data/manifest.xm']\r\nvocab_path: data/vocab.txt\r\n------------------------------------------------\r\nWARNING: AVX is not support on your machine. Hence, no_avx core will be imported, It has much worse preformance than avx core.\r\n/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  def convert_to_list(value, n, name, dtype=np.int):\r\n/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/scipy/fftpack/__init__.py:103: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\r\n  from numpy.dual import register_func\r\n/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n-----------  Configuration Arguments -----------\r\nmanifest_path: data/manifest.xm\r\nnum_samples: 1\r\noutput_path: data/mean_std.npz\r\nspecgram_type: linear\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/develop/DeepSpeech/examples/xm_test/../..//utils/compute_mean_std.py\", line 60, in <module>\r\n    main()\r\n  File \"/home/develop/DeepSpeech/examples/xm_test/../..//utils/compute_mean_std.py\", line 55, in main\r\n    num_samples=args.num_samples)\r\n  File \"/home/develop/DeepSpeech/deepspeech/frontend/normalizer.py\", line 56, in __init__\r\n    self._compute_mean_std(manifest_path, featurize_func, num_samples)\r\n  File \"/home/develop/DeepSpeech/deepspeech/frontend/normalizer.py\", line 94, in _compute_mean_std\r\n    AudioSegment.from_file(instance[\"audio_filepath\"])))\r\n  File \"/home/develop/DeepSpeech/deepspeech/frontend/audio.py\", line 82, in from_file\r\n    samples, sample_rate = soundfile.read(file, dtype='float32')\r\n  File \"/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/soundfile.py\", line 373, in read\r\n    subtype, endian, format, closefd) as f:\r\n  File \"/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/soundfile.py\", line 740, in __init__\r\n    self._file = self._open(file, mode_int, closefd)\r\n  File \"/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/soundfile.py\", line 1265, in _open\r\n    \"Error opening {0!r}: \".format(self.name))\r\n  File \"/home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages/soundfile.py\", line 1455, in _error_check\r\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\r\nRuntimeError: Error opening '/home/develop/DeepSpeech/examples/xm_test/dataset/xmspeech/mao.flac': File contains data in an unimplemented format.\r\nCompute mean and stddev failed. Terminated.\r\n\r\n(venvnew) [root@bogon xm_test]# python --version\r\nPython 3.7.6\r\n(venvnew) [root@bogon xm_test]# pip show paddlepaddle\r\nName: paddlepaddle\r\nVersion: 2.0.0\r\nSummary: Parallel Distributed Deep Learning\r\nHome-page: UNKNOWN\r\nAuthor: UNKNOWN\r\nAuthor-email: UNKNOWN\r\nLicense: UNKNOWN\r\nLocation: /home/develop/DeepSpeech/tools/venvnew/lib/python3.7/site-packages\r\nRequires: Pillow, gast, protobuf, requests, six, decorator, astor, numpy\r\nRequired-by: \r\n(venvnew) [root@bogon xm_test]# \r\n",
        "state": "closed",
        "user": "DemoMoon",
        "closed_by": "DemoMoon",
        "created_at": "2021-03-22T08:59:29+00:00",
        "updated_at": "2021-03-25T10:12:13+00:00",
        "closed_at": "2021-03-24T01:44:44+00:00",
        "comments_count": [
            "DemoMoon",
            "DemoMoon",
            "zhangyifei1",
            "zhangyifei1",
            "zh794390558",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "zhangyifei1",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 576
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 569,
        "title": "bash run.sh",
        "body": "(base) root@a8e4df74e22d:/DeepSpeech/DeepSpeech-develop/examples/tiny# bash run.sh\r\n/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:297: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  warnings.warn(\r\nSkip downloading and unpacking. Data already exists in /DeepSpeech/DeepSpeech-develop/examples/tiny/../..//examples/dataset/aishell.\r\nCreating manifest data/manifest ...\r\n\r\n/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:297: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  warnings.warn(\r\n-----------  Configuration Arguments -----------\r\ncount_threshold: 0\r\nmanifest_paths: ['data/manifest.train', 'data/manifest.dev']\r\nvocab_path: data/vocab.txt\r\n------------------------------------------------\r\n/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:297: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  warnings.warn(\r\n-----------  Configuration Arguments -----------\r\nmanifest_path: data/manifest.train\r\nnum_samples: 2000\r\noutput_path: data/mean_std.npz\r\nspecgram_type: linear\r\n------------------------------------------------\r\nAishell data preparation done.\r\nusing 2 gpus...\r\n/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:297: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/DeepSpeech/DeepSpeech-develop/examples/tiny/../..//deepspeech/exps/deepspeech2/bin/train.py\", line 26, in <module>\r\n    from deepspeech.exps.deepspeech2.config import get_cfg_defaults\r\n  File \"/DeepSpeech/DeepSpeech-develop/deepspeech/exps/deepspeech2/config.py\", line 16, in <module>\r\n    from deepspeech.models.deepspeech2 import DeepSpeech2Model\r\n  File \"/DeepSpeech/DeepSpeech-develop/deepspeech/models/deepspeech2.py\", line 31, in <module>\r\n    from deepspeech.modules.ctc import CTCDecoder\r\n  File \"/DeepSpeech/DeepSpeech-develop/deepspeech/modules/ctc.py\", line 23, in <module>\r\n    from deepspeech.decoders.swig_wrapper import Scorer\r\n  File \"/DeepSpeech/DeepSpeech-develop/deepspeech/decoders/swig_wrapper.py\", line 16, in <module>\r\n    import swig_decoders\r\nModuleNotFoundError: No module named 'swig_decoders'\r\n",
        "state": "closed",
        "user": "zhangyifei1",
        "closed_by": "zh794390558",
        "created_at": "2021-03-23T02:31:20+00:00",
        "updated_at": "2021-03-25T02:41:50+00:00",
        "closed_at": "2021-03-24T08:15:17+00:00",
        "comments_count": [
            "zh794390558",
            "zhangyifei1",
            "zhangyifei1",
            "zh794390558",
            "zhangyifei1",
            "zhangyifei1",
            "zhangyifei1",
            "zh794390558",
            "zhangyifei1",
            "zh794390558",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "DemoMoon",
            "JohnDoe117",
            "zh794390558",
            "zhangyifei1",
            "DemoMoon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 571,
        "title": "使用官方模型，英文用时1秒，中文3分钟，请问如何优化",
        "body": "使用官方模型，英文用时1秒，中文3分钟，请问如何优化，差距好大",
        "state": "closed",
        "user": "535495945",
        "closed_by": "zh794390558",
        "created_at": "2021-03-24T02:32:29+00:00",
        "updated_at": "2021-03-24T08:13:01+00:00",
        "closed_at": "2021-03-24T08:13:01+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 577
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 581
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 582
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 585
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 586
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 579,
        "title": "普通话识别效果差",
        "body": "ｄｅｍｏ普通话识别效果差，不具备语音识别功能",
        "state": "closed",
        "user": "zazgf",
        "closed_by": "zazgf",
        "created_at": "2021-03-25T07:07:57+00:00",
        "updated_at": "2021-03-25T07:12:27+00:00",
        "closed_at": "2021-03-25T07:12:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 587
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 588
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 583,
        "title": "请问解码出来的文字，可以输出每个文字的置信度么？",
        "body": "",
        "state": "closed",
        "user": "zcswdt",
        "closed_by": "zh794390558",
        "created_at": "2021-03-31T08:45:20+00:00",
        "updated_at": "2021-04-06T07:41:44+00:00",
        "closed_at": "2021-04-06T07:41:44+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 584,
        "title": "能不能本地搭建一个玩啊！",
        "body": "Mac 搭建好像很复制\r\nMac中使用docker也很难受",
        "state": "closed",
        "user": "BigData-YC",
        "closed_by": "zh794390558",
        "created_at": "2021-04-01T09:05:56+00:00",
        "updated_at": "2021-04-06T07:42:14+00:00",
        "closed_at": "2021-04-06T07:42:14+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 593
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 589,
        "title": "请问下deepspeech输出asr结果包含概率吗？就是类似置信度的参数",
        "body": "请问下deepspeech输出asr结果包含概率吗？就是类似置信度的参数",
        "state": "closed",
        "user": "zhangyifei1",
        "closed_by": "zh794390558",
        "created_at": "2021-04-09T02:00:05+00:00",
        "updated_at": "2021-04-09T02:34:38+00:00",
        "closed_at": "2021-04-09T02:34:27+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 590,
        "title": "请问语言模型是如何得到的？",
        "body": "",
        "state": "closed",
        "user": "zcswdt",
        "closed_by": "zh794390558",
        "created_at": "2021-04-12T02:16:08+00:00",
        "updated_at": "2021-04-12T11:01:05+00:00",
        "closed_at": "2021-04-12T11:01:04+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 598
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 599
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 597,
        "title": "It repeats some words or partial word in transcript result.",
        "body": "Hello, when I tested some audio transcription, it repeats words in the result.\r\nFor example, \r\n1) the latter legacy later alligator....\r\n2) here we go far go five four....\r\n3) when a excess profile at excess professor...\r\n4) we will start will start testing again...\r\n... ...\r\nAny thought on this issue?\r\nRegards to help.",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2021-04-19T06:43:29+00:00",
        "updated_at": "2021-04-19T08:10:23+00:00",
        "closed_at": "2021-04-19T08:10:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 592,
        "title": "想将语音识别为拼音，但WER一直等于1正常吗？",
        "body": "我尝试使用DeepSpeech训练自己的数据来识别带声调的拼音(例如：pu3 tong1 hua4)\r\n数据大约有500小时采样率为16K的wav，质量一般，我进行了降噪和vad处理\r\n训练时设置力lang_model_path为空，其他参数未动\r\n\r\nepoch>60后，loss在0.6-1.2之间震荡\r\ntest结果全部为“< u n k >”\r\nwer等于1\r\n\r\n我想知道问题出在哪？",
        "state": "closed",
        "user": "gezimonkey",
        "closed_by": "zh794390558",
        "created_at": "2021-04-12T11:01:31+00:00",
        "updated_at": "2021-04-12T11:02:48+00:00",
        "closed_at": "2021-04-12T11:02:48+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 595,
        "title": "有关“普通话语言模型”一节说”在两个字符之间插入空白字符“的问题",
        "body": "你好！\r\n\r\n> 在1.8.5版本的文档中，”普通话语言模型“一节，说语料库在预处理阶段要”在两个字符之间插入空白字符“。但是用 examples/aishell/run_data.sh 脚本生成的 manifest.train 文件中， text 部分的句子之间的字符没有空白字符，比如：”浙江的民营企业有着极为灵敏的商业嗅觉“，但是在 aishell 语料库中的 transcript 文件下是有空格的，比如：”而 对 楼市 成交 抑制 作用 最 大 的 限 购“。所以目前有两个疑惑点：\r\n\r\n1. 语料库在预处理阶段要”在两个字符之间插入空白字符“的作用是什么，对训练有什么影响\r\n\r\n2. manifest.train 文件中的 text ，需不需要在两个字符之间插入空白字符，或者是要按照类似”而 对 楼市 成交 抑制 作用 最 大 的 限 购“这样的效果插入空白字符。",
        "state": "closed",
        "user": "Jackie-J",
        "closed_by": "zh794390558",
        "created_at": "2021-04-13T08:35:39+00:00",
        "updated_at": "2021-04-14T09:15:25+00:00",
        "closed_at": "2021-04-14T09:15:25+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 596,
        "title": "请问现在如何下载 BaiduCN1.2k Model 的预训练模型",
        "body": "在项目中到处都找不到，请问现在还提供吗？",
        "state": "closed",
        "user": "jiangshen95",
        "closed_by": "zh794390558",
        "created_at": "2021-04-18T13:16:50+00:00",
        "updated_at": "2021-04-20T07:47:44+00:00",
        "closed_at": "2021-04-20T07:47:44+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 608
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 600,
        "title": "How to get the duration and start time of each word?",
        "body": "```\r\nds2_model.decode_batch_beam_search\r\n```\r\nonly return text and confidence",
        "state": "closed",
        "user": "hebo1982",
        "closed_by": "zh794390558",
        "created_at": "2021-04-26T12:15:09+00:00",
        "updated_at": "2022-02-09T07:05:08+00:00",
        "closed_at": "2021-04-29T12:16:17+00:00",
        "comments_count": [
            "zh794390558",
            "hengshan123",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 615,
        "title": "ModuleNotFoundError: No module named 'swig_decoders'",
        "body": "现在不是已经支持python3了么\r\n",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-05-17T05:51:33+00:00",
        "updated_at": "2021-05-17T06:46:54+00:00",
        "closed_at": "2021-05-17T06:46:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 601,
        "title": "有训练好的中文和英文模型吗？可以和语言模型来做推理",
        "body": "如果音频有很多背景音乐和噪音，有什么好办法去除吗\r\n",
        "state": "closed",
        "user": "yxy-lol",
        "closed_by": "zh794390558",
        "created_at": "2021-04-26T14:05:54+00:00",
        "updated_at": "2021-04-29T12:16:51+00:00",
        "closed_at": "2021-04-29T12:16:50+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 602,
        "title": "一定得是Linux环境吗？ win10环境可以吗 ",
        "body": "⤴️ 谢谢",
        "state": "closed",
        "user": "wingdi",
        "closed_by": "zh794390558",
        "created_at": "2021-05-11T01:55:39+00:00",
        "updated_at": "2021-05-12T07:34:33+00:00",
        "closed_at": "2021-05-11T05:05:14+00:00",
        "comments_count": [
            "zh794390558",
            "wingdi",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 609,
        "title": "install link is invaild",
        "body": "\r\n",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "ZeyuChen",
        "created_at": "2021-05-13T08:00:34+00:00",
        "updated_at": "2021-05-13T11:26:26+00:00",
        "closed_at": "2021-05-13T11:26:26+00:00",
        "comments_count": [
            "zh794390558",
            "daixiangzi",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 616,
        "title": "使用baidu_cn1.2k_model_fluid.tar.gz和zh_giga.no_cna_cmn.prune01244.klm 推理",
        "body": "这三个文件怎么获取\r\nmanifest.dev-clean,\r\n mean_std.npz\r\n vocab.txt",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-05-17T07:18:57+00:00",
        "updated_at": "2021-05-17T07:35:48+00:00",
        "closed_at": "2021-05-17T07:35:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 617,
        "title": "RuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((2048, 2048)), while the loaded parameter (namely [ layer_3_forward_rnn_weight ]) has a shape of  ((2048, 6144)).",
        "body": "python3 deploy/demo_server.py\r\n用的模型：zh_giga.no_cna_cmn.prune01244.klm和baidu_cn1.2k_model_fluid.tar.gz\r\n配置参数：\r\nadd_arg('beam_size',        int,    500,    \"Beam search width.\")\r\nadd_arg('num_conv_layers',  int,    2,      \"# of convolution layers.\")\r\nadd_arg('num_rnn_layers',   int,    3,      \"# of recurrent layers.\")\r\nadd_arg('rnn_layer_size',   int,    2048,   \"# of recurrent cells per layer.\")\r\nadd_arg('alpha',            float,  2.5,   \"Coef of LM for beam search.\")\r\nadd_arg('beta',             float,  0.3,   \"Coef of WC for beam search.\")\r\nadd_arg('cutoff_prob',      float,  1.0,    \"Cutoff probability for pruning.\")\r\nadd_arg('cutoff_top_n',     int,    40,     \"Cutoff number for pruning.\")\r\nadd_arg('use_gru',          bool,   False,  \"Use GRUs instead of simple RNNs.\")\r\nadd_arg('use_gpu',          bool,   False,   \"Use GPU or not.\")\r\nadd_arg('share_rnn_weights',bool,  False,   \"Share input-hidden weights across \"\r\n                                            \"bi-directional RNNs. Not for GRU.\")",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-05-17T09:29:35+00:00",
        "updated_at": "2023-06-27T02:29:25+00:00",
        "closed_at": "2021-05-17T10:15:45+00:00",
        "comments_count": [
            "daixiangzi",
            "a0735a"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 624,
        "title": "保存模型出错。",
        "body": "with fluid.program_guard(infer_program, startup_prog):  \r\n   with fluid.unique_name.guard():  \r\n                feeder, log_probs, inputs = self.create_network(is_infer=True)  \r\ninfer_program = infer_program.clone(for_test=True)  \r\nexe = fluid.Executor(self._place)  \r\nif not self._init_from_pretrained_model:  \r\n       exit(\"No pretrain model file path!\")\r\nself.init_from_pretrained_model(exe, infer_program)\r\n**fluid.io.save_inference_model(\"./\",['masks','seq_len_data','audio_data'],[log_probs], exe,main_program=infer_program)**\r\n\r\n\r\nInvalidArgumentError: The Tensor in the save Op's Input Variable X(softmax_0.tmp_0) is not initialized.\r\n      [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] (at /paddle/paddle/fluid/framework/operator.cc:1511)\r\n      [operator < save > error]\r\n``",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-05-18T10:33:22+00:00",
        "updated_at": "2021-05-19T06:16:16+00:00",
        "closed_at": "2021-05-19T06:16:16+00:00",
        "comments_count": [
            "daixiangzi",
            "zh794390558",
            "daixiangzi",
            "daixiangzi",
            "zh794390558",
            "zh794390558",
            "daixiangzi",
            "zh794390558",
            "daixiangzi",
            "zh794390558",
            "daixiangzi"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 631,
        "title": "多进程cuda 初始化错误",
        "body": "\r\n错误信息：\r\nOSError: (External)  Cuda error(3), initialization error.\r\n  [Advise: The API call failed because the CUDA driver and runtime could not be initialized. ] (at /paddle/paddle/fluid/platform/gpu_info.cc:200)\r\n ",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "stale[bot]",
        "created_at": "2021-05-20T03:21:29+00:00",
        "updated_at": "2021-08-03T14:43:50+00:00",
        "closed_at": "2021-08-03T14:43:50+00:00",
        "comments_count": [
            "daixiangzi",
            "zh794390558",
            "daixiangzi",
            "daixiangzi",
            "zh794390558",
            "daixiangzi",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 632,
        "title": "G2P 变调",
        "body": "https://en.wikipedia.org/wiki/Standard_Chinese_phonology#Tone_sandhi\r\nhttps://github.com/Kyubyong/g2pC/blob/master/g2pc/g2pc.py#L84\r\nhttps://github.com/mozillazg/python-pinyin/issues/133\r\nhttps://zh.wikipedia.org/wiki/%E8%AE%8A%E8%AA%BF\r\n\r\n```\r\n三声变调\r\n最普通的变调规则即是在一组两个上声（第三声）的合音节中，须将合音节中领先的第一个音节提升到阳平（第二声）。\r\n举例来说，你好（nǐ hǎo）为最普通的中文问候语，nǐ与hǎo原调都是上声，不过合音节第三声的“你”须读为调值略低的阳平（实际为上声的后半段，但听感与阳平几乎一致）即“你好”要念为“ní hǎo”。\r\n\r\n1. 两个三声：\r\n  When there are two Third Tones together, the first one changes into the Second Tone.\r\n2. 三个三声\r\n  ABC：  three number \"nine\" are equally put together, the first two syllables both change into the Second Tone.\r\n（AB)+C：(syllable A + B) is a word, and it modifies syllable C. Both (syllable A + B) change into the Second Tone.\r\n  A+(BC):   syllable A is a word, and it modifies (syllable B + C). Only syllable B changes into the Second Tone. Also, syllable A in this situation is actually pronounced in the Half Third Tone\r\n3. half third tone\r\nWhen Chinese Pinyin Third Tone goes before the First, the Second or the Fourth Tone\r\nSo when we have a 3-syllable word. With the Tones like below, the syllable marked in red and underlined is pronounced as Half Third Tone.\r\nnǎ gēn nǎ ——> Half 3rd + 1st + Full 3rd\r\ngēn nǎ -> 1st + Full 3rd\r\n\r\n三声变调：最大匹配三声序列，分两个或者三个三声。\r\n三个三声：找到后可以分词，然后应用规则。\r\n是否要加入半三声？\r\n\r\n\r\n两个四声\r\n第一个四声变成半四声。\r\n\r\n\r\n轻声\r\nThey are 2-syllable words with both syllables made of the same characters. \r\nIn each word, the first character is pronounced in its original Tone \r\nwhile the second character is pronounced in the Neutral Tone.\r\n爸爸，妈妈，哥哥，他的，好吧，要不，孩子，东西，钉子，脑子\r\n\r\nThe Third Tone in Front of The Neutral Tone\r\nNo.1 When the original Tone of the Neutral-tone syllable is the Third Tone, the Third Tone in front of it becomes the Second Tone; \r\nNo.2 When the Neutral-tone syllable is originally in the First, the Second or the Fourth Tone, the Third Tone in front of it is pronounced in the Half Third Tone.\r\n\r\n\r\n一不变调\r\n当“一”和“不”夹在词语中间念轻声，例如“看一看”、“好不好”等等。\r\n\r\n“一”的变调\r\n“一”的原调是第一声。\r\n当“一”在表示数目时，以及在词尾出现时，念为原调。例如︰一二三四、第一等等。\r\n当“一”与量词配搭时，如量词的声调是第一声、第二声或第三声，“一”念成第四声，例如“一根”、“一钱”和“一种”。\r\n如果量词的声调是第四声，“一”念成第二声，例如“一寸”。\r\n(1) When 一 is by itself, meaning \"the mathematical number one\", it is pronounced in the First Tone \"yī\".\r\n(2) When Character Yi 一 goes before the First, the Second and the Third Tone, it is pronounced in the Fourth Tone \"yì\"; \r\n(3) When Character Yi 一 goes before the Fourth Tone, it is pronounced in the Second Tone \"yí\".\r\n\r\n“不”的变调\r\n“不”的原调是第四声。\r\n当“不”后面跟着第一声、第二声和第三声的字，或者“不”出现在词末，念为原调。例如︰“不高”、“不祥”、“不好”和“我就不”。  \r\n当“不”后面的字是第四声，念为第二声，例如“不要”。\r\n```",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "stale[bot]",
        "created_at": "2021-05-20T08:00:38+00:00",
        "updated_at": "2021-09-07T04:13:11+00:00",
        "closed_at": "2021-09-07T04:13:11+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 652
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 653
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 638,
        "title": "_pickle.UnpicklingError: invalid load key, '\\x00'.",
        "body": "aishell 下提供的预训练模型参数文件有问题，加载时报错了，报错内容如下：_pickle.UnpicklingError: invalid load key, '\\x00'.",
        "state": "closed",
        "user": "kinda830",
        "closed_by": "kinda830",
        "created_at": "2021-05-21T09:22:15+00:00",
        "updated_at": "2021-06-29T06:19:27+00:00",
        "closed_at": "2021-05-21T10:15:27+00:00",
        "comments_count": [
            "zh794390558",
            "Leon0427"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 635,
        "title": "如何测试中文模型",
        "body": "我下载了楼主提供的中文模型，请问如何开始啊？难道只要执行path.sh 和 run.sh就可以了？",
        "state": "closed",
        "user": "fangg2021",
        "closed_by": "stale[bot]",
        "created_at": "2021-05-20T22:23:19+00:00",
        "updated_at": "2021-08-04T16:41:11+00:00",
        "closed_at": "2021-08-04T16:41:11+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 642,
        "title": "pushd tools; make; popd命令,CetOS系统只有yum，没有apt-get,安装不成功",
        "body": "pushd tools; make; popd命令,CetOS系统只有yum，没有apt-get,安装不成功",
        "state": "closed",
        "user": "sion1989",
        "closed_by": "stale[bot]",
        "created_at": "2021-05-24T11:37:17+00:00",
        "updated_at": "2021-08-18T10:21:01+00:00",
        "closed_at": "2021-08-18T10:21:01+00:00",
        "comments_count": [
            "zh794390558",
            "Kkkassini",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 644,
        "title": "百度1.8中开源的中文语音模型，会限制待识别的语音长度么",
        "body": "\r\n",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "stale[bot]",
        "created_at": "2021-05-25T09:08:04+00:00",
        "updated_at": "2021-08-09T09:07:48+00:00",
        "closed_at": "2021-08-09T09:07:48+00:00",
        "comments_count": [
            "zh794390558",
            "daixiangzi",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 649,
        "title": "_compute_linear_specgram算法有沒有相关资料看一下",
        "body": "我看对音频特征提取默认是使用这个算法，估计是它比MFCC要好，但我没找到该算法的相关介绍和论文，有没有相关资料我看一下。\r\n\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/03e5a64d26eeab3cc81192542d369bd9a47a701e/deepspeech/frontend/featurizer/audio_featurizer.py#L170-L218",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-06-01T03:18:21+00:00",
        "updated_at": "2021-06-01T09:07:06+00:00",
        "closed_at": "2021-06-01T09:07:06+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 654,
        "title": "我发现使用mean_std.npz对数据归一化，很多都没有在[-1, 1]内",
        "body": "下面就是一个音频处理后的结果，可以看到很多值都不在[-1, 1]内。\r\n```\r\nTensor(shape=[1, 161, 838], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\r\n       [[[ 0.19748375, -0.15710881, -0.25388885, ..., -0.63230032,  0.33487847,  0.59903646],\r\n         [-0.37781027, -0.83931553, -0.83468038, ..., -1.45805180, -0.02257396,  0.24038246],\r\n         [-1.69875002, -0.90235049, -1.20287299, ..., -0.90580356, -0.73685694, -0.53953153],\r\n         ...,\r\n         [ 3.01285100,  2.89813972,  7.02651882, ...,  2.16382766,  0.03995297,  7.50421524],\r\n         [ 2.25123835, -0.75411123,  9.37080574, ...,  2.84863853,  0.77789980, 10.60489750],\r\n         [-0.00255691,  2.74228144, 10.31020546, ...,  1.69122100,  3.56170893, 11.67463398]]])\r\n```\r\n\r\n如果使用下面这种方式，就可以保证每个数据都在[-1, 1]内，但是这样mean和std每次都不一样，这好像又不行。那上面这种很多都没有在[-1, 1]内的数据会对训练和预测有影响吗？\r\n```python\r\n  mean = np.mean(audio_feature, axis=0)\r\n  std = np.std(audio_feature, axis=0)\r\n  normalized = (audio_feature - mean) / (std + 1e-6)\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-06-04T09:22:24+00:00",
        "updated_at": "2021-06-05T02:14:25+00:00",
        "closed_at": "2021-06-05T02:14:25+00:00",
        "comments_count": [
            "zh794390558",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 660,
        "title": "在损失函数中为啥不直接使用nn.CTCLoss(blank=blank, reduction='mean')呢",
        "body": "为啥不是使用这个`nn.CTCLoss(blank=blank, reduction='mean')`\r\n\r\n而是求和`nn.CTCLoss(blank=blank, reduction='sum')`，之后在除以batch size。这样处理不是一样的结果吗？\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/fbe022fdef53ad8bd26791996e43b330849f93fd/deepspeech/modules/loss.py#L52-L54",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-06-07T03:49:10+00:00",
        "updated_at": "2021-06-08T06:02:01+00:00",
        "closed_at": "2021-06-08T06:02:01+00:00",
        "comments_count": [
            "zh794390558",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 674,
        "title": "save k-best ckpt",
        "body": "参考https://github.com/PaddlePaddle/Parakeet/pull/114 ，将checkpoint相关操作抽象成类，组合KBest实现功能。",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2021-06-18T03:17:20+00:00",
        "updated_at": "2021-06-30T04:16:46+00:00",
        "closed_at": "2021-06-30T04:16:46+00:00",
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 659,
        "title": "Demo发散",
        "body": "新配服务器：3090+CUDA11.2+cuDNN8.1，在paddle2.1上训练自建数据集和官方数据集时train loss较大且发散。但之前在旧服务器上：2080+CUDA11.1+cuDNN8.0，在paddle2.0上训练ok。更奇怪的是将训练好的模型部署在新服务器上直接做测试的结果也有问题。不知道有没有大佬在新服务器配置上训练过\r\n**loss:**\r\n[INFO 2021/06/05 22:50:31 model.py:72] Train: Rank: 0, epoch: 192, step: 6106, time: 2.204s, train_loss: 421.891632\r\n[INFO 2021/06/05 22:50:31 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6106, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:33 model.py:72] Train: Rank: 0, epoch: 192, step: 6107, time: 1.459s, train_loss: 264.403625\r\n[INFO 2021/06/05 22:50:33 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6107, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:34 model.py:72] Train: Rank: 0, epoch: 192, step: 6108, time: 1.691s, train_loss: 301.924622\r\n[INFO 2021/06/05 22:50:34 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6108, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:35 model.py:72] Train: Rank: 0, epoch: 192, step: 6109, time: 1.086s, train_loss: 169.005737\r\n[INFO 2021/06/05 22:50:35 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6109, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:36 model.py:72] Train: Rank: 0, epoch: 192, step: 6110, time: 0.773s, train_loss: 102.978607\r\n[INFO 2021/06/05 22:50:36 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6110, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:37 model.py:72] Train: Rank: 0, epoch: 192, step: 6111, time: 1.142s, train_loss: 212.450012\r\n[INFO 2021/06/05 22:50:37 trainer.py:177] Train: Rank: 0, epoch: 192, step: 6111, dataloader time: 0.000s,\r\n[INFO 2021/06/05 22:50:40 model.py:72] Train: Rank: 0, epoch: 192, step: 6112, time: 2.869s, train_loss: 510.787109\r\n**预测：**\r\n[INFO 2021/06/06 16:12:58 model.py:259] Current error rate [cer] = 1.666667\r\n[INFO 2021/06/06 16:12:58 model.py:257]\r\nTarget Transcription: 杨海彪\r\nOutput Transcription: 这是一个不大不小的一个\r\n[INFO 2021/06/06 16:12:58 model.py:259] Current error rate [cer] = 3.666667\r\n[INFO 2021/06/06 16:12:58 model.py:257]\r\nTarget Transcription: 收不收短信\r\nOutput Transcription: 这是一个不大不小的一个\r\n[INFO 2021/06/06 16:12:58 model.py:259] Current error rate [cer] = 2.000000\r\n[INFO 2021/06/06 16:12:58 model.py:257]\r\nTarget Transcription: 我爱你我在找\r\nOutput Transcription: 这是一个不大不小的一个\r\n更变解码参数α和β：\r\nTarget Transcription: 来首歌\r\nOutput Transcription: 这是一个在天上一个在天上一个在天上一个在天上一个在天上一个在\r\n[INFO 2021/06/06 16:06:16 model.py:259] Current error rate [cer] = 10.000000\r\n[INFO 2021/06/06 16:06:16 model.py:257]\r\nTarget Transcription: 会刮\r\nOutput Transcription: 这是一个在天上一个在天上一个在天上一个在天上一个在天上一个在\r\n[INFO 2021/06/06 16:06:16 model.py:259] Current error rate [cer] = 15.000000\r\n[INFO 2021/06/06 16:06:16 model.py:257]\r\nTarget Transcription: 听个玩笑\r\nOutput Transcription: 这是一个在天上一个在天上一个在天上一个在天上一个在天上一个在\r\n",
        "state": "closed",
        "user": "FrankWhh",
        "closed_by": "FrankWhh",
        "created_at": "2021-06-06T08:41:05+00:00",
        "updated_at": "2021-06-09T01:21:22+00:00",
        "closed_at": "2021-06-09T01:21:22+00:00",
        "comments_count": [
            "zh794390558",
            "FrankWhh",
            "FrankWhh",
            "zh794390558",
            "FrankWhh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 663,
        "title": "没有推理脚本",
        "body": "在这个文件路径下 /mnt/ASRT/DeepSpeech/examples/librispeech/s0/local 缺少 推理脚本infer.sh\r\n请问在哪里下载预训练模型呢？",
        "state": "closed",
        "user": "mingo-doer",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-08T02:35:54+00:00",
        "updated_at": "2021-10-04T04:40:02+00:00",
        "closed_at": "2021-10-04T04:40:02+00:00",
        "comments_count": [
            "zh794390558",
            "shanmon110",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 672,
        "title": "升级3070后，python3进程卡住cpu 100%",
        "body": "开始测试1080ti，程序正常，环境：\r\ndocker运行\r\npaddlepaddle_gpu-1.8.5.post107\r\ncuda 10.1\r\ncdnn 7.5\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\r\n| 40%   27C    P0    58W / 250W |      0MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n| 47%   36C    P0    57W / 250W |      0MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\r\n| 49%   30C    P0    54W / 250W |      0MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  Off  | 00000000:8A:00.0 Off |                  N/A |\r\n| 55%   29C    P0    53W / 250W |      0MiB / 11178MiB |      5%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n另一台机器升级3070，环境相同，但驱动因为需要升级：\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.84       Driver Version: 460.84       CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 3070    Off  | 00000000:82:00.0 Off |                  N/A |\r\n|  0%   33C    P8     6W / 220W |    303MiB /  7982MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\ncuda安装10.1，使用nvcc -V查看：\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Fri_Feb__8_19:08:17_PST_2019\r\nCuda compilation tools, release 10.1, V10.1.105\r\n\r\n程序启动后，就夯住了，python3进程cpu 100%\r\n\r\nW0617 04:06:56.153712   194 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 86, Driver API Version: 11.2, Runtime API Version: 10.0\r\nW0617 04:06:56.153888   194 device_context.cc:260] device: 0, cuDNN Version: 7.5.\r\nW0617 04:06:56.512885   194 device_context.h:155] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\n\r\n![image](https://user-images.githubusercontent.com/5362672/122330705-3f448100-cf66-11eb-84ed-d102eb11fb6f.png)\r\n",
        "state": "closed",
        "user": "hebo1982",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-17T04:20:41+00:00",
        "updated_at": "2021-09-12T15:50:39+00:00",
        "closed_at": "2021-09-12T15:50:39+00:00",
        "comments_count": [
            "hebo1982",
            "hebo1982",
            "zh794390558",
            "hebo1982",
            "hebo1982",
            "zh794390558",
            "zh794390558",
            "hebo1982",
            "zh794390558",
            "hebo1982",
            "hebo1982",
            "zh794390558",
            "hebo1982",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "Deployment"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 675,
        "title": "训练的过程中，从第二个epoch开始，lr=0.00000000,train_lossp徘徊在15左右",
        "body": "[INFO 2021/06/19 16:01:34 model.py:61] Train: Rank: 0, epoch: 1, step: 5310, batch : 1559/1876, lr: 0.00000000, data time: 0.000s, train time: 3.019s, batch size: 64, train_loss: 16.030918\r\n[INFO 2021/06/19 16:01:37 model.py:61] Train: Rank: 0, epoch: 1, step: 5311, batch : 1560/1876, lr: 0.00000000, data time: 0.000s, train time: 2.954s, batch size: 64, train_loss: 15.383665\r\n[INFO 2021/06/19 16:01:40 model.py:61] Train: Rank: 0, epoch: 1, step: 5312, batch : 1561/1876, lr: 0.00000000, data time: 0.000s, train time: 3.016s, batch size: 64, train_loss: 17.136696\r\n[INFO 2021/06/19 16:01:43 model.py:61] Train: Rank: 0, epoch: 1, step: 5313, batch : 1562/1876, lr: 0.00000000, data time: 0.001s, train time: 2.932s, batch size: 64, train_loss: 16.347980\r\n[INFO 2021/06/19 16:01:46 model.py:61] Train: Rank: 0, epoch: 1, step: 5314, batch : 1563/1876, lr: 0.00000000, data time: 0.000s, train time: 3.120s, batch size: 64, train_loss: 12.675243\r\n[INFO 2021/06/19 16:01:49 model.py:61] Train: Rank: 0, epoch: 1, step: 5315, batch : 1564/1876, lr: 0.00000000, data time: 0.000s, train time: 3.011s, batch size: 64, train_loss: 15.479199\r\n[INFO 2021/06/19 16:01:52 model.py:61] Train: Rank: 0, epoch: 1, step: 5316, batch : 1565/1876, lr: 0.00000000, data time: 0.000s, train time: 2.994s, batch size: 64, train_loss: 16.016537\r\n[INFO 2021/06/19 16:01:55 model.py:61] Train: Rank: 0, epoch: 1, step: 5317, batch : 1566/1876, lr: 0.00000000, data time: 0.001s, train time: 2.938s, batch size: 64, train_loss: 14.940930\r\n[INFO 2021/06/19 16:01:58 model.py:61] Train: Rank: 0, epoch: 1, step: 5318, batch : 1567/1876, lr: 0.00000000, data time: 0.000s, train time: 2.984s, batch size: 64, train_loss: 16.664011\r\n[INFO 2021/06/19 16:02:01 model.py:61] Train: Rank: 0, epoch: 1, step: 5319, batch : 1568/1876, lr: 0.00000000, data time: 0.001s, train time: 2.917s, batch size: 64, train_loss: 15.314414\r\n[INFO 2021/06/19 16:02:04 model.py:61] Train: Rank: 0, epoch: 1, step: 5320, batch : 1569/1876, lr: 0.00000000, data time: 0.000s, train time: 3.067s, batch size: 64, train_loss: 19.256882\r\n[INFO 2021/06/19 16:02:07 model.py:61] Train: Rank: 0, epoch: 1, step: 5321, batch : 1570/1876, lr: 0.00000000, data time: 0.001s, train time: 3.073s, batch size: 64, train_loss: 17.577530\r\n[INFO 2021/06/19 16:02:10 model.py:61] Train: Rank: 0, epoch: 1, step: 5322, batch : 1571/1876, lr: 0.00000000, data time: 0.000s, train time: 3.058s, batch size: 64, train_loss: 13.793201\r\n[INFO 2021/06/19 16:02:13 model.py:61] Train: Rank: 0, epoch: 1, step: 5323, batch : 1572/1876, lr: 0.00000000, data time: 0.001s, train time: 2.957s, batch size: 64, train_loss: 17.981644\r\n[INFO 2021/06/19 16:02:16 model.py:61] Train: Rank: 0, epoch: 1, step: 5324, batch : 1573/1876, lr: 0.00000000, data time: 0.001s, train time: 3.084s, batch size: 64, train_loss: 16.675428\r\n[INFO 2021/06/19 16:02:19 model.py:61] Train: Rank: 0, epoch: 1, step: 5325, batch : 1574/1876, lr: 0.00000000, data time: 0.000s, train time: 3.019s, batch size: 64, train_loss: 16.754436\r\n[INFO 2021/06/19 16:02:22 model.py:61] Train: Rank: 0, epoch: 1, step: 5326, batch : 1575/1876, lr: 0.00000000, data time: 0.000s, train time: 3.084s, batch size: 64, train_loss: 12.173172\r\n[INFO 2021/06/19 16:02:25 model.py:61] Train: Rank: 0, epoch: 1, step: 5327, batch : 1576/1876, lr: 0.00000000, data time: 0.000s, train time: 3.141s, batch size: 64, train_loss: 17.882875\r\n[INFO 2021/06/19 16:02:28 model.py:61] Train: Rank: 0, epoch: 1, step: 5328, batch : 1577/1876, lr: 0.00000000, data time: 0.000s, train time: 2.959s, batch size: 64, train_loss: 14.933475\r\n[INFO 2021/06/19 16:02:32 model.py:61] Train: Rank: 0, epoch: 1, step: 5329, batch : 1578/1876, lr: 0.00000000, data time: 0.001s, train time: 3.190s, batch size: 64, train_loss: 16.997902\r\n[INFO 2021/06/19 16:02:34 model.py:61] Train: Rank: 0, epoch: 1, step: 5330, batch : 1579/1876, lr: 0.00000000, data time: 0.000s, train time: 2.941s, batch size: 64, train_loss: 16.430275\r\n[INFO 2021/06/19 16:02:38 model.py:61] Train: Rank: 0, epoch: 1, step: 5331, batch : 1580/1876, lr: 0.00000000, data time: 0.000s, train time: 3.125s, batch size: 64, train_loss: 16.318769\r\n[INFO 2021/06/19 16:02:41 model.py:61] Train: Rank: 0, epoch: 1, step: 5332, batch : 1581/1876, lr: 0.00000000, data time: 0.000s, train time: 3.028s, batch size: 64, train_loss: 18.299578\r\n[INFO 2021/06/19 16:02:44 model.py:61] Train: Rank: 0, epoch: 1, step: 5333, batch : 1582/1876, lr: 0.00000000, data time: 0.000s, train time: 3.112s, batch size: 64, train_loss: 14.934775\r\n[INFO 2021/06/19 16:02:47 model.py:61] Train: Rank: 0, epoch: 1, step: 5334, batch : 1583/1876, lr: 0.00000000, data time: 0.001s, train time: 3.093s, batch size: 64, train_loss: 17.445869\r\n[INFO 2021/06/19 16:02:50 model.py:61] Train: Rank: 0, epoch: 1, step: 5335, batch : 1584/1876, lr: 0.00000000, data time: 0.001s, train time: 2.957s, batch size: 64, train_loss: 18.386488\r\n[INFO 2021/06/19 16:02:53 model.py:61] Train: Rank: 0, epoch: 1, step: 5336, batch : 1585/1876, lr: 0.00000000, data time: 0.000s, train time: 2.978s, batch size: 64, train_loss: 15.902421\r\n[INFO 2021/06/19 16:02:56 model.py:61] Train: Rank: 0, epoch: 1, step: 5337, batch : 1586/1876, lr: 0.00000000, data time: 0.000s, train time: 2.977s, batch size: 64, train_loss: 12.690172\r\n[INFO 2021/06/19 16:02:59 model.py:61] Train: Rank: 0, epoch: 1, step: 5338, batch : 1587/1876, lr: 0.00000000, data time: 0.000s, train time: 3.012s, batch size: 64, train_loss: 13.637624\r\n[INFO 2021/06/19 16:03:02 model.py:61] Train: Rank: 0, epoch: 1, step: 5339, batch : 1588/1876, lr: 0.00000000, data time: 0.001s, train time: 3.089s, batch size: 64, train_loss: 15.179820\r\n[INFO 2021/06/19 16:03:05 model.py:61] Train: Rank: 0, epoch: 1, step: 5340, batch : 1589/1876, lr: 0.00000000, data time: 0.000s, train time: 2.981s, batch size: 64, train_loss: 16.540697\r\n[INFO 2021/06/19 16:03:08 model.py:61] Train: Rank: 0, epoch: 1, step: 5341, batch : 1590/1876, lr: 0.00000000, data time: 0.001s, train time: 3.051s, batch size: 64, train_loss: 16.708530\r\n[INFO 2021/06/19 16:03:11 model.py:61] Train: Rank: 0, epoch: 1, step: 5342, batch : 1591/1876, lr: 0.00000000, data time: 0.000s, train time: 3.056s, batch size: 64, train_loss: 14.384456\r\n[INFO 2021/06/19 16:03:14 model.py:61] Train: Rank: 0, epoch: 1, step: 5343, batch : 1592/1876, lr: 0.00000000, data time: 0.000s, train time: 2.957s, batch size: 64, train_loss: 15.726199\r\n[INFO 2021/06/19 16:03:17 model.py:61] Train: Rank: 0, epoch: 1, step: 5344, batch : 1593/1876, lr: 0.00000000, data time: 0.000s, train time: 3.002s, batch size: 64, train_loss: 14.959470\r\n[INFO 2021/06/19 16:03:20 model.py:61] Train: Rank: 0, epoch: 1, step: 5345, batch : 1594/1876, lr: 0.00000000, data time: 0.001s, train time: 3.075s, batch size: 64, train_loss: 15.619622\r\n[INFO 2021/06/19 16:03:23 model.py:61] Train: Rank: 0, epoch: 1, step: 5346, batch : 1595/1876, lr: 0.00000000, data time: 0.000s, train time: 3.058s, batch size: 64, train_loss: 15.734484\r\n[INFO 2021/06/19 16:03:26 model.py:61] Train: Rank: 0, epoch: 1, step: 5347, batch : 1596/1876, lr: 0.00000000, data time: 0.000s, train time: 3.292s, batch size: 64, train_loss: 16.957069\r\n[INFO 2021/06/19 16:03:29 model.py:61] Train: Rank: 0, epoch: 1, step: 5348, batch : 1597/1876, lr: 0.00000000, data time: 0.001s, train time: 3.123s, batch size: 64, train_loss: 17.215548\r\n[INFO 2021/06/19 16:03:32 model.py:61] Train: Rank: 0, epoch: 1, step: 5349, batch : 1598/1876, lr: 0.00000000, data time: 0.000s, train time: 3.005s, batch size: 64, train_loss: 16.323082\r\n[INFO 2021/06/19 16:03:36 model.py:61] Train: Rank: 0, epoch: 1, step: 5350, batch : 1599/1876, lr: 0.00000000, data time: 0.000s, train time: 3.110s, batch size: 64, train_loss: 16.539949\r\n[INFO 2021/06/19 16:03:39 model.py:61] Train: Rank: 0, epoch: 1, step: 5351, batch : 1600/1876, lr: 0.00000000, data time: 0.001s, train time: 3.086s, batch size: 64, train_loss: 15.122108\r\n[INFO 2021/06/19 16:03:42 model.py:61] Train: Rank: 0, epoch: 1, step: 5352, batch : 1601/1876, lr: 0.00000000, data time: 0.000s, train time: 3.012s, batch size: 64, train_loss: 14.657473\r\n[INFO 2021/06/19 16:03:45 model.py:61] Train: Rank: 0, epoch: 1, step: 5353, batch : 1602/1876, lr: 0.00000000, data time: 0.001s, train time: 3.190s, batch size: 64, train_loss: 18.860703\r\n[INFO 2021/06/19 16:03:48 model.py:61] Train: Rank: 0, epoch: 1, step: 5354, batch : 1603/1876, lr: 0.00000000, data time: 0.000s, train time: 3.012s, batch size: 64, train_loss: 18.484442\r\n[INFO 2021/06/19 16:03:51 model.py:61] Train: Rank: 0, epoch: 1, step: 5355, batch : 1604/1876, lr: 0.00000000, data time: 0.000s, train time: 3.143s, batch size: 64, train_loss: 18.698807\r\n[INFO 2021/06/19 16:03:54 model.py:61] Train: Rank: 0, epoch: 1, step: 5356, batch : 1605/1876, lr: 0.00000000, data time: 0.000s, train time: 3.029s, batch size: 64, train_loss: 15.407411\r\n[INFO 2021/06/19 16:03:57 model.py:61] Train: Rank: 0, epoch: 1, step: 5357, batch : 1606/1876, lr: 0.00000000, data time: 0.000s, train time: 3.219s, batch size: 64, train_loss: 16.926647",
        "state": "closed",
        "user": "yhz5256",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-19T08:04:17+00:00",
        "updated_at": "2021-09-06T12:52:36+00:00",
        "closed_at": "2021-09-06T12:52:36+00:00",
        "comments_count": [
            "zh794390558",
            "yhz5256",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 678,
        "title": "Implement a text frontend",
        "body": "# TTS 文本前端任务\r\n\r\n我们参考一般的流程，把文本前端分为4个阶段\r\n![tts_text_frontend](http://5b0988e595225.cdn.sohucs.com/images/20190812/1fb4a8f9515b42459fb9ea76a786ce79.png)\r\n1. 句子结构分析；\r\n我们给系统输入一个文本，系统要先判断这个文本是什么语言，只有知道是什么语言才知道接下来如何处理。然后把文本划分成一个一个的句子。这些句子再送给后面的模块处理。\r\n2. 文本正则化；\r\n在中文场景下，文本正则的目的是把那些不是汉字的标点或者数字转化为汉字。比如「这个操作666啊」，系统需要把「666」转化为「六六六」。\r\n3. 文本转音素；\r\n也就是把文本转化为拼音，由于中文中多音字的存在，所以我们不能直接通过像查新华字典一样的方法去找一个字的读音，必须通过其他辅助信息和一些算法来正确的决策到底要怎么读。这些辅助信息就包括了分词和每个词的词性。\r\n4. 韵律预测；\r\n用于决定读一句话时的节奏，也就是抑扬顿挫。但是一般的简化的系统都只是预测句子中的停顿信息。也就是一个字读完后是否需要停顿，停顿多久的决策。\r\n\r\n\r\n其中文本正则化分为三个阶段：\r\n\r\n1. tokenization（怎么处理 NSW (None Standard Word)让他不被分开，或者如何后处理，找出 NSW 片段）;\r\n2. NSW 分类（总的类别个数设计，如何分类。其中 1 和 2 可以融合成一个阶段）；\r\n3. Verbalization: 应用对应的规则进行分类（规则的可复用性，比如大多数数字相关的短语会调用数字的读法）。\r\n\r\n文本转音素分为两个阶段：\r\n\r\n1. 汉字转拼音（需要处理多音字，变调，专有名词特殊读法）；\r\n2. 拼音转音素。\r\n\r\n下面分阶段说明我们希望它如何运作：\r\n\r\n## 文本正则化\r\n\r\n### Tokenization\r\n\r\n一般来说，tokenization 并不等于分词，Multiple Word Token 是存在的，对于 TTS 领域尤为如此，把 4/5, 2020 分开之后，4/5 单独来看可能就难以分清是分数还是比率还是日期了。在基于规则的 Kestrel 系统中，也同样存在。日期，时间，货币，度量短语等是被作为一个单独的 token 处理的，这样也更加符合 TTS 领域的需求。\r\n\r\n对于中文领域，如果能复用现有的分词工具是最理想的选择。但现有的中文的分词工具，在分词时，对于 NSW 或者非汉语片段的处理方式值得注意，并没有明确或者统一的处理方式。\r\n\r\n### NSW 分类\r\n\r\n按照 Kestrel 的做法，对于每个 token 进行三分类，\r\n\r\n1.  standard words, 直接照抄即可；\r\n2. 标点符号，不发音；\r\n3. semiotic class 亦即 NSW. 需要进一步分类。\r\n\r\n目前我们计划支持的类别有\r\n\r\n1. 整数 CARDINAL\r\n\r\n   基础组件，在其他类型的 NSW 基本都需要。\r\n\r\n2. 序数 ORDINAL\r\n\r\n   汉语里面基本和基数读法没有差别，除了前附的“第-” ，以及序数中不使用“两”表示数字 `2`.\r\n\r\n3. 浮点数 DECIMAL\r\n\r\n   整数部分按整数读法，小数部分按编号读法。\r\n\r\n4. 百分数 PERCENTAGE\r\n\r\n   百分比的部分按照浮点数读法，前附“百分之”。\r\n\r\n5. 分数 FRACTION\r\n\r\n   分子和分母按照浮点数读法，分母 + “分之” + 分子。\r\n\r\n   如果有前附整数，先读整数部分，中间加“又”。\r\n\r\n6. 比值 RATIO\r\n\r\n   两部分按浮点数读法，中间加比。\r\n\r\n7. 时间 TIME & DURATION\r\n\r\n   分时间点和时间段两种读法。同时还需要判断是时分秒齐全还是仅有时分还是仅有分秒。\r\n\r\n   时间段的读法，几小时几分钟几秒即可，各个部分按照整数读法。\r\n\r\n   时间点的读法，几点几分几秒，各个部分按照整数读法，但是，从第二个数字开始，前附的 0 需要读出。\r\n\r\n8. 日期 DATE\r\n\r\n   需要判断是年月日各段齐全还是仅包含年月还是月和日，各个部分按照整数的读法。\r\n\r\n9. 货币 CURRENCY\r\n\r\n   判断是仅包含一种货币单位的浮点数读法。\r\n\r\n   还是十元五角这种包含多个货币单位的读法，按照文本的实际写法读出。各个部分按照整数读法。\r\n\r\n10. 度量短语 MEASUREMENT EXPRESSION\r\n\r\n    按照浮点数读法加上对应的度量即可。但是部分度量可能影响符号的读法，比如零下三度一般不读作负三度。度量则需要一个词典。\r\n\r\n11. 编号 DIGITS\r\n\r\n    按照各个数位读出即可。\r\n\r\n12. 电话 PHONE\r\n\r\n    一般按照编号的读法，但是可能存在`一`读作 `yao1` 的惯例。\r\n\r\n13. 邮箱 EMAIL\r\n\r\n14. 网址\r\n\r\n邮箱和网址主要都是涉及英文的读法，所以目前还没有很好的处理方式。\r\n\r\n我们的方案是：\r\n\r\n一个规则采用 `f: NSW -> normalized words `的方法实现。NSW 里面可以根据不同的类别设定不同的字段，并且把字段填充上，这样 verbalization 的时候就可以无需再进行解析。填充的过程可以使用正则表达式做分组匹配。\r\n\r\n目前需要做的是，对每一个类别实现一个类型，约定其需要填充的字段，并且写好对应的正则表达式规则去匹配。\r\n\r\n### Verbalization\r\n\r\nVerbalization 的部分是对于每一类提供单独的规则进行展开。其中大部分可以调用数字的 verbalization 方法。各个类别的 Verbalization 方法已经写在上面一节。\r\n\r\n\r\n\r\n## G2P \r\n\r\n### 汉字转拼音\r\n\r\n目前使用的方案就是先分词（对正则化后的文本分词），然后把分词的结果交由 pypinyin 处理。自定义可以通过自定义单字字段和短语字典的方式来实现。目前主要的问题有多音字和变调。\r\n\r\n**多音字**目前主要通过扩增短语词典的方式来实现，这样我们可以通过扩增词典来修改 bad case.\r\n\r\n**轻声**可以通过词典解决.\r\n\r\n“一” “不” 变调的问题相对简单，只要看其后面的字的声调即可。\r\n\r\n三声变调问题相对复杂一些。对于连续的上声字组成的短语，需要分析内部的结构才能准确标注变调。\r\n\r\n### 拼音转音素\r\n\r\n目前我们有两个方案，但是大同小异，其中一套和汉语拼音更为相近，只需要做简单的处理，另一套则则是识别领域的方案。\r\n\r\n\r\n\r\n## Reference\r\n* https://www.shenzhenware.com/articles/13355\r\n* https://zhuanlan.zhihu.com/p/70629035\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "iclementine",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-21T11:53:16+00:00",
        "updated_at": "2021-09-07T14:51:06+00:00",
        "closed_at": "2021-09-07T14:51:06+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 681,
        "title": "v1.8.5 ctc_beam_search en8k [ctc_beam_search_decoder.cpp:42] FATAL: \"(probs_seq[i].size()) == (vocabulary.size())\" check failed. The shape of probs_seq does not match with the shape of the vocabulary",
        "body": "I am getting error with version 1.8.5, \"ctc_beam_search\" with en8k model. The \"ctc_speedy\" decoder works fine. Is there any workaround/fix for \"ctc_beam_search\"? Thanks\r\n\r\n[INFO 2021-06-22 08:14:12,183 model.py:475] begin to initialize the external scorer for decoding\r\n[INFO 2021-06-22 08:15:51,802 model.py:482] language model: is_character_based = 0, max_order = 5, dict_size = 400000\r\n[INFO 2021-06-22 08:15:51,911 model.py:486] end initializing scorer\r\n[INFO 2021-06-22 08:15:51,912 infer.py:115] start inference ...\r\nfinish initing model from pretrained params from models/baidu_en8k\r\n[ctc_beam_search_decoder.cpp:42] FATAL: \"(probs_seq[i].size()) == (vocabulary.size())\" check failed. The shape of probs_seq does not match with the shape of the vocabulary\r\n[ctc_beam_search_decoder.cpp:42] FATAL: \"(probs_seq[i].size()) == (vocabulary.size())\" check failed. The shape of probs_seq does not match with the shape of the vocabulary\r\ncorrupted double-linked list\r\n\r\nCUDA_VISIBLE_DEVICES=0 \\\r\npython3 -u infer.py \\\r\n--num_samples=10 \\\r\n--beam_size=500 \\\r\n--num_proc_bsearch=5 \\\r\n--num_conv_layers=2 \\\r\n--num_rnn_layers=3 \\\r\n--rnn_layer_size=1024 \\\r\n--alpha=1.4 \\\r\n--beta=0.35 \\\r\n--cutoff_prob=1.0 \\\r\n--cutoff_top_n=40 \\\r\n--use_gru=True \\\r\n--use_gpu=True \\\r\n--share_rnn_weights=False \\\r\n--infer_manifest='data/tiny/manifest.test-clean' \\\r\n--mean_std_path='models/baidu_en8k/mean_std.npz' \\\r\n--vocab_path='models/baidu_en8k/vocab.txt' \\\r\n--model_path='models/baidu_en8k' \\\r\n--lang_model_path='models/lm/common_crawl_00.prune01111.trie.klm' \\\r\n--decoding_method='ctc_beam_search' \\\r\n--error_rate_type='wer' \\\r\n--specgram_type='linear'",
        "state": "closed",
        "user": "lightsailpro",
        "closed_by": "lightsailpro",
        "created_at": "2021-06-22T15:40:17+00:00",
        "updated_at": "2021-06-23T14:16:44+00:00",
        "closed_at": "2021-06-23T14:15:55+00:00",
        "comments_count": [
            "zh794390558",
            "lightsailpro"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 708
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 686,
        "title": "Possible memory leak during inference",
        "body": "**Describe the bug**\r\nMemory leak during inference.\r\n\r\n**To Reproduce**\r\nI am loading the model at the beginning and using the following method for inference, I added the tracking of memory with psutil after each step:\r\n```\r\ndef infer(data_generator, ds2_model, num_samples, manifest_path):\r\n\r\n    print('\\n start inference...')\r\n    print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\r\n\r\n    batch_reader = data_generator.batch_reader_creator(\r\n        manifest_path=manifest_path,\r\n        batch_size=num_samples,\r\n        sortagrad=False,\r\n        shuffle_method=None)\r\n\r\n    print('\\n batch reader done...')\r\n    print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\r\n\r\n    infer_data = next(batch_reader())\r\n\r\n    print('\\n infer data done...')\r\n    print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\r\n\r\n    # decoders only accept string encoded in utf-8\r\n    vocab_list = [chars.encode(\"utf-8\") for chars in data_generator.vocab_list]\r\n\r\n    print('\\n vocab list done...')\r\n    print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\r\n\r\n    #ds2_model.logger.info(\"start inference ...\")\r\n    probs_split = ds2_model.infer_batch_probs(\r\n        infer_data=infer_data,\r\n        feeding_dict=data_generator.feeding)\r\n\r\n    print('\\n end inference...')\r\n    print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\r\n\r\n    return probs_split, vocab_list\r\n```\r\n\r\nwhat it prints is the following:\r\n```\r\n1. #####\r\n start inference...\r\n524.296875\r\n\r\n batch reader done...\r\n524.296875\r\n\r\n infer data done...\r\n894.58984375\r\n\r\n vocab list done...\r\n894.58984375\r\n\r\n end inference...\r\n1416.91015625\r\n\r\n2. #####\r\n start inference...\r\n1416.31640625\r\n\r\n batch reader done...\r\n1416.31640625\r\n\r\n infer data done...\r\n1639.375\r\n\r\n vocab list done...\r\n1639.375\r\n\r\n end inference...\r\n1646.7109375\r\n\r\n3. #####\r\n\r\n start inference...\r\n1644.5703125\r\n\r\n batch reader done...\r\n1644.5703125\r\n\r\n infer data done...\r\n1649.79296875\r\n\r\n vocab list done...\r\n1649.79296875\r\n\r\n end inference...\r\n1655.1484375\r\n\r\n4. #####\r\n start inference...\r\n1655.69921875\r\n\r\n batch reader done...\r\n1655.69921875\r\n\r\n infer data done...\r\n1666.7265625\r\n\r\n vocab list done...\r\n1666.7265625\r\n\r\n end inference...\r\n1671.68359375\r\n\r\n#####\r\n start inference...\r\n1673.09765625\r\n\r\n batch reader done...\r\n1673.09765625\r\n\r\n infer data done...\r\n1914.06640625\r\n\r\n vocab list done...\r\n1914.06640625\r\n\r\n end inference...\r\n1962.15625\r\n```\r\n\r\n**Expected behavior**\r\nMemory should be released after inference.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: MacOS\r\n - GCC/G++ Version: g++ (Debian 8.3.0-6) 8.3.0\r\n - Python Version: 3.7.4\r\n - PaddlePaddle Version: 1.8.0\r\n - GPU/DRIVER Information: None\r\n - CUDA/CUDNN Version: None\r\n\r\n**Additional context**\r\nThe model is not running on GPU.\r\nThe model is fine-tuned on custom data.\r\nI am using [this configuration](https://github.com/shoegazerstella/DeepSpeech_CPU_py37) of DS running on python 3.7 in CPU mode only\r\n\r\nIs there some specific paddlepaddle method for releasing the memory?\r\nThanks in advance for your help",
        "state": "closed",
        "user": "shoegazerstella",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-24T08:46:34+00:00",
        "updated_at": "2021-11-04T00:56:00+00:00",
        "closed_at": "2021-11-04T00:56:00+00:00",
        "comments_count": [
            "stale[bot]",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 709
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 687,
        "title": "ManifestDataset' object has no attribute 'feature_size",
        "body": "ManifestDataset' object has no attribute 'feature_size",
        "state": "closed",
        "user": "xqmmy",
        "closed_by": "xqmmy",
        "created_at": "2021-06-25T00:06:36+00:00",
        "updated_at": "2021-06-25T05:28:08+00:00",
        "closed_at": "2021-06-25T05:28:08+00:00",
        "comments_count": [
            "zh794390558",
            "xqmmy"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 712
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 713
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 706,
        "title": "Run inference using pre-trained librispeech ",
        "body": "Hi, how may I run inference usingthe pretrained librispeech model for single .wav file? I can't find the file infer.sh in examples/librispeech/s0/local.",
        "state": "closed",
        "user": "Reuben-Lim",
        "closed_by": "Reuben-Lim",
        "created_at": "2021-07-14T06:38:32+00:00",
        "updated_at": "2021-07-21T01:56:56+00:00",
        "closed_at": "2021-07-21T01:56:56+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "Reuben-Lim"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 689,
        "title": "Failed in starting demo server!",
        "body": "Traceback (most recent call last):\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/server.py\", line 128, in <module>\r\n    main(config, args)\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/server.py\", line 94, in main\r\n    start_server(config, args)\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/server.py\", line 40, in start_server\r\n    dataset = ManifestDataset.from_config(config)\r\n  File \"/home/DeepSpeech/deepspeech/io/dataset.py\", line 57, in from_config\r\n    assert config.data.manifest\r\nAssertionError\r\nFailed in starting demo server!",
        "state": "closed",
        "user": "xqmmy",
        "closed_by": "stale[bot]",
        "created_at": "2021-06-25T05:36:57+00:00",
        "updated_at": "2021-09-08T12:11:30+00:00",
        "closed_at": "2021-09-08T12:11:30+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 707,
        "title": "python3.7启动服务出现问题",
        "body": "![image](https://user-images.githubusercontent.com/57654726/126030582-1c77d30b-2b2d-430b-b783-93a1171c55c1.png)\r\n![image](https://user-images.githubusercontent.com/57654726/126030596-583256ea-6449-4d0b-a09f-5169a5d561b8.png)\r\nsercer可以正常启动，但是本地音频录制就初选问题。\r\n",
        "state": "closed",
        "user": "xialei2821212670",
        "closed_by": "stale[bot]",
        "created_at": "2021-07-17T08:05:03+00:00",
        "updated_at": "2021-10-04T04:40:03+00:00",
        "closed_at": "2021-10-04T04:40:03+00:00",
        "comments_count": [
            "zh794390558",
            "xialei2821212670",
            "zh794390558",
            "xialei2821212670",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 724
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 725
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 710,
        "title": "导出模型报错，deepspeech.utils.checkpoint' has no attribute 'load_parameters'",
        "body": " File \"/home/lz/DeepSpeech/deepspeech/models/deepspeech2.py\", line 225, in from_pretrained\r\n    infos = checkpoint.load_parameters(\r\nAttributeError: module 'deepspeech.utils.checkpoint' has no attribute 'load_parameters'\r\nFailed in export!\r\n\r\n导出模型的时候报错，但是deepspeech.utils.checkpoint有load_parameters这个函数，怎么回事？",
        "state": "closed",
        "user": "shanmon110",
        "closed_by": "stale[bot]",
        "created_at": "2021-07-19T05:53:36+00:00",
        "updated_at": "2021-10-04T19:29:33+00:00",
        "closed_at": "2021-10-04T19:29:33+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 715,
        "title": "如何应用百度发布的“BaiduEN8k Model”模型？",
        "body": "https://www.paddlepaddle.org.cn/modelbasedetail/DeepSpeech2#%E5%8F%91%E5%B8%83%E6%A8%A1%E5%9E%8B\r\n\r\n这里提供里一些发布模型，如何应用？",
        "state": "closed",
        "user": "shanmon110",
        "closed_by": "stale[bot]",
        "created_at": "2021-07-20T15:41:30+00:00",
        "updated_at": "2021-10-14T08:47:05+00:00",
        "closed_at": "2021-10-14T08:47:04+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 716,
        "title": "如何添加自定义热词？",
        "body": "如何在此代码基础上添加热词，提高热词表的识别准确率？",
        "state": "closed",
        "user": "shanmon110",
        "closed_by": "stale[bot]",
        "created_at": "2021-07-20T15:44:23+00:00",
        "updated_at": "2023-07-06T01:39:46+00:00",
        "closed_at": "2021-10-04T19:29:32+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "tcexeexe",
            "jeffzhengye",
            "ericg108"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 721,
        "title": "Paddlehub部署",
        "body": "尝试在Windows环境下部署，修改好modul.py文件后用hub install DeepSpeech，显示no module swig-decoder，不知该怎么解决，有成功过的吗？",
        "state": "closed",
        "user": "FrankWhh",
        "closed_by": "FrankWhh",
        "created_at": "2021-07-22T07:59:00+00:00",
        "updated_at": "2021-07-23T00:37:25+00:00",
        "closed_at": "2021-07-23T00:37:25+00:00",
        "comments_count": [
            "zh794390558",
            "FrankWhh"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 759
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 726,
        "title": "执行bash local/client.sh时候报错ModuleNotFoundError: No module named 'auto_log'",
        "body": "执行bash local/client.sh时候报错ModuleNotFoundError: No module named 'auto_log'\r\n",
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "wonder2025",
        "created_at": "2021-07-25T11:47:21+00:00",
        "updated_at": "2021-10-20T02:28:48+00:00",
        "closed_at": "2021-07-25T12:06:14+00:00",
        "comments_count": [
            "wonder2025",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 727,
        "title": "aishell训练完的模型，测试效果，启动客户端报错，启动命令 bash ./local/client.sh ，按下空格键 ，报错如下",
        "body": "ys:1: DeprecationWarning: PY_SSIZE_T_CLEAN will be required for '#' formats\r\n Start Recording ...                                                                              Traceback (most recent call last):\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/client.py\", line 65, in callback\r\n    socket_send(args.host_ip, args.host_port, ''.join(data_list))\r\nTypeError: sequence item 0: expected str instance, bytes found\r\nTraceback (most recent call last):\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/client.py\", line 95, in <module>\r\n    main()\r\n  File \"/home/DeepSpeech/examples/aishell/s0/../../..//deepspeech/exps/deepspeech2/bin/deploy/client.py\", line 85, in main\r\n    if keyboard.record('esc'):\r\n  File \"/home/miniconda3/lib/python3.9/site-packages/keyboard/__init__.py\", line 1042, in record\r\n    wait(until, suppress=suppress, trigger_on_release=trigger_on_release)\r\n  File \"/home/miniconda3/lib/python3.9/site-packages/keyboard/__init__.py\", line 882, in wait\r\n    lock.wait()\r\n  File \"/home/miniconda3/lib/python3.9/site-packages/keyboard/__init__.py\", line 117, in wait\r\n    if _UninterruptibleEvent.wait(self, 0.5):\r\n  File \"/home/miniconda3/lib/python3.9/threading.py\", line 574, in wait\r\n    signaled = self._cond.wait(timeout)\r\n  File \"/home/miniconda3/lib/python3.9/threading.py\", line 316, in wait\r\n    gotit = waiter.acquire(True, timeout)\r\nTypeError\r\nFailed in starting demo client!\r\n",
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "wonder2025",
        "created_at": "2021-07-26T07:51:01+00:00",
        "updated_at": "2021-08-05T02:21:21+00:00",
        "closed_at": "2021-08-05T02:21:21+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 736,
        "title": "no download_model.sh in develop and release/v2.1 branch",
        "body": "Under DeepSpeech/examples/aishell/s0/local/, I cannot find download_model.sh in develop and release/v2.1 branch, but server.sh still uses it.\r\n",
        "state": "closed",
        "user": "wfchair",
        "closed_by": "stale[bot]",
        "created_at": "2021-07-28T10:14:48+00:00",
        "updated_at": "2021-11-02T03:08:14+00:00",
        "closed_at": "2021-11-02T03:08:14+00:00",
        "comments_count": [
            "zh794390558",
            "wfchair",
            "zh794390558",
            "wfchair",
            "zh794390558",
            "wfchair",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 760
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 764
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 765
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 738,
        "title": "2.1中如何用已训练的模型，加入数据继续训练呢",
        "body": "",
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "wonder2025",
        "created_at": "2021-08-01T11:46:53+00:00",
        "updated_at": "2021-08-04T01:06:11+00:00",
        "closed_at": "2021-08-04T01:06:11+00:00",
        "comments_count": [
            "zh794390558",
            "wonder2025",
            "zh794390558",
            "wonder2025",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 758,
        "title": "如何使用baidu_cn1.2k_model_fluid.tar.gz模型做识别？",
        "body": "我看到github上的DeepSpeech能够支持python3.7和paddlepaddle 2.x，请问我要用baidu_cn1.2k_model_fluid.tar.gz模型做语音识别用几个文件，说明文档并没有说明，谢谢！",
        "state": "closed",
        "user": "leesky20116",
        "closed_by": "stale[bot]",
        "created_at": "2021-08-17T06:56:32+00:00",
        "updated_at": "2021-11-01T00:19:10+00:00",
        "closed_at": "2021-11-01T00:19:10+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 771
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 772
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 773
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 762,
        "title": "dataloader多线程读取数据报错：无'_shutdown'属性",
        "body": "[ERROR 2021/08/18 08:55:40 trainer.py:182] Can't pickle <class 'deepspeech.io.dataset.local_data'>: attribute lookup local_data on deepspeech.io.dataset failed\r\nException ignored in: <function _DataLoaderIterMultiProcess.__del__ at 0x7f752502b290>\r\nTraceback (most recent call last):\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 763, in __del__\r\n    self._try_shutdown_all()\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 577, in _try_shutdown_all\r\n    if not self._shutdown:\r\nAttributeError: '_DataLoaderIterMultiProcess' object has no attribute '_shutdown'\r\n\r\n\r\nnum_workers=0可以正常训练，但速度太慢了，然后设置不为0时就会报上述错误，请问怎么解决该问题？",
        "state": "closed",
        "user": "zdyupup",
        "closed_by": "zdyupup",
        "created_at": "2021-08-18T09:15:17+00:00",
        "updated_at": "2021-08-23T01:14:30+00:00",
        "closed_at": "2021-08-23T01:14:30+00:00",
        "comments_count": [
            "zh794390558",
            "zdyupup"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 774
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 799
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 800
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 770,
        "title": "server.py里引用路径错误",
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\ndeepspeech/exps/deepspeech2/bin/deploy/server.py 里面引用的是 from deepspeech.models.deepspeech2 import DeepSpeech2Model，实际应该是 deepspeech.models.ds2，建议更新代码。\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.  查看代码  (日期：2021-8-19)\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/develop/deepspeech/exps/deepspeech2/bin/deploy/server.py#L24\r\n引用的是deepspeech2\r\n2. 查看被引用的目录 https://github.com/PaddlePaddle/DeepSpeech/tree/develop/deepspeech/models\r\n子目录只有 ds2\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nserver.py的引用应该跟代码一致，其他地方也可能有类似问题。\r\n\r\n",
        "state": "closed",
        "user": "liweigu",
        "closed_by": "zh794390558",
        "created_at": "2021-08-19T08:32:18+00:00",
        "updated_at": "2021-08-20T03:27:47+00:00",
        "closed_at": "2021-08-20T03:27:47+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 803
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 804
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 805
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 790,
        "title": "insufficient shared memory",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n在Docker下训练一段时间报错：\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 在Docker下训练一段时间（Train: Rank: 0, epoch: 0, step: 831, batch : 832/1876,）报共享内存不足的错。\r\n2. 在 deepspeech2.yaml 里添加以下内容后，仍然报错：\r\nloader:\r\n  use_shared_memory: False\r\ndeepspeech2.yaml 好像不能设置不使用共享内存。\r\n\r\n**Expected behavior**\r\n期望能持续训练，不报共享内存的错。\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: Ubuntu 20.04, Docker version 19.03.9\r\n - GCC/G++ Version: Docker内(Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\r\n - Python Version: 3.8.10\r\n - PaddlePaddle Version: 2.1.2\r\n - Model Version: 从头训练\r\n - GPU/DRIVER Informationo: NVIDIA-SMI 460.91.03, Driver Version: 460.91.03, NVIDIA UNIX x86_64 Kernel Module  460.91.03\r\n - CUDA/CUDNN Version: cuda-11.2\r\n\r\n",
        "state": "closed",
        "user": "liweigu",
        "closed_by": "liweigu",
        "created_at": "2021-08-26T01:27:49+00:00",
        "updated_at": "2021-08-27T06:06:06+00:00",
        "closed_at": "2021-08-27T06:06:06+00:00",
        "comments_count": [
            "zh794390558",
            "liweigu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 778,
        "title": "如何用1.8版本微调“BaiduEN8k Model”模型？",
        "body": "我用1.8版本的代码跑通了测试的，但是目前我想用我自己的数据微调，但是没有提供脚本。我自己写的时候参数对不上。请问如何用1.8版本微调“BaiduEN8k Model”模型？\r\n\r\nMany thanks for your help\r\n",
        "state": "closed",
        "user": "shanmon110",
        "closed_by": "stale[bot]",
        "created_at": "2021-08-23T05:46:03+00:00",
        "updated_at": "2021-11-07T09:08:09+00:00",
        "closed_at": "2021-11-07T09:08:09+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 797,
        "title": "Trying Live Demo with Your Own Voice.",
        "body": "根据给定的[教程](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/doc/src/server.md)执行相关启动ASR服务端引擎。\r\n\r\n但是查看了server.sh源码发现，必须制定checkpoint_path，否则退出。\r\n相关代码如下：\r\n`if [[ $# != 1 ]];then\r\n   echo \"usage: $1 checkpoint_path\"\r\n   exit -1\r\nfi`\r\n\r\n但是根据教程是可以省略checkpoint_path参数的。\r\n\r\n其次，使用预训练模型（pre-trained Chinese model (trained with AISHELL1)）进行推理需要data/manifest.test文件。使用预训练模型还需要先训练一遍吗。。。（这不合理）。此处推测是相关教程忘记修改了。\r\n\r\n",
        "state": "closed",
        "user": "qjaden",
        "closed_by": "qjaden",
        "created_at": "2021-08-31T06:38:29+00:00",
        "updated_at": "2021-09-01T07:53:33+00:00",
        "closed_at": "2021-09-01T07:53:33+00:00",
        "comments_count": [
            "zh794390558",
            "qjaden",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 806
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 795,
        "title": "请问有使用到发音字典吗",
        "body": "请问有使用到发音字典吗",
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "wonder2025",
        "created_at": "2021-08-30T15:03:26+00:00",
        "updated_at": "2021-09-09T08:29:30+00:00",
        "closed_at": "2021-09-09T08:29:30+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 807
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 849
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 834,
        "title": "2.1 版本怎么在预训练模型上进行训练的",
        "body": "![微信截图_20210916153555](https://user-images.githubusercontent.com/30387771/133570295-219f99fb-77a2-449c-b1e2-76646249fb97.png)\r\n请问一下，怎么在 Ds2 Online Aishell Model 模型上进行训练的，需要添加些什么参数？还是在 yaml 配置文件添加？",
        "state": "closed",
        "user": "maomaoyu2",
        "closed_by": "maomaoyu2",
        "created_at": "2021-09-16T07:39:07+00:00",
        "updated_at": "2021-09-16T08:42:00+00:00",
        "closed_at": "2021-09-16T08:42:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 825,
        "title": "bash run.sh 出现报错",
        "body": "![微信截图_20210914175845](https://user-images.githubusercontent.com/30387771/133237615-7ab1ebc0-6731-4cf6-bae6-279680ad86fe.png)\r\n",
        "state": "closed",
        "user": "maomaoyu2",
        "closed_by": "maomaoyu2",
        "created_at": "2021-09-14T10:00:26+00:00",
        "updated_at": "2021-09-16T06:07:31+00:00",
        "closed_at": "2021-09-16T06:07:31+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 826,
        "title": "导入数据出错",
        "body": "![image](https://user-images.githubusercontent.com/31851742/133256870-82b8799a-b91a-4951-a5e2-2ea7ba9a090d.png)",
        "state": "closed",
        "user": "qq1440837150",
        "closed_by": "qq1440837150",
        "created_at": "2021-09-14T12:23:54+00:00",
        "updated_at": "2021-09-14T12:25:49+00:00",
        "closed_at": "2021-09-14T12:25:49+00:00",
        "comments_count": [
            "qq1440837150"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 830,
        "title": "运行例子出错",
        "body": "checkpoint name deepspeech2\r\n  File \"/DeepSpeech/examples/dataset/librispeech/librispeech.py\", line 122\r\n    print(f\"{subset}:\", file=f)\r\n                     ^\r\nSyntaxError: invalid syntax\r\nPrepare LibriSpeech failed. Terminated.\r\n![image](https://user-images.githubusercontent.com/31851742/133457098-56babf41-e985-4ec1-8d71-0094f6743f38.png)\r\n",
        "state": "closed",
        "user": "qq1440837150",
        "closed_by": "stale[bot]",
        "created_at": "2021-09-15T14:54:02+00:00",
        "updated_at": "2021-11-30T10:56:29+00:00",
        "closed_at": "2021-11-30T10:56:29+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 832,
        "title": "kenlm训练得到的模型在哪里可以下载呢",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "expresschen",
        "closed_by": "stale[bot]",
        "created_at": "2021-09-16T04:12:11+00:00",
        "updated_at": "2021-12-03T11:03:43+00:00",
        "closed_at": "2021-12-03T11:03:43+00:00",
        "comments_count": [
            "zh794390558",
            "expresschen",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 835,
        "title": "install.md链接坏了",
        "body": "是不是换这个链接啊？还是说仓库更新了，老的install.md不好使了？\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/src/install.md\r\n",
        "state": "closed",
        "user": "pandahop",
        "closed_by": "yt605155624",
        "created_at": "2021-09-16T07:58:37+00:00",
        "updated_at": "2021-11-10T14:07:34+00:00",
        "closed_at": "2021-11-10T14:07:34+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 836,
        "title": "2.1版本在 Ds2 Online Aishell Model 预训练模型上进行训练",
        "body": "\r\n请教一下，2.1版本要在在 Ds2 Online Aishell Model 预训练模型上进行训练，需要添加什么参数？",
        "state": "closed",
        "user": "maomaoyu2",
        "closed_by": "stale[bot]",
        "created_at": "2021-09-16T09:20:21+00:00",
        "updated_at": "2021-12-03T11:03:44+00:00",
        "closed_at": "2021-12-03T11:03:44+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 887,
        "title": "import auto_log 这个库Google都搜不到啊",
        "body": "下面这个文件中的库，请问哪里可以找到？\r\n\r\n/data/yezheng/audio/DeepSpeech/deepspeech/utils/log.py\r\n121         import auto_log",
        "state": "closed",
        "user": "jeffzhengye",
        "closed_by": "jeffzhengye",
        "created_at": "2021-10-13T05:29:44+00:00",
        "updated_at": "2021-10-25T08:06:15+00:00",
        "closed_at": "2021-10-25T08:06:15+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 895
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 896
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 893,
        "title": "在运行example/tiny/s0/local/test.sh时报错",
        "body": "使用的docker环境，镜像为registry.baidubce.com/paddlepaddle/paddle:2.1.3-gpu-cuda10.2-cudnn7，解决了各种问题后，终于环境编译通过，现在运行tiny/run.sh进行测试，在运行到test.sh时会发生错误，找不到解决方法，请求帮助。以下为报错信息\r\n\r\n2021-10-14 08:27:28.545 | INFO     | deepspeech.exps.deepspeech2.model:test:358 - Test Total Examples: 10\r\n2021-10-14 08:27:28,605 - auto_log.autolog - INFO - Init logger done!\r\n2021-10-14 08:27:28.841 | INFO     | deepspeech.modules.ctc:_init_ext_scorer:170 - begin to initialize the external scorer for decoding\r\n2021-10-14 08:27:28.842 | INFO     | deepspeech.training.timer:__exit__:44 - Test/Decode Done: 0:00:01.069955\r\nTraceback (most recent call last):\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/bin/test.py\", line 54, in <module>\r\n    main(config, args)\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/bin/test.py\", line 28, in main\r\n    main_sp(config, args)\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/bin/test.py\", line 24, in main_sp\r\n    exp.run_test()\r\n  File \"/DeepSpeech/deepspeech/training/trainer.py\", line 335, in run_test\r\n    self.test()\r\n  File \"/DeepSpeech/deepspeech/utils/mp_tools.py\", line 27, in wrapper\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n    result = func(*args, **kwargs)\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/model.py\", line 371, in test\r\n    texts_len, fout)\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/model.py\", line 306, in compute_metrics\r\n    vocab_list, cfg)\r\n  File \"/DeepSpeech/deepspeech/exps/deepspeech2/model.py\", line 343, in compute_result_transcripts\r\n    num_processes=cfg.num_proc_bsearch)\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/DeepSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/DeepSpeech/deepspeech/models/ds2/deepspeech2.py\", line 194, in decode\r\n    decoding_method=decoding_method)\r\n  File \"/DeepSpeech/deepspeech/modules/ctc.py\", line 237, in init_decode\r\n    vocab_list)\r\n  File \"/DeepSpeech/deepspeech/modules/ctc.py\", line 172, in _init_ext_scorer\r\n    self._ext_scorer = Scorer(beam_alpha, beam_beta,\r\nNameError: name 'Scorer' is not defined\r\n/DeepSpeech/tools/venv/lib/python3.7/site-packages/scipy/fftpack/__init__.py:103: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\r\n  from numpy.dual import register_func\r\n/DeepSpeech/tools/venv/lib/python3.7/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n/DeepSpeech/tools/venv/lib/python3.7/site-packages/swig_decoders-1.1-py3.7-linux-x86_64.egg/swig_decoders.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n2021-10-14 08:27:29.818 | INFO     | deepspeech.modules.ctc:<module>:30 - ctcdecoder not installed!\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/python3.7.0/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/multiprocessing/synchronize.py\", line 111, in __setstate__\r\n    self._semlock = _multiprocessing.SemLock._rebuild(*state)\r\nFileNotFoundError: [Errno 2] No such file or directory\r\nFailed in evaluation!",
        "state": "closed",
        "user": "26903651",
        "closed_by": "stale[bot]",
        "created_at": "2021-10-14T08:49:41+00:00",
        "updated_at": "2022-01-03T08:26:07+00:00",
        "closed_at": "2022-01-03T08:26:07+00:00",
        "comments_count": [
            "zh794390558",
            "26903651",
            "26903651",
            "26903651",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 902,
        "title": "deepspeech2中offline和online有什么区别？",
        "body": "介绍中offline模型使用堆叠的双向 rnn 层，而online模型使用单向 rnn 层并且不使用 fc 层。\r\n这样做法使得这两个模型有什么不同之处吗？\r\n它们区分为Streaming和No-Streaming，这是什么意思？是不是说Streaming可以实时识别？不需要等一句话说完？",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-10-18T03:59:10+00:00",
        "updated_at": "2021-10-19T07:08:05+00:00",
        "closed_at": "2021-10-19T07:08:05+00:00",
        "comments_count": [
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 911,
        "title": "我是用deepspeech2_online训练thchs30模型不收敛",
        "body": "训练的损失一直在200左右，一直下不去，训练23个epoch了。还是不变，测试时，字错率在\r\n\r\nTest: epoch: 22, step: 3589, Final error rate [cer] (2495/2495) = 0.976127\r\n\r\n使用的配置：\r\n```\r\ngpus=0\r\nstage=0\r\nstop_stage=100\r\nconf_path=conf/deepspeech2_online.yaml\r\navg_num=1\r\nmodel_type=online\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-10-20T03:06:59+00:00",
        "updated_at": "2021-11-08T08:29:02+00:00",
        "closed_at": "2021-11-08T08:29:02+00:00",
        "comments_count": [
            "Jackwaterveg",
            "yeyupiaoling",
            "Jackwaterveg",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 914,
        "title": "deepspeech2数据输入问题",
        "body": "我发现两个deepspeech2的模型输入shape不同，online的是`[B, T, D]`，普通的是`[B, D, T]`，是不是写错了，还是就是这样的？为什么？\r\n\r\n这个是online的\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/0674d9ec24a29090707ae29b76d48fc1d6310c14/deepspeech/models/ds2_online/deepspeech2.py#L130\r\n\r\n这个普通的\r\nhttps://github.com/PaddlePaddle/DeepSpeech/blob/0674d9ec24a29090707ae29b76d48fc1d6310c14/deepspeech/models/ds2/deepspeech2.py#L73-L74",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-10-20T09:38:45+00:00",
        "updated_at": "2021-10-21T03:13:11+00:00",
        "closed_at": "2021-10-21T03:13:11+00:00",
        "comments_count": [
            "Jackwaterveg",
            "yeyupiaoling",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 950,
        "title": "如何使用语言模型用于解码？",
        "body": "最近在看deepspeech-latest，发现2个问题：\r\n1、查看aishell/s1中demo并没有使用语言模型(u2)，如何使用自训练的模型\r\n2、TLG在解码时如何使用\r\n\r\n希望给予帮助或者提供可以学习的资料。再次感谢🙏",
        "state": "closed",
        "user": "teng19880904",
        "closed_by": "stale[bot]",
        "created_at": "2021-10-30T03:32:52+00:00",
        "updated_at": "2022-01-19T04:55:03+00:00",
        "closed_at": "2022-01-19T04:55:03+00:00",
        "comments_count": [
            "zh794390558",
            "teng19880904",
            "zh794390558",
            "teng19880904",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 924,
        "title": " ERROR: Failed building wheel for paddle-speech",
        "body": "Requirement already satisfied: argcomplete>=1.8.1 in ./tools/venv/lib/python3.7/site-packages (from yq->paddle-speech==2.1.2) (1.12.3)\r\nBuilding wheels for collected packages: paddle-speech\r\n  Building wheel for paddle-speech (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /home/data/zhijiangbei/yinping/DeepSpeech/tools/venv/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-abywj844/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-abywj844/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-4c81siu0\r\n       cwd: /tmp/pip-req-build-abywj844/\r\n  Complete output (794 lines):\r\n  /home/data/zhijiangbei/yinping/DeepSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n    % (opt, underscore_opt))\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib\r\n  creating build/lib/utils\r\n  copying utils/__init__.py -> build/lib/utils\r\n  copying utils/manifest_key_value.py -> build/lib/utils\r\n  copying utils/utility.py -> build/lib/utils\r\n  copying utils/zh_tn.py -> build/lib/utils\r\n  copying utils/compute_statistics.py -> build/lib/utils\r\n  copying utils/format_data.py -> build/lib/utils\r\n  copying utils/avg_model.py -> build/lib/utils\r\n  copying utils/json2trn.py -> build/lib/utils\r\n  copying utils/compute_mean_std.py -> build/lib/utils\r\n  copying utils/filter.py -> build/lib/utils\r\n  copying utils/gen_duration_from_textgrid.py -> build/lib/utils\r\n  copying utils/build_vocab.py -> build/lib/utils\r\n  copying utils/dump_manifest.py -> build/lib/utils\r\n  copying utils/format_triplet_data.py -> build/lib/utils\r\n  creating build/lib/parakeet\r\n  copying parakeet/__init__.py -> build/lib/parakeet\r\n  creating build/lib/third_party\r\n  copying third_party/__init__.py -> build/lib/third_party\r\n  creating build/lib/deepspeech\r\n  copying deepspeech/__init__.py -> build/lib/deepspeech\r\n  creating build/lib/parakeet/data\r\n  copying parakeet/data/__init__.py -> build/lib/parakeet/data\r\n  copying parakeet/data/batch.py -> build/lib/parakeet/data\r\n  copying parakeet/data/get_feats.py -> build/lib/parakeet/data\r\n  copying parakeet/data/dataset.py -> build/lib/parakeet/data\r\n  creating build/lib/parakeet/datasets\r\n  copying parakeet/datasets/__init__.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/preprocess_utils.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/common.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/ljspeech.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/am_batch_fn.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/data_table.py -> build/lib/parakeet/datasets\r\n  copying parakeet/datasets/vocoder_batch_fn.py -> build/lib/parakeet/datasets\r\n  creating build/lib/parakeet/frontend\r\n  copying parakeet/frontend/__init__.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/vocab.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/pinyin.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/zh_frontend.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/generate_lexicon.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/tone_sandhi.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/phonectic.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/punctuation.py -> build/lib/parakeet/frontend\r\n  copying parakeet/frontend/arpabet.py -> build/lib/parakeet/frontend\r\n  creating build/lib/parakeet/utils\r\n  copying parakeet/utils/display.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/profiler.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/__init__.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/timeline.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/profile.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/error_rate.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/layer_tools.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/internals.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/scheduler.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/mp_tools.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/checkpoint.py -> build/lib/parakeet/utils\r\n  copying parakeet/utils/h5_utils.py -> build/lib/parakeet/utils\r\n  creating build/lib/parakeet/models\r\n  copying parakeet/models/__init__.py -> build/lib/parakeet/models\r\n  copying parakeet/models/waveflow.py -> build/lib/parakeet/models\r\n  copying parakeet/models/lstm_speaker_encoder.py -> build/lib/parakeet/models\r\n  copying parakeet/models/tacotron2.py -> build/lib/parakeet/models\r\n  creating build/lib/parakeet/training\r\n  copying parakeet/training/__init__.py -> build/lib/parakeet/training\r\n  copying parakeet/training/trigger.py -> build/lib/parakeet/training\r\n  copying parakeet/training/optimizer.py -> build/lib/parakeet/training\r\n  copying parakeet/training/default_config.py -> build/lib/parakeet/training\r\n  copying parakeet/training/experiment.py -> build/lib/parakeet/training\r\n  copying parakeet/training/trainer.py -> build/lib/parakeet/training\r\n  copying parakeet/training/cli.py -> build/lib/parakeet/training\r\n  copying parakeet/training/reporter.py -> build/lib/parakeet/training\r\n  copying parakeet/training/seeding.py -> build/lib/parakeet/training\r\n  copying parakeet/training/updater.py -> build/lib/parakeet/training\r\n  copying parakeet/training/extension.py -> build/lib/parakeet/training\r\n  creating build/lib/parakeet/modules\r\n  copying parakeet/modules/__init__.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/expansion.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/conv.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/losses.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/positional_encoding.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/layer_norm.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/masking.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/nets_utils.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/geometry.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/transformer.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/glu.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/style_encoder.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/stft_loss.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/masked_fill.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/attention.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/audio.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/ssim.py -> build/lib/parakeet/modules\r\n  copying parakeet/modules/normalizer.py -> build/lib/parakeet/modules\r\n  creating build/lib/parakeet/audio\r\n  copying parakeet/audio/__init__.py -> build/lib/parakeet/audio\r\n  copying parakeet/audio/spec_normalizer.py -> build/lib/parakeet/audio\r\n  copying parakeet/audio/audio.py -> build/lib/parakeet/audio\r\n  creating build/lib/parakeet/exps\r\n  copying parakeet/exps/__init__.py -> build/lib/parakeet/exps\r\n  creating build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/num.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/__init__.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/char_convert.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/quantifier.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/constants.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/chronology.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/text_normlization.py -> build/lib/parakeet/frontend/zh_normalization\r\n  copying parakeet/frontend/zh_normalization/phonecode.py -> build/lib/parakeet/frontend/zh_normalization\r\n  creating build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/__init__.py -> build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/width.py -> build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/acronyms.py -> build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/abbrrviation.py -> build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/numbers.py -> build/lib/parakeet/frontend/normalizer\r\n  copying parakeet/frontend/normalizer/normalizer.py -> build/lib/parakeet/frontend/normalizer\r\n  creating build/lib/parakeet/models/parallel_wavegan\r\n  copying parakeet/models/parallel_wavegan/__init__.py -> build/lib/parakeet/models/parallel_wavegan\r\n  copying parakeet/models/parallel_wavegan/parallel_wavegan_updater.py -> build/lib/parakeet/models/parallel_wavegan\r\n  copying parakeet/models/parallel_wavegan/parallel_wavegan.py -> build/lib/parakeet/models/parallel_wavegan\r\n  creating build/lib/parakeet/models/transformer_tts\r\n  copying parakeet/models/transformer_tts/__init__.py -> build/lib/parakeet/models/transformer_tts\r\n  copying parakeet/models/transformer_tts/transformer_tts_updater.py -> build/lib/parakeet/models/transformer_tts\r\n  copying parakeet/models/transformer_tts/transformer_tts.py -> build/lib/parakeet/models/transformer_tts\r\n  creating build/lib/parakeet/models/fastspeech2\r\n  copying parakeet/models/fastspeech2/__init__.py -> build/lib/parakeet/models/fastspeech2\r\n  copying parakeet/models/fastspeech2/fastspeech2_updater.py -> build/lib/parakeet/models/fastspeech2\r\n  copying parakeet/models/fastspeech2/fastspeech2.py -> build/lib/parakeet/models/fastspeech2\r\n  creating build/lib/parakeet/models/speedyspeech\r\n  copying parakeet/models/speedyspeech/__init__.py -> build/lib/parakeet/models/speedyspeech\r\n  copying parakeet/models/speedyspeech/speedyspeech.py -> build/lib/parakeet/models/speedyspeech\r\n  copying parakeet/models/speedyspeech/speedyspeech_updater.py -> build/lib/parakeet/models/speedyspeech\r\n  creating build/lib/parakeet/training/triggers\r\n  copying parakeet/training/triggers/__init__.py -> build/lib/parakeet/training/triggers\r\n  copying parakeet/training/triggers/interval_trigger.py -> build/lib/parakeet/training/triggers\r\n  copying parakeet/training/triggers/limit_trigger.py -> build/lib/parakeet/training/triggers\r\n  copying parakeet/training/triggers/time_trigger.py -> build/lib/parakeet/training/triggers\r\n  creating build/lib/parakeet/training/updaters\r\n  copying parakeet/training/updaters/__init__.py -> build/lib/parakeet/training/updaters\r\n  copying parakeet/training/updaters/standard_updater.py -> build/lib/parakeet/training/updaters\r\n  creating build/lib/parakeet/training/extensions\r\n  copying parakeet/training/extensions/__init__.py -> build/lib/parakeet/training/extensions\r\n  copying parakeet/training/extensions/visualizer.py -> build/lib/parakeet/training/extensions\r\n  copying parakeet/training/extensions/snapshot.py -> build/lib/parakeet/training/extensions\r\n  copying parakeet/training/extensions/evaluator.py -> build/lib/parakeet/training/extensions\r\n  creating build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/__init__.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/decoder.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/repeat.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/multi_layer_conv.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/positionwise_feed_forward.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/encoder_layer.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/embedding.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/mask.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/lightconv.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/attention.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/decoder_layer.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  copying parakeet/modules/fastspeech2_transformer/encoder.py -> build/lib/parakeet/modules/fastspeech2_transformer\r\n  creating build/lib/parakeet/modules/tacotron2\r\n  copying parakeet/modules/tacotron2/__init__.py -> build/lib/parakeet/modules/tacotron2\r\n  copying parakeet/modules/tacotron2/decoder.py -> build/lib/parakeet/modules/tacotron2\r\n  copying parakeet/modules/tacotron2/encoder.py -> build/lib/parakeet/modules/tacotron2\r\n  creating build/lib/parakeet/modules/fastspeech2_predictor\r\n  copying parakeet/modules/fastspeech2_predictor/__init__.py -> build/lib/parakeet/modules/fastspeech2_predictor\r\n  copying parakeet/modules/fastspeech2_predictor/variance_predictor.py -> build/lib/parakeet/modules/fastspeech2_predictor\r\n  copying parakeet/modules/fastspeech2_predictor/duration_predictor.py -> build/lib/parakeet/modules/fastspeech2_predictor\r\n  copying parakeet/modules/fastspeech2_predictor/length_regulator.py -> build/lib/parakeet/modules/fastspeech2_predictor\r\n  creating build/lib/parakeet/exps/fastspeech2\r\n  copying parakeet/exps/fastspeech2/__init__.py -> build/lib/parakeet/exps/fastspeech2\r\n  creating build/lib/parakeet/exps/gan_vocoder\r\n  copying parakeet/exps/gan_vocoder/__init__.py -> build/lib/parakeet/exps/gan_vocoder\r\n  creating build/lib/parakeet/exps/gan_vocoder/pwgan\r\n  copying parakeet/exps/gan_vocoder/pwgan/__init__.py -> build/lib/parakeet/exps/gan_vocoder/pwgan\r\n  creating build/lib/third_party/paddle_audio\r\n  copying third_party/paddle_audio/__init__.py -> build/lib/third_party/paddle_audio\r\n  creating build/lib/third_party/text_processing\r\n  copying third_party/text_processing/__init__.py -> build/lib/third_party/text_processing\r\n  copying third_party/text_processing/__ini__.py -> build/lib/third_party/text_processing\r\n  creating build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/num.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/__init__.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/phone.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/char_convert.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/quantifier.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/constants.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/chronology.py -> build/lib/third_party/text_processing/normalization\r\n  copying third_party/text_processing/normalization/sentence_split.py -> build/lib/third_party/text_processing/normalization\r\n  creating build/lib/deepspeech/decoders\r\n  copying deepspeech/decoders/__init__.py -> build/lib/deepspeech/decoders\r\n  copying deepspeech/decoders/beam_search.py -> build/lib/deepspeech/decoders\r\n  copying deepspeech/decoders/utils.py -> build/lib/deepspeech/decoders\r\n  creating build/lib/deepspeech/frontend\r\n  copying deepspeech/frontend/__init__.py -> build/lib/deepspeech/frontend\r\n  copying deepspeech/frontend/utility.py -> build/lib/deepspeech/frontend\r\n  copying deepspeech/frontend/speech.py -> build/lib/deepspeech/frontend\r\n  copying deepspeech/frontend/audio.py -> build/lib/deepspeech/frontend\r\n  copying deepspeech/frontend/normalizer.py -> build/lib/deepspeech/frontend\r\n  creating build/lib/deepspeech/utils\r\n  copying deepspeech/utils/profiler.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/__init__.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/socket_server.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/utility.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/error_rate.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/tensor_utils.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/dynamic_import.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/layer_tools.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/text_grid.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/log.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/mp_tools.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/checkpoint.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/bleu_score.py -> build/lib/deepspeech/utils\r\n  copying deepspeech/utils/ctc_utils.py -> build/lib/deepspeech/utils\r\n  creating build/lib/deepspeech/models\r\n  copying deepspeech/models/__init__.py -> build/lib/deepspeech/models\r\n  copying deepspeech/models/u2_st.py -> build/lib/deepspeech/models\r\n  creating build/lib/deepspeech/training\r\n  copying deepspeech/training/gradclip.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/__init__.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/timer.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/optimizer.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/scheduler.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/trainer.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/cli.py -> build/lib/deepspeech/training\r\n  copying deepspeech/training/reporter.py -> build/lib/deepspeech/training\r\n  creating build/lib/deepspeech/modules\r\n  copying deepspeech/modules/__init__.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/decoder.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/conformer_convolution.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/positionwise_feed_forward.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/cmvn.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/encoder_layer.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/subsampling.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/embedding.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/mask.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/loss.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/attention.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/activation.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/crf.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/decoder_layer.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/encoder.py -> build/lib/deepspeech/modules\r\n  copying deepspeech/modules/ctc.py -> build/lib/deepspeech/modules\r\n  creating build/lib/deepspeech/io\r\n  copying deepspeech/io/collator.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/__init__.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/utility.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/reader.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/dataloader.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/batchfy.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/sampler.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/dataset.py -> build/lib/deepspeech/io\r\n  copying deepspeech/io/converter.py -> build/lib/deepspeech/io\r\n  creating build/lib/deepspeech/exps\r\n  copying deepspeech/exps/__init__.py -> build/lib/deepspeech/exps\r\n  creating build/lib/deepspeech/decoders/ctcdecoder\r\n  copying deepspeech/decoders/ctcdecoder/__init__.py -> build/lib/deepspeech/decoders/ctcdecoder\r\n  copying deepspeech/decoders/ctcdecoder/decoders_deprecated.py -> build/lib/deepspeech/decoders/ctcdecoder\r\n  copying deepspeech/decoders/ctcdecoder/scorer_deprecated.py -> build/lib/deepspeech/decoders/ctcdecoder\r\n  copying deepspeech/decoders/ctcdecoder/swig_wrapper.py -> build/lib/deepspeech/decoders/ctcdecoder\r\n  creating build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/__init__.py -> build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/ctc_prefix_score.py -> build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/length_bonus.py -> build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/score_interface.py -> build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/ngram.py -> build/lib/deepspeech/decoders/scorers\r\n  copying deepspeech/decoders/scorers/ctc.py -> build/lib/deepspeech/decoders/scorers\r\n  creating build/lib/deepspeech/decoders/ctcdecoder/swig\r\n  copying deepspeech/decoders/ctcdecoder/swig/__init__.py -> build/lib/deepspeech/decoders/ctcdecoder/swig\r\n  copying deepspeech/decoders/ctcdecoder/swig/setup.py -> build/lib/deepspeech/decoders/ctcdecoder/swig\r\n  creating build/lib/deepspeech/frontend/featurizer\r\n  copying deepspeech/frontend/featurizer/__init__.py -> build/lib/deepspeech/frontend/featurizer\r\n  copying deepspeech/frontend/featurizer/text_featurizer.py -> build/lib/deepspeech/frontend/featurizer\r\n  copying deepspeech/frontend/featurizer/speech_featurizer.py -> build/lib/deepspeech/frontend/featurizer\r\n  copying deepspeech/frontend/featurizer/audio_featurizer.py -> build/lib/deepspeech/frontend/featurizer\r\n  creating build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/__init__.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/impulse_response.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/resample.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/speed_perturb.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/volume_perturb.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/augmentation.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/base.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/noise_perturb.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/spec_augment.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/online_bayesian_normalization.py -> build/lib/deepspeech/frontend/augmentor\r\n  copying deepspeech/frontend/augmentor/shift_perturb.py -> build/lib/deepspeech/frontend/augmentor\r\n  creating build/lib/deepspeech/models/ds2\r\n  copying deepspeech/models/ds2/__init__.py -> build/lib/deepspeech/models/ds2\r\n  copying deepspeech/models/ds2/conv.py -> build/lib/deepspeech/models/ds2\r\n  copying deepspeech/models/ds2/rnn.py -> build/lib/deepspeech/models/ds2\r\n  copying deepspeech/models/ds2/deepspeech2.py -> build/lib/deepspeech/models/ds2\r\n  creating build/lib/deepspeech/models/ds2_online\r\n  copying deepspeech/models/ds2_online/__init__.py -> build/lib/deepspeech/models/ds2_online\r\n  copying deepspeech/models/ds2_online/conv.py -> build/lib/deepspeech/models/ds2_online\r\n  copying deepspeech/models/ds2_online/deepspeech2.py -> build/lib/deepspeech/models/ds2_online\r\n  creating build/lib/deepspeech/models/u2\r\n  copying deepspeech/models/u2/__init__.py -> build/lib/deepspeech/models/u2\r\n  copying deepspeech/models/u2/u2.py -> build/lib/deepspeech/models/u2\r\n  copying deepspeech/models/u2/updater.py -> build/lib/deepspeech/models/u2\r\n  creating build/lib/deepspeech/training/triggers\r\n  copying deepspeech/training/triggers/__init__.py -> build/lib/deepspeech/training/triggers\r\n  copying deepspeech/training/triggers/interval_trigger.py -> build/lib/deepspeech/training/triggers\r\n  copying deepspeech/training/triggers/limit_trigger.py -> build/lib/deepspeech/training/triggers\r\n  copying deepspeech/training/triggers/time_trigger.py -> build/lib/deepspeech/training/triggers\r\n  creating build/lib/deepspeech/training/updaters\r\n  copying deepspeech/training/updaters/__init__.py -> build/lib/deepspeech/training/updaters\r\n  copying deepspeech/training/updaters/standard_updater.py -> build/lib/deepspeech/training/updaters\r\n  copying deepspeech/training/updaters/trainer.py -> build/lib/deepspeech/training/updaters\r\n  copying deepspeech/training/updaters/updater.py -> build/lib/deepspeech/training/updaters\r\n  creating build/lib/deepspeech/training/extensions\r\n  copying deepspeech/training/extensions/__init__.py -> build/lib/deepspeech/training/extensions\r\n  copying deepspeech/training/extensions/visualizer.py -> build/lib/deepspeech/training/extensions\r\n  copying deepspeech/training/extensions/snapshot.py -> build/lib/deepspeech/training/extensions\r\n  copying deepspeech/training/extensions/evaluator.py -> build/lib/deepspeech/training/extensions\r\n  copying deepspeech/training/extensions/extension.py -> build/lib/deepspeech/training/extensions\r\n  creating build/lib/deepspeech/exps/deepspeech2\r\n  copying deepspeech/exps/deepspeech2/__init__.py -> build/lib/deepspeech/exps/deepspeech2\r\n  copying deepspeech/exps/deepspeech2/model.py -> build/lib/deepspeech/exps/deepspeech2\r\n  copying deepspeech/exps/deepspeech2/config.py -> build/lib/deepspeech/exps/deepspeech2\r\n  creating build/lib/deepspeech/exps/u2_kaldi\r\n  copying deepspeech/exps/u2_kaldi/__init__.py -> build/lib/deepspeech/exps/u2_kaldi\r\n  copying deepspeech/exps/u2_kaldi/model.py -> build/lib/deepspeech/exps/u2_kaldi\r\n  creating build/lib/deepspeech/exps/u2_st\r\n  copying deepspeech/exps/u2_st/__init__.py -> build/lib/deepspeech/exps/u2_st\r\n  copying deepspeech/exps/u2_st/model.py -> build/lib/deepspeech/exps/u2_st\r\n  copying deepspeech/exps/u2_st/config.py -> build/lib/deepspeech/exps/u2_st\r\n  creating build/lib/deepspeech/exps/u2\r\n  copying deepspeech/exps/u2/__init__.py -> build/lib/deepspeech/exps/u2\r\n  copying deepspeech/exps/u2/trainer.py -> build/lib/deepspeech/exps/u2\r\n  copying deepspeech/exps/u2/model.py -> build/lib/deepspeech/exps/u2\r\n  copying deepspeech/exps/u2/config.py -> build/lib/deepspeech/exps/u2\r\n  installing to build/bdist.linux-x86_64/wheel\r\n  running install\r\n  running install_lib\r\n  creating build/bdist.linux-x86_64\r\n  creating build/bdist.linux-x86_64/wheel\r\n  creating build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/__init__.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/manifest_key_value.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/utility.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/zh_tn.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/compute_statistics.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/format_data.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/avg_model.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/json2trn.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/compute_mean_std.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/filter.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/gen_duration_from_textgrid.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/build_vocab.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/dump_manifest.py -> build/bdist.linux-x86_64/wheel/utils\r\n  copying build/lib/utils/format_triplet_data.py -> build/bdist.linux-x86_64/wheel/utils\r\n  creating build/bdist.linux-x86_64/wheel/parakeet\r\n  copying build/lib/parakeet/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/data\r\n  copying build/lib/parakeet/data/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/data\r\n  copying build/lib/parakeet/data/batch.py -> build/bdist.linux-x86_64/wheel/parakeet/data\r\n  copying build/lib/parakeet/data/get_feats.py -> build/bdist.linux-x86_64/wheel/parakeet/data\r\n  copying build/lib/parakeet/data/dataset.py -> build/bdist.linux-x86_64/wheel/parakeet/data\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/preprocess_utils.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/common.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/ljspeech.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/am_batch_fn.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/data_table.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  copying build/lib/parakeet/datasets/vocoder_batch_fn.py -> build/bdist.linux-x86_64/wheel/parakeet/datasets\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/vocab.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/num.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/char_convert.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/quantifier.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/constants.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/chronology.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/text_normlization.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/zh_normalization/phonecode.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/zh_normalization\r\n  copying build/lib/parakeet/frontend/pinyin.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/zh_frontend.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/generate_lexicon.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/tone_sandhi.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/width.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/acronyms.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/abbrrviation.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/numbers.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/normalizer/normalizer.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend/normalizer\r\n  copying build/lib/parakeet/frontend/phonectic.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/punctuation.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  copying build/lib/parakeet/frontend/arpabet.py -> build/bdist.linux-x86_64/wheel/parakeet/frontend\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/display.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/profiler.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/timeline.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/profile.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/error_rate.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/layer_tools.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/internals.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/scheduler.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/mp_tools.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/checkpoint.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  copying build/lib/parakeet/utils/h5_utils.py -> build/bdist.linux-x86_64/wheel/parakeet/utils\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/models\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/models/parallel_wavegan\r\n  copying build/lib/parakeet/models/parallel_wavegan/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/models/parallel_wavegan\r\n  copying build/lib/parakeet/models/parallel_wavegan/parallel_wavegan_updater.py -> build/bdist.linux-x86_64/wheel/parakeet/models/parallel_wavegan\r\n  copying build/lib/parakeet/models/parallel_wavegan/parallel_wavegan.py -> build/bdist.linux-x86_64/wheel/parakeet/models/parallel_wavegan\r\n  copying build/lib/parakeet/models/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/models\r\n  copying build/lib/parakeet/models/waveflow.py -> build/bdist.linux-x86_64/wheel/parakeet/models\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/models/transformer_tts\r\n  copying build/lib/parakeet/models/transformer_tts/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/models/transformer_tts\r\n  copying build/lib/parakeet/models/transformer_tts/transformer_tts_updater.py -> build/bdist.linux-x86_64/wheel/parakeet/models/transformer_tts\r\n  copying build/lib/parakeet/models/transformer_tts/transformer_tts.py -> build/bdist.linux-x86_64/wheel/parakeet/models/transformer_tts\r\n  copying build/lib/parakeet/models/lstm_speaker_encoder.py -> build/bdist.linux-x86_64/wheel/parakeet/models\r\n  copying build/lib/parakeet/models/tacotron2.py -> build/bdist.linux-x86_64/wheel/parakeet/models\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/models/fastspeech2\r\n  copying build/lib/parakeet/models/fastspeech2/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/models/fastspeech2\r\n  copying build/lib/parakeet/models/fastspeech2/fastspeech2_updater.py -> build/bdist.linux-x86_64/wheel/parakeet/models/fastspeech2\r\n  copying build/lib/parakeet/models/fastspeech2/fastspeech2.py -> build/bdist.linux-x86_64/wheel/parakeet/models/fastspeech2\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/models/speedyspeech\r\n  copying build/lib/parakeet/models/speedyspeech/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/models/speedyspeech\r\n  copying build/lib/parakeet/models/speedyspeech/speedyspeech.py -> build/bdist.linux-x86_64/wheel/parakeet/models/speedyspeech\r\n  copying build/lib/parakeet/models/speedyspeech/speedyspeech_updater.py -> build/bdist.linux-x86_64/wheel/parakeet/models/speedyspeech\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/trigger.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/optimizer.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/default_config.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/experiment.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/trainer.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/cli.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/reporter.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/training/triggers\r\n  copying build/lib/parakeet/training/triggers/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/training/triggers\r\n  copying build/lib/parakeet/training/triggers/interval_trigger.py -> build/bdist.linux-x86_64/wheel/parakeet/training/triggers\r\n  copying build/lib/parakeet/training/triggers/limit_trigger.py -> build/bdist.linux-x86_64/wheel/parakeet/training/triggers\r\n  copying build/lib/parakeet/training/triggers/time_trigger.py -> build/bdist.linux-x86_64/wheel/parakeet/training/triggers\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/training/updaters\r\n  copying build/lib/parakeet/training/updaters/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/training/updaters\r\n  copying build/lib/parakeet/training/updaters/standard_updater.py -> build/bdist.linux-x86_64/wheel/parakeet/training/updaters\r\n  copying build/lib/parakeet/training/seeding.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  copying build/lib/parakeet/training/updater.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/training/extensions\r\n  copying build/lib/parakeet/training/extensions/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/training/extensions\r\n  copying build/lib/parakeet/training/extensions/visualizer.py -> build/bdist.linux-x86_64/wheel/parakeet/training/extensions\r\n  copying build/lib/parakeet/training/extensions/snapshot.py -> build/bdist.linux-x86_64/wheel/parakeet/training/extensions\r\n  copying build/lib/parakeet/training/extensions/evaluator.py -> build/bdist.linux-x86_64/wheel/parakeet/training/extensions\r\n  copying build/lib/parakeet/training/extension.py -> build/bdist.linux-x86_64/wheel/parakeet/training\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/expansion.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/decoder.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/repeat.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/multi_layer_conv.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/positionwise_feed_forward.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/encoder_layer.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/embedding.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/mask.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/lightconv.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/attention.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/decoder_layer.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/fastspeech2_transformer/encoder.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_transformer\r\n  copying build/lib/parakeet/modules/conv.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/losses.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/positional_encoding.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/layer_norm.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/masking.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/nets_utils.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/modules/tacotron2\r\n  copying build/lib/parakeet/modules/tacotron2/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/tacotron2\r\n  copying build/lib/parakeet/modules/tacotron2/decoder.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/tacotron2\r\n  copying build/lib/parakeet/modules/tacotron2/encoder.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/tacotron2\r\n  copying build/lib/parakeet/modules/geometry.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/transformer.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/glu.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/style_encoder.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/stft_loss.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/masked_fill.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/attention.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_predictor\r\n  copying build/lib/parakeet/modules/fastspeech2_predictor/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_predictor\r\n  copying build/lib/parakeet/modules/fastspeech2_predictor/variance_predictor.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_predictor\r\n  copying build/lib/parakeet/modules/fastspeech2_predictor/duration_predictor.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_predictor\r\n  copying build/lib/parakeet/modules/fastspeech2_predictor/length_regulator.py -> build/bdist.linux-x86_64/wheel/parakeet/modules/fastspeech2_predictor\r\n  copying build/lib/parakeet/modules/audio.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/ssim.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  copying build/lib/parakeet/modules/normalizer.py -> build/bdist.linux-x86_64/wheel/parakeet/modules\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/audio\r\n  copying build/lib/parakeet/audio/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/audio\r\n  copying build/lib/parakeet/audio/spec_normalizer.py -> build/bdist.linux-x86_64/wheel/parakeet/audio\r\n  copying build/lib/parakeet/audio/audio.py -> build/bdist.linux-x86_64/wheel/parakeet/audio\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/exps\r\n  copying build/lib/parakeet/exps/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/exps\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/exps/fastspeech2\r\n  copying build/lib/parakeet/exps/fastspeech2/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/exps/fastspeech2\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/exps/gan_vocoder\r\n  copying build/lib/parakeet/exps/gan_vocoder/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/exps/gan_vocoder\r\n  creating build/bdist.linux-x86_64/wheel/parakeet/exps/gan_vocoder/pwgan\r\n  copying build/lib/parakeet/exps/gan_vocoder/pwgan/__init__.py -> build/bdist.linux-x86_64/wheel/parakeet/exps/gan_vocoder/pwgan\r\n  creating build/bdist.linux-x86_64/wheel/third_party\r\n  copying build/lib/third_party/__init__.py -> build/bdist.linux-x86_64/wheel/third_party\r\n  creating build/bdist.linux-x86_64/wheel/third_party/paddle_audio\r\n  copying build/lib/third_party/paddle_audio/__init__.py -> build/bdist.linux-x86_64/wheel/third_party/paddle_audio\r\n  creating build/bdist.linux-x86_64/wheel/third_party/text_processing\r\n  creating build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/num.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/phone.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/char_convert.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/quantifier.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/constants.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/chronology.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/normalization/sentence_split.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing/normalization\r\n  copying build/lib/third_party/text_processing/__init__.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing\r\n  copying build/lib/third_party/text_processing/__ini__.py -> build/bdist.linux-x86_64/wheel/third_party/text_processing\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/decoders\r\n  copying build/lib/deepspeech/decoders/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/decoders_deprecated.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder/swig\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/swig/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder/swig\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/swig/setup.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder/swig\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/scorer_deprecated.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder\r\n  copying build/lib/deepspeech/decoders/ctcdecoder/swig_wrapper.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/ctcdecoder\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/ctc_prefix_score.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/length_bonus.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/score_interface.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/ngram.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/scorers/ctc.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders/scorers\r\n  copying build/lib/deepspeech/decoders/beam_search.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders\r\n  copying build/lib/deepspeech/decoders/utils.py -> build/bdist.linux-x86_64/wheel/deepspeech/decoders\r\n  copying build/lib/deepspeech/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  copying build/lib/deepspeech/frontend/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  copying build/lib/deepspeech/frontend/utility.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/frontend/featurizer\r\n  copying build/lib/deepspeech/frontend/featurizer/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/featurizer\r\n  copying build/lib/deepspeech/frontend/featurizer/text_featurizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/featurizer\r\n  copying build/lib/deepspeech/frontend/featurizer/speech_featurizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/featurizer\r\n  copying build/lib/deepspeech/frontend/featurizer/audio_featurizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/featurizer\r\n  copying build/lib/deepspeech/frontend/speech.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/impulse_response.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/resample.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/speed_perturb.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/volume_perturb.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/augmentation.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/base.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/noise_perturb.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/spec_augment.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/online_bayesian_normalization.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/augmentor/shift_perturb.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend/augmentor\r\n  copying build/lib/deepspeech/frontend/audio.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  copying build/lib/deepspeech/frontend/normalizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/frontend\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/profiler.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/socket_server.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/utility.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/error_rate.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/tensor_utils.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/dynamic_import.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/layer_tools.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/text_grid.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/log.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/mp_tools.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/checkpoint.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/bleu_score.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  copying build/lib/deepspeech/utils/ctc_utils.py -> build/bdist.linux-x86_64/wheel/deepspeech/utils\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/models\r\n  copying build/lib/deepspeech/models/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/models\r\n  copying build/lib/deepspeech/models/u2_st.py -> build/bdist.linux-x86_64/wheel/deepspeech/models\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/models/ds2\r\n  copying build/lib/deepspeech/models/ds2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2\r\n  copying build/lib/deepspeech/models/ds2/conv.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2\r\n  copying build/lib/deepspeech/models/ds2/rnn.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2\r\n  copying build/lib/deepspeech/models/ds2/deepspeech2.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/models/ds2_online\r\n  copying build/lib/deepspeech/models/ds2_online/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2_online\r\n  copying build/lib/deepspeech/models/ds2_online/conv.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2_online\r\n  copying build/lib/deepspeech/models/ds2_online/deepspeech2.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/ds2_online\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/models/u2\r\n  copying build/lib/deepspeech/models/u2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/u2\r\n  copying build/lib/deepspeech/models/u2/u2.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/u2\r\n  copying build/lib/deepspeech/models/u2/updater.py -> build/bdist.linux-x86_64/wheel/deepspeech/models/u2\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/gradclip.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/timer.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/trainer.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/cli.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  copying build/lib/deepspeech/training/reporter.py -> build/bdist.linux-x86_64/wheel/deepspeech/training\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/training/triggers\r\n  copying build/lib/deepspeech/training/triggers/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/triggers\r\n  copying build/lib/deepspeech/training/triggers/interval_trigger.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/triggers\r\n  copying build/lib/deepspeech/training/triggers/limit_trigger.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/triggers\r\n  copying build/lib/deepspeech/training/triggers/time_trigger.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/triggers\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/training/updaters\r\n  copying build/lib/deepspeech/training/updaters/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/updaters\r\n  copying build/lib/deepspeech/training/updaters/standard_updater.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/updaters\r\n  copying build/lib/deepspeech/training/updaters/trainer.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/updaters\r\n  copying build/lib/deepspeech/training/updaters/updater.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/updaters\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  copying build/lib/deepspeech/training/extensions/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  copying build/lib/deepspeech/training/extensions/visualizer.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  copying build/lib/deepspeech/training/extensions/snapshot.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  copying build/lib/deepspeech/training/extensions/evaluator.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  copying build/lib/deepspeech/training/extensions/extension.py -> build/bdist.linux-x86_64/wheel/deepspeech/training/extensions\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/decoder.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/conformer_convolution.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/positionwise_feed_forward.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/cmvn.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/encoder_layer.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/subsampling.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/embedding.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/mask.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/loss.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/attention.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/activation.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/crf.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/decoder_layer.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/encoder.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  copying build/lib/deepspeech/modules/ctc.py -> build/bdist.linux-x86_64/wheel/deepspeech/modules\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/collator.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/utility.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/reader.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/dataloader.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/batchfy.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/sampler.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/dataset.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  copying build/lib/deepspeech/io/converter.py -> build/bdist.linux-x86_64/wheel/deepspeech/io\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/exps\r\n  copying build/lib/deepspeech/exps/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/exps/deepspeech2\r\n  copying build/lib/deepspeech/exps/deepspeech2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/deepspeech2\r\n  copying build/lib/deepspeech/exps/deepspeech2/model.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/deepspeech2\r\n  copying build/lib/deepspeech/exps/deepspeech2/config.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/deepspeech2\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_kaldi\r\n  copying build/lib/deepspeech/exps/u2_kaldi/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_kaldi\r\n  copying build/lib/deepspeech/exps/u2_kaldi/model.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_kaldi\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_st\r\n  copying build/lib/deepspeech/exps/u2_st/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_st\r\n  copying build/lib/deepspeech/exps/u2_st/model.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_st\r\n  copying build/lib/deepspeech/exps/u2_st/config.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2_st\r\n  creating build/bdist.linux-x86_64/wheel/deepspeech/exps/u2\r\n  copying build/lib/deepspeech/exps/u2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2\r\n  copying build/lib/deepspeech/exps/u2/trainer.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2\r\n  copying build/lib/deepspeech/exps/u2/model.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2\r\n  copying build/lib/deepspeech/exps/u2/config.py -> build/bdist.linux-x86_64/wheel/deepspeech/exps/u2\r\n  running install_egg_info\r\n  running egg_info\r\n  creating paddle_speech.egg-info\r\n  writing paddle_speech.egg-info/PKG-INFO\r\n  writing dependency_links to paddle_speech.egg-info/dependency_links.txt\r\n  writing requirements to paddle_speech.egg-info/requires.txt\r\n  writing top-level names to paddle_speech.egg-info/top_level.txt\r\n  writing manifest file 'paddle_speech.egg-info/SOURCES.txt'\r\n  reading manifest file 'paddle_speech.egg-info/SOURCES.txt'\r\n  adding license file 'LICENSE'\r\n  writing manifest file 'paddle_speech.egg-info/SOURCES.txt'\r\n  Copying paddle_speech.egg-info to build/bdist.linux-x86_64/wheel/paddle_speech-2.1.2-py3.7.egg-info\r\n  running install_scripts\r\n  Post Install...\r\n  Get:1 file:/var/cuda-repo-10-1-local-10.1.105-418.39  InRelease\r\n  Ign:1 file:/var/cuda-repo-10-1-local-10.1.105-418.39  InRelease\r\n  Get:2 file:/var/cuda-repo-9-0-local  InRelease\r\n  Ign:2 file:/var/cuda-repo-9-0-local  InRelease\r\n  Get:3 file:/var/nccl-repo-2.7.6-ga-cuda10.2  InRelease\r\n  Ign:3 file:/var/nccl-repo-2.7.6-ga-cuda10.2  InRelease\r\n  Get:4 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n  Ign:4 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n  Get:5 file:/var/cuda-repo-10-1-local-10.1.105-418.39  Release [574 B]\r\n  Get:6 file:/var/cuda-repo-9-0-local  Release [574 B]\r\n  Get:7 file:/var/nccl-repo-2.7.6-ga-cuda10.2  Release [574 B]\r\n  Get:8 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n  Get:5 file:/var/cuda-repo-10-1-local-10.1.105-418.39  Release [574 B]\r\n  Get:6 file:/var/cuda-repo-9-0-local  Release [574 B]\r\n  Get:7 file:/var/nccl-repo-2.7.6-ga-cuda10.2  Release [574 B]\r\n  Get:8 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n  Get:13 https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial InRelease [66.2 kB]\r\n  Hit:14 https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64  InRelease\r\n  Hit:15 https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64  InRelease\r\n  Hit:16 https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64  InRelease\r\n  Get:17 http://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial InRelease [247 kB]\r\n  Hit:18 http://linux.teamviewer.com/deb stable InRelease\r\n  Hit:19 http://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-updates InRelease\r\n  Hit:20 http://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-backports InRelease\r\n  Hit:21 http://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-security InRelease\r\n  Ign:22 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial InRelease\r\n  Hit:23 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease\r\n  Ign:24 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial Release\r\n  Ign:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Ign:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Ign:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Ign:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Ign:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Err:25 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 Packages\r\n    404  Not Found [IP: 91.189.95.85 80]\r\n  Ign:26 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main i386 Packages\r\n  Ign:27 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main all Packages\r\n  Ign:28 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en_US\r\n  Ign:29 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main Translation-en\r\n  Ign:30 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main amd64 DEP-11 Metadata\r\n  Ign:31 http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial/main DEP-11 64x64 Icons\r\n  Fetched 313 kB in 49s (6,276 B/s)\r\n  Reading package lists...\r\n  W: The repository 'http://ppa.launchpad.net/fcitx-team/nightly/ubuntu xenial Release' does not have a Release file.\r\n  E: Failed to fetch http://ppa.launchpad.net/fcitx-team/nightly/ubuntu/dists/xenial/main/binary-amd64/Packages  404  Not Found [IP: 91.189.95.85 80]\r\n  E: Some index files failed to download. They have been ignored, or old ones used instead.\r\n  /tmp/pip-req-build-abywj844/setup.py:55: CMD: apt-get update -y, Error: None\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/tmp/pip-req-build-abywj844/setup.py\", line 195, in <module>\r\n      setup(**setup_info)\r\n    File \"/home/data/zhijiangbei/yinping/DeepSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\r\n      return distutils.core.setup(**attrs)\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/core.py\", line 148, in setup\r\n      dist.run_commands()\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n      self.run_command(cmd)\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/home/data/zhijiangbei/yinping/DeepSpeech/tools/venv/lib/python3.7/site-packages/wheel/bdist_wheel.py\", line 335, in run\r\n      self.run_command('install')\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n      self.distribution.run_command(command)\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n      cmd_obj.run()\r\n    File \"/tmp/pip-req-build-abywj844/setup.py\", line 112, in run\r\n      self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/cmd.py\", line 335, in execute\r\n      util.execute(func, args, msg, dry_run=self.dry_run)\r\n    File \"/home/msi/anaconda3/lib/python3.7/distutils/util.py\", line 291, in execute\r\n      func(*args)\r\n    File \"/tmp/pip-req-build-abywj844/setup.py\", line 68, in _post_install\r\n      check_call(\"apt-get update -y\")\r\n    File \"/tmp/pip-req-build-abywj844/setup.py\", line 58, in check_call\r\n      raise e\r\n    File \"/tmp/pip-req-build-abywj844/setup.py\", line 52, in check_call\r\n      executable=\"/bin/bash\" if shell else executable)\r\n    File \"/home/msi/anaconda3/lib/python3.7/subprocess.py\", line 363, in check_call\r\n      raise CalledProcessError(retcode, cmd)\r\n  subprocess.CalledProcessError: Command '['apt-get', 'update', '-y']' returned non-zero exit status 100.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for paddle-speech\r\n  Running setup.py clean for paddle-speech\r\nFailed to build paddle-speech\r\nInstalling collected packages: paddle-speech\r\n  Attempting uninstall: paddle-speech\r\n    Found existing installation: paddle-speech 2.1.2\r\n    Uninstalling paddle-speech-2.1.2:\r\n      Successfully uninstalled paddle-speech-2.1.2\r\n    Running setup.py install for paddle-speech ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /home/data/zhijiangbei/yinping/DeepSpeech/tool",
        "state": "closed",
        "user": "ChasingStar95",
        "closed_by": "stale[bot]",
        "created_at": "2021-10-22T18:12:35+00:00",
        "updated_at": "2022-01-09T04:20:39+00:00",
        "closed_at": "2022-01-09T04:20:39+00:00",
        "comments_count": [
            "zh794390558",
            "ChasingStar95",
            "zh794390558",
            "ChasingStar95",
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 994,
        "title": "ERROR: Could not find a version that satisfies the requirement ConfigArgParse",
        "body": "安装PaddleSpeech时出现如下错误：\r\n命令：pip install -e .\r\n错误：\r\n![image](https://user-images.githubusercontent.com/14884056/141717082-b0f272fd-3435-4b64-829d-6bb21264f6f5.png)\r\n\r\n请问如何解决，谢谢～",
        "state": "closed",
        "user": "XYZ-916",
        "closed_by": "yt605155624",
        "created_at": "2021-11-15T03:19:52+00:00",
        "updated_at": "2021-12-17T10:20:44+00:00",
        "closed_at": "2021-12-17T10:20:44+00:00",
        "comments_count": [
            "yt605155624",
            "XYZ-916"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 979,
        "title": "多语言支持",
        "body": "我找来找去，都是只支持中文或者英文（不同语言会报错），就想问问能不能同时支持中英日三语的输出？（个人用Tacotron2",
        "state": "closed",
        "user": "RedElectricity",
        "closed_by": "stale[bot]",
        "created_at": "2021-11-08T14:50:34+00:00",
        "updated_at": "2022-08-08T03:13:26+00:00",
        "closed_at": "2022-01-23T12:29:30+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]",
            "dzcmingdi"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 991,
        "title": "请问你们这个支持在3090上运行吗",
        "body": "请问你们这个支持在3090上运行吗？我的系统是centos，显卡为3090，cuda为11.1，python为3.8\r\n\r\n我按照readme的指令运行后报错。\r\n指令为 FLAGS_allocator_strategy=naive_best_fit FLAGS_fraction_of_gpu_memory_to_use=0.01 python3 ${BIN_DIR}/synthesize_e2e.py   --fastspeech2-config=fastspeech2_nosil_baker_ckpt_0.4/default.yaml   --fastspeech2-checkpoint=fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz   --fastspeech2-stat=fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy   --pwg-config=pwg_baker_ckpt_0.4/pwg_default.yaml   --pwg-checkpoint=pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz   --pwg-stat=pwg_baker_ckpt_0.4/pwg_stats.npy   --text=${BIN_DIR}/../sentences.txt   --output-dir=exp/default/test_e2e   --inference-dir=exp/default/inference   --phones-dict=fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\r\n应该和readme上的一致\r\n\r\n报错信息：\r\nTraceback (most recent call last):\r\n  File \"/usr/local/notebook_dir/图像/TTS/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/synthesize_e2e.py\", line 185, in <module>\r\n    main()\r\n  File \"/usr/local/notebook_dir/图像/TTS/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/synthesize_e2e.py\", line 181, in main\r\n    evaluate(args, fastspeech2_config, pwg_config)\r\n  File \"/usr/local/notebook_dir/图像/TTS/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/synthesize_e2e.py\", line 51, in evaluate\r\n    model = FastSpeech2(\r\n  File \"/usr/local/notebook_dir/图像/TTS/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 166, in __init__\r\n    encoder_input_layer = nn.Embedding(\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/nn/layer/common.py\", line 1386, in __init__\r\n    self.weight = self.create_parameter(\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 423, in create_parameter\r\n    return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/layer_helper_base.py\", line 373, in create_parameter\r\n    return self.main_program.global_block().create_parameter(\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3137, in create_parameter\r\n    initializer(param, self)\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/initializer.py\", line 561, in __call__\r\n    op = block.append_op(\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3163, in append_op\r\n    _dygraph_tracer().trace_op(type,\r\n  File \"/root/.jupyter/Paddlepaddle-2.0.0/lib/python3.8/site-packages/paddle/fluid/dygraph/tracer.py\", line 43, in trace_op\r\n    self.trace(type, inputs, outputs, attrs,\r\nSystemError: (Fatal) Operator uniform_random raises an thrust::system::system_error exception.\r\nThe exception content is\r\n:parallel_for failed: cudaErrorNoKernelImageForDevice: no kernel image is available for execution on the device. (at /paddle/paddle/fluid/imperative/tracer.cc:221)\r\n\r\n\r\npaddle-gpu安装是没有问题的，运行fluid.install_check.run_check()显示成功\r\n\r\n请问上面的报错是什么原因呢？\r\n",
        "state": "closed",
        "user": "ZZHHogan",
        "closed_by": "stale[bot]",
        "created_at": "2021-11-11T09:30:10+00:00",
        "updated_at": "2022-03-12T17:41:24+00:00",
        "closed_at": "2022-03-12T17:41:24+00:00",
        "comments_count": [
            "yt605155624",
            "ZZHHogan",
            "yt605155624",
            "xxllp",
            "yt605155624",
            "BoragoCode",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 996,
        "title": "建议将nltk_data下载到百度自己的服务器上",
        "body": "在aistudio上运行Text-To-Speech FastSpeech2 + Parallel WaveGAN on CSMSC 下载nltk_data很慢\r\n希望能下载到百度自己的服务器，然后通过一个download脚本加速下载过程",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-15T09:32:19+00:00",
        "updated_at": "2021-11-15T09:52:21+00:00",
        "closed_at": "2021-11-15T09:52:21+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1028
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1029
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 999,
        "title": "Chinese Rule Based Text Frontend的例子develop版中似乎没了？",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/tts/zh_text_frontend.md\r\n这个页面中描述的\r\n\r\n现在有将以下这一套做完的吗？\r\nText Segmentation\r\nText Normalization (TN)\r\nWord Segmentation (mainly in Chinese)\r\nPart-of-Speech\r\nProsody\r\nG2P (Grapheme-to-Phoneme, include Polyphone and Tone Sandhi, etc.)\r\nLinguistic Features/Charactors/Phonemes",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-16T03:55:58+00:00",
        "updated_at": "2021-11-16T06:38:10+00:00",
        "closed_at": "2021-11-16T06:38:10+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1000,
        "title": "len('……')得到的结果为2，zh_frontend.py在函数_merge_erhua中会assert False",
        "body": "print('finals', len(finals), finals)\r\nprint('word', len(word), word)\r\nassert len(finals) == len(word)\r\n\r\n打印得到的结果如下\r\nfinals 1 ['……']\r\nword 2 ……\r\n这算是bug还是要将这种符号提前处理一下？\r\n\r\n",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "yt605155624",
        "created_at": "2021-11-16T08:34:38+00:00",
        "updated_at": "2021-11-29T05:36:47+00:00",
        "closed_at": "2021-11-29T05:36:47+00:00",
        "comments_count": [
            "zouhan6806504",
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1004,
        "title": "ValueError: The requested field (wave) is not foundin the data. Fields in the data is dict_keys(['utt_id', 'spk_id', 'text', 'text_lengths', 'speech_lengths', 'durations', 'speech', 'pitch', 'energy']) ",
        "body": "训练voc1模型的时候出现了该错误，请问如何解决？\r\n![图片](https://user-images.githubusercontent.com/14884056/141971467-551edaaa-f38e-46dd-af6a-e85289dd3b39.png)\r\n",
        "state": "closed",
        "user": "XYZ-916",
        "closed_by": "yt605155624",
        "created_at": "2021-11-16T10:46:54+00:00",
        "updated_at": "2021-11-29T12:12:59+00:00",
        "closed_at": "2021-11-29T12:12:59+00:00",
        "comments_count": [
            "yt605155624",
            "XYZ-916",
            "XYZ-916",
            "yt605155624",
            "yt605155624",
            "XYZ-916",
            "XYZ-916",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1043
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1001,
        "title": "在运行Text-To-Speech  FastSpeech2 + Parallel WaveGAN on CSMSC，如果想改变最终音频的码率，目前有设置的地方吗？",
        "body": "或者生成后再找工具转码一次？",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-11-16T09:42:50+00:00",
        "updated_at": "2021-11-16T12:04:41+00:00",
        "closed_at": "2021-11-16T09:48:56+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "zouhan6806504"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1008,
        "title": "[music]旋律支持",
        "body": "普通的tts输出只有一个调，但是我想让输出可以输出多个调(简单来说就是虚拟歌姬引擎)，请问有什么解决方案？(btw，有无相关的dataset？\n\n目前行业有实现的例子[Synthesizer V](https://dreamtonics.com/en/synthesizerv/)，他只需用少量的人声样本就能制作清晰的音源，目前我知道paddlehub上有个声音克隆的例子，但是无法解决旋律",
        "state": "closed",
        "user": "RedElectricity",
        "closed_by": "yt605155624",
        "created_at": "2021-11-19T02:22:42+00:00",
        "updated_at": "2022-04-22T09:40:55+00:00",
        "closed_at": "2022-04-22T09:40:55+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1017,
        "title": "Inference for Chinese ASR(Speech to Text)",
        "body": "Hi, Thanks for this amazing project. Can we download/use any pretrained model to perform Chinese ASR(Speech to Text)?\r\n\r\nAnd if can do it, what are the steps?",
        "state": "closed",
        "user": "Aksh97",
        "closed_by": "stale[bot]",
        "created_at": "2021-11-23T03:19:19+00:00",
        "updated_at": "2022-02-12T17:54:08+00:00",
        "closed_at": "2022-02-12T17:54:08+00:00",
        "comments_count": [
            "zh794390558",
            "jerryuhoo",
            "yt605155624",
            "zh794390558",
            "yfq512",
            "jerryuhoo",
            "jerryuhoo",
            "jerryuhoo",
            "Jackwaterveg",
            "jerryuhoo",
            "Jackwaterveg",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1044
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1072
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1100
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1073
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1102
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1110
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1047,
        "title": "speec to text可以提供python的部署方法么？",
        "body": "文档看的一头雾水，shell脚本看不懂呀😂",
        "state": "closed",
        "user": "yfq512",
        "closed_by": "stale[bot]",
        "created_at": "2021-11-29T10:03:30+00:00",
        "updated_at": "2022-02-25T03:55:06+00:00",
        "closed_at": "2022-02-25T03:55:06+00:00",
        "comments_count": [
            "yfq512",
            "zh794390558",
            "weizequan",
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1057,
        "title": "Output of librispeech manifest format do not match with the required format in paddlespeech/s2t/frontend/utility.py",
        "body": "In paddlespeech/s2t/frontend/utility.py, input field and token len field are required to handle with the manifest.tiny.raw, while these two fields are not contained in the output manifest file of libripeech.py .\r\n\r\nThe output format of librispeech:\r\njson_lines.append(\r\n                    json.dumps({\r\n                        'utt': utt,\r\n                        'utt2spk': utt2spk,\r\n                        'feat': audio_filepath,\r\n                        'feat_shape': (duration, ),  # second\r\n                        'text': text,\r\n                    }))\r\nThe requied formt in paddlespeech/s2t/frontend/utility.py:\r\n\r\n        for json_data in reader:\r\n            feat_len = json_data[\"input\"][0][\"shape\"][\r\n                0] if 'shape' in json_data[\"input\"][0] else 1.0\r\n            token_len = json_data[\"output\"][0][\"shape\"][\r\n                0] if 'shape' in json_data[\"output\"][0] else 1.0\r\n            conditions = [\r\n                feat_len >= min_input_len,\r\n                feat_len <= max_input_len,\r\n                token_len >= min_output_len,\r\n                token_len <= max_output_len,\r\n                token_len / feat_len >= min_output_input_ratio,\r\n                token_len / feat_len <= max_output_input_ratio,\r\n            ]\r\n\r\n\r\n",
        "state": "closed",
        "user": "josh-zhu",
        "closed_by": "josh-zhu",
        "created_at": "2021-11-30T10:58:16+00:00",
        "updated_at": "2021-12-01T06:05:01+00:00",
        "closed_at": "2021-12-01T06:05:00+00:00",
        "comments_count": [
            "zh794390558",
            "josh-zhu",
            "zh794390558",
            "josh-zhu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1066,
        "title": "g2p目前有语料库吗？",
        "body": "搜了一下网上，似乎都只是单个字的多音列举，语句下的 polyphone 和tone sandhi没有相关数据",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2021-12-02T02:20:26+00:00",
        "updated_at": "2021-12-28T05:41:04+00:00",
        "closed_at": "2021-12-02T02:39:43+00:00",
        "comments_count": [
            "yt605155624",
            "madosma",
            "yt605155624",
            "madosma"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1133
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1170
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1124,
        "title": "when using paddlespeech asr/tts/st , a exp/log dir will be generated",
        "body": "Need to be fixed\r\n\r\nThis is caused by Loger in `paddlespeech.s2t.__init__`\r\n\r\nactually, when you  `import paddlespeech.s2t.*` will meet this issue.\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2021-12-14T13:29:57+00:00",
        "updated_at": "2021-12-24T13:17:09+00:00",
        "closed_at": "2021-12-24T13:17:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1111,
        "title": "建议：将数据集路径放到conf/中的设置文件里",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/9db1710ba78c18185e5180f366ff8e5e3d70b5e2/examples/csmsc/tts3/local/preprocess.sh#L12\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/9db1710ba78c18185e5180f366ff8e5e3d70b5e2/examples/csmsc/tts3/local/preprocess.sh#L22\r\n\r\n以标贝tts3为例，是否能把这些路径放到设置文件里，或者作为某个可以指定的参数呢？这样可以更灵活的指定数据集路径。\r\n",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-13T13:54:41+00:00",
        "updated_at": "2022-03-06T03:39:07+00:00",
        "closed_at": "2022-03-06T03:39:07+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "jerryuhoo",
            "zh794390558",
            "jerryuhoo",
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1125,
        "title": "about the final 'io'",
        "body": "**Describe the bug**\r\ni have check that there is 39 finals in paddlespeech symbols, but i found a unknown 'io' final, i want to know which pinyin can generate this final??\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/f6ca14c5fadac76833b4d1b020f39cbb0eceb825/paddlespeech/t2s/frontend/generate_lexicon.py#L29-L34\r\n",
        "state": "closed",
        "user": "azraelkuan",
        "closed_by": "azraelkuan",
        "created_at": "2021-12-15T02:22:40+00:00",
        "updated_at": "2021-12-15T07:14:50+00:00",
        "closed_at": "2021-12-15T07:14:50+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "azraelkuan",
            "yt605155624",
            "azraelkuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1143,
        "title": "Lack shell scripts in wenetspeech examples",
        "body": "There's no `train.sh`、 `avg.sh`、`align.sh`、`export.sh`、`test_hub.sh` in `examples/wenetspeech/asr1/run.sh`. My branch is `developer`.\r\n\r\n```bash\r\n# examples/wenetspeech/asr1/run.sh\r\nif [ ${stage} -le 1 ] && [ ${stop_stage} -ge 1 ]; then\r\n    # train model, all `ckpt` under `exp` dir\r\n    CUDA_VISIBLE_DEVICES=${gpus} ./local/train.sh ${conf_path}  ${ckpt}\r\nfi\r\n```",
        "state": "closed",
        "user": "aizls",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-16T06:55:26+00:00",
        "updated_at": "2022-03-06T03:39:06+00:00",
        "closed_at": "2022-03-06T03:39:06+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1151,
        "title": "升级praatio到5.0",
        "body": "由于Montreal-Forced-Aligner 2.0用的是praatio==5.0，是否可以考虑把paddlespeech中的praatio升级到5.0呢？这样在同时安装两个包的时候不会冲突。\r\n需要修改的部分是把import tigo替换为textgrid。\r\n例如在gen_duration_from_textgrid.py中：\r\n```python\r\nfrom praatio import textgrid\r\n...\r\nalignment = textgrid.openTextgrid(tg_path, includeEmptyIntervals=True)\r\n```",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "zh794390558",
        "created_at": "2021-12-16T12:40:29+00:00",
        "updated_at": "2021-12-17T08:13:19+00:00",
        "closed_at": "2021-12-17T08:13:19+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1188
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1177,
        "title": "wenetspeech 模型识别同样一个test.wav，paddlespeech 要比pytorch 慢4倍",
        "body": "conformer 模型中包含 conv1d, paddle conv1d 速度慢是已知问题\r\n![image](https://user-images.githubusercontent.com/24568452/146900542-917d3157-2527-4ffe-9d8d-62f20350379a.png)\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-21T08:54:23+00:00",
        "updated_at": "2022-03-20T16:41:14+00:00",
        "closed_at": "2022-03-20T16:41:14+00:00",
        "comments_count": [
            "Jackwaterveg",
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "enhancement",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1194
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1180,
        "title": "ASR run run.sh   error  ",
        "body": "SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception\r\n [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n",
        "state": "closed",
        "user": "silencervan",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-21T10:30:20+00:00",
        "updated_at": "2022-03-12T17:41:25+00:00",
        "closed_at": "2022-03-12T17:41:25+00:00",
        "comments_count": [
            "silencervan",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1195
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1182,
        "title": "Mac：assert offset + x.shape[1] < self.max_len",
        "body": "Mac 12.1系统，使用python调用api进行识别的时候，会报AssertionError，不知道怎么解决\r\n\r\n![image](https://user-images.githubusercontent.com/40975871/146924298-4eb4b32d-bb49-4c54-b6fb-b60995f08b7b.png)\r\n\r\n",
        "state": "closed",
        "user": "ReBenDish",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-21T11:40:08+00:00",
        "updated_at": "2022-03-12T17:41:26+00:00",
        "closed_at": "2022-03-12T17:41:26+00:00",
        "comments_count": [
            "zh794390558",
            "ReBenDish",
            "zh794390558",
            "ReBenDish",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1186,
        "title": "StyleFastSpeech2Inference doesn't support multiple speakers",
        "body": "fastspeech2.py中的StyleFastSpeech2Inference目前只支持单人数据集的变速变调（标贝），是否考虑加入spk_id，以及加一个aishell3的inference的例子呢？",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "yt605155624",
        "created_at": "2021-12-21T14:40:56+00:00",
        "updated_at": "2021-12-23T02:56:27+00:00",
        "closed_at": "2021-12-23T02:56:27+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1187,
        "title": "支持c++部署环境吗？",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "xiaogao22",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-22T01:10:37+00:00",
        "updated_at": "2022-10-17T11:49:17+00:00",
        "closed_at": "2022-03-20T16:41:15+00:00",
        "comments_count": [
            "zh794390558",
            "dinglizhi",
            "stale[bot]",
            "stale[bot]",
            "hhxdestiny"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1201
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1198,
        "title": "语音识别过程中音频文件过大可能报错或killed",
        "body": "可能是机器资源不够或者音频长度超过最大值，可以手动切分长音频或者用VAD自动切分",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-23T01:55:42+00:00",
        "updated_at": "2022-03-20T16:41:13+00:00",
        "closed_at": "2022-03-20T16:41:13+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1199,
        "title": "对于超长文本，语音合成最后的结果不好",
        "body": "FastSpeech2 模型是非自回归模型，这个问题是该模型本身的问题，PaddleSpeech 的中文文本前端提供了按照标点切句的功能，您可以在调用文本前端时设置 merge_sentence=False，然后按照分句一个一个合成，再把分句的结果 concat 到一起，类似于下图\r\n![mmexport1640224872489](https://user-images.githubusercontent.com/24568452/147176584-b72daa2e-cdd5-4467-8a8a-c0ba2e834f7b.png)\r\n目前调用时为了统一中文和英文模型，默认 merge_sentence=True\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-23T02:06:25+00:00",
        "updated_at": "2022-07-13T11:54:58+00:00",
        "closed_at": "2022-03-12T17:41:23+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]",
            "e3u3"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1211,
        "title": "使用paddlespeech asr命令的时候会产生exp/log, 其中有较大的日志文件",
        "body": "描述：\r\n使用paddlespeech asr命令的时候会产生exp/log, 其中有较大的日志文件\r\n![image](https://user-images.githubusercontent.com/87408988/147321494-26f9f97c-0a77-45a8-bb3e-6b8f5e257782.png)\r\n\r\n\r\n复现：\r\n安装paddlespeech后，paddlespeech asr --input xxx\r\n\r\n期望：\r\n日志文件尽量小，最好没有\r\n\r\n环境：\r\nubuntu\r\n\r\n",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "yt605155624",
        "created_at": "2021-12-24T05:46:41+00:00",
        "updated_at": "2023-02-24T02:37:00+00:00",
        "closed_at": "2021-12-24T13:16:53+00:00",
        "comments_count": [
            "yt605155624",
            "Alc-z"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1206,
        "title": "请问speech2text可以转换到paddlelite 然后在android上运行吗",
        "body": "如题,",
        "state": "closed",
        "user": "Ray8716397",
        "closed_by": "yt605155624",
        "created_at": "2021-12-23T08:44:44+00:00",
        "updated_at": "2022-04-22T10:35:50+00:00",
        "closed_at": "2022-04-22T10:35:50+00:00",
        "comments_count": [
            "zh794390558",
            "Ray8716397",
            "Jackwaterveg",
            "stale[bot]",
            "wy676579037",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1213,
        "title": "啥时候会有多说话人分割功能啊~",
        "body": "啥时候会有多说话人分割功能啊~  ",
        "state": "closed",
        "user": "lucylqe",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-24T06:24:07+00:00",
        "updated_at": "2022-04-02T09:17:42+00:00",
        "closed_at": "2022-04-02T09:17:42+00:00",
        "comments_count": [
            "zh794390558",
            "lucylqe",
            "zh794390558",
            "godeity",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1230
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1217,
        "title": "metaverse/run.sh，发现第40行代码，${BIN_DIR}目录下并没有synthesize_e2e.py这个文件",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2021-12-24T09:53:52+00:00",
        "updated_at": "2023-02-13T12:27:54+00:00",
        "closed_at": "2021-12-24T10:15:15+00:00",
        "comments_count": [
            "caixxiong"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1229
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1220,
        "title": "Failed to build pyworld bottleneck",
        "body": "pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple 报错\r\n\r\n\r\nFailed to build pyworld bottleneck\r\nERROR: Could not build wheels for pyworld, bottleneck, which is required to install pyproject.toml-based projects\r\n\r\n  error: command 'XXX/envs/paddle/bin/x86_64-conda-linux-gnu-c++' failed with exit code 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for pyworld\r\n  Building wheel for bottleneck (pyproject.toml) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: xxx/anaconda3/envs/paddle/bin/python3.7 xxx/anaconda3/envs/paddle/lib/python3.7/site-packages/pip/_vendor/pep517/in_process/_in_process.py build_wheel /tmp/tmpa026yewa\r\n       cwd: /tmp/pip-install-1hmqtmzj/bottleneck_f4131d72736d4fea982e804e9fa8e0ac\r\n  Complete output (49 lines):\r\n  /bin/sh: warning: setlocale: LC_ALL: cannot change locale (en_US.utf-8)\r\n\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [Ubuntu:16]\r\n - GCC/G++ Version [ 8.4]\r\n - Python Version [3.7]\r\n - PaddlePaddle Version [2.0.0]\r\n - Model Version [2.0.0]\r\n - GPU/DRIVER Informationo [Tesla V100]\r\n - CUDA/CUDNN Version [cuda-10.2]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "geekchen007",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-26T15:00:16+00:00",
        "updated_at": "2025-06-30T09:25:15+00:00",
        "closed_at": "2022-03-20T16:41:16+00:00",
        "comments_count": [
            "yt605155624",
            "geekchen007",
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "DragonnZhang"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1224,
        "title": "请问frontend是怎么处理“得”这个多音字的",
        "body": "我发现在前端模块并没有处理得字的多音字，只是调用lazy_pinyin模块去获取de这个发音\r\n",
        "state": "closed",
        "user": "madosma",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-28T03:51:06+00:00",
        "updated_at": "2022-03-20T16:41:17+00:00",
        "closed_at": "2022-03-20T16:41:17+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1222,
        "title": "Speedyspeech multi-speaker support",
        "body": "Speedyspeech目前不支持多人语音合成。后续会有加speaker embedding的计划吗？",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "yt605155624",
        "created_at": "2021-12-27T09:50:06+00:00",
        "updated_at": "2022-01-05T05:19:06+00:00",
        "closed_at": "2022-01-05T05:19:06+00:00",
        "comments_count": [
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1231
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1232
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1234
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1233
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1249
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1250
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1235,
        "title": "GPU内存泄露？",
        "body": "WSL + paddlepaddle2.2.1 + 3090 24G\r\nfine-tune conformer_wenetspeech-zh-16k 这个与训练模型，batch_size=64 正常的时候使用gpu内存10G左右，但是时不时内存会飙升到20多G然后又降到10G左右，但有时候也会内存耗尽崩溃。是不是程序有内存泄漏啊？\r\n配置文件如下：\r\n\r\n\r\n# network architecture\r\nmodel:\r\n    # encoder related\r\n    encoder: conformer\r\n    blank_id: 0\r\n    encoder_conf:\r\n        output_size: 512    # dimension of attention\r\n        attention_heads: 8\r\n        linear_units: 2048  # the number of units of position-wise feed forward\r\n        num_blocks: 12      # the number of encoder blocks\r\n        dropout_rate: 0.1\r\n        positional_dropout_rate: 0.1\r\n        attention_dropout_rate: 0.0\r\n        input_layer: conv2d # encoder input type, you can chose conv2d, conv2d6 and conv2d8\r\n        normalize_before: True\r\n        use_cnn_module: True\r\n        cnn_module_kernel: 15\r\n        cnn_module_norm: layer_norm\r\n        activation_type: swish\r\n        pos_enc_layer_type: rel_pos\r\n        selfattention_layer_type: rel_selfattn\r\n\r\n    # decoder related\r\n    decoder: transformer\r\n    decoder_conf:\r\n        attention_heads: 8\r\n        linear_units: 2048\r\n        num_blocks: 6\r\n        dropout_rate: 0.1\r\n        positional_dropout_rate: 0.1\r\n        self_attention_dropout_rate: 0.0\r\n        src_attention_dropout_rate: 0.0\r\n\r\n    # hybrid CTC/attention\r\n    model_conf:\r\n        ctc_weight: 0.3\r\n        ctc_dropoutrate: 0.0\r\n        ctc_grad_norm_type: null\r\n        lsm_weight: 0.1     # label smoothing option\r\n        length_normalized_loss: false\r\n\r\n# https://yaml.org/type/float.html\r\ndata:\r\n  train_manifest: data/manifest.train\r\n  dev_manifest: data/manifest.test\r\n  test_manifest: data/manifest.test\r\n  min_input_len: 0.0\r\n  max_input_len: 12.0\r\n  min_output_len: 1.0\r\n  max_output_len: 400.0\r\n  min_output_input_ratio: 0.05\r\n  max_output_input_ratio: 20.0\r\n\r\ncollator:\r\n  vocab_filepath: data/vocab.txt \r\n  unit_type: 'char'\r\n  spm_model_prefix: ''\r\n#  augmentation_config: conf/preprocess.yaml\r\n  augmentation_config: conf/augmentation.json\r\n  batch_size: 64\r\n  raw_wav: True  # use raw_wav or kaldi feature\r\n  spectrum_type: fbank #linear, mfcc, fbank\r\n  feat_dim: 80\r\n  delta_delta: False\r\n  dither: 1.0\r\n  target_sample_rate: 16000\r\n  max_freq: None\r\n  n_fft: None\r\n  stride_ms: 10.0\r\n  window_ms: 25.0\r\n  use_dB_normalization: True \r\n  target_dB: -20\r\n  random_seed: 0\r\n  keep_transcription_text: False\r\n  sortagrad: True \r\n  shuffle_method: batch_shuffle\r\n  num_workers: 1\r\n\r\n\r\ntraining:\r\n  n_epoch: 40\r\n  accum_grad: 1\r\n  global_grad_clip: 5.0\r\n  log_interval: 400\r\n  checkpoint:\r\n    kbest_n: 50\r\n    latest_n: 5\r\n  optim: adam\r\n  optim_conf:\r\n    lr: 0.0005\r\n    weight_decay: 1e-6\r\n  scheduler: warmuplr     # pytorch v1.1.0+ required\r\n  scheduler_conf:\r\n    warmup_steps: 5000\r\n    lr_decay: 1.0\r\n\r\n\r\ndecoding:\r\n  batch_size: 64\r\n  error_rate_type: cer\r\n#  decoding_method: ctc_greedy_search # 'attention', 'ctc_greedy_search', 'ctc_prefix_beam_search', 'attention_rescoring'\r\n  decoding_method: ctc_beam_search # \"ctc_greedy\", \"ctc_beam_search\", ctc.py中只支持这两个\r\n  lang_model_path: data/lm/common_crawl_00.prune01111.trie.klm\r\n  alpha: 2.5\r\n  beta: 0.3\r\n  beam_size: 5\r\n  cutoff_prob: 1.0\r\n  cutoff_top_n: 0\r\n  num_proc_bsearch: 8\r\n  ctc_weight: 0.5 # ctc weight for attention rescoring decode mode.\r\n  decoding_chunk_size: -1 # decoding chunk size. Defaults to -1.\r\n      # <0: for decoding, use full chunk.\r\n      # >0: for decoding, use fixed chunk size as set.\r\n      # 0: used for training, it's prohibited here. \r\n  num_decoding_left_chunks: -1  # number of left chunks for decoding. Defaults to -1.\r\n  simulate_streaming: False  # simulate streaming inference. Defaults to False.",
        "state": "closed",
        "user": "jeffzhengye",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-28T17:00:41+00:00",
        "updated_at": "2022-03-20T16:41:12+00:00",
        "closed_at": "2022-03-20T16:41:12+00:00",
        "comments_count": [
            "Jackwaterveg",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1237,
        "title": "安装PaddleSpeech出错",
        "body": "错误信息：\r\n\r\nERROR: Could not find a version that satisfies the requirement kaldiio (from paddlespeech) (from versions: 2.13.2, 2.13.3, 2.13.4, 2.13.6, 2.13.7, 2.13.8, 2.13.9, 2.14.0, 2.14.1, 2.15.0, 2.15.1, 2.16.0a1, 2.16.0, 2.17.0, 2.17.1, 2.17.2)\r\nERROR: No matching distribution found for kaldiio\r\n\r\n环境信息：\r\n\r\nPython 3.7.10\r\n\r\npip 21.3.1\r\n\r\nCentOS Linux release 7.3.1611 (Core)\r\n\r\nimport platform\r\nplatform.architecture()\r\n('64bit', '')",
        "state": "closed",
        "user": "dean-lhb",
        "closed_by": "Jackwaterveg",
        "created_at": "2021-12-29T06:21:05+00:00",
        "updated_at": "2023-01-12T02:28:48+00:00",
        "closed_at": "2022-01-12T11:58:28+00:00",
        "comments_count": [
            "Jackwaterveg",
            "dean-lhb",
            "yt605155624",
            "dean-lhb",
            "yt605155624",
            "yt605155624",
            "dean-lhb",
            "yt605155624",
            "dean-lhb",
            "dean-lhb",
            "yt605155624",
            "dean-lhb",
            "yt605155624",
            "dean-lhb",
            "00851"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1238,
        "title": "中英文前端统一默认使用分句合成",
        "body": "否则输入过长可能 fastspeech2 句末效果不好或爆显存\r\n英文 transformer tts 和 tacotron2 除外",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2021-12-29T09:04:05+00:00",
        "updated_at": "2021-12-30T02:29:13+00:00",
        "closed_at": "2021-12-30T02:29:13+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1240,
        "title": "AttributeError: module 'paddle' has no attribute 'float32'",
        "body": "\r\n**Describe the bug**\r\n使用 pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple 安装后，在终端使用命令行运行报错。即是无论输入什么命令，比如 `speech` 也会报错，显示 \"AttributeError: module 'paddle' has no attribute 'float32'\"\r\n\r\n\r\n**Screenshots**\r\n![](https://s2.loli.net/2021/12/29/g1lXfDNCUSGMdzw.png)\r\n\r\n** Environment (please complete the following information):**\r\n - OS: Ubuntu 20.04.3 LTS\r\n - GCC/G++ Version gcc version 9.3.0\r\n - Python Version:  Python 3.8\r\n - PaddlePaddle Version: 2.0.1\r\n - Model Version: ?\r\n - GPU/DRIVER Informationo eForce RTX 2070\r\n - CUDA/CUDNN Version: 11.2\r\n\r\n\r\n",
        "state": "closed",
        "user": "ultrasev",
        "closed_by": "ultrasev",
        "created_at": "2021-12-29T12:21:37+00:00",
        "updated_at": "2021-12-30T08:55:47+00:00",
        "closed_at": "2021-12-30T08:55:47+00:00",
        "comments_count": [
            "yt605155624",
            "ultrasev"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1251
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1244,
        "title": "vctk's pwgan has bad high frequency noise",
        "body": "Whether synthesize with GT mel or synthesize with generated mel, the vctk pwgan will generate noise at high frequency, I will try to fix this soon. \r\nAn alternative way is that: since **the vocoder is language independent**, you can use the aishell3's pwgan here, which will get a better result. (You must use a multi speaker vocoder here, single speaker vocoder trained with a famale's voice is not good for male)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2021-12-30T07:08:17+00:00",
        "updated_at": "2022-03-20T16:41:11+00:00",
        "closed_at": "2022-03-20T16:41:11+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1247,
        "title": "TTS一些小问题总结",
        "body": "文本1：产业智能化升级和开源生态共建的“大航海“计划也进阶到2.0。\r\n问题：2.0没有被正确读出，只读了2\r\n\r\n文本2：社区6000+小时课程向学生免费开放\r\n问题：读成了 六零零零\r\n\r\n文本3：现货黄金小幅上扬3美元，报1809.93美元/盎司\r\n问题：斜杆没有读成1\r\n\r\n文本4：两个工厂相加今年出货量预计会超1 GWh\r\n问题：单位没读出\r\n建议：考虑下g2p可以让用户自定义词典，将一些单位还有其他专业英文缩写翻译成中文\r\n\r\n问题：长文本中句号的时间间隔似乎比逗号还短，句与句之间的停顿时间不够。\r\n\r\n问题：生成音频最后一个字停得太快，希望可以增加一秒空音频在后面确保最后一个字读完",
        "state": "closed",
        "user": "JiehangXie",
        "closed_by": "yt605155624",
        "created_at": "2021-12-30T09:24:58+00:00",
        "updated_at": "2023-07-21T07:13:17+00:00",
        "closed_at": "2022-02-28T13:24:14+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "JiehangXie",
            "yt605155624",
            "stale[bot]",
            "fidding"
        ],
        "labels": [
            "feature request",
            "good first issue"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1252
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1248,
        "title": "kaldiio安装出错解决方案",
        "body": "问题： Could not find a version that satisfies the requirement kaldiio.\r\n\r\n\r\n使用清华源安装pytest-runner。\r\n`pip install pytest-runner -i https://pypi.tuna.tsinghua.edu.cn/simple`\r\n",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "Jackwaterveg",
        "created_at": "2021-12-30T09:49:06+00:00",
        "updated_at": "2022-01-24T12:15:22+00:00",
        "closed_at": "2022-01-24T12:15:22+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1255
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1256
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1265
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1266
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1264
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1267
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1253,
        "title": "import _locale 引用出错",
        "body": "环境：windows 11 paddlepaddle 2.2.1 第一次安装 paddlespeech `测试以下代码运行正常，后面又安装了ppgan ，结果 程序 就不行正常运行，通过分析发现 from paddlespeech.cli import ASRExecutor, TextExecutor 这一句有问题，转到定义处：__init__.py 查看：\r\n发现：import _locale 引用出错导致，试过各种办法问题无法解决。",
        "state": "closed",
        "user": "youufis",
        "closed_by": "yt605155624",
        "created_at": "2021-12-31T03:04:00+00:00",
        "updated_at": "2022-10-19T03:36:16+00:00",
        "closed_at": "2022-04-22T09:37:47+00:00",
        "comments_count": [
            "yt605155624",
            "youufis",
            "yt605155624",
            "youufis",
            "yt605155624",
            "yt605155624",
            "youufis",
            "yt605155624",
            "youufis",
            "youufis",
            "yt605155624",
            "youufis",
            "SkySailing"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1268
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1257,
        "title": "[asr]ASR建议输出timeline结构信息",
        "body": "语音识别，很多时候需要时间轴，可以用户做提词器之类的工能。  强烈建议考虑一下",
        "state": "closed",
        "user": "big-pang",
        "closed_by": "zh794390558",
        "created_at": "2022-01-02T07:24:34+00:00",
        "updated_at": "2024-01-12T08:51:21+00:00",
        "closed_at": "2022-05-06T02:27:55+00:00",
        "comments_count": [
            "zh794390558",
            "bikekoala",
            "zh794390558",
            "bikekoala",
            "josh-zhu",
            "214929177",
            "stale[bot]",
            "DidaDidaDidaD",
            "nevertoday",
            "nevertoday",
            "simin75simin",
            "tomfat",
            "iftaken",
            "Dewey-Ding",
            "twoDogy",
            "mapleleafss",
            "entalent",
            "777sfdf",
            "777sfdf"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1258,
        "title": "tacotron2-ge2e synthesize poor quality audio with vocoder WaveGan",
        "body": "i want to implent multispeaker tts and i try to compare the two project in this repo. Since the tacotron2-ge2e and fastspeech2-ge2e use different vocoder(waveflow for t2-ge2e and wavegan for f2-ge2e), to figure out the best synthesizer, it is essential to use the same vocoder. So i change the vocoder of t2-ge2e from waveflow to wavegan, the same as f2-ge2e. But i found that the synthesized audio is poor with very low energy and human not understanding. While it has good perfomance in f2-ge2e. It seems that the synthesizers are coupled with the vocoders. Should it be like this?\r\n\r\nDose anyone know why? Thanks",
        "state": "closed",
        "user": "PingAnPH",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-04T03:02:33+00:00",
        "updated_at": "2022-03-20T16:41:11+00:00",
        "closed_at": "2022-03-20T16:41:11+00:00",
        "comments_count": [
            "yt605155624",
            "PingAnPH",
            "PingAnPH",
            "yt605155624",
            "PingAnPH",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1263,
        "title": "linux环境中已经安装了miniconda，现在安装PaddleSpeech步骤中再安装一个minicoda，对原来的miniconda会有影响吗？",
        "body": "linux环境中已经安装了miniconda，现在安装PaddleSpeech步骤中再安装一个minicoda，对原来的miniconda会有影响吗？\r\n",
        "state": "closed",
        "user": "richard201410",
        "closed_by": "richard201410",
        "created_at": "2022-01-05T01:14:21+00:00",
        "updated_at": "2022-01-06T13:58:40+00:00",
        "closed_at": "2022-01-06T13:57:59+00:00",
        "comments_count": [
            "Jackwaterveg",
            "richard201410"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1279
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1280
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1270,
        "title": "[docker]有没有cpu版的镜像可以用",
        "body": "cpu环境安装一直报错，ubuntu和centos都出错，有没有cpu版的镜像可以用？",
        "state": "closed",
        "user": "lang101",
        "closed_by": "yt605155624",
        "created_at": "2022-01-05T08:02:46+00:00",
        "updated_at": "2022-04-22T10:48:34+00:00",
        "closed_at": "2022-04-22T10:48:33+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1277,
        "title": "tts出错",
        "body": "[2022-01-06 13:39:46,020] [    INFO] [log.py] [L57] - /root/.paddlespeech/models/pwgan_csmsc-zh/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\r\nERROR: Exception on /tts [POST]\r\nTraceback (most recent call last):\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 2073, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1518, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1516, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1502, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n  File \"app.py\", line 66, in tts_to_file\r\n    device=paddle.get_device())\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/cli/tts/infer.py\", line 639, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/cli/tts/infer.py\", line 511, in infer\r\n    text, merge_sentences=True, get_tone_ids=get_tone_ids)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 269, in get_input_ids\r\n    robot=robot)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 236, in get_phonemes\r\n    sentences, merge_sentences=merge_sentences, with_erhua=with_erhua)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 117, in _g2p\r\n    sub_finals)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/t2s/frontend/tone_sandhi.py\", line 342, in modified_tone\r\n    finals = self._three_sandhi(word, finals)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/t2s/frontend/tone_sandhi.py\", line 200, in _three_sandhi\r\n    sub[0] = sub[0][:-1] + \"2\"\r\nIndexError: list index out of range\r\nself.phones_dict: /root/.paddlespeech/models/fastspeech2_csmsc-zh/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\r\nself.phones_dict: /root/.paddlespeech/models/fastspeech2_csmsc-zh/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\r\nvocab_size: 268\r\nfrontend done!\r\nencoder_type is transformer\r\ndecoder_type is transformer\r\nacoustic model done!\r\nvoc done!",
        "state": "closed",
        "user": "sshnuke3",
        "closed_by": "sshnuke3",
        "created_at": "2022-01-06T05:41:52+00:00",
        "updated_at": "2022-01-06T06:53:16+00:00",
        "closed_at": "2022-01-06T06:53:16+00:00",
        "comments_count": [
            "yt605155624",
            "sshnuke3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1276,
        "title": "asr出错",
        "body": "[2022-01-06 11:21:08,920] [    INFO] - audio feat shape: [1, 32104, 80]\r\nERROR: Exception on /asr [POST]\r\nTraceback (most recent call last):\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 2073, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1518, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1516, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/root/tools/env/lib/python3.7/site-packages/flask/app.py\", line 1502, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n  File \"app.py\", line 32, in asr_from_file\r\n    device=paddle.get_device())\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 446, in __call__\r\n    self.infer(model)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 320, in infer\r\n    simulate_streaming=cfg.simulate_streaming)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 802, in decode\r\n    simulate_streaming=simulate_streaming)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 579, in attention_rescoring\r\n    num_decoding_left_chunks, simulate_streaming)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 465, in _ctc_prefix_beam_search\r\n    simulate_streaming)  # (B, maxlen, encoder_dim)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 268, in _forward_encoder\r\n    num_decoding_left_chunks=num_decoding_left_chunks\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/modules/encoder.py\", line 167, in forward\r\n    xs, pos_emb, masks = self.embed(xs, masks.astype(xs.dtype), offset=0)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/modules/subsampling.py\", line 141, in forward\r\n    x, pos_emb = self.pos_enc(x, offset)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/tools/env/lib/python3.7/site-packages/paddlespeech/s2t/modules/embedding.py\", line 161, in forward\r\n    assert offset + x.shape[1] < self.max_len\r\nAssertionError\r\n\r\n相关代码\r\n    19  @app.route('/asr', methods=['GET', 'POST'])\r\n    20  def asr_from_file():\r\n    21      if request.method == 'POST':\r\n    22          file = request.files['the_file']\r\n    23          file.save(f\"/www/example/upload/{secure_filename(file.filename)}\")\r\n    24          result1 = asr_executor(\r\n    25              model='conformer_wenetspeech',\r\n    26              lang='zh',\r\n    27              sample_rate=16000,\r\n    28              config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    29              ckpt_path=None,\r\n    30              audio_file=f\"/www/example/upload/{secure_filename(file.filename)}\",\r\n    31              force_yes=True,\r\n    32              device=paddle.get_device())\r\n    33          result2 = text_executor(\r\n    34              text=format(result1),\r\n    35              task='punc',\r\n    36              model='ernie_linear_p7_wudao',\r\n    37              lang='zh',\r\n    38              config=None,\r\n    39              ckpt_path=None,\r\n    40              punc_vocab=None,\r\n    41              device=paddle.get_device())\r\n    42          return {\r\n    43                  \"asr_result\":format(result1),\r\n    44                  \"punc_result\":format(result2)\r\n    45              },200\r\n\r\n显卡驱动\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |\r\n| N/A   45C    P0    28W /  70W |   6232MiB / 15109MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      8487      C   python                                      6221MiB |\r\n+-----------------------------------------------------------------------------+",
        "state": "closed",
        "user": "sshnuke3",
        "closed_by": "sshnuke3",
        "created_at": "2022-01-06T04:28:05+00:00",
        "updated_at": "2022-01-06T06:53:32+00:00",
        "closed_at": "2022-01-06T06:53:31+00:00",
        "comments_count": [
            "yt605155624",
            "sshnuke3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1281,
        "title": "[tts] 复现 简单的 music_generation",
        "body": "https://www.tensorflow.org/tutorials/audio/music_generation\r\n鼓励社区用户给 PaddleSpeech 提交代码",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-06T11:25:01+00:00",
        "updated_at": "2023-03-21T08:01:07+00:00",
        "closed_at": "2023-03-21T08:01:07+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1282,
        "title": "[tts] 基于 BERT 实现语音合成文本前端的停顿预测",
        "body": "简单的序列预测问题，数据集可以用标贝的文本，其实就是判断每个字后面是否有停顿，如果有的话，是 `#1`~`#4` 中的哪一个，是一个 5 分类的序列预测问题\r\n可以把标贝的文本和 aishell3 的文本结合到一起（但是 aishell3 只有两级停顿，需要考虑一下映射）\r\n实在没有停顿数据的，可以用 MFA 的结果（sp 帧数 > 某个值表示长停顿、< 表示短停顿）\r\n参考 example, [标点预测](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/iwslt2012/punc0)（BERT ERNIE 直接用 PaddleNLP 的模型，trainer 用 PaddleSpeech 提供的模板，自己需要补充的部分很少）\r\n\r\n进阶：多任务的 BERT \r\n![image](https://user-images.githubusercontent.com/24568452/148382039-170504db-dbde-4ade-bcfd-ac2ed484a72c.png)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-06T11:35:45+00:00",
        "updated_at": "2022-10-26T06:42:15+00:00",
        "closed_at": "2022-10-26T06:42:15+00:00",
        "comments_count": [
            "sixyang",
            "yt605155624"
        ],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1283,
        "title": "[tts] 基于 BERT 实现语音合成文本前端的多音字预测",
        "body": "目前的多音字使用 pypinyin 或者 g2pM，精度有限，想做一个基于 BERT (或者 ERNIE) 多音字预测模型，简单来说就是假设某语言有 100 个多音字，每个多音字最多有 3 个发音，那么可以在 BERT 后面接 100 个 3 分类器（简单的 fc 层即可），在预测时，找到对应的分类器进行分类即可。\r\n参考论文：\r\n[tencent_polyphone.pdf](https://github.com/PaddlePaddle/PaddleSpeech/files/7821488/tencent_polyphone.pdf)\r\n\r\n数据可以用 https://github.com/kakaobrain/g2pM 提供的数据\r\n\r\n进阶：多任务的 BERT \r\n![image](https://user-images.githubusercontent.com/24568452/148382039-170504db-dbde-4ade-bcfd-ac2ed484a72c.png)\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-06T11:45:51+00:00",
        "updated_at": "2022-11-18T08:24:39+00:00",
        "closed_at": "2022-11-18T08:24:39+00:00",
        "comments_count": [
            "Jzow",
            "yt605155624",
            "Jzow",
            "GloryRoadWangzh",
            "yt605155624",
            "lucasjinreal",
            "yt605155624"
        ],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1286,
        "title": "“宁”转换出错",
        "body": "    sentence = '保持宁静'\r\n    TTS = TTSExecutor('default.yaml')\r\n    input_ids = TTS.frontend.get_phonemes(sentence, merge_sentences=True, print_info=True)[0]\r\n    print(input_ids)\r\n\r\n----------------\r\n输出：\r\n----------------------------\r\ntext norm results:\r\n['保持㝉静']\r\n----------------------------\r\ng2p results:\r\n[['b', 'ao3', 'ch', 'iii2', 'zh', 'u4', 'j', 'ing4']]\r\n----------------------------\r\n['b', 'ao3', 'ch', 'iii2', 'zh', 'u4', 'j', 'ing4']\r\n",
        "state": "closed",
        "user": "ABC0408",
        "closed_by": "yt605155624",
        "created_at": "2022-01-07T06:19:45+00:00",
        "updated_at": "2022-01-18T10:56:30+00:00",
        "closed_at": "2022-01-07T06:58:22+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1298,
        "title": "[cli] CLI 缺少英文支持",
        "body": "1. CLI 目前提示中有en选项，但没有相应的模型提供下载，需要提供一下\r\n2. 最好添加使用decode method的选项。",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-10T09:59:57+00:00",
        "updated_at": "2022-01-13T06:23:40+00:00",
        "closed_at": "2022-01-11T06:48:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1289,
        "title": "[audio] support kaldi stft/fbank/mfcc",
        "body": "align kaldi with fbank/mfcc/pitch, support on cpu/gpu\r\n\r\nwork branch: https://github.com/KPatr1ck/Paddle/tree/speech_op\r\n\r\n- [x] STFT op https://github.com/PaddlePaddle/Paddle/pull/40113\r\n- [x] Fbank\r\n- [x] MFCC\r\n- [x]  window",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-07T09:54:57+00:00",
        "updated_at": "2022-03-15T06:14:07+00:00",
        "closed_at": "2022-03-15T06:14:07+00:00",
        "comments_count": [
            "stale[bot]",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1292,
        "title": "想问一下 自动语音识别 的 识别英语的模型和 使用文档在哪里",
        "body": "我参考官网只看到了识别 中文的 例子，并没有找到英文的，如果有可以发我一下吗，非常感谢",
        "state": "closed",
        "user": "Jzow",
        "closed_by": "Jzow",
        "created_at": "2022-01-10T04:09:43+00:00",
        "updated_at": "2022-07-28T03:15:48+00:00",
        "closed_at": "2022-01-10T07:46:35+00:00",
        "comments_count": [
            "Jzow",
            "Jzow",
            "Jzow",
            "yt605155624",
            "Jzow",
            "Jzow",
            "yt605155624",
            "xinyujituan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1296,
        "title": "[tts] csmsc Tacotron2",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-01-10T07:58:32+00:00",
        "updated_at": "2022-01-19T03:17:30+00:00",
        "closed_at": "2022-01-19T03:17:30+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "zh794390558",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1300,
        "title": "[Doc] The released model need to be updated",
        "body": "The released models in docs/sources/released_model.md can not be used due to the config files of them haven't been updated. Please update the released models.\r\n",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-11T02:30:11+00:00",
        "updated_at": "2022-01-24T12:14:16+00:00",
        "closed_at": "2022-01-24T12:14:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1299,
        "title": "speech_recognition示例运行出错",
        "body": "这是源码：\r\nimport paddle\r\nfrom paddlespeech.cli import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='input.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n\r\n运行后提示：\r\nTraceback (most recent call last):\r\n  File \"D:\\BaiduNetdiskDownload\\PaddleSpeech-r0.1.0\\demos\\speech_recognition\\speech_recognition.py\", line 5, in <module>\r\n    text = asr_executor(\r\n  File \"D:\\BaiduNetdiskDownload\\PaddleSpeech-r0.1.0\\paddlespeech\\cli\\asr\\infer.py\", line 449, in __call__\r\n    self._init_from_path(model, lang, sample_rate, config, ckpt_path)\r\n  File \"D:\\BaiduNetdiskDownload\\PaddleSpeech-r0.1.0\\paddlespeech\\cli\\asr\\infer.py\", line 166, in _init_from_path\r\n    self.config.merge_from_file(self.cfg_path)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 212, in merge_from_file\r\n    cfg = self.load_cfg(f)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 349, in load_cfg\r\n    return cls._load_cfg_from_file(cfg_file_obj_or_str)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 358, in _load_cfg_from_file\r\n    return cls._load_cfg_from_yaml_str(file_obj.read())\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 371, in _load_cfg_from_yaml_str\r\n    return cls(cfg_as_dict)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 126, in _create_config_tree_from_dict\r\n    dic[k] = cls(v, key_list=key_list + [k])\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 126, in _create_config_tree_from_dict\r\n    dic[k] = cls(v, key_list=key_list + [k])\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 129, in _create_config_tree_from_dict\r\n    _assert_with_logging(\r\n  File \"D:\\SoftWare\\Anaconda\\lib\\site-packages\\yacs\\config.py\", line 521, in _assert_with_logging\r\n    assert cond, msg\r\nAssertionError: Key model.model_conf.ctc_grad_norm_type with value <class 'NoneType'> is not a valid type; valid types: {<class 'list'>, <class 'tuple'>, <class 'str'>, <class 'int'>, <class 'float'>, <class 'bool'>}\r\n\r\n目前是按照文档在windows下进行的paddlepaddle安装，并下载了PaddleSpeech-r0.1.0源码后直接进行的测试，请问我该如何解决这个问题，谢谢",
        "state": "closed",
        "user": "yp8976",
        "closed_by": "yp8976",
        "created_at": "2022-01-10T17:15:04+00:00",
        "updated_at": "2022-01-11T11:04:46+00:00",
        "closed_at": "2022-01-11T09:59:06+00:00",
        "comments_count": [
            "yp8976",
            "zh794390558",
            "yp8976",
            "Jackwaterveg",
            "Jackwaterveg",
            "Jackwaterveg",
            "yp8976",
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1305,
        "title": "[cli] 增加统一的config名为model.yaml,给CLI提供支持",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-11T07:21:57+00:00",
        "updated_at": "2022-01-13T06:23:25+00:00",
        "closed_at": "2022-01-12T06:30:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1303,
        "title": "[vec] support ECAPA-TDNN model on voxceleb",
        "body": null,
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-11T07:14:13+00:00",
        "updated_at": "2022-03-28T02:40:04+00:00",
        "closed_at": "2022-03-28T02:40:04+00:00",
        "comments_count": [
            "stale[bot]"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1306,
        "title": "[Doc] Update released model for r0.1.1",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-11T07:22:25+00:00",
        "updated_at": "2022-01-12T07:21:51+00:00",
        "closed_at": "2022-01-12T07:21:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1304,
        "title": "[vec] support Speaker Diarization on AMI",
        "body": null,
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-11T07:14:22+00:00",
        "updated_at": "2022-03-22T08:49:59+00:00",
        "closed_at": "2022-03-22T08:49:59+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1309,
        "title": "为什么会有如此多的shell去执行程序,为什么不去繁从简,站在使用者的角度去构建工程? [尽管是吐槽,但期望你们还是认真思考下]",
        "body": "1 建议把example写的简洁统一些,不要做shell里面调用python或别的什么,虽然这些shell写的很简单,但这个真没什么必要,为什么要如此奇葩,在秀技能还是怕直接一点容易烂大街?  还是工程的同学水平太差, 只能为了实现就脚本呼叫? 假如你在考虑局部自动化,那我想说这点过程本来没那么复杂,不需要徒增没用的东西\r\n\r\n2 看完工程的所有目录和内容, 发现工程师没去想如果简单高效的分类介绍原理 -> 训练 -> 在线服务(web) , 本来从使用者的角度去用,并不复杂的东西被构建的很复杂, 另外为什么很多说明不是中文为主, 英语虽然也没什么问题, 但都2021年了,很多顶级项目和组织都开始加入便捷的中文文档,虽然翻译有点像google translate.  这简直匪夷所思, paddlepaddle的研发团队和所在的公司姓中还是姓美? 团队的人员有没点脑子?\r\n\r\n3 我花了5分钟不到的时间,尝试了语音识别, 但我花了近两天的时间去集成到python web构建docker镜像服务,在集成环节如此多的问题,是我从没想到的,尽管还是有些问题. ",
        "state": "closed",
        "user": "rhygyj",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-11T08:09:05+00:00",
        "updated_at": "2022-07-26T07:27:02+00:00",
        "closed_at": "2022-04-02T09:17:43+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1307,
        "title": "[asr] csj recipe",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-11T07:22:39+00:00",
        "updated_at": "2022-04-14T15:32:31+00:00",
        "closed_at": "2022-04-14T15:32:31+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1317,
        "title": "Installation error in tools/install_kaldi.sh ",
        "body": "\r\nDescribe:\r\n![image](https://user-images.githubusercontent.com/87408988/149077916-fdf78f8d-e4de-4c3c-9f5f-d1963308333b.png)\r\n\r\n使用安装kaldi的脚本出问题\r\n",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-12T06:52:14+00:00",
        "updated_at": "2022-01-12T07:22:57+00:00",
        "closed_at": "2022-01-12T07:22:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1315,
        "title": "BadZipFile: File is not a zip file",
        "body": "您好，我导入的时候发生了点问题。\r\n之前导入paddlespeech是正常的，今天重新配了一遍，第一次import的时间过长，我以为是卡住了，就中断了。结果重新运行的时候，出现BadZipFile: File is not a zip file。重新安也没用。\r\n\r\n`---------------------------------------------------------------------------\r\nBadZipFile                                Traceback (most recent call last)\r\n/tmp/ipykernel_2495/2475697323.py in <module>\r\n      1 import paddle\r\n----> 2 from paddlespeech.cli import ASRExecutor, TextExecutor\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/cli/__init__.py in <module>\r\n     20 from .st import STExecutor\r\n     21 from .text import TextExecutor\r\n---> 22 from .tts import TTSExecutor\r\n     23 \r\n     24 _locale._getdefaultlocale = (lambda *args: ['en_US', 'utf8'])\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/cli/tts/__init__.py in <module>\r\n     12 # See the License for the specific language governing permissions and\r\n     13 # limitations under the License.\r\n---> 14 from .infer import TTSExecutor\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py in <module>\r\n     31 from ..utils import MODEL_HOME\r\n     32 from paddlespeech.s2t.utils.dynamic_import import dynamic_import\r\n---> 33 from paddlespeech.t2s.frontend import English\r\n     34 from paddlespeech.t2s.frontend.zh_frontend import Frontend\r\n     35 from paddlespeech.t2s.modules.normalizer import ZScore\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/t2s/__init__.py in <module>\r\n     17 from . import datasets\r\n     18 from . import exps\r\n---> 19 from . import frontend\r\n     20 from . import models\r\n     21 from . import modules\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/t2s/frontend/__init__.py in <module>\r\n     14 from .generate_lexicon import *\r\n     15 from .normalizer import *\r\n---> 16 from .phonectic import *\r\n     17 from .punctuation import *\r\n     18 from .tone_sandhi import *\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/t2s/frontend/phonectic.py in <module>\r\n     16 \r\n     17 import paddle\r\n---> 18 from g2p_en import G2p\r\n     19 from g2pM import G2pM\r\n     20 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/g2p_en/__init__.py in <module>\r\n----> 1 from .g2p import G2p\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/g2p_en/g2p.py in <module>\r\n     24     nltk.download('averaged_perceptron_tagger')\r\n     25 try:\r\n---> 26     nltk.data.find('corpora/cmudict.zip')\r\n     27 except LookupError:\r\n     28     nltk.download('cmudict')\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/nltk/data.py in find(resource_name, paths)\r\n    540                 if os.path.exists(p):\r\n    541                     try:\r\n--> 542                         return ZipFilePathPointer(p, zipentry)\r\n    543                     except OSError:\r\n    544                         # resource not in zipfile\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/nltk/compat.py in _decorator(*args, **kwargs)\r\n     39     def _decorator(*args, **kwargs):\r\n     40         args = (args[0], add_py3_data(args[1])) + args[2:]\r\n---> 41         return init_func(*args, **kwargs)\r\n     42 \r\n     43     return wraps(init_func)(_decorator)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/nltk/data.py in __init__(self, zipfile, entry)\r\n    392         \"\"\"\r\n    393         if isinstance(zipfile, str):\r\n--> 394             zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))\r\n    395 \r\n    396         # Check that the entry exists:\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/nltk/compat.py in _decorator(*args, **kwargs)\r\n     39     def _decorator(*args, **kwargs):\r\n     40         args = (args[0], add_py3_data(args[1])) + args[2:]\r\n---> 41         return init_func(*args, **kwargs)\r\n     42 \r\n     43     return wraps(init_func)(_decorator)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/nltk/data.py in __init__(self, filename)\r\n    933         if not isinstance(filename, str):\r\n    934             raise TypeError(\"ReopenableZipFile filename must be a string\")\r\n--> 935         zipfile.ZipFile.__init__(self, filename)\r\n    936         assert self.filename == filename\r\n    937         self.close()\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/zipfile.py in __init__(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\r\n   1267         try:\r\n   1268             if mode == 'r':\r\n-> 1269                 self._RealGetContents()\r\n   1270             elif mode in ('w', 'x'):\r\n   1271                 # set the modified flag so central directory gets written\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/zipfile.py in _RealGetContents(self)\r\n   1334             raise BadZipFile(\"File is not a zip file\")\r\n   1335         if not endrec:\r\n-> 1336             raise BadZipFile(\"File is not a zip file\")\r\n   1337         if self.debug > 1:\r\n   1338             print(endrec)\r\n\r\nBadZipFile: File is not a zip file`\r\n\r\n救命55",
        "state": "closed",
        "user": "zHaOshuAnGye",
        "closed_by": "zHaOshuAnGye",
        "created_at": "2022-01-12T06:10:43+00:00",
        "updated_at": "2022-09-20T12:29:45+00:00",
        "closed_at": "2022-01-12T06:25:36+00:00",
        "comments_count": [
            "yt605155624",
            "zHaOshuAnGye",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1318,
        "title": "speedyspeech inference 函数优化",
        "body": "see https://github.com/PaddlePaddle/PaddleSpeech/pull/1302#discussion_r782736012",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-12T06:54:38+00:00",
        "updated_at": "2022-01-12T08:31:36+00:00",
        "closed_at": "2022-01-12T07:31:40+00:00",
        "comments_count": [],
        "labels": [
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1325
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1326
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1320,
        "title": "[CLI] Need unit test for cli for r0.1.1",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-12T07:22:04+00:00",
        "updated_at": "2022-01-12T07:31:39+00:00",
        "closed_at": "2022-01-12T07:31:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1331
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1324,
        "title": "[tts] vocoder - WaveRNN",
        "body": "reference to https://github.com/PaddlePaddle/Parakeet/pull/99",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-01-12T07:43:45+00:00",
        "updated_at": "2022-02-08T13:13:57+00:00",
        "closed_at": "2022-02-08T13:13:57+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1323,
        "title": "[speechx] speech inference base architecture",
        "body": "- [x] dir tree\r\n- [x] cmakefile\r\n- [x] absl\r\n- [x] kaldi deps",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-12T07:35:53+00:00",
        "updated_at": "2022-01-24T11:54:15+00:00",
        "closed_at": "2022-01-24T11:54:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1352
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1338,
        "title": "[tts] fastspeech2 aishell3 动转静报错",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/dae6bea546dc2123eb7c3f76661bb152efb96167/paddlespeech/t2s/exps/synthesize_e2e.py#L160-L164\r\n我想要导出fastspeech2的多人静态模型，然后把下面的单人模型的动转静代码复制了过来，但是导出静态模型的时候报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 350, in <module>\r\n    main()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 346, in main\r\n    evaluate(args)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 232, in evaluate\r\n    mel = am_inference(part_phone_ids, spk_id)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/io.py\", line 1274, in __i_m_p_l__\r\n    return _run_dygraph(self, input, program_holder)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/io.py\", line 766, in _run_dygraph\r\n    var.name = program_holder.input_descs[i].name()\r\nIndexError: list index out of range\r\n```",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "zh794390558",
        "created_at": "2022-01-13T08:47:16+00:00",
        "updated_at": "2022-01-18T04:53:36+00:00",
        "closed_at": "2022-01-18T04:53:36+00:00",
        "comments_count": [
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo",
            "jerryuhoo",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "jerryuhoo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1342,
        "title": "We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.",
        "body": "您好，谢谢，很好的项目。\r\n\r\n我发现语音识别时有的音频会报错。请问这是什么原因导致的呢。\r\n\r\n代码：\r\n```\r\nfor file in file_list:  # file是wav文件 大约20s\r\n    # 语音识别\r\n    text = asr_executor(\r\n        model='conformer_wenetspeech',\r\n        lang='zh',\r\n        sample_rate=16000,\r\n        config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n        ckpt_path=None,\r\n        audio_file= dir_name+'/'+file,\r\n        force_yes=False,\r\n        device='cpu')\r\n\r\n```\r\n\r\n\r\n报错：\r\n```\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n/tmp/ipykernel_24717/43460022.py in <module>\r\n      7 \r\n      8     # 语音识别\r\n----> 9     text = asr_executor(\r\n     10         model='conformer_wenetspeech',\r\n     11         lang='zh',\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py in __call__(self, audio_file, model, lang, sample_rate, config, ckpt_path, force_yes, device)\r\n    447         self._check(audio_file, sample_rate, force_yes)\r\n    448         paddle.set_device(device)\r\n--> 449         self._init_from_path(model, lang, sample_rate, config, ckpt_path)\r\n    450         self.preprocess(model, audio_file)\r\n    451         self.infer(model)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py in _init_from_path(self, model_type, lang, sample_rate, cfg_path, ckpt_path)\r\n    204         model_conf = self.config.model\r\n    205         logger.info(model_conf)\r\n--> 206         model = model_class.from_config(model_conf)\r\n    207         self.model = model\r\n    208         self.model.eval()\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py in from_config(cls, configs)\r\n    915             nn.Layer: U2Model\r\n    916         \"\"\"\r\n--> 917         model = cls(configs)\r\n    918         return model\r\n    919 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py in __init__(self, configs)\r\n    831 class U2Model(U2DecodeModel):\r\n    832     def __init__(self, configs: dict):\r\n--> 833         vocab_size, encoder, decoder, ctc = U2Model._init_from_config(configs)\r\n    834 \r\n    835         model_conf = configs.get('model_conf', dict())\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py in _init_from_config(cls, configs)\r\n    877                 input_dim, global_cmvn=global_cmvn, **configs['encoder_conf'])\r\n    878         elif encoder_type == 'conformer':\r\n--> 879             encoder = ConformerEncoder(\r\n    880                 input_dim, global_cmvn=global_cmvn, **configs['encoder_conf'])\r\n    881         else:\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/modules/encoder.py in __init__(self, input_size, output_size, attention_heads, linear_units, num_blocks, dropout_rate, positional_dropout_rate, attention_dropout_rate, input_layer, pos_enc_layer_type, normalize_before, concat_after, static_chunk_size, use_dynamic_chunk, global_cmvn, use_dynamic_left_chunk, positionwise_conv_kernel_size, macaron_style, selfattention_layer_type, activation_type, use_cnn_module, cnn_module_kernel, causal, cnn_module_norm)\r\n    458         \"\"\"\r\n    459         assert check_argument_types()\r\n--> 460         super().__init__(input_size, output_size, attention_heads, linear_units,\r\n    461                          num_blocks, dropout_rate, positional_dropout_rate,\r\n    462                          attention_dropout_rate, input_layer,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/modules/encoder.py in __init__(self, input_size, output_size, attention_heads, linear_units, num_blocks, dropout_rate, positional_dropout_rate, attention_dropout_rate, input_layer, pos_enc_layer_type, normalize_before, concat_after, static_chunk_size, use_dynamic_chunk, global_cmvn, use_dynamic_left_chunk)\r\n    126             odim=output_size,\r\n    127             dropout_rate=dropout_rate,\r\n--> 128             pos_enc_class=pos_enc_class(\r\n    129                 d_model=output_size, dropout_rate=positional_dropout_rate), )\r\n    130 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/modules/embedding.py in __init__(self, d_model, dropout_rate, max_len)\r\n    148             max_len (int, optional): [Maximum input length.]. Defaults to 5000.\r\n    149         \"\"\"\r\n--> 150         super().__init__(d_model, dropout_rate, max_len, reverse=True)\r\n    151 \r\n    152     def forward(self, x: paddle.Tensor,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddlespeech/s2t/modules/embedding.py in __init__(self, d_model, dropout_rate, max_len, reverse)\r\n     88         self.d_model = d_model\r\n     89         self.max_len = max_len\r\n---> 90         self.xscale = paddle.to_tensor(math.sqrt(self.d_model))\r\n     91         self.dropout = nn.Dropout(p=dropout_rate)\r\n     92         self.pe = paddle.zeros([self.max_len, self.d_model])  #[T,D]\r\n\r\n<decorator-gen-250> in to_tensor(data, dtype, place, stop_gradient)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py in __impl__(func, *args, **kwargs)\r\n     23     def __impl__(func, *args, **kwargs):\r\n     24         wrapped_func = decorator_func(func)\r\n---> 25         return wrapped_func(*args, **kwargs)\r\n     26 \r\n     27     return __impl__\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/framework.py in __impl__(*args, **kwargs)\r\n    225 def _dygraph_only_(func):\r\n    226     def __impl__(*args, **kwargs):\r\n--> 227         assert in_dygraph_mode(\r\n    228         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\r\n    229         return func(*args, **kwargs)\r\n\r\nAssertionError: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\r\n```",
        "state": "closed",
        "user": "zHaOshuAnGye",
        "closed_by": "zHaOshuAnGye",
        "created_at": "2022-01-13T13:04:25+00:00",
        "updated_at": "2022-01-18T02:34:48+00:00",
        "closed_at": "2022-01-18T02:34:48+00:00",
        "comments_count": [
            "zh794390558",
            "zHaOshuAnGye",
            "zh794390558",
            "zHaOshuAnGye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1344,
        "title": "Voice time limit",
        "body": "In the process of speech recognition, the length of a single input audio cannot exceed 1 minute. What is the reason?\r\n",
        "state": "closed",
        "user": "xbsdsongnan",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-14T07:59:41+00:00",
        "updated_at": "2022-04-14T15:32:32+00:00",
        "closed_at": "2022-04-14T15:32:32+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1353,
        "title": "The version between the setup.py and __init__.py is not synchronized.",
        "body": "The version in setup.py is 0.1.1, but the version in __init.py is 0.1.0.",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "yt605155624",
        "created_at": "2022-01-17T03:17:46+00:00",
        "updated_at": "2022-01-17T07:33:21+00:00",
        "closed_at": "2022-01-17T07:33:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1348,
        "title": "[tts] repeat api",
        "body": "主要是为了解决 https://github.com/PaddlePaddle/PaddleSpeech/issues/1345\r\n在训练的时候用 numpy 版本的实现，速度会变快，但是在预测的时候由于需要动转静，一定要用到 paddle.Tensor 的实现，速度会变慢\r\nsee https://github.com/PaddlePaddle/Paddle/issues/37227\r\nsee https://github.com/tensorflow/tensorflow/blob/v2.7.0/tensorflow/python/ops/array_ops.py#L6622-L6673",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-14T11:00:44+00:00",
        "updated_at": "2022-04-22T10:36:03+00:00",
        "closed_at": "2022-04-22T10:36:03+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1346,
        "title": "[asr]未找到augment.json的使用方式",
        "body": "[asr]未找到augment.json的使用方式",
        "state": "closed",
        "user": "kejom-ou",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-14T10:21:26+00:00",
        "updated_at": "2022-04-14T15:32:33+00:00",
        "closed_at": "2022-04-14T15:32:33+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1345,
        "title": "expand 函数直接用 tensor 处理而不是 numpy 处理导致 fastspeech2 和 speedyspeech 训练 ips 变慢",
        "body": "see paddle issue  https://github.com/PaddlePaddle/Paddle/issues/38957",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-01-14T10:07:46+00:00",
        "updated_at": "2022-01-17T08:11:27+00:00",
        "closed_at": "2022-01-17T08:11:27+00:00",
        "comments_count": [
            "yt605155624",
            "jerryuhoo",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1351,
        "title": "应用技术问题",
        "body": "想用SPEECH的语音转文字功能实现即时的会议发言转成文字功能，请问咱们这个技术可以实现吗？有相关的DEMO吗？",
        "state": "closed",
        "user": "apmosquito",
        "closed_by": "yt605155624",
        "created_at": "2022-01-15T02:26:11+00:00",
        "updated_at": "2022-04-22T10:44:27+00:00",
        "closed_at": "2022-04-22T10:44:27+00:00",
        "comments_count": [
            "zh794390558",
            "Jackwaterveg",
            "apmosquito",
            "Jackwaterveg",
            "qthui6",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1355,
        "title": "[CLI] ASR, Add DeepSpeech2 online and offline model",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-17T08:25:21+00:00",
        "updated_at": "2022-01-17T11:29:30+00:00",
        "closed_at": "2022-01-17T11:29:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1357,
        "title": "[ASR] deprecate the collators in deepspeech2 models",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-17T11:29:45+00:00",
        "updated_at": "2022-01-24T12:14:38+00:00",
        "closed_at": "2022-01-24T12:14:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1358,
        "title": "[speechx] core engine, kaldi style",
        "body": null,
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-17T12:00:18+00:00",
        "updated_at": "2022-01-24T11:55:20+00:00",
        "closed_at": "2022-01-24T11:55:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1367
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1359,
        "title": "[speechx] PaddleInference ds2",
        "body": "- [x] linear feat \r\n- [x] thread pool  #1400 \r\n- [x] queue for wav, frames, hiddens and so on.\r\n- [x] decodeable interface\r\n- [x] paddle infererence\r\n- [x] ctcdecoder online (swig_decoder)",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-17T12:01:52+00:00",
        "updated_at": "2022-03-17T02:35:22+00:00",
        "closed_at": "2022-03-17T02:35:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1365,
        "title": "[Others] g2p issues",
        "body": "![image](https://user-images.githubusercontent.com/87408988/150277714-66d59022-d4f2-43c9-8453-57820db5228a.png)\r\n",
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "yt605155624",
        "created_at": "2022-01-20T05:14:54+00:00",
        "updated_at": "2022-01-20T08:37:36+00:00",
        "closed_at": "2022-01-20T05:45:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1368,
        "title": "[server] tts server",
        "body": "python tts server\r\n\r\n- speedyspeech/fastspeech2\r\n- pwgan/melgan/mbmelgan/hifigan\r\n\r\npython| paddleinference",
        "state": "closed",
        "user": "lym0302",
        "closed_by": "zh794390558",
        "created_at": "2022-01-20T10:52:30+00:00",
        "updated_at": "2022-03-09T11:06:48+00:00",
        "closed_at": "2022-03-09T11:06:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1372,
        "title": "ASRencode return different shape ",
        "body": "I fellow `paddlespeech/s2t/exps/u2/bin/test_wav.py` load model. \r\nI want to get ARS encode result. But it return  different type. \r\nEX: input size is [32, 453, 80]， after encoder  turns to [32, 112, 256]\r\nHow to keep same size?  ",
        "state": "closed",
        "user": "bingyulab",
        "closed_by": "bingyulab",
        "created_at": "2022-01-21T10:01:02+00:00",
        "updated_at": "2022-01-24T03:31:26+00:00",
        "closed_at": "2022-01-24T03:31:26+00:00",
        "comments_count": [
            "zh794390558",
            "bingyulab",
            "zh794390558",
            "bingyulab"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1369,
        "title": "[server] asr server",
        "body": "\r\n- deepspeech2\r\n- conformer\r\n- transformer\r\n\r\npython | paddle_inference\r\n",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-01-21T03:22:13+00:00",
        "updated_at": "2022-03-09T11:07:01+00:00",
        "closed_at": "2022-03-09T11:07:01+00:00",
        "comments_count": [
            "lidh15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1393,
        "title": "[vector] Add voxceleb recipe",
        "body": null,
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-01-26T10:16:23+00:00",
        "updated_at": "2022-01-28T04:31:22+00:00",
        "closed_at": "2022-01-28T04:31:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1373,
        "title": "请问有没有男生的数据集连接呢？",
        "body": null,
        "state": "closed",
        "user": "FeiNoLabel",
        "closed_by": "stale[bot]",
        "created_at": "2022-01-22T05:09:02+00:00",
        "updated_at": "2022-04-14T15:32:30+00:00",
        "closed_at": "2022-04-14T15:32:30+00:00",
        "comments_count": [
            "yt605155624",
            "FeiNoLabel",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1377,
        "title": "[tts] will vits support",
        "body": "[speech] will vits support ? an e2e tts model based on transformer?",
        "state": "closed",
        "user": "lucasjinreal",
        "closed_by": "yt605155624",
        "created_at": "2022-01-24T07:42:49+00:00",
        "updated_at": "2022-04-22T12:07:48+00:00",
        "closed_at": "2022-04-22T12:07:48+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1387,
        "title": "The package must be rebuilt with conda-build > 2.0.",
        "body": "Hi there, when i follow the install scripts:\r\n---------------------------------------------------\r\n```\r\nInstall the Conda\r\n\r\n#download the miniconda\r\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -P tools/\r\n#install the miniconda\r\nbash tools/Miniconda3-latest-Linux-x86_64.sh -b\r\n#conda init\r\n$HOME/miniconda3/bin/conda init\r\n#use the \"bash\" command to make the conda environment works\r\nbash\r\n#create a conda virtual environment\r\nconda create -y -p tools/venv python=3.7\r\n...\r\n```\r\n---------------------------------------------------\r\nthe `conda create -y -p tools/venv python=3.7` complains:\r\n\r\nPaddingError: Placeholder of length '33' too short in package /home/berg/PaddleSpeech/tools/venv/python.pdb.\r\nThe package must be rebuilt with conda-build > 2.0.\r\n\r\nI'm working in the ubuntu-18.04.6, with CUDA and cuDNN installed.\r\n\r\nIt seems that the something is wrong with miniconda, or something i've missed. ",
        "state": "closed",
        "user": "iamfoolberg",
        "closed_by": "iamfoolberg",
        "created_at": "2022-01-25T15:11:15+00:00",
        "updated_at": "2022-01-26T11:00:22+00:00",
        "closed_at": "2022-01-26T11:00:22+00:00",
        "comments_count": [
            "Jackwaterveg",
            "Jackwaterveg",
            "iamfoolberg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1388,
        "title": "[tts] hifigan vocoder 修改超参数训练报错",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/446e83ad2534bc4e0643edba0b2c730c27d1a205/examples/csmsc/voc5/conf/default.yaml#L31-L32\r\n根据原论文的超参数，我想试试把这两行修改为\r\n```yaml\r\nupsample_scales: [8, 8, 2, 2]         # Upsampling scales. \r\nupsample_kernel_sizes: [16, 16, 4, 4] # Kernel size for upsampling layers. \r\n```\r\n但是报错\r\n```\r\nException in main training loop: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [8, 80, 24] and the shape of Y = [8, 80, 29]. Received [24] in X is not equal to [29] in Y at i:2.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:240)\r\n  [operator < elementwise_sub > error]\r\nTraceback (most recent call last):\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 109, in update\r\n    self.update_core(batch)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/models/hifigan/hifigan_updater.py\", line 100, in update_core\r\n    mel_loss = self.criterion_mel(wav_, wav)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/modules/losses.py\", line 923, in forward\r\n    mel_loss = F.l1_loss(mel_hat, mel)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/nn/functional/loss.py\", line 690, in l1_loss\r\n    unreduced = _elementwise_op_in_dygraph(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 229, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layers/nn.py\", line 206, in _elementwise_op_in_dygraph\r\n    out = op(x, y, 'axis', axis, 'use_mkldnn', use_mkldnn)\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 275, in <module>\r\n    main()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 271, in main\r\n    train_sp(args, config)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 239, in train_sp\r\n    trainer.run()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 109, in update\r\n    self.update_core(batch)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/models/hifigan/hifigan_updater.py\", line 100, in update_core\r\n    mel_loss = self.criterion_mel(wav_, wav)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/modules/losses.py\", line 923, in forward\r\n    mel_loss = F.l1_loss(mel_hat, mel)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/nn/functional/loss.py\", line 690, in l1_loss\r\n    unreduced = _elementwise_op_in_dygraph(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 229, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layers/nn.py\", line 206, in _elementwise_op_in_dygraph\r\n    out = op(x, y, 'axis', axis, 'use_mkldnn', use_mkldnn)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [8, 80, 24] and the shape of Y = [8, 80, 29]. Received [24] in X is not equal to [29] in Y at i:2.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:240)\r\n  [operator < elementwise_sub > error]\r\n```",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "jerryuhoo",
        "created_at": "2022-01-26T03:29:17+00:00",
        "updated_at": "2022-01-26T06:08:14+00:00",
        "closed_at": "2022-01-26T06:08:14+00:00",
        "comments_count": [
            "jerryuhoo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1384,
        "title": "[tts] StyleFastSpeech2Inference 改进/动转静问题",
        "body": "之前StyleFastSpeech2Inference遇到动转静报错 #1338\r\n我发现好像原因是在StyleFastSpeech2Inference里调用了两次模型，可能是报错的原因？然后我觉得可以改进一下，直接在_forward里面完成对duration，energy，pitch的变化，尝试改进如下：\r\nhttps://github.com/jerryuhoo/PaddleSpeech/commit/c3336e6e06b69de554ae3387092cd83a0cfe4990\r\n但是有两个问题，一个是robot好像效果不是很明显？还有一个问题是动转静依然会报错，\r\n动转静的代码为：\r\n```python\r\nam_inference = jit.to_static(\r\n    am_inference,\r\n    input_spec=[\r\n        InputSpec([-1], dtype=paddle.int64), # text\r\n        None,\r\n        InputSpec([1], dtype=paddle.float32),\r\n        InputSpec([1], dtype=paddle.float32),\r\n        None,\r\n        InputSpec([1], dtype=paddle.float32),\r\n        InputSpec([1], dtype=paddle.float32),\r\n        None,\r\n        InputSpec([1], dtype=paddle.float32),\r\n        InputSpec([1], dtype=paddle.float32),\r\n        InputSpec([1], dtype=paddle.bool),\r\n        None,\r\n        None,\r\n    ]\r\n)\r\n```\r\n报错信息为：\r\n```\r\nTraceback (most recent call last):\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 415, in <module>\r\n    main()\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 411, in main\r\n    evaluate(args)\r\n  File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 281, in evaluate\r\n    mel = am_inference(part_phone_ids, None, 1.0, None , None, 1.3, None, None, 1, None, True, None, None)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 376, in __call__\r\n    error_data.raise_new_exception()\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 336, in raise_new_exception\r\n    six.exec_(\"raise new_exception from None\")\r\n  File \"<string>\", line 1, in <module>\r\nRuntimeError: In transformed code:\r\n\r\n    File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 1020, in forward\r\n        normalized_mel, d_outs, p_outs, e_outs = self.acoustic_model.inference(\r\n    File \"/workspace/code/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 823, in inference\r\n        else:\r\n            # (1, L, odim)\r\n            _, outs, d_outs, p_outs, e_outs = self._forward(\r\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n                xs,\r\n                ilens,\r\n\r\n    File \"/tmp/tmpbj7svjlf.py\", line 243, in _forward\r\n        d_outs, e_embs, e_outs, hs, p_embs, p_outs = (paddle.jit.dy2static.\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n        out = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 271, in _run_py_ifelse\r\n        return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/tmp/tmpbj7svjlf.py\", line 204, in true_fn_23\r\n        p_outs = paddle.jit.dy2static.convert_ifelse(robot, true_fn_22,\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 208, in convert_ifelse\r\n        out = _run_paddle_cond(pred, true_fn, false_fn, true_args, false_args,\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 266, in _run_paddle_cond\r\n        return control_flow.cond(pred, lambda: true_fn(*true_args),\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layers/control_flow.py\", line 2468, in cond\r\n        mask = cast(pred, dtype='int32')\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layers/tensor.py\", line 264, in cast\r\n        helper.append_op(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n        return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3178, in append_op\r\n        op = Operator(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2224, in __init__\r\n        for frame in traceback.extract_stack():\r\n\r\n    PreconditionNotMetError: The tensor of Input(X) is not initialized.\r\n      [Hint: Expected tensor->IsInitialized() == true, but received tensor->IsInitialized():0 != true:1.] (at /paddle/paddle/fluid/operators/cast_op.cc:78)\r\n      [operator < cast > error]  [operator < run_program > error]\r\n\r\n    Revise suggestion: \r\n        1. Please ensure all your sublayers are inheritted from nn.Layer.\r\n        2. Please ensure there is no tensor created explicitly depended on external data, we suggest to register it as buffer tensor. See https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/04_dygraph_to_static/export_model/principle_cn.html#parameters-buffers for details\r\n```",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "jerryuhoo",
        "created_at": "2022-01-25T02:44:06+00:00",
        "updated_at": "2022-01-25T08:38:29+00:00",
        "closed_at": "2022-01-25T08:38:28+00:00",
        "comments_count": [
            "yt605155624",
            "jerryuhoo",
            "yt605155624",
            "jerryuhoo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1402,
        "title": "[ASR] cli support ds2-librispeech offline",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "yt605155624",
        "created_at": "2022-01-27T06:00:12+00:00",
        "updated_at": "2022-01-27T12:28:13+00:00",
        "closed_at": "2022-01-27T12:28:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1395,
        "title": "ERROR: ImportError: cannot import name '__version__' from 'paddlespeech' ",
        "body": "Hi there, when i managed to execute the demo command:\r\n`(/home/berg/PaddleSpeech/tools/venvs) root@bergtts:~/PaddleSpeech# paddlespeech tts --input \"你好，欢迎使用飞桨深度学习框架！\" --output output.wav`\r\n\r\nit complains the following error.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/berg/PaddleSpeech/tools/venvs/bin/paddlespeech\", line 33, in <module>\r\n    sys.exit(load_entry_point('paddlespeech', 'console_scripts', 'paddlespeech')())\r\n  File \"/home/berg/PaddleSpeech/tools/venvs/bin/paddlespeech\", line 25, in importlib_load_entry_point\r\n    return next(matches).load()\r\n  File \"/home/berg/PaddleSpeech/tools/venvs/lib/python3.7/site-packages/importlib_metadata/__init__.py\", line 167, in load\r\n    module = import_module(match.group('module'))\r\n  File \"/home/berg/PaddleSpeech/tools/venvs/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/berg/PaddleSpeech/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/home/berg/PaddleSpeech/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/home/berg/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 30, in <module>\r\n    from ..utils import cli_register\r\n  File \"/home/berg/PaddleSpeech/paddlespeech/cli/utils.py\", line 33, in <module>\r\n    from .. import __version__\r\nImportError: cannot import name '__version__' from 'paddlespeech' (/home/berg/PaddleSpeech/paddlespeech/__init__.py)\r\n\r\n```\r\nAfter installing miniconda in ubuntu 18.04.3, i changed to root, and go on creating the venvs and executing pip installs...\r\n`#conda create -y -p tools/venvs python=3.7 `\r\n",
        "state": "closed",
        "user": "iamfoolberg",
        "closed_by": "zh794390558",
        "created_at": "2022-01-26T10:58:21+00:00",
        "updated_at": "2022-01-27T03:00:03+00:00",
        "closed_at": "2022-01-27T03:00:03+00:00",
        "comments_count": [
            "iamfoolberg"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1408
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1403,
        "title": "[TTS] add new version tacotron2 in ljspeech",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-01-27T06:06:42+00:00",
        "updated_at": "2022-02-08T12:20:39+00:00",
        "closed_at": "2022-02-08T12:20:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1404,
        "title": "[TTS]日语语音合成 JSUT 上的 fastspeech2",
        "body": "日语学习资料：\r\n1. https://jp.hjenglish.com/subject/pronounce/\r\n2. https://easypronunciation.com/zh/japanese-kanji-to-romaji-converter （使用罗马音查）\r\n3. https://hts.sp.nitech.ac.jp/",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-01-27T06:06:46+00:00",
        "updated_at": "2022-04-22T10:37:02+00:00",
        "closed_at": "2022-04-22T10:37:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1418,
        "title": "[TTS] update voice cloning  of tacotron2 with  aishell3 dataset",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-01-29T07:30:26+00:00",
        "updated_at": "2022-02-08T12:13:33+00:00",
        "closed_at": "2022-02-08T12:13:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1397,
        "title": "安装PaddleSpeech相关问题讨论（Windows）",
        "body": "无论使用怎样的安装方法，所需的C++也安装了，总是报错：\r\n\r\nFailed to build pyworld webrtcvad bottleneck\r\nERROR: Could not build wheels for pyworld, bottleneck, which is required to install pyproject.toml-based projects\r\n\r\n网上找了各种方法都不成功，诚心求教！\r\n",
        "state": "closed",
        "user": "qibinran",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-27T01:20:07+00:00",
        "updated_at": "2023-08-25T12:24:50+00:00",
        "closed_at": "2022-02-05T02:44:00+00:00",
        "comments_count": [
            "Jackwaterveg",
            "qibinran",
            "qibinran",
            "qibinran",
            "Jackwaterveg",
            "Jackwaterveg",
            "qibinran",
            "Jackwaterveg",
            "qibinran",
            "qibinran",
            "qibinran",
            "qibinran",
            "Jackwaterveg",
            "Jackwaterveg",
            "qibinran",
            "qibinran",
            "yt605155624",
            "Jackwaterveg",
            "Jackwaterveg",
            "Jackwaterveg",
            "qibinran",
            "qibinran",
            "Jackwaterveg",
            "qibinran",
            "Jackwaterveg",
            "qibinran",
            "Jackwaterveg",
            "qibinran",
            "yt605155624",
            "qibinran",
            "qibinran",
            "qibinran",
            "qibinran",
            "yt605155624",
            "qibinran",
            "qibinran",
            "qibinran",
            "qibinran",
            "Jackwaterveg",
            "zh794390558"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1406,
        "title": "Blocking queue is killed because the data reader raises an exception",
        "body": "File \"make_manifest1.py\", line 201, in compute_mean_std\r\n    num_workers=num_workers)\r\n  File \"/home/qzh/py_project/PPASR-master/ppasr/data_utils/normalizer.py\", line 38, in __init__\r\n    self._compute_mean_std(manifest_path, num_samples, num_workers)\r\n  File \"/home/qzh/py_project/PPASR-master/ppasr/data_utils/normalizer.py\", line 81, in _compute_mean_std\r\n    for std1, means1, number1 in tqdm(test_loader()):\r\n  File \"/root/anaconda3/envs/yuyin/lib/python3.7/site-packages/tqdm/std.py\", line 1178, in __iter__\r\n    for obj in iterable:\r\n  File \"/root/anaconda3/envs/yuyin/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 779, in __next__\r\n    data = self._reader.read_next_var_list()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:158)\r\n\r\n\r\nlinux\r\npaddlepaddle-gpu==2.0.2.post100",
        "state": "closed",
        "user": "skyriver1",
        "closed_by": "skyriver1",
        "created_at": "2022-01-27T06:43:30+00:00",
        "updated_at": "2022-01-27T07:11:56+00:00",
        "closed_at": "2022-01-27T07:11:56+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1423
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1410,
        "title": "jit.to_static 没有效果",
        "body": "注释掉paddlespeech/t2s/exps/synthesize_e2e.py中jit.to_static 相关代码，运行时间无明显变化。Why?",
        "state": "closed",
        "user": "sharingTSU",
        "closed_by": "yt605155624",
        "created_at": "2022-01-27T10:54:28+00:00",
        "updated_at": "2022-04-22T09:38:17+00:00",
        "closed_at": "2022-04-22T09:38:17+00:00",
        "comments_count": [
            "yt605155624",
            "sharingTSU",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1434
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1433
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1420,
        "title": "请提供TTS的python代码好吗",
        "body": " #1047提供了ASR的python代码，也请提供一下TTS的python代码好吗？ #1047",
        "state": "closed",
        "user": "qibinran",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-01-30T14:46:28+00:00",
        "updated_at": "2022-02-05T03:29:07+00:00",
        "closed_at": "2022-02-05T03:29:07+00:00",
        "comments_count": [
            "yt605155624",
            "qibinran"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1421,
        "title": "Ubuntu18.04root源码安装Hard PaddleSpeech出错",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nUbuntu18.04+Nidia Driver470.82.00+cuda11.2+cudnn8\r\nconda 4.11.0+paddle_env3.7\r\npaddle2.2\r\neverything be essential for install paddleSpeech is ok \r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to dir 'PaddleSpeech'\r\n2. run  'pip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple'\r\n3. See error\r\n\r\n**Expected behavior**\r\nERROR: Command errored out with exit status 1:\r\n     command: /home/DBL/anaconda3/envs/paddle_env/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/DBL/MyProject/Project/PaddleSpeech/setup.py'\"'\"'; __file__='\"'\"'/home/DBL/MyProject/Project/PaddleSpeech/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /home/DBL/MyProject/Project/PaddleSpeech/\r\n    Complete output (61 lines):\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /home/DBL/anaconda3/envs/paddle_env/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n    Adding paddlespeech 0.1.1 to easy-install.pth file\r\n    Installing paddlespeech script to /home/DBL/anaconda3/envs/paddle_env/bin\r\n    \r\n    Installed /home/DBL/MyProject/Project/PaddleSpeech\r\n    Post Install...\r\n    apt update -y\r\n    \r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n    \r\n    Reading package lists...\r\n    E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\r\n    E: Unable to lock directory /var/lib/apt/lists/\r\n    W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\r\n    W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\r\n    Makefile:27: recipe for target 'apt.done' failed\r\n    make: *** [apt.done] Error 100\r\n    /home/DBL/anaconda3/envs/paddle_env/lib/python3.7/site-packages/setuptools/dist.py:720: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n      % (opt, underscore_opt)\r\n    /home/DBL/anaconda3/envs/paddle_env/lib/python3.7/site-packages/setuptools/dist.py:720: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n      % (opt, underscore_opt)\r\n    /home/DBL/MyProject/Project/PaddleSpeech/setup.py:130: CMD: make, Error: None\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/home/DBL/MyProject/Project/PaddleSpeech/setup.py\", line 259, in <module>\r\n        setup(**setup_info)\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/DBL/MyProject/Project/PaddleSpeech/setup.py\", line 160, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/distutils/cmd.py\", line 335, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/distutils/util.py\", line 291, in execute\r\n        func(*args)\r\n      File \"/home/DBL/MyProject/Project/PaddleSpeech/setup.py\", line 146, in _post_install\r\n        check_call(\"make\")\r\n      File \"/home/DBL/MyProject/Project/PaddleSpeech/setup.py\", line 133, in check_call\r\n        raise e\r\n      File \"/home/DBL/MyProject/Project/PaddleSpeech/setup.py\", line 127, in check_call\r\n        executable=\"/bin/bash\" if shell else executable)\r\n      File \"/home/DBL/anaconda3/envs/paddle_env/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    /home/DBL/MyProject/Project/PaddleSpeech/tools\r\n    ----------------------------------------\r\n  Rolling back uninstall of paddlespeech\r\n  Moving to /home/DBL/anaconda3/envs/paddle_env/bin/paddlespeech\r\n   from /tmp/pip-uninstall-4cfsmdx1/paddlespeech\r\n  Moving to /home/DBL/anaconda3/envs/paddle_env/lib/python3.7/site-packages/paddlespeech.egg-link\r\n   from /tmp/pip-uninstall-ahl4tbc0/paddlespeech.egg-link\r\nERROR: Command errored out with exit status 1: /home/DBL/anaconda3/envs/paddle_env/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/DBL/MyProject/Project/PaddleSpeech/setup.py'\"'\"'; __file__='\"'\"'/home/DBL/MyProject/Project/PaddleSpeech/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\r\n```\r\n\r\n\r\n**Screenshots**\r\n![Error1](https://user-images.githubusercontent.com/45030098/152520969-ccba7fe3-8927-4e55-8c38-659d77423941.png)\r\n![Error2](https://user-images.githubusercontent.com/45030098/152520992-aa00dad8-7b6e-4b04-ade7-52db0c3b4b3e.png)\r\n\r\n\r\n** Environment (please complete the following information):**\r\n - OS: Ubuntu18.04\r\n - GCC/G++ Version:7.5.0\r\n - Python Version:3.7(in conda virtual env)\r\n - PaddlePaddle Version:2.2.0\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Information:nvidia1660ti+Driver:470.82\r\n - CUDA/CUDNN Version:cuda-11.2+cudnn8\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\n安装说需要root权限,我具备这个权限,但我安装paddleSpeech想使用普通使用者权限.\r\n我应该怎么做去成功安装他\r\n",
        "state": "closed",
        "user": "ccbptm",
        "closed_by": "yt605155624",
        "created_at": "2022-02-04T11:26:30+00:00",
        "updated_at": "2022-04-22T10:36:50+00:00",
        "closed_at": "2022-04-22T10:36:50+00:00",
        "comments_count": [
            "ccbptm",
            "Jackwaterveg",
            "ccbptm",
            "ccbptm",
            "Jackwaterveg",
            "ccbptm",
            "Jackwaterveg",
            "Jackwaterveg",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1424,
        "title": "安装PaddleSpeech一直失败",
        "body": "用的是aistudio的notebook环境\r\n会失败两次，第一次提示Permission denied 第二次提示版本冲突\r\n![微信截图_20220207115041](https://user-images.githubusercontent.com/54951765/152722023-138bfd8d-abba-446e-8e22-1017fd26e5ae.png)\r\n![微信截图_20220207115214](https://user-images.githubusercontent.com/54951765/152722052-4a7e3333-2987-4d2a-9224-4b839f360750.png)\r\n\r\n",
        "state": "closed",
        "user": "kslz",
        "closed_by": "kslz",
        "created_at": "2022-02-07T03:54:26+00:00",
        "updated_at": "2022-02-11T02:25:28+00:00",
        "closed_at": "2022-02-11T02:20:57+00:00",
        "comments_count": [
            "Jackwaterveg",
            "Jackwaterveg",
            "kslz",
            "kslz",
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1426,
        "title": "TypeError: resample() takes 1 positional argument but 3 were given",
        "body": "ENV\r\nUbuntu 18.04.6 LTS\r\npaddleaudio               0.1.0                    pypi_0    pypi\r\npaddlenlp                 2.2.4                    pypi_0    pypi\r\npaddlepaddle              2.2.2                    pypi_0    pypi\r\npaddlespeech              0.1.1                    pypi_0    pypi\r\npaddlespeech-ctcdecoders  0.1.1                    pypi_0    pypi\r\npaddlespeech-feat         0.1.0                    pypi_0    pypi\r\n\r\nI dont know why the same code and env can run on another server.\r\n\r\n\r\n[2022-02-08 16:25:19,939] [   ERROR] - resample() takes 1 positional argument but 3 were given\r\nTraceback (most recent call last):\r\n  File \"/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 414, in execute\r\n    decode_method, force_yes, device)\r\n  File \"/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 335, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 439, in __call__\r\n    self.preprocess(model, audio_file)\r\n  File \"/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 256, in preprocess\r\n    self.sample_rate)\r\nTypeError: resample() takes 1 positional argument but 3 were given\r\n\r\n\r\n",
        "state": "closed",
        "user": "tianrking",
        "closed_by": "yt605155624",
        "created_at": "2022-02-08T08:28:20+00:00",
        "updated_at": "2022-02-10T06:34:38+00:00",
        "closed_at": "2022-02-10T06:34:38+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1456
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1457
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1435,
        "title": "TypeError: resample() takes 1 positional argument but 3 were given",
        "body": "### Input\r\n`paddlespeech asr --model transformer_librispeech --lang en --input ./output_from_your_TTS_code.wav `\r\n### Log\r\n`[2022-02-10 14:53:08,504] [    INFO] - checking the audio file format......\r\n[2022-02-10 14:53:08,504] [    INFO] - The sample rate is 22050\r\n[2022-02-10 14:53:08,504] [ WARNING] - The sample rate of the input file is not 16000.\r\n                             The program will resample the wav file to 16000.\r\n                             If the result does not meet your expectations，\r\n                             Please input the 16k 16 bit 1 channel wav file.                         \r\n[2022-02-10 14:53:08,504] [    INFO] - Whether to change the sample rate and the channel. Y: change the sample. N: exit the prgream.\r\nInput(Y/N):y\r\n[2022-02-10 14:53:26,614] [    INFO] - change the sampele rate, channel to 16k and 1 channel\r\n[2022-02-10 14:53:26,614] [    INFO] - File /home/xxx/.paddlespeech/models/transformer_librispeech-en-16k/asr1_transformer_librispeech_ckpt_0.1.1.model.tar.gz md5 checking...\r\n[2022-02-10 14:53:27,976] [    INFO] - Use pretrained model stored in: /home/xxx/.paddlespeech/models/transformer_librispeech-en-16k/asr1_transformer_librispeech_ckpt_0.1.1.model.tar\r\n[2022-02-10 14:53:27,976] [    INFO] - /home/xxx/.paddlespeech/models/transformer_librispeech-en-16k/asr1_transformer_librispeech_ckpt_0.1.1.model.tar\r\n[2022-02-10 14:53:27,976] [    INFO] - /home/xxx/.paddlespeech/models/transformer_librispeech-en-16k/asr1_transformer_librispeech_ckpt_0.1.1.model.tar/model.yaml\r\n[2022-02-10 14:53:27,976] [    INFO] - /home/xxx/.paddlespeech/models/transformer_librispeech-en-16k/asr1_transformer_librispeech_ckpt_0.1.1.model.tar/exp/transformer/checkpoints/avg_10.pdparams\r\n[2022-02-10 14:53:29,345] [    INFO] - Preprocess audio_file:/home/xxx/Projects/Paddle-speech/output.wav\r\n[2022-02-10 14:53:29,345] [    INFO] - get the preprocess conf\r\n[2022-02-10 14:53:29,368] [    INFO] - read the audio file\r\n[2022-02-10 14:53:29,369] [   ERROR] - resample() takes 1 positional argument but 3 were given\r\nTraceback (most recent call last):\r\n  File \"/home/xxx/miniconda3/envs/paddle-speech/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 414, in execute\r\n    decode_method, force_yes, device)\r\n  File \"/home/xxx/miniconda3/envs/paddle-speech/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 335, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/xxx/miniconda3/envs/paddle-speech/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 439, in __call__\r\n    self.preprocess(model, audio_file)\r\n  File \"/home/xxx/miniconda3/envs/paddle-speech/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 256, in preprocess\r\n    self.sample_rate)\r\nTypeError: resample() takes 1 positional argument but 3 were given\r\n`\r\n\r\n**In a word, when the audio sample rate is not 8000 or 16000, it has to be resampled to 16000, then a TypeError appears.**\r\n",
        "state": "closed",
        "user": "Nyquist0",
        "closed_by": "Nyquist0",
        "created_at": "2022-02-10T07:05:29+00:00",
        "updated_at": "2022-09-20T12:24:40+00:00",
        "closed_at": "2022-02-10T07:31:45+00:00",
        "comments_count": [
            "yt605155624",
            "Nyquist0"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1458
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1448,
        "title": "你好，请问下有支持模型转换onnx的计划嘛",
        "body": null,
        "state": "closed",
        "user": "Gmgge",
        "closed_by": "Gmgge",
        "created_at": "2022-02-15T00:52:20+00:00",
        "updated_at": "2022-02-16T00:39:39+00:00",
        "closed_at": "2022-02-16T00:39:39+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1438,
        "title": "批量合成语音",
        "body": "请问如何批量合成语音音频呢？\r\n",
        "state": "closed",
        "user": "zcswdt",
        "closed_by": "yt605155624",
        "created_at": "2022-02-11T08:02:17+00:00",
        "updated_at": "2022-04-22T09:36:36+00:00",
        "closed_at": "2022-04-22T09:36:36+00:00",
        "comments_count": [
            "zh794390558",
            "yt605155624",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1455,
        "title": " tts python api 第二次调用还是加载了模型",
        "body": "现在已发布版本 tts python api 第二次调用还是加载了模型，刚才已经修复了问题\r\n原本的条件是，在第一次调用之后，就不用重新加载模型了，但是之前的判断规则写错了，现在已经改好了，\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/ae521d37005736da0c7e6727bbb0140bdf6fbd1d/paddlespeech/cli/tts/infer.py#L434\r\n\r\n可以安装 develop 版本的 PaddleSpeech (clone 仓库后 pip install .) 再看看用 python api 第二次的调用时间\r\n安装最新的 develop ，我使用如下代码在 GPU 上运行结果如下（因为之前调用过，所以模型已经下载好了）\r\n```bash\r\nfrom paddlespeech.cli import TTSExecutor\r\nimport time\r\nimport paddle\r\ntts_executor = TTSExecutor()\r\ntime_1 = time.time()\r\nwav_file = tts_executor(\r\n    text='对数据集进行预处理',\r\n    output='1.wav',\r\n    am='fastspeech2_csmsc',\r\n    am_config=None,\r\n    am_ckpt=None,\r\n    am_stat=None,\r\n    spk_id=0,\r\n    phones_dict=None,\r\n    tones_dict=None,\r\n    speaker_dict=None,\r\n    voc='pwgan_csmsc',\r\n    voc_config=None,\r\n    voc_ckpt=None,\r\n    voc_stat=None,\r\n    lang='zh',\r\n    device=paddle.get_device())\r\ntime_2 = time.time()\r\nprint(\"time of first time:\", time_2-time_1)\r\nwav_file = tts_executor(\r\n    text='你好吗',\r\n    output='2.wav',\r\n    am='fastspeech2_csmsc',\r\n    am_config=None,\r\n    am_ckpt=None,\r\n    am_stat=None,\r\n    spk_id=0,\r\n    phones_dict=None,\r\n    tones_dict=None,\r\n    speaker_dict=None,\r\n    voc='pwgan_csmsc',\r\n    voc_config=None,\r\n    voc_ckpt=None,\r\n    voc_stat=None,\r\n    lang='zh',\r\n    device=paddle.get_device())\r\nprint(\"time of second time:\", time.time()-time_2)\r\n```\r\n```text\r\ntime of first time: 14.119463205337524\r\n[2022-02-17 11:07:20,596] [    INFO] - Models had been initialized.\r\ntime of second time: 0.09334707260131836\r\n```\r\n使用 CPU\r\n```bash\r\nexport CUDA_VISIBLE_DEVICES=\r\n```\r\n结果如下：\r\n```text\r\ntime of first time: 12.853452920913696\r\n[2022-02-17 11:10:51,317] [    INFO] - Models had been initialized.\r\ntime of second time: 1.82204008102417\r\n```\r\n可以发现，使用 CPU 的时间是 1.82s 使用 GPU 的时间是 0.093s, 第一次执行慢是因为需要加载模型\r\n之前的判断条件错了，导致第二次执行还是加载了模型",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-02-17T11:24:15+00:00",
        "updated_at": "2022-04-22T09:36:53+00:00",
        "closed_at": "2022-04-22T09:36:53+00:00",
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1464
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1465
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1461,
        "title": "中英混合怎样处理呢？",
        "body": "大家好。中英混合的情况怎么处理呢？\r\n如：喜欢唱、跳、rap、篮球\r\n结果：https://raw.githubusercontent.com/logerlink/logerlink.github.io/master/page/2022/result.wav\r\nrap 无法读出来了，请问有什么方案吗？或者参考资料\r\n",
        "state": "closed",
        "user": "logerlink",
        "closed_by": "logerlink",
        "created_at": "2022-02-19T09:12:57+00:00",
        "updated_at": "2022-02-21T09:22:36+00:00",
        "closed_at": "2022-02-21T09:22:36+00:00",
        "comments_count": [
            "zh794390558",
            "logerlink"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1462,
        "title": "请问这里的fastspeech2，在推理中能否进行音高、音长和能量的参数设置？",
        "body": "请问这里的fastspeech2，在推理中 能否进行音高、音长和能量的参数设置？具体如何设置呢？",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-02-20T09:49:39+00:00",
        "updated_at": "2022-04-22T09:34:40+00:00",
        "closed_at": "2022-04-22T09:34:40+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1463,
        "title": "安装Deepspeech2 demo失败",
        "body": "在Aiaistudio执行，按照课程步骤执行，失败，\r\n![image](https://user-images.githubusercontent.com/18001708/154837613-93337c59-f8c5-4d33-9bf5-f234fd955bb6.png)\r\n\r\n",
        "state": "closed",
        "user": "stoneLee81",
        "closed_by": "stoneLee81",
        "created_at": "2022-02-20T10:05:20+00:00",
        "updated_at": "2022-02-22T06:04:18+00:00",
        "closed_at": "2022-02-22T06:04:18+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1468,
        "title": "any idea about the error when run \"bash run.sh\"? ",
        "body": "Generate durations.txt from MFA results ...\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/utils/gen_duration_from_textgrid.py\", line 113, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/utils/gen_duration_from_textgrid.py\", line 109, in main\r\n    gen_duration_from_textgrid(inputdir, output, config.fs, config.n_shift)\r\n  File \"/PaddleSpeech/utils/gen_duration_from_textgrid.py\", line 68, in gen_duration_from_textgrid\r\n    list_dir = os.listdir(inputdir)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'baker_alignment_tone'\r\nExtract features ...\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../preprocess.py\", line 292, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../preprocess.py\", line 183, in main\r\n    assert rootdir.is_dir()\r\nAssertionError\r\nGet features' stats ...\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\nNormalize ...\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/dev/raw/metadata.jsonl'\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/test/raw/metadata.jsonl'",
        "state": "closed",
        "user": "everschen",
        "closed_by": "everschen",
        "created_at": "2022-02-21T11:57:29+00:00",
        "updated_at": "2022-02-22T14:45:45+00:00",
        "closed_at": "2022-02-22T14:45:45+00:00",
        "comments_count": [
            "everschen",
            "yt605155624",
            "everschen",
            "yt605155624",
            "everschen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1469,
        "title": "请问paddlespeech支持多语种语音合成吗",
        "body": "multi-lingual and code switch speech synthesis",
        "state": "closed",
        "user": "jiusansan222",
        "closed_by": "yt605155624",
        "created_at": "2022-02-22T02:55:03+00:00",
        "updated_at": "2022-04-22T09:38:38+00:00",
        "closed_at": "2022-04-22T09:38:38+00:00",
        "comments_count": [
            "yt605155624",
            "everschen",
            "yt605155624",
            "everschen",
            "jerryuhoo",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1467,
        "title": "asr --lang de",
        "body": "dear all,\r\ncurrently, asr only supports english or chinese. \r\nCould you please document what needs to be done to add new languages (e.g. german) ?\r\nThankyou \r\nXie Xie.",
        "state": "closed",
        "user": "luto65",
        "closed_by": "yt605155624",
        "created_at": "2022-02-21T08:19:28+00:00",
        "updated_at": "2022-04-22T10:37:19+00:00",
        "closed_at": "2022-04-22T10:37:19+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1473,
        "title": "Deepspeech2语音识别，怎么能断句打标点？",
        "body": "用demo试了下时间长的语音识别，识别出的文本都没有断句标点，这个怎么实现呢？",
        "state": "closed",
        "user": "stoneLee81",
        "closed_by": "stoneLee81",
        "created_at": "2022-02-22T06:05:35+00:00",
        "updated_at": "2022-02-22T13:10:14+00:00",
        "closed_at": "2022-02-22T13:10:14+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1476,
        "title": "ubuntu20.0.4安装PaddleSpeech失败",
        "body": "error: subprocess-exited-with-error\r\n\r\n× python setup.py develop did not run successfully.\r\n│ exit code: 1\r\n╰─> [105 lines of output]\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /usr/local/lib/python3.8/dist-packages/paddlespeech.egg-link (link to .)\r\n    paddlespeech 0.1.1 is already the active version in easy-install.pth\r\n    Installing paddlespeech script to /usr/local/bin\r\n    \r\n    Installed /home/fp/Desktop/PaddleSpeech\r\n    Post Install...\r\n    apt update -y\r\n    \r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n    \r\n    Hit:1 http://us.archive.ubuntu.com/ubuntu focal InRelease\r\n    Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\r\n    Get:3 http://us.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\r\n    Get:4 http://us.archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\r\n    Fetched 336 kB in 3s (132 kB/s)\r\n    Reading package lists...\r\n    Building dependency tree...\r\n    Reading state information...\r\n    211 packages can be upgraded. Run 'apt list --upgradable' to see them.\r\n    apt install -y bc flac jq vim tig tree pkg-config libsndfile1 libflac-dev libogg-dev libvorbis-dev libboost-dev swig python3-dev\r\n    \r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n    \r\n    Reading package lists...\r\n    Building dependency tree...\r\n    Reading state information...\r\n    bc is already the newest version (1.07.1-2build1).\r\n    bc set to manually installed.\r\n    pkg-config is already the newest version (0.29.1-0ubuntu4).\r\n    pkg-config set to manually installed.\r\n    python3-dev is already the newest version (3.8.2-0ubuntu2).\r\n    python3-dev set to manually installed.\r\n    libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\r\n    libsndfile1 set to manually installed.\r\n    The following additional packages will be installed:\r\n      libboost1.71-dev libjq1 libonig5 swig4.0 vim-common vim-runtime vim-tiny\r\n    Suggested packages:\r\n      libboost-doc libboost1.71-doc libboost-atomic1.71-dev\r\n      libboost-chrono1.71-dev libboost-container1.71-dev libboost-context1.71-dev\r\n      libboost-contract1.71-dev libboost-coroutine1.71-dev\r\n      libboost-date-time1.71-dev libboost-exception1.71-dev libboost-fiber1.71-dev\r\n      libboost-filesystem1.71-dev libboost-graph1.71-dev\r\n      libboost-graph-parallel1.71-dev libboost-iostreams1.71-dev\r\n      libboost-locale1.71-dev libboost-log1.71-dev libboost-math1.71-dev\r\n      libboost-mpi1.71-dev libboost-mpi-python1.71-dev libboost-numpy1.71-dev\r\n      libboost-program-options1.71-dev libboost-python1.71-dev\r\n      libboost-random1.71-dev libboost-regex1.71-dev\r\n      libboost-serialization1.71-dev libboost-stacktrace1.71-dev\r\n      libboost-system1.71-dev libboost-test1.71-dev libboost-thread1.71-dev\r\n      libboost-timer1.71-dev libboost-type-erasure1.71-dev libboost-wave1.71-dev\r\n      libboost1.71-tools-dev libmpfrc++-dev libntl-dev swig-doc swig-examples\r\n      swig4.0-examples swig4.0-doc ctags vim-doc vim-scripts indent\r\n    The following NEW packages will be installed:\r\n      flac jq libboost-dev libboost1.71-dev libflac-dev libjq1 libogg-dev libonig5\r\n      libvorbis-dev swig swig4.0 tig tree vim vim-runtime\r\n    The following packages will be upgraded:\r\n      vim-common vim-tiny\r\n    2 upgraded, 15 newly installed, 0 to remove and 209 not upgraded.\r\n    Need to get 121 kB/19.4 MB of archives.\r\n    After this operation, 184 MB of additional disk space will be used.\r\n    **Err:1 http://us.archive.ubuntu.com/ubuntu focal/universe amd64 flac amd64 1.3.3-1build1\r\n      Connection failed [IP: 91.189.91.38 80]\r\n    E: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/universe/f/flac/flac_1.3.3-1build1_amd64.deb  Connection failed [IP: 91.189.91.38 80]\r\n    E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\r\n    make: *** [Makefile:28: apt.done] Error 100\r\n    /home/fp/Desktop/PaddleSpeech/setup.py:130: CMD: make, Error: None**\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 2, in <module>\r\n      File \"<pip-setuptools-caller>\", line 34, in <module>\r\n      File \"/home/fp/Desktop/PaddleSpeech/setup.py\", line 259, in <module>\r\n        setup(**setup_info)\r\n      File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/fp/Desktop/PaddleSpeech/setup.py\", line 160, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/usr/lib/python3.8/distutils/cmd.py\", line 335, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/usr/lib/python3.8/distutils/util.py\", line 303, in execute\r\n        func(*args)\r\n      File \"/home/fp/Desktop/PaddleSpeech/setup.py\", line 146, in _post_install\r\n        check_call(\"make\")\r\n      File \"/home/fp/Desktop/PaddleSpeech/setup.py\", line 133, in check_call\r\n        raise e\r\n      File \"/home/fp/Desktop/PaddleSpeech/setup.py\", line 124, in check_call\r\n        sp.check_call(\r\n      File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    /home/fp/Desktop/PaddleSpeech/tools\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
        "state": "closed",
        "user": "Ironnnnnny",
        "closed_by": "Ironnnnnny",
        "created_at": "2022-02-22T07:46:43+00:00",
        "updated_at": "2023-12-29T13:19:01+00:00",
        "closed_at": "2022-03-01T08:05:13+00:00",
        "comments_count": [
            "Ironnnnnny",
            "zh794390558",
            "Ironnnnnny",
            "Ironnnnnny",
            "zh794390558",
            "happywch"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1487,
        "title": "[ASR] Unit test for ds2 online inference",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-02-25T06:15:59+00:00",
        "updated_at": "2022-02-28T10:03:54+00:00",
        "closed_at": "2022-02-28T10:03:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1478,
        "title": "训练前的一些问题请教",
        "body": "1.Download and Extract\r\nDownload CSMSC from it's [Official Website](https://test.data-baker.com/data/index/source).\r\n这个地址进去会跳转，哪怕登入后进去也会跳转，是不是链接有更新？还是现在不支持下载了呢？\r\n\r\n2. You can download from here [baker_alignment_tone.tar.gz](https://paddlespeech.bj.bcebos.com/MFA/BZNSYP/with_tone/baker_alignment_tone.tar.gz)\r\n这个文件下载后，如果是docker的模式请问放在哪个目录里呢？谢谢\r\n\r\n3.Assume the path to the dataset is ~/datasets/BZNSYP. Assume the path to the MFA result of CSMSC is ./baker_alignment_tone. Run the command below to\r\n\r\nsource path.\r\npreprocess the dataset.\r\ntrain the model.\r\nsynthesize wavs.\r\nsynthesize waveform from metadata.jsonl.\r\nsynthesize waveform from a text file.\r\ninference using the static model.\r\n\r\n./run.sh \r\n请问这个run.sh是保护了上面从source path开始的所有行为吗？\r\n~/datasets/BZNSYP 请问这里面放哪些dataset呢？\r\nAssume the path to the MFA result of CSMSC is ./baker_alignment_tone 是指和run.sh相同目录吗？\r\n\r\n谢谢",
        "state": "closed",
        "user": "everschen",
        "closed_by": "everschen",
        "created_at": "2022-02-22T14:52:23+00:00",
        "updated_at": "2022-02-24T12:59:21+00:00",
        "closed_at": "2022-02-24T12:59:21+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "everschen",
            "yt605155624",
            "everschen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1492,
        "title": "use uwsgi error No module named 'paddle' ",
        "body": " - OS:  Ubuntu 16.04\r\n - GCC/G++ Version gcc version 5.5.0 20171010\r\n - Python Version 3.9.10\r\n - PaddlePaddle Version 2.2.2\r\n\r\npaddle已安装\r\nroot@zzz-Virtual-Machine:~# python3\r\nPython 3.9.10 (main, Feb 22 2022, 11:13:30) \r\n[GCC 5.5.0 20171010] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ... \r\nPaddlePaddle works well on 1 CPU.\r\nW0225 17:03:44.327996 63401 fuse_all_reduce_op_pass.cc:76] Find all_reduce operators: 2. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 2.\r\nPaddlePaddle works well on 2 CPUs.\r\nPaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n\r\n我搭建了django框架，实现语音识别服务，通过uwsgi发布的服务端，但在使用时会报错：\r\n\r\nspawned uWSGI http 1 (pid: 63454)\r\nInternal Server Error: /speechToText\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/django/core/handlers/exception.py\", line 47, in inner\r\n    response = get_response(request)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/utils/deprecation.py\", line 116, in __call__\r\n    response = self.process_request(request)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/middleware/common.py\", line 53, in process_request\r\n    if self.should_redirect_with_slash(request):\r\n  File \"/usr/local/lib/python3.6/site-packages/django/middleware/common.py\", line 70, in should_redirect_with_slash\r\n    if not is_valid_path(request.path_info, urlconf):\r\n  File \"/usr/local/lib/python3.6/site-packages/django/urls/base.py\", line 153, in is_valid_path\r\n    return resolve(path, urlconf)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/urls/base.py\", line 24, in resolve\r\n    return get_resolver(urlconf).resolve(path)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/urls/resolvers.py\", line 560, in resolve\r\n    for pattern in self.url_patterns:\r\n  File \"/usr/local/lib/python3.6/site-packages/django/utils/functional.py\", line 48, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/urls/resolvers.py\", line 602, in url_patterns\r\n    patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/utils/functional.py\", line 48, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"/usr/local/lib/python3.6/site-packages/django/urls/resolvers.py\", line 595, in urlconf_module\r\n    return import_module(self.urlconf_name)\r\n  File \"/usr/local/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"./vins_kalibr/urls.py\", line 19, in <module>\r\n    import vins_kalibr.views\r\n  File \"./vins_kalibr/views.py\", line 11, in <module>\r\n    import vins_kalibr.transformtest\r\n  File \"./vins_kalibr/transformtest.py\", line 2, in <module>\r\n    import paddle\r\nModuleNotFoundError: No module named 'paddle'   这里报错了，不知道咋解决\r\n[pid: 63452|app: 0|req: 1/1] 10.0.71.101 () {40 vars in 612 bytes} [Fri Feb 25 17:04:39 2022] POST /speechToText => generated 144139 bytes in 128 msecs (HTTP/1.1 500) 3 headers in 126 bytes (1 switches on core 0)",
        "state": "closed",
        "user": "zhang52104",
        "closed_by": "zhang52104",
        "created_at": "2022-02-25T09:19:34+00:00",
        "updated_at": "2022-02-25T09:48:19+00:00",
        "closed_at": "2022-02-25T09:48:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1498,
        "title": "[ASR] Add topic of ctc loss speed comparing",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-02-25T11:41:49+00:00",
        "updated_at": "2022-02-28T10:48:59+00:00",
        "closed_at": "2022-02-28T10:48:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1501,
        "title": " paddlespeech_server: command not found",
        "body": "\r\n paddlespeech_server 不知道这个命令怎么装",
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "wonder2025",
        "created_at": "2022-02-26T03:47:15+00:00",
        "updated_at": "2022-02-26T04:14:11+00:00",
        "closed_at": "2022-02-26T04:14:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1500,
        "title": "关于训练自己语音的问题咨询",
        "body": "1.标贝是不是只有一个女声的open source的数据集免费下载，其他的是收费的？\r\n\r\n2.如果需要训练自己的声音，请问怎么制作数据集，有相关文档吗？https://paddlespeech.readthedocs.io/en/latest/index.html 这里好像没有是吧？\r\n\r\n谢谢",
        "state": "closed",
        "user": "everschen",
        "closed_by": "everschen",
        "created_at": "2022-02-25T15:36:07+00:00",
        "updated_at": "2022-02-26T02:36:21+00:00",
        "closed_at": "2022-02-26T02:36:21+00:00",
        "comments_count": [
            "yt605155624",
            "everschen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1502,
        "title": "运行paddlespeech_server start --config_file ./conf/application.yaml 产生错误TypeError: get_engine() missing 1 required positional argument: 'engine_type'",
        "body": null,
        "state": "closed",
        "user": "wonder2025",
        "closed_by": "yt605155624",
        "created_at": "2022-02-26T15:51:41+00:00",
        "updated_at": "2022-04-22T11:11:29+00:00",
        "closed_at": "2022-04-22T11:11:29+00:00",
        "comments_count": [
            "lym0302",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1519,
        "title": "加载phone_id_map.txt的时候提示 gbk编码错误",
        "body": "![image](https://user-images.githubusercontent.com/24568452/156324830-a74e9111-ff19-4390-98be-22fa1f3f210e.png)\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zh794390558",
        "created_at": "2022-03-02T08:34:38+00:00",
        "updated_at": "2022-03-02T11:25:37+00:00",
        "closed_at": "2022-03-02T11:25:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1505,
        "title": "Parallel WaveGAN with CSMSC error",
        "body": "我参考这个案例进行训练\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/tree/19f67e1f564f1dcd49b89159b39bb4a34b7b6cdd/examples/csmsc/voc1\r\n\r\n已经下载好了数据集\r\n```\r\n(base) root@ff21c21bf0ea:/opt/PaddleSpeech/examples/csmsc/voc1# ll ~/datasets/\r\ntotal 1156\r\ndrwxr-sr-x 3 root   users 593920 Feb 25 09:31 ./\r\ndrwsrwsr-x 1 jovyan users   4096 Feb 28 06:06 ../\r\ndrwxr-sr-x 3 root   users 577536 Feb 25 09:31 BZNSYP/\r\n```\r\n\r\nbaker_alignment_tone.tar.gz文件也解压到了当前的目录中\r\n已经满足了README文件中的条件\r\n```\r\nAssume the path to the dataset is ~/datasets/BZNSYP. Assume the path to the MFA result of CSMSC is ./baker_alignment_tone. Run the command below to\r\n\r\nsource path.\r\npreprocess the dataset.\r\ntrain the model.\r\nsynthesize wavs.\r\nsynthesize waveform from metadata.jsonl.\r\n./run.sh\r\n```\r\n\r\n在运行`run.sh` 的时候，我得到了下面的错误信息，我不知道该怎样解决\r\n```\r\n(base) root@ff21c21bf0ea:/opt/PaddleSpeech/examples/csmsc/voc1# ./run.sh\r\nGenerate durations.txt from MFA results ...\r\nExtract features ...\r\n/home/jovyan/datasets/BZNSYP\r\nGet features' stats ...\r\nTraceback (most recent call last):\r\n  File \"/opt/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/opt/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/opt/conda/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\nNormalize ...\r\nTraceback (most recent call last):\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/opt/conda/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\nTraceback (most recent call last):\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/opt/conda/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/dev/raw/metadata.jsonl'\r\nTraceback (most recent call last):\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 133, in <module>\r\n    main()\r\n  File \"/opt/PaddleSpeech/paddlespeech/t2s/exps/gan_vocoder/parallelwave_gan/../normalize.py\", line 81, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/opt/conda/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/test/raw/metadata.jsonl'\r\n```\r\n\r\ndump/train/raw/metadata.jsonl 应该是run.sh 生成的吧，但实际上并没有生成这个文件",
        "state": "closed",
        "user": "yJun-Chen",
        "closed_by": "yt605155624",
        "created_at": "2022-02-28T06:20:31+00:00",
        "updated_at": "2022-08-12T09:22:10+00:00",
        "closed_at": "2022-03-07T02:51:15+00:00",
        "comments_count": [
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "yt605155624",
            "yJun-Chen",
            "yt605155624",
            "barryhunt",
            "xusk",
            "sixyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1503,
        "title": "demos/speech_server 目录中执行  ./server.sh ，客户端访问时报 NameError: name 'Scorer' is not defined",
        "body": "demos/speech_server 目录中执行  ./server.sh ，可以正常启动。但通过客户端执行 ASR 时报下来错误，请问该如何解决？\r\n\r\n异常如下：\r\nself._ext_scorer = Scorer(beam_alpha, beam_beta,\r\nNameError: name 'Scorer' is not defined\r\n\r\npaddlespeech_ctcdecoders 有安装但不起作用。\r\n\r\n\r\n<img width=\"1474\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31823117/155889226-992b3f40-1dae-4dae-afac-6b98e8df2b78.png\">\r\n\r\n<img width=\"1448\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31823117/155889242-5faaca9b-b748-4a65-9683-015afb11b2a9.png\">\r\n\r\n<img width=\"1122\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31823117/155889257-047e7567-7d17-4b63-8267-1a2deecc710b.png\">\r\n\r\n<img width=\"1229\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31823117/155889141-43bf6527-186f-4261-b5e7-40e891bb453d.png\">\r\n",
        "state": "closed",
        "user": "wang01234",
        "closed_by": "yt605155624",
        "created_at": "2022-02-27T15:46:25+00:00",
        "updated_at": "2022-04-22T09:39:02+00:00",
        "closed_at": "2022-04-22T09:39:02+00:00",
        "comments_count": [
            "lakensei",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1512,
        "title": "语音合成:  inference:  FatalError: `Segmentation fault` is detected by the operating system.",
        "body": "你好，我在语音合成inference中，遇到以下问题：\r\n路径：/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell3/tts3/local/inference.sh\r\n\r\n问题:\r\n**\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1646127884 (unix time) try \"date -d @1646127884\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 73394 (TID 0x7f723740c740) from PID 0 ***]\r\n\r\n./local/inference.sh: line 18: 73394 Segmentation fault      python3 ${BIN_DIR}/../inference.py --inference_dir=${train_output_path}/inference --am=fastspeech2_aishell3 --voc=pwgan_aishell3 --text=${BIN_DIR}/../sentences.txt --output_dir=${train_output_path}/pd_infer_out --phones_dict=dump/phone_id_map.txt --speaker_dict=dump/speaker_id_map.txt --spk_id=0\r\n**\r\n\r\n\r\n我的 cuda是 11.2 ,    cudnn 是 8,  paddlepaddle-gpu == 2.2.2\r\n请问这个问题是什么原因呢，怎么解决这个问题呢？\r\n\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-03-01T10:14:22+00:00",
        "updated_at": "2022-03-02T08:02:07+00:00",
        "closed_at": "2022-03-02T08:02:07+00:00",
        "comments_count": [
            "yt605155624",
            "Tian14267",
            "Tian14267",
            "yt605155624",
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1513,
        "title": "TTS部分为什么没有fastSpeech2s?",
        "body": "TTS部分为什么没有fastSpeech2s?速度不是比fastSpeech2更快吗？\r\n@reyoung ",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "lawo123",
        "created_at": "2022-03-01T10:28:08+00:00",
        "updated_at": "2022-03-01T10:50:56+00:00",
        "closed_at": "2022-03-01T10:50:56+00:00",
        "comments_count": [
            "yt605155624",
            "lawo123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1522,
        "title": "不同的数据集会影响vocoder时间吗？",
        "body": "为什么我测试英文数据集和中文数据集的vocoder的时间差很多？\r\n",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-03-02T11:27:08+00:00",
        "updated_at": "2022-04-22T09:34:30+00:00",
        "closed_at": "2022-04-22T09:34:30+00:00",
        "comments_count": [
            "yt605155624",
            "lawo123",
            "yt605155624",
            "lawo123",
            "yt605155624",
            "lawo123",
            "yt605155624",
            "lawo123",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1524,
        "title": "运行stage3时报错",
        "body": "我是使用ubuntu docker安装的gpu版本的paddle\r\n\r\n（1）在/example/aishell/asr0中运行bash run.sh --stage 3 --stop_stage 3，模型是下载后再解压到asr0中的预训练模型\r\n \r\n报错：\r\n2022-03-03 04:26:05.990 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:234 - MASKCTC id: -1\r\n    2022-03-03 04:26:05.991 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:setup_dataloader:240 - Setup test  Dataloader!\r\nmain_sp(config, args)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test.py\", line 25, in main_sp\r\n    exp.setup()\r\n  File \"/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 155, in setup\r\n    self.setup_model()\r\n  File \"/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py\", line 146, in setup_model\r\n    model = DeepSpeech2Model.from_config(config)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 233, in from_config\r\n    share_rnn_weights=config.share_rnn_weights,\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/yacs/config.py\", line 141, in __getattr__\r\n    raise AttributeError(name)\r\nAttributeError: share_rnn_weights\r\nFailed in evaluation!\r\n\r\n（2）在/example/tiny/asr0中运行bash run.sh --stage 3 --stop_stage 3时报错：\r\n2022-03-03 04:31:24.538 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:184 - begin to initialize the external scorer for decoding\r\n    2022-03-03 04:31:24.538 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Test/Decode Done: 0:00:00.451815\r\nmain(config, args)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test.py\", line 30, in main\r\n    main_sp(config, args)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test.py\", line 26, in main_sp\r\n    exp.run_test()\r\n  File \"/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 355, in run_test\r\n    self.test()\r\n  File \"/PaddleSpeech/paddlespeech/s2t/utils/mp_tools.py\", line 27, in wrapper\r\n    result = func(*args, **kwargs)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py\", line 316, in test\r\n    decode_cfg.cutoff_top_n, decode_cfg.num_proc_bsearch)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/modules/ctc.py\", line 280, in init_decoder\r\n    vocab_list)\r\n  File \"/PaddleSpeech/paddlespeech/s2t/modules/ctc.py\", line 186, in _init_ext_scorer\r\n    self._ext_scorer = Scorer(beam_alpha, beam_beta,\r\nNameError: name 'Scorer' is not defined\r\nFailed in evaluation!\r\n\r\n请问是为什么，运行前面的stage就不会报错,stage4导出也是正常的\r\n",
        "state": "closed",
        "user": "larry-xue",
        "closed_by": "yt605155624",
        "created_at": "2022-03-03T04:34:34+00:00",
        "updated_at": "2022-09-20T12:25:05+00:00",
        "closed_at": "2022-04-29T02:11:03+00:00",
        "comments_count": [
            "yt605155624",
            "larry-xue",
            "Jackwaterveg",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1525,
        "title": "fastSpeech2和TensorflowTTS比耗时长很多",
        "body": "为什么我用paddle提供的[fastspeech2-ljspeech] 耗时0.8s而用TensorflowTTS提供的fastspeech2耗时0.3s？",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-03-03T07:13:27+00:00",
        "updated_at": "2022-04-22T09:32:56+00:00",
        "closed_at": "2022-04-22T09:32:56+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1543,
        "title": "[vec] database and similarity search",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "zh794390558",
        "created_at": "2022-03-08T02:06:06+00:00",
        "updated_at": "2022-03-28T02:40:43+00:00",
        "closed_at": "2022-03-18T05:43:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1526,
        "title": "Parallel WaveGAN 至少训练多少步",
        "body": "我自己按照csmsc格式搜集整理的语料来训练FastSpecch2+Parallel WaveGAN模型 FastSpecch2已完成153000步训练 请问Parallel WaveGAN至少需要训练到多少步 教程里要训练到400000步 目的是为了快速验证自己搜集的语料能否训练成功",
        "state": "closed",
        "user": "liyuhui",
        "closed_by": "yt605155624",
        "created_at": "2022-03-03T08:13:14+00:00",
        "updated_at": "2022-03-04T02:22:31+00:00",
        "closed_at": "2022-03-04T02:22:31+00:00",
        "comments_count": [
            "yt605155624",
            "liyuhui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1532,
        "title": "加载预训练模型时报错",
        "body": "我在ai studio中加载预训练模型时，出现了路径错误，请问这是为什么？我运行的是百度deepspeech课程所提供的项目：\r\n[项目地址](url)\r\n之前在本地加载预训练模型时也报了相同的错误，请问是为什么？\r\n\r\n---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)/tmp/ipykernel_99/3136689281.py in <module>\r\n----> 1 model_dict = paddle.load(checkpoint_path)\r\n      2 model.set_state_dict(model_dict)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py in load(path, **configs)\r\n    983 \r\n    984     else:\r\n--> 985         load_result = _legacy_load(path, **configs)\r\n    986 \r\n    987     return load_result\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py in _legacy_load(path, **configs)\r\n   1001     else:\r\n   1002         # file prefix and directory are compatible cases\r\n-> 1003         model_path, config = _build_load_path_and_config(path, config)\r\n   1004         # check whether model file exists\r\n   1005         if config.model_filename is None:\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py in _build_load_path_and_config(path, config)\r\n    159                 \"example, it should be written as `paddle.load('model.pdparams')` instead of \" \\\r\n    160                 \"`paddle.load('model')`.\"\r\n--> 161         raise ValueError(error_msg % path)\r\n    162     else:\r\n    163         if prefix_format_exist:\r\nValueError: The ``path`` (./exp/deepspeech/checkpoints/avg_1.pdparams) to load model not exists.",
        "state": "closed",
        "user": "larry-xue",
        "closed_by": "larry-xue",
        "created_at": "2022-03-03T16:15:48+00:00",
        "updated_at": "2022-03-14T16:17:36+00:00",
        "closed_at": "2022-03-14T16:17:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1527,
        "title": "语音识别成文字时候报错:提示MemoryError: (ResourceExhausted) Fail to alloc memory of 5189386240 size, error code is 12.",
        "body": "华为云AI服务器 2核心8G  无GPU \r\n\r\n\r\n执行的指令 \r\n`\r\npaddlespeech asr --input a.wav \r\n\r\n`\r\na.wav 文件 18969704  \r\n\r\n报错信息 \r\n`\r\n(/opt/ai/PaddleSpeech/tools/venv) root@ecs-58b4:/opt/workSpace# paddlespeech asr --input a.wav \r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nRequirement already satisfied: paddlespeech_ctcdecoders in /opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages (0.1.1)\r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\r\n[2022-03-03 16:44:46,388] [    INFO] - Preprocess audio_file:/opt/workSpace/a.wav\r\n[2022-03-03 16:44:46,388] [    INFO] - get the preprocess conf\r\n[2022-03-03 16:44:46,408] [    INFO] - read the audio file\r\n[2022-03-03 16:44:46,413] [    INFO] - audio shape: (9484748,)\r\n[2022-03-03 16:44:51,779] [    INFO] - audio feat shape: [1, 59278, 80]\r\nMemoryError: (ResourceExhausted) Fail to alloc memory of 5189386240 size, error code is 12.\r\n  [Hint: Expected error == 0, but received error:12 != 0:0.] (at /paddle/paddle/fluid/memory/detail/system_allocator.cc:62)\r\n  [operator < conv2d > error](/opt/ai/PaddleSpeech/tools/venv) root@ecs-58b4:/opt/workSpace#\r\n`\r\n",
        "state": "closed",
        "user": "xueyangkk",
        "closed_by": "yt605155624",
        "created_at": "2022-03-03T08:51:21+00:00",
        "updated_at": "2022-03-10T13:30:59+00:00",
        "closed_at": "2022-03-04T02:22:22+00:00",
        "comments_count": [
            "yt605155624",
            "xueyangkk",
            "yt605155624",
            "xueyangkk",
            "yt605155624",
            "xueyangkk",
            "yt605155624",
            "zHaOshuAnGye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1529,
        "title": "官方示例：automatic_video_subtitiles  换了一个大视频就出错了 错误信息如下 ",
        "body": "华为云AI服务器 2核心8G 无GPU\r\n\r\n官方的视频使用起来没有任何问题 \r\n\r\n自己视频网上随便下的，转换后可以播放，只是想比较官方提供的示例大了很多\r\n\r\n`\r\n(/opt/ai/PaddleSpeech/tools/venv) root@ecs-58b4:/opt/workSpace/automatic_video_subtitiles# ./run.sh \r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-03-03 17:31:49,028] [    INFO] - checking the audio file format......\r\n[2022-03-03 17:31:49,033] [    INFO] - The sample rate is 16000\r\n[2022-03-03 17:31:49,033] [    INFO] - The audio file format is right\r\n[2022-03-03 17:31:49,033] [    INFO] - File /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz md5 checking...\r\n[2022-03-03 17:31:53,137] [    INFO] - Use pretrained model stored in: /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar\r\n[2022-03-03 17:31:53,138] [    INFO] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar\r\n[2022-03-03 17:31:53,138] [    INFO] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/model.yaml\r\n[2022-03-03 17:31:53,138] [    INFO] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/exp/conformer/checkpoints/wenetspeech.pdparams\r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nRequirement already satisfied: paddlespeech_ctcdecoders in /opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages (0.1.1)\r\n/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/pip/_vendor/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  DeprecationWarning,\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\r\n[2022-03-03 17:31:58,449] [    INFO] - Preprocess audio_file:/opt/workSpace/automatic_video_subtitiles/subtitle_demo1.wav\r\n[2022-03-03 17:31:58,449] [    INFO] - get the preprocess conf\r\n[2022-03-03 17:31:58,478] [    INFO] - read the audio file\r\n[2022-03-03 17:31:58,480] [    INFO] - audio shape: (4789627,)\r\n[2022-03-03 17:32:01,084] [    INFO] - audio feat shape: [1, 29933, 80]\r\nTraceback (most recent call last):\r\n  File \"recognize.py\", line 35, in <module>\r\n    device=args.device)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 338, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 536, in __call__\r\n    self.infer(model)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 351, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 381, in infer\r\n    simulate_streaming=cfg.simulate_streaming)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 351, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 751, in decode\r\n    simulate_streaming=simulate_streaming)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 528, in attention_rescoring\r\n    num_decoding_left_chunks, simulate_streaming)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 414, in _ctc_prefix_beam_search\r\n    simulate_streaming)  # (B, maxlen, encoder_dim)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 217, in _forward_encoder\r\n    num_decoding_left_chunks=num_decoding_left_chunks\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/modules/encoder.py\", line 167, in forward\r\n    xs, pos_emb, masks = self.embed(xs, masks.astype(xs.dtype), offset=0)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/modules/subsampling.py\", line 141, in forward\r\n    x, pos_emb = self.pos_enc(x, offset)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/opt/ai/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech/s2t/modules/embedding.py\", line 161, in forward\r\n    assert offset + x.shape[1] < self.max_len\r\nAssertionError\r\n(/opt/ai/PaddleSpeech/tools/venv) root@ecs-58b4:/opt/workSpace/automatic_video_subtitiles# \r\n`",
        "state": "closed",
        "user": "xueyangkk",
        "closed_by": "yt605155624",
        "created_at": "2022-03-03T09:35:53+00:00",
        "updated_at": "2022-03-04T02:22:15+00:00",
        "closed_at": "2022-03-04T02:22:15+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1534,
        "title": "安装 PaddleSpeech 时候出错 ",
        "body": "本地电脑  ubuntu 20.04 \r\n\r\n\r\n\r\n前面都没有任何问题 运行 \r\n`\r\npip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n`\r\n报错信息如下\r\n\r\n`Installing collected packages: paddlespeech, gpustat, coverage, ConfigArgParse\r\n  Running setup.py develop for paddlespeech\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /home/zy/workSpace/PaddleSpeech/tools/venv/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/zy/workSpace/PaddleSpeech/setup.py'\"'\"'; __file__='\"'\"'/home/zy/workSpace/PaddleSpeech/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /home/zy/workSpace/PaddleSpeech/\r\n    Complete output (62 lines):\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n    Adding paddlespeech 0.1.2 to easy-install.pth file\r\n    Installing paddlespeech script to /home/zy/workSpace/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_client script to /home/zy/workSpace/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_server script to /home/zy/workSpace/PaddleSpeech/tools/venv/bin\r\n    \r\n    Installed /home/zy/workSpace/PaddleSpeech\r\n    Post Install...\r\n    apt update -y\r\n    \r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n    \r\n    Reading package lists...\r\n    E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\r\n    E: Unable to lock directory /var/lib/apt/lists/\r\n    W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\r\n    W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\r\n    make: *** [Makefile:27: apt.done] Error 100\r\n    /home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:720: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n      % (opt, underscore_opt)\r\n    /home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:720: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n      % (opt, underscore_opt)\r\n    /home/zy/workSpace/PaddleSpeech/setup.py:141: CMD: make, Error: None\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/home/zy/workSpace/PaddleSpeech/setup.py\", line 274, in <module>\r\n        setup(**setup_info)\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/zy/workSpace/PaddleSpeech/setup.py\", line 171, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/distutils/cmd.py\", line 335, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/distutils/util.py\", line 291, in execute\r\n        func(*args)\r\n      File \"/home/zy/workSpace/PaddleSpeech/setup.py\", line 157, in _post_install\r\n        check_call(\"make\")\r\n      File \"/home/zy/workSpace/PaddleSpeech/setup.py\", line 144, in check_call\r\n        raise e\r\n      File \"/home/zy/workSpace/PaddleSpeech/setup.py\", line 138, in check_call\r\n        executable=\"/bin/bash\" if shell else executable)\r\n      File \"/home/zy/workSpace/PaddleSpeech/tools/venv/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    /home/zy/workSpace/PaddleSpeech/tools\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /home/zy/workSpace/PaddleSpeech/tools/venv/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/zy/workSpace/PaddleSpeech/setup.py'\"'\"'; __file__='\"'\"'/home/zy/workSpace/PaddleSpeech/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\r\n\r\n`\r\n\r\n",
        "state": "closed",
        "user": "xueyangkk",
        "closed_by": "iftaken",
        "created_at": "2022-03-04T07:34:01+00:00",
        "updated_at": "2023-01-15T04:41:41+00:00",
        "closed_at": "2022-07-07T09:50:19+00:00",
        "comments_count": [
            "yt605155624",
            "cjy6666666",
            "stale[bot]",
            "olive900",
            "linkec",
            "tone2158",
            "linkec",
            "tone2158"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1564
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1555,
        "title": "能否提供wenetspeech 的预训练权重？",
        "body": "由于训练资源有限，能否提供已经训练好的wenetspeech数据集的权重，以此方便大家做模型的微调，也避免重复训练造成资源浪费",
        "state": "closed",
        "user": "heguodui",
        "closed_by": "yt605155624",
        "created_at": "2022-03-10T02:19:13+00:00",
        "updated_at": "2022-07-27T07:02:41+00:00",
        "closed_at": "2022-07-27T07:02:41+00:00",
        "comments_count": [
            "yt605155624",
            "heguodui",
            "yt605155624",
            "tcexeexe",
            "stale[bot]",
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1557,
        "title": "使用预训练模型内存不足",
        "body": "您好，我在使用如下代码进行语音识别的时候，每次输入一条40s的语音，输入多次。查看资源使用情况，跑的过程中用到了40g+的内存，且内存会随着每次的输入增加，跑着跑着就死机了。。为什么跑测试需要这么大的内存呢，是我哪里写错了吗，有什么解决的办法呢，求教了拜托🙏🏻\r\n\r\ntext = asr_executor(\r\n      model='conformer_wenetspeech',\r\n      lang='zh',\r\n      sample_rate=16000,\r\n      config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n      ckpt_path=None,\r\n      audio_file= 一条40s的wav16k语音,\r\n      force_yes=False,\r\n      device='gpu:0')\r\n\r\ntext = text_executor(\r\n      text=text,\r\n      task='punc',\r\n      model='ernie_linear_p7_wudao',\r\n      lang='zh',\r\n      config=None,\r\n      ckpt_path=None,\r\n      punc_vocab=None,\r\n      device='gpu:0')\r\n",
        "state": "closed",
        "user": "zHaOshuAnGye",
        "closed_by": "yt605155624",
        "created_at": "2022-03-11T08:57:53+00:00",
        "updated_at": "2022-05-30T02:52:03+00:00",
        "closed_at": "2022-05-30T02:52:03+00:00",
        "comments_count": [
            "zh794390558",
            "zHaOshuAnGye",
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1560,
        "title": "关于采样率的设置",
        "body": "![image](https://user-images.githubusercontent.com/44777088/158098286-75f568f4-5ad3-44bf-a6cb-a4c6cedbfa86.png)\r\n中文数据集的原始采样率为48kHz,为什么我们的配置文件的fs=24000 ？",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-03-14T03:11:08+00:00",
        "updated_at": "2022-04-22T10:02:15+00:00",
        "closed_at": "2022-04-22T10:02:15+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1575,
        "title": "提升 conformer 的精度",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-03-17T03:27:49+00:00",
        "updated_at": "2022-03-22T11:15:14+00:00",
        "closed_at": "2022-03-22T11:15:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1567,
        "title": "[speechx] wfst based decoder",
        "body": "- [ ] mem pool\r\n- [x] wfst decoder\r\n- [ ] timeline decoder\r\n- [x] fbank & mfcc\r\n- [x] get partial result\n- [x] websoket server\r\n- [x] class/slot wfst\r\n- [x] ngram train\r\n- [x] cer not consistent",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "stale[bot]",
        "created_at": "2022-03-14T10:17:09+00:00",
        "updated_at": "2022-09-30T22:48:08+00:00",
        "closed_at": "2022-09-30T22:48:08+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "Deployment"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1573,
        "title": "按照官方的安装方法，提示找不到 paddleaudio 这个包。",
        "body": "安装完成以后，运行 paddlespeech命令，提示：\r\nTraceback (most recent call last):\r\n  File \"/home/allen/.aliot/miniconda3/envs/paddle_env/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/home/allen/.aliot/miniconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/home/allen/.aliot/miniconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/home/allen/.aliot/miniconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 31, in <module>\r\n    from ..utils import cli_register\r\n  File \"/home/allen/.aliot/miniconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 31, in <module>\r\n    import paddleaudio\r\nModuleNotFoundError: No module named 'paddleaudio'\r\n\r\n试了一下 pip install paddleaudio 也没问题。请问如何解？谢谢\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "allenxln",
        "closed_by": "yt605155624",
        "created_at": "2022-03-17T02:12:03+00:00",
        "updated_at": "2022-04-22T10:45:07+00:00",
        "closed_at": "2022-04-22T10:45:07+00:00",
        "comments_count": [
            "zh794390558",
            "thomascatlee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1579,
        "title": "HuggingFace 上面的 PaddleSpeechASR 怎么使用",
        "body": "\r\nhttps://huggingface.co/spaces/KPatrick/PaddleSpeechASR  上传到HuggingFace 上面的模型，怎么用transformers 模块去使用",
        "state": "closed",
        "user": "dtMndas",
        "closed_by": "dtMndas",
        "created_at": "2022-03-17T07:03:30+00:00",
        "updated_at": "2022-03-21T09:43:58+00:00",
        "closed_at": "2022-03-21T09:43:58+00:00",
        "comments_count": [
            "zh794390558",
            "dtMndas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1580,
        "title": "如果下载包?",
        "body": "求教下  我想把语音识别 集成到我们的项目里   \r\n\r\n\r\n```\r\nimport paddle\r\n\r\nfrom paddlespeech.cli import ASRExecutor\r\nfrom paddlespeech.cli import \r\n```\r\n\r\n时候提示没有这些包 ，请问 我需要去哪里下载这些包？如何下载 ？非常感谢 ",
        "state": "closed",
        "user": "xueyangkk",
        "closed_by": "yt605155624",
        "created_at": "2022-03-17T07:09:51+00:00",
        "updated_at": "2022-04-22T10:44:16+00:00",
        "closed_at": "2022-04-22T10:44:16+00:00",
        "comments_count": [
            "zh794390558",
            "dtMndas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1584,
        "title": "numpy.ndarray has the wrong size, try recompiling",
        "body": "最新的develop版本，测试demo的时候报错\r\n\r\nTraceback (most recent call last):\r\n  File \"demos/automatic_video_subtitiles/recognize.py\", line 22, in <module>\r\n    from paddlespeech.cli import ASRExecutor\r\n  File \"./paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"./paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"./paddlespeech/cli/asr/infer.py\", line 31, in <module>\r\n    from ..utils import cli_register\r\n  File \"./paddlespeech/cli/utils.py\", line 31, in <module>\r\n    import paddleaudio\r\n  File \"./paddleaudio/__init__.py\", line 19, in <module>\r\n    from . import metric\r\n  File \"./paddleaudio/metric/__init__.py\", line 15, in <module>\r\n    from .mcd import mcd_distance\r\n  File \"./paddleaudio/metric/mcd.py\", line 14, in <module>\r\n    import mcd.metrics_fast as mt\r\n  File \"__init__.pxd\", line 178, in init mcd.metrics_fast (mcd/metrics_fast.c:4107)\r\nValueError: numpy.ndarray has the wrong size, try recompiling\r\n",
        "state": "closed",
        "user": "yangy996",
        "closed_by": "yangy996",
        "created_at": "2022-03-21T09:20:47+00:00",
        "updated_at": "2022-04-11T16:11:53+00:00",
        "closed_at": "2022-03-22T01:04:56+00:00",
        "comments_count": [
            "zh794390558",
            "yangy996",
            "yangy996",
            "w5688414"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1588,
        "title": "RTX3080 第一次运行时间6.5s 第二次 3.5s 大佬帮忙分析下",
        "body": "PaddleDetection team appreciate any suggestion or problem you delivered~\r\n运行代码：\r\nfrom paddlespeech.cli import TTSExecutor\r\nimport time\r\nimport paddle\r\ntts_executor = TTSExecutor()\r\ntime_1 = time.time()\r\nwav_file = tts_executor(\r\ntext='对数据集进行预处理',\r\noutput='1.wav',\r\nam='fastspeech2_csmsc',\r\nam_config=None,\r\nam_ckpt=None,\r\nam_stat=None,\r\nspk_id=0,\r\nphones_dict=None,\r\ntones_dict=None,\r\nspeaker_dict=None,\r\nvoc='pwgan_csmsc',\r\nvoc_config=None,\r\nvoc_ckpt=None,\r\nvoc_stat=None,\r\nlang='zh',\r\ndevice=paddle.get_device())\r\ntime_2 = time.time()\r\nprint(\"time of first time:\", time_2-time_1)\r\nwav_file = tts_executor(\r\ntext='对数据集进行预处理222的地方安身的地方',\r\noutput='2.wav',\r\nam='fastspeech2_csmsc',\r\nam_config=None,\r\nam_ckpt=None,\r\nam_stat=None,\r\nspk_id=0,\r\nphones_dict=None,\r\ntones_dict=None,\r\nspeaker_dict=None,\r\nvoc='pwgan_csmsc',\r\nvoc_config=None,\r\nvoc_ckpt=None,\r\nvoc_stat=None,\r\nlang='zh',\r\ndevice=paddle.get_device())\r\nprint(\"time of second time:\", time.time()-time_2)\r\n\r\n运行log:\r\nC:\\Users\\admin\\Desktop\\PaddleGPU\\venv\\Scripts\\python.exe C:/Users/admin/Desktop/PaddleGPU/main.py\r\n[2022-03-22 16:58:16,434] [ INFO] - File C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4.zip md5 checking...\r\n[2022-03-22 16:58:17,185] [ INFO] - Use pretrained model stored in: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-03-22 16:58:17,185] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-03-22 16:58:17,185] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\default.yaml\r\n[2022-03-22 16:58:17,185] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\snapshot_iter_76000.pdz\r\n[2022-03-22 16:58:17,185] [ INFO] - File C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4.zip md5 checking...\r\nself.phones_dict: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\phone_id_map.txt\r\nself.phones_dict: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\phone_id_map.txt\r\n[2022-03-22 16:58:17,210] [ INFO] - Use pretrained model stored in: C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\r\n[2022-03-22 16:58:17,210] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\r\n[2022-03-22 16:58:17,210] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\\pwg_default.yaml\r\n[2022-03-22 16:58:17,210] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\\pwg_snapshot_iter_400000.pdz\r\nvocab_size: 268\r\nfrontend done!\r\nW0322 16:58:17.252873 7164 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.6, Runtime API Version: 11.2\r\nW0322 16:58:17.262846 7164 device_context.cc:465] device: 0, cuDNN Version: 8.2.\r\nencoder_type is transformer\r\ndecoder_type is transformer\r\nC:\\Users\\admin\\Desktop\\PaddleGPU\\venv\\lib\\site-packages\\paddle\\framework\\io.py:415: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\r\nif isinstance(obj, collections.Iterable) and not isinstance(obj, (\r\nacoustic model done!\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-03-22 16:58:21] [DEBUG] [init.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache C:\\Users\\admin\\AppData\\Local\\Temp\\jieba.cache\r\n[2022-03-22 16:58:21] [DEBUG] [init.py:132] Loading model from cache C:\\Users\\admin\\AppData\\Local\\Temp\\jieba.cache\r\nvoc done!\r\nLoading model cost 0.440 seconds.\r\n[2022-03-22 16:58:21] [DEBUG] [init.py:164] Loading model cost 0.440 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-03-22 16:58:21] [DEBUG] [init.py:166] Prefix dict has been built successfully.\r\nC:\\Users\\admin\\Desktop\\PaddleGPU\\venv\\lib\\site-packages\\paddle\\fluid\\dygraph\\math_op_patch.py:251: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.int32, the right dtype will convert to paddle.int64\r\nwarnings.warn(\r\ntime of first time: 6.327423810958862\r\n[2022-03-22 16:58:22,761] [ INFO] - File C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4.zip md5 checking...\r\n[2022-03-22 16:58:23,508] [ INFO] - Use pretrained model stored in: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-03-22 16:58:23,508] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-03-22 16:58:23,508] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\default.yaml\r\n[2022-03-22 16:58:23,508] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\snapshot_iter_76000.pdz\r\n[2022-03-22 16:58:23,508] [ INFO] - File C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4.zip md5 checking...\r\nself.phones_dict: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\phone_id_map.txt\r\nself.phones_dict: C:\\Users\\admin.paddlespeech\\models\\fastspeech2_csmsc-zh\\fastspeech2_nosil_baker_ckpt_0.4\\phone_id_map.txt\r\n[2022-03-22 16:58:23,533] [ INFO] - Use pretrained model stored in: C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\r\n[2022-03-22 16:58:23,533] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\r\n[2022-03-22 16:58:23,533] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\\pwg_default.yaml\r\n[2022-03-22 16:58:23,533] [ INFO] - C:\\Users\\admin.paddlespeech\\models\\pwgan_csmsc-zh\\pwg_baker_ckpt_0.4\\pwg_snapshot_iter_400000.pdz\r\nvocab_size: 268\r\nfrontend done!\r\nencoder_type is transformer\r\ndecoder_type is transformer\r\nacoustic model done!\r\nvoc done!\r\ntime of second time: 3.6099960803985596\r\n\r\nProcess finished with exit code 0\r\n\r\n\r\n环境/Environment\r\npaddlepaddle_gpu-2.2.2.post112-cp39-cp39\r\n\r\n请提供您使用的操作系统信息，如Linux/Windows/MacOS /Please provide the OS information, e.g., Linux：\r\nWIN10\r\n\r\n请问您使用的Python版本是？/ Please provide the version of Python you used.\r\nPython3.9\r\n\r\n请问您使用的CUDA/cuDNN的版本号是？/ Please provide the version of CUDA/cuDNN you used.\r\nCUDA 11.2 cudnn-11.3-windows-x64-v8.2.1.32\r\n",
        "state": "closed",
        "user": "19920716",
        "closed_by": "yt605155624",
        "created_at": "2022-03-22T09:10:44+00:00",
        "updated_at": "2022-04-29T02:08:35+00:00",
        "closed_at": "2022-04-29T02:08:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1586,
        "title": "找不到pretrained_models",
        "body": "在paddlespeech 的demo（https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/speech_recognition/README_cn.md），在文档最后有列了支持的模型，但是选择 “deepspeech2offline_aishell” 代码却报错说找不到对应的模型：\r\n![image](https://user-images.githubusercontent.com/9609594/159237442-954e2707-b396-404e-b9fe-1109d240f880.png)\r\n\r\n从源码中发现，在paddlespeech  只支持两个模型：\r\n```\r\npretrained_models = {\r\n    # The tags for pretrained_models should be \"{model_name}[_{dataset}][-{lang}][-...]\".\r\n    # e.g. \"conformer_wenetspeech-zh-16k\" and \"panns_cnn6-32k\".\r\n    # Command line and python api use \"{model_name}[_{dataset}]\" as --model, usage:\r\n    # \"paddlespeech asr --model conformer_wenetspeech --lang zh --sr 16000 --input ./input.wav\"\r\n    \"conformer_wenetspeech-zh-16k\": {\r\n        'url':\r\n        'https://paddlespeech.bj.bcebos.com/s2t/wenetspeech/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz',\r\n        'md5':\r\n        '76cb19ed857e6623856b7cd7ebbfeda4',\r\n        'cfg_path':\r\n        'model.yaml',\r\n        'ckpt_path':\r\n        'exp/conformer/checkpoints/wenetspeech',\r\n    },\r\n    \"transformer_librispeech-en-16k\": {\r\n        'url':\r\n        'https://paddlespeech.bj.bcebos.com/s2t/librispeech/asr1/asr1_transformer_librispeech_ckpt_0.1.1.model.tar.gz',\r\n        'md5':\r\n        '2c667da24922aad391eacafe37bc1660',\r\n        'cfg_path':\r\n        'model.yaml',\r\n        'ckpt_path':\r\n        'exp/transformer/checkpoints/avg_10',\r\n    },\r\n}\r\n```\r\n",
        "state": "closed",
        "user": "dtMndas",
        "closed_by": "yt605155624",
        "created_at": "2022-03-21T09:49:27+00:00",
        "updated_at": "2022-04-08T02:01:25+00:00",
        "closed_at": "2022-04-08T02:01:25+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1585,
        "title": "安装时无法获取部分文件",
        "body": "在Ubuntu 20.04.2 LTS执行安装命令`pip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple`时出现\r\nRunning setup.py develop for paddlespeech\r\n    error: subprocess-exited-with-error\r\n\r\n    × python setup.py develop did not run successfully.\r\n    │ exit code: 1\r\n    ╰─> [125 lines of output]\r\n        running develop\r\n        running egg_info\r\n        writing paddlespeech.egg-info/PKG-INFO\r\n        writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n        writing entry points to paddlespeech.egg-info/entry_points.txt\r\n        writing requirements to paddlespeech.egg-info/requires.txt\r\n        writing top-level names to paddlespeech.egg-info/top_level.txt\r\n        reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n        adding license file 'LICENSE'\r\n        writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n        running build_ext\r\n        Creating /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n        Adding paddlespeech 0.2.0 to easy-install.pth file\r\n        Installing paddlespeech script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n        Installing paddlespeech_client script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n        Installing paddlespeech_server script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n\r\n        Installed /home/ai2021/PaddleSpeech\r\n        Post Install...\r\n        apt update -y\r\n\r\n        WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n        Get:1 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n        Ign:1 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n        Get:2 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n        Get:2 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n        Hit:4 http://cn.archive.ubuntu.com/ubuntu focal InRelease\r\n        Hit:5 http://cn.archive.ubuntu.com/ubuntu focal-updates InRelease\r\n        Hit:6 http://cn.archive.ubuntu.com/ubuntu focal-backports InRelease\r\n        Hit:7 http://security.ubuntu.com/ubuntu focal-security InRelease\r\n        Hit:8 https://download.sublimetext.com apt/stable/ InRelease\r\n        Hit:9 https://download.docker.com/linux/ubuntu focal InRelease\r\n        Reading package lists...\r\n        Building dependency tree...\r\n        Reading state information...\r\n        163 packages can be upgraded. Run 'apt list --upgradable' to see them.\r\n        apt install -y bc flac jq vim tig tree pkg-config libsndfile1 libflac-dev libogg-dev libvorbis-dev libboost-dev swig python3-dev\r\n\r\n        WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n        Reading package lists...\r\n        Building dependency tree...\r\n        Reading state information...\r\n        bc is already the newest version (1.07.1-2build1).\r\n        bc set to manually installed.\r\n        pkg-config is already the newest version (0.29.1-0ubuntu4).\r\n        pkg-config set to manually installed.\r\n        tree is already the newest version (1.8.0-1).\r\n        libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\r\n        libsndfile1 set to manually installed.\r\n        vim is already the newest version (2:8.1.2269-1ubuntu5.7).\r\n        The following additional packages will be installed:\r\n          libboost1.71-dev libexpat1-dev libjq1 libonig5 libpython3-dev\r\n          libpython3.8-dev python3-distutils python3-lib2to3 python3.8-dev swig4.0\r\n          zlib1g-dev\r\n        Suggested packages:\r\n          libboost-doc libboost1.71-doc libboost-atomic1.71-dev\r\n          libboost-chrono1.71-dev libboost-container1.71-dev libboost-context1.71-dev\r\n          libboost-contract1.71-dev libboost-coroutine1.71-dev\r\n          libboost-date-time1.71-dev libboost-exception1.71-dev libboost-fiber1.71-dev\r\n          libboost-filesystem1.71-dev libboost-graph1.71-dev\r\n          libboost-graph-parallel1.71-dev libboost-iostreams1.71-dev\r\n          libboost-locale1.71-dev libboost-log1.71-dev libboost-math1.71-dev\r\n          libboost-mpi1.71-dev libboost-mpi-python1.71-dev libboost-numpy1.71-dev\r\n          libboost-program-options1.71-dev libboost-python1.71-dev\r\n          libboost-random1.71-dev libboost-regex1.71-dev\r\n          libboost-serialization1.71-dev libboost-stacktrace1.71-dev\r\n          libboost-system1.71-dev libboost-test1.71-dev libboost-thread1.71-dev\r\n          libboost-timer1.71-dev libboost-type-erasure1.71-dev libboost-wave1.71-dev\r\n          libboost1.71-tools-dev libmpfrc++-dev libntl-dev swig-doc swig-examples\r\n          swig4.0-examples swig4.0-doc\r\n        The following NEW packages will be installed:\r\n          flac jq libboost-dev libboost1.71-dev libexpat1-dev libflac-dev libjq1\r\n          libogg-dev libonig5 libpython3-dev libpython3.8-dev libvorbis-dev\r\n          python3-dev python3-distutils python3-lib2to3 python3.8-dev swig swig4.0 tig\r\n          zlib1g-dev\r\n        0 upgraded, 20 newly installed, 0 to remove and 163 not upgraded.\r\n        Need to get 121 kB/16.5 MB of archives.\r\n        After this operation, 173 MB of additional disk space will be used.\r\n        Err:1 http://cn.archive.ubuntu.com/ubuntu focal/universe amd64 flac amd64 1.3.3-1build1\r\n          Connection failed [IP: 91.189.91.39 80]\r\n        E: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/pool/universe/f/flac/flac_1.3.3-1build1_amd64.deb  Connection failed [IP: 91.189.91.39 80]\r\n        E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\r\n        make: *** [Makefile:28: apt.done] Error 100\r\n        /home/ai2021/PaddleSpeech/tools\r\n        /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:742: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n          % (opt, underscore_opt)\r\n        /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:742: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n          % (opt, underscore_opt)\r\n        /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n          EasyInstallDeprecationWarning,\r\n        /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n          setuptools.SetuptoolsDeprecationWarning,\r\n        /home/ai2021/PaddleSpeech/setup.py:141: CMD: make, Error: None\r\n        Traceback (most recent call last):\r\n          File \"<string>\", line 36, in <module>\r\n          File \"<pip-setuptools-caller>\", line 34, in <module>\r\n          File \"/home/ai2021/PaddleSpeech/setup.py\", line 274, in <module>\r\n            setup(**setup_info)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 155, in setup\r\n            return distutils.core.setup(**attrs)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 148, in setup\r\n            return run_commands(dist)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 163, in run_commands\r\n            dist.run_commands()\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\r\n            self.run_command(cmd)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n            cmd_obj.run()\r\n          File \"/home/ai2021/PaddleSpeech/setup.py\", line 171, in run\r\n            self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/cmd.py\", line 335, in execute\r\n            util.execute(func, args, msg, dry_run=self.dry_run)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/util.py\", line 322, in execute\r\n            func(*args)\r\n          File \"/home/ai2021/PaddleSpeech/setup.py\", line 157, in _post_install\r\n            check_call(\"make\")\r\n          File \"/home/ai2021/PaddleSpeech/setup.py\", line 144, in check_call\r\n            raise e\r\n          File \"/home/ai2021/PaddleSpeech/setup.py\", line 138, in check_call\r\n            executable=\"/bin/bash\" if shell else executable)\r\n          File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/subprocess.py\", line 363, in check_call\r\n            raise CalledProcessError(retcode, cmd)\r\n        subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n        [end of output]\r\n\r\n    note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× python setup.py develop did not run successfully.\r\n│ exit code: 1\r\n╰─> [125 lines of output]\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n    Adding paddlespeech 0.2.0 to easy-install.pth file\r\n    Installing paddlespeech script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_client script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_server script to /home/ai2021/PaddleSpeech/tools/venv/bin\r\n\r\n    Installed /home/ai2021/PaddleSpeech\r\n    Post Install...\r\n    apt update -y\r\n\r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n    Get:1 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n    Ign:1 file:/var/nccl-repo-2.7.8-ga-cuda10.1  InRelease\r\n    Get:2 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n    Get:2 file:/var/nccl-repo-2.7.8-ga-cuda10.1  Release [574 B]\r\n    Hit:4 http://cn.archive.ubuntu.com/ubuntu focal InRelease\r\n    Hit:5 http://cn.archive.ubuntu.com/ubuntu focal-updates InRelease\r\n    Hit:6 http://cn.archive.ubuntu.com/ubuntu focal-backports InRelease\r\n    Hit:7 http://security.ubuntu.com/ubuntu focal-security InRelease\r\n    Hit:8 https://download.sublimetext.com apt/stable/ InRelease\r\n    Hit:9 https://download.docker.com/linux/ubuntu focal InRelease\r\n    Reading package lists...\r\n    Building dependency tree...\r\n    Reading state information...\r\n    163 packages can be upgraded. Run 'apt list --upgradable' to see them.\r\n    apt install -y bc flac jq vim tig tree pkg-config libsndfile1 libflac-dev libogg-dev libvorbis-dev libboost-dev swig python3-dev\r\n\r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n    Reading package lists...\r\n    Building dependency tree...\r\n    Reading state information...\r\n    bc is already the newest version (1.07.1-2build1).\r\n    bc set to manually installed.\r\n    pkg-config is already the newest version (0.29.1-0ubuntu4).\r\n    pkg-config set to manually installed.\r\n    tree is already the newest version (1.8.0-1).\r\n    libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\r\n    libsndfile1 set to manually installed.\r\n    vim is already the newest version (2:8.1.2269-1ubuntu5.7).\r\n    The following additional packages will be installed:\r\n      libboost1.71-dev libexpat1-dev libjq1 libonig5 libpython3-dev\r\n      libpython3.8-dev python3-distutils python3-lib2to3 python3.8-dev swig4.0\r\n      zlib1g-dev\r\n    Suggested packages:\r\n      libboost-doc libboost1.71-doc libboost-atomic1.71-dev\r\n      libboost-chrono1.71-dev libboost-container1.71-dev libboost-context1.71-dev\r\n      libboost-contract1.71-dev libboost-coroutine1.71-dev\r\n      libboost-date-time1.71-dev libboost-exception1.71-dev libboost-fiber1.71-dev\r\n      libboost-filesystem1.71-dev libboost-graph1.71-dev\r\n      libboost-graph-parallel1.71-dev libboost-iostreams1.71-dev\r\n      libboost-locale1.71-dev libboost-log1.71-dev libboost-math1.71-dev\r\n      libboost-mpi1.71-dev libboost-mpi-python1.71-dev libboost-numpy1.71-dev\r\n      libboost-program-options1.71-dev libboost-python1.71-dev\r\n      libboost-random1.71-dev libboost-regex1.71-dev\r\n      libboost-serialization1.71-dev libboost-stacktrace1.71-dev\r\n      libboost-system1.71-dev libboost-test1.71-dev libboost-thread1.71-dev\r\n      libboost-timer1.71-dev libboost-type-erasure1.71-dev libboost-wave1.71-dev\r\n      libboost1.71-tools-dev libmpfrc++-dev libntl-dev swig-doc swig-examples\r\n      swig4.0-examples swig4.0-doc\r\n    The following NEW packages will be installed:\r\n      flac jq libboost-dev libboost1.71-dev libexpat1-dev libflac-dev libjq1\r\n      libogg-dev libonig5 libpython3-dev libpython3.8-dev libvorbis-dev\r\n      python3-dev python3-distutils python3-lib2to3 python3.8-dev swig swig4.0 tig\r\n      zlib1g-dev\r\n    0 upgraded, 20 newly installed, 0 to remove and 163 not upgraded.\r\n    Need to get 121 kB/16.5 MB of archives.\r\n    After this operation, 173 MB of additional disk space will be used.\r\n    Err:1 http://cn.archive.ubuntu.com/ubuntu focal/universe amd64 flac amd64 1.3.3-1build1\r\n      Connection failed [IP: 91.189.91.39 80]\r\n    E: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/pool/universe/f/flac/flac_1.3.3-1build1_amd64.deb  Connection failed [IP: 91.189.91.39 80]\r\n    E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\r\n    make: *** [Makefile:28: apt.done] Error 100\r\n    /home/ai2021/PaddleSpeech/tools\r\n    /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:742: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n      % (opt, underscore_opt)\r\n    /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:742: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n      % (opt, underscore_opt)\r\n    /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n      EasyInstallDeprecationWarning,\r\n    /home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n      setuptools.SetuptoolsDeprecationWarning,\r\n    /home/ai2021/PaddleSpeech/setup.py:141: CMD: make, Error: None\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 36, in <module>\r\n      File \"<pip-setuptools-caller>\", line 34, in <module>\r\n      File \"/home/ai2021/PaddleSpeech/setup.py\", line 274, in <module>\r\n        setup(**setup_info)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 155, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 148, in setup\r\n        return run_commands(dist)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 163, in run_commands\r\n        dist.run_commands()\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/ai2021/PaddleSpeech/setup.py\", line 171, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/cmd.py\", line 335, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/util.py\", line 322, in execute\r\n        func(*args)\r\n      File \"/home/ai2021/PaddleSpeech/setup.py\", line 157, in _post_install\r\n        check_call(\"make\")\r\n      File \"/home/ai2021/PaddleSpeech/setup.py\", line 144, in check_call\r\n        raise e\r\n      File \"/home/ai2021/PaddleSpeech/setup.py\", line 138, in check_call\r\n        executable=\"/bin/bash\" if shell else executable)\r\n      File \"/home/ai2021/PaddleSpeech/tools/venv/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n有尝试过修改dns，但似乎没有解决问题\r\n",
        "state": "closed",
        "user": "Enoryl",
        "closed_by": "yt605155624",
        "created_at": "2022-03-21T09:28:34+00:00",
        "updated_at": "2022-04-22T11:53:20+00:00",
        "closed_at": "2022-04-22T11:53:20+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1606,
        "title": "[vec]please add speaker verification model description",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-03-25T11:10:09+00:00",
        "updated_at": "2022-03-28T02:03:39+00:00",
        "closed_at": "2022-03-28T02:03:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1594,
        "title": "windows 安装的时候 报gbk codec can't decode byte 0x80 in position 5365",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3f/84/5afa0f957d1f3053478882b40565f454f8755532b696224e880600a3d35a/soxbindings-1.2.3.tar.gz (16 kB)\r\n    ERROR: Command errored out with exit status 1:\r\n     command: 'D:\\conda1\\envs\\paddle-detection\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\chenlin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dj_x2shn\\\\soxbindings\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ch\r\nenlin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dj_x2shn\\\\soxbindings\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'\r\n))' egg_info --egg-base 'C:\\Users\\chenlin\\AppData\\Local\\Temp\\pip-install-dj_x2shn\\soxbindings\\pip-egg-info'\r\n         cwd: C:\\Users\\chenlin\\AppData\\Local\\Temp\\pip-install-dj_x2shn\\soxbindings\\\r\n    Complete output (5 lines):\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"C:\\Users\\chenlin\\AppData\\Local\\Temp\\pip-install-dj_x2shn\\soxbindings\\setup.py\", line 107, in <module>\r\n        long_description = f.read()\r\n    UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 5365: illegal multibyte sequence\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "lindychan",
        "closed_by": "yt605155624",
        "created_at": "2022-03-23T06:27:01+00:00",
        "updated_at": "2022-05-30T02:33:06+00:00",
        "closed_at": "2022-05-30T02:33:06+00:00",
        "comments_count": [
            "zh794390558",
            "lindychan",
            "zh794390558",
            "lindychan",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1608,
        "title": "[vec][search] update to paddlespeech model",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "zh794390558",
        "created_at": "2022-03-26T15:56:22+00:00",
        "updated_at": "2022-03-28T09:24:08+00:00",
        "closed_at": "2022-03-28T09:24:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1607,
        "title": "如何在Python api中使用标点恢复？",
        "body": null,
        "state": "closed",
        "user": "standyyyy",
        "closed_by": "yt605155624",
        "created_at": "2022-03-26T09:27:50+00:00",
        "updated_at": "2022-04-22T11:11:13+00:00",
        "closed_at": "2022-04-22T11:11:13+00:00",
        "comments_count": [
            "zh794390558",
            "standyyyy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1611,
        "title": "[asr]使用 paddleaudio 的 kaldi fbank 替换原有的 kaldi fbank",
        "body": null,
        "state": "closed",
        "user": "Jackwaterveg",
        "closed_by": "zh794390558",
        "created_at": "2022-03-28T03:37:34+00:00",
        "updated_at": "2022-03-29T14:07:43+00:00",
        "closed_at": "2022-03-29T14:07:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1618,
        "title": "[vec]use paddlespeech.dataset to prepare the voxceleb experiment",
        "body": "Now PaddleSpeech use paddleaudio.dataset to prepare the voxceleb data,\r\nif PaddleSpeech can use paddlespeech.dataset to prepare the dataset",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "LeoMax-Xiong",
        "created_at": "2022-03-29T06:13:12+00:00",
        "updated_at": "2022-04-11T04:57:45+00:00",
        "closed_at": "2022-04-11T04:57:45+00:00",
        "comments_count": [],
        "labels": [
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1622,
        "title": "[tts] streaming tts",
        "body": "- [ ] gan vocoder(hifigan/mbmelgan) streaming\n- [ ]  am(fs2) streaming",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "yt605155624",
        "created_at": "2022-03-29T09:27:46+00:00",
        "updated_at": "2022-04-22T10:43:56+00:00",
        "closed_at": "2022-04-22T10:43:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1623,
        "title": "[asr] streaming asr",
        "body": "- [x] websocket api\r\n- [x]  vad\r\n- [x] cache buffer\r\n- [x] ds2 online\r\n- [x] aishell streaming conformer ",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-03-29T09:30:18+00:00",
        "updated_at": "2022-04-23T05:20:58+00:00",
        "closed_at": "2022-04-23T05:20:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1617,
        "title": "No module named 'paddleaudio.compliance'",
        "body": "After I followed the [instruction](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/install.md#medium-get-the-major-functions-support-linux), I successfully installed `paddlespeech`. However, when I run the script,\r\n\r\n```python\r\nimport paddle\r\nfrom paddlespeech.cli import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='./audio.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n```\r\n\r\nit shows:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/data5/data/fyy_data/Windlike_repo/PaddleSpeech/listener.py\", line 2, in <module>\r\n    from paddlespeech.cli import ASRExecutor\r\n  File \"/data5/data/fyy_data/Windlike_repo/PaddleSpeech/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/data5/data/fyy_data/Windlike_repo/PaddleSpeech/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/data5/data/fyy_data/Windlike_repo/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 31, in <module>\r\n    from ..utils import cli_register\r\n  File \"/data5/data/fyy_data/Windlike_repo/PaddleSpeech/paddlespeech/cli/utils.py\", line 31, in <module>\r\n    import paddleaudio\r\n  File \"/home/fyy/miniconda3/envs/py37/lib/python3.7/site-packages/paddleaudio/__init__.py\", line 16, in <module>\r\n    from .compliance import *\r\nModuleNotFoundError: No module named 'paddleaudio.compliance'\r\n```\r\n\r\nI checked `/home/fyy/miniconda3/envs/py37/lib/python3.7/site-packages/paddleaudio/__init__.py` and found only `backends` and `features` are imported.\r\n\r\n```python\r\n# Copyright (c) 2021 PaddlePaddle Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nfrom .backends import *\r\nfrom .features import *\r\n\r\n__version__ = '0.1.0'\r\n```\r\n\r\nEnvironment:\r\n- OS: Ubuntu 18.04.6 LTS\r\n- Python Version: 3.7.11\r\n- GCC Version: 7.5.0\r\n- Paddlepaddle Version: cuda 11.0 `python -m pip install paddlepaddle-gpu==2.2.2.post110 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html`\r\n- CUDA Version: 11.0\r\n",
        "state": "closed",
        "user": "Wind2375like",
        "closed_by": "yt605155624",
        "created_at": "2022-03-29T04:01:35+00:00",
        "updated_at": "2022-04-22T09:28:43+00:00",
        "closed_at": "2022-04-22T09:28:43+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "KPatr1ck",
            "Wind2375like",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1620,
        "title": "👨🏻‍🦱 TTS 男性音色（Male speaker）（如何更换音色）",
        "body": "there are no single speaker datasets for male, but in multi-speaker tts datasets(aishell3, vctk)，there are Male speakers,\r\nYou can find speaker_id_map.txt in `~/.paddlespeech/models/fastspeech2_aishell3-zh/fastspeech2_nosil_aishell3_ckpt_0.4/speaker_id_map.txt` or `~/.paddlespeech/models/fastspeech2_vctk-en/fastspeech2_nosil_vctk_ckpt_0.5/speaker_id_map.txt` and check the gender of speakers in the origin datasets(aishell3/vctk), then, use `--spk_id` to use the speaker you want in multi-speaker tts datasets\r\n\r\nmore usage for multi-speaker cli https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/text_to_speech\r\n\r\nalso see https://github.com/PaddlePaddle/PaddleSpeech/issues/1373\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2022-03-29T09:07:39+00:00",
        "updated_at": "2023-08-15T04:17:29+00:00",
        "closed_at": "2023-05-21T10:48:20+00:00",
        "comments_count": [
            "yt605155624",
            "ayongbox",
            "yt605155624",
            "yt605155624",
            "iftaken",
            "thehzzz",
            "yt605155624",
            "EzrealoveQXY",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]",
            "treya-lin"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1636
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1639
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1625,
        "title": "paddlespeech/s2t/modules/attention.py在转换静态图的时候出错",
        "body": "**Describe the bug**\r\n在运行paddlespeech/s2t/exps/u2/bin/export.py脚本将Transformer模型转换成inference格式时出错。\r\n\r\n**Screenshots**\r\n<img width=\"1200\" alt=\"截屏2022-03-30 下午3 34 18\" src=\"https://user-images.githubusercontent.com/30340135/160777529-e2baf8f8-d364-4a22-be1c-c5b309a51e14.png\">\r\n\r\n\r\n** Environment (please complete the following information):**\r\n - OS: macOS 12.2.1\r\n - Python Version 3.9.11\r\n - PaddlePaddle Version 2.2.2\r\n - PaddleSpeech Version r0.1.1\r\n\r\n**Additional context**\r\n是否是PaddlePaddle版本过高的问题？\r\n",
        "state": "closed",
        "user": "NYF-BRICK",
        "closed_by": "yt605155624",
        "created_at": "2022-03-30T07:45:02+00:00",
        "updated_at": "2022-10-11T08:30:55+00:00",
        "closed_at": "2022-09-07T03:35:49+00:00",
        "comments_count": [
            "NYF-BRICK",
            "zh794390558",
            "NYF-BRICK",
            "zh794390558",
            "NYF-BRICK",
            "zh794390558",
            "NYF-BRICK",
            "zh794390558",
            "stale[bot]",
            "EricLingRui",
            "NYF-BRICK"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1653
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1629,
        "title": "centos7 + cpu : 找不到paddleaudio.compliance",
        "body": "padddleSpeech : 0.2.0 版本， paddleaudio : 0.1.0. 在导入VectorExecutor时候，报错如下：\r\n![image](https://user-images.githubusercontent.com/9609594/160957683-c3c782f4-7896-4a24-8741-ab80da83741f.png)\r\n",
        "state": "closed",
        "user": "dtMndas",
        "closed_by": "dtMndas",
        "created_at": "2022-03-30T09:51:05+00:00",
        "updated_at": "2022-03-31T02:00:38+00:00",
        "closed_at": "2022-03-31T02:00:38+00:00",
        "comments_count": [
            "yt605155624",
            "dtMndas"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1647,
        "title": "[vec]add speaker verification score function",
        "body": "In speaker verification domain, please add score demo",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "LeoMax-Xiong",
        "created_at": "2022-04-04T14:38:43+00:00",
        "updated_at": "2022-04-08T07:48:39+00:00",
        "closed_at": "2022-04-08T07:48:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1650,
        "title": "[vec] add speaker diarization pipeline",
        "body": null,
        "state": "closed",
        "user": "ccrrong",
        "closed_by": "qingen",
        "created_at": "2022-04-06T03:31:53+00:00",
        "updated_at": "2022-04-11T04:34:33+00:00",
        "closed_at": "2022-04-11T04:34:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1645,
        "title": "How to generate MFA with tone?",
        "body": "I want to train my own TTS model on CSMSC dataset. In data preparing stage, I have tried to run `PaddleSpeech-develop/examples/other/mfa/run.sh` to generate  MFA model and Textgrid but  got `baker_alignment` which didn't have tone. <br>\r\nSo I wanna to know hot to generate MFA with tone.",
        "state": "closed",
        "user": "phoenixsfly",
        "closed_by": "yt605155624",
        "created_at": "2022-04-04T00:56:48+00:00",
        "updated_at": "2022-04-22T09:28:31+00:00",
        "closed_at": "2022-04-22T09:28:31+00:00",
        "comments_count": [
            "phoenixsfly",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1648,
        "title": "class BatchBeamSearch():     pass",
        "body": "ctc-prefix-beam-search能够支持batch-beam-search吗？",
        "state": "closed",
        "user": "lifuyang",
        "closed_by": "lifuyang",
        "created_at": "2022-04-05T03:28:53+00:00",
        "updated_at": "2022-04-08T00:53:27+00:00",
        "closed_at": "2022-04-08T00:53:27+00:00",
        "comments_count": [
            "zh794390558",
            "lifuyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1667,
        "title": "[vec] add PLDA model",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "qingen",
        "created_at": "2022-04-07T08:53:53+00:00",
        "updated_at": "2022-04-19T07:14:45+00:00",
        "closed_at": "2022-04-19T07:14:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1654,
        "title": "Cento 7.5 安装Paddle 不能导入import paddle 报错如下",
        "body": "![image](https://user-images.githubusercontent.com/35989496/162104225-bf314591-9dd7-44ff-b385-26068b038bb7.png)\r\n\r\n\r\nCentOS7.5\r\nPython 3.9",
        "state": "closed",
        "user": "979170768",
        "closed_by": "yt605155624",
        "created_at": "2022-04-07T01:52:24+00:00",
        "updated_at": "2022-04-07T02:31:10+00:00",
        "closed_at": "2022-04-07T02:31:10+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1655,
        "title": "paddlespeech 安装错误",
        "body": "pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n```\r\nBuilding wheels for collected packages: mcd\r\n  Building wheel for mcd (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: 'C:\\ProgramData\\Miniconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-wheel-ugcrggid'\r\n       cwd: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-install-2g9bgdo0\\mcd_613618804b9946e486d73881a33fa62d\\\r\n  Complete output (20 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build\\lib.win-amd64-3.7\r\n  creating build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\dtw.py -> build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\metrics.py -> build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\test_dtw.py -> build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\test_metrics.py -> build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\util.py -> build\\lib.win-amd64-3.7\\mcd\r\n  copying mcd\\__init__.py -> build\\lib.win-amd64-3.7\\mcd\r\n  running build_ext\r\n  building 'mcd.metrics_fast' extension\r\n  creating build\\temp.win-amd64-3.7\r\n  creating build\\temp.win-amd64-3.7\\Release\r\n  creating build\\temp.win-amd64-3.7\\Release\\mcd\r\n  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\include -IC:\\ProgramData\\Miniconda3\\include -IC:\\ProgramData\\Miniconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\" /Tcmcd\\metrics_fast.c /Fobuild\\temp.win-amd64-3.7\\Release\\mcd\\metrics_fast.obj -Wno-unused-but-set-variable -O3\r\n  cl: 命令行 error D8021 :无效的数值参数“/Wno-unused-but-set-variable”\r\n  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit status 2\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for mcd\r\n  Running setup.py clean for mcd\r\nFailed to build mcd\r\nInstalling collected packages: mcd, h5py, dtaidistance, datasets, asgiref, uvicorn, sentencepiece, sacrebleu, pyworld, pypinyin-dict, prettytable, praatio, pattern-singleton, paddlespeech-feat, paddlenlp, paddleaudio, nara-wpe, loguru, librosa, kaldiio, jsonlines, g2pM, g2p-en, fastapi, editdistance, paddlespeech\r\n    Running setup.py install for mcd ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: 'C:\\ProgramData\\Miniconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-record-r8hftadi\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Miniconda3\\Include\\mcd'\r\n         cwd: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-install-2g9bgdo0\\mcd_613618804b9946e486d73881a33fa62d\\\r\n    Complete output (20 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build\\lib.win-amd64-3.7\r\n    creating build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\dtw.py -> build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\metrics.py -> build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\test_dtw.py -> build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\test_metrics.py -> build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\util.py -> build\\lib.win-amd64-3.7\\mcd\r\n    copying mcd\\__init__.py -> build\\lib.win-amd64-3.7\\mcd\r\n    running build_ext\r\n    building 'mcd.metrics_fast' extension\r\n    creating build\\temp.win-amd64-3.7\r\n    creating build\\temp.win-amd64-3.7\\Release\r\n    creating build\\temp.win-amd64-3.7\\Release\\mcd\r\n    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\include -IC:\\ProgramData\\Miniconda3\\include -IC:\\ProgramData\\Miniconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\" /Tcmcd\\metrics_fast.c /Fobuild\\temp.win-amd64-3.7\\Release\\mcd\\metrics_fast.obj -Wno-unused-but-set-variable -O3\r\n    cl: 命令行 error D8021 :无效的数值参数“/Wno-unused-but-set-variable”\r\n    error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit status 2\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: 'C:\\ProgramData\\Miniconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2g9bgdo0\\\\mcd_613618804b9946e486d73881a33fa62d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\pip-record-r8hftadi\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Miniconda3\\Include\\mcd' Check the logs for full command output.\r\n```",
        "state": "closed",
        "user": "zkx456",
        "closed_by": "zh794390558",
        "created_at": "2022-04-07T02:18:15+00:00",
        "updated_at": "2022-07-14T08:34:21+00:00",
        "closed_at": "2022-04-07T10:42:48+00:00",
        "comments_count": [
            "zh794390558",
            "yt605155624",
            "zkx456"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1669,
        "title": "Add the QRcode of Wechat Group",
        "body": "![图片1](https://user-images.githubusercontent.com/23690325/162169937-59123539-86b3-44bb-80c4-84dbacb2f3a2.png)\r\n",
        "state": "closed",
        "user": "D-DanielYang",
        "closed_by": "D-DanielYang",
        "created_at": "2022-04-07T09:38:46+00:00",
        "updated_at": "2022-04-07T09:39:46+00:00",
        "closed_at": "2022-04-07T09:39:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1671,
        "title": "aishell asr0 如何使用现有模型推理？",
        "body": "目前ASR的README里的模型好像不是最新的？根据这里下载好的模型之后，运行run.sh，stage设为6，但是会报config的错，看了下README里下载的和conf里的不同。\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/aishell/asr0/README.md#pretrained-model\r\n然后我又找到了https://github.com/PaddlePaddle/PaddleSpeech/blob/82cd7015d749eccc14e170b63e03ff36e125c6f2/docs/source/released_model.md\r\n这里的ds offline模型，然后报错\r\n```FileNotFoundError: [Errno 2] No such file or directory: 'data/manifest.test'```\r\n这个文件是preprocess生成的，但是为什么不一起放在能下载的模型里呢？\r\n如果要调用已有的ds2 online/offline模型，应该下载哪个模型，如何操作呢？\r\n我看到脚本也会自动下载模型，是存放在这个位置吗```~/.paddlespeech/models/``` ？\r\n感谢解答！",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "jerryuhoo",
        "created_at": "2022-04-07T10:01:27+00:00",
        "updated_at": "2022-11-28T09:33:56+00:00",
        "closed_at": "2022-04-12T03:11:38+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "jerryuhoo",
            "zh794390558",
            "Jackwaterveg",
            "ben-8878"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1678,
        "title": "local variable 'tag' in asr_engine.py",
        "body": "Error occured with 'cfg_path', 'am_model', 'am_params'  are not none. So, local variable 'tag' must be assigned. ",
        "state": "closed",
        "user": "lang101",
        "closed_by": "lym0302",
        "created_at": "2022-04-08T07:45:18+00:00",
        "updated_at": "2022-05-07T02:08:10+00:00",
        "closed_at": "2022-05-07T02:06:45+00:00",
        "comments_count": [
            "zh794390558",
            "lang101",
            "WilliamZhang06",
            "lang101",
            "lym0302",
            "lym0302"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1679,
        "title": "speedyspeech 静态图推理 mkldnn 报错，paddle2onnx 也会失败",
        "body": "推理侧一般不考虑 NHWC 这个格式, 需要调整模型结构重新训练模型，进而使得静态模型可以使用 PaddleInference 的 mkldnn 以及走通 paddle2onnx 进行 onnxruntime 推理，增加语音合成 onnx 部署能力（目前 am 仅有 fastspeech2 支持 onnx）\r\n关联 issue 证明开发者有对 speedyspeech onnx 部署的需求 https://github.com/PaddlePaddle/Paddle2ONNX/issues/471",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-04-08T08:00:51+00:00",
        "updated_at": "2022-04-14T05:54:37+00:00",
        "closed_at": "2022-04-14T05:54:37+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1684,
        "title": "csmsc/voc5 onnx模型加载有误",
        "body": "- 测试[hifigan_csmsc_onnx_0.2.0](https://paddlespeech.bj.bcebos.com/Parakeet/released_models/hifigan/hifigan_csmsc_onnx_0.2.0.zip)时，报错：\r\n```python\r\n>>> import onnx\r\n>>> model = onnx.load('pretrained_model/fastspeech2_csmsc_onnx_0.2.0/hifigan_csmsc.onnx')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/onnx/__init__.py\", line 121, in load_model\r\n    model = load_model_from_string(s, format=format)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/onnx/__init__.py\", line 158, in load_model_from_string\r\n    return _deserialize(s, ModelProto())\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/onnx/__init__.py\", line 99, in _deserialize\r\n    decoded = cast(Optional[int], proto.ParseFromString(s))\r\ngoogle.protobuf.message.DecodeError: Error parsing message\r\n```\r\n- 测试环境：\r\n```text\r\nOS: CentOS\r\nPython: 3.7\r\nonnx: 1.10.1\r\n```",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "SWHL",
        "created_at": "2022-04-09T08:38:19+00:00",
        "updated_at": "2022-04-11T00:54:59+00:00",
        "closed_at": "2022-04-11T00:54:59+00:00",
        "comments_count": [
            "yt605155624",
            "jiangjiajun",
            "SWHL"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1689,
        "title": "[vec]complete the speaker verification notes and speakers in yaml",
        "body": "complete the speaker verification notes and speakers in yaml\r\nNow the speakers in conf/ecapa_tdnn.yaml is 1211, but the speakers in vox1&vox2 is 7205",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "LeoMax-Xiong",
        "created_at": "2022-04-11T15:44:12+00:00",
        "updated_at": "2022-04-12T07:01:16+00:00",
        "closed_at": "2022-04-12T07:01:16+00:00",
        "comments_count": [],
        "labels": [
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1695,
        "title": "[vec][server] vpr demo support",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "zh794390558",
        "created_at": "2022-04-13T10:28:45+00:00",
        "updated_at": "2022-04-15T03:50:25+00:00",
        "closed_at": "2022-04-15T03:50:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1683,
        "title": "paddlespeech_ctcdecoders 这个库windows下载不了",
        "body": "paddlespeech_ctcdecoders 这个库下载不了，所以swig_wrapper.py没法用。。。\r\n",
        "state": "closed",
        "user": "qqqkoko123",
        "closed_by": "yt605155624",
        "created_at": "2022-04-08T12:10:35+00:00",
        "updated_at": "2022-07-13T10:01:31+00:00",
        "closed_at": "2022-05-30T02:51:47+00:00",
        "comments_count": [
            "zh794390558",
            "Jackwaterveg",
            "SWHL",
            "zh794390558",
            "Doubledongli"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1685,
        "title": "csmsc/tts3 推理报错:Tensor holds the wrong type, it holds int64_t, but desires to be int",
        "body": "### 测试环境:\r\n  ```text\r\n  OS: CentOS\r\n  python: 3.7\r\n  paddlepaddle-gpu: 2.2.2.post101\r\n  ```\r\n\r\n### 运行代码\r\n- 提前下载好`pretrained_model`到`${MAIN_ROOT}`下\r\n  ```text\r\n  pretrained_model/\r\n  ├── fastspeech2_nosil_baker_ckpt_0.4\r\n  │   ├── default.yaml\r\n  │   ├── energy_stats.npy\r\n  │   ├── phone_id_map.txt\r\n  │   ├── pitch_stats.npy\r\n  │   ├── snapshot_iter_76000.pdz\r\n  │   └── speech_stats.npy\r\n  └── pwg_baker_ckpt_0.4\r\n      ├── pwg_default.yaml\r\n      ├── pwg_snapshot_iter_400000.pdz\r\n      └── pwg_stats.npy\r\n  ```\r\n- 在`examples/csmsc/tts3`创建`main.sh`脚本，输入以下代码：\r\n    ```bash\r\n    source path.sh\r\n    \r\n    FLAGS_allocator_strategy=naive_best_fit \\\r\n    FLAGS_fraction_of_gpu_memory_to_use=0.01 \\\r\n    \r\n    model_dir=\"${MAIN_ROOT}/pretrained_model\"\r\n    \r\n    python ${BIN_DIR}/../synthesize_e2e.py \\\r\n      --am=fastspeech2_csmsc \\\r\n      --am_config\"=${model_dir}/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\" \\\r\n      --am_ckpt=\"${model_dir}/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\" \\\r\n      --am_stat=\"${model_dir}/fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy\"  \\\r\n      --voc=pwgan_csmsc \\\r\n      --voc_config=\"${model_dir}/pwg_baker_ckpt_0.4/pwg_default.yaml\" \\\r\n      --voc_ckpt=\"${model_dir}/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\" \\\r\n      --voc_stat=\"${model_dir}/pwg_baker_ckpt_0.4/pwg_stats.npy\" \\\r\n      --lang=zh \\\r\n      --text=${BIN_DIR}/../sentences.txt \\\r\n      --output_dir=exp/default/test_e2e \\\r\n      --inference_dir=exp/default/inference \\\r\n      --phones_dict=\"${model_dir}/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\"\r\n    ```\r\n#### 报错信息\r\n```python\r\n========Args========\r\nam: fastspeech2_csmsc\r\nam_ckpt: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\r\nam_config: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\nam_stat: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy\r\ninference_dir: exp/default/inference\r\nlang: zh\r\nngpu: 1\r\noutput_dir: exp/default/test_e2e\r\nphones_dict: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\r\nspeaker_dict: null\r\nspk_id: 0\r\ntext: /da2/SWHL/_exp/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../sentences.txt\r\ntones_dict: null\r\nvoc: pwgan_csmsc\r\nvoc_ckpt: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\r\nvoc_config: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/pwg_baker_ckpt_0.4/pwg_default.yaml\r\nvoc_stat: /da2/SWHL/_exp/PaddleSpeech-develop/pretrained_model/pwg_baker_ckpt_0.4/pwg_stats.npy\r\n\r\n========Config========\r\nbatch_size: 64\r\nf0max: 400\r\nf0min: 80\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\nmax_epoch: 1000\r\nmodel:\r\n  adim: 384\r\n  aheads: 2\r\n  decoder_normalize_before: True\r\n  dlayers: 4\r\n  dunits: 1536\r\n  duration_predictor_chans: 256\r\n  duration_predictor_kernel_size: 3\r\n  duration_predictor_layers: 2\r\n  elayers: 4\r\n  encoder_normalize_before: True\r\n  energy_embed_dropout: 0.0\r\n  energy_embed_kernel_size: 1\r\n  energy_predictor_chans: 256\r\n  energy_predictor_dropout: 0.5\r\n  energy_predictor_kernel_size: 3\r\n  energy_predictor_layers: 2\r\n  eunits: 1536\r\n  init_dec_alpha: 1.0\r\n  init_enc_alpha: 1.0\r\n  init_type: xavier_uniform\r\n  pitch_embed_dropout: 0.0\r\n  pitch_embed_kernel_size: 1\r\n  pitch_predictor_chans: 256\r\n  pitch_predictor_dropout: 0.5\r\n  pitch_predictor_kernel_size: 5\r\n  pitch_predictor_layers: 5\r\n  positionwise_conv_kernel_size: 3\r\n  positionwise_layer_type: conv1d\r\n  postnet_chans: 256\r\n  postnet_filts: 5\r\n  postnet_layers: 5\r\n  reduction_factor: 1\r\n  stop_gradient_from_energy_predictor: False\r\n  stop_gradient_from_pitch_predictor: True\r\n  transformer_dec_attn_dropout_rate: 0.2\r\n  transformer_dec_dropout_rate: 0.2\r\n  transformer_dec_positional_dropout_rate: 0.2\r\n  transformer_enc_attn_dropout_rate: 0.2\r\n  transformer_enc_dropout_rate: 0.2\r\n  transformer_enc_positional_dropout_rate: 0.2\r\n  use_scaled_pos_enc: True\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_snapshots: 5\r\nnum_workers: 4\r\noptimizer:\r\n  learning_rate: 0.001\r\n  optim: adam\r\nseed: 10086\r\nupdater:\r\n  use_masking: True\r\nwin_length: 1200\r\nwindow: hann\r\nallow_cache: True\r\nbatch_max_steps: 25500\r\nbatch_size: 6\r\ndiscriminator_grad_norm: 1\r\ndiscriminator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ndiscriminator_params:\r\n  bias: True\r\n  conv_channels: 64\r\n  in_channels: 1\r\n  kernel_size: 3\r\n  layers: 10\r\n  nonlinear_activation: LeakyReLU\r\n  nonlinear_activation_params:\r\n    negative_slope: 0.2\r\n  out_channels: 1\r\n  use_weight_norm: True\r\ndiscriminator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 5e-05\r\n  step_size: 200000\r\ndiscriminator_train_start_steps: 100000\r\neval_interval_steps: 1000\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\ngenerator_grad_norm: 10\r\ngenerator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ngenerator_params:\r\n  aux_channels: 80\r\n  aux_context_window: 2\r\n  bias: True\r\n  dropout: 0.0\r\n  freq_axis_kernel_size: 1\r\n  gate_channels: 128\r\n  in_channels: 1\r\n  interpolate_mode: nearest\r\n  kernel_size: 3\r\n  layers: 30\r\n  nonlinear_activation: None\r\n  nonlinear_activation_params:\r\n    \r\n  out_channels: 1\r\n  residual_channels: 64\r\n  skip_channels: 64\r\n  stacks: 3\r\n  upsample_scales: [4, 5, 3, 5]\r\n  use_causal_conv: False\r\n  use_weight_norm: True\r\ngenerator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 0.0001\r\n  step_size: 200000\r\nlambda_adv: 4.0\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_save_intermediate_results: 4\r\nnum_snapshots: 10\r\nnum_workers: 4\r\npin_memory: True\r\nremove_short_samples: True\r\nsave_interval_steps: 5000\r\nseed: 42\r\nstft_loss_params:\r\n  fft_sizes: [1024, 2048, 512]\r\n  hop_sizes: [120, 240, 50]\r\n  win_lengths: [600, 1200, 240]\r\n  window: hann\r\ntop_db: 60\r\ntrain_max_steps: 400000\r\ntrim_frame_length: 2048\r\ntrim_hop_length: 512\r\ntrim_silence: False\r\nwin_length: 1200\r\nwindow: hann\r\nfrontend done!\r\nvocab_size: 268\r\nW0409 16:39:01.139977 31890 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 10.1, Runtime API Version: 10.1\r\nW0409 16:39:01.145202 31890 device_context.cc:465] device: 0, cuDNN Version: 7.6.\r\nencoder_type is transformer\r\ndecoder_type is transformer\r\n/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/framework/io.py:415: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  if isinstance(obj, collections.Iterable) and not isinstance(obj, (\r\nacoustic model done!\r\nvoc done!\r\n/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  return (isinstance(seq, collections.Sequence) and\r\n/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/framework.py:2253: UserWarning: The Attr(force_cpu) of Op(fill_constant) will be deprecated in the future, please use 'device_guard' instead. 'device_guard' has higher priority when they are used at the same time.\r\n  \"used at the same time.\" % type)\r\n/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/framework.py:744: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  elif dtype == np.bool:\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-04-09 16:39:17] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2022-04-09 16:39:17] [DEBUG] [__init__.py:133] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.653 seconds.\r\n[2022-04-09 16:39:18] [DEBUG] [__init__.py:165] Loading model cost 0.653 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-04-09 16:39:18] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\nTraceback (most recent call last):\r\n  File \"/da2/SWHL/_exp/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 250, in <module>\r\n    main()\r\n  File \"/da2/SWHL/_exp/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 246, in main\r\n    evaluate(args)\r\n  File \"/da2/SWHL/_exp/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 106, in evaluate\r\n    mel = am_inference(part_phone_ids)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/dygraph/io.py\", line 1279, in __i_m_p_l__\r\n    return _run_dygraph(self, input, program_holder)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/dygraph/io.py\", line 829, in _run_dygraph\r\n    'program_id': _hash_with_id(trace_program)\r\n  File \"/da2/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op\r\n    not stop_gradient)\r\nValueError: (InvalidArgument) Tensor holds the wrong type, it holds int64_t, but desires to be int\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] (at /paddle/paddle/fluid/framework/tensor_impl.h:51)\r\n  [operator < reshape2 > error]  [operator < run_program > error]\r\n```",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "yt605155624",
        "created_at": "2022-04-09T08:49:24+00:00",
        "updated_at": "2022-04-15T06:59:53+00:00",
        "closed_at": "2022-04-15T06:59:53+00:00",
        "comments_count": [
            "yt605155624",
            "jerryuhoo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1686,
        "title": "deepspeech2如何从pretrained model导出inference model???",
        "body": "ds2如何从pretrained model导出inference model???",
        "state": "closed",
        "user": "frotms",
        "closed_by": "frotms",
        "created_at": "2022-04-09T10:37:00+00:00",
        "updated_at": "2022-04-11T02:07:29+00:00",
        "closed_at": "2022-04-11T02:07:29+00:00",
        "comments_count": [
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1705,
        "title": "[asr][server]add asr conformer online server",
        "body": "Please asr conformer online server",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-15T10:46:26+00:00",
        "updated_at": "2022-04-19T16:20:39+00:00",
        "closed_at": "2022-04-19T16:20:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1702,
        "title": "[asr][websocket]the server get the bytes result, not the str",
        "body": "the websocket_client.py get the bytes result from the server, and it does not convert it to string",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-14T11:55:02+00:00",
        "updated_at": "2022-04-19T16:20:39+00:00",
        "closed_at": "2022-04-19T16:20:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1699,
        "title": "[TTS]VITS",
        "body": "论文：\r\n- https://arxiv.org/abs/2106.06103\r\n\r\npaper reading: \r\n- https://mp.weixin.qq.com/s/eoviPIPkmd4cI9nEXdxrhA\r\n- https://zhuanlan.zhihu.com/p/419883319\r\n- [举世无双语音合成系统 VITS 发展历程](https://zhuanlan.zhihu.com/p/474601997)\r\n\r\n复现：\r\n- 官方：https://github.com/jaywalnut310/vits\r\n- espnet：https://github.com/espnet/espnet/blob/master/egs2/csmsc/tts1/conf/tuning/train_vits.yaml\r\nhttps://github.com/espnet/espnet/blob/master/egs2/csmsc/tts1/conf/tuning/train_full_band_vits.yaml\r\n- coqui tts：https://github.com/coqui-ai/TTS/blob/main/TTS/tts/models/vits.py \r\n- coqui tts：https://github.com/Edresson/YourTTS/ （基于 VITS 的 zero shot 的多说话人和多语言模型）\r\n\r\n参考文献：\r\n1. [变分自编码器（一）：原来是这么一回事](https://spaces.ac.cn/archives/5253)\r\n2. [VAE变分自编码机详解——原理篇](https://zhuanlan.zhihu.com/p/108262170?from_voters_page=true)\r\n3. [细水长flow之NICE：流模型的基本概念与实现](https://spaces.ac.cn/archives/5776)\r\n4. [细水长flow之RealNVP与Glow：流模型的传承与升华](https://spaces.ac.cn/archives/5807)\r\n5. [细水长flow之f-VAEs：Glow与VAEs的联姻](https://spaces.ac.cn/archives/5977)\r\n6. [当VAE遇到TTS——基于VAE的语音风格迁移](https://zhuanlan.zhihu.com/p/106943196)\r\n\r\n2-Stage 语音合成面临的挑战\r\n1. 声学模型 + 声码器有可能需要用 GTA mel finetune 声码器，如果声码器是 HiFiGAN、MB MelGAN 这种输入不带 noise 的 GAN Vocoder，不 finetune 可能合成的音频会有明显的金属感，这导致训练过程很复杂\r\n  a. 训练声学模型（不考虑 MFA 训练的话）\r\n  b. 训练声码器\r\n  c. 用训练好的声学模型生成的 GTA mel finetune 声码器\r\n2. 使用 mel 频谱等特征作为中间特征，限制了语音合成效果的进一步提升，直接一步到位可能更好\r\n3. 推理时间长、部署复杂\r\n\r\nFastSpeech2s \r\n1. text2wav 面临的挑战\r\n  a. wav 含有相位信息，text2mel 比 text2wav 面临的 gap 更大\r\n  b. 由于 GPU 内存的限制，输入只能是 clip of audio，part of text，这损害的输入文本之间的相关性，使得文本 embedding 更难学习\r\n2. 解决办法：\r\n  a. wav decoder，对抗性训练 ，结构是类似于 WaveNet 的结构，判别器用的是 PWGAN 的判别器\r\n  b. mel-spectrogram decoder来辅助文本特征表示的学习\r\n3. 效果，原论文的 MOS 值是 fastspeech2s < fastspeech2 +  pwgan\r\n\r\nVITS\r\n\r\n1. Posterior encoder\r\n非因果 WaveNet 残差模块\r\n3. Prior encoder (self.text_encoder 和 self.flow)\r\n包括文本编码器和提升先验分布多样性的标准化流, 标准化流模块包含若干 WaveNet 的残差块\r\n5. Decoder\r\n与 HiFi-GAN V1 的生成器结构相同\r\n6. Discriminator\r\n与 HiFI-GAN 中的多周期判别器结构相同\r\n7. Stochastic duration predictor\r\n与 Glow-TTS 相似的单调对齐搜索 (Monotonic Alignment Search, MAS) \r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "lym0302",
        "created_at": "2022-04-14T06:13:54+00:00",
        "updated_at": "2023-05-16T06:58:57+00:00",
        "closed_at": "2022-07-18T03:22:24+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "LifeIsStrange",
            "yt605155624",
            "jucaowei",
            "yt605155624",
            "Chopin68",
            "yt605155624",
            "jucaowei",
            "jucaowei",
            "Chopin68",
            "jucaowei"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1717,
        "title": "[vec] support large scale speaker training",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "qingen",
        "created_at": "2022-04-19T07:43:53+00:00",
        "updated_at": "2022-04-20T03:30:08+00:00",
        "closed_at": "2022-04-20T03:30:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1706,
        "title": "!paddlespeech asr --lang en --model transformer_librispeech --input demo.wav  taking forever to produce output",
        "body": "![Screenshot (393)](https://user-images.githubusercontent.com/74759605/163564485-8867ca37-d9ee-4e5e-b8c6-4d1a1235beb8.png)\r\n",
        "state": "closed",
        "user": "foyezkabir",
        "closed_by": "foyezkabir",
        "created_at": "2022-04-15T11:14:02+00:00",
        "updated_at": "2022-04-15T12:36:34+00:00",
        "closed_at": "2022-04-15T12:36:34+00:00",
        "comments_count": [
            "foyezkabir",
            "zh794390558",
            "foyezkabir"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1708,
        "title": "尝试voice clone 示例时失败PaddleSpeech/examples/aishell3/vc1/",
        "body": "如标题，设备环境\r\n操作系统Ubuntu20.04\r\n显卡3070ti，nvidia-smi显示cuda version\r\nnvcc -V 显示\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2020 NVIDIA Corporation\r\nBuilt on Tue_Sep_15_19:10:02_PDT_2020\r\nCuda compilation tools, release 11.1, V11.1.74\r\nBuild cuda_11.1.TC455_06.29069683_0\r\n首先是第一个**_怀疑_**的点，在termianl下进入`/usr/local `文件夹，发现存在两个cuda文件夹\r\n`cuda   cuda-11.1`\r\n仅安装过一次cuda-11.1并复制cudnn文件进相应的文件夹。但是在bashrc添加cuda-11.1的路径之后输入官方文档的import paddle等语句测试，发现无法检测到paddlepaddle。把路径改为cuda并复制相应的cudnn文件后，再次检测成功，paddlespeech可正常执行命令行语句\r\n按照文档下载aishell-3并保存于`datasets/data_aishell3` ，`vc1/aishell3_alignment_tone` ，`vc1/ge2e_ckpt_0.3` 后，执行`./run.sh --stage 0 --stop-stage 0`，首先出现下列信息_**多次提示nltk_data无法下载**_(已经按照文档下载解压保存在`/home`文件夹下)\r\nLoaded encoder ge2e_ckpt_0.3/step-3000000\r\n0 utterances in total\r\n0utterance [00:00, ?utterance/s]\r\nGenerate durations.txt from MFA results ...\r\nExtract features ...\r\n·················································\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/preprocess.py\", line 370, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/preprocess.py\", line 235, in main\r\n    assert rootdir.is_dir()\r\nAssertionError\r\n\r\n以及`dump` 文件夹下没有完整生成子文件夹\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\n\r\n/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\n/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/paddle/vision/transforms/functional_pil.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\r\n  'nearest': Image.NEAREST,\r\n\r\n/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\nNormalize ...\r\n\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 184, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 92, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\n\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 184, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 92, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/dev/raw/metadata.jsonl\r\n\r\n接着执行`CUDA_VISIBLE_DEVICES=0 ./local/preprocess.sh 、./conf ./ge2e_ckpt_0.3`时，出现如下信息\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 184, in <module>\r\n    main()\r\n  File \"/home/xht/SourceCode/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/normalize.py\", line 92, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/xht/.conda/envs/paddlespeech/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 623, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/test/raw/metadata.jsonl'",
        "state": "closed",
        "user": "QiFuChina",
        "closed_by": "yt605155624",
        "created_at": "2022-04-15T11:59:27+00:00",
        "updated_at": "2022-04-17T08:07:05+00:00",
        "closed_at": "2022-04-17T08:07:05+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1711,
        "title": "退出代码-1073741819 (0xC0000005)",
        "body": "代码一运行过会就停止了，尝试过网络上那些更改h5py版本办法 ，但是还是不行  。\r\n![image](https://user-images.githubusercontent.com/39285732/163667723-83167c8c-9f74-4387-8659-ef3c1ab92f8f.png)\r\n\r\n代码：\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='F:\\github\\py_speech_seg-master/1234.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n用的是windows 。\r\n",
        "state": "closed",
        "user": "standyyyy",
        "closed_by": "yt605155624",
        "created_at": "2022-04-16T08:16:18+00:00",
        "updated_at": "2022-05-30T02:31:50+00:00",
        "closed_at": "2022-05-30T02:31:50+00:00",
        "comments_count": [
            "zh794390558",
            "standyyyy",
            "zh794390558",
            "standyyyy",
            "Jackwaterveg",
            "standyyyy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1714,
        "title": "mac m1 怎么安装兼容?",
        "body": "mac m1 怎么安装兼容?",
        "state": "closed",
        "user": "DaxstUz",
        "closed_by": "yt605155624",
        "created_at": "2022-04-18T14:59:57+00:00",
        "updated_at": "2023-03-21T13:30:08+00:00",
        "closed_at": "2022-04-22T09:28:22+00:00",
        "comments_count": [
            "yt605155624",
            "Herz3h"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1721,
        "title": "[vec] deal with class imbalances",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "qingen",
        "created_at": "2022-04-20T02:17:11+00:00",
        "updated_at": "2022-04-20T06:42:31+00:00",
        "closed_at": "2022-04-20T06:42:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1718,
        "title": "Punctuation Restoration如何动转静？",
        "body": "在`punc_restore.py'73行后中加入\r\n```python\r\nstatic_model = jit.to_static(\r\n    model,\r\n    input_spec=[\r\n        InputSpec([-1], dtype=paddle.int64),\r\n        InputSpec([-1], dtype=paddle.int64),\r\n    ], )\r\nlogits, _ = static_model(input_ids, seg_ids)\r\n```\r\n报错：\r\n```\r\npaddlespeech/text/exps/ernie_linear/punc_restore.py\", line 84, in test\r\n    logits, _ = static_model(input_ids, seg_ids)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 921, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 911, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 378, in __call__\r\n    error_data.raise_new_exception()\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 336, in raise_new_exception\r\n    six.exec_(\"raise new_exception from None\")\r\n  File \"<string>\", line 1, in <module>\r\nValueError: In transformed code:\r\n\r\n    File \"/workspace/code/TextToSpeech/TrainScripts/PaddleSpeech/paddlespeech/text/models/ernie_linear/ernie_linear.py\", line 56, in forward\r\n                position_ids=None,\r\n                attention_mask=None):\r\n        y = self.ernie(\r\n        ~~~~~~~~~~~~~~~ <--- HERE\r\n            input_ids,\r\n            token_type_ids=token_type_ids,\r\n\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 921, in __call__\r\n        return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 911, in _dygraph_call_func\r\n        outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddlenlp/transformers/ernie/modeling.py\", line 588, in forward\r\n        sequence_output, _ = self.ernie(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 921, in __call__\r\n        return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 911, in _dygraph_call_func\r\n        outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddlenlp/transformers/ernie/modeling.py\", line 373, in forward\r\n        embedding_output = self.embeddings(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 921, in __call__\r\n        return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 911, in _dygraph_call_func\r\n        outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddlenlp/transformers/ernie/modeling.py\", line 71, in forward\r\n        embeddings = self.layer_norm(embeddings)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 921, in __call__\r\n        return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 911, in _dygraph_call_func\r\n        outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/nn/layer/norm.py\", line 535, in forward\r\n        return layer_norm(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/nn/functional/norm.py\", line 347, in layer_norm\r\n        helper.append_op(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 44, in append_op\r\n        return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3576, in append_op\r\n        op = Operator(\r\n    File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2596, in __init__\r\n        for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The first dimension value of Input(Scale) must equal to be thesecond dimension value of the flattened 2D matrix of Input(X),But received the first dimension value of Input(Scale) is[768], the second dimension value of the flattened 2D matrix of Input(Scale) is [19968].\r\n      [Hint: Expected ctx->GetInputDim(\"Scale\")[0] == right, but received ctx->GetInputDim(\"Scale\")[0]:768 != right:19968.] (at /paddle/paddle/fluid/operators/layer_norm_op.cc:71)\r\n      [operator < layer_norm > error]  [operator < run_program > error]\r\n```",
        "state": "closed",
        "user": "jerryuhoo",
        "closed_by": "yt605155624",
        "created_at": "2022-04-19T08:29:32+00:00",
        "updated_at": "2022-09-07T02:57:53+00:00",
        "closed_at": "2022-09-07T02:57:53+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1724,
        "title": "[vec] add GRL to domain adaptation",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "qingen",
        "created_at": "2022-04-20T06:44:54+00:00",
        "updated_at": "2022-04-20T14:33:14+00:00",
        "closed_at": "2022-04-20T14:33:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1753
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1730,
        "title": "[vec] support unsupervised learning",
        "body": null,
        "state": "closed",
        "user": "qingen",
        "closed_by": "LeoMax-Xiong",
        "created_at": "2022-04-20T14:34:49+00:00",
        "updated_at": "2022-04-25T03:41:42+00:00",
        "closed_at": "2022-04-25T03:41:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1726,
        "title": "关于asr模型的多batch推理",
        "body": "我这边想在asr的test_wav下实现多batch推理，然后我就简单的cat了两个相同的输入：（1,590,80）->（2,590,80）送入模型推理，理论上\r\nresult_transcripts出来两个推理结果应该是一样的，因为我cat的是两个相同输入。但是现在第一个结果是对的，第二个结果不对很奇怪\r\n![image](https://user-images.githubusercontent.com/93525180/164193568-94e1ad2f-3930-4dd3-9270-2eda09950597.png)\r\n请大佬帮我看下\r\n",
        "state": "closed",
        "user": "Chenwe111",
        "closed_by": "Jackwaterveg",
        "created_at": "2022-04-20T09:09:37+00:00",
        "updated_at": "2022-04-22T11:36:31+00:00",
        "closed_at": "2022-04-22T11:36:31+00:00",
        "comments_count": [
            "Jackwaterveg",
            "Jackwaterveg",
            "Chenwe111",
            "Jackwaterveg",
            "Chenwe111",
            "Jackwaterveg",
            "Chenwe111",
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1738,
        "title": "[asr][websocket]add streaming asr demo",
        "body": "add streaming asr demo",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-21T08:11:19+00:00",
        "updated_at": "2022-04-21T11:23:35+00:00",
        "closed_at": "2022-04-21T11:23:35+00:00",
        "comments_count": [],
        "labels": [
            "S2T",
            "Demo"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1745,
        "title": "[vec]Please add the vector voxceleb exp readme.md",
        "body": "Please add the vector voxceleb exp readme.md",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-21T16:20:34+00:00",
        "updated_at": "2022-04-22T02:37:54+00:00",
        "closed_at": "2022-04-22T02:37:54+00:00",
        "comments_count": [],
        "labels": [
            "Vector"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1755
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1734,
        "title": "可以通过 test_wav.sh实现多batch 实现前向推理吗？",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "silencervan",
        "closed_by": "iftaken",
        "created_at": "2022-04-21T06:55:12+00:00",
        "updated_at": "2022-07-07T09:58:27+00:00",
        "closed_at": "2022-07-07T09:58:27+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1773,
        "title": "[text]Please add the text server",
        "body": "Please add the text server and we can use it with streaming asr server",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-24T15:03:37+00:00",
        "updated_at": "2022-04-25T03:35:47+00:00",
        "closed_at": "2022-04-25T03:35:47+00:00",
        "comments_count": [],
        "labels": [
            "Server"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1780
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1807
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1756,
        "title": "语音翻译成文字，目前只支持英译汉吗？什么时候出个汉译英的？多谢",
        "body": "语音翻译成文字，目前只支持英译汉吗？什么时候出个汉译英的？多谢",
        "state": "closed",
        "user": "DidaDidaDidaD",
        "closed_by": "DidaDidaDidaD",
        "created_at": "2022-04-22T08:00:05+00:00",
        "updated_at": "2022-07-06T02:55:25+00:00",
        "closed_at": "2022-04-30T05:57:36+00:00",
        "comments_count": [
            "zh794390558",
            "DidaDidaDidaD",
            "zh794390558",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1775,
        "title": "[vec][server]Please add the speaker verification server",
        "body": "Please add the speaker verification server, and we want get the speaker service",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-25T03:00:17+00:00",
        "updated_at": "2022-05-05T10:06:17+00:00",
        "closed_at": "2022-05-05T10:06:17+00:00",
        "comments_count": [],
        "labels": [
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1763,
        "title": "Always the same speaker output in fastspeech2 aishell3 voice conversion",
        "body": "**Describe the bug**\r\nAlways the same speaker output in fastspeech2 aishell3 voice conversion\r\n\r\n**To Reproduce**\r\n1. [PaddleSpeech语音克隆](https://aistudio.baidu.com/aistudio/projectdetail/3475121?channelType=0&channel=0) always output the same speaker.\r\n2. When I change the synthesizer to Tacotron2, everything works fine, the model can generate different speaker speech.\r\n3. Here are some outputs I packed:\r\n[output_sound_fastspeech2.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/8546729/output_sound_fastspeech2.zip)\r\n[output_sound_tacotron2.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/8546739/output_sound_tacotron2.zip)\r\n\r\n",
        "state": "closed",
        "user": "HighCWu",
        "closed_by": "yt605155624",
        "created_at": "2022-04-23T10:38:20+00:00",
        "updated_at": "2022-08-12T09:18:16+00:00",
        "closed_at": "2022-04-26T11:06:41+00:00",
        "comments_count": [
            "zh794390558",
            "HighCWu",
            "yt605155624",
            "yt605155624",
            "HighCWu",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "sixyang"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1812,
        "title": "speechx will core dump when stop after start immediately",
        "body": "**Describe the bug**\r\nspeechx ws server will broken when start, and then stop immediately. \r\n\r\n**To Reproduce**\r\n![aaa5401d58cb779894b977a8e104584e](https://user-images.githubusercontent.com/3038472/165510142-ff6311c1-7331-4fe2-b4cc-9609c9d9c59d.jpg)\r\n\r\n",
        "state": "closed",
        "user": "zh794390558",
        "closed_by": "zh794390558",
        "created_at": "2022-04-27T11:40:02+00:00",
        "updated_at": "2022-05-12T12:10:03+00:00",
        "closed_at": "2022-05-12T12:10:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1785,
        "title": "Please add punctuation ability for asr",
        "body": "Please add punctuation ability for asr",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-04-25T07:53:40+00:00",
        "updated_at": "2022-04-25T09:45:33+00:00",
        "closed_at": "2022-04-25T09:45:33+00:00",
        "comments_count": [],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1816,
        "title": "[ TTS ] Vocoder(Pwgan): covert onnx model to TRT ERROR",
        "body": "In TTS,  I cover `Vocoder(Pwgan)` paddle model to onnx model with your code,  it is OK, and the onnx model is OK;\r\nThen I cover that onnx model to TensorRT model, It is error.  And the error is like that:\r\n```\r\nLoading ONNX file from path ../data/paddle_onnx/onnx_model/pwgan_aishell3.onnx...\r\nBeginning ONNX file parsing\r\n[04/27/2022-21:39:16] [TRT] [W] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\nCompleted parsing of ONNX file\r\nBuilding an engine from file ../data/paddle_onnx/onnx_model/pwgan_aishell3.onnx; this may take a while...\r\n[04/27/2022-21:39:16] [TRT] [E] 4: [network.cpp::validate::2633] Error Code 4: Internal Error (Network must have at least one output)\r\nCompleted creating Engine\r\nTraceback (most recent call last):\r\n  File \"onnx2trt_paddle.py\", line 95, in <module>\r\n    engine = ONNX_build_engine(onnx_file_path, trt_output, write_engine)\r\n  File \"onnx2trt_paddle.py\", line 44, in ONNX_build_engine\r\n    f.write(engine.serialize())\r\nAttributeError: 'NoneType' object has no attribute 'serialize'\r\n\r\n```\r\nThe code I use to cober TRT is just like this:\r\n<img width=\"419\" alt=\"1\" src=\"https://user-images.githubusercontent.com/27938135/165532168-d48efcf3-3a26-4aef-8c40-e969e937752f.png\">\r\n<img width=\"370\" alt=\"2\" src=\"https://user-images.githubusercontent.com/27938135/165532198-94856e6b-2793-463b-8ec0-7e5b8a718114.png\">\r\n\r\nI covert vocoder from `pytorch --> onnx --> TRT `is OK\r\n\r\n**So, Does** `paddle --> onnx` **model spport** `onnx --> TRT` **model ?**\r\n\r\n\r\n** Environment (please complete the following information):**\r\n - OS:  Ubuntu\r\n - Python Version:  3.7\r\n - GPU/DRIVER Informationo : GeForce RTX 3090\r\n - CUDA/CUDNN Version : cuda-11.2\r\n- TensorRT Version :  8.2.1.8\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-04-27T13:47:08+00:00",
        "updated_at": "2022-04-29T05:56:32+00:00",
        "closed_at": "2022-04-29T02:08:18+00:00",
        "comments_count": [
            "yt605155624",
            "Tian14267",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1841
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1842
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1837,
        "title": "[asr][server]Please add punctuation server to asr",
        "body": "Please add punctuation server to asr",
        "state": "closed",
        "user": "LeoMax-Xiong",
        "closed_by": "zh794390558",
        "created_at": "2022-05-02T12:15:20+00:00",
        "updated_at": "2022-05-05T11:50:30+00:00",
        "closed_at": "2022-05-05T11:50:30+00:00",
        "comments_count": [],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1819,
        "title": "识别长音频的需求",
        "body": "从其他的issue里看到最长识别时长是50s，但是在现实场景中一定是大于这个数值的，能否PaddleSpeech进行自动的切割，然后分段进行识别。使用场景可能为会议纪要。",
        "state": "closed",
        "user": "ChenjieXu",
        "closed_by": "yt605155624",
        "created_at": "2022-04-27T17:15:32+00:00",
        "updated_at": "2022-06-08T03:37:42+00:00",
        "closed_at": "2022-05-30T02:36:16+00:00",
        "comments_count": [
            "zh794390558",
            "DidaDidaDidaD",
            "ChenjieXu",
            "ChenjieXu",
            "DidaDidaDidaD",
            "zh794390558",
            "charmby",
            "zh794390558",
            "zHaOshuAnGye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1831,
        "title": "长语音识别效果还不错，就是没分片，而且没有时间信息",
        "body": "长语音识别效果还不错，就是没分片，而且没有时间信息，如果使用vad，发现分片数量越多，用paddlespeech识别的效果越差，看样子和上下文有关系，但音频开始和结尾识别的错误率明显挺大的。不知道什么时候能出长语音识别，同时断句以及时间信息",
        "state": "closed",
        "user": "DidaDidaDidaD",
        "closed_by": "yt605155624",
        "created_at": "2022-04-30T09:15:39+00:00",
        "updated_at": "2022-12-12T07:19:16+00:00",
        "closed_at": "2022-05-30T02:47:46+00:00",
        "comments_count": [
            "DidaDidaDidaD",
            "LeoMax-Xiong",
            "DidaDidaDidaD",
            "charmby",
            "LeoMax-Xiong",
            "yt605155624",
            "QuantumLiu",
            "SoulSnow"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1820,
        "title": "使用CLI的时候需要键盘输入",
        "body": "使用CLI的时候需要键盘输入 INPUT（Y/N），不太理解这个是干什么用的？\r\n能否提供使用脚本进行识别的例子？",
        "state": "closed",
        "user": "ChenjieXu",
        "closed_by": "ChenjieXu",
        "created_at": "2022-04-27T17:17:35+00:00",
        "updated_at": "2022-04-29T17:53:33+00:00",
        "closed_at": "2022-04-29T17:53:33+00:00",
        "comments_count": [
            "zh794390558",
            "Jackwaterveg",
            "ChenjieXu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1839,
        "title": "Add acknowledgment to WeNet",
        "body": "Parts of the `speechx` projects are basically the same as the ones used inside WeNet. I would recommend adding acknowledgment to WeNet in `speechx/README.md`.\r\n\r\n1. `websocket_server` and  `websocket_client` are basically equal to WebSocket in WeNet, see `diff` below:\r\n<img width=\"960\" alt=\"72cb781624f8454f74fa8b4be483165\" src=\"https://user-images.githubusercontent.com/13466943/166688197-06105606-57f7-460b-8279-1e10173d311d.png\">\r\n<img width=\"960\" alt=\"efabdb41e7d3d57f04465fd06edbfef\" src=\"https://user-images.githubusercontent.com/13466943/166688318-a7556c84-f4c7-4bc4-aebf-31f43c028ecf.png\">\r\n\r\n2. `openfst patch` is identical to WeNet, it is non-trivial to find proper patches and make them work correctly in the whole WeNet project. This kind of work is time-consuming but could be easily overlooked.\r\n",
        "state": "closed",
        "user": "xingchensong",
        "closed_by": "zh794390558",
        "created_at": "2022-05-04T13:23:02+00:00",
        "updated_at": "2022-05-08T10:20:56+00:00",
        "closed_at": "2022-05-05T03:11:30+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1834,
        "title": "希望能添加一下声纹识别的教程文档",
        "body": null,
        "state": "closed",
        "user": "landd1897",
        "closed_by": "yt605155624",
        "created_at": "2022-05-01T07:37:10+00:00",
        "updated_at": "2022-05-30T02:30:11+00:00",
        "closed_at": "2022-05-30T02:30:11+00:00",
        "comments_count": [
            "qingen",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1847,
        "title": "engine pool cannot initialize",
        "body": "env: ubuntu20.04, python3.8\r\n\r\n\r\ncommand:\r\n```\r\npaddlespeech_server start --config_file ./conf/tts_online_application.yaml\r\n```\r\n\r\n```\r\n/home/xxx/xxx/lib/python3.8/site-packages/sklearn/utils/multiclass.py:14: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\r\n  from scipy.sparse.base import spmatrix\r\n/home/xxx/xxx/lib/python3.8/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/xxx/xxx/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\r\n  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\r\n/home/xxx/xxx/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\r\n  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\r\nTraceback (most recent call last):\r\n  File \"/home/xxx/xxx/bin/paddlespeech_server\", line 8, in <module>\r\n    sys.exit(server_execute())\r\n  File \"/home/xxx/xxx/lib/python3.8/site-packages/paddlespeech/server/entry.py\", line 36, in server_execute\r\n    status = 0 if com['_entry']().execute(sys.argv[idx:]) else 1\r\n  File \"/home/xxx/xxx/lib/python3.8/site-packages/paddlespeech/server/bin/paddlespeech_server.py\", line 78, in execute\r\n    if self.init(config):\r\n  File \"/home/xxx/xxx/lib/python3.8/site-packages/paddlespeech/server/bin/paddlespeech_server.py\", line 69, in init\r\n    if not init_engine_pool(config):\r\n  File \"/home/xxx/xxx/lib/python3.8/site-packages/paddlespeech/server/engine/engine_pool.py\", line 37, in init_engine_pool\r\n    if not ENGINE_POOL[engine].init(config=config[engine_and_type]):\r\nAttributeError: 'NoneType' object has no attribute 'init'\r\n\r\n```\r\n\r\nwho can help me about this error?\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "vpegasus",
        "closed_by": "yt605155624",
        "created_at": "2022-05-06T01:16:57+00:00",
        "updated_at": "2022-05-06T14:33:59+00:00",
        "closed_at": "2022-05-06T14:33:45+00:00",
        "comments_count": [
            "lym0302",
            "vpegasus",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1895,
        "title": "PaddleSpeech跨域访问错误",
        "body": "使用PaddleSpeech Server在远程服务器部署标点服务后，本地客户端通过游览器的JS脚本访问对应接口，发生禁止跨域访问错误。\r\n\r\n开启服务代码：\r\n```shell\r\ncd demos/streaming_asr_server\r\n# 开启服务 8190端口\r\npaddlespeech_server start --config_file conf/punc_application.yaml\r\n```\r\n\r\n本地游览器访问对应的接口\r\n```js\r\nvar url = \"*.*.*.*:8190/paddlespeech/text\"\r\nconst result = axios.post(url, {text:text})\r\n```\r\n\r\n发生跨域访问错误 CORS policy\r\n![7e64959bda7ed39eec8e6e9a2bf27d77](https://user-images.githubusercontent.com/30135920/168252478-0bcae329-c061-44b2-b3a3-4adbd8e7bdd3.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "iftaken",
        "closed_by": "yt605155624",
        "created_at": "2022-05-13T09:16:47+00:00",
        "updated_at": "2022-05-13T12:12:40+00:00",
        "closed_at": "2022-05-13T12:12:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1867,
        "title": "ubuntu安装时显示版本冲突",
        "body": "![image](https://user-images.githubusercontent.com/23391279/167234273-6b7aa644-6342-4b50-84ef-f19b18bfd84b.png)\r\n我看之前的issue好像有人也出现了类似的问题，但是不知道是怎么解决的。python版本3.6.9 ubuntu版本18.04.5",
        "state": "closed",
        "user": "PoPdark",
        "closed_by": "yt605155624",
        "created_at": "2022-05-07T02:28:35+00:00",
        "updated_at": "2022-05-17T09:30:53+00:00",
        "closed_at": "2022-05-12T11:01:48+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1875,
        "title": "streaming service /service 如何使用pretrained 之外的模型？",
        "body": "配置文件里am 选择为['fastspeech2_csmsc_onnx', 'fastspeech2_cnndecoder_csmsc_onnx']\r\n如何使用自己训练的模型搭建服务？",
        "state": "closed",
        "user": "bingyulab",
        "closed_by": "yt605155624",
        "created_at": "2022-05-09T02:21:49+00:00",
        "updated_at": "2022-06-17T09:02:17+00:00",
        "closed_at": "2022-05-11T05:32:49+00:00",
        "comments_count": [
            "lym0302",
            "lym0302",
            "bingyulab",
            "lym0302",
            "bingyulab",
            "yt605155624",
            "Jackiexiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1876,
        "title": "请问如何实现tts--fastspeech2多说话人的语音时长修改？",
        "body": "你好，现在的paddlespeech的TTS，能够转换成静态模型和inference版本的，都是默认时长参数为1.0的。如果我想把模型的语音时长参数调整为0.8，然后在把模型转换成静态模型，实现一个快语速的静态模型，请问该如何实现？",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-05-09T08:26:28+00:00",
        "updated_at": "2022-05-10T08:01:50+00:00",
        "closed_at": "2022-05-10T08:01:50+00:00",
        "comments_count": [
            "yt605155624",
            "Tian14267"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1886,
        "title": "关于TTS的采样率为8k时的参数配置问题",
        "body": "大佬你好，我想咨询一下，如果我想把 TTS 的采样率改成 8k 的话，那么我训练**声学模型**和**声码器**的话，参数应该怎么调整？麻烦大佬给个建议啊。\r\n\r\n<img width=\"426\" alt=\"1\" src=\"https://user-images.githubusercontent.com/27938135/167974773-19568708-f4c4-4799-9669-048e5114fa57.png\">\r\n<img width=\"408\" alt=\"02\" src=\"https://user-images.githubusercontent.com/27938135/167974784-73e81a80-5e0e-41f3-9de2-1b3603e646ff.png\">\r\n<img width=\"539\" alt=\"3\" src=\"https://user-images.githubusercontent.com/27938135/167974789-1d957282-7fc4-4b74-9a00-de0617c2f661.png\">\r\n\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-05-12T01:40:17+00:00",
        "updated_at": "2022-05-13T06:03:24+00:00",
        "closed_at": "2022-05-12T11:01:54+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "Tian14267"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1883,
        "title": "AISHELL-1下面asr0，静态图推理报错No stack trace in paddle, may be caused by external reasons.",
        "body": "在基于AISHELL1复现deepspeech2_online时，导出静态图后测试时遇到以下问题，请问是什么原因呢\r\n\r\n```\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1652237584 (unix time) try \"date -d @1652237584\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30378 (TID 0x7f82ea7fb240) from PID 0 ***]\r\n\r\n./local/test_export.sh: line 28: 30378 Segmentation fault      (core dumped) python3 -u ${BIN_DIR}/test_export.py --ngpu ${ngpu} --config ${config_path} --decode_cfg ${decode_config_path} --result_file ${jit_model_export_path}.rsl --export_path ${jit_model_export_path} --model_type ${model_type}\r\nFailed in evaluation!\r\n\r\n```\r\n",
        "state": "closed",
        "user": "yingzhao27",
        "closed_by": "yt605155624",
        "created_at": "2022-05-11T03:27:48+00:00",
        "updated_at": "2022-05-30T02:38:38+00:00",
        "closed_at": "2022-05-30T02:38:38+00:00",
        "comments_count": [
            "Jackwaterveg",
            "yingzhao27",
            "zh794390558",
            "yingzhao27",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1900,
        "title": "标点服务器帮助 (python3)",
        "body": "标点服务器帮助 (python3)",
        "state": "closed",
        "user": "kmeitidenu",
        "closed_by": "yt605155624",
        "created_at": "2022-05-14T03:47:22+00:00",
        "updated_at": "2022-06-28T11:52:56+00:00",
        "closed_at": "2022-06-28T11:52:56+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1908,
        "title": "如何提升TTS在CPU下的推断速度？",
        "body": "现在的服务器的CPU环境是4核4线程，模型使用的是fastspeech2和parallelwaveGAN，推断一个7字车牌号需要4s的时间。目前cpu占用是100%，请问如何提升推断速度，需要启动多核推断吗，还是进行模型压缩？",
        "state": "closed",
        "user": "Kevinkaiyan",
        "closed_by": "yt605155624",
        "created_at": "2022-05-16T06:13:25+00:00",
        "updated_at": "2023-04-18T06:37:31+00:00",
        "closed_at": "2022-05-19T03:09:38+00:00",
        "comments_count": [
            "yt605155624",
            "Kevinkaiyan",
            "yt605155624",
            "MingyuLau",
            "MingyuLau",
            "nuass"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1909,
        "title": "TTS功能无法输出英文语音",
        "body": "使用的是简单模式的命令行输出，仅能输出中文和数字。\r\n请问需要什么额外的配置吗？谢谢",
        "state": "closed",
        "user": "YukiRus",
        "closed_by": "YukiRus",
        "created_at": "2022-05-16T10:04:29+00:00",
        "updated_at": "2022-05-17T02:28:34+00:00",
        "closed_at": "2022-05-17T02:28:34+00:00",
        "comments_count": [
            "yt605155624",
            "YukiRus"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1922,
        "title": "无法转换为音频",
        "body": "我通过/paddlespeech/tts/streaming这个接口获取到音频的base64编码，但是无法转码为音频文件，尝试了MP3格式和WAV格式",
        "state": "closed",
        "user": "CHSSea",
        "closed_by": "CHSSea",
        "created_at": "2022-05-19T13:02:06+00:00",
        "updated_at": "2023-08-25T07:11:25+00:00",
        "closed_at": "2022-05-20T01:10:51+00:00",
        "comments_count": [
            "zh794390558",
            "CHSSea",
            "CHSSea",
            "lym0302",
            "shaoxiang",
            "wuxiy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1925,
        "title": "❣️ [nltk_data] zipfile.BadZipFile: File is not a zip file",
        "body": "运行的时候报错\r\nTraceback (most recent call last):\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/cli/__init__.py\", line 23, in <module>\r\n    from .tts import TTSExecutor\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/cli/tts/infer.py\", line 36, in <module>\r\n    from paddlespeech.t2s.frontend import English\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/t2s/__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/t2s/frontend/__init__.py\", line 16, in <module>\r\n    from .phonectic import *\r\n  File \"/home/user/Database/temp_workspace/PaddleSpeech/paddlespeech/t2s/frontend/phonectic.py\", line 20, in <module>\r\n    from g2p_en import G2p\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/g2p_en/__init__.py\", line 1, in <module>\r\n    from .g2p import G2p\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/g2p_en/g2p.py\", line 26, in <module>\r\n    nltk.data.find('corpora/cmudict.zip')\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/nltk/data.py\", line 542, in find\r\n    return ZipFilePathPointer(p, zipentry)\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/nltk/data.py\", line 394, in __init__\r\n    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/site-packages/nltk/data.py\", line 935, in __init__\r\n    zipfile.ZipFile.__init__(self, filename)\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/zipfile.py\", line 1258, in __init__\r\n    self._RealGetContents()\r\n  File \"/home/caopu/anaconda3/envs/pad/lib/python3.7/zipfile.py\", line 1325, in _RealGetContents\r\n    raise BadZipFile(\"File is not a zip file\")\r\nzipfile.BadZipFile: File is not a zip file\r\n请问是那个包有冲突么，下边是我的环境：\r\naiohttp            3.8.1\r\naiosignal          1.2.0\r\nanyio              3.6.1\r\nappdirs            1.4.4\r\nasgiref            3.5.2\r\nastor              0.8.1\r\nasync-timeout      4.0.2\r\nasynctest          0.13.0\r\nattrs              21.4.0\r\naudioread          2.1.9\r\nBabel              2.10.1\r\nbce-python-sdk     0.8.64\r\nBottleneck         1.3.4\r\ncached-property    1.5.2\r\ncertifi            2022.5.18.1\r\ncffi               1.15.0\r\ncfgv               3.3.1\r\ncharset-normalizer 2.0.12\r\nclick              8.1.3\r\ncolorama           0.4.4\r\ncolorlog           6.6.0\r\ncycler             0.11.0\r\nCython             0.29.30\r\ndatasets           2.2.1\r\ndecorator          5.1.1\r\ndill               0.3.5\r\nDistance           0.1.3\r\ndistlib            0.3.4\r\ndtaidistance       2.3.1\r\neditdistance       0.6.0\r\nfastapi            0.78.0\r\nfilelock           3.7.0\r\nflake8             4.0.1\r\nFlask              2.1.2\r\nFlask-Babel        2.0.0\r\nflatbuffers        2.0\r\nfonttools          4.33.3\r\nfrozenlist         1.3.0\r\nfsspec             2022.5.0\r\nfuture             0.18.2\r\ng2p-en             2.1.0\r\ng2pM               0.1.2.5\r\nh11                0.13.0\r\nh5py               3.6.0\r\nhuggingface-hub    0.6.0\r\nidentify           2.5.1\r\nidna               3.3\r\nimportlib-metadata 4.2.0\r\ninflect            5.6.0\r\nitsdangerous       2.1.2\r\njieba              0.42.1\r\nJinja2             3.1.2\r\njoblib             1.1.0\r\njsonlines          3.0.0\r\nkaldiio            2.17.2\r\nkiwisolver         1.4.2\r\nlibrosa            0.8.1\r\nllvmlite           0.38.0\r\nloguru             0.6.0\r\nMarkupSafe         2.1.1\r\nmatplotlib         3.5.2\r\nmccabe             0.6.1\r\nmock               4.0.3\r\nmultidict          6.0.2\r\nmultiprocess       0.70.12.2\r\nnara-wpe           0.0.8\r\nnltk               3.7\r\nnodeenv            1.6.0\r\nnumba              0.55.1\r\nnumpy              1.21.6\r\nonnx               1.9.0\r\nonnxruntime        1.11.1\r\nopt-einsum         3.3.0\r\npackaging          21.3\r\npaddle-bfloat      0.1.2\r\npaddle2onnx        0.9.6\r\npaddleaudio        1.0.0\r\npaddlefsl          1.1.0\r\npaddlenlp          2.3.1\r\npaddlepaddle       2.3.0\r\npaddlepaddle-gpu   2.3.0.post112\r\npaddlespeech       0.0.0\r\npaddlespeech-feat  0.1.0\r\npandas             1.3.5\r\npathos             0.2.8\r\npattern-singleton  1.2.0\r\nPillow             9.1.1\r\npip                21.2.2\r\nplatformdirs       2.5.2\r\npooch              1.6.0\r\nportalocker        2.4.0\r\npox                0.3.1\r\nppft               1.7.6.5\r\npraatio            5.0.0\r\npre-commit         2.19.0\r\nprettytable        3.3.0\r\nprotobuf           3.20.1\r\npyarrow            8.0.0\r\npycodestyle        2.8.0\r\npycparser          2.21\r\npycryptodome       3.14.1\r\npydantic           1.9.1\r\npyflakes           2.4.0\r\npyparsing          3.0.9\r\npypinyin           0.46.0\r\npypinyin-dict      0.2.0\r\npytest-runner      6.0.0\r\npython-dateutil    2.8.2\r\npytz               2022.1\r\npyworld            0.3.0\r\nPyYAML             6.0\r\nregex              2022.4.24\r\nrequests           2.27.1\r\nresampy            0.2.2\r\nresponses          0.18.0\r\nsacrebleu          2.1.0\r\nscikit-learn       1.0.2\r\nscipy              1.7.3\r\nsentencepiece      0.1.96\r\nseqeval            1.2.2\r\nsetuptools         61.2.0\r\nshellcheck-py      0.8.0.4\r\nsix                1.16.0\r\nsniffio            1.2.0\r\nSoundFile          0.10.3.post1\r\nstarlette          0.19.1\r\ntabulate           0.8.9\r\nTextGrid           1.5\r\nthreadpoolctl      3.1.0\r\ntimer              0.2.2\r\ntoml               0.10.2\r\ntqdm               4.64.0\r\ntypeguard          2.13.3\r\ntyping_extensions  4.2.0\r\nurllib3            1.26.9\r\nuvicorn            0.17.6\r\nvirtualenv         20.14.1\r\nvisualdl           2.2.3\r\nwcwidth            0.2.5\r\nwebrtcvad          2.0.10\r\nwebsockets         10.3\r\nWerkzeug           2.1.2\r\nwheel              0.37.1\r\nxxhash             3.0.0\r\nyacs               0.1.8\r\nyarl               1.7.2\r\nzhon               1.1.5\r\nzipp               3.8.0\r\n我重新安装过一次环境，执行了 pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n还是这个错误",
        "state": "open",
        "user": "qiuyuzhao",
        "closed_by": "qiuyuzhao",
        "created_at": "2022-05-20T04:09:11+00:00",
        "updated_at": "2023-02-08T10:52:35+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "zh794390558",
            "alphasnow"
        ],
        "labels": [
            "Installation",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1923,
        "title": "ImportError",
        "body": "运行的时候提示importerror，ImportError: cannot import name '_non_static_mode' from 'paddle.fluid.framework' (/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/framework.py)\r\n\r\n\r\nFile \"/home/caopu/workspace/PaddleSpeech/wav_vec.py\", line 1, in <module>\r\n    import paddle\r\n  File \"/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/__init__.py\", line 47, in <module>\r\n    import paddle.distribution  # noqa: F401\r\n  File \"/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/distribution/__init__.py\", line 15, in <module>\r\n    from paddle.distribution import transform\r\n  File \"/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/distribution/transform.py\", line 24, in <module>\r\n    from paddle.distribution import (constraint, distribution,\r\n  File \"/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/distribution/distribution.py\", line 33, in <module>\r\n    from paddle.fluid.framework import _non_static_mode, in_dygraph_mode\r\nImportError: cannot import name '_non_static_mode' from 'paddle.fluid.framework' (/home/caopu/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/framework.py)\r\n请问这是什么原因，是我没有安装对么",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "qiuyuzhao",
        "created_at": "2022-05-20T02:23:37+00:00",
        "updated_at": "2022-05-20T04:06:52+00:00",
        "closed_at": "2022-05-20T04:06:52+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1933,
        "title": "可以设置不检测paddlespeech-ctcdecoders 这个组件？",
        "body": "语音识别执行命令：\r\npaddlespeech asr --lang zh --input  C:\\Users\\Administrator\\Desktop\\test.wav -v\r\n\r\n一直检测paddlespeech-ctcdecoders 组件但是又没起到作用，执行命令识别比较慢，是否可以去除这个检测机制\r\n![image](https://user-images.githubusercontent.com/44693150/169677231-2ebb06ad-f1fc-4e95-bb59-92930b47159c.png)\r\n\r\n",
        "state": "closed",
        "user": "MrJson1",
        "closed_by": "yt605155624",
        "created_at": "2022-05-22T03:35:28+00:00",
        "updated_at": "2022-05-30T15:37:01+00:00",
        "closed_at": "2022-05-30T15:37:01+00:00",
        "comments_count": [
            "Jackwaterveg",
            "MrJson1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1926,
        "title": "采样率",
        "body": "请问想推理44100hz采样率的音频应该用那个模型？",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "yt605155624",
        "created_at": "2022-05-20T06:15:47+00:00",
        "updated_at": "2022-05-24T09:16:00+00:00",
        "closed_at": "2022-05-24T09:16:00+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1932,
        "title": "AttributeError: 'ASRExecutor' object has no attribute 'max_len'",
        "body": "运行程序时候提示错误：  \r\nFile \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 371, in _check\r\n    if audio_duration > self.max_len:\r\nAttributeError: 'ASRExecutor' object has no attribute 'max_len'\r\n下边是我的代码：\r\nimport paddle\r\nfrom paddlespeech.cli import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='data/zh.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n请问这是什么原因啊？\r\n",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "yt605155624",
        "created_at": "2022-05-20T17:04:23+00:00",
        "updated_at": "2022-05-26T03:17:25+00:00",
        "closed_at": "2022-05-26T03:17:25+00:00",
        "comments_count": [
            "prophesier",
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1934,
        "title": "Out of memory error on GPU 0",
        "body": "运行deepspeech2offline_aishell模型的时候提示：\r\n\r\nConnected to pydev debugger (build 201.8538.36)\r\n/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-05-23 09:27:06,773] [    INFO] - start to init the model\r\n[2022-05-23 09:27:06,774] [    INFO] - File /root/.paddlespeech/models/deepspeech2offline_aishell-zh-16k/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar.gz md5 checking...\r\n[2022-05-23 09:27:11,201] [    INFO] - Use pretrained model stored in: /root/.paddlespeech/models/deepspeech2offline_aishell-zh-16k/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar\r\n[2022-05-23 09:27:11,201] [    INFO] - /root/.paddlespeech/models/deepspeech2offline_aishell-zh-16k/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar\r\n[2022-05-23 09:27:11,201] [    INFO] - /root/.paddlespeech/models/deepspeech2offline_aishell-zh-16k/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar/model.yaml\r\n[2022-05-23 09:27:11,201] [    INFO] - /root/.paddlespeech/models/deepspeech2offline_aishell-zh-16k/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar/exp/deepspeech2/checkpoints/avg_1.pdparams\r\n[2022-05-23 09:27:13,483] [    INFO] - unique_endpoints {''}\r\n[2022-05-23 09:27:13,484] [    INFO] - File /root/.paddlespeech/models/language_model/data/lm/zh_giga.no_cna_cmn.prune01244.klm md5 checking...\r\n[2022-05-23 09:27:20,268] [    INFO] - Found /root/.paddlespeech/models/language_model/data/lm/zh_giga.no_cna_cmn.prune01244.klm\r\n/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nW0523 09:27:20.295001 1187855 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 10.2\r\nW0523 09:27:20.299127 1187855 gpu_context.cc:306] device: 0, cuDNN Version: 8.3.\r\n[2022-05-23 09:27:30,077] [    INFO] - Preprocess audio_file:/home/ssd/suimang/project/PaddleSpeech/1.wav\r\n[2022-05-23 09:27:30,091] [    INFO] - audio feat shape: [1, 707, 161]\r\n[2022-05-23 09:27:30,092] [    INFO] - audio feat process success\r\n[2022-05-23 09:27:58,393] [    INFO] - start to infer the model to get the output\r\nTraceback (most recent call last):\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 302, in infer\r\n    result_transcripts = self.model.decode(audio, audio_len)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 171, in decode\r\n    eouts, eouts_len = self.encoder(audio, audio_len)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 77, in forward\r\n    x, x_lens = self.conv(x, x_lens)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/models/ds2/conv.py\", line 168, in forward\r\n    x, x_len = self.conv_in(x, x_len)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/models/ds2/conv.py\", line 114, in forward\r\n    masks = make_non_pad_mask(x_len)  #[B, T]\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/modules/mask.py\", line 90, in make_non_pad_mask\r\n    return make_pad_mask(lengths).logical_not()\r\n  File \"/home/ssd/suimang/project/PaddleSpeech/paddlespeech/s2t/modules/mask.py\", line 61, in make_pad_mask\r\n    seq_range = paddle.arange(0, max_len, dtype=paddle.int64)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/tensor/creation.py\", line 567, in arange\r\n    return paddle.fluid.layers.range(start, end, step, dtype, name)\r\n  File \"/home/ssd/suimang/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/tensor.py\", line 1505, in range\r\n    out = _C_ops.range(start, end, step)\r\nSystemError: (Fatal) Operator range raises an paddle::memory::allocation::BadAlloc exception.\r\nThe exception content is\r\n:ResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 1.035075EB memory on GPU 0, 1.563965GB memory has been allocated and available memory is only 22.135559GB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\r\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\r\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\r\n但是我0卡的显存应该够用啊，是我输入的不对么，下面的代码：\r\nimport paddle\r\nfrom paddlespeech.cli import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='deepspeech2offline_aishell',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='1.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "yt605155624",
        "created_at": "2022-05-23T01:32:41+00:00",
        "updated_at": "2023-04-25T06:01:26+00:00",
        "closed_at": "2022-05-30T02:33:02+00:00",
        "comments_count": [
            "yt605155624",
            "qiuyuzhao",
            "yt605155624",
            "ianZzzzzz",
            "leolle"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1936,
        "title": "[Do not reply]QR code of joining wechat group",
        "body": "![aeb3b8c321dd01d1398f1872aa9ca84a](https://user-images.githubusercontent.com/23690325/169763015-cbd8e28d-602c-4723-810d-dbc6da49441e.jpg)\r\n",
        "state": "closed",
        "user": "D-DanielYang",
        "closed_by": "D-DanielYang",
        "created_at": "2022-05-23T07:08:41+00:00",
        "updated_at": "2022-05-23T07:08:46+00:00",
        "closed_at": "2022-05-23T07:08:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1965
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1937,
        "title": "ASR-python api will waiting input() don't continue",
        "body": "**Describe the bug**\r\ni try to use asr-api of  paddleSpeech.cli，but I happen a problem that it don't working，because can't input in python runtime\r\n\r\n**To Reproduce**\r\n\r\n1. Go to ready environment\r\n2. input asr python api demo\r\n3. run it\r\n\r\n**Expected behavior**\r\n![image](https://user-images.githubusercontent.com/5794205/169762724-b7b0968e-1313-45dc-a46b-c3973ecfc482.png)\r\n\r\n**Try solution**\r\n\r\n![image](https://user-images.githubusercontent.com/5794205/169762312-cbfd6b71-4f14-4951-b2e3-6f7017ea4d5d.png)\r\n",
        "state": "closed",
        "user": "liqiujiong",
        "closed_by": "liqiujiong",
        "created_at": "2022-05-23T07:11:06+00:00",
        "updated_at": "2022-05-24T08:03:28+00:00",
        "closed_at": "2022-05-24T08:03:28+00:00",
        "comments_count": [
            "yt605155624",
            "liqiujiong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1939,
        "title": "deepspeech2提取音频特征",
        "body": "请问deepspeech2提取音频特征在代码中是encoder出来的就是音频特征了么？decoder是吧提取到的音频特征和解码成文字么？",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "qiuyuzhao",
        "created_at": "2022-05-23T08:20:15+00:00",
        "updated_at": "2022-05-24T04:10:13+00:00",
        "closed_at": "2022-05-24T04:10:13+00:00",
        "comments_count": [
            "zh794390558",
            "qiuyuzhao",
            "zh794390558"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1944,
        "title": "音频长度和特征长度",
        "body": "请问输入一段音频在encoder outputs,中返会的维度是[1 T, D]，这个T要怎么和音频的长度对应上呢？",
        "state": "closed",
        "user": "qiuyuzhao",
        "closed_by": "stale[bot]",
        "created_at": "2022-05-24T04:19:31+00:00",
        "updated_at": "2022-11-01T15:17:57+00:00",
        "closed_at": "2022-11-01T15:17:57+00:00",
        "comments_count": [
            "yt605155624",
            "qiuyuzhao",
            "Jackwaterveg",
            "qiuyuzhao",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1947,
        "title": "2022-05-24编译paddlespeech_ctcdecoders的时候遇到setup.sh文件有换行符错误",
        "body": "今天用树莓派编译paddlespeech_ctcdecoders的时候遇到setup.sh文件有换行符错误的问题，具体报错如下：\r\n\r\n/PaddleSpeech/third_party/ctc_decoders# `bash ./setup.sh`\r\n\r\n/setup.sh: line 2: $'\\r': command not found\r\n/setup.sh: line 25: syntax error: unexpected end of file\r\n\r\n---\r\n将里面的代码复制出来放到新建的文件里就能正常编译了，`麻烦大佬们修正一下吧`\r\n\r\n - OS: 树莓派 Linux PI 5.15.32-v8+ #1538 SMP PREEMPT Thu Mar 31 19:40:39 BST 2022 aarch64 GNU/Linux\r\n - Python Version [e.g. 3.9.2]\r\n",
        "state": "closed",
        "user": "SuperKsa",
        "closed_by": "yt605155624",
        "created_at": "2022-05-24T09:08:44+00:00",
        "updated_at": "2022-06-29T11:34:31+00:00",
        "closed_at": "2022-06-29T11:34:31+00:00",
        "comments_count": [
            "Jackwaterveg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1960,
        "title": "为什么tacotron2中文效果比fastspeech2效果差？",
        "body": "我在使用推理时发现tacotron2的中文效果没有fastspeech2好，但是原始英文论文是tacotron2比fastspeech2好的，是有做什么改动吗？\r\n\r\n",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-05-26T00:35:46+00:00",
        "updated_at": "2022-05-30T02:23:22+00:00",
        "closed_at": "2022-05-30T02:23:22+00:00",
        "comments_count": [
            "yt605155624",
            "lawo123",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1952,
        "title": "PP-TTS G2P 的准确率",
        "body": ">https://mp.weixin.qq.com/s/GFek2OafvXXbqsEQy5fkTg\r\nPP-TTS 提供了针对中文场景的语音合成文本前端优化方案：针对时间、日期、电话、温度等常见非标准词进行了文本正则化处理；开源了针对中文场景的轻声变调、三声变调和“一”“不”变调等字音转换（ G2P ）解决方案。在自建的文本正则化测试集上， CER 低至0.73%；以 CSMSC 数据集的拼音标注为 Ground Truth ，**字音转换（ G2P ）的 WER 低至 2.6%**。\r\n\r\n请问目前在 CSMSC 上面 WER = 2.6% 的 G2P 模型已经开源了吗？",
        "state": "closed",
        "user": "asr-pub",
        "closed_by": "yt605155624",
        "created_at": "2022-05-24T13:26:30+00:00",
        "updated_at": "2022-05-26T03:17:01+00:00",
        "closed_at": "2022-05-26T03:17:01+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1964,
        "title": "asr_online client推理报错，np数组维度对不上",
        "body": "按示例测试：\r\n**server：** paddlespeech_server start --config_file conf/ws_conformer_application.yaml &> streaming_asr.log &\r\n**client：** paddlespeech_client asr_online --server_ip 127.0.0.1 --port 8091 --input ~/Projects/babyedu/splits/shuxiaodi_010.wav\r\n\r\n**client日志：**\r\nminiconda/envs/pd/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-05-26 11:28:08,005] [    INFO] - asr websocket client start\r\n[2022-05-26 11:28:08,005] [    INFO] - endpoint: ws://127.0.0.1:8091/paddlespeech/asr/streaming\r\n[2022-05-26 11:28:08,022] [    INFO] - client receive msg={\"status\": \"ok\", \"signal\": \"server_ready\"}\r\n[2022-05-26 11:28:08,024] [   ERROR] - Failed to speech recognition.\r\n[2022-05-26 11:28:08,024] [   ERROR] - all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\r\n\r\n请问这是什么问题？",
        "state": "closed",
        "user": "lanyuer",
        "closed_by": "yt605155624",
        "created_at": "2022-05-26T03:48:38+00:00",
        "updated_at": "2022-05-30T02:23:14+00:00",
        "closed_at": "2022-05-30T02:23:14+00:00",
        "comments_count": [
            "zh794390558",
            "lanyuer"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1972
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1968,
        "title": "请问没有英文语音识别的流式服务吗？",
        "body": "demos/streaming_asr_server 下只支持中文的语音识别服务部署嘛？",
        "state": "closed",
        "user": "HandsLing",
        "closed_by": "yt605155624",
        "created_at": "2022-05-26T09:00:01+00:00",
        "updated_at": "2022-05-30T02:28:49+00:00",
        "closed_at": "2022-05-30T02:28:49+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1973
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1980
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1969,
        "title": "PP-ASR超过15秒识别就越来越慢",
        "body": null,
        "state": "closed",
        "user": "forlor",
        "closed_by": "zh794390558",
        "created_at": "2022-05-26T09:23:56+00:00",
        "updated_at": "2022-09-08T02:43:44+00:00",
        "closed_at": "2022-06-08T03:50:42+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1970,
        "title": "TypeError: Descriptors cannot not be created directly. If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.",
        "body": "问题原因：\r\nprotobuf 于 2022.05.26 发布了 4.12 版本，默认安装 paddle 时会安装 protobuf 4.12（如果当前的环境中没有 protobuf 的话），安装成功但是 import paddle 会报错，目前 develop 版本的 paddle 已经修复了这个问题（ see [#43009](https://github.com/PaddlePaddle/Paddle/pull/43009) ），但是发行版依旧存在这个问题\r\n参考: \r\n1. [Streamlit run with protocbuf error](https://discuss.streamlit.io/t/streamlit-run-with-protocbuf-error/25632)\r\n2. [TypeError: Descriptors cannot not be created directly](https://discuss.streamlit.io/t/typeerror-descriptors-cannot-not-be-created-directly/25639)\r\n\r\n解决办法：\r\n1. 手动降低 protobuf 为 3.x\r\n```bash\r\npip install protobuf==3.20.1\r\n```\r\n2. 直接安装 develop 版本的 paddle, 但是如果你的环境里面已经有了 4.x 版本的 protobuf，还是会报错的~\r\n\r\n完整报错:\r\n```text\r\n(py39) C:\\Users\\Admin>hub install ge2e_fastspeech2_pwgan==1.0.0\r\nTraceback (most recent call last):\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"f:\\anaconda3\\envs\\py39\\Scripts\\hub.exe\\__main__.py\", line 4, in <module>\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddlehub\\__init__.py\", line 18, in <module>\r\n    import paddle\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\framework\\__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\framework\\random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\fluid\\__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 35, in <module>\r\n    from .proto import framework_pb2\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\paddle\\fluid\\proto\\framework_pb2.py\", line 33, in <module>\r\n    _descriptor.EnumValueDescriptor(\r\n  File \"f:\\anaconda3\\envs\\py39\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 755, in __new__\r\n    _message.Message._CheckCalledFromGeneratedFile()\r\nTypeError: Descriptors cannot not be created directly.\r\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\r\n 1. Downgrade the protobuf package to 3.20.x or lower.\r\n 4. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\n\r\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\r\n```",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-05-26T09:57:21+00:00",
        "updated_at": "2022-09-06T08:14:22+00:00",
        "closed_at": "2022-09-06T08:14:22+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "Installation",
            "Paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1971,
        "title": "安装paddlespeech出现如下错误，求指导",
        "body": "安装paddlespeech，出现如下错误：\r\n\r\nerror: could not create 'build\\bdist.win-amd64\\wheel\\.\\dtaidistance\\lib\\DTAIDistanceC\\DTAIDistanceC.xcod\r\neproj\\xcuserdata\\wannes.xcuserdatad\\xcdebugger\\Breakpoints_v2.xcbkptlist': No such file or directory\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for dtaidistance\r\n\r\nERROR: Could not build wheels for dtaidistance, which is required to install pyproject.toml-based projects\r\n",
        "state": "closed",
        "user": "ciihai",
        "closed_by": "ciihai",
        "created_at": "2022-05-26T10:19:21+00:00",
        "updated_at": "2022-05-26T15:42:16+00:00",
        "closed_at": "2022-05-26T15:42:16+00:00",
        "comments_count": [
            "yt605155624",
            "ciihai"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1989
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1975,
        "title": "Installation error on MacOS Monterrey",
        "body": "bash-3.2$ paddlespeech cls --input mySampleAudio.wav \r\n\r\nand I get this error: \r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/base_commands.py\", line 17, in <module>\r\n    from .utils import cli_register\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from .proto import framework_pb2\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/fluid/proto/framework_pb2.py\", line 33, in <module>\r\n    _descriptor.EnumValueDescriptor(\r\n  File \"/usr/local/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 755, in __new__\r\n    _message.Message._CheckCalledFromGeneratedFile()\r\nTypeError: Descriptors cannot not be created directly.\r\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\r\n 1. Downgrade the protobuf package to 3.20.x or lower.\r\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\n\r\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\r\n\r\n\r\nAny idea what is causing it?\r\n\r\nThanks",
        "state": "closed",
        "user": "inglesuniversal",
        "closed_by": "yt605155624",
        "created_at": "2022-05-26T17:10:06+00:00",
        "updated_at": "2022-09-20T12:23:54+00:00",
        "closed_at": "2022-05-30T02:34:04+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1974,
        "title": "paddlespeech总是安装不上",
        "body": "1、已安装VS2019 ， paddleocr 好用\r\n2、在pycharm 终端使用 pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple   安装paddlespeech\r\n3、总是出现一下错误：\r\n Building wheel for dtaidistance (pyproject.toml) ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Building wheel for dtaidistance (pyproject.toml) did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [298 lines of output]\r\n      WARNING: Numpy was not found, preparing a version without Numpy support.\r\n error: could not create 'build\\bdist.win-amd64\\wheel\\.\\dtaidistance\\lib\\DTAIDistanceC\\DTAIDistanceC.xcod\r\neproj\\xcuserdata\\wannes.xcuserdatad\\xcdebugger\\Breakpoints_v2.xcbkptlist': No such file or directory\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for dtaidistance\r\nFailed to build dtaidistance\r\nERROR: Could not build wheels for dtaidistance, which is required to install pyproject.toml-based projects\r\n\r\n4、试过numpy 1.22.4  numpy1.22.3 ,试了网上各种办法，都不好用。\r\n5、请指点。\r\n\r\n\r\n",
        "state": "closed",
        "user": "ciihai",
        "closed_by": "ciihai",
        "created_at": "2022-05-26T16:06:32+00:00",
        "updated_at": "2022-07-14T08:34:35+00:00",
        "closed_at": "2022-05-27T13:45:35+00:00",
        "comments_count": [
            "yt605155624",
            "ciihai",
            "yt605155624",
            "ciihai",
            "qijigaici",
            "yt605155624",
            "ciihai",
            "yt605155624",
            "ciihai",
            "qijigaici"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1981,
        "title": "PaddleSpeech有端侧部署吗？",
        "body": null,
        "state": "closed",
        "user": "Fyee",
        "closed_by": "yt605155624",
        "created_at": "2022-05-27T06:26:00+00:00",
        "updated_at": "2022-05-30T02:26:36+00:00",
        "closed_at": "2022-05-30T02:26:36+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2004
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1983,
        "title": "fastspeech2静态图推断下怎么调整语速？",
        "body": "fastspeech2的onnx模型我是从链接下载的，自己尝试将stylefastspeech2转换为onnx一直报错，有没有什么办法在fastspeech2_csmsc_onnx_0.2.0.onnx上优化语速问题呢？",
        "state": "closed",
        "user": "Kevinkaiyan",
        "closed_by": "yt605155624",
        "created_at": "2022-05-27T09:36:13+00:00",
        "updated_at": "2022-06-01T02:12:11+00:00",
        "closed_at": "2022-06-01T02:12:11+00:00",
        "comments_count": [
            "yt605155624",
            "Kevinkaiyan",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1990,
        "title": "Feature request: Please include Spanish",
        "body": "So far I see only two languages under your documentation.\r\n\r\nThanks\r\n\r\n",
        "state": "closed",
        "user": "inglesuniversal",
        "closed_by": "yt605155624",
        "created_at": "2022-05-30T08:37:17+00:00",
        "updated_at": "2024-11-21T22:08:29+00:00",
        "closed_at": "2022-05-31T12:04:20+00:00",
        "comments_count": [
            "yt605155624",
            "puppetm4st3r"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 1999,
        "title": "AttributeError: 'ASRServerExecutor' object has no attribute 'max_len'",
        "body": "**Describe the bug**\r\nasr_inference 服务异常\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 使用 paddlespeech_server 启动 asr_inference 服务\r\n2. 调用 asr_inference 服务\r\n\r\n**Expected behavior**\r\n服务正常工作\r\n\r\n**Screenshots**\r\n```\r\n[2022-05-31 09:14:27,188] [   ERROR] - 'ASRServerExecutor' object has no attribute 'max_len'                                                                                                  \r\nTraceback (most recent call last):                                                                                                                                                            \r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/cli/asr/infer.py\", line 365, in _check                                                                                            \r\n    if audio_duration > self.max_len:                                                                                                                                                         \r\nAttributeError: 'ASRServerExecutor' object has no attribute 'max_len'                                                                                                                         \r\n[2022-05-31 09:14:27,189] [   ERROR] - can not open the audio file, please check the audio file format is 'wav'.                                                                              \r\n                  you can try to use sox to change the file format.                                                                                                                           \r\n                  For example:                                                                                                                                                                \r\n                  sample rate: 16k                                                                                                                                                            \r\n                  sox input_audio.xx --rate 16k --bits 16 --channels 1 output_audio.wav                                                                                                       \r\n                  sample rate: 8k                                                                                                                                                             \r\n                  sox input_audio.xx --rate 8k --bits 16 --channels 1 output_audio.wav                                                                                                        \r\n                                                                                                                                                                                              \r\n[2022-05-31 09:14:27,189] [    INFO] - file check failed!                                                                                                                                     \r\nTraceback (most recent call last):                                                                                                                                                            \r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/restful/asr_api.py\", line 71, in asr                                                                                       \r\n    asr_engine.run(audio_data)                                                                                                                                                                \r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/paddleinference/asr_engine.py\", line 215, in run                                                                \r\n    logger.info(\"inference time: {}\".format(infer_time))                                                                                                                                      \r\nUnboundLocalError: local variable 'infer_time' referenced before assignment                                                                                                                   \r\n```",
        "state": "closed",
        "user": "shinoi2",
        "closed_by": "shinoi2",
        "created_at": "2022-05-31T09:22:33+00:00",
        "updated_at": "2022-06-07T06:07:29+00:00",
        "closed_at": "2022-06-07T06:07:29+00:00",
        "comments_count": [
            "yt605155624",
            "shinoi2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2009,
        "title": "AssertionError: condition input's numel should be 1",
        "body": "**Describe the bug**\r\n/home/aistudio/PaddleSpeech/examples/voxceleb/sv0下执行bash ./run.sh --stage 1 --stop_stage 1\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '/home/aistudio/PaddleSpeech/examples/voxceleb/sv0'\r\n2. Run 'bash ./run.sh --stage 1 --stop_stage 1'\r\n4. See error\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/49608605/171609801-0fe1235e-2e4f-4eb1-b4bd-8f0a254a7ac0.png)\r\n\r\n**Additional context**\r\nrun.sh ：gpus=0\r\n\r\n\r\n**Additional log**\r\n```\r\naistudio@jupyter-2318074-4109838:~/PaddleSpeech/examples/voxceleb/sv0$ bash ./run.sh --stage 1 --stop_stage 1\r\nusing 1 gpus...\r\nLAUNCH INFO 2022-06-02 18:27:10,087 -----------  Configuration  ----------------------\r\nLAUNCH INFO 2022-06-02 18:27:10,087 devices: None\r\nLAUNCH INFO 2022-06-02 18:27:10,087 elastic_level: -1\r\nLAUNCH INFO 2022-06-02 18:27:10,087 elastic_timeout: 30\r\nLAUNCH INFO 2022-06-02 18:27:10,087 gloo_port: 6767\r\nLAUNCH INFO 2022-06-02 18:27:10,087 host: None\r\nLAUNCH INFO 2022-06-02 18:27:10,087 job_id: default\r\nLAUNCH INFO 2022-06-02 18:27:10,087 legacy: False\r\nLAUNCH INFO 2022-06-02 18:27:10,087 log_dir: log\r\nLAUNCH INFO 2022-06-02 18:27:10,087 log_level: INFO\r\nLAUNCH INFO 2022-06-02 18:27:10,087 master: None\r\nLAUNCH INFO 2022-06-02 18:27:10,087 max_restart: 3\r\nLAUNCH INFO 2022-06-02 18:27:10,087 nnodes: 1\r\nLAUNCH INFO 2022-06-02 18:27:10,087 nproc_per_node: None\r\nLAUNCH INFO 2022-06-02 18:27:10,087 rank: -1\r\nLAUNCH INFO 2022-06-02 18:27:10,087 run_mode: collective\r\nLAUNCH INFO 2022-06-02 18:27:10,087 server_num: None\r\nLAUNCH INFO 2022-06-02 18:27:10,087 servers: \r\nLAUNCH INFO 2022-06-02 18:27:10,087 trainer_num: None\r\nLAUNCH INFO 2022-06-02 18:27:10,088 trainers: \r\nLAUNCH INFO 2022-06-02 18:27:10,088 training_script: /home/aistudio/PaddleSpeech/paddlespeech/vector/exps/ecapa_tdnn/train.py\r\nLAUNCH INFO 2022-06-02 18:27:10,088 training_script_args: ['--device', 'gpu', '--checkpoint-dir', 'exp/ecapa-tdnn-vox12-big/', '--data-dir', 'data/', '--config', 'conf/ecapa_tdnn.yaml']\r\nLAUNCH INFO 2022-06-02 18:27:10,088 with_gloo: 0\r\nLAUNCH INFO 2022-06-02 18:27:10,088 --------------------------------------------------\r\nLAUNCH WARNING 2022-06-02 18:27:10,088 Compatible mode enable with args ['--gpus=0']\r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\ncluster_topo_path: None\r\nelastic_pre_hook: None\r\nelastic_server: None\r\nenable_auto_mapping: False\r\nforce: False\r\ngpus: 0\r\nheter_devices: \r\nheter_worker_num: None\r\nheter_workers: \r\nhost: None\r\nhttp_port: None\r\nips: 127.0.0.1\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrank_mapping_path: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: /home/aistudio/PaddleSpeech/paddlespeech/vector/exps/ecapa_tdnn/train.py\r\ntraining_script_args: ['--device', 'gpu', '--checkpoint-dir', 'exp/ecapa-tdnn-vox12-big/', '--data-dir', 'data/', '--config', 'conf/ecapa_tdnn.yaml']\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nWARNING 2022-06-02 18:27:10,089 launch.py:519] Not found distinct arguments and compiled with cuda or xpu or npu or mlu. Default use collective mode\r\nWARNING 2022-06-02 18:27:10,089 launch.py:519] Not found distinct arguments and compiled with cuda or xpu or npu or mlu. Default use collective mode\r\nlaunch train in GPU mode!\r\nINFO 2022-06-02 18:27:10,089 launch_utils.py:679] Change selected_gpus into reletive values. --ips:0 will change into relative_ips:[0] according to your CUDA_VISIBLE_DEVICES:['0']\r\nINFO 2022-06-02 18:27:10,089 launch_utils.py:679] Change selected_gpus into reletive values. --ips:0 will change into relative_ips:[0] according to your CUDA_VISIBLE_DEVICES:['0']\r\nINFO 2022-06-02 18:27:10,091 launch_utils.py:561] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:52939               |\r\n    |                     PADDLE_TRAINERS_NUM                        1                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:52939               |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2022-06-02 18:27:10,091 launch_utils.py:561] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:52939               |\r\n    |                     PADDLE_TRAINERS_NUM                        1                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:52939               |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2022-06-02 18:27:10,092 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nINFO 2022-06-02 18:27:10,092 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:27947 idx:0\r\n/home/aistudio/PaddleSpeech/paddlespeech/vector/modules/loss.py:246: DeprecationWarning: invalid escape sequence \\l\r\n  \"\"\"\r\n---------------------------- augment: True\r\nbatch_size: 32\r\nchunk_duration: 3.0\r\ncohort_size: 20000\r\nembedding_mean_norm: True\r\nembedding_std_norm: False\r\nepochs: 10\r\nglobal_embedding_norm: True\r\nhop_size: 160\r\nlearning_rate: 1e-08\r\nlog_interval: 10\r\nmargin: 0.2\r\nmax_lr: 0.001\r\nmodel:\r\n  attention_channels: 128\r\n  channels: [1024, 1024, 1024, 1024, 3072]\r\n  dilations: [1, 2, 3, 4, 1]\r\n  input_size: 80\r\n  kernel_sizes: [5, 3, 3, 3, 1]\r\n  lin_neurons: 192\r\nn_mels: 80\r\nn_train_snts: 400000\r\nnum_speakers: 7205\r\nnum_workers: 2\r\nrandom_chunk: True\r\nsave_interval: 10\r\nscale: 30\r\nscore_norm: s-norm\r\nseed: 1986\r\nshuffle: True\r\nskip_prep: False\r\nsplit_ratio: 0.9\r\nsr: 16000\r\nstep_size: 140000\r\nverification_file: data/vox1/veri_test2.txt\r\nwindow_size: 400\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:158: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\r\n  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\r\n2022-06-02 18:27:12.034 | INFO     | paddlespeech.vector.training.seeding:seed_everything:28 - Set the seed of paddle, random, np.random to 1986.\r\n2022-06-02 18:27:12.037 | INFO     | paddlespeech.vector.io.augment:build_augment_pipeline:842 - start to build the augment pipeline\r\n2022-06-02 18:27:12.055 | WARNING  | paddlespeech.vector.io.dataset:load_speaker_to_label:129 - No speaker id to label file\r\n2022-06-02 18:27:12.057 | WARNING  | paddlespeech.vector.io.dataset:load_speaker_to_label:129 - No speaker id to label file\r\nW0602 18:27:12.062904 27947 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\r\nW0602 18:27:12.067212 27947 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/exps/ecapa_tdnn/train.py\", line 366, in <module>\r\n    main(args, config)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/exps/ecapa_tdnn/train.py\", line 175, in main\r\n    waveforms = waveform_augment(waveforms, augment_pipeline)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/io/augment.py\", line 895, in waveform_augment\r\n    waveforms_aug = aug(waveforms)  # (N, L)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/io/augment.py\", line 769, in forward\r\n    waveforms = self.speed_perturb(waveforms)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/io/augment.py\", line 419, in forward\r\n    perturbed_waveform = self.resamplers[self.samp_index](waveform)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/io/augment.py\", line 226, in forward\r\n    self._indices_and_weights(waveforms)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/vector/io/augment.py\", line 367, in _indices_and_weights\r\n    delta_t.masked_select(inside_window_indices)))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 778, in __setitem__\r\n    return _setitem_impl_(self, item, value)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/variable_index.py\", line 610, in _setitem_impl_\r\n    return set_value_for_bool_tensor(var, slice_item, value)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/variable_index.py\", line 739, in set_value_for_bool_tensor\r\n    cond(item.any(), lambda: idx_not_empty(var, item, value))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/control_flow.py\", line 2451, in cond\r\n    assert pred.size == 1, \"condition input's numel should be 1\"\r\nAssertionError: condition input's numel should be 1\r\nINFO 2022-06-02 18:27:23,132 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-02 18:27:23,132 launch_utils.py:343] terminate all the procs\r\nERROR 2022-06-02 18:27:23,133 launch_utils.py:642] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nERROR 2022-06-02 18:27:23,133 launch_utils.py:642] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2022-06-02 18:27:27,137 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-02 18:27:27,137 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-02 18:27:27,137 launch.py:402] Local processes completed.\r\nINFO 2022-06-02 18:27:27,137 launch.py:402] Local processes completed.\r\n\r\n```",
        "state": "closed",
        "user": "1105135335",
        "closed_by": "yt605155624",
        "created_at": "2022-06-02T10:31:03+00:00",
        "updated_at": "2022-06-06T06:38:01+00:00",
        "closed_at": "2022-06-05T09:01:35+00:00",
        "comments_count": [
            "yt605155624",
            "1105135335"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2008,
        "title": "raise ValueError('all input arrays must have the same shape') ValueError: all input arrays must have the same shape",
        "body": "大佬，您好，我按照语音分类的方法制作数据集，但是训练的时候一致报错，\r\nraise ValueError('all input arrays must have the same shape')\r\nValueError: all input arrays must have the same shape\r\n请问大佬，怎么解决呢？\r\n",
        "state": "closed",
        "user": "wuxiaolianggit",
        "closed_by": "yt605155624",
        "created_at": "2022-06-02T09:14:02+00:00",
        "updated_at": "2023-02-07T12:59:39+00:00",
        "closed_at": "2022-07-27T06:48:33+00:00",
        "comments_count": [
            "zh794390558",
            "wuxiaolianggit",
            "wuxiaolianggit",
            "zh794390558",
            "wuxiaolianggit",
            "zh794390558",
            "wuxiaolianggit",
            "wuxiaolianggit",
            "zh794390558",
            "wuxiaolianggit",
            "wuxiaolianggit",
            "zh794390558",
            "suzhou-Second"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2013,
        "title": "代码问题多了一个括号",
        "body": "\r\n<img width=\"975\" alt=\"2a92e0da444840b5ab28841c37c6fed\" src=\"https://user-images.githubusercontent.com/44693150/172105558-294365c0-2ae2-45b6-b216-ecab29080cd9.png\">\r\n",
        "state": "closed",
        "user": "MrJson1",
        "closed_by": "SmileGoat",
        "created_at": "2022-06-06T06:13:32+00:00",
        "updated_at": "2022-06-08T02:02:51+00:00",
        "closed_at": "2022-06-08T02:02:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2010,
        "title": "ted_en_zh的st任务相关问题",
        "body": "您好，我在ted_en_zh这个st任务中尝试切换数据集。\r\n1.之前切换过相对小的数据集（6000句左右），能够运行并验证，但是验证的时候，对于读取的任何wav,hyp一直只重复同一句结果，请问什么原因呢？修改了epoch但是没有效果。\r\n2.这次切换了一个只有400条的极小数据集（因为文本更准确），在第一步数据处理部分就出现了这个问题，请问如何修改？\r\n`\r\n2022-06-03 20:13:34.284 | INFO     | paddlespeech.s2t.frontend.augmentor.augmentation:__init__:123 - Augmentation: []\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/work/PaddleSpeech/utils/compute_mean_std.py\", line 87, in <module>\r\n    main()\r\n  File \"/home/aistudio/work/PaddleSpeech/utils/compute_mean_std.py\", line 82, in main\r\n    num_workers=args.num_workers)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/frontend/normalizer.py\", line 118, in __init__\r\n    num_workers)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/frontend/normalizer.py\", line 195, in _compute_mean_std\r\n    'mean_stat': list(all_mean_stat.tolist()),\r\nAttributeError: 'NoneType' object has no attribute 'tolist'\r\n`\r\n",
        "state": "closed",
        "user": "jannicaTan",
        "closed_by": "stale[bot]",
        "created_at": "2022-06-03T12:22:12+00:00",
        "updated_at": "2023-01-21T04:45:39+00:00",
        "closed_at": "2023-01-21T04:45:39+00:00",
        "comments_count": [
            "zh794390558",
            "jannicaTan",
            "stale[bot]",
            "jannicaTan",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2011,
        "title": "MFA训练过程中意外中断",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nMFA训练到sat_3步骤后到生成TextGrid阶段时报错中断\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.打开conda虚拟环境\r\n2.键入指令：mfa train data/wav/EILEEN/split/ MFA/pinyin_eng.dict MFA/EILEEN.zip data/TextGrid/EILEEN/ --clean\r\n\r\n**Screenshots**\r\n![08d39dc43e6f42b4fa078cca3bc473a](https://user-images.githubusercontent.com/62604868/171990459-ee22cccf-9fa3-4200-94e5-287692942ff6.png)\r\n\r\n** Environment (please complete the following information):**\r\n - OS: Windows 10\r\n - Python Version: 3.9.10\r\n - PaddlePaddle Version: 2.3\r\n - Model Version [e.g. 2.0.0]\r\n - GPU: NVIDIA RTX 2060 6GB\r\n - CUDA/CUDNN Version: CUDA 11.2 \r\n - 基于VtuberTalk(https://github.com/jerryuhoo/VTuberTalk)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "yrsn509",
        "closed_by": "yt605155624",
        "created_at": "2022-06-04T08:04:06+00:00",
        "updated_at": "2022-06-05T08:59:00+00:00",
        "closed_at": "2022-06-05T08:59:00+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2022,
        "title": "ASRExecutor是否支持长语音",
        "body": "识别长语音时发生报错，说要少于50秒，能否支持长时间的音频？\r\n\r\n\r\n------------------------------\r\n[2022-06-08 14:38:19,952] [    INFO] - checking the audio file format......\r\n[2022-06-08 14:38:19,956] [   ERROR] - Please input audio file less then 50 seconds.",
        "state": "closed",
        "user": "detectivewu",
        "closed_by": "yt605155624",
        "created_at": "2022-06-08T09:43:11+00:00",
        "updated_at": "2022-09-07T02:57:44+00:00",
        "closed_at": "2022-09-07T02:57:44+00:00",
        "comments_count": [
            "Jackwaterveg",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2021,
        "title": "openslr语言资料下载失败",
        "body": "尝试使用examples/tiny下的run.sh去演示模型训练，但是在下载语言资料包时直接报错 403：Forbidden\r\n\r\n请问如何处理？\r\n\r\n```\r\ncheckpoint name deepspeech2\r\nDownloading http://www.openslr.org/resources/12/test-clean.tar.gz ...\r\nDownloading http://www.openslr.org/resources/12/dev-clean.tar.gz ...\r\n--2022-06-08 16:29:08--  http://www.openslr.org/resources/12/test-clean.tar.gz\r\n--2022-06-08 16:29:08--  http://www.openslr.org/resources/12/dev-clean.tar.gz\r\nResolving www.openslr.org (www.openslr.org)... Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\r\nConnecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... 46.101.158.64\r\nConnecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\r\nHTTP request sent, awaiting response... connected.\r\nHTTP request sent, awaiting response... 302 Found\r\nLocation: https://openslr.magicdatatech.com/resources/12/dev-clean.tar.gz [following]\r\n--2022-06-08 16:29:08--  https://openslr.magicdatatech.com/resources/12/dev-clean.tar.gz\r\nResolving openslr.magicdatatech.com (openslr.magicdatatech.com)... 39.96.249.211\r\nConnecting to openslr.magicdatatech.com (openslr.magicdatatech.com)|39.96.249.211|:443... connected.\r\n302 Found\r\nLocation: https://openslr.magicdatatech.com/resources/12/test-clean.tar.gz [following]\r\n--2022-06-08 16:29:08--  https://openslr.magicdatatech.com/resources/12/test-clean.tar.gz\r\nResolving openslr.magicdatatech.com (openslr.magicdatatech.com)... 39.96.249.211\r\nConnecting to openslr.magicdatatech.com (openslr.magicdatatech.com)|39.96.249.211|:443... HTTP request sent, awaiting response... connected.\r\n403 Forbidden\r\n2022-06-08 16:29:08 ERROR 403: Forbidden.\r\n```",
        "state": "closed",
        "user": "litterGuy",
        "closed_by": "litterGuy",
        "created_at": "2022-06-08T09:12:41+00:00",
        "updated_at": "2022-06-09T06:18:38+00:00",
        "closed_at": "2022-06-09T03:48:17+00:00",
        "comments_count": [
            "litterGuy",
            "dongdong168"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2035
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2023,
        "title": "Why is the normalized mel inversed in am_inference?",
        "body": "Hi, I have a question:\r\nIn the forward() of FastSpeech2Inference , the normalized mel is inversed:\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/05fd9a0e2ccdf5d3ca0e4da15c26cb4533889870/paddlespeech/t2s/models/fastspeech2/fastspeech2.py#L818\r\n\r\nIn paddlespeech\\t2s\\exps\\synthesize.py,  use this inversed mel to infer: \r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/05fd9a0e2ccdf5d3ca0e4da15c26cb4533889870/paddlespeech/t2s/exps/synthesize.py#L111\r\n\r\nBut when training voc model, the input mel is normalized :\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/05fd9a0e2ccdf5d3ca0e4da15c26cb4533889870/examples/aishell3/voc1/local/train.sh#L9\r\n\r\nWhy is the normalized mel inversed in am_inference?\r\n\r\nI guess, the pretrained voc model is trained use unnormalized mel, so it must be inversed in am_inference.\r\n\r\nWhen training  voc model, we should use the normalized mel, right?\r\n\r\n@yt605155624 \r\n\r\n\r\n",
        "state": "closed",
        "user": "wangyanbn",
        "closed_by": "wangyanbn",
        "created_at": "2022-06-08T09:44:32+00:00",
        "updated_at": "2022-06-10T02:02:29+00:00",
        "closed_at": "2022-06-10T02:02:29+00:00",
        "comments_count": [
            "yt605155624",
            "wangyanbn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2024,
        "title": "TTS 推理完之后内存不释放",
        "body": "你好，我遇到一个问题，TTS预测万之后内存不释放的情况。详细情况如下：\r\n**TTS模型：动态声学模型 + onnx声码器**\r\n服务：使用Websocket 进行模型加载和部署\r\n详情：\r\n**1：初始加载模型和服务的时候，**会消耗GPU大概1.7G内存（如图）：\r\n<img width=\"164\" alt=\"0\" src=\"https://user-images.githubusercontent.com/27938135/172755662-3ed4fb72-92eb-40be-b536-4b3e6005add7.png\">\r\n**2：加载完之后**进行语音合成的时候内存会涨上去。整个合成任务过程中，内存能够涨到13G左右（如图），任务结束之后，这个内存无法释放。即，无法从13G回到1.7G。\r\n<img width=\"162\" alt=\"1\" src=\"https://user-images.githubusercontent.com/27938135/172755822-efac4ae5-133f-4a89-ad17-888e3d831624.png\">\r\n请问paddle有没有内存释放机制，能够在任务结束之后，再不关闭服务的前提下，把多出来的内存释放了？\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-06-09T03:09:20+00:00",
        "updated_at": "2022-06-17T06:47:27+00:00",
        "closed_at": "2022-06-17T06:47:27+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2041
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2027,
        "title": "ASR 测试语音时出现错误",
        "body": "环境：centos ，使用paddle 2.3.0版本，python3.9\r\n环境安装完成\r\n![image](https://user-images.githubusercontent.com/99238498/172830997-463c512b-9364-434f-94b1-e1550a143db0.png)\r\n![image](https://user-images.githubusercontent.com/99238498/172831112-7f8f6328-1e24-4a04-8fe4-b134838a78c0.png)\r\n安装完成之后，asr语音识别测试语音出现错误，如下：\r\n![image](https://user-images.githubusercontent.com/99238498/172830720-cdc24cdc-d6b9-42fe-9478-b081a084cff1.png)\r\n麻烦回复一下哪里的错误，是环境没有搭建好还是其他",
        "state": "closed",
        "user": "weekdaysun",
        "closed_by": "yt605155624",
        "created_at": "2022-06-09T10:56:26+00:00",
        "updated_at": "2022-07-27T06:51:47+00:00",
        "closed_at": "2022-07-27T06:51:47+00:00",
        "comments_count": [
            "zh794390558",
            "iftaken"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2029,
        "title": "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed",
        "body": "使用 examples/aishell/asr0进行普通话训练的例子，出现了如标题的错误。\r\n执行\r\n```\r\nbash run.sh\r\n```\r\n然后报了以下错误\r\n```\r\n2022-06-10 15:35:20.062 | INFO     | paddlespeech.s2t.utils.utility:all_version:45 - Deps Module Version:[('python', '3.7.13 (default, Mar 29 2022, 02:18:16) \\n[GCC 7.5.0]'),\r\n ('paddle', '2.3.0'),\r\n ('paddle_commit', '590b4dbcdd989324089ce43c22ef151c746c92a3'),\r\n ('soundfile', '0.10.3')]\r\n2022-06-10 15:35:20.063 | INFO     | paddlespeech.s2t.training.trainer:__init__:112 - Rank: 0/4\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['127.0.0.1:35953', '127.0.0.1:51237', '127.0.0.1:58673']\r\nINFO 2022-06-10 15:35:21,402 launch_utils.py:322] terminate process group gid:51514\r\nINFO 2022-06-10 15:35:21,402 launch_utils.py:322] terminate process group gid:51514\r\nINFO 2022-06-10 15:35:25,405 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-10 15:35:25,405 launch_utils.py:343] terminate all the procs\r\nERROR 2022-06-10 15:35:25,405 launch_utils.py:642] ABORT!!! Out of all 4 trainers, the trainer process with rank=[1, 2, 3] was aborted. Please check its log.\r\nERROR 2022-06-10 15:35:25,405 launch_utils.py:642] ABORT!!! Out of all 4 trainers, the trainer process with rank=[1, 2, 3] was aborted. Please check its log.\r\nINFO 2022-06-10 15:35:29,409 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-10 15:35:29,409 launch_utils.py:343] terminate all the procs\r\nINFO 2022-06-10 15:35:29,409 launch.py:402] Local processes completed.\r\nINFO 2022-06-10 15:35:29,409 launch.py:402] Local processes completed.\r\nNamespace(ckpt_dir='exp/deepspeech2/checkpoints', dst_model='exp/deepspeech2/checkpoints/avg_1.pdparams', max_epoch=65536, min_epoch=0, num=1, val_best=True)\r\nTraceback (most recent call last):\r\n  File \"/home/xsy/works/PaddleSpeech/utils/avg_model.py\", line 116, in <module>\r\n    main(args)\r\n  File \"/home/xsy/works/PaddleSpeech/utils/avg_model.py\", line 43, in main\r\n    sort_idx = np.argsort(val_scores[:, 1])\r\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\r\nFailed in avg ckpt!\r\n```\r\n\r\n这个问题是因为什么，该如何修复呢？希望大佬提供下帮助\r\n\r\n",
        "state": "closed",
        "user": "litterGuy",
        "closed_by": "litterGuy",
        "created_at": "2022-06-10T08:09:57+00:00",
        "updated_at": "2022-06-11T03:54:50+00:00",
        "closed_at": "2022-06-11T03:54:49+00:00",
        "comments_count": [
            "Jackwaterveg",
            "litterGuy",
            "litterGuy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2033,
        "title": "Out of memory error on GPU ",
        "body": "你好。我想问一个问题。我再训练fastspeech2的时候，config文件都没有变动，batch=64，但是会报错“Out of memory error on GPU 0”。\r\n**GPU: v100，32G**\r\n无论我的batch改成32还是16，同样会报“Out of memory ”这个错误，用多张卡训练也是一样的情况：\r\n```\r\nException in main training loop: (Fatal) Operator where raises an paddle::memory::allocation::BadAlloc exception.\r\nThe exception content is\r\n:ResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 1.083714GB memory on GPU 0, 30.711914GB memory has been allocated and available memory is only 1.036621GB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.60 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n (at /paddle/paddle/fluid/memory/detail/system_allocator.cc:155)\r\n. (at /paddle/paddle/fluid/imperative/tracer.cc:221)\r\n\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 109, in update\r\n    self.update_core(batch)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 83, in update_core\r\n    spk_emb=spk_emb)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 557, in forward\r\n    tone_id=tone_id)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 656, in _forward\r\n    zs, _ = self.decoder(hs, h_masks)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/encoder.py\", line 415, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 101, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/attention.py\", line 155, in forward\r\n    return self.forward_attention(v, scores, mask)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/attention.py\", line 115, in forward_attention\r\n    scores = masked_fill(scores, mask, min_value)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/masked_fill.py\", line 48, in masked_fill\r\n    xs = paddle.where(mask, trues, xs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/tensor/search.py\", line 522, in where\r\n    return _C_ops.where(condition, x, y)\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/exps/fastspeech2/train.py\", line 214, in <module>\r\n    main()\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/exps/fastspeech2/train.py\", line 210, in main\r\n    train_sp(args, config)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/exps/fastspeech2/train.py\", line 167, in train_sp\r\n    trainer.run()\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 109, in update\r\n    self.update_core(batch)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 83, in update_core\r\n    spk_emb=spk_emb)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 557, in forward\r\n    tone_id=tone_id)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 656, in _forward\r\n    zs, _ = self.decoder(hs, h_masks)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/encoder.py\", line 415, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 101, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/attention.py\", line 155, in forward\r\n    return self.forward_attention(v, scores, mask)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/transformer/attention.py\", line 115, in forward_attention\r\n    scores = masked_fill(scores, mask, min_value)\r\n  File \"/ultra/fffan/0_TTS/temp/PaddleSpeech/0_Paddlespeech/paddlespeech/t2s/modules/masked_fill.py\", line 48, in masked_fill\r\n    xs = paddle.where(mask, trues, xs)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/tensor/search.py\", line 522, in where\r\n    return _C_ops.where(condition, x, y)\r\nSystemError: (Fatal) Operator where raises an paddle::memory::allocation::BadAlloc exception.\r\nThe exception content is\r\n:ResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 1.083714GB memory on GPU 0, 30.711914GB memory has been allocated and available memory is only 1.036621GB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please try one of the following suggestions:\r\n   1) Decrease the batch size of your model.\r\n   2) FLAGS_fraction_of_gpu_memory_to_use is 0.60 now, please set it to a higher value but less than 1.0.\r\n      The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`.\r\n\r\n (at /paddle/paddle/fluid/memory/detail/system_allocator.cc:155)\r\n. (at /paddle/paddle/fluid/imperative/tracer.cc:221)\r\n```\r\n\r\n我更换成其他训练数据，batch=64都没有问题。请问这是什么原因。训练数据是magicdata，",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-06-15T03:35:20+00:00",
        "updated_at": "2022-06-17T03:18:34+00:00",
        "closed_at": "2022-06-17T03:18:34+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2047
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2038,
        "title": "关于标点恢复",
        "body": "标点恢复的模块怎么训练啊？",
        "state": "closed",
        "user": "CocaColaKing",
        "closed_by": "CocaColaKing",
        "created_at": "2022-06-16T05:50:03+00:00",
        "updated_at": "2022-07-19T01:31:18+00:00",
        "closed_at": "2022-07-19T01:31:18+00:00",
        "comments_count": [
            "yt605155624",
            "CocaColaKing",
            "CocaColaKing",
            "yaleimeng",
            "yaleimeng",
            "CocaColaKing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2057,
        "title": "该怎样对多人对话音频，进行说话人区分？",
        "body": "对于多人对话音频，想得到不同的人分别说了什么话。该使用语音分类还是声纹识别呢？该怎样实现更高效？谢谢。\r\n",
        "state": "closed",
        "user": "BeyondLightYear",
        "closed_by": "BeyondLightYear",
        "created_at": "2022-06-21T07:45:12+00:00",
        "updated_at": "2022-06-21T07:58:33+00:00",
        "closed_at": "2022-06-21T07:58:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2060
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2049,
        "title": "可以变合成边播放吗？数据比较多，pwg_infweence(mel)很慢",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "PCITBoy",
        "closed_by": "yt605155624",
        "created_at": "2022-06-17T08:17:13+00:00",
        "updated_at": "2022-07-07T10:02:46+00:00",
        "closed_at": "2022-07-07T10:02:46+00:00",
        "comments_count": [
            "yt605155624",
            "linkec",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2058,
        "title": "怎样对多人对话音频，进行说话人区分？",
        "body": "对多人对话的音频，想区分不同的人，在哪个时间区间说了什么话。该使用语音分类还是声纹识别呢？如何实现呢？谢谢。",
        "state": "closed",
        "user": "BeyondLightYear",
        "closed_by": "yt605155624",
        "created_at": "2022-06-21T08:03:36+00:00",
        "updated_at": "2022-09-07T03:35:21+00:00",
        "closed_at": "2022-09-07T03:35:21+00:00",
        "comments_count": [
            "yt605155624",
            "BeyondLightYear",
            "SmileGoat"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2064,
        "title": "[tts] Multilingual Speech Synthesis 中英文混合语音合成 ",
        "body": "Input a sentence that contains both Chinese and English, and TTS outputs the corresponding audio and keeps the voice consistent\r\n\r\n```text\r\nhello, 你好吗？I love you！\r\n```\r\n\r\nsee: [Learning to Speak Fluently in a Foreign Language: Multilingual Speech Synthesis and Cross-Language Voice Cloning](https://arxiv.org/abs/1907.04448)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-22T09:46:10+00:00",
        "updated_at": "2022-09-07T02:57:27+00:00",
        "closed_at": "2022-09-07T02:57:27+00:00",
        "comments_count": [
            "lym0302",
            "yt605155624",
            "Lennon-cheng",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2067,
        "title": "已经指定本地模型的前提下，cli 错误加载模型资源",
        "body": "server 的 cli , 即使指定了本地的模型也会下载，挪了 self.task_resource.set_task_model() 的位置就好了，已经在 https://github.com/PaddlePaddle/PaddleSpeech/pull/2056 中修复\r\n\r\ncli/tts/infer.py 发现 self.task_resource.set_task_model()  也是在 if else 之前, 指定模型也会下载... https://github.com/PaddlePaddle/PaddleSpeech/blob/0ea9def0b8725c6b7994e9fa9cd5dd3da76200c5/paddlespeech/cli/tts/infer.py#L180 \r\n![744462e1c652792b554f3aca109a626e](https://user-images.githubusercontent.com/24568452/175010189-91b2c3e4-fba8-48b7-940c-902c05319350.png)\r\n![e2b85b5aeb080ad37e35a05cf543f20d](https://user-images.githubusercontent.com/24568452/175010266-6286a580-1641-4795-b9d5-b3301cdf6881.png)\r\n![1a1cec9a60edfe752f9d3a5cedee0e8f](https://user-images.githubusercontent.com/24568452/175010349-82a06bb3-1227-42fd-8c9d-2c7f22acc204.png)\r\n\r\n但是 cli 的代码不敢像上述 pr 那样直接改，因为后面是会用到 self.task_resource.res_dict 的，直接挪到 if 里面，如果自己指定了模型，进的是 else 判断，self.task_resource.res_dict 变量就会不存在\r\n![9e3f3beb97d10d23e3d68294f5cbe731](https://user-images.githubusercontent.com/24568452/175010231-a3623968-2d52-4017-9248-56a051a9d0a0.png)\r\n\r\n目前除了 https://github.com/PaddlePaddle/PaddleSpeech/pull/2056 已经修复的地方，所有资源加载的位置都有此问题\r\n\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-22T10:48:46+00:00",
        "updated_at": "2022-06-30T04:46:26+00:00",
        "closed_at": "2022-06-30T04:46:26+00:00",
        "comments_count": [],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2066,
        "title": "[tts] add onnx engine for non streaming TTS server",
        "body": "1. export onnx model for tts3 + gan vocoders for csmsc/aishell3/ljspeech/vctk @yt605155624 \r\n   - fixed in https://github.com/PaddlePaddle/PaddleSpeech/pull/2068 \r\n   - add tts static/onnx models in pretrained_models.py https://github.com/PaddlePaddle/PaddleSpeech/pull/2074\r\n2. add onnx engine for non streaming TTS server to speed up @lym0302 ",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-22T10:11:54+00:00",
        "updated_at": "2023-03-21T08:00:56+00:00",
        "closed_at": "2023-03-21T08:00:56+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2070,
        "title": "develop  版本 paddlespeech_server 启动后会打印 2 遍 log",
        "body": "```bash\r\npaddlespeech_server start --config_file ./conf/application.yaml\r\n```\r\nlog：\r\n```text\r\n[2022-06-23 06:18:31,311] [    INFO] - start to init the engine\r\n[2022-06-23 06:18:31,311] [    INFO] - start to init the engine\r\n[2022-06-23 06:18:31,312] [    INFO] - tts : python engine.\r\n[2022-06-23 06:18:31,312] [    INFO] - tts : python engine.\r\nfrom .pretrained_models import tts_dynamic_pretrained_models\r\n[2022-06-23 06:18:36,330] [    INFO] - File /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4.zip md5 checking...\r\n[2022-06-23 06:18:36,330] [    INFO] - File /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4.zip md5 checking...\r\n[2022-06-23 06:18:37,699] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-06-23 06:18:37,699] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4\r\n[2022-06-23 06:18:37,699] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\n[2022-06-23 06:18:37,699] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\n[2022-06-23 06:18:37,700] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\r\n[2022-06-23 06:18:37,700] [    INFO] - /home/xxx/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\r\n[2022-06-23 06:18:37,700] [    INFO] - File /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4.zip md5 checking...\r\n[2022-06-23 06:18:37,700] [    INFO] - File /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4.zip md5 checking...\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4/pwg_default.yaml\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4/pwg_default.yaml\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\r\n[2022-06-23 06:18:37,744] [    INFO] - /home/xxx/.paddlespeech/models/pwgan_csmsc-zh/1.0/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\r\nvocab_size: 268\r\nfrontend done!\r\n```\r\n有问题的 commit 号：\r\n```text\r\n5e03d75\r\n```\r\n\r\n没问题的 commit 号：\r\n```text\r\n803800\r\n```\r\n引起问题的 commit\r\n<img width=\"522\" alt=\"image\" src=\"https://user-images.githubusercontent.com/24568452/175233071-0cf2e8fa-78e0-4497-afa9-584b4b61c3bd.png\">\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-23T06:22:00+00:00",
        "updated_at": "2022-07-01T06:15:36+00:00",
        "closed_at": "2022-07-01T06:15:36+00:00",
        "comments_count": [],
        "labels": [
            "Bug"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2073
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2042,
        "title": "paddlespeech_client 使用websocket协议连接 server失败",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/streaming_tts_server\r\n我按照上述链接进行测试，使用http协议时tts合成正常，使用websocket协议时server返回403\r\n![image](https://user-images.githubusercontent.com/5378476/174051395-6d248c1c-f9a8-4ce5-934b-b557c3880297.png)\r\n",
        "state": "closed",
        "user": "91he",
        "closed_by": "91he",
        "created_at": "2022-06-16T10:30:49+00:00",
        "updated_at": "2022-06-27T08:49:35+00:00",
        "closed_at": "2022-06-16T10:38:18+00:00",
        "comments_count": [
            "mader89",
            "91he"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2055,
        "title": "centos7 环境下安装了paddlespeech，服务命令无法使用",
        "body": "centos7 x86_64环境下安装了paddle和paddlespeech，能启动http服务使用，但是在终端上无法使用paddlespeech命令。\r\nbash: paddlespeech: command not found...\r\nwindows环境下，装好有，请问这个什么原因导致的？",
        "state": "closed",
        "user": "wutl92",
        "closed_by": "wutl92",
        "created_at": "2022-06-20T05:30:59+00:00",
        "updated_at": "2022-06-21T01:26:02+00:00",
        "closed_at": "2022-06-21T01:26:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2083
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2059,
        "title": "下载不了",
        "body": "Downloading paddlespeech_ctcdecoders-0.2.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.8 MB)",
        "state": "closed",
        "user": "PCITBoy",
        "closed_by": "yt605155624",
        "created_at": "2022-06-22T01:28:18+00:00",
        "updated_at": "2022-06-30T02:07:05+00:00",
        "closed_at": "2022-06-30T02:07:05+00:00",
        "comments_count": [
            "linkec"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2072,
        "title": "examples/voxceleb/sv0/local/下缺少convert.sh文件",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/voxceleb/sv0/local/\r\n路径下缺少convert.sh文件\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n** Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "songfuture",
        "closed_by": "yt605155624",
        "created_at": "2022-06-23T08:33:12+00:00",
        "updated_at": "2022-06-27T09:29:22+00:00",
        "closed_at": "2022-06-27T09:29:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2065,
        "title": "[tts] prosody control in acoustic model",
        "body": "This issue needs to be solved at the same time as https://github.com/PaddlePaddle/PaddleSpeech/issues/1282\r\nsee: [DurIAN](https://arxiv.org/abs/1909.01700)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-22T09:49:55+00:00",
        "updated_at": "2022-12-02T09:13:50+00:00",
        "closed_at": "2022-12-02T09:13:50+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2071,
        "title": "paddlespeech_server 多并发情况下偶现报错",
        "body": "![3D5766A06901E0DBE6B22AC85FB4EC17](https://user-images.githubusercontent.com/24568452/175229519-7c3f3c1d-29f3-4851-b017-15888bef963c.jpg)\r\n![E0A38A1C54F64146DBCAAD22EA9B328D](https://user-images.githubusercontent.com/24568452/175229612-5c203510-1102-4828-b1cf-3244716cf258.jpg)\r\n\r\n问题的原因是在相加的时候，x 的长度和 self.pe[:,:T] 的长度不一致了，可能是多并发的时候，不同的输入相互影响，所以 119 行计算的 shape 和 x 的 shape 不一致了..\r\n\r\n具体报错代码位置：\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/0fa3fdb9ee89ca399b0f63ef2117c6370dc1f33d/paddlespeech/t2s/modules/transformer/embedding.py#L119",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-06-23T06:23:46+00:00",
        "updated_at": "2022-11-15T05:52:09+00:00",
        "closed_at": null,
        "comments_count": [
            "wutl92",
            "yt605155624",
            "zhangfeifan6428",
            "chenheshan"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2078,
        "title": "streaming_asr_server服务无法启动",
        "body": "按照说明文档一步步操作，安装完成后，输入命令paddlespeech_server start，命令无法识别，在Windows系统，应该用什么工具来启动，我试过cmd，vscode，powershell都不行，又尝试了启动streaming_asr_server.py脚本，报错demos\\streaming_asr_server\\streaming_asr_server.py\", line 16, in <module> from paddlespeech.cli.log import logger ModuleNotFoundError: No module named 'paddlespeech'",
        "state": "closed",
        "user": "mader89",
        "closed_by": "mader89",
        "created_at": "2022-06-27T07:42:35+00:00",
        "updated_at": "2022-06-27T08:22:39+00:00",
        "closed_at": "2022-06-27T08:22:39+00:00",
        "comments_count": [
            "mader89"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2069,
        "title": "多音字支持吗?需要怎么设置?",
        "body": "多音字支持吗?需要怎么设置?",
        "state": "closed",
        "user": "wangcc57",
        "closed_by": "yt605155624",
        "created_at": "2022-06-23T01:57:50+00:00",
        "updated_at": "2022-06-27T03:36:39+00:00",
        "closed_at": "2022-06-27T03:36:39+00:00",
        "comments_count": [
            "yt605155624",
            "wangcc57",
            "wangcc57",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2077,
        "title": "ASR LibriSpeech 数据集下载失败",
        "body": "![21b954acc984f2caca9f96b7a50b085](https://user-images.githubusercontent.com/20540661/175883421-20244db1-97f5-475d-9956-055b1151a9b3.png)\r\n",
        "state": "closed",
        "user": "Doubledongli",
        "closed_by": "yt605155624",
        "created_at": "2022-06-27T07:26:17+00:00",
        "updated_at": "2022-06-28T11:29:46+00:00",
        "closed_at": "2022-06-28T11:29:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2101,
        "title": "流式 TTS 服务支持更改采样率",
        "body": "用户提了一个 pr https://github.com/PaddlePaddle/PaddleSpeech/pull/2096 \r\n但是要求 server 也启动有个 8k 的模型才行，否则如果模型是 24k 的，但是用户输入了 8k, 此时保存的音频就有问题\r\n目前 24k 写死也不好，如果后续想要加 22.05k 的模型的话，目前这么写是有问题的",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-06-29T09:46:45+00:00",
        "updated_at": "2022-07-07T10:46:14+00:00",
        "closed_at": "2022-07-07T10:46:14+00:00",
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2093,
        "title": "请问支持流式语音识别再训练吗？",
        "body": "我想根据自己的使用场景，增加数据再训练一下流式语音识别，请问要训练example下面的哪个文件呢？",
        "state": "closed",
        "user": "HandsLing",
        "closed_by": "yt605155624",
        "created_at": "2022-06-29T07:51:03+00:00",
        "updated_at": "2022-09-27T08:19:48+00:00",
        "closed_at": "2022-09-27T08:19:47+00:00",
        "comments_count": [
            "yt605155624",
            "HandsLing",
            "Jackwaterveg",
            "HandsLing",
            "stale[bot]",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2092,
        "title": "调用语音合成播报报错",
        "body": "ubuntu流式语音合成服务，服务是设置开机自启动，开始一两次调用语音合成正常，后面在调用服务就报OSError: [Errno -9997] Invalid sample rate，服务进程还在，只有重启之后，后续调用语音合成就没有问题\r\n",
        "state": "closed",
        "user": "PCITBoy",
        "closed_by": "yt605155624",
        "created_at": "2022-06-29T05:57:49+00:00",
        "updated_at": "2022-07-27T06:56:14+00:00",
        "closed_at": "2022-07-27T06:56:14+00:00",
        "comments_count": [
            "lym0302"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2095,
        "title": "代码错误",
        "body": "调用训练代码 PaddleSpeech\\paddlespeech\\s2t\\exps\\u2\\bin\\train.py 发现\r\n![8d8c24e14acff86c64b7dfac7bc2876](https://user-images.githubusercontent.com/20540661/176392814-3356fa34-2049-40dc-bf2f-049f604e0278.png)\r\n\r\n\r\n这个地方，如果是截取文件后缀，是不是第一个split也应该是-1而不是0",
        "state": "closed",
        "user": "Doubledongli",
        "closed_by": "yt605155624",
        "created_at": "2022-06-29T08:42:10+00:00",
        "updated_at": "2022-07-01T02:54:03+00:00",
        "closed_at": "2022-07-01T02:54:03+00:00",
        "comments_count": [
            "SmileGoat"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2112,
        "title": "About log redundancy",
        "body": "cli:\r\n- command line: https://github.com/PaddlePaddle/PaddleSpeech/pull/2107\r\n- python api: https://github.com/PaddlePaddle/PaddleSpeech/pull/2111\r\n\r\nserver:\r\n- print the log twice: https://github.com/PaddlePaddle/PaddleSpeech/pull/2109\r\n- command line: https://github.com/PaddlePaddle/PaddleSpeech/pull/2113",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-07-01T10:03:15+00:00",
        "updated_at": "2022-07-05T01:52:49+00:00",
        "closed_at": "2022-07-05T00:42:03+00:00",
        "comments_count": [],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2099,
        "title": "Demo Speech Web 测试问题",
        "body": "**Describe the bug**\r\nSafari 测试所有功能无反应；chrome 测试端到端合成可以，流式不行，其他功能无反应。\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 按教程部署\r\n2. 正常运行\r\n\r\n**Screenshots**\r\nWeb：\r\n![WechatIMG15](https://user-images.githubusercontent.com/33193762/176398337-afaaaf26-451c-445f-8611-5f5095c54efc.jpeg)\r\nServer：\r\n![WechatIMG17](https://user-images.githubusercontent.com/33193762/176398429-b814e700-7651-4765-8702-f9e2b8e3a8c4.png)\r\n\r\n** Environment (please complete the following information):**\r\n - OS: CentOS 7.9.2009 x86_64\r\n - GCC/G++ Version 4.8.5 20150623 (Red Hat 4.8.5-44)\r\n - Python Version 3.7.13\r\n - PaddlePaddle Version 2.3.0\r\n - Model Version [e.g. 2.0.0]\r\n\r\n",
        "state": "closed",
        "user": "ansent788",
        "closed_by": "yt605155624",
        "created_at": "2022-06-29T09:14:52+00:00",
        "updated_at": "2022-09-06T07:33:48+00:00",
        "closed_at": "2022-09-06T07:33:48+00:00",
        "comments_count": [
            "iftaken",
            "ansent788"
        ],
        "labels": [
            "Bug",
            "Demo"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2110,
        "title": "批量提取音频特征并用于音频检索",
        "body": "目前有一个应用场景，是在许多较长的音频文件中，提供一个不定长的音频文件（一般来说在十几秒钟左右）来检索它来自哪个音频文件以及开始与结束位置。\r\nPaddleSpeech/demos/audio_searching/项目主要参考自这里。\r\n为了拟合输入数据得到正确的匹配结果，我尝试将大段音频文件切分成具有小段间隔且高度重叠的小音频文件并提取特征，主要根据PaddleSpeech/demos/audio_searching/src/encode.py进行改写，它看起来效果不错。但是面对大量的文件进行嵌入并提取特征时，效率太低，这是否与每次重新加载模型并初始化有关？我是不是错过了官方的批量提取接口？",
        "state": "closed",
        "user": "Sweet-BeanOnE",
        "closed_by": "yt605155624",
        "created_at": "2022-07-01T03:11:44+00:00",
        "updated_at": "2022-07-02T02:12:04+00:00",
        "closed_at": "2022-07-02T02:12:04+00:00",
        "comments_count": [
            "yt605155624",
            "Sweet-BeanOnE",
            "yt605155624",
            "Sweet-BeanOnE"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2118,
        "title": "asr对于语音文件的结尾识别不是很好，请问这个有什么解决方案吗",
        "body": null,
        "state": "closed",
        "user": "tianyunzqs",
        "closed_by": "tianyunzqs",
        "created_at": "2022-07-06T05:54:50+00:00",
        "updated_at": "2022-07-06T06:31:08+00:00",
        "closed_at": "2022-07-06T06:31:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2114,
        "title": "数据类型有错误哦",
        "body": "2022-07-05 11:07:06.922 | INFO     | paddlespeech.s2t.training.trainer:do_train:271 - Train Total Examples: 6245\r\nTraceback (most recent call last):\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\training\\trainer.py\", line 342, in run\r\n    self.do_train()\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\training\\trainer.py\", line 307, in do_train\r\n    raise e\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\training\\trainer.py\", line 286, in do_train\r\n    self.train_batch(batch_index, batch, msg)\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\exps\\deepspeech2\\model.py\", line 55, in train_batch\r\n    loss = self.model(audio, audio_len, text, text_len)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\models\\ds2\\deepspeech2.py\", line 292, in forward\r\n    loss = self.decoder(eouts, eouts_len, text, text_len)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n2022-07-05 11:07:18.467 | ERROR    | paddlespeech.s2t.training.trainer:do_train:306 - (InvalidArgument) The type of data we are trying to retrieve does not match the type of data currently contained in the container. (at C:\\home\\workspace\\Paddle_release\\paddle\\phi\\core\\dense_tensor.cc:148)\r\n  [operator < warpctc > error]\r\n2022-07-05 11:07:18.468 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Epoch-Train Time Cost: 0:00:11.545535\r\n2022-07-05 11:07:18.468 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Training Done: 0:00:12.690650\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\modules\\ctc.py\", line 95, in forward\r\n    loss = self.criterion(logits, ys_pad, hlens, ys_lens)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\develop\\workspace\\PaddleSpeech\\paddlespeech\\s2t\\modules\\loss.py\", line 93, in forward\r\n    loss = self.loss(logits, ys_pad, hlens, ys_lens, **self._kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\nn\\layer\\loss.py\", line 1130, in forward\r\n    norm_by_times=norm_by_times)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\nn\\functional\\loss.py\", line 1126, in ctc_loss\r\n    input_lengths, label_lengths)\r\n  File \"D:\\conda\\envs\\asr\\lib\\site-packages\\paddle\\fluid\\layers\\loss.py\", line 613, in warpctc\r\n    norm_by_times, )\r\nValueError: (InvalidArgument) The type of data we are trying to retrieve does not match the type of data currently contained in the container. (at C:\\home\\workspace\\Paddle_release\\paddle\\phi\\core\\dense_tensor.cc:148)\r\n  [operator < warpctc > error]\r\n\r\n![image](https://user-images.githubusercontent.com/20540661/177243521-a50b2802-b641-45a2-8399-1e9b5587c7c4.png)\r\n![image](https://user-images.githubusercontent.com/20540661/177243544-586de79a-80ea-48b8-9299-2c6942da0430.png)\r\n这个错误，起先是数据类型错误，后来我自己转了下类型还是错误，我的操作系统是下面的配置。\r\n![image](https://user-images.githubusercontent.com/20540661/177243641-9fadf039-74e2-453a-978d-f6c9042e18e6.png)\r\n![image](https://user-images.githubusercontent.com/20540661/177243788-deec1ee1-91e9-4507-886c-f4398f6d1fd1.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "Doubledongli",
        "closed_by": "yt605155624",
        "created_at": "2022-07-05T03:28:04+00:00",
        "updated_at": "2022-07-19T11:17:45+00:00",
        "closed_at": "2022-07-19T11:17:45+00:00",
        "comments_count": [
            "zh794390558",
            "Doubledongli",
            "zh794390558",
            "Doubledongli",
            "yt605155624"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2134
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2141
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2144
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2123,
        "title": "安装paddlespeech 过程中过pyworld装不上",
        "body": "  Running setup.py install for pyworld ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × Running setup.py install for pyworld did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [22 lines of output]\r\n      /home/data_dev/miniconda3/envs/asr/lib/python3.7/site-packages/setuptools/dist.py:774: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n        % (opt, underscore_opt)\r\n      running install\r\n      /home/data_dev/miniconda3/envs/asr/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n        setuptools.SetuptoolsDeprecationWarning,\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build/lib.linux-x86_64-cpython-37\r\n      creating build/lib.linux-x86_64-cpython-37/pyworld\r\n      copying pyworld/__init__.py -> build/lib.linux-x86_64-cpython-37/pyworld\r\n      running build_ext\r\n      skipping 'pyworld/pyworld.cpp' Cython extension (up-to-date)\r\n      building 'pyworld.pyworld' extension\r\n      creating build/temp.linux-x86_64-cpython-37\r\n      creating build/temp.linux-x86_64-cpython-37/lib\r\n      creating build/temp.linux-x86_64-cpython-37/lib/World\r\n      creating build/temp.linux-x86_64-cpython-37/lib/World/src\r\n      creating build/temp.linux-x86_64-cpython-37/pyworld\r\n      gcc -pthread -B /home/data_dev/miniconda3/envs/asr/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -Ilib/World/src -I/home/data_dev/miniconda3/envs/asr/include/python3.7m -I/home/data_dev/miniconda3/envs/asr/lib/python3.7/site-packages/numpy/core/include -c lib/World/src/cheaptrick.cpp -o build/temp.linux-x86_64-cpython-37/lib/World/src/cheaptrick.o\r\n      gcc: error trying to exec 'cc1plus': execvp: 没有那个文件或目录\r\n      error: command '/usr/bin/gcc' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n× Encountered error while trying to install package.\r\n╰─> pyworld\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\n",
        "state": "closed",
        "user": "chengming1108",
        "closed_by": "yt605155624",
        "created_at": "2022-07-07T09:24:02+00:00",
        "updated_at": "2022-08-26T07:06:19+00:00",
        "closed_at": "2022-07-27T06:48:00+00:00",
        "comments_count": [
            "Jackwaterveg",
            "chengming1108",
            "chengming1108",
            "chengming1108",
            "ChuxiJ"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2131,
        "title": "💬 PaddleSpeech 文档问题留言",
        "body": "【这个Issue用于文档问题留言与跟进，开发者们遇到问题的地方以及相关的建议可以在这里进行留言】\r\n\r\nPaddleSpeech文档资料\r\n+ [【readthedoc】](https://paddlespeech.readthedocs.io/en/latest/)\r\n+ [【飞桨PaddleSpeech语音技术】](https://aistudio.baidu.com/aistudio/education/group/info/25130)\r\n+ [【wiki】](https://github.com/PaddlePaddle/PaddleSpeech/wiki)\r\n+ [【FAQ】](https://github.com/PaddlePaddle/PaddleSpeech/discussions/1989)\r\n\r\n[【Discussions】](https://github.com/PaddlePaddle/PaddleSpeech/discussions)区也有很多精华内容\r\n\r\n目前PaddleSpeech入门教程[【PaddleSpeechStudy】](https://github.com/iftaken/PaddleSpeechStudy)在编写中，大家有想了解的问题或者Demo可以在本Issue下进行留言。\r\n\r\n\r\n",
        "state": "closed",
        "user": "iftaken",
        "closed_by": "stale[bot]",
        "created_at": "2022-07-11T06:24:07+00:00",
        "updated_at": "2022-12-23T21:25:16+00:00",
        "closed_at": "2022-12-23T21:25:16+00:00",
        "comments_count": [
            "iftaken",
            "lijielijie",
            "yt605155624",
            "BrightXiaoHan",
            "yt605155624",
            "SuperMaskv",
            "yt605155624",
            "J-ZZ",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Documentation",
            "Stale",
            "Report"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2132,
        "title": "【建议】希望能细化ASR/TTS的训练流程",
        "body": "首先我们要肯定PaddleSpeech是一个值得推荐的项目，希望PS能走得更好、更快，所以提出一些针对新手友好性的建议，同时也希望PS能成为强力的基石。\r\n\r\n### 关于TTS的数据集处理流程建议\r\n根据文档（[此处](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/tts/quick_start_cn.md)）所示，我们可以按照CSMSC（biaobei）数据集进行训练，但TTS作为AI行业的门脸形象，对个性化的需求很强，所以需要自己准备数据集的需求也随之更高。\r\n\r\n--- 社区[kslz](https://github.com/kslz)同学写了一篇文章[关于训练一个自己的TTS模型](https://github.com/PaddlePaddle/PaddleSpeech/discussions/1842)，但感觉也是有点懵，中间的MFA处理和数据预处理过程不是很明白\r\n\r\n**自定义数据集训练是否能简单化？**\r\n\r\n比如：\r\n\r\n**自定义训练步骤：**\r\n`准备数据 - 预处理 - 训练 - 推理测试`\r\n\r\n1、按照下列目录结果填充数据\r\n```\r\n/dataset/\r\n        |- wav/  （音频目录）\r\n        |- data.txt (音频标注，每行：文件名|中文|拼音|音色ID)\r\n```\r\n\r\n2、预处理自定义数据集\r\n\r\n`执行文件or命令xxx`\r\n\r\n成功后会生成预处理目录：\r\n```\r\n/preprocessData/\r\n    |- wav/ 音频预处理后的npy\r\n    |- mel/  音频对应的mel\r\n    |- embeds/ 音频对应的特征\r\n    |- train.txt  待训练的数据标注\r\n```\r\n\r\n3、开始训练\r\n```\r\n      a. 训练合成器\r\n      b. 训练声码器（训练声码器是个苦差事）\r\n```\r\n\r\n4、训练完成，推理验证\r\n`执行文件or命令xxx`\r\n\r\n\r\n\r\n**如何在原模型基础上增量训练与微调？**\r\n`执行文件or命令xxx`\r\n\r\n\r\n\r\n**训练过程中的一些问题介绍：**\r\n1、loss值大概什么时候可以得到一个好的推理结果？\r\n\r\n2、对显卡要求的一些建议\r\n如：低显存的显卡需要修改文件xxx\r\n\r\n3、调整训练batchSize是否会影响到训练结果？\r\n\r\n4、能否在代码中舍弃sh脚本？\r\n\r\n5、长时间不收敛可能的一些原因？\r\n\r\n6、训练结果有杂音、电流音的原因猜想等\r\n\r\n7、儿化音的特殊处理介绍\r\n\r\n\r\n-------------------------------------------\r\n### 关于对ASR的自定义训练也如上面类似\r\n\r\n",
        "state": "closed",
        "user": "SuperKsa",
        "closed_by": "yt605155624",
        "created_at": "2022-07-11T06:53:35+00:00",
        "updated_at": "2022-09-07T11:47:51+00:00",
        "closed_at": "2022-09-07T11:47:51+00:00",
        "comments_count": [
            "SuperKsa"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2126,
        "title": "tts onnx流式部署，am和voc模型不能部署到指定的GPU",
        "body": "paddle版本 paddlepaddle-gpu: 2.3.0.post112\r\n1. 使用动态模型部署，指定gpu:2, 两个模型均可以部署在gpu2上。\r\n2. 使用onnx部署，指定gpu:2，会出现一个模型部署在gpu:0, 一个模型部署在gpu:2上。\r\n![001](https://user-images.githubusercontent.com/3365153/178140670-c4a07948-3019-4791-bb11-94c4eb950c5f.jpg)\r\n![002](https://user-images.githubusercontent.com/3365153/178140673-9527eca5-27ab-40f2-9d9d-857bce91c286.jpeg)\r\n\r\n",
        "state": "closed",
        "user": "raycool",
        "closed_by": "yt605155624",
        "created_at": "2022-07-10T10:15:52+00:00",
        "updated_at": "2022-07-12T02:56:26+00:00",
        "closed_at": "2022-07-11T05:51:06+00:00",
        "comments_count": [
            "lym0302",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2136,
        "title": "【TTS】使用RTX 3080 GPU进行语音合成报错， CPU版本正常",
        "body": "cuda 信息：\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2020 NVIDIA Corporation\r\nBuilt on Tue_Sep_15_19:10:02_PDT_2020\r\nCuda compilation tools, release 11.1, V11.1.74\r\nBuild cuda_11.1.TC455_06.29069683_0\r\n```\r\n\r\npaddlepaddle-gpu==2.3.1 和 paddlespeech=1.0.1\r\ngpu 测试\r\n\r\n```\r\n>>> paddle.fluid.install_check.run_check()\r\nRunning Verify Fluid Program ... \r\nW0711 19:49:13.336194 11295 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.1, Runtime API Version: 10.2\r\nW0711 19:49:13.337954 11295 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\nYour Paddle Fluid works well on SINGLE GPU or CPU.\r\nYour Paddle Fluid works well on MUTIPLE GPU or CPU.\r\nYour Paddle Fluid is installed successfully! Let's start deep Learning with Paddle Fluid now\r\n>>> paddle.fluid.is_compiled_with_cuda()\r\nTrue\r\n```\r\n执行合成指令\r\n```\r\npaddlespeech tts --am fastspeech2_aishell3 --voc pwgan_aishell3 --input \"你好，欢迎使用百度飞桨深度学习框架！\" --spk_id 0\r\n```\r\n\r\n错误信息：\r\n```\r\nvocab_size: 306\r\nspk_num: 174\r\nfrontend done!\r\nW0711 19:47:24.556126 10579 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.1, Runtime API Version: 10.2\r\nW0711 19:47:24.557787 10579 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\nencoder_type is transformer\r\ndecoder_type is transformer\r\nacoustic model done!\r\nvoc done!\r\nValueError: (InvalidArgument) The value (1055172892) of the non-singleton dimension does not match the corresponding value (1000) in shape for expand_v2 op.\r\n  [Hint: Expected vec_in_dims[i] == expand_shape[i], but received vec_in_dims[i]:1055172892 != expand_shape[i]:1000.] (at /paddle/paddle/phi/kernels/impl/expand_kernel_impl.h:61)\r\n  [operator < expand_v2 > error]\r\n```\r\n\r\n注：在 RTX 2080S 上进行测试，同样的paddlepaddle-gpu==2.3.1 和 paddlespeech=1.0.1 合成是正常的。",
        "state": "closed",
        "user": "phecda-xu",
        "closed_by": "phecda-xu",
        "created_at": "2022-07-12T03:03:10+00:00",
        "updated_at": "2023-10-28T19:26:51+00:00",
        "closed_at": "2022-07-12T08:57:05+00:00",
        "comments_count": [
            "yt605155624",
            "phecda-xu",
            "ChengsongLu"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2147
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2140,
        "title": "按照困难的安装教程报错",
        "body": "命令：sudo pip install -e . -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n报错：\r\nRunning setup.py develop for paddlespeech\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/lizhaohui/PaddleSpeech-develop/setup.py'\"'\"'; __file__='\"'\"'/home/lizhaohui/PaddleSpeech-develop/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /home/lizhaohui/PaddleSpeech-develop/\r\n    Complete output (149 lines):\r\n    fatal: not a git repository (or any of the parent directories): .git\r\n\r\n    __version__ = '0.0.0'\r\n\r\n\r\n    __commit__ = ''\r\n\r\n    write_version_py done\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /usr/local/lib/python3.8/dist-packages/paddlespeech.egg-link (link to .)\r\n    paddlespeech 0.0.0 is already the active version in easy-install.pth\r\n    Installing paddlespeech script to /usr/local/bin\r\n    Installing paddlespeech_client script to /usr/local/bin\r\n    Installing paddlespeech_server script to /usr/local/bin\r\n\r\n    Installed /home/lizhaohui/PaddleSpeech-develop\r\n    Post Install...\r\n    apt update -y\r\n\r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n    命中:1 https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/amd64  InRelease\r\n    命中:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\r\n    命中:3 https://download.docker.com/linux/ubuntu focal InRelease\r\n    命中:4 https://apt.repos.intel.com/mkl all InRelease\r\n    命中:5 http://mirrors.aliyun.com/ubuntu focal InRelease\r\n    命中:6 http://mirrors.aliyun.com/ubuntu focal-security InRelease\r\n    命中:7 http://mirrors.aliyun.com/ubuntu focal-updates InRelease\r\n    命中:8 http://mirrors.aliyun.com/ubuntu focal-proposed InRelease\r\n    命中:9 http://mirrors.aliyun.com/ubuntu focal-backports InRelease\r\n    正在读取软件包列表...\r\n    正在分析软件包的依赖关系树...\r\n    正在读取状态信息...\r\n    有 396 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\r\n    apt install -y bc flac jq vim tig tree sox pkg-config libsndfile1 libflac-dev libogg-dev libvorbis-dev libboost-dev swig python3-dev\r\n\r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n    正在读取软件包列表...\r\n    正在分析软件包的依赖关系树...\r\n    正在读取状态信息...\r\n    bc 已经是最新版 (1.07.1-2build1)。\r\n    libboost-dev 已经是最新版 (1.71.0.0ubuntu2)。\r\n    libflac-dev 已经是最新版 (1.3.3-1build1)。\r\n    libogg-dev 已经是最新版 (1.3.4-0ubuntu1)。\r\n    libvorbis-dev 已经是最新版 (1.3.6-2ubuntu1)。\r\n    pkg-config 已经是最新版 (0.29.1-0ubuntu4)。\r\n    python3-dev 已经是最新版 (3.8.2-0ubuntu2)。\r\n    flac 已经是最新版 (1.3.3-1build1)。\r\n    sox 已经是最新版 (14.4.2+git20190427-2)。\r\n    swig 已经是最新版 (4.0.1-5build1)。\r\n    tig 已经是最新版 (2.4.1-1ubuntu1)。\r\n    tree 已经是最新版 (1.8.0-1)。\r\n    libsndfile1 已经是最新版 (1.0.28-7ubuntu0.1)。\r\n    vim 已经是最新版 (2:8.1.2269-1ubuntu5.7)。\r\n    jq 已经是最新版 (1.6-1ubuntu0.20.04.1)。\r\n    下列软件包是自动安装的并且现在不需要了：\r\n      linux-headers-5.4.0-44 linux-headers-5.4.0-44-generic\r\n      linux-image-5.4.0-44-generic linux-modules-5.4.0-44-generic\r\n      linux-modules-extra-5.4.0-44-generic\r\n    使用'sudo apt autoremove'来卸载它(它们)。\r\n    升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 396 个软件包未被升级。\r\n    echo \"check_certificate = off\" >> ~/.wgetrc\r\n    touch apt.done\r\n    # Ubuntu 16.04 透過 apt 會安裝 boost 1.58.0\r\n    # it seems that boost (1.54.0) requires higher version. After I switched to g++-5 it compiles normally.\r\n    apt install -y --allow-unauthenticated build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev\r\n\r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\n    正在读取软件包列表...\r\n    正在分析软件包的依赖关系树...\r\n    正在读取状态信息...\r\n    cmake 已经是最新版 (3.16.3-1ubuntu1)。\r\n    libboost-program-options-dev 已经是最新版 (1.71.0.0ubuntu2)。\r\n    libboost-system-dev 已经是最新版 (1.71.0.0ubuntu2)。\r\n    libboost-thread-dev 已经是最新版 (1.71.0.0ubuntu2)。\r\n    libbz2-dev 已经是最新版 (1.0.8-2)。\r\n    libboost-test-dev 已经是最新版 (1.71.0.0ubuntu2)。\r\n    libeigen3-dev 已经是最新版 (3.3.7-2)。\r\n    liblzma-dev 已经是最新版 (5.2.4-1ubuntu1.1)。\r\n    zlib1g-dev 已经是最新版 (1:1.2.11.dfsg-2ubuntu1.3)。\r\n    build-essential 已经是最新版 (12.8ubuntu1.1)。\r\n    下列软件包是自动安装的并且现在不需要了：\r\n      linux-headers-5.4.0-44 linux-headers-5.4.0-44-generic\r\n      linux-image-5.4.0-44-generic linux-modules-5.4.0-44-generic\r\n      linux-modules-extra-5.4.0-44-generic\r\n    使用'sudo apt autoremove'来卸载它(它们)。\r\n    升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 396 个软件包未被升级。\r\n    apt-get install -y gcc-5 g++-5 && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 50  && update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 50\r\n    正在读取软件包列表...\r\n    正在分析软件包的依赖关系树...\r\n    正在读取状态信息...\r\n    没有可用的软件包 g++-5，但是它被其它的软件包引用了。\r\n    这可能意味着这个缺失的软件包可能已被废弃，\r\n    或者只能在其他发布源中找到\r\n    然而下列软件包会取代它：\r\n      gcc-10-test-results gcc-9-test-results:i386 gcc-10-test-results:i386\r\n      gcc-9-test-results gcc-8-test-results:i386 gcc-8-test-results\r\n      gcc-7-test-results\r\n\r\n    没有可用的软件包 gcc-5，但是它被其它的软件包引用了。\r\n    这可能意味着这个缺失的软件包可能已被废弃，\r\n    或者只能在其他发布源中找到\r\n\r\n    E: 软件包 gcc-5 没有可安装候选\r\n    E: 软件包 g++-5 没有可安装候选\r\n    make: *** [Makefile:37: kenlm.done] Error 100\r\n    /home/lizhaohui/PaddleSpeech-develop/setup.py:126: CMD: git rev-parse HEAD, Error: b''\r\n    /home/lizhaohui/PaddleSpeech-develop/setup.py:113: CMD: make, Error: None\r\n    /usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\r\n      warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/home/lizhaohui/PaddleSpeech-develop/setup.py\", line 331, in <module>\r\n        setup(**setup_info)\r\n      File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/lizhaohui/PaddleSpeech-develop/setup.py\", line 176, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/usr/lib/python3.8/distutils/cmd.py\", line 335, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/usr/lib/python3.8/distutils/util.py\", line 303, in execute\r\n        func(*args)\r\n      File \"/home/lizhaohui/PaddleSpeech-develop/setup.py\", line 162, in _post_install\r\n        check_call(\"make\")\r\n      File \"/home/lizhaohui/PaddleSpeech-develop/setup.py\", line 116, in check_call\r\n        raise e\r\n      File \"/home/lizhaohui/PaddleSpeech-develop/setup.py\", line 107, in check_call\r\n        sp.check_call(\r\n      File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    /home/lizhaohui/PaddleSpeech-develop/tools\r\n    ----------------------------------------\r\n  ERROR: Can't roll back paddlespeech; was not uninstalled\r\nERROR: Command errored out with exit status 1: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/home/lizhaohui/PaddleSpeech-develop/setup.py'\"'\"'; __file__='\"'\"'/home/lizhaohui/PaddleSpeech-develop/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.",
        "state": "closed",
        "user": "LZH-0225",
        "closed_by": "yt605155624",
        "created_at": "2022-07-12T09:36:41+00:00",
        "updated_at": "2024-06-06T06:04:21+00:00",
        "closed_at": "2022-07-27T06:47:45+00:00",
        "comments_count": [
            "yt605155624",
            "LZH-0225",
            "yt605155624"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2148
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2156
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2145,
        "title": "请问Ubuntu18.04在medium模式下支持声音克隆的训练吗？如果是的话，训练流程是什么",
        "body": "如题",
        "state": "closed",
        "user": "SchweitzerGAO",
        "closed_by": "yt605155624",
        "created_at": "2022-07-13T04:12:22+00:00",
        "updated_at": "2022-07-18T03:29:42+00:00",
        "closed_at": "2022-07-13T04:50:30+00:00",
        "comments_count": [
            "yt605155624",
            "SchweitzerGAO",
            "yt605155624",
            "SchweitzerGAO"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2152,
        "title": "按照教程跑语音分类报错",
        "body": "代码\r\nimport paddle\r\nimport numpy as np\r\nimport soundfile as sf\r\nfrom matplotlib import pyplot as plt\r\nfrom paddleaudio import load\r\n\r\ndata, sr = load(file='./dog.wav', mono=True, dtype='float32')  # 单通道，float32音频样本点\r\n\r\nx = paddle.to_tensor(data,place=paddle.CUDAPlace(2))#需要一张完整的卡跑\r\nn_fft = 1024#FFT样本点个数\r\nwin_length = 1024#窗函数长度\r\nhop_length = 320#音频帧之间的间隔\r\n\r\nspectrogram = paddle.signal.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, onesided=True)  \r\nprint('spectrogram.shape: {}'.format(spectrogram.shape))\r\nprint('spectrogram.dtype: {}'.format(spectrogram.dtype))\r\n\r\n报错\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_345753/1984477273.py in <module>\r\n----> 1 spectrogram = paddle.signal.stft(x, n_fft=n_fft, win_length=win_length, hop_length=hop_length, onesided=True)\r\n      2 print('spectrogram.shape: {}'.format(spectrogram.shape))\r\n      3 print('spectrogram.dtype: {}'.format(spectrogram.dtype))\r\n\r\n~/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/signal.py in stft(x, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, name)\r\n    315 \r\n    316     if x_rank == 1:  # (batch, seq_length)\r\n--> 317         x = x.unsqueeze(0)\r\n    318 \r\n    319     if hop_length is None:\r\n\r\n~/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/tensor/manipulation.py in unsqueeze(x, axis, name)\r\n   1337     \"\"\"\r\n   1338 \r\n-> 1339     return layers.unsqueeze(x, axis, name)\r\n   1340 \r\n   1341 \r\n\r\n~/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layers/nn.py in unsqueeze(input, axes, name)\r\n   6570             ]\r\n   6571         if _in_legacy_dygraph():\r\n-> 6572             out, _ = _C_ops.unsqueeze2(input, 'axes', axes)\r\n   6573             return out\r\n   6574         return _C_ops.final_state_unsqueeze(input, axes)[1]\r\n\r\nRuntimeError:   [operator < unsqueeze2 > error]",
        "state": "closed",
        "user": "LZH-0225",
        "closed_by": "LZH-0225",
        "created_at": "2022-07-15T02:40:21+00:00",
        "updated_at": "2022-07-26T03:08:29+00:00",
        "closed_at": "2022-07-18T10:24:55+00:00",
        "comments_count": [
            "yt605155624",
            "LZH-0225",
            "yt605155624",
            "SmileGoat",
            "LZH-0225",
            "LZH-0225"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2154,
        "title": "[TTS]ErnieSAT",
        "body": "Introduction:\r\n- https://github.com/PaddlePaddle/ERNIE/tree/repro/ernie-sat\r\n\r\nPR:\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2052\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2117\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2263\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2287\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2316",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-07-15T07:03:21+00:00",
        "updated_at": "2022-09-06T07:37:09+00:00",
        "closed_at": "2022-09-06T07:37:09+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "sixyang",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2160,
        "title": "TTS 粵語 男聲/女聲 數據集",
        "body": "請問哪裡可以下載適合PaddleSpeech的粵語 男聲/女聲 數據集，謝謝！",
        "state": "closed",
        "user": "dentalab",
        "closed_by": "yt605155624",
        "created_at": "2022-07-18T02:43:23+00:00",
        "updated_at": "2022-07-18T03:20:47+00:00",
        "closed_at": "2022-07-18T03:16:17+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2161,
        "title": "voxceleb2下载不了了？",
        "body": "` wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aacaa --user ***** --password *******\r\n--2022-07-18 15:41:36--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aacaa\r\nResolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\r\nConnecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\r\nHTTP request sent, awaiting response... 301 Moved Permanently\r\nLocation: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aacaa [following]\r\n--2022-07-18 15:41:39--  https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aacaa\r\nConnecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\r\nHTTP request sent, awaiting response... 404 Not Found\r\n2022-07-18 15:41:40 ERROR 404: Not Found.\r\n`\r\n有谁知道怎么下载吗？",
        "state": "closed",
        "user": "haha010508",
        "closed_by": "yt605155624",
        "created_at": "2022-07-18T07:44:49+00:00",
        "updated_at": "2023-10-30T10:15:53+00:00",
        "closed_at": "2022-09-07T02:59:22+00:00",
        "comments_count": [
            "SmileGoat",
            "haha010508",
            "starmoon-1134"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2166,
        "title": "是否支持流式实时语音克隆服务呢",
        "body": "在 #2145 的基础上，请问是否支持流式实时语音克隆服务呢，谢谢！",
        "state": "closed",
        "user": "SchweitzerGAO",
        "closed_by": "SchweitzerGAO",
        "created_at": "2022-07-18T15:15:20+00:00",
        "updated_at": "2022-07-20T02:15:33+00:00",
        "closed_at": "2022-07-20T02:15:33+00:00",
        "comments_count": [
            "yt605155624",
            "SchweitzerGAO",
            "SchweitzerGAO",
            "yt605155624",
            "SchweitzerGAO"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2150,
        "title": "🏗️ 安装报错留言区（Summary of Installation Errors）",
        "body": "\r\nPaddleSpeech安装过程中遇到的问题都可以在这里留言，一些跟安装相关的问题也会在这里进行汇总\r\n\r\nProblems encountered during the installation of paddlespeech can be left here, and some installation related problems will also be summarized here",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2022-07-14T07:56:49+00:00",
        "updated_at": "2025-06-12T12:14:24+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "BrightXiaoHan",
            "OfOdin",
            "yt605155624",
            "yt605155624",
            "OfOdin",
            "SuperMaskv",
            "SuperMaskv",
            "yuanzicheng",
            "lucasjinreal",
            "linxiaohui",
            "linxiaohui",
            "stale[bot]",
            "yeapllg",
            "2954456878",
            "iftaken",
            "panli841",
            "2954456878",
            "276397082",
            "iftaken",
            "songqikong",
            "ontheway-arch",
            "kenny-chen",
            "MrLittleHand",
            "kenny-chen",
            "monkeycc",
            "monkeycc",
            "mgsky1",
            "truthsun22",
            "truthsun22",
            "ZWHY007",
            "yifei-lu",
            "ZiqingYip",
            "z070204z",
            "kobe24o",
            "zimuyanghua",
            "cherishs001",
            "sunqb",
            "ttPrivacy",
            "LDBS666",
            "Farewell-CK",
            "Farewell-CK",
            "qingjiaozyn",
            "wuchaooooo",
            "zhoufqing",
            "Farewell-CK",
            "Farewell-CK",
            "zhaoxueyu",
            "IMYin",
            "wpx1997-stack",
            "toyosky",
            "can-glan",
            "pdxrlj",
            "vicky-yuan",
            "fanthos",
            "Yangcy207"
        ],
        "labels": [
            "enhancement",
            "Installation",
            "Report"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2163,
        "title": "该怎样进行语音情绪识别工作呢",
        "body": null,
        "state": "closed",
        "user": "BeyondLightYear",
        "closed_by": "yt605155624",
        "created_at": "2022-07-18T08:50:15+00:00",
        "updated_at": "2022-07-26T03:07:14+00:00",
        "closed_at": "2022-07-26T01:54:12+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Emotion"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2170,
        "title": "切换英文语音合成报错 get_input_ids() got an unexpected keyword argument 'get_tone_ids'",
        "body": "要切换成英文语音合成时，更改了/paddlespeech/server/conf/application.yaml这个配置文件中的tts_python里面的声学模型和声码器，声学模型用的是fastspeech2_ljspeech，声码器用的pwgan_ljspeech，并且lang改为en，但是报错 get_input_ids() got an unexpected keyword argument 'get_tone_ids'",
        "state": "closed",
        "user": "Betterman-qs",
        "closed_by": "lym0302",
        "created_at": "2022-07-19T14:21:09+00:00",
        "updated_at": "2023-02-21T06:55:02+00:00",
        "closed_at": "2022-07-20T02:22:21+00:00",
        "comments_count": [
            "wangtiance"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2173,
        "title": "标点恢复怎样进行批处理呢？",
        "body": "请问，想要对大量文本做标点恢复，怎样调取接口来做呢？\r\n",
        "state": "closed",
        "user": "lianyi-q",
        "closed_by": "yt605155624",
        "created_at": "2022-07-20T07:17:23+00:00",
        "updated_at": "2022-07-26T03:06:58+00:00",
        "closed_at": "2022-07-26T01:54:24+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2175,
        "title": "csmsc TTS pipeline 跑不出结果",
        "body": "- 下载了 fastspeech2_nosil_baker_ckpt_0.4 和 pwg_baker_ckpt_0.4 两个模型\r\n- 然后按照 TTS 流水线 给的demo，跑不出来结果\r\n\r\n```python\r\nmodel.set_state_dict(\r\n    paddle.load(args.fastspeech2_checkpoint)[\"main_params\"])\r\n\r\n这个args 是bug吗？我直接替换成了\r\n\r\nmodel.set_state_dict(\r\n    paddle.load(\"./fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\")[\"main_params\"])\r\n```\r\n\r\n- 希望解答，谢谢",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "hackerxiaobai",
        "created_at": "2022-07-20T10:39:44+00:00",
        "updated_at": "2022-07-20T11:58:46+00:00",
        "closed_at": "2022-07-20T11:58:46+00:00",
        "comments_count": [
            "yt605155624",
            "hackerxiaobai"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2176,
        "title": "TTS 声学模型fastspeech2 和声码器hifigan，模型转换是否支持batchsize",
        "body": "您好，实际部署模型时候，希望模型能支持batchsize 增加并发，训练完成的tts 声学模型fastspeech2 和 声码器hifigan ，在动态模型到静态模型转换加入batchsize维度报错，请问这个可以怎么解决呢？\r\n\r\nam_inference = jit.to_static(\r\n                am_inference,\r\n                input_spec=[\r\n                    InputSpec(shape=[-1,-1], dtype=paddle.int64)\r\n                   ])",
        "state": "closed",
        "user": "liroda",
        "closed_by": "yt605155624",
        "created_at": "2022-07-21T05:48:55+00:00",
        "updated_at": "2022-08-02T08:50:31+00:00",
        "closed_at": "2022-07-26T01:54:33+00:00",
        "comments_count": [
            "yt605155624",
            "piekey1994"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2177,
        "title": "csmsc synthesize 和 synthesize_e2e 两者跑出来的音频结果差距挺大",
        "body": "- 第一次跑TTS相关的，在自己数据集上训练的模型\r\n- csmsc synthesize 和 synthesize_e2e 两者跑出来的音频结果差距挺大\r\n- 请问这个是合理的吗？",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "hackerxiaobai",
        "created_at": "2022-07-21T07:19:07+00:00",
        "updated_at": "2022-07-26T03:04:56+00:00",
        "closed_at": "2022-07-23T05:46:55+00:00",
        "comments_count": [
            "hackerxiaobai",
            "yt605155624",
            "hackerxiaobai"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2178,
        "title": "fastspeech2 采用 conformer 时，合成语音不圆润，是什么问题？",
        "body": "如题，不过vocoder部分没有重新训练，和这个有关系吗？",
        "state": "closed",
        "user": "ychyyz",
        "closed_by": "yt605155624",
        "created_at": "2022-07-21T08:03:14+00:00",
        "updated_at": "2022-07-26T03:05:32+00:00",
        "closed_at": "2022-07-26T02:05:32+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2179,
        "title": "流式语音识别的输入也是wav文件，怎样实现流式识别呢？",
        "body": "是遇到空白截断，然后发送一个wav文件给server吗？ 还是按固定时间间隔保存声波文件发过去？\r\n能直接对接麦克风进行流式语音识别吗？",
        "state": "closed",
        "user": "yaleimeng",
        "closed_by": "yaleimeng",
        "created_at": "2022-07-21T08:55:37+00:00",
        "updated_at": "2022-07-26T03:04:33+00:00",
        "closed_at": "2022-07-26T02:05:09+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2183,
        "title": "fastspeech2声学模型转onnx有问题，推理报错。",
        "body": "你好，我使用最新的paddlespeech代码，训练出的 fastspeech2-pwgan模型，转成onnx之后，会报错，请问是什么情况啊。\r\n\r\n```\r\nmodel_name: fastspeech2\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/fastspeech2_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/fastspeech2_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_119.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_119.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_44', it will rename to 'p2o.tmp_44.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_5.tmp_0', it will rename to 'p2o.fill_constant_5.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_5.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_5.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_15_', it will rename to 'p2o.auto_15_.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_127.tmp_0', it will rename to 'p2o.fill_constant_127.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_127.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_127.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_88_', it will rename to 'p2o.auto_88_.0'.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\nmodel_name: pwgan\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/pwgan_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/pwgan_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:110: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  long_ = _make_signed(np.long)\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:111: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  ulong = _make_unsigned(np.long)\r\nfrontend done!\r\n2022-07-26 08:54:45.875347923 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.415'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875407802 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.412'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875421803 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.400'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875431503 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.418'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875448096 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.409'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875458417 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.406'. It is not used by any node and should be removed from the model.\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:133] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.677 seconds.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:165] Loading model cost 0.677 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\n2022-07-26 08:54:47.545056644 [E:onnxruntime:, sequential_executor.cc:368 Execute] Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 227, in <module>\r\n    main()\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 223, in main\r\n    ort_predict(args)\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 86, in ort_predict\r\n    am_sess.run(None, input_feed=am_input_feed)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 200, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\n```\r\n\r\n**paddle2onxx** 版本使用了 **0.9.5** 、**0.9.8** 和 **1.0.0rc0**版本都不行。\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-07-26T00:59:12+00:00",
        "updated_at": "2022-07-28T00:38:38+00:00",
        "closed_at": "2022-07-26T01:46:18+00:00",
        "comments_count": [],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2181,
        "title": "搭建demos下speech_web，能进入页面但是功能不可用",
        "body": "简单描述下遇到的问题，搭建成功的大佬帮忙解决下回个帖\r\n1.搭建demos下speech_web，能进入页面但是功能不可用，启用\r\ncd web_client\r\nyarn dev --port 8011\r\n一点击音频文件识别，上传.wav后，一直识别，没结果，然后报错\r\n16:40:32 [vite] http proxy error:\r\nError: read ECONNRESET\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:217:20)\r\n16:42:25 [vite] http proxy error:\r\nError: read ECONNRESET\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:217:20) (x2)\r\n16:53:35 [vite] http proxy error:\r\nError: read ECONNRESET\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:217:20) (x3)\r\n2.在后端部署时报错，但是我没管，没影响页面，\r\ncd speech_server\r\n# 默认8010端口\r\npython main.py --port 8010\r\n报错如下：\r\n(PaddleSpeech) D:\\workspace\\bzy\\demovoice\\PaddleSpeech-develop\\demos\\speech_web\\speech_server>python main.py --port 8010\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 11004] getaddrinfo failed>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 11004]\r\n[nltk_data]     getaddrinfo failed>\r\nD:\\workspace\\syt\\soft\\anaconda\\ana\\envs\\PaddleSpeech\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nD:\\workspace\\syt\\soft\\anaconda\\ana\\envs\\PaddleSpeech\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py:111: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  warnings.warn(\r\nD:\\workspace\\syt\\soft\\anaconda\\ana\\envs\\PaddleSpeech\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py:111: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  warnings.warn(\r\nERROR: Could not find a version that satisfies the requirement paddlespeech_ctcdecoders (from versions: none)\r\nERROR: No matching distribution found for paddlespeech_ctcdecoders\r\n2022-07-23 16:33:42.124 | INFO     | paddlespeech.s2t.modules.ctc:<module>:43 - paddlespeech_ctcdecoders not installed!\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 29, in <module>\r\n    from src.robot import Robot\r\n  File \"D:\\workspace\\bzy\\demovoice\\PaddleSpeech-develop\\demos\\speech_web\\speech_server\\src\\robot.py\", line 6, in <module>\r\n    from src.SpeechBase.asr import ASR\r\n  File \"D:\\workspace\\bzy\\demovoice\\PaddleSpeech-develop\\demos\\speech_web\\speech_server\\src\\SpeechBase\\asr.py\", line 7, in <module>\r\n    from paddlespeech.server.engine.asr.online.python.asr_engine import ASREngine\r\nModuleNotFoundError: No module named 'paddlespeech.server.engine.asr.online.python'",
        "state": "closed",
        "user": "bzy456",
        "closed_by": "yt605155624",
        "created_at": "2022-07-23T09:10:37+00:00",
        "updated_at": "2023-02-01T12:34:57+00:00",
        "closed_at": "2022-07-26T01:49:02+00:00",
        "comments_count": [
            "lucky0604",
            "yt605155624",
            "bbqkj"
        ],
        "labels": [
            "Demo"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2182,
        "title": "长文本怎么进行语音合成",
        "body": "看到有websocket的api 应该是可以分段的上传文字 然后合并成一个wav\r\n\r\n还是说需要自己分段上传 然后合并多个wav",
        "state": "closed",
        "user": "lroyzz",
        "closed_by": "yt605155624",
        "created_at": "2022-07-25T07:03:46+00:00",
        "updated_at": "2022-08-31T14:01:01+00:00",
        "closed_at": "2022-08-31T14:01:01+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2184,
        "title": "fastspeech2声学模型转onnx有问题，推理报错。",
        "body": "你好，我使用最新的paddlespeech代码，训练出的 fastspeech2-pwgan模型，转成onnx之后，会报错，请问是什么情况啊。\r\n\r\n```\r\nmodel_name: fastspeech2\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/fastspeech2_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/fastspeech2_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_119.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_119.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_44', it will rename to 'p2o.tmp_44.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_5.tmp_0', it will rename to 'p2o.fill_constant_5.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_5.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_5.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_15_', it will rename to 'p2o.auto_15_.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_127.tmp_0', it will rename to 'p2o.fill_constant_127.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_127.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_127.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_88_', it will rename to 'p2o.auto_88_.0'.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\nmodel_name: pwgan\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/pwgan_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/pwgan_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:110: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  long_ = _make_signed(np.long)\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:111: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  ulong = _make_unsigned(np.long)\r\nfrontend done!\r\n2022-07-26 08:54:45.875347923 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.415'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875407802 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.412'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875421803 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.400'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875431503 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.418'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875448096 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.409'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875458417 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.406'. It is not used by any node and should be removed from the model.\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:133] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.677 seconds.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:165] Loading model cost 0.677 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\n2022-07-26 08:54:47.545056644 [E:onnxruntime:, sequential_executor.cc:368 Execute] Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 227, in <module>\r\n    main()\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 223, in main\r\n    ort_predict(args)\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 86, in ort_predict\r\n    am_sess.run(None, input_feed=am_input_feed)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 200, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\n```\r\n\r\n**paddle2onxx** 版本使用了 **0.9.5** 、**0.9.8** 和 **1.0.0rc0**版本都不行。\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "Tian14267",
        "created_at": "2022-07-26T00:59:44+00:00",
        "updated_at": "2023-03-20T06:31:32+00:00",
        "closed_at": "2022-07-26T01:46:04+00:00",
        "comments_count": [
            "Tian14267",
            "yt605155624",
            "MgArcher",
            "MgArcher"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2185,
        "title": "websocket流式服务的客户端问题",
        "body": "ASR和TTS都支持了websocket协议的流式服务，但是客户端总不能只在本机运行吧？\r\n其他电脑怎样通过websocket协议跟服务器进行交互？麻烦提供一个非本机的客户端访问脚本。\r\n\r\n别告诉我安装全套paddlespeech然后执行那一段示例代码。。一个客户端安装paddlepaddle太离谱。",
        "state": "closed",
        "user": "yaleimeng",
        "closed_by": "yaleimeng",
        "created_at": "2022-07-26T07:03:31+00:00",
        "updated_at": "2022-07-27T05:47:34+00:00",
        "closed_at": "2022-07-26T07:32:35+00:00",
        "comments_count": [
            "yaleimeng",
            "yt605155624",
            "yaleimeng"
        ],
        "labels": [
            "Server"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2186,
        "title": "联合流式语音识别和标点预测速度很慢",
        "body": "运行联合流式语音识别和标点预测很慢   \r\n![图片](https://user-images.githubusercontent.com/94445730/180955793-d41bba23-a97f-47f1-8fb1-56819a428dbc.png)一个40秒的音频要500多秒\r\n                                              ",
        "state": "closed",
        "user": "gfhjjk",
        "closed_by": "THUzyt21",
        "created_at": "2022-07-26T08:03:11+00:00",
        "updated_at": "2022-08-12T08:49:29+00:00",
        "closed_at": "2022-08-12T08:49:29+00:00",
        "comments_count": [
            "zh794390558",
            "yaleimeng",
            "zh794390558",
            "THUzyt21"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2188,
        "title": "启动server时 程序killed",
        "body": "![image](https://user-images.githubusercontent.com/29371605/180968051-b91e2dc0-c887-4ba5-831e-5a65513df2e7.png)\r\n\r\n正常安装\r\ncentos\r\npaddle.utils.run_check 正常\r\n\r\n机器2C2G内存 是内存不足的 原因吗",
        "state": "closed",
        "user": "lroyzz",
        "closed_by": "yt605155624",
        "created_at": "2022-07-26T09:05:01+00:00",
        "updated_at": "2022-08-30T12:51:06+00:00",
        "closed_at": "2022-08-30T12:51:06+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Server"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2187,
        "title": "ImportError: paddle/fluid/core_noavx.so: undefined symbol: shm_unlink",
        "body": "When running PaddleSpeech on RaspberryPi, I am given an ImportError regarding noavx in Paddle. I have followed instructions from [QEngineering](https://github.com/Qengineering/Paddle-Raspberry-Pi) to download the paddlepaddle wheel for aarch64 machines.\r\n\r\n## Reproduction Steps\r\n```bash\r\n## Installation\r\n$ sudo apt-get install cmake wget libatlas-base-dev libopenblas-dev libblas-dev liblapack-dev patchelf gfortran\r\n$ pip install Cython six requests wheel pyyaml protobuf==3.13.0\r\n$ pip install -U setuptools\r\n$ wget https://github.com/Qengineering/Paddle-Raspberry-Pi/raw/main/paddlepaddle-2.3.1-cp39-cp39-linux_aarch64.whl\r\n$ pip install paddlepaddle-2.3.1-cp39-cp39-linux_aarch64.whl\r\n$ pip install pytest-runner -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n$ pip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n\r\n## Execution\r\n$ paddlespeech asr –model transformer_librispeech –lang en –input sample.wav -v\r\nError: Can not import noavx core while this file exists: /home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/core_noavx.so\r\nTraceback (most recent call last):\r\n  File \"/home/elock/archiconda3/envs/paddle/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\r\n    import paddle\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 37, in <module>\r\n    from . import core\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/core.py\", line 366, in <module>\r\n    raise e\r\n  File \"/home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/core.py\", line 314, in <module>\r\n    from . import core_noavx\r\nImportError: /home/elock/archiconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/core_noavx.so: undefined symbol: shm_unlink\r\n```\r\n\r\n## OS\r\n```\r\n$ uname -a\r\nLinux raspberrypi 5.15.32-v8+ #1538 SMP PREEMPT Thu Mar 31 19:40:39 BST 2022 aarch64 GNU/Linux\r\n```\r\n\r\n## GPU\r\nNone\r\n\r\n## Environment\r\n- Conda 4.5.12\r\n- Python 3.9.13\r\n- GCC 10.2.1\r\n- PaddlePaddle 2.3.1\r\n- PaddleSpeech 1.0.1\r\n\r\n## Misc\r\n```\r\npaddle-bfloat      0.1.7\r\npaddle2onnx        0.9.2\r\npaddleaudio        1.0.1\r\npaddlefsl          1.1.0\r\npaddlenlp          2.3.4\r\npaddlepaddle       2.3.1\r\npaddlespeech       1.0.1\r\npaddlespeech-feat  0.1.0\r\n```\r\n",
        "state": "closed",
        "user": "kwokyto",
        "closed_by": "yt605155624",
        "created_at": "2022-07-26T08:47:30+00:00",
        "updated_at": "2022-09-06T07:33:38+00:00",
        "closed_at": "2022-09-06T07:33:38+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2191,
        "title": "PaddleSpeech的AIstudio课程中声音分类项目报错",
        "body": "运行AI Studio课程中的声音分类项目，安装了paddleaudio pip list | grep audio 显示paddleaudio 1.0.1   导入import paddleaudio时 程序还是报 No module named 'paddleaudio'错误。此前曾在paddleocr安装是遇到过类似错误，是No module named shapely.不清楚是环境问题，还是权限问题。记得当时是有过一次ai studio的升级。",
        "state": "closed",
        "user": "sosojust1984",
        "closed_by": "sosojust1984",
        "created_at": "2022-07-27T07:55:03+00:00",
        "updated_at": "2022-07-28T00:38:04+00:00",
        "closed_at": "2022-07-28T00:25:47+00:00",
        "comments_count": [
            "sosojust1984"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2192,
        "title": "asr模型可以导出静态图推理吗",
        "body": null,
        "state": "closed",
        "user": "njustczr",
        "closed_by": "yt605155624",
        "created_at": "2022-07-27T09:27:30+00:00",
        "updated_at": "2022-09-07T03:00:29+00:00",
        "closed_at": "2022-09-07T03:00:29+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2190,
        "title": "s2t项目中asr1 如何在训练时预加载提供的conformer预训练模型？",
        "body": "asr1项目中  想在自己的数据集上进行训练  想加载提供的conformer预训练模型进行参数初始化并冻结一些层，请问如何修改源码？",
        "state": "closed",
        "user": "wangdabee",
        "closed_by": "yt605155624",
        "created_at": "2022-07-27T01:58:09+00:00",
        "updated_at": "2022-09-07T02:59:32+00:00",
        "closed_at": "2022-09-07T02:59:32+00:00",
        "comments_count": [
            "SmileGoat",
            "Jackwaterveg"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2194,
        "title": "请问标点符号的训练资料格式",
        "body": "我想使用自己的data fine-tune标点符号。 \r\nexample提供的iwslt2012_zh，是来自于TED talks，文本当中的每一句字数不多。\r\n想请问每句字数有限制?\r\n或是一句当中最多几个标点符号?\r\n\r\n先行感谢回覆",
        "state": "closed",
        "user": "jeremy110",
        "closed_by": "jeremy110",
        "created_at": "2022-07-27T09:35:43+00:00",
        "updated_at": "2022-07-28T00:37:10+00:00",
        "closed_at": "2022-07-27T11:09:27+00:00",
        "comments_count": [
            "yt605155624",
            "jeremy110"
        ],
        "labels": [
            "Text"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2205
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2196,
        "title": "🔍 TTS 文本前端问题汇总（Text Frontend Bugs）",
        "body": "## Please report TTS text frontend bugs here, for examples: text normalization, polyphone and tone sandhi, etc.\r\n\r\n**We encourage developers to solve these problems.**\r\n\r\n1. polyphone: 能说多长(zhang3 ❎)的语音呢？是否可以长(zhang3 ❎)语音合成呢？长(chang2 ✅)语音，长(zhang3 ❎)文本 -> fixed\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-07-28T02:36:06+00:00",
        "updated_at": "2025-06-27T02:32:48+00:00",
        "closed_at": null,
        "comments_count": [
            "LiuChiachi",
            "yt605155624",
            "yt605155624",
            "BarryKCL",
            "yt605155624",
            "yt605155624",
            "pengzhendong",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "HandsLing",
            "HandsLing",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "yt605155624",
            "mogosmart",
            "yt605155624",
            "mogosmart",
            "yt605155624",
            "yt605155624",
            "stale[bot]",
            "HumbleShaw",
            "zhuqn",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "T2S",
            "good first issue",
            "Report"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2207
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2201,
        "title": "[TTS]add cli for zh_en mix tts",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-07-28T11:30:29+00:00",
        "updated_at": "2022-07-29T08:20:36+00:00",
        "closed_at": "2022-07-29T08:20:36+00:00",
        "comments_count": [],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2197,
        "title": "为什么你们的fastspeech2的长文本中文合成效果好？",
        "body": "同样用baker数据集训练\r\n我训练的结果 长文本后半段就异常了\r\n[our_fastspeech2.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/9205043/our_fastspeech2.zip)\r\n\r\n你们的fastspeech2预训练模型的结果就是正常的，为什么你们支持的长度比我的长，而数据集是一致的\r\n[paddle_fastspeech2.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/9205044/paddle_fastspeech2.zip)\r\n",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-07-28T03:06:04+00:00",
        "updated_at": "2022-09-06T08:19:11+00:00",
        "closed_at": "2022-09-06T08:19:11+00:00",
        "comments_count": [
            "yt605155624",
            "lawo123",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2199,
        "title": "💬【夸夸】留言区",
        "body": "PaddleSpeech语音机器人 🤖  已上线，你可以在这里给陌生人留言，留一句【鼓励】他人的话 👻  ，可以是励志金句，也可以是🌈  屁，可以是你的人生座右铭，也可以是你喜欢的诗词歌句，我们筛选后会放入机器人的【夸夸 🤠  】后台，本活动长期有效，希望我们的机器人能够为你带来一些快乐 🥰  ~\r\n\r\n参与方式：【留言类型】+ 留言内容，留言类型分为【鼓励】与【建议】，【鼓励】中的句子我们筛选后会放入后台，【建议】中的句子为建议留言，我们根据建议，对机器人内容与形式进行调整。🤓\r\n\r\n示例一：【鼓励】留言 😝\r\n>【鼓励】你是我见过最可爱的人！爱你！\r\n>【鼓励】路漫漫其修远兮，吾将上下而求索！希望你克服万难，勇往直前！\r\n\r\n示例二：【建议】留言 🧐\r\n> 【建议】建议增加更多的音色\r\n\r\n**添加机器人的方式**：\r\n\r\n微信扫码，添加PaddleSpeech机器人微信：\r\n\r\n<img width=\"273\" alt=\"98a77df5450cc931b0da6a7880c38097\" src=\"https://user-images.githubusercontent.com/30135920/181512213-b1be165b-4365-4563-b49a-308bdd8a359a.png\">\r\n\r\n\r\n\r\n**加入PaddleSpeech夸夸群聊**：\r\n\r\n> **入群注意事项**：\r\n> 1. 可以跟机器人互动，也可以跟群里的朋友们一起吹水！但是注意发言，文明和谐友善，不可以发广告，不可以触犯法律底线！请大家发言遵守文明公约！！！👮 \r\n> 2. 谨防诈骗，不要随意添加陌生人 😈  的微信，保护好自己的信息安全！\r\n> 3. 希望大家一起玩得开心😆  \r\n> 4. 你可以@PaddleSpeech之后，跟它说 【夸夸我】【夸夸我，我是男孩子】【夸夸我，我是女孩子】等试试，期待你的加入\r\n\r\n微信扫码，回复【语音】，加入【PaddleSpeech交流群】👻  \r\n\r\n![71ed871c5c8ff7829ed04144bd4eb516](https://user-images.githubusercontent.com/30135920/181512966-e31155a2-b3d7-46c6-9972-bd8a2f32ea3e.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "iftaken",
        "closed_by": "stale[bot]",
        "created_at": "2022-07-28T08:57:56+00:00",
        "updated_at": "2023-01-21T04:45:35+00:00",
        "closed_at": "2023-01-21T04:45:35+00:00",
        "comments_count": [
            "stale[bot]",
            "dahu1",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "Report"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2204,
        "title": "tts voc1 中的defualt.yaml 参数设定bug",
        "body": "- 问题是我自己的数据集出现了一个batch的数据中的 b['feats'].shape[0] 都小于 self.mel_threshold 这个只，导致后面的 np.stack 异常\r\n- 其实是需要更改 default.yaml 里的 batch_max_steps 或者 n_shift 参数，但是我没有什么建议，这两个参数我直接调小 batch_max_steps，bug就不会有了，能给一些建议吗？关于调整这个参数\r\n- bug代码问题就是 vocoder_batch_fn.py \r\n ```python\r\n# 某一个batch的数据都小于 self.mel_threshold，导致 batch 为空\r\n batch = [\r\n            self._adjust_length(b['wave'], b['feats']) for b in batch\r\n            if b['feats'].shape[0] > self.mel_threshold\r\n        ]\r\n\r\n```",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "hackerxiaobai",
        "created_at": "2022-07-29T08:30:13+00:00",
        "updated_at": "2022-07-30T07:21:15+00:00",
        "closed_at": "2022-07-30T07:21:15+00:00",
        "comments_count": [
            "yt605155624",
            "hackerxiaobai"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2198,
        "title": "sndfile library not found",
        "body": "版本都对\r\n![WechatIMG0 1](https://user-images.githubusercontent.com/59203496/181461310-989fbf0e-8ca3-4c5a-9cae-b64aa83fa2a0.png)\r\n的\r\n也有libsndfile1\r\n![1](https://user-images.githubusercontent.com/59203496/181461423-27b63f81-d290-42ae-85bb-08945a118502.png)\r\n\r\n",
        "state": "closed",
        "user": "laity-slf",
        "closed_by": "yt605155624",
        "created_at": "2022-07-28T08:39:34+00:00",
        "updated_at": "2022-12-27T06:59:53+00:00",
        "closed_at": "2022-08-30T12:50:53+00:00",
        "comments_count": [
            "yt605155624",
            "laity-slf",
            "yt605155624",
            "lizezheng"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2208
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2210
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2211
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2206,
        "title": "睡得着觉",
        "body": "@PaddleSpeech 合成：睡得着觉\r\n目前：shui de zhe jue❌\r\n标签：shui de zhao jiao✔",
        "state": "closed",
        "user": "Randall-zhang",
        "closed_by": "yt605155624",
        "created_at": "2022-07-29T15:07:53+00:00",
        "updated_at": "2022-08-16T02:36:03+00:00",
        "closed_at": "2022-08-16T02:36:03+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2209,
        "title": "音频降噪的本repo有计划支持吗？",
        "body": "- 如标题",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "hackerxiaobai",
        "created_at": "2022-08-01T06:11:27+00:00",
        "updated_at": "2023-08-01T06:22:53+00:00",
        "closed_at": "2022-08-02T09:49:34+00:00",
        "comments_count": [
            "zh794390558",
            "hackerxiaobai",
            "starmoon-1134"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2223,
        "title": "报错zipfile.BadZipFile: File is not a zip file",
        "body": "看了之前的回答，重新安装了很多次环境都没有解决这个问题，请问为什么？\r\n报错如下：\r\nTraceback (most recent call last):\r\n  File \"/usr/local/zx/PaddleSpeech-develop/try_1.py\", line 1, in <module>\r\n    from paddlespeech.cli.tts.infer import TTSExecutor\r\n  File \"/usr/local/zx/PaddleSpeech-develop/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/usr/local/zx/PaddleSpeech-develop/paddlespeech/cli/tts/infer.py\", line 32, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_frontend\r\n  File \"/usr/local/zx/PaddleSpeech-develop/paddlespeech/t2s/__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"/usr/local/zx/PaddleSpeech-develop/paddlespeech/t2s/frontend/__init__.py\", line 16, in <module>\r\n    from .phonectic import *\r\n  File \"/usr/local/zx/PaddleSpeech-develop/paddlespeech/t2s/frontend/phonectic.py\", line 20, in <module>\r\n    from g2p_en import G2p\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/g2p_en/__init__.py\", line 1, in <module>\r\n    from .g2p import G2p\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/g2p_en/g2p.py\", line 22, in <module>\r\n    nltk.data.find('taggers/averaged_perceptron_tagger.zip')\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/nltk/data.py\", line 542, in find\r\n    return ZipFilePathPointer(p, zipentry)\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/nltk/data.py\", line 394, in __init__\r\n    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/site-packages/nltk/data.py\", line 935, in __init__\r\n    zipfile.ZipFile.__init__(self, filename)\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/zipfile.py\", line 1266, in __init__\r\n    self._RealGetContents()\r\n  File \"/root/anaconda3/envs/speech/lib/python3.9/zipfile.py\", line 1333, in _RealGetContents\r\n    raise BadZipFile(\"File is not a zip file\")\r\nzipfile.BadZipFile: File is not a zip file\r\n\r\n环境如下：\r\n![2 2](https://user-images.githubusercontent.com/88191580/182757239-713036e5-5ecf-4213-b2b1-816e394cfcf6.png)\r\n\r\n",
        "state": "closed",
        "user": "jiweizhangxu",
        "closed_by": "yt605155624",
        "created_at": "2022-08-04T03:32:48+00:00",
        "updated_at": "2022-09-20T12:23:22+00:00",
        "closed_at": "2022-08-04T04:48:23+00:00",
        "comments_count": [
            "dzcmingdi",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2218,
        "title": "wenetspeech streaming ASR failed",
        "body": "When upgrade paddlespeech to the latest develop version, there are shape mismatch errors in logs. But the older version works well.\r\n```\r\n[2022-08-02 20:46:34,856] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2022-08-02 20:46:34,856] [    INFO] - start to do model forward\r\n[2022-08-02 20:46:34,860] [   ERROR] - (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 512, 19], X's size = 155648, 'shape' is [1, 16, 0], the capacity of 'shape' is 8192.\r\n  [Hint: Expected capacity == in_size, but received capacity:8192 != in_size:155648.] (at /paddle/paddle/fluid/operators/reshape_op.cc:204)\r\n  [operator < reshape2 > error]\r\nTraceback (most recent call last):\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 477, in advance_decoding\r\n    (y, self.att_cache, self.cnn_cache) = self.model.encoder.forward_chunk(\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddlespeech/s2t/modules/encoder.py\", line 230, in forward_chunk\r\n    xs, pos_emb, _ = self.embed(xs, tmp_masks, offset=offset)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddlespeech/s2t/modules/subsampling.py\", line 143, in forward\r\n    x = self.out(x.transpose([0, 2, 1, 3]).reshape([b, t, c * f]))\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddle/tensor/manipulation.py\", line 2139, in reshape\r\n    return paddle.fluid.layers.reshape(x=x, shape=shape, name=name)\r\n  File \"/data/miniconda3/envs/ljh_paddle/lib/python3.9/site-packages/paddle/fluid/layers/nn.py\", line 6373, in reshape\r\n    out, _ = _C_ops.reshape2(x, None, 'shape', shape)\r\nValueError: (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 512, 19], X's size = 155648, 'shape' is [1, 16, 0], the capacity of 'shape' is 8192.\r\n  [Hint: Expected capacity == in_size, but received capacity:8192 != in_size:155648.] (at /paddle/paddle/fluid/operators/reshape_op.cc:204)\r\n  [operator < reshape2 > error]\r\n```",
        "state": "closed",
        "user": "JaheimLee",
        "closed_by": "yt605155624",
        "created_at": "2022-08-02T12:53:54+00:00",
        "updated_at": "2022-08-30T12:50:25+00:00",
        "closed_at": "2022-08-30T12:50:25+00:00",
        "comments_count": [
            "zh794390558",
            "JaheimLee",
            "yt605155624"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2225,
        "title": "💡 Load specified model files for TTS cli",
        "body": "## use specified model files:\r\n```python\r\nfrom paddlespeech.cli.tts import TTSExecutor\r\nimport time\r\ntts_executor = TTSExecutor()\r\ntime_3 = time.time()\r\nwav_file = tts_executor(\r\n    text='对数据集进行预处理',\r\n    output='3.wav',\r\n    am='fastspeech2_csmsc',\r\n    am_ckpt='./fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz',\r\n    phones_dict='./fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt',\r\n    am_config='./fastspeech2_nosil_baker_ckpt_0.4/default.yaml',\r\n    am_stat='./fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy',\r\n    voc='hifigan_csmsc',\r\n    voc_ckpt='./hifigan_csmsc_ckpt_0.1.1/snapshot_iter_2500000.pdz',\r\n    voc_config='./hifigan_csmsc_ckpt_0.1.1/default.yaml',\r\n    voc_stat='./hifigan_csmsc_ckpt_0.1.1/feats_stats.npy',\r\n    lang='zh')\r\nprint(\"time of third time:\", time.time()-time_3)\r\ntime_4 = time.time()\r\nwav_file = tts_executor(\r\n    text='对数据集进行预处理',\r\n    output='4.wav',\r\n    am='fastspeech2_csmsc',\r\n    voc='hifigan_csmsc',\r\n    lang='zh')\r\nprint(\"time of forth time:\", time.time()-time_4)\r\n```\r\n```text\r\ntime of third time: 18.366825342178345\r\ntime of forth time: 0.11493206024169922\r\n```\r\n## use specified model files for ljspeech:\r\n```python\r\n# NOTE: You must set `fs` to `22050` for ljspeech when using specified model files for the first time,\r\n#       cause the defualt value of fs  in cli is 24000 but ljspeech's fs is 22050\r\nfrom paddlespeech.cli.tts import TTSExecutor\r\nimport time\r\ntts_executor = TTSExecutor()\r\ntime_3 = time.time()\r\nwav_file = tts_executor(\r\n    text=\"Life was like a box of chocolates, you never know what you're gonna get.\",\r\n    output='lj_test1.wav',\r\n    am='fastspeech2_ljspeech',\r\n    am_ckpt='./fastspeech2_ljspeech_onnx_1.1.0/fastspeech2_ljspeech.onnx',\r\n    phones_dict='./fastspeech2_ljspeech_onnx_1.1.0/phone_id_map.txt',\r\n    voc='hifigan_ljspeech',\r\n    voc_ckpt='./hifigan_ljspeech_onnx_1.1.0/hifigan_ljspeech.onnx',\r\n    lang='en',\r\n    use_onnx=True,\r\n    cpu_threads=2,\r\n    fs=22050)\r\nprint(\"time of third time:\", time.time()-time_3)\r\ntime_4 = time.time()\r\nwav_file = tts_executor(\r\n    text=\"Life was like a box of chocolates, you never know what you're gonna get.\",\r\n    output='lj_test2.wav',\r\n    am='fastspeech2_ljspeech',\r\n    voc='hifigan_ljspeech',\r\n    lang='en',\r\n    use_onnx=True,\r\n    cpu_threads=2)\r\nprint(\"time of forth time:\", time.time()-time_4)\r\n```\r\n```text\r\ntime of third time: 3.591158390045166\r\ntime of forth time: 1.7778213024139404\r\n```",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-08-04T06:54:10+00:00",
        "updated_at": "2023-02-07T02:47:52+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2224,
        "title": "请问一下输入的wav文件必须是16000hz的吗？.mp4之类的文件不能输入吗？",
        "body": "paddle有什么规范输入音频文件格式的程序吗？\r\n",
        "state": "closed",
        "user": "jiweizhangxu",
        "closed_by": "yt605155624",
        "created_at": "2022-08-04T03:34:49+00:00",
        "updated_at": "2022-08-30T12:36:54+00:00",
        "closed_at": "2022-08-30T12:36:54+00:00",
        "comments_count": [
            "wangdabee",
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2226,
        "title": " __init__() got an unexpected keyword argument 'negative_slope'",
        "body": "设备是 jetson nx 8G 版本是jetson 4.6.1 \r\n运行 `paddlespeech asr --lang zh --input zh.wav ` 可以返回正确的结果 \r\n但运行  ` paddlespeech_server start --config_file conf/ws_conformer_wenetspeech_application.yaml` 出现如下错误 启动服务失败\r\n\r\n`[2022-08-04 16:39:21,856] [    INFO] - start to init the engine\r\n[2022-08-04 16:39:21,857] [    INFO] - asr : online engine.\r\n[2022-08-04 16:39:38,210] [   ERROR] - Failed to start server.\r\n2022-08-04 16:39:38.207 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n[2022-08-04 16:39:38,212] [   ERROR] - __init__() got an unexpected keyword argument 'negative_slope'\r\n`",
        "state": "closed",
        "user": "lsfoo",
        "closed_by": "lsfoo",
        "created_at": "2022-08-04T08:46:40+00:00",
        "updated_at": "2022-08-04T09:13:29+00:00",
        "closed_at": "2022-08-04T09:13:29+00:00",
        "comments_count": [
            "yt605155624",
            "lsfoo"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2231,
        "title": "ValueError: `paddle.load` can not parse the file:/Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/exp/conformer/checkpoints/wenetspeech.pdparams.",
        "body": "我执行程序 main.py 报错\r\n\r\n**执行环境：**\r\n\r\n> python 3.8.9\r\n> paddlepaddle 2.3.1\r\n> paddlespeech 1.0.1\r\n\r\n**执行代码：**\r\n\r\n```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\nprint(result)\r\n```\r\n**报错：**\r\n\r\n/Users/petergu/workspace/python/paddle/venv/bin/python /Users/petergu/workspace/python/paddle/main.py\r\n[2022-08-08 15:04:14,091] [    INFO] - checking the audio file format......\r\n[2022-08-08 15:04:14,104] [    INFO] - The sample rate is 16000\r\n[2022-08-08 15:04:14,104] [    INFO] - The audio file format is right\r\n[2022-08-08 15:04:14,104] [    INFO] - start to init the model\r\n[2022-08-08 15:04:14,104] [    INFO] - File /Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz md5 checking...\r\n[2022-08-08 15:04:18,679] [    INFO] - Use pretrained model stored in: /Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar\r\n[2022-08-08 15:04:18,679] [    INFO] - /Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar\r\n[2022-08-08 15:04:18,679] [    INFO] - /Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/model.yaml\r\n[2022-08-08 15:04:18,679] [    INFO] - /Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/exp/conformer/checkpoints/wenetspeech.pdparams\r\nTraceback (most recent call last):\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 952, in load\r\n    load_result = _pickle_loads_mac(path, f)\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/fluid/io.py\", line 1950, in _pickle_loads_mac\r\n    load_result = pickle.loads(pickle_bytes, encoding='latin1')\r\n_pickle.UnpicklingError: pickle data was truncated\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 980, in load\r\n    tensor, _ = _load_selected_rows(path)\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 541, in _load_selected_rows\r\n    _seek = core.load_selected_rows(temp_sr, file_name)\r\nValueError: (InvalidArgument) Only version 0 SelectedRows is supported.\r\n  [Hint: Expected version == 0U, but received version:680854656 != 0U:0.] (at /home/Paddle/paddle/fluid/framework/selected_rows_utils.cc:68)\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 984, in load\r\n    tensor, _ = _load_lod_tensor(path)\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 502, in _load_lod_tensor\r\n    _seek = paddle.fluid.core.load_lod_tensor(temp_t, file_name)\r\nValueError: (InvalidArgument) Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 680854656 found).\r\n  [Hint: Expected version == 0U, but received version:680854656 != 0U:0.] (at /home/Paddle/paddle/fluid/framework/lod_tensor.cc:276)\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 995, in load\r\n    program = Program.parse_from_string(\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 5762, in parse_from_string\r\n    p.desc = core.ProgramDesc(binary_str)\r\nValueError: (InvalidArgument) Failed to parse program_desc from binary string.\r\n  [Hint: Expected desc_.ParseFromString(binary_str) == true, but received desc_.ParseFromString(binary_str):0 != true:1.] (at /home/Paddle/paddle/fluid/framework/program_desc.cc:103)\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/petergu/workspace/python/paddle/main.py\", line 3, in <module>\r\n    result = asr(audio_file=\"zh.wav\")\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 338, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 454, in __call__\r\n    self._init_from_path(model, lang, sample_rate, config, decode_method,\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 192, in _init_from_path\r\n    model_dict = paddle.load(self.ckpt_path)\r\n  File \"/Users/petergu/workspace/python/paddle/venv/lib/python3.8/site-packages/paddle/framework/io.py\", line 999, in load\r\n    raise ValueError(\r\nValueError: `paddle.load` can not parse the file:/Users/petergu/.paddlespeech/models/conformer_wenetspeech-zh-16k/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/exp/conformer/checkpoints/wenetspeech.pdparams.\r\n\r\nProcess finished with exit code 1\r\n",
        "state": "closed",
        "user": "gubaoya123456",
        "closed_by": "yt605155624",
        "created_at": "2022-08-08T07:49:50+00:00",
        "updated_at": "2024-08-09T01:01:53+00:00",
        "closed_at": "2022-08-30T12:50:08+00:00",
        "comments_count": [
            "zh794390558",
            "feng-1985",
            "qinhuangdaoStation",
            "qinhuangdaoStation"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2228,
        "title": "paddlespeech stream server can't start up",
        "body": "ubunt16.04 使用docker 安装 :\r\ndocker pull paddlecloud/paddlespeech:develop-cpu-bb7f2a\r\n\r\n创建docker:\r\ndocker run --name pdspeech \\\r\n  -v /etc/localtime:/etc/localtime \\\r\n  -p 8205:8090 -it  \\\r\n  paddlecloud/paddlespeech:develop-cpu-bb7f2a  /bin/bash\r\n\r\n进入docker后：\r\npaddlespeech_server start --config_file ./demos/streaming_asr_server/conf/ws_conformer_wenetspeech_application_faster.yaml\r\n\r\n报错：\r\nλ 09bd999a5b50 /home/PaddleSpeech paddlespeech_server start --config_file ./demos/streaming_asr_server/conf/ws_conformer_wenetspeech_application_faster.yaml\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n[2022-08-06 08:13:13,946] [    INFO] - start to init the engine\r\n[2022-08-06 08:13:13,946] [    INFO] - asr : online engine.\r\n[2022-08-06 08:13:19,852] [   ERROR] - Failed to start server.\r\n[2022-08-06 08:13:19,853] [   ERROR] - __init__() got an unexpected keyword argument 'negative_slope'\r\n2022-08-06 08:13:19.851 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n\r\n更换其它几个yaml配置文件也是同样的错误\r\n",
        "state": "closed",
        "user": "zoushanjun",
        "closed_by": "yt605155624",
        "created_at": "2022-08-06T00:29:14+00:00",
        "updated_at": "2022-08-08T01:53:42+00:00",
        "closed_at": "2022-08-08T01:53:42+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2227,
        "title": "Set device failed, please check if device '0' is already used and the parameter 'device' in the yaml file",
        "body": "jetson nx 8G \r\n用gpu运行 ` paddlespeech_server start --config_file conf/ws_conformer_wenetspeech_application.yaml` 报错,\r\n\r\n```\r\n[2022-08-04 17:33:41,094] [   ERROR] - Set device failed, please check if device '0' is already used and the parameter 'device' in the yaml file\r\n[2022-08-04 17:33:41,094] [   ERROR] - If all GPU or XPU is used, you can set the server to 'cpu'\r\n```\r\n\r\n而用 `paddlespeech asr --lang zh --input zh.wav ` 正常加载gpu\r\n\r\n`W0804 17:35:40.169039 22715 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.2, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW0804 17:35:40.176759 22715 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n我认为跑步最重要的就是给我带来了身体健康`\r\n\r\n另外 jetson nx 用gpu运行 streaming_tts_server 是正常工作的. \r\n\r\n当然我部署在tesla a10 24G的服务器上,也是正常的.",
        "state": "closed",
        "user": "lsfoo",
        "closed_by": "lsfoo",
        "created_at": "2022-08-04T09:38:10+00:00",
        "updated_at": "2024-05-09T02:50:22+00:00",
        "closed_at": "2022-08-05T01:20:16+00:00",
        "comments_count": [
            "lsfoo",
            "lzy83925",
            "wu-xiaohua",
            "qingjiaozyn",
            "Ch180907",
            "lzy83925",
            "Ch180907",
            "488283943",
            "qingjiaozyn",
            "488283943"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2238
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2232,
        "title": "when process english text with !\" , get error",
        "body": "English text: The girls stared at their father. Mrs. Bennet said only, \"Nonsense, nonsense!\"\r\n\r\nremove !  then the error disappeared.\r\n\r\nError Log:\r\n\r\nTraceback (most recent call last):\r\n  File \"readText_Paddle.py\", line 1175, in <module>\r\n    englishTxt2WavbyPaddle(mp3filepath,textforSpeak)\r\n  File \"readText_Paddle.py\", line 147, in englishTxt2WavbyPaddle\r\n    wav_file = tts_executor(\t\\\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/cli/tts/infer.py\", line 538, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/home/grow/.conda/envs/paddleconda/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/grow/.conda/envs/paddleconda/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 331, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/cli/tts/infer.py\", line 405, in infer\r\n    mel = self.am_inference(part_phone_ids)\r\n  File \"/home/grow/.conda/envs/paddleconda/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 812, in forward\r\n    normalized_mel, d_outs, p_outs, e_outs = self.acoustic_model.inference(\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 709, in inference\r\n    _, outs, d_outs, p_outs, e_outs = self._forward(\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 514, in _forward\r\n    x_masks = self._source_mask(ilens)\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 783, in _source_mask\r\n    x_masks = make_non_pad_mask(ilens)\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 249, in make_non_pad_mask\r\n    return paddle.logical_not(make_pad_mask(lengths, xs, length_dim))\r\n  File \"/home/grow/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 148, in make_pad_mask\r\n    seq_range_expand = seq_range.unsqueeze(0).expand([bs, maxlen])\r\n  File \"/home/grow/.conda/envs/paddleconda/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 1869, in expand\r\n    return _C_ops.expand_v2(x, 'shape', shape)\r\nValueError: (InvalidArgument) The 1th element of 'shape' for expand_v2 op must be greater than 0, but the value given is 0.\r\n  [Hint: Expected expand_shape[i] > 0, but received expand_shape[i]:0 <= 0:0.] (at /paddle/paddle/fluid/operators/expand_v2_op.cc:78)\r\n  [operator < expand_v2 > error]\r\n\r\n",
        "state": "closed",
        "user": "david-95",
        "closed_by": "yt605155624",
        "created_at": "2022-08-08T08:17:18+00:00",
        "updated_at": "2022-08-10T04:21:44+00:00",
        "closed_at": "2022-08-10T04:21:44+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2233,
        "title": "服务多并发出现多个并发的结果相互串了的情况",
        "body": "算法：fastspeech2,  pwgan\r\n服务部署：websocket\r\n并发：2个并发\r\n具体情况：并发1的文本，出来的语音确是并发2的结果；并发2的文本，出来的语音确是并发1的结果；即，两个结果搞串了。\r\n情况追踪：\r\n        通过追踪发现，模型的输入是正常，但是输出不正常。\r\n      \r\n![image](https://user-images.githubusercontent.com/27938135/183391346-7f89ca07-c9a4-42c3-8829-01ec7f21a4e2.png)\r\n`phones_handle`的输入正常，`am_output_data`的结果却不对。请问这情况是什么原因啊，这么解决这个问题。",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "stale[bot]",
        "created_at": "2022-08-08T09:53:22+00:00",
        "updated_at": "2022-11-01T15:17:56+00:00",
        "closed_at": "2022-11-01T15:17:56+00:00",
        "comments_count": [
            "yt605155624",
            "lym0302",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2236,
        "title": "asr 长录音识别",
        "body": "目前 paddlespeech asr 一次识别的音频长度是 50s，虽然可以通过  paddlespeech asr -d 批量识别提高识别效率。但整体效率还是较低，请问有没通用的解决方案，提高离线大文件音频的识别效率呢？\r\n比如识别一段 10分钟 或者 30 分钟的音频。",
        "state": "closed",
        "user": "jkluo",
        "closed_by": "jkluo",
        "created_at": "2022-08-10T03:55:47+00:00",
        "updated_at": "2022-08-10T07:24:58+00:00",
        "closed_at": "2022-08-10T07:24:58+00:00",
        "comments_count": [
            "lym0302",
            "jkluo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2237,
        "title": "asr 长录音识别",
        "body": "目前 paddlespeech asr 一次识别的音频长度是 50s，虽然可以通过  paddlespeech asr -d 批量识别提高识别效率。但整体效率还是较低，请问有没通用的解决方案，提高离线大文件音频的识别效率呢？\r\n比如识别一段 10分钟 或者 30 分钟的音频。",
        "state": "closed",
        "user": "jkluo",
        "closed_by": "stale[bot]",
        "created_at": "2022-08-10T03:57:00+00:00",
        "updated_at": "2022-11-23T00:37:43+00:00",
        "closed_at": "2022-11-23T00:37:43+00:00",
        "comments_count": [
            "zh794390558",
            "jkluo",
            "zh794390558",
            "JaheimLee",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2239,
        "title": "asr  对于ctc alignment.py  的一些疑问和问题",
        "body": "    自己做数据集，重新训练conformer，并实现音频和识别出的文本对齐功能。\r\n    问题描述：asr中，实现音频和文本对齐功能的alignment.py  源码是对整个测试集（batch_size强制为1）进行识别对齐（集成到了Tester中），这一过程需要加载测试集的数据（即align dataloader）和vocab.txt ，vocab.txt （数据集中字符的集合）和dataload （测试集是manifest.test）需要测试数据的wav音频文件和label（标注的txt文本） ，有两个疑问：\r\n1.是不是实现音频和识别出的文本对齐功能，需要标注好测试音频 然后按照data.sh 处理数据，生成manifest文件和vocab文件，之后利用alignment.py实现功能？\r\n2.想要实现像测试单个音频的test_wave.py一样，实现单个音频的识别与对齐功能，除了1说的方法之外，还有没有较为简便的方法（即就像test_wave.py一样，只需要vocab.txt，输入一个音频，就可以识别成文本）？\r\n谢谢！",
        "state": "closed",
        "user": "wangdabee",
        "closed_by": "yt605155624",
        "created_at": "2022-08-10T07:28:25+00:00",
        "updated_at": "2022-09-27T08:16:43+00:00",
        "closed_at": "2022-09-27T08:16:43+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2240,
        "title": "关于tts前端部分韵律预测的疑问",
        "body": "想请教一下，这里文本的韵律预测是在哪个文件，哪个函数实现的？",
        "state": "closed",
        "user": "Zz-ww",
        "closed_by": "yt605155624",
        "created_at": "2022-08-10T10:26:52+00:00",
        "updated_at": "2022-08-10T10:35:51+00:00",
        "closed_at": "2022-08-10T10:35:43+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2242,
        "title": "Multi Band MelGAN为什么没有英文的预训练模型？",
        "body": "Multi Band MelGAN为什么没有英文的预训练模型？",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-08-11T07:56:46+00:00",
        "updated_at": "2022-08-11T08:16:52+00:00",
        "closed_at": "2022-08-11T08:16:41+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2241,
        "title": "关于zh_en_tts/tts3任务的问题",
        "body": "在zh_en_tts/tts3任务中，输入文字如果是15.58万元，它会念成一千五百五十八万元，自动去掉了.点号，有什么好的解决方法吗？谢谢。 ",
        "state": "closed",
        "user": "70557dzqc",
        "closed_by": "yt605155624",
        "created_at": "2022-08-11T03:39:36+00:00",
        "updated_at": "2022-08-19T03:16:29+00:00",
        "closed_at": "2022-08-19T03:16:29+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2245,
        "title": "请教语音克隆，音质优化的方向",
        "body": "使用 AIshell3 训练合成器，效果如下：\r\n![snapshot_iter_193800](https://user-images.githubusercontent.com/33142144/184300909-9426c46f-2d49-4fb6-b610-3d7eb60f0a2c.jpg)\r\n\r\n与第三方TTS效果对比：\r\n![test](https://user-images.githubusercontent.com/33142144/184301028-9ceea9be-b98a-48f4-bb37-41cffec27a21.jpg)\r\n\r\n自己训练的语音质量不高，有沙沙的声音、字之间的清晰度较差。\r\n\r\n小白请教下各位大佬，想要提高语音质量，我该如何优化？\r\n\r\n注：复制链接 wget 下，并将jpg 后缀需要改为 wav\r\n\r\n谢谢！！！\r\n",
        "state": "closed",
        "user": "Lennon-cheng",
        "closed_by": "stale[bot]",
        "created_at": "2022-08-12T06:50:54+00:00",
        "updated_at": "2022-12-23T21:25:25+00:00",
        "closed_at": "2022-12-23T21:25:25+00:00",
        "comments_count": [
            "sixyang",
            "yt605155624",
            "sixyang",
            "Lennon-cheng",
            "yt605155624",
            "Lennon-cheng",
            "sixyang",
            "yt605155624",
            "sixyang",
            "yt605155624",
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2246,
        "title": "KeyError: 'generator_params'",
        "body": "我使用csmsc中的cnndecoder.yaml 作为配置文件训练了一个模型（也就是 #2166 中的方法），在synthesize的过程中报如题错误，请问如何解决，以及如何替换训练好按这个方法训练的模型的基准音呢，谢谢！",
        "state": "closed",
        "user": "SchweitzerGAO",
        "closed_by": "SchweitzerGAO",
        "created_at": "2022-08-13T14:05:17+00:00",
        "updated_at": "2022-08-16T02:11:08+00:00",
        "closed_at": "2022-08-16T02:11:08+00:00",
        "comments_count": [
            "yt605155624",
            "SchweitzerGAO"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2247,
        "title": "请问语音克隆生成的声音太平淡了，没有抑扬顿挫的感觉需要怎么调整？",
        "body": "如题，这里采用的是 vc1 里面的方案，已经把电流音等噪音去的很好了，并且也用的高音质的 ref_audio(女声)，但是最终实现的声音效果有点平淡，就是感觉是一个调调，不像日常交流那样子。并且停顿也不自然，需要手动控制标点符号(加一些逗号等)。请问有什么优化方式吗？谢谢！",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "sixyang",
        "created_at": "2022-08-14T08:41:30+00:00",
        "updated_at": "2022-09-15T07:05:30+00:00",
        "closed_at": "2022-08-18T06:40:57+00:00",
        "comments_count": [
            "lym0302",
            "sixyang",
            "yt605155624",
            "sixyang",
            "oyb1125"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2256,
        "title": "【bug】英文中句号未断句",
        "body": "样例：欢迎使用飞桨 Paddle Speech 语音合成功能，你可以使用 Python 完成 T T S功能的体验，欢迎在 Git hub 中 Star 收藏，持续关注。Welcome to Paddle Speech . You can use Python to experience T T S . Welcome to Star in Git hub and continue to pay attention .\r\n\r\n合成的音频中没有断句",
        "state": "closed",
        "user": "iftaken",
        "closed_by": "yt605155624",
        "created_at": "2022-08-16T08:30:08+00:00",
        "updated_at": "2022-08-19T03:16:30+00:00",
        "closed_at": "2022-08-19T03:16:30+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2248,
        "title": "有个小疑问",
        "body": "请问百度智能云语音识别服务用的是这个repo吗\r\n如果是的话，背后算法用的是最新的pp系列吗",
        "state": "closed",
        "user": "lmk123568",
        "closed_by": "yt605155624",
        "created_at": "2022-08-15T06:13:25+00:00",
        "updated_at": "2022-08-15T10:54:35+00:00",
        "closed_at": "2022-08-15T08:18:02+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2252,
        "title": "speedyspeech训练LJSpeech",
        "body": "请问我怎样才能让speedyspeech训练LJSpeech数据集呢？",
        "state": "closed",
        "user": "dzcmingdi",
        "closed_by": "yt605155624",
        "created_at": "2022-08-16T02:51:57+00:00",
        "updated_at": "2022-08-16T06:32:13+00:00",
        "closed_at": "2022-08-16T06:32:13+00:00",
        "comments_count": [
            "yt605155624",
            "dzcmingdi"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2259,
        "title": "paddlespeech的 Conformer里面的MultiHeadAttention跟pytorch的行为是一致的吗？",
        "body": "RT。",
        "state": "closed",
        "user": "lucasjinreal",
        "closed_by": "yt605155624",
        "created_at": "2022-08-16T14:39:51+00:00",
        "updated_at": "2022-08-30T12:48:15+00:00",
        "closed_at": "2022-08-30T12:48:15+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2258,
        "title": "想转换PaddleSpeech到ONNX格式，但是报错",
        "body": "**问题描述**\r\n目前想转换PaddleSpeech到ONNX格式，代码如下：\r\n```\r\n# 从模型代码中导入模型\r\nimport paddle\r\n\r\n# 实例化模型\r\nmodel_for_onnx = asr_engine.executor.model.encoder\r\n# 将模型设置为推理状态\r\nmodel_for_onnx.eval()\r\n\r\ninput_spec = [\r\n    paddle.static.InputSpec(\r\n        shape=[1, 67, 80],\r\n        dtype='float32',\r\n        name='xs'),\r\n    paddle.static.InputSpec(\r\n        shape=[0],\r\n        dtype='int64',\r\n        name='offset'),\r\n    paddle.static.InputSpec(\r\n        shape=[-16],\r\n        dtype='int64',\r\n        name='required_cache_size'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 16, 512],\r\n        dtype='float32',\r\n        name='subsampling_cache'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 16, 512],\r\n        dtype='float32',\r\n        name='elayers_output_cache'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 512, 14],\r\n        dtype='float32',\r\n        name='conformer_cnn_cache'),\r\n]\r\n\r\n# ONNX模型导出\r\npaddle.onnx.export(model_for_onnx, 'deep_111', input_spec=input_spec, opset_version=12, enable_onnx_checker=True)\r\n\r\n```\r\n\r\n但是报错\r\n\r\n**报错截图**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 6889, in _dygraph_guard\r\n    yield\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/jit.py\", line 868, in save\r\n    with_hook=with_hook)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 528, in concrete_program_specify_input_spec\r\n    *desired_input_spec, with_hook=with_hook)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 436, in get_concrete_program\r\n    concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 801, in __getitem__\r\n    self._caches[item_id] = self._build_once(item)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 790, in _build_once\r\n    **cache_key.kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 740, in from_func_spec\r\n    error_data.raise_new_exception()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 336, in raise_new_exception\r\n    six.exec_(\"raise new_exception from None\")\r\n  File \"<string>\", line 1, in <module>\r\nAssertionError: In transformed code:\r\n\r\n    File \"/github/PaddleSpeech/paddlespeech/s2t/modules/encoder.py\", line 349, in forward\r\n            pos_emb,\r\n            output_cache=attn_cache,\r\n            cnn_cache=cnn_cache)\r\n            ~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n        r_elayers_output_cache.append(xs[:, next_cache_start:, :])\r\n        r_conformer_cnn_cache.append(new_cnn_cache)\r\n\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n\treturn self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n\toutputs = self.forward(*inputs, **kwargs)\r\n    File \"/tmp/tmpgf4ex6_9.py\", line 88, in forward\r\n\toutput_cache, residual, self, x), (mask, residual, x_q))\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n\tout = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 257, in _run_py_ifelse\r\n\treturn true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/tmp/tmpgf4ex6_9.py\", line 77, in false_fn_10\r\n\tpaddle.jit.dy2static.convert_assert(output_cache.shape[0] == x.shape[0]\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 478, in convert_assert\r\n\tassert cond, message\r\n\r\n    AssertionError\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n想请教一下是什么原因？\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhijianli",
        "closed_by": "yt605155624",
        "created_at": "2022-08-16T11:28:38+00:00",
        "updated_at": "2022-09-22T06:08:50+00:00",
        "closed_at": "2022-09-22T06:08:50+00:00",
        "comments_count": [
            "zh794390558",
            "lesliexufdu",
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2260,
        "title": "试图加载deepspeech2online_wenetspeech的onnx文件，但是报错",
        "body": "试图加载deepspeech2online_wenetspeech的onnx文件，代码如下\r\n\r\n```\r\n# 动态图导出的ONNX模型测试\r\nimport time\r\nimport numpy as np\r\nfrom onnxruntime import InferenceSession\r\naudio = np.random.randn(1, 498, 161).astype('float32')\r\naudio_len = np.random.randn(1).astype(\"int64\")\r\ntext = np.random.randn(1, 1, 1).astype('float32')\r\ntext_len = np.random.randn(1, 2, 1).astype('float32')\r\n\r\n# 加载ONNX模型\r\ndeepspeech_onnx = InferenceSession('/data/deepspeech2_online_wenetspeech/onnx/model.quant.int8.onnx')\r\nort_inputs = {'chunk_state_c_box': text_len,\r\n              'chunk_state_h_box': text,\r\n              'audio_chunk_lens': audio_len,\r\n              'audio_chunk': audio\r\n              }\r\nort_outs = deepspeech_onnx.run(None,ort_inputs)\r\n```\r\n\r\n但报错：\r\n`onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Split node. Name:'p2o.Split.0' Status Message: Input cannot be split evenly on selected axis. Input shape={1,1,1} Axis=0 NumOutputs=5`\r\n\r\n看起来似乎是　text = np.random.randn(1, 1, 1).astype('float32')　这一行的形状没有设置对，想问一下，这个text和text_len的形状是什么，有人知道吗？\r\n\r\n",
        "state": "closed",
        "user": "zhijianli",
        "closed_by": "yt605155624",
        "created_at": "2022-08-17T04:08:06+00:00",
        "updated_at": "2022-09-27T08:16:29+00:00",
        "closed_at": "2022-09-27T08:16:29+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2277
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2271,
        "title": "🔥 r1.1.0 release note",
        "body": "# S2T\r\n\r\n\r\n# TTS\r\n  - Fix random speaker embedding bug in voice clone. https://github.com/PaddlePaddle/PaddleSpeech/pull/1828 by @jerryuhoo\r\n  - Add VITS model. https://github.com/PaddlePaddle/PaddleSpeech/pull/1855 https://github.com/PaddlePaddle/PaddleSpeech/pull/1957 https://github.com/PaddlePaddle/PaddleSpeech/pull/2040 \r\n  - Add kunlun support for speedyspeech. https://github.com/PaddlePaddle/PaddleSpeech/pull/1879 by @QingshuChen\r\n  - Normalize wav max value to 1 in preprocess. https://github.com/PaddlePaddle/PaddleSpeech/pull/1887 by @jerryuhoo\r\n  - Remove fluid dependence in TTS. https://github.com/PaddlePaddle/PaddleSpeech/pull/1940\r\n  - Add onnx models for aishell3/ljspeech/vctk's tts3/voc1/voc5. https://github.com/PaddlePaddle/PaddleSpeech/pull/2068\r\n  - Add TTS static/onnx models in pretrained_models.py. https://github.com/PaddlePaddle/PaddleSpeech/pull/2074 \r\n  - Add Ernie SAT model. https://github.com/PaddlePaddle/PaddleSpeech/pull/2052 https://github.com/PaddlePaddle/PaddleSpeech/pull/2117\r\n  - Add Chinese English mixed TTS frontend. https://github.com/PaddlePaddle/PaddleSpeech/pull/2143\r\n  - Add Chinese English mixed TTS example. https://github.com/PaddlePaddle/PaddleSpeech/pull/2234\r\n  - Fix English text frontend bug. https://github.com/PaddlePaddle/PaddleSpeech/pull/2235 by @david-95\r\n  - Add g2pW to Chinese frontend. https://github.com/PaddlePaddle/PaddleSpeech/pull/2230 by @BarryKCL\r\n  - Fix text frontend bugs. https://github.com/PaddlePaddle/PaddleSpeech/pull/1912 https://github.com/PaddlePaddle/PaddleSpeech/pull/2250 https://github.com/PaddlePaddle/PaddleSpeech/pull/2254 https://github.com/PaddlePaddle/PaddleSpeech/pull/2255 https://github.com/PaddlePaddle/PaddleSpeech/pull/2272\r\n\r\n# Speechx\r\n- add custom asr script. https://github.com/PaddlePaddle/PaddleSpeech/pull/1946\r\n- refactor frontend. https://github.com/PaddlePaddle/PaddleSpeech/pull/2003\r\n- deepspeech2 to onnx https://github.com/PaddlePaddle/PaddleSpeech/pull/2034\r\n    \r\n# Audio\r\n  - Refactor paddleaudio to paddlespeech.audio. https://github.com/PaddlePaddle/PaddleSpeech/pull/2007\r\n  - Add webdataset in paddlespeech.audio. https://github.com/PaddlePaddle/PaddleSpeech/pull/2062\r\n\r\n\r\n# Server\r\n  - Remove extra logs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2111 https://github.com/PaddlePaddle/PaddleSpeech/pull/2113 \r\n  - Change streaming tts servers' fs from 24k to models' fs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2121\r\n  - Fix bug in engine_warmup. https://github.com/PaddlePaddle/PaddleSpeech/pull/2171 by @Betterman-qs\r\n  - Replace default vocoder in seerver to mb_melgan. https://github.com/PaddlePaddle/PaddleSpeech/pull/2214\r\n  - Fix bug in streaming_asr_server with punctuation restoration. https://github.com/PaddlePaddle/PaddleSpeech/pull/2244\r\n\r\n\r\n# CLI\r\n  - Add paddlespeech.resource module. https://github.com/PaddlePaddle/PaddleSpeech/pull/1917\r\n  - Dynamic cli commands registration. https://github.com/PaddlePaddle/PaddleSpeech/pull/1959\r\n  - Fix unnecessary download. https://github.com/PaddlePaddle/PaddleSpeech/pull/2103\r\n  - Remove extra logs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2084 https://github.com/PaddlePaddle/PaddleSpeech/pull/2085 https://github.com/PaddlePaddle/PaddleSpeech/pull/2107 \r\n  - Add Chinese English mixed TTS CLI. https://github.com/PaddlePaddle/PaddleSpeech/pull/2249\r\n  - Add onnxruntime infer for CLI. https://github.com/PaddlePaddle/PaddleSpeech/pull/2222 \r\n    \r\n\r\n# Demo\r\n  - Add speech web demo. https://github.com/PaddlePaddle/PaddleSpeech/pull/2039 https://github.com/PaddlePaddle/PaddleSpeech/pull/2080\r\n  - Add kws cli and demo. https://github.com/PaddlePaddle/PaddleSpeech/pull/2063\r\n  - Use paddle web for streaming asr. https://github.com/PaddlePaddle/PaddleSpeech/pull/2105\r\n  - add custom asr script https://github.com/PaddlePaddle/PaddleSpeech/pull/1946\r\n \r\n\r\n# Doc\r\n  - Add API doc. https://github.com/PaddlePaddle/PaddleSpeech/pull/2075\r\n  - Format tts doc string for read the docs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2115\r\n\r\n# Others\r\n  - Fix CPU Dockerfile. https://github.com/PaddlePaddle/PaddleSpeech/pull/2172 by @BrightXiaoHan\r\n  - Add PaddleSpeech Dockerfile for hard mode of installation. https://github.com/PaddlePaddle/PaddleSpeech/pull/2127 by @buchongyu2 \r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-08-19T06:38:40+00:00",
        "updated_at": "2022-09-30T08:50:05+00:00",
        "closed_at": "2022-09-06T07:48:52+00:00",
        "comments_count": [],
        "labels": [
            "Documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2264,
        "title": "TTS 在 inference 的时候我想把save出来的音频音量调高，需要怎么处理啊？",
        "body": "如题",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "yt605155624",
        "created_at": "2022-08-18T03:43:36+00:00",
        "updated_at": "2022-08-22T03:15:43+00:00",
        "closed_at": "2022-08-22T03:15:43+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2266,
        "title": "aishell asr0示例无法运行",
        "body": "反馈：https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr0#stage-6-single-audio-file-inference\r\n\r\n![image](https://user-images.githubusercontent.com/30135920/185374879-6a53c518-7502-4cb1-9e0a-4718832f3154.png)\r\n\r\n问题：\r\ntest_wav.sh 是要接收四个参数 脚本运行的时候会检测传了几个参 这个里面只写了三个参数，直接运行这个截图里面的代码 好像没法运行成功",
        "state": "closed",
        "user": "iftaken",
        "closed_by": "yt605155624",
        "created_at": "2022-08-18T10:34:44+00:00",
        "updated_at": "2022-08-30T12:47:44+00:00",
        "closed_at": "2022-08-30T12:47:44+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2276,
        "title": "中英文混合 TTS 现在还是在内侧阶段？",
        "body": "我看到你们已经更新了中英文混合TTS，但是好像还是不能用啊？\r\npaddlespeech tts --am fastspeech2_mix --voc pwgan_ljspeech --lang mix  --input \"我们的声学模型使用了 Fast Speech Two, 声码器使用了 Parallel Wave GAN and Hifi GAN.\" --spk_id 1  --output mix_spk1.wav",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "yt605155624",
        "created_at": "2022-08-19T10:22:59+00:00",
        "updated_at": "2023-06-10T14:38:07+00:00",
        "closed_at": "2022-08-19T12:29:38+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "AI-Mart"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2278,
        "title": "paddlespeech如何训练自己的数据,选择使用不同框架的预训练模型测试效果",
        "body": "paddlespeech/exampeles/下有不同数据集所对应的不同处理方式以及不同的任务\r\n1.请问如果想实现语音识别应该选择哪个数据集下的预训练模型,如果想更换预训练模型应该如何操作\r\n2.是否有考虑在examples下设立一个专门为了训练自己数据的一个执行流程\r\n",
        "state": "closed",
        "user": "J-ZZ",
        "closed_by": "J-ZZ",
        "created_at": "2022-08-21T03:30:15+00:00",
        "updated_at": "2023-08-07T05:35:06+00:00",
        "closed_at": "2022-08-21T03:30:24+00:00",
        "comments_count": [
            "prcvoldermort"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2279,
        "title": "Text-to-Speech 提示 cannot load library libsndfile.dylib",
        "body": "\r\n** Environment (please complete the following information):**\r\n - OS: Mac M1\r\n - Python Version 3.8\r\n - PaddlePaddle Version 2.3.1\r\n\r\n\r\n克隆之后，安装失败，修改onnxruntime==1.12.1 和 conda install libsndfile 后安装成功，在使用Text-to-Speech报如下错误\r\n\r\n`paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n`\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/soundfile.py\", line 143, in <module>\r\n    _snd = _ffi.dlopen(_libname)\r\nOSError: cannot load library '/Users/chenchun/miniforge3/envs/paddle_env/bin/../lib/libsndfile.dylib': dlopen(/Users/chenchun/miniforge3/envs/paddle_env/bin/../lib/libsndfile.dylib, 0x0002): Library not loaded: '@rpath/libvorbis.0.4.9.dylib'\r\n  Referenced from: '/Users/chenchun/miniforge3/envs/paddle_env/lib/libsndfile.1.0.31.dylib'\r\n  Reason: tried: '/Users/chenchun/miniforge3/envs/paddle_env/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/chenchun/miniforge3/envs/paddle_env/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/chenchun/miniforge3/envs/paddle_env/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/chenchun/miniforge3/envs/paddle_env/bin/../lib/libvorbis.0.4.9.dylib' (no such file), '/usr/local/lib/libvorbis.0.4.9.dylib' (no such file), '/usr/lib/libvorbis.0.4.9.dylib' (no such file)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/paddlespeech/cli/base_commands.py\", line 19, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/soundfile.py\", line 162, in <module>\r\n    _snd = _ffi.dlopen(_os.path.join(\r\nOSError: cannot load library '/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/_soundfile_data/libsndfile.dylib': dlopen(/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/_soundfile_data/libsndfile.dylib, 0x0002): tried: '/Users/chenchun/miniforge3/envs/paddle_env/lib/python3.8/site-packages/_soundfile_data/libsndfile.dylib' (no such file)\r\n```",
        "state": "closed",
        "user": "clstech",
        "closed_by": "yt605155624",
        "created_at": "2022-08-21T13:18:00+00:00",
        "updated_at": "2022-08-21T15:41:56+00:00",
        "closed_at": "2022-08-21T15:41:56+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2280,
        "title": "我自己训练的TTS模型，但是语料里是没有英文的，现在在inference阶段想中英文混合的生成，是不是不行啊？",
        "body": "\r\n如题",
        "state": "closed",
        "user": "hackerxiaobai",
        "closed_by": "yt605155624",
        "created_at": "2022-08-22T04:18:07+00:00",
        "updated_at": "2022-08-23T09:44:17+00:00",
        "closed_at": "2022-08-23T09:44:17+00:00",
        "comments_count": [
            "yt605155624",
            "hackerxiaobai",
            "yt605155624",
            "hackerxiaobai"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2291
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2281,
        "title": "想在paddlespeech 中的asr的预训练模型的基础上训练自己的数据请问改如何做呢",
        "body": "想在aishell 的asr1中训练在预训练模型的基础上在训练自己的数据请问该怎么做呢",
        "state": "closed",
        "user": "J-ZZ",
        "closed_by": "yt605155624",
        "created_at": "2022-08-22T06:44:56+00:00",
        "updated_at": "2022-08-30T12:48:25+00:00",
        "closed_at": "2022-08-30T12:48:25+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2282,
        "title": "请问后面会支持多 speaker 的 vits 模型吗？",
        "body": "如题",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "sixyang",
        "created_at": "2022-08-22T07:41:53+00:00",
        "updated_at": "2022-08-22T07:50:51+00:00",
        "closed_at": "2022-08-22T07:50:51+00:00",
        "comments_count": [
            "yt605155624",
            "sixyang"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2285,
        "title": "这部分代码有问题，导致不能支持自定义模型文件",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/99977b2f7e13c2c5002e0be365ebbfd72cb688ab/paddlespeech/server/engine/asr/python/asr_engine.py#L70\r\n\r\n原因是asr_engine类的自定义参数有一个num_decoding_left_chunks，这里却没有，因此如果是自定义的模型文件就会导致参数错位的错误。",
        "state": "closed",
        "user": "lesliexufdu",
        "closed_by": "yt605155624",
        "created_at": "2022-08-22T08:02:24+00:00",
        "updated_at": "2022-09-06T07:30:12+00:00",
        "closed_at": "2022-09-06T07:30:12+00:00",
        "comments_count": [
            "zh794390558",
            "lesliexufdu",
            "zh794390558",
            "yt605155624"
        ],
        "labels": [
            "S2T",
            "Server"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2293
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2286,
        "title": "ernie-sat 运行报错",
        "body": "运行 run_gen_en_new.sh 出现如下问题：\r\n```\r\nroot@container-c6d2118d3c-6824b4ba:~/xx/PaddleSpeech-r1.1.0/examples/ernie_sat# ./run_gen_en_new.sh \r\n\r\nnew_str is  We are trying to establish a date.I enjoy my life, do you?\r\nTraceback (most recent call last):\r\n  File \"local/inference_new.py\", line 613, in <module>\r\n    data_dict = evaluate(\r\n  File \"local/inference_new.py\", line 599, in evaluate\r\n    results_dict = get_wav(\r\n  File \"local/inference_new.py\", line 51, in get_wav\r\n    wav_org, output_feat, old_span_bdy, new_span_bdy, fs, hop_length = get_mlm_output(\r\n  File \"local/inference_new.py\", line 548, in get_mlm_output\r\n    mlm_model, train_conf = load_model(model_name)\r\n  File \"local/inference_new.py\", line 81, in load_model\r\n    odim = conf.n_mels\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/yacs/config.py\", line 141, in __getattr__\r\n    raise AttributeError(name)\r\nAttributeError: n_mels\r\n```\r\n\r\n运行 run_gen_en.sh 显示缺失这个文件：\r\n```\r\nroot@container-c6d2118d3c-6824b4ba:~/xx/PaddleSpeech-r1.1.0/examples/ernie_sat# ./run_gen_en.sh\r\n\r\nnew_str is  We are trying to establish a date.I enjoy my life, do you?\r\nW0822 18:15:55.987232 38375 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.6, Runtime API Version: 11.2\r\nW0822 18:15:55.989818 38375 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\nsh: 1: tools/htk/HTKTools/HCopy: not found\r\nsh: 1: tools/htk/HTKTools/HVite: not found\r\nTraceback (most recent call last):\r\n  File \"local/inference.py\", line 600, in <module>\r\n    data_dict = evaluate(\r\n  File \"local/inference.py\", line 586, in evaluate\r\n    results_dict = get_wav(\r\n  File \"local/inference.py\", line 49, in get_wav\r\n    wav_org, output_feat, old_span_bdy, new_span_bdy, fs, hop_length = get_mlm_output(\r\n  File \"local/inference.py\", line 549, in get_mlm_output\r\n    return decode_with_model(\r\n  File \"local/inference.py\", line 491, in decode_with_model\r\n    batch, old_span_bdy, new_span_bdy = prep_feats(\r\n  File \"local/inference.py\", line 450, in prep_feats\r\n    wav, phns, mfa_start, mfa_end, old_span_bdy, new_span_bdy = prep_feats_with_dur(\r\n  File \"local/inference.py\", line 340, in prep_feats_with_dur\r\n    mfa_start, mfa_end, old_phns, new_phns, span_to_repl, span_to_add = get_phns_and_spans(\r\n  File \"local/inference.py\", line 168, in get_phns_and_spans\r\n    intervals, word2phns = alignment(wav_path, old_str)\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/examples/ernie_sat/local/align.py\", line 348, in alignment\r\n    with open(tmpbase + '.aligned', 'r') as fid:\r\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/root_38375.aligned'\r\n```\r\n\r\n请问如何解决，谢谢！",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "sixyang",
        "created_at": "2022-08-22T10:23:20+00:00",
        "updated_at": "2022-08-26T04:59:54+00:00",
        "closed_at": "2022-08-22T12:35:36+00:00",
        "comments_count": [
            "sixyang",
            "yt605155624",
            "sixyang",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2290,
        "title": "run PaddleSpeech  VectorExecutor on xpu device fail",
        "body": "-Description：\r\nEnvironment：\r\nARM, Kunlun R200\r\nOS: Linux localhost.localdomain 4.19.152-801.s2500.el8_1.aarch64 #1 SMP Fri Jun 24 11:57:19 CST 2022 aarch64 aarch64 aarch64 GNU/Linux\r\n\r\npython:3.7.4\r\npaddle:  compile and build on source  with xpu\r\n\r\n-Test code\r\nimport paddle\r\nfrom paddlespeech.cli.vector import VectorExecutor\r\nfrom scipy.spatial.distance import cosine\r\n\r\nvector_executor = VectorExecutor()\r\naudio_emb = vector_executor(\r\n    model='ecapatdnn_voxceleb12',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='./85236145389.wav',\r\n    device=paddle.get_device())\r\nprint('Audio embedding Result: \\n{}'.format(audio_emb))\r\n\r\ntest_emb = vector_executor(\r\n    model='ecapatdnn_voxceleb12',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='./123456789.wav',\r\n    device=paddle.get_device())\r\nprint('Test embedding Result: \\n{}'.format(test_emb))\r\n\r\nscore = vector_executor.get_embeddings_score(audio_emb, test_emb)\r\nprint(f\"Eembeddings Score: {score}\")\r\n\r\nscore = 1 - cosine(audio_emb, test_emb)\r\nprint(f\"Eembeddings Score2: {score}\")\r\n\r\n-Error:\r\n[INFO][BKCL][/home/users/yangyu22/baidu/xpu/bkcl/src/globals.cpp:52] set BKCL timeout to 600 seconds\r\n[INFO][BKCL][/home/users/yangyu22/baidu/xpu/bkcl/src/globals.cpp:53] set BKCL RING BUFFER SIZE to 1048576\r\nXPURT /usr/local/lib64/python3.7/site-packages/paddle/fluid/../libs/libxpurt.so loaded\r\nW0823 14:50:02.136422 61499 pybind.cc:2107] Cannot use get_all_custom_device_type because you have installedCPU/GPU version PaddlePaddle.\r\nIf you want to use get_all_custom_device_type, please try to install CustomDevice version PaddlePaddle by: pip install paddlepaddle-core\r\nW0823 14:50:03.240737 61499 xpu_context.cc:89] Please NOTE: xpu device: 0\r\nW0823 14:50:03.241063 61499 device_context.cc:310] Please NOTE: xpu device: 0\r\n/usr/local/lib64/python3.7/site-packages/scipy/fftpack/__init__.py:103: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\r\n  from numpy.dual import register_func\r\n/usr/local/lib64/python3.7/site-packages/scipy/sparse/sputils.py:16: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\r\n  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\r\n/usr/local/lib64/python3.7/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n/usr/local/lib64/python3.7/site-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from .mio5_utils import VarReader5\r\nTraceback (most recent call last):\r\n  File \"test_sv_xpu.py\", line 12, in <module>\r\n    device=paddle.get_device())\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/vector/infer.py\", line 257, in __call__\r\n    self.infer(model)\r\n  File \"<decorator-gen-441>\", line 2, in infer\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/vector/infer.py\", line 358, in infer\r\n    embedding = self.model.backbone(feats, lengths).squeeze().numpy()\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/vector/models/ecapa_tdnn.py\", line 511, in forward\r\n    x = self.mfa(x)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/vector/models/ecapa_tdnn.py\", line 208, in forward\r\n    return self.norm(self.activation(self.conv(x)))\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/vector/models/ecapa_tdnn.py\", line 177, in forward\r\n    x_n = self.norm(x)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/nn/layer/norm.py\", line 666, in forward\r\n    use_global_stats=self._use_global_stats)\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/nn/functional/norm.py\", line 207, in batch_norm\r\n    variance_out, *attrs)\r\nOSError: \r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)\r\n1   void paddle::imperative::Tracer::TraceOpImpl<paddle::imperative::VarBase>(std::string const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::framework::AttributeMap&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, paddle::framework::AttributeMap*, bool)\r\n2   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&, paddle::framework::AttributeMap const&)\r\n3   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<phi::XPUPlace, false, 0ul, paddle::operators::BatchNormXPUKernel<paddle::platform::XPUDeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n4   paddle::operators::BatchNormXPUKernel<paddle::platform::XPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n5   phi::enforce::EnforceNotMet::EnforceNotMet(phi::ErrorSummary const&, char const*, int)\r\n6   phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError: The batch_norm_infer XPU API return wrong value[1 xpu api invalid param]\r\n  [Hint: Expected r == xpu::Error_t::SUCCESS, but received r:1 != xpu::Error_t::SUCCESS:0.] (at /workspace/qiyuan/Paddle/paddle/fluid/operators/batch_norm_op_xpu.cc:121)\r\n  [operator < batch_norm > error]\r\n\r\n-misc\r\nrun normally with param device=\"cpu\".",
        "state": "closed",
        "user": "gyb4git",
        "closed_by": "yt605155624",
        "created_at": "2022-08-23T06:59:57+00:00",
        "updated_at": "2022-08-30T12:49:55+00:00",
        "closed_at": "2022-08-30T12:49:55+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Vector",
            "XPU"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2292,
        "title": "[TTS]g2pW 模块提升可读性",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/paddlespeech/t2s/frontend/g2pw\r\n\r\n1. 增加代码注释\r\n2. 增加 typehint\r\n\r\n欢迎开发者提交 pr ~\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "lym0302",
        "created_at": "2022-08-23T12:35:02+00:00",
        "updated_at": "2022-09-16T08:00:54+00:00",
        "closed_at": "2022-09-16T08:00:54+00:00",
        "comments_count": [],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2307,
        "title": "声纹识别安全性问题，能别录音欺骗",
        "body": "1、我生成了三个录音：tellong.wav作为原始录制的模版声音；teloriginal.wav是测试由真人说话生成的录音；recording.wav是播放真人录音形成的录音（模拟使用录音冒充他人声音）；\r\n2、我使用命令“paddlespeech vector --task score --input 'recording.wav tellong.wav'”，计算冒充人和模版声音的相似度，得到：0.5637418627738953；\r\n3、我使用命令“paddlespeech vector --task score --input 'teloriginal.wav tellong.wav'“，计算真人说话和模版声音的相似度，得到：\r\n0.5126219987869263\r\n4、使用录音的相似度反而更高。这样对于系统就无法识别伪装者了。\r\n请教这个过程有什么问题吗？",
        "state": "closed",
        "user": "zhaoyiyong",
        "closed_by": "yt605155624",
        "created_at": "2022-08-26T02:23:11+00:00",
        "updated_at": "2022-09-27T08:21:29+00:00",
        "closed_at": "2022-09-27T08:21:29+00:00",
        "comments_count": [
            "SmileGoat",
            "zhaoyiyong",
            "SmileGoat",
            "zhaoyiyong"
        ],
        "labels": [
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2296,
        "title": "[TTS]Use ECAPA TDNN to generate spk emb for  Voice Cloning",
        "body": null,
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-08-24T09:16:45+00:00",
        "updated_at": "2022-09-09T03:02:09+00:00",
        "closed_at": "2022-09-09T03:02:08+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2294,
        "title": "zh_en_tts 推理出错",
        "body": "报错如下所示：\r\n```\r\nacoustic model done!\r\nvoc done!\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 262, in <module>\r\n    main()\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 258, in main\r\n    evaluate(args)\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 106, in evaluate\r\n    frontend_dict = run_frontend(\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/paddlespeech/t2s/exps/syn_utils.py\", line 193, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"/root/autodl-tmp/PaddleSpeech-r1.1.0/paddlespeech/t2s/frontend/mix_frontend.py\", line 253, in get_input_ids\r\n    phones_seg.append(input_ids[\"phone_ids\"][0])\r\nUnboundLocalError: local variable 'input_ids' referenced before assignment\r\n```\r\n定位到问题如下所示：\r\n```\r\n242                 if lang == \"zh\":\r\n243                     input_ids = self.zh_frontend.get_input_ids(\r\n244                         content,\r\n245                         merge_sentences=True,\r\n246                         get_tone_ids=get_tone_ids,\r\n247                         to_tensor=to_tensor)\r\n248 \r\n249                 elif lang == \"en\":\r\n250                     input_ids = self.en_frontend.get_input_ids(\r\n251                         content, merge_sentences=True, to_tensor=to_tensor)\r\n252 \r\n253                 phones_seg.append(input_ids[\"phone_ids\"][0])\r\n254                 if add_sp:\r\n255                     phones_seg.append(self.sp_id_tensor)\r\n```\r\n这里应该是没有更新 lang 的 mix 选项~",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "sixyang",
        "created_at": "2022-08-23T14:39:49+00:00",
        "updated_at": "2022-08-25T11:42:07+00:00",
        "closed_at": "2022-08-24T06:46:23+00:00",
        "comments_count": [
            "sixyang",
            "yt605155624",
            "sixyang",
            "yt605155624",
            "sixyang",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2310,
        "title": "docker 安装 paddlespeech时，测试单卡没问题，多卡测试时报  Bus error (core dumped)",
        "body": "按照提供的dockerfile安装后， paddle.utils.run_check() 测试显卡时，出现以下报错：\r\n\r\n`Python 3.7.13 (default, Aug 25 2022, 17:42:24) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ... \r\nW0826 13:33:08.306574  4132 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.2, Runtime API Version: 11.2\r\nW0826 13:33:08.310814  4132 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\nPaddlePaddle works well on 1 GPU.\r\nW0826 13:33:10.297623  4132 parallel_executor.cc:642] Cannot enable P2P access from 0 to 1\r\nW0826 13:33:10.297649  4132 parallel_executor.cc:642] Cannot enable P2P access from 1 to 0\r\nlibibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.\r\nlibibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1\r\nlibibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Access to an undefined portion of a memory object` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1661491991 (unix time) try \"date -d @1661491991\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGBUS (@0x7f59a9dd8000) received by PID 4132 (TID 0x7f5b04cd0700) from PID 18446744072264450048 ***]\r\n\r\nBus error (core dumped)`\r\n\r\n并在当前目录下生成 core.* 文件\r\n请问该如何解决？谢谢。\r\n",
        "state": "closed",
        "user": "wangdabee",
        "closed_by": "yt605155624",
        "created_at": "2022-08-26T05:41:10+00:00",
        "updated_at": "2022-08-30T12:47:16+00:00",
        "closed_at": "2022-08-30T12:47:16+00:00",
        "comments_count": [
            "yt605155624",
            "wangdabee",
            "yt605155624",
            "yt605155624",
            "wangdabee",
            "yt605155624",
            "wangdabee"
        ],
        "labels": [
            "Installation",
            "Paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2319,
        "title": "向 aishell3 里添加自己的音频数据进行训练",
        "body": "如题，tts 中，我想给 aishell3 数据里额外添加一些数据来进行训练(采样率相同)，对于 am 和 voc，请问我除了需要 '文本内容' 和 '音频数据' 外，还需要其他东西吗？我看到其他 issue 里面说，直接给 aishell3 的数据里面加一个 speaker_id 即可，那除此之外的步骤能大概描述一下吗？非常感谢！",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "sixyang",
        "created_at": "2022-08-27T14:12:25+00:00",
        "updated_at": "2022-09-01T06:42:51+00:00",
        "closed_at": "2022-09-01T06:42:51+00:00",
        "comments_count": [
            "sixyang",
            "sixyang",
            "yt605155624",
            "sixyang",
            "sixyang",
            "lym0302",
            "sixyang",
            "sixyang",
            "sixyang",
            "yt605155624",
            "sixyang"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2322,
        "title": "streaming asr GPU利用率不到4%",
        "body": "本地用流式识别方式跑个长时间的音频文件，GPU利用率一直很低，怎么可以提升利用率啊？",
        "state": "closed",
        "user": "JaheimLee",
        "closed_by": "yt605155624",
        "created_at": "2022-08-29T09:53:20+00:00",
        "updated_at": "2022-09-27T08:16:15+00:00",
        "closed_at": "2022-09-27T08:16:15+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2320,
        "title": "请问原版vits的数据集&filelist如何转到paddlespeech训练？",
        "body": "原版vits的train_filelist.txt.cleaned似乎在这里无法使用，paddle文档提到要用MFA提取音素，但非中英文语种数据集很难做MFA处理，是否可以直接用适用于原版vits的train_filelist.txt.cleaned搭配数据集训练？\r\n\r\n即：\r\n音频文件|speakerID|国际音标\r\n\r\n`\r\nDUMMY2/p364/p364_240.wav|88|ɪt hɐd hˈæpənd tə hˌɪm.\r\n\r\nDUMMY2/p280/p280_148.wav|52|ɪt ɪz ˈoʊpən sˈiːzən ɑːnðɪ ˈoʊld fˈɜːm.\r\n\r\nDUMMY2/p231/p231_320.wav|50|haʊˈɛvɚ, hiː ɪz ɐ kˈoʊtʃ, ænd hiː ɹɪmˈeɪnz ɐ kˈoʊtʃ æt hˈɑːɹt.\r\n\r\nDUMMY2/p282/p282_129.wav|83|ɪt ɪz nˌɑːɾə jˈuːtˈɜːn.\r\n\r\nDUMMY2/p254/p254_015.wav|41|ðə ɡɹˈiːks jˈuːzd tʊ ɪmˈædʒɪn ðˌɐɾɪt wʌzɐ sˈaɪn fɹʌmðə ɡˈɑːdz tə foːɹtˈɛl wˈɔːɹ ɔːɹ hˈɛvi ɹˈeɪn.\r\n\r\nDUMMY2/p228/p228_285.wav|57|ðə sˈɔŋz ɑːɹ dʒˈʌst sˌoʊ ɡˈʊd.\r\n\r\nDUMMY2/p334/p334_307.wav|38|ɪf ðeɪ dˈoʊnt, ðeɪ kæn ɛkspˈɛkt ðɛɹ fˈʌndɪŋ təbi kˈʌt.\r\n\r\nDUMMY2/p287/p287_081.wav|77|aɪv nˈɛvɚ sˈiːn ˈɛnɪθˌɪŋ lˈaɪk ɪt.\r\n\r\nDUMMY2/p247/p247_083.wav|14|ɪt ɪz ɐ dʒˈɑːb kɹiːˈeɪʃən skˈiːm.\r\n\r\nDUMMY2/p264/p264_051.wav|65|wiː wɜː lˈiːdɪŋ baɪ tˈuː ɡˈoʊlz.\r\n\r\nDUMMY2/p335/p335_058.wav|49|lˈɛts sˈiː ðæt ˈɪnkɹiːs ˌoʊvɚ ðə jˈɪɹz.\r\n\r\nDUMMY2/p236/p236_225.wav|75|ðɛɹ ɪz nˈoʊ kwˈɪk fˈɪks.\r\n\r\nDUMMY2/p374/p374_353.wav|11|ænd ðæt bɹˈɪŋz ˌʌs tə ðə pˈɔɪnt.`\r\n\r\n是否可以通过这样的filelists&数据集训练？\r\n",
        "state": "closed",
        "user": "RyougiShiki-214",
        "closed_by": "yt605155624",
        "created_at": "2022-08-28T07:50:37+00:00",
        "updated_at": "2022-09-06T07:27:11+00:00",
        "closed_at": "2022-09-06T07:27:11+00:00",
        "comments_count": [
            "yt605155624",
            "RyougiShiki-214",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2325,
        "title": "💡 paddlespeech 提交代码须知",
        "body": "### Discussed in https://github.com/PaddlePaddle/PaddleSpeech/discussions/1326\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **yt605155624** January 12, 2022</sup>\r\n1. 写完代码之后可以用我们的 pre-commit 检查一下代码格式，注意只改自己修改的代码的格式即可，其他的代码有可能也被改了格式，不要 add 就好\r\n```\r\npip install pre-commit\r\npre-commit run --file 你修改的代码\r\n```\r\n2. 提交 commit 中增加必要信息跳过不必要的 CI\r\n- 提交 asr 相关代码\r\n```text\r\ngit commit -m \"xxxxxx, test=asr\"\r\n```\r\n- 提交 tts 相关代码\r\n```text\r\ngit commit -m \"xxxxxx, test=tts\"\r\n```\r\n- 仅修改文档\r\n```text\r\ngit commit -m \"xxxxxx, test=doc\"\r\n```\r\n注意：\r\n1. 虽然跳过了 CI，但是还要先排队排到才能跳过，所以非自己方向看到 pending 不要着急 🤣\r\n2. 在 `git commit --amend` 的时候才加 `test=xxx` 可能不太有效\r\n3. 一个 pr 多次提交 commit 注意每次都要加 `test=xxx`，因为每个 commit 都会触发 CI\r\n4. 删除 python 环境中已经安装好的的 paddlespeech，否则可能会影响 import paddlespeech 的顺序</div>\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-08-30T02:21:13+00:00",
        "updated_at": "2023-05-26T11:24:35+00:00",
        "closed_at": null,
        "comments_count": [
            "xyj44"
        ],
        "labels": [
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2326,
        "title": "下载的模型放到哪个路径 Where should I put models in path?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n服务器不能下载，手工下载了\r\nhttps://paddlespeech.bj.bcebos.com/s2t/wenetspeech/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz\r\n\r\n运行命令仍然会自动下载\r\n\r\n已经查了文档，尝试了下面类似的命令：\r\npaddlespeech asr --model conformer_wenetspeech --ckpt_path /opt/paddlespeech-models/asr1_conformer_wenetspeech_ckpt_0.1.1.model --lang zh --input zh.wav\r\n\r\n自己下载的模型应该放到哪个路径？或者命令行可以指定路径吗？\r\n\r\n谢谢，简单问题麻烦加到文档里。\r\n",
        "state": "closed",
        "user": "idreamerhx",
        "closed_by": "idreamerhx",
        "created_at": "2022-08-30T03:19:09+00:00",
        "updated_at": "2024-02-26T06:36:50+00:00",
        "closed_at": "2022-08-30T04:15:57+00:00",
        "comments_count": [
            "idreamerhx",
            "yt605155624",
            "idreamerhx",
            "idreamerhx",
            "idreamerhx",
            "Noahs007",
            "lijianxin520",
            "Samge0"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2329,
        "title": "[TTS][Server] application.yaml 指定 spk_id 无效",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/speech_server/conf/application.yaml\r\n修改里面的 spk_id 是无效的，需要在 client 端访问时指定 spk_id\r\n\r\n感兴趣的开发者可以提交 pr 删除 application.yaml 里的 spk_id，注意需要验证",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-08-30T11:18:16+00:00",
        "updated_at": "2022-09-14T08:11:15+00:00",
        "closed_at": "2022-09-14T08:11:15+00:00",
        "comments_count": [],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2328,
        "title": "声纹识别和所说的话内容应该不相关吧，但是测试却发现不是这样的",
        "body": "首先我录制了三段语音做为模版文件：\r\nzhao1.wav:说的是一句简短的中文；\r\nzhao2.wav:说的是0-9的数字；\r\nzhao3.wav：说的是另一句不同的中文；\r\n然后我按照模版文件内容再生成三个录音：\r\nfile1.wav和zhao1.wav,file2.wav和zhao2.wav,file3.wav和zhao3.wav的内容分别相同。\r\n然后两两做score，得出的结果是：\r\nzhao1.wav(file1.wav):0.7422892451286316;zhao1.wav(filé.wav):0.6398638486862183;zhao1(file3.wav):0.6861986517906189\r\nzhao2.wav(file1.wav):0.43911170959472656;zhao2.wav(filé.wav):0.7633090019226074;zhao2(file3.wav):0.4422371983528137\r\nzhao3.wav(file1.wav):0.6625332236289978;zhao3.wav(filé.wav):0.6106154322624207;zhao3(file3.wav):0.7869642972946167\r\n可以看到zhao1.wav(file1.wav)，zhao2.wav(filé.wav)，zhao3(file3.wav)得分最高。\r\n这如何解释呢？",
        "state": "closed",
        "user": "zhaoyiyong",
        "closed_by": "yt605155624",
        "created_at": "2022-08-30T10:32:14+00:00",
        "updated_at": "2022-09-27T08:18:40+00:00",
        "closed_at": "2022-09-27T08:18:40+00:00",
        "comments_count": [
            "SmileGoat",
            "zhaoyiyong",
            "SmileGoat"
        ],
        "labels": [
            "Question",
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2330,
        "title": "[TTS][Server] 支持中英文混合语音合成",
        "body": "1. engine_warmup.py 添加了 tts_engine.lang == 'mix'的分支，避免paddlespeech_server 启动失败。\r\n2. application.yaml中tts_python中am和lang改为 #2249 需要的模型参数\r\n3. client 端调用时传入 spk_id （推荐 174）\r\n\r\n感兴趣的开发者可以加一下 1 提个 pr\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-08-30T11:24:22+00:00",
        "updated_at": "2023-06-11T06:31:10+00:00",
        "closed_at": "2022-09-14T08:11:15+00:00",
        "comments_count": [
            "sixyang",
            "yt605155624",
            "wutl92",
            "yt605155624",
            "unparalleled-ysj",
            "yt605155624",
            "unparalleled-ysj",
            "lucasjinreal",
            "AI-Mart"
        ],
        "labels": [
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2338,
        "title": "Punctuation Restoration Pretrained Model",
        "body": "I have executed your \"Punctuation Restoration\" part It was executed successfully. But I can't able to find out the exact path where the pre-trained model \"ernie-1.0\" was saved in the local machine.  I have searched the model in this location \"${HOME}/.paddlenlp/models/ernie-1.0\" but didn't find any.  However, I have checked in another location also \"/home/kiit/.paddlespeech/models/ernie_linear_p7_wudao-punc-zh/ernie_linear_p7_wudao-punc-zh.tar/ckpt/model_state.pdparams\".   So .pdparms is a model or not?\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": "yt605155624",
        "created_at": "2022-08-31T15:23:13+00:00",
        "updated_at": "2022-09-22T06:29:27+00:00",
        "closed_at": "2022-09-22T06:29:27+00:00",
        "comments_count": [
            "yt605155624",
            "ghost",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2333,
        "title": "声纹识别的准确率问题，我们应用过程中只有71%，这是正常水平吗？",
        "body": "说明：\r\n1、我们分别采样了7个人的声音，每个人采样三段声音。将这些声音做为基础声音模版库；\r\n2、第一句:说的是一句简短的中文；第二句:说的是0-9的数字；第三句：说的是另一句不同的中文；\r\n3、然后将这21个声音分别从中找到最相似的声纹；\r\n4、实际验证结果是非常不理想，请帮忙指出我们流程哪里出错了，以及如何进行改进。我们是真的希望能够将其应用到实际业务场景中。\r\n5、总共21次比对，准确找到的：15；找错人的：6；准确率只有71%。\r\n    \r\n明细结果：每个语音声纹最相似的语音，以及score。（score 的计算方法：paddlespeech vector --task score --input ' ')\r\nzhao1.wav\r\n----------------\r\n   1 zhao3.wav  0.7540673613548279\r\nzhao2.wav\r\n----------------\r\n   1 zhao1.wav  0.657843291759491\r\nzhao3.wav\r\n----------------\r\n   1 zhao1.wav  0.7540673613548279\r\nliu1.wav\r\n----------------\r\n   1 liu3.wav   0.8753328919410706\r\nliu2.wav\r\n----------------\r\n   1 liu1.wav   0.5090296864509583\r\nliu3.wav\r\n----------------\r\n   1 liu1.wav   0.8753328919410706\r\nchen1.wav\r\n----------------\r\n   1 song1.wav  0.6430302858352661\r\nchen2.wav\r\n----------------\r\n   1 chen1.wav  0.601645827293396\r\nchen3.wav\r\n----------------\r\n   1 he3.wav    0.6503283381462097\r\nhuo1.wav\r\n----------------\r\n   1 huo3.wav   0.6945995092391968\r\nhuo2.wav\r\n----------------\r\n   1 huo1.wav   0.6929069757461548\r\nhuo3.wav\r\n----------------\r\n   1 huo1.wav   0.6945995092391968\r\nhe1.wav\r\n----------------\r\n   1 yu3.wav    0.657242476940155\r\nhe2.wav\r\n----------------\r\n   1 huo1.wav   0.5130718350410461\r\nhe3.wav\r\n----------------\r\n   1 he1.wav    0.6525829434394836\r\nsong1.wav\r\n----------------\r\n   1 song3.wav  0.7202233076095581\r\nsong2.wav\r\n----------------\r\n   1 song3.wav  0.7258925437927246\r\nsong3.wav\r\n----------------\r\n   1 song2.wav  0.7258925437927246\r\nyu1.wav\r\n----------------\r\n   1 yu3.wav    0.6325151920318604\r\nyu2.wav\r\n----------------\r\n   1 huo2.wav   0.659753143787384\r\nyu3.wav\r\n----------------\r\n   1 he1.wav    0.657242476940155",
        "state": "closed",
        "user": "zhaoyiyong",
        "closed_by": "yt605155624",
        "created_at": "2022-08-31T03:22:07+00:00",
        "updated_at": "2022-09-27T08:15:07+00:00",
        "closed_at": "2022-09-27T08:15:07+00:00",
        "comments_count": [
            "zhaoyiyong",
            "zh794390558",
            "zhaoyiyong",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2339,
        "title": "Pretrained Punctuation Restoration model",
        "body": "import paddle\r\nfrom paddlespeech.cli.text import TextExecutor\r\ntext_executor = TextExecutor()\r\nresult = text_executor(\r\n    text='今天的天气真不错啊你下午有空吗我想约你一起去吃饭',\r\n    task='punc',\r\n    lang='zh',\r\n    config=None,\r\n    ckpt_path=None,\r\n    punc_vocab=None,\r\n    device=paddle.get_device())\r\nprint('Text Result: \\n{}'.format(result))\r\n\r\nI have executed the above code without mentioning the path of pretrained model. But still it is executed how?",
        "state": "closed",
        "user": "ghost",
        "closed_by": "THUzyt21",
        "created_at": "2022-08-31T16:01:12+00:00",
        "updated_at": "2022-09-01T11:51:32+00:00",
        "closed_at": "2022-09-01T11:51:32+00:00",
        "comments_count": [
            "zh794390558",
            "THUzyt21"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2340,
        "title": "关于ppASR 语音识别开源项目",
        "body": "中文训练的可以正常运行，但是英文其他语言不能正常运行\r\n\r\n原因 中文连续写的语言种类   \r\n\r\n比如 数据集  {\"audio_filepath\": \"C:\\\\xunlei\\\\data_thchs30\\\\data\\\\A11_1.wav\", \"duration\": 8.84, \"text\": \"我爱中国\"}\r\n\r\n但是 英文和其他语言 {\"audio_filepath\": \"C:\\\\xunlei\\\\data_thchs30\\\\data\\\\A11_1.wav\", \"duration\": 8.84, \"text\": \"i love china\"}\r\n\r\ntext 字段有空格 训练的时候出错\r\n\r\n出错，错误信息: ''\r\n\r\n[2022-08-31 23:52:40.751534 ERROR  ] reader:__getitem__:49 - 数据: ['E:\\\\ai_ai\\\\PPASR-master\\\\dataset\\\\voice\\\\1.wav', 'bu dorini hëlila qaynatqan caqqan bol issiqida iciwalghin'] 出错，错误信息: '<unk>'\r\n\r\n line 43 in __getitem__\r\n",
        "state": "closed",
        "user": "xjsdn",
        "closed_by": "yt605155624",
        "created_at": "2022-08-31T16:25:58+00:00",
        "updated_at": "2022-09-01T02:03:08+00:00",
        "closed_at": "2022-09-01T02:03:08+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2341,
        "title": "train models with gpu memory error",
        "body": "## General Question\r\nI try to train a s2t model by paddlespeech on our owns machine with 7 gpus, but always report error about having no aviliable GPU memory, I have set batch_size ==8 and wav-id is sorted by name,  our dataset contains 300+  million audios totally.\r\nCan anyone help me solve this gpu memory issue please? THX",
        "state": "closed",
        "user": "Logan-SUN",
        "closed_by": "yt605155624",
        "created_at": "2022-09-01T06:34:37+00:00",
        "updated_at": "2022-09-27T08:15:00+00:00",
        "closed_at": "2022-09-27T08:15:00+00:00",
        "comments_count": [
            "Zth9730",
            "Logan-SUN",
            "Zth9730",
            "Logan-SUN",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2342,
        "title": "[TTS]PaddleSpeech Server RESTful API接口报错",
        "body": "/demos/speech_server按照文档启动服务，配置文件参照conf下的application.yaml.\r\n\r\n**Describe the bug**\r\n`GET  /paddlespeech/tts/streaming/samplerate` 报错。`paddlespeech/server/restful/tts_api ` 171行\r\n\r\n![image](https://user-images.githubusercontent.com/16896367/187853730-c6fef83a-b4b5-47fa-a576-d231537ed041.png)\r\n\r\nPaddleSpeech使用1.1.3版本\r\n![image](https://user-images.githubusercontent.com/16896367/187854734-40778942-6515-4495-965e-02d401ef822f.png)\r\n\r\n\r\n另外，`/paddlespeech/tts`这个接口是否可以考虑取消`save_path`参数，服务端的保存路径为啥要让客户端决定。\r\n",
        "state": "closed",
        "user": "byteszard",
        "closed_by": "byteszard",
        "created_at": "2022-09-01T07:30:52+00:00",
        "updated_at": "2022-09-08T14:42:24+00:00",
        "closed_at": "2022-09-08T14:42:24+00:00",
        "comments_count": [
            "lym0302",
            "byteszard",
            "lym0302"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2348
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2343,
        "title": "Punctuation Restoration Part",
        "body": "At the time of training model is generated but at the time of testing when we are given the path of trained model into the config file. \r\nHowever, it is only executing without giving the path of pretrained model how is it possible? ",
        "state": "closed",
        "user": "Banerjee1234",
        "closed_by": "yt605155624",
        "created_at": "2022-09-01T09:44:14+00:00",
        "updated_at": "2022-09-22T06:30:03+00:00",
        "closed_at": "2022-09-22T06:30:03+00:00",
        "comments_count": [
            "yt605155624",
            "THUzyt21"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2349
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2344,
        "title": "Punctuation Restoration ",
        "body": "After training i got \"snapshot_iter_1926.pdz\" model. But kindly tell me the steps how to use this model \"snapshot_iter_1926.pdz\" for testing.",
        "state": "closed",
        "user": "Anupro123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-01T15:37:37+00:00",
        "updated_at": "2022-09-22T06:29:42+00:00",
        "closed_at": "2022-09-22T06:29:42+00:00",
        "comments_count": [
            "yt605155624",
            "THUzyt21"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2345,
        "title": "Text Punctuation",
        "body": "When i have remove the \"ernie_v1_chn_base.pdparams\" file from this particuar catin \"paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\" then it doesnot generate the output. From this it is concluded that the trained model is not working it is dependent on  ernie_v1_chn_base.pdparams file only\r\nconf_path=. /PaddleSpeech/examples/iwslt2012/punc0/conf\r\ntrain_output_path=./PaddleSpeech/examples/iwslt2012/punc0/conf_path=/home/anasua/Desktop/PaddleSpeech/examples/iwslt2012/punc0/conf\r\ntrain_output_path=. /PaddleSpeech/examples/iwslt2012/punc0/\r\nckpt_name=./paddlespeech/models/ernie_linear_p7_wudao-punc-zh/1.0/ernie_linear_p7_wudao-punc-zh.tar/ckpt/snapshot_iter_1284.pdz\r\npaddlespeech text --input 因此我可以在互联网上出售我的烘烤食品和诸如此类的东西我\r\n们聚到了一起去探望那些家庭什么的除此以外还有一些为介绍奖项的人所设置的小平台和一\r\n些别的玩意环绕在舞台周围大家都很饿了无名树的果实看起来象熟了的芒果那么美味中国公\r\n民有信仰宗教的自由和不信仰宗教、宣传无神论的自由无信与迷信二者宁愿无信也不要迷信\r\n信必须智信把它描述为无神论的一种宗教信仰将会更恰当一些她本来是个无神论者可是现在\r\n她说自己的信仰改变了不伯莎如果你是个无神论者我不能再和你交往所以就因为你是个无神\r\n论者我就不能庆祝这些节日了散兵坑里不存在无神论者已与集体安全条约组织成员国谈论过\r\n这一问题他们的名气服饰和作品确实使我陶醉令我着迷卡弗夫妇抚养了孤儿乔治并让他随他\r\n们姓了卡弗\\n,\r\n",
        "state": "closed",
        "user": "DrMukherjee",
        "closed_by": "yt605155624",
        "created_at": "2022-09-02T11:44:39+00:00",
        "updated_at": "2022-09-22T06:29:35+00:00",
        "closed_at": "2022-09-22T06:29:35+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2346,
        "title": "关于ASR中加载KenLM 的问题",
        "body": "你好，请问下ASR里面说“ CTC beam search decoder”需要加载KenLM 模型，这个在哪加载啊，我好像没有找到加载的接口？\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/asr/quick_start.md\r\n![image](https://user-images.githubusercontent.com/27938135/188410805-44f4ad58-a10d-4a47-95bc-78b1171b57d1.png)\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-09-05T09:00:06+00:00",
        "updated_at": "2022-09-07T02:56:40+00:00",
        "closed_at": "2022-09-07T02:56:40+00:00",
        "comments_count": [
            "Zth9730",
            "Tian14267"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2358,
        "title": "Add Chinese doc and language switcher for demos of metaverse, style_fs2 and story_talker",
        "body": "Add Chinese doc and language switcher for demos of metaverse, style_fs2 and story_talker",
        "state": "closed",
        "user": "WongLaw",
        "closed_by": "WongLaw",
        "created_at": "2022-09-07T06:21:34+00:00",
        "updated_at": "2022-09-07T07:18:08+00:00",
        "closed_at": "2022-09-07T07:18:07+00:00",
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2350,
        "title": "ASR模型测试遇到这个问题：assert 'augmentation_config' in config",
        "body": "测试模型：PaddleSpeech/examples/aishell/asr0/里面的模型，测试报错：\r\n```\r\nFile \"/ultra/fffan/0_TTS/temp/PaddleSpeech/PaddleSpeech_asr/paddlespeech/s2t/io/collator.py\", line 230, in from_config\r\n    assert 'augmentation_config' in config\r\nAssertionError\r\n```\r\n查看代码发现，代码里有这几行：\r\n```\r\nassert 'augmentation_config' in config\r\nassert 'keep_transcription_text' in config\r\nassert 'mean_std_filepath' in config\r\nassert 'vocab_filepath' in config\r\nassert 'spectrum_type' in config\r\nassert 'n_fft' in config\r\n```\r\n这些配置在模型配置中并没有。请问这是啥情况",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-09-05T11:20:57+00:00",
        "updated_at": "2022-09-06T07:32:19+00:00",
        "closed_at": "2022-09-06T07:32:19+00:00",
        "comments_count": [
            "zh794390558",
            "Tian14267",
            "Tian14267",
            "zh794390558",
            "Tian14267",
            "zh794390558",
            "Tian14267",
            "Zth9730"
        ],
        "labels": [
            "Bug",
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2363,
        "title": "Added pre-install doc for G2P and TN modules and updated the dependency version of pypinyin",
        "body": "Added pre-install doc for G2P and TN modules and updated the dependency version of pypinyin",
        "state": "closed",
        "user": "WongLaw",
        "closed_by": "yt605155624",
        "created_at": "2022-09-08T12:15:02+00:00",
        "updated_at": "2022-09-08T12:34:15+00:00",
        "closed_at": "2022-09-08T12:34:15+00:00",
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2361,
        "title": "如何使用speedyspeech_csmsc声学模型替换默认的模型",
        "body": "你好，当我改变am参数时，报出错误KeyError: 'tone_ids'\r\ntts(text=\"因海而生，向海而荣。世界目光聚焦魅力鹭岛，金砖合作定格厦门时间。作为海上丝绸之路的战略支点城市，厦门成功举办金砖国家领导人第九次会晤，中国智慧、中国魅力再一次为世界带来温暖与力量。\", output='df_trans.wav', voc='pwgan_csmsc',am='speedyspeech_csmsc')\r\n```KeyError                                  Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp\\ipykernel_26856\\3154004847.py in <module>\r\n      1 tts(text=\"因海而生，向海而荣。世界目光聚焦魅力鹭岛，金砖合作定格厦门时间。作为海上丝绸之路的战略支点城市，厦门成功举办金砖国家领导人第九次会晤，中国智慧、中国魅力再一次为世界带来温暖与力量。\", output='df_trans.wav', \r\n----> 2     voc='pwgan_csmsc', am='speedyspeech_csmsc', tones_dict=r'C:\\Users\\80665\\.paddlespeech\\models\\speedyspeech_csmsc-zh\\1.0\\speedyspeech_csmsc_ckpt_0.2.0\\tones_id_map.txt')\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\cli\\utils.py in _warpper(self, *args, **kwargs)\r\n    326         except Exception:\r\n    327             pass\r\n--> 328         return executor_func(self, *args, **kwargs)\r\n    329 \r\n    330     return _warpper\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py in __call__(self, text, am, am_config, am_ckpt, am_stat, spk_id, phones_dict, tones_dict, speaker_dict, voc, voc_config, voc_ckpt, voc_stat, lang, device, output, use_onnx, cpu_threads, fs)\r\n    682                 lang=lang)\r\n    683 \r\n--> 684             self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n    685             res = self.postprocess(output=output)\r\n    686             return res\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\decorator.py in fun(*args, **kw)\r\n    230             if not kwsyntax:\r\n    231                 args, kw = fix(args, kw, sig)\r\n--> 232             return caller(func, *(extras + args), **kw)\r\n    233     fun.__name__ = func.__name__\r\n    234     fun.__doc__ = func.__doc__\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py in _decorate_function(func, *args, **kwargs)\r\n    352         def _decorate_function(func, *args, **kwargs):\r\n    353             with self:\r\n--> 354                 return func(*args, **kwargs)\r\n    355 \r\n    356         @decorator.decorator\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py in infer(self, text, lang, am, spk_id)\r\n    448             merge_sentences=merge_sentences,\r\n    449             get_tone_ids=get_tone_ids,\r\n--> 450             lang=lang)\r\n    451         self.frontend_time = time.time() - frontend_st\r\n    452         self.am_time = 0\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py in run_frontend(frontend, text, merge_sentences, get_tone_ids, lang, to_tensor)\r\n    184         phone_ids = input_ids[\"phone_ids\"]\r\n    185         if get_tone_ids:\r\n--> 186             tone_ids = input_ids[\"tone_ids\"]\r\n    187             outs.update({'tone_ids': tone_ids})\r\n    188     elif lang == 'en':\r\n\r\nKeyError: 'tone_ids'```",
        "state": "closed",
        "user": "swx-10",
        "closed_by": "yt605155624",
        "created_at": "2022-09-08T09:16:13+00:00",
        "updated_at": "2022-09-08T10:52:45+00:00",
        "closed_at": "2022-09-08T10:52:21+00:00",
        "comments_count": [
            "yt605155624",
            "swx-10"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2360,
        "title": "[S2T]aishell 训练时报错",
        "body": "装好环境之后，通过aishell/asr1里面的脚本run.sh进行训练, 在创建模型参数的时候提示config里面没有num_conv_layers这个选项，见图1\r\n<img width=\"990\" alt=\"image\" src=\"https://user-images.githubusercontent.com/36858700/189056068-c6c16c42-b50f-4206-b244-59c731ca952c.png\">\r\n**图1 报错信息**\r\n然后看了一下对应的run.sh里的config，见图2\r\n<img width=\"630\" alt=\"image\" src=\"https://user-images.githubusercontent.com/36858700/189056461-74946394-830b-4c36-9cb1-c0371b903298.png\">\r\n**图2 run.sh里面的配置参数**\r\n发现默认提供的conformer.ymal里面没有对应的num_conv_layer的参数，请问是我的配置文件选择出了问题吗？",
        "state": "closed",
        "user": "im73",
        "closed_by": "yt605155624",
        "created_at": "2022-09-08T07:06:00+00:00",
        "updated_at": "2022-09-27T08:22:48+00:00",
        "closed_at": "2022-09-27T08:22:48+00:00",
        "comments_count": [
            "Zth9730"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2366,
        "title": "KeyError: 'phone_ids'",
        "body": "Hello I got a Key Error (KeyError: 'phone_ids') while running `paddlespeech tts --input \"hello world\" --output output.wav`\r\n\r\nWindows 11\r\nfresh conda environment with python 3.7\r\nfollowed the instuctions as listed here for easy https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/install.md\r\n0 install errors\r\n \r\n",
        "state": "closed",
        "user": "Wemmons831",
        "closed_by": "yt605155624",
        "created_at": "2022-09-09T02:05:37+00:00",
        "updated_at": "2022-09-09T02:11:45+00:00",
        "closed_at": "2022-09-09T02:11:45+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2365,
        "title": "[S2T]如何不输入Y/N",
        "body": "**Describe the bug**\r\n1. 如图在命令行调用时，即使加了 -y 选项，还是要求我输入y/n\r\n2. 在使用python接口ASRExecutor时如何避免输入y/n\r\n\r\n**To Reproduce**\r\n`paddlespeech asr -y --input chunks\\03_human_1.wav \r\n`\r\n**Expected behavior**\r\n不用输入Y/N\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/21980268/189188783-217c10e2-4ee5-4d28-9eb7-86092f08c3aa.png)\r\n\r\n**Environment (please complete the following information):**\r\n - OS:win10\r\n - Python Version 3.7\r\n - PaddlePaddle Version [gpu          2.3.1.post112 ]\r\n - Model Version [paddlespeech              1.1.3 ]\r\n \r\n\r\n",
        "state": "closed",
        "user": "QuantumLiu",
        "closed_by": "QuantumLiu",
        "created_at": "2022-09-08T17:39:29+00:00",
        "updated_at": "2023-06-02T00:47:57+00:00",
        "closed_at": "2022-09-08T17:46:34+00:00",
        "comments_count": [
            "mxzgn"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2368,
        "title": "CSMSC/vits报错",
        "body": "使用预训练模型在运行examples/csmsc/vits的例子时出现下面这个报错，提示我找不到这个模块，但是我看代码里面有这个文件，请问是什么原因？\r\n![image](https://user-images.githubusercontent.com/62881198/189265764-12148087-7905-4466-a76c-3f978e6bd12d.png)\r\n\r\n",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "yt605155624",
        "created_at": "2022-09-09T03:29:38+00:00",
        "updated_at": "2022-09-09T06:31:38+00:00",
        "closed_at": "2022-09-09T06:31:38+00:00",
        "comments_count": [
            "yt605155624",
            "oyb1125",
            "yt605155624",
            "oyb1125"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2371,
        "title": "使用conformer_wenetspeech模型测试时发生Skip loading for encoder.embed.out.0.weight.",
        "body": "Hello，我在使用conformer_wenetspeech模型测试时发生Skip loading for encoder.embed.out.0.weight.的报错，\r\n猜测是某一层的权重维度与模型不匹配，研究了很长时间都没找到错误原因，请帮忙指点下啊，感谢。\r\n\r\n报错和日志如下，\r\n\r\n报错:\r\n```\r\n2022-09-09 16:17:06.267 | INFO     | paddlespeech.s2t.exps.u2.model:setup_model:263 - Setup model!\r\nD:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py:1492: UserWarning: Skip loading for encoder.embed.out.0.weight. encoder.embed.out.0.weight receives a shape [9728, 512], but the expected shape is [19968, 512].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n2022-09-09 16:17:07.686 | INFO     | paddlespeech.s2t.utils.checkpoint:load_parameters:117 - Rank 0: Restore model from configs/conformer_wenetspeech-zh-16k_1.0/wenetspeech.pdparams\r\n2022-09-09 16:17:07.689 | INFO     | paddlespeech.s2t.exps.u2.model:test:390 - Test Total Examples: 5\r\nD:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.int32, the right dtype will convert to paddle.int64\r\n  format(lhs_dtype, rhs_dtype, lhs_dtype))\r\nTraceback (most recent call last):\r\n  File \"d:/Code/PADDLE/PaddleSpeech-develop/demos/speech_recognition/eval.py\", line 72, in <module>\r\n2022-09-09 16:17:08.058    exp.run_test()\r\n |   File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\training\\trainer.py\", line 365, in run_test\r\nINFO        self.test()\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\utils\\mp_tools.py\", line 27, in wrapper\r\n |     paddlespeech.s2t.training.timerresult = func(*args, **kwargs)\r\n:  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n__exit__:    return caller(func, *(extras + args), **kw)\r\n44  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 354, in _decorate_function\r\n -     return func(*args, **kwargs)\r\nTest/Decode Done: 0:00:01.790112  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\exps\\u2\\model.py\", line 399, in test\r\n\r\n    metrics = self.compute_metrics(*batch, fout=fout)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\exps\\u2\\model.py\", line 353, in compute_metrics\r\n    simulate_streaming=decode_config.simulate_streaming)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 736, in decode\r\n    simulate_streaming=simulate_streaming)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 258, in recognize\r\n    simulate_streaming)  # (B, maxlen, encoder_dim)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 221, in _forward_encoder\r\n    num_decoding_left_chunks=num_decoding_left_chunks\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\modules\\encoder.py\", line 168, in forward\r\n    xs, pos_emb, masks = self.embed(xs, masks.astype(xs.dtype), offset=0)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddlespeech\\s2t\\modules\\subsampling.py\", line 143, in forward\r\n    x = self.out(x.transpose([0, 2, 1, 3]).reshape([b, t, c * f]))\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func\r\n__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 915, in _dygraph_call_func    \r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\layer\\common.py\", line 172, in forward\r\n    x=input, weight=self.weight, bias=self.bias, name=self.name)\r\n  File \"D:\\Program\\miniconda3\\envs\\paddle\\lib\\site-packages\\paddle\\nn\\functional\\common.py\", line 1542, in linear\r\n    False)\r\nValueError: (InvalidArgument) Input(Y) has error dim.Y'dims[0] must be equal to 9728But received Y'dims[0] is 19968\r\n  [Hint: Expected y_dims[y_ndim - 2] == K, but received y_dims[y_ndim - 2]:19968 != K:9728.] (at C:\\home\\workspace\\Paddle_release\\paddle/phi/kernels/impl/matmul_kernel_impl.h:315)\r\n  [operator < matmul_v2 > error]\r\n```\r\n\r\n日志:\r\n[py_eval.LAPTOP-CD0ILM5K.lichuan.2022-09-09_16-16-08_948182.log](https://github.com/PaddlePaddle/PaddleSpeech/files/9533844/py_eval.LAPTOP-CD0ILM5K.lichuan.2022-09-09_16-16-08_948182.log)\r\n",
        "state": "closed",
        "user": "lichuanqi",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-09T08:41:12+00:00",
        "updated_at": "2022-12-23T21:25:19+00:00",
        "closed_at": "2022-12-23T21:25:19+00:00",
        "comments_count": [
            "lichuanqi",
            "Zth9730",
            "lichuanqi",
            "zh794390558",
            "lichuanqi",
            "lichuanqi",
            "Zth9730",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2375,
        "title": "paddlespeech_server Failed to start server",
        "body": "## Version: \r\n* `Python                    3.9.6`\r\n* `paddlepaddle         2.3.2`\r\n* `paddlespeech         1.1.3`\r\n* `paddlespeech-feat  0.1.0`\r\n* `platform                  Window11`\r\n\r\n## Steps:\r\n1. `mkvirtualenv test_env`\r\n2. `pip install paddlepaddle paddlespeech`\r\n3. `!wget -P data https://paddlespeech.bj.bcebos.com/Parakeet/tools/nltk_data.tar.gz`\r\n4. `!tar zxvf data/nltk_data.tar.gz`\r\n5. `dir`\r\n```\r\n2021/07/01  16:28    <DIR>          nltk_data\r\n```\r\n6. `paddlespeech_server start --config_file ./config/paddle-speech.yaml`\r\n\r\n## Files: \r\n`./config/paddle-speech.yaml`\r\n``` yaml\r\nhost: 0.0.0.0\r\nport: 8090\r\nprotocol: \"http\"\r\nengine_list: [\"asr_python\", \"tts_python\", \"cls_python\", \"text_python\", \"vector_python\"]\r\n```\r\n\r\n##  Errors:\r\n``` log\r\n[2022-09-11 17:36:42,635] [    INFO] - start to init the engine\r\n[2022-09-11 17:36:42,635] [    INFO] - asr : python engine.\r\n[2022-09-11 17:36:43,117] [   ERROR] - Failed to start server.\r\n[2022-09-11 17:36:43,117] [   ERROR] - 'asr_python'\r\n```",
        "state": "closed",
        "user": "imohuan",
        "closed_by": "imohuan",
        "created_at": "2022-09-11T09:46:14+00:00",
        "updated_at": "2022-09-13T09:43:02+00:00",
        "closed_at": "2022-09-13T09:43:02+00:00",
        "comments_count": [
            "Zth9730",
            "imohuan"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2377,
        "title": "[TTS]英文开头的A发音错误怎么解决？",
        "body": "A: Among many others, I have taken Western Economics, International Trade, Marketing and Principles of Accounting. Here is my score book, from which you can learn much more about me.\r\n这句话开始的A发音错误，怎么解决呢？\r\n[20.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/9556348/20.zip)\r\n",
        "state": "closed",
        "user": "lawo123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-13T10:51:15+00:00",
        "updated_at": "2022-09-15T05:57:51+00:00",
        "closed_at": "2022-09-15T05:57:51+00:00",
        "comments_count": [
            "yt605155624",
            "lawo123",
            "yt605155624",
            "lawo123",
            "yt605155624",
            "lawo123",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2379,
        "title": "The one-time configuration of analysis predictor failed, which may be due to native predictor called first and its configurations taken effect.",
        "body": "(cuda1100) [qyh@localhost tts3]$ CUDA_VISIBLE_DEVICES='4' ./local/inference.sh ./train\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-09-14 11:08:36,615] [    INFO] - Already cached /home/qyh/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\nW0914 11:08:40.740352 1356097 analysis_predictor.cc:1118] The one-time configuration of analysis predictor failed, which may be due to native predictor called first and its configurations taken effect.\r\nTraceback (most recent call last):\r\n  File \"/resources/qyh/TTS/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../inference.py\", line 198, in <module>\r\n    main()\r\n  File \"/resources/qyh/TTS/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../inference.py\", line 127, in main\r\n    device=args.device)\r\n  File \"/resources/qyh/TTS/PaddleSpeech-develop/paddlespeech/t2s/exps/syn_utils.py\", line 366, in get_predictor\r\n    predictor = inference.create_predictor(config)\r\nRuntimeError: (NotFound) Cannot open file train/inference/fastspeech2_csmsc.pdmodel, please confirm whether the file is normal.\r\n  [Hint: Expected static_cast<bool>(fin.is_open()) == true, but received static_cast<bool>(fin.is_open()):0 != true:1.] (at /paddle/paddle/fluid/inference/api/analysis_predictor.cc:1500)\r\n\r\nI use PaddleSpeech-develop/examples/csmsc/tts3.\r\nHow can I solve this issure?",
        "state": "closed",
        "user": "michelleqyhqyh",
        "closed_by": "yt605155624",
        "created_at": "2022-09-14T03:23:52+00:00",
        "updated_at": "2022-09-14T09:35:48+00:00",
        "closed_at": "2022-09-14T06:07:21+00:00",
        "comments_count": [
            "yt605155624",
            "michelleqyhqyh",
            "michelleqyhqyh",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2384,
        "title": "No stack trace in paddle, may be caused by external reasons.",
        "body": "W0915 09:12:33.177958 2665464 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\nW0915 09:12:33.180549 2665465 gpu_resources.cc:91] device: 1, cuDNN Version: 8.2.\r\nrank: 1, pid: 2665465, parent_pid: 2665115\r\nmultiple speaker fastspeech2!\r\nspk_num: 283\r\nrank: 0, pid: 2665464, parent_pid: 2665115\r\nmultiple speaker fastspeech2!\r\nspk_num: 283\r\nsamplers done!\r\ndataloaders done!\r\nvocab_size: 388\r\nsamplers done!\r\ndataloaders done!\r\nvocab_size: 388\r\nmodel done!\r\noptimizer done!\r\nmodel done!\r\noptimizer done!\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1663204373 (unix time) try \"date -d @1663204373\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 2665465 (TID 0x7fe4bb7fb740) from PID 0 ***]\r\n\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\nNo stack trace in paddle, may be caused by external reasons.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1663204373 (unix time) try \"date -d @1663204373\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 2665464 (TID 0x7fc432385740) from PID 0 ***]\r\n\r\nTraceback (most recent call last):\r\n  File \"/resources/qyh/TTS/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/train.py\", line 212, in <module>\r\n    main()\r\n  File \"/resources/qyh/TTS/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/train.py\", line 206, in main\r\n    dist.spawn(train_sp, (args, config), nprocs=args.ngpu)\r\n  File \"/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/paddle/distributed/spawn.py\", line 565, in spawn\r\n    while not context.join():\r\n  File \"/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/paddle/distributed/spawn.py\", line 373, in join\r\n    self._throw_exception(error_index)\r\n  File \"/home/qyh/anaconda3/envs/cuda1100/lib/python3.7/site-packages/paddle/distributed/spawn.py\", line 381, in _throw_exception\r\n    (error_index, name))\r\nException: Process 0 terminated with signal SIGSEGV\r\n\r\n\r\nWhen I run in CUDA_VISIBLE_DEVICES='0,6,7' ./local/train.sh ./conf/default.yaml ./train in PaddleSpeech-develop/examples/zh_en_tts/tts3, I meet this error. Can you help me to fix it?",
        "state": "closed",
        "user": "michelleqyhqyh",
        "closed_by": "yt605155624",
        "created_at": "2022-09-15T01:20:02+00:00",
        "updated_at": "2022-09-15T05:57:01+00:00",
        "closed_at": "2022-09-15T05:57:01+00:00",
        "comments_count": [
            "yt605155624",
            "michelleqyhqyh"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2383,
        "title": "请问自己 finetune 的 tts 模型能够改变语速吗？",
        "body": "代码参考的 [finetune](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/other/tts_finetune/tts3/README.md) 这里，请问一下，这里的 fastspeech2 能调节语速吗？\r\nstylefs 里面需要 tts 的流程，但是我想直接给定一个音频，然后调节其语速，找了一圈，感觉其他的效果都不怎么好，请问有什么推荐吗？谢谢！",
        "state": "closed",
        "user": "sixyang",
        "closed_by": "yt605155624",
        "created_at": "2022-09-14T10:36:17+00:00",
        "updated_at": "2023-02-02T02:19:51+00:00",
        "closed_at": "2022-09-15T05:57:58+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2387,
        "title": "[S2T]Win10上运行程序无法获取结果",
        "body": "想在Win平台上离线运行\r\n\r\n用如下代码：\r\n> from paddlespeech.cli.asr.infer import ASRExecutor\r\n> asr = ASRExecutor()\r\n> result = asr(audio_file=\"k:\\\\test3.wav\")\r\n> print(result)\r\n\r\n或者命令行：\r\n`paddlespeech asr --lang zh --input test3.wav`\r\n\r\n最后没有print出任何结果。屏幕上唯一有的信息是\r\n`\r\n2022-09-15 01:05:46.604 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2022-09-15 01:05:46.749 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n`\r\ntest3.wav是一个单声道，16000采样率，不足5秒的纯人声音频，应该符合条件的",
        "state": "closed",
        "user": "dsyrock",
        "closed_by": "yt605155624",
        "created_at": "2022-09-15T06:50:06+00:00",
        "updated_at": "2023-05-18T09:28:37+00:00",
        "closed_at": "2022-09-16T01:12:03+00:00",
        "comments_count": [
            "yt605155624",
            "JiaXiao243",
            "dsyrock",
            "yt605155624",
            "dsyrock",
            "dsyrock",
            "yt605155624",
            "dsyrock",
            "yt605155624",
            "dsyrock",
            "younghuvee",
            "Chuyaoyuan"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2408
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2393,
        "title": "voxceleb2下载不了了？ ",
        "body": "--2022-09-16 17:21:19--  https://www.robots.ox.ac.uk/~vgg/data/voxceleb/data//vox2_dev_aac_partaa\r\nResolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\r\nConnecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\r\nHTTP request sent, awaiting response... 404 Not Found\r\n2022-09-16 17:21:19 ERROR 404: Not Found.",
        "state": "closed",
        "user": "JJun-Guo",
        "closed_by": "yt605155624",
        "created_at": "2022-09-16T09:25:49+00:00",
        "updated_at": "2022-09-28T03:09:09+00:00",
        "closed_at": "2022-09-19T02:22:45+00:00",
        "comments_count": [
            "yt605155624",
            "will-wiki"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2394,
        "title": "Error when running one part of the paddle code",
        "body": "AttributeError: module 'paddle' has no attribute 'tensor'\r\n![image](https://user-images.githubusercontent.com/18138003/190639761-28267b08-be22-4a2f-81a0-a3da58c6c7f7.png)\r\n",
        "state": "closed",
        "user": "ezekny",
        "closed_by": "ezekny",
        "created_at": "2022-09-16T12:34:45+00:00",
        "updated_at": "2022-09-18T16:45:45+00:00",
        "closed_at": "2022-09-18T16:45:45+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2407
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2401,
        "title": "TypeError: __init__() got an unexpected keyword argument 'negative_slope'",
        "body": "你好，\r\n我使用docker镜像想要运行这个Paddle Speech Demo [speech_web，依照这个readme文档](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_web)\r\n 在执行 `python main.py --port 8010` 时报错\r\n`grep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n[2022-09-17 02:56:35,240] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'source/model'.\r\n---    fused 0 elementwise_add with relu activation\r\n---    fused 0 elementwise_add with tanh activation\r\n---    fused 0 elementwise_add with leaky_relu activation\r\n---    fused 0 elementwise_add with swish activation\r\n---    fused 0 elementwise_add with hardswish activation\r\n---    fused 0 elementwise_add with sqrt activation\r\n---    fused 0 elementwise_add with abs activation\r\n---    fused 0 elementwise_add with clip activation\r\n---    fused 0 elementwise_add with gelu activation\r\n---    fused 0 elementwise_add with relu6 activation\r\n---    fused 0 elementwise_add with sigmoid activation\r\n---    fused 0 elementwise_sub with relu activation\r\n---    fused 0 elementwise_sub with tanh activation\r\n---    fused 0 elementwise_sub with leaky_relu activation\r\n---    fused 0 elementwise_sub with swish activation\r\n---    fused 0 elementwise_sub with hardswish activation\r\n---    fused 0 elementwise_sub with sqrt activation\r\n---    fused 0 elementwise_sub with abs activation\r\n---    fused 0 elementwise_sub with clip activation\r\n---    fused 0 elementwise_sub with gelu activation\r\n---    fused 0 elementwise_sub with relu6 activation\r\n---    fused 0 elementwise_sub with sigmoid activation\r\n---    fused 0 elementwise_mul with relu activation\r\n---    fused 0 elementwise_mul with tanh activation\r\n---    fused 0 elementwise_mul with leaky_relu activation\r\n---    fused 0 elementwise_mul with swish activation\r\n---    fused 0 elementwise_mul with hardswish activation\r\n---    fused 0 elementwise_mul with sqrt activation\r\n---    fused 0 elementwise_mul with abs activation\r\n---    fused 0 elementwise_mul with clip activation\r\n---    fused 0 elementwise_mul with gelu activation\r\n---    fused 0 elementwise_mul with relu6 activation\r\n---    fused 0 elementwise_mul with sigmoid activation\r\n[2022-09-17 02:56:36,889] [    INFO] - Already cached /root/.paddlenlp/models/plato-mini/plato-mini-vocab.txt[2022-09-17 02:56:36,890] [    INFO] - Already cached /root/.paddlenlp/models/plato-mini/plato-mini-spm.model[2022-09-17 02:56:36,948] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/plato-mini/tokenizer_config.json\r\n[2022-09-17 02:56:36,949] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/plato-mini/special_tokens_map.json\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 73, in <module>\r\n2022-09-17 02:56:48.298 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n    chatbot = Robot(asr_config, tts_config, asr_init_path, ie_model_path=ie_model_path)\r\n  File \"/home/PaddleSpeech/demos/speech_web/speech_server/src/robot.py\", line 15, in __init__\r\n    self.asr = ASR(config_path=asr_config)\r\n  File \"/home/PaddleSpeech/demos/speech_web/speech_server/src/SpeechBase/asr.py\", line 37, in __init__\r\n    self.engine.init(self.config)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 891, in init\r\n    if not self.init_model():\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 862, in init_model\r\n    am_predictor_conf=self.config.am_predictor_conf):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 836, in _init_from_path\r\n    self.init_model()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 756, in init_model\r\n    model = model_class.from_config(self.config)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 886, in from_config\r\n    model = cls(configs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 803, in __init__\r\n    configs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 849, in _init_from_config\r\n    input_dim, global_cmvn=global_cmvn, **configs['encoder_conf'])\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/modules/encoder.py\", line 472, in __init__\r\n    use_dynamic_left_chunk, max_len)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/modules/encoder.py\", line 130, in __init__\r\n    max_len=max_len), )\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/modules/subsampling.py\", line 114, in __init__\r\n    Conv2D(1, odim, 3, 2),\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/modules/align.py\", line 131, in __init__\r\n    weight_attr = paddle.ParamAttr(initializer=nn.initializer.KaimingUniform(fan_in=None, negative_slope=math.sqrt(5), nonlinearity='leaky_relu'))\r\nTypeError: __init__() got an unexpected keyword argument 'negative_slope'`\r\n环境 ： ubuntu 20.04 \r\ndocker image TAG develop-cpu-5d5888",
        "state": "closed",
        "user": "YuBYan",
        "closed_by": "yt605155624",
        "created_at": "2022-09-17T03:29:05+00:00",
        "updated_at": "2022-09-23T03:44:18+00:00",
        "closed_at": "2022-09-19T02:06:25+00:00",
        "comments_count": [
            "yt605155624",
            "YuBYan"
        ],
        "labels": [
            "Paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2402,
        "title": "关于用pyinstaller打包后找不到模型的问题",
        "body": "我在尝试用pyinstaller打包后运行遇到一个问题\r\n\r\n> Traceback (most recent call last):\r\n  File \"DSY_PaddleSpeech.py\", line 12, in <module>\r\n  File \"paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n  File \"paddlespeech\\cli\\asr\\infer.py\", line 473, in __call__\r\n  File \"paddlespeech\\cli\\asr\\infer.py\", line 146, in _init_from_path\r\n  File \"paddlespeech\\resource\\resource.py\", line 72, in set_task_model\r\nAssertionError: Can't find \"conformer_wenetspeech-zh-16k\" in resource. Model name must be one of []\r\n[26888] Failed to execute script 'DSY_PaddleSpeech' due to unhandled exception!\r\n\r\n首先确认在正常情况下，python里运行是成功的，只是打包后出错。从信息看是找不到上述的模型文件。我能找到这个文件位于c盘的路径下，但尝试过直接把他复制去打包的路径下，得到同样的出错信息。\r\n\r\n假如我打包的路径是 K:\\paddlespeech\\\r\n请问我要复制到哪个路径下，让程序能成功定位到模型文件？\r\n",
        "state": "closed",
        "user": "dsyrock",
        "closed_by": "yt605155624",
        "created_at": "2022-09-17T15:55:01+00:00",
        "updated_at": "2022-09-27T08:15:14+00:00",
        "closed_at": "2022-09-27T08:15:14+00:00",
        "comments_count": [
            "yt605155624",
            "dsyrock",
            "dsyrock",
            "dsyrock",
            "yt605155624",
            "SmileGoat",
            "dsyrock",
            "dsyrock",
            "dsyrock"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2404,
        "title": "input audio file from gdrive",
        "body": "Hello, thanks for the answer to the previous question paddlespeech. i have successfully installed the paddlespeech and now working according to the guide shown in the tutorial.\r\nMeanwhile, i will like to input my audio file from google drive and get the corresponding chinese and english text. Up till now i could not achieve that. Can somebody help out on this as well. Thanks.\r\nThe code is as follows:\r\n\r\n**from google.colab import drive\r\ndrive.mount('/content/gdrive/', force_remount=True)\r\nexpr_file = \"/content/gdrive/MyDrive/Colab Notebooks/paddle3/hs.wav\"**\r\n\r\ni used this to ensure the sample rate is inline with the model\r\n\r\n**_from scipy.io.wavfile import read as read_wav\r\nimport os\r\n#os.chdir('path') # change to the file directory\r\nsampling_rate, data=read_wav(expr_file) # enter your filename\r\nprint (sampling_rate)_**\r\n\r\nHowever, when i execute\r\n**!paddlespeech asr --lang zh --input expr_file**\r\ni received this error\r\n\r\n_/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-09-18 16:30:46,212] [   ERROR] - Please input the right audio file path_\r\n\r\nWhat am i missing from the code? ",
        "state": "closed",
        "user": "ezekny",
        "closed_by": "yt605155624",
        "created_at": "2022-09-18T16:50:33+00:00",
        "updated_at": "2022-09-20T12:00:55+00:00",
        "closed_at": "2022-09-20T12:00:55+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2409,
        "title": "Paddle2ONNX 转存失败",
        "body": "## General Question\r\n使用Paddle2ONNX对声纹模型转存，报错失败\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Failed to parse paddlepaddle model from read content.\r\n[Paddle2ONNX] Failed to load program of PaddlePaddle model.\r\n[Paddle2ONNX] Paddle model parsing failed.\r\n[Paddle2ONNX] Paddle model convert failed.\r\n",
        "state": "closed",
        "user": "JJun-Guo",
        "closed_by": "yt605155624",
        "created_at": "2022-09-19T09:13:27+00:00",
        "updated_at": "2022-09-27T08:31:51+00:00",
        "closed_at": "2022-09-27T08:31:51+00:00",
        "comments_count": [
            "yt605155624",
            "JJun-Guo",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "Vector"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2433
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2434
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2419,
        "title": "[TTS] 合成语音中的 \"1\" 念法为 yao, 再用语音识别出来为 \"幺\"",
        "body": "**Describe the bug**\r\n初始文本: `你好, 你的验证码是 991347`\r\n合成语音后再识别文本: `你好你的验证码是九九幺三四七`\r\n\r\n初始文本中的 `1` 被识别成了 `幺`\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. `paddlespeech tts --input \"你好，你的验证码是 991347\" --output demo.wav`\r\n2. `paddlespeech asr --lang zh --input demo.wav`\r\n\r\n**Expected behavior**\r\n期望初始文本中的 `1` 被识别成了 `一`\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Docker Ubuntu18 (构建于 ./docker/ubuntu18-cpu/Dockerfile)\r\n\r\n",
        "state": "closed",
        "user": "monkeydp",
        "closed_by": "yt605155624",
        "created_at": "2022-09-20T08:07:28+00:00",
        "updated_at": "2022-09-20T12:00:45+00:00",
        "closed_at": "2022-09-20T12:00:45+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2410,
        "title": "How to adjust the speed of speech？",
        "body": "I used PaddleSpeech-develop/examples/zh_en_tts/tts3 to train the model. But when I test, I think the speed of speech is a little bit fast. Is there any method which can adjust the speed of speech？",
        "state": "closed",
        "user": "michelleqyhqyh",
        "closed_by": "yt605155624",
        "created_at": "2022-09-19T09:14:03+00:00",
        "updated_at": "2023-04-29T12:04:31+00:00",
        "closed_at": "2022-09-20T07:12:23+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "michelleqyhqyh",
            "michelleqyhqyh",
            "peiqianggao",
            "futureflsl"
        ],
        "labels": [
            "Question",
            "T2S",
            "duplicate"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2413,
        "title": "[TTS]Voc流式推理拼接时出现了高频噪音",
        "body": "更新结论:\r\nvoc流式合成中,对每一个sub_wav进行change_speed()可能存在问题.\r\n当速度 <1的时候,最终concat出来的声音会有噪音断层,解决方案是把所有生成的新sub_wav最后出席的所有0值删除.\r\n当速度 >1的时候,最终concat出来的声音会有噪音包络,尚未解决\r\n\r\n---------------\r\n更新1:\r\naudio_process.py文件\r\nchange_speed() 这个函数 转换了pcm就会有噪音\r\n---------------------------------------------\r\n\r\n我们在做流式推理的时候, 在voc流式合成 block1 block2后 . \r\n对b1 b2进行连接之后播放出来的声音会有一点高频的噪音. \r\n我们觉得是 b1 b2 的交接点不一致造成的 .  \r\n观察了下pad和depad的代码好像也没找到问题.\r\n但是通过频谱图的观察有两个观点:\r\n1、频谱图有的拼接处有明显的一条竖线\r\n2、竖线所在频谱图对应的时域图表现为振幅为0\r\n麻烦看看呢~\r\n\r\n---------\r\n用的fastspeech2和hifigan\r\nblock size是36, padsize是20\r\n\r\n![image](https://user-images.githubusercontent.com/57442574/191147616-3e272c27-41d0-4d69-a84b-912c96adbd85.png)\r\n![image](https://user-images.githubusercontent.com/57442574/191147783-1beffc43-4ace-48a4-b549-74ce7013f65e.png)\r\n",
        "state": "closed",
        "user": "SoloPro-Git",
        "closed_by": "SoloPro-Git",
        "created_at": "2022-09-20T01:33:39+00:00",
        "updated_at": "2024-12-03T10:01:55+00:00",
        "closed_at": "2022-09-21T06:02:45+00:00",
        "comments_count": [
            "yt605155624",
            "liwei0826",
            "Ankh-L"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2424,
        "title": "如何使用Python部署自己的模型",
        "body": "## General Question\r\nHello，我微调asr模型后，部署自己微调后模型报错，一直未能解决，请帮忙指点下啊，感谢。\r\n使用Python的进行调用，\r\n\r\n调用如下\r\ntext = asr_executor(\r\n        output_name,\r\n        model='conformer_wenetspeech-zh-16k',\r\n        config='/home/formal_ai/www/PaddleSpeech-develop/examples/aishell/asr1/conf/conformer1.yaml',\r\n        ckpt_path='/home/formal_ai/www/PaddleSpeech-develop/examples/aishell/asr1/exp/conformer/checkpoints/5', \r\n        device=paddle.get_device())\r\n\r\n报错:\r\n[2022-09-20 15:15:59,625] [    INFO] - checking the audio file format......\r\n[2022-09-20 15:15:59,628] [    INFO] - The sample rate is 16000\r\n[2022-09-20 15:15:59,628] [    INFO] - The audio file format is right\r\n[2022-09-20 15:15:59,628] [    INFO] - start to init the model\r\n[2022-09-20 15:15:59,628] [    INFO] - /home/formal_ai/www/PaddleSpeech-develop/examples/aishell/asr1/conf/conformer.yaml\r\n[2022-09-20 15:15:59,629] [    INFO] - /home/formal_ai/www/PaddleSpeech-develop/examples/aishell/asr1/exp/conformer/checkpoints/5.pdparams\r\n[2022-09-20 15:15:59] [INFO] [_internal.py:224] 127.0.0.1 - - [20/Sep/2022 15:15:59] \"POST /upload1 HTTP/1.1\" 500 -\r\nTraceback (most recent call last):\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 2091, in __call__\r\n    return self.wsgi_app(environ, start_response)\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 2076, in wsgi_app\r\n    response = self.handle_exception(e)\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 2073, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 1519, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 1517, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/flask/app.py\", line 1503, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\r\n  File \"/home/formal_ai/www/PaddleSpeech-develop/asr11.py\", line 32, in upload_wav\r\n    device=paddle.get_device())\r\n  File \"/home/formal_ai/www/PaddleSpeech-develop/paddlespeech/cli/utils.py\", line 346, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/formal_ai/www/PaddleSpeech-develop/paddlespeech/cli/asr/infer.py\", line 469, in __call__\r\n    ckpt_path)\r\n  File \"/home/formal_ai/www/PaddleSpeech-develop/paddlespeech/cli/asr/infer.py\", line 189, in _init_from_path\r\n    self.config.decode.decoding_method = decode_method\r\n  File \"/home/anaconda3/envs/py37_pp/lib/python3.7/site-packages/yacs/config.py\", line 141, in __getattr__\r\n    raise AttributeError(name)\r\nAttributeError: decode\r\n\r\n",
        "state": "closed",
        "user": "zyw11270106",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-20T09:52:13+00:00",
        "updated_at": "2022-12-23T21:25:18+00:00",
        "closed_at": "2022-12-23T21:25:18+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "zyw11270106",
            "zyw11270106",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2428,
        "title": "Problems with the pronunciation of abbreviated characters",
        "body": "I used PaddleSpeech-develop/examples/zh_en_tts/tts3 to train the model. But when I test, I found when I input a sentence \"AI 智能\" or ”SCI文献“，it will pronunce a continuous sound but not one by one word （like A. I., or S. C. I.）. How can I solve this problem?",
        "state": "closed",
        "user": "michelleqyhqyh",
        "closed_by": "yt605155624",
        "created_at": "2022-09-21T07:50:44+00:00",
        "updated_at": "2022-09-22T06:04:20+00:00",
        "closed_at": "2022-09-22T06:04:20+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2431,
        "title": "windows10 Pycharm运行报错",
        "body": "```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\npath = 'sound/1.wav'\r\nres = asr(audio_file=path, sample_rate=8000)\r\nprint(res)\r\n```\r\n这里audio_file=path高亮，查看代码发现没有此变量，要改成什么？\r\n\r\n报错信息：\r\n`C:\\Users\\usr\\.conda\\envs\\py38\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"C:/Users/usr/PycharmProjects/SpeechRecog/SpeRecog.py\", line 6, in <module>\r\n    res = asr(audio_file=path, sample_rate=8000)\r\n  File \"C:\\Users\\usr\\.conda\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"C:\\Users\\usr\\.conda\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 473, in __call__\r\n    self._init_from_path(model, lang, sample_rate, config, decode_method,\r\n  File \"C:\\Users\\usr\\.conda\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 146, in _init_from_path\r\n    self.task_resource.set_task_model(tag, version=None)\r\n  File \"C:\\Users\\usr\\.conda\\envs\\py38\\lib\\site-packages\\paddlespeech\\resource\\resource.py\", line 72, in set_task_model\r\n    assert model_tag in self.pretrained_models, \\\r\nAssertionError: Can't find \"conformer_wenetspeech-zh-8k\" in resource. Model name must be one of ['conformer_wenetspeech-zh-16k', 'conformer_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_aishell-zh-16k', 'conformer_online_aishell-zh-16k', 'transformer_librispeech-en-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2offline_aishell-zh-16k', 'deepspeech2online_aishell-zh-16k', 'deepspeech2offline_librispeech-en-16k']\r\n\r\n查看生成的日志：\r\n`2022-09-21 18:04:50.441 | DEBUG    | paddlespeech.s2t:<module>:42 - register user softmax to paddle, remove this when fixed!\r\n2022-09-21 18:04:50.441 | DEBUG    | paddlespeech.s2t:<module>:46 - register user log_softmax to paddle, remove this when fixed!\r\n2022-09-21 18:04:50.441 | DEBUG    | paddlespeech.s2t:<module>:50 - register user sigmoid to paddle, remove this when fixed!\r\n2022-09-21 18:04:50.441 | DEBUG    | paddlespeech.s2t:<module>:54 - register user log_sigmoid to paddle, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:58 - register user relu to paddle, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:67 - override cat of paddle if exists or register, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:89 - override long of paddle.Tensor if exists or register, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:111 - override new_full of paddle.Tensor if exists or register, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:122 - override contiguous of paddle.Tensor if exists or register, remove this when fixed!\r\n2022-09-21 18:04:50.442 | DEBUG    | paddlespeech.s2t:<module>:134 - register user view to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.443 | DEBUG    | paddlespeech.s2t:<module>:144 - register user view_as to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.443 | DEBUG    | paddlespeech.s2t:<module>:181 - register user masked_fill to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.443 | DEBUG    | paddlespeech.s2t:<module>:200 - register user masked_fill_ to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.443 | DEBUG    | paddlespeech.s2t:<module>:224 - register user repeat to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.445 | DEBUG    | paddlespeech.s2t:<module>:230 - register user softmax to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.445 | DEBUG    | paddlespeech.s2t:<module>:235 - register user sigmoid to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.445 | DEBUG    | paddlespeech.s2t:<module>:240 - register user relu to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.445 | DEBUG    | paddlespeech.s2t:<module>:249 - register user type_as to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.446 | DEBUG    | paddlespeech.s2t:<module>:266 - register user to to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.446 | DEBUG    | paddlespeech.s2t:<module>:276 - register user float to paddle.Tensor, remove this when fixed!\r\n2022-09-21 18:04:50.446 | DEBUG    | paddlespeech.s2t:<module>:287 - register user int to paddle.Tensor, remove this when fixed!`\r\n`\r\n是没有模型的问题吗？模型是要在哪里下，保存在哪里？",
        "state": "closed",
        "user": "starflag",
        "closed_by": "yt605155624",
        "created_at": "2022-09-21T10:56:17+00:00",
        "updated_at": "2022-09-22T06:04:12+00:00",
        "closed_at": "2022-09-22T06:04:12+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2435,
        "title": "希望ASRExecutor有Timestamp功能",
        "body": "`👏🏻 2022.05.06: PaddleSpeech Streaming Server is available for Streaming ASR with Punctuation Restoration and Token Timestamp and Text-to-Speech.`\r\n请问为什么本地的ASRExecutor识别没有Timestamp功能？未来是否会添加，谢谢！",
        "state": "open",
        "user": "QuantumLiu",
        "closed_by": null,
        "created_at": "2022-09-22T05:42:15+00:00",
        "updated_at": "2023-04-19T06:02:28+00:00",
        "closed_at": null,
        "comments_count": [
            "dengzhenhai",
            "SmileGoat",
            "yt605155624",
            "QuantumLiu",
            "stale[bot]",
            "stale[bot]",
            "1547481339"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2436,
        "title": "rir_noise MD5 报错！！！",
        "body": "MD5 Chesksum ./PaddleSpeech-develop/dataset/rir_noise/rirs_noises.zip ...\r\nTraceback (most recent call last):\r\n  File \"./PaddleSpeech-develop/dataset/rir_noise/rir_noise.py\", line 117, in <module>\r\n    main()\r\n  File \"./PaddleSpeech-develop/dataset/rir_noise/rir_noise.py\", line 113, in main\r\n    manifest_path=args.manifest_prefix)\r\n  File \"./PaddleSpeech-develop/dataset/rir_noise/rir_noise.py\", line 97, in prepare_dataset\r\n    filepath = download(url, md5sum, target_dir)\r\n  File \"./PaddleSpeech-develop/utils/utility.py\", line 146, in download\r\n    raise RuntimeError(\"MD5 checksum failed.\")\r\nRuntimeError: MD5 checksum failed.\r\nPrepare rir_noise failed. Terminated.\r\n",
        "state": "closed",
        "user": "JJun-Guo",
        "closed_by": "JJun-Guo",
        "created_at": "2022-09-22T06:10:19+00:00",
        "updated_at": "2022-09-22T06:19:30+00:00",
        "closed_at": "2022-09-22T06:15:36+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2437,
        "title": "❣️ [TTS] MFA 报错 No such file or directory: \"xx/xx/xx/train/mfcc/raw_mfcc.0.scp\"",
        "body": "\r\n一般是因为系统环境问题，可能是某个系统库没有安装，可以查看 `--temp_directory` 路径下的 logging 文件, 如果使用 MFA 时未指定 `--temp_directory`, 默认路径在 `${HOME}/Documents/MFA`\r\n![1621663831963_ pic](https://user-images.githubusercontent.com/24568452/191685777-82750ffa-30de-459a-bc6e-d9d349fd484d.jpg)\r\n\r\n![8861663830996_ pic](https://user-images.githubusercontent.com/24568452/191686894-51e4b373-d22e-4598-a7ff-921e2a615f91.jpg)\r\n\r\n\r\n\r\n![8841663830901_ pic](https://user-images.githubusercontent.com/24568452/191686853-75fb1192-08c1-45f9-9b6b-1125f7217764.jpg)\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-09-22T07:38:46+00:00",
        "updated_at": "2023-05-10T03:45:16+00:00",
        "closed_at": null,
        "comments_count": [
            "tianruoyou2022",
            "david-95",
            "CnYiXiaoNaiHe",
            "henryhtm",
            "haoxue1215",
            "haoxue1215",
            "JiadiLee",
            "hhuyzp"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2438,
        "title": "微调TTS时，报错FileNotFoundError: [Errno 2] No such file or directory: '/home/ti/Documents/MFA/newdir/train/mfcc/raw_mfcc.0.scp'",
        "body": "Creating dictionary information...\r\nSetting up training data...\r\nCalculating MFCCs...\r\nTraceback (most recent call last):\r\n  File \"aligner/command_line/align.py\", line 186, in <module>\r\n  File \"aligner/command_line/align.py\", line 142, in validate_args\r\n  File \"aligner/command_line/align.py\", line 94, in align_corpus\r\n  File \"aligner/aligner/pretrained.py\", line 74, in __init__\r\n  File \"aligner/aligner/pretrained.py\", line 122, in setup\r\n  File \"aligner/aligner/base.py\", line 89, in setup\r\n  File \"aligner/corpus.py\", line 979, in initialize_corpus\r\n  File \"aligner/corpus.py\", line 852, in create_mfccs\r\n  File \"aligner/corpus.py\", line 863, in _combine_feats\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/ti/Documents/MFA/newdir/train/mfcc/raw_mfcc.0.scp'\r\n我是按照PaddleSpeech/examples/other/tts_finetune/tts3的步骤来的，就是这里报错，不知道为什么，不知道怎么解决",
        "state": "closed",
        "user": "kq-cheng",
        "closed_by": "kq-cheng",
        "created_at": "2022-09-22T08:20:19+00:00",
        "updated_at": "2022-09-23T03:22:48+00:00",
        "closed_at": "2022-09-23T03:22:48+00:00",
        "comments_count": [
            "yt605155624",
            "kq-cheng"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2441,
        "title": "依赖",
        "body": "![bcfae547bf3622ba43a544ec4ae3d1f](https://user-images.githubusercontent.com/108966996/191884046-72dbf042-029d-4f75-846e-4757b7ee3fa1.jpg)\r\n![微信图片_20220923105440](https://user-images.githubusercontent.com/108966996/191884103-6d6cde41-b410-49ae-8c99-d52657e6fe6f.jpg)\r\n为什么运行了setup.py之后还是没有相关的库呀",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-23T02:55:31+00:00",
        "updated_at": "2022-09-26T03:02:07+00:00",
        "closed_at": "2022-09-26T03:02:07+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2439,
        "title": "language questions",
        "body": "可以有全中文的文档吗，英语真的看不懂\r\n",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-22T12:00:24+00:00",
        "updated_at": "2022-09-26T05:29:18+00:00",
        "closed_at": "2022-09-26T05:29:18+00:00",
        "comments_count": [
            "yaleimeng"
        ],
        "labels": [
            "Documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2440,
        "title": "with s-norm or without s-norm ???",
        "body": "请问声纹识别复现的是without s-norm的model吗？with s-norm的代码没有吗？\r\n",
        "state": "closed",
        "user": "JJun-Guo",
        "closed_by": "yt605155624",
        "created_at": "2022-09-23T02:34:22+00:00",
        "updated_at": "2023-03-21T08:01:42+00:00",
        "closed_at": "2023-03-21T08:01:42+00:00",
        "comments_count": [
            "SmileGoat",
            "JJun-Guo",
            "stale[bot]",
            "JJun-Guo",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2442,
        "title": "TTS Finetune / TTS3对multi-speaker数据进行微调",
        "body": "您好，我在使用`examples/other/tts_finetune/tts3`(commit_id 863609) finetune自己的数据集时遇到了问题：\r\n\r\nexample只提供了在csmsc_mini single-speaker上finetune的tutorial，但是对于tune on multi speaker dataset仍然是不可用的\r\n\r\n为了finetune on multi speaker dataset，我尝试通过MFA align来获取音素的duration，但使用`./tools/montreal-forced-aligner/bin/mfa_align`时会有一部分文件无法生成TextGrid结果，查看log显示：\r\n```\r\nWARNING (gmm-align-compiled[5.4.247~1-2148]:main():gmm-align-compiled.cc:103) No features for utterance 000xxx\r\n```\r\n\r\n而后，我尝试使用latest MFA (from conda)与repo中提供的字典和AM提取音素duration，可正常生成结果，但是在训练一些step后会产生维度匹配错误，我想咨询下我的处理流程是否有问题？为什么在训练过程中会有bug？如果想保证训练过程的正常进行，应如何修改？\r\n\r\n```\r\nmultiple speaker fastspeech2!\r\nspk_num: 174\r\nsamplers done!\r\ndataloaders done!\r\nvocab_size: 306\r\nW0923 19:56:10.536396 43391 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.1\r\nW0923 19:56:10.542753 43391 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nmodel done!\r\noptimizer done!\r\n/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\nINFO 2022-09-23 19:56:16,280 trainer.py:167]  iter: 96401/1200, Rank: 0, l1_loss: 1.856183, duration_loss: 0.316927, pitch_loss: 0.978752, energy_loss: 6.169956, loss: 9.321817, avg_reader_cost: 0.00075 sec, avg_batch_cost: 2.49490 sec, avg_samples: 32, avg_ips: 12.82615 sequences/sec\r\nINFO 2022-09-23 19:56:16,432 trainer.py:167]  iter: 96402/1200, Rank: 0, l1_loss: 1.837183, duration_loss: 0.331705, pitch_loss: 2.075590, energy_loss: 5.443483, loss: 9.687962, avg_reader_cost: 0.00023 sec, avg_batch_cost: 0.15020 sec, avg_samples: 32, avg_ips: 213.05078 sequences/sec\r\nINFO 2022-09-23 19:56:16,797 trainer.py:167]  iter: 96403/1200, Rank: 0, l1_loss: 1.924996, duration_loss: 0.372018, pitch_loss: 1.120224, energy_loss: 5.148971, loss: 8.566210, avg_reader_cost: 0.00028 sec, avg_batch_cost: 0.36255 sec, avg_samples: 32, avg_ips: 88.26467 sequences/sec\r\nINFO 2022-09-23 19:56:17,012 trainer.py:167]  iter: 96404/1200, Rank: 0, l1_loss: 1.770270, duration_loss: 0.278578, pitch_loss: 0.868206, energy_loss: 4.675483, loss: 7.592536, avg_reader_cost: 0.00017 sec, avg_batch_cost: 0.21332 sec, avg_samples: 32, avg_ips: 150.00853 sequences/sec\r\nINFO 2022-09-23 19:56:17,226 fastspeech2_updater.py:174] Evaluate: l1_loss: 2.153552, duration_loss: 0.385811, pitch_loss: 0.574073, energy_loss: 5.581622, loss: 8.695057\r\nINFO 2022-09-23 19:56:20,039 trainer.py:167]  iter: 96405/1200, Rank: 0, l1_loss: 1.780190, duration_loss: 0.277861, pitch_loss: 1.635613, energy_loss: 5.039042, loss: 8.732705, avg_reader_cost: 0.24950 sec, avg_batch_cost: 0.51928 sec, avg_samples: 32, avg_ips: 61.62427 sequences/sec\r\nINFO 2022-09-23 19:56:20,205 trainer.py:167]  iter: 96406/1200, Rank: 0, l1_loss: 1.688078, duration_loss: 0.244555, pitch_loss: 0.762871, energy_loss: 4.326387, loss: 7.021891, avg_reader_cost: 0.00062 sec, avg_batch_cost: 0.16330 sec, avg_samples: 32, avg_ips: 195.95860 sequences/sec\r\nINFO 2022-09-23 19:56:20,473 trainer.py:167]  iter: 96407/1200, Rank: 0, l1_loss: 1.639309, duration_loss: 0.291534, pitch_loss: 0.861395, energy_loss: 4.975361, loss: 7.767599, avg_reader_cost: 0.00019 sec, avg_batch_cost: 0.26607 sec, avg_samples: 32, avg_ips: 120.26807 sequences/sec\r\nINFO 2022-09-23 19:56:20,654 trainer.py:167]  iter: 96408/1200, Rank: 0, l1_loss: 1.648149, duration_loss: 0.320221, pitch_loss: 0.792124, energy_loss: 4.360466, loss: 7.120960, avg_reader_cost: 0.00018 sec, avg_batch_cost: 0.17950 sec, avg_samples: 32, avg_ips: 178.27264 sequences/sec\r\nINFO 2022-09-23 19:56:20,908 fastspeech2_updater.py:174] Evaluate: l1_loss: 2.084182, duration_loss: 0.419054, pitch_loss: 0.366559, energy_loss: 4.915794, loss: 7.785589\r\nINFO 2022-09-23 19:56:23,792 trainer.py:167]  iter: 96409/1200, Rank: 0, l1_loss: 1.634000, duration_loss: 0.245067, pitch_loss: 1.825069, energy_loss: 4.637261, loss: 8.341396, avg_reader_cost: 0.27610 sec, avg_batch_cost: 0.54012 sec, avg_samples: 32, avg_ips: 59.24561 sequences/sec\r\nINFO 2022-09-23 19:56:24,009 trainer.py:167]  iter: 96410/1200, Rank: 0, l1_loss: 1.596452, duration_loss: 0.312945, pitch_loss: 0.717812, energy_loss: 3.500055, loss: 6.127264, avg_reader_cost: 0.00023 sec, avg_batch_cost: 0.21478 sec, avg_samples: 32, avg_ips: 148.99175 sequences/sec\r\nINFO 2022-09-23 19:56:24,189 trainer.py:167]  iter: 96411/1200, Rank: 0, l1_loss: 1.579894, duration_loss: 0.246891, pitch_loss: 0.851606, energy_loss: 4.034445, loss: 6.712835, avg_reader_cost: 0.00030 sec, avg_batch_cost: 0.17803 sec, avg_samples: 32, avg_ips: 179.74425 sequences/sec\r\nINFO 2022-09-23 19:56:24,458 trainer.py:167]  iter: 96412/1200, Rank: 0, l1_loss: 1.544847, duration_loss: 0.266166, pitch_loss: 0.645351, energy_loss: 4.618836, loss: 7.075200, avg_reader_cost: 0.00021 sec, avg_batch_cost: 0.26733 sec, avg_samples: 32, avg_ips: 119.70131 sequences/sec\r\nINFO 2022-09-23 19:56:24,691 fastspeech2_updater.py:174] Evaluate: l1_loss: 2.006938, duration_loss: 0.450204, pitch_loss: 0.262614, energy_loss: 4.423265, loss: 7.143022\r\nINFO 2022-09-23 19:56:27,653 trainer.py:167]  iter: 96413/1200, Rank: 0, l1_loss: 1.563614, duration_loss: 0.288662, pitch_loss: 1.887361, energy_loss: 3.617754, loss: 7.357391, avg_reader_cost: 0.27405 sec, avg_batch_cost: 0.53012 sec, avg_samples: 32, avg_ips: 60.36321 sequences/sec\r\nINFO 2022-09-23 19:56:27,927 trainer.py:167]  iter: 96414/1200, Rank: 0, l1_loss: 1.547978, duration_loss: 0.275924, pitch_loss: 0.660862, energy_loss: 3.920330, loss: 6.405094, avg_reader_cost: 0.00029 sec, avg_batch_cost: 0.27138 sec, avg_samples: 32, avg_ips: 117.91451 sequences/sec\r\nINFO 2022-09-23 19:56:28,144 trainer.py:167]  iter: 96415/1200, Rank: 0, l1_loss: 1.496017, duration_loss: 0.253219, pitch_loss: 0.574959, energy_loss: 3.712186, loss: 6.036382, avg_reader_cost: 0.00030 sec, avg_batch_cost: 0.21546 sec, avg_samples: 32, avg_ips: 148.51825 sequences/sec\r\nINFO 2022-09-23 19:56:28,325 trainer.py:167]  iter: 96416/1200, Rank: 0, l1_loss: 1.476836, duration_loss: 0.215573, pitch_loss: 0.774607, energy_loss: 4.139956, loss: 6.606973, avg_reader_cost: 0.00029 sec, avg_batch_cost: 0.17925 sec, avg_samples: 32, avg_ips: 178.51734 sequences/sec\r\nINFO 2022-09-23 19:56:28,529 fastspeech2_updater.py:174] Evaluate: l1_loss: 1.925813, duration_loss: 0.436651, pitch_loss: 0.225853, energy_loss: 4.057889, loss: 6.646207\r\nINFO 2022-09-23 19:56:31,268 trainer.py:167]  iter: 96417/1200, Rank: 0, l1_loss: 1.507729, duration_loss: 0.278215, pitch_loss: 0.658901, energy_loss: 3.469983, loss: 5.914828, avg_reader_cost: 0.28339 sec, avg_batch_cost: 0.48521 sec, avg_samples: 32, avg_ips: 65.95148 sequences/sec\r\nINFO 2022-09-23 19:56:31,511 trainer.py:167]  iter: 96418/1200, Rank: 0, l1_loss: 1.498667, duration_loss: 0.226933, pitch_loss: 0.807640, energy_loss: 3.796876, loss: 6.330114, avg_reader_cost: 0.00028 sec, avg_batch_cost: 0.24016 sec, avg_samples: 32, avg_ips: 133.24319 sequences/sec\r\nException in main training loop: (InvalidArgument) The value (281) of the non-singleton dimension does not match the corresponding value (289) in shape for expand_v2 op.\r\n  [Hint: Expected vec_in_dims[i] == expand_shape[i], but received vec_in_dims[i]:281 != expand_shape[i]:289.] (at /paddle/paddle/phi/kernels/impl/expand_kernel_impl.h:61)\r\n  [operator < expand_v2 > error]\r\nTraceback (most recent call last):\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 63, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens = self.model(\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 550, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs = self._forward(\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 667, in _forward\r\n    zs, _ = self.decoder(hs, h_masks)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/encoder.py\", line 409, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 99, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/attention.py\", line 144, in forward\r\n    return self.forward_attention(v, scores, mask)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/attention.py\", line 107, in forward_attention\r\n    scores = masked_fill(scores, mask, min_value)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/masked_fill.py\", line 44, in masked_fill\r\n    mask = mask.broadcast_to(bshape)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/tensor/manipulation.py\", line 1917, in broadcast_to\r\n    return _C_ops.expand_v2(x, 'shape', shape)\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/examples/other/tts_finetune/tts3/local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/examples/other/tts_finetune/tts3/local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 63, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens = self.model(\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 550, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs = self._forward(\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 667, in _forward\r\n    zs, _ = self.decoder(hs, h_masks)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/encoder.py\", line 409, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 99, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/attention.py\", line 144, in forward\r\n    return self.forward_attention(v, scores, mask)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/transformer/attention.py\", line 107, in forward_attention\r\n    scores = masked_fill(scores, mask, min_value)\r\n  File \"/home/xxxx/icassp_workspace/PaddleSpeech/paddlespeech/t2s/modules/masked_fill.py\", line 44, in masked_fill\r\n    mask = mask.broadcast_to(bshape)\r\n  File \"/home/xxxx/.custom/cuda-11.4.2-cudnn8-devel-ubuntu20.04-pytorch1.9.0_full_tensorboard/envs/paddle_env/lib/python3.9/site-packages/paddle/tensor/manipulation.py\", line 1917, in broadcast_to\r\n    return _C_ops.expand_v2(x, 'shape', shape)\r\nValueError: (InvalidArgument) The value (281) of the non-singleton dimension does not match the corresponding value (289) in shape for expand_v2 op.\r\n  [Hint: Expected vec_in_dims[i] == expand_shape[i], but received vec_in_dims[i]:281 != expand_shape[i]:289.] (at /paddle/paddle/phi/kernels/impl/expand_kernel_impl.h:61)\r\n  [operator < expand_v2 > error]\r\n```",
        "state": "closed",
        "user": "dc3ea9f",
        "closed_by": "yt605155624",
        "created_at": "2022-09-23T12:15:58+00:00",
        "updated_at": "2023-09-13T09:05:03+00:00",
        "closed_at": "2022-10-18T03:08:35+00:00",
        "comments_count": [
            "yt605155624",
            "dc3ea9f",
            "dc3ea9f",
            "dc3ea9f",
            "yt605155624",
            "dc3ea9f",
            "dc3ea9f",
            "graciechen",
            "hello2mao",
            "hello2mao",
            "ray1a1",
            "Tony-xubiao",
            "hello2mao"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2444
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2443,
        "title": "[TTS]英文数据 MFA 之前过滤标点，防止标点和单词黏连导致 OOV 变成 spn",
        "body": null,
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-09-23T14:56:26+00:00",
        "updated_at": "2022-12-27T14:15:51+00:00",
        "closed_at": null,
        "comments_count": [
            "binbinxue",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2445
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2452,
        "title": "🔥 r1.2.0 release note",
        "body": "# S2T\r\n - Fix conformer/transformer multi GPU training. #2327 #2334 #2336 #2372 by @Zth9730\r\n - Fix deepspeech2 decode_wav. #2351 by @Zth9730\r\n - Support BiTransformer decoder. #2415 by @Zth9730\r\n \r\n\r\n# T2S\r\n - Update VITS to support VITS and its voice cloning training on AISHELL-3. #2268 by @HighCWu\r\n - Add ERNIE-SAT synthesize_e2e. #2287 #2316 #2355 #2378 #2432 by @yt605155624\r\n - Specify the input data type of G2PW. #2288 by @kslz\r\n - Add TTS finetune example. #2297 #2385 #2418 #2430 by @lym0302\r\n - Fix Chinese English mixed TTS frontend. #2299 #2493 by @lym0302\r\n - Add words into polyphonic.yaml for g2pW. #2300 by @david-95\r\n - Update the quantifier unit in Text Normalization. #2308 by @pengzhendong\r\n - Fix Chinese frontend bugs. #2312 #2323 by @david-95\r\n - Add AISHELL-3 Voice Cloning with ECAPA-TDNN speaker encoder. #2359 #2429 by @yt605155624\r\n - Add pre-install doc for G2P and TN, update version of pypinyin. #2364 by @WongLaw\r\n - Add tools to compare two test results of G2P to show differences. #2367 by @david-95\r\n - Revise must_neural_tone_words. #2370 by @WongLaw\r\n - Add type-hint for g2pW. #2390 by @yt605155624\r\n - Replaced fixed path with path variable in MFA. #2416 by @WongLaw\r\n - Solve \"unknown format: 3\" for wavfile.write(). #2422 by @zhoupc2015\r\n\r\n\r\n# Text\r\n - Create preprocess.py for Punctuation Restoration. #2295 by @THUzyt21\r\n \r\n# Demo\r\n - Add Voice Cloning, TTS finetune, and ERNIE-SAT in speech_web. #2412 #2451 by @iftaken\r\n\r\n# Server\r\n - Add num_decoding_left_chunks in streaming_asr_server's config. #2337 by @THUzyt21\r\n - Removed useless spk_id in speech_server and streaming_tts_server, support Chinese English mixed TTS server engine. #2380 by @WongLaw\r\n\r\n\r\n# Doc\r\n - Add Chinese doc and language switcher for metaverse, style_fs2 and story_talker. #2357 by @WongLaw\r\n - Update API docs. #2406 by @yt605155624\r\n - Add finetune demos in readthedocs. #2411 by @yt605155624\r\n\r\n# Test\r\n - Add barrier for distributed training using multiple machines. #2309 #2311 by @sneaxiy\r\n - Fix prepare.sh for PWGAN TIPC. #2376 by @yuehuayingxueluo\r\n\r\n# Other\r\n - Format paddlespeech with pre-commit. #2331 by @yt605155624\r\n \r\n\r\n# Acknowledgements\r\nSpecial thanks to @yt605155624  @lym0302  @THUzyt21  @iftaken  @Zth9730  @zhoupc2015  @WongLaw  @david-95  @pengzhendong  @kslz  @HighCWu  @yuehuayingxueluo  @sneaxiy @SmileGoat \r\n\r\n## New Contributors\r\n- @HighCWu made their first contribution in #2268\r\n- @pengzhendong made their first contribution in #2308 \r\n- @Zth9730 made their first contribution in #2327\r\n- @WongLaw made their first contribution in #2357\r\n- @yuehuayingxueluo made their first contribution in #2376\r\n- @zhoupc2015 made their first contribution in #2422\r\n\r\n\r\n**Full Changelog**: https://github.com/PaddlePaddle/PaddleSpeech/compare/r1.1.0...r1.2.0\r\n",
        "state": "closed",
        "user": "lym0302",
        "closed_by": "lym0302",
        "created_at": "2022-09-26T04:26:47+00:00",
        "updated_at": "2022-10-10T03:42:50+00:00",
        "closed_at": "2022-10-10T03:42:50+00:00",
        "comments_count": [],
        "labels": [
            "Documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2447,
        "title": "PaddleSpeech Create Srt file",
        "body": "# Qustion\r\nIs it possible to quickly convert an hour-long audio to a srt subtitle file?\r\n\r\n# Individual\r\nI had a preliminary understanding of PaddleSpeech converting audio to text, but my text didn't even have punctuation.\r\nMaybe it's my code.",
        "state": "closed",
        "user": "imohuan",
        "closed_by": "yt605155624",
        "created_at": "2022-09-24T04:14:23+00:00",
        "updated_at": "2023-04-11T09:29:32+00:00",
        "closed_at": "2022-10-09T12:51:48+00:00",
        "comments_count": [
            "yt605155624",
            "imohuan",
            "imohuan",
            "imohuan",
            "twoDogy"
        ],
        "labels": [
            "S2T",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2446,
        "title": "为什么第二天要重新安装库",
        "body": "为什么前一天缺少的包都安装了，第二天进去怎么又要重新安装呢\r\n![Snipaste_2022-09-24_09-53-32](https://user-images.githubusercontent.com/108966996/192075170-29c1f523-0b43-415e-b657-03c56f873e1c.png)\r\n",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-24T01:56:26+00:00",
        "updated_at": "2022-09-26T02:45:11+00:00",
        "closed_at": "2022-09-26T02:45:11+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2454,
        "title": "[TTS]小样本 finetune 时，batch_size 要 <= 样本数，否则会报错 ",
        "body": "![746C9A289B829C5B591F587ECF4511EF](https://user-images.githubusercontent.com/24568452/192253300-7febc465-6e9d-438d-9623-d08a4ad650c4.jpg)\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-09-26T10:21:47+00:00",
        "updated_at": "2022-09-26T11:09:51+00:00",
        "closed_at": "2022-09-26T11:09:51+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2448,
        "title": "脚本执行结果",
        "body": "![image](https://user-images.githubusercontent.com/108966996/192087100-d7a4e4ff-fce7-457a-9ca2-51117c8d2685.png)\r\n请问这个脚本执行之后为什么不训练呢",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-24T07:53:28+00:00",
        "updated_at": "2022-10-09T12:51:39+00:00",
        "closed_at": "2022-10-09T12:51:39+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123",
            "AlphaMind123",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2450,
        "title": "请问有使用ASR模型导出的 pdmodel 和 padiparams文件推理的示例嘛",
        "body": "请问有使用模型导出的 pdmodel 和 padiparams文件推理的示例嘛，\r\n不知道为啥在GPU上用config和pdparams预测asr的时候很慢，大概10s左右（和我在笔记本上用CPU预测的时间差不多），\r\n看了一下显存占用1000M多点，不知道正常不啊。\r\n我根据百度搜到的 paddle.inference 相关资料，尝试使用 deepspeech2_online_aishell_fbank161 导出的 pdmodel 和 padiparams文件进行预测，但是没搞懂输入输出都是啥啊，卡在一个很奇怪的报错上进行不下去了。\r\n\r\n```\r\ninput_names:  ['audio_chunk', 'audio_chunk_lens', 'chunk_state_h_box', 'chunk_state_c_box']\r\noutput_names: ['softmax_0.tmp_0', 'tmp_5', 'concat_0.tmp_0', 'concat_1.tmp_0']\r\n```\r\n\r\n代码如下：\r\n```\r\n# 使用 deepspeech2_online_aishell_fbank161 导出的\r\n# pdmodel 和 padiparams 文件推理\r\n\r\nimport argparse\r\nimport numpy as np\r\nfrom yacs.config import CfgNode\r\n\r\nimport paddle\r\n# 引用 paddle inference 预测库\r\nimport paddle.inference as paddle_infer\r\nfrom paddlespeech.s2t.frontend.speech import SpeechSegment\r\nfrom paddlespeech.s2t.frontend.normalizer import FeatureNormalizer\r\nfrom paddlespeech.s2t.frontend.featurizer.audio_featurizer import AudioFeaturizer\r\n\r\ndef main():\r\n    args = parse_args()\r\n\r\n    cfg = CfgNode(new_allowed=True)\r\n    cfg.merge_from_file(args.cfg_path)\r\n    cfg.freeze()\r\n\r\n    # 创建 config\r\n    config = paddle_infer.Config(args.model_file, args.params_file)\r\n    config.disable_gpu()\r\n\r\n    print(f'已加载模型\\n' \r\n          f'model_file: {args.model_file}\\n' \r\n          f'params_file: {args.params_file}')\r\n\r\n    # 根据 config 创建 predictor\r\n    predictor = paddle_infer.create_predictor(config)\r\n\r\n    # 获取输入名称\r\n    input_names = predictor.get_input_names()\r\n    print('input_names: ',input_names)\r\n    # 获取输出名称\r\n    output_names = predictor.get_output_names()\r\n    print('output_names:', output_names)\r\n\r\n    # 特征提取\r\n    audio_featurizer = AudioFeaturizer(spectrum_type='fbank',\r\n                                    feat_dim=161,\r\n                                    delta_delta=False,\r\n                                    stride_ms=10.0,\r\n                                    window_ms=20.0,\r\n                                    n_fft=None,\r\n                                    max_freq=None,\r\n                                    target_sample_rate=16000,\r\n                                    use_dB_normalization=True,\r\n                                    target_dB=-20,\r\n                                    dither=1.0)\r\n    speech_segment = SpeechSegment.from_file(args.audio_path, \"None\")\r\n    audio_feature = audio_featurizer.featurize(speech_segment)\r\n    # 归一化\r\n    # feature_normalizer = FeatureNormalizer(mean_std_filepath) if feat_config.mean_std_filepath else None\r\n    # audio_feature_i = feature_normalizer.apply(audio_feature)\r\n    \r\n    audio_feature = np.array(audio_feature).astype(np.float32)[np.newaxis, :]\r\n    audio_len = np.array(audio_feature.shape[2]).astype(np.int64)\r\n    print(f\"feature shape: {audio_feature.shape}\")\r\n\r\n    # 获取输入层\r\n    input_handle_audio = predictor.get_input_handle(input_names[0])\r\n    input_handle_audio_len = predictor.get_input_handle(input_names[1])\r\n    # 设置输入\r\n    input_handle_audio.reshape([audio_feature.shape[0], audio_feature.shape[1], audio_feature.shape[2]])\r\n    input_handle_audio.copy_from_cpu(audio_feature)\r\n    input_handle_audio_len.reshape([audio_len])\r\n    input_handle_audio_len.copy_from_cpu(audio_len)\r\n\r\n    # 运行predictor\r\n    predictor.run()\r\n\r\n    output_handle = predictor.get_output_handle(output_names[0])\r\n    output_data = output_handle.copy_to_cpu() # numpy.ndarray类型\r\n    print(\"Output data is {}\".format(output_data))\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--cfg_path\", \r\n            default='configs/deepspeech2_online_aishell_fbank161/conf/deepspeech2_online.yaml',\r\n            type=str, help=\"*.pdmodel filepath\")\r\n    parser.add_argument(\"--model_file\", \r\n            default='configs/deepspeech2_online_aishell_fbank161/export/avg_1.jit.pdmodel',\r\n            type=str, help=\"*.pdmodel filepath\")\r\n    parser.add_argument(\"--params_file\",\r\n            default='configs/deepspeech2_online_aishell_fbank161/export/avg_1.jit.pdiparams',\r\n            type=str, help=\"*.padiparams filepath\")\r\n    parser.add_argument(\"--audio_path\",\r\n            default='D:/Data/Speech/short/001.wav',\r\n            type=str, help=\"*.wav filepath\")\r\n    parser.add_argument(\"--batch_size\", type=int, default=1, help=\"batch size\")\r\n    \r\n    return parser.parse_args()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n目前的终端输出和报错情况如下：\r\n```\r\nPS D:\\Code\\PADDLE\\PaddleSpeech-develop> & D:/Program/miniconda3/envs/paddle/python.exe d:/Code/PADDLE/PaddleSpeech-develop/demos/speech_recognition/infer_ds2.py\r\n已加载模型\r\nmodel_file: configs/deepspeech2_online_aishell_fbank161/export/avg_1.jit.pdmodel\r\nparams_file: configs/deepspeech2_online_aishell_fbank161/export/avg_1.jit.pdiparams\r\ne[1me[35m--- Running analysis [ir_graph_build_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_graph_clean_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_analysis_pass]e[0m\r\ne[32m--- Running IR pass [simplify_with_basic_ops_pass]e[0m\r\ne[32m--- Running IR pass [layer_norm_fuse_pass]e[0m\r\ne[37m---    Fused 0 subgraphs into layer_norm op.e[0m\r\ne[32m--- Running IR pass [attention_lstm_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]e[0m\r\ne[32m--- Running IR pass [mul_lstm_fuse_pass]e[0m\r\ne[32m--- Running IR pass [fc_gru_fuse_pass]e[0m\r\ne[37m---    fused 0 pairs of fc gru patternse[0m\r\ne[32m--- Running IR pass [mul_gru_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seq_concat_fc_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [matmul_v2_scale_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]e[0m\r\nI0925 18:00:40.682015 14972 fuse_pass_base.cc:57] ---  detected 1 subgraphs\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]e[0m\r\ne[32m--- Running IR pass [matmul_scale_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]e[0m\r\ne[32m--- Running IR pass [fc_fuse_pass]e[0m\r\nI0925 18:00:40.697669 14972 fuse_pass_base.cc:57] ---  detected 1 subgraphs\r\ne[32m--- Running IR pass [repeated_fc_relu_fuse_pass]e[0m\r\ne[32m--- Running IR pass [squared_mat_sub_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_transpose_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [is_test_pass]e[0m\r\ne[32m--- Running IR pass [runtime_context_cache_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_params_sync_among_devices_pass]e[0m\r\ne[1me[35m--- Running analysis [adjust_cudnn_workspace_size_pass]e[0m\r\ne[1me[35m--- Running analysis [inference_op_replace_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_graph_to_program_pass]e[0m\r\nI0925 18:00:40.809091 14972 analysis_predictor.cc:1035] ======= optimize end =======\r\nI0925 18:00:40.809091 14972 naive_executor.cc:102] ---  skip [feed], feed -> chunk_state_c_box\r\nI0925 18:00:40.810307 14972 naive_executor.cc:102] ---  skip [feed], feed -> chunk_state_h_box\r\nI0925 18:00:40.810307 14972 naive_executor.cc:102] ---  skip [feed], feed -> audio_chunk_lens\r\nI0925 18:00:40.811797 14972 naive_executor.cc:102] ---  skip [feed], feed -> audio_chunk\r\nI0925 18:00:40.813787 14972 naive_executor.cc:102] ---  skip [softmax_0.tmp_0], fetch -> fetch\r\nI0925 18:00:40.814805 14972 naive_executor.cc:102] ---  skip [tmp_5], fetch -> fetch\r\nI0925 18:00:40.815081 14972 naive_executor.cc:102] ---  skip [concat_0.tmp_0], fetch -> fetch\r\nI0925 18:00:40.815081 14972 naive_executor.cc:102] ---  skip [concat_1.tmp_0], fetch -> fetch\r\ninput_names:  ['audio_chunk', 'audio_chunk_lens', 'chunk_state_h_box', 'chunk_state_c_box']\r\noutput_names: ['softmax_0.tmp_0', 'tmp_5', 'concat_0.tmp_0', 'concat_1.tmp_0']\r\nfeature shape: (1, 476, 161)\r\nTraceback (most recent call last):\r\n  File \"d:/Code/PADDLE/PaddleSpeech-develop/demos/speech_recognition/infer_ds2.py\", line 98, in <module>\r\n    main()\r\n  File \"d:/Code/PADDLE/PaddleSpeech-develop/demos/speech_recognition/infer_ds2.py\", line 73, in main\r\n    predictor.run()\r\nValueError: In user code:\r\n\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/exps/deepspeech2/bin/export.py\", line 56, in <module>\r\n      main(config, args)\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/exps/deepspeech2/bin/export.py\", line 30, in main\r\n      main_sp(config, args)\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/exps/deepspeech2/bin/export.py\", line 26, in main_sp\r\n      exp.run_export()\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/training/trainer.py\", line 365, in run_export\r\n      self.export()\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 351, in _decorate_function\r\n      return func(*args, **kwargs)\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/exps/deepspeech2/model.py\", line 434, in export\r\n      paddle.jit.save(static_model, self.args.export_path)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/jit.py\", line 744, in save \r\n      inner_input_spec)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 517, in concrete_program_specify_input_spec\r\n      *desired_input_spec)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 427, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 723, in __getitem__\r\n      self._caches[item] = self._build_once(item)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 714, in _build_once\r\n      **cache_key.kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 662, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/models/ds2_online/deepspeech2.py\", line 378, in forward\r\n      audio_chunk, audio_chunk_lens, chunk_state_h_box, chunk_state_c_box)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 917, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 907, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/tmp/tmpktxfs6wq.py\", line 59, in forward\r\n      init_state_list))\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 257, in _run_py_ifelse\r\n      return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/tmp/tmpktxfs6wq.py\", line 50, in true_fn_1\r\n      init_state_list)))\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 257, in _run_py_ifelse\r\n      return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/home/huangyuxin/workspace/PaddleSpeech_for_align_develop/PaddleSpeech_align_dist_fusion_init/paddlespeech/s2t/models/ds2_online/deepspeech2.py\", line 119, in forward\r\n      init_state_h_box, self.num_rnn_layers, axis=0)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/tensor/manipulation.py\", line 850, in split\r\n      input=x, num_or_sections=num_or_sections, dim=axis, name=name)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 5029, in split \r\n      type='split', inputs=inputs, outputs={'Out': outs}, attrs=attrs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3184, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/home/huangyuxin/miniconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2224, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The split Op's Input Variable `X` contains uninitialized Tensor.\r\n      [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] (at C:\\home\\workspace\\Paddle_release\\paddle\\fluid\\framework\\operator.cc:2094)\r\n      [operator < split > error]\r\n```",
        "state": "closed",
        "user": "lichuanqi",
        "closed_by": "lichuanqi",
        "created_at": "2022-09-25T10:31:50+00:00",
        "updated_at": "2022-09-26T02:45:49+00:00",
        "closed_at": "2022-09-26T02:45:49+00:00",
        "comments_count": [
            "yt605155624",
            "lichuanqi"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2455,
        "title": "example/csmsc/tts3里边synthesize_streaming.sh 和inference_streaming.sh的区别？",
        "body": "您好，很感谢你们公开这么好的工作。再看了代码以后我对比这两个文件的区别发现他们的区别在于：\r\n- synthesize_streaming这个脚本中包含了静态图的转换，但是在inference_streaming中没有静态图的转换；\r\n- synthesize_streaming合成mel是分的chunk，Mel拼接一起产生的wav。inference_streaming也是这个过程。其实在这个过程中他们是一样的。\r\n\r\n期待您的回复，谢谢您。",
        "state": "closed",
        "user": "panxin801",
        "closed_by": "panxin801",
        "created_at": "2022-09-26T10:22:16+00:00",
        "updated_at": "2022-09-26T11:01:40+00:00",
        "closed_at": "2022-09-26T11:01:40+00:00",
        "comments_count": [
            "yt605155624",
            "panxin801"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2453,
        "title": "请问是否有同时支持中英文的ASR模型",
        "body": "如果预训练的模型只支持中文的话，实际适用场景很受限制",
        "state": "closed",
        "user": "UprightNeether",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-26T08:24:15+00:00",
        "updated_at": "2023-03-25T12:01:33+00:00",
        "closed_at": "2023-03-25T12:01:33+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng",
            "yt605155624",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2463
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2456,
        "title": "💡 TTS 小样本 finetune / 声音克隆问题汇总",
        "body": "**如果 12 句 finetune 效果不佳，一般是因为数据集太小了，建议增加数据集，一般是 300 ~ 600 条，数据量和质量越好，合成的效果越好**\r\n数据的质量要求没有混响，没有杂音，离麦克风距离适中，具体可以参考标贝的数据质量。\r\nfinetune 出来的音色与 目标说话人和原始说话人的相似度有关，即目标说话人和原始说话人相似度越高，finetune 出来的音色更接近目标说话人。\r\nfinetune 出来的音频质量与原始说话人的音频质量有关，原始说话人的音频质量不好，finetune 出来的效果也可能不好。\r\n综上，finetune 方案在数据采集，选择原始说话人上需要好好选择。\r\n\r\n小样本 finetune 原理参考 [关于训练一个自己的TTS模型](https://github.com/PaddlePaddle/PaddleSpeech/discussions/1842)\r\n\r\n1. https://github.com/PaddlePaddle/PaddleSpeech/issues/2437\r\n2. https://github.com/PaddlePaddle/PaddleSpeech/issues/2454\r\n3. https://github.com/PaddlePaddle/PaddleSpeech/issues/2383\r\n4. 预处理都没有问题，为什么不跑训练流程？-> epoch 的设置有问题，参考： https://github.com/PaddlePaddle/PaddleSpeech/issues/2319#issuecomment-1231618015\r\n5. https://github.com/PaddlePaddle/PaddleSpeech/issues/2442\r\n6. https://github.com/PaddlePaddle/PaddleSpeech/issues/2471 -> 安装 develop 版本的 paddlespeech\r\n7. https://github.com/PaddlePaddle/PaddleSpeech/issues/2245\r\n8. https://github.com/PaddlePaddle/PaddleSpeech/issues/2485 -> 安装 develop 版本的 paddlespeech\r\n9. https://github.com/PaddlePaddle/PaddleSpeech/issues/2583 -> 推荐使用 finetune 方案\r\n10. https://github.com/PaddlePaddle/PaddleSpeech/issues/2586\r\n11. https://github.com/PaddlePaddle/PaddleSpeech/issues/2607\r\n12. https://github.com/PaddlePaddle/PaddleSpeech/issues/2790\r\n13. https://github.com/PaddlePaddle/PaddleSpeech/issues/2953\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-09-26T10:23:18+00:00",
        "updated_at": "2023-10-28T18:55:46+00:00",
        "closed_at": null,
        "comments_count": [
            "UserName-wang",
            "yt605155624",
            "exceedzhang",
            "zhouzyc",
            "maize-j",
            "yt605155624",
            "maize-j",
            "yt605155624",
            "Rapheal-Madfrog",
            "Rapheal-Madfrog",
            "joisonwk"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2458,
        "title": "将文本数据集转化为语音数据集",
        "body": "我想把一个文本数据集转化为语音数据集，请问paddlespeech里面有提供转换的代码吗",
        "state": "closed",
        "user": "MingyuLau",
        "closed_by": "MingyuLau",
        "created_at": "2022-09-27T00:26:42+00:00",
        "updated_at": "2022-09-28T14:38:17+00:00",
        "closed_at": "2022-09-28T14:38:17+00:00",
        "comments_count": [
            "yaleimeng",
            "MingyuLau",
            "MingyuLau",
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2459,
        "title": "[S2T] aishell/asr1 训练过程卡住不动",
        "body": "你好，我发现一个问题，对于ASR训练（文件夹：examples/aishell/asr1）,训练到中间部分的时候，就直接卡住不动了，主要有以下情况：\r\n1：单卡训练的时候，训练到中间部分，训练就卡住了，GPU也完全不动了，GPU内存却正常占用；\r\n![image](https://user-images.githubusercontent.com/27938135/192408393-6ce0f5e4-7cbc-43cf-80e5-72db30478aaa.png)\r\n打印的日志只更新到26号，训练epoch到25就不动了（设置的epoch是30）;\r\n\r\n2: 双卡训练的时候，也一样的情况。重启之后，1个epoch都没训练就卡住了。状态和上面一样。\r\n![image](https://user-images.githubusercontent.com/27938135/192408745-3ebd652d-cb24-4242-8535-b06cab46f69c.png)\r\n![image](https://user-images.githubusercontent.com/27938135/192408785-4a4771e4-e00d-4513-8d62-d6fdc6f9e06d.png)\r\n这两张卡一直处于静止状态。请问这个问题是什么情况啊\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "zh794390558",
        "created_at": "2022-09-27T01:16:10+00:00",
        "updated_at": "2022-10-08T00:57:24+00:00",
        "closed_at": "2022-09-29T02:31:54+00:00",
        "comments_count": [
            "Tian14267",
            "zh794390558",
            "Zth9730",
            "Tian14267",
            "Tian14267",
            "Tian14267",
            "Zth9730",
            "Tian14267",
            "Tian14267"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2462,
        "title": "DeepSpeech2 使用导出模型pdmodel和pdiparams测试时预测时间比使用cfg和ckpt预测的还要慢很多",
        "body": "Hello，我挑了5条测试音频使用deepspeech2测试时发现导出模型的预测时间在30s左右，比使用 cfg 和 ckpt 预测的11s还要慢很多。终端输出也确实显示了使用 gpu:0，不知道为啥很慢。而且导出的比不导出的还慢。\r\n\r\n环境：\r\n* Ubuntu 20.04\r\n* python 3.7\r\n* paddlepaddle 2.3.2\r\n* CUDA 10.2\r\n* cuDNN 7.6\r\n\r\n模型：deepspeech2_online_wenetspeech_1.0.4\r\n导出模型文件：`from paddlespeech.s2t.exps.deepspeech2.model import DeepSpeech2ExportTester as ExportTester`\r\n导出模型结果：\r\n```\r\nSetup model!\r\n2022-09-27 10:16:00.647 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:352 - Test Total Examples: 5\r\n2022-09-27 10:16:00.649 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:187 - begin to initialize the external scorer for decoding\r\n2022-09-27 10:16:00.958 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:197 - language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2022-09-27 10:16:00.961 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:198 - end initializing scorer\r\nW0927 10:16:02.442078 137610 rnn_kernel.cu.cc:243] If the memory space of the Input WeightList is not continuous, less efficient calculation will be called. Please call flatten_parameters() to make the input memory continuous.\r\nW0927 10:16:02.443998 137610 rnn_kernel.cu.cc:243] If the memory space of the Input WeightList is not continuous, less efficient calculation will be called. Please call flatten_parameters() to make the input memory continuous.\r\n2022-09-27 10:16:08.502 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_1\r\n2022-09-27 10:16:08.504 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 他仅凭腰部的力量在泳道上下翻腾蛹动蛇行状如海豚一直以一头的优势领先\r\n2022-09-27 10:16:08.504 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 仅凭腰部的力量在甬道上下翻腾涌动蛇形状如海豚一直以一头的优势领先\r\n2022-09-27 10:16:08.518 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.121212\r\n2022-09-27 10:16:08.518 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:388 - Error rate [cer] (1/?) = 0.121212\r\n2022-09-27 10:16:14.018 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_0\r\n2022-09-27 10:16:14.020 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然\r\n2022-09-27 10:16:14.020 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 律是杨春燕京大块文章的底色四月的更是绿的鲜活秀美诗意盎然\r\n2022-09-27 10:16:14.030 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.266667\r\n2022-09-27 10:16:14.031 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:388 - Error rate [cer] (2/?) = 0.190476\r\n2022-09-27 10:16:19.489 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_4\r\n2022-09-27 10:16:19.490 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 她看看夜己很深白天的炎热已给夜凉吹散吩咐大家各自安息明天继续玩乐\r\n2022-09-27 10:16:19.490 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 他看看夜已很深白天的炎热夜凉吹散吩咐大家各自安息明天继续玩乐\r\n2022-09-27 10:16:19.503 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.125000\r\n2022-09-27 10:16:19.503 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:388 - Error rate [cer] (3/?) = 0.168421\r\n2022-09-27 10:16:24.497 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_3\r\n2022-09-27 10:16:24.498 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 菜做好了一碗清蒸武昌鱼一碗蕃茄炒鸡蛋一碗榨菜干子炒肉丝\r\n2022-09-27 10:16:24.499 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 菜做好了一碗清蒸武昌鱼一碗番茄炒鸡蛋一碗榨菜干煸炒肉丝\r\n2022-09-27 10:16:24.508 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.074074\r\n2022-09-27 10:16:24.508 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:388 - Error rate [cer] (4/?) = 0.147541\r\n2022-09-27 10:16:29.299 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_2\r\n2022-09-27 10:16:29.300 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 企业依靠技术挖潜增效他负责全厂产品质量与技术培训成了厂里的大忙人\r\n2022-09-27 10:16:29.301 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 企业依靠技术挖潜增效他负责全厂产品质量与技术培训成了厂里的大忙人\r\n2022-09-27 10:16:29.301 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.000000\r\n2022-09-27 10:16:29.302 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:388 - Error rate [cer] (5/?) = 0.116883\r\n2022-09-27 10:16:29.357 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:395 - Test: epoch: 0, step: 0, Final error rate [cer] (5/5) = 0.116883\r\n2022-09-27 10:16:29.361 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Test/Decode Done: 0:00:28.713772\r\n```\r\ncfg 和 ckpt 预测文件：`from paddlespeech.s2t.exps.deepspeech2.model import DeepSpeech2Tester as Tester`\r\ncfg 和 ckpt 预测输出：\r\n```\r\n2022-09-27 10:07:51.278 | INFO     | paddlespeech.s2t.utils.layer_tools:print_params:60 - Total parameters: 38.0, 164.71M elements.\r\n2022-09-27 10:07:51.278 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:setup_model:146 - Setup model!\r\n2022-09-27 10:07:56.522 | INFO     | paddlespeech.s2t.utils.checkpoint:load_parameters:117 - Rank 0: Restore model from configs/deepspeech2_online_wenetspeech_1.0.4/avg_10.pdparams\r\n2022-09-27 10:07:56.526 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:297 - Test Total Examples: 5\r\n2022-09-27 10:07:56.527 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:187 - begin to initialize the external scorer for decoding\r\n2022-09-27 10:07:56.831 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:197 - language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n2022-09-27 10:07:56.832 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:198 - end initializing scorer\r\n2022-09-27 10:07:59.325 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_1\r\n2022-09-27 10:07:59.326 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 他仅凭腰部的力量在泳道上下翻腾蛹动蛇行状如海豚一直以一头的优势领先\r\n2022-09-27 10:07:59.326 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 仅凭腰部的力量在甬道上下翻腾涌动蛇形状如海豚一直以一头的优势领先\r\n2022-09-27 10:07:59.339 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.121212\r\n2022-09-27 10:07:59.340 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:322 - Error rate [cer] (1/?) = 0.121212\r\n2022-09-27 10:08:00.198 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_0\r\n2022-09-27 10:08:00.198 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然\r\n2022-09-27 10:08:00.199 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 律是杨春燕京大块文章的底色四月的更是绿的鲜活秀美诗意盎然\r\n2022-09-27 10:08:00.209 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.266667\r\n2022-09-27 10:08:00.210 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:322 - Error rate [cer] (2/?) = 0.190476\r\n2022-09-27 10:08:00.981 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_4\r\n2022-09-27 10:08:00.982 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 她看看夜己很深白天的炎热已给夜凉吹散吩咐大家各自安息明天继续玩乐\r\n2022-09-27 10:08:00.982 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 他看看夜已很深白天的炎热夜凉吹散吩咐大家各自安息明天继续玩乐\r\n2022-09-27 10:08:00.994 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.125000\r\n2022-09-27 10:08:00.995 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:322 - Error rate [cer] (3/?) = 0.168421\r\n2022-09-27 10:08:01.753 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_3\r\n2022-09-27 10:08:01.754 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 菜做好了一碗清蒸武昌鱼一碗蕃茄炒鸡蛋一碗榨菜干子炒肉丝\r\n2022-09-27 10:08:01.755 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 菜做好了一碗清蒸武昌鱼一碗番茄炒鸡蛋一碗榨菜干煸炒肉丝\r\n2022-09-27 10:08:01.770 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.074074\r\n2022-09-27 10:08:01.770 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:322 - Error rate [cer] (4/?) = 0.147541\r\n2022-09-27 10:08:02.450 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:276 - Utt: A2_2\r\n2022-09-27 10:08:02.451 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:277 - Ref: 企业依靠技术挖潜增效他负责全厂产品质量与技术培训成了厂里的大忙人\r\n2022-09-27 10:08:02.451 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:278 - Hyp: 企业依靠技术挖潜增效他负责全厂产品质量与技术培训成了厂里的大忙人\r\n2022-09-27 10:08:02.452 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:compute_metrics:281 - Current error rate [cer] = 0.000000\r\n2022-09-27 10:08:02.453 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:322 - Error rate [cer] (5/?) = 0.116883\r\n2022-09-27 10:08:02.494 | INFO     | paddlespeech.s2t.exps.deepspeech2.model:test:330 - Test: epoch: 0, step: 0, Final error rate [cer] (5/5) = 0.116883\r\n2022-09-27 10:08:02.497 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Test/Decode Done: 0:00:11.218123\r\n```",
        "state": "closed",
        "user": "lichuanqi",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-27T02:25:47+00:00",
        "updated_at": "2022-12-23T21:25:21+00:00",
        "closed_at": "2022-12-23T21:25:21+00:00",
        "comments_count": [
            "zh794390558",
            "lichuanqi",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2467,
        "title": "请问语音合成可以使用GPU进行推理吗，如果可以应该怎么操作呢？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "MingyuLau",
        "closed_by": "yt605155624",
        "created_at": "2022-09-27T15:43:25+00:00",
        "updated_at": "2022-10-17T11:46:28+00:00",
        "closed_at": "2022-10-17T11:46:28+00:00",
        "comments_count": [
            "yaleimeng",
            "MingyuLau",
            "yaleimeng",
            "yt605155624",
            "MingyuLau",
            "MingyuLau",
            "MingyuLau",
            "MingyuLau",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2461,
        "title": "[TTS]使用speech_web的小数据集微调报错",
        "body": "Traceback (most recent call last):\r\n  File \"aligner/command_line/align.py\", line 186, in <module>\r\n  File \"aligner/command_line/align.py\", line 142, in validate_args\r\n  File \"aligner/command_line/align.py\", line 69, in align_corpus\r\nTypeError: 'NoneType' object is not subscriptable\r\n[4100] Failed to execute script align\r\n10 1\r\n100%|████████████████████████████████████████| 10/10 [00:00<00:00, 16905.70it/s]\r\nDone\r\nTraceback (most recent call last):\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 335, in <module>\r\n    pretrained_model_dir=pretrained_model_dir)\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 254, in extract_feature\r\n    vocab_speaker, dump_dir, \"train\")\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 148, in normalize\r\n    \"energy\": np.load,\r\n  File \"/home/fyy/miniconda3/envs/paddle_env/lib/python3.7/site-packages/paddlespeech/t2s/datasets/data_table.py\", line 45, in __init__\r\n    assert len(data) > 0, \"This dataset has no examples\"\r\nAssertionError: This dataset has no examples\r\nrank: 0, pid: 4132, parent_pid: 4071\r\nmultiple speaker fastspeech2!\r\nspk_num: 174\r\nTraceback (most recent call last):\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/examples/other/tts_finetune/tts3/local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/examples/other/tts_finetune/tts3/local/finetune.py\", line 120, in train_sp\r\n    with jsonlines.open(args.train_metadata, 'r') as reader:\r\n  File \"/home/fyy/miniconda3/envs/paddle_env/lib/python3.7/site-packages/jsonlines/jsonlines.py\", line 627, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/fyy/ResourceCode/PaddleSpeech/demos/speech_web/speech_server/tmp_dir/finetune/default/dump/train/norm/metadata.jsonl'\r\n上面是报错信息",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "oyb1125",
        "created_at": "2022-09-27T01:57:09+00:00",
        "updated_at": "2022-09-27T07:53:37+00:00",
        "closed_at": "2022-09-27T07:53:37+00:00",
        "comments_count": [
            "yt605155624",
            "oyb1125"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2469,
        "title": "!bash run.sh --stage 1 --stop_stage 1 --gpus 0请问使用这个命令运行报错是什么原因",
        "body": "home/aistudio/PaddleSpeech/examples/aishell/asr1\r\nThe standard file /home/aistudio/PaddleSpeech/tools/kaldi/tools/config/common_path.sh is not present, can not using Kaldi!\r\ncheckpoint name conformer\r\nusing 1 gpus...\r\n\r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\nelastic_server: None\r\nforce: False\r\ngpus: 0\r\nheter_devices: \r\nheter_worker_num: None\r\nheter_workers: \r\nhost: None\r\nhttp_port: None\r\nips: 127.0.0.1\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: /home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\r\ntraining_script_args: ['--ngpu', '1', '--seed', '0', '--config', 'conf/conformer.yaml', '--output', 'exp/conformer', '--profiler-options', '', '--benchmark-batch-size', '0', '--benchmark-max-step', '0']\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nWARNING 2022-09-28 09:13:22,403 launch.py:423] Not found distinct arguments and compiled with cuda or xpu. Default use collective mode\r\nlaunch train in GPU mode!\r\nINFO 2022-09-28 09:13:22,403 launch_utils.py:641] Change selected_gpus into reletive values. --ips:0 will change into relative_ips:[0] according to your CUDA_VISIBLE_DEVICES:['0']\r\nINFO 2022-09-28 09:13:22,404 launch_utils.py:528] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:34673               |\r\n    |                     PADDLE_TRAINERS_NUM                        1                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:34673               |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2022-09-28 09:13:22,404 launch_utils.py:532] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:3126 idx:0\r\nW0928 09:13:24.236148  3126 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\nW0928 09:13:24.238968  3126 device_context.cc:465] device: 0, cuDNN Version: 8.2.\r\n----------- train.py Arguments -----------\r\nbenchmark_batch_size: 0\r\nbenchmark_max_step: 0\r\ncheckpoint_path: None\r\nconf: None\r\nconfig: conf/conformer.yaml\r\ndecode_cfg: None\r\ndump_config: None\r\nngpu: 1\r\nnxpu: 0\r\nopts: None\r\noutput: exp/conformer\r\nprofiler_options: \r\nseed: 0\r\n-----------------------------------------------------------\r\naccum_grad: 8\r\nbatch_bins: 0\r\nbatch_count: auto\r\nbatch_frames_in: 0\r\nbatch_frames_inout: 0\r\nbatch_frames_out: 0\r\nbatch_size: 32\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\ncmvn_file: None\r\ncmvn_file_type: json\r\ndecoder: transformer\r\ndecoder_conf:\r\n  attention_heads: 4\r\n  dropout_rate: 0.1\r\n  linear_units: 2048\r\n  num_blocks: 6\r\n  positional_dropout_rate: 0.1\r\n  self_attention_dropout_rate: 0.0\r\n  src_attention_dropout_rate: 0.0\r\ndev_manifest: data/manifest.dev\r\ndist_sampler: False\r\nencoder: conformer\r\nencoder_conf:\r\n  activation_type: swish\r\n  attention_dropout_rate: 0.0\r\n  attention_heads: 4\r\n  cnn_module_kernel: 15\r\n  dropout_rate: 0.1\r\n  input_layer: conv2d\r\n  linear_units: 2048\r\n  normalize_before: True\r\n  num_blocks: 12\r\n  output_size: 256\r\n  pos_enc_layer_type: rel_pos\r\n  positional_dropout_rate: 0.1\r\n  selfattention_layer_type: rel_selfattn\r\n  use_cnn_module: True\r\nfeat_dim: 80\r\nglobal_grad_clip: 5.0\r\nlog_interval: 100\r\nmaxlen_in: 512\r\nmaxlen_out: 150\r\nminibatches: 0\r\nmodel_conf:\r\n  ctc_weight: 0.3\r\n  init_type: kaiming_uniform\r\n  length_normalized_loss: False\r\n  lsm_weight: 0.1\r\nn_epoch: 150\r\nnum_encs: 1\r\nnum_workers: 2\r\noptim: adam\r\noptim_conf:\r\n  lr: 0.002\r\n  weight_decay: 1e-06\r\npreprocess_config: conf/preprocess.yaml\r\nscheduler: warmuplr\r\nscheduler_conf:\r\n  lr_decay: 1.0\r\n  warmup_steps: 25000\r\nsortagrad: 0\r\nspm_model_prefix: \r\nstride_ms: 10.0\r\nsubsampling_factor: 1\r\ntest_manifest: data/manifest.test\r\ntrain_manifest: data/manifest.train\r\nunit_type: char\r\nvocab_filepath: data/lang_char/vocab.txt\r\nwindow_ms: 25.0\r\n2022-09-28 09:13:27.162 | INFO     | paddlespeech.s2t.utils.utility:all_version:45 - Deps Module Version:[('python', '3.7.4 (default, Aug 13 2019, 20:35:49) \\n[GCC 7.3.0]'),\r\n ('paddle', '2.2.2'),\r\n ('paddle_commit', 'b031c389938bfa15e15bb20494c76f86289d77b0'),\r\n ('soundfile', '0.10.3')]\r\n2022-09-28 09:13:27.164 | INFO     | paddlespeech.s2t.training.trainer:__init__:116 - Rank: 0/1\r\n2022-09-28 09:13:29.897 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:400 - count is auto detected as seq\r\n2022-09-28 09:13:30.132 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:424 - # utts: 120098\r\n2022-09-28 09:13:30.155 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:467 - # minibatches: 3754\r\n2022-09-28 09:13:30.254 | WARNING  | paddlespeech.s2t.io.reader:__init__:76 - [Experimental feature] Some preprocessing will be done for the mini-batch creation using Transformation(\r\n    0: LogMelSpectrogramKaldi(fs=16000, n_mels=80, n_frame_shift=10.0, n_frame_length=25.0, dither=0.1))\r\n    1: GlobalCMVN(\r\n            cmvn_path=data/mean_std.json,\r\n            norm_means=True,\r\n            norm_vars=True,)\r\n    2: TimeWarp(max_time_warp=5, inplace=True, mode=PIL)\r\n    3: FreqMask(F=30, n_mask=2, replace_with_zero=False, inplace=True)\r\n    4: TimeMask(T=40, n_mask=2, replace_with_zero=False, inplace=True))\r\n2022-09-28 09:13:30.970 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:400 - count is auto detected as seq\r\n2022-09-28 09:13:30.993 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:424 - # utts: 14326\r\n2022-09-28 09:13:30.995 | INFO     | paddlespeech.s2t.io.batchfy:make_batchset:467 - # minibatches: 448\r\n2022-09-28 09:13:31.001 | WARNING  | paddlespeech.s2t.io.reader:__init__:76 - [Experimental feature] Some preprocessing will be done for the mini-batch creation using Transformation(\r\n    0: LogMelSpectrogramKaldi(fs=16000, n_mels=80, n_frame_shift=10.0, n_frame_length=25.0, dither=0.1))\r\n    1: GlobalCMVN(\r\n            cmvn_path=data/mean_std.json,\r\n            norm_means=True,\r\n            norm_vars=True,)\r\n    2: TimeWarp(max_time_warp=5, inplace=True, mode=PIL)\r\n    3: FreqMask(F=30, n_mask=2, replace_with_zero=False, inplace=True)\r\n    4: TimeMask(T=40, n_mask=2, replace_with_zero=False, inplace=True))\r\n2022-09-28 09:13:31.002 | INFO     | paddlespeech.s2t.exps.u2.model:setup_dataloader:233 - Setup train/valid Dataloader!\r\n2022-09-28 09:13:31.234 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\", line 56, in <module>\r\n    pr.runcall(main, config, args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/cProfile.py\", line 121, in runcall\r\n    return func(*args, **kw)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\", line 34, in main\r\n    main_sp(config, args)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\", line 29, in main_sp\r\n    exp.setup()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 165, in setup\r\n    self.setup_model()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/model.py\", line 255, in setup_model\r\n    model = U2Model.from_config(model_conf)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 953, in from_config\r\n    model = cls(configs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 861, in __init__\r\n    configs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 906, in _init_from_config\r\n    input_dim, global_cmvn=global_cmvn, **configs['encoder_conf'])\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/modules/encoder.py\", line 468, in __init__\r\n    use_dynamic_left_chunk, max_len)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/modules/encoder.py\", line 130, in __init__\r\n    max_len=max_len), )\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/modules/subsampling.py\", line 114, in __init__\r\n    Conv2D(1, odim, 3, 2),\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/modules/align.py\", line 152, in __init__\r\n    nonlinearity='leaky_relu'))\r\nTypeError: __init__() got an unexpected keyword argument 'negative_slope'\r\nINFO 2022-09-28 09:13:38,447 launch_utils.py:341] terminate all the procs\r\nERROR 2022-09-28 09:13:38,448 launch_utils.py:604] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2022-09-28 09:13:42,451 launch_utils.py:341] terminate all the procs\r\nINFO 2022-09-28 09:13:42,451 launch.py:311] Local processes completed.",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T01:25:41+00:00",
        "updated_at": "2022-09-28T06:08:37+00:00",
        "closed_at": "2022-09-28T06:08:37+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2470,
        "title": "标点恢复example中的预训练模型如何使用",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n官网给出的调用方式是这个\r\n<img width=\"774\" alt=\"image\" src=\"https://user-images.githubusercontent.com/59203496/192670983-6e20cf5c-d26c-474d-84db-6379fbfe31c3.png\">\r\n\r\n但我model=None 实际上会报错，因为后续有一个从model_type 取子字符串的操作。\r\n<img width=\"772\" alt=\"image\" src=\"https://user-images.githubusercontent.com/59203496/192672100-b3018e6d-79fa-44cc-8d00-2cae4a90ff4d.png\">\r\n\r\n然后按照如下的调用方式也会报错，原因应该是无法识别defaut.yaml 文件\r\n<img width=\"773\" alt=\"image\" src=\"https://user-images.githubusercontent.com/59203496/192672373-2e386d46-14c4-48ab-a0db-8168b941e990.png\">\r\n\r\n请问我该如何解决？\r\n",
        "state": "closed",
        "user": "laity-slf",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T02:07:36+00:00",
        "updated_at": "2022-09-29T10:36:28+00:00",
        "closed_at": "2022-09-29T10:36:28+00:00",
        "comments_count": [
            "yt605155624",
            "laity-slf"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2471,
        "title": "使用ecapa-tdnn进行语音克隆报错",
        "body": "![2022-09-28 10-27-22 的屏幕截图](https://user-images.githubusercontent.com/62881198/192674046-4c64e0a4-fb26-4a9d-9382-be28115919f5.png)\r\n如图 使用这个功能报下面的错是什么原因\r\nTraceback (most recent call last):\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 233, in <module>\r\n    main()\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 229, in main\r\n    voice_cloning(args)\r\n  File \"/home/fyy/ResourceCode/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 69, in voice_cloning\r\n    audio_file=input_dir / os.listdir(input_dir)[0], force_yes=True)\r\n  File \"/home/fyy/miniconda3/envs/paddle_env/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\nTypeError: __call__() got an unexpected keyword argument 'force_yes'",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T02:30:55+00:00",
        "updated_at": "2022-09-28T11:14:03+00:00",
        "closed_at": "2022-09-28T11:14:03+00:00",
        "comments_count": [
            "yt605155624",
            "oyb1125"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2472,
        "title": "💫 安装 develop 版本的 paddlespeech",
        "body": "当使用 PaddleSpeech 的某些功能时（主要是 demos 中的功能，examples 里面的代码会强制 source 当前目录所在的 paddlespeech 到 ${PYTHONPATH}，参考 [path.sh](https://github.com/PaddlePaddle/PaddleSpeech/blob/a657cc3e1b5452cc564c9d3ae4bff25717910a49/examples/csmsc/tts3/path.sh#L10)），可能会发现你安装的 release 版本的 paddlespeech 并没有此功能/文件/函数，这是因为我们还没有对此功能进行发版（没有把最新的代码打包成 pip 包发布到 pypi 上），此时你需要安装 develop 版本的 paddlespeech。\r\n请 git clone PaddleSpeech 之后，在 PaddleSpeech 目录执行安装：\r\n```bash\r\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git\r\ncd PaddleSpeech\r\n# 安装依赖和 paddlespeech\r\npip install .\r\n# 不安装依赖仅安装 paddlespeech \r\npython3 setup.py install\r\n```",
        "state": "open",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-28T03:24:20+00:00",
        "updated_at": "2023-02-08T08:08:21+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Installation",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2473,
        "title": "[TTS]XXXXpkg_resources.DistributionNotFound: The 'editdistance' distribution was not found and is required by paddlespeech",
        "body": "pkg_resources.DistributionNotFound: The 'editdistance' distribution was not found and is required by paddlespeech",
        "state": "closed",
        "user": "lucasjinreal",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T06:30:46+00:00",
        "updated_at": "2022-09-29T10:46:20+00:00",
        "closed_at": "2022-09-29T10:46:20+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2474,
        "title": "where is synthesize.py??",
        "body": "where is synthesize.py??",
        "state": "closed",
        "user": "lucasjinreal",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T06:39:45+00:00",
        "updated_at": "2022-09-29T10:36:19+00:00",
        "closed_at": "2022-09-29T10:36:19+00:00",
        "comments_count": [
            "yt605155624",
            "lucasjinreal",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2476,
        "title": "请问语音转文字是否支持选择声道?",
        "body": null,
        "state": "closed",
        "user": "monkeydp",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T10:02:08+00:00",
        "updated_at": "2022-10-09T12:50:43+00:00",
        "closed_at": "2022-10-09T12:50:43+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng",
            "yt605155624",
            "yaleimeng"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2475,
        "title": "标点预测 _clean_text() 函数第二个 sub 多余了",
        "body": "标点预测 `_clean_text()` 函数第二个 sub 多余了，因为第一个 sub 已经把所有标点过滤掉了，该函数完全不需要输入 `punc_list`\r\n\r\n测试代码：\r\n```python3\r\nimport re\r\ndef clean_text(text,punc_list):\r\n    text = text.lower()\r\n    print(\"text0:\",text)\r\n    text = re.sub('[^A-Za-z0-9\\u4e00-\\u9fa5]', '', text)\r\n    print(\"text1:\",text)\r\n    text = re.sub(f'[{\"\".join([p for p in punc_list][1:])}]', '',\r\n                    text)\r\n    print(\"text2:\",text)\r\n    return text\r\n\r\ntext = \"你好，我是飞桨？的程序员。你好吗！\"\r\npunc_list=['，','。','？']\r\nprint(clean_text(text,punc_list))\r\n```\r\noutput:\r\n```text\r\ntext0: 你好，我是飞桨？的程序员。你好吗！\r\ntext1: 你好我是飞桨的程序员你好吗\r\ntext2: 你好我是飞桨的程序员你好吗\r\n你好我是飞桨的程序员你好吗\r\n```\r\n用到的位置：\r\n1. https://github.com/PaddlePaddle/PaddleSpeech/blob/764fa0a8599a6b20c6f719b70bb45a3b4d52b245/paddlespeech/cli/text/infer.py#L205\r\n2. https://github.com/PaddlePaddle/PaddleSpeech/blob/764fa0a8599a6b20c6f719b70bb45a3b4d52b245/paddlespeech/text/exps/ernie_linear/punc_restore.py#L31\r\n\r\n鼓励开发者提交 pr 修改",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-28T07:14:20+00:00",
        "updated_at": "2023-05-20T16:19:46+00:00",
        "closed_at": "2023-05-20T16:19:46+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "good first issue",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2477,
        "title": "s2t数据处理相关",
        "body": "![image](https://user-images.githubusercontent.com/108966996/192758441-e42987fd-16b9-4ba4-a0ea-51a0f8ba5320.png)\r\n请问为什么这里会有2个prepare_dataset,manifest_path有参数无参数是怎么回事呀，",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T10:38:52+00:00",
        "updated_at": "2022-10-12T07:04:13+00:00",
        "closed_at": "2022-10-12T07:04:13+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2479,
        "title": "[S2T] 在example/aishell/asr1中如何fine-tuning？",
        "body": "在 example/aishell/asr1 中，train相关的代码里面，并没有找到如何fine-tuning，请问一下，如何在仓库提供的 asr1_transformer_aishell_ckpt_0.1.1.model.tar.gz 基础上，进行fine-tuning？",
        "state": "closed",
        "user": "Ardang666",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T12:15:53+00:00",
        "updated_at": "2022-10-09T12:49:46+00:00",
        "closed_at": "2022-10-09T12:49:46+00:00",
        "comments_count": [
            "Ardang666",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2480,
        "title": "local variable 'wav_all' referenced before assignment ",
        "body": "在运行语音合成[demo](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/text_to_speech) 的时候报了如下错误：\r\n\r\n`File\"/home/user/.conda/envs/mmlab/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\r\n    result = (True, func(*args, **kwds))\r\n  File \"o2s.py\", line 58, in convertor\r\n    device=paddle.get_device())\r\n  File \"/home/user/yl/PaddleSpeech/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/user/yl/PaddleSpeech/paddlespeech/cli/tts/infer.py\", line 708, in __call__\r\n    self.infer_onnx(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/home/user/yl/PaddleSpeech/paddlespeech/cli/tts/infer.py\", line 537, in infer_onnx\r\n    self._outputs['wav'] = wav_all\r\nUnboundLocalError: local variable 'wav_all' referenced before assignment\r\n`",
        "state": "closed",
        "user": "MingyuLau",
        "closed_by": "yt605155624",
        "created_at": "2022-09-28T13:31:41+00:00",
        "updated_at": "2022-10-12T07:04:03+00:00",
        "closed_at": "2022-10-12T07:04:03+00:00",
        "comments_count": [
            "yt605155624",
            "MingyuLau",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2481,
        "title": "语音识别时能否保留数字",
        "body": "我看文档里有写到这一项功能\r\n\r\n> Supported NSW (Non-Standard-Word) Normalization\r\n\r\n但如果我不希望全部转成中文，想保留数字形式的话，这个能实现吗？",
        "state": "open",
        "user": "dsyrock",
        "closed_by": "stale[bot]",
        "created_at": "2022-09-28T17:23:15+00:00",
        "updated_at": "2023-04-19T14:10:24+00:00",
        "closed_at": null,
        "comments_count": [
            "yaleimeng",
            "yt605155624",
            "SmileGoat",
            "dsyrock",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]",
            "1547481339",
            "yaleimeng"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2483,
        "title": "[TTS]examples/aishell3/vits-vc训练的模型为啥效果不好？啥时候出训练模型结果文件?",
        "body": "目录examples/aishell3/vits-vc训练的模型为啥效果不好？V100单卡GPU训练了3天，mel_loss下不来一直在26左右徘徊。可以给出你们paddlespeech训练好的模型文件瞅瞅么？\r\n日志示例：\r\nINFO 2022-09-20 10:58:28,841 trainer.py:167]  iter: 74635/350000, Rank: 0, real_loss: 1.203158, fake_loss: 1.163633, discriminator_loss: 2.366791, g\r\nenerator_loss: 35.696995, generator_mel_loss: 25.517664, generator_kl_loss: 1.996764, generator_dur_loss: 2.306179, generator_adv_loss: 2.221788, ge\r\nnerator_feat_match_loss: 3.654603, avg_reader_cost: 0.00034 sec, avg_batch_cost: 2.39460 sec, avg_samples: 50, avg_ips: 20.88035 sequences/sec\r\nINFO 2022-09-20 10:58:31,169 trainer.py:167]  iter: 74636/350000, Rank: 0, real_loss: 1.248867, fake_loss: 1.126140, discriminator_loss: 2.375007, g\r\nenerator_loss: 36.339199, generator_mel_loss: 26.522982, generator_kl_loss: 1.727793, generator_dur_loss: 2.320811, generator_adv_loss: 2.271485, ge\r\nnerator_feat_match_loss: 3.496129, avg_reader_cost: 0.00029 sec, avg_batch_cost: 2.31373 sec, avg_samples: 50, avg_ips: 21.61016 sequences/sec \r\nINFO 2022-09-20 10:58:33,541 trainer.py:167]  iter: 74637/350000, Rank: 0, real_loss: 1.228455, fake_loss: 1.174015, discriminator_loss: 2.402470, g\r\nenerator_loss: 36.243534, generator_mel_loss: 26.122320, generator_kl_loss: 2.049680, generator_dur_loss: 2.297820, generator_adv_loss: 2.229776, ge\r\nnerator_feat_match_loss: 3.543939, avg_reader_cost: 0.00036 sec, avg_batch_cost: 2.35778 sec, avg_samples: 50, avg_ips: 21.20636 sequences/sec\r\nINFO 2022-09-20 10:58:35,905 trainer.py:167]  iter: 74638/350000, Rank: 0, real_loss: 1.233365, fake_loss: 1.132419, discriminator_loss: 2.365783, g\r\nenerator_loss: 36.313385, generator_mel_loss: 26.273182, generator_kl_loss: 1.906548, generator_dur_loss: 2.294973, generator_adv_loss: 2.265149, ge\r\nnerator_feat_match_loss: 3.573530, avg_reader_cost: 0.00030 sec, avg_batch_cost: 2.35022 sec, avg_samples: 50, avg_ips: 21.27463 sequences/sec\r\nINFO 2022-09-20 10:58:38,317 trainer.py:167]  iter: 74639/350000, Rank: 0, real_loss: 1.166814, fake_loss: 1.176862, discriminator_loss: 2.343676, g\r\nenerator_loss: 36.301010, generator_mel_loss: 26.083799, generator_kl_loss: 1.860562, generator_dur_loss: 2.323201, generator_adv_loss: 2.231595, ge\r\nnerator_feat_match_loss: 3.801853, avg_reader_cost: 0.00038 sec, avg_batch_cost: 2.39805 sec, avg_samples: 50, avg_ips: 20.85030 sequences/sec\r\nINFO 2022-09-20 10:58:40,702 trainer.py:167]  iter: 74640/350000, Rank: 0, real_loss: 1.215568, fake_loss: 1.201060, discriminator_loss: 2.416629, g\r\nenerator_loss: 35.916458, generator_mel_loss: 25.964396, generator_kl_loss: 1.874138, generator_dur_loss: 2.341110, generator_adv_loss: 2.173471, ge\r\nnerator_feat_match_loss: 3.563343, avg_reader_cost: 0.00039 sec, avg_batch_cost: 2.37029 sec, avg_samples: 50, avg_ips: 21.09451 sequences/sec \r\nINFO 2022-09-20 10:58:43,096 trainer.py:167]  iter: 74641/350000, Rank: 0, real_loss: 1.245020, fake_loss: 1.108281, discriminator_loss: 2.353301, g\r\nenerator_loss: 36.572319, generator_mel_loss: 26.206434, generator_kl_loss: 2.026091, generator_dur_loss: 2.339233, generator_adv_loss: 2.298341, ge\r\nnerator_feat_match_loss: 3.702222, avg_reader_cost: 0.00032 sec, avg_batch_cost: 2.37950 sec, avg_samples: 50, avg_ips: 21.01280 sequences/sec\r\nINFO 2022-09-20 10:58:45,468 trainer.py:167]  iter: 74642/350000, Rank: 0, real_loss: 1.271199, fake_loss: 1.184860, discriminator_loss: 2.456059, g\r\nenerator_loss: 35.333931, generator_mel_loss: 25.618114, generator_kl_loss: 1.949838, generator_dur_loss: 2.322937, generator_adv_loss: 2.159736, ge\r\nnerator_feat_match_loss: 3.283306, avg_reader_cost: 0.00031 sec, avg_batch_cost: 2.35818 sec, avg_samples: 50, avg_ips: 21.20278 sequences/sec",
        "state": "closed",
        "user": "liukaiyueyuo",
        "closed_by": "yt605155624",
        "created_at": "2022-09-29T02:21:00+00:00",
        "updated_at": "2022-10-09T12:49:00+00:00",
        "closed_at": "2022-10-09T12:49:00+00:00",
        "comments_count": [
            "yt605155624",
            "liukaiyueyuo"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2492
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2485,
        "title": "ImportError: cannot import name 'norm' from 'paddlespeech.t2s.exps.syn_utils' (/opt/conda/envs/paddlespeech/lib/python3.7/site-packages/paddlespeech/t2s/exps/syn_utils.py)",
        "body": "在做ERNIE-SAT 个性化合成体验的时候，按照流程走的时候，出现这个问题，我看了下syn_utils的源码，里面没有norm这个实例。",
        "state": "closed",
        "user": "kq-cheng",
        "closed_by": "kq-cheng",
        "created_at": "2022-09-29T06:57:26+00:00",
        "updated_at": "2022-09-29T07:11:36+00:00",
        "closed_at": "2022-09-29T07:11:12+00:00",
        "comments_count": [
            "yt605155624",
            "kq-cheng"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2486,
        "title": "参数问题",
        "body": "请问run.sh里面的ips变量的意义是什么\r\n-->\r\n",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-09-29T07:18:55+00:00",
        "updated_at": "2022-09-29T10:45:32+00:00",
        "closed_at": "2022-09-29T10:45:32+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123",
            "yt605155624",
            "AlphaMind123",
            "AlphaMind123",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2487,
        "title": "[TTS]PaddleLite&MNN离线推理转换问题",
        "body": "想把TTS做离线，尝试了以下两种方式：\r\n## 1、MNN转换：fastspeech2_mix onnx模型错误\r\n\r\n`\r\nError for compute convolution shape, inputCount:1536, outputCount:384, KH:1, KW:3, group:1\r\ninputChannel: 0, batch:1536, width:0, height:0. Input data channel may be mismatch with filter channel count\r\n`\r\n\r\n## 2、PaddleLite转换：显示不支持算子和量化错误\r\n### fastspeech2错误\r\n`\r\nError: This model is not supported, because 3 ops are not supported on 'arm'. These unsupported ops are: 'round, set_value, share_data'.\r\n`\r\n\r\n### pwgan错误\r\n如果不进行量化能够正常导出，加上量化选项--quant_type=QUANT_INT8显示\r\n\r\n`\r\n1.Model is successfully loaded!\r\n Segmentation fault (core dumped)\r\n`",
        "state": "closed",
        "user": "yazone",
        "closed_by": "lym0302",
        "created_at": "2022-09-29T08:12:37+00:00",
        "updated_at": "2022-11-21T07:28:39+00:00",
        "closed_at": "2022-11-21T07:28:39+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "yazone",
            "yt605155624",
            "yazone",
            "yt605155624",
            "yazone",
            "yt605155624",
            "yazone",
            "yt605155624",
            "yazone",
            "yt605155624",
            "QShiX",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2490,
        "title": "使用ONNXRuntime推理的cpu_thread和python多线程的线程数是什么关系，会起冲突吗？",
        "body": "在用文本数据合成语音的时候使用了ONNXRuntime推理的模型：\r\n`tts_executor = TTSExecutor()\r\n    wav_file = tts_executor(\r\n        text=text,\r\n        output=outputpath,\r\n        am='fastspeech2_vctk',\r\n        voc='hifigan_ljspeech',\r\n        lang='en',\r\n        use_onnx=True,\r\n        cpu_threads=14)`\r\n同时我将python多线程的pool的WORKERS数量也设置为14，请问这两个之间会发生冲突吗？",
        "state": "closed",
        "user": "MingyuLau",
        "closed_by": "yt605155624",
        "created_at": "2022-09-30T07:50:27+00:00",
        "updated_at": "2022-10-09T12:48:42+00:00",
        "closed_at": "2022-10-09T12:48:42+00:00",
        "comments_count": [
            "yt605155624",
            "MingyuLau"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2491,
        "title": "🎉  PaddleSpeech 实现多种卡通音色和方言的中英文混合 TTS",
        "body": "实现单模型TTS中英文发音初步尝试了3种方案：单发音人方式、多发音人语料混合方式、finetune方式。\r\n\r\n示例句子：\r\n```text\r\n大家好，我是parrot虚拟老师，我们来读一首诗，我与春风皆过客， I and the spring breeze are passing by,你携秋水揽星河， you take the autumn water to take the galaxy。\r\n```\r\n\r\n## （一）单发音人方式（有数据才行！）\r\n使用同一发音人中文、英文语料，这种方式效果最佳，听听效果：\r\n\r\n中英文女：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193219058-5a98685b-c93d-4c74-8356-914c781b4d27.mp4\r\n\r\n\r\n中英文男：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193215189-501ab75b-7eca-4675-a304-2ad7488922a5.mp4\r\n\r\n## （二）多发音人语料混合方式（音色串了！）\r\n有开源数据中文baker、英文ljspeech数据，将数据混合成单发音人训练出一个模型，能听出一句话中文是baker、英文是ljspecch两种音色，我想音色差别不大的时候可以选用这种方式，听听效果：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193216645-30394fd8-d4e4-4e4b-9612-436f130cfad9.mp4\r\n\r\n\r\n## （三）finetune方式（音色一致了！）\r\n在第一种中英文预训练模型上进行finetune，实现特色语音、动漫语音、方言，效果如下：\r\n\r\n### 特色普通话\r\nBaker说中英文：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193209914-fdc5e771-c7bc-4be3-b6ef-00016f0089a5.mp4\r\n\r\n抖音鸡汤女说中英文：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193210117-774d58e4-eefd-4c8a-8018-826fc2b1d4ae.mp4\r\n\r\n### 动漫\r\n\r\n蜡笔小新说中英文：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193217824-2eda00ba-1760-4da9-adf9-91beae36cd36.mp4\r\n\r\n海绵宝宝说中英文：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218064-f0111d64-7d6d-4e2a-918e-58ebe228b9cb.mp4\r\n\r\n### 方言\r\n东北话：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218466-4213202a-b3ac-4ce6-9d8f-cd09e641c155.mp4\r\n\r\n广西话：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218528-f191e296-fb64-4cfc-90a0-22407c04eb2c.mp4\r\n\r\n河南话：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218587-0a5cd848-c6ae-44e5-956f-980e9f233bd7.mp4\r\n\r\n四川话：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218647-84c18656-de58-499e-a180-67b2aae1b9b3.mp4\r\n\r\n天津话：\r\n\r\nhttps://user-images.githubusercontent.com/10195479/193218707-944f5801-2894-4e64-83c2-c92176df63cb.mp4\r\n\r\n粤语：\r\n\r\nhttps://user-images.githubusercontent.com/24568452/193232486-25b64f7a-164a-4433-8e7e-02f11c4036d4.mp4\r\n\r\n<br>\r\n\r\n后续是否可以在第二种方案的模型上进行finetune达到好的效果再进行验证，这样就不需要单发音人的中英文预训练模型了，只需要开源数据就OK了。\r\n\r\n**×××××××××××PaddleTTS实现起来还是很方便的，感谢各位大佬...××××××××××**\r\n",
        "state": "closed",
        "user": "yazone",
        "closed_by": null,
        "created_at": "2022-09-30T08:02:42+00:00",
        "updated_at": "2022-09-30T08:58:28+00:00",
        "closed_at": "2022-09-30T08:58:28+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2494,
        "title": "关于语音识别预训练模型的加载问题",
        "body": "## General Question\r\n请问我在PaddleSpeech\\examples\\aishell\\asr1 路径下的训练时，我想要加载预训练权重，通过\r\nwget https://paddlespeech.bj.bcebos.com/s2t/aishell/asr1/asr1_transformer_aishell_ckpt_0.1.1.model.tar.gz\r\ntar xzvf asr1_transformer_aishell_ckpt_0.1.1.model.tar.gz\r\nsource path.sh\r\n当我执行上面的语句时，执行到source path.sh ,提示我The standard file /home/aistudio/PaddleSpeech/tools/kaldi/tools/config/common_path.sh is not present, can not using Kaldi!\r\n我很疑惑为什么没有这个文件，是不是我遗漏了什么步骤\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "NICECPU",
        "closed_by": "yt605155624",
        "created_at": "2022-10-02T09:08:24+00:00",
        "updated_at": "2022-10-09T02:06:43+00:00",
        "closed_at": "2022-10-09T02:06:43+00:00",
        "comments_count": [
            "Ardang666",
            "NICECPU"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2496,
        "title": "stage2报错",
        "body": "![image](https://user-images.githubusercontent.com/108966996/194043849-3559e977-b035-42a8-90d7-e62f86f8d2ec.png)\r\nWhy are errors reported in stage2 ？Thank you.",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-10-05T10:52:43+00:00",
        "updated_at": "2022-10-10T02:39:28+00:00",
        "closed_at": "2022-10-10T02:39:28+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2497,
        "title": "windows 下安装报错",
        "body": "Using legacy 'setup.py install' for pyworld, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for resampy, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for kaldiio, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for pattern-singleton, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for webrtcvad, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for audioread, since package 'wheel' is not installed.\r\nUsing legacy 'setup.py install' for distance, since package 'wheel' is not installed.\r\nInstalling collected packages: webrtcvad, timer, textgrid, opencc, flatbuffers, distance, braceexpand, appdirs, yacs, win32-setctime, websockets, typeguard, tabulate, regex, pypinyin, pycparser, pybind11, prettytable, praatio, ppft, pox, portalocker, pattern-singleton, onnxruntime, mock, lxml, llvmlite, kaldiio, jsonlines, h5py, g2pM, editdistance, cython, bottleneck, audioread, sacrebleu, pyworld, pypinyin-dict, pooch, pathos, paddlespeech-feat, numba, nltk, loguru, inflect, cffi, soundfile, resampy, g2p-en, nara-wpe, librosa, paddlespeech\r\n  Running setup.py install for webrtcvad ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Running setup.py install for webrtcvad did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [9 lines of output]\r\n      running install\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\\lib.win-amd64-3.8\r\n      copying webrtcvad.py -> build\\lib.win-amd64-3.8\r\n      running build_ext\r\n      building '_webrtcvad' extension\r\n      error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n× Encountered error while trying to install package.\r\n╰─> webrtcvad\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.2.2\r\n[notice] To update, run: c:\\users\\l\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip\r\n",
        "state": "closed",
        "user": "lvsh2012",
        "closed_by": "yt605155624",
        "created_at": "2022-10-06T05:26:25+00:00",
        "updated_at": "2022-10-09T02:10:08+00:00",
        "closed_at": "2022-10-09T02:10:08+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2495,
        "title": "包问题",
        "body": "![image](https://user-images.githubusercontent.com/108966996/193975287-df3f3e0e-92ba-4eda-b872-9954d5919913.png)\r\n为什么我这样安装包之后它还是会显示没有这个module\r\n![image](https://user-images.githubusercontent.com/108966996/193975360-8a5d95a3-b0e5-40c3-be01-ef3b371d79bb.png)\r\n",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "AlphaMind123",
        "created_at": "2022-10-05T03:29:39+00:00",
        "updated_at": "2022-10-08T02:38:28+00:00",
        "closed_at": "2022-10-08T02:38:27+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123",
            "AlphaMind123"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2498,
        "title": "合成语言有没有字数限制?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "lvsh2012",
        "closed_by": "yt605155624",
        "created_at": "2022-10-07T14:45:18+00:00",
        "updated_at": "2022-10-09T12:48:27+00:00",
        "closed_at": "2022-10-09T12:48:27+00:00",
        "comments_count": [
            "yaleimeng",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2503,
        "title": "[S2T] FatalError: `Erroneous arithmetic operation` is detected by the operating system.",
        "body": "您好，我按安装教程拉取官网dockers安装。[develop-gpu-cuda11.2-cudnn8-latest]\r\n之后按example/aishell/sr1 的教程，bash run.sh --stage 1 --stop_stage 1时，出现以下错误：\r\nTypeError: __init__() got an unexpected keyword argument 'negative_slope'\r\n参考其他issues，将paddle2.3.0-gpu升级为2.3.1-gpu，主机环境为A100、CUDA Version: 11.2，结果出现以下错误：\r\n。。。\r\n2022-10-08 07:16:43.986 | INFO     | paddlespeech.s2t.training.optimizer:from_args:120 - <Optimizer paddle.optimizer.adam.Adam> LR: WarmupLR(warmup_steps=25000, lr=0.002, last_epoch=0)\r\n2022-10-08 07:16:43.986 | INFO     | paddlespeech.s2t.exps.u2.model:setup_model:304 - Setup optimizer/lr_scheduler!\r\n2022-10-08 07:16:43.987 | INFO     | paddlespeech.s2t.training.trainer:resume_or_scratch:225 - Init from scratch!\r\n2022-10-08 07:16:44.464 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:286 - Saved model to exp/conformer/checkpoints/init.pdparams\r\n2022-10-08 07:16:44.466 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:292 - Saved optimzier state to exp/conformer/checkpoints/init.pdopt\r\n2022-10-08 07:16:44.466 | INFO     | paddlespeech.s2t.exps.u2.model:do_train:160 - Train Total Examples: 30025\r\n/home/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:48: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:50: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:48: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:50: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)\r\n1   void paddle::imperative::Tracer::TraceOpImpl<paddle::imperative::VarBase>(std::string const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::framework::AttributeMap&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, paddle::framework::AttributeMap*, bool)\r\n2   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&, paddle::framework::AttributeMap const&)\r\n3   void phi::ArangeKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Erroneous arithmetic operation` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1665213404 (unix time) try \"date -d @1665213404\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGFPE (@0x7ff9b1daf5f3) received by PID 1460 (TID 0x7ffa0b562740) from PID 18446744072398501363 ***]\r\n\r\nINFO 2022-10-08 07:16:59,575 launch_utils.py:343] terminate all the procs\r\nINFO 2022-10-08 07:16:59,575 launch_utils.py:343] terminate all the procs\r\nERROR 2022-10-08 07:16:59,575 launch_utils.py:642] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nERROR 2022-10-08 07:16:59,575 launch_utils.py:642] ABORT!!! Out of all 1 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2022-10-08 07:17:03,579 launch_utils.py:343] terminate all the procs\r\nINFO 2022-10-08 07:17:03,579 launch_utils.py:343] terminate all the procs\r\nINFO 2022-10-08 07:17:03,579 launch.py:402] Local processes completed.\r\nINFO 2022-10-08 07:17:03,579 launch.py:402] Local processes completed.\r\n\r\n",
        "state": "closed",
        "user": "MoYinYu",
        "closed_by": "MoYinYu",
        "created_at": "2022-10-08T07:47:12+00:00",
        "updated_at": "2022-10-09T07:19:22+00:00",
        "closed_at": "2022-10-09T07:19:22+00:00",
        "comments_count": [
            "yt605155624",
            "MoYinYu"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2504,
        "title": "TTS微调完后，如何使用style_fs2改变语速，我试着按照style_fs2的文档把fastspeech2模型换成自己的，但是一直报OOM",
        "body": "python3 style_syn.py \r\n--fastspeech2-config\r\n=/opt/ml/server/PaddleSpeechserver/demos/speech_web/speech_server/tmp_dir/finetune/trans/exp/default.yaml \r\n--fastspeech2-checkpoint\r\n=/opt/ml/server/PaddleSpeechserver/demos/speech_web/speech_server/tmp_dir/finetune/trans/exp/checkpoints/snapshot_iter_120292.pdz \r\n--fastspeech2-stat=download/fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy         \r\n--fastspeech2-pitch-stat=download/fastspeech2_nosil_baker_ckpt_0.4/pitch_stats.npy         \r\n--fastspeech2-energy-stat=download/fastspeech2_nosil_baker_ckpt_0.4/energy_stats.npy         \r\n--pwg-config=download/pwg_baker_ckpt_0.4/pwg_default.yaml         \r\n--pwg-checkpoint=download/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz         \r\n--pwg-stat=download/pwg_baker_ckpt_0.4/pwg_stats.npy \r\n--text=/opt/ml/server/PaddleSpeechserver/demos/speech_web/speech_server/tmp_dir/finetune/trans/sentences.txt \r\n--output-dir=output --phones-dict=download/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt\r\n\r\n其中fastspeech2-config和fastspeech2-checkpoint是我自己微调的模型，其他的没变。那几个npy文件不知道怎么生成，是npy引起的OOM吗。设置GPU自增长不管用，改用cpu也是内存错误",
        "state": "closed",
        "user": "kq-cheng",
        "closed_by": "kq-cheng",
        "created_at": "2022-10-08T07:52:56+00:00",
        "updated_at": "2022-12-08T15:14:05+00:00",
        "closed_at": "2022-10-09T06:47:35+00:00",
        "comments_count": [
            "yt605155624",
            "kq-cheng",
            "Christophy",
            "SG-XM"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2506,
        "title": "[TTS] TextExecutor().text_punc(text=\"xx\")异常退出",
        "body": "没有任何错误输出，直接退出，gpu有2G，只用到了几百兆\r\nwin11，NVIDIA Quadro M620， device: 0, GPU Compute Capability: 5.0, Driver API Version: 11.7, Runtime API Version: 11.7，cuDNN Version: 8.5，cuda-toolkit-cuda_11.7.1_516.94_windows，cuda-driver-517.40-quadro-rtx-desktop-notebook-win10-win11-64bit-international-dch-whql，nvidia cuda 11.7.102 driver\r\npaddle-bfloat 0.1.7\r\npaddle2onnx 1.0.1\r\npaddleclas 2.4.3\r\npaddlefsl 1.1.0\r\npaddlehub 2.3.0\r\npaddlenlp 2.4.0\r\npaddleocr 2.6\r\npaddlepaddle-gpu 2.4.0rc0.post117\r\npaddleslim 2.2.1\r\npaddlespeech 1.1.3\r\npaddlespeech-feat 0.1.0\r\npaddlex 2.1.0\r\n\r\n\r\n\r\n(paddle) G:\\work_py\\notebook\\paddle\\PaddleSpeech>python\r\nPython 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 05:35:01) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from paddlespeech.cli.text.infer import TextExecutor\r\n>>> text_punc = TextExecutor()\r\n>>> result = text_punc(text=\"今天的天气真不错啊你下午有空吗我想约你一起去吃饭\")\r\nE:\\pfile\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\image_utils.py:213: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\r\n  resample=Image.BILINEAR,\r\nE:\\pfile\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\image_utils.py:379: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\r\n  resample=Image.NEAREST,\r\nE:\\pfile\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\ernie_vil\\feature_extraction.py:65: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  resample=Image.BICUBIC,\r\nE:\\pfile\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddlenlp\\transformers\\clip\\feature_extraction.py:64: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  resample=Image.BICUBIC,\r\nW1008 20:29:08.600579  3124 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 5.0, Driver API Version: 11.7, Runtime API Version: 11.7\r\nW1008 20:29:08.613807  3124 gpu_resources.cc:91] device: 0, cuDNN Version: 8.5.\r\n(paddle) G:\\work_py\\notebook\\paddle\\PaddleSpeech>",
        "state": "closed",
        "user": "liuyang77886",
        "closed_by": "liuyang77886",
        "created_at": "2022-10-08T12:34:31+00:00",
        "updated_at": "2024-05-23T13:19:03+00:00",
        "closed_at": "2022-10-09T12:57:56+00:00",
        "comments_count": [
            "yt605155624",
            "liuyang77886",
            "liuyang77886",
            "yt605155624",
            "liuyang77886",
            "abcdbosh"
        ],
        "labels": [
            "Bug",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2505,
        "title": "[TTS]空白文本、文本中连续多个符号合成语音报错，无法正常合成",
        "body": "tts_python、tts_inference合成的文本存在以下情况时会直接报错，无法正常合成\r\n1. 文本为空白字符串时，如：\"\"、\"   \"\r\n2. 文本中首部有符号时，如：\"，\"、\"，测试\"\r\n3. 文本中有连续的符号时，如：\"测试，，\"、\"测试，。\"、\"测试。“。\"\r\n\r\n![image](https://user-images.githubusercontent.com/3991083/194697566-710c5c29-1aa1-4b01-9d3e-15f7ce7cab36.png)\r\n",
        "state": "open",
        "user": "tianyu8969",
        "closed_by": null,
        "created_at": "2022-10-08T08:17:00+00:00",
        "updated_at": "2022-10-12T07:07:15+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "yt605155624",
            "tianyu8969",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2507,
        "title": "test输出问题",
        "body": "\r\n![image](https://user-images.githubusercontent.com/108966996/194707961-cd017d97-5c36-4ee8-a7c2-e6db41ae7f07.png)\r\n\r\n运行stage3test的时候，输出打印为什么hyp是空的\r\n",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-10-08T12:37:48+00:00",
        "updated_at": "2022-10-09T12:43:52+00:00",
        "closed_at": "2022-10-09T12:43:52+00:00",
        "comments_count": [
            "Zth9730",
            "AlphaMind123",
            "Zth9730",
            "AlphaMind123"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2514
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2508,
        "title": "asr1中stage2",
        "body": "asr1中stage2取前k个模型参数进行平均的依据是不是利用dev文件夹下的数据进行测试的结果，如果不是那么dev是用在什么地方的",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-10-08T14:49:28+00:00",
        "updated_at": "2022-10-09T12:44:00+00:00",
        "closed_at": "2022-10-09T12:44:00+00:00",
        "comments_count": [
            "AlphaMind123",
            "AlphaMind123",
            "Zth9730",
            "AlphaMind123"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2516
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2515
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2509,
        "title": "有关标点符号的训练问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n就是在我使用自己数据训练的时候发现，后面的文字他不会进行标点恢复。\r\n比如：\r\nPunctuation Restoration Result: 新华社北京10月8日电记者从有关方面获悉，中国共产党第二十次全国代表大会新闻中心将于10月12日启用，并开始对外接待服务新闻中心记者接待服务区设在北京新世纪日航饭店新闻中心将热情为前来采访党的二十大的香港特别行政区澳门特别行政区台湾地区的媒体记者和外国媒体记者办理采访证件受理采访申请组织大会新闻发布会和记者招待会安排记者参加大会采访活动。\r\n\r\n造成这个现象的原因是模型没有收敛么？？？\r\n\r\n但是我看loss其实已经在震荡了。\r\n\r\n数据采用的是清华新闻数据集：\r\n部分数据如下，我对字符数少于20个的行会直接过滤；\r\n<img width=\"976\" alt=\"image\" src=\"https://user-images.githubusercontent.com/59203496/194716083-05ad3302-9e62-452b-8aa3-9b631fbcd435.png\">\r\n\r\n有没有大佬给个意见=-=\r\n我先多train 几个epoch看看\r\n",
        "state": "closed",
        "user": "laity-slf",
        "closed_by": "yt605155624",
        "created_at": "2022-10-08T15:52:30+00:00",
        "updated_at": "2022-10-10T02:18:30+00:00",
        "closed_at": "2022-10-10T02:18:30+00:00",
        "comments_count": [
            "zh794390558",
            "laity-slf",
            "zh794390558",
            "laity-slf",
            "yt605155624",
            "laity-slf",
            "yt605155624",
            "laity-slf",
            "yt605155624",
            "laity-slf"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2512,
        "title": "❗❗[Server]declarative() got an unexpected keyword argument 'property'",
        "body": "按照官网教程：https://aistudio.baidu.com/aistudio/projectdetail/4668770?forkThirdPart=1\r\n在服务器端部署paddle时：\r\n\r\n# 进入根目录\r\ncd /home/aistudio/PaddleSpeech\r\n# 开启服务\r\npaddlespeech_server start --config_file ./paddlespeech/server/conf/application.yaml\r\n\r\n报错显示：\r\n[2022-10-09 11:30:23,153] [    INFO] - start to init the engine\r\n[2022-10-09 11:30:23,154] [    INFO] - asr : python engine.\r\n[2022-10-09 11:30:31,894] [   ERROR] - Failed to start server.\r\n[2022-10-09 11:30:31,895] [   ERROR] - declarative() got an unexpected keyword argument 'property'\r\n\r\n求解，个人猜测可能是版本问题遗留的一个bug？\r\n",
        "state": "closed",
        "user": "Plutoisme",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-09T03:33:46+00:00",
        "updated_at": "2023-04-05T06:28:25+00:00",
        "closed_at": "2023-01-21T04:45:36+00:00",
        "comments_count": [
            "yt605155624",
            "Plutoisme",
            "zh794390558",
            "yt605155624",
            "JYCcx",
            "yt605155624",
            "stale[bot]",
            "stale[bot]",
            "shenhua4286"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2513,
        "title": "[STT] downloading of  deepspeech2offline_librispeech is too slow",
        "body": "I am on Ubuntu 20.04 platform. I live in Türkiye. I installed `PaddleSpeech` via `pip`.\r\n\r\nWhen I want to test offline model with:\r\n\r\n        paddlespeech asr --model deepspeech2offline_librispeech --lang en --input ./en.wav -v\r\n\r\nit starts to download but it's extremely slow around 300KB. \r\nIs it possible for me to download the speech model manually and extract it to `PaddleSpeech`'s directory (I don't know where)?\r\nBest regards.",
        "state": "closed",
        "user": "trappedinspacetime",
        "closed_by": "yt605155624",
        "created_at": "2022-10-09T14:03:46+00:00",
        "updated_at": "2022-10-10T02:18:16+00:00",
        "closed_at": "2022-10-10T02:18:16+00:00",
        "comments_count": [
            "yt605155624",
            "trappedinspacetime"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2517,
        "title": "[S2T]基于aishell数据训练的U2模型（transformer）的CER达到23.9%",
        "body": "你好，我用这里相应的配置和流程，训练aishell数据的ASR模型（U2模型（transformer）），测试出来的CER达到23%。请问自己训练的效果为啥这么差啊。配置没有变动。epoch==30.\r\n我是按照这个训练的：https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-10T11:40:13+00:00",
        "updated_at": "2023-01-21T04:45:37+00:00",
        "closed_at": "2023-01-21T04:45:37+00:00",
        "comments_count": [
            "yt605155624",
            "Tian14267",
            "Tian14267",
            "zh794390558",
            "AlphaMind123",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2519,
        "title": "看不明白发生啥了",
        "body": "D:\\PaddleSpeech-develop\\demos\\speech_web\\speech_server>python main.py --port 8010\r\n2022-10-11 03:52:59.439 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 11004] getaddrinfo failed>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 11004]\r\n[nltk_data]     getaddrinfo failed>\r\nINFO 2022-10-11 03:53:02,951 loader.py:54] Loading faiss with AVX2 support.\r\nINFO 2022-10-11 03:53:02,951 loader.py:58] Could not load library with AVX2 support due to:\r\nModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\r\nINFO 2022-10-11 03:53:02,951 loader.py:64] Loading faiss.\r\nINFO 2022-10-11 03:53:03,085 loader.py:66] Successfully loaded faiss.\r\n[2022-10-11 03:53:03,398] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'source/model'.\r\nW1011 03:53:03.420004 13704 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.6\r\nW1011 03:53:03.421998 13704 dynamic_loader.cc:276] Note: [Recommend] copy cudnn into CUDA installation directory.\r\n For instance, download cudnn-10.0-windows10-x64-v7.6.5.32.zip from NVIDIA's official website,\r\nthen, unzip it and copy it into C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\r\nYou should do this according to your CUDA installation directory and CUDNN version.\r\nTraceback (most recent call last):\r\n  File \"D:\\PaddleSpeech-develop\\demos\\speech_web\\speech_server\\main.py\", line 65, in <module>\r\n    chatbot = Robot(\r\n  File \"D:\\PaddleSpeech-develop\\demos\\speech_web\\speech_server\\src\\robot.py\", line 17, in __init__\r\n    self.nlp = NLP(ie_model_path=ie_model_path)\r\n  File \"D:\\PaddleSpeech-develop\\demos\\speech_web\\speech_server\\src\\SpeechBase\\nlp.py\", line 8, in __init__\r\n    self.ie_model = Taskflow(\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\taskflow\\taskflow.py\", line 513, in __init__\r\n    self.task_instance = task_class(model=self.model,\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\taskflow\\information_extraction.py\", line 361, in __init__\r\n    self._get_inference_model()\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\taskflow\\task.py\", line 228, in _get_inference_model\r\n    self._construct_model(self.model)\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\taskflow\\information_extraction.py\", line 419, in _construct_model\r\n    model_instance = UIE.from_pretrained(self._task_path)\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\transformers\\model_utils.py\", line 348, in from_pretrained\r\n    base_model = cls.base_model_class(*base_args, **base_kwargs)\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\transformers\\utils.py\", line 159, in __impl__\r\n    init_func(self, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\transformers\\ernie\\modeling.py\", line 841, in __init__\r\n    self.embeddings = ErnieEmbeddings(vocab_size, hidden_size,\r\n  File \"C:\\Program Files\\Python39\\lib\\site-packages\\paddlenlp\\transformers\\ernie\\modeling.py\", line 59, in __init__\r\n    self.word_embeddings = nn.Embedding(vocab_size,\r\n  File \"C:\\Users\\Ydroxy\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\nn\\layer\\common.py\", line 1453, in __init__\r\n    self.weight = self.create_parameter(\r\n  File \"C:\\Users\\Ydroxy\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 423, in create_parameter\r\n    return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\r\n  File \"C:\\Users\\Ydroxy\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\fluid\\layer_helper_base.py\", line 376, in create_parameter\r\n    return self.main_program.global_block().create_parameter(\r\n  File \"C:\\Users\\Ydroxy\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\fluid\\framework.py\", line 3572, in create_parameter\r\n    initializer(param, self)\r\n  File \"C:\\Users\\Ydroxy\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\fluid\\initializer.py\", line 472, in __call__\r\n    out_var = _C_ops.truncated_gaussian_random(\r\nRuntimeError: (PreconditionNotMet) The third-party dynamic library (cudnn64_8.dll) that Paddle depends on is not configured correctly. (error code is 126)\r\n  Suggestions:\r\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure third-party dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX; (at ..\\paddle\\phi\\backends\\dynload\\dynamic_loader.cc:303)\r\n  [operator < truncated_gaussian_random > error]\r\n\r\nD:\\PaddleSpeech-develop\\demos\\speech_web\\speech_server>\r\n",
        "state": "closed",
        "user": "ydroxy",
        "closed_by": "yt605155624",
        "created_at": "2022-10-10T19:54:39+00:00",
        "updated_at": "2022-10-17T09:15:20+00:00",
        "closed_at": "2022-10-17T09:15:20+00:00",
        "comments_count": [
            "ydroxy",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2520,
        "title": "英伟达官方无此安装包  CuDNN7.5 (for  CUDA 10.2)",
        "body": "##  install_cn.md 写gpu2.4rc依赖是 CUDA 10.2， CuDNN7.5 \r\n\r\n通过看英伟达官方提供的 [cudnn列表](https://developer.nvidia.com/rdp/cudnn-archive)，没发现 CuDNN7.5  for cuda10.2；\r\n\r\n所以你们的 [install_cn.md ](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/install_cn.md)文件是否编写有误？\r\n\r\n如果是paddle自己编译或者开发的 cudnn，可否提供一下下载链接？\r\n\r\n",
        "state": "closed",
        "user": "312shan",
        "closed_by": "yt605155624",
        "created_at": "2022-10-11T02:21:27+00:00",
        "updated_at": "2022-10-11T06:19:55+00:00",
        "closed_at": "2022-10-11T06:19:55+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2523,
        "title": "[TTS]合成语音怎么改变语速",
        "body": "在仓库搜索了change_speed函数，但是还是不太会用，请问有没有详细一点的说明",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "yt605155624",
        "created_at": "2022-10-12T01:36:12+00:00",
        "updated_at": "2022-10-12T01:41:01+00:00",
        "closed_at": "2022-10-12T01:41:01+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2521,
        "title": "安装paddlespeech报错",
        "body": "**安装方法**\r\n安装指导中的【[简单](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/install_cn.md#%E7%AE%80%E5%8D%95-%E8%8E%B7%E5%8F%96%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD%E6%94%AF%E6%8C%81-linuxmac-%E5%92%8C-windows)】方法，\r\npaddlepaddle-gpu==2.3.0版本\r\n安装命令如下：\r\npip install pytest-runner -i https://pypi.tuna.tsinghua.edu.cn/simple \r\npip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n\r\n**出现报错信息：**\r\nERROR: Cannot install paddlespeech==0.0.1a0, paddlespeech==0.0.2a0, paddlespeech==0.1.0a0, paddlespeech==0.1.0a1, paddlespeech==0.1.0a2, paddlespeech==0.1.0a3, paddlespeech==0.1.0a4, paddlespeech==0.1.0a5 and paddlespeech==0.1.0a6 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    paddlespeech 0.1.0a6 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a5 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a4 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a3 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a2 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a1 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a0 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.0.2a0 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.0.1a0 depends on paddlespeech-ctcdecoders\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict",
        "state": "open",
        "user": "will-wiki",
        "closed_by": null,
        "created_at": "2022-10-11T08:34:33+00:00",
        "updated_at": "2022-10-17T09:05:04+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "will-wiki",
            "yt605155624",
            "will-wiki",
            "yt605155624",
            "liucongg",
            "will-wiki",
            "will-wiki",
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2526,
        "title": "使用paddlespeech asr 报错",
        "body": "运行 paddlespeech asr --lang zh --input zh.wav时，报错paddlespeech/models/conformer_u2pp_wenetspeech-zh-16k/1.1/asr1_chunk_conformer_u2pp_wenetspeech_ckpt_1.1.3.model.tar/model.yaml 找不到，请问这是什么原因呢？",
        "state": "closed",
        "user": "armada2013",
        "closed_by": "yt605155624",
        "created_at": "2022-10-13T06:50:35+00:00",
        "updated_at": "2022-10-19T09:44:36+00:00",
        "closed_at": "2022-10-19T09:44:35+00:00",
        "comments_count": [
            "zh794390558",
            "Zth9730",
            "jackeymango",
            "jackeymango",
            "Zth9730",
            "jackeymango",
            "yt605155624",
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2536
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2529,
        "title": "tts-streaming相关问题请教",
        "body": "1.介绍中说am-encoder中FFT-block模块没有转化成卷积，但是推理时候是一个音素一个音素进行，这样会对结果造成影响吧？\r\n2.tts-streaming的训练代码有开源吗？\r\n3.VITS如果想做流式模型训练和推理，需要改哪几个模块？\r\n谢谢",
        "state": "closed",
        "user": "yiluzhuimeng",
        "closed_by": "yt605155624",
        "created_at": "2022-10-14T03:41:18+00:00",
        "updated_at": "2023-02-09T09:58:01+00:00",
        "closed_at": "2022-10-21T03:27:01+00:00",
        "comments_count": [
            "zh794390558",
            "yiluzhuimeng",
            "yt605155624",
            "panxin801",
            "15755841658",
            "panxin801",
            "yiluzhuimeng"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2534,
        "title": "[OpenCL] pwg_baker_static_0.4 fail",
        "body": "标题：[OpenCL] pwg_baker_static_0.4 fail\r\n    版本、预测库信息：\r\n       1）Paddle Lite 版本：branch develop\r\n       2）Host 环境：Ubuntu 22.04\r\n       3）运行设备环境：X86\r\n       4）预测后端信息：OpenCL AMD Radeon RX 6900 XT\r\n    预测信息\r\n       1）预测 API：API：C++\r\n       2）预测选项信息：benchmark_bin，\r\n\r\ncmd=\"gdb -args ./build.lite.linux.x86.gcc.opencl/lite/api/tools/benchmark/benchmark_bin --model_file=./models/pwg_baker_static_0.4/pwgan_csmsc.pdmodel --param_file=./models/pwg_baker_static_0.4/pwgan_csmsc.pdiparams -input_shape=1,80 --warmup=10 --repeats=20 --backend=opencl,x86 --gpu_precision=fp32\"\r\n\r\n-Model link\r\nhttps://paddlespeech.bj.bcebos.com/Parakeet/released_models/pwgan/pwg_baker_static_0.4.zip\r\n\r\n======= Opt Info =======\r\nLoad paddle model from ./models/pwg_baker_static_0.4/pwgan_csmsc.pdmodel and ./models/pwg_baker_static_0.4/pwgan_csmsc.pdiparams\r\nSave optimized model to ./models/pwg_baker_static_0.4/opt.nb\r\nI1017 10:41:20.336551 3691052 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 10:41:20.336556 3691052 paddle_api.cc:57] Found opencl library:1\r\nI1017 10:41:20.336557 3691052 paddle_api.cc:63] dlsym_success:1\r\nI1017 10:41:20.336560 3691052 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 10:41:20.336561 3691052 paddle_api.cc:70] opencl_valid:1\r\nI1017 10:41:20.336565 3691052 paddle_api.cc:323] opencl binary path and file name:/paddle_lite_opencl_kernel.bin\r\nI1017 10:41:20.336566 3691052 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 10:41:20.336567 3691052 paddle_api.cc:57] Found opencl library:1\r\nI1017 10:41:20.336568 3691052 paddle_api.cc:63] dlsym_success:1\r\nI1017 10:41:20.336570 3691052 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 10:41:20.336571 3691052 paddle_api.cc:70] opencl_valid:1\r\nI1017 10:41:20.336578 3691052 cl_runtime.cc:863] tuned_file:/paddle_lite_opencl_tuned.params\r\nW1017 10:41:20.336585 3691052 cl_runtime.cc:872] Not found tuned file:/paddle_lite_opencl_tuned.params\r\n[New Thread 0x7ffff751f640 (LWP 3691100)]\r\nI1017 10:41:20.345726 3691052 paddle_api.cc:341] set opencl_tune_mode: CL_TUNE_NORMAL, lws_repeats:4\r\nI1017 10:41:20.345738 3691052 paddle_api.cc:344] tuned file path & name:/paddle_lite_opencl_tuned.params\r\nI1017 10:41:20.345741 3691052 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 10:41:20.345742 3691052 paddle_api.cc:57] Found opencl library:1\r\nI1017 10:41:20.345743 3691052 paddle_api.cc:63] dlsym_success:1\r\nI1017 10:41:20.345744 3691052 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 10:41:20.345747 3691052 paddle_api.cc:70] opencl_valid:1\r\nI1017 10:41:20.345748 3691052 paddle_api.cc:356] set opencl precision: CL_PRECISION_FP32\r\n[Thread 0x7ffff75d0640 (LWP 3691057) exited]\r\nI1017 10:41:20.388281 3691052 cl_runtime.h:93] need to check fp16 valid:0\r\nW1017 10:41:20.388857 3691052 cl_runtime.cc:220] There is no precompiled OpenCL binary[/paddle_lite_opencl_kernel.bin] in the given OpenCL binary path. Also please make sure the storage directory exist and you have Write&Read permission. Jump to build program from source.\r\nI1017 10:41:20.474515 3691052 elementwise_image_compute.cc:100] with y->persistable\r\nI1017 10:41:20.522027 3691052 elementwise_image_compute.cc:100] with y->persistable\r\n\r\nThread 1 \"benchmark_bin\" received signal SIGSEGV, Segmentation fault.\r\n0x00007ffff7663a6e in clEnqueueCopyBuffer () from /opt/rocm-5.2.3/lib/libamdocl64.so\r\n\r\n(gdb) bt\r\n#0 0x00007ffff7663a6e in clEnqueueCopyBuffer () from /opt/rocm-5.2.3/lib/libamdocl64.so\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/1 0x00007ffff7fb3f42 in clEnqueueCopyBuffer (command_queue=0x555559946820, src_buffer=0xbdc131e43daa7a32, dst_buffer=0x555559fc3000, src_offset=0,\r\ndst_offset=0, cb=128000, num_events_in_wait_list=0, event_wait_list=0x0, event=0x0)\r\nat /home/qingchuan/work/ROCm/ROCm-OpenCL-Runtime/khronos/icd/loader/icd_dispatch.c:975\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/2 0x00005555567d22fb in clEnqueueCopyBuffer (command_queue=0x555559946820, src_buffer=0xbdc131e43daa7a32, dst_buffer=0x555559fc3000, src_offset=0,\r\ndst_offset=0, size=128000, num_events_in_wait_list=0, event_wait_list=0x0, event=0x0)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/backends/opencl/cl_wrapper.cc:759\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/3 0x0000555557564b23 in cl::CommandQueue::enqueueCopyBuffer (this=0x7fffffffd608, src=..., dst=..., src_offset=0, dst_offset=0, size=128000,\r\nevents=0x0, event=0x0) at /home/yaoyao/work/gitlab/fortest/paddle-lite/third-party/opencl/include/CL/cl2.hpp:7090\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/4 0x0000555557562c6a in paddle::lite::TargetWrapper<(paddle::lite_api::TargetType)5, cl::CommandQueue, cl::Event>::MemcpySync (dst=0x555559696690,\r\nsrc=0x555558eccfc0, size=128000, dir=paddle::lite::IoDirection::DtoD)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/backends/opencl/target_wrapper.cc:250\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/5 0x00005555569a05a7 in paddle::lite::kernels::opencl::CopyFromDeviceToDeviceSync (target=0x555559696690, source=0x555558eccfc0, size=128000)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/kernels/opencl/io_copy_buffer_compute.cc:66\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/6 0x000055555697e85d in paddle::lite::kernels::opencl::SqueezeUnsqueezeCompute::Run (this=0x55555925bc20)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/kernels/opencl/squeeze_unsqueeze_buffer_compute.cc:63\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/7 0x00005555567f8a08 in paddle::lite::KernelBase::Launch (this=0x55555925bc20) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/core/kernel.h:116\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/8 0x00005555578e1145 in paddle::lite::Instruction::Run (this=0x555558b93130) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/core/program.cc:843\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/9 0x00005555578df449 in paddle::lite::RuntimeProgram::Run (this=0x5555591fd3a0)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/core/program.cc:643\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/10 0x000055555688577a in paddle::lite::LightPredictor::Run (this=0x55555902e9b0)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/light_api.h:71\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/11 0x00005555568820a8 in paddle::lite::LightPredictorImpl::Run (this=0x555559286ec0)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/light_api_impl.cc:139\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/12 0x00005555566da0e4 in paddle::lite_api::RunImpl (predictor=std::shared_ptrpaddle::lite_api::PaddlePredictor (use count 2, weak count 0) = {...},\r\nperf_data=0x7fffffffdbb0) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:82\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/13 0x00005555566da677 in paddle::lite_api::Run (model_file=\"./models/pwg_baker_static_0.4/opt.nb\",\r\ninput_shapes=std::vector of length 1, capacity 1 = {...}) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:193\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/14 0x00005555566d9e7f in paddle::lite_api::Benchmark (argc=1, argv=0x7fffffffe230)\r\nat /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:60\r\nhttps://github.com/PaddlePaddle/Paddle-Lite/issues/15 0x00005555566d9d87 in main (argc=8, argv=0x7fffffffe1f8) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:36\r\n(gdb)",
        "state": "closed",
        "user": "yyqwert4",
        "closed_by": "yt605155624",
        "created_at": "2022-10-17T03:07:25+00:00",
        "updated_at": "2023-03-02T09:23:57+00:00",
        "closed_at": "2023-03-02T09:23:57+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2537
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2538
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2535,
        "title": "[OpenCL] panns_cnn14_static fail ",
        "body": "标题：[OpenCL] panns_cnn14_static fail\r\n    版本、预测库信息：\r\n       1）Paddle Lite 版本：branch develop\r\n       2）Host 环境：Ubuntu 22.04\r\n       3）运行设备环境：X86\r\n       4）预测后端信息：OpenCL AMD Radeon RX 6900 XT\r\n    预测信息\r\n       1）预测 API：API：C++\r\n       2）预测选项信息：benchmark_bin，\r\n\r\ncmd=\"gdb -args ./build.lite.linux.x86.gcc.opencl/lite/api/tools/benchmark/benchmark_bin --model_file=./models/panns_cnn14_static/inference.pdmodel --param_file=./models/panns_cnn14_static/inference.pdiparams -input_shape=1,1,1,64 --warmup=10 --repeats=20 --backend=opencl,x86 --gpu_precision=fp32\"\r\n\r\n-Model link\r\nhttps://paddlespeech.bj.bcebos.com/cls/inference_model/panns_cnn14_static.tar.gz\r\n\r\n======= Opt Info =======\r\nLoad paddle model from ./models/panns_cnn14_static/inference.pdmodel and ./models/panns_cnn14_static/inference.pdiparams\r\nSave optimized model to ./models/panns_cnn14_static/opt.nb\r\nI1017 11:15:30.897446 3721898 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 11:15:30.897454 3721898 paddle_api.cc:57] Found opencl library:1\r\nI1017 11:15:30.897454 3721898 paddle_api.cc:63] dlsym_success:1\r\nI1017 11:15:30.897456 3721898 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 11:15:30.897459 3721898 paddle_api.cc:70] opencl_valid:1\r\nI1017 11:15:30.897461 3721898 paddle_api.cc:323] opencl binary path and file name:/paddle_lite_opencl_kernel.bin\r\nI1017 11:15:30.897464 3721898 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 11:15:30.897465 3721898 paddle_api.cc:57] Found opencl library:1\r\nI1017 11:15:30.897466 3721898 paddle_api.cc:63] dlsym_success:1\r\nI1017 11:15:30.897467 3721898 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 11:15:30.897469 3721898 paddle_api.cc:70] opencl_valid:1\r\nI1017 11:15:30.897502 3721898 cl_runtime.cc:863] tuned_file:/paddle_lite_opencl_tuned.params\r\nW1017 11:15:30.897512 3721898 cl_runtime.cc:872] Not found tuned file:/paddle_lite_opencl_tuned.params\r\n[New Thread 0x7ffff79fa640 (LWP 3721912)]\r\nI1017 11:15:30.904769 3721898 paddle_api.cc:341] set opencl_tune_mode: CL_TUNE_NORMAL, lws_repeats:4\r\nI1017 11:15:30.904780 3721898 paddle_api.cc:344] tuned file path & name:/paddle_lite_opencl_tuned.params\r\nI1017 11:15:30.904783 3721898 paddle_api.cc:50] need to check fp16 valid:0\r\nI1017 11:15:30.904783 3721898 paddle_api.cc:57] Found opencl library:1\r\nI1017 11:15:30.904785 3721898 paddle_api.cc:63] dlsym_success:1\r\nI1017 11:15:30.904786 3721898 cl_runtime.h:93] need to check fp16 valid:0\r\nI1017 11:15:30.904788 3721898 paddle_api.cc:70] opencl_valid:1\r\nI1017 11:15:30.904789 3721898 paddle_api.cc:356] set opencl precision: CL_PRECISION_FP32\r\n[Thread 0x7fffe4178640 (LWP 3721905) exited]\r\nI1017 11:15:31.079012 3721898 cl_runtime.h:93] need to check fp16 valid:0\r\nW1017 11:15:31.080636 3721898 cl_runtime.cc:220] There is no precompiled OpenCL binary[/paddle_lite_opencl_kernel.bin] in the given OpenCL binary path. Also please make sure the storage directory exist and you have Write&Read permission. Jump to build program from source.\r\nF1017 11:15:33.805438 3721898 reshape_op.cc:239] Check failed: unk_dim_idx == -1 (0 vs. -1) Only one input dimension of Attr(shape) can be unknown.\r\n*** Check failure stack trace: ***\r\n\r\nThread 1 \"benchmark_bin\" received signal SIGABRT, Aborted.\r\n__pthread_kill_implementation (no_tid=0, signo=6, threadid=140737347850624) at ./nptl/pthread_kill.c:44\r\n44      ./nptl/pthread_kill.c: No such file or directory.\r\n\r\n\r\n\r\n(gdb) bt\r\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=140737347850624) at ./nptl/pthread_kill.c:44\r\n#1  __pthread_kill_internal (signo=6, threadid=140737347850624) at ./nptl/pthread_kill.c:78\r\n#2  __GI___pthread_kill (threadid=140737347850624, signo=signo@entry=6) at ./nptl/pthread_kill.c:89\r\n#3  0x00007ffff7a47476 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\r\n#4  0x00007ffff7a2d7f3 in __GI_abort () at ./stdlib/abort.c:79\r\n#5  0x00005555567137ba in google::logging_fail() ()\r\n#6  0x00005555567137ec in google::LogMessage::Fail() ()\r\n#7  0x0000555556713727 in google::LogMessage::SendToLog() ()\r\n#8  0x0000555556713058 in google::LogMessage::Flush() ()\r\n#9  0x0000555556716666 in google::LogMessageFatal::~LogMessageFatal() ()\r\n#10 0x00005555574fb8ae in paddle::lite::operators::ValidateShape (shape=std::vector of length 3, capacity 3 = {...}, input_dims=...)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/operators/reshape_op.cc:239\r\n#11 0x00005555574fa228 in paddle::lite::operators::ReshapeOp::InferShapeImpl (this=0x555558c6e460)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/operators/reshape_op.cc:139\r\n#12 0x00005555574f99a9 in paddle::lite::operators::ReshapeOp::InferShape (this=0x555558c6e460)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/operators/reshape_op.cc:70\r\n#13 0x00005555578e112d in paddle::lite::Instruction::Run (this=0x555558e14320) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/core/program.cc:842\r\n#14 0x00005555578df449 in paddle::lite::RuntimeProgram::Run (this=0x555558bd9650)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/core/program.cc:643\r\n#15 0x000055555688577a in paddle::lite::LightPredictor::Run (this=0x555558bbbf20)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/light_api.h:71\r\n#16 0x00005555568820a8 in paddle::lite::LightPredictorImpl::Run (this=0x555558dfeaa0)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/light_api_impl.cc:139\r\n#17 0x00005555566da0e4 in paddle::lite_api::RunImpl (predictor=std::shared_ptr<paddle::lite_api::PaddlePredictor> (use count 2, weak count 0) = {...},\r\n    perf_data=0x7fffffffdbc0) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:82\r\n#18 0x00005555566da677 in paddle::lite_api::Run (model_file=\"./models/panns_cnn14_static/opt.nb\",\r\n    input_shapes=std::vector of length 1, capacity 1 = {...}) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:193\r\n#19 0x00005555566d9e7f in paddle::lite_api::Benchmark (argc=1, argv=0x7fffffffe240)\r\n    at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:60\r\n#20 0x00005555566d9d87 in main (argc=8, argv=0x7fffffffe208) at /home/yaoyao/work/gitlab/fortest/paddle-lite/lite/api/tools/benchmark/benchmark.cc:36\r\n(gdb)\r\n",
        "state": "closed",
        "user": "yyqwert4",
        "closed_by": "yyqwert4",
        "created_at": "2022-10-17T03:18:54+00:00",
        "updated_at": "2022-10-20T03:31:56+00:00",
        "closed_at": "2022-10-20T03:31:56+00:00",
        "comments_count": [
            "zh794390558",
            "QShiX",
            "yt605155624",
            "QShiX"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2551
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2555
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2556
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2540,
        "title": "[TTS]静态模型转 Paddle-Lite 失败问题汇总",
        "body": "![WechatIMG45](https://user-images.githubusercontent.com/24568452/196322601-fbfe0f51-24c2-4c84-ad89-e68759f9ad99.jpeg)\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2487\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2534 \r\n- https://github.com/PaddlePaddle/Paddle-Lite/issues/9556\r\n- https://github.com/PaddlePaddle/Paddle-Lite/issues/9563",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-10-18T02:38:23+00:00",
        "updated_at": "2023-03-02T09:23:49+00:00",
        "closed_at": "2023-03-02T09:23:49+00:00",
        "comments_count": [
            "LiuChiachi"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2541,
        "title": "[S2T] ASR : 多卡训练aishell数据报错：'RelPositionMultiHeadedAttention' object has no attribute 'weight'",
        "body": "**具体报错信息如下：**\r\n![image](https://user-images.githubusercontent.com/27938135/196336381-7bf0fb1e-5d0d-4997-bbd9-0d0a30888a7b.png)\r\n![image](https://user-images.githubusercontent.com/27938135/196336418-203250ed-299d-4650-9ec4-b458e67edfb8.png)\r\n**我的paddle版本是这个：**\r\n![image](https://user-images.githubusercontent.com/27938135/196336457-4ee1ebb1-6ed0-4117-80f7-410d0b67ec4b.png)\r\n**请问这个报错是什么情况？**",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "zh794390558",
        "created_at": "2022-10-18T04:37:00+00:00",
        "updated_at": "2022-10-18T10:39:40+00:00",
        "closed_at": "2022-10-18T10:39:40+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2546,
        "title": "[S2T]离线ASR识别支持输出时间戳吗？",
        "body": "如题，请问离线ASR识别支持输出时间戳吗？",
        "state": "open",
        "user": "kingmpw2015",
        "closed_by": null,
        "created_at": "2022-10-18T14:18:26+00:00",
        "updated_at": "2022-10-20T10:19:55+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "AlphaMind123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2550,
        "title": "paddlespeech paddlenlp报错",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n当我使用python=3.7.12 ，paddlepaddle版本为2.0.2，会报错。\r\n<img width=\"1056\" alt=\"image\" src=\"https://user-images.githubusercontent.com/59203496/196607174-98b7cddf-a603-4e32-b1e6-21f28a481b27.png\">\r\n是asr不支持这个版本的paddle吗",
        "state": "closed",
        "user": "laity-slf",
        "closed_by": "yt605155624",
        "created_at": "2022-10-19T05:48:52+00:00",
        "updated_at": "2022-10-19T06:38:15+00:00",
        "closed_at": "2022-10-19T06:38:15+00:00",
        "comments_count": [
            "yt605155624",
            "laity-slf",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2547,
        "title": "[S2T]  U2模型训练暂停问题",
        "body": "**大神们好。我再实验U2模型多卡训练aishell数据的时候，会出现在某个epoch之后模型不在更新，日志不再更新，训练暂停的问题。之前提过一次该问题，代码和版本更新之后，现在还有该问题，现在情况如下：**\r\n**1：7卡训练U2模型，在epoch=10之后训练停下了，但是GPU还在运行中，且GPU使用率还在实时更新，如下：**\r\n![image](https://user-images.githubusercontent.com/27938135/196572230-e217bb30-6e95-4f9f-9d18-fda8d6b3c7ee.png)\r\n\r\n**2：截止到现在这个时间点，模型已经有8个多小时没有更新。最新模型只截止到夜里12点左右：**\r\n![image](https://user-images.githubusercontent.com/27938135/196572350-74c739b7-33cd-4ee5-b2d5-b35d7af3ae56.png)\r\n\r\n**3：服务器目前只有这一个任务在跑，机器内存是完全够的。如下（还有200G+空闲内存）：**\r\n![image](https://user-images.githubusercontent.com/27938135/196572444-731ee22d-d160-4674-a62b-09a2887142b2.png)\r\n\r\n**下面是打印出来的日志情况：**\r\n![image](https://user-images.githubusercontent.com/27938135/196572558-46cb94b7-4a06-403e-b914-5d1062d25522.png)\r\n日志只更新到12点37就不更新了。\r\n\r\n请问下这个问题是啥问题啊。另外，我的paddle版本应该也是最新的了：\r\n![image](https://user-images.githubusercontent.com/27938135/196572717-fac830ae-133b-4959-86cd-d794c26a1ace.png)\r\n",
        "state": "open",
        "user": "Tian14267",
        "closed_by": null,
        "created_at": "2022-10-19T01:00:04+00:00",
        "updated_at": "2022-10-20T09:13:00+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2553,
        "title": "[S2T] 关于U2模型的8k采样率训练参数问题",
        "body": "各位大神好，我想问下**U2模型**的训练参数当前是`16k`采样率的（基于aishell数据训练）。我现在想训练`8k`采样率的模型。请问下能否公布一份基于`8K`采样率的训练参数配置？因为我自己修改的参数不确定是否有问题。拜托各位大神了。",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "yt605155624",
        "created_at": "2022-10-19T08:04:03+00:00",
        "updated_at": "2022-10-21T03:25:32+00:00",
        "closed_at": "2022-10-21T03:25:32+00:00",
        "comments_count": [
            "Zth9730"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2557,
        "title": "[S2T]AIstudio中DeepSpeech2教程的demo无法正常运行",
        "body": "https://aistudio.baidu.com/aistudio/course/introduce/25130 \r\n该教程中语音识别的DeepSpeech2的demo无法正常运行，出现的错误的具体代码段如下：\r\n![微信图片_20221019224727](https://user-images.githubusercontent.com/74460795/196724940-f9d500c6-cf97-40b2-ae84-e504abc72277.jpg)\r\n![微信图片_20221019224735](https://user-images.githubusercontent.com/74460795/196725032-b3733ed7-cce1-4490-947b-bd356db4ad67.jpg)\r\n经检查，发现下载下来的deepspeech2.yaml配置文件中没有rnn_direction、num_fc_layers、fc_layers_size_list, 这个该如何解决？\r\n\r\n\r\n",
        "state": "closed",
        "user": "ykx123-hub",
        "closed_by": "yt605155624",
        "created_at": "2022-10-19T14:50:37+00:00",
        "updated_at": "2023-02-25T15:27:19+00:00",
        "closed_at": "2022-10-21T03:25:43+00:00",
        "comments_count": [
            "zh794390558",
            "cailuyu"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2560,
        "title": "字音转换问题",
        "body": "![image](https://user-images.githubusercontent.com/108966996/196894299-3878b33c-4970-4751-b1e6-25f74b5184e9.png)\r\n![image](https://user-images.githubusercontent.com/108966996/196895228-f21269b2-0bbe-4df9-a8cf-e47fe986345d.png)\r\n\r\n为什么w变成了u\r\n![image](https://user-images.githubusercontent.com/108966996/196894808-5a4e7b9b-85b6-4dc7-9a69-5018ea8f8b1b.png)\r\n![image](https://user-images.githubusercontent.com/108966996/196895228-f21269b2-0bbe-4df9-a8cf-e47fe986345d.png)\r\n\r\n\r\n为什么yun4变成了vn4，zhi1为什么变成了zh iii\r\n还有就是韵律符号怎么也没有了呢",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-10-20T08:19:57+00:00",
        "updated_at": "2022-10-21T06:22:57+00:00",
        "closed_at": "2022-10-21T06:22:57+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2561,
        "title": "多说话人数据集用于TTS",
        "body": "请问一下：在用多说话人的数据集做TTS时与单一说话人的数据集有什么区别，是将各个speaker的语音分开像单一的speaker一样进行训练吗，在测试的时候合成哪个speaker的音色是不是可以设置的",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-10-20T10:18:31+00:00",
        "updated_at": "2022-10-20T12:12:26+00:00",
        "closed_at": "2022-10-20T12:12:26+00:00",
        "comments_count": [
            "yt605155624",
            "AlphaMind123"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2563,
        "title": "arm架构下部署paddlespeech",
        "body": "我尝试在jetson nano上部署paddlespeech , 但是paddlepaddle的最高版本是2.3.2。部署的过程中发现paddlespeech_ctcdecoders没有arm架构的包。部署之后运行speech_web/speech_server报错\r\n\r\nFile \"/usr/local/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 611, in U2BaseModel\r\n    @jit.to_static(property=True)\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n\r\n环境：python 3.7，paddlepaddle2.3.2\r\n\r\n请问我该如何解决出现的问题？\r\n",
        "state": "closed",
        "user": "cater555",
        "closed_by": "yt605155624",
        "created_at": "2022-10-21T00:18:52+00:00",
        "updated_at": "2022-10-24T02:36:42+00:00",
        "closed_at": "2022-10-24T02:36:42+00:00",
        "comments_count": [
            "yt605155624",
            "cater555",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2562,
        "title": "MacOS调用paddleSpeech_server报错",
        "body": "<img width=\"1440\" alt=\"截屏2022-10-19 下午9 56 38\" src=\"https://user-images.githubusercontent.com/116180233/196980808-fbb1ae0f-7701-4f0a-9123-504593e354f2.png\">\r\n\r\nMacOS按照gitee上简单模式安装，在启动服务时路径明明正确，但是出现了上图的报错\r\npaddlespeech_server start --config_file ./PaddleSpeech-develop/demos/speech_server/conf/application.yaml\r\npaddlespeech_server start ./PaddleSpeech-develop/demos/speech_server/conf/application.yaml\r\n最终都失败了\r\n（萌新，不是很懂python，求指教）\r\n",
        "state": "closed",
        "user": "Hezzle",
        "closed_by": "yt605155624",
        "created_at": "2022-10-20T14:45:54+00:00",
        "updated_at": "2022-10-24T02:49:04+00:00",
        "closed_at": "2022-10-24T02:49:04+00:00",
        "comments_count": [
            "lym0302",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2565,
        "title": "❗❗[Server]run() got an unexpected keyword argument 'debug'",
        "body": "When you run:\r\n```bash\r\npaddlespeech_server start --config_file ./conf/application.yaml\r\n```\r\nYou may encounter the following error:\r\n```text\r\nrun() got an unexpected keyword argument 'debug'\r\n```\r\nThis is due to the incompatibility upgrade of 0.19.0  release of `uvicorn` on 2022.10.20.\r\n\r\nWe have fix this bug in develop branch, see https://github.com/PaddlePaddle/PaddleSpeech/pull/2558.\r\nplease install develop version of paddlespeech, see https://github.com/PaddlePaddle/PaddleSpeech/issues/2472.\r\n\r\nor install `uvicorn<=0.18.3`:\r\n```bash\r\npip install uvicorn==0.18.3\r\n```",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-21T02:49:51+00:00",
        "updated_at": "2023-01-21T04:45:35+00:00",
        "closed_at": "2023-01-21T04:45:35+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "Installation",
            "Server"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2564,
        "title": "fastspeech 等声学模型、Multi_band MelGAN等声码器流式与非流式模型的参数量，计算量区别？端侧相关",
        "body": "## General Question\r\n如题，流式模型在端侧部署时，是否会有更低的计算量，或者有更好的效果，有没有数据佐证。\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "Xsx93",
        "closed_by": "yt605155624",
        "created_at": "2022-10-21T01:16:10+00:00",
        "updated_at": "2022-10-24T02:36:23+00:00",
        "closed_at": "2022-10-24T02:36:23+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2566,
        "title": "[TTS]当文本中包含全角数字的时候会报错",
        "body": "\r\n**Describe the bug**\r\n文本包含全角数字报错\r\n\r\n\r\n**期望**\r\n正常转换\r\n\r\n\r\n**错误信息**\r\n```bash\r\nspecial_tokens_map.json\r\nTraceback (most recent call last):\r\n  File \"/home/like/tts/tts.py\", line 8, in <module>\r\n    tts(text=context, output=\"output.wav\")\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 684, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 445, in infer\r\n    frontend_dict = run_frontend(\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 183, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 408, in get_input_ids\r\n    phonemes = self.get_phonemes(\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 374, in get_phonemes\r\n    sentences = self.text_normalizer.normalize(sentence)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/text_normlization.py\", line 115, in normalize\r\n    sentences = [self.normalize_sentence(sent) for sent in sentences]\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/text_normlization.py\", line 115, in <listcomp>\r\n    sentences = [self.normalize_sentence(sent) for sent in sentences]\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/text_normlization.py\", line 86, in normalize_sentence\r\n    sentence = RE_DATE.sub(replace_date, sentence)\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/chronology.py\", line 104, in replace_date\r\n    result += f\"{verbalize_digit(year)}年\"\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/num.py\", line 211, in verbalize_digit\r\n    result_symbols = [DIGITS[digit] for digit in value_string]\r\n  File \"/home/like/.virtualenvs/tts/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_normalization/num.py\", line 211, in <listcomp>\r\n    result_symbols = [DIGITS[digit] for digit in value_string]\r\nKeyError: '１'\r\n```\r\n",
        "state": "closed",
        "user": "arashrun",
        "closed_by": "yt605155624",
        "created_at": "2022-10-21T08:07:15+00:00",
        "updated_at": "2022-11-21T07:25:12+00:00",
        "closed_at": "2022-11-21T07:25:12+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2567,
        "title": "语音识别报错",
        "body": "paddlespeech安装完成后快速测试语音识别报错：（执行语音合成命令正常响应）\r\n执行：paddlespeech asr --lang zh --input zh.wav\r\n报错：/anaconda3/envs/paddlepaddle39/lib/python3.9/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTypeError: declarative() got an unexpected keyword argument 'property'(paddlepaddle39)\r\n\r\n本地环境：ubuntu18.04+conda创建虚拟环境（python3.9）\r\n\r\n安装参考：https://github.com/PaddlePaddle/PaddleSpeech\r\n                  https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/install_cn.md\r\n",
        "state": "closed",
        "user": "ChayYue",
        "closed_by": "yt605155624",
        "created_at": "2022-10-21T08:25:36+00:00",
        "updated_at": "2022-10-27T03:12:33+00:00",
        "closed_at": "2022-10-27T03:12:33+00:00",
        "comments_count": [
            "yt605155624",
            "JYCcx",
            "yt605155624"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2575
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2569,
        "title": "style_fs2 怎么由单人改多人？希望能有个小demo参考一下，谢谢",
        "body": "style_fs2 怎么由单人改多人？希望能有个小demo参考一下，谢谢",
        "state": "closed",
        "user": "thehzzz",
        "closed_by": "yt605155624",
        "created_at": "2022-10-21T10:27:23+00:00",
        "updated_at": "2022-12-10T06:00:06+00:00",
        "closed_at": "2022-10-24T02:27:39+00:00",
        "comments_count": [
            "thehzzz",
            "yt605155624",
            "SG-XM"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2570,
        "title": "使用AiStudio进入服务器的时候出现ERROR提示",
        "body": "<img width=\"991\" alt=\"截屏2022-10-21 下午8 37 22\" src=\"https://user-images.githubusercontent.com/116180233/197197398-e7d139bf-e145-41a4-b5bd-4b0e10e3b0be.png\">\r\n\r\n使用AiStudio进入服务器的时候，前面的步骤均已完成，但是出现了上图的ERROR\r\n求指教qwq",
        "state": "closed",
        "user": "Hezzle",
        "closed_by": "Hezzle",
        "created_at": "2022-10-21T12:39:26+00:00",
        "updated_at": "2022-10-21T14:26:46+00:00",
        "closed_at": "2022-10-21T14:26:46+00:00",
        "comments_count": [
            "Hezzle"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2576,
        "title": "❣️❣️【🔝长期置顶】常见使用问题合集（总入口）❣️❣️",
        "body": "从 **2022.10.24日**起，把遇到的问题汇总在这里，以便让开发者能够较快的找到解决方案。后期如果问题增多的再进行分类。\r\n\r\n1、【paddle2onnx】**paddle模型转onnx模型**过程中，遇到**算子不支持**的问题。报错如下：\r\n**[ERROR] Due to the unsupported operators, the conversion is aborted.**\r\n\r\n![C210F3DDE659AB10AE44EC7E54C1825A](https://user-images.githubusercontent.com/34430015/197445446-7a7f1dea-2fae-4b85-a8cf-f63303f21c20.png)\r\n\r\n**解决方案**：使用 paddlepaddle 2.3.1 + paddle2onnx 0.9.8 或者 paddlepaddle 2.4.0(paddlepaddle_develop) + paddle2onnx 1.0.0 搭配将动态模型转换成静态模型，再将静态模型转换成 onnx 模型即可。\r\n参考 \r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2347\r\n\r\nps: paddle 静态图模型（`*.pdmodel`）和 onnx 模型（`*.onnx`）可以拖动到 https://netron.app/ 进行可视化\r\n\r\n2、【server】启动 server 服务的时候有报错：\r\n**got an unexpected keyword argument 'debug'** \r\n解决方案：目前最新的paddlespeech 代码已经解决该问题。若使用旧版本的代码需要把uvicorn 的版本降级到 0.18.3\r\n原因： uvicorn 升级了版本去掉了 debug 参数，我们之前启动服务的代码中使用了这个参数。\r\n参考 \r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2565\r\n\r\n## FAQ\r\n- https://github.com/PaddlePaddle/PaddleSpeech/discussions/1989\r\n\r\n## 安装相关\r\n- https://github.com/PaddlePaddle/PaddleSpeech/discussions/1195\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2150\r\n\r\n## 中英文混合 TTS\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2942\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2895\r\n\r\n## TTS 端上部署相关\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/3037\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2975\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2858\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2933\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2540\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2981\r\n\r\n## TTS 其他常见问题\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/3009\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2669\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2456\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2196\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/1620\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2943\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/1925\r\n\r\n## ASR 常见问题\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2897\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2885\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2512\r\n\r\n## 更多问题汇总\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2325\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2577\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2792\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2750\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2909\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2931\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2472\r\n\r\n",
        "state": "open",
        "user": "lym0302",
        "closed_by": null,
        "created_at": "2022-10-24T03:56:24+00:00",
        "updated_at": "2023-03-14T08:10:17+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Question",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2572,
        "title": "流式asr服务启动报错AttributeError: num_decoding_left_chunks",
        "body": "流式asr服务启动报错AttributeError: num_decoding_left_chunks\r\n<img width=\"1440\" alt=\"image\" src=\"https://user-images.githubusercontent.com/30432137/197335817-9898b704-c852-44d1-ba8f-bc362e9c6b8e.png\">\r\n<img width=\"1440\" alt=\"image\" src=\"https://user-images.githubusercontent.com/30432137/197336040-91037d71-3e21-4604-9d69-496461bcf0cf.png\">\r\n\r\n课程的配置文件示例也没有num_decoding_left_chunks字段\r\n<img width=\"1438\" alt=\"image\" src=\"https://user-images.githubusercontent.com/30432137/197335934-6c5d4a74-2ab6-43a9-b5fc-acfa084ce4a0.png\">\r\n\r\npaddlepaddle: 2.4.0rc0\r\npython:3.8",
        "state": "closed",
        "user": "ShawnyinsGit",
        "closed_by": "yt605155624",
        "created_at": "2022-10-22T11:13:56+00:00",
        "updated_at": "2022-10-27T03:12:40+00:00",
        "closed_at": "2022-10-27T03:12:40+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2573,
        "title": "aishell model convert to  onnx model error",
        "body": "paddle2onnx convert deepspeech2_aishell pretrianed model error, is that supported ?\r\n./tonnx.sh ../data/exp/deepspeech2_online/checkpoints/ avg_10.jit.pdmodel  avg_10.pdparams  ./avg_10.jit.onnxRequirement already satisfied: paddle2onnx in /usr/local/lib/python3.8/dist-packages (0.9.8)\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\r\nRequirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (1.11.0)\r\nRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from onnx) (3.19.5)\r\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.23.1)\r\nRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.3.0)\r\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ../data/exp/deepspeech2_online/checkpoints/avg_10.jit.pdmodel\r\n[Paddle2ONNX] Paramters file path: ../data/exp/deepspeech2_online/checkpoints/avg_10.pdparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Paddle2ONNX: Only support weight with lod_level = 0.\r\n./tonnx.sh: line 25: 24306 Aborted                 (core dumped) paddle2onnx --model_dir $dir --model_filename $model --params_filename $param --save_file $output --enable_dev_version True --opset_version 11 --enable_onnx_checker True\r\n-->\r\n",
        "state": "open",
        "user": "ZX183",
        "closed_by": null,
        "created_at": "2022-10-23T03:33:27+00:00",
        "updated_at": "2022-10-24T09:42:26+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2571,
        "title": "[TTS]特殊的句子及标点导致报错",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n特殊句式导致报错\r\n\r\n**To Reproduce**\r\n报错句子：`并且——说来会使他惭愧——是以庄重口气谈到的,`\r\n\r\n**Expected behavior**\r\n正常生成\r\n\r\n**Screenshots**\r\n```shell\r\nLoading model cost 0.382 seconds.\r\nDEBUG 2022-10-22 17:58:41,857 __init__.py:164] Loading model cost 0.382 seconds.\r\nPrefix dict has been built successfully.\r\nDEBUG 2022-10-22 17:58:41,857 __init__.py:166] Prefix dict has been built successfully.\r\n[并且——说来会使他惭愧——是以庄重口气谈到的,] not in g2pW dict,use g2pM\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ming\\Desktop\\1\\2.py\", line 28, in <module>\r\n    tts(text=text, output=\"output.wav\")\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\cli\\tts\\infer.py\", line 684, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"C:\\Users\\ming\\envs\\b-site\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"C:\\Users\\ming\\envs\\b-site\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 354, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\cli\\tts\\infer.py\", line 445, in infer\r\n    frontend_dict = run_frontend(\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 195, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 517, in get_input_ids\r\n    phonemes = self.get_phonemes(\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 437, in get_phonemes\r\n    phonemes = self._g2p(\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 243, in _g2p\r\n    sub_finals = self.tone_modifier.modified_tone(word, pos,\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\frontend\\tone_sandhi.py\", line 352, in modified_tone\r\n    finals = self._neural_sandhi(word, pos, finals)\r\n  File \"c:\\users\\ming\\envs\\b-site\\paddlespeech\\paddlespeech\\t2s\\frontend\\tone_sandhi.py\", line 89, in _neural_sandhi\r\n    finals[-1] = finals[-1][:-1] + \"5\"\r\nIndexError: list index out of range\r\n```\r\n",
        "state": "closed",
        "user": "arashrun",
        "closed_by": "yt605155624",
        "created_at": "2022-10-22T10:02:04+00:00",
        "updated_at": "2022-11-28T06:54:24+00:00",
        "closed_at": "2022-11-28T06:54:24+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2577,
        "title": "AIStudio 教程报错合集",
        "body": "由于 PaddleSpeech 不兼容升级 [飞桨PaddleSpeech语音技术课程](https://aistudio.baidu.com/aistudio/course/introduce/25130) 中的教程可能存在跑不通的情况，相关问题可以在本 issue 反馈\r\n\r\n1. [[S2T]AIstudio中DeepSpeech2教程的demo无法正常运行](https://github.com/PaddlePaddle/PaddleSpeech/issues/2557)、https://github.com/PaddlePaddle/PaddleSpeech/issues/2512#issuecomment-1288081988\r\n2. [流式asr服务启动报错AttributeError: num_decoding_left_chunks](https://github.com/PaddlePaddle/PaddleSpeech/issues/2572)\r\n3. [No mudule named 'paddlespeech.s2t.transform'](https://github.com/PaddlePaddle/PaddleSpeech/issues/2567)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-10-24T07:12:09+00:00",
        "updated_at": "2022-10-27T03:13:03+00:00",
        "closed_at": "2022-10-27T03:13:03+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2574,
        "title": "[TTS]example/aishell3/tts3 自己的数据集训练synthesize_e2e出来没有声音",
        "body": "请问在example/aishell3/tts3 中，我用aishell3数据集训练没有问题，但是我用我自己的数据训练，不报错，但是推理出来的音频没有声音，只有 “”enenen“”的声音，请问这是怎么回事呢",
        "state": "closed",
        "user": "HandsLing",
        "closed_by": "HandsLing",
        "created_at": "2022-10-24T00:36:21+00:00",
        "updated_at": "2022-10-24T06:47:20+00:00",
        "closed_at": "2022-10-24T06:47:20+00:00",
        "comments_count": [
            "yt605155624",
            "HandsLing"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2578,
        "title": "语音识别可以同时识别多个文件吗",
        "body": "想问一下怎么批量识别多个音频文件\r\n",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "yt605155624",
        "created_at": "2022-10-24T09:49:06+00:00",
        "updated_at": "2022-10-26T02:20:51+00:00",
        "closed_at": "2022-10-26T02:20:51+00:00",
        "comments_count": [
            "zh794390558",
            "oyb1125"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2579,
        "title": "TTS, 小样本合成项目用BML Colab运行出现bug",
        "body": "按照https://aistudio.baidu.com/aistudio/projectdetail/4573549?channelType=0&channel=0 上Paddle开源的项目，打开BML Colab进行复现。在GE2E语音生成模块前端出现bug:\r\n\r\n\r\n{'code': -1, 'result': None, 'message': '克隆失败，检查克隆脚本是否有效'}\r\n\r\n此时后端显示：\r\n\r\npython3 /home/aistudio/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py                     --am=fastspeech2_aishell3                     --am_config=source/model/fastspeech2_nosil_aishell3_vc1_ckpt_0.5/default.yaml                     --am_ckpt=source/model/fastspeech2_nosil_aishell3_vc1_ckpt_0.5/snapshot_iter_96400.pdz                     --am_stat=source/model/fastspeech2_nosil_aishell3_vc1_ckpt_0.5/speech_stats.npy                     --voc=pwgan_aishell3                     --voc_config=source/model/pwg_aishell3_ckpt_0.5/default.yaml                     --voc_ckpt=source/model/pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz                     --voc_stat=source/model/pwg_aishell3_ckpt_0.5/feats_stats.npy                     --ge2e_params_path=source/model/ge2e_ckpt_0.3/step-3000000.pdparams                     --text=\"欢迎使用飞桨语音套件\"                     --input-dir=/home/aistudio/PaddleSpeech/demos/speech_web/speech_server/tmp_dir/ge2e                     --output-dir=source/wav/vc/out                     --phones-dict=source/model/fastspeech2_nosil_aishell3_vc1_ckpt_0.5/phone_id_map.txt                     --ngpu=1\r\n        \r\n运行结果： 139\r\nINFO:     127.0.0.1:41752 - \"POST /vc/clone_g2p HTTP/1.1\" 200 OK\r\n\r\n",
        "state": "closed",
        "user": "Plutoisme",
        "closed_by": "Plutoisme",
        "created_at": "2022-10-24T10:19:56+00:00",
        "updated_at": "2022-10-25T03:20:30+00:00",
        "closed_at": "2022-10-25T03:20:30+00:00",
        "comments_count": [
            "iftaken"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2580,
        "title": "OSError: (External) CUFFT error(50).",
        "body": "The enviroment is cuda 10.2 cudnn 7.6, report the error while i run the command `paddlespeech cls --input dog.wav --device gpu:0`\r\nThe output as below:\r\n```\r\nW1024 12:42:32.074532 13131 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 10.2\r\nW1024 12:42:32.078289 13131 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\n\r\nYou are running using the stub version of cufft\r\nOSError: (External) CUFFT error(50).\r\n  [Hint: Please search for the error code(50) on website (https://docs.nvidia.com/cuda/cufft/index.html#cufftresult) to get Nvidia's official solution and advice about CUFFT Error.] (at /paddle/paddle/fluid/operators/spectral_op.cu.h:84)\r\n  [operator < fft_r2c > error].\r\n```\r\n\r\nAny suggest for this problem?\r\n",
        "state": "closed",
        "user": "pkuCactus",
        "closed_by": "yt605155624",
        "created_at": "2022-10-24T12:46:23+00:00",
        "updated_at": "2023-05-27T18:24:41+00:00",
        "closed_at": "2022-11-02T01:15:07+00:00",
        "comments_count": [
            "yt605155624",
            "pkuCactus",
            "yt605155624",
            "pkuCactus",
            "chxx"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2583,
        "title": "声音克隆单句话克隆效果很差",
        "body": "任务：https://aistudio.baidu.com/bj-gpu-02/user/997789/4888326/lab/tree/PaddleSpeech/demos/speech_web/speech_server/src/finetune.py\r\n具体问题描述：\r\n用3秒西游记中猴哥声音做克隆，效果很差\r\n用小样本fintune教程不够详细，没有跑成功\r\n感觉问题应该是声纹抽取、声音编码器迁移效果不够好",
        "state": "closed",
        "user": "liangwq",
        "closed_by": "yt605155624",
        "created_at": "2022-10-26T08:34:31+00:00",
        "updated_at": "2022-11-15T09:13:58+00:00",
        "closed_at": "2022-11-15T09:13:58+00:00",
        "comments_count": [
            "yt605155624",
            "liangwq",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2582,
        "title": "[TTS]onnx无法batch输入",
        "body": "请问example/aishell3/tts里面基于aishell3训练的模型导成onnx，只支持一个输入，无法支持batch输入，这个后期能支持吗？",
        "state": "closed",
        "user": "HandsLing",
        "closed_by": "yt605155624",
        "created_at": "2022-10-25T09:28:58+00:00",
        "updated_at": "2022-10-26T02:20:39+00:00",
        "closed_at": "2022-10-26T02:20:39+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2584,
        "title": "asr性能、动转静问题",
        "body": "请问项目中的ASRExecutor，是静态的还是动态的？现在是想提升一下性能有什么方法？\r\n## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "beingjoey",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-26T09:50:12+00:00",
        "updated_at": "2023-03-25T12:04:03+00:00",
        "closed_at": "2023-03-25T12:04:03+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "wqn1",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2586,
        "title": "为什么使用ERNIE-SAT声音克隆，从中文生成的英文语音完全听不懂？",
        "body": "您好，我正在尝试https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell3_vctk/ernie_sat的声音克隆，发现使用我自己的中文语音生成的英文语音完全听不懂，和乱码一样。\r\n\r\n我的输入是：\r\n--old_str=\"除此之外，在看电影生肉时，中文字幕搭配中文原声，让你更加声临其境。\"\r\n--new_str=\"In addition, when watching the movie raw meat, Chinese subtitles with the Chinese original sound, let you more immersive.\"\r\n\r\n我打印了synthesize_e2e.py中的with_dur_outs，并没有发现什么问题：\r\nwith_dur_outs:{'new_wav': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'new_phns': ['sp', 'ch', 'u2', 'c', 'ii3', 'zh', 'iii1', 'uai4', 'sp', 'z', 'ai4', 'k', 'an4', 'd', 'ian4', 'ing3', 'sh', 'eng1', 'r', 'ou4', 'sh', 'iii2', 'sp', 'zh', 'ong1', 'uen2', 'z', 'ii4', 'm', 'u4', 'd', 'a1', 'p', 'ei4', 'zh', 'ong1', 'uen2', 'van2', 'sh', 'eng1', 'sp', 'r', 'ang4', 'n', 'i3', 'g', 'eng4', 'j', 'ia1', 'sh', 'eng1', 'l', 'in2', 'q', 'i2', 'j', 'ing4', 'sp', 'IH0', 'N', 'AH0', 'D', 'IH1', 'SH', 'AH0', 'N', 'W', 'EH1', 'N', 'W', 'AA1', 'CH', 'IH0', 'NG', 'DH', 'AH0', 'M', 'UW1', 'V', 'IY0', 'R', 'AA1', 'M', 'IY1', 'T', 'CH', 'AY0', 'N', 'IY1', 'Z', 'S', 'AH1', 'B', 'T', 'AY2', 'T', 'AH0', 'L', 'Z', 'W', 'IH1', 'DH', 'DH', 'AH0', 'CH', 'AY0', 'N', 'IY1', 'Z', 'ER0', 'IH1', 'JH', 'AH0', 'N', 'AH0', 'L', 'S', 'AW1', 'N', 'D', 'L', 'EH1', 'T', 'Y', 'UW1', 'M', 'AO1', 'R', 'spn'], 'new_mfa_start': [0, 75, 84, 91, 102, 109, 116, 120, 163, 168, 183, 196, 210, 222, 232, 249, 253, 263, 270, 279, 288, 300, 327, 345, 356, 370, 379, 387, 394, 404, 416, 425, 437, 448, 459, 468, 481, 493, 511, 522, 551, 569, 575, 588, 594, 604, 610, 620, 627, 648, 660, 671, 675, 689, 706, 711, 719, 741, 767, 779, 788, 800, 812, 824, 841, 850, 862, 871, 878, 894, 905, 926, 943, 949, 960, 966, 975, 989, 1006, 1017, 1034, 1050, 1064, 1080, 1099, 1105, 1122, 1146, 1157, 1174, 1190, 1206, 1217, 1226, 1243, 1259, 1268, 1275, 1287, 1303, 1314, 1320, 1331, 1338, 1347, 1364, 1383, 1392, 1408, 1425, 1449, 1458, 1470, 1476, 1482, 1489, 1500, 1526, 1547, 1556, 1562, 1576, 1587, 1601, 1610, 1624, 1635, 1644, 1653], 'new_mfa_end': [75, 84, 91, 102, 109, 116, 120, 163, 168, 183, 196, 210, 222, 232, 249, 253, 263, 270, 279, 288, 300, 327, 345, 356, 370, 379, 387, 394, 404, 416, 425, 437, 448, 459, 468, 481, 493, 511, 522, 551, 569, 575, 588, 594, 604, 610, 620, 627, 648, 660, 671, 675, 689, 706, 711, 719, 741, 767, 779, 788, 800, 812, 824, 841, 850, 862, 871, 878, 894, 905, 926, 943, 949, 960, 966, 975, 989, 1006, 1017, 1034, 1050, 1064, 1080, 1099, 1105, 1122, 1146, 1157, 1174, 1190, 1206, 1217, 1226, 1243, 1259, 1268, 1275, 1287, 1303, 1314, 1320, 1331, 1338, 1347, 1364, 1383, 1392, 1408, 1425, 1449, 1458, 1470, 1476, 1482, 1489, 1500, 1526, 1547, 1556, 1562, 1576, 1587, 1601, 1610, 1624, 1635, 1644, 1653, 1785], 'old_span_bdy': [767, 767], 'new_span_bdy': [767, 1785]}\r\n\r\n我的操作应该没有问题，因为我尝试从英文语音克隆生成中文语音是成功的，虽然音色不太像，但是合成的语音质量很不错。我不知道为什么中文克隆到英文就失败，请问您能帮下我嘛？\r\n",
        "state": "closed",
        "user": "guo453585719",
        "closed_by": "yt605155624",
        "created_at": "2022-10-27T08:57:47+00:00",
        "updated_at": "2022-11-15T09:14:14+00:00",
        "closed_at": "2022-11-15T09:14:14+00:00",
        "comments_count": [
            "guo453585719",
            "yt605155624",
            "guo453585719",
            "yt605155624",
            "guo453585719",
            "guo453585719",
            "yt605155624",
            "guo453585719",
            "yt605155624",
            "guo453585719",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2581,
        "title": "paddlespeech_server asr 有没有办法可以降低GPU内存的使用啊？",
        "body": "paddlespeech_server asr 有没有办法可以降低GPU内存的使用啊？\r\n\r\n我已经修改了application.yml 中只用 engine_list: ['asr_python']\r\nconformer_wenetspeech 模型占用内存较高2.6G，我在笔记本上做应用gpu内存有限。\r\n预测的时候是否有可能精度减少不多前提下，精度gpu 内存使用？\r\n\r\n如果用cpu 预测太慢了，2S以上无法接受\r\n",
        "state": "closed",
        "user": "jeffzhengye",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-25T03:51:13+00:00",
        "updated_at": "2023-01-21T04:45:38+00:00",
        "closed_at": "2023-01-21T04:45:38+00:00",
        "comments_count": [
            "zh794390558",
            "jeffzhengye",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2589,
        "title": "speech_web的web_client前端启动失败",
        "body": "Hi I have followed the instructions in https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_web and installed npm, nodejs and yarn.  I started the voice cloning service at the speech server end, and it worked fine with API, but I failed to start it at the web client end\r\n\r\n```\r\nPaddleSpeech/demos/speech_web/web_client$ yarn dev --port 8011\r\nyarn run v1.22.19\r\n$ vite --port 8011\r\n/bin/sh: 1: vite: not found\r\nerror Command failed with exit code 127.\r\ninfo Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\r\n```\r\n\r\nIs there any step missing?",
        "state": "closed",
        "user": "treya-lin",
        "closed_by": "stale[bot]",
        "created_at": "2022-10-28T01:43:47+00:00",
        "updated_at": "2023-01-21T04:45:40+00:00",
        "closed_at": "2023-01-21T04:45:40+00:00",
        "comments_count": [
            "iftaken",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2595
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2594
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2597
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2598
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2593,
        "title": "语音log mel和MFA提取的phone durations总和的frames相差问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n我对语音做了切分和停顿的各种处理，然后用MFA 2.X提取了durations, 我对比了所有处理过后语音的duration和MFA durations总和，误差在1e-3 秒以下(1ms以下). 考虑到hop window用的是12.5ms这应该没有问题，因为MFA的TG文件只到小数点第二三位, log mel提取后frames数和phone durations用librosa.time_to_frames转换后的frames数有时候会差1个frame. log mel提取是根据你们那个script提取的，用到librosa.stft加上center padding. 然后librosa.time_to_frames用到flooring方程，我看了你们VTuberTalk那个repo, 对此的处理是把两者相差加进去，想问下你们paddlespeech repo里面有根据padding以及duration to frames转换有什么特别处理吗？\r\n我的意思是，librosa.stft 的pad mode是reflective应该是两边都做了padding, 这样1frame的差别有可能会造成所有phoneme的frame对齐偏差一个frame吧？\r\n\r\n看过这两行https://github.com/PaddlePaddle/PaddleSpeech/blob/a778f160144c242536c8333a4d442416967993bf/paddlespeech/t2s/exps/fastspeech2/preprocess.py#L69, 里面并没有对mismatch做处理，后面几行compare_...那个方程是把相差的frame加到duration frame那边。",
        "state": "closed",
        "user": "binbinxue",
        "closed_by": "binbinxue",
        "created_at": "2022-10-28T13:03:37+00:00",
        "updated_at": "2022-10-31T10:00:37+00:00",
        "closed_at": "2022-10-31T10:00:37+00:00",
        "comments_count": [
            "binbinxue",
            "yt605155624",
            "binbinxue"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2592,
        "title": "TTS英语g2p转换的问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n在你们群里面问过, 英语语料训练数据用到MFA的话用english_us_arpa的g2p产生的phoneme set和front end用g2p_en的phoneme set有区别, g2p_en有额外的'UW'. 还有一个问题就是，MFA对text的处理和g2p_en处理不一样，同样的词，没有多音的词，MFA产生的phonemes和g2p_en产生的phonemes不一样。它们对于punctuation的处理也不一样。比如 I'm 的话g2p_en会把它分成 I am两个词来产生phonemes, 而MFA不会。还有括号，以及其他punctuations\r\n另外，你们的代码用MFA 1.x记得是假设phoneme sequence前后都会有silence, MFA 2.x不一定会产生leading/trailing silences. 我试了一下改它们的silence probability参数，结果是一样的。\r\n不影响跑通训练，我觉得有可能会影响合成质量\r\n",
        "state": "closed",
        "user": "binbinxue",
        "closed_by": "binbinxue",
        "created_at": "2022-10-28T13:00:20+00:00",
        "updated_at": "2022-10-31T10:00:48+00:00",
        "closed_at": "2022-10-31T10:00:48+00:00",
        "comments_count": [
            "yt605155624",
            "binbinxue"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2601,
        "title": "[TTS]25cm 无法正常合成",
        "body": "目前 TN 没有处理英文单位的情况\r\n目前仅处理了摄氏度，参考：https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/t2s/frontend/zh_normalization/quantifier.py\r\n英文单位与汉字映射情况参考：https://github.com/NVIDIA/NeMo/blob/main/nemo_text_processing/text_normalization/zh/data/measure/units_en.tsv",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-10-31T13:00:26+00:00",
        "updated_at": "2022-11-09T06:45:04+00:00",
        "closed_at": "2022-11-09T06:45:04+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2599,
        "title": "gpu内存不够报错【已解决】",
        "body": "【已解决】\r\n终端输入nvidia-smi查看cuda版本\r\n参考 https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html\r\n选择对应cuda版本的paddle\r\n【原题】\r\n数据集有四千多条数据，但是之前五千多条的时候没有报错，为什么会这样呢？该怎么办？\r\n![Snipaste_2022-10-30_10-36-00](https://user-images.githubusercontent.com/110005064/198860038-980cf8ef-e9fe-4e43-b5f1-b37b892e18fd.png)\r\n",
        "state": "closed",
        "user": "yunqi777",
        "closed_by": "yt605155624",
        "created_at": "2022-10-30T02:39:50+00:00",
        "updated_at": "2022-11-01T15:13:49+00:00",
        "closed_at": "2022-11-01T15:13:49+00:00",
        "comments_count": [
            "yt605155624",
            "yunqi777",
            "yt605155624",
            "idreamerhx",
            "idreamerhx",
            "idreamerhx",
            "yt605155624",
            "idreamerhx",
            "idreamerhx",
            "yunqi777",
            "idreamerhx",
            "yunqi777"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2602,
        "title": "[S2T] U2模型：大数据训练会出错",
        "body": "大神你好。我在使用大数据量训练U2模型的时候，会有相应的报错（报错信息没保存下来）。大概意思就是内存问题。我的训练数据集月1700万数据量，总时长2万小时。数据大小超过1T。这个时候数据全部转出mel加载到`DataLoader`是加不进去的。请问这个地方能进行一个优化吗？谢谢大神。",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-01T01:28:01+00:00",
        "updated_at": "2023-01-21T04:45:44+00:00",
        "closed_at": "2023-01-21T04:45:43+00:00",
        "comments_count": [
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2604,
        "title": "请问fastspeech2声学模型中的while算子是在fastspeech2代码中哪个模块呢？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n我想了解下while算子里面的具体内容，但是我在代码中找不到while算子。\r\n\r\n![截图 2022-11-01 10-08-13](https://user-images.githubusercontent.com/37565801/199143162-6ffb51a0-e7ed-4487-96c9-d6ec717418e6.png)\r\n\r\n",
        "state": "closed",
        "user": "dzcmingdi",
        "closed_by": "yt605155624",
        "created_at": "2022-11-01T02:08:35+00:00",
        "updated_at": "2022-11-01T10:34:03+00:00",
        "closed_at": "2022-11-01T10:34:03+00:00",
        "comments_count": [
            "yt605155624",
            "dzcmingdi"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2603,
        "title": "暖和 搅和 这个“和”字发音huo，没有后面的数字",
        "body": null,
        "state": "closed",
        "user": "HandsLing",
        "closed_by": "yt605155624",
        "created_at": "2022-11-01T02:04:44+00:00",
        "updated_at": "2022-11-01T05:52:11+00:00",
        "closed_at": "2022-11-01T05:51:21+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2607,
        "title": "[TTS]一键微调功能问题",
        "body": "使用默认示例点击一键微调，终端微调完成，但是界面还是一直在微调中，前端控制台也有报错\r\n![2022-11-01 15-15-23屏幕截图](https://user-images.githubusercontent.com/62881198/199179417-929a9b62-12b0-496f-89cc-0bcda9e19e8c.png)\r\n",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "oyb1125",
        "created_at": "2022-11-01T07:16:27+00:00",
        "updated_at": "2023-10-12T08:10:23+00:00",
        "closed_at": "2022-11-01T09:43:46+00:00",
        "comments_count": [
            "iftaken",
            "wmlgl"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2605,
        "title": "in paddlespeech/cls/exps/panns/deploy/predict.py   from paddleaudio.features import melspectrogram error",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\nIn paddlespeech/cls/exps/panns/deploy/predict.py  file\r\n`import numpy as np\r\nfrom paddle import inference\r\nfrom paddleaudio.backends import load as load_audio\r\nfrom paddleaudio.datasets import ESC50\r\n**from paddleaudio.features import melspectrogram**\r\nfrom scipy.special import softmax`\r\nthe melspectrogram is error import, \r\nwhen in 'PaddleSpeech/examples/esc50/cls0' dir \r\nrun  './run.sh 4 cpu ./export /audio/dog.wav'\r\ngot \r\n`--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI1101 10:49:58.253744 1347346 analysis_predictor.cc:714] ======= optimize end =======\r\nI1101 10:49:58.253801 1347346 naive_executor.cc:98] ---  skip [feed], feed -> x\r\nI1101 10:49:58.254617 1347346 naive_executor.cc:98] ---  skip [linear_4.tmp_1], fetch -> fetch\r\n['/home/wayne/audio/dog.wav']\r\nW1101 10:49:58.256059 1347346 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.4, Runtime API Version: 11.2\r\nW1101 10:49:58.257632 1347346 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\nTraceback (most recent call last):\r\n  File \"/home/wayne/project/baidu/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 143, in <module>\r\n    results = predictor.predict(wavs)\r\n  File \"/home/wayne/project/baidu/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 119, in predict\r\n    feats = extract_features(wavs)\r\n  File \"/home/wayne/project/baidu/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 57, in extract_features\r\n    feat = MelSpectrogram(waveforms[i], sr, **kwargs).transpose()\r\n  File \"/home/wayne/.local/lib/python3.8/site-packages/paddleaudio/features/layers.py\", line 145, in __init__\r\n    self.fbank_matrix = compute_fbank_matrix(\r\n  File \"/home/wayne/.local/lib/python3.8/site-packages/paddleaudio/functional/functional.py\", line 179, in compute_fbank_matrix\r\n    fftfreqs = fft_frequencies(sr=sr, n_fft=n_fft, dtype=dtype)\r\n  File \"/home/wayne/.local/lib/python3.8/site-packages/paddleaudio/functional/functional.py\", line 145, in fft_frequencies\r\n    return paddle.linspace(0, float(sr) / 2, int(1 + n_fft // 2), dtype=dtype)`\r\nimport change to \r\n‘from paddleaudio.compliance.librosa import melspectrogram’\r\nthen can work.\r\n\r\n\r\n",
        "state": "closed",
        "user": "wayneck",
        "closed_by": "yt605155624",
        "created_at": "2022-11-01T03:08:05+00:00",
        "updated_at": "2022-11-01T08:55:05+00:00",
        "closed_at": "2022-11-01T08:55:05+00:00",
        "comments_count": [
            "yt605155624",
            "wayneck",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2611,
        "title": "运行打包后的程序报ModuleNotFoundError: No module named 'framework_pb2'",
        "body": null,
        "state": "closed",
        "user": "haoao1",
        "closed_by": "yt605155624",
        "created_at": "2022-11-02T02:35:22+00:00",
        "updated_at": "2022-11-02T02:39:20+00:00",
        "closed_at": "2022-11-02T02:39:20+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2609,
        "title": "文件下载到电脑失败",
        "body": "我从aistudio上下载我训练好的模型，但是下载一会儿就会断开\r\n我不是打包下载，而是把文件转为压缩包之后再下载\r\n请问各位大佬有没有什么更好的办法能稳定下载呢？",
        "state": "closed",
        "user": "yunqi777",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-01T10:05:31+00:00",
        "updated_at": "2023-03-25T12:06:29+00:00",
        "closed_at": "2023-03-25T12:06:29+00:00",
        "comments_count": [
            "lilith-zy",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2608,
        "title": "关于数据集",
        "body": "asr 训练用的数据集同一个人数据集有200个小时的\r\n这样训练效果怎么样？",
        "state": "closed",
        "user": "xjsdn",
        "closed_by": "yt605155624",
        "created_at": "2022-11-01T07:37:20+00:00",
        "updated_at": "2022-11-15T09:14:39+00:00",
        "closed_at": "2022-11-15T09:14:39+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2612,
        "title": "请问ASR支持多个音频文件的并行处理吗？没看到例子，模型应该是支持的吧？需求是大量音频文件，想把GPU跑满。",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "linuxnms",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-02T03:36:33+00:00",
        "updated_at": "2023-05-21T10:48:15+00:00",
        "closed_at": "2023-05-21T10:48:15+00:00",
        "comments_count": [
            "oyb1125",
            "zh794390558",
            "zh794390558",
            "stale[bot]",
            "dsyrock",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2618,
        "title": "server里application配置了text_python，程序一直hang住，无法启动",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "superzhaoyy",
        "closed_by": "superzhaoyy",
        "created_at": "2022-11-02T15:21:16+00:00",
        "updated_at": "2022-11-02T15:28:26+00:00",
        "closed_at": "2022-11-02T15:28:26+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2613,
        "title": "GPU又爆炸了(悲)",
        "body": "cuda11.2\r\n![image](https://user-images.githubusercontent.com/110005064/199388757-62ca4ce7-25ee-409b-a799-c066f6ce77a7.png)\r\n时好时坏，怎么会这样呢？",
        "state": "closed",
        "user": "yunqi777",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-02T03:39:53+00:00",
        "updated_at": "2023-01-21T04:45:43+00:00",
        "closed_at": "2023-01-21T04:45:42+00:00",
        "comments_count": [
            "yunqi777",
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2614,
        "title": "[TTS] Failed to convert onnx to TensorRT ",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nfailed to convert the onnx file generated by paddle2onnx to tensorRT model\r\n\r\n**To Reproduce**\r\n1. generator the files that paddle2onnx needed.\r\n```\r\ncd examples/csmsc/tts3/ \r\nsource path.sh \r\nFLAGS_allocator_strategy=naive_best_fit \r\nFLAGS_fraction_of_gpu_memory_to_use=0.01 \r\npython3 ${BIN_DIR}/../synthesize_e2e.py --am=fastspeech2_csmsc --am_config=fastspeech2_cnndecoder_csmsc_ckpt_1.0.0/cnndecoder.yaml --am_ckpt=fastspeech2_cnndecoder_csmsc_ckpt_1.0.0/snapshot_iter_153000.pdz --am_stat=fastspeech2_cnndecoder_csmsc_ckpt_1.0.0/speech_stats.npy --phones_dict=fastspeech2_cnndecoder_csmsc_ckpt_1.0.0/phone_id_map.txt --voc=hifigan_csmsc --voc_config=hifigan_csmsc_ckpt_0.1.1/default.yaml --voc_ckpt=hifigan_csmsc_ckpt_0.1.1/snapshot_iter_2500000.pdz --voc_stat=hifigan_csmsc_ckpt_0.1.1/feats_stats.npy --lang=zh --text=${BIN_DIR}/../sentences.txt --output_dir=exp/default/test_e2e --ngpu=0 --inference_dir=infer \r\n```\r\n2. ./local/paddle2onnx.sh . infer onnx fastspeech2_csmsc\r\n3. push the onnx file to NGC  [nvcr.io/nvidia/tensorrt:22.08-py3](http://nvcr.io/nvidia/tensorrt:22.08-py3)\r\n4. run trtexec --onnx=fastspeech2_csmsc.onnx --saveEngine=fastspeech2_csmsc.trt --best --fp16\r\n\r\n**Expected behavior**\r\nno error in trtexec log\r\n\r\n**Screenshots**\r\n[11/02/2022-06:15:54] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:367: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n[11/02/2022-06:15:56] [E] Error[9]: [graph.cpp::computeInputExecutionUses::553] Error Code 9: Internal Error (p2o.Conv.16: IConvolutionLayer cannot be used to compute a shape tensor)\r\n[11/02/2022-06:15:56] [E] [TRT] parsers/onnx/ModelImporter.cpp:773: While parsing node number 730 [ConstantOfShape -> \"p2o.ConstantOfShape.3\"]:\r\n[11/02/2022-06:15:56] [E] [TRT] parsers/onnx/ModelImporter.cpp:774: --- Begin node ---\r\n[11/02/2022-06:15:56] [E] [TRT] parsers/onnx/ModelImporter.cpp:775: input: \"p2o.auto.cast.87\"\r\noutput: \"p2o.ConstantOfShape.3\"\r\nname: \"p2o.ConstantOfShape.2\"\r\nop_type: \"ConstantOfShape\"\r\nattribute {\r\n  name: \"value\"\r\n  t {\r\n    dims: 1\r\n    data_type: 1\r\n    name: \"fill_constant_111.tmp_0\"\r\n    raw_data: \"\\000\\000\\000\\000\"\r\n  }\r\n  type: TENSOR\r\n}\r\n\r\n[11/02/2022-06:15:56] [E] [TRT] parsers/onnx/ModelImporter.cpp:776: --- End node ---\r\n[11/02/2022-06:15:56] [E] [TRT] parsers/onnx/ModelImporter.cpp:778: ERROR: parsers/onnx/ModelImporter.cpp:180 In function parseGraph:\r\n[6] Invalid Node - p2o.ConstantOfShape.2\r\n[graph.cpp::computeInputExecutionUses::553] Error Code 9: Internal Error (p2o.Conv.16: IConvolutionLayer cannot be used to compute a shape tensor)\r\n[11/02/2022-06:15:56] [E] Failed to parse onnx file\r\n[11/02/2022-06:15:56] [I] Finish parsing network model\r\n[11/02/2022-06:15:56] [E] Parsing model failed\r\n[11/02/2022-06:15:56] [E] Failed to create engine from model or file.\r\n[11/02/2022-06:15:56] [E] Engine set up failed\r\n&&&& FAILED TensorRT.trtexec [TensorRT v8402] # trtexec --onnx=fastspeech2_csmsc.onnx --saveEngine=fastspeech2_csmsc.trt --best --fp16\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version 3.8\r\n - PaddlePaddle Version  2.3.1\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo A100\r\n - CUDA/CUDNN Version 11.7\r\n - MKL Version\r\n- TensorRT Version 8.4.2-1+cuda11.6\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "ljliu",
        "closed_by": "yt605155624",
        "created_at": "2022-11-02T07:32:29+00:00",
        "updated_at": "2022-11-09T04:15:29+00:00",
        "closed_at": "2022-11-09T04:15:29+00:00",
        "comments_count": [
            "ljliu",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2616,
        "title": "win 10系统 anaconda 安装paddlespeech webrtcvad报错，vs 2022社区版已安装",
        "body": "Building wheels for collected packages: webrtcvad\r\n  Building wheel for webrtcvad (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × python setup.py bdist_wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [19 lines of output]\r\n      running bdist_wheel\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\\lib.win-amd64-cpython-37\r\n      copying webrtcvad.py -> build\\lib.win-amd64-cpython-37\r\n      running build_ext\r\n      building '_webrtcvad' extension\r\n      creating build\\temp.win-amd64-cpython-37\r\n      creating build\\temp.win-amd64-cpython-37\\Release\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\\signal_processing\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\\vad\r\n      D:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -D_WIN32 -Icbits -ID:\\Anaconda3\\envs\\paddlepaddle\\include -ID:\\Anaconda3\\envs\\paddlepaddle\\Include -ID:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include -ID:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\include /Tccbits\\pywebrtcvad.c /Fobuild\\temp.win-amd64-cpython-37\\Release\\cbits\\pywebrtcvad.obj\r\n      pywebrtcvad.c\r\n      D:\\Anaconda3\\envs\\paddlepaddle\\include\\pyconfig.h(59): fatal error C1083: 无法打开包括文件: “io.h”: No such file or directory\r\n      error: command 'D:\\\\VisualStudio\\\\IDE\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for webrtcvad\r\n  Running setup.py clean for webrtcvad\r\nFailed to build webrtcvad\r\nInstalling collected packages: webrtcvad, timer, textgrid, sentencepiece, opencc, jieba, flatbuffers, distance, braceexpand, appdirs, xxhash, win32-setctime, Werkzeug, websockets, typeguard, tqdm, threadpoolctl, tabulate, sniffio, regex, pyyaml, pypinyin, pydantic, pycryptodome, pybind11, pyarrow, praatio, ppft, pox, portalocker, pattern-singleton, paddle2onnx, onnxruntime, multidict, mock, lxml, llvmlite, kaldiio, jsonlines, joblib, itsdangerous, h5py, h11, g2pM, future, fsspec, frozenlist, filelock, editdistance, dill, cython, colorlog, bottleneck, Babel, audioread, asynctest, async-timeout, yarl, yacs, soundfile, scikit-learn, sacrebleu, responses, pyworld, pypinyin-dict, pooch, paddlespeech-feat, paddlefsl, numba, multiprocess, loguru, inflect, huggingface-hub, click, bce-python-sdk, anyio, aiosignal, uvicorn, starlette, seqeval, resampy, pathos, nltk, nara-wpe, flask, aiohttp, librosa, g2p-en, Flask-Babel, fastapi, visualdl, datasets, paddlenlp, paddlespeech\r\n  Running setup.py install for webrtcvad ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Running setup.py install for webrtcvad did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [21 lines of output]\r\n      running install\r\n      D:\\Anaconda3\\envs\\paddlepaddle\\lib\\site-packages\\setuptools\\command\\install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n        setuptools.SetuptoolsDeprecationWarning,\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\\lib.win-amd64-cpython-37\r\n      copying webrtcvad.py -> build\\lib.win-amd64-cpython-37\r\n      running build_ext\r\n      building '_webrtcvad' extension\r\n      creating build\\temp.win-amd64-cpython-37\r\n      creating build\\temp.win-amd64-cpython-37\\Release\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\\signal_processing\r\n      creating build\\temp.win-amd64-cpython-37\\Release\\cbits\\webrtc\\common_audio\\vad\r\n      D:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -D_WIN32 -Icbits -ID:\\Anaconda3\\envs\\paddlepaddle\\include -ID:\\Anaconda3\\envs\\paddlepaddle\\Include -ID:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include -ID:\\VisualStudio\\IDE\\VC\\Tools\\MSVC\\14.31.31103\\include /Tccbits\\pywebrtcvad.c /Fobuild\\temp.win-amd64-cpython-37\\Release\\cbits\\pywebrtcvad.obj\r\n      pywebrtcvad.c\r\n      D:\\Anaconda3\\envs\\paddlepaddle\\include\\pyconfig.h(59): fatal error C1083: 无法打开包括文件: “io.h”: No such file or directory\r\n      error: command 'D:\\\\VisualStudio\\\\IDE\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n× Encountered error while trying to install package.\r\n╰─> webrtcvad\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.",
        "state": "closed",
        "user": "longwangtang",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-02T14:28:45+00:00",
        "updated_at": "2024-09-24T07:42:20+00:00",
        "closed_at": "2023-01-21T04:45:41+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "dididiskq"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2617,
        "title": "ASR api接口，punc参数不生效",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "superzhaoyy",
        "closed_by": null,
        "created_at": "2022-11-02T14:49:52+00:00",
        "updated_at": "2023-07-06T06:17:47+00:00",
        "closed_at": null,
        "comments_count": [
            "superzhaoyy",
            "Javacr"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2619,
        "title": "TypeError: declarative() got an unexpected keyword argument 'property'",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n执行\r\n paddlespeech asr --lang zh --input zh.wav\r\n报错\r\n/home/PaddleSpeech/tools/venv/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nW1102 22:26:24.607908 24372 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.7, Runtime API Version: 10.2\r\nW1102 22:26:24.610229 24372 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n\r\n环境：\r\n\r\npaddlepaddle = 2.4rc\r\npython= 3.7\r\nlinux 7.9\r\n\r\n(/home/PaddleSpeech/tools/venv) [root@MiWiFi-R3D-srv tts3]# nvidia-smi \r\nWed Nov  2 22:37:52 2022       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n| 31%   34C    P0    39W / 215W |      0MiB /  8192MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n",
        "state": "closed",
        "user": "snailyang",
        "closed_by": "yt605155624",
        "created_at": "2022-11-03T02:38:26+00:00",
        "updated_at": "2022-11-03T12:15:22+00:00",
        "closed_at": "2022-11-03T12:15:22+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2623,
        "title": "ECAPA-TDNN 动转静问题",
        "body": "PaddleSpeech 提供的预训练模型 ECAPA-TDNN 动转静存在问题",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2022-11-03T13:35:40+00:00",
        "updated_at": "2022-12-27T14:14:04+00:00",
        "closed_at": null,
        "comments_count": [
            "gfhjjk",
            "stale[bot]"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2622,
        "title": "离线语音识别的解决方案",
        "body": "目前没有完整的 example，推荐 ds2 转 lite",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2022-11-03T13:34:02+00:00",
        "updated_at": "2024-03-09T09:31:42+00:00",
        "closed_at": null,
        "comments_count": [
            "fengmao31",
            "yt605155624",
            "stale[bot]",
            "fantasysea"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2631
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2633
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2634
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2624,
        "title": "KWS 动转静问题",
        "body": "PaddleSpeech 目前 CLI 中提供的 KWS 预训练模型动转静存在问题",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2022-11-03T13:37:27+00:00",
        "updated_at": "2022-12-27T14:14:25+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2626,
        "title": "安装成功了以后，运行asr报错，其他功能正常",
        "body": "## General Question\r\n\r\n(paddle) baker@bakertop:~/PaddleSpeech$ paddlespeech asr --lang zh --input zh.wav\r\n/home/baker/anaconda3/envs/paddle/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nW1104 17:15:45.559458 503005 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.4, Runtime API Version: 10.2\r\nW1104 17:15:45.559866 503005 gpu_resources.cc:91] device: 0, cuDNN Version: 8.6.\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n\r\n",
        "state": "closed",
        "user": "cyd1123",
        "closed_by": "yt605155624",
        "created_at": "2022-11-04T09:04:43+00:00",
        "updated_at": "2022-11-07T02:36:30+00:00",
        "closed_at": "2022-11-07T02:23:29+00:00",
        "comments_count": [
            "cyd1123",
            "cyd1123",
            "yt605155624",
            "cyd1123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2627,
        "title": "paddlespeech安装报错",
        "body": "docker镜像    paddlecloud/paddlespeech:develop-gpu-cuda10.2-cudnn7-fb4d25\r\n\r\n操作系统\r\nNAME=\"Ubuntu\"\r\nVERSION=\"16.04.7 LTS (Xenial Xerus)\"\r\nID=ubuntu\r\nID_LIKE=debian\r\nPRETTY_NAME=\"Ubuntu 16.04.7 LTS\"\r\nVERSION_ID=\"16.04\"\r\nHOME_URL=\"http://www.ubuntu.com/\"\r\nSUPPORT_URL=\"http://help.ubuntu.com/\"\r\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\r\nVERSION_CODENAME=xenial\r\nUBUNTU_CODENAME=xenial\r\n\r\npaddle版本\r\npaddlepaddle-gpu==2.4.0rc0\r\n\r\n在docker里安装Hard PaddleSpeech，执行步骤：\r\n1. choice1\r\n2. Install the Conda\r\n3. Install PaddlePaddle\r\n4. Install PaddleSpeech in Developing Mode\r\n\r\n执行pip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple时报错，报错如下：\r\n\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nObtaining file:///workspace/PaddleSpeech\r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: editdistance in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.6.1)\r\nRequirement already satisfied: g2p_en in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.1.0)\r\nRequirement already satisfied: g2pM in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.2.5)\r\nRequirement already satisfied: h5py in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.7.0)\r\nRequirement already satisfied: inflect in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (6.0.2)\r\nRequirement already satisfied: jieba in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.42.1)\r\nRequirement already satisfied: jsonlines in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.1.0)\r\nRequirement already satisfied: kaldiio in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.17.2)\r\nRequirement already satisfied: librosa==0.8.1 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.8.1)\r\nRequirement already satisfied: loguru in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.6.0)\r\nRequirement already satisfied: matplotlib in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.5.3)\r\nRequirement already satisfied: nara_wpe in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.0.8)\r\nRequirement already satisfied: onnxruntime==1.10.0 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.10.0)\r\nRequirement already satisfied: opencc in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.1.4)\r\nRequirement already satisfied: pandas in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.3.5)\r\nRequirement already satisfied: paddlenlp in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.4.2)\r\nRequirement already satisfied: paddlespeech_feat in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.0)\r\nRequirement already satisfied: Pillow>=9.0.0 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (9.2.0)\r\nRequirement already satisfied: praatio==5.0.0 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (5.0.0)\r\nRequirement already satisfied: protobuf<=3.20.0,>=3.1.0 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.20.0)\r\nRequirement already satisfied: pypinyin<=0.44.0 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.44.0)\r\nRequirement already satisfied: pypinyin-dict in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.4.0)\r\nRequirement already satisfied: python-dateutil in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.8.2)\r\nRequirement already satisfied: pyworld==0.2.12 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.12)\r\nRequirement already satisfied: resampy==0.2.2 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.2)\r\nRequirement already satisfied: sacrebleu in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.3.1)\r\nRequirement already satisfied: scipy in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.7.3)\r\nRequirement already satisfied: sentencepiece~=0.1.96 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.97)\r\nRequirement already satisfied: soundfile~=0.10 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.11.0)\r\nRequirement already satisfied: textgrid in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.5)\r\nRequirement already satisfied: timer in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.2)\r\nRequirement already satisfied: tqdm in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (4.64.1)\r\nRequirement already satisfied: typeguard in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.13.3)\r\nRequirement already satisfied: visualdl in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.4.1)\r\nRequirement already satisfied: webrtcvad in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.0.10)\r\nRequirement already satisfied: yacs~=0.1.8 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.8)\r\nRequirement already satisfied: prettytable in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.5.0)\r\nRequirement already satisfied: zhon in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.1.5)\r\nRequirement already satisfied: colorlog in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (6.7.0)\r\nRequirement already satisfied: pathos==0.2.8 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.8)\r\nRequirement already satisfied: braceexpand in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.7)\r\nRequirement already satisfied: pyyaml in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (6.0)\r\nRequirement already satisfied: pybind11 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.10.1)\r\nRequirement already satisfied: paddleslim==2.3.4 in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.3.4)\r\nRequirement already satisfied: fastapi in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.86.0)\r\nRequirement already satisfied: uvicorn in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.19.0)\r\nRequirement already satisfied: pattern_singleton in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.2.0)\r\nRequirement already satisfied: websockets in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (10.4)\r\nRequirement already satisfied: ConfigArgParse in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.5.3)\r\nRequirement already satisfied: coverage in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (6.5.0)\r\nRequirement already satisfied: gpustat in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.0.0)\r\nRequirement already satisfied: paddlespeech_ctcdecoders in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.1)\r\nRequirement already satisfied: phkit in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.2.11)\r\nRequirement already satisfied: pypi-kenlm in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (0.1.20220713)\r\nRequirement already satisfied: snakeviz in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.1.1)\r\nRequirement already satisfied: sox in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.4.1)\r\nRequirement already satisfied: soxbindings in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.2.3)\r\nRequirement already satisfied: unidecode in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (1.3.6)\r\nRequirement already satisfied: yq in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (3.1.0)\r\nRequirement already satisfied: pre-commit in ./tools/venv/lib/python3.7/site-packages (from paddlespeech==0.0.0) (2.20.0)\r\nRequirement already satisfied: decorator>=3.0.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (5.1.1)\r\nRequirement already satisfied: packaging>=20.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (21.3)\r\nRequirement already satisfied: numpy>=1.15.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (1.21.6)\r\nRequirement already satisfied: joblib>=0.14 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (1.2.0)\r\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (1.0.2)\r\nRequirement already satisfied: audioread>=2.0.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (3.0.0)\r\nRequirement already satisfied: pooch>=1.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (1.6.0)\r\nRequirement already satisfied: numba>=0.43.0 in ./tools/venv/lib/python3.7/site-packages (from librosa==0.8.1->paddlespeech==0.0.0) (0.56.4)\r\nRequirement already satisfied: flatbuffers in ./tools/venv/lib/python3.7/site-packages (from onnxruntime==1.10.0->paddlespeech==0.0.0) (22.10.26)\r\nRequirement already satisfied: pyzmq in ./tools/venv/lib/python3.7/site-packages (from paddleslim==2.3.4->paddlespeech==0.0.0) (24.0.1)\r\nRequirement already satisfied: ppft>=1.6.6.4 in ./tools/venv/lib/python3.7/site-packages (from pathos==0.2.8->paddlespeech==0.0.0) (1.7.6.6)\r\nRequirement already satisfied: multiprocess>=0.70.12 in ./tools/venv/lib/python3.7/site-packages (from pathos==0.2.8->paddlespeech==0.0.0) (0.70.12.2)\r\nRequirement already satisfied: dill>=0.3.4 in ./tools/venv/lib/python3.7/site-packages (from pathos==0.2.8->paddlespeech==0.0.0) (0.3.4)\r\nRequirement already satisfied: pox>=0.3.0 in ./tools/venv/lib/python3.7/site-packages (from pathos==0.2.8->paddlespeech==0.0.0) (0.3.2)\r\nRequirement already satisfied: typing-extensions in ./tools/venv/lib/python3.7/site-packages (from praatio==5.0.0->paddlespeech==0.0.0) (4.4.0)\r\nRequirement already satisfied: cython>=0.24.0 in ./tools/venv/lib/python3.7/site-packages (from pyworld==0.2.12->paddlespeech==0.0.0) (0.29.32)\r\nRequirement already satisfied: six>=1.3 in ./tools/venv/lib/python3.7/site-packages (from resampy==0.2.2->paddlespeech==0.0.0) (1.16.0)\r\nRequirement already satisfied: cffi>=1.0 in ./tools/venv/lib/python3.7/site-packages (from soundfile~=0.10->paddlespeech==0.0.0) (1.15.1)\r\nRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in ./tools/venv/lib/python3.7/site-packages (from fastapi->paddlespeech==0.0.0) (1.10.2)\r\nRequirement already satisfied: starlette==0.20.4 in ./tools/venv/lib/python3.7/site-packages (from fastapi->paddlespeech==0.0.0) (0.20.4)\r\nRequirement already satisfied: anyio<5,>=3.4.0 in ./tools/venv/lib/python3.7/site-packages (from starlette==0.20.4->fastapi->paddlespeech==0.0.0) (3.6.2)\r\nRequirement already satisfied: nltk>=3.2.4 in ./tools/venv/lib/python3.7/site-packages (from g2p_en->paddlespeech==0.0.0) (3.7)\r\nRequirement already satisfied: distance>=0.1.3 in ./tools/venv/lib/python3.7/site-packages (from g2p_en->paddlespeech==0.0.0) (0.1.3)\r\nRequirement already satisfied: blessed>=1.17.1 in ./tools/venv/lib/python3.7/site-packages (from gpustat->paddlespeech==0.0.0) (1.19.1)\r\nRequirement already satisfied: psutil>=5.6.0 in ./tools/venv/lib/python3.7/site-packages (from gpustat->paddlespeech==0.0.0) (5.9.3)\r\nRequirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in ./tools/venv/lib/python3.7/site-packages (from gpustat->paddlespeech==0.0.0) (11.495.46)\r\nRequirement already satisfied: attrs>=19.2.0 in ./tools/venv/lib/python3.7/site-packages (from jsonlines->paddlespeech==0.0.0) (22.1.0)\r\nRequirement already satisfied: cycler>=0.10 in ./tools/venv/lib/python3.7/site-packages (from matplotlib->paddlespeech==0.0.0) (0.11.0)\r\nRequirement already satisfied: fonttools>=4.22.0 in ./tools/venv/lib/python3.7/site-packages (from matplotlib->paddlespeech==0.0.0) (4.38.0)\r\nRequirement already satisfied: pyparsing>=2.2.1 in ./tools/venv/lib/python3.7/site-packages (from matplotlib->paddlespeech==0.0.0) (3.0.9)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in ./tools/venv/lib/python3.7/site-packages (from matplotlib->paddlespeech==0.0.0) (1.4.4)\r\nRequirement already satisfied: click in ./tools/venv/lib/python3.7/site-packages (from nara_wpe->paddlespeech==0.0.0) (8.1.3)\r\nRequirement already satisfied: bottleneck in ./tools/venv/lib/python3.7/site-packages (from nara_wpe->paddlespeech==0.0.0) (1.3.5)\r\nRequirement already satisfied: datasets>=2.0.0 in ./tools/venv/lib/python3.7/site-packages (from paddlenlp->paddlespeech==0.0.0) (2.6.1)\r\nRequirement already satisfied: paddlefsl in ./tools/venv/lib/python3.7/site-packages (from paddlenlp->paddlespeech==0.0.0) (1.1.0)\r\nRequirement already satisfied: paddle2onnx in ./tools/venv/lib/python3.7/site-packages (from paddlenlp->paddlespeech==0.0.0) (1.0.1)\r\nRequirement already satisfied: colorama in ./tools/venv/lib/python3.7/site-packages (from paddlenlp->paddlespeech==0.0.0) (0.4.6)\r\nRequirement already satisfied: seqeval in ./tools/venv/lib/python3.7/site-packages (from paddlenlp->paddlespeech==0.0.0) (1.2.2)\r\nRequirement already satisfied: mock in ./tools/venv/lib/python3.7/site-packages (from paddlespeech_feat->paddlespeech==0.0.0) (4.0.3)\r\nRequirement already satisfied: pytz>=2017.3 in ./tools/venv/lib/python3.7/site-packages (from pandas->paddlespeech==0.0.0) (2022.6)\r\nRequirement already satisfied: hanziconv in ./tools/venv/lib/python3.7/site-packages (from phkit->paddlespeech==0.0.0) (0.3.2)\r\nRequirement already satisfied: nodeenv>=0.11.1 in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (1.7.0)\r\nRequirement already satisfied: cfgv>=2.0.0 in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (3.3.1)\r\nRequirement already satisfied: identify>=1.0.0 in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (2.5.8)\r\nRequirement already satisfied: toml in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (0.10.2)\r\nRequirement already satisfied: virtualenv>=20.0.8 in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (20.16.6)\r\nRequirement already satisfied: importlib-metadata in ./tools/venv/lib/python3.7/site-packages (from pre-commit->paddlespeech==0.0.0) (4.13.0)\r\nRequirement already satisfied: wcwidth in ./tools/venv/lib/python3.7/site-packages (from prettytable->paddlespeech==0.0.0) (0.2.5)\r\nRequirement already satisfied: portalocker in ./tools/venv/lib/python3.7/site-packages (from sacrebleu->paddlespeech==0.0.0) (2.6.0)\r\nRequirement already satisfied: regex in ./tools/venv/lib/python3.7/site-packages (from sacrebleu->paddlespeech==0.0.0) (2022.10.31)\r\nRequirement already satisfied: lxml in ./tools/venv/lib/python3.7/site-packages (from sacrebleu->paddlespeech==0.0.0) (4.9.1)\r\nRequirement already satisfied: tabulate>=0.8.9 in ./tools/venv/lib/python3.7/site-packages (from sacrebleu->paddlespeech==0.0.0) (0.9.0)\r\nRequirement already satisfied: tornado>=2.0 in ./tools/venv/lib/python3.7/site-packages (from snakeviz->paddlespeech==0.0.0) (6.2)\r\nRequirement already satisfied: h11>=0.8 in ./tools/venv/lib/python3.7/site-packages (from uvicorn->paddlespeech==0.0.0) (0.14.0)\r\nRequirement already satisfied: Flask-Babel>=1.0.0 in ./tools/venv/lib/python3.7/site-packages (from visualdl->paddlespeech==0.0.0) (2.0.0)\r\nRequirement already satisfied: requests in ./tools/venv/lib/python3.7/site-packages (from visualdl->paddlespeech==0.0.0) (2.28.1)\r\nRequirement already satisfied: flask>=1.1.1 in ./tools/venv/lib/python3.7/site-packages (from visualdl->paddlespeech==0.0.0) (2.2.2)\r\nRequirement already satisfied: bce-python-sdk in ./tools/venv/lib/python3.7/site-packages (from visualdl->paddlespeech==0.0.0) (0.8.74)\r\nRequirement already satisfied: xmltodict>=0.11.0 in ./tools/venv/lib/python3.7/site-packages (from yq->paddlespeech==0.0.0) (0.13.0)\r\nRequirement already satisfied: argcomplete>=1.8.1 in ./tools/venv/lib/python3.7/site-packages (from yq->paddlespeech==0.0.0) (2.0.0)\r\nRequirement already satisfied: pycparser in ./tools/venv/lib/python3.7/site-packages (from cffi>=1.0->soundfile~=0.10->paddlespeech==0.0.0) (2.21)\r\nRequirement already satisfied: fsspec[http]>=2021.11.1 in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (2022.10.0)\r\nRequirement already satisfied: pyarrow>=6.0.0 in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (10.0.0)\r\nRequirement already satisfied: xxhash in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (3.1.0)\r\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (0.10.1)\r\nRequirement already satisfied: aiohttp in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (3.8.3)\r\nRequirement already satisfied: responses<0.19 in ./tools/venv/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (0.18.0)\r\nRequirement already satisfied: Jinja2>=3.0 in ./tools/venv/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlespeech==0.0.0) (3.1.2)\r\nRequirement already satisfied: itsdangerous>=2.0 in ./tools/venv/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlespeech==0.0.0) (2.1.2)\r\nRequirement already satisfied: Werkzeug>=2.2.2 in ./tools/venv/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlespeech==0.0.0) (2.2.2)\r\nRequirement already satisfied: Babel>=2.3 in ./tools/venv/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlespeech==0.0.0) (2.11.0)\r\nRequirement already satisfied: zipp>=0.5 in ./tools/venv/lib/python3.7/site-packages (from importlib-metadata->pre-commit->paddlespeech==0.0.0) (3.10.0)\r\nRequirement already satisfied: setuptools in ./tools/venv/lib/python3.7/site-packages (from nodeenv>=0.11.1->pre-commit->paddlespeech==0.0.0) (65.5.0)\r\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in ./tools/venv/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.8.1->paddlespeech==0.0.0) (0.39.1)\r\nRequirement already satisfied: appdirs>=1.3.0 in ./tools/venv/lib/python3.7/site-packages (from pooch>=1.0->librosa==0.8.1->paddlespeech==0.0.0) (1.4.4)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in ./tools/venv/lib/python3.7/site-packages (from requests->visualdl->paddlespeech==0.0.0) (2.1.1)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in ./tools/venv/lib/python3.7/site-packages (from requests->visualdl->paddlespeech==0.0.0) (1.26.12)\r\nRequirement already satisfied: idna<4,>=2.5 in ./tools/venv/lib/python3.7/site-packages (from requests->visualdl->paddlespeech==0.0.0) (3.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in ./tools/venv/lib/python3.7/site-packages (from requests->visualdl->paddlespeech==0.0.0) (2022.9.24)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in ./tools/venv/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->paddlespeech==0.0.0) (3.1.0)\r\nRequirement already satisfied: platformdirs<3,>=2.4 in ./tools/venv/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit->paddlespeech==0.0.0) (2.5.3)\r\nRequirement already satisfied: distlib<1,>=0.3.6 in ./tools/venv/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit->paddlespeech==0.0.0) (0.3.6)\r\nRequirement already satisfied: filelock<4,>=3.4.1 in ./tools/venv/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit->paddlespeech==0.0.0) (3.8.0)\r\nRequirement already satisfied: pycryptodome>=3.8.0 in ./tools/venv/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlespeech==0.0.0) (3.15.0)\r\nRequirement already satisfied: future>=0.6.0 in ./tools/venv/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlespeech==0.0.0) (0.18.2)\r\nRequirement already satisfied: sniffio>=1.1 in ./tools/venv/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->paddlespeech==0.0.0) (1.3.0)\r\nRequirement already satisfied: aiosignal>=1.1.2 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (1.2.0)\r\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (4.0.2)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (6.0.2)\r\nRequirement already satisfied: frozenlist>=1.1.1 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (1.3.1)\r\nRequirement already satisfied: asynctest==0.13.0 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (0.13.0)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in ./tools/venv/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->paddlespeech==0.0.0) (1.8.1)\r\nRequirement already satisfied: MarkupSafe>=2.0 in ./tools/venv/lib/python3.7/site-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl->paddlespeech==0.0.0) (2.1.1)\r\nInstalling collected packages: paddlespeech\r\n  Running setup.py develop for paddlespeech\r\n    error: subprocess-exited-with-error\r\n    \r\n    × python setup.py develop did not run successfully.\r\n    │ exit code: 1\r\n    ╰─> [89 lines of output]\r\n        \r\n        __version__ = '0.0.0'\r\n        \r\n        \r\n        __commit__ = 'd622b8bc5fb2cae106ef25fa7dfb329ea9ce2b34'\r\n        \r\n        write_version_py done\r\n        running develop\r\n        running egg_info\r\n        writing paddlespeech.egg-info/PKG-INFO\r\n        writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n        writing entry points to paddlespeech.egg-info/entry_points.txt\r\n        writing requirements to paddlespeech.egg-info/requires.txt\r\n        writing top-level names to paddlespeech.egg-info/top_level.txt\r\n        reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n        reading manifest template 'MANIFEST.in'\r\n        adding license file 'LICENSE'\r\n        writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n        running build_ext\r\n        Creating /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n        Adding paddlespeech 0.0.0 to easy-install.pth file\r\n        Installing paddlespeech script to /workspace/PaddleSpeech/tools/venv/bin\r\n        Installing paddlespeech_client script to /workspace/PaddleSpeech/tools/venv/bin\r\n        Installing paddlespeech_server script to /workspace/PaddleSpeech/tools/venv/bin\r\n        \r\n        Installed /workspace/PaddleSpeech\r\n        Post Install...\r\n        sudo apt update -y\r\n        \r\n        WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n        \r\n        Hit:1 http://archive.ubuntu.com/ubuntu xenial InRelease\r\n        Get:2 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [99.8 kB]\r\n        Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [99.8 kB]\r\n        Get:4 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [97.4 kB]\r\n        Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\r\n        Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease [1,581 B]\r\n        Err:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\r\n          The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\r\n        Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\r\n        Reading package lists...\r\n        W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\r\n        E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease' is not signed.\r\n        Makefile:27: recipe for target 'apt.done' failed\r\n        make: *** [apt.done] Error 100\r\n        /workspace/PaddleSpeech/tools\r\n        /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:774: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n          % (opt, underscore_opt)\r\n        /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:774: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n          % (opt, underscore_opt)\r\n        /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\r\n          warnings.warn(msg, warning_class)\r\n        /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n          EasyInstallDeprecationWarning,\r\n        /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n          setuptools.SetuptoolsDeprecationWarning,\r\n        /workspace/PaddleSpeech/setup.py:111: CMD: make, Error: None\r\n        Traceback (most recent call last):\r\n          File \"<string>\", line 36, in <module>\r\n          File \"<pip-setuptools-caller>\", line 34, in <module>\r\n          File \"/workspace/PaddleSpeech/setup.py\", line 329, in <module>\r\n            setup(**setup_info, include_package_data=True)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\r\n            return distutils.core.setup(**attrs)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n            return run_commands(dist)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n            dist.run_commands()\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\r\n            self.run_command(cmd)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py\", line 1217, in run_command\r\n            super().run_command(command)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\r\n            cmd_obj.run()\r\n          File \"/workspace/PaddleSpeech/setup.py\", line 174, in run\r\n            self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/cmd.py\", line 340, in execute\r\n            util.execute(func, args, msg, dry_run=self.dry_run)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/util.py\", line 337, in execute\r\n            func(*args)\r\n          File \"/workspace/PaddleSpeech/setup.py\", line 160, in _post_install\r\n            check_call(\"make\")\r\n          File \"/workspace/PaddleSpeech/setup.py\", line 114, in check_call\r\n            raise e\r\n          File \"/workspace/PaddleSpeech/setup.py\", line 108, in check_call\r\n            executable=\"/bin/bash\" if shell else executable)\r\n          File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/subprocess.py\", line 363, in check_call\r\n            raise CalledProcessError(retcode, cmd)\r\n        subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n        [end of output]\r\n    \r\n    note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× python setup.py develop did not run successfully.\r\n│ exit code: 1\r\n╰─> [89 lines of output]\r\n    \r\n    __version__ = '0.0.0'\r\n    \r\n    \r\n    __commit__ = 'd622b8bc5fb2cae106ef25fa7dfb329ea9ce2b34'\r\n    \r\n    write_version_py done\r\n    running develop\r\n    running egg_info\r\n    writing paddlespeech.egg-info/PKG-INFO\r\n    writing dependency_links to paddlespeech.egg-info/dependency_links.txt\r\n    writing entry points to paddlespeech.egg-info/entry_points.txt\r\n    writing requirements to paddlespeech.egg-info/requires.txt\r\n    writing top-level names to paddlespeech.egg-info/top_level.txt\r\n    reading manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    reading manifest template 'MANIFEST.in'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'paddlespeech.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    Creating /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/paddlespeech.egg-link (link to .)\r\n    Adding paddlespeech 0.0.0 to easy-install.pth file\r\n    Installing paddlespeech script to /workspace/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_client script to /workspace/PaddleSpeech/tools/venv/bin\r\n    Installing paddlespeech_server script to /workspace/PaddleSpeech/tools/venv/bin\r\n    \r\n    Installed /workspace/PaddleSpeech\r\n    Post Install...\r\n    sudo apt update -y\r\n    \r\n    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n    \r\n    Hit:1 http://archive.ubuntu.com/ubuntu xenial InRelease\r\n    Get:2 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [99.8 kB]\r\n    Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [99.8 kB]\r\n    Get:4 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [97.4 kB]\r\n    Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\r\n    Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease [1,581 B]\r\n    Err:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\r\n      The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\r\n    Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\r\n    Reading package lists...\r\n    W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\r\n    E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease' is not signed.\r\n    Makefile:27: recipe for target 'apt.done' failed\r\n    make: *** [apt.done] Error 100\r\n    /workspace/PaddleSpeech/tools\r\n    /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:774: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n      % (opt, underscore_opt)\r\n    /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py:774: UserWarning: Usage of dash-separated 'index-url' will not be supported in future versions. Please use the underscore name 'index_url' instead\r\n      % (opt, underscore_opt)\r\n    /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\r\n      warnings.warn(msg, warning_class)\r\n    /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n      EasyInstallDeprecationWarning,\r\n    /workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n      setuptools.SetuptoolsDeprecationWarning,\r\n    /workspace/PaddleSpeech/setup.py:111: CMD: make, Error: None\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 36, in <module>\r\n      File \"<pip-setuptools-caller>\", line 34, in <module>\r\n      File \"/workspace/PaddleSpeech/setup.py\", line 329, in <module>\r\n        setup(**setup_info, include_package_data=True)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n        return run_commands(dist)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n        dist.run_commands()\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/dist.py\", line 1217, in run_command\r\n        super().run_command(command)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\r\n        cmd_obj.run()\r\n      File \"/workspace/PaddleSpeech/setup.py\", line 174, in run\r\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/cmd.py\", line 340, in execute\r\n        util.execute(func, args, msg, dry_run=self.dry_run)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/site-packages/setuptools/_distutils/util.py\", line 337, in execute\r\n        func(*args)\r\n      File \"/workspace/PaddleSpeech/setup.py\", line 160, in _post_install\r\n        check_call(\"make\")\r\n      File \"/workspace/PaddleSpeech/setup.py\", line 114, in check_call\r\n        raise e\r\n      File \"/workspace/PaddleSpeech/setup.py\", line 108, in check_call\r\n        executable=\"/bin/bash\" if shell else executable)\r\n      File \"/workspace/PaddleSpeech/tools/venv/lib/python3.7/subprocess.py\", line 363, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['make']' returned non-zero exit status 2.\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
        "state": "closed",
        "user": "1nlplearner",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-07T08:32:06+00:00",
        "updated_at": "2023-06-25T18:46:06+00:00",
        "closed_at": "2023-03-25T12:04:46+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "joisonwk"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2632,
        "title": "小样本微调方案的采样率问题",
        "body": "## 小样本微调方案的采样率问题\r\n\r\n\r\n你好，我在学习这个文档来进行小样本微调：https://github.com/PaddlePaddle/PaddleSpeech/tree/7cc1d66863a48b50c2430059c8b84060d84b11a3/examples/other/tts_finetune/tts3\r\n但是我对于微调样本的音频要求有点困惑。我看到提供的csmsc_mini的音频是48000Hz，ljspeech_mini的音频是22050Hz，SSB0005_mini是44100Hz。然后我看到get_duration.py和extract_feature.py里面的采样率写死是24000Hz。请问是底层的代码中已经预先将音频都上采样/降采样到24000Hz来统一处理吗？\r\n\r\n我另外准备自己数据时对采样率需要有什么讲究吗？16kHz是不是会自动上采变成24k不会报错，只是可能效果会变差？\r\n\r\n谢谢！\r\n\r\n",
        "state": "closed",
        "user": "treya-lin",
        "closed_by": "yt605155624",
        "created_at": "2022-11-08T02:23:36+00:00",
        "updated_at": "2022-11-18T07:20:55+00:00",
        "closed_at": "2022-11-18T07:20:55+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2635,
        "title": "手撸ASR",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n有没有从0手撸ASR的例子呀，感觉官方给的例子都是用的套件，原理还不太明白，想找个手撸的例子看看",
        "state": "closed",
        "user": "2017040264",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-09T01:19:15+00:00",
        "updated_at": "2023-03-25T12:05:55+00:00",
        "closed_at": "2023-03-25T12:05:55+00:00",
        "comments_count": [
            "zh794390558",
            "iftaken",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2638,
        "title": "PaddleSpeech是否支持选择立体声声道",
        "body": "我查看文档和代码，仅仅发现PaddleSpeech支持sample_rate，并没有发现PaddleSpeech有设置单声道和立体声的地方。",
        "state": "closed",
        "user": "fengmao31",
        "closed_by": "fengmao31",
        "created_at": "2022-11-09T10:54:32+00:00",
        "updated_at": "2022-11-18T07:14:06+00:00",
        "closed_at": "2022-11-18T07:14:06+00:00",
        "comments_count": [
            "zh794390558",
            "fengmao31"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2642,
        "title": "PaddleSpeech是否支持16-bit pcm编码输出？",
        "body": "观察到PaddleSpeech是32-bit pcm的wav编码。\r\nPaddleSpeech是否支持16-bit pcm编码输出？\r\n或者有什么方法能够转换32-bit pcm输出到16-bit pcm输出？",
        "state": "closed",
        "user": "fengmao31",
        "closed_by": "yt605155624",
        "created_at": "2022-11-11T03:49:22+00:00",
        "updated_at": "2022-11-18T08:26:15+00:00",
        "closed_at": "2022-11-18T08:26:15+00:00",
        "comments_count": [
            "yt605155624",
            "fengmao31",
            "fengmao31",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2641,
        "title": "[S2T]ASR，使用官方脚本训练，存在内存泄漏",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n参考PPASR aishell1，https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1在V100上训练，使用示例脚本4卡训练，监控到内存一直在增长。\r\n使用API打印内存占用也能监控到内存不断增长。\r\n \r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 在PaddleSpeech/paddlespeech/s2t/exps/u2/model.py：196后加入如下打印：\r\n                            memory_allocated = paddle.device.cuda.memory_allocated() / 1024 / 1024\r\n                            max_memory_allocated = paddle.device.cuda.max_memory_allocated() / 1024 / 1024\r\n                            memory_reserved = paddle.device.cuda.memory_reserved() / 1024 / 1024\r\n                            max_memory_reserved = paddle.device.cuda.max_memory_reserved() / 1024 / 1024\r\n                            logger.info(f\"Step memory summary:allcated/max allocated: {memory_allocated:.3f}/{max_memory_allocated:.3f}, reserved/max reserved: {memory_reserved:.3f}/{max_memory_reserved:.3f}\")\r\n\r\n2. 执行脚本\r\ncd PaddleSpeech/examples/aishell/asr1\r\nbash run.sh --stage 0 --stop-stage 1\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n![image](https://user-images.githubusercontent.com/8046546/201251499-539b4a1d-fbdc-4b4b-96eb-c3fde592872a.png)\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu] registry.baidubce.com/paddlepaddle/paddle:latest-gpu-cuda10.2-cudnn7-dev\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7] 3.7\r\n - PaddlePaddle Version [e.g. 2.0.0] 2.3.2\r\n - Model Version [e.g. 2.0.0] 15ca007ea48147963fdafd18eb0551801c9215e3\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00] V100 32G\r\n - CUDA/CUDNN Version [e.g. cuda-10.2] 10.2\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "liddk",
        "closed_by": null,
        "created_at": "2022-11-11T02:45:15+00:00",
        "updated_at": "2022-11-18T08:54:02+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "liddk"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2644,
        "title": "AssertionError: choose a window size 400 that is [2, 1]",
        "body": "代码：\r\nimport paddle\r\nfrom paddlespeech.kws.models import MDTC\r\nfrom paddlespeech.kws.models.mdtc import KWSModel\r\n\r\n\r\nbackbone = MDTC(\r\n    stack_num=3,\r\n    stack_size=4,\r\n    in_channels=80,\r\n    res_channels=32,\r\n    kernel_size=5,\r\n)\r\nmodel = KWSModel(backbone=backbone, num_keywords=1)\r\nkws_checkpoint = './kws.pdparams'\r\nmodel.set_state_dict(paddle.load(kws_checkpoint))\r\nmodel.eval()\r\n\r\n\r\nimport paddleaudio\r\nfrom paddleaudio.compliance.kaldi import fbank\r\n\r\nfeat_func = lambda waveform, sr: fbank(\r\n    waveform=paddle.to_tensor(waveform).unsqueeze(0), \r\n    sr=sr, \r\n    frame_shift=10, \r\n    frame_length=25, \r\n    n_mels=80)\r\n\r\nkeyword_feat = feat_func(\r\n    *paddleaudio.load('./keyword.wav'))\r\nnon_keyword_feat = feat_func(\r\n    *paddleaudio.load('./non-keyword.wav'))\r\n    \r\n\r\nprint(keyword_feat.shape, non_keyword_feat.shape)\r\n\r\n\r\nkeyword_logits = model(keyword_feat.unsqueeze(0))\r\nkeyword_score = paddle.max(keyword_logits).numpy().item()\r\nprint(keyword_score)\r\nnon_keyword_logits = model(non_keyword_feat.unsqueeze(0))\r\nnon_keyword_score = paddle.max(non_keyword_logits).numpy().item()\r\nprint(non_keyword_score)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n执行结果：\r\nW1112 15:31:06.841100 17938 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.6, Runtime API Version: 10.2\r\nW1112 15:31:06.854442 17938 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"test3.py\", line 29, in <module>\r\n    keyword_feat = feat_func(\r\n  File \"test3.py\", line 22, in <lambda>\r\n    feat_func = lambda waveform, sr: fbank(\r\n  File \"/home/daydreamer/miniconda3/envs/python3.8/lib/python3.8/site-packages/paddleaudio/compliance/kaldi.py\", line 458, in fbank\r\n    waveform, window_shift, window_size, padded_window_size = _get_waveform_and_window_properties(\r\n  File \"/home/daydreamer/miniconda3/envs/python3.8/lib/python3.8/site-packages/paddleaudio/compliance/kaldi.py\", line 125, in _get_waveform_and_window_properties\r\n    assert 2 <= window_size <= len(waveform), (\r\nAssertionError: choose a window size 400 that is [2, 1]\r\n",
        "state": "closed",
        "user": "dayDreamer5920",
        "closed_by": "yt605155624",
        "created_at": "2022-11-12T07:57:17+00:00",
        "updated_at": "2023-11-01T07:57:54+00:00",
        "closed_at": "2022-12-02T13:17:27+00:00",
        "comments_count": [
            "yt605155624",
            "liuying66",
            "Change0028"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2645,
        "title": "paddlespeech-ctcdecoders 这个包的编译步骤有提供吗",
        "body": "在arm64环境没有找到相关的依赖包\r\n1.paddlespeech-ctcdecoders支持在arm64下编译后的正常使用吗？\r\n2.如果支持那么编译的步骤有提供相关的文档吗？环境依赖，编译步骤等...",
        "state": "closed",
        "user": "364378743",
        "closed_by": "yt605155624",
        "created_at": "2022-11-12T13:26:03+00:00",
        "updated_at": "2023-02-07T02:49:03+00:00",
        "closed_at": "2023-02-07T02:49:03+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2646,
        "title": "已知文本的话，语音比对和时间戳对齐有示例吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "lanyuer",
        "closed_by": "lanyuer",
        "created_at": "2022-11-14T03:24:01+00:00",
        "updated_at": "2022-11-18T03:35:18+00:00",
        "closed_at": "2022-11-18T03:35:18+00:00",
        "comments_count": [
            "zh794390558",
            "lanyuer"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2650
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2648,
        "title": "VITS 流式推理改进",
        "body": "您好 ，请问 VITS如果想做流式模型训练和推理，需要改哪几个模块？ 谢谢您的回复",
        "state": "closed",
        "user": "panxin801",
        "closed_by": "yt605155624",
        "created_at": "2022-11-14T06:20:57+00:00",
        "updated_at": "2022-11-16T10:32:58+00:00",
        "closed_at": "2022-11-16T10:32:58+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2651
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2649,
        "title": "[TTS]流式的TTS是否可以支持8000Hz 16bit的音频输出",
        "body": "流式的TTS是否可以支持8000Hz 16bit的音频输出",
        "state": "closed",
        "user": "fjcondy",
        "closed_by": "yt605155624",
        "created_at": "2022-11-14T09:44:17+00:00",
        "updated_at": "2022-11-16T10:32:50+00:00",
        "closed_at": "2022-11-16T10:32:50+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2652,
        "title": "声纹识别模型的多卡训练",
        "body": "切请问声纹识别模型ECAPA在进行多卡训练时（比如2卡），学习速率和batch_size 如何调整呢？保持原始吗？\r\n",
        "state": "closed",
        "user": "JJun-Guo",
        "closed_by": "yt605155624",
        "created_at": "2022-11-15T09:29:15+00:00",
        "updated_at": "2022-11-15T10:05:34+00:00",
        "closed_at": "2022-11-15T10:05:34+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2653,
        "title": "[TTS]wavernn合成报错",
        "body": "使用fastspeech2和wavernn进行合成，命令如下\r\n```\r\npython3 /home/aistudio/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py \\\r\n--am=fastspeech2_mix \\\r\n--am_config=/home/aistudio/checkpoint/fastspeech2_mix_ckpt_1.2.0/default.yaml \\\r\n--am_ckpt=/home/aistudio/work/exp_spkxtdt/output/checkpoints/snapshot_iter_113958.pdz \\\r\n--am_stat=/home/aistudio/checkpoint/fastspeech2_mix_ckpt_1.2.0/speech_stats.npy \\\r\n--voc=wavernn_csmsc \\\r\n--voc_config=/home/aistudio/checkpoint/wavernn_csmsc_ckpt_0.2.0/default.yaml \\\r\n--voc_ckpt=/home/aistudio/checkpoint/wavernn_csmsc_ckpt_0.2.0/snapshot_iter_400000.pdz \\\r\n--voc_stat=/home/aistudio/checkpoint/wavernn_csmsc_ckpt_0.2.0/feats_stats.npy \\\r\n--lang=mix \\\r\n--text=/home/aistudio/work/exp_spkxtdt/sentence.txt \\\r\n--output_dir=/home/aistudio/work/exp_spkxtdt/wav_out_rnn \\\r\n--phones_dict=/home/aistudio/checkpoint/fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt \\\r\n--speaker_dict=/home/aistudio/checkpoint/fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt \\\r\n--spk_id=0 \\\r\n--ngpu=1\r\n```\r\n\r\n经测试 fs2+pwg 运行正常，使用下面的方式调用 fs2+wavernn 合成成功，唯独使用synthesize_e2e.py合成失败\r\n```\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\ntts(text=\"欢迎使用飞桨！\",\r\n    output=\"output.wav\", \r\n    am=\"fastspeech2_mix\",\r\n    am_ckpt=am_ckpt,           # 微调后的模型地址\r\n    am_config = os.path.join(out_am_path, \"default.yaml\"),\r\n    am_stat = os.path.join(out_am_path, \"speech_stats.npy\"),\r\n    \r\n    phones_dict = os.path.join(out_am_path, \"phone_id_map.txt\"),\r\n    speaker_dict = os.path.join(out_am_path, \"speaker_id_map.txt\"),\r\n    spk_id = 0,\r\n    \r\n    voc = \"wavernn_csmsc\",\r\n    voc_config = os.path.join(out_vocoder_path, \"default.yaml\"),\r\n    voc_ckpt = os.path.join(out_vocoder_path, \"snapshot_iter_400000.pdz\"),\r\n    voc_stat = os.path.join(out_vocoder_path, \"feats_stats.npy\"),\r\n    lang=\"mix\"\r\n    )\r\n```",
        "state": "open",
        "user": "kslz",
        "closed_by": "kslz",
        "created_at": "2022-11-15T09:40:41+00:00",
        "updated_at": "2022-11-17T03:00:58+00:00",
        "closed_at": null,
        "comments_count": [
            "kslz",
            "yt605155624",
            "kslz",
            "yt605155624",
            "kslz",
            "yt605155624",
            "kslz",
            "kslz",
            "kslz"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2657,
        "title": "在windows下模型下载的默认路径可以更改吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "yt605155624",
        "created_at": "2022-11-16T02:41:42+00:00",
        "updated_at": "2022-11-16T03:31:34+00:00",
        "closed_at": "2022-11-16T03:31:34+00:00",
        "comments_count": [
            "yt605155624",
            "oyb1125"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2654,
        "title": "speedyspeech batchnorm的问题",
        "body": "\r\nspeedyspeech用到batchnorm, 模型的输入是padded phoneme sequence, 如果dataloader没有用到bucketization的话，sample的phoneme sequence length相差会很大。以下的batch norm没有考虑到padding，虽然不影响跑通代码，但是这应该会影响到模型收敛和模型质量吧？\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/f110928195edf5a078f5f621460ac0dcd9e0cc18/paddlespeech/t2s/models/speedyspeech/speedyspeech.py#L168",
        "state": "closed",
        "user": "binbinxue",
        "closed_by": "binbinxue",
        "created_at": "2022-11-15T11:48:27+00:00",
        "updated_at": "2022-12-27T13:58:58+00:00",
        "closed_at": "2022-11-15T12:10:55+00:00",
        "comments_count": [
            "yt605155624",
            "binbinxue",
            "binbinxue",
            "yt605155624",
            "binbinxue"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2665,
        "title": "[S2T]用confomer跑分类时半截报错，用的是asr1_chunk_conformer_u2pp_wenetspeech_ckpt_1.1.3的encoder",
        "body": "paddle 2.4rc\r\npaddlespeech是develop版本\r\ncuda11.6\r\ncudnn是8.4\r\nubuntu20.04\r\npy38\r\n![68600962845acd10a483d8879148fe8](https://user-images.githubusercontent.com/24219258/202608492-30f4603b-4bf8-43a3-9405-75c9855f4f64.jpg)\r\n",
        "state": "closed",
        "user": "janelu9",
        "closed_by": "janelu9",
        "created_at": "2022-11-18T03:13:53+00:00",
        "updated_at": "2022-11-23T05:54:41+00:00",
        "closed_at": "2022-11-23T02:48:10+00:00",
        "comments_count": [
            "zh794390558",
            "janelu9",
            "janelu9",
            "zh794390558",
            "janelu9",
            "janelu9",
            "janelu9"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2662,
        "title": "如何实现指定说话人音色的方言TTS？",
        "body": "请问下各位大佬，该怎么实现指定说话人音色的方言TTS？\r\n\r\n我尝试了微调tts3的方案，已经实现了说话人A的音色，接下来我该怎么实现让A说出方言呢？是不是直接继续用方言数据集进行微调？方言数据集是由其他说话人录制的，会干扰A的音色吗？",
        "state": "closed",
        "user": "guo453585719",
        "closed_by": "yt605155624",
        "created_at": "2022-11-17T09:08:50+00:00",
        "updated_at": "2022-11-21T02:19:41+00:00",
        "closed_at": "2022-11-21T02:19:41+00:00",
        "comments_count": [
            "yt605155624",
            "guo453585719",
            "yt605155624",
            "guo453585719"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2668,
        "title": "Add Andorid demo for TTS ",
        "body": "refer to: https://github.com/PaddlePaddle/Paddle-Lite-Demo",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-11-18T07:31:18+00:00",
        "updated_at": "2022-12-09T05:06:48+00:00",
        "closed_at": "2022-12-09T05:06:48+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2659,
        "title": "[TTS]aishell3/tts3训练时报错",
        "body": "执行./run.sh --stage 1 --stop-stage 1时报错\r\nTypeError: __init__() got an unexpected keyword argument 'enable_spk_cls'\r\n这是什么原因",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "oyb1125",
        "created_at": "2022-11-16T13:27:58+00:00",
        "updated_at": "2022-11-17T08:07:54+00:00",
        "closed_at": "2022-11-17T01:28:09+00:00",
        "comments_count": [
            "yt605155624",
            "oyb1125"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2669,
        "title": "[TTS] 粤语语音合成调研",
        "body": "粤语，又称广东话、广府话、白话。历史比较悠久，粤语是南方方言里面保留中古汉语成分较多的一种。其中最突出的特色就是它较为完整地保留了中古汉语普遍存在的入声，其声母、韵母、声调与古汉语标准韵书《广韵》高度吻合。国学大师南怀谨先生认为粤语是唐代国语。\r\n\r\n据说，1911年中华民国成立后，首届国会中有人提议奉广州话为国语；当时来自广东的国会议员刚好过半数，通过这一法案似乎不成问题。不过，身为广东人的临时大总统孙中山为了顾全革命大局，劝说粤籍议员放弃以粤语为国语。结果，北京话以一票之差压倒广州话成为国语。\r\n\r\n粤语目前主要分布于广东、 广西、 香港和澳门。\r\n两省区的粤语分为广府、 四邑、 高阳、 勾漏、 吴化、 琶得、 钦廉 7 片。\r\n\r\n片区|特点\r\n-- | --\r\n广府 | 是粤语中最具影响、使用人数最多的一片方言, 主要分布于广东珠江三角洲一带, 及广西西江流域上游的部分地区。还有香港、 澳门两个地区，大部分海外粤语区。\r\n四邑 | 主要分布于广东潭江流域的一些地方。\r\n高阳 | 主要分布于粤西南。\r\n吴化 | 主要集中于茂名西南、 湛江以东的海湾地带。\r\n勾漏 | 主要分布于广东西部的清远、 肇庆两市所辖的部分地 区及广西东部地带。\r\n琶得 | 广西壮族自治区的中西部与北部的大多数地区。\r\n钦廉 | 广西壮族自治区东南隅。\r\n\r\n广州(广府)话是粤方言区最有 代表性的方言，当然也是大湾区最有代表性的方言，以至于一般人经常把广州话跟粤方言，甚至跟广东话混为一谈。有分城内音（东山口音）、西关口音等等。虽然西关口音被视为标准广州话口音，但现在依《广州音字典》所收字音来看，并没有专门视西关口音为主收对象，而是以当前珠三角广府人通用口音为标准。\r\n\r\n### 港澳地区与广州粤语的区别([Ref](https://www.zhihu.com/question/20663233))\r\n总的来说差别不大。有些差异只表现在“使用频率”上，有些则表现在“年龄层次”上，如一些香港人使用的外语借词，广州的中老年人可能听不懂，年轻 人则能听懂一部分或接近全能听懂，而一些香港人现仍使用的‘旧词’，广州的老年人则可能比年轻 人较能理解一些。\r\n\r\n1. 腔调的区别：由于香港人成份复杂，移民众多，由此产生不少变化。比如，懒音很重，经常前后鼻音、l和n不分，声调比较高，听起来自带温柔的调性，最适合用来唱情深款款的情歌，这也是为什么香港流行歌的传唱度会特别高。\r\n2. 部分字发音不同：上世纪70年代，香港的官方语言定为“广州粤语”，表示要有西关口音。然而在当时，香港中文大学的何文汇教授反对这一点，他认为标准粤语应该按照北宋初年的《广韵》的音。于是，在香港出现了两大流派，一是以广州话为代表的现代粤语，另一派便是遵循古籍的复古粤语。\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695772-3c3ecb80-0ebc-4a83-828b-5c89fb1a215c.png\" width=\"500\">\r\n3. 部分用词习惯不同：\r\n香港的外来词比较多，常常会有直接用英语译音作为词语，如士多啤梨（草莓）、的士（出租车）、维他命（维生素）等。\r\n而广式粤语受普通话影响较多，很多就是普通话按粤语读出来\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695817-beb00346-b358-4dde-beeb-c263952ab619.png\" width=\"500\">\r\n\r\n\r\n### 粤语拼音\r\n粤语没有统一的拼音方案，甚至不同的粤语字典的拼音也会不同，现今最常用的是1993香港语言学学会粤语拼音方案，简称粤拼（英文：Jyutping）。([Ref](https://www.zhihu.com/question/39827067)，[Ref](https://www.bilibili.com/video/BV1aY4y1z76a/))\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695856-d58cffae-4dfe-42a6-9836-b4e1c45e64fd.png\" width=\"600\">\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695869-265bff5d-87ea-4b3a-bc62-0cda8f0ea17f.png\" width=\"600\">\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695882-fcb209f1-3fb6-4e3b-a6b5-b7f1bee38da5.png\" width=\"600\">\r\n\r\n有些韵腹可以作为结尾，而有些则需要结合韵尾。\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695900-55e9ef6d-1d42-4a73-adbd-4f6e789783c3.png\" width=\"600\">\r\n\r\n关于九声六调：\r\n阴平、阴上、阴去、阳平、阳上、阳去、阴入、中入、阳入\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695921-e3f8ea61-ee0e-48ce-ad09-ec95fc1c344d.png\" width=\"600\">\r\n\r\n一般而言只有六调，即六种不同调值的发音（第一声到第六声）。前三种为阴，较为高，后三种为阳，较为低沉\r\n\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695938-7e07882d-a73a-4aaa-80c3-7c17e01be6ba.png\" width=\"600\">\r\n\r\n而九声，就是另外三个入声（ptk结尾，只做口型不发音）。相同点：音高相同；不同点：顿挫性（短促版本的发音，听上去就比较有顿挫感）。所以加上顿挫性的差异就有九声了。\r\n第7声调约等于粤语发音第1声调\r\n第8声调约等于粤语发音第3声调\r\n第9声调约等于粤语发音第6声调\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695960-e5bfefff-0a09-4d4c-bdb6-dcfa78f53874.png\" width=\"600\">\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695972-099e3552-a72e-45fa-8d50-fea205413df8.png\" width=\"600\">\r\n<img src=\"https://user-images.githubusercontent.com/24568452/202695991-67df8345-fd61-494e-ae66-ccf31fe49d36.png\" width=\"600\">\r\n\r\n为什么会有这种差异：1）语音学上说，只要调值一致就是同一声调，不考虑其他因素；2）汉语语音学上说，声调的意义包含了抑扬和顿挫，抑扬就是音高和调值，而顿挫就是舒音和促声。\r\n\r\nnote：ptk本身就带有调值属性，所以后面的数字也可以不用写\r\n所以具体含义是，九种声调，六种音高。\r\n\r\n\r\n### 数据集\r\n\r\n| |时长|人数|句子|话题|录制环境|格式|文本|\r\n| -- | -- | --| --| --| --| --|--|\r\n|https://magichub.com/datasets/guangzhou-cantonese-conversational-speech-corpus/|4.25h|20|10 </br>(需要切分)|日常|手机|wav|粤语字|\r\n|https://magichub.com/datasets/guangzhou-cantonese-scripted-speech-corpus-daily-use-sentence/|4.06|10|4,060|日常|手机|wav|粤语字和普通话字|\r\n|https://magichub.com/datasets/guangzhou-cantonese-scripted-speech-corpus-in-the-vehicle/|5|10|6,219|数字，</br> 命令，</br>询问|麦克风（车里|wav|粤语字|\r\n|https://github.com/hltchkust/cantonese-asr https://storage.googleapis.com/samcah-bucket/cantonese-asr/cantonese_dataset.zip|73.6| |83,275|philosophy, politics, education, culture, lifestyle, family||fbank, npy（参数未知|\r\n|https://github.com/gwinterstein/CantoMap|12.48|40||地图|\r\n|Common Voice 11版|106|2943||日常|||\r\n\r\n### 工具\r\n\r\n1. 粤拼输入法：\r\n- https://github.com/rime/rime-cantonese\r\n3. 分词：\r\n- https://github.com/wchan757/Cantonese_Word_Segmentation\r\n- https://github.com/meganndare/cantonese-nlp\r\n4. 一些粤语词典：\r\n- https://github.com/Gahory/Mandarin2Cantonese/tree/main/resources\r\n- https://github.com/mirfan899/CTTS/blob/master/misc/cantonese_mtts.lexicon\r\n- https://github.com/soon14/cantoneseTTS/tree/master/src/cantoneseTTS\r\n5. G2P：\r\n- https://github.com/imdreamrunner/python-jyutping 用法简单，多音字有歧义\r\n\t<img src=\"https://user-images.githubusercontent.com/24568452/202696027-daf6590e-0a87-4d20-9bba-3893c238511f.png\" width=\"500\">\r\n\t\r\n- https://github.com/jacksonllee/pycantonese 大而全，但g2p时会带有分词功能，需要后续进一步处理\r\n\t<img src=\"https://user-images.githubusercontent.com/24568452/202696107-6d559fb4-bc92-4f64-baca-7b717558be8e.png\" width=\"500\">\r\n\t\r\n- https://github.com/CanCLID/ToJyutping 用法简单，支持多音字\r\n\t<img src=\"https://user-images.githubusercontent.com/24568452/202696203-780c2068-0b80-4f7a-aa0e-6a2973f39290.png\" width=\"500\">\r\n\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-11-18T11:34:45+00:00",
        "updated_at": "2024-05-11T12:44:10+00:00",
        "closed_at": "2023-02-16T02:16:43+00:00",
        "comments_count": [
            "stale[bot]",
            "yt605155624",
            "yt605155624",
            "pengzhendong"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2671,
        "title": "[TTS] Voice Conversion",
        "body": "- https://github.com/PaddlePaddle/PaddleSpeech/pull/2842\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/3143",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-11-18T11:39:22+00:00",
        "updated_at": "2023-04-07T11:25:24+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2672,
        "title": "[S2T]ImportError: cannot import name dataclass_transform",
        "body": "Any one install successful but run with error?\r\n\r\nWhen I finished installation successfully with no error, I try to run [Punctuation Restoration]:\r\nCommand:   paddlespeech text --task punc --input 今天的天气真不错啊你下午有空吗我想约你一起去吃饭\r\n\r\nThen, an error appear:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/lgx/anaconda3/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/cli/text/__init__.py\", line 14, in <module>\r\n    from .infer import TextExecutor\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/cli/text/infer.py\", line 29, in <module>\r\n    from paddlespeech.text.models.ernie_linear import ErnieLinear\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/text/models/__init__.py\", line 15, in <module>\r\n    from .ernie_linear import ErnieLinear\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/text/models/ernie_linear/__init__.py\", line 16, in <module>\r\n    from .ernie_linear_updater import *\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/text/models/ernie_linear/ernie_linear_updater.py\", line 24, in <module>\r\n    from paddlespeech.t2s.training.extensions.evaluator import StandardEvaluator\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/t2s/__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/t2s/frontend/__init__.py\", line 15, in <module>\r\n    from .normalizer import *\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/t2s/frontend/normalizer/__init__.py\", line 14, in <module>\r\n    from paddlespeech.t2s.frontend.normalizer.normalizer import *\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/t2s/frontend/normalizer/normalizer.py\", line 18, in <module>\r\n    from paddlespeech.t2s.frontend.normalizer.numbers import normalize_numbers\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/paddlespeech/t2s/frontend/normalizer/numbers.py\", line 17, in <module>\r\n    import inflect\r\n  File \"/home/lgx/anaconda3/lib/python3.7/site-packages/inflect/__init__.py\", line 76, in <module>\r\n    from pydantic import Field, validate_arguments\r\n  File \"pydantic/__init__.py\", line 2, in init pydantic.__init__\r\n  File \"pydantic/dataclasses.py\", line 52, in init pydantic.dataclasses\r\n    #   |\r\nImportError: cannot import name dataclass_transform\r\n\r\n\r\n\r\n\r\nHow can I fix it? thanks.",
        "state": "open",
        "user": "KHLau96",
        "closed_by": null,
        "created_at": "2022-11-19T09:00:31+00:00",
        "updated_at": "2023-03-21T14:39:55+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "wizardforcel",
            "vscv"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2673,
        "title": "[TTS]命令行tts调用了错误的英文模型",
        "body": "运行\r\ntts = TTSExecutor()\r\ntts(text=\"hello world\", output=\"output.wav\", lang=\"en\")\r\n\r\n报错提示：\r\n![image](https://user-images.githubusercontent.com/54951765/202890199-0569c1ba-ccda-4f39-87a3-c99f1ba55358.png)\r\n",
        "state": "closed",
        "user": "kslz",
        "closed_by": "yt605155624",
        "created_at": "2022-11-20T07:06:49+00:00",
        "updated_at": "2022-11-21T02:26:39+00:00",
        "closed_at": "2022-11-21T02:26:39+00:00",
        "comments_count": [
            "kslz",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2675,
        "title": "使用hifigan时报错",
        "body": "![image](https://user-images.githubusercontent.com/108966996/202975417-d1c8f711-97a8-49a6-8a36-3f98ed3ac61d.png)\r\n请问这个错误是怎么回事呢",
        "state": "closed",
        "user": "AlphaMind123",
        "closed_by": "yt605155624",
        "created_at": "2022-11-21T05:53:57+00:00",
        "updated_at": "2023-02-07T02:46:11+00:00",
        "closed_at": "2023-02-07T02:46:11+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2681,
        "title": "Speaker Diarization task: why do we use the reference rttms for obtaining time intervals(subsegments)?",
        "body": "I tried to implement the diarization project present in the folder _examples/ami/sd0/_. I first ran the example on the Amicorpus dataset and the DER results were accurate with the performances presented in the description of the project. Then I tried to adapt the example to create a script for end-to-end inference on an unknown audio file, and here is where I faced a couple of questions.\r\n\r\nFrom what I understood from the code, the pipeline is as follows:\r\n1. Chose the audio files from the Amicorpus with local/ami_splits.py.\r\n2. Prepare metadata using the reference rttm files for each audio. From the reference rttm files we EXTRACT THE SUBSEGMENTS' durations, without the speaker_id info.\r\n3. We feed the subsegments to the embeddings extractor from the _*.subseg.json_ file.\r\n4. We perform diarization on the output of the embedding extraction step.\r\n5. We calculate DER using diarization result and reference rttm.\r\n\r\nAt first, I tried to diarize an audio file without using VAD or the time intervals from the refference rttms and I got big differences in performance results. Without VAD or the reference rttms, I considered the an interval from (0 to duration of audio), from which I obtained subsegments using the same method you implemented. The difference in performance were huge: from 3.96% DER(using the reference rttm to get subsegments) to 63% DER(without using the reference rttm to get subsegments).\r\n\r\nMy questions are: why do we use the reference rttm files to extract the subsegments durations? Shouldn't there be a VAD implemented before the embeddings extraction step? It looks more like an example to show the implementation of the clustering methods for the diarization at the moment. Is it a functionality that will be implemented in the future?(the subsegments extraction without reference rttms or VAD)\r\n\r\nThank you in advance and I'm looking forward to your answer!\r\n",
        "state": "closed",
        "user": "gabitza-tech",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-23T09:18:50+00:00",
        "updated_at": "2023-03-25T12:03:14+00:00",
        "closed_at": "2023-03-25T12:03:14+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2676,
        "title": "在windows上使用speech_web报错",
        "body": "按照教程前后端都启动成功了\r\n但是点击使用功能时就没反应，这是怎么回事\r\n![image](https://user-images.githubusercontent.com/62881198/202985960-e5f4930a-06e2-436f-a12b-3418664a5a53.png)\r\n![image](https://user-images.githubusercontent.com/62881198/202985311-b37e8e2f-7399-4499-9b19-1f74804c791b.png)\r\n![image](https://user-images.githubusercontent.com/62881198/202986045-5030a926-3817-4958-ab1d-d8102a918823.png)\r\n",
        "state": "closed",
        "user": "oyb1125",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-21T07:05:43+00:00",
        "updated_at": "2023-03-25T12:01:06+00:00",
        "closed_at": "2023-03-25T12:01:06+00:00",
        "comments_count": [
            "iftaken",
            "oyb1125",
            "iftaken",
            "oyb1125",
            "iftaken",
            "oyb1125",
            "iftaken",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2678,
        "title": "[TTS] 流式tts输出音素在音频文件的时间戳信息",
        "body": "online-onnx 输出音素对应的时间戳信息，比如 **今天天气怎么样**，输出phone的时间戳信息。",
        "state": "closed",
        "user": "changyuzhe",
        "closed_by": "yt605155624",
        "created_at": "2022-11-22T04:48:38+00:00",
        "updated_at": "2023-10-26T10:50:59+00:00",
        "closed_at": "2022-11-22T05:50:35+00:00",
        "comments_count": [
            "yt605155624",
            "changyuzhe",
            "changyuzhe",
            "yt605155624",
            "changyuzhe",
            "yt605155624",
            "changyuzhe",
            "changyuzhe",
            "yt605155624",
            "Sloaix",
            "zhuxiu1234",
            "Sloaix"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2682,
        "title": "请问，fastspeech2 模型能否进行paddleslim 量化呢？声学模型部署，onnx 能否支持tensorrt 优化？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "liroda",
        "closed_by": "yt605155624",
        "created_at": "2022-11-24T10:57:35+00:00",
        "updated_at": "2022-12-09T06:10:46+00:00",
        "closed_at": "2022-12-09T06:10:46+00:00",
        "comments_count": [
            "yt605155624",
            "liroda",
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2687,
        "title": "ImportError: cannot import name 'load' from 'paddleaudio.backends'",
        "body": "## Others\r\n\r\n<img width=\"723\" alt=\"image\" src=\"https://user-images.githubusercontent.com/61535808/203936174-a2633803-4950-47b6-8608-063e7efd786c.png\">\r\n",
        "state": "closed",
        "user": "MelanthaWang246",
        "closed_by": "yt605155624",
        "created_at": "2022-11-25T08:31:51+00:00",
        "updated_at": "2022-12-02T13:15:35+00:00",
        "closed_at": "2022-11-28T17:44:17+00:00",
        "comments_count": [
            "yt605155624",
            "MelanthaWang246",
            "wangtiance",
            "yt605155624"
        ],
        "labels": [
            "Audio"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2696
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2689,
        "title": "UnicodeDecodeError: 'gbk' codec can't decode byte 0x8c in position 2088: illegal multibyte sequence",
        "body": "![image](https://user-images.githubusercontent.com/8639389/204082536-59031b28-0737-4286-abd7-40031fe45c45.png)",
        "state": "closed",
        "user": "stuyun",
        "closed_by": "yt605155624",
        "created_at": "2022-11-26T09:46:53+00:00",
        "updated_at": "2024-01-17T06:51:15+00:00",
        "closed_at": "2023-02-02T05:04:22+00:00",
        "comments_count": [
            "stuyun",
            "yt605155624",
            "bbqkj",
            "yfqvip",
            "Darksiderlyd"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2690,
        "title": "添加其他语言模型",
        "body": "![image](https://user-images.githubusercontent.com/8639389/204117042-0a7b0f84-e8ba-4a23-afb5-c6278a4c7e7a.png)\r\n![image](https://user-images.githubusercontent.com/8639389/204117053-7a3d1cc1-794c-4442-b43e-a060ac6b751c.png)\r\n",
        "state": "closed",
        "user": "stuyun",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-27T02:50:03+00:00",
        "updated_at": "2023-03-25T12:01:08+00:00",
        "closed_at": "2023-03-25T12:01:08+00:00",
        "comments_count": [
            "lym0302",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2691,
        "title": "ST相关：FileNotFoundError: [WinError 2] 系统找不到指定的文件。",
        "body": "as I run `paddlespeech st --input en.wav`\r\nI get \r\n`(venv) E:\\Github_repository\\PaddleSpeech>paddlespeech st --input en.wav\r\nE:\\Github_repository\\PaddleSpeech\\venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2022-11-27 20:24:35.447 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2022-11-27 20:24:36.027 | INFO     | paddlespeech.s2t.models.u2_st.u2_st:_init_from_config:581 - U2 Encoder type: transformer\r\n2022-11-27 20:24:38.496 | INFO     | paddlespeech.s2t.models.u2_st.u2_st:_init_from_config:596 - ASR Joint Training Weight: 0.5\r\nFileNotFoundError: [WinError 2] 系统找不到指定的文件。\r\n(venv) E:\\Github_repository\\PaddleSpeech>\r\n`\r\nas I run the code below\r\n`from paddlespeech.cli.st.infer import STExecutor\r\nst = STExecutor()\r\nresult = st(audio_file=\"en.wav\")\r\n`\r\nI get\r\n`E:\\Github_repository\\PaddleSpeech\\venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2022-11-27 20:21:40.534 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2022-11-27 20:21:40.877 | INFO     | paddlespeech.s2t.models.u2_st.u2_st:_init_from_config:581 - U2 Encoder type: transformer\r\n2022-11-27 20:21:42.771 | INFO     | paddlespeech.s2t.models.u2_st.u2_st:_init_from_config:596 - ASR Joint Training Weight: 0.5\r\nTraceback (most recent call last):\r\n  File \"E:\\Github_repository\\PaddleSpeech\\my_demo\\en2zh_demo.py\", line 7, in <module>\r\n    result = st(audio_file=\"en.wav\")\r\n  File \"E:\\Github_repository\\PaddleSpeech\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"E:\\Github_repository\\PaddleSpeech\\paddlespeech\\cli\\st\\infer.py\", line 346, in __call__\r\n    self.preprocess(audio_file, model)\r\n  File \"E:\\Github_repository\\PaddleSpeech\\paddlespeech\\cli\\st\\infer.py\", line 206, in preprocess\r\n    fbank_extract_process = subprocess.Popen(\r\n  File \"D:\\python\\lib\\subprocess.py\", line 947, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"D:\\python\\lib\\subprocess.py\", line 1416, in _execute_child\r\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\r\nFileNotFoundError: [WinError 2] 系统找不到指定的文件。\r\n\r\nProcess finished with exit code 1\r\n`\r\n\r\nit seems to be something missing with my user_path or system_path environment parameters, but I have no idea.\r\n",
        "state": "closed",
        "user": "LaHeriody",
        "closed_by": "LaHeriody",
        "created_at": "2022-11-27T12:30:02+00:00",
        "updated_at": "2022-11-28T02:55:08+00:00",
        "closed_at": "2022-11-28T02:55:08+00:00",
        "comments_count": [
            "zh794390558",
            "LaHeriody"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2695,
        "title": "[TTS]流式接口调用失败，docker内正常调用，docker外报错",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n流式接口paddlespeech_client tts_online在docker外调用失败，docker外安装了简单版的pip库。\r\n\r\n\r\ndocker内部正常调用：\r\n/home/PaddleSpeech/demos/streaming_tts_server bash test_client.sh\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2022-11-28 10:28:30,339] [    INFO] - tts http client start\r\n[2022-11-28 10:28:30,339] [    INFO] - endpoint: http://127.0.0.1:20620/paddlespeech/tts/streaming\r\n[2022-11-28 10:28:31,822] [    INFO] - sentence: 您好，欢迎使用百度飞桨语音合成服务。\r\n[2022-11-28 10:28:31,822] [    INFO] - duration: 3.825 s\r\n[2022-11-28 10:28:31,822] [    INFO] - first response: 0.1715390682220459 s\r\n[2022-11-28 10:28:31,822] [    INFO] - final response: 1.4812896251678467 s\r\n[2022-11-28 10:28:31,822] [    INFO] - RTF: 0.38726526148178997\r\n[2022-11-28 10:28:31,822] [    INFO] - Audio successfully saved in output.wav\r\n[2022-11-28 10:28:31,822] [    INFO] - The sentence has no delay in streaming synthesis.\r\n\r\n远程服务器调用失败：\r\n(base) xxxx:/platform_tech/xxxx/code/fastspeech2$ paddlespeech_client tts_online --server_ip 192.168.190.80 --port 20620 --protocol http --input \"您好，欢迎使用百度飞桨语音合成服务。\" --output paddleTTS.wav\r\n/home/xxxx/miniconda3/lib/python3.8/site-packages/scipy/special/orthogonal.py:79: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n/home/xxxx/miniconda3/lib/python3.8/site-packages/scipy/io/matlab/mio5.py:95: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from .mio5_utils import VarReader5\r\n[2022-11-28 18:26:07,634] [    INFO] - tts http client start\r\n[2022-11-28 18:26:07,638] [   ERROR] - Failed to synthesized audio.\r\n[2022-11-28 18:26:07,638] [   ERROR] - 'sample_rate'\r\n\r\nserver端显示：\r\nINFO:     192.168.190.79:51488 - \"GET /paddlespeech/tts/streaming/samplerate HTTP/1.1\" 404 Not Found\r\n\r\n**Environment (please complete the following information):**\r\n - OS：Ubuntu\r\n - GCC/G++ Version [9.3]\r\n - Python Version [3.8]\r\n - PaddlePaddle Version [2.4.0]\r\n - CUDA/CUDNN Version [cuda-11.2]\r\n\r\n",
        "state": "closed",
        "user": "Approximetal",
        "closed_by": "yt605155624",
        "created_at": "2022-11-28T10:31:21+00:00",
        "updated_at": "2023-02-07T02:45:51+00:00",
        "closed_at": "2023-02-07T02:45:51+00:00",
        "comments_count": [
            "lym0302",
            "Approximetal",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2694,
        "title": "模型下载失败-初学",
        "body": "按照首页提示安装所有依赖包，测试时遇到模型下载问题。\r\n```\r\npaddlespeech asr --lang zh --input 30229_20220628133853089_right_55_16khz.wav\r\n/home//miniconda3/envs/paddlespeech/lib/python3.8/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nRuntimeError: Download from https://paddlespeech.bj.bcebos.com/s2t/wenetspeech/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz failed. Retry limit reached(paddlespeech) \r\n```\r\n",
        "state": "closed",
        "user": "ben-8878",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-28T10:05:09+00:00",
        "updated_at": "2023-09-01T02:50:10+00:00",
        "closed_at": "2023-03-25T12:02:17+00:00",
        "comments_count": [
            "lym0302",
            "ben-8878",
            "lym0302",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]",
            "rogerBridge"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2699,
        "title": "[TTS语音合成] UnboundLocalError: local variable 'wav_all' referenced before assignment ",
        "body": "使用语音合成时遇到了3个问题：\r\n1）我对一个文本中的多条数据逐条进行语音合成时，进行到3772条时程序报错：UnboundLocalError: local variable 'wav_all' referenced before assignment 。是程序漏洞吗？\r\n2）我使用混合模型mix合成包含中文、英文、数字的内容时，英文内容不能合成。如 \"welcome to 北京2008\"，这种情况如何处理？\r\n3）我想使用男声进行语音合成，但是根据推荐，我根据示例：\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\ntts(am=\"fastspeech2_male\", voc=\"pwgan_male\", text=\"今天天气十分不错。\", output=\"output.wav\")\r\n报错：AssertionError: Can't find \"fastspeech2_male-zh\" in resource. \r\n我看了其他的issue，提到了使用男声的方法，我想问的时，有没有明确的使用男声的方法？\r\n\r\n期待回复！3ks!\r\n",
        "state": "closed",
        "user": "newuserforstudy",
        "closed_by": "yt605155624",
        "created_at": "2022-11-29T06:48:01+00:00",
        "updated_at": "2022-12-01T08:54:49+00:00",
        "closed_at": "2022-12-01T08:54:49+00:00",
        "comments_count": [
            "yt605155624",
            "newuserforstudy",
            "yt605155624",
            "newuserforstudy"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2700,
        "title": " [   ERROR] - Please input audio file less then 200.0 seconds.",
        "body": "这是我本地部署的功能，也要限制时间嘛？长音频要用哪个参数？",
        "state": "closed",
        "user": "wizardforcel",
        "closed_by": "zxcd",
        "created_at": "2022-11-29T10:22:37+00:00",
        "updated_at": "2022-12-02T10:32:48+00:00",
        "closed_at": "2022-12-02T10:32:48+00:00",
        "comments_count": [
            "zh794390558",
            "wizardforcel",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2709,
        "title": "installation error",
        "body": "## General Question\r\n\r\nHi,\r\n\r\nI couldn't execute text-to-speech module because of an importing error below.\r\nI install all dependencies on my mac m1 ventura. Why may this happen?\r\n\r\n<img width=\"1119\" alt=\"image\" src=\"https://user-images.githubusercontent.com/69839085/204802593-8a3678e9-53a9-4b3b-a86f-f920b72b5432.png\">\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "murat-gunay",
        "closed_by": "yt605155624",
        "created_at": "2022-11-30T13:01:04+00:00",
        "updated_at": "2022-12-28T11:19:48+00:00",
        "closed_at": "2022-12-28T11:19:48+00:00",
        "comments_count": [
            "zxcd",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2718
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2717
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2711,
        "title": "[S2T] FatalError: Erroneous arithmetic operation is detected by the operating system",
        "body": "您好,我跟着官网的s2t的安装教程,安装了中等的训练环境之后在examples/aishell/asr1的路径下执行bash run.sh --stage 1 --stop_stage 1时出现了以下错误,想请教您该如何解决这问题：\r\n训练环境为ubuntu18.04.6 、CUDA Version: 10.2、cudnn:7.6.5 、paddlepaddle 2.3.1  、paddlepaddle-gpu  2.4.0rc0\r\n\r\nLAUNCH INFO 2022-11-30 21:07:29,721 ------------------------- ERROR LOG DETAIL -------------------------\r\nINFO     | paddlespeech.s2t.utils.dynamic_import:instance_class:68 - Instance: Adam {'grad_clip': ClipGradByGlobalNormWithLog(global_clip_norm=5.0), 'weight_decay': <paddle.regularizer.L2Decay object at 0x7f3ebb882950>, 'learning_rate': WarmupLR(warmup_steps=25000, lr=0.002, last_epoch=0)}.\r\n2022-11-30 21:07:28.175 | INFO     | paddlespeech.s2t.training.optimizer:from_args:120 - <Optimizer paddle.optimizer.adam.Adam> LR: WarmupLR(warmup_steps=25000, lr=0.002, last_epoch=0)\r\n2022-11-30 21:07:28.175 | INFO     | paddlespeech.s2t.exps.u2.model:setup_model:308 - Setup optimizer/lr_scheduler!\r\n2022-11-30 21:07:28.176 | INFO     | paddlespeech.s2t.training.trainer:resume_or_scratch:221 - Init from scratch!\r\n2022-11-30 21:07:28.590 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:286 - Saved model to exp/transformer/checkpoints/init.pdparams\r\n2022-11-30 21:07:28.590 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:292 - Saved optimzier state to exp/transformer/checkpoints/init.pdopt\r\n2022-11-30 21:07:28.591 | INFO     | paddlespeech.s2t.exps.u2.model:do_train:161 - Train Total Examples: 15013\r\n/home/navy/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:49: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/navy/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:51: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/navy/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:49: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n/home/navy/PaddleSpeech/paddlespeech/audio/transform/spec_augment.py:51: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\r\n  Image.BICUBIC)\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   arange_ad_func(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::DataType, phi::Place)\r\n1   paddle::experimental::arange(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::DataType, phi::Place const&)\r\n2   void phi::ArangeKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Erroneous arithmetic operation` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1669813648 (unix time) try \"date -d @1669813648\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGFPE (@0x7f3f596b116d) received by PID 11056 (TID 0x7f3fd123c200) from PID 1500189037 ***]",
        "state": "closed",
        "user": "navy7913",
        "closed_by": "stale[bot]",
        "created_at": "2022-11-30T13:49:40+00:00",
        "updated_at": "2023-05-20T16:19:49+00:00",
        "closed_at": "2023-05-20T16:19:49+00:00",
        "comments_count": [
            "zxcd",
            "zh794390558",
            "navy7913",
            "navy7913",
            "zxcd",
            "navy7913",
            "zxcd",
            "navy7913",
            "zxcd",
            "navy7913",
            "navy7913",
            "zxcd",
            "zxcd",
            "navy7913",
            "zxcd",
            "navy7913",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2712,
        "title": "如何修改PaddleSpeech预训练模型默认下载路径？",
        "body": "如何修改PaddleSpeech预训练模型默认下载路径？",
        "state": "closed",
        "user": "503718696",
        "closed_by": "zxcd",
        "created_at": "2022-12-01T07:37:03+00:00",
        "updated_at": "2022-12-08T02:20:57+00:00",
        "closed_at": "2022-12-08T02:20:57+00:00",
        "comments_count": [
            "zxcd",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2716,
        "title": "Python API for mixed-language TTS",
        "body": "Following the examples in https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/text_to_speech\r\nI'm able to call Python API for Chinese/English TTS:\r\n\r\nimport paddle\r\nfrom paddlespeech.cli.tts import TTSExecutor\r\n    tts_executor = TTSExecutor()\r\n    for spk_id in range(174):\r\n        tts_executor(\r\n            text='今天的天气不错啊',\r\n            output=f'demo_{spk_id}.wav',\r\n            am='fastspeech2_aishell3',\r\n            spk_id=spk_id,\r\n            voc='pwgan_aishell3',\r\n            lang='zh',\r\n            device=paddle.get_device())\r\n\r\nBut I can't set lang to 'mix' like with the command line. Is there support for mixed TTS with pretrained models in Python? Also, which vocoder is recommended for mixed TTS? Thank you!",
        "state": "closed",
        "user": "wangtiance",
        "closed_by": "wangtiance",
        "created_at": "2022-12-02T10:24:39+00:00",
        "updated_at": "2022-12-07T03:35:37+00:00",
        "closed_at": "2022-12-07T03:35:37+00:00",
        "comments_count": [
            "yt605155624",
            "wangtiance",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2715,
        "title": "ImportError: libpython3.10.so.1.0: cannot open shared object file: No such file or directory",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nHow I installed: pip install paddlepaddle paddlespeech\r\nIssue: I ran paddlespeech from the command line and got the following:\r\n\r\nError: Can not import paddle core while this file exists: /home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/home/spt/miniconda3/envs/xuanci/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\r\n    import paddle\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 37, in <module>\r\n    from . import core\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/fluid/core.py\", line 304, in <module>\r\n    raise e\r\n  File \"/home/spt/miniconda3/envs/xuanci/lib/python3.10/site-packages/paddle/fluid/core.py\", line 249, in <module>\r\n    from . import libpaddle\r\nImportError: libpython3.10.so.1.0: cannot open shared object file: No such file or directory\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Centos 7\r\n - GCC/G++ Version 4.8.5\r\n - Python Version 3.10\r\npaddle-bfloat      0.1.7\r\npaddle2onnx        1.0.3\r\npaddleaudio        1.0.2\r\npaddlefsl          1.1.0\r\npaddlenlp          2.4.4\r\npaddlepaddle       2.4.0\r\npaddlespeech       1.0.1\r\npaddlespeech-feat  0.1.0\r\n\r\n\r\n",
        "state": "closed",
        "user": "wangtiance",
        "closed_by": "wangtiance",
        "created_at": "2022-12-02T07:07:06+00:00",
        "updated_at": "2022-12-02T13:20:07+00:00",
        "closed_at": "2022-12-02T07:16:09+00:00",
        "comments_count": [
            "wangtiance",
            "wangtiance",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2719,
        "title": "[S2T] ASR 和whisper准确度较差",
        "body": "![image](https://user-images.githubusercontent.com/10295461/205566514-dcf81673-aee0-45e4-b5c3-1b26a2c7b563.png)\r\n",
        "state": "open",
        "user": "wuhongsheng",
        "closed_by": null,
        "created_at": "2022-12-05T06:43:18+00:00",
        "updated_at": "2022-12-07T07:07:33+00:00",
        "closed_at": null,
        "comments_count": [
            "wuhongsheng",
            "iftaken"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2727
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2720,
        "title": "[TTS]一百二十户，\"一\" 无法正确变调",
        "body": "因为 一 在序列中念一声，一百二十刚好撞了这个判断\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/a3d5d93dd444f34b90a8d130292dc9d0e27c9bdb/paddlespeech/t2s/frontend/tone_sandhi.py#L135\r\n如果开发者有什么好的解决办法，欢迎提 pr 修复",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-12-06T03:27:13+00:00",
        "updated_at": "2022-12-06T10:22:24+00:00",
        "closed_at": null,
        "comments_count": [
            "yaleimeng",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2722,
        "title": "[TTS] StyleInference aishell3 问题",
        "body": "参考 baker https://github.com/PaddlePaddle/PaddleSpeech/tree/022f1ce8e932a79844d6fa4a0e400b480ceca07d/demos/style_fs2\r\n我写了一个 aishell3 的 py 和 sh\r\n但是 GPU OOM, 只是添加了pitch energy duration control 不应该需要这么大显存啊\r\n<img width=\"1439\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32589854/206130041-4ab67620-3e7d-47cc-a52a-4fb8b84f20eb.png\">\r\n\r\n```\r\n#!/bin/bash\r\npython3 style_syn.py \\\r\n        --fastspeech2-config=./pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/default.yaml  \\\r\n        --fastspeech2-checkpoint=./pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/snapshot_iter_96400.pdz \\\r\n        --fastspeech2-stat=./pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/speech_stats.npy \\\r\n        --fastspeech2-pitch-stat=./pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/pitch_stats.npy \\\r\n        --fastspeech2-energy-stat=./pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/energy_stats.npy \\\r\n        --pwg-config=./pretrained_models/pwg_aishell3_ckpt_0.5/default.yaml \\\r\n        --pwg-checkpoint=./pretrained_models/pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz \\\r\n        --pwg-stat=./pretrained_models/pwg_aishell3_ckpt_0.5/feats_stats.npy \\\r\n        --text=./sentences.txt \\\r\n        --output-dir=output \\\r\n        --speaker_dict=./dump/speaker_id_map.txt \\\r\n        --phones-dict=./dump/phone_id_map.txt\r\n```\r\n```\r\n# Copyright (c) 2021 PaddlePaddle Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nimport argparse\r\nfrom pathlib import Path\r\n\r\nimport numpy as np\r\nimport paddle\r\nimport soundfile as sf\r\nimport yaml\r\nfrom yacs.config import CfgNode\r\n\r\nfrom paddlespeech.t2s.frontend.zh_frontend import Frontend\r\nfrom paddlespeech.t2s.models.fastspeech2 import FastSpeech2\r\nfrom paddlespeech.t2s.models.fastspeech2 import StyleFastSpeech2Inference\r\nfrom paddlespeech.t2s.models.parallel_wavegan import PWGGenerator\r\nfrom paddlespeech.t2s.models.parallel_wavegan import PWGInference\r\nfrom paddlespeech.t2s.modules.normalizer import ZScore\r\n\r\n\r\ndef evaluate(args, fastspeech2_config, pwg_config):\r\n    # construct dataset for evaluation\r\n    sentences = []\r\n    # am_config=None\r\n    # with open(args.fastspeech2-config) as f:\r\n    #     am_config = CfgNode(yaml.safe_load(f))\r\n    with open(args.text, 'rt') as f:\r\n        for line in f:\r\n            items = line.strip().split()\r\n            utt_id = items[0]\r\n            sentence = \"\".join(items[1:])\r\n            sentences.append((utt_id, sentence))\r\n    with open(args.phones_dict, \"r\") as f:\r\n        phn_id = [line.strip().split() for line in f.readlines()]\r\n    vocab_size = len(phn_id)\r\n    print(\"vocab_size:\", vocab_size)\r\n    spk_num = None\r\n    if args.speaker_dict is not None:\r\n        with open(args.speaker_dict, 'rt') as f:\r\n            spk_id = [line.strip().split() for line in f.readlines()]\r\n        spk_num = len(spk_id)\r\n    odim = fastspeech2_config.n_mels\r\n    model = FastSpeech2(\r\n        idim=vocab_size, spk_num=spk_num,\r\n        odim=odim, **fastspeech2_config[\"model\"])\r\n\r\n    model.set_state_dict(\r\n        paddle.load(args.fastspeech2_checkpoint)[\"main_params\"])\r\n    model.eval()\r\n\r\n    vocoder = PWGGenerator(**pwg_config[\"generator_params\"])\r\n    vocoder.set_state_dict(paddle.load(args.pwg_checkpoint)[\"generator_params\"])\r\n    vocoder.remove_weight_norm()\r\n    vocoder.eval()\r\n    print(\"model done!\")\r\n\r\n    frontend = Frontend(phone_vocab_path=args.phones_dict)\r\n    print(\"frontend done!\")\r\n\r\n    stat = np.load(args.fastspeech2_stat)\r\n    mu, std = stat\r\n    mu = paddle.to_tensor(mu)\r\n    std = paddle.to_tensor(std)\r\n    fastspeech2_normalizer = ZScore(mu, std)\r\n\r\n    stat = np.load(args.pwg_stat)\r\n    mu, std = stat\r\n    mu = paddle.to_tensor(mu)\r\n    std = paddle.to_tensor(std)\r\n    pwg_normalizer = ZScore(mu, std)\r\n\r\n    fastspeech2_inference = StyleFastSpeech2Inference(\r\n        fastspeech2_normalizer, model, args.fastspeech2_pitch_stat,\r\n        args.fastspeech2_energy_stat)\r\n    fastspeech2_inference.eval()\r\n\r\n    pwg_inference = PWGInference(pwg_normalizer, vocoder)\r\n    pwg_inference.eval()\r\n\r\n    output_dir = Path(args.output_dir)\r\n    output_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n    styles = [\"normal\", \"robot\", \"1.2xspeed\", \"0.8xspeed\", \"child_voice\"]\r\n    for style in styles:\r\n        robot = False\r\n        durations = None\r\n        durations_scale = None\r\n        durations_bias = None\r\n        pitch = None\r\n        pitch_scale = None\r\n        pitch_bias = None\r\n        energy = None\r\n        energy_scale = None\r\n        energy_bias = None\r\n        if style == \"robot\":\r\n            # all tones in phones be `1`\r\n            # all pitch should be the same, we use mean here\r\n            robot = True\r\n        if style == \"1.2xspeed\":\r\n            durations_scale = 1 / 1.2\r\n        if style == \"0.8xspeed\":\r\n            durations_scale = 1 / 0.8\r\n        if style == \"child_voice\":\r\n            pitch_scale = 1.3\r\n        sub_output_dir = output_dir / style\r\n        sub_output_dir.mkdir(parents=True, exist_ok=True)\r\n        for utt_id, sentence in sentences:\r\n            input_ids = frontend.get_input_ids(\r\n                sentence, merge_sentences=True, robot=robot)\r\n            phone_ids = input_ids[\"phone_ids\"][0]\r\n\r\n            with paddle.no_grad():\r\n                mel = fastspeech2_inference(\r\n                    phone_ids,\r\n                    durations=durations,\r\n                    durations_scale=durations_scale,\r\n                    durations_bias=durations_bias,\r\n                    pitch=pitch,\r\n                    pitch_scale=pitch_scale,\r\n                    pitch_bias=pitch_bias,\r\n                    energy=energy,\r\n                    energy_scale=energy_scale,\r\n                    energy_bias=energy_bias,\r\n                    robot=robot,\r\n                    spk_id=paddle.to_tensor(args.spk_id))\r\n                # wav = pwg_inference(mel)\r\n\r\n            # sf.write(\r\n            #     str(sub_output_dir / (utt_id + \".wav\")),\r\n            #     wav.numpy(),\r\n            #     samplerate=fastspeech2_config.fs)\r\n            # print(f\"{style}_{utt_id} done!\")\r\n\r\n\r\ndef main():\r\n    # parse args and config and redirect to train_sp\r\n    parser = argparse.ArgumentParser(\r\n        description=\"Synthesize with fastspeech2 & parallel wavegan.\")\r\n    parser.add_argument(\r\n        \"--fastspeech2-config\", type=str, help=\"fastspeech2 config file.\")\r\n    parser.add_argument(\r\n        \"--fastspeech2-checkpoint\",\r\n        type=str,\r\n        help=\"fastspeech2 checkpoint to load.\")\r\n    parser.add_argument(\r\n        \"--fastspeech2-stat\",\r\n        type=str,\r\n        help=\"mean and standard deviation used to normalize spectrogram when training fastspeech2.\"\r\n    )\r\n    parser.add_argument(\r\n        \"--fastspeech2-pitch-stat\",\r\n        type=str,\r\n        help=\"mean and standard deviation used to normalize pitch when training fastspeech2\"\r\n    )\r\n    parser.add_argument(\r\n        \"--fastspeech2-energy-stat\",\r\n        type=str,\r\n        help=\"mean and standard deviation used to normalize energy when training fastspeech2.\"\r\n    )\r\n    parser.add_argument(\r\n        \"--pwg-config\", type=str, help=\"parallel wavegan config file.\")\r\n    parser.add_argument(\r\n        \"--pwg-checkpoint\",\r\n        type=str,\r\n        help=\"parallel wavegan generator parameters to load.\")\r\n    parser.add_argument(\r\n        \"--pwg-stat\",\r\n        type=str,\r\n        help=\"mean and standard deviation used to normalize spectrogram when training parallel wavegan.\"\r\n    )\r\n    parser.add_argument(\r\n        \"--phones-dict\",\r\n        type=str,\r\n        default=\"phone_id_map.txt\",\r\n        help=\"phone vocabulary file.\")\r\n    parser.add_argument(\r\n        \"--text\",\r\n        type=str,\r\n        help=\"text to synthesize, a 'utt_id sentence' pair per line.\")\r\n    parser.add_argument(\"--output-dir\", type=str, help=\"output dir.\")\r\n    parser.add_argument(\r\n        \"--ngpu\", type=int, default=1, help=\"if ngpu == 0, use cpu.\")\r\n    parser.add_argument(\"--verbose\", type=int, default=1, help=\"verbose.\")\r\n    parser.add_argument(\r\n        \"--speaker_dict\", type=str, default=None, help=\"speaker id map file.\")\r\n    parser.add_argument(\r\n        '--spk_id',\r\n        type=int,\r\n        default=0,\r\n        help='spk id for multi speaker acoustic model')\r\n    args = parser.parse_args()\r\n\r\n    if args.ngpu == 0:\r\n        paddle.set_device(\"cpu\")\r\n    elif args.ngpu > 0:\r\n        paddle.set_device(\"gpu\")\r\n    else:\r\n        print(\"ngpu should >= 0 !\")\r\n\r\n    with open(args.fastspeech2_config) as f:\r\n        fastspeech2_config = CfgNode(yaml.safe_load(f))\r\n    with open(args.pwg_config) as f:\r\n        pwg_config = CfgNode(yaml.safe_load(f))\r\n\r\n    print(\"========Args========\")\r\n    print(yaml.safe_dump(vars(args)))\r\n    print(\"========Config========\")\r\n    print(fastspeech2_config)\r\n    print(pwg_config)\r\n\r\n    evaluate(args, fastspeech2_config, pwg_config)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```",
        "state": "closed",
        "user": "SG-XM",
        "closed_by": "yt605155624",
        "created_at": "2022-12-07T08:41:13+00:00",
        "updated_at": "2022-12-28T03:10:42+00:00",
        "closed_at": "2022-12-28T03:10:42+00:00",
        "comments_count": [
            "SG-XM",
            "yt605155624",
            "SG-XM",
            "SG-XM",
            "SG-XM",
            "SG-XM",
            "SG-XM",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2721,
        "title": "[TTS] error when starting server",
        "body": "The config file is the same as demos/speech_server/conf/application.yaml, except I only kept tts in engine list.\r\n\r\npaddlespeech_server start --config_file paddle_conf.yaml \r\n[2022-12-06 17:46:28,565] [    INFO] - start to init the engine\r\n[2022-12-06 17:46:28,565] [    INFO] - tts : python engine.\r\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 477172/477172 [00:39<00:00, 12109.45it/s]\r\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71120/71120 [00:09<00:00, 7598.92it/s]\r\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 575056/575056 [00:50<00:00, 11439.20it/s]\r\n[2022-12-06 17:48:33,716] [    INFO] - Downloading https://bj.bcebos.com/paddle-hapi/models/bert/bert-base-chinese-vocab.txt and saved to /home/spt/.paddlenlp/models/bert-base-chinese\r\n[2022-12-06 17:48:34,487] [    INFO] - PaddleAudio | unique_endpoints {''}\r\n[2022-12-06 17:48:34,488] [    INFO] - PaddleAudio | Downloading bert-base-chinese-vocab.txt from https://bj.bcebos.com/paddle-hapi/models/bert/bert-base-chinese-vocab.txt\r\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:00<00:00, 1717.38it/s]\r\n[2022-12-06 17:48:34,676] [    INFO] - tokenizer config file saved in /home/spt/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2022-12-06 17:48:34,676] [    INFO] - Special tokens file saved in /home/spt/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\n[2022-12-06 17:48:45,423] [    INFO] - Initialize TTS server engine successfully on device: cpu.\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-12-06 17:48:45,426] [   DEBUG] __init__.py:113 - Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2022-12-06 17:48:45,431] [   DEBUG] __init__.py:132 - Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.885 seconds.\r\n[2022-12-06 17:48:46,312] [   DEBUG] __init__.py:164 - Loading model cost 0.885 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-12-06 17:48:46,312] [   DEBUG] __init__.py:166 - Prefix dict has been built successfully.\r\n[2022-12-06 17:48:49,079] [   ERROR] - Failed to start server.\r\n[2022-12-06 17:48:49,079] [   ERROR] - run() got an unexpected keyword argument 'debug'\r\n\r\nmy paddle versions:\r\npaddle-bfloat             0.1.7                    pypi_0    pypi\r\npaddle2onnx               1.0.3                    pypi_0    pypi\r\npaddlefsl                 1.1.0                    pypi_0    pypi\r\npaddlenlp                 2.4.4                    pypi_0    pypi\r\npaddlepaddle              2.4.0           py39_cpu_many_linux    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle\r\npaddleslim                2.3.4                    pypi_0    pypi\r\npaddlespeech              1.2.0                    pypi_0    pypi\r\npaddlespeech-feat         0.1.0                    pypi_0    pypi\r\n",
        "state": "closed",
        "user": "wangtiance",
        "closed_by": "yt605155624",
        "created_at": "2022-12-06T09:52:55+00:00",
        "updated_at": "2022-12-06T10:19:04+00:00",
        "closed_at": "2022-12-06T10:19:04+00:00",
        "comments_count": [
            "wangtiance"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2725,
        "title": "deepspeech2转onnx模型怎么使用",
        "body": "我想问一下 deepspeech2转onnx模型有详细点的教程吗。我看了一下官方提供的infer_check.py代码（位于paddlespeechdevelop/speechx/examples/ds2_ol/onnx/local/infer_check.py）,显示onnx模型的输入是audio_chunk，audio_chunk_lens，chunk_state_h_box，chunk_state_c_box四个参数，最后模型预测输出也是ort_res_chunk, ort_res_lens, ort_chunk_state_h, ort_chunk_state_c四个参数，不是很理解一个音频样本怎么传入模型进行预测，最后输出结果的，官方有详细点的教程吗。",
        "state": "closed",
        "user": "Potato-wll",
        "closed_by": "stale[bot]",
        "created_at": "2022-12-08T01:40:45+00:00",
        "updated_at": "2023-03-25T12:00:45+00:00",
        "closed_at": "2023-03-25T12:00:45+00:00",
        "comments_count": [
            "zh794390558",
            "Potato-wll",
            "zh794390558",
            "Potato-wll",
            "zh794390558",
            "Potato-wll",
            "Potato-wll",
            "Potato-wll",
            "Potato-wll",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2724,
        "title": "训练出来的模型在linux部署时出现了错误",
        "body": "我按照 https://aistudio.baidu.com/aistudio/projectdetail/5003396  训练出了名为ce.zip的模型\r\n并根据 https://zhuanlan.zhihu.com/p/587765776  的教程在linux上部署了飞桨环境，但每次都会出现意想不到的错误。\r\n如下：\r\n\r\n_python3 test.py\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python3/lib/python3.9/site-packages/soundfile.py\", line 151, in <module>\r\n    raise OSError('sndfile library not found')\r\nOSError: sndfile library not found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python3/lib/python3.9/site-packages/soundfile.py\", line 178, in <module>\r\n    _snd = _ffi.dlopen(_os.path.join(_path, '_soundfile_data', _packaged_libname))\r\nOSError: cannot load library '/usr/local/python3/lib/python3.9/site-packages/_soundfile_data/libsndfile.so': /usr/local/python3/lib/python3.9/site-packages/_soundfile_data/libsndfile.so: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/PaddleSpeech/test.py\", line 2, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/python3/lib/python3.9/site-packages/soundfile.py\", line 189, in <module>\r\n    _snd = _ffi.dlopen(_libname)\r\nOSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory_\r\n\r\n\r\n **_test.py 里的内容：_**\r\nfrom pathlib import Path\r\nimport soundfile as sf\r\nimport os\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_output\r\nfrom paddlespeech.t2s.exps.syn_utils import get_frontend\r\nfrom paddlespeech.t2s.exps.syn_utils import get_predictor\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_output\r\n\r\n# 在其他环境中，记得修改下面这两个变量的路径\r\nam_inference_dir = \"/home/ce\"\r\nvoc_inference_dir = \"/home/pwgan_aishell3_static_1.1.0\"  # 这里以 pwgan_aishell3 为例子\r\n# 音频生成的路径，修改成你音频想要保存的路径\r\nwav_output_dir = \"/home\"\r\n\r\n# 选择设备[gpu / cpu]，这里以GPU为例子， \r\ndevice = \"cpu\"\r\n\r\n# 想要生成的文本和对应文件名\r\n\r\ntext_dict = {\r\n    \"1\": \"我很快失去了下棋的斗志\",\r\n    \"2\": \"我认为跑步给我的身体带来了健康。\",\r\n}\r\n\r\n# frontend\r\nfrontend = get_frontend(\r\n    lang=\"mix\",\r\n    phones_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n    tones_dict=None\r\n)\r\n\r\n# am_predictor\r\nam_predictor = get_predictor(\r\n    model_dir=am_inference_dir,\r\n    model_file=\"fastspeech2_mix\" + \".pdmodel\",\r\n    params_file=\"fastspeech2_mix\" + \".pdiparams\",\r\n    device=device)\r\n\r\n# voc_predictor\r\nvoc_predictor = get_predictor(\r\n    model_dir=voc_inference_dir,\r\n    model_file=\"pwgan_aishell3\" + \".pdmodel\",    # 这里以 pwgan_aishell3 为例子，其它模型记得修改此处模型名称\r\n    params_file=\"pwgan_aishell3\" + \".pdiparams\",\r\n    device=device)\r\n\r\noutput_dir = Path(wav_output_dir)\r\noutput_dir.mkdir(parents=True, exist_ok=True)\r\n\r\nsentences = list(text_dict.items())\r\n\r\nmerge_sentences = True\r\nfs = 24000\r\nfor utt_id, sentence in sentences:\r\n    am_output_data = get_am_output(\r\n        input=sentence,\r\n        am_predictor=am_predictor,\r\n        am=\"fastspeech2_mix\",\r\n        frontend=frontend,\r\n        lang=\"mix\",\r\n        merge_sentences=merge_sentences,\r\n        speaker_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n        spk_id=0, )\r\n    wav = get_voc_output(\r\n            voc_predictor=voc_predictor, input=am_output_data)\r\n    # 保存文件\r\n    sf.write(output_dir / (utt_id + \".wav\"), wav, samplerate=fs)\r\n\r\n\r\n\r\n-----------------------\r\n我想知道我大概在那一步出了问题，因为我不管怎么去修改重新安装python环境或者在docker中运行，都会报各种错误。非常感谢。\r\n\r\n我大致的想法是把训练的模型部署在linux服务器中，通过http接口的形式去让项目调用。\r\n\r\n\r\n",
        "state": "closed",
        "user": "GuangHeLiZi",
        "closed_by": "GuangHeLiZi",
        "created_at": "2022-12-07T18:04:51+00:00",
        "updated_at": "2022-12-08T14:28:17+00:00",
        "closed_at": "2022-12-08T14:28:17+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2726,
        "title": "ASR解码方式有没有beam search",
        "body": "我看文档里的解码方式，有ctc_greedy_search和ctc_prefix_beam_search等，除了ctc_greedy_search其他方式耗时都很长。\r\nctc_prefix_beam_search应该是用语言模型实现的，所以耗时才长吧，有没有只用beam search不加语言模型的方案，作为一个折中？",
        "state": "closed",
        "user": "lesliexufdu",
        "closed_by": "stale[bot]",
        "created_at": "2022-12-08T03:40:12+00:00",
        "updated_at": "2023-03-25T11:59:34+00:00",
        "closed_at": "2023-03-25T11:59:34+00:00",
        "comments_count": [
            "zh794390558",
            "lesliexufdu",
            "lesliexufdu",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2731,
        "title": "[TTS] 歌声合成",
        "body": "- https://github.com/PaddlePaddle/PaddleSpeech/issues/2821\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2822",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-12-09T05:08:55+00:00",
        "updated_at": "2023-01-11T03:08:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2730,
        "title": "[S2T]LogMelSpectrogram抽mfcc特征报异常",
        "body": "你好，想问下用paddle的LogMelSpectrogram抽特征出现以下报错是为什么？代码能够正常跑通，但是结束会打印异常信息。\r\npaddle版本：2.2.2\r\npaddleaudio版本:1.0.2\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport sys\r\nimport paddle\r\nfrom paddleaudio.features import LogMelSpectrogram\r\n\r\nfeature_extractor = LogMelSpectrogram(sr=16000,\r\n                                      n_fft=400,\r\n                                      hop_length=160,\r\n                                      n_mels=80)\r\n\r\n\r\ndata = paddle.randn(shape=(1, 48000))\r\noutput = feature_extractor(data)\r\nprint(output.shape, output.dtype)\r\n```\r\n\r\n控制台输出：\r\n<img width=\"1875\" alt=\"image\" src=\"https://user-images.githubusercontent.com/22003927/206620983-7c67c105-6586-40c1-83a5-5c085aa176fe.png\">\r\n",
        "state": "closed",
        "user": "will-wiki",
        "closed_by": "SmileGoat",
        "created_at": "2022-12-09T03:58:42+00:00",
        "updated_at": "2022-12-09T07:56:56+00:00",
        "closed_at": "2022-12-09T07:56:56+00:00",
        "comments_count": [
            "SmileGoat",
            "will-wiki"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2734,
        "title": "🔥 r1.3.0 release note",
        "body": "# T2S\r\n- Add seek for BytesIO. https://github.com/PaddlePaddle/PaddleSpeech/pull/2484 by @ZapBird \r\n- Add mix finetune. https://github.com/PaddlePaddle/PaddleSpeech/pull/2525 https://github.com/PaddlePaddle/PaddleSpeech/pull/2647 by @lym0302 \r\n- Add streaming TTS fastdeploy serving. https://github.com/PaddlePaddle/PaddleSpeech/pull/2528 by @HexToString \r\n- Add SSML for Chinese Text Frontend. https://github.com/PaddlePaddle/PaddleSpeech/pull/2531 by @david-95 \r\n- Add [end-to-end Prosody Prediction pipeline](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/csmsc/tts3_rhy) (including using prosody labels in Acoustic Model). https://github.com/PaddlePaddle/PaddleSpeech/pull/2548 https://github.com/PaddlePaddle/PaddleSpeech/pull/2615 https://github.com/PaddlePaddle/PaddleSpeech/pull/2693 by @WongLaw \r\n- Add [Adversarial Loss](https://arxiv.org/pdf/1907.04448.pdf) for [Chinese English mixed TTS](https://github.com/lym0302/PaddleSpeech/blob/develop/examples/zh_en_tts/tts3). https://github.com/PaddlePaddle/PaddleSpeech/pull/2588 by @lym0302\r\n- Fix frontend bugs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2539 https://github.com/PaddlePaddle/PaddleSpeech/pull/2606 by @yt605155624 \r\n- Add TN for English unit. https://github.com/PaddlePaddle/PaddleSpeech/pull/2629 by @WongLaw \r\n- Add male voice for TTS. https://github.com/PaddlePaddle/PaddleSpeech/pull/2660 by @lym0302 \r\n- Add double byte char for zh normalization. https://github.com/PaddlePaddle/PaddleSpeech/pull/2661 by @david-95 \r\n- Fix badcase of g2pW. https://github.com/PaddlePaddle/PaddleSpeech/pull/2664 by @kFoodie \r\n- Add TTS Paddle-Lite x86 inference. https://github.com/PaddlePaddle/PaddleSpeech/pull/2636 https://github.com/PaddlePaddle/PaddleSpeech/pull/2667 by @yt605155624 \r\n- Add greek char and fix #2571. https://github.com/PaddlePaddle/PaddleSpeech/pull/2683 by @david-95 \r\n- Add Slim for TTS. https://github.com/PaddlePaddle/PaddleSpeech/pull/2729 by @yt605155624 \r\n\r\n\r\n# S2T\r\n- Add whisper. #2640 #2704 by @zxcd\r\n- Fix gpu training hang. #2478 by @Zth9730 \r\n- Support u2++ based cli and server. #2489 #2510 by @Zth9730 \r\n- Add wav2vec2-en. #2518 #2527 #2637 by @Zth9730 \r\n- Add wav2vec2-zh cli. #2697 by @Zth9730 \r\n\r\n# Text\r\n- Fix bug of Punctuation Restoration https://github.com/PaddlePaddle/PaddleSpeech/pull/2554 by @dahu1 \r\n\r\n# Audio\r\n- Move paddlespeech/audio to paddleaudio. https://github.com/PaddlePaddle/PaddleSpeech/pull/2706 by @SmileGoat \r\n- Fix bug of paddleaudio.load. https://github.com/PaddlePaddle/PaddleSpeech/pull/2706 by @SmileGoat \r\n\r\n# Demo\r\n- Add TTSAndroid demo. https://github.com/PaddlePaddle/PaddleSpeech/pull/2703 by @yt605155624 \r\n- Add whisper. #2677 by @zxcd\r\n- Add wav2vec2. #2674 @Zth9730 \r\n\r\n# Documentation\r\n- Update install.md. https://github.com/PaddlePaddle/PaddleSpeech/pull/2666 by @michael-skynorth \r\n- Update docs. https://github.com/PaddlePaddle/PaddleSpeech/pull/2688 by @heyudage \r\n\r\n# Other\r\n* Fixed paddlenlp version to paddlenlp >=2.4.3 in setup.py. #2701 by @zxcd\r\n* Fixed the error when dim of tensor is 0. #2621 by @Zth9730 \r\n\r\n# Acknowledgements\r\nSpecial thanks to @SmileGoat @yt605155624  @Zth9730 @zxcd  @WongLaw @lym0302 @ZapBird \r\n@HexToString @david-95  @kFoodie @michael-skynort @heyudage \r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "SmileGoat",
        "created_at": "2022-12-09T07:04:09+00:00",
        "updated_at": "2022-12-12T03:50:59+00:00",
        "closed_at": "2022-12-12T03:50:59+00:00",
        "comments_count": [],
        "labels": [
            "Documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2735,
        "title": "我安装了paddlespeech 但是还是报错了",
        "body": "PS E:\\paddlepaddle\\github\\PaddleSpeech\\demos\\streaming_asr_server> python .\\local\\streaming_asr_server.py\r\nTraceback (most recent call last):\r\n  File \"E:\\paddlepaddle\\github\\PaddleSpeech\\demos\\streaming_asr_server\\local\\streaming_asr_server.py\", line 16, in <module>\r\n    from paddlespeech.cli.log import logger\r\nModuleNotFoundError: No module named 'paddlespeech'\r\n",
        "state": "closed",
        "user": "SoulSnow",
        "closed_by": "SoulSnow",
        "created_at": "2022-12-09T08:23:40+00:00",
        "updated_at": "2022-12-12T07:03:54+00:00",
        "closed_at": "2022-12-12T07:03:54+00:00",
        "comments_count": [
            "yaleimeng",
            "SoulSnow"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2743,
        "title": "PaddleSpeech可否支持下Paddle lite方便部署在嵌入式设备上",
        "body": "如题所述，如果后续支持Paddle lite的话还望到时一并给出操作说明，方便新手去部署",
        "state": "closed",
        "user": "jackyzjk",
        "closed_by": "yt605155624",
        "created_at": "2022-12-15T02:00:25+00:00",
        "updated_at": "2023-03-21T08:02:41+00:00",
        "closed_at": "2023-03-21T08:02:41+00:00",
        "comments_count": [
            "yt605155624",
            "jackyzjk",
            "lizezheng",
            "stale[bot]"
        ],
        "labels": [
            "feature request",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2737,
        "title": "在线ASR推理能否启用多线程加速？",
        "body": "目前用conformer_u2pp_online_wenetspeech模型在CPU上进行推理，推理所使用的时间要长于音频时长，无法达到实时的效果。看了一下CPU的使用情况，发现4核的CPU只有一个核跑满了，另外三个核几乎都是空闲状态。",
        "state": "closed",
        "user": "nailvcoronation",
        "closed_by": "nailvcoronation",
        "created_at": "2022-12-13T06:29:53+00:00",
        "updated_at": "2022-12-15T13:54:02+00:00",
        "closed_at": "2022-12-15T13:54:02+00:00",
        "comments_count": [
            "zh794390558",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2747,
        "title": "asr怎么识别中英混合语音？",
        "body": "asr怎么识别中英混合语音？\r\n好像只能识别中文？\r\n请大佬帮帮忙，Thanks♪(･ω･)ﾉ",
        "state": "open",
        "user": "yunqi777",
        "closed_by": null,
        "created_at": "2022-12-16T07:18:24+00:00",
        "updated_at": "2022-12-22T02:38:22+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2744,
        "title": "[S2T]基于U2的ASR模型流式部署并发测试报错",
        "body": "大神们好。我试验了一下U2的ASR模型流式部署和测试，写了一个多进程的多路并发测试，测试发现（动态模型），总会有几路会报错。比如说，我并发10路，发现会有两路或者3路报错，报错信息如下：\r\n`Process ForkPoolWorker-7:\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\r\n    put((job, i, result))\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/queues.py\", line 368, in put\r\n    self._writer.send_bytes(obj)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n    self._send_bytes(m[offset:offset + size])\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n    self._send(header + buf)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n    n = write(self._handle, buf)\r\nOSError: [Errno 9] Bad file descriptor\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/pool.py\", line 136, in worker\r\n    put((job, i, (False, wrapped)))\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/queues.py\", line 368, in put\r\n    self._writer.send_bytes(obj)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n    self._send_bytes(m[offset:offset + size])\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n    self._send(header + buf)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n    n = write(self._handle, buf)\r\nOSError: [Errno 9] Bad file descriptor`\r\n这里就有两路报错\r\n\r\n这个是写的多路并发测试代码：\r\n[get_url_stream_test_mutil_doing.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/10235981/get_url_stream_test_mutil_doing.zip)\r\n还请大神们帮忙看看，是并发的测试代码问题，还是ASR流式部署的Bug问题？多谢各位大神",
        "state": "open",
        "user": "Tian14267",
        "closed_by": null,
        "created_at": "2022-12-15T10:13:09+00:00",
        "updated_at": "2022-12-22T02:39:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "Tian14267",
            "Tian14267",
            "Tian14267",
            "zxcd",
            "Tian14267",
            "zxcd",
            "Tian14267"
        ],
        "labels": [
            "Bug",
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2749,
        "title": "ubuntu22.04 安装 PaddleSpeech r1.3.0 对 onnxruntime 的依赖问题",
        "body": "## Others\r\n\r\n在 `setup.py` 中指定的版本 `onnxruntime==1.11.0` 现在已经无法下载到，需要把这一行代码改成 `onnxruntime>=1.11.0`",
        "state": "closed",
        "user": "rocket049",
        "closed_by": "SmileGoat",
        "created_at": "2022-12-16T11:21:48+00:00",
        "updated_at": "2022-12-28T06:51:56+00:00",
        "closed_at": "2022-12-28T06:51:56+00:00",
        "comments_count": [
            "yt605155624",
            "HuaHuaY",
            "yt605155624"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2750,
        "title": "PaddleSpeech如何关闭log信息输出",
        "body": "import paddle\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(audio_file=audio_path,device=paddle.get_device(), force_yes=True)\r\n\r\n上面函数方式调用，产生大量log信息日志，如何关闭？下面是日志样例。\r\n\r\n日志样例：\r\n[2022-12-17 00:08:09,180] [ WARNING] - The sample rate of the input file is not 16000.\r\n                             The program will resample the wav file to 16000.\r\n                             If the result does not meet your expectations，\r\n                             Please input the 16k 16 bit 1 channel wav file.                         \r\n2022-12-17 00:08:12.485 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:229 - BLANK id: 0\r\n2022-12-17 00:08:12.486 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:230 - UNK id: 1\r\n2022-12-17 00:08:12.486 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:231 - EOS id: 5536\r\n2022-12-17 00:08:12.487 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:232 - SOS id: 5536\r\n2022-12-17 00:08:12.487 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:233 - SPACE id: -1\r\n2022-12-17 00:08:12.488 | INFO     | paddlespeech.s2t.frontend.featurizer.text_featurizer:_load_vocabulary_from_file:234 - MASKCTC id: -1\r\n2022-12-17 00:08:12.488 | INFO     | paddlespeech.s2t.models.u2.u2:_init_from_config:829 - U2 Encoder type: conformer\r\n2022-12-17 00:08:12.639 | INFO     | paddlespeech.s2t.modules.loss:__init__:40 - CTCLoss Loss reduction: sum, div-bs: True\r\n2022-12-17 00:08:12.640 | INFO     | paddlespeech.s2t.modules.loss:__init__:42 - CTCLoss Grad Norm Type: None\r\n2022-12-17 00:08:12.640 | INFO     | paddlespeech.s2t.modules.loss:__init__:73 - CTCLoss() kwargs:{'norm_by_times': False}, not support: {'norm_by_batchsize': False, 'norm_by_total_logits_len': False}\r\n2022-12-17 00:08:14.397 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 1, out_tensor [10, 2], tensor [1]\r\n2022-12-17 00:08:14.397 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.399 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 1, out_tensor [10, 2], tensor [1]\r\n2022-12-17 00:08:14.399 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.400 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.401 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.401 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 1, out_tensor [10, 2], tensor [1]\r\n2022-12-17 00:08:14.402 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.402 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 2, out_tensor [10, 2], tensor [2]\r\n2022-12-17 00:08:14.403 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:96 - length 1, out_tensor [10, 2], tensor [1]",
        "state": "closed",
        "user": "503718696",
        "closed_by": "zxcd",
        "created_at": "2022-12-17T00:39:11+00:00",
        "updated_at": "2023-03-30T12:13:00+00:00",
        "closed_at": "2023-03-30T12:13:00+00:00",
        "comments_count": [
            "yt605155624",
            "503718696",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2751,
        "title": "mix中英文流式tts模型转static报错",
        "body": "我用csmsc/tts3/conf/cnndecoder.yaml配置，运行zh_en_tts/tts3的run.sh，训练完后跑./local/synthesize_e2e.sh报错，请问要如何修改：\r\nValueError: The feeded_var_names[1]: 'spk_id' doesn't exist in pruned inference program. Please check whether 'spk_id' is a valid feed_var name, or remove it from feeded_var_names if 'spk_id' is not involved in the target_vars calculation.\r\n",
        "state": "closed",
        "user": "lzhin",
        "closed_by": "yt605155624",
        "created_at": "2022-12-19T09:42:15+00:00",
        "updated_at": "2023-06-28T02:00:45+00:00",
        "closed_at": "2023-02-07T02:43:01+00:00",
        "comments_count": [
            "yt605155624",
            "lzhin",
            "yt605155624",
            "a0735a"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2756,
        "title": "在微调中英混合的tts模型，用的是自带的文本前端转的拼音，发现有些字母（比如QQ、app等）无法转成拼音，check_oov的时候就会被过滤掉，想问下怎样解决？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "MrInouye",
        "closed_by": "MrInouye",
        "created_at": "2022-12-20T10:11:16+00:00",
        "updated_at": "2022-12-20T10:13:48+00:00",
        "closed_at": "2022-12-20T10:13:32+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2752,
        "title": "[TTS]ERNIE-SAT个性化合成报错",
        "body": "**Describe the bug**\r\n`{'code': -1, 'result': None, 'message': 'SAT 合成失败，请从后台检查错误信息！'}`\r\n\r\n**To Reproduce**\r\n步骤参考的是[ERNIE-SAT 个性化合成体验](https://aistudio.baidu.com/aistudio/projectdetail/4573549?sUid=2470186&shared=1&ts=1663753541400)\r\n\r\n```\r\nurl = \"http://127.0.0.1:8010/vc/clone_sat\"\r\nmethods = \"post\"\r\npara = {\r\n\t'old_str': \"请播放歌曲小苹果\",\r\n\t'new_str': \"你可以使用我的声音合成其它文本\",\r\n\t'language': \"zh\",\r\n\t'function': \"synthesize\",\r\n\t'wav': \"source/wav/SAT/upload/SSB03540307.wav\",\r\n\t'filename': \"SSB03540307.wav\"\r\n}\r\nr = use_api(url, methods, json.dumps(para))\r\nr.json()\r\n```\r\n\r\n**Screenshots**\r\n```\r\n/home/envs/paddle_speech_test/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\ntmp_name in alignment: root_35741_a75f0b25dd7d6d18b3e60a7c8973819f\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 1.0\r\nPaddleSpeech/demos/speech_web/speech_server/tools/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nCreating dictionary information...\r\nfstcompile: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by PaddleSpeech/demos/speech_web/speech_server/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstarcsort: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by PaddleSpeech/demos/speech_web/speech_server/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstcompile: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by PaddleSpeech/demos/speech_web/speech_server/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstarcsort: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by PaddleSpeech/demos/speech_web/speech_server/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nSetting up training data...\r\nCalculating MFCCs...\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 1.0\r\nDone with setup.\r\n100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.34it/s]\r\nDone! Everything took 3.393775463104248 seconds\r\nTraceback (most recent call last):\r\n  File \"PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 474, in <module>\r\n    task_name=args.task_name)\r\n  File \"PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 285, in get_wav\r\n    n_shift=n_shift)\r\n  File \"PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 239, in get_mlm_output\r\n    n_shift=n_shift)\r\n  File \"PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 175, in prep_feats\r\n    n_shift=n_shift)\r\n  File \"PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 74, in prep_feats_with_dur\r\n    n_shift=n_shift)\r\n  File \"/home/envs/paddle_speech_test/lib/python3.7/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 217, in get_phns_spans\r\n    wav_path=wav_path, text=old_str, lang=lang, fs=fs, n_shift=n_shift)\r\n  File \"/home/envs/paddle_speech_test/lib/python3.7/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 136, in alignment\r\n    phn_dur, word2phns = _readtg(tg_path, lang=lang)\r\n  File \"/home/envs/paddle_speech_test/lib/python3.7/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 39, in _readtg\r\n    alignment = textgrid.openTextgrid(tg_path, includeEmptyIntervals=True)\r\n  File \"/home/envs/paddle_speech_test/lib/python3.7/site-packages/praatio/textgrid.py\", line 70, in openTextgrid\r\n    with io.open(fnFullPath, \"r\", encoding=\"utf-16\") as fd:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tmp_dir/root_35741_a75f0b25dd7d6d18b3e60a7c8973819f/root_35741_a75f0b25dd7d6d18b3e60a7c8973819f/SSB03540307.TextGrid'\r\n\r\n            FLAGS_allocator_strategy=naive_best_fit             FLAGS_fraction_of_gpu_memory_to_use=0.01             python3 PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py                 --task_name=synthesize                 --wav_path=PaddleSpeech/demos/speech_web/speech_server/source/wav/SAT/upload/SSB03540307.wav                 --old_str='请播放歌曲小苹果'                 --new_str='你可以使用我的声音合成其它文本'                 --source_ --target_lang=zh                 --erniesat_config=PaddleSpeech/demos/speech_web/speech_server/source/model/erniesat_aishell3_ckpt_1.2.0/default.yaml                 --phones_dict=PaddleSpeech/demos/speech_web/speech_server/source/model/erniesat_aishell3_ckpt_1.2.0/phone_id_map.txt                 --erniesat_ckpt=PaddleSpeech/demos/speech_web/speech_server/source/model/erniesat_aishell3_ckpt_1.2.0/snapshot_iter_289500.pdz                 --erniesat_stat=PaddleSpeech/demos/speech_web/speech_server/source/model/erniesat_aishell3_ckpt_1.2.0/speech_stats.npy                 --voc=hifigan_aishell3                 --voc_config=PaddleSpeech/demos/speech_web/speech_server/source/model/hifigan_aishell3_ckpt_0.2.0/default.yaml                 --voc_ckpt=PaddleSpeech/demos/speech_web/speech_server/source/model/hifigan_aishell3_ckpt_0.2.0/snapshot_iter_2500000.pdz                 --voc_stat=PaddleSpeech/demos/speech_web/speech_server/source/model/hifigan_aishell3_ckpt_0.2.0/feats_stats.npy                 --output_name=PaddleSpeech/demos/speech_web/speech_server/source/wav/SAT/out/sat_syn_zh_SSB03540307.wav                 --ngpu=0\r\n        \r\n运行结果： 1\r\n\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Redhat\r\n - GCC/G++ Version: 4.8.5\r\n - Python Version: 3.7.10\r\n - PaddlePaddle Version: 2.4.1\r\n",
        "state": "closed",
        "user": "wjddd",
        "closed_by": "wjddd",
        "created_at": "2022-12-19T10:19:05+00:00",
        "updated_at": "2022-12-22T08:46:50+00:00",
        "closed_at": "2022-12-22T08:46:50+00:00",
        "comments_count": [
            "wjddd",
            "iftaken",
            "wjddd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2758,
        "title": "音频时长和Tensor 错误",
        "body": "## General Question\r\n<!--\r\n1.PaddleSpeech识别语音时长问题？\r\nError:Please input audio file less then 200.0 seconds.\r\n问题：针对大量对话且时间较长的文件，无法采用PaddleSpeech asr 方式去识别，导致产品功能无法使用，请问这个时长是否可以根据文件的大小自适用设置\r\n2.speech_server中部署web服务的时候，提示Tensor错误。\r\nError：cannot import name 'Tensor' from 'paddle' \r\n问题：Tensor此问题，没有找到具体的解决方式，请问这个错误，是因为版本升级的问题吗 ？\r\n-->\r\n",
        "state": "closed",
        "user": "CanRuoHan",
        "closed_by": "yt605155624",
        "created_at": "2022-12-20T10:37:30+00:00",
        "updated_at": "2022-12-21T02:17:35+00:00",
        "closed_at": "2022-12-21T02:17:35+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2753,
        "title": "tts微调效果问题",
        "body": "原始数据频率是8k的，试过改变采样频率为24k，finetune之后合成的模型有噪声，如果直接用8k的数据微调，效果会好一点吗？\r\n",
        "state": "closed",
        "user": "graciechen",
        "closed_by": "yt605155624",
        "created_at": "2022-12-19T11:36:14+00:00",
        "updated_at": "2022-12-28T02:55:35+00:00",
        "closed_at": "2022-12-28T02:55:35+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2757,
        "title": "[TTS]微调tts中英混合问题",
        "body": "在微调中英混合的tts模型，用的是自带的文本前端转的拼音，发现有些字母（比如QQ、app等）无法转成拼音，check_oov的时候就会被过滤掉，想问下怎样解决？\r\n\r\n![转拼音的方法](https://user-images.githubusercontent.com/73767263/208643926-0a366be6-089e-49b5-af9d-5c508e62bb1b.png)\r\n![拼音结果](https://user-images.githubusercontent.com/73767263/208644454-7ed7bbb2-149c-412c-a960-9e93e9e0030c.png)\r\n![oov](https://user-images.githubusercontent.com/73767263/208644922-4dbbc14b-aa15-49c6-9189-ec29fc66aa82.png)\r\n",
        "state": "closed",
        "user": "MrInouye",
        "closed_by": "yt605155624",
        "created_at": "2022-12-20T10:15:28+00:00",
        "updated_at": "2022-12-28T02:55:27+00:00",
        "closed_at": "2022-12-28T02:55:27+00:00",
        "comments_count": [
            "yt605155624",
            "MrInouye",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2759,
        "title": "使用时报错",
        "body": "## Others\r\nMac下安装，报下面的错，请问是啥问题?\r\n\r\n\r\n paddlespeech tts --input \"你好\" --output out.wav\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.10/site-packages/paddlespeech/cli/__init__.py\", line 24, in <module>\r\n    from .vector import VectorExecutor\r\n  File \"/usr/local/lib/python3.10/site-packages/paddlespeech/cli/vector/__init__.py\", line 14, in <module>\r\n    from .infer import VectorExecutor\r\n  File \"/usr/local/lib/python3.10/site-packages/paddlespeech/cli/vector/infer.py\", line 25, in <module>\r\n    from paddleaudio.backends import load as load_audio\r\nImportError: cannot import name 'load' from 'paddleaudio.backends' (/usr/local/lib/python3.10/site-packages/paddleaudio/backends/__init__.py)\r\n\r\n",
        "state": "closed",
        "user": "deyimsf",
        "closed_by": "yt605155624",
        "created_at": "2022-12-21T06:01:13+00:00",
        "updated_at": "2022-12-26T08:32:11+00:00",
        "closed_at": "2022-12-26T08:32:11+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2760,
        "title": "SSML 除了拼音还可加其他功能吗",
        "body": "目前，SSML 只能改拼音。可以加 styles 吗？例如pitch，frequency， emotion，之类。\r\n\r\nhttps://www.tencentcloud.com/document/product/1154/47883",
        "state": "open",
        "user": "keelezibel",
        "closed_by": null,
        "created_at": "2022-12-21T06:08:32+00:00",
        "updated_at": "2022-12-22T02:33:35+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2772,
        "title": "[TTS] iSTFTNet -> speed up HiFiGAN !!",
        "body": "speed up HiFiGAN !!\r\n\r\n- Paper: [iSTFTNet : Fast and Lightweight Mel-spectrogram Vocoder Incorporating Inverse Short-time Fourier Transform](https://arxiv.org/pdf/2203.02395.pdf)\r\n\r\n- Code: https://github.com/rishikksh20/iSTFTNet-pytorch  \r\n\r\nPlease compare with original HiFiGAN to get the diff: https://github.com/jik876/hifi-gan \r\n\r\nAfter this work, you can also modify VITS to VITS_iSTFT",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "lym0302",
        "created_at": "2022-12-28T02:33:02+00:00",
        "updated_at": "2023-04-10T03:16:15+00:00",
        "closed_at": "2023-04-10T03:16:15+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2761,
        "title": "[TTS] 请问如何使用数据集里的韵律标签",
        "body": "默认的 PaddleSpeech fs2 的前端是不含韵律信息的 ,如果我引入了韵律标注, 如何在训练过程中引入这个信息呢? 这是否意味着要修改声学模型的代码? 声学模型的输入pitch energy duration的那些特征信息吧,我该怎么引入韵律信息呢? ",
        "state": "closed",
        "user": "SG-XM",
        "closed_by": "yt605155624",
        "created_at": "2022-12-22T15:04:19+00:00",
        "updated_at": "2023-10-21T04:02:06+00:00",
        "closed_at": "2023-03-21T08:00:09+00:00",
        "comments_count": [
            "yt605155624",
            "SG-XM",
            "yt605155624",
            "SG-XM",
            "yt605155624",
            "1nlplearner",
            "yt605155624",
            "1nlplearner",
            "Daisyqk"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2762,
        "title": "（arm平台）流式语音识别服务启动和被调用时报错（启动：[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error ；被调用：tensor  has not been initialized），识别出的文字都为空",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n## 流式语音识别服务启动和被调用时报错（启动：[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error ；被调用：tensor  has not been initialized），识别出的文字都为空。各位大佬知道大概是什么原因嘛\r\n## linux系统版本\r\nLinux localhost.localdomain 4.19.90-24.4.v2101.ky10.aarch64 #1 SMP Mon May 24 14:45:37 CST 2021 aarch64 aarch64 aarch64 GNU/Linux\r\n## 根据这个页面操作 \r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_asr_server/README_cn.md\r\n## 启动服务命令\r\npaddlespeech_server start --config_file ./conf/ws_conformer_wenetspeech_application.yaml\r\n### 日志\r\n/usr/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\n[2022-12-23 14:13:20,290] [    INFO] - start to init the engine\r\n[2022-12-23 14:13:20,290] [    INFO] - asr : online engine.\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nERROR: Could not find a version that satisfies the requirement paddlespeech_ctcdecoders (from versions: none)\r\nERROR: No matching distribution found for paddlespeech_ctcdecoders\r\n2022-12-23 14:13:28.724 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2022-12-23 14:13:39.032 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2022-12-23 14:13:44,891] [    INFO] - Initialize ASR server engine successfully on device: cpu.\r\nINFO:     Started server process [77126]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)\r\n\r\n\r\n## 调用服务命令\r\npaddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input ../../../zh.wav\r\n### 服务端日志\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   phi::enforce::EnforceNotMet::EnforceNotMet(phi::ErrorSummary const&, char const*, int)\r\n1   phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: tensor  has not been initialized, we can only slice initialized tensor please init it first with numpy or other tensor.\r\n  [Hint: Expected self->tensor.initialized() == true, but received self->tensor.initialized():0 != true:1.] (at /workspace/paddleocr/Paddle/paddle/fluid/pybind/eager_method.cc:768)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"<decorator-gen-600>\", line 2, in advance_decoding\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 356, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 483, in advance_decoding\r\n    cnn_cache=self.cnn_cache)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/s2t/modules/encoder.py\", line 254, in forward_chunk\r\n    att_cache=att_cache[i:i + 1],\r\n  File \"/usr/local/lib64/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 753, in __getitem__\r\n    return self._getitem_index_not_tensor(item)\r\nValueError: \r\n### 客户端日志\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\n[2022-12-23 13:52:26,614] [    INFO] - asr websocket client start\r\n[2022-12-23 13:52:26,615] [    INFO] - endpoint: None\r\n[2022-12-23 13:52:26,615] [    INFO] - endpoint: ws://127.0.0.1:8090/paddlespeech/asr/streaming\r\n[2022-12-23 13:52:26,695] [    INFO] - client receive msg={\"status\": \"ok\", \"signal\": \"server_ready\"}\r\n[2022-12-23 13:52:26,738] [    INFO] - client receive msg={'result': ''}\r\n[2022-12-23 13:52:26,752] [    INFO] - client receive msg={'result': ''}\r\n... 后面一直是空文本，但音频文件实际上时由内容的\r\n",
        "state": "open",
        "user": "LangJiHuangSha",
        "closed_by": null,
        "created_at": "2022-12-23T06:55:21+00:00",
        "updated_at": "2023-02-06T04:35:29+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "zh794390558",
            "LangJiHuangSha",
            "LangJiHuangSha",
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2773,
        "title": "[TTS] JETS -> E2E FastSpeech2 + HiFiGAN",
        "body": "E2E FastSpeech2 + HiFiGAN\r\n\r\nPaper: [JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to\r\nSpeech](https://arxiv.org/pdf/2203.16852.pdf)\r\n\r\nAlso check for more information about E2E-training TTS:\r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/1699",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-12-28T02:46:39+00:00",
        "updated_at": "2023-04-19T04:50:08+00:00",
        "closed_at": "2023-04-19T04:50:08+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2766,
        "title": "执行语音转文字报错",
        "body": "## General Question\r\n\r\nTraceback (most recent call last):\r\n  File \"/tmp/dataspell_projects/Users/fanwenjie/Documents/project/paddle241/demo8.py\", line 1, in <module>\r\n    from paddlespeech.cli.asr.infer import ASRExecutor\r\n  File \"/root/anaconda3/envs/paddle241/lib/python3.10/site-packages/paddlespeech/cli/__init__.py\", line 24, in <module>\r\n    from .vector import VectorExecutor\r\n  File \"/root/anaconda3/envs/paddle241/lib/python3.10/site-packages/paddlespeech/cli/vector/__init__.py\", line 14, in <module>\r\n    from .infer import VectorExecutor\r\n  File \"/root/anaconda3/envs/paddle241/lib/python3.10/site-packages/paddlespeech/cli/vector/infer.py\", line 25, in <module>\r\n    from paddleaudio.backends import load as load_audio\r\nImportError: cannot import name 'load' from 'paddleaudio.backends' (/root/anaconda3/envs/paddle241/lib/python3.10/site-packages/paddleaudio/backends/__init__.py)\r\n\r\n版本\r\nconda 22.11.1\r\npaddle2onnx               1.0.5                    pypi_0    pypi\r\npaddleaudio               1.0.2                    pypi_0    pypi\r\npaddlefsl                 1.1.0                    pypi_0    pypi\r\npaddlenlp                 2.4.7                    pypi_0    pypi\r\npaddleocr                 2.6.1.2                  pypi_0    pypi\r\npaddlepaddle-gpu          2.4.1.post117            pypi_0    pypi\r\npaddlespeech              1.0.1                    pypi_0    pypi\r\npaddlespeech-feat         0.1.0                    pypi_0    pypi\r\n\r\n系统 ubantu 20.04\r\n\r\n\r\n执行的代码：\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"/data/paddle241/zh.wav\")\r\nprint(result)",
        "state": "closed",
        "user": "MemoryF",
        "closed_by": "yt605155624",
        "created_at": "2022-12-27T01:47:26+00:00",
        "updated_at": "2022-12-28T02:55:12+00:00",
        "closed_at": "2022-12-28T02:55:12+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2777
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2774,
        "title": "[S2T] PaddleSpeech illegal instruction 4 on Apple Silicon M1",
        "body": "This error is very persistent on Apple Silicon M1 -\r\nI have tried alternative installations with pip and docker with the same error.\r\n\r\nThe safest installation due to better dependency checks seems to be with conda.\r\n\r\n**Describe the bug**\r\nAfter installation, any paddlespeech command throws the error message:\r\n\r\n```\r\npaddlespeech help\r\nIllegal instruction: 4\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nCONDA_SUBDIR=osx-64 create -n paddle pip python=3.10 sox libsndfile swig bzip2\r\nconda activate paddle\r\n\r\n# install paddlepaddle with conda for osx64\r\nCONDA_SUBDIR=osx-64 conda install paddlepaddle --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/\r\n\r\n# due to thrown error for invalid wheel for opencv-python\r\npip install --upgrade pip --force\r\npip install paddleocr --upgrade\r\n\r\n# due to installation issue https://github.com/PaddlePaddle/PaddleSpeech/issues/2687\r\npip install paddleaudio==1.0.1\r\n\r\n# final paddlespeech installation\r\npip install paddlespeech\r\n```\r\n\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "agilebean",
        "closed_by": null,
        "created_at": "2022-12-28T04:33:30+00:00",
        "updated_at": "2023-05-20T20:00:46+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "askona"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2775,
        "title": "File \"/root/anaconda3/envs/rpa/lib/python3.8/site-packages/yacs/config.py\", line 141, in getattr raise AttributeError(name) AttributeError: preprocess_config",
        "body": "跑脚本代码为： \r\n```bash\r\nCUDA_VISIBLE_DEVICES=1 ./local/test_wav.sh conf/deepspeech2.yaml conf/tuning/decode.yaml exp/deepspeech2/checkpoints/avg_1 data/demo_01_03.wav，\r\n```\r\n报的错为：\r\n\r\n\r\nTraceback (most recent call last):   File \"/data/rshm/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py\", line 201, in <module>     main(config, args)   File \"/data/rshm/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py\", line 169, in main     main_sp(config, args)   File \"/data/rshm/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py\", line 163, in main_sp     exp = DeepSpeech2Tester_hub(config, args)   File \"/data/rshm/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py\", line 42, in __init__     self.preprocess_conf = config.preprocess_config   File \"/root/anaconda3/envs/rpa/lib/python3.8/site-packages/yacs/config.py\", line 141, in __getattr__     raise AttributeError(name) AttributeError: preprocess_config\r\n",
        "state": "open",
        "user": "shumeirao",
        "closed_by": null,
        "created_at": "2022-12-28T08:15:49+00:00",
        "updated_at": "2022-12-29T02:32:57+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2776,
        "title": "使用命令行进行文字语言合成时，报错：“raise BadZipFile(\"File is not a zip file\") zipfile.BadZipFile: File is not a zip file”",
        "body": "具体：\r\nTraceback (most recent call last):\r\n  File \"D:\\ProgramFiles\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"D:\\ProgramFiles\\Python38\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\Scripts\\paddlespeech.exe\\__main__.py\", line 7, in <module>\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\cli\\entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\cli\\tts\\__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\t2s\\__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\__init__.py\", line 16, in <module>\r\n    from .phonectic import *\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\phonectic.py\", line 20, in <module>\r\n    from g2p_en import G2p\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\g2p_en\\__init__.py\", line 1, in <module>\r\n    from .g2p import G2p\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\g2p_en\\g2p.py\", line 26, in <module>\r\n    nltk.data.find('corpora/cmudict.zip')\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\nltk\\data.py\", line 542, in find\r\n    return ZipFilePathPointer(p, zipentry)\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\nltk\\compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\nltk\\data.py\", line 394, in __init__\r\n    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\nltk\\compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"E:\\PycharmProjects\\ConvertWebWithAjax\\venv\\lib\\site-packages\\nltk\\data.py\", line 935, in __init__\r\n    zipfile.ZipFile.__init__(self, filename)\r\n  File \"D:\\ProgramFiles\\Python38\\lib\\zipfile.py\", line 1269, in __init__\r\n    self._RealGetContents()\r\n  File \"D:\\ProgramFiles\\Python38\\lib\\zipfile.py\", line 1336, in _RealGetContents\r\n    raise BadZipFile(\"File is not a zip file\")\r\nzipfile.BadZipFile: File is not a zip file\r\n\r\n下载了nltk也解压到项目根目录，但总是报错，不知道什么原因，求解？",
        "state": "closed",
        "user": "yinghao2016",
        "closed_by": "yt605155624",
        "created_at": "2022-12-28T09:13:11+00:00",
        "updated_at": "2022-12-28T12:34:57+00:00",
        "closed_at": "2022-12-28T12:34:57+00:00",
        "comments_count": [
            "yt605155624",
            "yinghao2016"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2780,
        "title": "非流式的tts_inference引擎下，多说话人合成报错",
        "body": "\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **zupu8** December 28, 2022</sup>\r\n系统环境：win10\r\n软件：Paddlespeech_Server \r\n问题：非流式的tts_inference引擎下的模型调用tts_python下的模型报错\r\n配置文件：\r\n\r\nhost: 0.0.0.0\r\nport: 8099\r\n\r\nprotocol: 'http'\r\nengine_list: ['tts_inference']\r\n\r\n\r\n//################################### TTS #########################################//\r\n//################### speech task: tts; engine_type: python #######################//\r\ntts_python:\r\n    # am (acoustic model) choices=['speedyspeech_csmsc', 'fastspeech2_csmsc',\r\n    #                             'fastspeech2_ljspeech', 'fastspeech2_aishell3',\r\n    #                             'fastspeech2_vctk', 'fastspeech2_mix',\r\n    #                             'tacotron2_csmsc', 'tacotron2_ljspeech']\r\n    am: 'fastspeech2_aishell3'   \r\n    am_config: \r\n    am_ckpt: \r\n    am_stat: \r\n    phones_dict: \r\n    tones_dict: \r\n    speaker_dict: \r\n\r\n\r\n    # voc (vocoder) choices=['pwgan_csmsc', 'pwgan_ljspeech', 'pwgan_aishell3',\r\n    #                        'pwgan_vctk', 'mb_melgan_csmsc', 'style_melgan_csmsc',\r\n    #                        'hifigan_csmsc', 'hifigan_ljspeech', 'hifigan_aishell3',\r\n    #                        'hifigan_vctk', 'wavernn_csmsc']\r\n    voc: 'hifigan_aishell3'\r\n    voc_config: \r\n    voc_ckpt: \r\n    voc_stat: \r\n\r\n    # others\r\n    lang: 'zh'\r\n    device: # set 'gpu:id' or 'cpu'\r\n\r\n\r\n################### speech task: tts; engine_type: inference #######################\r\ntts_inference:\r\n    # am (acoustic model) choices=['speedyspeech_csmsc', 'fastspeech2_csmsc']\r\n    am: 'fastspeech2_aishell3'   \r\n    am_model: # the pdmodel file of your am static model (XX.pdmodel)\r\n    am_params: # the pdiparams file of your am static model (XX.pdipparams)\r\n    am_sample_rate: 24000\r\n    phones_dict: \r\n    tones_dict: \r\n    speaker_dict: \r\n    spk_id: 0\r\n\r\n    am_predictor_conf:\r\n        device:  # set 'gpu:id' or 'cpu'\r\n        switch_ir_optim: True\r\n        glog_info: False # True -> print glog\r\n        summary: True  # False -> do not show predictor config\r\n\r\n    # voc (vocoder) choices=['pwgan_csmsc', 'mb_melgan_csmsc','hifigan_csmsc']\r\n    voc: 'hifigan_aishell3'\r\n    voc_model: # the pdmodel file of your vocoder static model (XX.pdmodel)\r\n    voc_params: # the pdiparams file of your vocoder static model (XX.pdipparams)\r\n    voc_sample_rate: 24000\r\n\r\n    voc_predictor_conf:\r\n        device:  # set 'gpu:id' or 'cpu'  \r\n        switch_ir_optim: True  \r\n        glog_info: False # True -> print glog\r\n        summary: True  # False -> do not show predictor config\r\n\r\n    # others\r\n    lang: 'zh'\r\n\r\n启动：paddlespeech_server start --config_file .paddlespeech\\conf\\application.yaml\r\n报错：\r\n[2022-12-28 16:46:57,668] [    INFO] - Initialize TTS server engine successfully on device: gpu:0.\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-12-28 16:46:57] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\r\n[2022-12-28 16:46:57] [DEBUG] [__init__.py:132] Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\r\nLoading model cost 0.465 seconds.\r\n[2022-12-28 16:46:58] [DEBUG] [__init__.py:164] Loading model cost 0.465 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-12-28 16:46:58] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\n[2022-12-28 16:46:58,240] [   ERROR] - Failed to warm up on tts engine.\r\n[2022-12-28 16:46:58,240] [   ERROR] - local variable 'mel' referenced before assignment</div>",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "lym0302",
        "created_at": "2022-12-28T13:34:22+00:00",
        "updated_at": "2022-12-28T13:58:45+00:00",
        "closed_at": "2022-12-28T13:58:45+00:00",
        "comments_count": [],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2782,
        "title": "[TTS]歌声转换（Sing Voice Conversion）",
        "body": "https://github.com/prophesier/diff-svc",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2022-12-29T03:27:06+00:00",
        "updated_at": "2022-12-29T05:09:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2785
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2788
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2781,
        "title": "想请问一下用python api进行语音识别，用的默认的conformer模型，是否可以以batch的形式进行预测呢？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "shumeirao",
        "closed_by": null,
        "created_at": "2022-12-29T02:57:08+00:00",
        "updated_at": "2023-01-05T02:18:03+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2778,
        "title": "【S2T】请问speechX是否支持ASR流式的多线程并发部署？",
        "body": "如题。各位大神，请问现在的speechX是否支持多线程并发部署？我直接使用提供的python代码部署ASR流式识别，发现其不能进行多线程并发。请问speechX可以吗？",
        "state": "open",
        "user": "Tian14267",
        "closed_by": null,
        "created_at": "2022-12-28T10:24:17+00:00",
        "updated_at": "2023-04-12T06:26:38+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "bonad"
        ],
        "labels": [
            "Question",
            "feature request",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2789
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2783,
        "title": "fast deploy 并发问题",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/96d76c83ade6dad94738ef4ae1a095dec3f858b3/demos/streaming_tts_serving_fastdeploy/streaming_tts_serving/stream_client.py#L74\r\nvalue = [’哈哈', '哈哈'] 报错\r\n‘’‘\r\ntritonclient.utils.InferenceServerException: [request id: 0] input 'INPUT_0' already exists in request\r\n’‘’\r\n",
        "state": "closed",
        "user": "kFoodie",
        "closed_by": "lym0302",
        "created_at": "2022-12-29T03:48:04+00:00",
        "updated_at": "2022-12-29T10:33:56+00:00",
        "closed_at": "2022-12-29T08:52:11+00:00",
        "comments_count": [
            "lym0302",
            "lym0302",
            "kFoodie"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2787,
        "title": "四川话TTS前端有好的方案么",
        "body": null,
        "state": "closed",
        "user": "Pydataman",
        "closed_by": "yt605155624",
        "created_at": "2022-12-30T08:39:55+00:00",
        "updated_at": "2023-03-02T09:21:42+00:00",
        "closed_at": "2023-03-02T09:21:42+00:00",
        "comments_count": [
            "yt605155624",
            "Pydataman",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2792,
        "title": "💡 使用 paddlespeech CLI 或者 paddlespeech_server 报错，但是无法看到具体的报错信息 -> 修改 log 日志等级后查看",
        "body": "参考 \r\n- https://github.com/PaddlePaddle/PaddleSpeech/issues/2387",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-01-04T06:29:22+00:00",
        "updated_at": "2023-01-04T09:26:44+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2790,
        "title": "关于小样本微调测试的报错【This dataset has no examples】",
        "body": "<img width=\"1761\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12654801/210199150-b534dbfd-12be-4fd1-ac68-8c3afb90601b.png\">\r\n\r\n已参考 https://github.com/PaddlePaddle/PaddleSpeech/issues/2456 及 https://github.com/PaddlePaddle/PaddleSpeech/issues/2319 ，但未能解决问题，期待答复 ~",
        "state": "closed",
        "user": "peiqianggao",
        "closed_by": "peiqianggao",
        "created_at": "2023-01-02T06:04:44+00:00",
        "updated_at": "2023-05-19T05:27:20+00:00",
        "closed_at": "2023-01-03T07:00:33+00:00",
        "comments_count": [
            "peiqianggao",
            "yt605155624",
            "peiqianggao",
            "peiqianggao",
            "iftaken",
            "peiqianggao",
            "NLPerxue",
            "truthsun22",
            "truthsun22",
            "NLPerxue"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2803,
        "title": "[TTS] Try to train a universial GAN Vocoder using CSMSC + LJSpeech + AISHELL3 + VCTK",
        "body": "An universial GAN Vocoder may works well for all AMs of different datasets, for example, CSMSC is a single female dataset, may generate bad wavs for mels of male speakers, cause different genders have different distribution of speech features.\r\n\r\nPlease try to train a universial GAN Vocoder using CSMSC + LJSpeech + AISHELL3 + VCTK + some other TTS datasets (if you want) with the config of CSMSC (24kHz).\r\n\r\nLJSpeech is 22.05kHz, but you don't need to resample it yourself, cause we will resample the wavs to the sample rate setted in config file in preprocess stage ~\r\n\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-01-06T11:34:34+00:00",
        "updated_at": "2023-01-06T11:40:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2797,
        "title": "流式语音识别运行报错",
        "body": "运行流式websocket语音识别ws_conformer_wenetspeech_application_faster.yaml显示\r\n![图片](https://user-images.githubusercontent.com/94445730/210710787-7e2ea9ca-3eea-40ab-b5f9-a42f644529d2.png)\r\n",
        "state": "closed",
        "user": "gfhjjk",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-05T05:50:03+00:00",
        "updated_at": "2023-05-21T10:48:11+00:00",
        "closed_at": "2023-05-21T10:48:11+00:00",
        "comments_count": [
            "zxcd",
            "gfhjjk",
            "yt605155624",
            "zxcd",
            "gfhjjk",
            "zxcd",
            "gfhjjk",
            "yt605155624",
            "gfhjjk",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2793,
        "title": "文本加标点，文本字数是否有限制",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n当输入文本较长时，后面部分添加的标点是乱的。请问是什么原因？\r\n效果如下：\r\n\r\n全国政协十号在京召开网络议政远程协商会，议题是：加强大数据时代个人信息，保护中共中央政治局常委、全国政协主席汪洋主持会议并讲话，他强调，要深入学习贯彻习近平总书记关于网络安全和个人信息保护工作的重要指示精神，以发展的眼光和辩证的思维，看待大数据时代个人信息保护问题；坚持以人民为中心，坚持政府监管、行业自律、社会参与、统筹推进，坚持标本监制，在提高信息资源利用水平的同时，科学有效保护信息安全，让大数据更好服务社会、造福人民；十四位委员与专家在全国政协机关和辽宁、安徽、湖南、贵州五个会场，以及通过手机连线方式发言，近一把式卫；委员通过移动旅职平台发表意见，大家认为，党中央高度重视大数据时代个人信息保护，有关方面做了大量工作，取得了积极成效，但传统个人信息保护制度和方式，跟不上；互联网广泛普及和数字产业迅猛发展的新形式，维护信息安全，依然任重到源；一些委员建议，要加快出台专门的个人信息保护法律，加大专项治理力度，重权，打击非法收集、交易、使用个人信息的违法犯罪活动，提高违法违规成本，最大限度挤压网络黑灰产业生存空间，要实施分级分类保护，建立个人信息利用清单强化对人，脸，识别数据爬取等技术，应用和人，肉，搜索，等行为的监、管要压，实企业主体责，任、广泛宣传个人，信息安全知识技术，和理、念，增强公、民；自我保护；意识不给违法、犯罪行为以可乘之机要加强部门；间信息共享和统、筹；协、调建、立统、一的个人，信息保护；监、管平台避免多头，执法、和重复执法、中央网信办，工业和信息化部公、安部卫生、健康委市场，监、管总局等部门；负责，同志，现场，做了互动交流",
        "state": "closed",
        "user": "nuo900617",
        "closed_by": "nuo900617",
        "created_at": "2023-01-04T06:33:09+00:00",
        "updated_at": "2023-01-12T09:48:51+00:00",
        "closed_at": "2023-01-12T09:48:51+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2795,
        "title": "[S2T]使用源码安装whisper时调用cli会报错提示找不到mel_filters.npz",
        "body": "环境：AIstudio\r\n![image](https://user-images.githubusercontent.com/54951765/210551499-0c91e219-f88b-4cf2-bb38-5f51560e7b26.png)\r\n\r\n新建环境使用pip安装后可以正常运行\r\n![image](https://user-images.githubusercontent.com/54951765/210522435-e7a65271-882a-4ca3-905c-592453476b35.png)\r\n![image](https://user-images.githubusercontent.com/54951765/210551402-c720dab0-9d10-4867-b42e-c394789ce6cb.png)\r\n",
        "state": "closed",
        "user": "kslz",
        "closed_by": "kslz",
        "created_at": "2023-01-04T09:18:21+00:00",
        "updated_at": "2023-01-05T03:09:16+00:00",
        "closed_at": "2023-01-05T03:09:16+00:00",
        "comments_count": [
            "zxcd",
            "kslz",
            "zxcd",
            "kslz",
            "zxcd",
            "kslz"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2798,
        "title": "[ASR] paddlespeech的ASR流式部署有什么优势",
        "body": "**大神们好。我有个问题想咨询下各位大神们。**\r\n\r\n**Paddlespeech**的**ASR**流式部署，我看使用的是`fastapi`中的`WebSocket`进行部署的。以及有部分`APIRouter()`，这样部署和直接使用`pip install websockets`中的`websockets`，有什么样的优势和不同吗？\r\n\r\n比如说，是效率更高吗？还是说更加能够避免某些问题？\r\n\r\n另外，流式部署调用的时候，如果语音流传入间隔较大，是否会导致服务端无法及时收到数据和处理数据，导致服务自动关闭（ping tiomeout）呢？这样的情况可以控制和避免吗？\r\n\r\n最后，如果使用Paddlespeech的这个部署方案，在预测器（模型）方面启动多个实例，异步调用的时候，能否实现多个实例同时预测（多个实例由同一个IP和PORT管理）\r\n\r\n**非常感谢各位大神们的耐心阅读和解答。感谢。**",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-05T07:00:39+00:00",
        "updated_at": "2023-05-20T16:19:50+00:00",
        "closed_at": "2023-05-20T16:19:50+00:00",
        "comments_count": [
            "zh794390558",
            "iftaken",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2804,
        "title": "用PyCharm使用语音转文字代码时报错",
        "body": "![image](https://user-images.githubusercontent.com/103914941/211036922-8e1fda56-da9b-4017-ba4e-ad7a81676dce.png)\r\n如图，显示缺少paddle模块，在Anaconda pip安装又出现错误：\r\n![image](https://user-images.githubusercontent.com/103914941/211037162-297ef9d2-a081-4427-8cd3-302d9b034ae1.png)\r\n",
        "state": "closed",
        "user": "suna2000",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-06T14:55:52+00:00",
        "updated_at": "2023-05-21T10:48:13+00:00",
        "closed_at": "2023-05-21T10:48:13+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2808
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2805,
        "title": "想知道在tts finetune微调模型中，可以在一个模型中微调多个自定义发音人吗",
        "body": "使用aishell多发音人模型，然后用自定义发音人A的数据集微调出来新的模型，替代了原模型中的spkid=0，\r\n\r\n请问可以基于这个新的模型再使用自定义发音人B的数据集，替代原模型中的spkid=1，微调出包含两个自定义发音人的模型吗？\r\n\r\n这样在使用微调后模型的时候，可以通过指定发音人id来合成不同音色的语音 ~",
        "state": "closed",
        "user": "peiqianggao",
        "closed_by": "peiqianggao",
        "created_at": "2023-01-07T10:23:45+00:00",
        "updated_at": "2023-01-16T03:49:21+00:00",
        "closed_at": "2023-01-16T03:49:21+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2810
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2811
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2812
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2806,
        "title": "如何设置paddlespeech的st识别中文音频并翻译为英语",
        "body": "## General Question\r\n如何设置paddlespeech的st识别中文音频并翻译为英语\r\npaddlespeech st 如何设置使用什么模型，可以将中文音频文件翻译为英语文本？\r\n",
        "state": "closed",
        "user": "wwbnjsace",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-08T05:17:17+00:00",
        "updated_at": "2023-05-21T10:48:13+00:00",
        "closed_at": "2023-05-21T10:48:13+00:00",
        "comments_count": [
            "zh794390558",
            "zxcd",
            "wwbnjsace",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2807,
        "title": "流式语音识别发送pcm16数据报错",
        "body": "我用paddlepaddle==2.3.1,paddlespeech==1.1.3 进行流式语音识别，开始信号是连接成功的，发送数据报这个错\r\n![图片](https://user-images.githubusercontent.com/94445730/211184922-d447acc4-de07-4247-83b0-7347a83cdec2.png)\r\n",
        "state": "open",
        "user": "gfhjjk",
        "closed_by": null,
        "created_at": "2023-01-08T07:17:25+00:00",
        "updated_at": "2023-01-10T10:45:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "gfhjjk",
            "zh794390558",
            "zh794390558",
            "gfhjjk",
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2813,
        "title": "Speechx编译报错",
        "body": "环境：使用了`registry.baidubce.com/paddlepaddle/paddle:2.4.1`的docker镜像，所使用的服务器没有GPU。\r\n\r\n步骤：按照[文档](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/speechx/README.md)中的步骤进行编译，仅将文档中`docker run --privileged  --net=host --ipc=host -it --rm -v /path/to/paddlespeech:/workspace --name=dev registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7 /bin/bash`改为了`docker run --privileged  --net=host --ipc=host -it --rm -v /path/to/paddlespeech/:/workspace --name=dev registry.baidubce.com/paddlepaddle/paddle:2.4.1 /bin/bash`\r\n\r\n另外，我也尝试了使用文档中的docker镜像进行编译，结果仍然编译错误，`registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7`的`CMakeError.log`如下：\r\n```\r\nPerforming C SOURCE FILE Test CMAKE_HAVE_LIBC_PTHREAD failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_e8d3f/fast && /usr/bin/make -f CMakeFiles/cmTC_e8d3f.dir/build.make CMakeFiles/cmTC_e8d3f.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_e8d3f.dir/src.c.o\r\n/usr/bin/cc   -DCMAKE_HAVE_LIBC_PTHREAD   -o CMakeFiles/cmTC_e8d3f.dir/src.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.c\r\nLinking C executable cmTC_e8d3f\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_e8d3f.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCMAKE_HAVE_LIBC_PTHREAD    -rdynamic CMakeFiles/cmTC_e8d3f.dir/src.c.o  -o cmTC_e8d3f \r\nCMakeFiles/cmTC_e8d3f.dir/src.c.o: In function `main':\r\nsrc.c:(.text+0x2d): undefined reference to `pthread_create'\r\nsrc.c:(.text+0x39): undefined reference to `pthread_detach'\r\nsrc.c:(.text+0x4a): undefined reference to `pthread_join'\r\nsrc.c:(.text+0x5e): undefined reference to `pthread_atfork'\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_e8d3f.dir/build.make:86: recipe for target 'cmTC_e8d3f' failed\r\nmake[1]: *** [cmTC_e8d3f] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_e8d3f/fast' failed\r\nmake: *** [cmTC_e8d3f/fast] Error 2\r\n\r\n\r\nSource file was:\r\n#include <pthread.h>\r\n\r\nvoid* test_func(void* data)\r\n{\r\n  return data;\r\n}\r\n\r\nint main(void)\r\n{\r\n  pthread_t thread;\r\n  pthread_create(&thread, NULL, test_func, NULL);\r\n  pthread_detach(thread);\r\n  pthread_join(thread, NULL);\r\n  pthread_atfork(NULL, NULL, NULL);\r\n  pthread_exit(NULL);\r\n\r\n  return 0;\r\n}\r\n\r\nDetermining if the function pthread_create exists in the pthreads failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_9c875/fast && /usr/bin/make -f CMakeFiles/cmTC_9c875.dir/build.make CMakeFiles/cmTC_9c875.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_9c875.dir/CheckFunctionExists.c.o\r\n/usr/bin/cc   -DCHECK_FUNCTION_EXISTS=pthread_create   -o CMakeFiles/cmTC_9c875.dir/CheckFunctionExists.c.o   -c /home/cmake-3.16.0-Linux-x86_64/share/cmake-3.16/Modules/CheckFunctionExists.c\r\nLinking C executable cmTC_9c875\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_9c875.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCHECK_FUNCTION_EXISTS=pthread_create    -rdynamic CMakeFiles/cmTC_9c875.dir/CheckFunctionExists.c.o  -o cmTC_9c875  -lpthreads \r\n/usr/local/bin/ld: cannot find -lpthreads\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_9c875.dir/build.make:86: recipe for target 'cmTC_9c875' failed\r\nmake[1]: *** [cmTC_9c875] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_9c875/fast' failed\r\nmake: *** [cmTC_9c875/fast] Error 2\r\n\r\n\r\n\r\nDetermining if the include file libunwind.h exists failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_9fd3b/fast && /usr/bin/make -f CMakeFiles/cmTC_9fd3b.dir/build.make CMakeFiles/cmTC_9fd3b.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_9fd3b.dir/CheckIncludeFile.c.o\r\n/usr/bin/cc    -o CMakeFiles/cmTC_9fd3b.dir/CheckIncludeFile.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:10: fatal error: libunwind.h: No such file or directory\r\n #include <libunwind.h>\r\n          ^~~~~~~~~~~~~\r\ncompilation terminated.\r\nCMakeFiles/cmTC_9fd3b.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_9fd3b.dir/CheckIncludeFile.c.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_9fd3b.dir/CheckIncludeFile.c.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_9fd3b/fast' failed\r\nmake: *** [cmTC_9fd3b/fast] Error 2\r\n\r\n\r\n\r\nDetermining size of unsigned __int16 failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_7a0fc/fast && /usr/bin/make -f CMakeFiles/cmTC_7a0fc.dir/build.make CMakeFiles/cmTC_7a0fc.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_7a0fc.dir/HAVE___UINT16.c.o\r\n/usr/bin/cc    -o CMakeFiles/cmTC_7a0fc.dir/HAVE___UINT16.c.o   -c /workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:23:31: error: expected ‘)’ before ‘__int16’\r\n #define SIZE (sizeof(unsigned __int16))\r\n                     ~         ^~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:25:12: note: in expansion of macro ‘SIZE’\r\n   ('0' + ((SIZE / 10000)%10)),\r\n            ^~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:23:31: error: expected ‘)’ before ‘__int16’\r\n #define SIZE (sizeof(unsigned __int16))\r\n                     ~         ^~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:26:12: note: in expansion of macro ‘SIZE’\r\n   ('0' + ((SIZE / 1000)%10)),\r\n            ^~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:23:31: error: expected ‘)’ before ‘__int16’\r\n #define SIZE (sizeof(unsigned __int16))\r\n                     ~         ^~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:27:12: note: in expansion of macro ‘SIZE’\r\n   ('0' + ((SIZE / 100)%10)),\r\n            ^~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:23:31: error: expected ‘)’ before ‘__int16’\r\n #define SIZE (sizeof(unsigned __int16))\r\n                     ~         ^~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:28:12: note: in expansion of macro ‘SIZE’\r\n   ('0' + ((SIZE / 10)%10)),\r\n            ^~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:23:31: error: expected ‘)’ before ‘__int16’\r\n #define SIZE (sizeof(unsigned __int16))\r\n                     ~         ^~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:29:12: note: in expansion of macro ‘SIZE’\r\n   ('0' +  (SIZE    % 10)),\r\n            ^~~~\r\nCMakeFiles/cmTC_7a0fc.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_7a0fc.dir/HAVE___UINT16.c.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_7a0fc.dir/HAVE___UINT16.c.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_7a0fc/fast' failed\r\nmake: *** [cmTC_7a0fc/fast] Error 2\r\n\r\n\r\n/workspace/speechx/build/CMakeFiles/CheckTypeSize/HAVE___UINT16.c:\r\n#include <sys/types.h>\r\n#include <stdint.h>\r\n#include <stddef.h>\r\n\r\n\r\n#undef KEY\r\n#if defined(__i386)\r\n# define KEY '_','_','i','3','8','6'\r\n#elif defined(__x86_64)\r\n# define KEY '_','_','x','8','6','_','6','4'\r\n#elif defined(__ppc__)\r\n# define KEY '_','_','p','p','c','_','_'\r\n#elif defined(__ppc64__)\r\n# define KEY '_','_','p','p','c','6','4','_','_'\r\n#elif defined(__aarch64__)\r\n# define KEY '_','_','a','a','r','c','h','6','4','_','_'\r\n#elif defined(__ARM_ARCH_7A__)\r\n# define KEY '_','_','A','R','M','_','A','R','C','H','_','7','A','_','_'\r\n#elif defined(__ARM_ARCH_7S__)\r\n# define KEY '_','_','A','R','M','_','A','R','C','H','_','7','S','_','_'\r\n#endif\r\n\r\n#define SIZE (sizeof(unsigned __int16))\r\nstatic char info_size[] =  {'I', 'N', 'F', 'O', ':', 's','i','z','e','[',\r\n  ('0' + ((SIZE / 10000)%10)),\r\n  ('0' + ((SIZE / 1000)%10)),\r\n  ('0' + ((SIZE / 100)%10)),\r\n  ('0' + ((SIZE / 10)%10)),\r\n  ('0' +  (SIZE    % 10)),\r\n  ']',\r\n#ifdef KEY\r\n  ' ','k','e','y','[', KEY, ']',\r\n#endif\r\n  '\\0'};\r\n\r\n#ifdef __CLASSIC_C__\r\nint main(argc, argv) int argc; char *argv[];\r\n#else\r\nint main(int argc, char *argv[])\r\n#endif\r\n{\r\n  int require = 0;\r\n  require += info_size[argc];\r\n  (void)argv;\r\n  return require;\r\n}\r\n\r\n\r\nDetermining if the function dladdr exists failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_2cdcc/fast && /usr/bin/make -f CMakeFiles/cmTC_2cdcc.dir/build.make CMakeFiles/cmTC_2cdcc.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_2cdcc.dir/CheckFunctionExists.c.o\r\n/usr/bin/cc   -DCHECK_FUNCTION_EXISTS=dladdr   -o CMakeFiles/cmTC_2cdcc.dir/CheckFunctionExists.c.o   -c /home/cmake-3.16.0-Linux-x86_64/share/cmake-3.16/Modules/CheckFunctionExists.c\r\nLinking C executable cmTC_2cdcc\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_2cdcc.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCHECK_FUNCTION_EXISTS=dladdr    -rdynamic CMakeFiles/cmTC_2cdcc.dir/CheckFunctionExists.c.o  -o cmTC_2cdcc \r\nCMakeFiles/cmTC_2cdcc.dir/CheckFunctionExists.c.o: In function `main':\r\nCheckFunctionExists.c:(.text+0x10): undefined reference to `dladdr'\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_2cdcc.dir/build.make:86: recipe for target 'cmTC_2cdcc' failed\r\nmake[1]: *** [cmTC_2cdcc] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_2cdcc/fast' failed\r\nmake: *** [cmTC_2cdcc/fast] Error 2\r\n\r\n\r\n\r\nPerforming C++ SOURCE FILE Test HAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_e6bdf/fast && /usr/bin/make -f CMakeFiles/cmTC_e6bdf.dir/build.make CMakeFiles/cmTC_e6bdf.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_e6bdf.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -DHAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS   -Wunnamed-type-template-args -o CMakeFiles/cmTC_e6bdf.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-Wunnamed-type-template-args'\r\nCMakeFiles/cmTC_e6bdf.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_e6bdf.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_e6bdf.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_e6bdf/fast' failed\r\nmake: *** [cmTC_e6bdf/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nDetermining if the function get_static_proc_name exists in the unwind failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_2a6fd/fast && /usr/bin/make -f CMakeFiles/cmTC_2a6fd.dir/build.make CMakeFiles/cmTC_2a6fd.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_2a6fd.dir/CheckFunctionExists.c.o\r\n/usr/bin/cc   -DCHECK_FUNCTION_EXISTS=get_static_proc_name   -o CMakeFiles/cmTC_2a6fd.dir/CheckFunctionExists.c.o   -c /home/cmake-3.16.0-Linux-x86_64/share/cmake-3.16/Modules/CheckFunctionExists.c\r\nLinking C executable cmTC_2a6fd\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_2a6fd.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCHECK_FUNCTION_EXISTS=get_static_proc_name    -rdynamic CMakeFiles/cmTC_2a6fd.dir/CheckFunctionExists.c.o  -o cmTC_2a6fd  -lunwind \r\n/usr/local/bin/ld: cannot find -lunwind\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_2a6fd.dir/build.make:86: recipe for target 'cmTC_2a6fd' failed\r\nmake[1]: *** [cmTC_2a6fd] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_2a6fd/fast' failed\r\nmake: *** [cmTC_2a6fd/fast] Error 2\r\n\r\n\r\n\r\nDetermining if the function UnDecorateSymbolName exists in the dbghelp failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_5f64c/fast && /usr/bin/make -f CMakeFiles/cmTC_5f64c.dir/build.make CMakeFiles/cmTC_5f64c.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_5f64c.dir/CheckFunctionExists.c.o\r\n/usr/bin/cc   -DCHECK_FUNCTION_EXISTS=UnDecorateSymbolName   -o CMakeFiles/cmTC_5f64c.dir/CheckFunctionExists.c.o   -c /home/cmake-3.16.0-Linux-x86_64/share/cmake-3.16/Modules/CheckFunctionExists.c\r\nLinking C executable cmTC_5f64c\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_5f64c.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCHECK_FUNCTION_EXISTS=UnDecorateSymbolName    -rdynamic CMakeFiles/cmTC_5f64c.dir/CheckFunctionExists.c.o  -o cmTC_5f64c  -ldbghelp \r\n/usr/local/bin/ld: cannot find -ldbghelp\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_5f64c.dir/build.make:86: recipe for target 'cmTC_5f64c' failed\r\nmake[1]: *** [cmTC_5f64c] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_5f64c/fast' failed\r\nmake: *** [cmTC_5f64c/fast] Error 2\r\n\r\n\r\n\r\nPerforming C SOURCE FILE Test HAVE_RWLOCK failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_b116c/fast && /usr/bin/make -f CMakeFiles/cmTC_b116c.dir/build.make CMakeFiles/cmTC_b116c.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_b116c.dir/src.c.o\r\n/usr/bin/cc   -DHAVE_RWLOCK   -o CMakeFiles/cmTC_b116c.dir/src.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.c\r\nLinking C executable cmTC_b116c\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_b116c.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DHAVE_RWLOCK    -rdynamic CMakeFiles/cmTC_b116c.dir/src.c.o  -o cmTC_b116c \r\nCMakeFiles/cmTC_b116c.dir/src.c.o: In function `main':\r\nsrc.c:(.text+0x15): undefined reference to `pthread_rwlock_init'\r\nsrc.c:(.text+0x21): undefined reference to `pthread_rwlock_rdlock'\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/cmTC_b116c.dir/build.make:86: recipe for target 'cmTC_b116c' failed\r\nmake[1]: *** [cmTC_b116c] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_b116c/fast' failed\r\nmake: *** [cmTC_b116c/fast] Error 2\r\n\r\n\r\nSource file was:\r\n\r\n#define _XOPEN_SOURCE 500\r\n#include <pthread.h>\r\nint main(void)\r\n{\r\n  pthread_rwlock_t l;\r\n  pthread_rwlock_init(&l, NULL);\r\n  pthread_rwlock_rdlock(&l);\r\n  return 0;\r\n}\r\n\r\nPerforming C SOURCE FILE Test HAVE___DECLSPEC failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_34f9b/fast && /usr/bin/make -f CMakeFiles/cmTC_34f9b.dir/build.make CMakeFiles/cmTC_34f9b.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_34f9b.dir/src.c.o\r\n/usr/bin/cc   -DHAVE___DECLSPEC   -o CMakeFiles/cmTC_34f9b.dir/src.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.c\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c:2:1: warning: return type defaults to ‘int’ [-Wimplicit-int]\r\n __declspec(selectany) int a;\r\n ^~~~~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c: In function ‘__declspec’:\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c:3:16: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘{’ token\r\n int main(void) { return 0; }\r\n                ^\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c:2:1: warning: type of ‘selectany’ defaults to ‘int’ [-Wimplicit-int]\r\n __declspec(selectany) int a;\r\n ^~~~~~~~~~\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c:2:27: error: declaration for parameter ‘a’ but no such parameter\r\n __declspec(selectany) int a;\r\n                           ^\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.c:4: error: expected ‘{’ at end of input\r\n \r\n \r\nCMakeFiles/cmTC_34f9b.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_34f9b.dir/src.c.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_34f9b.dir/src.c.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_34f9b/fast' failed\r\nmake: *** [cmTC_34f9b/fast] Error 2\r\n\r\n\r\nSource file was:\r\n\r\n__declspec(selectany) int a;\r\nint main(void) { return 0; }\r\n\r\nPerforming C++ SOURCE FILE Test STL_NO_NAMESPACE failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_9311b/fast && /usr/bin/make -f CMakeFiles/cmTC_9311b.dir/build.make CMakeFiles/cmTC_9311b.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_9311b.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -DSTL_NO_NAMESPACE   -o CMakeFiles/cmTC_9311b.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx:3:1: error: ‘vector’ does not name a type\r\n vector<int> t; int main() { }\r\n ^~~~~~\r\nCMakeFiles/cmTC_9311b.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_9311b.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_9311b.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_9311b/fast' failed\r\nmake: *** [cmTC_9311b/fast] Error 2\r\n\r\n\r\nSource file was:\r\n\r\n#include <vector>\r\nvector<int> t; int main() { }\r\n\r\nPerforming C++ SOURCE FILE Test HAVE_MSVC_TLS failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_9390b/fast && /usr/bin/make -f CMakeFiles/cmTC_9390b.dir/build.make CMakeFiles/cmTC_9390b.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_9390b.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -DHAVE_MSVC_TLS   -o CMakeFiles/cmTC_9390b.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx:2:11: error: expected constructor, destructor, or type conversion before ‘(’ token\r\n __declspec(thread) int tls;\r\n           ^\r\nCMakeFiles/cmTC_9390b.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_9390b.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_9390b.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_9390b/fast' failed\r\nmake: *** [cmTC_9390b/fast] Error 2\r\n\r\n\r\nSource file was:\r\n\r\n__declspec(thread) int tls;\r\nint main() { }\r\n\r\nDetermining if the include file direct.h exists failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_dab35/fast && /usr/bin/make -f CMakeFiles/cmTC_dab35.dir/build.make CMakeFiles/cmTC_dab35.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_dab35.dir/CheckIncludeFile.c.o\r\n/usr/bin/cc    -o CMakeFiles/cmTC_dab35.dir/CheckIncludeFile.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:10: fatal error: direct.h: No such file or directory\r\n #include <direct.h>\r\n          ^~~~~~~~~~\r\ncompilation terminated.\r\nCMakeFiles/cmTC_dab35.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_dab35.dir/CheckIncludeFile.c.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_dab35.dir/CheckIncludeFile.c.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_dab35/fast' failed\r\nmake: *** [cmTC_dab35/fast] Error 2\r\n\r\n\r\n\r\nDetermining if the include file io.h exists failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_045cc/fast && /usr/bin/make -f CMakeFiles/cmTC_045cc.dir/build.make CMakeFiles/cmTC_045cc.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_045cc.dir/CheckIncludeFile.c.o\r\n/usr/bin/cc    -o CMakeFiles/cmTC_045cc.dir/CheckIncludeFile.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\r\n/workspace/speechx/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:10: fatal error: io.h: No such file or directory\r\n #include <io.h>\r\n          ^~~~~~\r\ncompilation terminated.\r\nCMakeFiles/cmTC_045cc.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_045cc.dir/CheckIncludeFile.c.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_045cc.dir/CheckIncludeFile.c.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_045cc/fast' failed\r\nmake: *** [cmTC_045cc/fast] Error 2\r\n\r\n\r\n\r\nPerforming C SOURCE FILE Test CPU_CLIPS_POSITIVE failed with the following compile output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_173a9/fast && /usr/bin/make -f CMakeFiles/cmTC_173a9.dir/build.make CMakeFiles/cmTC_173a9.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_173a9.dir/src.c.o\r\n/usr/bin/cc   -DCPU_CLIPS_POSITIVE   -o CMakeFiles/cmTC_173a9.dir/src.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.c\r\nLinking C executable cmTC_173a9\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_173a9.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCPU_CLIPS_POSITIVE    -rdynamic CMakeFiles/cmTC_173a9.dir/src.c.o  -o cmTC_173a9  -lm \r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\n\r\n\r\n...and run output:\r\n\r\nReturn value: 1\r\nSource file was:\r\n\r\n\t\t\t#define\t_ISOC9X_SOURCE\t1\r\n\t\t\t#define _ISOC99_SOURCE\t1\r\n\t\t\t#define\t__USE_ISOC99\t1\r\n\t\t\t#define __USE_ISOC9X\t1\r\n\t\t\t#include <math.h>\r\n\t\t\tint main (void)\r\n\t\t\t{\tdouble\tfval ;\r\n\t\t\t\tint k, ival ;\r\n\r\n\t\t\t\tfval = 1.0 * 0x7FFFFFFF ;\r\n\t\t\t\tfor (k = 0 ; k < 100 ; k++)\r\n\t\t\t\t{\tival = (lrint (fval)) >> 24 ;\r\n\t\t\t\t\tif (ival != 127)\r\n\t\t\t\t\t\treturn 1 ;\r\n\t\t\t\t\r\n\t\t\t\t\tfval *= 1.2499999 ;\r\n\t\t\t\t\t} ;\r\n\t\t\t\t\r\n\t\t\t\t\treturn 0 ;\r\n\t\t\t\t}\r\n\t\t\t\r\nPerforming C SOURCE FILE Test CPU_CLIPS_NEGATIVE failed with the following compile output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_e8ff3/fast && /usr/bin/make -f CMakeFiles/cmTC_e8ff3.dir/build.make CMakeFiles/cmTC_e8ff3.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding C object CMakeFiles/cmTC_e8ff3.dir/src.c.o\r\n/usr/bin/cc   -DCPU_CLIPS_NEGATIVE   -o CMakeFiles/cmTC_e8ff3.dir/src.c.o   -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.c\r\nLinking C executable cmTC_e8ff3\r\n/home/cmake-3.16.0-Linux-x86_64/bin/cmake -E cmake_link_script CMakeFiles/cmTC_e8ff3.dir/link.txt --verbose=1\r\n/usr/bin/cc  -DCPU_CLIPS_NEGATIVE    -rdynamic CMakeFiles/cmTC_e8ff3.dir/src.c.o  -o cmTC_e8ff3  -lm \r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\n\r\n\r\n...and run output:\r\n\r\nReturn value: 1\r\nSource file was:\r\n\r\n\t\t\t#define\t_ISOC9X_SOURCE\t1\r\n\t\t\t#define _ISOC99_SOURCE\t1\r\n\t\t\t#define\t__USE_ISOC99\t1\r\n\t\t\t#define __USE_ISOC9X\t1\r\n\t\t\t#include <math.h>\r\n\t\t\tint main (void)\r\n\t\t\t{\tdouble\tfval ;\r\n\t\t\t\tint k, ival ;\r\n\r\n\t\t\t\tfval = -8.0 * 0x10000000 ;\r\n\t\t\t\tfor (k = 0 ; k < 100 ; k++)\r\n\t\t\t\t{\tival = (lrint (fval)) >> 24 ;\r\n\t\t\t\t\tif (ival != -128)\r\n\t\t\t\t\t\treturn 1 ;\r\n\t\t\t\t\r\n\t\t\t\t\tfval *= 1.2499999 ;\r\n\t\t\t\t\t} ;\r\n\t\t\t\t\r\n\t\t\t\t\treturn 0 ;\r\n\t\t\t\t}\r\n\t\t\t\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_Wshorten64to32 failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_5dd96/fast && /usr/bin/make -f CMakeFiles/cmTC_5dd96.dir/build.make CMakeFiles/cmTC_5dd96.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_5dd96.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -pedantic -Wall -Wextra -Wundef -Wcast-align -Wchar-subscripts -Wnon-virtual-dtor -Wunused-local-typedefs -Wpointer-arith -Wwrite-strings -Wformat-security -DCOMPILER_SUPPORT_Wshorten64to32 -Werror   -Wshorten-64-to-32 -o CMakeFiles/cmTC_5dd96.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-Wshorten-64-to-32'\r\nCMakeFiles/cmTC_5dd96.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_5dd96.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_5dd96.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_5dd96/fast' failed\r\nmake: *** [cmTC_5dd96/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_Wenumconversion failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_a4dbf/fast && /usr/bin/make -f CMakeFiles/cmTC_a4dbf.dir/build.make CMakeFiles/cmTC_a4dbf.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_a4dbf.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -pedantic -Wall -Wextra -Wundef -Wcast-align -Wchar-subscripts -Wnon-virtual-dtor -Wunused-local-typedefs -Wpointer-arith -Wwrite-strings -Wformat-security -Wlogical-op -DCOMPILER_SUPPORT_Wenumconversion -Werror   -Wenum-conversion -o CMakeFiles/cmTC_a4dbf.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-Wenum-conversion'; did you mean '-Wno-conversion'?\r\nCMakeFiles/cmTC_a4dbf.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_a4dbf.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_a4dbf.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_a4dbf/fast' failed\r\nmake: *** [cmTC_a4dbf/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_Wcpp11extensions failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_57bc6/fast && /usr/bin/make -f CMakeFiles/cmTC_57bc6.dir/build.make CMakeFiles/cmTC_57bc6.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_57bc6.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -pedantic -Wall -Wextra -Wundef -Wcast-align -Wchar-subscripts -Wnon-virtual-dtor -Wunused-local-typedefs -Wpointer-arith -Wwrite-strings -Wformat-security -Wlogical-op -DCOMPILER_SUPPORT_Wcpp11extensions -Werror   -Wc++11-extensions -o CMakeFiles/cmTC_57bc6.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-Wc++11-extensions'; did you mean '-fms-extensions'?\r\nCMakeFiles/cmTC_57bc6.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_57bc6.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_57bc6.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_57bc6/fast' failed\r\nmake: *** [cmTC_57bc6/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_wd981 failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_6cefb/fast && /usr/bin/make -f CMakeFiles/cmTC_6cefb.dir/build.make CMakeFiles/cmTC_6cefb.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_6cefb.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -pedantic -Wall -Wextra -Wundef -Wcast-align -Wchar-subscripts -Wnon-virtual-dtor -Wunused-local-typedefs -Wpointer-arith -Wwrite-strings -Wformat-security -Wlogical-op -Wdouble-promotion -Wshadow -Wno-psabi -Wno-variadic-macros -Wno-long-long -fno-check-new -fno-common -fstrict-aliasing -DCOMPILER_SUPPORT_wd981 -Werror   -wd981 -o CMakeFiles/cmTC_6cefb.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-wd981'\r\nCMakeFiles/cmTC_6cefb.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_6cefb.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_6cefb.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_6cefb/fast' failed\r\nmake: *** [cmTC_6cefb/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_wd2304 failed with the following output:\r\nChange Dir: /workspace/speechx/build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make cmTC_4d45c/fast && /usr/bin/make -f CMakeFiles/cmTC_4d45c.dir/build.make CMakeFiles/cmTC_4d45c.dir/build\r\nmake[1]: Entering directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nBuilding CXX object CMakeFiles/cmTC_4d45c.dir/src.cxx.o\r\n/usr/bin/c++    --std=c++14 -pthread -fPIC -O0 -Wall -g -pedantic -Wall -Wextra -Wundef -Wcast-align -Wchar-subscripts -Wnon-virtual-dtor -Wunused-local-typedefs -Wpointer-arith -Wwrite-strings -Wformat-security -Wlogical-op -Wdouble-promotion -Wshadow -Wno-psabi -Wno-variadic-macros -Wno-long-long -fno-check-new -fno-common -fstrict-aliasing -DCOMPILER_SUPPORT_wd2304 -Werror   -wd2304 -o CMakeFiles/cmTC_4d45c.dir/src.cxx.o -c /workspace/speechx/build/CMakeFiles/CMakeTmp/src.cxx\r\nc++: error: unrecognized command line option '-wd2304'\r\nCMakeFiles/cmTC_4d45c.dir/build.make:65: recipe for target 'CMakeFiles/cmTC_4d45c.dir/src.cxx.o' failed\r\nmake[1]: *** [CMakeFiles/cmTC_4d45c.dir/src.cxx.o] Error 1\r\nmake[1]: Leaving directory '/workspace/speechx/build/CMakeFiles/CMakeTmp'\r\nMakefile:121: recipe for target 'cmTC_4d45c/fast' failed\r\nmake: *** [cmTC_4d45c/fast] Error 2\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\n\r\n```\r\n\r\n另外除了log中的错误，似乎还缺少`pyconfig.h`、`fst/types.h`等头文件。",
        "state": "closed",
        "user": "nailvcoronation",
        "closed_by": "nailvcoronation",
        "created_at": "2023-01-09T17:08:30+00:00",
        "updated_at": "2023-01-11T08:31:41+00:00",
        "closed_at": "2023-01-11T08:31:41+00:00",
        "comments_count": [
            "zh794390558",
            "nailvcoronation",
            "zh794390558",
            "nailvcoronation",
            "zh794390558",
            "nailvcoronation"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2817,
        "title": " 是否考虑引入微软NaturalSpeech库中最新的模型",
        "body": "是否考虑引入微软NaturalSpeech库中最新的模型",
        "state": "open",
        "user": "tianlinzx",
        "closed_by": null,
        "created_at": "2023-01-10T14:18:49+00:00",
        "updated_at": "2023-01-11T05:25:18+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2821,
        "title": "[TTS] DiffSinger",
        "body": "- https://github.com/PaddlePaddle/PaddleSpeech/pull/3005\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2902\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2868\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2834\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2832\r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2023-01-11T03:05:43+00:00",
        "updated_at": "2023-03-13T10:20:23+00:00",
        "closed_at": "2023-03-13T10:20:22+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2823,
        "title": "[TTS] 训练一套多说话人 VITS 的模型参数",
        "body": "开发者 @HighCWu 贡献了多说话人的 VITS 模型代码，但是个人算力有限，没有贡献完整的预训练模型参数\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2268\r\n\r\n建议把 VITS-VC 里面的 speaker-encoder 从 GE2E 换成 ECAPA-TDNN, 参考 aishell3/vc2",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-01-11T03:13:16+00:00",
        "updated_at": "2023-01-11T06:58:51+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2820,
        "title": "result is in chinese or raises error",
        "body": "Im trying to do an inference and use this code:\r\n\r\n```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"./Record1new.wav\")\r\nprint(result)\r\n```\r\nBut it prints out in chinese\r\nWhen I change to this\r\n```\r\nresult = asr(audio_file=\"./ASR/s3prl/s3prl/mani2.wav\", lang=\"en\")\r\n```\r\nit raises error:\r\n```\r\n \"Can't find \\\"{}\\\" in resource. Model name must be one of {}\".format(model_tag, list(self.pretrained_models.keys()))\r\nAssertionError: Can't find \"conformer_wenetspeech-en-16k\" in resource. Model name must be one of ['conformer_wenetspeech-zh-16k', 'conformer_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_aishell-zh-16k', 'conformer_online_aishell-zh-16k', 'transformer_librispeech-en-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2offline_aishell-zh-16k', 'deepspeech2online_aishell-zh-16k', 'deepspeech2offline_librispeech-en-16k']\r\n```\r\nAny idea how can I pass the lang?\r\n\r\nThanks\r\n",
        "state": "closed",
        "user": "benam2",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-10T23:49:24+00:00",
        "updated_at": "2023-05-21T10:48:12+00:00",
        "closed_at": "2023-05-21T10:48:12+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2819,
        "title": "[S2T] Whisper ASR Model excution got TypeError",
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n```python-traceback\r\nTraceback (most recent call last)/tmp/ipykernel_98/3684188953.py in <module>\r\n     10     audio_file=audio_file,\r\n     11     language='ja',\r\n---> 12     device=paddle.get_device())\r\n~/external-libraries/paddlespeech/cli/utils.py in _warpper(self, *args, **kwargs)\r\n    326         except Exception:\r\n    327             pass\r\n--> 328         return executor_func(self, *args, **kwargs)\r\n    329 \r\n    330     return _warpper\r\n~/external-libraries/paddlespeech/cli/whisper/infer.py in __call__(self, audio_file, model, lang, task, size, language, sample_rate, config, ckpt_path, decode_method, num_decoding_left_chunks, force_yes, rtf, device)\r\n    482 \r\n    483         self.preprocess(model, audio_file)\r\n--> 484         self.infer(model)\r\n    485         res = self.postprocess()  # Retrieve result of asr.\r\n    486 \r\n<decorator-gen-695> in infer(self, model_type)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in _decorate_function(func, *args, **kwargs)\r\n    373         def _decorate_function(func, *args, **kwargs):\r\n    374             with self:\r\n--> 375                 return func(*args, **kwargs)\r\n    376 \r\n    377         @decorator.decorator\r\n~/external-libraries/paddlespeech/cli/whisper/infer.py in infer(self, model_type)\r\n    293             initial_prompt=cfg.initial_prompt,\r\n    294             condition_on_previous_text=cfg.condition_on_previous_text,\r\n--> 295             no_speech_threshold=cfg.no_speech_threshold)\r\n    296 \r\n    297     def postprocess(self) -> Union[str, os.PathLike]:\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in transcribe(model, mel, resource_path, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\r\n    623                         time_precision,\r\n    624                         text_tokens=sliced_tokens[1:-1],\r\n--> 625                         result=result, )\r\n    626                     last_slice = current_slice\r\n    627                 last_timestamp_position = (\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in add_segment(start, end, text_tokens, result)\r\n    552                     result: DecodingResult):\r\n    553         text = tokenizer.decode(\r\n--> 554             [token for token in text_tokens if token < tokenizer.eot])\r\n    555         if len(text.strip()) == 0:  # skip empty text output\r\n    556             return\r\n~/external-libraries/paddlespeech/s2t/models/whisper/tokenizer.py in decode(self, token_ids, **kwargs)\r\n    157             token_ids = ids_list\r\n    158 \r\n--> 159         return self.tokenizer.decode(token_ids, **kwargs)\r\n    160 \r\n    161     def decode_with_timestamps(self, tokens) -> str:\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils_base.py in decode(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\r\n   3156             skip_special_tokens=skip_special_tokens,\r\n   3157             clean_up_tokenization_spaces=clean_up_tokenization_spaces,\r\n-> 3158             **kwargs,\r\n   3159         )\r\n   3160 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py in _decode(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\r\n   1404 \r\n   1405         filtered_tokens = self.convert_ids_to_tokens(\r\n-> 1406             token_ids, skip_special_tokens=skip_special_tokens)\r\n   1407 \r\n   1408         # To avoid mixing byte-level and unicode for byte-level BPT\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py in convert_ids_to_tokens(self, ids, skip_special_tokens)\r\n    837         tokens = []\r\n    838         for index in ids:\r\n--> 839             index = int(index)\r\n    840             if skip_special_tokens and index in self.all_special_ids:\r\n    841                 continue\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\r\n```\r\n\r\n**To Reproduce**\r\n\r\n```py\r\naudio_file = 'audio.wav'\r\nwhisper_executor = paddlespeech.cli.whisper.WhisperExecutor()\r\nresult = whisper_executor(\r\n    model='whisper',\r\n    task='transcribe',\r\n    size='medium',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file=audio_file,\r\n    language='ja',\r\n    device=paddle.get_device())\r\n```\r\n\r\n遇到这个问题时, 被推理的音频都比较长 (比如 100s 音频,  我这手动改了 `self.max_len` 50 秒限制) , 无端猜测可能和音频长度/显存有关｡ 但真正显存不足的时候 cuda 运行库会直接报告显存不足, 所以又感觉不像｡ \r\n\r\n**Environment (please complete the following information):**\r\n - **Baidu AIStudio V100 / A100**\r\n - OS: Ubuntu\r\n - GCC/G++ Version unkonwn\r\n - Python Version 3.7\r\n - PaddlePaddle Version 2.4.0\r\n - Model Version [whisper-large](https://paddlespeech.bj.bcebos.com/whisper/whisper_model_20221122/whisper-large-model.tar.gz) medium, small 也会遇到\r\n - GPU/DRIVER Information Tesla V100-SXM2-32GB/460.32.03, A100 也会遇到\r\n - CUDA/CUDNN Version cuda-10.2/cuDNN Version-8.2\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n@zxcd ",
        "state": "closed",
        "user": "cxumol",
        "closed_by": "zxcd",
        "created_at": "2023-01-10T22:39:30+00:00",
        "updated_at": "2023-01-12T02:23:58+00:00",
        "closed_at": "2023-01-12T02:23:58+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2818,
        "title": "[S2T] Whisper ASR Model excution got ValueError",
        "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n```python-traceback\r\nTraceback (most recent call last)/tmp/ipykernel_2835/486400536.py in <module>\r\n     10     audio_file=audio_file,\r\n     11     language='ja',\r\n---> 12     device=paddle.get_device())\r\n~/external-libraries/paddlespeech/cli/utils.py in _warpper(self, *args, **kwargs)\r\n    326         except Exception:\r\n    327             pass\r\n--> 328         return executor_func(self, *args, **kwargs)\r\n    329 \r\n    330     return _warpper\r\n~/external-libraries/paddlespeech/cli/whisper/infer.py in __call__(self, audio_file, model, lang, task, size, language, sample_rate, config, ckpt_path, decode_method, num_decoding_left_chunks, force_yes, rtf, device)\r\n    482 \r\n    483         self.preprocess(model, audio_file)\r\n--> 484         self.infer(model)\r\n    485         res = self.postprocess()  # Retrieve result of asr.\r\n    486 \r\n<decorator-gen-695> in infer(self, model_type)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in _decorate_function(func, *args, **kwargs)\r\n    373         def _decorate_function(func, *args, **kwargs):\r\n    374             with self:\r\n--> 375                 return func(*args, **kwargs)\r\n    376 \r\n    377         @decorator.decorator\r\n~/external-libraries/paddlespeech/cli/whisper/infer.py in infer(self, model_type)\r\n    293             initial_prompt=cfg.initial_prompt,\r\n    294             condition_on_previous_text=cfg.condition_on_previous_text,\r\n--> 295             no_speech_threshold=cfg.no_speech_threshold)\r\n    296 \r\n    297     def postprocess(self) -> Union[str, os.PathLike]:\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in transcribe(model, mel, resource_path, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\r\n    586 \r\n    587             decode_options[\"prompt\"] = all_tokens[prompt_reset_since:]\r\n--> 588             result: DecodingResult = decode_with_fallback(segment)\r\n    589             tokens = paddle.to_tensor(result.tokens)\r\n    590 \r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in decode_with_fallback(segment)\r\n    518 \r\n    519             options = DecodingOptions(**kwargs, temperature=t)\r\n--> 520             decode_result = model.decode(segment, options, resource_path)\r\n    521 \r\n    522             needs_fallback = False\r\n<decorator-gen-692> in decode(model, mel, options, resource_path)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in _decorate_function(func, *args, **kwargs)\r\n    373         def _decorate_function(func, *args, **kwargs):\r\n    374             with self:\r\n--> 375                 return func(*args, **kwargs)\r\n    376 \r\n    377         @decorator.decorator\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in decode(model, mel, options, resource_path)\r\n   1296         mel = mel.unsqueeze(0)\r\n   1297 \r\n-> 1298     result = DecodingTask(model, options, resource_path).run(mel)\r\n   1299 \r\n   1300     if single:\r\n<decorator-gen-689> in run(self, mel)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in _decorate_function(func, *args, **kwargs)\r\n    373         def _decorate_function(func, *args, **kwargs):\r\n    374             with self:\r\n--> 375                 return func(*args, **kwargs)\r\n    376 \r\n    377         @decorator.decorator\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in run(self, mel)\r\n   1219         # call the main sampling loop\r\n   1220         tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features,\r\n-> 1221                                                                 tokens)\r\n   1222 \r\n   1223         # reshape the tensors to have (batch_size, beam_size) as the first two dimensions\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in _main_loop(self, audio_features, tokens)\r\n   1167                 # expand the tokens tensor with the selected next tokens\r\n   1168                 tokens, completed = self.decoder.update(tokens, logits,\r\n-> 1169                                                         sum_logprobs)\r\n   1170                 if completed or tokens.shape[-1] > self.n_ctx:\r\n   1171                     break\r\n~/external-libraries/paddlespeech/s2t/models/whisper/whipser.py in update(self, tokens, logits, sum_logprobs)\r\n    782 \r\n    783         next_tokens[tokens[:, -1] == self.eot] = self.eot\r\n--> 784         tokens = paddle.concat([tokens, next_tokens[:, None]], axis=-1)\r\n    785 \r\n    786         completed = paddle.all((tokens[:, -1] == self.eot))\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/manipulation.py in concat(x, axis, name)\r\n   1138         if not isinstance(input, Variable):\r\n   1139             input = [t for t in input if t.shape.count(0) == 0]\r\n-> 1140         return _C_ops.concat(input, axis)\r\n   1141 \r\n   1142     if _in_legacy_dygraph():\r\nValueError: (InvalidArgument) The shape of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [5, 3], input[1]'s shape = [5, 1, 51865, 5].\r\n  [Hint: Expected inputs_dims[i].size() == out_dims.size(), but received inputs_dims[i].size():4 != out_dims.size():2.] (at /paddle/paddle/phi/kernels/funcs/concat_funcs.h:55)\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n```py\r\naudio_file = 'audio.wav'\r\nwhisper_executor = paddlespeech.cli.whisper.WhisperExecutor()\r\nresult = whisper_executor(\r\n    model='whisper',\r\n    task='transcribe',\r\n    size='medium',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file=audio_file,\r\n    language='ja',\r\n    device=paddle.get_device())\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n\r\n - **Baidu AIStudio V100 32G**\r\n - OS: Ubuntu\r\n - GCC/G++ Version unkonwn\r\n - Python Version 3.7\r\n - PaddlePaddle Version 2.4.0\r\n - Model Version [whisper-large](https://paddlespeech.bj.bcebos.com/whisper/whisper_model_20221122/whisper-large-model.tar.gz)\r\n - GPU/DRIVER Information Tesla V100-SXM2-32GB/460.32.03\r\n - CUDA/CUDNN Version cuda-10.2/cuDNN Version-8.2\r\n\r\n@zxcd ",
        "state": "closed",
        "user": "cxumol",
        "closed_by": "zxcd",
        "created_at": "2023-01-10T22:18:50+00:00",
        "updated_at": "2023-01-12T02:23:58+00:00",
        "closed_at": "2023-01-12T02:23:58+00:00",
        "comments_count": [
            "zxcd",
            "cxumol",
            "zxcd",
            "cxumol",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2822,
        "title": "[TTS] VISinger/VISinger2",
        "body": "- PaddleSpeech 活跃开发者 @jerryuhoo 基于非官方开源实现 https://github.com/So-Fann/VISinger 为 espent 贡献了 VISinger 模型代码，预处理部分不是自己写的，可以等 DiffSinger 串通整体流程后再开始 VISinger 的**模型**复现\r\n- VISinger2 官方实现已开源：https://github.com/zhangyongmao/VISinger2",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-01-11T03:08:33+00:00",
        "updated_at": "2023-02-27T06:01:11+00:00",
        "closed_at": null,
        "comments_count": [
            "kFoodie"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2826,
        "title": "[TTS] VITS dygraph-to-static、Paddle2ONNX、Paddle-Lite",
        "body": "- [x] dygraph-to-static\r\n- [x] PaddleInference\r\n- [ ] Paddle2ONNX\r\n- [ ] OnnxRuntime Infer\r\n- [x] Paddle-Lite opt (x86、arm)\r\n- [x] Paddle-Lite Infer (x86、arm)",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-01-12T02:52:48+00:00",
        "updated_at": "2023-04-27T12:26:01+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "yt605155624"
        ],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2838
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2837
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2827,
        "title": "[S2T] Whisper transcription cannot choose languages",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n\r\nEven if users specify a language, program will still detect language by itself.\r\n\r\n**To Reproduce**\r\n\r\n```py\r\nimport paddle\r\nfrom paddlespeech.cli.whisper import WhisperExecutor\r\n\r\naudio_file = 'path/to/test.wav' \r\nwhisper_executor = WhisperExecutor()\r\nresult = whisper_executor(\r\n    model='whisper',\r\n    task='transcribe',\r\n    size='tiny',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file=audio_file,\r\n    language='fr',\r\n    device=paddle.get_device())\r\n```\r\n\r\n**Screenshots**\r\n\r\n![image](https://user-images.githubusercontent.com/8279655/211976128-6bd4d272-4189-4a37-bbf6-08c23c090947.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "cxumol",
        "closed_by": "zxcd",
        "created_at": "2023-01-12T04:27:37+00:00",
        "updated_at": "2023-01-12T06:04:11+00:00",
        "closed_at": "2023-01-12T06:04:11+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2835,
        "title": "README.md--Recent Update章节中年份错误",
        "body": "## Others\r\n\r\nRecent Update\r\n\r\n🔥 2022.01.10: Add [code-switch asr CLI and Demos](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_recognition).\r\n👑 2022.01.06: Add [code-switch asr tal_cs recipe](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/tal_cs/asr1/).\r\n🎉 2022.12.02: Add [end-to-end Prosody Prediction pipeline](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/csmsc/tts3_rhy) (including using prosody labels in Acoustic Model).\r\n🎉 2022.11.30: Add [TTS Android Demo](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSAndroid).\r\n\r\n\r\n最新的两个更新应该是2023年才对吧？",
        "state": "closed",
        "user": "zhangfelix",
        "closed_by": "lym0302",
        "created_at": "2023-01-16T09:24:31+00:00",
        "updated_at": "2023-01-17T05:55:20+00:00",
        "closed_at": "2023-01-17T05:55:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2833,
        "title": "paddle:2.4.1-jupyter docker安装报错",
        "body": "我根据官网使用docker安装paddle:2.4.1-jupyter的版本的paddlepaddle后进行paddlespeech的安装\r\npip install paddlespeech安装过程报错找不到gcc，g++，应该是gcc的环境问题，包括还遇到了gcc-mutilib的相关报错\r\n在 conda install gcc gxx后继续进行pip install paddlespeech，报以下图片中错误。\r\n想请教一下 如何在docker paddle:2.4.1-jupyter容器中安装好gcc环境？\r\n\r\n另外：paddle:2.4.1的docker环境是没问题的\r\n\r\n\r\n\r\n  /opt/conda/compiler_compat/ld: cannot find /lib64/libpthread.so.0: No such file or directory\r\n  /opt/conda/compiler_compat/ld: cannot find /usr/lib64/libpthread_nonshared.a: No such file or directory\r\n  collect2: error: ld returned 1 exit status\r\n  error: command 'g++' failed with exit status 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for pyworld\r\n  Running setup.py clean for pyworld\r\n  Building wheel for webrtcvad (setup.py) ... error\r\n\r\n",
        "state": "closed",
        "user": "tone2158",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-14T15:07:40+00:00",
        "updated_at": "2023-05-21T10:48:16+00:00",
        "closed_at": "2023-05-21T10:48:16+00:00",
        "comments_count": [
            "linkec",
            "tone2158",
            "iftaken",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2836,
        "title": "启动paddlespeech server报错Can't find \"hifigan_vctk-zh\" in resource.",
        "body": "使用 aishell3 的 am 想配置用 hifigan_vctk 的voc，但启动报错了，请问是什么原因呢\r\n<img width=\"1725\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12654801/212663948-818e2dff-f401-4894-8f9d-0c5c348fd6ec.png\">\r\n",
        "state": "closed",
        "user": "peiqianggao",
        "closed_by": "peiqianggao",
        "created_at": "2023-01-16T11:06:56+00:00",
        "updated_at": "2023-01-18T03:43:44+00:00",
        "closed_at": "2023-01-18T03:43:44+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2844,
        "title": "[S2T]Using Whisper but an error occured",
        "body": "the code is :\r\n```\r\n  recognizer_whisper = WhisperExecutor()\r\n  result_tmp = recognizer_whisper(model='whisper',\r\n                                  task='transcribe',\r\n                                  size='medium',\r\n                                  sample_rate=16000,\r\n                                  config=None,\r\n                                  ckpt_path=None,\r\n                                  audio_file=audio_file,\r\n                                  # lang='zh',\r\n                                  device='gpu:' + device)\r\n\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"audio_seg_recognition_masr.py\", line 191, in <module>\r\n    run(video_path, audio_path, result_path, config['audio_rcg'])\r\n  File \"audio_seg_recognition_masr.py\", line 132, in run\r\n    result_tmp = recognizer_whisper(model='whisper',\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/cli/whisper/infer.py\", line 484, in __call__\r\n    self.infer(model)\r\n  File \"<decorator-gen-688>\", line 2, in infer\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/cli/whisper/infer.py\", line 280, in infer\r\n    self._outputs[\"result\"] = self.model.transcribe(\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 588, in transcribe\r\n    result: DecodingResult = decode_with_fallback(segment)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 520, in decode_with_fallback\r\n    decode_result = model.decode(segment, options, resource_path)\r\n  File \"<decorator-gen-685>\", line 2, in decode\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 1298, in decode\r\n    result = DecodingTask(model, options, resource_path).run(mel)\r\n  File \"<decorator-gen-682>\", line 2, in run\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 1220, in run\r\n    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features,\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 1168, in _main_loop\r\n    tokens, completed = self.decoder.update(tokens, logits,\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddlespeech/s2t/models/whisper/whipser.py\", line 784, in update\r\n    tokens = paddle.concat([tokens, next_tokens[:, None]], axis=-1)\r\n  File \"/share/program/workspace/miniconda3/envs/news/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 1140, in concat\r\n    return _C_ops.concat(input, axis)\r\nValueError: (InvalidArgument) The shape of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [5, 227], input[1]'s shape = [5, 1, 51865, 5].\r\n  [Hint: Expected inputs_dims[i].size() == out_dims.size(), but received inputs_dims[i].size():4 != out_dims.size():2.] (at /paddle/paddle/phi/kernels/funcs/concat_funcs.h:55)\r\n```\r\n\r\n\r\nI am confused, I just pass in the audio file path, but it raises the dims mismatch error.",
        "state": "closed",
        "user": "Winter-Dry",
        "closed_by": "Winter-Dry",
        "created_at": "2023-01-20T10:22:32+00:00",
        "updated_at": "2023-01-20T10:59:16+00:00",
        "closed_at": "2023-01-20T10:59:16+00:00",
        "comments_count": [
            "zxcd",
            "Winter-Dry"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2845,
        "title": "conformer_talcs 模型无法使用",
        "body": "按照教程，使用命令行：\r\n`\r\npaddlespeech asr --model conformer_talcs --lang zh_en --codeswitch True --input ./ch_zh_mix.wav -v\r\n`\r\n出现提示：\r\n\r\n> paddlespeech.asr: error: argument --model: invalid choice: 'conformer_talcs' (choose from 'conformer_wenetspeech', 'conformer_online_wenetspeech', 'conformer_u2pp_online_wenetspeech', 'conformer_online_multicn', 'conformer_aishell', 'conformer_online_aishell', 'transformer_librispeech', 'deepspeech2online_wenetspeech', 'deepspeech2offline_aishell', 'deepspeech2online_aishell', 'deepspeech2offline_librispeech')\r\n\r\n如果使用python api形式，则提示\r\n\r\n>   File \"F:\\Python\\Python38\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\nTypeError: __call__() got an unexpected keyword argument 'codeswitch'\r\n\r\n运行前已经执行过升级paddlespeech的命令，确保是最新版\r\n`pip install -U paddlespeech`",
        "state": "closed",
        "user": "dsyrock",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-22T04:06:55+00:00",
        "updated_at": "2025-05-06T05:24:31+00:00",
        "closed_at": "2025-05-06T05:24:31+00:00",
        "comments_count": [
            "zxcd",
            "zx9088",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2846,
        "title": "是否有部署ASR和TTS到android 和 IOS上的方案和demo？",
        "body": "## General Question\r\n目前只看到一个TTSAndroid项目，请问是否有其他的比如ios上的 ASR部署方案\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "shen2009fei",
        "closed_by": null,
        "created_at": "2023-01-26T10:29:35+00:00",
        "updated_at": "2023-11-16T05:52:42+00:00",
        "closed_at": null,
        "comments_count": [
            "shen2009fei",
            "zxcd",
            "shen2009fei",
            "zxcd",
            "shen2009fei",
            "zxcd",
            "iftaken",
            "csukuangfj",
            "shen2009fei",
            "csukuangfj",
            "summerHearts",
            "csukuangfj"
        ],
        "labels": [
            "Question",
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2848,
        "title": "TypeError: declarative() got an unexpected keyword argument 'property'",
        "body": "代码：\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\nprint(result)\r\n\r\n环境：\r\nwindows\r\ncuda 11.0 cudnn7\r\npaddlepaddle-gpu 2.3.2\r\npaddlespeech 1.3.0\r\n\r\n报错：\r\n\r\nC:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\python.exe D:/PycharmProjects/Projects/SpeechRecognition/test/main.py\r\nC:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n100%|██████████| 487739/487739 [00:20<00:00, 23841.41it/s]\r\nC:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nW0128 15:06:29.214216 34136 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.0\r\nW0128 15:06:29.221197 34136 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\r\n2023-01-28 15:06:29.211 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\nTraceback (most recent call last):\r\n  File \"D:/PycharmProjects/Projects/SpeechRecognition/test/main.py\", line 3, in <module>\r\n    result = asr(audio_file=\"./data/zh.wav\")\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 489, in __call__\r\n    num_decoding_left_chunks, ckpt_path)\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 199, in _init_from_path\r\n    model_class = self.task_resource.get_model_class(model_name)\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\resource\\resource.py\", line 115, in get_model_class\r\n    ret.append(dynamic_import(import_path))\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\utils\\dynamic_import.py\", line 37, in dynamic_import\r\n    m = importlib.import_module(module_name)\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\__init__.py\", line 14, in <module>\r\n    from .u2 import U2InferModel\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 65, in <module>\r\n    class U2BaseModel(ASRInterface, nn.Layer):\r\n  File \"C:\\Users\\14548\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 611, in U2BaseModel\r\n    @jit.to_static(property=True)\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n\r\nProcess finished with exit code 1\r\n",
        "state": "closed",
        "user": "sweetboxwwy",
        "closed_by": "yt605155624",
        "created_at": "2023-01-28T07:13:00+00:00",
        "updated_at": "2023-02-07T02:25:19+00:00",
        "closed_at": "2023-02-07T02:25:19+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2847,
        "title": "Is there an English model for streaming ASR?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\nI tried changing the `lang` parameter in `streaming_asr_server/conf/ws_conformer_application` from 'zh' to 'en' and got the following error (when trying to run the server example given in the streaming ASR documentation):\r\n\r\n`\r\nAssertionError: Can't find \"conformer_online_wenetspeech-en-16k\" in resource. Model name must be one of ['conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_online_aishell-zh-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2online_aishell-zh-16k']\r\n`\r\n\r\nIs there any way to access English based streaming ASR engines? Do they exist yet? (The chinese engine works pretty well btw)\r\n",
        "state": "closed",
        "user": "adithya-tp",
        "closed_by": "adithya-tp",
        "created_at": "2023-01-28T04:26:53+00:00",
        "updated_at": "2023-08-16T08:26:31+00:00",
        "closed_at": "2023-01-28T23:45:19+00:00",
        "comments_count": [
            "zxcd",
            "litongjava",
            "ScottXiao233"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2849,
        "title": "[speechX] 编译speechX出错：recipe for target 'all' failed",
        "body": "大神们好。我在编译speechX的时候报错：\r\n```\r\nMakefile:154: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n```\r\n请问这个是啥问题啊。\r\n详细的编译LOG在压缩包里：\r\n[nohup_log.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/10526953/nohup_log.zip)\r\n",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "stale[bot]",
        "created_at": "2023-01-28T10:00:41+00:00",
        "updated_at": "2023-05-21T10:48:17+00:00",
        "closed_at": "2023-05-21T10:48:17+00:00",
        "comments_count": [
            "Tian14267",
            "Tian14267",
            "SmileGoat",
            "SmileGoat",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2850,
        "title": "[S2T]语音识别 CLI 英文识别默认配置Bug",
        "body": "develop分支代码\r\n\r\n版本：140aed4b545885cdb9a13117e9d1a009466c44ac\r\n\r\n问题：CLI 快速体验英文存在bug，使用默认配置无法体验，提示模型不存在\r\n\r\n输入命令\r\n```bash\r\nwget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\r\npaddlespeech asr --lang en --input en.wav\r\n```\r\n\r\n报错信息\r\n```text\r\nAssertionError: Can't find \"conformer_u2pp_online_wenetspeech-en-16k\" in resource. Model name must be one of ['conformer_wenetspeech-zh-16k', 'conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_aishell-zh-16k', 'conformer_online_aishell-zh-16k', 'transformer_librispeech-en-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2offline_aishell-zh-16k', 'deepspeech2online_aishell-zh-16k', 'deepspeech2offline_librispeech-en-16k', 'conformer_talcs-codeswitch_zh_en-16k']\r\n```\r\n需要单独指定模型\r\n\r\n",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2023-01-29T06:50:00+00:00",
        "updated_at": "2023-04-16T06:47:55+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "ticaleenlx"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2864
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2856,
        "title": "流式语音合成问题",
        "body": "请问一下，在流式语音合成中是否可以支持更改duration、pitch、energy 这些参数呢\r\n",
        "state": "closed",
        "user": "yyanning",
        "closed_by": "yt605155624",
        "created_at": "2023-01-30T18:18:38+00:00",
        "updated_at": "2023-03-23T07:59:41+00:00",
        "closed_at": "2023-03-01T07:00:59+00:00",
        "comments_count": [
            "yaleimeng",
            "yt605155624",
            "i4never"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2855,
        "title": "流式语音合成遇到的问题",
        "body": "在已经成功打开服务端的情况下，打开客户端的时候遇到了下面这个问题，请问应该怎么解决呢？\r\n[   ERROR] - HTTPConnectionPool(host='127.0.0.1', port=8092): Max retries exceeded with url: /paddlespeech/tts/streaming/samplerate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021E36386EC8>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))\r\n",
        "state": "closed",
        "user": "yyanning",
        "closed_by": "yt605155624",
        "created_at": "2023-01-30T17:12:56+00:00",
        "updated_at": "2023-03-01T07:01:07+00:00",
        "closed_at": "2023-03-01T07:01:07+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2857,
        "title": "ECAPA-TDNN语音克隆问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n尝试用vc2中提供的预训练模型跑了下voice cloning，但音色和参考人音色差异还蛮大呢，请问下，添加参考人音频重训speaker encoder是否会有改善呢；如果重训的话，音频采样率都是16k嘛？\r\n另外，speaker encoder采样率是16k，声码器和合成器采样率是24k，这里采样率不匹配是不影响vc效果的吧\r\n",
        "state": "closed",
        "user": "xiaoyeye1117",
        "closed_by": "yt605155624",
        "created_at": "2023-01-31T06:13:08+00:00",
        "updated_at": "2023-03-21T07:59:36+00:00",
        "closed_at": "2023-03-21T07:59:36+00:00",
        "comments_count": [
            "yt605155624",
            "WhiteFu",
            "yt605155624",
            "xiaoyeye1117"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2858,
        "title": "[TTS][Android Demo]💡Paddle-Lite opt工具进行模型转换报错 -> 自行编译 develop 版本的 Paddle-Lite",
        "body": "在android的TTS中准备使用中英混合的声学模型fastspeech2_mix_static_0.2.0，在用OPT工具将其转换为paddlelite格式的过程中报错：\r\nError: This model is not supported, because 3 ops are not supported on 'arm'. These unsupported ops are: 'round, set_value,   share_data'，更换paddle_lite_opt为最新版本后转换也不成功，请问是ARM架构cpu本身对这三个算子不支持吗，还是说是模型的问题，请教？\r\n",
        "state": "closed",
        "user": "Vincent2Liu",
        "closed_by": "yt605155624",
        "created_at": "2023-01-31T06:51:18+00:00",
        "updated_at": "2023-12-05T07:54:42+00:00",
        "closed_at": "2023-02-07T02:25:08+00:00",
        "comments_count": [
            "Vincent2Liu",
            "yt605155624",
            "Vincent2Liu",
            "Vincent2Liu",
            "Vincent2Liu",
            "yt605155624",
            "Vincent2Liu",
            "Vincent2Liu",
            "yt605155624",
            "dota2015"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2861,
        "title": "result = self.asr(audio_file=wav_file)运行报错，貌似是动态导入报错",
        "body": "  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/asr/infer.py\", line 210, in _init_from_path\r\n    model_class = self.task_resource.get_model_class(model_name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 115, in get_model_class\r\n    ret.append(dynamic_import(import_path))\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/utils/dynamic_import.py\", line 37, in dynamic_import\r\n    m = importlib.import_module(module_name)\r\n  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/__init__.py\", line 14, in <module>\r\n    from .u2 import U2InferModel\r\n  File \"/root/.pycharm_helpers/pydev/_pydev_bundle/pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 65, in <module>\r\n    class U2BaseModel(ASRInterface, nn.Layer):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 611, in U2BaseModel\r\n    @jit.to_static(property=True)\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n",
        "state": "open",
        "user": "chenmingwei00",
        "closed_by": null,
        "created_at": "2023-01-31T12:16:13+00:00",
        "updated_at": "2023-02-01T02:44:18+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2869,
        "title": "关于 VectorExecutor抽取文本特征",
        "body": "# from paddlespeech.cli.vector import VectorExecutor\r\n请问paddlespeech支持同时抽取文本和语音特征吗，类似clip处理图像特征那样，基于双塔模型建立文本和语音的关联，可应用于文本对speech的检索系统",
        "state": "closed",
        "user": "yanchaoguo",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-02T06:25:51+00:00",
        "updated_at": "2023-05-21T10:48:19+00:00",
        "closed_at": "2023-05-21T10:48:19+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2872,
        "title": "请问支持Audio/Text Multimodal吗",
        "body": "PaddleSpeech包含训练好的文本-语音多模态特征提取模型吗",
        "state": "open",
        "user": "yanchaoguo",
        "closed_by": null,
        "created_at": "2023-02-03T09:10:32+00:00",
        "updated_at": "2023-02-09T02:18:16+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "yanchaoguo",
            "iftaken"
        ],
        "labels": [
            "Question",
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2870,
        "title": "avg.sh best exp/deepspeech2/checkpoints 1  时报错  too many indices for array: array is 1-dimensional, but 2 were indexed",
        "body": "![9 VM}BY6QQ{QU$0X_YWN6L](https://user-images.githubusercontent.com/88914706/216286850-4a1cd039-a297-4b38-8628-563ff4af1ce1.png)\r\n\r\n\r\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\r\nFailed in avg ckpt!",
        "state": "closed",
        "user": "2954456878",
        "closed_by": "2954456878",
        "created_at": "2023-02-02T09:35:12+00:00",
        "updated_at": "2023-02-10T01:55:08+00:00",
        "closed_at": "2023-02-10T01:55:08+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2875,
        "title": "dygraph-to-static",
        "body": null,
        "state": "closed",
        "user": "zxcd",
        "closed_by": "zxcd",
        "created_at": "2023-02-06T02:46:49+00:00",
        "updated_at": "2023-02-06T04:42:56+00:00",
        "closed_at": "2023-02-06T04:42:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2873,
        "title": "punc可以导出推理模型以支持C++(如Paddle/FastDeploy或Paddle Inference)部署么？",
        "body": null,
        "state": "closed",
        "user": "hhxdestiny",
        "closed_by": "hhxdestiny",
        "created_at": "2023-02-03T09:40:44+00:00",
        "updated_at": "2023-03-01T08:04:05+00:00",
        "closed_at": "2023-03-01T08:04:05+00:00",
        "comments_count": [
            "zh794390558",
            "hhxdestiny",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "feature request",
            "S2T",
            "Text"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2874,
        "title": "关于缺少paddlespeech_ctcdecoders module",
        "body": "运行asr_server时，提示缺少下列内容\r\nmodule>:45 - paddlespeech_ctcdecoders not installed!\r\n请问，此模块需要去什么位置下载\r\n\r\n",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-04T03:35:11+00:00",
        "updated_at": "2023-05-21T10:48:18+00:00",
        "closed_at": "2023-05-21T10:48:17+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2877,
        "title": "输入越长推理事件越长。",
        "body": "如果使用paddle_inference C++高性能服务器部署，是否同等情况下，推理效率会提高呢\r\n            ",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "CnYiXiaoNaiHe",
        "created_at": "2023-02-06T04:55:22+00:00",
        "updated_at": "2023-02-06T04:55:59+00:00",
        "closed_at": "2023-02-06T04:55:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2876,
        "title": "关于使用英伟达T40(16G)进行ASR推理，处理10s的语音数据，每秒GPU可以推理出5个语音识别结果,超过后推理时间增加，请问这种情况正常吗",
        "body": "主要想了解下这种是实际情况，还是需要进行额外的设置\r\n",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "CnYiXiaoNaiHe",
        "created_at": "2023-02-06T03:11:21+00:00",
        "updated_at": "2023-02-23T13:19:55+00:00",
        "closed_at": "2023-02-23T13:19:55+00:00",
        "comments_count": [
            "zh794390558",
            "CnYiXiaoNaiHe"
        ],
        "labels": [
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2878,
        "title": "[TTS]  使用ERNIE-SAT克隆语音时，No such file or directory: *.TextGrid'",
        "body": "sh: 1: mfa_align: not found\r\ntg_path:  tmp_dir/shang_12352_a75f0b25dd7d6d18b3e60a7c8973819f/shang_12352_a75f0b25dd7d6d18b3e60a7c8973819f/SSB03540307.TextGrid\r\nTraceback (most recent call last):\r\n  File \"/home/shang/python/PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 469, in <module>\r\n    wav_dict = get_wav(\r\n  File \"/home/shang/python/PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 277, in get_wav\r\n    outs = get_mlm_output(\r\n  File \"/home/shang/python/PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 231, in get_mlm_output\r\n    prep_feats_outs = prep_feats(\r\n  File \"/home/shang/python/PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 167, in prep_feats\r\n    with_dur_outs = prep_feats_with_dur(\r\n  File \"/home/shang/python/PaddleSpeech/paddlespeech/t2s/exps/ernie_sat/synthesize_e2e.py\", line 67, in prep_feats_with_dur\r\n    phns_spans_outs = get_phns_spans(\r\n  File \"/home/shang/anaconda3/envs/TTS3.8/lib/python3.8/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 219, in get_phns_spans\r\n    phn, dur, w2p = alignment(\r\n  File \"/home/shang/anaconda3/envs/TTS3.8/lib/python3.8/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 138, in alignment\r\n    phn_dur, word2phns = _readtg(tg_path, lang=lang)\r\n  File \"/home/shang/anaconda3/envs/TTS3.8/lib/python3.8/site-packages/paddlespeech/t2s/exps/ernie_sat/align.py\", line 40, in _readtg\r\n    alignment = textgrid.openTextgrid(tg_path, includeEmptyIntervals=True)\r\n  File \"/home/shang/anaconda3/envs/TTS3.8/lib/python3.8/site-packages/praatio/textgrid.py\", line 72, in openTextgrid\r\n    with io.open(fnFullPath, \"r\", encoding=\"utf-16\") as fd:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tmp_dir/shang_12352_a75f0b25dd7d6d18b3e60a7c8973819f/shang_12352_a75f0b25dd7d6d18b3e60a7c8973819f/SSB03540307.TextGrid'\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu20.04]\r\n - GCC/G++ Version [e.g. 5]\r\n - Python Version [e.g. 3.8]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. 3090-24GB]\r\n - CUDA/CUDNN Version [e.g. cuda-11.6]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "13604099691",
        "closed_by": "yt605155624",
        "created_at": "2023-02-06T05:33:09+00:00",
        "updated_at": "2023-02-06T08:45:59+00:00",
        "closed_at": "2023-02-06T08:45:59+00:00",
        "comments_count": [
            "yt605155624",
            "13604099691",
            "yt605155624",
            "13604099691",
            "13604099691"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2881,
        "title": "音频转文字过程中显存不断增加，最终 out of memory",
        "body": "## General Question\r\n\r\n因为音频文件比较大，所以我是给切分成 20s 一段再进行识别\r\n\r\n```\r\nimport auditok\r\nfrom paddlespeech.cli.text.infer import TextExecutor\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nimport sys\r\nfrom tempfile import NamedTemporaryFile\r\nimport os\r\nfrom pydub import AudioSegment\r\n\r\ndef dot(txt):\r\n    text_punc = TextExecutor()\r\n    result = text_punc(txt)\r\n    return result\r\n\r\n\r\n# split returns a generator of AudioRegion objects\r\n\r\nfor root, dirs, files in os.walk(\".\", topdown=False):\r\n    for name in files:\r\n        if name.endswith('mp3'):\r\n            full_path = os.path.join(root, name)\r\n            print(full_path)\r\n            wav_file = full_path.replace('.mp3', '.wav')\r\n            txt_file = full_path.replace('.mp3', '.txt')\r\n            # convert to wav\r\n            sound = AudioSegment.from_mp3(full_path)\r\n            sound.export(wav_file, format=\"wav\")\r\n\r\n            audio_regions = auditok.split(\r\n                wav_file,\r\n                min_dur=0.2,     # minimum duration of a valid audio event in seconds\r\n                max_dur=20,       # maximum duration of an event\r\n                max_silence=10,  # maximum duration of tolerated continuous silence within an event\r\n                energy_threshold=55  # threshold of detection\r\n            )\r\n\r\n            with open(txt_file, 'w') as t:\r\n\r\n                for i, r in enumerate(audio_regions):\r\n                    with NamedTemporaryFile(suffix='.wav') as f:\r\n                        r.save(f.name)\r\n                        asr = ASRExecutor()\r\n                        raw_result = asr(audio_file=f.name, force_yes=True)\r\n                        t.write(dot(raw_result))\r\n\r\n```\r\n识别过程中随着一个个音频分片的解析，眼瞅着 GPU 不断增长，从几百兆增加到 8G 最终 out of memory\r\n\r\n试了 FLAGS_use_cuda_managed_memory 改为 true 和 false 都不行\r\n\r\nCUDA 版本 11.2\r\n\r\n```\r\nW0206 08:26:41.720482 13625 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.2\r\nW0206 08:26:41.722322 13625 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n\r\npaddlepaddle-gpu         2.4.1.post112 \r\n```\r\n\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "sunzhaoyang",
        "closed_by": "sunzhaoyang",
        "created_at": "2023-02-06T08:33:27+00:00",
        "updated_at": "2023-09-19T08:32:40+00:00",
        "closed_at": "2023-02-28T11:46:40+00:00",
        "comments_count": [
            "yt605155624",
            "coderLinJ5945"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2889,
        "title": "[TTS]tts_finetune/tts3/  用自己数据集finetune的时候遇到以下错误",
        "body": "(TTS3.7) shang@USER-20221125QS:~/python/PaddleSpeech/examples/other/tts_finetune/tts3$ ./run.sh\r\ncheck oov\r\nget mfa result\r\nCMD:  mfa_align ./input/lu/newdir tools/aligner/simple.lexicon tools/aligner/aishell3_model.zip ./mfa_result\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nSetting up corpus information...\r\nTraceback (most recent call last):\r\n  File \"aligner/command_line/align.py\", line 186, in <module>\r\n  File \"aligner/command_line/align.py\", line 142, in validate_args\r\n  File \"aligner/command_line/align.py\", line 85, in align_corpus\r\n  File \"aligner/corpus.py\", line 543, in speaker_utterance_info\r\nZeroDivisionError: division by zero\r\n[11923] Failed to execute script align\r\n\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 5]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.4]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. RTX3090-24GB]\r\n - CUDA/CUDNN Version [e.g. cuda-11.6]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "13604099691",
        "closed_by": "yt605155624",
        "created_at": "2023-02-07T05:06:06+00:00",
        "updated_at": "2023-03-02T09:21:07+00:00",
        "closed_at": "2023-03-02T09:21:07+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2885,
        "title": "💡[S2T]ERROR: No matching distribution found for paddlespeech_ctcdecoders",
        "body": "If your system is Linux, you can install paddlespeech_ctcdecoders through pip\r\nIf your system is Windows, you should bulid paddlespeech_ctcdecoders by yourself, see\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2167",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-02-07T02:29:50+00:00",
        "updated_at": "2024-07-16T08:35:14+00:00",
        "closed_at": null,
        "comments_count": [
            "zqkou"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2890,
        "title": "【ASR】1分钟多通道wav文件转写文本内容不正确",
        "body": "1分钟多通道wav文件转写文本内容不正确。\r\n使用librosa先to_mono再resample读音频转写文本内容正确。初步测试是下面代码转换有精度损失导致转写不正确\r\n     audio, audio_sample_rate = soundfile.read(audio_file, dtype=\"int16\", always_2d=True)\r\n     if self.change_format:\r\n                if audio.shape[1] >= 2:\r\n                    audio = audio.mean(axis=1, dtype=np.int16)\r\n                else:\r\n                    audio = audio[:, 0]\r\n                # pcm16 -> pcm 32\r\n                audio = self._pcm16to32(audio)\r\n                audio = librosa.resample(\r\n                    audio,\r\n                    orig_sr=audio_sample_rate,\r\n                    target_sr=self.sample_rate)\r\n                audio_sample_rate = self.sample_rate\r\n                # pcm32 -> pcm 16\r\n                audio = self._pcm32to16(audio)",
        "state": "open",
        "user": "git3210",
        "closed_by": null,
        "created_at": "2023-02-07T06:22:28+00:00",
        "updated_at": "2023-02-07T08:04:42+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2888,
        "title": "ASRExecutor音频转汉字，含有部分英文，哪个model的效果最好？",
        "body": "场景是给留学生辅导，主要语言中文，含有少量英文词汇，目前默认设置转换出来的效果\r\n```\r\n好的朋友们早上好呀来我给咱们共享一些屏幕好来那我们还是常规的来恰克一下能不能听到我说话呢\r\n听到不能听到了咱们来个莫莉啊六六六都可以好的来拆可一下啊行\r\n能听到吗诶能听到是吧好好我看你们没敲字我以为你们听不到好那我们来说一下今天咱们要干什么吧好吧那有些人如果说没有看上一节的课的话呢他可能有些差异说为什么杰森一\r\n是直接打开了上节课的这个P皮器对吧好那我们今天因为上节课咱们留下来了一些遗留的问题对不对咱们上节课讲到了这个非的和普克的时候呢咱们就看了咱们说等到下节课的时候咱们来一起讲对不对\r\n所以今天咱们要干的事的是咱们先把尚节课剩下的这些因用那发的知识讲完那咱们把这些新知识讲完之后再去讲一下这个拆文注理克的克特森陪神好好那么由于我之前也说了这个拆文注贝克的特\r\n黑意思呢其实咱们写这两个小时但其实是他怎么说呢如果说它是一个喷心动斯克的话他值得两个小时你知道吗但是由于你们现在是一个陪审了那么无论说从你们个人的帕斯科的这个\r\n啊\r\n怎么说个人帕斯克的这个难艺程度上还是说你们准备这个帕斯克所需要的时间都比以前简单得多了你知道吧都比以前的这个门槛要低得多了所以呢就是说咱们也不需要那么长的时间来去讲你们的这个\r\n```\r\n感觉效果一般，需要自己训练吗？",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2023-02-07T03:01:04+00:00",
        "updated_at": "2023-02-10T10:00:20+00:00",
        "closed_at": "2023-02-10T10:00:20+00:00",
        "comments_count": [
            "zxcd",
            "zouhan6806504",
            "zxcd",
            "zouhan6806504",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2893,
        "title": "docker安装后，直接执行demo提示错误，执行失败",
        "body": "## General Question\r\n\r\n<!--\r\n安装方式：docker\r\n操作方式：安装后直接执行命令/home/PaddleSpeech/demos/speech_recognition：paddlespeech asr --lang zh --input zh.wav或执行sh run.sh\r\n提示报错：zipfile.BadZipFile: File is not a zip file\r\n![demofail](https://user-images.githubusercontent.com/57940617/217457401-f4555338-eb79-4b07-954f-69c3fde7f590.png)\r\n\r\n-->\r\n",
        "state": "closed",
        "user": "panli841",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-08T07:01:08+00:00",
        "updated_at": "2023-05-20T16:19:47+00:00",
        "closed_at": "2023-05-20T16:19:47+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2891,
        "title": "使用attention_rescoring模式测试自己训练的模型时报错",
        "body": "出错的信息：\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/test.py\", line 61, in <module>\r\n    pr.runcall(main, config, args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/cProfile.py\", line 121, in runcall\r\n    return func(*args, **kw)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/test.py\", line 32, in main\r\n    main_sp(config, args)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/test.py\", line 28, in main_sp\r\n    exp.run_test()\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 361, in run_test\r\n    self.test()\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/utils/mp_tools.py\", line 27, in wrapper\r\n    result = func(*args, **kwargs)\r\n  File \"<decorator-gen-532>\", line 2, in test\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/exps/u2/model.py\", line 401, in test\r\n    metrics = self.compute_metrics(*batch, fout=fout)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/exps/u2/model.py\", line 355, in compute_metrics\r\n    reverse_weight=reverse_weight)\r\n  File \"<decorator-gen-524>\", line 2, in decode\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 826, in decode\r\n    reverse_weight=reverse_weight)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 536, in attention_rescoring\r\n    assert hasattr(self.decoder, 'right_decoder')\r\nAssertionError\r\nFailed in evaluation!\r\n\r\n使用的是配置如下：\r\nconf_path=conf/chunk_conformer.yaml\r\ndecode_conf_path=conf/tuning/chunk_decode.yaml\r\n\r\nchunk_conformer.yaml的内容：\r\n############################################\r\n#           Network Architecture           #\r\n############################################\r\ncmvn_file: \r\ncmvn_file_type: \"json\"\r\n# encoder related\r\nencoder: conformer\r\nencoder_conf:\r\n    output_size: 256    # dimension of attention\r\n    attention_heads: 4\r\n    linear_units: 2048  # the number of units of position-wise feed forward\r\n    num_blocks: 12      # the number of encoder blocks\r\n    dropout_rate: 0.1   # sublayer output dropout\r\n    positional_dropout_rate: 0.1\r\n    attention_dropout_rate: 0.0\r\n    input_layer: conv2d # encoder input type, you can chose conv2d, conv2d6 and conv2d8\r\n    normalize_before: True\r\n    cnn_module_kernel: 15\r\n    use_cnn_module: True\r\n    activation_type: 'swish'\r\n    pos_enc_layer_type: 'rel_pos'\r\n    selfattention_layer_type: 'rel_selfattn'\r\n    causal: true\r\n    use_dynamic_chunk: true\r\n    cnn_module_norm: 'layer_norm' # using nn.LayerNorm makes model converge faster\r\n    use_dynamic_left_chunk: false\r\n# decoder related\r\ndecoder: transformer\r\ndecoder_conf:\r\n    attention_heads: 4\r\n    linear_units: 2048\r\n    num_blocks: 6\r\n    dropout_rate: 0.1  # sublayer output dropout\r\n    positional_dropout_rate: 0.1\r\n    self_attention_dropout_rate: 0.0\r\n    src_attention_dropout_rate: 0.0\r\n# hybrid CTC/attention\r\nmodel_conf:\r\n    ctc_weight: 0.3\r\n    lsm_weight: 0.1     # label smoothing option\r\n    length_normalized_loss: false\r\n    init_type: 'kaiming_uniform' # !Warning: need to convergence\r\n\r\n###########################################\r\n#                   Data                  #\r\n###########################################\r\n\r\ntrain_manifest: data/manifest.train\r\ndev_manifest: data/manifest.dev\r\ntest_manifest: data/manifest.test\r\n\r\n\r\n###########################################\r\n#              Dataloader                 #\r\n###########################################\r\n\r\nvocab_filepath: data/lang_char/vocab.txt \r\nspm_model_prefix: ''\r\nunit_type: 'char'\r\npreprocess_config: conf/preprocess.yaml\r\nfeat_dim: 80\r\nstride_ms: 10.0\r\nwindow_ms: 25.0\r\nsortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs \r\nbatch_size: 32\r\nmaxlen_in: 512  # if input length  > maxlen-in, batchsize is automatically reduced\r\nmaxlen_out: 150  # if output length > maxlen-out, batchsize is automatically reduced\r\nminibatches: 0 # for debug\r\nbatch_count: auto\r\nbatch_bins: 0\r\nbatch_frames_in: 0\r\nbatch_frames_out: 0\r\nbatch_frames_inout: 0\r\nnum_workers: 2\r\nsubsampling_factor: 1\r\nnum_encs: 1\r\n\r\n###########################################\r\n#                 Training                #\r\n###########################################\r\nn_epoch: 240 \r\naccum_grad: 24\r\nglobal_grad_clip: 5.0\r\ndist_sampler: True\r\noptim: adam\r\noptim_conf:\r\n  lr: 0.001\r\n  weight_decay: 1.0e-6\r\nscheduler: warmuplr\r\nscheduler_conf:\r\n  warmup_steps: 25000\r\n  lr_decay: 1.0\r\nlog_interval: 100\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\n\r\n使用的chunk_decode.yaml内容如下：\r\nbeam_size: 10\r\ndecoding_method: attention # 'attention', 'ctc_greedy_search', 'ctc_prefix_beam_search', 'attention_rescoring'\r\nctc_weight: 0.5 # ctc weight for attention rescoring decode mode.\r\nreverse_weight: 0.3 # reverse weight for attention rescoring decode mode.\r\ndecoding_chunk_size: 16 # decoding chunk size. Defaults to -1.\r\n    # <0: for decoding, use full chunk.\r\n    # >0: for decoding, use fixed chunk size as set.\r\n    # 0: used for training, it's prohibited here. \r\nnum_decoding_left_chunks: -1  # number of left chunks for decoding. Defaults to -1.\r\nsimulate_streaming: True  # simulate streaming inference. Defaults to False.\r\ndecode_batch_size: 128\r\nerror_rate_type: cer \r\n\r\n",
        "state": "closed",
        "user": "upcmb",
        "closed_by": "upcmb",
        "created_at": "2023-02-07T08:43:25+00:00",
        "updated_at": "2023-02-08T09:23:38+00:00",
        "closed_at": "2023-02-08T09:23:38+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2894,
        "title": "请问一下asr如果长时间调用会对环境造成影响需要重启吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->我采用kafka消息队列来进行多线程去调用asr（gpu）,我在我的环境中一次性启动了三个asr的线程来给kafka使用，我发现多次，我每周需要把所有asr全部重启一下后，识别语音速度才会正常不然会卡住很久或者识别语音莫名其妙丢失了比如我使用 auditok切分一个长语音为500条后识别完传给下一个接口后可能会变为499,498条。请问这个是我们环境网络问题还是asr长时间使用后会对环境造成影响需要定时重启。\r\n",
        "state": "closed",
        "user": "xuhongtian",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-08T07:17:53+00:00",
        "updated_at": "2025-06-27T03:38:18+00:00",
        "closed_at": "2025-06-27T03:38:18+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "great-wind",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2895,
        "title": "[TTS]💡关于中英文混合 TTS 中数字的读法问题",
        "body": "PaddleSpeech 已经开源了中英文混合 TTS\r\n\r\nCLI 和 Python API 一句话调用\r\n- https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/text_to_speech\r\n\r\n数据预处理、训练、合成、推理全流程\r\n- https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/zh_en_tts/tts3\r\n\r\n关于中英文混合 TTS 中数字的读法问题，请注意：\r\n\r\n1. 目前中英文本前端**数字跟着前面临近的字词的语言**，如果数字前面是中文那就按照中文的规则，数字前面是英文就按照英文的读法\r\n2. 如果想把英文后面的数字改成中文读法，可以：\r\n    - 手动将英文变为中文接近的字，用纯中文模型\r\n    - 将数字改成汉字，用中英混合模型\r\n\r\nps. 如果有更好的中英文混合 TTS 前端设计方案，欢迎讨论和提交 pr\r\n\r\n\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-02-08T07:38:33+00:00",
        "updated_at": "2023-02-08T07:42:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2901,
        "title": "执行paddlespeech help 报错",
        "body": "![image](https://user-images.githubusercontent.com/88914706/217702662-cbd368d1-f333-47a0-9aaa-9a1d24622d9e.png)",
        "state": "closed",
        "user": "2954456878",
        "closed_by": "2954456878",
        "created_at": "2023-02-09T02:33:01+00:00",
        "updated_at": "2023-02-09T02:47:13+00:00",
        "closed_at": "2023-02-09T02:47:01+00:00",
        "comments_count": [
            "zxcd",
            "2954456878",
            "zxcd",
            "2954456878"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2897,
        "title": "[ASR] 💡关于ASR语音输入时长范围问题",
        "body": "目前对于ASR输入的语音，部分模型结构会对语音最大长度有所限制，具体如下表：\r\n\r\n| Model Type | 单个音频最大处理时长 |\r\n| :--- | :---: | \r\n| DeepSpeech | 无限制 |\r\n| Conformer  | 50s |\r\n| Wav2vec2 | 与预训练模型有关 |\r\n| Whisper | 无限制 |\r\n\r\n对于过长的语音建议使用vad工具进行语音切分后再进行识别",
        "state": "open",
        "user": "zxcd",
        "closed_by": null,
        "created_at": "2023-02-08T07:51:44+00:00",
        "updated_at": "2025-03-02T14:55:30+00:00",
        "closed_at": null,
        "comments_count": [
            "fuxiaoiii"
        ],
        "labels": [
            "S2T",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2898,
        "title": "[TTS]报错 Killed",
        "body": "环境：\r\npython 3.7.13\r\nPaddlePaddle 2.4.1\r\ngcc version 8.2.0\r\n\r\n以下是版本信息：\r\n```\r\nλ 4d007693f246 /paddle/PaddleSpeech python -V\r\nPython 3.7.13\r\n\r\nλ 4d007693f246 /paddle/PaddleSpeech paddle\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nPaddlePaddle 2.4.1, compiled with\r\n    with_avx: ON\r\n    with_gpu: OFF\r\n    with_mkl: ON\r\n    with_mkldnn: ON\r\n    with_python: ON\r\n\r\nλ 4d007693f246 /paddle/PaddleSpeech gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/local/gcc-8.2/libexec/gcc/x86_64-pc-linux-gnu/8.2.0/lto-wrapper\r\nTarget: x86_64-pc-linux-gnu\r\nConfigured with: ../gcc-8.2.0/configure --prefix=/usr/local/gcc-8.2 --enable-threads=posix --disable-checking --disable-multilib\r\nThread model: posix\r\ngcc version 8.2.0 (GCC)\r\n```\r\n\r\n语音识别可以正常使用\r\n```\r\nλ 4d007693f246 /paddle/PaddleSpeech paddlespeech asr --lang zh --input zh.wav\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/math_op_patch.py:277: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64\r\n  .format(lhs_dtype, rhs_dtype, lhs_dtype))\r\n我认为跑步最重要的就是给我带来了身体健康\r\n```\r\n\r\n## 语音合并报错\r\n```\r\nλ 4d007693f246 /paddle/PaddleSpeech paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2023-02-08 09:22:51] [DEBUG] [retry.py:351] Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=None, status=None)\r\n[2023-02-08 09:22:51] [DEBUG] [retry.py:351] Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=None, status=None)\r\n[2023-02-08 09:22:51] [DEBUG] [connectionpool.py:232] Starting new HTTP connection (1): paddlepaddle.org.cn:80\r\n[2023-02-08 09:22:51,477] [   DEBUG] - File /root/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4.zip md5 checking...\r\n[2023-02-08 09:22:51] [DEBUG] [connectionpool.py:465] http://paddlepaddle.org.cn:80 \"GET /paddlehub/stat?task=tts&version=0.0.0&from=ppspeech&model=fastspeech2_csmsc&extra=%7B%22paddle_version%22%3A+%222.4.1%22%2C+%22lang%22%3A+%22zh%22%2C+%22vocoder%22%3A+%22hifigan_csmsc%22%2C+%22cache_info%22%3A+%221e698915b313efe46c239944b3ec9f13-1675842853%22%7D HTTP/1.1\" 301 186\r\n[2023-02-08 09:22:51] [DEBUG] [connectionpool.py:1007] Starting new HTTPS connection (1): paddlepaddle.org.cn:443\r\n[2023-02-08 09:22:51] [DEBUG] [connectionpool.py:465] https://paddlepaddle.org.cn:443 \"GET /paddlehub/stat?task=tts&version=0.0.0&from=ppspeech&model=fastspeech2_csmsc&extra=%7B%22paddle_version%22%3A+%222.4.1%22%2C+%22lang%22%3A+%22zh%22%2C+%22vocoder%22%3A+%22hifigan_csmsc%22%2C+%22cache_info%22%3A+%221e698915b313efe46c239944b3ec9f13-1675842853%22%7D HTTP/1.1\" 200 13\r\n[2023-02-08 09:22:52,865] [   DEBUG] - /root/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4\r\n[2023-02-08 09:22:52,865] [   DEBUG] - /root/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\n[2023-02-08 09:22:52,866] [   DEBUG] - /root/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz\r\n[2023-02-08 09:22:52,867] [   DEBUG] - File /root/.paddlespeech/models/hifigan_csmsc-zh/1.0/hifigan_csmsc_ckpt_0.1.1.zip md5 checking...\r\n[2023-02-08 09:22:55,460] [   DEBUG] - /root/.paddlespeech/models/hifigan_csmsc-zh/1.0/hifigan_csmsc_ckpt_0.1.1\r\n[2023-02-08 09:22:55,460] [   DEBUG] - /root/.paddlespeech/models/hifigan_csmsc-zh/1.0/hifigan_csmsc_ckpt_0.1.1/default.yaml\r\n[2023-02-08 09:22:55,460] [   DEBUG] - /root/.paddlespeech/models/hifigan_csmsc-zh/1.0/hifigan_csmsc_ckpt_0.1.1/snapshot_iter_2500000.pdz\r\n[2023-02-08 09:22:56,918] [   DEBUG] - File /root/.paddlespeech/models/G2PWModel_1.1.zip md5 checking...\r\n[2023-02-08 09:23:00,512] [    INFO] - Already cached /root/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-02-08 09:23:00,560] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-02-08 09:23:00,561] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\nKilled\r\n```",
        "state": "closed",
        "user": "nanfeng",
        "closed_by": "nanfeng",
        "created_at": "2023-02-08T08:31:29+00:00",
        "updated_at": "2023-02-08T12:04:13+00:00",
        "closed_at": "2023-02-08T12:04:13+00:00",
        "comments_count": [
            "yt605155624",
            "nanfeng",
            "yt605155624",
            "nanfeng"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2903,
        "title": "ASR训练u2++模型的时候报错",
        "body": "感觉把manifest.train里面的内容作为路径去读取了....\r\n\r\n**错误详情**\r\n2023-02-09 11:36:33.600 | INFO     | paddlespeech.s2t.training.trainer:resume_or_scratch:221 - Init from scratch!\r\n2023-02-09 11:36:37.840 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:286 - Saved model to exp/chunk_conformer_u2pp/checkpoints/init.pdparams\r\n2023-02-09 11:36:37.841 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:292 - Saved optimzier state to exp/chunk_conformer_u2pp/checkpoints/init.pdopt\r\n[2023-02-09 11:36:38,409] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:0\r\n[2023-02-09 11:36:38,410] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:1\r\n[2023-02-09 11:36:38,410] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:3\r\n[2023-02-09 11:36:38,410] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:2\r\n[2023-02-09 11:36:38,410] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:4\r\n[2023-02-09 11:36:38,411] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:5\r\n[2023-02-09 11:36:38,411] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:6\r\n[2023-02-09 11:36:38,411] [    INFO] - paddlespeech.audio.streamdata.shardlists | num_workers:8, worker:7\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 536, in _thread_loop\r\n    batch = self._get_data()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 674, in _get_data\r\n    batch.reraise()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 172, in reraise\r\n    raise self.exc_type(msg)\r\nFileNotFoundError: DataLoader worker(5) caught FileNotFoundError with message:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 339, in _worker_loop\r\n    batch = fetcher.fetch(indices)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 107, in fetch\r\n    data = next(self.dataset_iter)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/pipeline.py\", line 67, in iterator\r\n    for sample in self.iterator1():\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 990, in _audio_cmvn\r\n    for batch in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 962, in _audio_padding\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 912, in _batched\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 885, in _sort\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 218, in _shuffle\r\n    for sample in data:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 847, in _audio_spec_aug\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 791, in _audio_compute_fbank\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 756, in _audio_resample\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 653, in _audio_data_filter\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/filters.py\", line 706, in _audio_tokenize\r\n    for sample in source:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/tariterators.py\", line 221, in tar_file_and_group_expander\r\n    for source in data:\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/tariterators.py\", line 79, in url_opener\r\n    if handler(exn):\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/handlers.py\", line 22, in reraise_exception\r\n    raise exn\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/tariterators.py\", line 74, in url_opener\r\n    stream = gopen.gopen(url, **kw)\r\n  File \"/home/aistudio/work/PaddleSpeech/paddlespeech/audio/streamdata/gopen.py\", line 315, in gopen\r\n    return open(url, mode, buffering=bufsize)\r\nFileNotFoundError: [Errno 2] No such file or directory: '{\"input\": [{\"name\": \"input1\", \"shape\": [1.28, 80], \"feat\": \"/home/aistudio/work/PaddleSpeech/dataset/tal_cs/TALCS_corpus/train_set/wav/308c413eea021d9f4c12bd2f910be944.wav\", \"filetype\": \"sound\"}], \"output\": [{\"name\": \"target1\", \"shape\": [1, 29], \"text\": \"o\", \"token\": \"o\", \"tokenid\": \"16\"}], \"utt\": \"308c413eea021d9f4c12bd2f910be944\", \"utt2spk\": \"308c413eea021d9f4c12bd2f910be944\"}'\r\n**配置：chunk_conformer_u2pp.yaml**\r\n############################################\r\n#           Network Architecture           #\r\n############################################\r\ncmvn_file: \"data/mean_std.json\"\r\ncmvn_file_type: \"json\"\r\n# encoder related\r\nencoder: conformer\r\nencoder_conf:\r\n    output_size: 512    # dimension of attention\r\n    attention_heads: 8\r\n    linear_units: 2048  # the number of units of position-wise feed forward\r\n    num_blocks: 12      # the number of encoder blocks\r\n    dropout_rate: 0.1\r\n    positional_dropout_rate: 0.1\r\n    attention_dropout_rate: 0.1\r\n    input_layer: conv2d # encoder input type, you can chose conv2d, conv2d6 and conv2d8\r\n    normalize_before: True\r\n    use_cnn_module: True\r\n    cnn_module_kernel: 15\r\n    activation_type: swish\r\n    pos_enc_layer_type: rel_pos\r\n    selfattention_layer_type: rel_selfattn\r\n    causal: true\r\n    use_dynamic_chunk: true\r\n    cnn_module_norm: 'layer_norm' # using nn.LayerNorm makes model converge faster\r\n    use_dynamic_left_chunk: false\r\n# decoder related\r\ndecoder: bitransformer\r\ndecoder_conf:\r\n    attention_heads: 8\r\n    linear_units: 2048\r\n    num_blocks: 3     # the number of encoder blocks\r\n    r_num_blocks: 3   #only for bitransformer\r\n    dropout_rate: 0.1\r\n    positional_dropout_rate: 0.1\r\n    self_attention_dropout_rate: 0.1\r\n    src_attention_dropout_rate: 0.1\r\n\r\n# hybrid CTC/attention\r\nmodel_conf:\r\n    ctc_weight: 0.3\r\n    lsm_weight: 0.1     # label smoothing option\r\n    length_normalized_loss: false\r\n    reverse_weight: 0.3    # only for bitransformer decoder\r\n    init_type: 'kaiming_uniform' # !Warning: need to convergence\r\n\r\n###########################################\r\n#                   Data                  #\r\n###########################################\r\ntrain_manifest: data/manifest.train\r\ndev_manifest: data/manifest.dev\r\ntest_manifest: data/manifest.test\r\n\r\n###########################################\r\n#              Dataloader                 #\r\n###########################################\r\nuse_stream_data: True\r\nvocab_filepath: data/lang_char/vocab.txt \r\nunit_type: 'char'\r\npreprocess_config: conf/preprocess.yaml\r\nspm_model_prefix: ''\r\nfeat_dim: 80\r\nstride_ms: 10.0\r\nwindow_ms: 25.0\r\nsortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs \r\nbatch_size: 32\r\ndo_filter: True\r\ndither: 0.1\r\nresample_rate: 16000\r\nmaxlen_in: 1200  # if do_filter == False && input length  > maxlen-in, batchsize is automatically reduced\r\nmaxlen_out: 100  # if do_filter == False && output length > maxlen-out, batchsize is automatically reduced\r\nminlen_in: 10\r\nminlen_out: 0\r\nminibatches: 0 # for debug\r\nbatch_count: auto\r\nbatch_bins: 0 \r\nbatch_frames_in: 0\r\nbatch_frames_out: 0\r\nbatch_frames_inout: 0\r\nsubsampling_factor: 1\r\nnum_encs: 1\r\nshuffle_size: 1500 # read number of 'shuffle_size' data as a chunk, shuffle the data in the chunk\r\nsort_size: 1000  # read number of 'sort_size' data as a chunk, sort the data in the chunk \r\nnum_workers: 8\r\nprefetch_factor: 10\r\n\r\n###########################################\r\n#                 Training                #\r\n###########################################\r\nn_epoch: 150 \r\naccum_grad: 8\r\nglobal_grad_clip: 5.0\r\ndist_sampler: False\r\noptim: adam\r\noptim_conf:\r\n  lr: 0.002\r\n  weight_decay: 1.0e-6\r\nscheduler: warmuplr\r\nscheduler_conf:\r\n  warmup_steps: 25000\r\n  lr_decay: 1.0\r\nlog_interval: 100\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\n**chunk_decode.yaml 配置**\r\nbeam_size: 10\r\ndecoding_method: attention # 'attention', 'ctc_greedy_search', 'ctc_prefix_beam_search', 'attention_rescoring'\r\nctc_weight: 0.5 # ctc weight for attention rescoring decode mode.\r\nreverse_weight: 0.3 # reverse weight for attention rescoring decode mode.\r\ndecoding_chunk_size: 16 # decoding chunk size. Defaults to -1.\r\n    # <0: for decoding, use full chunk.\r\n    # >0: for decoding, use fixed chunk size as set.\r\n    # 0: used for training, it's prohibited here. \r\nnum_decoding_left_chunks: -1  # number of left chunks for decoding. Defaults to -1.\r\nsimulate_streaming: True  # simulate streaming inference. Defaults to False.\r\ndecode_batch_size: 128\r\nerror_rate_type: cer \r\n",
        "state": "open",
        "user": "upcmb",
        "closed_by": null,
        "created_at": "2023-02-09T05:06:37+00:00",
        "updated_at": "2023-05-20T16:19:26+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "upcmb",
            "zxcd",
            "upcmb",
            "zxcd",
            "upcmb",
            "zxcd",
            "upcmb",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2904,
        "title": "使用websocket_client.py 出现 keepalive timeout，中断传输",
        "body": "在哪里能修改这个时长呢\r\n![image](https://user-images.githubusercontent.com/88914706/217798468-3f1176a7-f6be-49f4-ab66-3a7a79a00274.png)",
        "state": "closed",
        "user": "2954456878",
        "closed_by": "2954456878",
        "created_at": "2023-02-09T11:19:31+00:00",
        "updated_at": "2023-02-13T05:58:23+00:00",
        "closed_at": "2023-02-13T05:58:23+00:00",
        "comments_count": [
            "yt605155624",
            "2954456878",
            "2954456878"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2906,
        "title": "请问一下用自己的数据对声音分类模型进行微调，是要求数据一样长度嘛？或者对数据最长长度有要求嘛，大概是几秒到几秒之间合适呢？",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "shumeirao",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-10T03:22:13+00:00",
        "updated_at": "2023-05-20T16:19:44+00:00",
        "closed_at": "2023-05-20T16:19:44+00:00",
        "comments_count": [
            "zxcd",
            "shumeirao",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2905,
        "title": "[Install] gpu版本安装成功，运行报错",
        "body": "\r\ngpu：4080（公版）\r\ncuda版本：12.0\r\n具体如下：\r\nThu Feb  9 22:03:30 2023       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA GeForce ...  Off  | 00000000:83:00.0 Off |                  N/A |\r\n| 30%   26C    P0    32W / 320W |      0MiB / 16376MiB |      1%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2022 NVIDIA Corporation\r\nBuilt on Mon_Oct_24_19:12:58_PDT_2022\r\nCuda compilation tools, release 12.0, V12.0.76\r\nBuild cuda_12.0.r12.0/compiler.31968024_0\r\n\r\n#define CUDNN_MAJOR 8\r\n#define CUDNN_MINOR 8\r\n#define CUDNN_PATCHLEVEL 0\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n\r\n/* cannot use constexpr here since this is a C-only file */\r\n\r\n\r\npaddlepaddle                   2.4.1\r\npaddlespeech                   1.0.1\r\n\r\n\r\n运行后报如下错误：\r\nError: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/home/yeapllg/video/test.py\", line 72, in <module>\r\n    from paddlespeech.cli.tts.infer import TTSExecutor\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\r\n    import paddle\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/framework.py\", line 37, in <module>\r\n    from . import core\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/core.py\", line 304, in <module>\r\n    raise e\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/core.py\", line 249, in <module>\r\n    from . import libpaddle\r\nImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory\r\n\r\n提示libcudart.so.10.2这包没有\r\n\r\n经过检查发现，cuda12.0版本的libcudart.so包版本为libcudart.so.12,\r\n\r\nroot@ubuntu:/home/yeapllg/video# ls /usr/local/cuda/lib64/libcudart*\r\n/usr/local/cuda/lib64/libcudart.so  /usr/local/cuda/lib64/libcudart.so.12  /usr/local/cuda/lib64/libcudart.so.12.0.107  /usr/local/cuda/lib64/libcudart_static.a\r\n\r\n",
        "state": "closed",
        "user": "yeapllg",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-09T14:16:30+00:00",
        "updated_at": "2025-06-27T04:33:59+00:00",
        "closed_at": "2025-06-27T04:33:59+00:00",
        "comments_count": [
            "yt605155624",
            "yaleimeng",
            "stale[bot]",
            "angiewlz",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2908,
        "title": "[TTS]使用gpu合成后显存未释放",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n我使用https://zhuanlan.zhihu.com/p/587765776中的代码块在anaconda的命令行窗口进行合成，windows11，gpu是rtx3050移动端，4g显存，发现每次运行完保存完文件之后显存一直维持在近满的状态，直到关闭窗口重进或退出python环境后重置。\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.打开anaconda，进入虚拟环境，python版本3.8.16\r\n2. 运行更改了待合成文本的代码块\r\n3. 第一次合成正常，运行完后显存维持在3.7g左右，等待一两分钟无果\r\n4. 再次合成即报错，显示（翻译）未能分配足够（大概500m）显存，剩余0，退出重新进入合成能正常运行，但又出现以上情况\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\n![wrong](https://user-images.githubusercontent.com/125204819/218322977-378741f9-7228-4e77-ace1-23067ce81832.png)\r\n\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [Windows11家庭版美版22623.1255]\r\n - GCC/G++ Version [gcc (MinGW.org GCC-6.3.0-1) 6.3.0]\r\n - Python Version [3.8.16]\r\n - PaddlePaddle Version [paddlepaddle-gpu  2.4.1.post117]\r\n![image](https://user-images.githubusercontent.com/125204819/218323300-55e5cf8e-5061-4f62-9a6a-008eaa8a4bc7.png)\r\n\r\n - Model Version [？]声码器是pwgan_aishell3_static_1.1.0，模型是我在飞桨ai studio上代码块微调后导出的\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [cuda-11.7/cudnn8.8？or8.4]\r\n![image](https://user-images.githubusercontent.com/125204819/218323715-829da62e-c475-40cf-8677-a12e1b0a8fd0.png)\r\n![image](https://user-images.githubusercontent.com/125204819/218323862-ef3977a0-28f2-4ec4-9b40-5a0fc83f043c.png)\r\n![image](https://user-images.githubusercontent.com/125204819/218323871-c49b5919-1f3e-4629-981a-eb0d36a8b973.png)\r\n\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\n我paddlespeech本来是使用源码编译安装的，会显示paddlespeech0.0.0，于是我用pip install paddlespeech==1.3重新安装的\r\n",
        "state": "closed",
        "user": "shiyv132",
        "closed_by": "yt605155624",
        "created_at": "2023-02-12T16:43:57+00:00",
        "updated_at": "2023-03-02T09:20:34+00:00",
        "closed_at": "2023-03-02T09:20:34+00:00",
        "comments_count": [
            "iftaken",
            "shiyv132",
            "iftaken"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2909,
        "title": "💡离线使用 paddlespeech",
        "body": "在liunx环境已安装cpu版的paddlepaddle和paddlespeech 使用时报错 模型无下载网络 手动下载fastspeech2_nosil_baker_ckpt_0.4.zip和nltk_data.tar.gz 请问怎么安装",
        "state": "open",
        "user": "joy0921",
        "closed_by": null,
        "created_at": "2023-02-13T03:38:25+00:00",
        "updated_at": "2023-03-29T07:30:35+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "Matiz7",
            "Matiz7",
            "shanchao0906",
            "shanchao0906",
            "zxcd"
        ],
        "labels": [
            "Question",
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2919,
        "title": "test",
        "body": "## Others\r\njust for test\r\n-->\r\n",
        "state": "closed",
        "user": "GGBond8488",
        "closed_by": "GGBond8488",
        "created_at": "2023-02-14T06:32:49+00:00",
        "updated_at": "2023-02-14T06:36:32+00:00",
        "closed_at": "2023-02-14T06:36:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2910,
        "title": "请问是否有client.py 客户端脚本进行流式传输数据到/paddlespeech/asr/streaming这个接口的，而不用客户端去下载全套paddlespeech",
        "body": null,
        "state": "closed",
        "user": "2954456878",
        "closed_by": "2954456878",
        "created_at": "2023-02-13T04:01:48+00:00",
        "updated_at": "2023-02-18T08:04:25+00:00",
        "closed_at": "2023-02-18T08:04:25+00:00",
        "comments_count": [
            "zxcd",
            "2954456878",
            "2954456878",
            "iftaken"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2917,
        "title": "AttributeError: '_lzma.LZMADecompressor' object has no attribute 'needs_input'",
        "body": "使用paddlespeech时报错\r\nAttributeError: '_lzma.LZMADecompressor' object has no attribute 'needs_input'\r\n\r\n环境\r\npython3.8 pandas1.5.3\r\n\r\n看了其他模块下相同的报错 说是python3.7升到3.8就解决了 可是我的python版本本来就是3.8 请问是什么原因",
        "state": "closed",
        "user": "joy0921",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-14T02:40:43+00:00",
        "updated_at": "2023-05-20T16:19:45+00:00",
        "closed_at": "2023-05-20T16:19:45+00:00",
        "comments_count": [
            "yt605155624",
            "joy0921",
            "yt605155624",
            "joy0921",
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2920,
        "title": "test-bot",
        "body": "test bot installation\r\n",
        "state": "closed",
        "user": "GGBond8488",
        "closed_by": "GGBond8488",
        "created_at": "2023-02-14T06:40:22+00:00",
        "updated_at": "2023-02-14T06:54:49+00:00",
        "closed_at": "2023-02-14T06:54:49+00:00",
        "comments_count": [
            "GGBond8488"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2921,
        "title": "更强的vad用于语音断句",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\npaddlespeech使用的vad算法为webrtc，是否考虑使用更加先进的vad算法",
        "state": "open",
        "user": "speakstone",
        "closed_by": null,
        "created_at": "2023-02-14T07:42:53+00:00",
        "updated_at": "2023-02-16T06:54:28+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2926,
        "title": "docker版本paddlespeech-cpu运行demo报错",
        "body": "```shell\r\n1. pull images\r\ndocker pull paddlecloud/paddlespeech:develop-cpu-bb7f2a\r\n2. run 参照https://hub.docker.com/r/paddlecloud/paddlespeech\r\ndocker run --name dev -v $PWD:/mnt -p 8888:8888 -it docker.io/paddlecloud/paddlespeech:develop-cpu-bb7f2a  /bin/bash\r\n3. cd demo dir\r\ncd /home/PaddleSpeech/demos/speaker_verification\r\n4. run\r\n ./run.sh\r\n--2023-02-11 08:59:56--  https://paddlespeech.bj.bcebos.com/vector/audio/85236145389.wav\r\nResolving paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)... 220.181.33.44, 2409:8c04:1001:1002:0:ff:b001:368a\r\nConnecting to paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)|220.181.33.44|:443... connected.\r\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\r\n\r\n    The file is already fully retrieved; nothing to do.\r\n\r\n--2023-02-11 08:59:57--  https://paddlespeech.bj.bcebos.com/vector/audio/123456789.wav\r\nResolving paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)... 220.181.33.44, 2409:8c04:1001:1002:0:ff:b001:368a\r\nConnecting to paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)|220.181.33.44|:443... connected.\r\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\r\n\r\n    The file is already fully retrieved; nothing to do.\r\n\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/base_commands.py\", line 19, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 142, in <module>\r\n    raise OSError('sndfile library not found')\r\nOSError: sndfile library not found\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/base_commands.py\", line 19, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 142, in <module>\r\n    raise OSError('sndfile library not found')\r\nOSError: sndfile library not found\r\n```\r\n",
        "state": "closed",
        "user": "fuguohong1024",
        "closed_by": "yt605155624",
        "created_at": "2023-02-14T14:23:51+00:00",
        "updated_at": "2023-02-15T06:17:08+00:00",
        "closed_at": "2023-02-15T06:16:09+00:00",
        "comments_count": [
            "fuguohong1024",
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2928,
        "title": "关于使用batch_size，并行推理asr，结果不同的疑问？",
        "body": "使用asr接口，调试batch_size并行输出结果。输入相同的数据，在下面的操作中（concat），不同的batch_size发现推理的结果不同。\r\n\r\n所作操作：\r\n1.import paddle\r\nfrom paddlespeech.cli.asr import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\n\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech', # conformer_wenetspeech conformer_talcs\r\n    lang=\"zh\", # zh_en zh\r\n    sample_rate=16000,\r\n    decode_method='attention',\r\n    codeswitch=False, # False True\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='../test_2.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\n\r\nprint('ASR Result: \\n{}'.format(text))\r\n\r\n2.concat\r\n![1676440342424](https://user-images.githubusercontent.com/69195822/218944192-c8d44479-bdb1-4ef0-9a21-65df687176be.png)\r\n\r\n3.音频信息：\r\n![1676440869485](https://user-images.githubusercontent.com/69195822/218945467-c1e80481-bac5-4ac1-8993-b59f755214d5.png)\r\n数据为：\r\n[test_2.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/10739804/test_2.zip)\r\n\r\n\r\n结果如下：\r\nbatch_size = 1 (不做concat) : \r\n![1676440534750](https://user-images.githubusercontent.com/69195822/218944613-10c747a4-76b1-4ea3-ba50-bee91bf3e971.png)\r\n\r\nbatch_size = 2 (做concat)\r\n![1676440652620](https://user-images.githubusercontent.com/69195822/218944886-a2995377-0f05-402f-aa64-de8efe534968.png)\r\n\r\n\r\n",
        "state": "open",
        "user": "DerekKars",
        "closed_by": null,
        "created_at": "2023-02-15T06:03:14+00:00",
        "updated_at": "2023-02-22T07:09:39+00:00",
        "closed_at": null,
        "comments_count": [
            "DerekKars",
            "zxcd",
            "DerekKars",
            "zxcd",
            "DerekKars",
            "zxcd",
            "DerekKars",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2930,
        "title": " nvidia Jetson Xavier NX 平台上 paddlespeech安装报错，pyworld报错",
        "body": "\r\nnvidia Jetson Xavier NX 平台上 paddlespeech安装不上，用 pip install paddlespeech 安装不上。是否可以提供一个编译好的 aarch64 的包。依赖的paddlepaddle版本是2.3.2\r\n\r\n我执行的命令是 pip install paddlespeech\r\n\r\n**环境:**\r\n - OS: Jetson Xavier NX \r\n - jp:4.6.1\r\n - Python Version 3.7\r\n - PaddlePaddle Version 2.3.2\r\n - CUDA/CUDNN Version 10.2\r\n- TensorRT 7.0\r\n",
        "state": "open",
        "user": "geekplusaa",
        "closed_by": null,
        "created_at": "2023-02-15T10:19:25+00:00",
        "updated_at": "2023-10-20T09:45:02+00:00",
        "closed_at": null,
        "comments_count": [
            "lizezheng",
            "geekplusaa",
            "lizezheng",
            "geekplusaa",
            "lizezheng",
            "sunqb"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2933,
        "title": "[TTS]Android中无法设置long类型数据，多讲话人声学模型无法设置讲话人id",
        "body": "参考\r\n- https://github.com/PaddlePaddle/Paddle-Lite/issues/10005",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-02-16T12:12:17+00:00",
        "updated_at": "2023-03-16T03:04:10+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "SwimmingTiger"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2931,
        "title": "The default pre-trained model downloaded path and modification",
        "body": "## General Question\r\nHi, this is a question concerning path detection.\r\n\r\nLike here:\r\n\r\n```\r\npaddlespeech tts --am fastspeech2_ljspeech --voc hifigan_ljspeech --lang en\r\n```\r\nIt will download the ```fastspeech2_ljspeech``` and ```hifigan_ljspeech```pre-trained model when it first runs. \r\n\r\nAccording to my search in the other places, I only knew that once I installed the model, the path to the acoustic model may depend on the installation method and location. I need to check the documentation for the installation instructions or check the installation location to find the path. Still, after I tried those ways, I did not find where the pre-trained model's downloaded default path like for ```fastspeech2_ljspeech``` and ```hifigan_ljspeech``` here. \r\n\r\nWith my best thanks, is there could be a way that enables me to find it or even change the default saved model path? Any suggestion could be much appreciated to me. \r\n\r\n",
        "state": "open",
        "user": "xiao11lam",
        "closed_by": null,
        "created_at": "2023-02-16T00:53:30+00:00",
        "updated_at": "2023-02-16T02:12:20+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2934,
        "title": "Improve the performace",
        "body": "My CPU is amd 3900x, but it cost 5s to tts of the '今天的天气真不错啊'，\r\n\r\nand cost 3s convert the zh.wav to '我认为跑步最重要的就是给我带来了身体健康',\r\n\r\nit is too slow for use for even for a single device.",
        "state": "open",
        "user": "bnuzhouwei",
        "closed_by": null,
        "created_at": "2023-02-16T14:50:39+00:00",
        "updated_at": "2023-02-17T08:32:11+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "bnuzhouwei"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2935,
        "title": "[TTS]粤语模型a韵的字发不出音",
        "body": "测试了几句，有几个a韵的字发不出音，分别是：\r\n![image](https://user-images.githubusercontent.com/51190264/219414415-fb0c078a-183a-46b5-9804-3bb02ce10142.png)\r\n\r\n然后我用“啊啊啊啊啊”试了一个极端情况，然后phone_id_map报错，应该是a相关的音没有被训练\r\n![image](https://user-images.githubusercontent.com/51190264/219414771-30712ea1-20a6-46be-9926-e09903e66300.png)\r\n![image](https://user-images.githubusercontent.com/51190264/219414794-a23eac57-2b9a-4ddb-82dd-bc1bd4cec6cd.png)\r\n",
        "state": "closed",
        "user": "JiehangXie",
        "closed_by": "yt605155624",
        "created_at": "2023-02-16T15:41:13+00:00",
        "updated_at": "2023-02-28T09:12:23+00:00",
        "closed_at": "2023-02-28T09:12:23+00:00",
        "comments_count": [
            "JiehangXie",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2936,
        "title": "关于想通过自己搜集的语音材料来训练模型，需要通过什么样的规则来进行原始音频标注",
        "body": "\r\n关于想通过自己搜集的语音材料来训练模型，需要通过什么样的规则来进行原始音频标注。请问有帖可以提供这样的方案吗？纯语音小白一枚。",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-17T02:51:12+00:00",
        "updated_at": "2025-05-06T05:24:29+00:00",
        "closed_at": "2025-05-06T05:24:29+00:00",
        "comments_count": [
            "yt605155624",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2940,
        "title": "[TTS] TTS CLI  中新增中英文混合、male 的 onnxruntime 推理",
        "body": "参考:\r\n-  https://github.com/PaddlePaddle/PaddleSpeech/pull/2222",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2023-02-20T08:10:57+00:00",
        "updated_at": "2023-02-22T09:44:17+00:00",
        "closed_at": "2023-02-22T09:44:17+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2938,
        "title": "Docker hub上的跑不动，卡住了，缺 上lib包",
        "body": "手动装好后，跑不起来，一直卡着，GPU最新版本\r\n\r\n```\r\nOSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory\r\n```\r\n\r\n安装apt install libsndfiel1\r\n\r\n接着报\r\n\r\n```\r\nTypeError: declarative() got an unexpected keyword argument 'property'λ d9ed99f2a49e /app/static/test \r\n```",
        "state": "closed",
        "user": "bnuzhouwei",
        "closed_by": "yt605155624",
        "created_at": "2023-02-18T01:18:21+00:00",
        "updated_at": "2023-02-20T02:54:47+00:00",
        "closed_at": "2023-02-20T02:54:47+00:00",
        "comments_count": [
            "yt605155624",
            "bnuzhouwei",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2939,
        "title": "请问是否有wss连接 接受实时语音传输，现在都是ws",
        "body": null,
        "state": "closed",
        "user": "2954456878",
        "closed_by": "stale[bot]",
        "created_at": "2023-02-18T06:13:27+00:00",
        "updated_at": "2025-05-06T05:24:30+00:00",
        "closed_at": "2025-05-06T05:24:30+00:00",
        "comments_count": [
            "2954456878",
            "zh794390558",
            "2954456878",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2943,
        "title": "[TTS]OSError: sndfile library not found",
        "body": "报错：\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/base_commands.py\", line 19, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 142, in <module>\r\n    raise OSError('sndfile library not found')\r\nOSError: sndfile library not found\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/base_commands.py\", line 19, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 142, in <module>\r\n    raise OSError('sndfile library not found')\r\nOSError: sndfile library not found\r\n```\r\n解决办法：\r\n```bash\r\n\r\nsudo apt-get install libsndfile1\r\n\r\n```",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-02-21T08:55:07+00:00",
        "updated_at": "2023-02-21T10:11:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2941,
        "title": "在使用MFA的时候提示There were words not found in the dictionary. Would you like to abort to fix them? (Y/N)",
        "body": "训练为中文语料，这种忽略（N）的话会有什么影响吗",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "CnYiXiaoNaiHe",
        "created_at": "2023-02-20T13:08:18+00:00",
        "updated_at": "2023-02-23T13:17:57+00:00",
        "closed_at": "2023-02-23T13:17:57+00:00",
        "comments_count": [
            "lym0302",
            "lym0302",
            "CnYiXiaoNaiHe",
            "yt605155624",
            "CnYiXiaoNaiHe"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2942,
        "title": "[TTS]chinese - english mixed training 中英文混合语料训练",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "bigsausage",
        "closed_by": "yt605155624",
        "created_at": "2023-02-21T06:01:34+00:00",
        "updated_at": "2024-05-18T10:46:15+00:00",
        "closed_at": "2023-03-21T08:04:18+00:00",
        "comments_count": [
            "bigsausage",
            "yt605155624",
            "Alital",
            "bigsausage",
            "lancelee98",
            "Daisyqk",
            "wytyl13"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2946,
        "title": "[S2T] 使用官方的conformer_talcs训练中英文混合语音识别模型，算法不收敛",
        "body": "## 使用官方的conformer_talcs从头开始训练中英文混合语音识别模型，算法不收敛。\r\n数据集：TALCS dataset(https://ai.100tal.com/dataset)\r\n硬件配置：英伟达3090显卡 24GB显存\r\n卡数：单卡\r\n训练时长：30个epoch\r\n模型参数：官方conformer.yaml文件\r\n",
        "state": "closed",
        "user": "choshiho",
        "closed_by": "choshiho",
        "created_at": "2023-02-22T03:49:10+00:00",
        "updated_at": "2023-08-16T06:11:19+00:00",
        "closed_at": "2023-03-06T02:50:42+00:00",
        "comments_count": [
            "zxcd",
            "choshiho",
            "zxcd",
            "choshiho",
            "zxcd",
            "choshiho",
            "zxcd",
            "choshiho",
            "zxcd",
            "choshiho",
            "zxcd",
            "choshiho",
            "ainndejj11",
            "choshiho"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2947,
        "title": "非流式语音合成服务中官方案例换成自己finetune的多人说话模型后报错",
        "body": "在非流式语音合成服务的官方案例中，我将配置文件application.yaml中tts部分改成了如图所示\r\n![image](https://user-images.githubusercontent.com/38137923/220529138-a01b0741-d3ce-469e-9f74-85f68de39c6d.png)\r\n通过 paddlespeech_server start --config_file application.yaml 命令启动服务，但是报错了如图：\r\n![image](https://user-images.githubusercontent.com/38137923/220528734-91b048b0-9e28-498e-8bad-826a93f93ebb.png)\r\n官方给的application.yaml是关于单人模型配置的，我改成多人模型的就报错了，请问下应该怎么修改？",
        "state": "closed",
        "user": "myhaha",
        "closed_by": "yt605155624",
        "created_at": "2023-02-22T05:16:13+00:00",
        "updated_at": "2023-02-22T05:41:43+00:00",
        "closed_at": "2023-02-22T05:41:43+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2952,
        "title": "关于使用第一次训练好的自定义fastspeech2模型，想要进行二次训练，使得模型推理时可以有多人语音。具体该如何实现",
        "body": "大概的模型二次训练思路，和实例是怎样的",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "CnYiXiaoNaiHe",
        "created_at": "2023-02-23T13:17:39+00:00",
        "updated_at": "2023-02-23T13:24:08+00:00",
        "closed_at": "2023-02-23T13:24:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2948,
        "title": "关于流式服务器 并发识别的问题",
        "body": "paddlespeech_server start 启动流式服务器后\r\n通过 paddlespeech_client asr_online  进行识别调用\r\n开启单个线程，识 时长 audio duration: 50.181, elapsed time: 26.64584755897522\r\n开启2个线程  识别时长 audio duration: 50.181, elapsed time: 83.6750648021698\r\n\r\n服务端是不能多线程处理识别请求吗？ 为什么同时处理2个识别请求，花费的时长翻倍",
        "state": "closed",
        "user": "2954456878",
        "closed_by": "zxcd",
        "created_at": "2023-02-22T06:57:18+00:00",
        "updated_at": "2024-04-11T08:00:40+00:00",
        "closed_at": "2023-02-28T07:01:28+00:00",
        "comments_count": [
            "zxcd",
            "2954456878",
            "zxcd",
            "springbootyp"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2951,
        "title": "[TTS]tts3_rhy韵律预测报错 AttributeError: 'ErnieForTokenClassification' object has no attribute 'num_labels'",
        "body": "说明文档中没有要求paddlenlp的版本要求，我使用paddlenlp==2.3.0和2.2.5版本都出现了，PaddleSpeech/examples/csmsc/tts3_rhy下synthesize_e2e.sh的推理都存在报错。报错信息如下：\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 281, in <module>\r\n    main()\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 277, in main\r\n    evaluate(args)\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 50, in evaluate\r\n    frontend = get_frontend(\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/exps/syn_utils.py\", line 266, in get_frontend\r\n    frontend = Frontend(\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/frontend/zh_frontend.py\", line 113, in __init__\r\n    self.rhy_predictor = RhyPredictor()\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/t2s/frontend/rhy_prediction/rhy_predictor.py\", line 48, in __init__\r\n    self.model = DefinedClassifier[\"ErnieLinear\"](**config[\"model\"])\r\n  File \"/home/aaa/PaddleSpeech/paddlespeech/text/models/ernie_linear/ernie_linear.py\", line 48, in __init__\r\n    self.num_classes = self.ernie.num_labels\r\n  File \"/home/aaa/anaconda3/envs/paddlespeech/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 1123, in __getattr__\r\n    return object.__getattribute__(self, name)\r\nAttributeError: 'ErnieForTokenClassification' object has no attribute 'num_labels'\r\n\r\n升级paddlenlp==2.5.0，这个报错消失，能正常推理。\r\n",
        "state": "closed",
        "user": "Zz-ww",
        "closed_by": "yt605155624",
        "created_at": "2023-02-23T03:33:49+00:00",
        "updated_at": "2023-02-23T05:46:08+00:00",
        "closed_at": "2023-02-23T05:46:08+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2949,
        "title": "[ASR][ERROR] - offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000",
        "body": "[ERROR] - offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000\r\n使用conformer_online_wenetspeech模型进行流式语音识别，模型启用几分钟后会这个错误。想问一下这个该如何修改改进？\r\n[ERROR] - offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000        \r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\python\\asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 375, in _decorate_function        \r\n    return self.forward(*inputs, **kwargs)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddlespeech\\s2t\\modules\\subsampling.py\", line 144, in forward            x, pos_emb = self.pos_enc(x, offset)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line  948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"D:\\Anaconda3\\lib\\site-packages\\paddlespeech\\s2t\\modules\\embedding.py\", line 164, in forward\r\n    assert offset + x.shape[\r\nAssertionError: offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000\r\n",
        "state": "closed",
        "user": "gooloosk",
        "closed_by": "zxcd",
        "created_at": "2023-02-22T09:41:59+00:00",
        "updated_at": "2024-02-26T15:09:57+00:00",
        "closed_at": "2023-02-28T07:01:41+00:00",
        "comments_count": [
            "zxcd",
            "gooloosk",
            "LDBS666",
            "gooloosk",
            "LDBS666",
            "LDBS666",
            "gooloosk"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2953,
        "title": "如何通过自己训练的单人speaker的fastspeech2模型进行二次微调，并且加入到模型中，且可以通过id索引的方式进行推理不同音色",
        "body": "一共两个问题。\r\n1.在单音色原有的基础上进行调整训练形成另一个音色。\r\n2.如何讲上面二次训练的音色配置到模型中，并且推理阶段可以通过索引来控制使用哪种音色合成",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "yt605155624",
        "created_at": "2023-02-23T14:01:07+00:00",
        "updated_at": "2023-03-21T07:58:01+00:00",
        "closed_at": "2023-03-21T07:58:01+00:00",
        "comments_count": [
            "yt605155624",
            "CnYiXiaoNaiHe",
            "yt605155624",
            "CnYiXiaoNaiHe"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2954,
        "title": " 'gbk' codec can't decode byte 0x96 in position 2: illegal multibyte sequence",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n![image](https://user-images.githubusercontent.com/19903385/221125827-d8670ab0-6b9b-443b-85ba-dc4555550e26.png)\r\n",
        "state": "closed",
        "user": "19920716",
        "closed_by": "19920716",
        "created_at": "2023-02-24T08:07:19+00:00",
        "updated_at": "2023-05-02T05:03:51+00:00",
        "closed_at": "2023-02-24T08:07:30+00:00",
        "comments_count": [
            "jirengu"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2955,
        "title": "[S2T]'gbk' codec can't decode byte 0x96 in position 2: illegal multibyte sequence",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [ win 10]\r\n - Python Version 3.10.6\r\n - PaddlePaddle Version 2.4.2  gpu\r\n - Model Version [2.0.0]\r\n - GPU/DRIVER Informationo [3070 ti]\r\n - CUDA/CUDNN Version cuda-10.2\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n![image](https://user-images.githubusercontent.com/19903385/221125895-5a490dbc-f5aa-4205-a748-aacf967b7cfe.png)\r\n",
        "state": "closed",
        "user": "19920716",
        "closed_by": "19920716",
        "created_at": "2023-02-24T08:07:59+00:00",
        "updated_at": "2023-08-25T09:21:08+00:00",
        "closed_at": "2023-02-25T03:38:31+00:00",
        "comments_count": [
            "19920716",
            "pmwangyang"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 2962
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2956,
        "title": "使用样例代码报错",
        "body": "from paddlespeech.cli.asr.infer import ASRExecutor\r\n\r\naudio = \"zh.wav\"\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=audio, force_yes=True)\r\nprint(result)\r\n![1677227556294](https://user-images.githubusercontent.com/59003815/221131554-546d534a-6828-4801-94b2-74bcb4e05099.jpg)\r\n\r\n\r\n## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "suc-suc",
        "closed_by": "zxcd",
        "created_at": "2023-02-24T08:37:41+00:00",
        "updated_at": "2023-02-28T07:01:00+00:00",
        "closed_at": "2023-02-28T07:01:00+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2957,
        "title": "onnxruntine gpu decoding error",
        "body": "```\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py\", line 696, in __call__\r\n    self._init_from_path_onnx(\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py\", line 410, in _init_from_path_onnx\r\n    self.frontend = get_frontend(\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 163, in get_frontend\r\n    frontend = Frontend(\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 116, in __init__\r\n    self.g2pW_model = G2PWOnnxConverter(\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/paddlespeech/t2s/frontend/g2pw/onnx_api.py\", line 80, in __init__\r\n    self.session_g2pW = onnxruntime.InferenceSession(\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 360, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/ybZhang/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 388, in _create_inference_session\r\n    raise ValueError(\r\nValueError: This ORT build has ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], ...)\r\n\r\n```",
        "state": "closed",
        "user": "ben-8878",
        "closed_by": "yt605155624",
        "created_at": "2023-02-24T10:29:18+00:00",
        "updated_at": "2023-09-20T09:09:10+00:00",
        "closed_at": "2023-02-24T11:46:10+00:00",
        "comments_count": [
            "ben-8878",
            "ChandlerBent"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2958,
        "title": "[TTS]使用自定义小数据集微调方案得到的微调后的模型可否被speech_server调用？可以的话，下述具体配置问题如何解决？",
        "body": "问题详细描述：\r\n**01 使用图1中PaddleSpeech的小数据集（自己录制的音频文件）微调方案得到微调后的模型（12句模型）目录结构如图2**\r\n \r\n![image](https://user-images.githubusercontent.com/126248892/221166226-db6e51f7-d27a-4359-9f26-17749f031f2f.png)\r\n**图1 小数据集微调方案**\r\n方案地址：https://aistudio.baidu.com/aistudio/projectdetail/4573549?sUid=2470186&shared=1&ts=1663753541400\r\n \r\n \r\n \r\n \r\n \r\n![image](https://user-images.githubusercontent.com/126248892/221166396-14aeeee8-3665-44e8-b5b2-f52149223ba4.png)\r\n![image](https://user-images.githubusercontent.com/126248892/221166410-31bf8ea0-a7d1-4a58-897b-e12b0cf74ec0.png)\r\n![image](https://user-images.githubusercontent.com/126248892/221166429-d5e7946b-848b-4c57-a398-c8f99b41133e.png)\r\n![image](https://user-images.githubusercontent.com/126248892/221166437-8bd9cbde-2d91-4801-848f-7f17c509ce66.png)\r\n![image](https://user-images.githubusercontent.com/126248892/221166443-2ae8c2b1-88a5-49f6-adc5-3bf2feffe18e.png)\r\n**图2 自定义微调模型结果目录**\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n02 得到微调模型后，想在speech_server这里面配置对应的微调模型时，am, voc, lang, voc_config, voc_ckpt, voc_stat完全同图5配置；engine_list同图4配置；am_config, am_ckpt, phones_dict, speaker_dict配置为自定义的图2微调模型对应的文件；**_am_stat部分因为12句微调模型未生成该文件，此处应该填写什么？其它配置有问题吗？_**\r\n \r\n![image](https://user-images.githubusercontent.com/126248892/221166575-8f727e38-a9c1-484f-a281-5a9c80dfd3fa.png)\r\n**图4 PaddleSpeech技术老师提供的speech_server的application.yaml配置信息**\r\n \r\n![image](https://user-images.githubusercontent.com/126248892/221166598-6749f8ac-551a-4356-838b-31da8c0db459.png)\r\n**图5 PaddleSpeech技术老师提供的speech_server的application.yaml配置信息**\r\n配置信息对应的项目地址：/home/aistudio/PaddleSpeech/paddlespeech/server/conf/application.yaml\r\n",
        "state": "open",
        "user": "StanfordAgula",
        "closed_by": null,
        "created_at": "2023-02-24T11:22:43+00:00",
        "updated_at": "2023-06-18T21:21:44+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "exceedzhang",
            "iftaken",
            "yunduobaba"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2961,
        "title": "example中的csmsc数据集的voc5的train.sh的问题",
        "body": "Traceback (most recent call last):\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 536, in _thread_loop\r\n    batch = self._get_data()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 674, in _get_data\r\n    batch.reraise()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 172, in reraise\r\n    raise self.exc_type(msg)\r\nFileNotFoundError: DataLoader worker(0) caught FileNotFoundError with message:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 339, in _worker_loop\r\n    batch = fetcher.fetch(indices)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 125, in fetch\r\n    data.append(self.dataset[idx])\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/datasets/data_table.py\", line 118, in __getitem__\r\n    example = self._convert(meta_datum)\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/datasets/data_table.py\", line 100, in _convert\r\n    converted_field = converter(meta_datum_field)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 417, in load\r\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aistudio/data/PaddleSpeech/examples/csmsc/voc5/dump/train/norm/001271_wave.npy'\r\n\r\n\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 108, in update\r\n    batch = self.read_batch()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 178, in read_batch\r\n    batch = next(self.train_iterator)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 745, in __next__\r\n    self._reader.read_next_list()[0])\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 274, in <module>\r\n    main()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 270, in main\r\n    train_sp(args, config)\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/exps/gan_vocoder/hifigan/train.py\", line 239, in train_sp\r\n    trainer.run()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 108, in update\r\n    batch = self.read_batch()\r\n  File \"/home/aistudio/work/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 178, in read_batch\r\n    batch = next(self.train_iterator)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 745, in __next__\r\n    self._reader.read_next_list()[0])\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:175)\r\n运行stage1时候报这个错误是为什么?",
        "state": "closed",
        "user": "wrz1999",
        "closed_by": "yt605155624",
        "created_at": "2023-02-26T16:05:52+00:00",
        "updated_at": "2023-02-28T06:18:47+00:00",
        "closed_at": "2023-02-28T06:18:47+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2959,
        "title": "想请问一下这边的whisper是否做了提速的改进呢，我看原始的large模型速度有点慢",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "shumeirao",
        "closed_by": "zxcd",
        "created_at": "2023-02-24T23:35:14+00:00",
        "updated_at": "2023-02-28T07:00:48+00:00",
        "closed_at": "2023-02-28T07:00:48+00:00",
        "comments_count": [
            "zxcd",
            "shumeirao"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2960,
        "title": "HifiGan的csmsc中的例子需要什么环境和库?",
        "body": "HifiGan的csmsc中的例子需要什么环境和库?装了最新版本的会报错，能否提供一个指定版本的requirements.txt文件并标注对应版本号。目前在预处理阶段就卡住了。",
        "state": "closed",
        "user": "wrz1999",
        "closed_by": "yt605155624",
        "created_at": "2023-02-26T11:33:24+00:00",
        "updated_at": "2023-02-28T06:18:41+00:00",
        "closed_at": "2023-02-28T06:18:41+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2965,
        "title": "关于流式TTS（streaming TTS）多说话人synthesize_streaming.py 推理失败问题",
        "body": "## General Question\r\n你好，我目前开发流式TT（多说话人）服务，信息总结如下：\r\n1.使用了aishell3数据集，在PaddleSpeech/examples/aishell3/tts3脚本中进行训练；\r\n2.训练阶段替换config文件为 conf/cnndecoder.yaml\r\n3.训练正常，并且在synthesize_e2e.py中可以正常推理（多说话人）；\r\n目前正在改造synthesize_streaming.py 文件，以期可以实现流式推理，修改细节如下：\r\na) 增加了 --speaker_dict 和 --spk_id ；\r\nb) 提前导入了 speaker_dict 并且计算了 spk_num\r\nc) 在初始化 am 的时候，将 line 77 修改为： am = am_class(idim=vocab_size, odim=odim, spk_num=spk_num,**am_config[\"model\"])\r\n增加了 spk_num=spk_num\r\nd) 在sentence推理的时候，将line 157 - line 159 改为：\r\n            with paddle.no_grad():\r\n                # acoustic model\r\n                spk_id = paddle.to_tensor(args.spk_id)\r\n                orig_hs = am_encoder_infer(phone_ids,spk_id=spk_id)\r\n\r\n遇到的问题：\r\n1）在推理的时候，返回错误：\r\n![image](https://user-images.githubusercontent.com/22590720/221575577-4bc29228-d086-4ba5-a96d-94325c7f9d72.png)\r\n\r\n2）如果去掉spk_id之后，生成语音为 静音\r\n![image](https://user-images.githubusercontent.com/22590720/221576186-f6c28b43-ca07-455b-a10a-004673ffe826.png)\r\n\r\n对于错误的猜想：\r\na) 在这个函数 line 85： am_encoder_infer = am.encoder_infer 是否要增加spk相关内容，如果是的话，应该怎么加\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "443127316",
        "closed_by": "443127316",
        "created_at": "2023-02-27T13:31:15+00:00",
        "updated_at": "2023-06-27T04:13:42+00:00",
        "closed_at": "2023-02-28T06:29:38+00:00",
        "comments_count": [
            "yt605155624",
            "443127316",
            "yt605155624",
            "443127316",
            "a0735a"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2963,
        "title": "[TTS] MFA 报错 No such file or directory: \"xx/xx/xx/train/mfcc/raw_mfcc.0.scp",
        "body": "执行如下脚本\r\nexport PATH=\"$MFA_DOWNLOAD_DIR/montreal-forced-aligner/bin\"\r\nif [ ! -d \"$EXP_DIR/baker_alignment\" ]; then\r\n    echo \"Start MFA training...\"\r\n    mfa_train_and_align $EXP_DIR/baker_corpus \"$EXP_DIR/$LEXICON_NAME.lexicon\" $EXP_DIR/baker_alignment -o $EXP_DIR/baker_model --clean --verbose --temp_directory $EXP_DIR/.mfa_train_and_align\r\n    # mfa_align $EXP_DIR/baker_corpus \"$EXP_DIR/$LEXICON_NAME.lexicon\"  \r\n    echo \"training done!\"\r\n    echo \"results: $EXP_DIR/baker_alignment\"\r\n    echo \"model: $EXP_DIR/baker_model\"\r\nfi\r\n\r\n报如下错误\r\n![image](https://user-images.githubusercontent.com/44515739/221458737-a31b2aed-f450-4397-935d-4f2355cbf421.png)\r\n\r\n按照#2437的方法查看到\r\n![image](https://user-images.githubusercontent.com/44515739/221458927-4bb174fc-f72d-44ea-95d9-174509aa8257.png)\r\n\r\nlibgfortran3已经安装，但是不知道是什么原因导致的这个问题，请指教下\r\n\r\n",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "yt605155624",
        "created_at": "2023-02-27T02:30:39+00:00",
        "updated_at": "2023-02-27T07:09:11+00:00",
        "closed_at": "2023-02-27T07:09:11+00:00",
        "comments_count": [
            "yt605155624",
            "CnYiXiaoNaiHe",
            "yt605155624",
            "CnYiXiaoNaiHe"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2969,
        "title": "[TTS]PaddleSpeech中使用使用PaddlePaddle2.4.1GPU版本训练找不到cuda和cudnn问题",
        "body": "使用anaconda安装的  cuda10.2 cudnn7.6.5，训练aishell3模型训练步骤时候提示找不到cuda和cudnn这种情况该如何解决\r\n",
        "state": "closed",
        "user": "CnYiXiaoNaiHe",
        "closed_by": "CnYiXiaoNaiHe",
        "created_at": "2023-02-28T04:10:52+00:00",
        "updated_at": "2023-02-28T07:31:29+00:00",
        "closed_at": "2023-02-28T07:31:29+00:00",
        "comments_count": [],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2966,
        "title": "流式语音识别,如何将单次识别时长缩短",
        "body": "我在使用asr_engine进行流式语音识别的过程中, 发现单次识别中,最后一个字的开始:结束时间差很大, 请问如何缩短这个时长差距\r\n(word time stamp中的最后一个字的开始时间戳和结束时间戳中间差了好多秒)\r\n![image](https://user-images.githubusercontent.com/26082263/221577882-2e6067c6-fe77-4ae6-b1d9-27b440616fa4.png)\r\n我使用的模型为: \"conformer_online_wenetspeech\"",
        "state": "closed",
        "user": "ArvinCharl",
        "closed_by": "ArvinCharl",
        "created_at": "2023-02-27T13:38:38+00:00",
        "updated_at": "2023-02-28T06:19:57+00:00",
        "closed_at": "2023-02-28T06:19:56+00:00",
        "comments_count": [
            "zxcd",
            "ArvinCharl",
            "ArvinCharl"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2967,
        "title": "🌟 安装PaddleSpeech相关问题讨论（Windows，mac），以及命令行使用问题",
        "body": "请问怎么在命令行运行PaddleSpeech？是在CMD中直接运行吗？为什么我的显示不是内部或外部命令，也不是可运行的程序？",
        "state": "closed",
        "user": "wangling6666",
        "closed_by": "yt605155624",
        "created_at": "2023-02-27T14:13:44+00:00",
        "updated_at": "2023-03-13T03:12:47+00:00",
        "closed_at": "2023-03-13T03:12:47+00:00",
        "comments_count": [
            "iftaken"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2971,
        "title": "[ASR] 有没有办法为识别结果添加语法约束，实现命令词识别/意图识别的效果",
        "body": "## General Question\r\n\r\n我想做个离线语音助手，用户输入一些关键词，绑定一些操作，在说出关键词后触发。如果ASR只是简单的语音到文本，就必须再做自然语言处理才能识别用户说的是什么命令（似乎很难离线实现）。\r\n\r\nPaddleSpeech 有没有办法限制识别结果的输出范围，比如只包含特定的关键词？\r\n\r\n我在 https://github.com/synesthesiam/voice2json 里看到了一种实现思路，根据语法文件动态编译Kaldi引擎的`G.fst `、`HCLGa.fst`等模型文件，从而让输出结果只包含语法文件里的关键词。不知道 PaddleSpeech 能不能进行类似的操作？如果可以的话，这种操作速度是否足够快，比如能否在几十秒内完成？因为关键词是用户指定的，可能会随时修改，所以生成太慢就不好用了。",
        "state": "open",
        "user": "SwimmingTiger",
        "closed_by": null,
        "created_at": "2023-02-28T08:40:09+00:00",
        "updated_at": "2023-05-20T16:19:27+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "SwimmingTiger",
            "zxcd",
            "iftaken",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2974,
        "title": "HifiGan的csmsc运行训练阶段时候报错!",
        "body": "## HifiGan的csmsc运行训练阶段时候报错\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   uniform_random_ad_func(paddle::experimental::IntArrayBase<paddle::experimental::Tensor>, paddle::experimental::DataType, paddle::experimental::ScalarBase<paddle::experimental::Tensor>, paddle::experimental::ScalarBase<paddle::experimental::Tensor>, int, phi::Place)\r\n1   paddle::experimental::uniform_random(paddle::experimental::IntArrayBase<paddle::experimental::Tensor> const&, paddle::experimental::DataType, paddle::experimental::ScalarBase<paddle::experimental::Tensor> const&, paddle::experimental::ScalarBase<paddle::experimental::Tensor> const&, int, phi::Place const&)\r\n2   paddle::experimental::GetDeviceContextByBackend(paddle::experimental::Backend)\r\n3   paddle::experimental::DeviceContextPool::Get(phi::Place const&)\r\n4   paddle::platform::DeviceContextPool::Get(phi::Place const&)\r\n5   std::__future_base::_Deferred_state<std::thread::_Invoker<std::tuple<std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > (*)(phi::Place const&, bool), phi::Place, bool> >, std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > >::_M_complete_async()\r\n6   std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)\r\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::thread::_Invoker<std::tuple<std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > (*)(phi::Place const&, bool), phi::Place, bool> >, std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\r\n8   std::unique_ptr<phi::DeviceContext, std::default_delete<phi::DeviceContext> > paddle::platform::CreateDeviceContext<phi::GPUContext>(phi::Place const&, bool)\r\n9   phi::GPUContext::GPUContext(phi::GPUPlace const&, bool)\r\n10  phi::InitGpuProperties(phi::Place, int*, int*, int*, int*, int*, int*, std::array<int, 3ul>*)\r\n11  cudnnGetVersion\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1677655360 (unix time) try \"date -d @1677655360\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x5cd6) received by PID 23766 (TID 0x7fe36be18080) from PID 23766 ***]\r\n\r\n./local/train.sh: line 13: 23766 Aborted                 (core dumped) FLAGS_cudnn_exhaustive_search=true FLAGS_conv_workspace_size_limit=4000 python ${BIN_DIR}/train.py --train-metadata=dump/train/norm/metadata.jsonl --dev-metadata=dump/dev/norm/metadata.jsonl --config=${config_path} --output-dir=${train_output_path} --ngpu=1",
        "state": "closed",
        "user": "wrz1999",
        "closed_by": "yt605155624",
        "created_at": "2023-03-01T07:23:36+00:00",
        "updated_at": "2023-03-13T05:53:37+00:00",
        "closed_at": "2023-03-13T05:53:37+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2975,
        "title": "[TTS]fastspeech2_aishell3 android 报错",
        "body": "fastspeech2_csmsc正常跑，换成了fastspeech2_aishell3就报错了\r\n```\r\nA/Paddle-Lite: [F  3/ 1 16:59: 1.950 ...lite/kernels/arm/lookup_table_compute.cc:53 Run] Check failed: (ids_data[i] < row_number): 2338328217695289344!<306 look uptable ids[i] < row_number check failed\r\nA/libc: Fatal signal 6 (SIGABRT), code -1 (SI_QUEUE) in tid 20221 (Predictor Worke), pid 20168 (e.lite.demo.tts)\r\n```\r\n模型用的是 https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_aishell3_pdlite_1.3.0.zip\r\n请问是啥原因啊？怎么解决？\r\n<img width=\"872\" alt=\"08f0b755bc2b822fa3495ea0c1c7029\" src=\"https://user-images.githubusercontent.com/16017418/222092941-6b4ab206-949b-49db-a3b1-0627d82c6a6a.png\">\r\n",
        "state": "closed",
        "user": "kFoodie",
        "closed_by": "yt605155624",
        "created_at": "2023-03-01T09:01:44+00:00",
        "updated_at": "2023-10-16T11:08:20+00:00",
        "closed_at": "2023-03-01T12:43:24+00:00",
        "comments_count": [
            "yt605155624",
            "kFoodie",
            "kFoodie",
            "ChengsongLu"
        ],
        "labels": [
            "Bug",
            "T2S",
            "duplicate"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2976,
        "title": "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error",
        "body": "\r\n![求助1](https://user-images.githubusercontent.com/86141016/222110119-6bbb6a21-c6d9-4844-918c-28692c976769.png)\r\n![求助2](https://user-images.githubusercontent.com/86141016/222110126-cf111792-114b-4121-a52d-0f395a402755.png)\r\n![求助](https://user-images.githubusercontent.com/86141016/222110130-f154b758-66b3-44a3-837f-800162326264.png)\r\n求助这个是哪里出了问题？文件可以正常生成\r\n麻烦具体告知怎么解决，纯小白一个",
        "state": "closed",
        "user": "qiaosir888",
        "closed_by": "yt605155624",
        "created_at": "2023-03-01T10:17:56+00:00",
        "updated_at": "2023-03-02T07:54:38+00:00",
        "closed_at": "2023-03-02T07:54:38+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "duplicate"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2978,
        "title": "【飞桨企业案例招募】欢迎与我们联系",
        "body": "【飞桨企业案例招募】\r\n飞桨源于产业实践，始终致力于与产业深入融合，锁定行业痛点、难点，不断形成优质可用的解决方案。 飞桨迄今已在智能质检、无人巡检、遥感监测、金融风控、 AI 医疗等众多领域应用落地，仍期待与更多合作伙伴一起帮助越来越多的行业完成 AI 赋能。\r\n如果您在产业生产实践的过程有使用飞桨相关技术，欢迎邮件至paddlespeech@baidu.com，填写企业与项目相关信息，有机会加入飞桨企业案例，获得技术支持，与飞桨共建品牌宣传合作。\r\nPaddleSpeech Repo主页: https://github.com/PaddlePaddle/PaddleSpeech\r\n飞桨往期企业案例集：https://www.paddlepaddle.org.cn/customercase\r\nPaddleSpeech 教程与精品项目合集：https://aistudio.baidu.com/aistudio/projectdetail/4692119?contributionType=1\r\nPaddleSpeech 遵循 Apache2.0 开源协议，支持开发者们做二次开发，免费商用（Apache LICENSE 2.0 : http://www.apache.org/licenses/LICENSE-2.0.html）",
        "state": "open",
        "user": "iftaken",
        "closed_by": null,
        "created_at": "2023-03-02T06:23:52+00:00",
        "updated_at": "2023-03-02T07:54:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2979,
        "title": "[TTS] 串通粤语模型的静态图推理流程和转 onnx、onnxruntime 推理流程",
        "body": "参考 https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/csmsc/tts3/run.sh 的 stage 4 ~ stage 6 需要改的不多，可能 py 文件加点 canton 的选项就行\r\n\r\n需要把静态图模型、onnx 模型链接更新到 readme (可以联系 maintainer 上传模型获取链接)\r\n\r\n@JiehangXie ",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2023-03-02T12:18:15+00:00",
        "updated_at": "2023-03-06T07:13:33+00:00",
        "closed_at": "2023-03-06T07:13:33+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2980,
        "title": "[TTS] 粤语合成的 onnxruntime 推理加到 cli 里面",
        "body": "参考这个 https://github.com/PaddlePaddle/PaddleSpeech/pull/2945 现在 cli 里面只有动态图推理\r\n\r\n@JiehangXie ",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2023-03-02T12:19:16+00:00",
        "updated_at": "2023-03-06T07:13:33+00:00",
        "closed_at": "2023-03-06T07:13:33+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2981,
        "title": "是否有可部署在ARM Linux上的中文文本处理前端Demo?",
        "body": "## General Question\r\n目前只在utils内找到用于中文文本正则化的zh_tn.py，不知道是否有其他的组成部分（如G2P）的实现代码？看了TTSAndroid的demo，这一部分并没有实现，个人从头实现感觉比较困难\r\n",
        "state": "closed",
        "user": "Coinsinical",
        "closed_by": "SmileGoat",
        "created_at": "2023-03-02T15:11:21+00:00",
        "updated_at": "2024-12-11T08:06:48+00:00",
        "closed_at": "2023-03-13T10:35:52+00:00",
        "comments_count": [
            "yt605155624",
            "Coinsinical",
            "yt605155624",
            "yt605155624",
            "Coinsinical",
            "yt605155624",
            "ningpengtao-coder",
            "ChengsongLu",
            "XTaoWang"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2982,
        "title": "[TTS]粤语TTS在numpy==1.22.4环境下报错",
        "body": "---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nRuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n/tmp/ipykernel_3653/4288988082.py in <cell line: 9>()\r\n      7 from paddle.static import InputSpec\r\n      8 import fastdeploy as fd\r\n----> 9 from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n     10 \r\n     11 fastspeech2_model_url = \"https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_canton_ckpt_1.4.0.zip\"\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/__init__.py in <module>\r\n     17 from . import exps\r\n     18 from . import frontend\r\n---> 19 from . import models\r\n     20 from . import modules\r\n     21 from . import ssml\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/models/__init__.py in <module>\r\n     12 # See the License for the specific language governing permissions and\r\n     13 # limitations under the License.\r\n---> 14 from .ernie_sat import *\r\n     15 from .fastspeech2 import *\r\n     16 from .hifigan import *\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/models/ernie_sat/__init__.py in <module>\r\n     13 # limitations under the License.\r\n     14 from .ernie_sat import *\r\n---> 15 from .ernie_sat_updater import *\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/models/ernie_sat/ernie_sat_updater.py in <module>\r\n     22 \r\n     23 from paddlespeech.t2s.modules.losses import MLMLoss\r\n---> 24 from paddlespeech.t2s.training.extensions.evaluator import StandardEvaluator\r\n     25 from paddlespeech.t2s.training.reporter import report\r\n     26 from paddlespeech.t2s.training.updaters.standard_updater import StandardUpdater\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/training/__init__.py in <module>\r\n     13 # limitations under the License.\r\n     14 from .cli import *\r\n---> 15 from .experiment import *\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/training/experiment.py in <module>\r\n     21 from visualdl import LogWriter\r\n     22 \r\n---> 23 from paddlespeech.t2s.utils import checkpoint\r\n     24 from paddlespeech.t2s.utils import mp_tools\r\n     25 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/utils/__init__.py in <module>\r\n     13 # limitations under the License.\r\n     14 from . import checkpoint\r\n---> 15 from . import display\r\n     16 from . import layer_tools\r\n     17 from . import mp_tools\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/paddlespeech/t2s/utils/display.py in <module>\r\n     12 # See the License for the specific language governing permissions and\r\n     13 # limitations under the License.\r\n---> 14 import librosa.display\r\n     15 import matplotlib.pylab as plt\r\n     16 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/librosa/display.py in <module>\r\n     47 import numpy as np\r\n     48 from matplotlib.cm import get_cmap\r\n---> 49 from matplotlib.axes import Axes\r\n     50 from matplotlib.ticker import Formatter, ScalarFormatter\r\n     51 from matplotlib.ticker import LogLocator, FixedLocator, MaxNLocator\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/matplotlib/axes/__init__.py in <module>\r\n      2                         unicode_literals)\r\n      3 \r\n----> 4 from ._subplots import *\r\n      5 from ._axes import *\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/matplotlib/axes/_subplots.py in <module>\r\n      5 from six.moves import map\r\n      6 \r\n----> 7 from matplotlib.gridspec import GridSpec, SubplotSpec\r\n      8 from matplotlib import docstring\r\n      9 import matplotlib.artist as martist\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/matplotlib/gridspec.py in <module>\r\n     25 \r\n     26 import matplotlib as mpl\r\n---> 27 from matplotlib import _pylab_helpers, tight_layout, rcParams\r\n     28 from matplotlib.transforms import Bbox\r\n     29 import matplotlib._layoutbox as layoutbox\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/matplotlib/tight_layout.py in <module>\r\n     13 \r\n     14 import matplotlib\r\n---> 15 from matplotlib.transforms import TransformedBbox, Bbox\r\n     16 \r\n     17 from matplotlib.font_manager import FontProperties\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/matplotlib/transforms.py in <module>\r\n     40 \r\n     41 import numpy as np\r\n---> 42 from matplotlib._path import (affine_transform, count_bboxes_overlapping_bbox,\r\n     43     update_path_extents)\r\n     44 from numpy.linalg import inv\r\n\r\nImportError: numpy.core.multiarray failed to import",
        "state": "closed",
        "user": "JiehangXie",
        "closed_by": "yt605155624",
        "created_at": "2023-03-03T06:40:49+00:00",
        "updated_at": "2023-03-03T09:11:25+00:00",
        "closed_at": "2023-03-03T09:11:25+00:00",
        "comments_count": [
            "yt605155624",
            "JiehangXie",
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2985,
        "title": "[S2T] Can't start server with zh_en model",
        "body": "When I start server with such config yaml:\r\n\r\n################################### ASR #########################################\r\n################### speech task: asr; engine_type: python #######################\r\nasr_python:\r\n    model: 'conformer_talcs'\r\n    lang: 'zh_en'\r\n    sample_rate: 16000\r\n    cfg_path: # [optional]\r\n    ckpt_path: # [optional]\r\n    decode_method: 'attention_rescoring'\r\n    num_decoding_left_chunks: -1\r\n    force_yes: True\r\n    device:  # set 'gpu:id' or 'cpu'\r\n\r\nI get error message:\r\n\r\npaddlespeech_server start --config_file asr.yaml\r\n[2023-03-03 17:55:11,828] [    INFO] - start to init the engine\r\n[2023-03-03 17:55:11,828] [    INFO] - asr : python engine.\r\n[2023-03-03 17:55:11,916] [   ERROR] - Failed to start server.\r\n[2023-03-03 17:55:11,916] [   ERROR] - codeswitch is true only in zh_en model\r\n\r\nBut I can't find a place to set codeswitch to True. However, 'conformer_talcs-codeswitch_zh_en-16k' is indeed in the list of available models.",
        "state": "closed",
        "user": "wangtiance",
        "closed_by": "zxcd",
        "created_at": "2023-03-03T10:14:14+00:00",
        "updated_at": "2023-05-02T07:39:03+00:00",
        "closed_at": "2023-03-13T11:34:00+00:00",
        "comments_count": [
            "zxcd",
            "achaosss"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2996,
        "title": "[TTS] paddlespeech_tts_cpp 的 cpp 版本文本前端加入 Arm Linux Demo",
        "body": "- https://github.com/PaddlePaddle/PaddleSpeech/pull/3018\r\n\r\n前置 pr: \r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/2991\r\n- https://github.com/lym0302/paddlespeech_tts_cpp/pull/1\r\n\r\n@SwimmingTiger",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "SmileGoat",
        "created_at": "2023-03-06T07:28:57+00:00",
        "updated_at": "2023-03-13T10:35:52+00:00",
        "closed_at": "2023-03-13T10:35:52+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2992,
        "title": "请问PaddleSpeech/examples/csmsc/voc5中PTQ_static.sh跑不通",
        "body": "问题：请问PaddleSpeech/examples/csmsc/voc5中PTQ_static.sh跑不通\r\n我在运行PaddleSpeech/examples/csmsc/voc5的run.sh的过程中，在stage=3时程序报错。\r\n对应运行命令：\r\n![image](https://user-images.githubusercontent.com/68834517/223012996-b6846af4-6c42-4186-a6e8-1d09333eb24a.png)\r\n\r\n对应报错截图：\r\n![image](https://user-images.githubusercontent.com/68834517/223013282-33d46563-e52e-4083-a136-5839b5d66a05.png)\r\n这里是hifigan训练后的输出文件夹：\r\n![image](https://user-images.githubusercontent.com/68834517/223013355-8706fff9-9111-4048-8b26-b6e1673e3cee.png)\r\n\r\n运行环境：\r\n![image](https://user-images.githubusercontent.com/68834517/223013528-649bd484-ef27-4ca4-ba04-5fe5ff9243a5.png)\r\n\r\n请问，我应该如何解决",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "yt605155624",
        "created_at": "2023-03-06T03:31:24+00:00",
        "updated_at": "2023-03-21T07:57:40+00:00",
        "closed_at": "2023-03-21T07:57:40+00:00",
        "comments_count": [
            "yt605155624",
            "longRookie"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2988,
        "title": "使用自己的声音做语音合成本地部署失败",
        "body": "参考[https://zhuanlan.zhihu.com/p/587765776](url)代码就改了下文件路径，运行报错，python和paddle都装好了。\r\n报错：\r\n\r\n`Traceback (most recent call last):\r\n  File \"E:\\Record\\anntest\\test_1.py\", line 26, in <module>\r\n    frontend = get_frontend(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 272, in get_frontend\r\n    frontend = MixFrontend(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\mix_frontend.py\", line 29, in __init__\r\n    self.zh_frontend = Frontend(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 147, in __init__\r\n    with open(phone_vocab_path, 'rt') as f:\r\nOSError: [Errno 22] Invalid argument: 'E:\\\\Record\\x07nntest\\\\demo\\\\phone_id_map.txt'\r\n`\r\n\r\n文件夹路径是E:\\Record\\anntest，模型在E:\\Record\\anntest\\demo，代码如下：\r\n`from pathlib import Path\r\nimport soundfile as sf\r\nimport os\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_output\r\nfrom paddlespeech.t2s.exps.syn_utils import get_frontend\r\nfrom paddlespeech.t2s.exps.syn_utils import get_predictor\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_output\r\n\r\n# 在其他环境中，记得修改下面这两个变量的路径\r\nam_inference_dir = \"E:\\Record\\anntest\\demo\"\r\nvoc_inference_dir = \"E:\\Record\\anntest\\pwgan_aishell3_static_1.1.0\"  # 这里以 pwgan_aishell3 为例子\r\n# 音频生成的路径，修改成你音频想要保存的路径\r\nwav_output_dir = \"E:\\Record\\anntest\\output\"\r\n\r\n# 选择设备[gpu / cpu]，这里以GPU为例子， \r\ndevice = \"cpu\"\r\n\r\n# 想要生成的文本和对应文件名\r\n\r\ntext_dict = {\r\n    \"1\": \"今天天气真不错，欢迎和我一起玩。\",\r\n    \"2\": \"我认为跑步给我的身体带来了健康。\",\r\n}\r\n\r\n# frontend\r\nfrontend = get_frontend(\r\n    lang=\"mix\",\r\n    phones_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n    tones_dict=None\r\n)\r\n\r\n# am_predictor\r\nam_predictor = get_predictor(\r\n    model_dir=am_inference_dir,\r\n    model_file=\"fastspeech2_mix\" + \".pdmodel\",\r\n    params_file=\"fastspeech2_mix\" + \".pdiparams\",\r\n    device=device)\r\n\r\n# voc_predictor\r\nvoc_predictor = get_predictor(\r\n    model_dir=voc_inference_dir,\r\n    model_file=\"pwgan_aishell3\" + \".pdmodel\",    # 这里以 pwgan_aishell3 为例子，其它模型记得修改此处模型名称\r\n    params_file=\"pwgan_aishell3\" + \".pdiparams\",\r\n    device=device)\r\n\r\noutput_dir = Path(wav_output_dir)\r\noutput_dir.mkdir(parents=True, exist_ok=True)\r\n\r\nsentences = list(text_dict.items())\r\n\r\nmerge_sentences = True\r\nfs = 24000\r\nfor utt_id, sentence in sentences:\r\n    am_output_data = get_am_output(\r\n        input=sentence,\r\n        am_predictor=am_predictor,\r\n        am=\"fastspeech2_mix\",\r\n        frontend=frontend,\r\n        lang=\"mix\",\r\n        merge_sentences=merge_sentences,\r\n        speaker_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n        spk_id=0, )\r\n    wav = get_voc_output(\r\n            voc_predictor=voc_predictor, input=am_output_data)\r\n    # 保存文件\r\n    sf.write(output_dir / (utt_id + \".wav\"), wav, samplerate=fs)\r\n`\r\n\r\n\r\n[参考](https://www.bilibili.com/opus/767904972680462342)用了另一种代码，报了另一种错。\r\n代码：\r\n`from pathlib import Path\r\n\r\nimport soundfile as sf\r\n\r\nimport os\r\n\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_output\r\n\r\nfrom paddlespeech.t2s.exps.syn_utils import get_frontend\r\n\r\nfrom paddlespeech.t2s.exps.syn_utils import get_predictor\r\n\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_output\r\n\r\n\r\n\r\ndef get_text_dict(name:str,txtname:str):\r\n\r\n  ff = open(txtname,\"r\",encoding=\"ISO-8859-1\")\r\n\r\n  msg = ff.read()\r\n\r\n  ff.close()\r\n\r\n  text_list = msg.split(\"\\n\")\r\n\r\n  text_dict = {}\r\n\r\n  num = 0\r\n\r\n  for i in text_list:\r\n\r\n    text_dict[name+str(num)] = i\r\n\r\n    num+=1\r\n\r\n    print(f\"{name}text:{num}\")\r\n\r\n  return text_dict\r\n\r\n\r\n\r\ndef the_main(text_dict):\r\n\r\n  # frontend\r\n\r\n  frontend = get_frontend(\r\n\r\n    lang=\"mix\",\r\n\r\n    phones_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n\r\n    tones_dict=None\r\n\r\n  )\r\n\r\n\r\n\r\n  # am_predictor\r\n\r\n  am_predictor = get_predictor(\r\n\r\n    model_dir=am_inference_dir,\r\n\r\n    model_file=\"fastspeech2_mix\" + \".pdmodel\",\r\n\r\n    params_file=\"fastspeech2_mix\" + \".pdiparams\",\r\n\r\n    device=device)\r\n\r\n\r\n\r\n  # voc_predictor\r\n\r\n  voc_predictor = get_predictor(\r\n\r\n    model_dir=voc_inference_dir,\r\n\r\n    model_file=\"pwgan_aishell3\" + \".pdmodel\",  # 这里以 pwgan_aishell3 为例子，其它模型记得修改此处模型名称\r\n\r\n    params_file=\"pwgan_aishell3\" + \".pdiparams\",\r\n\r\n    device=device)\r\n\r\n\r\n\r\n  output_dir = Path(wav_output_dir)\r\n\r\n  output_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n\r\n\r\n  sentences = list(text_dict.items())\r\n\r\n\r\n\r\n  merge_sentences = True\r\n\r\n  fs = 24000\r\n\r\n  for utt_id, sentence in sentences:\r\n\r\n    am_output_data = get_am_output(\r\n\r\n      input=sentence,\r\n\r\n      am_predictor=am_predictor,\r\n\r\n      am=\"fastspeech2_mix\",\r\n\r\n      frontend=frontend,\r\n\r\n      lang=\"mix\",\r\n\r\n      merge_sentences=merge_sentences,\r\n\r\n      speaker_dict=os.path.join(am_inference_dir, \"phone_id_map.txt\"),\r\n\r\n      spk_id=0, )\r\n\r\n    wav = get_voc_output(\r\n\r\n        voc_predictor=voc_predictor, input=am_output_data)\r\n\r\n    # 保存文件\r\n\r\n    sf.write(output_dir / (utt_id + \".wav\"), wav, samplerate=fs)\r\n\r\n  return\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n  #模型路径\r\n\r\n  am_inference_dir = \"demo\"\r\n\r\n  #声码器路径，这里以 pwgan_aishell3 为例子\r\n\r\n  voc_inference_dir = \"pwgan_aishell3_static_1.1.0\"\r\n\r\n  # 音频生成的路径，修改成你音频想要保存的路径\r\n\r\n  wav_output_dir = \"output\"\r\n\r\n  # 选择设备[gpu / cpu]，这里以GPU为例子， \r\n\r\n  device = \"cpu\"\r\n\r\n  # 想要生成的文本文档对应文件名\r\n\r\n  txt_name = \"文档.txt\"\r\n\r\n  the_main(get_text_dict(name=am_inference_dir,txtname=txt_name))\r\n`\r\n\r\n报错：\r\n`Traceback (most recent call last):\r\n  File \"E:\\Record\\anntest\\test_2.py\", line 155, in <module>\r\n    the_main(get_text_dict(name=am_inference_dir,txtname=txt_name))\r\n  File \"E:\\Record\\anntest\\test_2.py\", line 103, in the_main\r\n    am_output_data = get_am_output(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 503, in get_am_output\r\n    frontend_dict = run_frontend(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 310, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\mix_frontend.py\", line 123, in get_input_ids\r\n    input_ids = self.zh_frontend.get_input_ids(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 540, in get_input_ids\r\n    phonemes = self.get_phonemes(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 455, in get_phonemes\r\n    phonemes = self._g2p(\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\zh_frontend.py\", line 261, in _g2p\r\n    sub_finals = self.tone_modifier.modified_tone(word, pos,\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\tone_sandhi.py\", line 353, in modified_tone\r\n    finals = self._three_sandhi(word, finals)\r\n  File \"D:\\Program Files\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\tone_sandhi.py\", line 173, in _three_sandhi\r\n    finals[0] = finals[0][:-1] + \"2\"\r\nIndexError: list index out of range\r\n`\r\n",
        "state": "open",
        "user": "ANyyJS",
        "closed_by": null,
        "created_at": "2023-03-04T12:58:41+00:00",
        "updated_at": "2023-05-20T16:19:26+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "ANyyJS",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2994,
        "title": "如何将模型训练后的pdz文件转为pdmodel",
        "body": "## 如何将模型训练后的pdz文件转为pdmodel\r\n训练后得到\r\n![image](https://user-images.githubusercontent.com/68834517/223025316-2ff6857c-cca9-41a3-b865-12ead5835b38.png)\r\n\r\n请问我如何得到hifigan_csmsc.pdmodel",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "yt605155624",
        "created_at": "2023-03-06T05:26:27+00:00",
        "updated_at": "2023-03-06T06:56:09+00:00",
        "closed_at": "2023-03-06T06:56:09+00:00",
        "comments_count": [
            "yt605155624",
            "longRookie"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2995,
        "title": "请问是否可以语音识别粤语?",
        "body": "普通话和语音能否在一个speechserver里面同时部署?\r\n是否需要自己训练吗?\r\n感谢!\r\n\r\n",
        "state": "open",
        "user": "matakk",
        "closed_by": null,
        "created_at": "2023-03-06T06:58:43+00:00",
        "updated_at": "2023-08-04T11:34:56+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "AI-Mart",
            "zxcd"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2997,
        "title": "[TTS] mutiple pause mark in chinese sentences made TTSExecutor killed",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n\r\nTesting txts:\r\n本门晚一辈的，男的是：诸葛警我、岳雯、严人英、金蝉、石生、庄易、林寒、白侠孙南、石奇、赵燕儿、杨鲤、龙力子、七星手施林、神眼邱林、苦孩儿司徒平、铁沙弥悟修、黑孩儿尉迟火、云中鹤周淳、易家双矮易鼎和易震、南海双童甄艮和甄兑、独霸川东李震川、灵和居士徐祥鹅、周云从、商风子、章虎儿、张琪、黄玄极等；女的是：齐灵云和霞儿姊妹、李英琼、余英男、秦紫玲和寒萼姊妹、墨凤凰申若兰、女神童朱文、女殃神郑八姑、周轻云、女空空吴文琪、红娘子余莹姑、女神婴易静、廉红药、凌云凤、裘芷仙、章南姑、郁芳蘅、李文行、万珍、云紫绢、陆蓉波、金萍、赵铁娘，以及由金姥姥罗紫烟转引到本门的女飞熊吴玫、女大鹏崔绮、美仙娃向芳淑等。\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. python code as below:\r\n\r\n    try:\r\n        # tts_executor = TTSExecutor()\r\n        wav_file = tts_executor(\t\\\r\n        text=text,\\\r\n        output=outputpath,\\\r\n        am=model_cfg['am'],\\\r\n        am_config=model_cfg['am_config'], \\\r\n        am_ckpt=model_cfg['am_ckpt'], \\\r\n        am_stat=model_cfg['am_stat'], \\\r\n        spk_id=model_cfg['spk_id'], \\\r\n        phones_dict=model_cfg['phones_dict'], \\\r\n        tones_dict=model_cfg['tones_dict'], \\\r\n        speaker_dict=model_cfg['speaker_dict'], \\\r\n        voc=model_cfg['voc'], \\\r\n        voc_config=model_cfg['voc_config'], \\\r\n        voc_ckpt=model_cfg['voc_ckpt'], \\\r\n        voc_stat=model_cfg['voc_stat'], \\\r\n        lang=model_cfg['lang'], \\\r\n        device=paddle.get_device())\r\n        print(\"@an mixTxt2Wav(),tts_executor\",sys.getsizeof(wav_file))\r\n    except Exception as e :\r\n        print(\"Err Text:\",text)\r\n        os.system(\"echo \\'\"+text+\"\\' >> ./err.log\")\r\n        print(e)\r\n        exit(1)\r\n    print(\"output:\",mp3Filepath)\r\n\r\n**Expected behavior**\r\n expected wav file generated, but it failed as \"killed\"\r\n\r\n**Screenshots**\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "david-95",
        "closed_by": null,
        "created_at": "2023-03-07T05:39:29+00:00",
        "updated_at": "2023-03-07T05:49:55+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2998,
        "title": "[S2T]在AIstudio中安装存在依赖问题",
        "body": "![image](https://user-images.githubusercontent.com/54951765/223350322-513c3784-5191-42aa-a7bb-c13ec9969e66.png)\r\n复现方式：新建一个项目，然后在终端中pip install paddlespeech",
        "state": "closed",
        "user": "kslz",
        "closed_by": "kslz",
        "created_at": "2023-03-07T07:13:19+00:00",
        "updated_at": "2023-03-13T11:56:06+00:00",
        "closed_at": "2023-03-08T03:00:58+00:00",
        "comments_count": [
            "zxcd",
            "DongDongBan",
            "iftaken"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 2999,
        "title": "流式TTS并发多次，但是返回相同的session ID",
        "body": " 大佬，我遇到了一个非常奇怪的现象，和你沟通一下哈。针对流式TTS，我正在自己编写client端和sever端，1）在server端，我仿照tts_api.py 中的 async def websocket_endpoint(websocket: WebSocket)，进行编写，2）client端我仿照 audio_handler.py 中的class TTSWsHandler类 进行改写。\r\n我并发三次，返回情况如下：\r\n![image](https://user-images.githubusercontent.com/22590720/223371985-acb4e925-0c4d-499c-963c-6aa9c0eda2d4.png)\r\n由图片可以看到；\r\n三个session ID 一致，理论上，进行了三次请求，应该是三个session id（session ID 在server端生成，session = uuid.uuid1().hex ）；\r\n我设置并发的代码如下：\r\n![image](https://user-images.githubusercontent.com/22590720/223373066-8b99962a-1898-4923-a1ef-f19c640657b0.png)\r\n麻烦大佬帮忙看一下，这是为什么？\r\n\r\n\r\n",
        "state": "closed",
        "user": "443127316",
        "closed_by": "443127316",
        "created_at": "2023-03-07T09:00:12+00:00",
        "updated_at": "2023-09-21T05:08:40+00:00",
        "closed_at": "2023-03-07T09:47:11+00:00",
        "comments_count": [
            "AnnCY1"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3000,
        "title": "tts 中英混合播报",
        "body": "## tts 中英混合播报\r\n当我在mac M1的机器上，跑cli命令的时候，提示模型不存在。paddlespeech的版本是1.0.1，请问是什么原因呢？\r\n\r\n `\r\npaddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input \"热烈欢迎您在 Discussions 中提交问题，并在 Issues 中指出发现的 bug。此外，我们非常希望您参与到 Paddle Speech 的开发中！\" --spk_id 174 --output mix_spk174.wav\r\n`\r\n\r\nerror：\r\npaddlespeech.tts: error: argument --am: invalid choice: 'fastspeech2_mix' (choose from 'speedyspeech_csmsc', 'fastspeech2_csmsc', 'fastspeech2_ljspeech', 'fastspeech2_aishell3', 'fastspeech2_vctk', 'tacotron2_csmsc', 'tacotron2_ljspeech')",
        "state": "closed",
        "user": "jkluo",
        "closed_by": "jkluo",
        "created_at": "2023-03-07T09:29:35+00:00",
        "updated_at": "2023-03-07T09:51:44+00:00",
        "closed_at": "2023-03-07T09:33:42+00:00",
        "comments_count": [
            "jkluo"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3001,
        "title": "Python3.9.13  安装paddle失败",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n然后发现这个库自2011年就没再更新过了，为什么要依赖这么古老的一个库",
        "state": "closed",
        "user": "Matiz7",
        "closed_by": "Matiz7",
        "created_at": "2023-03-07T09:59:28+00:00",
        "updated_at": "2023-03-08T01:25:41+00:00",
        "closed_at": "2023-03-08T01:25:41+00:00",
        "comments_count": [
            "Matiz7",
            "yt605155624"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3007,
        "title": "韵律预测模型准确率有多少",
        "body": "## General Question",
        "state": "closed",
        "user": "Pydataman",
        "closed_by": "yt605155624",
        "created_at": "2023-03-08T06:34:37+00:00",
        "updated_at": "2023-03-13T03:08:28+00:00",
        "closed_at": "2023-03-13T03:08:28+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3003,
        "title": "流式TTS并发效率问题（CPU）",
        "body": "大佬，您好, 问题如标题，cpu型号为：Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz\r\n1）在server端，我仿照tts_api.py 中的 async def websocket_endpoint(websocket: WebSocket)，进行编写，2）client端我仿照 audio_handler.py 中的class TTSWsHandler类 进行改写。\r\n目前，并发数为2，感觉首包延迟和RTF呈线性增长，cpu使用效率为75%，详细情况如图：\r\n![image](https://user-images.githubusercontent.com/22590720/223420181-3c78e6a4-341c-4969-be79-0c90f5e00470.png)\r\n问题猜测：通过server端的log显示，请求的时候，是并行请求，但是处理任务的时候，可能是串行处理。\r\n请问，在paddle框架中，是否遇到过类似问题，如何解决呢？\r\n\r\n\r\n",
        "state": "closed",
        "user": "443127316",
        "closed_by": "443127316",
        "created_at": "2023-03-07T12:24:53+00:00",
        "updated_at": "2024-07-24T02:22:55+00:00",
        "closed_at": "2023-03-09T03:40:31+00:00",
        "comments_count": [
            "yt605155624",
            "443127316",
            "yt605155624",
            "yt605155624",
            "443127316",
            "443127316",
            "lixf071213",
            "184653090",
            "lixf071213"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3010,
        "title": "请教在aishell3上训练fastspeech2模型的相关问题",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n\r\n最近在aishell3数据集上训练fastspeech2模型的时候，遇到了几个问题想请教一下。\r\n\r\n【说明】声码器是HiFiGAN，batch size为64，MFA使用的是1.x版本，在自己的数据集上训练的mfa模型\r\n\r\n+ 问题1：不论是基于frame-level还是phoneme-level，在duration, energy和pitch上:在大约50k step之后都出现了过拟合现象。从合成的音频来看，100k step后的音频质量要比50k step左右要好的。我觉得是不是因为：1）合成音频的效果还是要看mel spec； 2）pitch、duration和energy即使过拟合，但是loss并没有相差太多，所以效果总体来说还是更好？\r\n+ 问题2：从合成音频的效果来看，我觉得frame-level的效果要比phoneme-level的效果更好，但是开源fastspeech2的作者说phoneme-leve的结果更好\r\n+ 问题3：paddlespeech在训练的时候有出现上面的问题吗？paddlespeech实现的好像也是phoneme-level的模型，是处于什么考虑呢？\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "yangqinj",
        "closed_by": "yt605155624",
        "created_at": "2023-03-09T02:19:40+00:00",
        "updated_at": "2023-08-21T00:38:54+00:00",
        "closed_at": "2023-03-13T03:08:15+00:00",
        "comments_count": [
            "yt605155624",
            "yangqinj",
            "yuxi-chen19"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3009,
        "title": "[TTS]TTS 模型 openvino 部署相关问题汇总",
        "body": "目前，HiFiGAN 可以直接使用 openvino 推理引擎，但是 fastspeech2 缺算子：\r\n- https://github.com/openvinotoolkit/openvino/issues/16153",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-03-09T02:13:11+00:00",
        "updated_at": "2024-06-03T08:58:05+00:00",
        "closed_at": null,
        "comments_count": [
            "junruizh2021"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3011,
        "title": "paddlespeech安装使用问题",
        "body": "Python3.10.9\r\n\r\n## General Question\r\n[2023-03-09 15:32:53,123] [ WARNING] warnings.py:109 - D:\\Python310\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\src\\paddspeech.py\", line 19, in <module>\r\n    text = asr_executor(\r\n  File \"D:\\Python310\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 338, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\nTypeError: ASRExecutor.__call__() got an unexpected keyword argument 'codeswitch'\r\n",
        "state": "closed",
        "user": "Matiz7",
        "closed_by": "zxcd",
        "created_at": "2023-03-09T07:37:00+00:00",
        "updated_at": "2023-03-13T11:34:12+00:00",
        "closed_at": "2023-03-13T11:34:12+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3015
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3022
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3014,
        "title": "🔥 r1.4.0 release note",
        "body": "# T2S\r\n- Add Cantonese TTS. https://github.com/PaddlePaddle/PaddleSpeech/pull/2977\r\n- Add StarGANv2-VC model scripts.  https://github.com/PaddlePaddle/PaddleSpeech/pull/2987\r\n\r\n# S2T\r\n- Add code-switch asr tal_cs recipe. https://github.com/PaddlePaddle/PaddleSpeech/pull/2796 @zxcd \r\n- Add wav2vec2-zh. https://github.com/PaddlePaddle/PaddleSpeech/pull/2916 @zxcd \r\n\r\n# Text\r\n\r\n# Audio\r\n\r\n\r\n# Demo\r\n- Add code-switch asr tal_cs recipe. https://github.com/PaddlePaddle/PaddleSpeech/pull/2816 @zxcd \r\n\r\n# Documentation\r\n\r\n\r\n# Other\r\n\r\n\r\n# Acknowledgements\r\nSpecial thanks to @lizezheng @zh794390558 @SmileGoat @yt605155624  @zxcd  @WongLaw @lym0302 ",
        "state": "closed",
        "user": "zxcd",
        "closed_by": "zxcd",
        "created_at": "2023-03-10T03:00:43+00:00",
        "updated_at": "2023-03-10T03:06:55+00:00",
        "closed_at": "2023-03-10T03:06:55+00:00",
        "comments_count": [],
        "labels": [
            "Documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3013,
        "title": "[Docker-Server-ASR] declarative() got an unexpected keyword argument 'property'",
        "body": "## 本问题和 #2512 很像，但未能解决\r\n\r\n\r\n### 安装环境\r\n用容器进行安装，容器来源：https://hub.docker.com/r/paddlecloud/paddlespeech/tags\r\n安装的tags：[develop-cpu-latest](https://hub.docker.com/layers/paddlecloud/paddlespeech/develop-cpu-latest/images/sha256-34fd00523078cfbba00e4540a2cbd971917cb333510ba164d3110fcec9ad476f?context=explore)\r\n\r\n### 创建容器命令\r\n`docker run --network host --name speech-asr -v /home/yuyi/SpeechServer/docker:/mnt -it paddlecloud/paddlespeech:develop-cpu-latest  /bin/bash`\r\n\r\n### 开启服务\r\n\r\n1. `cd /home/PaddleSpeech/demos/speech_server`\r\n\r\n2. `./server.sh`\r\n> 在开启服务前，参考 [#2387](https://github.com/PaddlePaddle/PaddleSpeech/issues/2387) 已修改 log 等级获取更多信息\r\n\r\n\r\n### 错误日志\r\n[2023-03-09 22:55:38,952] [    INFO] - start to init the engine\r\n[2023-03-09 22:55:38,953] [    INFO] - asr : python engine.\r\n[2023-03-09 22:55:39,036] [   DEBUG] - start to init the model\r\n[2023-03-09 22:55:39,036] [   DEBUG] - File /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/1.0/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar.gz md5 checking...\r\n[2023-03-09 22:55:44,661] [   DEBUG] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/1.0/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar\r\n[2023-03-09 22:55:44,661] [   DEBUG] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/1.0/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/model.yaml\r\n[2023-03-09 22:55:44,661] [   DEBUG] - /root/.paddlespeech/models/conformer_wenetspeech-zh-16k/1.0/asr1_conformer_wenetspeech_ckpt_0.1.1.model.tar/exp/conformer/checkpoints/wenetspeech.pdparams\r\n[2023-03-09 22:55:45,028] [   ERROR] - Failed to start server.\r\n[2023-03-09 22:55:45,028] [   ERROR] - declarative() got an unexpected keyword argument 'property'",
        "state": "closed",
        "user": "itsyuyi",
        "closed_by": "itsyuyi",
        "created_at": "2023-03-09T23:22:43+00:00",
        "updated_at": "2023-03-10T03:53:32+00:00",
        "closed_at": "2023-03-10T03:53:32+00:00",
        "comments_count": [
            "itsyuyi"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3017,
        "title": "为什么我训练的声音克隆模型生成的声音是数据集里的人声，不是参考文件夹里的wav文件的人声呢？ /example/aishell3/vc1/",
        "body": "其中am_ckpt是我迁移学习训练出来的单人模型，voc_ckpt是下载的预训练模型。同时我还有个疑问：voc_ckpt是需要我迁移学习吗？还是直接就用下载的预训练权重呢，readme在这点没有说明。\r\n![image](https://user-images.githubusercontent.com/95894804/224256640-cf15f16e-a7de-4a86-93e9-6b6e2270c6ab.png)\r\n",
        "state": "closed",
        "user": "Vebrun",
        "closed_by": "yt605155624",
        "created_at": "2023-03-10T07:55:37+00:00",
        "updated_at": "2023-05-18T05:18:04+00:00",
        "closed_at": "2023-03-13T03:03:51+00:00",
        "comments_count": [
            "yt605155624",
            "ben-8878"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3016,
        "title": "能否对字母数字混合的文本进行语音合成？",
        "body": "我有一段文本是字母数字混合的，例如A1234B567C89这种，我希望字母采用英文发音，数字采用中文发音，该如何实现呢？",
        "state": "closed",
        "user": "0-Maxwei-0",
        "closed_by": "0-Maxwei-0",
        "created_at": "2023-03-10T06:08:55+00:00",
        "updated_at": "2023-03-10T08:27:57+00:00",
        "closed_at": "2023-03-10T08:27:57+00:00",
        "comments_count": [
            "yt605155624",
            "0-Maxwei-0"
        ],
        "labels": [
            "Question",
            "T2S",
            "duplicate"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3020,
        "title": "tts_finetune的readme流程执行报错，提示'get mfa result'时'lack of features'是什么原因？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n简述：\r\n工作目录 `(paddle_env) root@ubuntu-desktop:~/PaddleSpeech/examples/other/tts_finetune/tts3#`\r\n参考tts_finetune的[readme](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3)，测试中文微调。只下载、准备与中文训练（微调）相关的数据。执行`run.sh`后报错。经调试推测问题出在`get mfa result`步骤，但具体原因就找不到了，无奈。\r\n\r\n主要日志：\r\n```\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 198.0\r\n...\r\nSetting up training data...\r\nCalculating MFCCs...\r\nSome utterances were ignored due to lack of features, please see /root/Documents/MFA/newdir/logging/corpus.log for more information.\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 0.0\r\n...\r\nAssertionError: This dataset has no examples\r\n```\r\n数据集中有200条数据，这里第一次能识别到 utterances 的数量为 198，但第二次识别不到。\r\n最终导致`AssertionError`错误。\r\n\r\n其他程序运行日志：\r\n```\r\n(paddle_env) root@ubuntu-desktop:~/PaddleSpeech/examples/other/tts_finetune/tts3# ./run.sh\r\ncheck oov\r\nget mfa result\r\nDEBUG >>> python3 local/get_mfa_result.py --input_dir=./input/csmsc_mini/newdir --mfa_dir=./mfa_result --lang=zh\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 198.0\r\n/root/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nCreating dictionary information...\r\nSetting up training data...\r\nCalculating MFCCs...\r\nSome utterances were ignored due to lack of features, please see /root/Documents/MFA/newdir/logging/corpus.log for more information.\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 0.0\r\nDone with setup.\r\n100%|#################################################################################################| 2/2 [00:01<00:00,  1.05it/s]\r\nDone! Everything took 8.438562870025635 seconds\r\ngenerate durations.txt\r\nextract feature\r\n/root/anaconda3/envs/paddle_env/lib/python3.10/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n196 1\r\n100%|██████████████████████████████████████████████████████████████████████████████████████████| 196/196 [00:00<00:00, 18817.58it/s]\r\nDone\r\nTraceback (most recent call last):\r\n  File \"/root/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 346, in <module>\r\n    extract_feature(\r\n  File \"/root/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 266, in extract_feature\r\n    normalize(speech_scaler, pitch_scaler, energy_scaler, vocab_phones,\r\n  File \"/root/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 155, in normalize\r\n    dataset = DataTable(\r\n  File \"/root/PaddleSpeech/paddlespeech/t2s/datasets/data_table.py\", line 45, in __init__\r\n    assert len(data) > 0, \"This dataset has no examples\"\r\nAssertionError: This dataset has no examples\r\n```\r\n\r\n/root/Documents/MFA/newdir/logging/corpus.log\r\n```\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 198.0\r\nSetting up training data...\r\nThe following utterances were ignored due to lack of features: 000001, 000002, 000003, 000004, 000005, 000006, 000007, 000008, 000009, 000010, 000011, 000012, 000013, 000014, 000015, 000016, 000017, 000018, 000019, 000020, 000021, 000022, 000023, 000024, 000025, 000026, 000027, 000028, 000030, 000031, 000032, 000033, 000034, 000035, 000036, 000037, 000038, 000039, 000040, 000041, 000042, 000043, 000044, 000045, 000046, 000047, 000048, 000049, 000050, 000051, 000052, 000053, 000054, 000055, 000056, 000057, 000058, 000059, 000060, 000061, 000062, 000063, 000064, 000065, 000066, 000067, 000068, 000069, 000070, 000071, 000072, 000073, 000074, 000075, 000076, 000077, 000078, 000079, 000080, 000081, 000082, 000083, 000084, 000085, 000086, 000087, 000088, 000089, 000090, 000091, 000092, 000093, 000094, 000095, 000096, 000097, 000098, 000099, 000100, 000101, 000102, 000103, 000104, 000105, 000106, 000107, 000108, 000109, 000110, 000111, 000112, 000113, 000114, 000115, 000116, 000117, 000118, 000119, 000120, 000121, 000122, 000123, 000124, 000125, 000126, 000127, 000128, 000129, 000130, 000131, 000132, 000133, 000134, 000135, 000136, 000137, 000138, 000139, 000140, 000141, 000142, 000143, 000144, 000145, 000146, 000147, 000148, 000149, 000150, 000151, 000152, 000153, 000154, 000155, 000156, 000157, 000158, 000159, 000160, 000161, 000162, 000163, 000164, 000165, 000166, 000167, 000168, 000169, 000170, 000171, 000172, 000173, 000174, 000175, 000176, 000177, 000178, 000179, 000180, 000181, 000182, 000183, 000184, 000185, 000186, 000187, 000188, 000189, 000190, 000191, 000192, 000193, 000194, 000196, 000197, 000198, 000199, 000200.  See relevant logs for more information\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 0.0\r\n```\r\n\r\n操作系统： ubuntu 18.04\r\n源码版本： r1.3.0\r\nPython 3.10.9\r\nPaddlePaddle 2.4.1\r\nmfa: binary v1.0.1",
        "state": "closed",
        "user": "zhaolibo1989",
        "closed_by": "zhaolibo1989",
        "created_at": "2023-03-10T11:49:57+00:00",
        "updated_at": "2024-07-08T08:38:39+00:00",
        "closed_at": "2023-03-21T06:15:59+00:00",
        "comments_count": [
            "yt605155624",
            "zhaolibo1989",
            "zhaolibo1989",
            "zhaolibo1989",
            "zhaolibo1989",
            "maize-j"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3021,
        "title": "[TTS] 导出ONNX模型，推理代码报错",
        "body": "我微调了fastspeech2_mix模型，paddle2onnx导出了一个onnx模型\r\n然后我照着这个教程里的onnx推理代码运行的时候，报错\r\n\r\n> Traceback (most recent call last):\r\n  File \"/remote-home/share/jzhan/EN-ZH-TTS/SpeechClone/inference_onnx.py\", line 44, in <module>\r\n    wav = inference(text)\r\n  File \"/remote-home/share/jzhan/EN-ZH-TTS/SpeechClone/inference_onnx.py\", line 34, in inference\r\n    am_output_data = am_infer_sess.run(None, input_feed={'text': phone_ids[0].numpy()})\r\n  File \"/usr/local/lib/python3.7/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 196, in run\r\n    raise ValueError(\"Model requires {} inputs. Input Feed contains {}\".format(num_required_inputs, num_inputs))\r\nValueError: Model requires 2 inputs. Input Feed contains 1\r\n\r\n是我哪一步出了问题？",
        "state": "closed",
        "user": "JunZhan2000",
        "closed_by": "JunZhan2000",
        "created_at": "2023-03-11T18:00:00+00:00",
        "updated_at": "2023-03-12T08:44:29+00:00",
        "closed_at": "2023-03-12T08:44:29+00:00",
        "comments_count": [
            "JunZhan2000"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3024,
        "title": "关于fs2的帧级别和音素级别",
        "body": "## General Question\r\n有几个问题，如下：\r\n1.这里的fastspeech2模型实现中关于pitch和energy使用的是帧级别还是音素级别特征啊，并且是否进行了normalization？\r\n2.我在另一个fs2项目基础上使用了帧级别和音素级别用中文数据集进行了实验（那个项目没人维护了...），发现音素级别+nz效果最好，其它的效果都不太好，如帧级别、帧级别+nz、音素级别，或多或少都有问题，如杂音、声音失真、错误的汉字发音（发音为其它汉字），不知道是本身对于中文数据效果不太好，还是MFA对齐不够准确，又或者是其它问题，不知道你们是否进行了类似的实验吗？\r\n",
        "state": "closed",
        "user": "hhm853610070",
        "closed_by": "yt605155624",
        "created_at": "2023-03-13T05:34:11+00:00",
        "updated_at": "2023-03-21T07:58:18+00:00",
        "closed_at": "2023-03-21T07:58:18+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3029,
        "title": "TTS推理接口无法指定gpu id",
        "body": "用docker安装的paddlespeech，paddlespeech/t2s/exps/syn_utils.py的get_predictor函数里没有device_id参数，默认用了GPU 0。。\r\n<img width=\"718\" alt=\"image\" src=\"https://user-images.githubusercontent.com/43952592/224693208-47596d5a-c3cc-4120-9ef2-9573d280e2ff.png\">\r\n\r\n而最新的github里的源码里是有的\r\n（docker安装）\r\n<img width=\"816\" alt=\"image\" src=\"https://user-images.githubusercontent.com/43952592/224693489-59eebb23-bac3-41e3-bec2-b7dac01ff398.png\">\r\n（源码安装）\r\n<img width=\"510\" alt=\"image\" src=\"https://user-images.githubusercontent.com/43952592/224693684-2761e37a-ba58-4c9f-b9ae-107f79fc9ac3.png\">\r\n\r\n\r\n用docker安装后，指定不了gpu，这会让人很困扰\r\n",
        "state": "closed",
        "user": "JunZhan2000",
        "closed_by": "yt605155624",
        "created_at": "2023-03-13T11:47:18+00:00",
        "updated_at": "2023-03-14T04:14:18+00:00",
        "closed_at": "2023-03-14T04:14:17+00:00",
        "comments_count": [
            "JunZhan2000",
            "yt605155624"
        ],
        "labels": [
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3032,
        "title": "[TTS] Fastspeech2训练与推断不一致",
        "body": "现有的实现转换为固定文本长度推理时发现的\r\n包含conv1d的ffn 与  pitch predictor 这些均有这个问题  \r\n\r\n训练是都是在批数据上pad  第一层transformer layer没问题但是经过第一层之后所有的pad位置都是有数值的 第二层进行conv1d时有效长度边缘之外的值就不是0了 而推理时因为长度是有效长度 有效长度外的conv1d是pad为0的 ",
        "state": "closed",
        "user": "sdli1995",
        "closed_by": "yt605155624",
        "created_at": "2023-03-14T05:25:56+00:00",
        "updated_at": "2023-03-21T07:58:42+00:00",
        "closed_at": "2023-03-21T07:58:42+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3033,
        "title": "Why is there conformer model not available for english/librispeech while running the asr inference?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-03-14T06:14:00+00:00",
        "updated_at": "2023-03-22T03:23:13+00:00",
        "closed_at": "2023-03-22T03:23:13+00:00",
        "comments_count": [
            "zxcd",
            "khushbookk",
            "zxcd",
            "khushbookk",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3036,
        "title": "[TTS] TTS Android Demo 调用 C++ 前端实现自定义输入的语音合成",
        "body": "通过 JNI 为 [TTS Android Demo](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSAndroid) 增加 [TTSCppFrontend](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSCppFrontend)\r\n\r\n@SwimmingTiger \r\n\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "zxcd",
        "created_at": "2023-03-14T07:49:39+00:00",
        "updated_at": "2025-06-03T09:15:45+00:00",
        "closed_at": "2025-06-03T09:15:44+00:00",
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3035,
        "title": "[TTS] C++ 前端崩溃测试用例",
        "body": "记录一些导致[C++前端](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSCppFrontend)崩溃的示例文本：\r\n\r\n1. 包含字母，断言异常。\r\n\r\n```\r\n./run_front_demo.sh --sentence 'TTS语音合成服务'\r\n```\r\n\r\n```\r\ntts_front_demo: /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:358: int ppspeech::FrontEngineInterface::GetInitialsFinals(const string&, std::vector<std::__cxx11::basic_string<char> >&, std::vector<std::__cxx11::basic_string<char> >&): Assertion `word_finals.size() == ppspeech::utf8string2wstring(word).length() && word_finals.size() == word_initials.size()' failed.\r\n```\r\n\r\n2. 字母在结尾，内存越界。\r\n\r\n```\r\n./run_front_demo.sh --sentence '语音合成服务a'\r\n\r\n# 调试\r\ngdb ./build/tts_front_demo -ex \"set args --sentence '语音合成服务a'\"\r\n```\r\n\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n(gdb) bt\r\n#0  __memcpy_generic () at ../sysdeps/aarch64/multiarch/../memcpy.S:100\r\n#1  0x0000007ff7fa8db0 in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*, std::forward_iterator_tag) () from /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/third-party/build/lib/libgflags.so.2.2\r\n#2  0x000000555558c500 in __gnu_cxx::new_allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::construct<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&> (this=0x7fffffeb18, __p=0x555ac91430) at /usr/include/c++/9/ext/new_allocator.h:146                                                                                                                                                                            \r\n#3  0x0000005555584ecc in std::allocator_traits<std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::construct<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&> (__a=..., __p=0x555ac91430) at /usr/include/c++/9/bits/alloc_traits.h:483                                                                                                                                                                        \r\n#4  0x000000555557f010 in std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::push_back (this=0x7fffffeb18, \r\n    __x=<error: Cannot access memory at address 0xff1f0000ff1b>) at /usr/include/c++/9/bits/stl_vector.h:1189\r\n#5  0x000000555556dd48 in ppspeech::FrontEngineInterface::GetInitialsFinals (this=0x5555638350, word=\"a\", word_initials=std::vector of length 1, capacity 1 = {...}, word_finals=std::vector of length 0, capacity 2)\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:349\r\n#6  0x000000555556df58 in ppspeech::FrontEngineInterface::GetFinals (this=0x5555638350, word=\"a\", word_finals=std::vector of length 0, capacity 2) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:366\r\n#7  0x000000555556ef30 in ppspeech::FrontEngineInterface::MergeThreeTones (this=0x5555638350, seg_result=std::vector of length 4, capacity 4 = {...}) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:512\r\n#8  0x000000555556ff34 in ppspeech::FrontEngineInterface::MergeforModify (this=0x5555638350, seg_word_type=std::vector of length 4, capacity 4 = {...}, modify_seg_word_type=std::vector of length 4, capacity 4 = {...})\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:634\r\n#9  0x000000555556d4f8 in ppspeech::FrontEngineInterface::Cut (this=0x5555638350, sentence=\"语音合成服务a\", cut_result=std::vector of length 4, capacity 4 = {...}) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:269\r\n#10 0x000000555556cc70 in ppspeech::FrontEngineInterface::GetSentenceIds (this=0x5555638350, sentence=\"语音合成服务a\", phoneids=std::vector of length 0, capacity 0, toneids=std::vector of length 0, capacity 0)\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:183\r\n#11 0x00000055555603b4 in main (argc=1, argv=0x7ffffff288) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/front_demo/front_demo.cpp:53\r\n```\r\n\r\n3. 包含空格，内存越界。\r\n\r\n```\r\n./run_front_demo.sh --sentence '语音合成 服务'\r\ngdb ./build/tts_front_demo -ex \"set args --sentence '语音合成 服务'\"\r\n```\r\n\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n__memcpy_generic () at ../sysdeps/aarch64/multiarch/../memcpy.S:100\r\n(gdb) bt\r\n#0  __memcpy_generic () at ../sysdeps/aarch64/multiarch/../memcpy.S:100\r\n#1  0x0000007ff7fa8db0 in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*, std::forward_iterator_tag) () from /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/third-party/build/lib/libgflags.so.2.2\r\n#2  0x000000555558c500 in __gnu_cxx::new_allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::construct<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&> (this=0x7fffffeb18, __p=0x555ac91430) at /usr/include/c++/9/ext/new_allocator.h:146                                                                                                                                                                            \r\n#3  0x0000005555584ecc in std::allocator_traits<std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::construct<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&> (__a=..., __p=0x555ac91430) at /usr/include/c++/9/bits/alloc_traits.h:483                                                                                                                                                                        \r\n#4  0x000000555557f010 in std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::push_back (this=0x7fffffeb18, \r\n    __x=<error: Cannot access memory at address 0xff1f0000ff1b>) at /usr/include/c++/9/bits/stl_vector.h:1189\r\n#5  0x000000555556dd48 in ppspeech::FrontEngineInterface::GetInitialsFinals (this=0x5555638350, word=\" \", word_initials=std::vector of length 1, capacity 1 = {...}, word_finals=std::vector of length 0, capacity 2)\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:349\r\n#6  0x000000555556df58 in ppspeech::FrontEngineInterface::GetFinals (this=0x5555638350, word=\" \", word_finals=std::vector of length 0, capacity 2) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:366\r\n#7  0x000000555556ef30 in ppspeech::FrontEngineInterface::MergeThreeTones (this=0x5555638350, seg_result=std::vector of length 4, capacity 4 = {...}) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:512\r\n#8  0x000000555556ff34 in ppspeech::FrontEngineInterface::MergeforModify (this=0x5555638350, seg_word_type=std::vector of length 4, capacity 4 = {...}, modify_seg_word_type=std::vector of length 4, capacity 4 = {...})\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:634\r\n#9  0x000000555556d4f8 in ppspeech::FrontEngineInterface::Cut (this=0x5555638350, sentence=\"语音合成 服务\", cut_result=std::vector of length 4, capacity 4 = {...}) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:269\r\n#10 0x000000555556cc70 in ppspeech::FrontEngineInterface::GetSentenceIds (this=0x5555638350, sentence=\"语音合成 服务\", phoneids=std::vector of length 0, capacity 0, toneids=std::vector of length 0, capacity 0)\r\n    at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/src/front/front_interface.cpp:183\r\n#11 0x00000055555603b4 in main (argc=1, argv=0x7ffffff288) at /home/firefly/work/tts/PaddleSpeech/demos/TTSCppFrontend/front_demo/front_demo.cpp:53\r\n```\r\n\r\n遇到其他情况时会继续追加。",
        "state": "open",
        "user": "SwimmingTiger",
        "closed_by": null,
        "created_at": "2023-03-14T07:13:17+00:00",
        "updated_at": "2023-11-16T08:53:18+00:00",
        "closed_at": null,
        "comments_count": [
            "jonkxdd",
            "tuotuoshao"
        ],
        "labels": [
            "Bug",
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3034,
        "title": "Why do asr give less accurate results for longer length audios?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-03-14T06:34:48+00:00",
        "updated_at": "2023-03-15T11:06:02+00:00",
        "closed_at": "2023-03-15T11:06:02+00:00",
        "comments_count": [
            "zxcd",
            "khushbookk",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3037,
        "title": "[TTS] 💡TTS 端上部署信息汇总",
        "body": "TTS Android Demo 链接:\r\n  - https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSAndroid\r\n\r\n包含中文文本前端的 TTS Arm Linux C++ 推理 Demo 链接: \r\n  - https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/TTSArmLinux 感谢 @老虎会游泳 的贡献\r\n\r\n相关 issue 参考【TTS Android Demo 相关】:\r\n  - https://github.com/PaddlePaddle/PaddleSpeech/issues/2576 \r\n\r\n**重点 issue** 多说话人 Andorid demo\r\n  - https://github.com/PaddlePaddle/PaddleSpeech/issues/2933\r\n\r\n目前 TTS Arm Linux C++ 推理 Demo 包含中文文本前端，TTS Android Demo 暂时不包含，但是可以参考 TTS Arm Linux C++ 推理 Demo 交叉编译后调用\r\n\r\n**阉割版 cpp 前端: ***\r\n - 中文前端 https://github.com/lym0302/paddlespeech_tts_cpp 感谢 @SwimmingTiger 新增了 CMakeLists.txt\r\n - 英文 g2p https://github.com/yazone/g2pE_mobile\r\n\r\n端上部署需要考虑内存问题，比如 pwgan 直接跑内存会爆，需要对输入分块，低端硬件推荐使用【流式语音合成】否则内存大概率无法支持。 感谢 @宗武 的经验\r\n\r\n对 PaddleSpeech TTS Android Demo 的改进，实现了中英文混合模型的推理和中英文混合 c++ 前端（含流式播放）:\r\n  - https://github.com/sheng895/androidtts 感谢开源\r\n\r\n据说要开源流式推理部分，坐等:\r\n  - https://github.com/yazone/OfflineTTS\r\n\r\n群聊二维码\r\n<img width=\"251\" alt=\"image\" src=\"https://user-images.githubusercontent.com/24568452/224934941-828793f7-7120-4c67-bc18-fb4463306e50.png\">\r\n",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-03-14T08:04:48+00:00",
        "updated_at": "2024-05-20T02:44:17+00:00",
        "closed_at": null,
        "comments_count": [
            "Xsx93",
            "vinint",
            "ChengsongLu",
            "ChengsongLu",
            "ChengsongLu",
            "yt605155624",
            "Crazy-MT",
            "Binkcn",
            "wytyl13"
        ],
        "labels": [
            "T2S",
            "Tips"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3044,
        "title": "No module named '_soundfile_data'",
        "body": "  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/soundfile.py\", line 161, in <module>\r\n    import _soundfile_data  # ImportError if this doesn't exist\r\nModuleNotFoundError: No module named '_soundfile_data'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/soundfile.py\", line 170, in <module>\r\n    raise OSError('sndfile library not found using ctypes.util.find_library')\r\nOSError: sndfile library not found using ctypes.util.find_library\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/workspace/sherpa/bin/pruned_transducer_statelessX/Server.py\", line 76, in infer\r\n    result['return'],result['result'] = od.predict([infer_path], self.cfg, self.writer)\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/workspace/sherpa/bin/pruned_transducer_statelessX/offline_detected.py\", line 398, in predict\r\n    result,word=deal_result(sound,wav,speech_timestamps,offline_asr,cfg,writer)\r\n  File \"/workspace/sherpa/bin/pruned_transducer_statelessX/result_process.py\", line 148, in deal_result\r\n    word=punctuation_restoration(word,save_path,writer)\r\n  File \"/workspace/sherpa/bin/pruned_transducer_statelessX/result_process.py\", line 76, in punctuation_restoration\r\n    from paddlespeech.cli.text.infer import TextExecutor\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/home/anaconda3/envs/autoasr/lib/python3.8/site-packages/soundfile.py\", line 192, in <module>\r\n    _snd = _ffi.dlopen(_explicit_libname)\r\nOSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory\r\n",
        "state": "closed",
        "user": "KajiMaCN",
        "closed_by": "KajiMaCN",
        "created_at": "2023-03-15T02:39:42+00:00",
        "updated_at": "2023-04-20T07:15:14+00:00",
        "closed_at": "2023-04-11T02:45:47+00:00",
        "comments_count": [
            "zxcd",
            "KajiMaCN",
            "zxcd",
            "moseranliunian",
            "KajiMaCN"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3045,
        "title": "训练一个英文字母识别的模型时，模型测试识别结果没有一个正确的",
        "body": "你好，我想训练一个英文字母识别的U2模型, 以下时我的配置：\r\nchunk_conformer.yaml：\r\n############################################\r\n#           Network Architecture           #\r\n############################################\r\ncmvn_file: \r\ncmvn_file_type: \"json\"\r\n# encoder related\r\nencoder: conformer\r\nencoder_conf:\r\n    output_size: 256    # dimension of attention\r\n    attention_heads: 4\r\n    linear_units: 2048  # the number of units of position-wise feed forward\r\n    num_blocks: 12      # the number of encoder blocks\r\n    dropout_rate: 0.1   # sublayer output dropout\r\n    positional_dropout_rate: 0.1\r\n    attention_dropout_rate: 0.0\r\n    input_layer: conv2d # encoder input type, you can chose conv2d, conv2d6 and conv2d8\r\n    normalize_before: True\r\n    cnn_module_kernel: 15\r\n    use_cnn_module: True\r\n    activation_type: 'swish'\r\n    pos_enc_layer_type: 'rel_pos'\r\n    selfattention_layer_type: 'rel_selfattn'\r\n    causal: true\r\n    use_dynamic_chunk: true\r\n    cnn_module_norm: 'layer_norm' # using nn.LayerNorm makes model converge faster\r\n    use_dynamic_left_chunk: false\r\n# decoder related\r\ndecoder: transformer\r\ndecoder_conf:\r\n    attention_heads: 4\r\n    linear_units: 2048\r\n    num_blocks: 6\r\n    dropout_rate: 0.1  # sublayer output dropout\r\n    positional_dropout_rate: 0.1\r\n    self_attention_dropout_rate: 0.0\r\n    src_attention_dropout_rate: 0.0\r\n# hybrid CTC/attention\r\nmodel_conf:\r\n    ctc_weight: 0.3\r\n    lsm_weight: 0.1     # label smoothing option\r\n    length_normalized_loss: false\r\n    reverse_weight: 0.0\r\n    init_type: 'kaiming_uniform' \r\n\r\n###########################################\r\n#                   Data                  #\r\n###########################################\r\n\r\ntrain_manifest: data/manifest.train\r\ndev_manifest: data/manifest.dev\r\ntest_manifest: data/manifest.test\r\n\r\n\r\n###########################################\r\n#              Dataloader                 #\r\n###########################################\r\n\r\nvocab_filepath: data/lang_char/vocab.txt \r\nspm_model_prefix: 'data/lang_char/bpe_bpe_56'\r\nunit_type: 'spm'\r\npreprocess_config: conf/preprocess.yaml\r\nfeat_dim: 80\r\nstride_ms: 10.0\r\nwindow_ms: 25.0\r\nsortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs \r\nbatch_size: 32\r\nmaxlen_in: 512  # if input length  > maxlen-in, batchsize is automatically reduced\r\nmaxlen_out: 150  # if output length > maxlen-out, batchsize is automatically reduced\r\nminibatches: 0 # for debug\r\nbatch_count: auto\r\nbatch_bins: 0\r\nbatch_frames_in: 0\r\nbatch_frames_out: 0\r\nbatch_frames_inout: 0\r\nnum_workers: 0\r\nsubsampling_factor: 1\r\nnum_encs: 1\r\n\r\n###########################################\r\n#                 Training                #\r\n###########################################\r\nn_epoch: 1000 \r\naccum_grad: 32\r\nglobal_grad_clip: 5.0\r\ndist_sampler: True\r\noptim: adam\r\noptim_conf:\r\n  lr: 0.001\r\n  weight_decay: 1.0e-6\r\nscheduler: warmuplr\r\nscheduler_conf:\r\n  warmup_steps: 25000\r\n  lr_decay: 1.0\r\nlog_interval: 100\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\n\r\ndata.sh\r\n#!/bin/bash\r\nstage=-1\r\nstop_stage=100\r\ndict_dir=data/lang_char\r\n\r\n# bpemode (unigram or bpe)\r\nnbpe=56\r\nbpemode=bpe\r\nbpeprefix=\"${dict_dir}/bpe_${bpemode}_${nbpe}\"\r\n\r\nstride_ms=20\r\nwindow_ms=30\r\nsample_rate=16000\r\nfeat_dim=80\r\n\r\nsource ${MAIN_ROOT}/utils/parse_options.sh\r\n\r\n\r\nmkdir -p data\r\nmkdir -p ${dict_dir}\r\nTARGET_DIR=${MAIN_ROOT}/dataset\r\nmkdir -p ${TARGET_DIR}\r\n\r\n#prepare data\r\nif [ ${stage} -le -1 ] && [ ${stop_stage} -ge -1 ]; then\r\n    if [ ! -d \"${MAIN_ROOT}/dataset/alphabet_data/alphabet\" ]; then\r\n        echo \"${MAIN_ROOT}/dataset/alphabet_data/alphabet does not exist. Please donwload alphabet data first.\"\r\n        exit\r\n    fi\r\n    # create manifest json file \r\n    python ${MAIN_ROOT}/dataset/alphabet_data/alphabet_cs.py --target_dir ${MAIN_ROOT}/dataset/alphabet_data/alphabet/ --manifest_prefix data/\r\nfi\r\n\r\nif [ ${stage} -le 0 ] && [ ${stop_stage} -ge 0 ]; then\r\n    # compute mean and stddev for normalizer\r\n    num_workers=$(nproc)\r\n    python3 ${MAIN_ROOT}/utils/compute_mean_std.py \\\r\n    --manifest_path=\"data/manifest.train.raw\" \\\r\n    --num_samples=-1 \\\r\n    --spectrum_type=\"fbank\" \\\r\n    --feat_dim=${feat_dim}  \\\r\n    --delta_delta=false \\\r\n    --sample_rate=${sample_rate} \\\r\n    --stride_ms=${stride_ms} \\\r\n    --window_ms=${window_ms} \\\r\n    --use_dB_normalization=False \\\r\n    --num_workers=${num_workers} \\\r\n    --output_path=\"data/mean_std.json\"\r\n    echo \"compute mean and stddev done.\"\r\nfi\r\n\r\nif [ ${stage} -le 1 ] && [ ${stop_stage} -ge 1 ]; then\r\n    #use train_set build dict\r\n    python3 ${MAIN_ROOT}/utils/build_vocab.py \\\r\n    --unit_type 'spm' \\\r\n    --count_threshold=0 \\\r\n    --vocab_path=\"${dict_dir}/vocab.txt\"  \\\r\n    --manifest_paths=\"data/manifest.train.raw\"  \\\r\n    --spm_mode=${bpemode} \\\r\n    --spm_vocab_size=${nbpe}  \\\r\n    --spm_model_prefix=${bpeprefix} \\\r\n    --spm_character_coverage=1 \r\n    echo \"build dict done.\"\r\nfi\r\n\r\n#use new dict format data\r\nif [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then\r\n    # format manifest with tokenids, vocab size\r\n    for sub in train dev test ; do\r\n    {\r\n        python3 ${MAIN_ROOT}/utils/format_data.py \\\r\n        --cmvn_path \"data/mean_std.json\" \\\r\n        --unit_type \"spm\" \\\r\n        --spm_model_prefix ${bpeprefix} \\\r\n        --vocab_path=\"${dict_dir}/vocab.txt\" \\\r\n        --manifest_path=\"data/manifest.${sub}.raw\" \\\r\n        --output_path=\"data/manifest.${sub}\"\r\n\r\n        if [ $? -ne 0 ]; then\r\n            echo \"Formt mnaifest failed. Terminated.\"\r\n            exit 1\r\n        fi\r\n    }&\r\n    done\r\n    wait\r\n    echo \"format data done.\"\r\nfi\r\n\r\n数据是自己录得英文字母拼读音频，label.txt的结构是这样的：\r\nabcd\ta b c d\r\nalter\ta l t e r\r\napple\ta p p l e\r\nazxs\ta z x s\r\nbacteria\tb a c t e r i a\r\nbcd\tb c d\r\nblast\tb l a s t\r\nbreed\tb r e e d\r\nbudget\tb u d g e t\r\nburst\tb u r s t\r\ncampus\tc a m p u s\r\ncandidate\tc a n d i d a t e\r\nconsume\tc o n s u m e\r\ndergbnm\td e r g b n m\r\ndfhgh\td f h g h\r\ndfhji\td f h j i\r\ndispose\td i s p o s e\r\n\r\n但最后测试的结果如下：\r\n| Model | Params | Config | Augmentation| Test set | Decode method | Loss | MER |  \r\n| --- | --- | --- | --- | --- | --- | --- | --- |\r\n| conformer | 47.63 M | conf/conformer.yaml | spec_aug | test-set | attention | 9.85091028213501 | 0.102786 |  \r\n| conformer | 47.63 M | conf/conformer.yaml | spec_aug | test-set | ctc_greedy_search | 9.85091028213501 | 0.103538 |  \r\n| conformer | 47.63 M | conf/conformer.yaml | spec_aug | test-set | ctc_prefix_beam_search | 9.85091028213501 | 0.103317 |  \r\n| conformer | 47.63 M | conf/conformer.yaml | spec_aug | test-set | attention_rescoring | 9.85091028213501 | 0.084374 |  \r\n\r\n几乎没有正确的：\r\n![image](https://user-images.githubusercontent.com/15813182/225192780-3c7b5916-f029-4f66-9092-3ee5963b5a57.png)\r\n\r\n这是什么原因？ 无论是spm还是char类型的都试了，也是一样的效果。\r\n是参数配置的问题？",
        "state": "open",
        "user": "upcmb",
        "closed_by": null,
        "created_at": "2023-03-15T02:52:39+00:00",
        "updated_at": "2023-05-20T16:19:25+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3048,
        "title": "中文语音识别",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n哪位大佬能科普一下中文语音识别是怎么编码的？英文中26个英文字母+一些标点，中文是怎么做的呢？我跑提供的语音识别demo看到log文件里有5000多个字的字典，中文在训练的时候也用这么大的字典吗？这个字典在代码里哪里能找到？",
        "state": "closed",
        "user": "shudong-zhang",
        "closed_by": "shudong-zhang",
        "created_at": "2023-03-15T06:10:16+00:00",
        "updated_at": "2023-03-15T09:22:20+00:00",
        "closed_at": "2023-03-15T09:22:19+00:00",
        "comments_count": [
            "zxcd",
            "shudong-zhang",
            "zxcd",
            "shudong-zhang"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3051,
        "title": "ImportError: cannot import name 'check_argument_types' from 'typeguard'",
        "body": "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/sparse/sputils.py:16: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\r\n  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/linalg/__init__.py:217: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\r\n  from numpy.dual import register_func\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/.data/webide/pip/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/cli/text/__init__.py\", line 14, in <module>\r\n    from .infer import TextExecutor\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/cli/text/infer.py\", line 29, in <module>\r\n    from paddlespeech.text.models.ernie_linear import ErnieLinear\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/text/models/__init__.py\", line 15, in <module>\r\n    from .ernie_linear import ErnieLinear\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/text/models/ernie_linear/__init__.py\", line 16, in <module>\r\n    from .ernie_linear_updater import *\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/text/models/ernie_linear/ernie_linear_updater.py\", line 24, in <module>\r\n    from paddlespeech.t2s.training.extensions.evaluator import StandardEvaluator\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/__init__.py\", line 19, in <module>\r\n    from . import models\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/models/__init__.py\", line 14, in <module>\r\n    from .ernie_sat import *\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/models/ernie_sat/__init__.py\", line 14, in <module>\r\n    from .ernie_sat import *\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/models/ernie_sat/ernie_sat.py\", line 21, in <module>\r\n    from paddlespeech.t2s.modules.activation import get_activation\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/modules/__init__.py\", line 16, in <module>\r\n    from .losses import *\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/modules/losses.py\", line 23, in <module>\r\n    from paddlespeech.t2s.modules.nets_utils import make_non_pad_mask\r\n  File \"/home/aistudio/.data/webide/pip/lib/python3.7/site-packages/paddlespeech/t2s/modules/nets_utils.py\", line 21, in <module>\r\n    from typeguard import check_argument_types\r\nImportError: cannot import name 'check_argument_types' from 'typeguard' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/typeguard/__init__.py)",
        "state": "closed",
        "user": "wangqingbang-austin",
        "closed_by": "wangqingbang-austin",
        "created_at": "2023-03-15T10:02:37+00:00",
        "updated_at": "2023-12-02T17:18:08+00:00",
        "closed_at": "2023-03-15T11:04:23+00:00",
        "comments_count": [
            "wangqingbang-austin",
            "hollykbuck",
            "wangqingbang-austin",
            "achaosss",
            "nyngwang",
            "hitjcl",
            "pwatx"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3052,
        "title": "语音识别中wav格式要求有哪些？？？",
        "body": "大佬，请教一下，这个.wav音频格式有具体的要求嘛，我发现有的wav格式识别不成功。\r\n\r\n提示报错：\r\n      tuntimeError: Err ODenin 'xx/20230315171431.way\": File cotains data in an UOKOM fomt.\r\n\r\n请教一下具体格式有哪些要求呢？\r\n\r\n比如：\r\n       \r\n![image](https://user-images.githubusercontent.com/19298723/225284095-0986068e-acdd-4e2f-a131-7e3d556e85e7.png)\r\n\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "zgz757183190",
        "closed_by": null,
        "created_at": "2023-03-15T10:37:17+00:00",
        "updated_at": "2023-04-12T03:23:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "zgz757183190",
            "zxcd",
            "zgz757183190",
            "zh794390558",
            "zgz757183190",
            "zxcd",
            "zgz757183190",
            "zgz757183190"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3055,
        "title": "[TTS]FatalError: Segmentation fault is detected by the operating system",
        "body": "When i used the tts finetune example csmsc_mini, it worked well. But when i switched to my own dataset, it came out the following error : `FatalError: Segmentation fault is detected by the operating system`.",
        "state": "closed",
        "user": "OswaldoBornemann",
        "closed_by": "yt605155624",
        "created_at": "2023-03-16T03:36:50+00:00",
        "updated_at": "2023-03-21T07:57:12+00:00",
        "closed_at": "2023-03-21T07:57:12+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3053,
        "title": "speech server：No module named  'paddle'",
        "body": "\r\n\r\nMAC：\r\n芯片：Apple M1 Pro\r\n内存：16 GB\r\n系统版本：12.3 \r\n\r\nPython版本：Python 3.10.10\r\n已经按照文档安装成功：https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/macos-pip.html\r\n\r\n<img width=\"1010\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5329730/225104368-7d6113ab-14ab-4a59-867b-745e18c8dbf1.png\">\r\n\r\n现在启动speech server，按照文档操作：https://aistudio.baidu.com/aistudio/projectdetail/4573549?channelType=0&channel=0\r\n**可以正常启动**\r\n<img width=\"800\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5329730/225104783-37afb9cc-0045-47a1-a64f-200cb483845f.png\">\r\n\r\n但是在收到请求后，server端报错：\r\n<img width=\"1727\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5329730/225104939-b9536f5d-1bda-4595-8a8b-34918b84aefa.png\">\r\n\r\n客户端返回结果：\r\n{'code': -1, 'result': None, 'message': '克隆失败，检查克隆脚本是否有效'}\r\n\r\n",
        "state": "open",
        "user": "henushang",
        "closed_by": null,
        "created_at": "2023-03-15T11:18:19+00:00",
        "updated_at": "2023-05-20T16:19:19+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "henushang",
            "iftaken",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3058,
        "title": "[ASR]使用官方文档提供的demo 进行电话录音识别，效果很差，有没有什么参数可以调整",
        "body": "使用官方文档上面提供的代码：\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nasr(audio_file = './in.wav')\r\n\r\n得到的结果是这样的：\r\n那静下这个招法关的就刚才有人说那个锡坑运为善说这边铜波变有一些什么异常性啊啊对对对我给果现在我就现场人员嘛啊那个啊然后他他说还有一些一信信号没部规你经看一下吧有个对然然后什么心号对我让你告诉我什么信态不管除就手机这这回这这就二号接地遍嘛\r\n\r\n几乎无法辨认其描述内容，想问一下有没有什么参数可以调整的，比如说选择模型之类的。看了infer的代码，里面的参数很多，但是无法确定如何给",
        "state": "open",
        "user": "123109",
        "closed_by": null,
        "created_at": "2023-03-16T09:40:04+00:00",
        "updated_at": "2023-05-20T16:19:21+00:00",
        "closed_at": null,
        "comments_count": [
            "Alone749-i",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3059,
        "title": "[ASR] 是否有生成VTT 或者SRT 字幕文件的选择？",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\nNo\r\n\r\n**Describe the feature you'd like:**\r\n希望可以自动生成VTT文件或者SRT文件\r\n\r\n**Describe alternatives you've considered:**\r\n我可以自己提PR，但是不知道应该在哪里处理\r\n",
        "state": "open",
        "user": "baobo5625",
        "closed_by": null,
        "created_at": "2023-03-16T15:23:06+00:00",
        "updated_at": "2023-04-11T09:29:03+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "twoDogy"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3061,
        "title": "流式TTS短语音合成质量不高问题",
        "body": "## General Question\r\n大佬，我所搭建流式TTS用的是fastspeech2 + cnndecoder 模型架构，padsize 和 blocksize 采用默认值；同时，训练数据用了aishell3 + 标贝 + 自有音色（2000句），目前遇到的问题是：在短句合成中（2- 3字），合成效果特别差（在非流式和流式长句合成中未出现该问题）\r\n大佬，这种问题一般怎么解决呢？\r\n\r\n",
        "state": "closed",
        "user": "443127316",
        "closed_by": "yt605155624",
        "created_at": "2023-03-20T02:05:18+00:00",
        "updated_at": "2023-03-21T07:55:56+00:00",
        "closed_at": "2023-03-21T07:55:56+00:00",
        "comments_count": [],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3060,
        "title": "在使用案例aishell/asr1时，各个参数含义是什么意思有解释吗？是否加载了预训练模型？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n在运行这个案例时，不清楚是否是在使用这个结构从头开始训练还是在已经大量语音基础上训练完的模型权重上，继续训练微调？\r\n在conf文件夹下，有特别多的参数都可以在哪里看见参数的解释说明？可以提供一下吗？\r\n",
        "state": "open",
        "user": "Alone749-i",
        "closed_by": null,
        "created_at": "2023-03-17T06:21:50+00:00",
        "updated_at": "2023-05-20T16:19:05+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "makeukus",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3066,
        "title": "[TTS] DiffSinger 文本前端移除对 pinyin_to_phone.txt 文件的依赖",
        "body": "目前 DiffSinger 的文本前端，通过 pinyin_to_phone.txt 文件（opencpop 数据集获取）得到 pinyin 到音素的映射关系，参考：\r\n- https://github.com/PaddlePaddle/PaddleSpeech/pull/3062\r\n\r\n可以通过不带 tone 的 pypinyin 输出加一些简单的规则移除掉对这个文件的依赖\r\n\r\n**需要注意的点:**\r\n1. 除了 zh ch sh 其他声母都是一个，或者无声母，zh ch sh 和 z c s 需要分类讨论\r\n2. 单纯拆的话应该比生成简单一点点，有一些细节需要考虑，比如 u v 变换, u 开头的韵母的变换等, 是生成字典的逆过程，字典生成过程可以参考 \r\n- https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/other/mfa/local/generate_lexicon.py \r\n- https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/topic/frontend/g2p.md",
        "state": "open",
        "user": "yt605155624",
        "closed_by": null,
        "created_at": "2023-03-21T07:49:57+00:00",
        "updated_at": "2023-03-21T07:54:39+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request",
            "T2S",
            "good first issue"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3063,
        "title": "非流式TTS当前是否有ONNX模型支持？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\nPaddleSpeech中非流式TTS当前是否有ONNX模型支持呢，似乎只看到流式TTS可以使用ONNX模型。如果没有能否从当前模型转换？\r\n",
        "state": "closed",
        "user": "RechinW",
        "closed_by": "yt605155624",
        "created_at": "2023-03-20T03:00:59+00:00",
        "updated_at": "2023-03-21T07:56:32+00:00",
        "closed_at": "2023-03-21T07:56:32+00:00",
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3064,
        "title": "TTS部署在自己服务器执行时微调会很慢？",
        "body": "\r\n![cbbe0ce5e5a8ec76efcab5c0e7abfc0](https://user-images.githubusercontent.com/46146110/226317166-4da18bde-0677-4351-91b8-2ac06f26d34a.png)\r\n经调试发现，在这步运行了二十多秒，请问是什么原因？服务器是ubuntu，GPU是V100 32G",
        "state": "open",
        "user": "kensofts",
        "closed_by": null,
        "created_at": "2023-03-20T10:50:14+00:00",
        "updated_at": "2023-05-20T16:19:18+00:00",
        "closed_at": null,
        "comments_count": [
            "iftaken",
            "kensofts",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3065,
        "title": "[S2T] 长音频持续识别时显存不释放，长时间使用GPU显存会占用9、10G，直至coredump",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\npaddlespeech封装对外提供flask服务，长音频持续识别时显存不释放，长时间使用GPU显存会占用9、10G，直至coredump\r\n请问这个显存占用最高达到多少G或需要GPU显存大小多少才能满足paddlespeech使用？ 有没有什么方法可以翻译显存？显存大小什么时候会增加，不能复用吗？\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS:Ubuntu\r\n - Python Version： 3.7\r\n - PaddlePaddle Version：2.4.1\r\n - Model Version：master最新代码\r\n - GPU/DRIVER Informationo： 1080Ti\r\n - CUDA/CUDNN Version:  cuda-10.2 cudnn-7.6\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "git3210",
        "closed_by": "git3210",
        "created_at": "2023-03-21T07:37:16+00:00",
        "updated_at": "2023-07-19T11:09:41+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "git3210",
            "zh794390558",
            "shanchao0906",
            "git3210",
            "git3210",
            "great-wind",
            "gooloosk",
            "git3210",
            "gooloosk",
            "git3210",
            "git3210"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3068,
        "title": "[S2T]ASR conformer_talcs模型 pdparams模型参数转换为opt支持格式",
        "body": "希望把conformer_talcs模型中,avg_10.pdparams这个参数文件转换成 opt可以使用的格式，想部署到paddle-lite中使用，这个可以做到吗",
        "state": "open",
        "user": "Tavish77",
        "closed_by": null,
        "created_at": "2023-03-21T10:10:29+00:00",
        "updated_at": "2023-03-21T12:11:59+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "feature request",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3072,
        "title": "[TTS]ImportError: cannot import name dataclass_transform",
        "body": "依照簡單方法安裝，但使用時報錯。\r\n\r\n$sudo pip install pytest-runner\r\n$sudo pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\r\n$sudo pip install paddlespeech\r\n\r\n$paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/cli/tts/infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/t2s/__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/t2s/frontend/__init__.py\", line 15, in <module>\r\n    from .normalizer import *\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/t2s/frontend/normalizer/__init__.py\", line 14, in <module>\r\n    from paddlespeech.t2s.frontend.normalizer.normalizer import *\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/t2s/frontend/normalizer/normalizer.py\", line 18, in <module>\r\n    from paddlespeech.t2s.frontend.normalizer.numbers import normalize_numbers\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/t2s/frontend/normalizer/numbers.py\", line 17, in <module>\r\n    import inflect\r\n  File \"/usr/local/lib/python3.8/dist-packages/inflect/__init__.py\", line 76, in <module>\r\n    from pydantic import Field, validate_arguments\r\n  File \"pydantic/__init__.py\", line 2, in init pydantic.__init__\r\n  File \"pydantic/dataclasses.py\", line 41, in init pydantic.dataclasses\r\n    # +---------+-----------------------------------------+\r\nImportError: cannot import name dataclass_transform",
        "state": "open",
        "user": "vscv",
        "closed_by": null,
        "created_at": "2023-03-21T14:53:36+00:00",
        "updated_at": "2023-03-27T12:39:54+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "vscv"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3074,
        "title": "Can I do transfer learning with the transformer_librispeech_en model in speech recognition?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-03-22T03:25:42+00:00",
        "updated_at": "2023-03-27T11:03:47+00:00",
        "closed_at": "2023-03-27T11:03:47+00:00",
        "comments_count": [
            "zxcd",
            "khushbookk",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3073,
        "title": "p p-tts遇到这个问题，是什么原因，如何解决",
        "body": "\r\n![F09B989A-4BE5-4068-A136-585165C758CC](https://user-images.githubusercontent.com/128556343/226771101-8b17095e-d679-4ee1-8f52-f5e97e4e1bc9.jpeg)\r\n![DD3649BC-1CE5-4729-A573-73623D1AC065](https://user-images.githubusercontent.com/128556343/226771107-5e0817e9-cf24-435b-a9ab-c6b6566f6220.jpeg)\r\n## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "Leo19880101",
        "closed_by": null,
        "created_at": "2023-03-22T00:26:15+00:00",
        "updated_at": "2023-05-20T16:19:17+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3076,
        "title": "流式TTS，怎样修改可以实现 边输入文字边合成语音？",
        "body": "## General Question\r\n流式TTS，怎样修改可以实现 边输入文字边合成语音？\r\n\r\n感谢大佬百忙之中抽出时间看这个问题？\r\n参考文档 [流式语音合成服务](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_tts_server/README_cn.md)，已经采用websocket方式实现。我想实现一边输入(eg：chatgpt返回的流式数据) 一边合成的效果，我该从哪方面修改呢？感谢大佬！\r\n![屏幕截图 2023-03-22 154014](https://user-images.githubusercontent.com/52820978/226833583-5355de2f-8fc1-401c-8292-7caeb7336556.jpg)\r\n![屏幕截图 2023-03-22 154828](https://user-images.githubusercontent.com/52820978/226835088-46a5ef5d-304f-4317-b193-50d74101e1b5.jpg)\r\n\r\n",
        "state": "open",
        "user": "BeyondLightYear",
        "closed_by": null,
        "created_at": "2023-03-22T07:43:11+00:00",
        "updated_at": "2025-06-27T02:32:38+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "BeyondLightYear",
            "BeyondLightYear",
            "lancelee98",
            "monkeycc",
            "ImmNaruto",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3077,
        "title": "声纹识别最大允许输入音频多大？能不能输入一大段，然后检测对话中的多人，都给检测出来",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "greasebig",
        "closed_by": null,
        "created_at": "2023-03-22T09:46:27+00:00",
        "updated_at": "2023-05-20T16:19:20+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3079,
        "title": "Can Paddle implement a time domain and frequency domain input PANNs of Cnn14",
        "body": "## Feature Request\r\n\r\nCurrently, Paddle only has the frequency domain input version of PANNs, but Python sometimes has both domain and frequency domain input versions of PANNs. I want to test whether time domain input can bring benefits to the service in Paddle\r\nmodel file:https://zenodo.org/record/3987831\r\ncode:https://github.com/qiuqiangkong/audioset_tagging_cnn\r\n",
        "state": "open",
        "user": "liwjun",
        "closed_by": null,
        "created_at": "2023-03-22T11:48:28+00:00",
        "updated_at": "2023-03-23T08:53:17+00:00",
        "closed_at": null,
        "comments_count": [
            "MarsMeng1994"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3080,
        "title": "[TTS] 文本前端对文本“直接说吧嗯别吞吞吐吐”转音素时，会报错IndexError",
        "body": "代码：\r\n> from paddlespeech.t2s.frontend.zh_frontend import Frontend as zhFrontend\r\nfrontend = zhFrontend()\r\nphoneme = frontend.get_phonemes(“直接说吧嗯别吞吞吐吐”)\r\n\r\n报错 IndexError: string index out of range\r\n\r\n直接从pip安装的paddlespeech\r\npaddlespeech版本: 1.0.1\r\n\r\n我本来想转大量文本，大概有几千分之一的文本会报错",
        "state": "open",
        "user": "JunZhan2000",
        "closed_by": null,
        "created_at": "2023-03-22T14:19:14+00:00",
        "updated_at": "2023-09-08T06:58:50+00:00",
        "closed_at": null,
        "comments_count": [
            "lym0302",
            "JunZhan2000",
            "JunZhan2000",
            "JunZhan2000",
            "JunZhan2000",
            "starmoon-1134",
            "starmoon-1134"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3081,
        "title": "asr 时候如何能默认输入 y？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n···\r\nC:\\Users\\R-wtg>paddlespeech asr --lang zh --input d:\\1.mp3\r\nC:\\Users\\R-wtg\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\nC:\\Users\\R-wtg\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nC:\\Users\\R-wtg\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nC:\\Users\\R-wtg\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nC:\\Users\\R-wtg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nC:\\Users\\R-wtg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\n  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\nC:\\Users\\R-wtg\\AppData\\Roaming\\Python\\Python310\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2023-03-22 23:19:34.242 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2023-03-22 23:19:34.345 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\nInput(Y/N):\r\n\r\n···\r\n这个input 如果输入n 就退出了，输入y会继续执行， 能否默认就输入y的效果 不要再用户输入了？ 谢谢。\r\n\r\n环境： win10   python 3.10 \r\n\r\nPaddleSpeech： 1.4",
        "state": "closed",
        "user": "youfanx",
        "closed_by": "youfanx",
        "created_at": "2023-03-22T15:21:56+00:00",
        "updated_at": "2023-03-24T07:33:04+00:00",
        "closed_at": "2023-03-24T07:33:04+00:00",
        "comments_count": [
            "zxcd",
            "youfanx"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3082,
        "title": "请问一下，有人在运行TTS项目时，有遇到过pypinyin这个错误吗？应该怎么解决呢，暂时没有找到解决的办法",
        "body": "Traceback (most recent call last):\r\n  File \".\\start.py\", line 15, in <module>\r\n    from src.transcribe import TTSExecutor, pretrained_models, front_models\r\n  File \"F:\\TTS\\py_scripts\\src\\transcribe.py\", line 31, in <module>\r\n    from paddlespeech.t2s.frontend import English\r\n  File \"F\\paddlespeech\\t2s\\__init__.py\", line 18, in <module>\r\n    from . import frontend\r\n  File \"F:\\paddlespeech\\t2s\\frontend\\__init__.py\", line 16, in <module>\r\n    from .phonectic import *\r\n  File \"F:\\paddlespeech\\t2s\\frontend\\phonectic.py\", line 26, in <module>\r\n    from paddlespeech.t2s.frontend.zh_normalization.text_normlization import TextNormalizer\r\n  File \"F:\\paddlespeech\\t2s\\frontend\\zh_normalization\\__init__.py\", line 14, in <module>\r\n    from paddlespeech.t2s.frontend.zh_normalization.text_normlization import *\r\n  File \"F:\\paddlespeech\\t2s\\frontend\\zh_normalization\\text_normlization.py\", line 25, in <module>\r\n    from .constants import F2H_ASCII_LETTERS\r\n  File \"F:\\paddlespeech\\t2s\\frontend\\zh_normalization\\constants.py\", line 17, in <module>\r\n    from pypinyin.constants import SUPPORT_UCS4\r\nModuleNotFoundError: No module named 'pypinyin.constants'; 'pypinyin' is not a package\r\n\r\n",
        "state": "closed",
        "user": "yyanning",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-22T17:08:40+00:00",
        "updated_at": "2025-06-27T03:38:43+00:00",
        "closed_at": "2025-06-27T03:38:43+00:00",
        "comments_count": [
            "lym0302",
            "yyanning",
            "yyanning",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3089,
        "title": "启动报错",
        "body": "centos7.9\r\npython3.7\r\n\r\n[root@iZbp11az18341wvtdjlaa0Z PaddleSpeech]# paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\r\n/usr/local/lib/python3.7/site-packages/paddleaudio/_internal/module_utils.py:104: UserWarning: Failed to import soundfile. 'soundfile' backend is not available.\r\n  \"Failed to import soundfile. 'soundfile' backend is not available.\")\r\n/usr/local/lib/python3.7/site-packages/paddleaudio/_extension.py:152: UserWarning: paddleaudio C++ extension is not available. sox_io, sox_effect, kaldi raw feature is not supported!!!\r\n  \"paddleaudio C++ extension is not available. sox_io, sox_effect, kaldi raw feature is not supported!!!\")\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech_server\", line 33, in <module>\r\n    sys.exit(load_entry_point('paddlespeech==0.0.0', 'console_scripts', 'paddlespeech_server')())\r\n  File \"/usr/local/bin/paddlespeech_server\", line 25, in importlib_load_entry_point\r\n    return next(matches).load()\r\n  File \"/usr/local/lib/python3.7/site-packages/importlib_metadata/__init__.py\", line 209, in load\r\n    module = import_module(match.group('module'))\r\n  File \"/usr/local/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/server/__init__.py\", line 16, in <module>\r\n    from .base_commands import ClientBaseCommand\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/server/base_commands.py\", line 18, in <module>\r\n    from .util import cli_client_register\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/server/util.py\", line 27, in <module>\r\n    import paddleaudio\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleaudio/__init__.py\", line 15, in <module>\r\n    from . import backends\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleaudio/backends/__init__.py\", line 14, in <module>\r\n    from . import utils\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleaudio/backends/utils.py\", line 10, in <module>\r\n    from . import no_backend\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleaudio/backends/no_backend.py\", line 7, in <module>\r\n    from paddle import Tensor\r\nImportError: cannot import name 'Tensor' from 'paddle' (/usr/local/lib/python3.7/site-packages/paddle/__init__.py)",
        "state": "closed",
        "user": "ruizhang81",
        "closed_by": "ruizhang81",
        "created_at": "2023-03-24T11:36:06+00:00",
        "updated_at": "2023-03-24T11:49:13+00:00",
        "closed_at": "2023-03-24T11:49:13+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3083,
        "title": "上传录音后，一直显示没有输入数据，没有办法检测到录音上传",
        "body": "![image](https://user-images.githubusercontent.com/63938197/227104760-bf0f6167-64c9-4287-ae5f-ad9e95d0a94f.png)\r\n",
        "state": "closed",
        "user": "ym19961210",
        "closed_by": "zxcd",
        "created_at": "2023-03-23T04:40:25+00:00",
        "updated_at": "2023-03-28T09:24:33+00:00",
        "closed_at": "2023-03-28T09:24:33+00:00",
        "comments_count": [
            "iftaken"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3087,
        "title": "文字转音频API 问题",
        "body": "```python\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\ntts(text=\"今天天气十分不错。\", output=\"output.wav\")\r\n```\r\n\r\n文字转音频\r\n\r\n怎么在这个API基础上\r\n自定义男女声音  发音速度\r\n\r\n现在教程太乱   代码量太杂",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "monkeycc",
        "created_at": "2023-03-24T02:37:19+00:00",
        "updated_at": "2023-05-05T15:06:48+00:00",
        "closed_at": "2023-05-05T15:06:48+00:00",
        "comments_count": [
            "lym0302"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3092,
        "title": "AttributeError: 'NoneType' object has no attribute 'tolist'",
        "body": "  File \"/home/PaddleSpeech/paddlespeech/s2t/frontend/normalizer.py\", line 195, in _compute_mean_std\r\n    'mean_stat': list(all_mean_stat.tolist()),\r\nAttributeError: 'NoneType' object has no attribute 'tolist'\r\nCompute mean and stddev failed. Terminated.",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-03-26T07:18:46+00:00",
        "updated_at": "2023-03-26T09:29:45+00:00",
        "closed_at": "2023-03-26T09:29:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3090,
        "title": "Docker 容器无法直接使用, 报错OSError: cannot load library 'libsndfile.so'",
        "body": "现象:\r\n使用 docker 运行最新的 docker 镜像, 执行 paddlespeech 指令报错, OSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory\r\n\r\n复现:\r\n```shell\r\nsudo docker run -it --name paddlespeech-test   -p 8888:8888  paddlecloud/paddlespeech:develop-cpu-6894a2  /bin/bash\r\n\r\n// 进入容器后 执行\r\npaddlespeech --help\r\n```\r\n\r\n报错信息\r\n```shell\r\nλ 1a25409e403f /home/PaddleSpeech paddlespeech --help\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 161, in <module>\r\n    import _soundfile_data  # ImportError if this doesn't exist\r\nModuleNotFoundError: No module named '_soundfile_data'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 170, in <module>\r\n    raise OSError('sndfile library not found using ctypes.util.find_library')\r\nOSError: sndfile library not found using ctypes.util.find_library\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 28, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/lib/python3.7/dist-packages/soundfile.py\", line 192, in <module>\r\n    _snd = _ffi.dlopen(_explicit_libname)\r\nOSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory\r\nλ 1a25409e403f /home/PaddleSpeech \r\n\r\n\r\n```\r\n",
        "state": "closed",
        "user": "Colin-XKL",
        "closed_by": "zxcd",
        "created_at": "2023-03-24T12:04:36+00:00",
        "updated_at": "2023-03-28T09:22:58+00:00",
        "closed_at": "2023-03-28T09:22:58+00:00",
        "comments_count": [
            "Colin-XKL",
            "zxcd"
        ],
        "labels": [
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3091,
        "title": "请问我在用古文的文字txt转粤语语音的时候，每句话之间接的很快，有什么控制每句话之间输出的参数吗",
        "body": "## General Question\r\n或者文本有什么规则可以让模型知道应该如何读吗，比如逗号，句号，和顿号之间的句子语速应该是不同的，\\n换行时应该停顿几秒这种。（而且发现粤语只有1个模型，我在处理仪礼文本的时候有些字读不出来，比如適）\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "hablee",
        "closed_by": null,
        "created_at": "2023-03-25T06:52:50+00:00",
        "updated_at": "2023-05-20T16:19:16+00:00",
        "closed_at": null,
        "comments_count": [
            "WongLaw",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3099,
        "title": "[TTS]FastSpeech2_mix中英混合语音，文本前端解析基本数学符号有问题",
        "body": "测试方式：\r\n输入\"5+8=13\"\r\n得到音频：\r\n五#八#幺三",
        "state": "open",
        "user": "yuexishuihan",
        "closed_by": null,
        "created_at": "2023-03-27T11:00:44+00:00",
        "updated_at": "2023-03-27T11:00:45+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3094,
        "title": "ECAPA-TDNN voice clone 问题",
        "body": "您好感谢你们公开的工作，不过有个问题想请教下。我在尝试examples/aishell3/vc2 TCAPA-TDNN的voice clone时，我直接跑了run.sh中voice_clone这部。我使用的测试src是我自己的原声（男声），但是tts出来的结果竟然是女声。我使用的都是预训练模型。请问这是不是spk_embedding有问题也就是tcapa-tdnn提取的有问题。",
        "state": "closed",
        "user": "panxin801",
        "closed_by": "panxin801",
        "created_at": "2023-03-27T07:35:37+00:00",
        "updated_at": "2025-04-26T04:48:24+00:00",
        "closed_at": "2025-04-26T04:48:24+00:00",
        "comments_count": [
            "ben-8878",
            "gooloosk",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3100,
        "title": "添加标点符号： “小数点”、 ”百分号“ 处理错误",
        "body": "## Others\r\n>>> from paddlespeech.cli.text.infer import TextExecutor\r\n>>> text_punc = TextExecutor()\r\n>>> result = text_punc(text=\"今天的天气真不错啊你下午有空吗我想约你一起去吃饭一共3.9元占预算10%\")\r\n今天的天气真不错啊！你下午有空吗？我想约你一起去吃饭，一共39元，占预算：10。\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "anyshu",
        "closed_by": null,
        "created_at": "2023-03-28T02:08:54+00:00",
        "updated_at": "2023-05-20T16:19:13+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "anyshu",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3102,
        "title": "能否编译tts部分到freeswitch进行结合使用？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "BarryJame",
        "closed_by": null,
        "created_at": "2023-03-28T04:05:49+00:00",
        "updated_at": "2023-05-20T16:19:14+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3103,
        "title": "如何使用官方的conformer_talcs中英文混合语音识别预训练模型在特定领域的数据集上进行微调",
        "body": "## General Question\r\n\r\n预训练模型数据集：TALCS dataset(https://ai.100tal.com/dataset)\r\n预训练模型：PaddleSpeech/examples/tal_cs/asr1/exp/conformer/checkpoints/avg_10.pdparams\r\n微调数据集：使用Audacity软件录制的采样率为16kHz、单声道的共计3945个特定领域的wav文件。\r\n硬件配置：英伟达3090显卡 24GB显存\r\n卡数：单卡\r\n训练时长：30个epoch\r\n模型参数：官方conformer.yaml文件\r\n",
        "state": "open",
        "user": "choshiho",
        "closed_by": null,
        "created_at": "2023-03-28T07:04:10+00:00",
        "updated_at": "2023-05-20T16:19:06+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "choshiho",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3104,
        "title": "installation bug",
        "body": "## General Question\r\n\r\nCould not find a version that satisfies the requirement paddleaudio>=1.1.0 (from paddlespeech==0.0.0) (from versions: 0.1.0a0, 0.1.0, 0.2.0, 0.2.1, 1.0.0a0, 1.0.0, 1.0.1, 1.0.2)\r\nNo matching distribution found for paddleaudio>=1.1.0 (from paddlespeech==0.0.0)\r\n\r\nWould you please tell me what is that?",
        "state": "open",
        "user": "Givemerun",
        "closed_by": null,
        "created_at": "2023-03-28T07:09:22+00:00",
        "updated_at": "2023-05-20T16:19:15+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "Installation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3105,
        "title": "Armlinux 编译 OpenMP_C 找不到",
        "body": "![image](https://user-images.githubusercontent.com/59154724/228188341-13ee3f50-96ec-4b58-90db-0282672dc2c2.png)\r\nArmlinux 编译时出现 OpenMP_C 找不到请问怎么解决",
        "state": "closed",
        "user": "BinGuang1997",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-28T09:13:36+00:00",
        "updated_at": "2025-06-27T03:37:33+00:00",
        "closed_at": "2025-06-27T03:37:33+00:00",
        "comments_count": [
            "zh794390558",
            "BinGuang1997",
            "yygg678",
            "shawl336",
            "Ryuk17",
            "BinGuang1997",
            "newuser123k789",
            "newuser123k789",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3106,
        "title": "[TTS]流式TTS服务返回的base64编码无法正常解码为wav文件",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n流式TTS服务返回的base64编码无法正常解码为wav文件\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 拉取PaddleSpeech镜像，docker run 启动容器\r\n2. paddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml 启动流式TTS服务\r\n3. ```response = base64.b64decode(response.content)\r\n    with open(out_file, 'wb') as f:\r\n        f.write(response)\r\n解码得到*.wav文件\r\n4. 打开wav文件提示损坏\r\n\r\n**Environment (please complete the following information):**\r\n官方docker pull的镜像环境\r\n\r\n**Additional context**\r\n使用非流式的TTS服务\r\npaddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\r\n正常解码\r\n",
        "state": "open",
        "user": "zzz-6",
        "closed_by": null,
        "created_at": "2023-03-28T09:31:42+00:00",
        "updated_at": "2025-02-28T04:42:21+00:00",
        "closed_at": null,
        "comments_count": [
            "c-fg",
            "duanbt",
            "xianyuxm"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3110,
        "title": "声学模型是否支持OpenVINO推理引擎？",
        "body": "## Feature Request\r\n\r\n希望使用OpenVINO推理引擎加速模型在cpu上的运算速度，目前使用声学模型fastspeech2和声码器melgan，melgan的onnx模型可以成功转换为IR，但是fastspeech2模型似乎存在算子不支持的情况。请问当前是否有可替代的声学模型供OpenVINO推理，后续有无适配计划。",
        "state": "open",
        "user": "RechinW",
        "closed_by": null,
        "created_at": "2023-03-29T05:02:42+00:00",
        "updated_at": "2023-03-29T05:02:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3107,
        "title": "[TTS]本地部署在ubuntu16.04服务器，没有gpu资源，CPU32核心，但微调训练极慢，有没有什么方法，谢谢",
        "body": "本地部署在ubuntu16.04服务器，没有gpu资源，CPU32核心，但微调训练极慢，有没有什么方法，谢谢\r\n![image](https://user-images.githubusercontent.com/129167335/228199037-5f1f37d5-2a99-4e6f-98b5-df4ee41d33f6.png)\r\n",
        "state": "open",
        "user": "qingxin113-1",
        "closed_by": null,
        "created_at": "2023-03-28T09:52:15+00:00",
        "updated_at": "2023-03-30T12:09:01+00:00",
        "closed_at": null,
        "comments_count": [
            "lizezheng"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3108,
        "title": "tts非常慢，如何解决？",
        "body": "第一次运行paddlespeech的tts，感觉非常慢。我的代码如下：\r\n```\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\n tts = TTSExecutor()\r\ntts(text=\"今天天气十分不错。\", output=\"output.wav\")\r\n\r\n```\r\n\r\n似乎无论cpu还是gpu都比较慢。当句子越长，就越慢。\r\n如何查看我可以切换哪些模型？才能尽可能的应对实时的要求？",
        "state": "open",
        "user": "tms2003",
        "closed_by": null,
        "created_at": "2023-03-28T09:54:50+00:00",
        "updated_at": "2023-05-20T16:19:11+00:00",
        "closed_at": null,
        "comments_count": [
            "JunZhan2000",
            "tms2003",
            "1099255210",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3111,
        "title": "请求审核PR",
        "body": "能否请您审核我的 PR 并提供反馈？我将不胜感激。\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/pull/3006\r\n",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "yt605155624",
        "created_at": "2023-03-29T06:26:48+00:00",
        "updated_at": "2023-04-10T04:40:53+00:00",
        "closed_at": "2023-04-10T04:40:53+00:00",
        "comments_count": [
            "lizezheng",
            "lym0302",
            "lym0302",
            "longRookie",
            "longRookie",
            "longRookie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3115,
        "title": "我是否需要安裝整個軟件？",
        "body": "Hi, guys. I am not a deep-leaning fan. My purpose for using paddlepaddle is that I want to use the TTS system to batch convert my articles to sound and then update them to my youtube channel.\r\n\r\nSo, do I need to install all the package or just a part of them?\r\n\r\n我只是想用這個軟件來進行批量轉換，文字轉換成語音文件，然後把語音文件上傳到YouTube。請問我需要安裝整個paddlepaddle？畢竟，我不是玩deep learning的。",
        "state": "closed",
        "user": "zzzgit",
        "closed_by": "zzzgit",
        "created_at": "2023-03-29T12:59:17+00:00",
        "updated_at": "2023-03-29T15:09:59+00:00",
        "closed_at": "2023-03-29T15:09:59+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3113,
        "title": "[S2T]在导入pynini库之后再导入paddlespeech_ctcdecoders就卡死了",
        "body": " - Ubuntu 18.04\r\n - Python 3.7 or 3.8\r\n\r\n在导入pynini库之后再导入paddlespeech_ctcdecoders就卡死了\r\n\r\n```\r\nPython 3.8.16 (default, Mar  2 2023, 03:21:46) \r\n[GCC 11.2.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import pynini\r\n>>> import paddlespeech_ctcdecoders\r\n\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2023-03-29T07:48:36+00:00",
        "updated_at": "2023-04-04T14:44:06+00:00",
        "closed_at": "2023-04-04T14:44:06+00:00",
        "comments_count": [
            "zh794390558",
            "yeyupiaoling",
            "yeyupiaoling",
            "yeyupiaoling",
            "zh794390558",
            "yeyupiaoling",
            "yeyupiaoling"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3114,
        "title": "【asr】使用GPU并行处理批量音频文件，达到语音识别+标点恢复的效果",
        "body": "本人是新手，想实现GPU并行处理批量音频文件，进行语音识别+标点恢复\r\n已经看了cli batch process的issue并做了实验，但是想将语音识别+标点恢复+批零处理整合在一起\r\n请问有没有大佬可以给出详细一点的步骤呀，十分感谢！",
        "state": "open",
        "user": "YangQX829",
        "closed_by": null,
        "created_at": "2023-03-29T10:02:05+00:00",
        "updated_at": "2023-05-20T16:19:12+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "YangQX829",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3117,
        "title": "failed to start the server",
        "body": "<img width=\"565\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1060733/228581368-c47b2708-db35-4142-910d-32424b71d003.png\">",
        "state": "closed",
        "user": "zzzgit",
        "closed_by": "zzzgit",
        "created_at": "2023-03-29T15:01:24+00:00",
        "updated_at": "2023-03-30T01:51:34+00:00",
        "closed_at": "2023-03-30T01:51:34+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3116,
        "title": "【asr】实现多客户音频和音频流并发asr处理的服务接口",
        "body": "想要设计服务接口，实现多用户音频的并发语音识别处理\r\n请问现在paddlespeech支持这样的功能吗？还是需要自己开发呀",
        "state": "closed",
        "user": "YangQX829",
        "closed_by": "zxcd",
        "created_at": "2023-03-29T13:38:08+00:00",
        "updated_at": "2023-04-04T03:40:18+00:00",
        "closed_at": "2023-04-04T03:40:18+00:00",
        "comments_count": [
            "lizezheng"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3119,
        "title": "TTS 内存占用的问题",
        "body": "在树莓派4B上运行 tts 的 python api\r\n\r\n```python\r\n    from paddlespeech.cli.tts import TTSExecutor\r\n    tts_executor = TTSExecutor()\r\n    tts_executor(\r\n        text=\"您好，欢迎使用！\",\r\n        output='output.wav',\r\n        am='speedyspeech_csmsc',\r\n        voc='mb_melgan_csmsc',\r\n        lang='zh',\r\n        use_onnx=True,\r\n        cpu_threads=4\r\n    )\r\n```\r\n\r\n成功运行，虽然前面启动速度慢，启动后多次生成的速度很快。\r\n但是目前的问题是内存占用很大，达到约2g的占用，想请问有没有减少内存占用的方法？毕竟模型的大小并不大，为什么总占用这么大？\r\n",
        "state": "open",
        "user": "1099255210",
        "closed_by": null,
        "created_at": "2023-03-30T08:02:35+00:00",
        "updated_at": "2023-05-20T16:19:08+00:00",
        "closed_at": null,
        "comments_count": [
            "lizezheng",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3118,
        "title": "failed without reason",
        "body": "<img width=\"565\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1060733/228706904-ba24bb7b-fb5d-4ccf-adaa-b21822807f80.png\">\r\n",
        "state": "closed",
        "user": "zzzgit",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-30T01:51:22+00:00",
        "updated_at": "2025-05-06T05:24:18+00:00",
        "closed_at": "2025-05-06T05:24:18+00:00",
        "comments_count": [
            "lizezheng",
            "zzzgit",
            "zxcd",
            "zzzgit",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3121,
        "title": "使用官方的conformer_talcs在好未来开源数据集上训练中英文混合语音识别模型，如何集成语言模型提升语音识别准确率",
        "body": "## General Question\r\n预训练模型数据集：TALCS dataset(https://ai.100tal.com/dataset)\r\n硬件配置：英伟达3090显卡 24GB显存\r\n卡数：单卡\r\n训练时长：30个epoch\r\n模型参数：官方conformer.yaml文件\r\n",
        "state": "open",
        "user": "choshiho",
        "closed_by": null,
        "created_at": "2023-03-31T03:35:18+00:00",
        "updated_at": "2023-05-20T16:19:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3124,
        "title": "【KWS】AssertionError: choose a window size 400 that is [2, 1]",
        "body": "Thank you for you work, but when I try the example of Keyword Spotting，there is a bug:\r\n\r\n![image](https://user-images.githubusercontent.com/46480540/229049882-ad4ad43c-1cad-4531-8215-84d6916dbdb1.png)\r\n\r\n\r\nwhat's more，my codes is just from the example: [https://aistudio.baidu.com/aistudio/projectdetail/5836435](https://aistudio.baidu.com/aistudio/projectdetail/5836435)\r\n\r\n`\r\nimport paddleaudio\r\nfrom paddleaudio.compliance.kaldi import fbank\r\n\r\nfeat_func = lambda waveform, sr: fbank(\r\n    waveform=paddle.to_tensor(waveform).unsqueeze(0), \r\n    sr=sr, \r\n    frame_shift=10, \r\n    frame_length=25, \r\n    n_mels=80)\r\n\r\nkeyword_feat = feat_func(\r\n    *paddleaudio.load('/home/aistudio/work/keyword.wav'))\r\nnon_keyword_feat = feat_func(\r\n    *paddleaudio.load('/home/aistudio/work/non-keyword.wav'))\r\n`",
        "state": "closed",
        "user": "Keyird",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-31T07:12:05+00:00",
        "updated_at": "2025-05-06T05:24:15+00:00",
        "closed_at": "2025-05-06T05:24:15+00:00",
        "comments_count": [
            "zxcd",
            "liuying66",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3131
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3122,
        "title": "'mfa_align' is not recognized as an internal or external command",
        "body": "## General Question\r\n\r\n我按照（[文章](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3)）的步骤进行操作，运行run.sh有报错\r\n\r\nAdministrator@DESKTOP-1B5BUG2 MINGW64 /i/Github/PaddleSpeech-develop/examples/other/tts_finetune/tts3\r\n$ ./run.sh\r\ncheck oov\r\nget mfa result\r\n'mfa_align' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n./input/csmsc_mini/newdir\r\n./mfa_result\r\ngenerate durations.txt\r\nTraceback (most recent call last):\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\generate_duration.py\", line 17, in <module>\r\n    from utils.gen_duration_from_textgrid import gen_duration_from_textgrid\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\utils\\gen_duration_from_textgrid.py\", line 18, in <module>\r\n    import librosa\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\librosa\\__init__.py\", line 210, in <module>\r\n    from ._cache import cache\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\librosa\\_cache.py\", line 6, in <module>\r\n    from joblib import Memory\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\joblib\\__init__.py\", line 113, in <module>\r\n    from .memory import Memory, MemorizedResult, register_store_backend\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\joblib\\memory.py\", line 32, in <module>\r\n    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\joblib\\_store_backends.py\", line 15, in <module>\r\n    from .backports import concurrency_safe_rename\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\joblib\\backports.py\", line 125, in <module>\r\n    import numpy as np\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\numpy\\__init__.py\", line 138, in <module>\r\n    from . import _distributor_init\r\n  File \"I:\\Github\\PaddleSpeech-develop\\examples\\other\\tts_finetune\\tts3\\local\\numpy\\_distributor_init.py\", line 26, in <module>\r\n    WinDLL(os.path.abspath(filename))\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39-32\\lib\\ctypes\\__init__.py\", line 374, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 193] %1 不是有效的 Win32 应用程序。\r\n\r\n我应该怎样处理？",
        "state": "closed",
        "user": "makeukus",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-31T04:23:57+00:00",
        "updated_at": "2025-04-27T18:51:28+00:00",
        "closed_at": "2025-04-27T18:51:28+00:00",
        "comments_count": [
            "makeukus",
            "makeukus",
            "makeukus",
            "lym0302",
            "makeukus",
            "ben-8878",
            "lancelee98",
            "stale[bot]",
            "HsiangLeekwok",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3126,
        "title": "流式TTS合成效果非流式差异较大",
        "body": "## General Question\r\n大佬您好，我目前在用基于fastspeech2_cnndecoder在进行流式TTS训练，目前流式的合成效果，和非流式差异明显（双方训练数据一致）。主要问题如下：\r\n1.在合成过程中，出现”噗噗“的声音（block=42,pad_size=12），\r\n2.结尾处合成声音明显发虚，\r\n3.背景声音不干净，可能有电流音。\r\n可能的推测：训练阶段非流式的L1_loss可以下降到0.4，但是流式模型的L1_loss稳定在0.5\r\n还请解惑啊！\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "443127316",
        "closed_by": "443127316",
        "created_at": "2023-03-31T13:39:46+00:00",
        "updated_at": "2023-04-04T03:36:04+00:00",
        "closed_at": "2023-04-04T03:36:04+00:00",
        "comments_count": [
            "443127316"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3125,
        "title": "基于多说话者模型finetune出自己的tts语音模型之后服务部署问题",
        "body": "根据以下教程finetune出自己的音色模型之后https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3\r\n通过以下教程部署了自己微调之后的模型，方式是将自己训练好的模型替换到 ~/.paddlespeech/models/fastspeech2_aishell3-zh/目录下，现在服务器上只能跑一个服务，我想将自己微调之后的其他音色的几个模型也部署到该服务器上应该怎么操作呢？\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/speech_server/README_cn.md",
        "state": "closed",
        "user": "myhaha",
        "closed_by": "myhaha",
        "created_at": "2023-03-31T11:29:42+00:00",
        "updated_at": "2023-04-27T06:24:48+00:00",
        "closed_at": "2023-04-27T06:24:48+00:00",
        "comments_count": [
            "lym0302"
        ],
        "labels": [
            "Question",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3127,
        "title": "PaddleSpeech Server RESTful API文档没有及时更新",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n代码已经开发出来了，但是文档没有及时更新\r\n### RESTful API文档\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/wiki/PaddleSpeech-Server-RESTful-API\r\n文档中没有提及声纹计算的接口，但是我需要使用。我在看另一个文档时，发现其实是有后端接口的👇\r\n![image](https://user-images.githubusercontent.com/68522736/229140969-93e65383-b81b-44d8-af8c-5a497109f0d9.png)\r\n然后就去找代码，最终找到了request_body的格式\r\n![image](https://user-images.githubusercontent.com/68522736/229142205-a08d4fba-c894-49d2-ab73-7519e6e570f9.png)\r\n希望尽可能同步文档，以免给更多开发者带来不便。",
        "state": "closed",
        "user": "Coly6",
        "closed_by": "stale[bot]",
        "created_at": "2023-03-31T14:04:52+00:00",
        "updated_at": "2025-06-27T03:38:47+00:00",
        "closed_at": "2025-06-27T03:38:47+00:00",
        "comments_count": [
            "zxcd",
            "prcvoldermort",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3129,
        "title": "from paddlespeech.cli.asr import ASRExecutor  似乎有些Bug，请问下怎么处理呀？",
        "body": "## General Question\r\n<img width=\"570\" alt=\"image\" src=\"https://user-images.githubusercontent.com/64762753/229361477-c6846121-c727-409b-a2f9-bca983d69efd.png\">\r\n\r\n当我想使用flask+gunicorn的方式部署paddlespeech，启动gunicorn时调用from paddlespeech.cli.asr import ASRExecutor 接口无响应，如果直接使用flask app启动则可以正常启动。\r\n断点测试可以看到程序运行到from paddlespeech.cli.asr import ASRExecutor 就变得无响应了，如下所示：\r\n<img width=\"647\" alt=\"image\" src=\"https://user-images.githubusercontent.com/64762753/229361363-c2257e3d-3c48-44be-b9a0-f4ba58c48563.png\">\r\n仔细查看paddlespeech源码发现运行到enum.py 【212】行有个错误如下：\r\n<img width=\"747\" alt=\"image\" src=\"https://user-images.githubusercontent.com/64762753/229361699-896bd95f-cd27-49ad-956f-678ae1659594.png\">\r\n\r\n\r\n<img width=\"838\" alt=\"image\" src=\"https://user-images.githubusercontent.com/64762753/229361667-61bc4e48-a209-4718-9943-8d34d8e5cee8.png\">\r\n\r\n不知道如何修复，请大佬指点，感谢感谢！！！\r\n",
        "state": "open",
        "user": "Mr-Late-93",
        "closed_by": null,
        "created_at": "2023-04-02T15:09:11+00:00",
        "updated_at": "2023-05-20T16:19:09+00:00",
        "closed_at": null,
        "comments_count": [
            "Mr-Late-93",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3130,
        "title": "基于现有模型微调，添加识别英文字母（a,b,c...x,y,z），conformer和chunk_conformer出来效果差别很大",
        "body": "你好，基于现有模型微调，添加识别英文字母（a,b,c...x,y,z），conformer和chunk_conformer出来效果差别很大：\r\n\r\n使用的训练数据是单个字母的音频，比如字母a，对应有a.wav\r\n使用的测试数据是多个字母的拼读音频，比如 a p p l e。\r\n\r\nfinetune的模型是：asr1_conformer_aishell_ckpt_1.0.1.model.tar.gz 和 asr1_chunk_conformer_aishell_ckpt_0.2.0.model.tar.gz\r\n\r\n使用conformer的模型的finetune，在测试的时候，用测试音频，可以正确识别成 a p p l e.\r\n但是使用chunk_conformer的模型去finetune，测试的时候，用测试音频，识别的只有一个字母a。所有的测试音频测试结果都是只有一个字母。\r\n这是什么原因？ 训练数据的原因么？\r\n\r\n",
        "state": "open",
        "user": "upcmb",
        "closed_by": null,
        "created_at": "2023-04-03T06:10:38+00:00",
        "updated_at": "2023-05-20T16:19:07+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "upcmb",
            "zh794390558",
            "upcmb",
            "zh794390558",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3132,
        "title": "如何通过Python API调用conformer_talcs中英文混合语音识别微调模型进行inference",
        "body": "## General Question\r\n\r\n预训练模型数据集：TALCS dataset(https://ai.100tal.com/dataset)\r\n预训练模型：PaddleSpeech/examples/tal_cs/asr1/exp/conformer/checkpoints/avg_10.pdparams\r\n微调数据集：使用Audacity软件录制的采样率为16kHz、单声道的共计3945个特定领域的wav文件。\r\n硬件配置：英伟达3090显卡 24GB显存\r\n卡数：单卡\r\n训练时长：30个epoch\r\n模型参数：官方conformer.yaml文件\r\n\r\n如何使用Python API调用训练好的微调模型进行inference\r\n\r\nimport paddle\r\nfrom paddlespeech.cli.asr import ASRExecutor\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_talcs',\r\n    lang='zh_en',\r\n    sample_rate=16000,\r\n    config=None, \r\n    ckpt_path=None,\r\n    audio_file='./ch_zh_mix.wav',\r\n    codeswitch=True,\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n\r\n请问此处的各个参数需要如何设置，才能调用自己的微调模型进行预测。\r\n\r\n",
        "state": "closed",
        "user": "choshiho",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-04T07:56:42+00:00",
        "updated_at": "2025-05-06T05:24:23+00:00",
        "closed_at": "2025-05-06T05:24:23+00:00",
        "comments_count": [
            "zxcd",
            "choshiho",
            "zh794390558",
            "choshiho",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3135,
        "title": "CI没有通过",
        "body": "## CI没有通过\r\n\r\n在多次尝试提交后均在代码风格检查这步失败，我force push了之前CI通过的一个版本，结果CI还是在代码风格检查这步出错，请问这是因为什么原因啊？\r\n",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "longRookie",
        "created_at": "2023-04-04T12:51:34+00:00",
        "updated_at": "2023-04-04T14:26:50+00:00",
        "closed_at": "2023-04-04T14:26:50+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3134,
        "title": "不用C++，哪位大哥帮忙看看这个onnx的build警告如何去除问题",
        "body": "--\r\n-- ******** Summary ********\r\n--   CMake version             : 3.20.5\r\n--   CMake command             : /usr/local/bin/cmake\r\n--   System                    : Linux\r\n--   C++ compiler              : /usr/bin/c++\r\n--   C++ compiler version      : 8.3.0\r\n--   CXX flags                 :  -ffunction-sections -fdata-sections -Wno-error=attributes -DCPUINFO_SUPPORTED -Wnon-virtual-dtor\r\n--   Build type                : RelWithDebInfo\r\n--   Compile definitions       : EIGEN_MPL2_ONLY;PLATFORM_POSIX;__STDC_FORMAT_MACROS\r\n--   CMAKE_PREFIX_PATH         :\r\n--   CMAKE_INSTALL_PREFIX      : /usr/local\r\n--   CMAKE_MODULE_PATH         : /home/srtdev/onn/onnxruntime/cmake/external\r\n--\r\n--   ONNX version              : 1.11.0\r\n--   ONNX NAMESPACE            : onnx\r\n--   ONNX_USE_LITE_PROTO       : ON\r\n--   USE_PROTOBUF_SHARED_LIBS  : OFF\r\n--   Protobuf_USE_STATIC_LIBS  : ON\r\n--   ONNX_DISABLE_EXCEPTIONS   : OFF\r\n--   ONNX_WERROR               : OFF\r\n--   ONNX_BUILD_TESTS          : OFF\r\n--   ONNX_BUILD_BENCHMARKS     : OFF\r\n--   ONNXIFI_DUMMY_BACKEND     : OFF\r\n--   ONNXIFI_ENABLE_EXT        : OFF\r\n--\r\n--   Protobuf compiler         :\r\n--   Protobuf includes         :\r\n--   Protobuf libraries        :\r\n--   BUILD_ONNX_PYTHON         : OFF\r\n-- Configuring done\r\n-- Generating done\r\n\r\n\r\n\r\n\r\n[ 42%] Building CXX object CMakeFiles/onnxruntime_providers.dir/home/srtdev/onn/onnxruntime/onnxruntime/core/providers/cpu/tensor/gather_elements.cc.o\r\n/home/srtdev/onn/onnxruntime/onnxruntime/core/providers/cpu/tensor/gather_elements.cc: In instantiation of ‘void onnxruntime::core_impl(const onnxruntime::Tensor*, const onnxruntime::Tensor*, onnxruntime::Tensor*, int64_t, onn\r\nxruntime::concurrency::ThreadPool*) [with bool is_string = true; T = std::__cxx11::basic_string<char>; Tin = int; int64_t = long int]’:\r\n/home/srtdev/onn/onnxruntime/onnxruntime/core/providers/cpu/tensor/gather_elements.cc:304:99:   required from here\r\n/home/srtdev/onn/onnxruntime/onnxruntime/core/providers/cpu/tensor/gather_elements.cc:193:17: 错误：‘void* memcpy(void*, const void*, size_t)’ writing to an object of type ‘class std::__cxx11::basic_string<char>’ with no trivi\r\nal copy-assignment; use copy-assignment or copy-initialization instead [-Werror=class-memaccess]\r\n\r\n\r\ncc1plus：所有的警告都被当作是错误\r\ngmake[2]: *** [CMakeFiles/onnxruntime_providers.dir/home/srtdev/onn/onnxruntime/onnxruntime/core/providers/cpu/tensor/gather_elements.cc.o] 错误 1\r\ngmake[1]: *** [CMakeFiles/onnxruntime_providers.dir/all] 错误 2\r\ngmake: *** [all] 错误 2",
        "state": "closed",
        "user": "judykula",
        "closed_by": "judykula",
        "created_at": "2023-04-04T08:53:56+00:00",
        "updated_at": "2023-04-04T10:45:46+00:00",
        "closed_at": "2023-04-04T10:45:46+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3137,
        "title": "CI的CodeStyle没有通过",
        "body": "## General Question\r\n\r\nforce push了之前CI通过的版本，也没有通过CodeStyle检查，不知道什么原因\r\n",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "longRookie",
        "created_at": "2023-04-05T05:12:49+00:00",
        "updated_at": "2023-04-05T06:55:10+00:00",
        "closed_at": "2023-04-05T06:55:10+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3133,
        "title": "Windows 下 paddlespeech_server无法运行",
        "body": " dos下运行paddlespeech_server help \r\n 报这个错误\r\n        nltk.data.find('taggers/averaged_perceptron_tagger.zip')",
        "state": "open",
        "user": "mjx1999",
        "closed_by": null,
        "created_at": "2023-04-04T08:22:14+00:00",
        "updated_at": "2023-04-04T08:26:40+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3136,
        "title": "CI报错信息",
        "body": "## 这个报错.........\r\n应该如何处理\r\n![image](https://user-images.githubusercontent.com/68834517/229826305-4b2de113-27d7-4af0-8085-ab4b926423e4.png)\r\n",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "longRookie",
        "created_at": "2023-04-04T14:34:53+00:00",
        "updated_at": "2023-04-05T02:01:37+00:00",
        "closed_at": "2023-04-05T02:01:37+00:00",
        "comments_count": [
            "yt605155624",
            "longRookie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3138,
        "title": "CI的codestyle无法通过",
        "body": "我在本地进行pre-commit检查；\r\n![image](https://user-images.githubusercontent.com/68834517/230082753-bd030bae-ae36-4c68-a02e-af02d98b9c30.png)\r\n\r\n在效率云上报错：\r\n![image](https://user-images.githubusercontent.com/68834517/230083071-37b265c9-4fb6-4d9f-a3aa-9dc2cb203850.png)\r\n\r\n",
        "state": "closed",
        "user": "longRookie",
        "closed_by": "yt605155624",
        "created_at": "2023-04-05T12:40:59+00:00",
        "updated_at": "2023-04-10T04:40:36+00:00",
        "closed_at": "2023-04-10T04:40:36+00:00",
        "comments_count": [
            "yt605155624",
            "yt605155624",
            "longRookie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3141,
        "title": "用“使用自己的声音做语音合成项目”提示代码错误",
        "body": "paddlespeech的各位大神们：\r\n\r\n我在运行‘使用自己的声音做语音合成’时，运行完实验所需环境后，双击untitled.streamlit.py文件后\r\n\r\n提示：ImportError: cannot import name 'check_argument_types' from 'typeguard' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/typeguard/__init__.py)\r\n\r\n怎么解决呢？\r\n![屏幕截图 2023-04-06 161815](https://user-images.githubusercontent.com/130042845/230321422-ccfd2bc0-d2cb-4464-b13d-78bb743f17a1.png)\r\n",
        "state": "closed",
        "user": "waya99",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-06T08:33:58+00:00",
        "updated_at": "2025-06-27T04:34:09+00:00",
        "closed_at": "2025-06-27T04:34:09+00:00",
        "comments_count": [
            "zxcd",
            "NLPerxue",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3142,
        "title": "训练结果能够听出电流声",
        "body": "我使用了 examples 下 tts_finetune/tts3 训练,  发现更换了多个质量比较高的语料或调整了训练步数, 生成的结果能从语音里面听出电流声.\r\n\r\n不知道哪个环节的调整能够对抑制电流声有帮助,  希望能够得到大家的建议🙏\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "chinawangyu",
        "closed_by": null,
        "created_at": "2023-04-07T03:25:59+00:00",
        "updated_at": "2025-04-26T03:45:56+00:00",
        "closed_at": null,
        "comments_count": [
            "honyue",
            "barryhunt",
            "lancelee98",
            "stale[bot]",
            "luobotaxinghu",
            "dasheng523",
            "laishujie",
            "starmoon-1134",
            "starmoon-1134",
            "dfsong",
            "stale[bot]",
            "Daisyqk",
            "Ankh-L",
            "Ankh-L",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3147,
        "title": "[S2T]使用erine模型做标点预测，使用 gpu推理，会有内存泄漏现象",
        "body": "**Describe the bug**\r\n使用 PaddleSpeech/examples/iwslt2012/punc0，finetune  ernie-3.0-base-zh 模型，做gpu的标点推理，会发现有内存泄漏的现象，（显存不会增加，内存会缓慢增加），不知道是不是paddle的版本的问题。请帮忙看一下。\r\n使用 PaddleSpeech/docker/ubuntu16-gpu/Dockerfile 进行编译paddle 。\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/22560013/230846183-e88d1e5c-5638-4205-9e7f-a0d72ad99924.png)\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [Ubuntu 16.04]\r\n - GCC/G++ Version [gcc (GCC) 8.2.0]\r\n - Python Version [Python 3.7.13]\r\n - PaddlePaddle Version \r\n    paddle-bfloat==0.1.7\r\n    paddle2onnx==1.0.6\r\n    paddlefsl==1.1.0\r\n    paddlenlp==2.5.0\r\n    paddlepaddle-gpu==2.3.1.post112\r\n    x2paddle==1.4.0\r\n\r\n - Model Version [ernie-3.0-base-zh]\r\n - GPU/DRIVER Informationo [NVIDIA GeForce RTX 3090-24GB/470.57.02]\r\n - CUDA/CUDNN Version [CUDA Version: 11.4 ]\r\n\r\n\r\n",
        "state": "closed",
        "user": "dahu1",
        "closed_by": "dahu1",
        "created_at": "2023-04-10T07:35:00+00:00",
        "updated_at": "2023-04-14T06:46:13+00:00",
        "closed_at": "2023-04-14T06:46:12+00:00",
        "comments_count": [
            "zh794390558",
            "dahu1",
            "zh794390558",
            "dahu1"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3144,
        "title": "有沒有可能做一個精簡版？",
        "body": "我只需要TTS功能，有沒有可能編譯一個簡化版？我不需要那麼龐大的軟件系統。",
        "state": "open",
        "user": "zzzgit",
        "closed_by": null,
        "created_at": "2023-04-07T12:02:33+00:00",
        "updated_at": "2023-04-14T01:42:15+00:00",
        "closed_at": null,
        "comments_count": [
            "zzzgit",
            "zzzgit",
            "kenny-chen",
            "Henryplay"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3151,
        "title": "I want to fine tune an asr model trained on librispeech with my own dataset specific to a domain, since it's said to use the vocab of the existing model to keep it consistent, but I want to append my vocabulary to the existing one, how do I do it?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-11T16:45:40+00:00",
        "updated_at": "2025-05-06T05:24:20+00:00",
        "closed_at": "2025-05-06T05:24:20+00:00",
        "comments_count": [
            "zh794390558",
            "khushbookk",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3148,
        "title": "paddlespeech有没有类似torchaudio那样在tensor层面上对audio做预处理的方法？",
        "body": "给的样例里面是在numpy层面上对audio做预处理，比如LogMelSpectrogram，得到的也是numpy形式的频谱图，然后再paddle.to_tensor。有没有直接在tensor上做的？这样反向传播的话可以直接拿到audio每个点的梯度。\r\n",
        "state": "closed",
        "user": "shudong-zhang",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-10T09:01:21+00:00",
        "updated_at": "2025-05-06T05:24:17+00:00",
        "closed_at": "2025-05-06T05:24:17+00:00",
        "comments_count": [
            "SmileGoat",
            "shudong-zhang",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3152,
        "title": "ASR能否实时监听话筒的音频流进行识别，而不是直接识别wav文件",
        "body": "ASR能否实时监听话筒的音频流进行识别，而不是直接识别wav文件",
        "state": "closed",
        "user": "shujun1992",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-12T02:33:04+00:00",
        "updated_at": "2025-05-06T05:24:19+00:00",
        "closed_at": "2025-05-06T05:24:19+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3153,
        "title": "应用可以部署在华为昇腾NPU服务器上不呢",
        "body": "大佬好，请教一下，\r\n    1、飞桨是不是所有的应用都可以部署在华为昇腾NPU服务器呢？\r\n    2、如果可以的话，帮忙分享一个关于如何部署，谢谢！\r\n\r\n",
        "state": "closed",
        "user": "zgz757183190",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-12T02:44:33+00:00",
        "updated_at": "2025-04-27T18:51:25+00:00",
        "closed_at": "2025-04-27T18:51:25+00:00",
        "comments_count": [
            "lizezheng",
            "zgz757183190",
            "stale[bot]",
            "fuxiaoiii",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3159
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3154,
        "title": "请问一下LogMelSpectrogram()和LogMelSpectrogramKaldi()的区别在哪里？",
        "body": "ASR小白一个，给的demo样例是用LogMelSpectrogramKaldi()处理音频文件的，想请问一下LogMelSpectrogram()和LogMelSpectrogramKaldi()的区别在哪里？我看这俩参数都不一样，用LogMelSpectrogram()处理音频的话也能达到LogMelSpectrogramKaldi()一样的识别效果吗？\r\n",
        "state": "closed",
        "user": "shudong-zhang",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-12T03:55:00+00:00",
        "updated_at": "2025-05-06T05:24:21+00:00",
        "closed_at": "2025-05-06T05:24:21+00:00",
        "comments_count": [
            "zh794390558",
            "shudong-zhang",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3158,
        "title": "[TTS]Docker develop-gpu-cuda10.2-cudnn7-latest 缺失 libsndfile1-dev 和 環境參數CUDA_VISIBLE_DEVICES",
        "body": "**Describe the bug**\r\nDocker develop-gpu-cuda10.2-cudnn7-latest 缺失:\r\n1. apt install libsndfile1-dev\r\n2. 環境參數 os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\n**To Reproduce**\r\n1. 按照官方教程，使用Docker鏡像部署 `docker pull paddlecloud/paddlespeech:develop-gpu-cuda10.2-cudnn7-latest`\r\n2. 進入Docker鏡像 `nvidia-docker run --runtime=nvidia -it -v ~/PycharmProjects/PaddleSpeech:/home paddlecloud/paddlespeech:develop-gpu-cuda10.2-cudnn7-latest /bin/bash`\r\n3. 成功捕獲顯示卡 `nvidia-smi`\r\n![image](https://user-images.githubusercontent.com/68576845/231620916-031193a5-e04e-4acd-b74f-7be0d91e38c3.png)\r\n`nvcc -V`\r\n![image](https://user-images.githubusercontent.com/68576845/231621003-690c0d9b-754b-45b4-aba8-1a4a08537a61.png)\r\n`./test_cuda`\r\n![image](https://user-images.githubusercontent.com/68576845/231621163-2294e2f4-c9e9-4987-b72c-95ab50fc17a2.png)\r\n4. 但執行demo項目，`cd demos/style_fs2 && ./run.sh` 出現error\r\n\r\n**Bug**\r\n1. 缺失 libsndfile1-dev\r\n`Traceback (most recent call last):\r\n  File \"style_syn.py\", line 22, in <module>\r\n    import soundfile as sf\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/soundfile.py\", line 192, in <module>\r\n    _snd = _ffi.dlopen(_explicit_libname)\r\nOSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory`\r\n我猜測，這是CUDA10.2官方docker的bug，里面缺少了libsndfile1-dev。\r\n當執行`apt install libsndfile1-dev`後，成功解決。\r\n\r\n2. 缺失 環境參數CUDA_VISIBLE_DEVICES\r\n`Traceback (most recent call last):\r\n  File \"style_syn.py\", line 228, in <module>\r\n    main()\r\n  File \"style_syn.py\", line 209, in main\r\n    paddle.set_device(\"gpu\")\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/device/__init__.py\", line 313, in set_device\r\n    place = _convert_to_place(device)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/device/__init__.py\", line 204, in _convert_to_place\r\n    place = core.CUDAPlace(ParallelEnv().dev_id)\r\nOSError: (External) CUDA error(100), no CUDA-capable device is detected.\r\n  [Hint: 'cudaErrorNoDevice'. This indicates that no CUDA-capable devices were detected by the installed CUDA driver. ] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:66)`\r\n因缺失 環境參數CUDA_VISIBLE_DEVICES，導致PaddleSpeech失敗獲取GPU。\r\n`import os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"`\r\n當設置CUDA_VISIBLE_DEVICES=0後，成功解決。\r\n\r\n**Environment:**\r\n - Docker: develop-gpu-cuda10.2-cudnn7-latest\r\n - CUDA: 10.2\r\n - CUDNN: 7\r\n\r\n**Suggestion**\r\n1. 在docker `develop-gpu-cuda10.2-cudnn7-latest` 鏡像 再安裝 `apt install libsndfile1-dev`\r\n2. 在 `/demos/style_fs2/style_syn.py` 新增 `import os os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"`\r\n",
        "state": "open",
        "user": "kenny-chen",
        "closed_by": null,
        "created_at": "2023-04-13T01:36:33+00:00",
        "updated_at": "2023-04-17T01:18:22+00:00",
        "closed_at": null,
        "comments_count": [
            "lizezheng",
            "kenny-chen"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3157,
        "title": "[S2T]examples/wenetspeech/local/data.sh 脚本中会使用的 utils/make_filted_shard_list.py 脚本不存在",
        "body": "examples/wenetspeech/local/data.sh 脚本中如下代码会使用的 utils/make_filted_shard_list.py 脚本不存在untils目录下\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/9c387577fd9758d04b43844f8297286632333bb3/examples/wenetspeech/asr1/local/data.sh#L93",
        "state": "open",
        "user": "lemondy",
        "closed_by": null,
        "created_at": "2023-04-12T11:53:27+00:00",
        "updated_at": "2023-05-18T08:23:32+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "lemondy",
            "zxcd",
            "lemondy",
            "lemondy",
            "lemondy",
            "zxcd",
            "lemondy",
            "Chuyaoyuan",
            "Chuyaoyuan"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3160,
        "title": "运行 mfa run.sh 的时候未生成 textGrid 文件，baker_alignment 文件夹下面为空",
        "body": "## General Question\r\n<img width=\"984\" alt=\"image\" src=\"https://user-images.githubusercontent.com/20272951/231660446-8430e3e2-85d7-44a5-8533-6812fa873a80.png\">\r\n\r\n错误信息如图所示，请问是什么原因\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "wang1309",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-13T05:18:53+00:00",
        "updated_at": "2025-05-06T05:24:22+00:00",
        "closed_at": "2025-05-06T05:24:22+00:00",
        "comments_count": [
            "lym0302",
            "wang1309",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3162,
        "title": "有沒有TTS的科普文章？",
        "body": "model、vocoder，這些概念以及他們的關係，有沒有能展開介紹的科普文章？",
        "state": "closed",
        "user": "zzzgit",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-14T03:50:45+00:00",
        "updated_at": "2025-05-06T05:24:28+00:00",
        "closed_at": "2025-05-06T05:24:28+00:00",
        "comments_count": [
            "lym0302",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3166,
        "title": "[TTS]TTS 男声怎么突然没有了",
        "body": "\r\n根据 https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/text_to_speech/README_cn.md\r\n\r\npaddlespeech tts --am fastspeech2_male --voc pwgan_male --lang mix --input \"我们的声学模型使用了 Fast Speech Two, 声码器使用了 Parallel Wave GAN and Hifi GAN.\" --output male_mix_fs2_pwgan.wav\r\n\r\n这个已经是参数错误了",
        "state": "closed",
        "user": "bigsausage",
        "closed_by": "bigsausage",
        "created_at": "2023-04-17T02:26:20+00:00",
        "updated_at": "2023-04-17T03:52:40+00:00",
        "closed_at": "2023-04-17T03:52:22+00:00",
        "comments_count": [
            "bigsausage"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3168,
        "title": "【求助】使用你自己的声音做语音合成项目中，模型微调时报错No such file or directory: '/home/aistudio/work/exp_demo/dump/train/norm/data_speech",
        "body": "微调模型时报错，发现确实没有自动生成/home/sysadmin/aistudio/work/exp_demo/dump/train这个目录，请问是哪一步缺失了，谢谢\r\nfinetune_train(args.dump_dir, args.output_dir, args.max_step, batch_size=args.batch_size, learning_rate=args.learning_rate)\r\n  File \"util/finetuneTrain.py\", line 62, in finetune_train\r\n    file_num = len([filename for filename in os.listdir(train_data_dir) if filename.endswith(\".npy\")])\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/sysadmin/aistudio/work/exp_demo/dump/train/norm/data_speech'",
        "state": "closed",
        "user": "qingxin113-1",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-18T10:01:49+00:00",
        "updated_at": "2025-05-06T05:24:25+00:00",
        "closed_at": "2025-05-06T05:24:25+00:00",
        "comments_count": [
            "qingxin113-1",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3169,
        "title": "tts长文本生成: Out of memory error on GPU",
        "body": "## tts生成的时候，使用自己训练的模型，3000字左右的文本，报错GPU内存溢出，测试500字的时候生成正常。\r\n谁能帮忙解释一下时什么原因吗？或者如何修改可以让它正常生成。\r\n之前在很渣的本地电脑使用命令行，默认模型，10000字的文本也可以正常生成。\r\n\r\n```sh\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::AnalysisPredictor::ZeroCopyRun()\r\n1   paddle::framework::NaiveExecutor::Run()\r\n2   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, phi::Place const&)\r\n3   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, phi::Place const&) const\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, phi::Place const&, paddle::framework::RuntimeContext*) const\r\n5   void phi::SoftmaxGPUDNNKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, phi::DenseTensor*)\r\n6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const\r\n7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, paddle::experimental::DataType, unsigned long, bool) const\r\n8   phi::DenseTensor::AllocateFrom(phi::Allocator*, paddle::experimental::DataType, unsigned long)\r\n9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)\r\n10  paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n11  paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n12  paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)\r\n14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)\r\n15  phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nResourceExhaustedError: \r\n\r\nOut of memory error on GPU 0. Cannot allocate 14.333986GB memory on GPU 0, 21.424561GB memory has been allocated and available memory is only 10.314819GB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model. \r\nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\r\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:95)\r\n```\r\n\r\n## 环境\r\nUbuntu22.04\r\nCUDA11.7\r\nTesla V100-SXM2-32GB\r\npaddlepaddle-gpu              2.4.2.post117",
        "state": "closed",
        "user": "hu81",
        "closed_by": "hu81",
        "created_at": "2023-04-18T10:17:00+00:00",
        "updated_at": "2023-04-19T05:18:53+00:00",
        "closed_at": "2023-04-19T05:18:22+00:00",
        "comments_count": [
            "hu81"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3170,
        "title": "File \"/home/PaddleSpeech/paddlespeech/s2t/models/u2/u2.py\", line 612, in U2BaseModel     @jit.to_static(property=True) TypeError: declarative() got an unexpected keyword argument 'property'",
        "body": null,
        "state": "closed",
        "user": "rishabh121999",
        "closed_by": "rishabh121999",
        "created_at": "2023-04-19T02:39:44+00:00",
        "updated_at": "2023-04-19T06:10:47+00:00",
        "closed_at": "2023-04-19T06:10:47+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3171,
        "title": "OSError: (External) NCCL error(1), unhandled cuda error. ",
        "body": "File \"/home/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 24, in <module>\r\n    dist.init_parallel_env()\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/distributed/parallel.py\", line 315, in init_parallel_env\r\n    parallel_helper._init_parallel_ctx()\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel_helper.py\", line 42, in _init_parallel_ctx\r\n    __parallel_ctx__clz__.init()\r\nOSError: (External) NCCL error(1), unhandled cuda error. \r\n  [Hint: 'ncclUnhandledCudaError'. A call to a CUDA function failed.] (at /paddle/paddle/fluid/platform/collective_helper.cc:100)\r\n\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-19T02:42:52+00:00",
        "updated_at": "2023-04-22T04:42:12+00:00",
        "closed_at": "2023-04-22T04:42:12+00:00",
        "comments_count": [
            "zh794390558",
            "khushbookk"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3172,
        "title": "如何调用conformer_talcs中英文混合语音识别微调模型进行流式语音识别",
        "body": "预训练模型数据集：TALCS dataset(https://ai.100tal.com/dataset)\r\n预训练模型：PaddleSpeech/examples/tal_cs/asr1/exp/conformer/checkpoints/avg_10.pdparams\r\n微调数据集：使用Audacity软件录制的采样率为16kHz、单声道的共计3945个特定领域的wav文件。\r\n硬件配置：英伟达3090显卡 24GB显存\r\n卡数：单卡\r\n训练时长：30个epoch\r\n模型参数：官方conformer.yaml文件\r\n",
        "state": "closed",
        "user": "choshiho",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-19T03:28:39+00:00",
        "updated_at": "2025-04-27T18:54:24+00:00",
        "closed_at": "2025-04-27T18:54:24+00:00",
        "comments_count": [
            "zxcd",
            "choshiho",
            "choshiho",
            "I8Robot",
            "choshiho",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3174,
        "title": "Finetune TTS错误：process_sentences() got an unexpected keyword argument 'write_metadata_method'",
        "body": "当我按照[官方文档](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3) Finetune时，遇到下面错误：\r\n![屏幕截图 2023-04-19 181809](https://user-images.githubusercontent.com/52820978/233045603-ff57f114-68ff-48ab-a0e8-ae6fc7a6f25b.png)\r\n\r\n我找到报错位置，发现调用process_sentences()传参时和 定义该函数的参数不一样：\r\n![屏幕截图 2023-04-19 182445](https://user-images.githubusercontent.com/52820978/233048083-6b855163-52d5-4112-8ae6-08e3b77ce257.png)\r\n![屏幕截图 2023-04-19 182639](https://user-images.githubusercontent.com/52820978/233048113-e32f7c3d-f482-4de8-abde-a30e62b87348.png)\r\n\r\n我怎样做比较好呢？",
        "state": "closed",
        "user": "BeyondLightYear",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-19T10:31:09+00:00",
        "updated_at": "2025-05-06T05:24:26+00:00",
        "closed_at": "2025-05-06T05:24:26+00:00",
        "comments_count": [
            "yt605155624",
            "BeyondLightYear",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3179,
        "title": "标点预测服务报错",
        "body": "[2023-04-20 11:00:04,503] [   ERROR] - Call punctuation http://xx.xxx.xx.xx:8190/paddlespeech/text occurs error\r\n[2023-04-20 11:00:04,503] [   ERROR] - HTTPConnectionPool(host='172.25.14.129', port=8080): Max retries exceeded with url: http://10.214.20.27:8190/paddlespeech/text (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\r\n\r\n测试\r\n [   ERROR] - Failed to Text punctuation.",
        "state": "open",
        "user": "TszSimLaw",
        "closed_by": null,
        "created_at": "2023-04-20T05:55:18+00:00",
        "updated_at": "2023-04-20T05:58:57+00:00",
        "closed_at": null,
        "comments_count": [
            "TszSimLaw"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3180,
        "title": "asr识别结果怎么获取时间线",
        "body": "离线识别asr识别结果怎么获取时间线",
        "state": "closed",
        "user": "1547481339",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-20T06:43:19+00:00",
        "updated_at": "2025-05-06T05:24:24+00:00",
        "closed_at": "2025-05-06T05:24:24+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3181,
        "title": "[TTS]Aishell3 vc2 example not using 16k sample rate while extracting spk embedding",
        "body": "Aishell3 vc2 example not using 16k sample rate while extracting spk embedding\r\n\r\nAlthough it checks the sample rate of input audio but I don't see any process that handles the resampling work.\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/9cf8c1985a98bb380c183116123672976bdfe5c9/paddlespeech/cli/vector/infer.py#L492-L497\r\n\r\nAnd you can see when the code excutes to this line, sr equals 44100 if you print sr here.\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/9cf8c1985a98bb380c183116123672976bdfe5c9/paddlespeech/cli/vector/infer.py#L415 \r\n\r\nThus, melspectrogram receives a waveform loaded with 44100 sample rate and a mismatch sample rate `self.config.sr ` which equals 16000\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/9cf8c1985a98bb380c183116123672976bdfe5c9/paddlespeech/cli/vector/infer.py#L422-L427\r\n",
        "state": "open",
        "user": "keshawnhsieh",
        "closed_by": null,
        "created_at": "2023-04-20T07:35:21+00:00",
        "updated_at": "2023-04-20T08:30:40+00:00",
        "closed_at": null,
        "comments_count": [
            "yt605155624"
        ],
        "labels": [
            "Bug",
            "Vector"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3190,
        "title": "Finetuning : training from scratch or resuming with pretrained model parameters",
        "body": "2023-04-21 15:13:53.765 | INFO     | paddlespeech.s2t.exps.u2.model:setup_model:308 - Setup optimizer/lr_scheduler!\r\n2023-04-21 15:13:54.034 | INFO     | paddlespeech.s2t.utils.checkpoint:load_parameters:117 - Rank 0: Restore model from exp/transformer/checkpoints/avg_10.pdparams\r\n2023-04-21 15:13:54.036 | INFO     | paddlespeech.s2t.training.trainer:resume_or_scratch:221 - Init from scratch!\r\n2023-04-21 15:13:54.381 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:286 - Saved model to exp/transformer/checkpoints/init.pdparams\r\n2023-04-21 15:13:54.383 | INFO     | paddlespeech.s2t.utils.checkpoint:_save_parameters:292 - Saved optimzier state to exp/transformer/checkpoints/init.pdopt\r\n2023-04-21 15:13:54.384 | INFO     | paddlespeech.s2t.exps.u2.model:do_train:161 - Train Total Examples: 53\r\n\r\nI have a confusion regarding this, is it getting trained from scratch or resuming with the pretrained model parameters?",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-21T15:31:39+00:00",
        "updated_at": "2023-04-21T17:03:29+00:00",
        "closed_at": "2023-04-21T17:03:29+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3191,
        "title": "OSError: (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. ",
        "body": "File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/nn/layer/conv.py\", line 678, in forward\r\n    use_cudnn=self._use_cudnn)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/nn/functional/conv.py\", line 144, in _conv_nd\r\n    pre_bias = getattr(_C_ops, op_type)(x, weight, *attrs)\r\nOSError: (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. \r\n  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /paddle/paddle/fluid/platform/device/gpu/cuda/cudnn_desc.h:171)\r\n  [operator < conv2d > error]",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-21T17:03:11+00:00",
        "updated_at": "2023-04-22T03:42:25+00:00",
        "closed_at": "2023-04-22T03:42:25+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3185,
        "title": "websocket流式tts接收到的结果问题",
        "body": "用一段文本访问websocket流式tts（\"/ws/tts/online\"），返回多个声音片段的声音数据，怎样确认每个声音片段数据对应的文字是什么。",
        "state": "closed",
        "user": "c-fg",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-20T11:00:39+00:00",
        "updated_at": "2025-05-06T05:24:27+00:00",
        "closed_at": "2025-05-06T05:24:27+00:00",
        "comments_count": [
            "lym0302",
            "c-fg",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3205
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3192,
        "title": "how to initialize self.visualizer? Should I use SummaryWriter?",
        "body": null,
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-22T14:48:52+00:00",
        "updated_at": "2023-04-23T13:51:27+00:00",
        "closed_at": "2023-04-23T13:51:27+00:00",
        "comments_count": [
            "zh794390558",
            "khushbookk"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3204,
        "title": "ValueError: The additional config (combine_params) of `paddle.jit.save` is not supported. Failed in export!",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-25T11:38:11+00:00",
        "updated_at": "2023-04-27T17:00:08+00:00",
        "closed_at": "2023-04-27T17:00:08+00:00",
        "comments_count": [
            "zh794390558",
            "khushbookk",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3195,
        "title": "How to visualize the graph of the asr model? ",
        "body": null,
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-24T04:35:06+00:00",
        "updated_at": "2023-04-29T13:59:33+00:00",
        "closed_at": "2023-04-29T13:59:33+00:00",
        "comments_count": [
            "zxcd",
            "khushbookk",
            "zh794390558"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3208,
        "title": "TypeError: declarative() got an unexpected keyword argument 'property'",
        "body": null,
        "state": "closed",
        "user": "shangchunli",
        "closed_by": "shangchunli",
        "created_at": "2023-04-27T01:58:04+00:00",
        "updated_at": "2023-04-27T02:00:13+00:00",
        "closed_at": "2023-04-27T01:59:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3206,
        "title": "[TTS]bus error on M1 Mac",
        "body": "**Describe the bug**\r\nGet error when `paddlespeech tts` .\r\n\r\n```\r\n98781 bus error  paddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input\r\n```\r\n\r\n**To Reproduce**\r\npaddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input \"热烈欢迎您在 Discussions 中提交问题，并在 Issues 中指出发现的 bug。此外，我们非常希望您参与到 Paddle Speech 的开发中！\" --spk_id 174 --output mix_spk174.wav\r\n\r\n**Expected behavior**\r\noutput mix_spk174.wav \r\n\r\n**Environment (please complete the following information):**\r\n - OS: macOS Ventura\r\n - Python 3.10.8\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - paddlepaddle==2.4.2\r\n - paddlespeech==1.4.1\r\n - fastspeech2_mix_ckpt_0.2.0\r\n - hifigan_csmsc_ckpt_0.1.1\r\n",
        "state": "open",
        "user": "vicalloy",
        "closed_by": null,
        "created_at": "2023-04-26T01:42:27+00:00",
        "updated_at": "2023-04-27T08:04:22+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "vicalloy"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3207,
        "title": "请问文档样音LJSpeech(英文)女声是哪一个模型和声码器生成的呢？",
        "body": "### Discussed in https://github.com/PaddlePaddle/PaddleSpeech/discussions/3159\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **thehzzz** April 13, 2023</sup>\r\n地址：https://paddlespeech.readthedocs.io/en/latest/tts/demo.html\r\n样音：Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\r\n\r\n我尝试了LJSpeech模型和对应的声码器，不能生成这个女声</div>",
        "state": "closed",
        "user": "thehzzz",
        "closed_by": "thehzzz",
        "created_at": "2023-04-26T05:26:38+00:00",
        "updated_at": "2023-06-08T05:58:23+00:00",
        "closed_at": "2023-06-08T05:58:23+00:00",
        "comments_count": [
            "zh794390558",
            "thehzzz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3209,
        "title": "from paddle.nn.utils import clip_grad_norm_ ImportError: cannot import name 'clip_grad_norm_' from 'paddle.nn.utils' (/home/kay/anaconda3/envs/major_paddle_medium/lib/python3.7/site-packages/paddle/nn/utils/_init_.py) Failed in export!",
        "body": null,
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-27T03:08:58+00:00",
        "updated_at": "2023-04-27T16:59:42+00:00",
        "closed_at": "2023-04-27T16:59:42+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3210,
        "title": "TTS 小样本 finetune 声音克隆多音色问题",
        "body": "通过官方给的样例：https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3 使用自己准备的单音色数据集，可以成功的克隆出自己需要的音色，现在我想使用多音色数据集去克隆出多音色模型，然后使用时通过speak_id选择音色。请问下应该在官方给的finetune样例中怎么修改呢？",
        "state": "closed",
        "user": "myhaha",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-27T03:41:57+00:00",
        "updated_at": "2025-06-27T04:34:04+00:00",
        "closed_at": "2025-06-27T04:34:04+00:00",
        "comments_count": [
            "zh794390558",
            "hhm853610070",
            "myhaha",
            "myhaha",
            "yaleimeng",
            "NLPerxue",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3211,
        "title": "TTS的labels.txt中分词用什么符号，比如aishell3里面用%分词，chi2 qi3 % hong2 ying1 qiang %",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "dawenxi-only",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-27T09:09:53+00:00",
        "updated_at": "2025-05-06T05:24:14+00:00",
        "closed_at": "2025-05-06T05:24:14+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3215,
        "title": "[S2T] chunk_conformer_u2pp_wenetspeech model failed in single machine multi A100 card",
        "body": "**Describe the bug**\r\n单机单卡上训练程序 train 能正常执行，改成多卡后，只有一个卡资源利用率100%，其他卡资源利用率 0%；\r\n看log/workerlog.4 下其他卡里面都打印错误日志：\r\n\r\nNotImplementedError: (Unimplemented) Place Place(gpu:0) is not supported. Please check that your paddle compiles with WITH_GPU, WITH_XPU orWITH_IPU option or check that your train process set the correct device id if you use Executor. (at ../paddle/phi/backends/context_pool.cc:79)\r\n\r\n单机多卡执行代码：\r\n\r\n`\r\nNCCL_SOCKET_IFNAME=eth0 /data/anaconda3/bin/python -m paddle.distributed.launch --selected_gpus=\"${gpus}\"  ${ips_config} ${BIN_DIR}/train.py \\\r\n        --seed ${seed} \\\r\n        --ngpu ${ngpu} \\\r\n        --config ${config_path} \\\r\n        --output ${ckpt_name} \\\r\n        --profiler-options \"${profiler_options}\" \\\r\n        --benchmark-batch-size ${benchmark_batch_size} \\\r\n        --benchmark-max-step ${benchmark_max_step}\r\n`\r\n\r\n其中 gpus=0,1,2,3,4,5,6,7\r\n\r\n安装的程序版本：\r\n\r\npaddle-bfloat                 0.1.7\r\npaddle2onnx                   1.0.6\r\npaddleaudio                   1.1.0\r\npaddlefsl                     1.1.0\r\npaddlenlp                     2.5.2\r\npaddlepaddle-gpu              0.0.0.post117\r\npaddleslim                    2.4.1\r\npaddlespeech                  1.4.1\r\npaddlespeech-ctcdecoders      0.2.0\r\npaddlespeech-feat             0.1.0",
        "state": "open",
        "user": "lemondy",
        "closed_by": null,
        "created_at": "2023-04-30T15:41:21+00:00",
        "updated_at": "2023-04-30T15:42:12+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3212,
        "title": "安装环境测试了一下语音合成，语速有点快音量有点小请问怎么设置生成的语速和音量",
        "body": "安装环境测试了一下语音合成官方demo，语速有点快音量有点小请问怎么设置生成的语速和音量",
        "state": "closed",
        "user": "futureflsl",
        "closed_by": "stale[bot]",
        "created_at": "2023-04-27T13:10:10+00:00",
        "updated_at": "2025-05-06T05:24:16+00:00",
        "closed_at": "2025-05-06T05:24:16+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3213,
        "title": "ValueError: The feeded_var_names[3]: 'cnn_cache' doesn't exist in pruned inference program. Please check whether 'cnn_cache' is a valid feed_var name, or remove it from feeded_var_names if 'cnn_cache' is not involved in the target_vars calculation. Failed in export!",
        "body": null,
        "state": "closed",
        "user": "khushbookk",
        "closed_by": "khushbookk",
        "created_at": "2023-04-27T17:03:04+00:00",
        "updated_at": "2024-08-07T07:08:45+00:00",
        "closed_at": "2023-04-29T13:59:21+00:00",
        "comments_count": [
            "a0735a",
            "colinlwz"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3218,
        "title": "Why is there no speaker_id_map.txt in fastspeech2_male_mix_ckpt_1.4.0.zip?",
        "body": "Hi,\r\n\r\nI wanted to fine-tune with male voice. But there isn't speaker_id_map.txt in https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_male_mix_ckpt_1.4.0.zip\r\n\r\nAny ideas on how I can get the speaker_id_map.txt?\r\n\r\nThanks!",
        "state": "closed",
        "user": "yihuitang",
        "closed_by": "yt605155624",
        "created_at": "2023-05-03T09:37:32+00:00",
        "updated_at": "2023-05-04T02:54:32+00:00",
        "closed_at": "2023-05-04T02:54:32+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3224
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3216,
        "title": "前端和的后端启动时都是正常的，但是打开前端ui界面时，后端显示403 forbidden",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n![捕获](https://user-images.githubusercontent.com/56627796/235873456-4f5d9e05-2cc8-4c30-a523-2cdd5b7b0ecc.PNG)\r\n\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "eaaajay",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-03T09:00:15+00:00",
        "updated_at": "2025-05-06T05:24:13+00:00",
        "closed_at": "2025-05-06T05:24:13+00:00",
        "comments_count": [
            "eaaajay",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3225
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3217,
        "title": "Why is there no speaker_id_map.txt in fastspeech2_male_mix_ckpt_1.4.0.zip",
        "body": "Hi,\r\n\r\nI wanted to fine-tune with male voice. But there isn't speaker_id_map.txt in https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_male_mix_ckpt_1.4.0.zip\r\n\r\nAny ideas on how I can get the speaker_id_map.txt?\r\n\r\nThanks!",
        "state": "closed",
        "user": "yihuitang",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-03T09:36:59+00:00",
        "updated_at": "2025-06-27T03:38:41+00:00",
        "closed_at": "2025-06-27T03:38:41+00:00",
        "comments_count": [
            "yihuitang",
            "yt605155624",
            "yihuitang",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3219,
        "title": "请问TTS的语音克隆效果如何？",
        "body": "我知道微调确实可以合成目标人相似的语音，但是对于只有一句目标说话人的情形，就只能使用融合了说话人编码器的模型，对于训练集中没有出现过的目标人的音频克隆效果好像不是很好，相似度很低，甚至出现提供同一个说话人的不同音频所克隆的音色不相同的情况，还出现提供女声克隆出男声的情况，请问你们训练的模型对于这种zero-shot场景的域外说话人的克隆效果如何？\r\n\r\n",
        "state": "closed",
        "user": "hhm853610070",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-04T05:11:39+00:00",
        "updated_at": "2025-06-27T03:38:14+00:00",
        "closed_at": "2025-06-27T03:38:14+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3220,
        "title": "[TTS][Errno 2] No such file or directory: '/home/wanghx/Documents/MFA/newdir/train/mfcc/raw_mfcc.0.scp'",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\nCalculating MFCCs...\r\nTraceback (most recent call last):\r\n  File \"aligner/command_line/align.py\", line 186, in <module>\r\n  File \"aligner/command_line/align.py\", line 142, in validate_args\r\n  File \"aligner/command_line/align.py\", line 94, in align_corpus\r\n  File \"aligner/aligner/pretrained.py\", line 74, in __init__\r\n  File \"aligner/aligner/pretrained.py\", line 122, in setup\r\n  File \"aligner/aligner/base.py\", line 89, in setup\r\n  File \"aligner/corpus.py\", line 979, in initialize_corpus\r\n  File \"aligner/corpus.py\", line 852, in create_mfccs\r\n  File \"aligner/corpus.py\", line 863, in _combine_feats\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/wanghx/Documents/MFA/newdir/train/mfcc/raw_mfcc.0.scp'\r\n[98494] Failed to execute script align\r\ngenerate durations.txt\r\nextract feature\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\n/home/wanghx/PaddleSpeech/tts/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n196 1\r\n100%|█████████████████| 196/196 [00:00<00:00, 16033.77it/s]\r\nDone\r\nTraceback (most recent call last):\r\n  File \"local/extract_feature.py\", line 352, in <module>\r\n    replace_spkid=args.replace_spkid)\r\n  File \"local/extract_feature.py\", line 267, in extract_feature\r\n    vocab_speaker, dump_dir, \"train\")\r\n  File \"local/extract_feature.py\", line 160, in normalize\r\n    \"energy\": np.load,\r\n  File \"/home/wanghx/PaddleSpeech/paddlespeech/t2s/datasets/data_table.py\", line 47, in __init__\r\n    assert len(data) > 0, \"This dataset has no examples\"\r\nAssertionError: This dataset has no examples\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n安装官方给的教程微调训练，官方要的文件夹内容都准备好了，但是报这个文件缺失错误，我看了下确实没有这个文件，但是官方给的文件里面并没有这个路径的这个文件，请问是什么时候生成的吗？我应该怎么解决呢？\r\n",
        "state": "open",
        "user": "haoxue1215",
        "closed_by": null,
        "created_at": "2023-05-04T08:05:51+00:00",
        "updated_at": "2023-10-17T09:25:04+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "gotoolkits",
            "starccy"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3223,
        "title": "语音合成效果与https://paddlespeech.readthedocs.io/en/latest/tts/demo.html给出的效果不一致",
        "body": "我在使用语音合成的时候遇到我自己合成的模型效果与平台给的示例效果不一致的情况： 示例读音是“钱伟长（chang2）想到上海来办学校是经过深思熟（shu2）虑的。”，而我使用paddlespeech  tts --input \"钱伟长想到上海来办学校是经过深思熟虑的。\" --output output.wav --voc pwgan_csmsc 生成文件的读音是“钱伟长（zhang3）想到上海来办学校是经过深思熟（shou2）虑的。”，\r\n![Uploading 002798a94885db0873bb460fc16ba26.png…]()\r\n",
        "state": "closed",
        "user": "breaveSun",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-04T16:30:29+00:00",
        "updated_at": "2025-06-27T04:33:55+00:00",
        "closed_at": "2025-06-27T04:33:55+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3227,
        "title": "[TTS]语音合成的音调与样例不一致",
        "body": "paddlespeech tts --input \"钱伟长想到上海来办学校是经过深思熟虑的。\" --output output.wav\r\n\r\n这句话合成的结果：钱伟长（zhang3）、深思熟（shou2）虑\r\n和 https://paddlespeech.readthedocs.io/en/latest/tts/demo.html#analysis-synthesis 给出的样例不一样啊。是要调整什么参数么？",
        "state": "open",
        "user": "leshphonc",
        "closed_by": null,
        "created_at": "2023-05-05T12:43:30+00:00",
        "updated_at": "2023-05-13T11:32:08+00:00",
        "closed_at": null,
        "comments_count": [
            "leshphonc",
            "leshphonc"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3226,
        "title": "流式语音识别接口参数问题",
        "body": "PaddleSpeech Streaming Server WebSocket API\r\n![1683273790081](https://user-images.githubusercontent.com/50041220/236406279-f0a8d470-0964-4c12-8bf6-5fe4c2e55130.png)\r\n**接口参数name是文件类型\r\n问题：一个场景用户与客服实时对话需要语音转文本，需要不停收集语音然后写入wav文件，最后发到服务端。这种方式要不停操作文件，会不会不太好？将语音转成二进制流直接发到服务端会不会更好？**\r\n",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-05T08:09:35+00:00",
        "updated_at": "2025-06-27T02:33:12+00:00",
        "closed_at": "2025-06-27T02:33:12+00:00",
        "comments_count": [
            "zh794390558",
            "zgz757183190",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3229,
        "title": "microphone_client.py  NotImplementedError",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/server/tests/asr/online/microphone_client.py\r\n\r\n```python\r\nif __name__ == \"__main__\":\r\n\r\n    logging.basicConfig(level=logging.INFO)\r\n    logging.info(\"asr websocket client start\")\r\n\r\n    handler = ASRWsAudioHandler(\"127.0.0.1\", 8090)\r\n    loop = asyncio.get_event_loop()\r\n    main_task = asyncio.ensure_future(handler.run())\r\n    for signal in [SIGINT, SIGTERM]:\r\n        loop.add_signal_handler(signal, main_task.cancel)\r\n    try:\r\n        loop.run_until_complete(main_task)\r\n    finally:\r\n        loop.close()\r\n\r\n    logging.info(\"asr websocket client finished\")\r\n\r\n```\r\n\r\nmicrophone_client 报错\r\n```\r\nINFO:root:asr websocket client start\r\nTraceback (most recent call last):\r\n  File \"microphone_client.py\", line 155, in <module>\r\n    loop.add_signal_handler(signal, main_task.cancel)\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\asyncio\\events.py\", line 540, in add_signal_handler\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```\r\n\r\n服务器端启动\r\n```\r\npaddlespeech_server start --config_file ./conf/ws_conformer_wenetspeech_application.yaml\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 11004] getaddrinfo failed>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 11004]\r\n[nltk_data]     getaddrinfo failed>\r\n[2023-05-05 23:01:57,339] [    INFO] - start to init the engine\r\n[2023-05-05 23:01:57,339] [    INFO] - asr : online engine.\r\n2023-05-05 23:01:57.419 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\nW0505 23:02:00.958895  2532 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.2\r\nW0505 23:02:00.964898  2532 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n2023-05-05 23:02:05.351 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-05-05 23:02:06,135] [    INFO] - Initialize ASR server engine successfully on device: gpu:0.\r\nINFO:     Started server process [2076]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://127.0.0.1:8090 (Press CTRL+C to quit)\r\n```",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-05T15:05:49+00:00",
        "updated_at": "2025-06-27T05:32:39+00:00",
        "closed_at": "2025-06-27T05:32:39+00:00",
        "comments_count": [
            "MolianWH",
            "monkeycc",
            "zh794390558",
            "monkeycc",
            "Skypow2012",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3228,
        "title": "流式语音怎么实现实时翻译 ",
        "body": "通过麦克风实时识别语音  \r\n再转换TTS 输出\r\n\r\nASR + TTS\r\n\r\n这种要怎么弄\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-05T14:04:49+00:00",
        "updated_at": "2025-06-27T03:38:16+00:00",
        "closed_at": "2025-06-27T03:38:16+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3231,
        "title": "websockets.exceptions.InvalidStatusCode: server rejected WebSocket connection: HTTP 403",
        "body": "```python\r\n# Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\"\"\"\r\nrecord wave from the mic\r\n\"\"\"\r\nimport asyncio\r\nimport json\r\nimport logging\r\nimport threading\r\nimport wave\r\nfrom signal import SIGINT\r\nfrom signal import SIGTERM\r\nimport signal\r\nimport pyaudio\r\nimport websockets\r\n\r\n\r\nclass ASRWsAudioHandler(threading.Thread):\r\n    def __init__(self, url=\"127.0.0.1\", port=8090):\r\n        threading.Thread.__init__(self)\r\n        self.url = url\r\n        self.port = port\r\n        self.url = \"ws://\" + self.url + \":\" + str(self.port) + \"/ws/asr\"\r\n        self.fileName = \"./output.wav\"\r\n        self.chunk = 5120\r\n        self.format = pyaudio.paInt16\r\n        self.channels = 1\r\n        self.rate = 16000\r\n        self._running = True\r\n        self._frames = []\r\n        self.data_backup = []\r\n\r\n    def startrecord(self):\r\n        \"\"\"\r\n        start a new thread to record wave\r\n        \"\"\"\r\n        threading._start_new_thread(self.recording, ())\r\n\r\n    def recording(self):\r\n        \"\"\"\r\n        recording wave\r\n        \"\"\"\r\n        self._running = True\r\n        self._frames = []\r\n        p = pyaudio.PyAudio()\r\n        stream = p.open(\r\n            format=self.format,\r\n            channels=self.channels,\r\n            rate=self.rate,\r\n            input=True,\r\n            frames_per_buffer=self.chunk)\r\n        while (self._running):\r\n            data = stream.read(self.chunk)\r\n            self._frames.append(data)\r\n            self.data_backup.append(data)\r\n\r\n        stream.stop_stream()\r\n        stream.close()\r\n        p.terminate()\r\n\r\n    def save(self):\r\n        \"\"\"\r\n        save wave data\r\n        \"\"\"\r\n        p = pyaudio.PyAudio()\r\n        wf = wave.open(self.fileName, 'wb')\r\n        wf.setnchannels(self.channels)\r\n        wf.setsampwidth(p.get_sample_size(self.format))\r\n        wf.setframerate(self.rate)\r\n        wf.writeframes(b''.join(self.data_backup))\r\n        wf.close()\r\n        p.terminate()\r\n\r\n    def stoprecord(self):\r\n        \"\"\"\r\n        stop recording\r\n        \"\"\"\r\n        self._running = False\r\n\r\n    async def run(self):\r\n        aa = input(\"是否开始录音？   (y/n)\")\r\n        if aa.strip() == \"y\":\r\n            self.startrecord()\r\n            logging.info(\"*\" * 10 + \"开始录音，请输入语音\")\r\n\r\n            async with websockets.connect(self.url) as ws:\r\n                # 发送开始指令\r\n                audio_info = json.dumps(\r\n                    {\r\n                        \"name\": \"test.wav\",\r\n                        \"signal\": \"start\",\r\n                        \"nbest\": 5\r\n                    },\r\n                    sort_keys=True,\r\n                    indent=4,\r\n                    separators=(',', ': '))\r\n                await ws.send(audio_info)\r\n                msg = await ws.recv()\r\n                logging.info(\"receive msg={}\".format(msg))\r\n\r\n                # send bytes data\r\n                logging.info(\"结束录音请: Ctrl + c。继续请按回车。\")\r\n                try:\r\n                    while True:\r\n                        while len(self._frames) > 0:\r\n                            await ws.send(self._frames.pop(0))\r\n                            msg = await ws.recv()\r\n                            msg = json.loads(msg)\r\n                            logging.info(\"receive msg={}\".format(msg))\r\n                except asyncio.CancelledError:\r\n                    # quit\r\n                    # send finished \r\n                    audio_info = json.dumps(\r\n                        {\r\n                            \"name\": \"test.wav\",\r\n                            \"signal\": \"end\",\r\n                            \"nbest\": 5\r\n                        },\r\n                        sort_keys=True,\r\n                        indent=4,\r\n                        separators=(',', ': '))\r\n                    await ws.send(audio_info)\r\n                    msg = await ws.recv()\r\n                    logging.info(\"receive msg={}\".format(msg))\r\n\r\n                    self.stoprecord()\r\n                    logging.info(\"*\" * 10 + \"录音结束\")\r\n                    self.save()\r\n        elif aa.strip() == \"n\":\r\n            exit()\r\n        else:\r\n            print(\"无效输入!\")\r\n            exit()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    logging.basicConfig(level=logging.INFO)\r\n    logging.info(\"asr websocket client start\")\r\n\r\n    handler = ASRWsAudioHandler(\"127.0.0.1\", 8090)\r\n    loop = asyncio.get_event_loop()\r\n    main_task = asyncio.ensure_future(handler.run())\r\n\r\n    signal.signal(signal.SIGINT, main_task.cancel)\r\n    signal.signal(signal.SIGTERM, main_task.cancel)\r\n\r\n    \r\n    # for signal in [SIGINT, SIGTERM]:\r\n    #     loop.add_signal_handler(signal, main_task.cancel)\r\n    try:\r\n        loop.run_until_complete(main_task)\r\n    finally:\r\n        loop.close()\r\n\r\n    logging.info(\"asr websocket client finished\")\r\n\r\n```\r\n\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/server/tests/asr/online/microphone_client.py\r\n```\r\n\r\nINFO:root:asr websocket client start\r\n是否开始录音？   (y/n)y\r\nINFO:root:**********开始录音，请输入语音\r\nTraceback (most recent call last):\r\n  File \"microphone_client.py\", line 163, in <module>\r\n    loop.run_until_complete(main_task)\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\asyncio\\base_events.py\", line 587, in run_until_complete\r\n    return future.result()\r\n  File \"microphone_client.py\", line 97, in run\r\n    async with websockets.connect(self.url) as ws:\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\websockets\\legacy\\client.py\", line 637, in __aenter__\r\n    return await self\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\websockets\\legacy\\client.py\", line 655, in __await_impl_timeout__\r\n    return await self.__await_impl__()\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\websockets\\legacy\\client.py\", line 667, in __await_impl__\r\n    extra_headers=protocol.extra_headers,\r\n  File \"D:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\websockets\\legacy\\client.py\", line 329, in handshake\r\n    raise InvalidStatusCode(status_code, response_headers)\r\nwebsockets.exceptions.InvalidStatusCode: server rejected WebSocket connection: HTTP 403\r\n```\r\n\r\n服务端\r\n```\r\n2023-05-06 19:26:12.167 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-05-06 19:26:12,835] [    INFO] - Initialize ASR server engine successfully on device: gpu:0.\r\nINFO:     Started server process [7548]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)\r\nINFO:     ('127.0.0.1', 58695) - \"WebSocket /ws/asr\" 403\r\nINFO:     connection failed (403 Forbidden)\r\nINFO:     connection closed\r\nINFO:     ('127.0.0.1', 58808) - \"WebSocket /ws/asr\" 403\r\nINFO:     connection failed (403 Forbidden)\r\nINFO:     connection closed\r\nINFO:     ('127.0.0.1', 58819) - \"WebSocket /ws/asr\" 403\r\nINFO:     connection failed (403 Forbidden)\r\nINFO:     connection closed\r\n\r\n-----\r\n\r\npaddlespeech_server start --config_file ./conf/ws_conformer_application.yaml\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nD:\\anaconda3\\envs\\PaddleSpeech\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n[2023-05-06 14:45:10,852] [    INFO] - start to init the engine\r\n[2023-05-06 14:45:10,852] [    INFO] - asr : online engine.\r\n2023-05-06 14:45:24.597 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2023-05-06 14:45:25.610 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-05-06 14:45:27,743] [    INFO] - Initialize ASR server engine successfully on device: cpu.\r\nINFO:     Started server process [1252]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)\r\nINFO:     ('127.0.0.1', 50247) - \"WebSocket /ws/asr\" 403\r\nINFO:     connection failed (403 Forbidden)\r\nINFO:     connection closed\r\n\r\n```",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-06T13:09:55+00:00",
        "updated_at": "2025-06-27T06:33:40+00:00",
        "closed_at": "2025-06-27T06:33:40+00:00",
        "comments_count": [
            "Fmaj7",
            "monkeycc",
            "qingjiaozyn",
            "LDBS666",
            "happywch",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3232,
        "title": "[TTS]0声母占位符",
        "body": "## General Question\r\n\r\n^被用来做0声母占位符，这个占位是否是必须的？是否有尝试过去掉占位符的效果呢？\r\n",
        "state": "closed",
        "user": "wizardk",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-08T02:09:32+00:00",
        "updated_at": "2025-06-27T04:33:58+00:00",
        "closed_at": "2025-06-27T04:33:58+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3233,
        "title": "音频base64怎么转为音频文件",
        "body": "![1683520704990](https://user-images.githubusercontent.com/50041220/236735040-5d11ea30-31da-4cf1-83f8-8e394aa86122.png)\r\n",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-08T04:38:42+00:00",
        "updated_at": "2025-06-27T04:34:25+00:00",
        "closed_at": "2025-06-27T04:34:25+00:00",
        "comments_count": [
            "Fmaj7",
            "Fmaj7",
            "Fmaj7",
            "Fmaj7",
            "zh794390558",
            "Fmaj7",
            "yaleimeng",
            "Fmaj7",
            "AnnCY1",
            "yaleimeng",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3240
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3234,
        "title": "Does the paddlespeech include PortaSpeech（https://github.com/keonlee9420/PortaSpeech）？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "dawenxi-only",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-08T11:06:36+00:00",
        "updated_at": "2025-06-27T04:34:00+00:00",
        "closed_at": "2025-06-27T04:34:00+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3235,
        "title": "numpy1.24.3报错",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n刚装好后，运行了：\r\npaddlespeech asr --lang zh --input zh.wav\r\nlog如下：\r\nTraceback (most recent call last):\r\n  File \"/home/user1/miniconda3/envs/paddle/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\r\n    import librosa\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/core/__init__.py\", line 9, in <module>\r\n    from .constantq import *  # pylint: disable=wildcard-import\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/core/constantq.py\", line 1059, in <module>\r\n    dtype=np.complex,\r\n  File \"/home/user1/miniconda3/envs/paddle/lib/python3.9/site-packages/numpy/__init__.py\", line 305, in __getattr__\r\n    raise AttributeError(__former_attrs__[attr])\r\nAttributeError: module 'numpy' has no attribute 'complex'.\r\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
        "state": "open",
        "user": "gxmlfx",
        "closed_by": null,
        "created_at": "2023-05-10T01:32:54+00:00",
        "updated_at": "2024-01-05T02:34:44+00:00",
        "closed_at": null,
        "comments_count": [
            "mgsky1",
            "hhuyzp",
            "mgsky1",
            "hhuyzp",
            "hhuyzp",
            "mgsky1",
            "hhuyzp",
            "gxmlfx",
            "mgsky1",
            "gxmlfx",
            "mgsky1",
            "xtdhwl",
            "androidfans",
            "alittlenico",
            "ilovejs"
        ],
        "labels": [
            "Question",
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3237,
        "title": "train.py运行完以后报错ValueError: The ``path`` (./exp/default/checkpoints/snapshot_iter_96699.pdz) to load model not exists.",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n我在微调完模型以后，遇到了以下问题：\r\n\r\n\r\n[2023-05-10 11:33:56,137] [&nbsp; &nbsp; INFO] - Already cached /home/user/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-05-10 11:33:56,146] [&nbsp; &nbsp; INFO] - tokenizer config file saved in /home/user/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-05-10 11:33:56,146] [&nbsp; &nbsp; INFO] - Special tokens file saved in /home/user/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\nfrontend done!\r\nW0510 11:33:56.385061 15086 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.6, Runtime API Version: 11.6\r\nW0510 11:33:56.388725 15086 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.\r\nTraceback (most recent call last):\r\n&nbsp; File \"/home/user/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 317, in <module&gt;\r\n&nbsp; &nbsp; main()\r\n&nbsp; File \"/home/user/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 313, in main\r\n&nbsp; &nbsp; evaluate(args)\r\n&nbsp; File \"/home/user/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 60, in evaluate\r\n&nbsp; &nbsp; am_inference = get_am_inference(\r\n&nbsp; File \"/home/user/PaddleSpeech/paddlespeech/t2s/exps/syn_utils.py\", line 423, in get_am_inference\r\n&nbsp; &nbsp; am.set_state_dict(paddle.load(am_ckpt)[\"main_params\"])\r\n&nbsp; File \"/home/user/miniconda3/envs/paddle/lib/python3.9/site-packages/paddle/framework/io.py\", line 1103, in load\r\n&nbsp; &nbsp; load_result = _legacy_load(path, **configs)\r\n&nbsp; File \"/home/user/miniconda3/envs/paddle/lib/python3.9/site-packages/paddle/framework/io.py\", line 1124, in _legacy_load\r\n&nbsp; &nbsp; model_path, config = _build_load_path_and_config(path, config)\r\n&nbsp; File \"/home/user/miniconda3/envs/paddle/lib/python3.9/site-packages/paddle/framework/io.py\", line 200, in _build_load_path_and_config\r\n&nbsp; &nbsp; raise ValueError(error_msg % path)\r\nValueError: The ``path`` (./exp/default/checkpoints/snapshot_iter_96699.pdz) to load model not exists.\r\n\r\n在最后一行的ValueError提示的path下，我找到了几个.pdz文件\r\n/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/records.jsonl文件里面的内容如下：\r\n{\"time\": \"2023-05-10 13:07:41.197976\", \"path\": \"/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/snapshot_iter_97360.pdz\", \"iteration\": 97360}\r\n{\"time\": \"2023-05-10 13:07:45.542799\", \"path\": \"/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/snapshot_iter_97370.pdz\", \"iteration\": 97370}\r\n{\"time\": \"2023-05-10 13:07:49.903181\", \"path\": \"/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/snapshot_iter_97380.pdz\", \"iteration\": 97380}\r\n{\"time\": \"2023-05-10 13:07:54.426551\", \"path\": \"/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/snapshot_iter_97390.pdz\", \"iteration\": 97390}\r\n{\"time\": \"2023-05-10 13:07:58.875535\", \"path\": \"/home/user/PaddleSpeech/examples/other/tts_finetune/tts3/exp/default/checkpoints/snapshot_iter_97400.pdz\", \"iteration\": 97400}\r\n\r\n有没有大佬可以帮忙指点一下",
        "state": "open",
        "user": "hhuyzp",
        "closed_by": null,
        "created_at": "2023-05-10T06:54:32+00:00",
        "updated_at": "2025-04-26T04:45:33+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "wytyl13",
            "wytyl13",
            "wytyl13",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3238,
        "title": "运行报错",
        "body": "运行：paddlespeech vector --task spk --input zh.wav\r\n报错：ImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory",
        "state": "closed",
        "user": "angiewlz",
        "closed_by": "angiewlz",
        "created_at": "2023-05-10T10:25:42+00:00",
        "updated_at": "2023-05-11T00:36:21+00:00",
        "closed_at": "2023-05-11T00:36:03+00:00",
        "comments_count": [
            "angiewlz",
            "angiewlz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3239,
        "title": "Paddelite 使用 Text to speech 问题",
        "body": "使用了 2.13rc 的 paddlite 编译了 windows 的包，并且已经调通，可以正常合成，希望可以解答一下这些问题：\r\n\r\n1. 中文中不能夹杂任何英文，否则推理会失败。这个如何解决？\r\n2. paddelite 部署能支持流式合成吗？ 如果能够支持，有没有 C++ 流式合成的代码（非客户端）可以参考，主要是使用流式合成模型时候 PaddlePredictor 怎么用，不是 Paddle Inference 的 c++ 代码也行。\r\n3. 从性能上说 windows 端侧部署，是不是 Paddle Inference 也可以用？ Paddle Inference 和 Paddle Lite 哪个更块一些。\r\n4. 一次合成支持的最大长度代码里怎么获取，现在发送文本过长也会合成失败\r\n",
        "state": "closed",
        "user": "endink",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-10T15:06:06+00:00",
        "updated_at": "2025-06-27T04:34:02+00:00",
        "closed_at": "2025-06-27T04:34:02+00:00",
        "comments_count": [
            "endink",
            "zh794390558",
            "endink",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3241,
        "title": "MFA for Cantonese language getting There were words not found in the dictionary. Would you like to abort to fix them?",
        "body": "## General Question\r\n\r\n尝试跑MFA for Cantonese, 但是得到这个There were words not found in the dictionary. Would you like to abort to fix them?\r\n\r\n根据这部分跑：https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/mfa\r\n\r\n请问有什么解决方法吗？",
        "state": "closed",
        "user": "mayuanyang",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-11T11:36:07+00:00",
        "updated_at": "2025-04-27T18:54:00+00:00",
        "closed_at": "2025-04-27T18:54:00+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3244,
        "title": "Blocking queue is killed error for aishell3 finetune with 400 wav of  csmsc dataset",
        "body": "```\r\nException in main training loop: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n\r\nTraceback (most recent call last):\r\nException in thread Thread-6:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 616, in _get_data\r\n    data = self._data_queue.get(timeout=self._timeout)\r\n  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 105, in get\r\n    raise Empty\r\n_queue.Empty\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 530, in _thread_loop\r\n    batch = self._get_data()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 632, in _get_data\r\n    \"pids: {}\".format(len(failed_workers), pids))\r\nRuntimeError: DataLoader 1 workers exit unexpectedly, pids: 16161\r\n\r\n  File \"/home/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/paddlespeech/t2s/training/updaters/standard_updater.py\", line 108, in update\r\n    batch = self.read_batch()\r\n  File \"/home/paddlespeech/t2s/training/updaters/standard_updater.py\", line 178, in read_batch\r\n    batch = next(self.train_iterator)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 742, in __next__\r\n    data = self._reader.read_next_var_list()\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/home/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/paddlespeech/t2s/training/updaters/standard_updater.py\", line 108, in update\r\n    batch = self.read_batch()\r\n  File \"/home/paddlespeech/t2s/training/updaters/standard_updater.py\", line 178, in read_batch\r\n    batch = next(self.train_iterator)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 742, in __next__\r\n    data = self._reader.read_next_var_list()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n\r\n\r\n```",
        "state": "closed",
        "user": "ben-8878",
        "closed_by": "ben-8878",
        "created_at": "2023-05-15T07:41:41+00:00",
        "updated_at": "2023-05-15T08:47:23+00:00",
        "closed_at": "2023-05-15T08:47:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3243,
        "title": "流式tts响应时间问题",
        "body": "在服务器部署了流式tts，请求一次的耗时大概2-3s，一段文本大概是是个字左右，用在客服和用户实时通话太慢了，有没优化方法",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-15T07:40:54+00:00",
        "updated_at": "2025-04-27T21:55:35+00:00",
        "closed_at": "2025-04-27T21:55:35+00:00",
        "comments_count": [
            "a0735a",
            "Fmaj7",
            "a0735a",
            "a0735a",
            "Fmaj7",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3245,
        "title": "多个人物的小样本TTS微调没有教程",
        "body": "在其他issue中回复，但无法引起注意。因此开一个新的issue。希望有人答疑解惑。\r\n\r\n此前已经实验了[develop/examples/other/tts_finetune/tts3](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3)，单个成年女声的迁移能力还行，大概能有8分相似了。\r\n但是这次我有男女几个不同的声音需要一起微调，就行不通了。怎么样组织数据？能不能有一份详细的教程或文档啊？\r\n有issue提到可以参考aishell3的tts示例，但也是跑不通。\r\n最关键问题是MFA异常，我看 examples/other/mfa 说明写了仅支持CSMSC数据集，那岂不是根本不能用于aishell3数据集？\r\nspk_id是数字，然而aishell3里面是SSB00XX这样的目录组织方式。怎样组织才能正常微调、后续用对应的spk_id推理呢？",
        "state": "closed",
        "user": "yaleimeng",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-15T08:33:59+00:00",
        "updated_at": "2025-04-27T21:56:31+00:00",
        "closed_at": "2025-04-27T21:56:31+00:00",
        "comments_count": [
            "xuriliuhen",
            "yaleimeng",
            "xuriliuhen",
            "yaleimeng",
            "xuriliuhen",
            "xuriliuhen",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3246,
        "title": "使用ASR推理时的ValueError，(InvalidArgument) Broadcast dimension mismatch.",
        "body": "## General Question\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n\r\n在运行下述代码时，出现了ValueError，请问怎么解决？\r\n```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\nprint(result)\r\n```\r\n报错信息如下：\r\n```\r\n[   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\nTraceback (most recent call last):\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/cli/asr/infer.py\", line 323, in infer\r\n    simulate_streaming=cfg.simulate_streaming)\r\n  File \"/home/root/anaconda3/envs/speech_env/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/root/anaconda3/envs/speech_env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 356, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 827, in decode\r\n    reverse_weight=reverse_weight)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 546, in attention_rescoring\r\n    num_decoding_left_chunks, simulate_streaming)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 428, in _ctc_prefix_beam_search\r\n    simulate_streaming)  # (B, maxlen, encoder_dim)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 234, in _forward_encoder\r\n    num_decoding_left_chunks=num_decoding_left_chunks\r\n  File \"/home/root/anaconda3/envs/speech_env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/modules/encoder.py\", line 184, in forward\r\n    num_decoding_left_chunks)\r\n  File \"/home/yuyinshibie/PaddleSpeech-develop/paddlespeech/s2t/modules/mask.py\", line 202, in add_optional_chunk_mask\r\n    chunk_masks = masks.logical_and(chunk_masks)  # (B, L, L)\r\n  File \"/home/root/anaconda3/envs/speech_env/lib/python3.7/site-packages/paddle/tensor/logic.py\", line 117, in logical_and\r\n    return _C_ops.logical_and(x, y)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n```\r\n请问这是什么原因造成的？",
        "state": "closed",
        "user": "great-wind",
        "closed_by": "great-wind",
        "created_at": "2023-05-16T02:38:40+00:00",
        "updated_at": "2024-03-08T14:27:46+00:00",
        "closed_at": "2023-05-31T01:59:22+00:00",
        "comments_count": [
            "zxcd",
            "ybb03",
            "great-wind",
            "breaveSun",
            "zxcd",
            "great-wind",
            "LjPro",
            "ljh-coder"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3247,
        "title": "[TTS] UNAVAILABLE: Internal: AttributeError: module 'triton_python_backend_utils' has no attribute 'using_decoupled_model_transaction_policy'",
        "body": "env：triton22.02\r\nPaddleSpeech \r\ndemos/streaming_tts_serving_fastdeploy/streaming_tts_serving\r\n出现以下错误，请问是什么原因？\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/39179481/a24dc3db-15df-4193-8a04-14c419ce67d6)\r\n\r\n\r\n",
        "state": "closed",
        "user": "duyanfang123",
        "closed_by": "duyanfang123",
        "created_at": "2023-05-16T06:07:29+00:00",
        "updated_at": "2023-05-24T13:57:36+00:00",
        "closed_at": "2023-05-24T13:57:36+00:00",
        "comments_count": [
            "duyanfang123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3253
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3248,
        "title": "TTS 小样本 finetune/声音克隆问题【This dataset has no examples】",
        "body": "在进行音色克隆任务微调时，使用官方给的测试样例程序能够跑通，能够生成最终结果；但是上传自己录制的数据时报错：This dataset has no examples。\r\n(paddlespeech-gpu) [root@int-gpu-001 tts3]$./run_mix.sh --stage 0 --stop-stage 3\r\ncheck oov\r\nget mfa result\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 11.0\r\n/opt/projects/psgpu/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nCreating dictionary information...\r\nSetting up training data...\r\nCalculating MFCCs...\r\nSome utterances were ignored due to lack of features, please see /root/Documents/MFA/newdir/logging/corpus.log for more information.\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 0.0\r\nDone with setup.\r\n100%|####################################################################################################################################################################################################################| 2/2 [00:01<00:00,  1.46it/s]\r\nDone! Everything took 3.8460099697113037 seconds\r\ngenerate durations.txt\r\nextract feature\r\n/opt/servers/anaconda3/envs/paddlespeech-gpu/lib/python3.10/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n/opt/servers/anaconda3/envs/paddlespeech-gpu/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/opt/servers/anaconda3/envs/paddlespeech-gpu/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/opt/servers/anaconda3/envs/paddlespeech-gpu/lib/python3.10/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n9 1\r\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 12714.29it/s]\r\nDone\r\nTraceback (most recent call last):\r\n  File \"/opt/projects/psgpu/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 346, in <module>\r\n    extract_feature(\r\n  File \"/opt/projects/psgpu/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 266, in extract_feature\r\n    normalize(speech_scaler, pitch_scaler, energy_scaler, vocab_phones,\r\n  File \"/opt/projects/psgpu/PaddleSpeech/examples/other/tts_finetune/tts3/local/extract_feature.py\", line 155, in normalize\r\n    dataset = DataTable(\r\n  File \"/opt/projects/psgpu/PaddleSpeech/paddlespeech/t2s/datasets/data_table.py\", line 47, in __init__\r\n    assert len(data) > 0, \"This dataset has no examples\"\r\nAssertionError: This dataset has no examples\r\n",
        "state": "open",
        "user": "NLPerxue",
        "closed_by": null,
        "created_at": "2023-05-16T06:41:38+00:00",
        "updated_at": "2023-10-27T05:13:25+00:00",
        "closed_at": null,
        "comments_count": [
            "NLPerxue",
            "NLPerxue",
            "yaleimeng",
            "NLPerxue",
            "NLPerxue",
            "joisonwk",
            "joisonwk",
            "yangpyoung",
            "iamfoolberg",
            "ChengsongLu"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3250,
        "title": "Why is the TTS effect of 1000 voice fine-tuning worse than that of 20 fine-tuning?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "dawenxi-only",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-17T01:57:11+00:00",
        "updated_at": "2025-06-27T04:34:11+00:00",
        "closed_at": "2025-06-27T04:34:11+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3249,
        "title": "[TTS] cannot import name 'timer' from 'timer'",
        "body": "paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n\r\nC:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\pkg_resources\\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\nC:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nC:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\pkg_resources\\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n[nltk_data] Downloading package averaged_perceptron_tagger to\r\n[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\r\n[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\r\n[nltk_data] Downloading package cmudict to\r\n[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\r\n[nltk_data]   Unzipping corpora\\cmudict.zip.\r\nC:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\Scripts\\paddlespeech.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\cli\\entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\cli\\tts\\__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\t2s\\__init__.py\", line 19, in <module>\r\n    from . import models\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\t2s\\models\\__init__.py\", line 14, in <module>\r\n    from .ernie_sat import *\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\t2s\\models\\ernie_sat\\__init__.py\", line 15, in <module>\r\n    from .ernie_sat_updater import *\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\t2s\\models\\ernie_sat\\ernie_sat_updater.py\", line 26, in <module>\r\n    from paddlespeech.t2s.training.updaters.standard_updater import StandardUpdater\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\ps_env\\lib\\site-packages\\paddlespeech\\t2s\\training\\updaters\\standard_updater.py\", line 25, in <module>\r\n    from timer import timer\r\nImportError: cannot import name 'timer' from 'timer' (C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\win32\\timer.pyd)\r\n(ps_env) PS C:\\Users\\Administrator\\Documents\\ftp\\qianyuhui\\src\\PaddleSpeech\\PaddleSpeech>",
        "state": "closed",
        "user": "guigenyi",
        "closed_by": "guigenyi",
        "created_at": "2023-05-16T10:36:33+00:00",
        "updated_at": "2024-08-27T07:31:13+00:00",
        "closed_at": "2023-05-17T01:57:11+00:00",
        "comments_count": [
            "guigenyi",
            "Myhjworld"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3251,
        "title": "Speech Server一键部署语音服务时TTS句首句末发音不全",
        "body": "## General Question\r\nSpeech Server一键部署语音服务，使用am为fastspeech2_aishell3，voc为pwgan_aishell3，生成的短句音频句首第一个字和句末最后一个字有吞音，句末吞音现象尤其严重，不加标点的话几乎听不到最后一个字。\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "menfanjia",
        "closed_by": "menfanjia",
        "created_at": "2023-05-17T08:37:52+00:00",
        "updated_at": "2023-06-19T08:44:03+00:00",
        "closed_at": "2023-05-17T09:03:34+00:00",
        "comments_count": [
            "Javacr",
            "Javacr",
            "Javacr"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3254,
        "title": "ASR流式服务，在比较安静的环境下，大概2秒之内没有音频传入，在说话就会返回新的内容",
        "body": "## General Question\r\nASR流式服务，在比较安静的环境下，大概2秒之内没有音频传入，在说话就会返回新的内容，输入end指令后返回的result是最后语音的内容，之前输入的内容没有返回。\r\n如何设置这个静音输入的时间，或者有没有其它的解决方式\r\napplication.yaml 的参数配置文档在哪里可以查到。\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "duxb",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-19T06:47:21+00:00",
        "updated_at": "2025-04-27T18:51:32+00:00",
        "closed_at": "2025-04-27T18:51:32+00:00",
        "comments_count": [
            "duxb",
            "zh794390558",
            "NLPerxue",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3255,
        "title": "Windows install webrtcvad easy way",
        "body": "## conda install -c conda-forge webrtcvad\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "943fansi",
        "closed_by": "943fansi",
        "created_at": "2023-05-19T07:54:30+00:00",
        "updated_at": "2023-06-28T13:12:47+00:00",
        "closed_at": "2023-06-28T13:12:47+00:00",
        "comments_count": [
            "943fansi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3257,
        "title": "标点恢复模型在句末有可能恢复的标点不正确或者句末没恢复标点",
        "body": "使用官方demo和数据进行训练，句末的标点恢复不准确，例如：\r\nPunctuation Restoration Result: 今天的天气真不错啊？你下午有空吗？我想约你一起去吃饭\r\nPunctuation Restoration Result: 我建议你每天放学进行一个小时的体育锻炼。虽然学习很重要，但身体更加重要\r\nPunctuation Restoration Result: 我建议你每天放学进行一个小时的体育锻炼。虽然学习很重要，但身体更加重要。今天天气很好，\r\n这可能是什么原因呢？有训练过正常的同学吗？\r\n另外，我把模型改成英文的模型，用自己的数据训练，也是有句末恢复不准确问题。",
        "state": "closed",
        "user": "dwaylin",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-20T02:40:00+00:00",
        "updated_at": "2025-06-27T03:37:53+00:00",
        "closed_at": "2025-06-27T03:37:53+00:00",
        "comments_count": [
            "zh794390558",
            "dwaylin",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3258,
        "title": "codeswitch is true only in zh_en model",
        "body": "输入paddlespeech_server start --config_file ./conf/application.yaml命令之后显示\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n[nltk_data] Downloading package averaged_perceptron_tagger to\r\n[nltk_data]     /root/nltk_data...\r\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\r\n[nltk_data] Downloading package cmudict to /root/nltk_data...\r\n[nltk_data]   Unzipping corpora/cmudict.zip.\r\n[2023-05-20 05:30:13,689] [    INFO] - start to init the engine\r\n[2023-05-20 05:30:13,689] [    INFO] - asr : python engine.\r\n[2023-05-20 05:30:13,889] [   ERROR] - Failed to start server.\r\n[2023-05-20 05:30:13,889] [   ERROR] - codeswitch is true only in zh_en model\r\n",
        "state": "closed",
        "user": "gzmasterpulse",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-20T05:45:27+00:00",
        "updated_at": "2025-04-27T21:55:27+00:00",
        "closed_at": "2025-04-27T21:55:27+00:00",
        "comments_count": [
            "gzmasterpulse",
            "zh794390558",
            "gzmasterpulse",
            "gzmasterpulse",
            "Fmaj7",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3256,
        "title": "流式ASR，webSocket API 接口调用",
        "body": "\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/87564147/19456831-e2ec-4a4d-942b-f98eb41b6262)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/87564147/6afcce4c-6583-49e8-88fc-9de343b0dcb5)\r\n\r\n是需要调整什么参数吗？\r\n",
        "state": "closed",
        "user": "HzQing",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-19T09:05:17+00:00",
        "updated_at": "2025-06-27T04:34:13+00:00",
        "closed_at": "2025-06-27T04:34:13+00:00",
        "comments_count": [
            "zgz757183190",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3259,
        "title": "voice_cloning demo for pretrained model infer",
        "body": "Add example code for voice clone using pretrained model for inferring.\r\n",
        "state": "open",
        "user": "943fansi",
        "closed_by": null,
        "created_at": "2023-05-20T07:59:13+00:00",
        "updated_at": "2023-05-22T02:35:53+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3261,
        "title": " tesla m40  24g版本  似乎跟paddle 很多地方不匹配",
        "body": "飞浆案例 \r\n飞桨PaddleSpeech语音技术课程系列——声音分类\r\n\r\n几乎原封不动的在本地环境执行代码 会出现\r\n![fbbfc2750e4d9ecbcfeebe362563c97](https://github.com/PaddlePaddle/PaddleSpeech/assets/24751044/868e7897-4012-4818-ba65-419b0f58b57a)\r\n\r\n\r\n\r\n windows10\r\n显卡是 tesla m40  24g版本\r\nC:\\Users\\Administrator>nvidia-smi\r\nMon May 22 13:36:12 2023\r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  NVIDIA GeForce GTX 1050       WDDM | 00000000:01:00.0  On |                  N/A |\r\n| 40%   44C    P8               N/A /  75W|   1166MiB /  2048MiB |      0%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n|   1  Tesla M40 24GB                WDDM | 00000000:02:00.0 Off |                    0 |\r\n| N/A   54C    P0               60W / 250W|      0MiB / 23040MiB |      0%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n\r\nC:\\Users\\Administrator>nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2022 NVIDIA Corporation\r\nBuilt on Wed_Jun__8_16:59:34_Pacific_Daylight_Time_2022\r\nCuda compilation tools, release 11.7, V11.7.99\r\nBuild cuda_11.7.r11.7/compiler.31442593_0\r\n\r\n\r\n(e:\\cd\\myabc001) C:\\Users\\Administrator>python -c \"import paddle; print(paddle.__version__)\"\r\n2.4.2\r\n\r\n",
        "state": "open",
        "user": "huangweixiao",
        "closed_by": null,
        "created_at": "2023-05-22T05:32:31+00:00",
        "updated_at": "2023-05-29T02:30:55+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3260,
        "title": "Android语音合成能做到离线吗，phone_id 在Android- demo里是写死的，怎样获取phone-id呢",
        "body": "## General Question\r\nprivate float[] phones = {};\r\n    private final float[][] sentencesToChoose = {\r\n            // 009901 昨日，这名“伤者”与医生全部被警方依法刑事拘留。\r\n            {261, 231, 175, 116, 179, 262, 44, 154, 126, 177, 19, 262, 42, 241, 72, 177, 56, 174, 245, 37, 186, 37, 49, 151, 127, 69, 19, 179, 72, 69, 4, 260, 126, 177, 116, 151, 239, 153, 141},\r\n            // 009902 钱伟长想到上海来办学校是经过深思熟虑的。\r\n            {174, 83, 213, 39, 20, 260, 89, 40, 30, 177, 22, 71, 9, 153, 8, 37, 17, 260, 251, 260, 99, 179, 177, 116, 151, 125, 70, 233, 177, 51, 176, 108, 177, 184, 153, 242, 40, 45},\r\n            // 009903 她见我一进门就骂，吃饭时也骂，骂得我抬不起头。\r\n            {182, 2, 151, 85, 232, 73, 151, 123, 154, 52, 151, 143, 154, 5, 179, 39, 113, 69, 17, 177, 114, 105, 154, 5, 179, 154, 5, 40, 45, 232, 182, 8, 37, 186, 174, 74, 182, 168},\r\n            // 009904 李述德在离开之前，只说了一句“柱驼杀父亲了”。\r\n            {153, 74, 177, 186, 40, 42, 261, 10, 153, 73, 152, 7, 262, 113, 174, 83, 179, 262, 115, 177, 230, 153, 45, 73, 151, 242, 180, 262, 186, 182, 231, 177, 2, 69, 186, 174, 124, 153, 45},\r\n            // 009905 这种车票和保险单捆绑出售属于重复性购买。\r\n            {262, 44, 262, 163, 39, 41, 173, 99, 71, 42, 37, 28, 260, 84, 40, 14, 179, 152, 220, 37, 21, 39, 183, 177, 170, 179, 177, 185, 240, 39, 162, 69, 186, 260, 128, 70, 170, 154, 9},\r\n            // 009906 戴佩妮的男友西米露接唱情歌，让她非常开心。\r\n            {40, 10, 173, 49, 155, 72, 40, 45, 155, 15, 142, 260, 72, 154, 74, 153, 186, 179, 151, 103, 39, 22, 174, 126, 70, 41, 179, 175, 22, 182, 2, 69, 46, 39, 20, 152, 7, 260, 120},\r\n            // 009907 观大势、谋大局、出大策始终是该院的办院方针。\r\n            {70, 199, 40, 5, 177, 116, 154, 168, 40, 5, 151, 240, 179, 39, 183, 40, 5, 38, 44, 179, 177, 115, 262, 161, 177, 116, 70, 7, 247, 40, 45, 37, 17, 247, 69, 19, 262, 51},\r\n            // 009908 他们骑着摩托回家，正好为农忙时的父母帮忙。\r\n            {182, 2, 154, 55, 174, 73, 262, 45, 154, 157, 182, 230, 71, 212, 151, 77, 180, 262, 59, 71, 29, 214, 155, 162, 154, 20, 177, 114, 40, 45, 69, 186, 154, 185, 37, 19, 154, 20},\r\n            // 009909 但是因为还没到退休年龄，只能掰着指头捱日子。\r\n            {40, 17, 177, 116, 120, 214, 71, 8, 154, 47, 40, 30, 182, 214, 260, 140, 155, 83, 153, 126, 180, 262, 115, 155, 57, 37, 7, 262, 45, 262, 115, 182, 171, 8, 175, 116, 261, 112},\r\n            // 009910 这几天雨水不断，人们恨不得待在家里不出门。\r\n            {262, 44, 151, 74, 182, 82, 240, 177, 213, 37, 184, 40, 202, 180, 175, 52, 154, 55, 71, 54, 37, 186, 40, 42, 40, 7, 261, 10, 151, 77, 153, 74, 37, 186, 39, 183, 154, 52}\r\n\r\n    };",
        "state": "closed",
        "user": "wwprootor",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-22T02:45:52+00:00",
        "updated_at": "2025-06-27T06:33:40+00:00",
        "closed_at": "2025-06-27T06:33:40+00:00",
        "comments_count": [
            "zh794390558",
            "wjbd",
            "niufwshd",
            "niufwshd",
            "csukuangfj",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3262,
        "title": "开源的TTS模型支持中英文吗？还是只支持中文，或者只支持英文",
        "body": "大佬，您好，开源的TTS模型支持中英文吗？还是只支持中文，或者只支持英文啊\r\n",
        "state": "closed",
        "user": "wuxiaolianggit",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-22T07:58:30+00:00",
        "updated_at": "2025-06-27T02:33:15+00:00",
        "closed_at": "2025-06-27T02:33:15+00:00",
        "comments_count": [
            "zh794390558",
            "YunzhaoLu",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3264,
        "title": "[TTS]字母+数值形式语音合成问题",
        "body": "如目标文本是：工号ABC00143OX000123DH\r\n这种场景下，模型一般会按英文+数值的形式返回音频，如A B C one hundred and forty-three……\r\n如果想达到A B C 0 0 1 4 3 O X……的效果，应该是怎么优化呢？",
        "state": "open",
        "user": "NLPerxue",
        "closed_by": null,
        "created_at": "2023-05-22T09:43:43+00:00",
        "updated_at": "2023-05-29T03:05:50+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "NLPerxue"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3267,
        "title": "中英文语音识别+timeline时间戳",
        "body": "有个需求需要做中英文混合语音识别，并且同时输出timeline时间戳。测试中发现目前demos/streaming_asr_server中可支持timeline输出，但是因为online和offline限制，不支持conformer_talcs-codeswitch_zh_en-16k，并且测试conformer_talcs-codeswitch_zh_en-16k输出没有时间戳信息，请问如果要实现这个功能，应该怎么做呢？",
        "state": "closed",
        "user": "xuriliuhen",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-24T02:10:14+00:00",
        "updated_at": "2025-04-27T18:51:35+00:00",
        "closed_at": "2025-04-27T18:51:35+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3266,
        "title": "kws模型是否能部署到Paddle-Lite",
        "body": "请问PaddleSpeech训练出来的kws模型，是否能部署到Paddle-Lite？",
        "state": "closed",
        "user": "xielong",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-23T02:39:41+00:00",
        "updated_at": "2025-04-27T18:54:15+00:00",
        "closed_at": "2025-04-27T18:54:15+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3269,
        "title": "请问语音合成的流式推理服务(stream_TTS)支持中英文混合吗？",
        "body": "如果还没有的话，有可参照的过程来自行训练吗？\r\n\r\n我所了解的信息：\r\npp-tts目前流式推理方案：fastspeech2_CNNDecoder + Multi Band MelGAN/HiFiGAN，支持中文，不支持中英混合\r\n如有错漏，还请海涵，谢谢！",
        "state": "closed",
        "user": "Tony-xubiao",
        "closed_by": "Tony-xubiao",
        "created_at": "2023-05-24T07:15:30+00:00",
        "updated_at": "2025-04-23T14:59:48+00:00",
        "closed_at": "2023-06-08T03:04:05+00:00",
        "comments_count": [
            "zh794390558",
            "Tony-xubiao",
            "ddbegun"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3273,
        "title": "配置GPU错误",
        "body": "![1685005581637](https://github.com/PaddlePaddle/PaddleSpeech/assets/50041220/ee748705-8e3e-473e-b140-6ae5eba32eca)\r\n![1685005621007](https://github.com/PaddlePaddle/PaddleSpeech/assets/50041220/70ccd4f7-7063-4b04-be14-2e2b7bb11655)\r\n\r\n",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "Fmaj7",
        "created_at": "2023-05-25T09:07:18+00:00",
        "updated_at": "2023-05-25T09:12:18+00:00",
        "closed_at": "2023-05-25T09:12:18+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3270,
        "title": "流式TTS如何修改参数：采样率、语速、音量、发音人",
        "body": "请问需要修改哪个模块的代码修改这些参数",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-25T03:22:10+00:00",
        "updated_at": "2025-06-27T03:38:05+00:00",
        "closed_at": "2025-06-27T03:38:05+00:00",
        "comments_count": [
            "yaleimeng",
            "linwownil",
            "gclm",
            "gclm",
            "linwownil",
            "gclm",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3271,
        "title": "使用FastSpeech2 with AISHELL-3训练完模型后无feats_stats.npy文件生成",
        "body": "## General Question\r\n使用下图方式训练fastspeech2模型，没有生成feats_stats.npy。请问，这是正常的吗？如果正常的话，语音合成时是不是没有fastspeech2对应的feats_stats.npy文件来使用呢？\r\n<img width=\"873\" alt=\"0b3a09added695f2e5e12418df2b803\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/126248892/ff9ac7a7-8d69-49d7-9976-724d3eb4d8fd\">\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "StanfordAgula",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-25T03:26:02+00:00",
        "updated_at": "2025-04-27T21:55:32+00:00",
        "closed_at": "2025-04-27T21:55:32+00:00",
        "comments_count": [
            "zh794390558",
            "StanfordAgula",
            "zh794390558",
            "StanfordAgula",
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3272,
        "title": "目前不支持英语流式TTS，英语流式ASR，什么时候可以推出支持英语流式TTS、英语流式ASR的模型，或者给一个自己训练的方法也可以",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n",
        "state": "closed",
        "user": "ouyangliping2021",
        "closed_by": "ouyangliping2021",
        "created_at": "2023-05-25T08:29:31+00:00",
        "updated_at": "2023-06-01T09:59:34+00:00",
        "closed_at": "2023-06-01T09:59:34+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3275,
        "title": "[TTS] OPT and Paddle-Lite version are not consistent",
        "body": "The model and Paddle-Lite are downloaded in download.sh\r\n```\r\ndownload 'inference_lite_lib.armlinux.armv8.gcc.with_extra.with_cv.tar.gz' \\\r\n    'https://paddlespeech.bj.bcebos.com/demos/TTSArmLinux/inference_lite_lib.armlinux.armv8.gcc.with_extra.with_cv.tar.gz' \\\r\n    '39e0c6604f97c70f5d13c573d7e709b9' \\\r\n    \"$LIBS_DIR\"\r\n\r\ndownload 'inference_lite_lib.armlinux.armv7hf.gcc.with_extra.with_cv.tar.gz' \\\r\n    'https://paddlespeech.bj.bcebos.com/demos/TTSArmLinux/inference_lite_lib.armlinux.armv7hf.gcc.with_extra.with_cv.tar.gz' \\\r\n    'f5ceb509f0b610dafb8379889c5f36f8' \\\r\n    \"$LIBS_DIR\"\r\n\r\ndownload 'fs2cnn_mbmelgan_cpu_v1.3.0.tar.gz' \\\r\n    'https://paddlespeech.bj.bcebos.com/demos/TTSAndroid/fs2cnn_mbmelgan_cpu_v1.3.0.tar.gz' \\\r\n    '93ef17d44b498aff3bea93e2c5c09a1e' \\\r\n    \"$MODELS_DIR\"\r\n```\r\n\r\nHoweve， I get the following warning and the exe exit with error.\r\n```\r\nwarning: the version of opt that transformed this model is not consistent with current Paddle-Lite version.\r\n      version of opt:d9e63bb\r\n      version of current Paddle-Lite:68b66fd\r\n\r\n```",
        "state": "open",
        "user": "Ryuk17",
        "closed_by": null,
        "created_at": "2023-05-25T09:42:36+00:00",
        "updated_at": "2023-05-29T02:24:24+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3274,
        "title": "[TTS]你好，安装成功了，但是运行报错了？望解答谢谢",
        "body": "[TTS]你好，安装成功了，但是使用的时候找不到？我使用安装命令是\r\n\r\npython -m pip install paddlepaddle-gpu==2.4.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\r\n\r\npython ：版本3.9\r\ncuda: 11.7\r\ncudnn: 8.9\r\n\r\n![截图 2023-05-25 17-23-42](https://github.com/PaddlePaddle/PaddleSpeech/assets/16934884/1a299d74-e29d-4efe-adbd-4daa14df7b1b)\r\n",
        "state": "closed",
        "user": "laishujie",
        "closed_by": "laishujie",
        "created_at": "2023-05-25T09:32:27+00:00",
        "updated_at": "2024-06-27T13:35:04+00:00",
        "closed_at": "2023-05-29T06:35:43+00:00",
        "comments_count": [
            "ajie425",
            "zh794390558",
            "shipshipliucixin1"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3276,
        "title": "流式 ASR 怎么实现麦克风实时识别",
        "body": "流式 ASR 怎么实现麦克风实时识别\r\n\r\n现在只能通过wav文件\r\n局限性很大",
        "state": "open",
        "user": "monkeycc",
        "closed_by": null,
        "created_at": "2023-05-25T13:33:36+00:00",
        "updated_at": "2025-04-26T03:46:24+00:00",
        "closed_at": null,
        "comments_count": [
            "NLPerxue",
            "zh794390558",
            "monkeycc",
            "xiaomingnio",
            "dididiskq",
            "stale[bot]",
            "linexjlin",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3277,
        "title": "[TTS]小数据微调后，合成报错",
        "body": "speech_web中，跑小数据微调完成后，后台显示运行结果为0，证明微调成功，但是页面还是显示微调中。然后输入在试验路径中输入微调后的路径，点击合成后，后台报错\r\n/home/deepiot/anaconda3/envs/paddle2.4/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nTraceback (most recent call last):\r\n  File \"/home/deepiot/ai/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/../synthesize_e2e.py\", line 27, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_sentences_svs\r\nImportError: cannot import name 'get_sentences_svs' from 'paddlespeech.t2s.exps.syn_utils' (/home/deepiot/anaconda3/envs/paddle2.4/lib/python3.8/site-packages/paddlespeech/t2s/exps/syn_utils.py)\r\n",
        "state": "open",
        "user": "truthsun22",
        "closed_by": null,
        "created_at": "2023-05-26T01:41:12+00:00",
        "updated_at": "2024-01-31T02:48:55+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "truthsun22",
            "yilia99"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3280,
        "title": "choose a TTS model",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\nHi, dears\r\nI want to train a TTS model, here are lots of models,\r\n1- which one is good? \r\n2- which examples are good?\r\nI want a model with good interface server time even quality is lower.\r\nbest regards",
        "state": "closed",
        "user": "lalimili6",
        "closed_by": "lalimili6",
        "created_at": "2023-05-27T16:57:58+00:00",
        "updated_at": "2023-05-30T10:48:22+00:00",
        "closed_at": "2023-05-30T10:48:22+00:00",
        "comments_count": [
            "zh794390558",
            "lalimili6",
            "zh794390558",
            "lalimili6"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3282,
        "title": "声音合成中英混合finetune数据格式是什么样的？",
        "body": "中文示例：000001|ka2 er2 pu3 pei2 wai4 sun1 wan2 hua2 ti1\r\n英文示例：LJ001-0001|Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\r\n那中英文混合的数据格式呢？就是上面两种混合写在label.txt里面吗？",
        "state": "closed",
        "user": "truthsun22",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-29T03:24:49+00:00",
        "updated_at": "2025-06-27T03:37:28+00:00",
        "closed_at": "2025-06-27T03:37:28+00:00",
        "comments_count": [
            "zh794390558",
            "truthsun22",
            "truthsun22",
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3278,
        "title": "[TTS]examples/aishell3/tts",
        "body": "跑样例过程中，在Synthesizing这一步中报错，请问是哪里的问题\r\nmultiple speaker fastspeech2!\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 259, in <module>\r\n    main()\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 255, in main\r\n    evaluate(args)\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 109, in evaluate\r\n    phone_ids, spk_id=spk_id, spk_emb=spk_emb)\r\n  File \"/home/ubuntu/miniconda3/envs/pdspeech/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 926, in forward\r\n    text, spk_id=spk_id, spk_emb=spk_emb)\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 822, in inference\r\n    tone_id=tone_id)\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 623, in _forward\r\n    hs = self._integrate_with_spk_embed(hs, spk_emb)\r\n  File \"/home/ubuntu/yqk/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 845, in _integrate_with_spk_embed\r\n    spk_emb = F.normalize(spk_emb).unsqueeze(1).expand(\r\n  File \"/home/ubuntu/miniconda3/envs/pdspeech/lib/python3.7/site-packages/paddle/nn/functional/norm.py\", line 82, in normalize\r\n    out = _C_ops.p_norm(x, float(p), axis, epsilon, True, False)\r\nValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[256].\r\n  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at ../paddle/phi/infermeta/unary.cc:2751)\r\n\r\n",
        "state": "closed",
        "user": "yeyeyeyeeeee",
        "closed_by": "yeyeyeyeeeee",
        "created_at": "2023-05-26T06:43:33+00:00",
        "updated_at": "2024-03-26T02:58:56+00:00",
        "closed_at": "2023-05-31T09:44:41+00:00",
        "comments_count": [
            "yeyeyeyeeeee",
            "GDbbq",
            "bardenthenry"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3279,
        "title": "针对使用demo的疑问",
        "body": "请问官方是否有提供非docker式使用方式，因为本身我这边就是在docker容器里做服务了，再嵌套一个会增大业务的复杂度，能否提供通过clone方式的简单demo",
        "state": "closed",
        "user": "AntyRia",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-27T10:42:58+00:00",
        "updated_at": "2025-04-27T21:56:05+00:00",
        "closed_at": "2025-04-27T21:56:05+00:00",
        "comments_count": [
            "zh794390558",
            "AntyRia",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3283,
        "title": "声音合成微调数据，有没有中文转换为拼音的工具？",
        "body": "我知道G2P有个工具，但转换完是这样的\r\n[['q', 'ian2', 'uei3', 'zh', 'ang3', 'x', 'iang3', 'd', 'ao4', 'sh', 'ang4', 'h', 'ai3', 'l', 'ai2', 'b', 'an4', 'x', 've2', 'x', 'iao4', 'sh', 'iii4', 'j', 'ing1', 'g', 'uo4', 'sh', 'en1', 's', 'ii1', 'sh', 'ou2', 'l', 'v4', 'd', 'e5']]\r\n我想转换成训练的格式，比如qian2 zhang3，有没有这样的工具？",
        "state": "closed",
        "user": "truthsun22",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-29T03:35:20+00:00",
        "updated_at": "2025-04-27T18:54:28+00:00",
        "closed_at": "2025-04-27T18:54:28+00:00",
        "comments_count": [
            "blackbird-fish",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3287
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3285,
        "title": "Cantonese finetune效果比较差",
        "body": "尝试用tts_finetune的模式去做广东话克隆，声音是像的，可是就是电流声大，训练数据是来自于自己的麦克风录音，训练数据听起来很清晰的，可是finetune出来的结果就是大“震音/电流音”， 尝试用其他TTS生成的wav和差不多的量作为训练题材，克隆出来的效果很不错。请问效果不好是因为录音问题吗？\r\n\r\nFinetune的步骤\r\n1. 用MFA对齐\r\n2. 使用了预训练模型fastspeech2_canton_ckpt_1.4.0.zip 和 pwg_aishell3_ckpt_0.5.zip\r\n\r\n这个是训练出来的样本\r\n[170.wav.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/11591608/170.wav.zip)\r\n\r\n",
        "state": "closed",
        "user": "mayuanyang",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-29T12:07:19+00:00",
        "updated_at": "2025-06-27T03:37:51+00:00",
        "closed_at": "2025-06-27T03:37:51+00:00",
        "comments_count": [
            "zxcd",
            "mayuanyang",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3286,
        "title": "请问如何提升tts的连续性，而不是一个字一个字地说",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "dawenxi-only",
        "closed_by": "stale[bot]",
        "created_at": "2023-05-30T01:55:50+00:00",
        "updated_at": "2025-04-27T21:55:58+00:00",
        "closed_at": "2025-04-27T21:55:58+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3289,
        "title": "[TTS]synthesize_e2e.py使用use_rhy=True报错,错误位置rhy_predictor.py, line117，text += self.punc_list[l]. IndexError：list index out of range。请问怎么解决",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "dawenxi-only",
        "closed_by": null,
        "created_at": "2023-05-30T09:27:28+00:00",
        "updated_at": "2023-06-06T07:19:45+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3288,
        "title": "如何规避运行时必须输入Y/N",
        "body": "想问一下这个模型的输入音频是否有要求，通过py脚本实现方式下，为什么每次运行都需要输入Y/N，最简单声纹官方demo也是如此。\r\n",
        "state": "open",
        "user": "AntyRia",
        "closed_by": null,
        "created_at": "2023-05-30T09:11:40+00:00",
        "updated_at": "2025-06-27T02:32:39+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "CobeeBryant",
            "stale[bot]",
            "Artrajz",
            "lonngxiang",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3291,
        "title": "numpy版本不匹配",
        "body": "我用win11,python10,快捷安装的pip install paddlespeech用pycharm运行报错，自动安装的numpy版本不匹配\r\nAttributeError: module 'numpy' has no attribute 'complex'.\r\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'complex_'?\r\n",
        "state": "open",
        "user": "jiangjunchishi",
        "closed_by": null,
        "created_at": "2023-05-31T04:48:28+00:00",
        "updated_at": "2023-06-02T09:54:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "barats",
            "barats",
            "barats",
            "Tony-Xie-182",
            "barats",
            "Tony-Xie-182",
            "Tony-Xie-182"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3295,
        "title": "[S2T]declarative() got an unexpected keyword argument 'property'",
        "body": "\r\n**使用容器镜像：** docker pull paddlecloud/paddlespeech:develop-cpu-latest\r\ndocker run -it -v ./paddle_volume:/mnt/volume docker.io/paddlecloud/paddlespeech:develop-cpu-latest /bin/bash\r\n\r\n**查看版本：paddlespeech version 输出：**\r\nCommit ID:\r\n    5f53e902e1c85a7ec6c1645d61a26701d171428a\r\n\r\n**执行命令：paddlespeech asr --lang zh --input /mnt/volume/zh.wav**\r\n      其中zh.wav来源于：https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav\r\n输出：\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py:1104: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  elif dtype == np.bool:\r\n**TypeError: declarative() got an unexpected keyword argument 'property'**\r\n\r\n这个镜像版本应该挺新的，跟[#2512](https://github.com/PaddlePaddle/PaddleSpeech/issues/2512)的升级版本好像不一样？\r\n请问这个应该怎么解决呢？\r\n",
        "state": "closed",
        "user": "itltf512116",
        "closed_by": "itltf512116",
        "created_at": "2023-05-31T07:31:54+00:00",
        "updated_at": "2023-06-03T02:21:15+00:00",
        "closed_at": "2023-06-02T03:06:46+00:00",
        "comments_count": [
            "zh794390558",
            "itltf512116",
            "zh794390558",
            "itltf512116",
            "itltf512116",
            "itltf512116",
            "RickCao-2017"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3296,
        "title": "paddlespeech_server 只有启动会占用显存，TTS服务调用时 显存没有变化",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/88914706/188be0a5-1c15-4230-8418-fe44002226db)\r\n服务端启动成功后 ，执行：\r\npaddle speech _ client TTS-server _ IP 127 . 0 . 0 . 1-端口8090 -输入\"您好,欢迎使用百度飞桨语音合成服务. \"- output output.wav\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/88914706/6b82c1f6-ac28-4033-944f-4400324500da)\r\n显存没有任何变化，cpu占用很高\r\n",
        "state": "closed",
        "user": "2954456878",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-01T02:23:37+00:00",
        "updated_at": "2025-04-27T21:55:47+00:00",
        "closed_at": "2025-04-27T21:55:47+00:00",
        "comments_count": [
            "2954456878",
            "a0735a",
            "2954456878",
            "zh794390558",
            "2954456878",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3297,
        "title": "TTS多音字问题",
        "body": "如题，“银行”、“行人”等模型可以正确识别；但是“欢迎来到我行办理业务”这种情况模型无法正确处理多音字，应该怎么解决？\r\n",
        "state": "closed",
        "user": "NLPerxue",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-01T02:53:29+00:00",
        "updated_at": "2025-06-27T06:33:36+00:00",
        "closed_at": "2025-06-27T06:33:36+00:00",
        "comments_count": [
            "zh794390558",
            "NLPerxue",
            "stale[bot]",
            "csukuangfj",
            "think4j",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3299,
        "title": "录音识别 可以针对双声道的录音，分声道进行识别吗",
        "body": null,
        "state": "closed",
        "user": "2954456878",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-01T09:21:43+00:00",
        "updated_at": "2025-04-27T21:55:39+00:00",
        "closed_at": "2025-04-27T21:55:39+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3304,
        "title": "基于hifigan_ljspeech的流式tts语音效果非常糟糕,感觉有些音会重复播放",
        "body": "              example中有介绍流式相关的训练流程，可以参看下。\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/librispeech/asr1/conf/chunk_conformer.yaml\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/csmsc/tts3/conf/cnndecoder.yaml\r\n\r\n_Originally posted by @zh794390558 in https://github.com/PaddlePaddle/PaddleSpeech/issues/3272#issuecomment-1566404766_\r\n            ",
        "state": "closed",
        "user": "ouyangliping2021",
        "closed_by": "ouyangliping2021",
        "created_at": "2023-06-02T07:31:12+00:00",
        "updated_at": "2023-06-16T08:35:37+00:00",
        "closed_at": "2023-06-16T08:35:37+00:00",
        "comments_count": [
            "ouyangliping2021"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3313
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3306,
        "title": "T2S 合成语音时，开始的几秒音量会比较小，这个有解吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "H-Yin",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-02T09:57:48+00:00",
        "updated_at": "2025-04-27T21:55:52+00:00",
        "closed_at": "2025-04-27T21:55:52+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3307,
        "title": "Voice Cloning . Got ValueError: (InvalidArgument) Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 589505315 found).",
        "body": "I wanted to test the paddlespeech repo to clone a voice . My target text is english. (is that possible?)\r\nHere are the steps that ive taken.\r\n\r\n- cloned the repo (` /mnt/msd/users/arnav/ ` is my workspace) and installed dependencies \r\n- cd into PaddleSpeech/examples/aishell3/vc1/\r\n- downloaded and unzipped the [fastspeech2_nosil_aishell3_vc1_ckpt_0.5.zip](https://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_nosil_aishell3_vc1_ckpt_0.5.zip) and [pwg_aishell3_ckpt_0.5.zip](https://paddlespeech.bj.bcebos.com/Parakeet/released_models/pwgan/pwg_aishell3_ckpt_0.5.zip)\r\n- Ive moved them into appropriate folders and this is how my file tree looks.\r\n- <img width=\"611\" alt=\"Screenshot 2023-06-02 at 4 14 48 PM\" src=\"https://github.com/PaddlePaddle/PaddleGAN/assets/133632434/bd729e55-64bd-4a4d-aace-f814afc99617\">\r\n- saloni is the voice i want to clone\r\n- ive modified the voice_cloning.sh as:\r\n```\r\n #!/bin/bash\r\n\r\nconfig_path=$1\r\ntrain_output_path=$2\r\nckpt_name=$3\r\nge2e_params_path=$4\r\nref_audio_dir=$5\r\n\r\npython3 /mnt/msd/users/arnav/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py \\\r\n    --am=fastspeech2_aishell3 \\\r\n    --am_config=${config_path} \\\r\n    --am_ckpt=${train_output_path}/checkpoints/${ckpt_name} \\\r\n    --am_stat=dump/train/speech_stats.npy \\\r\n    --voc=pwgan_aishell3 \\\r\n    --voc_config=pwg_aishell3_ckpt_0.5/default.yaml \\\r\n    --voc_ckpt=pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz \\\r\n    --voc_stat=pwg_aishell3_ckpt_0.5/feats_stats.npy \\\r\n    --ge2e_params_path=${ge2e_params_path} \\\r\n    --text=\"Hello my name is saloni\" \\\r\n    --input-dir=${ref_audio_dir} \\\r\n    --output-dir=${train_output_path}/vc_syn \\\r\n    --phones-dict=dump/phone_id_map.txt\r\n```\r\n- im running the code using : \r\n`CUDA_VISIBLE_DEVICES=0 ./voice_cloning.sh /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/conf/default.yaml /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/pretrained  fastspeech2_nosil_aishell3_vc1_ckpt_0.5 /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/local/ge2e_ckpt_0.3/step-3000000.pdparams /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/saloni`\r\n- This is the output im getting\r\n```\r\n/bin/bash: /home/newzera/anaconda3/envs/paddlespeech/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n========Args========\r\nam: fastspeech2_aishell3\r\nam_ckpt: /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/pretrained/checkpoints/fastspeech2_nosil_aishell3_vc1_ckpt_0.5\r\nam_config: /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/conf/default.yaml\r\nam_stat: dump/train/speech_stats.npy\r\nge2e_params_path: /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/local/ge2e_ckpt_0.3/step-3000000.pdparams\r\ninput_dir: /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/saloni\r\nngpu: 1\r\noutput_dir: /mnt/msd/users/arnav/PaddleSpeech/examples/aishell3/vc1/pretrained/vc_syn\r\nphones_dict: dump/phone_id_map.txt\r\ntext: Hello my name is saloni\r\nuse_ecapa: false\r\nvoc: pwgan_aishell3\r\nvoc_ckpt: pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz\r\nvoc_config: pwg_aishell3_ckpt_0.5/default.yaml\r\nvoc_stat: pwg_aishell3_ckpt_0.5/feats_stats.npy\r\n\r\n========Config========\r\nbatch_size: 64\r\nf0max: 400\r\nf0min: 80\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\nmax_epoch: 200\r\nmodel:\r\n  adim: 384\r\n  aheads: 2\r\n  decoder_normalize_before: True\r\n  dlayers: 4\r\n  dunits: 1536\r\n  duration_predictor_chans: 256\r\n  duration_predictor_kernel_size: 3\r\n  duration_predictor_layers: 2\r\n  elayers: 4\r\n  encoder_normalize_before: True\r\n  energy_embed_dropout: 0.0\r\n  energy_embed_kernel_size: 1\r\n  energy_predictor_chans: 256\r\n  energy_predictor_dropout: 0.5\r\n  energy_predictor_kernel_size: 3\r\n  energy_predictor_layers: 2\r\n  eunits: 1536\r\n  init_dec_alpha: 1.0\r\n  init_enc_alpha: 1.0\r\n  init_type: xavier_uniform\r\n  pitch_embed_dropout: 0.0\r\n  pitch_embed_kernel_size: 1\r\n  pitch_predictor_chans: 256\r\n  pitch_predictor_dropout: 0.5\r\n  pitch_predictor_kernel_size: 5\r\n  pitch_predictor_layers: 5\r\n  positionwise_conv_kernel_size: 3\r\n  positionwise_layer_type: conv1d\r\n  postnet_chans: 256\r\n  postnet_filts: 5\r\n  postnet_layers: 5\r\n  reduction_factor: 1\r\n  spk_embed_dim: 256\r\n  spk_embed_integration_type: concat\r\n  stop_gradient_from_energy_predictor: False\r\n  stop_gradient_from_pitch_predictor: True\r\n  transformer_dec_attn_dropout_rate: 0.2\r\n  transformer_dec_dropout_rate: 0.2\r\n  transformer_dec_positional_dropout_rate: 0.2\r\n  transformer_enc_attn_dropout_rate: 0.2\r\n  transformer_enc_dropout_rate: 0.2\r\n  transformer_enc_positional_dropout_rate: 0.2\r\n  use_scaled_pos_enc: True\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_snapshots: 5\r\nnum_workers: 2\r\noptimizer:\r\n  learning_rate: 0.001\r\n  optim: adam\r\nseed: 10086\r\nupdater:\r\n  use_masking: True\r\nwin_length: 1200\r\nwindow: hann\r\nallow_cache: True\r\nbatch_max_steps: 24000\r\nbatch_size: 8\r\ndiscriminator_grad_norm: 1\r\ndiscriminator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ndiscriminator_params:\r\n  bias: True\r\n  conv_channels: 64\r\n  in_channels: 1\r\n  kernel_size: 3\r\n  layers: 10\r\n  nonlinear_activation: LeakyReLU\r\n  nonlinear_activation_params:\r\n    negative_slope: 0.2\r\n  out_channels: 1\r\n  use_weight_norm: True\r\ndiscriminator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 5e-05\r\n  step_size: 200000\r\ndiscriminator_train_start_steps: 100000\r\neval_interval_steps: 1000\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\ngenerator_grad_norm: 10\r\ngenerator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ngenerator_params:\r\n  aux_channels: 80\r\n  aux_context_window: 2\r\n  dropout: 0.0\r\n  gate_channels: 128\r\n  in_channels: 1\r\n  kernel_size: 3\r\n  layers: 30\r\n  out_channels: 1\r\n  residual_channels: 64\r\n  skip_channels: 64\r\n  stacks: 3\r\n  upsample_scales: [4, 5, 3, 5]\r\n  use_weight_norm: True\r\ngenerator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 0.0001\r\n  step_size: 200000\r\nlambda_adv: 4.0\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_save_intermediate_results: 4\r\nnum_snapshots: 10\r\nnum_workers: 4\r\npin_memory: True\r\nremove_short_samples: True\r\nsave_interval_steps: 5000\r\nseed: 42\r\nstft_loss_params:\r\n  fft_sizes: [1024, 2048, 512]\r\n  hop_sizes: [120, 240, 50]\r\n  win_lengths: [600, 1200, 240]\r\n  window: hann\r\ntrain_max_steps: 1000000\r\nwin_length: 1200\r\nwindow: hann\r\nAudio Processor Done!\r\nW0602 10:52:56.641338 144178 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 10.2\r\nW0602 10:52:56.642062 144178 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\r\nGE2E Done!\r\n[2023-06-02 10:53:00,516] [    INFO] - Already cached /home/arnav-newzera/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-06-02 10:53:00,524] [    INFO] - tokenizer config file saved in /home/arnav-newzera/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-06-02 10:53:00,524] [    INFO] - Special tokens file saved in /home/arnav-newzera/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\nfrontend done!\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-06-02 10:53:00] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2023-06-02 10:53:00] [DEBUG] [__init__.py:133] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.499 seconds.\r\n[2023-06-02 10:53:01] [DEBUG] [__init__.py:165] Loading model cost 0.499 seconds.\r\nPrefix dict has been built successfully.\r\n[2023-06-02 10:53:01] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\nTraceback (most recent call last):\r\n  File \"/mnt/msd/users/arnav/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 233, in <module>\r\n    main()\r\n  File \"/mnt/msd/users/arnav/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 229, in main\r\n    voice_cloning(args)\r\n  File \"/mnt/msd/users/arnav/PaddleSpeech/paddlespeech/t2s/exps/voice_cloning.py\", line 106, in voice_cloning\r\n    phones_dict=args.phones_dict)\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 371, in get_am_inference\r\n    am.set_state_dict(paddle.load(am_ckpt)[\"main_params\"])\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/framework/io.py\", line 1103, in load\r\n    load_result = _legacy_load(path, **configs)\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/framework/io.py\", line 1150, in _legacy_load\r\n    load_result = _load_state_dict_from_save_params(model_path)\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/framework/io.py\", line 147, in _load_state_dict_from_save_params\r\n    attrs={'file_path': os.path.join(model_path, name)},\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py\", line 314, in trace_op\r\n    stop_gradient, inplace_map)\r\n  File \"/home/newzera/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py\", line 176, in eager_legacy_trace_op\r\n    returns = function_ptr(*arg_list, *attrs_list)\r\nValueError: (InvalidArgument) Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 589505315 found).\r\n  [Hint: Expected version == 0U, but received version:589505315 != 0U:0.] (at /paddle/paddle/phi/core/serialization.cc:106)\r\n  [operator < load > error]\r\n```\r\n\r\nCan anyone tell me what i did wrong? or how to resolve the error? Please be forgiving as im new to this. I did search the web for this error. The main consensus was that the model was corrupted but i dowloaded it twice. so it cant be that. \r\n",
        "state": "closed",
        "user": "arnav-newzera",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-02T11:10:09+00:00",
        "updated_at": "2025-06-27T04:34:22+00:00",
        "closed_at": "2025-06-27T04:34:22+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "Change0028",
            "Change0028",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3308,
        "title": "way to fix \"magic_number = pickle_module.load(f, **pickle_load_args)  EOFError: Ran out of input\"",
        "body": "If you encounter an error similar to the one below, please note your checkpoints file and pfggan files, they could both have only file names but 0 file sizes.\r\n![bugs](https://github.com/PaddlePaddle/PaddleSpeech/assets/48686098/0c260dce-41ef-47fd-a28e-b6368597adf8)\r\nI used this script and had this problem：\r\n’‘’bash scripts/download_models.sh‘’‘\r\nwhich was solved by using another way to download the file and upload them to the right place",
        "state": "closed",
        "user": "Tony-xubiao",
        "closed_by": "Tony-xubiao",
        "created_at": "2023-06-02T18:52:23+00:00",
        "updated_at": "2023-06-08T02:56:28+00:00",
        "closed_at": "2023-06-08T02:56:27+00:00",
        "comments_count": [
            "zh794390558",
            "Tony-xubiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3309,
        "title": "是否可以使用 paddlespeech 克隆英语语音？ 我有一个说英语的人，我想用她的声音做 tts。",
        "body": "\r\n是否可以使用 paddlespeech 克隆英语语音？ 我有一个说英语的人，我想用她的声音做 tts。\r\n\r\nIs it possible to clone a english voice using paddlespeech?  I have a english speaker, i want to do tts  using her voice.",
        "state": "closed",
        "user": "arnav-newzera",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-05T06:05:28+00:00",
        "updated_at": "2025-06-27T04:34:16+00:00",
        "closed_at": "2025-06-27T04:34:16+00:00",
        "comments_count": [
            "zh794390558",
            "arnav-newzera",
            "arnav-newzera",
            "zh794390558",
            "arnav-newzera",
            "NLPerxue",
            "lisc199",
            "Tony-xubiao",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3311,
        "title": "ASR多音字问题",
        "body": "使用流式ASR服务时，语音识别效果差，如识别结果为“晴初是身份证”，这种问题应该怎么优化呢，换模型吗？\r\n调用方式如下：\r\nfrom paddlespeech.server.bin.paddlespeech_server import ServerExecutor\r\nstreaming_asr_server = ServerExecutor()\r\nstreaming_asr_server(config_file=args.config_file, log_file=args.log_file)\r\n",
        "state": "closed",
        "user": "NLPerxue",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-06T05:51:59+00:00",
        "updated_at": "2025-06-27T03:38:10+00:00",
        "closed_at": "2025-06-27T03:38:10+00:00",
        "comments_count": [
            "zxcd",
            "NLPerxue",
            "zxcd",
            "NLPerxue",
            "yq-xfl",
            "wwfcnu",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3312,
        "title": "paddlespeech/server/restful/tts_api.py, line100, in tts   tts_engine = engine_pool['tts'] keyError:'tts'",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "shirly35",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-06T10:47:11+00:00",
        "updated_at": "2025-04-27T21:56:13+00:00",
        "closed_at": "2025-04-27T21:56:13+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3315
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3314,
        "title": "0英文样本的中文发音人  跨语言学习方案 是哪个项目呢",
        "body": "跨语言学习方案可以让0英文样本的中文发音人（Chinese Standard Mandarin Speech Copus）实现同音色双语播报。 想问一下具体项目位置。另外，还想问一下，目前有500句左右中文单人音频，足够训练出比较好的效果吗",
        "state": "closed",
        "user": "litao28",
        "closed_by": "litao28",
        "created_at": "2023-06-07T02:55:19+00:00",
        "updated_at": "2023-06-08T02:10:08+00:00",
        "closed_at": "2023-06-08T02:09:50+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3318,
        "title": "TTS中英文混合部分 大写字母A发音是a good girl 的”a“，那‘A’‘B’‘C’的A发音要怎么获取呢",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "litao28",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-08T02:22:27+00:00",
        "updated_at": "2025-06-27T03:37:47+00:00",
        "closed_at": "2025-06-27T03:37:47+00:00",
        "comments_count": [
            "litao28",
            "zxcd",
            "litao28",
            "zh794390558",
            "litao28",
            "arhcer",
            "litao28",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]",
            "litao28"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3317,
        "title": "[TTS]操作复杂，不易使用",
        "body": "paddlespeech没有一个统一的操作入口。\r\n比如语音合成，按常人逻辑来讲，应该是统一的客户端代码，然后指定模型名称或路径进行加载模型，然后加载声码器，进行语音合成，得到最后的语音数据，是保存为语音文件呢，还是其他操作，应该由用户自己决定。\r\n训练：应该直接在配置文件中配置好信息后，使用python脚本传递参数就可以进行训练或微调了。现在看到的文档上大部分都是教写python代码的，第一步写什么代码，第二步些什么代码等，太麻烦，难以使用。",
        "state": "open",
        "user": "zapjone",
        "closed_by": null,
        "created_at": "2023-06-08T02:03:28+00:00",
        "updated_at": "2023-06-08T03:09:49+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3319,
        "title": "TTS:如何不保存WAV,直接播放音频？",
        "body": "TTS:\r\n如何不保存WAV,直接播放音频？\r\n\r\n现在只能保存到WAV\r\n然后加载WAV 才能播放",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-08T04:06:23+00:00",
        "updated_at": "2025-06-27T02:33:17+00:00",
        "closed_at": "2025-06-27T02:33:17+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3320,
        "title": "请问ASR有批量处理的例子吗？",
        "body": "根据例子(基于 PP-ASR 的长语音转写)处理长语音转写，需要切分音频，再进行识别。在转写识别的过程中，要不断重新启动模型。请问有固定模型批量处理音频的例子吗？\r\n\r\nasr = ASRExecutor()\r\n\r\nlong_asr_result = \"\"\r\nfor idx, sub_wav in tqdm.tqdm(enumerate(sub_wavs)):\r\n    audio = f\"work/temp_{idx}.wav\"\r\n    soundfile.write(audio, sub_wav, sample_rate)\r\n    asr_result = asr(audio_file=audio, model='conformer_online_wenetspeech')\r\n    if asr_result:\r\n        # 有识别结果才恢复标点\r\n        text_result = text_punc(text=asr_result)\r\n        long_asr_result += text_result\r\n\r\n",
        "state": "closed",
        "user": "thehzzz",
        "closed_by": "thehzzz",
        "created_at": "2023-06-08T06:06:52+00:00",
        "updated_at": "2023-06-09T12:43:14+00:00",
        "closed_at": "2023-06-09T12:43:14+00:00",
        "comments_count": [
            "zh794390558",
            "thehzzz",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3322,
        "title": "[TTS]语音韵律合成MFA问题",
        "body": "参照https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/csmsc/tts3_rhy文档进行韵律标签生成时。\r\n执行sh run.sh --rhy-with-duration出现以下错误，请问大佬们，谁遇到过这种问题，怎么解决的呢？\r\ngenerating lexicon...\r\nDone!\r\nlexicon done\r\nreorganizing baker corpus...\r\nresampling: 0it [00:00, ?it/s]\r\ntranscription process: 100%|███████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 29822.81it/s]\r\nDone!\r\nreorganization done. Check output in exp/baker_corpus.\r\naudio files are resampled to 16kHz\r\ntranscription for each audio file is saved with the same namd in exp/baker_corpus \r\ndetecting oov...\r\nNamespace(corpus_dir='exp/baker_corpus', lexicon_path='exp/simple.lexicon', pattern='*.lab')\r\nWARNING:root:005107.lab has OOV ng1 .\r\nWARNING:root:002365.lab has OOV P .\r\nWARNING:root:002365.lab has OOV IY1 .\r\ndetecting oov done. you may consider regenerate lexicon if there is unexpected OOVs.\r\nStart MFA training...\r\nSetting up corpus information...\r\nset()\r\nTraceback (most recent call last):\r\n  File \"aligner/command_line/train_and_align.py\", line 171, in <module>\r\n  File \"aligner/command_line/train_and_align.py\", line 53, in align_corpus\r\n  File \"aligner/dictionary.py\", line 128, in __init__\r\n  File \"aligner/dictionary.py\", line 18, in compile_graphemes\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/re.py\", line 233, in compile\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/re.py\", line 301, in _compile\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_compile.py\", line 562, in compile\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_parse.py\", line 855, in parse\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_parse.py\", line 416, in _parse_sub\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_parse.py\", line 765, in _parse\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_parse.py\", line 416, in _parse_sub\r\n  File \"/home/michael/miniconda3/envs/aligner/lib/python3.6/sre_parse.py\", line 523, in _parse\r\nsre_constants.error: unterminated character set at position 5\r\n[2503831] Failed to execute script train_and_align\r\ntraining done!\r\nresults: exp/baker_alignment\r\nmodel: exp/baker_model",
        "state": "closed",
        "user": "zapjone",
        "closed_by": "zapjone",
        "created_at": "2023-06-08T10:38:47+00:00",
        "updated_at": "2023-06-14T00:28:50+00:00",
        "closed_at": "2023-06-14T00:28:50+00:00",
        "comments_count": [
            "zh794390558",
            "zapjone",
            "zapjone"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3321,
        "title": "一运行示例程序就中断内核",
        "body": "你好想问一下，我成功按照教程安装了相关的步骤，并且运行\r\nimport paddle\r\npaddle.utils.run_check()\r\n输出为：\r\nRunning verify PaddlePaddle program ...\r\nPaddlePaddle works well on 1 GPU.\r\nPaddlePaddle works well on 1 GPUs.\r\nPaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n\r\n但是一运行示例的程序比如\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"3_output.WAV\")\r\nprint(result)\r\n会显示D:\\Anaconda\\envs\\PaddleSpeech\\lib\\site-packages\\paddleaudio_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\nwarnings.warn(\"paddleaudio C++ extension is not available.\")\r\n2023-06-08 15:45:38.229 | INFO | paddlespeech.s2t.modules.ctc::45 - paddlespeech_ctcdecoders not installed!\r\nD:\\Anaconda\\envs\\PaddleSpeech\\lib\\site-packages_distutils_hack_init_.py:33: UserWarning: Setuptools is replacing distutils.\r\nwarnings.warn(\"Setuptools is replacing distutils.\")\r\n2023-06-08 15:45:39.392 | INFO | paddlespeech.s2t.modules.embedding:init:150 - max len: 5000\r\n接着运行到一般就中断了内核无法继续执行了，\r\n\r\n运行from paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\ntts(text=\"今天天气十分不错。\", output=\"output.wav\")也是，显示D:\\Anaconda\\envs\\PaddleSpeech\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\r\nfrom .autonotebook import tqdm as notebook_tqdm\r\nD:\\Anaconda\\envs\\PaddleSpeech\\lib\\site-packages_distutils_hack_init_.py:33: UserWarning: Setuptools is replacing distutils.\r\nwarnings.warn(\"Setuptools is replacing distutils.\")\r\n[2023-06-08 17:14:34,036] [ INFO] - Already cached C:\\Users\\Zixuan Xu.paddlenlp\\models\\bert-base-chinese\\bert-base-chinese-vocab.txt\r\n[2023-06-08 17:14:34,048] [ INFO] - tokenizer config file saved in C:\\Users\\Zixuan Xu.paddlenlp\\models\\bert-base-chinese\\tokenizer_config.json\r\n[2023-06-08 17:14:34,049] [ INFO] - Special tokens file saved in C:\\Users\\Zixuan Xu.paddlenlp\\models\\bert-base-chinese\\special_tokens_map.json\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-06-08 17:14:38,529] [ DEBUG] init.py:113 - Building prefix dict from the default dictionary ...\r\nLoading model from cache C:\\Users\\ZIXUAN1\\AppData\\Local\\Temp\\jieba.cache\r\n[2023-06-08 17:14:38,530] [ DEBUG] init.py:132 - Loading model from cache C:\\Users\\ZIXUAN1\\AppData\\Local\\Temp\\jieba.cache\r\nLoading model cost 0.463 seconds.\r\n[2023-06-08 17:14:38,993] [ DEBUG] init.py:164 - Loading model cost 0.463 seconds.\r\nPrefix dict has been built successfully.\r\n[2023-06-08 17:14:38,994] [ DEBUG] init.py:166 - Prefix dict has been built successfully.\r\n然后也是中断了内核无法继续执行\r\n\r\n这是什么原因，我也正确安装了，我的系统是win11， 在anaconda中安装，\r\n系统是：GPU 0\r\n\tNVIDIA GeForce RTX 3060 Laptop GPU\r\n\t驱动程序版本:\t31.0.15.3179\r\n\t驱动程序日期:\t2023/4/25\r\n\tDirectX 版本:\t12 (FL 12.1)\r\n\t物理位置：\tPCI 总线 1、设备 0、功能 0\r\n\t利用率\t0%\r\n\t专用 GPU 内存\t0.0/6.0 GB\r\n\t共享 GPU 内存\t0.0/7.6 GB\r\n\tGPU 内存\t0.0/13.6 GB\r\n也并没有过载运行，但是就是一运行就运行到一半中断内核，请问有人遇到相关的问题吗\r\n\r\n",
        "state": "closed",
        "user": "Zixuan-Xu-GodVision",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-08T09:36:35+00:00",
        "updated_at": "2025-06-27T02:33:16+00:00",
        "closed_at": "2025-06-27T02:33:16+00:00",
        "comments_count": [
            "Zixuan-Xu-GodVision",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3324,
        "title": "跑paddlespeech流式语音合成的demo报错",
        "body": "### bug描述 Describe the Bug\r\n跑paddlespeech流式语音合成的demo报错\r\n\r\n所用的demo:\r\n```\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_asr_server\r\n```\r\n环境;\r\n- Windows版本: win10 22H2\r\n- WSL版本: Ubuntu22.04\r\n- Python版本:3.8\r\n- Cuda版本: 11.7\r\n- paddle版本: paddlepaddle-gpu==2.4.2.post117\r\n- paddlespeech版本: \r\nName: paddlespeech\r\nVersion: 1.4.1\r\nSummary: Speech tools and models based on Paddlepaddle\r\nHome-page: https://github.com/PaddlePaddle/PaddleSpeech\r\nAuthor: PaddlePaddle Speech and Language Team\r\nAuthor-email: paddlesl@baidu.com\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.8/dist-packages\r\nRequires: braceexpand, editdistance, g2p-en, g2pM, h5py, hyperpyyaml, inflect, jsonlines, librosa, loguru, matplotlib, nara-wpe, onnxruntime, opencc, opencc-python-reimplemented, paddleaudio, paddlenlp, paddleslim, paddlespeech-feat, pandas, pattern-singleton, ppdiffusers, praatio, prettytable, pypinyin, pypinyin-dict, python-dateutil, pyworld, pyyaml, resampy, sacrebleu, textgrid, timer, ToJyutping, typeguard, webrtcvad, websockets, yacs, zhon\r\nRequired-by:\r\n- 显卡: NVIDIA GeForce 940MX\r\n- 显卡驱动:\r\nroot@DESKTOP-N1VBR8B:/home/donnchao/netstar-paddle-service# nvidia-smi\r\nThu Jun  8 18:13:14 2023\r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 530.50                 Driver Version: 531.79       CUDA Version: 12.1     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  NVIDIA GeForce 940MX            On | 00000000:02:00.0 Off |                  N/A |\r\n| N/A    0C    P8               N/A /  N/A|   1928MiB /  2048MiB |      7%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n\r\n+---------------------------------------------------------------------------------------+\r\n| Processes:                                                                            |\r\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n|        ID   ID                                                             Usage      |\r\n|=======================================================================================|\r\n|    0   N/A  N/A       460      C   /python3.8                                N/A      |\r\n|    0   N/A  N/A       619      C   /python3.8                                N/A      |\r\n+---------------------------------------------------------------------------------------+\r\n\r\n报错信息:\r\n```txt\r\nW0608 17:52:23.794795   619 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 5.0, Driver API Version: 12.1, Runtime API Version: 11.7\r\nW0608 17:52:23.795691   619 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\r\n2023-06-08 17:52:24.173 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-06-08 17:52:32,734] [    INFO] - Already cached /root/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-06-08 17:52:32,746] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-06-08 17:52:32,746] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\n[2023-06-08 17:52:34,041] [    INFO] - start to init the engine\r\n[2023-06-08 17:52:34,042] [    INFO] - asr : online engine.\r\n2023-06-08 17:52:38.759 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-06-08 17:52:44,145] [    INFO] - Initialize ASR server engine successfully on device: gpu:0.\r\nINFO:     Started server process [619]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)\r\nINFO:     ('127.0.0.1', 38850) - \"WebSocket /paddlespeech/asr/streaming\" [accepted]\r\nINFO:     connection open\r\n[2023-06-08 17:56:20,669] [    INFO] - first and second beam size: 10, 10\r\n[2023-06-08 17:56:20,669] [    INFO] - Endpont Opts: OnlineCTCEndpoingOpt(frame_shift_in_ms=10, blank=0, blank_threshold=0.8, rule1=OnlineCTCEndpointRule(must_contain_nonsilence=False, min_trailing_silence=5000, min_utterance_length=0), rule2=OnlineCTCEndpointRule(must_contain_nonsilence=True, min_trailing_silence=1000, min_utterance_length=0), rule3=OnlineCTCEndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20000))\r\n[2023-06-08 17:56:21,283] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,313] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,314] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,330] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,331] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,347] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,348] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,363] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,364] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,381] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,381] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,401] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,402] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,421] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,421] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:22,444] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:22,444] [    INFO] - start to do model forward\r\n[2023-06-08 17:56:29,403] [    INFO] - start to ctc prefix search\r\n[2023-06-08 17:56:29,403] [    INFO] - effect first and second beam size: 10, 10\r\nE0608 17:56:29.404129   619 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\nE0608 17:56:29.444546   619 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\n[2023-06-08 17:56:29,445] [   ERROR] - (OutOfRange) The starting index 34745229312 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [-5538, 5538). (at /paddle/paddle/fluid/pybind/slice_utils.h:209)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"/usr/local/lib/python3.8/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 504, in advance_decoding\r\n    self.searcher.search(ctc_probs, self.cached_feat.place)\r\n  File \"/usr/local/lib/python3.8/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/ctc_search.py\", line 108, in search\r\n    ps = logp[s].item()\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 753, in __getitem__\r\n    return self._getitem_index_not_tensor(item)\r\nIndexError: (OutOfRange) The starting index 34745229312 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [-5538, 5538). (at /paddle/paddle/fluid/pybind/slice_utils.h:209)\r\n\r\n[2023-06-08 17:56:29,456] [    INFO] - Online ASR extract the feat\r\n[2023-06-08 17:56:29,492] [    INFO] - we will use the transformer like model : conformer_online_wenetspeech\r\n[2023-06-08 17:56:29,493] [    INFO] - start to do model forward\r\n[2023-06-08 17:56:29,775] [    INFO] - start to ctc prefix search\r\n[2023-06-08 17:56:29,775] [    INFO] - effect first and second beam size: 10, 10\r\nE0608 17:56:29.776302   619 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\nE0608 17:56:29.805565   619 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\n[2023-06-08 17:56:29,806] [   ERROR] - (OutOfRange) The starting index 34394905088 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [-5538, 5538). (at /paddle/paddle/fluid/pybind/slice_utils.h:209)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"/usr/local/lib/python3.8/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/python/asr_engine.py\", line 504, in advance_decoding\r\n    self.searcher.search(ctc_probs, self.cached_feat.place)\r\n  File \"/usr/local/lib/python3.8/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/server/engine/asr/online/ctc_search.py\", line 108, in search\r\n    ps = logp[s].item()\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 753, in __getitem__\r\n    return self._getitem_index_not_tensor(item)\r\nIndexError: (OutOfRange) The starting index 34394905088 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [-5538, 5538). (at /paddle/paddle/fluid/pybind/slice_utils.h:209)\r\n```\r\n\r\n\r\n### 其他补充信息 Additional Supplementary Information\r\n\r\n_No response_",
        "state": "open",
        "user": "dongchao139",
        "closed_by": null,
        "created_at": "2023-06-09T02:13:46+00:00",
        "updated_at": "2023-06-12T06:40:38+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3325,
        "title": "能否实现这样的需求 2个声音是否发出相同的语音",
        "body": "paddlespeech 能实现 判断2个发音 是否 是同一个发音  比如声音1 男生说  你好（地方方言无法识别为文字的那种）  声音2  女生说   你好（地方方言无法识别为文字的那种）    ",
        "state": "open",
        "user": "huangweixiao",
        "closed_by": null,
        "created_at": "2023-06-09T11:19:04+00:00",
        "updated_at": "2023-06-12T07:17:50+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "huangweixiao",
            "huangweixiao"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3328
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3326,
        "title": "本地部署报错",
        "body": "E:\\jy\\test>python app.py\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 11004] getaddrinfo failed>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 11004]\r\n[nltk_data]     getaddrinfo failed>\r\nC:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\core\\constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2023-06-10 01:41:51,157] [    INFO] - Already cached C:\\Users\\79420\\.paddlenlp\\models\\bert-base-chinese\\bert-base-chinese-vocab.txt\r\n[2023-06-10 01:41:51,543] [    INFO] - tokenizer config file saved in C:\\Users\\79420\\.paddlenlp\\models\\bert-base-chinese\\tokenizer_config.json\r\n[2023-06-10 01:41:51,544] [    INFO] - Special tokens file saved in C:\\Users\\79420\\.paddlenlp\\models\\bert-base-chinese\\special_tokens_map.json\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\", line 84, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{zip_name}\")\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource cmudict not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('cmudict')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/cmudict.zip/cmudict/\r\n\r\n  Searched in:\r\n    - 'C:\\\\Users\\\\79420/nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Roaming\\\\nltk_data'\r\n    - 'C:\\\\nltk_data'\r\n    - 'D:\\\\nltk_data'\r\n    - 'E:\\\\nltk_data'\r\n**********************************************************************\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\jy\\test\\app.py\", line 26, in <module>\r\n    frontend = get_frontend(\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 274, in get_frontend\r\n    frontend = MixFrontend(\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\mix_frontend.py\", line 34, in __init__\r\n    self.en_frontend = English(phone_vocab_path=phone_vocab_path)\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\phonectic.py\", line 53, in __init__\r\n    self.backend = G2p()\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\g2p_en\\g2p.py\", line 71, in __init__\r\n    self.cmu = cmudict.dict()\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\", line 121, in __getattr__\r\n    self.__load()\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\", line 86, in __load\r\n    raise e\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\", line 81, in __load\r\n    root = nltk.data.find(f\"{self.subdir}/{self.__name}\")\r\n  File \"C:\\Users\\79420\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\", line 583, in find\r\n    raise LookupError(resource_not_found)\r\nLookupError:\r\n**********************************************************************\r\n  Resource cmudict not found.\r\n  Please use the NLTK Downloader to obtain the resource:\r\n\r\n  >>> import nltk\r\n  >>> nltk.download('cmudict')\r\n\r\n  For more information see: https://www.nltk.org/data.html\r\n\r\n  Attempted to load corpora/cmudict\r\n\r\n  Searched in:\r\n    - 'C:\\\\Users\\\\79420/nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\r\n    - 'C:\\\\Users\\\\79420\\\\AppData\\\\Roaming\\\\nltk_data'\r\n    - 'C:\\\\nltk_data'\r\n    - 'D:\\\\nltk_data'\r\n    - 'E:\\\\nltk_data'\r\n**********************************************************************\r\n\r\n\r\n环境：windows11\r\npython版本：3.9.9\r\nnltk_data也已重新下载\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import nltk\r\n>>>\r\n>>> nltk.find('.')\r\nFileSystemPathPointer('E:\\\\nltk_data')\r\n",
        "state": "closed",
        "user": "OneTrueSum95",
        "closed_by": "OneTrueSum95",
        "created_at": "2023-06-09T17:45:02+00:00",
        "updated_at": "2023-06-12T06:43:33+00:00",
        "closed_at": "2023-06-12T06:43:33+00:00",
        "comments_count": [
            "zh794390558",
            "OneTrueSum95"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3327,
        "title": "英文标点恢复使用哪个预训练模型比较好？ernie?bert?",
        "body": "demo中的是中文标点恢复模型，采用的是ernie。改成英文标点恢复的话，采用哪个模型比价好呢？谢谢！\r\n",
        "state": "closed",
        "user": "dwaylin",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-10T01:02:46+00:00",
        "updated_at": "2025-06-27T02:33:14+00:00",
        "closed_at": "2025-06-27T02:33:14+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3333,
        "title": "请问男声音克隆能不能用模型fastspeech2_male_zh来克隆男声？",
        "body": "请问男声音克隆能不能用模型fastspeech2_male_zh来克隆男声？\r\n是更换fastspeech2_mix_ckpt就可以实现吗？",
        "state": "closed",
        "user": "thehzzz",
        "closed_by": "thehzzz",
        "created_at": "2023-06-12T08:09:43+00:00",
        "updated_at": "2023-06-16T11:30:26+00:00",
        "closed_at": "2023-06-16T11:30:26+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3329,
        "title": "[TTS]合成依赖问题",
        "body": "paddlespeech语音合成模型训练时，各种报错，有没有哪个地方有写明，需要的各种包的依赖的版本清单呢？",
        "state": "open",
        "user": "zapjone",
        "closed_by": null,
        "created_at": "2023-06-12T05:52:55+00:00",
        "updated_at": "2023-06-12T06:42:53+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3331,
        "title": "想要demos\\streaming_asr_server\\web\\index.html的源码",
        "body": "网页示例的ASR效果很好，但index.html好像没有提供源码。",
        "state": "closed",
        "user": "907122187",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-12T06:56:20+00:00",
        "updated_at": "2025-04-27T21:56:40+00:00",
        "closed_at": "2025-04-27T21:56:40+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3330,
        "title": "使用gpu，语音转文字，提示下面的报错，如何处理",
        "body": "/## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n![QQ图片20230612135611](https://github.com/PaddlePaddle/PaddleSpeech/assets/76512139/30a48996-10d1-4d33-95e0-50b2a348cf23)\r\n",
        "state": "closed",
        "user": "alexjs001",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-12T05:59:25+00:00",
        "updated_at": "2025-04-27T21:56:26+00:00",
        "closed_at": "2025-04-27T21:56:26+00:00",
        "comments_count": [
            "zh794390558",
            "alexjs001",
            "alexjs001",
            "alexjs001",
            "zh794390558",
            "alexjs001",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3332,
        "title": "[TTS]使用diffsinger模型运行synthesize_e2e.py时，出现AttributeError: can't set attribute",
        "body": "\r\n![企业微信截图_16865539168111](https://github.com/PaddlePaddle/PaddleSpeech/assets/66147448/9b6b5b5c-3e08-4ff0-9d7c-75d550ebfa96)\r\n\r\n",
        "state": "open",
        "user": "MUFCLK",
        "closed_by": null,
        "created_at": "2023-06-12T07:30:54+00:00",
        "updated_at": "2023-09-18T11:26:46+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "MUFCLK",
            "1416924176"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3337,
        "title": "onnxruntime推理失败-stage6",
        "body": "执行examples/csmsc下的run.sh --stage 6 --stop-stage 6来进行onnxruntime推理时（stage0~stage5都是已成功执行完成），报以下错误，请问有谁遇到过吗？\r\n[2023-06-14 08:23:03,244] [    INFO] - Already cached /home/icksys/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-06-14 08:23:03,254] [    INFO] - tokenizer config file saved in /home/icksys/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-06-14 08:23:03,254] [    INFO] - Special tokens file saved in /home/icksys/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-06-14 08:23:03,932] [   DEBUG] __init__.py:113 - Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2023-06-14 08:23:03,933] [   DEBUG] __init__.py:132 - Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.624 seconds.\r\n[2023-06-14 08:23:04,556] [   DEBUG] __init__.py:164 - Loading model cost 0.624 seconds.\r\nPrefix dict has been built successfully.\r\n[2023-06-14 08:23:04,556] [   DEBUG] __init__.py:166 - Prefix dict has been built successfully.\r\n2023-06-14 08:23:04.586965864 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=216 must be within the inclusive range [-208,207]\r\nTraceback (most recent call last):\r\n  File \"/home/icksys/tts/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 235, in <module>\r\n    main()\r\n  File \"/home/icksys/tts/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 231, in main\r\n    ort_predict(args)\r\n  File \"/home/icksys/tts/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 86, in ort_predict\r\n    am_sess.run(None, input_feed=am_input_feed)\r\n  File \"/home/icksys/anaconda3/envs/paddle/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 217, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=216 must be within the inclusive range [-208,207]",
        "state": "open",
        "user": "zapjone",
        "closed_by": null,
        "created_at": "2023-06-14T00:26:01+00:00",
        "updated_at": "2025-06-27T02:32:37+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "wmlgl",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3335,
        "title": "内存Out of memory，如何修改batch size",
        "body": "语音转文字，提示内存Out of memory，如何修改batch size，在哪里修改\r\n![QQ截图20230613162448](https://github.com/PaddlePaddle/PaddleSpeech/assets/76512139/745480fd-e624-42ba-b666-e04b302d6e87)\r\n",
        "state": "closed",
        "user": "alexjs001",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-13T08:27:03+00:00",
        "updated_at": "2025-04-27T21:56:46+00:00",
        "closed_at": "2025-04-27T21:56:46+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3338,
        "title": "目前官方TTS流式语音合成支持中英文混合识别吗？",
        "body": "目前官方TTS流式语音合成支持中英文混合识别吗？测试发现只单独支持中文或者英文",
        "state": "open",
        "user": "AI-Mart",
        "closed_by": null,
        "created_at": "2023-06-14T05:43:05+00:00",
        "updated_at": "2025-06-27T02:32:45+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "gclm",
            "stale[bot]",
            "Ankh-L",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3341,
        "title": "[TTS]Circular Import",
        "body": "from paddlespeech.cli.tts.infer import TTSExecutor \r\nleading to the following Error:\r\nImport Error: cannot import name 'CommonTaskResource' from partially initialized module 'paddlespeech.resource' (most likely due to a circular import)",
        "state": "closed",
        "user": "NaNYeYuan",
        "closed_by": "NaNYeYuan",
        "created_at": "2023-06-15T09:38:32+00:00",
        "updated_at": "2023-06-16T01:21:48+00:00",
        "closed_at": "2023-06-16T01:21:47+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3339,
        "title": "[TTS]文本中的连续点号会导致bug",
        "body": "我用的是r1.4分支。\r\n当我输入文本    “一边...一边...”写出脱离险境的劳累    时，会报错，提示tone_sandhi.py第89行报错。\r\n排查发现，问题在于zh_frontend.py第235行有问题，更深一步的原因在于seg_cut = psg.lcut(seg)，而pinyins = self.g2pW_model(seg)[0]，pinyins中的每个元素即可能是一个字的拼音，也可能是连续标点，例如'...'，然后后续会报错。\r\n解决办法是更改zh_frontend.py中的232行至235行，改成如下：\r\n```\r\nfor i, (word, pos) in enumerate(seg_cut):\r\n    sub_initials = []\r\n    sub_finals = []\r\n    if not '\\u4e00' <= word[0] <= '\\u9fff':\r\n        if i > 0 and not '\\u4e00' <= seg_cut[i-1][0][0] <= '\\u9fff':\r\n            continue\r\n        else:\r\n            now_word_length = pre_word_length + 1\r\n    else:\r\n        now_word_length = pre_word_length + len(word)\r\n```\r\n\r\n",
        "state": "open",
        "user": "arhcer",
        "closed_by": null,
        "created_at": "2023-06-14T06:20:55+00:00",
        "updated_at": "2023-06-15T02:21:28+00:00",
        "closed_at": null,
        "comments_count": [
            "arhcer",
            "arhcer"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3340,
        "title": "ASR--模型微调",
        "body": "使用现有的命令行启动ASR任务，有些领域内专有名词无法识别（大多会识别为同音字），PaddleSpeech是否支持通过添加个性化训练语料以实现“定制化ASR”呢？如果有，辛苦贴一下链接，谢谢。\r\n",
        "state": "closed",
        "user": "NLPerxue",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-14T08:15:02+00:00",
        "updated_at": "2025-04-27T18:51:22+00:00",
        "closed_at": "2025-04-27T18:51:22+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "wudanwei",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3343,
        "title": "请问是否有使用ONNX runtime部署TTS部分到armv7板子上的方案和demo？",
        "body": "## General Question\r\n使用ubuntu20.04虚拟机交叉编译，用adb push到板子上\r\n看能否给一些思路，感激不尽\r\n",
        "state": "closed",
        "user": "Tony-Xie-182",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-16T10:08:23+00:00",
        "updated_at": "2025-04-28T04:57:38+00:00",
        "closed_at": "2025-04-28T04:57:38+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3342,
        "title": "使用Fastspeech2模型，ljspeech数据集，对齐工具MFA2.0.0a，进行流式TTS训练，发现某些音的听感特别不好，像是会破音一样，比如sentences_en.txt文件中的chocolates,words,times这些单词。如果在训练的模型上另外在进行fineturne，那这个问题会变得更加严重，请问是模型对mfa2.0.0a支持不够吗？另外有一个问题很好奇，就是ljspeech数据集原始的对齐文件应该是用MFA1.0.1生成的吧，现在找不到MFA的1.0.1版本的美式发音字典和声学模型，如果有这方面的下载链接能否提供一下？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "ouyangliping2021",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-16T08:34:07+00:00",
        "updated_at": "2025-04-27T21:57:06+00:00",
        "closed_at": "2025-04-27T21:57:06+00:00",
        "comments_count": [
            "zh794390558",
            "ouyangliping2021",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3344,
        "title": "PaddleSpeech/demos/TTSArmLinux 编译提示Could NOT find OpenMP_C",
        "body": "\r\nCMake Error at /usr/share/cmake-3.16/Modules/FindPackageHandleStandardArgs.cmake:146 (message):\r\n  Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\r\nCall Stack (most recent call first):\r\n  /usr/share/cmake-3.16/Modules/FindPackageHandleStandardArgs.cmake:393 (_FPHSA_FAILURE_MESSAGE)\r\n  /usr/share/cmake-3.16/Modules/FindOpenMP.cmake:511 (find_package_handle_standard_args)\r\n  CMakeLists.txt:51 (find_package)\r\n\r\n请问这个是什么原因造成，一般怎么解决",
        "state": "open",
        "user": "newuser123k789",
        "closed_by": null,
        "created_at": "2023-06-17T06:44:00+00:00",
        "updated_at": "2025-06-27T02:32:32+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "newuser123k789",
            "newuser123k789",
            "newuser123k789",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3345,
        "title": "wav file import problem",
        "body": "\r\n`audio_file_path = '17973-2-0-32.wav'\r\nlibrosa_audio_data, librosa_sample_rate = librosa.load(audio_file_path)`\r\n\r\n`---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\soundfile.py:161\r\n    159     raise OSError('no packaged library for this platform')\r\n--> 161 import _soundfile_data  # ImportError if this doesn't exist\r\n    162 _path = _os.path.dirname(_soundfile_data.__file__)  # TypeError if __file__ is None\r\n\r\nModuleNotFoundError: No module named '_soundfile_data'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nOSError                                   Traceback (most recent call last)\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\soundfile.py:171\r\n    170         raise OSError('sndfile library not found using ctypes.util.find_library')\r\n--> 171     _snd = _ffi.dlopen(_libname)\r\n    173 except OSError:\r\n    174     # Try explicit file name, if the general does not work (e.g. on nixos)\r\n\r\nOSError: cannot load library 'C:\\Users\\beek6\\anaconda3\\envs\\tensorflow2\\Library\\bin\\sndfile.dll': error 0x7e\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nOSError                                   Traceback (most recent call last)\r\nCell In[4], line 2\r\n      1 audio_file_path = '17973-2-0-32.wav'\r\n----> 2 librosa_audio_data, librosa_sample_rate = librosa.load(audio_file_path)\r\n\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\lazy_loader\\__init__.py:77, in attach.<locals>.__getattr__(name)\r\n     75 submod_path = f\"{package_name}.{attr_to_modules[name]}\"\r\n     76 submod = importlib.import_module(submod_path)\r\n---> 77 attr = getattr(submod, name)\r\n     79 # If the attribute lives in a file (module) with the same\r\n     80 # name as the attribute, ensure that the attribute and *not*\r\n     81 # the module is accessible on the package.\r\n     82 if name == attr_to_modules[name]:\r\n\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\lazy_loader\\__init__.py:76, in attach.<locals>.__getattr__(name)\r\n     74 elif name in attr_to_modules:\r\n     75     submod_path = f\"{package_name}.{attr_to_modules[name]}\"\r\n---> 76     submod = importlib.import_module(submod_path)\r\n     77     attr = getattr(submod, name)\r\n     79     # If the attribute lives in a file (module) with the same\r\n     80     # name as the attribute, ensure that the attribute and *not*\r\n     81     # the module is accessible on the package.\r\n\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\importlib\\__init__.py:127, in import_module(name, package)\r\n    125             break\r\n    126         level += 1\r\n--> 127 return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\nFile <frozen importlib._bootstrap>:1030, in _gcd_import(name, package, level)\r\n\r\nFile <frozen importlib._bootstrap>:1007, in _find_and_load(name, import_)\r\n\r\nFile <frozen importlib._bootstrap>:986, in _find_and_load_unlocked(name, import_)\r\n\r\nFile <frozen importlib._bootstrap>:680, in _load_unlocked(spec)\r\n\r\nFile <frozen importlib._bootstrap_external>:850, in exec_module(self, module)\r\n\r\nFile <frozen importlib._bootstrap>:228, in _call_with_frames_removed(f, *args, **kwds)\r\n\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\librosa\\core\\audio.py:10\r\n      7 import pathlib\r\n      8 import warnings\r\n---> 10 import soundfile as sf\r\n     11 import audioread\r\n     12 import numpy as np\r\n\r\nFile ~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\soundfile.py:192\r\n    190             _snd = _ffi.dlopen(_os.path.join(_hbrew_path, _explicit_libname))\r\n    191         else:\r\n--> 192             _snd = _ffi.dlopen(_explicit_libname)\r\n    194 __libsndfile_version__ = _ffi.string(_snd.sf_version_string()).decode('utf-8', 'replace')\r\n    195 if __libsndfile_version__.startswith('libsndfile-'):\r\n\r\nOSError: cannot load library 'libsndfile.dll': error 0xc1`",
        "state": "closed",
        "user": "BerkYxvuz",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-17T13:15:52+00:00",
        "updated_at": "2025-06-27T03:37:36+00:00",
        "closed_at": "2025-06-27T03:37:36+00:00",
        "comments_count": [
            "zh794390558",
            "BerkYxvuz",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3346,
        "title": "语音转文字失败",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n输入命令：paddlespeech tts --input \"南京现在很冷，下次再去夫子庙吧。\" --output  ./test_2.wav\r\n然后语音转文字，输入命令：paddlespeech asr --lang zh --input  test_2.wav\r\nterminal中输出结果如下：\r\n~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nW0618 16:31:50.041340 34357 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.2, Runtime API Version: 11.7\r\nW0618 16:31:50.041710 34357 gpu_resources.cc:91] device: 0, cuDNN Version: 8.9.\r\nInput(Y/N):Y\r\n[2023-06-18 16:31:52,881] [   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 333] and the shape of Y = [1, 82, 82]. Received [333] in X is not equal to [82] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\nTraceback (most recent call last):\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 819, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 544, in attention_rescoring\r\n    hyps, encoder_out = self._ctc_prefix_beam_search(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 425, in _ctc_prefix_beam_search\r\n    encoder_out, encoder_mask = self._forward_encoder(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 230, in _forward_encoder\r\n    encoder_out, encoder_mask = self.encoder(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddle/fluid/dygraph/layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/modules/encoder.py\", line 181, in forward\r\n    chunk_masks = add_optional_chunk_mask(\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddlespeech/s2t/modules/mask.py\", line 202, in add_optional_chunk_mask\r\n    chunk_masks = masks.logical_and(chunk_masks)  # (B, L, L)\r\n  File \"~/anaconda3/envs/paddle_env/lib/python3.9/site-packages/paddle/tensor/logic.py\", line 122, in logical_and\r\n    return _C_ops.logical_and(x, y)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 333] and the shape of Y = [1, 82, 82]. Received [333] in X is not equal to [82] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n\r\nKeyError: 'result'\r\n所用系统为ubuntu22.04，完全按照官方说明安装的，麻烦帮忙看下是什么问题，谢谢！",
        "state": "closed",
        "user": "ZMote123",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-18T08:41:56+00:00",
        "updated_at": "2025-06-27T03:38:30+00:00",
        "closed_at": "2025-06-27T03:38:30+00:00",
        "comments_count": [
            "ZMote123",
            "Javacr",
            "ZMote123",
            "ZMote123",
            "ZMote123",
            "zxcd",
            "Ma-Runcheng",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3349
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3347,
        "title": "[TTS]语音合成MFA BUG",
        "body": "语音合成中，按照examples/other/mfa中的操作，对于中文进行对齐，会报错，可以删除so.0来解决，local下的lexicon只适用于中文，因为无法使用该MFA，文档中也并没有写明中英文该怎么操作，文档和代码都欠缺。\r\n提供了下载的已经对齐好的tone文件，但如果自定义的数据集的话，将无法对齐。",
        "state": "open",
        "user": "zapjone",
        "closed_by": null,
        "created_at": "2023-06-19T07:18:11+00:00",
        "updated_at": "2023-06-25T06:25:48+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3348,
        "title": "[TTS]监听端口connect ECONNREFUSED ::1:8010",
        "body": "从PaddleSpeech\\demos\\speech_web\\web_client>启动了前后端分离项目，端口监听一直出错，如何解决\r\n\r\n[vite] http proxy error:\r\nError: connect ECONNREFUSED ::1:8010\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1494:16)",
        "state": "open",
        "user": "HaSaKiYasuooo",
        "closed_by": null,
        "created_at": "2023-06-19T10:30:05+00:00",
        "updated_at": "2023-06-25T06:24:45+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3350,
        "title": "jetson上编译源码时，paddleaudio仅支持1.1.0，但是arm的paddleaudio包只到1.0.2，这个包后面会上传吗",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n",
        "state": "open",
        "user": "may-ming",
        "closed_by": null,
        "created_at": "2023-06-20T09:58:38+00:00",
        "updated_at": "2023-06-25T06:22:43+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3351,
        "title": "[TTS]语音合成数据处理",
        "body": "Generate durations_baker.txt from MFA results ...\r\nTraceback (most recent call last):\r\n  File \"/data/tts/PaddleSpeech/utils/gen_duration_from_textgrid.py\", line 18, in <module>\r\n    import librosa\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/core/__init__.py\", line 5, in <module>\r\n    from .convert import *  # pylint: disable=wildcard-import\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/core/convert.py\", line 7, in <module>\r\n    from . import notation\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/core/notation.py\", line 8, in <module>\r\n    from ..util.exceptions import ParameterError\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/util/__init__.py\", line 83, in <module>\r\n    from .utils import *  # pylint: disable=wildcard-import\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/librosa/util/utils.py\", line 10, in <module>\r\n    import numba\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/numba/__init__.py\", line 43, in <module>\r\n    from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/numba/np/ufunc/__init__.py\", line 3, in <module>\r\n    from numba.np.ufunc.decorators import Vectorize, GUVectorize, vectorize, guvectorize\r\n  File \"/home/icksys/miniconda3/envs/paddle/lib/python3.9/site-packages/numba/np/ufunc/decorators.py\", line 3, in <module>\r\n    from numba.np.ufunc import _internal\r\nSystemError: initialization of _internal failed without raising an exception\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/zh_en_tts/tts3/README.md\r\n按照这里例子进行操作中英文混合数据合成时，报这种错误，是哪个库依赖版本不对吗？\r\n",
        "state": "open",
        "user": "zapjone",
        "closed_by": null,
        "created_at": "2023-06-21T05:22:40+00:00",
        "updated_at": "2023-06-21T10:27:46+00:00",
        "closed_at": null,
        "comments_count": [
            "zapjone",
            "LLouice"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3352,
        "title": "关于中英文混合tts finetune",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n您好，我这边希望用小样本去finetune一下中英文混合的tts模型（数据量大概中英文各有6，70条)，我看到example里有两个训练的脚本，一个是other中的run_mix.sh, 但是看脚本好像只会单独处理中文或者英文，如果要用这个训练，是需要中文和英文数据各finetune一遍嘛？或者还有zh_en_tts里的run.sh，但是这个脚本感觉是从头训练，不是小样本finetune，我这边应该用哪个比较合适呢\r\n另外还有一个问题就是，如果预料中是中英文混合的样式， 这种情况是不是需要重新训练MFA才可以使用？",
        "state": "closed",
        "user": "523997931",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-25T02:56:05+00:00",
        "updated_at": "2025-06-27T03:37:43+00:00",
        "closed_at": "2025-06-27T03:37:43+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3353,
        "title": "[TTS]tts中的男女声有版权限制吗？可以商业上使用吗？",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "qier777",
        "closed_by": null,
        "created_at": "2023-06-26T02:08:23+00:00",
        "updated_at": "2023-06-29T01:19:58+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "dungeon-kalath"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3354,
        "title": "默认采样率、采样位数、通道、刷新间隔是多少？",
        "body": "默认采样率、采样位数、通道、刷新间隔是多少？\r\n",
        "state": "closed",
        "user": "swxnh",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-26T03:35:11+00:00",
        "updated_at": "2025-06-27T06:33:24+00:00",
        "closed_at": "2025-06-27T06:33:24+00:00",
        "comments_count": [
            "zxcd",
            "swxnh",
            "stale[bot]",
            "Ankh-L",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3356,
        "title": "如何比较2个特征的相似性 ",
        "body": "audio_file1= \"./nihao002.mp3\"\r\nspeech_segment = SpeechSegment.from_file(audio_file1, \"None\")\r\naudio_feature1 = audio_featurizer.featurize(speech_segment)\r\naudio_feature_i1 = feature_normalizer.apply(audio_feature1)\r\n\r\naudio_len1 = audio_feature_i1.shape[0]\r\naudio_len1 = paddle.to_tensor(audio_len1)\r\naudio_feature1 = paddle.to_tensor(audio_feature_i1, dtype='float32')\r\naudio_feature1 = paddle.unsqueeze(audio_feature1, axis=0)\r\nprint(f\"shape: {audio_feature1.shape}\")\r\n\r\n用这些代码再加载一个audio_feature2  那么如何比较\r\naudio_feature1和audio_feature2的相似性 ？ 是不是很相似就说明 这2个音频文件的内容是一致的？",
        "state": "closed",
        "user": "huangweixiao",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-26T14:48:08+00:00",
        "updated_at": "2025-04-28T04:58:24+00:00",
        "closed_at": "2025-04-28T04:58:24+00:00",
        "comments_count": [
            "zxcd",
            "zouhan6806504",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3355,
        "title": "声音克隆相关",
        "body": "您好，\r\ntts声音克隆，例如我们用自己的音频训练出来的声音克隆，请问可以直接用做商用吗",
        "state": "closed",
        "user": "dungeon-kalath",
        "closed_by": "dungeon-kalath",
        "created_at": "2023-06-26T05:31:56+00:00",
        "updated_at": "2023-06-29T01:26:40+00:00",
        "closed_at": "2023-06-29T01:26:40+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3357,
        "title": "按教程里的说明，在执行到tts_finetue run.sh stage 5 报错",
        "body": "环境如下\r\n系统：wsl2 + ubuntu 20.04\r\npython版本：3.8\r\npytorch: 2.0.1\r\ncuda: 11.7\r\n出错运行代码如下，前面stage 0 - 4步运行都成功了\r\n===================================\r\n./run.sh --stage 5 --stop-stage 5\r\nfinetune...\r\nrank: 0, pid: 15672, parent_pid: 15660\r\nmultiple speaker fastspeech2!\r\nspk_num: 174\r\nsamplers done!\r\ndataloaders done!\r\nvocab_size: 306\r\nW0626 23:15:20.386186 15672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.1, Runtime API Version: 11.7\r\nW0626 23:15:20.387040 15672 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nI0626 23:15:26.244715 15672 eager_method.cc:143] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nI0626 23:15:26.245553 15672 eager_method.cc:143] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nmodel done!\r\noptimizer done!\r\n/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1896: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1896: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/nn/layer/norm.py:776: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\nException in main training loop: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\nTraceback (most recent call last):\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 334, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1242, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 994, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 799, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/home/ant/voice/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 334, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1242, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 994, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 799, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/home/ant/voice/PaddleSpeech/tools/venv/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nAssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\n======================================\r\n这个需要如何解决呢？ 提问前都找了相关的资料都没有解决方法，哪位大神指点下，万分感谢！",
        "state": "closed",
        "user": "joisonwk",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-26T15:53:42+00:00",
        "updated_at": "2025-04-27T18:51:11+00:00",
        "closed_at": "2025-04-27T18:51:11+00:00",
        "comments_count": [
            "a0735a",
            "a0735a",
            "joisonwk",
            "stale[bot]",
            "hlxs-c",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3358,
        "title": "用tts_finetue通过680条语音数据经过8000epoch训练出来的声音还是沙哑不清🤔",
        "body": "用tts_finetue通过680句对齐的语音在预训练模型的基础上经过8000epoch训练出来的声音为什么声音还是沙哑不清的呢？ 参数都是默认的，下面是结束训练时的Log，能帮我看下是什么原因吗？\r\n====================\r\n\r\n```\r\niter: 176399/82000, Rank: 0, l1_loss: 0.389511, duration_loss: 0.016910, pitch_loss: 0.125539, energy_loss: 0.144192, loss: 0.676153, avg_reader_cost: 0.00024 sec, avg_batch_cost: 0.35481 sec, avg_samples: 64, avg_ips: 180.37775 sequences/sec\r\n iter: 176400/82000, Rank: 0, l1_loss: 0.387860, duration_loss: 0.015845, pitch_loss: 0.127565, energy_loss: 0.138015, loss: 0.669285, avg_reader_cost: 0.00030 sec, avg_batch_cost: 0.34675 sec, avg_samples: 64, avg_ips: 184.57215 sequences/sec\r\nEvaluate: l1_loss: 0.835190, duration_loss: 0.078182, pitch_loss: 0.346834, energy_loss: 0.888089, loss: 2.148295\r\n```\r\n\r\n============================\r\n我用mockingbird训练也是这样，听说paddlespeech效果好些，虽然结果已经明显优于前者了，但还是存在效果很差的问题，求指点，感谢！",
        "state": "closed",
        "user": "joisonwk",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-28T06:06:35+00:00",
        "updated_at": "2025-06-27T03:37:45+00:00",
        "closed_at": "2025-06-27T03:37:45+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3360,
        "title": "[TTS]关于Style control in FastSpeech2疑问",
        "body": "在文档中https://paddlespeech.readthedocs.io/en/latest/tts/demo.html#style-control-in-fastspeech2 我看是支持语速的微调\r\n\r\ndemo使用的例子是 demos/style_fs2/style_syn.py\r\n    - 使用的模型是fastspeech2_csmsc-zh\r\n\r\n理论上讲只要是FastSpeech2模型都该支持才对，但是下载fastspeech2_aishell3-zh与fastspeech2_csmsc-zh\r\n模型对比缺少energy_stats.npy 与 pitch_stats.npy文件（如图）\r\n\r\n![截图 2023-06-28 16-45-06](https://github.com/PaddlePaddle/PaddleSpeech/assets/16934884/a756f007-be1b-4d02-8d1d-ba21dde0408a)\r\n\r\n我应该从那里获取或生成出这两个文件，从而支持与例子上提供变速的效果？谢谢",
        "state": "closed",
        "user": "laishujie",
        "closed_by": "laishujie",
        "created_at": "2023-06-28T09:21:43+00:00",
        "updated_at": "2023-07-03T02:12:19+00:00",
        "closed_at": "2023-07-03T02:12:19+00:00",
        "comments_count": [
            "zh794390558",
            "laishujie"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3361,
        "title": "[TTS]使用http协议的流式语音合成的接口的响应消息没有明确的分界点",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n无法稳定的还原服务端返回的文件。\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 打开wireshark或其他抓包软件\r\n2. 发送一个post请求到服务器\r\n3. 观察http响应内容\r\n\r\n**Expected behavior**\r\n接口响应没有按照标准返回，并且各个被加密的base64字符串之间并没有明确的分界点。\r\n\r\n**Screenshots**\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [Debian 12]\r\n - GCC/G++ Version [12.2.0]\r\n - Python Version [3.10]\r\n - PaddlePaddle Version [2.5.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [使用的是cpu]\r\n - CUDA/CUDNN Version [使用的是cpu]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\n虽然接口的响应被设置了Transfer-Encoding: chunked，但是响应消息并没有按照标准来返回。\r\n![2(34_MZ9YDY$YE3 L@2ZRXS_tmb](https://github.com/PaddlePaddle/PaddleSpeech/assets/9549027/88ee2ed9-32cc-4010-845c-4f487d3d01b3)\r\n\r\n标准的响应消息应该是：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/9549027/f1b78d87-dd52-429f-b1c8-114c78df702f)\r\n\r\n经过查看代码后得知：服务端会把一部分内容经过base64编码后返回给客户端，但问题是，并不能保证这部分内容长度固定。\r\n问题代码：https://github.com/PaddlePaddle/PaddleSpeech/blob/94987f26dfafda70ebc3515f0cc2e6d81ba8478a/paddlespeech/server/engine/tts/online/onnx/tts_engine.py#L457-L469\r\n\r\n经过实际测试发现，每段长度也确实不固定，可能是28800，也可能是13600：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/9549027/f7085ea8-036a-402f-9759-874305825e5e)\r\n\r\n这样就导致我无法根据长度来截取需要解码的base64字符串。\r\n\r\n**个人的建议是**：\r\n- **直接返回二进制内容，不要进行base64编码。**\r\n- **如果实在要编码，按照分块编码的标准进行返回。**\r\n- **在各个返回的base64之间增加明确的分界点，就像我在pr中修改的那样。**\r\n",
        "state": "closed",
        "user": "fantasy0v0",
        "closed_by": "fantasy0v0",
        "created_at": "2023-06-28T12:30:03+00:00",
        "updated_at": "2023-07-13T01:09:34+00:00",
        "closed_at": "2023-07-13T01:09:34+00:00",
        "comments_count": [
            "fantasy0v0"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3363,
        "title": "Provide examples based on pre training weights.",
        "body": "In voice cloning, there are two similar but different files, https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/t2s/exps/vits/voice_cloning.py and https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/t2s/exps/voice_cloning.py. Which one should I choose to adapt to ge2e_ckpt_0.3.zip?",
        "state": "closed",
        "user": "943fansi",
        "closed_by": "943fansi",
        "created_at": "2023-06-28T13:50:50+00:00",
        "updated_at": "2023-07-05T11:00:27+00:00",
        "closed_at": "2023-07-05T11:00:27+00:00",
        "comments_count": [
            "zxcd",
            "943fansi"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3364,
        "title": "TTS timestamp ",
        "body": "## Feature Request\r\n\r\n请支持一下TTS输出时间戳，需要利用TTS生成的语音来驱动脸部表情，需要音素或者字级的时间戳。\r\n",
        "state": "open",
        "user": "xiaomingnio",
        "closed_by": null,
        "created_at": "2023-06-29T09:56:57+00:00",
        "updated_at": "2023-07-04T03:08:39+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3366,
        "title": "语音合成 使用POST /paddlespeech/tts返回的base64编码的音频字符串在C#端解密有问题",
        "body": "我将返回的audio字符串和报存的wav加载后用base64编码，两边是不一样的，同样是”你好“的语音wav格式的编码\r\n![QQ截图20230630135902](https://github.com/PaddlePaddle/PaddleSpeech/assets/86875542/204dfd47-cce0-47ef-ac22-11359ed74bde)\r\naudio在C#端解码base64会有电流声，加载保存的wav就没有\r\n![QQ截图20230630175857](https://github.com/PaddlePaddle/PaddleSpeech/assets/86875542/7023df2e-af41-4eb6-b02e-ce1d1607ad46)\r\n\r\n我测试了一下，python的base64编码和C#的base64编码是一致的，音频的字节不一样，是个怎么个问题？\r\n",
        "state": "closed",
        "user": "qianmo0609",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-30T05:59:50+00:00",
        "updated_at": "2025-06-27T04:34:15+00:00",
        "closed_at": "2025-06-27T04:34:15+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3365,
        "title": "ASR识别出的方言中文过于怪异",
        "body": "## General Question\r\n尝试了一下方言识别，随便在抖音上找了一段语音，识别出来的文字只是在堆砌相似的读音，完全没有逻辑。\r\n示例：\r\npaddlespeech asr --lang zh --input fy.wav \r\n各地标方言名场面一起看看这十大方言有目有你的家乡方言吗监金化草嘛吵骂吵骂呀河南话那荣耀荣冷漠日子融四川话在一个就是矮气长沙画彪子料子陕西话好没有人心来吧简直是丧心冰狂招如情丝慕成绝上海话西萨问您们打家好好了以前K斯莱我觉得小黑屋山东话虽敢陕东天不叫天叫斜天转不掉翻掉邪妇你南画地黑门了吧你这广东话从甘听透透气猫桶雷胭雄一个东北话我是唐茂生口的胸前几天在我家买的内裤吧对啊专家买个裤的好了刚那您给个好评呗都发错户了还比啥好评啊我要的是瓶角的你给我邮过三脚楼三角的我也就认了我一百八十二十来斤你给我邮歪S嘛那我穿那不能不雷劈话走几步就家丁欧里走几步就假定欧这一刀净拽它整得我那裤衩嘎哨走快了还磨大腿底子子大腿底子给我们去黑喂我挂了\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/assets/134175197/290c42df-2a14-47a0-8749-0c172884a4a0\r\n\r\n",
        "state": "closed",
        "user": "didoll-john",
        "closed_by": "didoll-john",
        "created_at": "2023-06-29T10:08:32+00:00",
        "updated_at": "2023-06-30T10:55:32+00:00",
        "closed_at": "2023-06-30T10:55:31+00:00",
        "comments_count": [
            "zxcd",
            "didoll-john"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3367,
        "title": "有没有人把TTS的onnx模型成功转成瑞芯微的RKNN模型？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n有没有人把TTS的onnx模型成功转成瑞芯微的RKNN模型？\r\n我试了所有的声学模型都没办法转换成功。\r\n",
        "state": "closed",
        "user": "HUANGCD123456",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-30T08:28:45+00:00",
        "updated_at": "2025-04-27T21:57:50+00:00",
        "closed_at": "2025-04-27T21:57:50+00:00",
        "comments_count": [
            "HUANGCD123456",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3368,
        "title": "paddlespeech lite  的模型可以用在瑞芯微rv1126 npu 上吗",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\npaddlespeech lite  的模型可以用在瑞芯微rv1126 npu 上吗\r\n",
        "state": "closed",
        "user": "HUANGCD123456",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-30T09:51:50+00:00",
        "updated_at": "2025-04-28T04:58:20+00:00",
        "closed_at": "2025-04-28T04:58:20+00:00",
        "comments_count": [
            "zxcd",
            "HUANGCD123456",
            "newuser123k789",
            "HUANGCD123456",
            "HUANGCD123456",
            "newuser123k789",
            "HUANGCD123456",
            "newuser123k789",
            "HUANGCD123456",
            "newuser123k789",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3369,
        "title": "demos 不能使用",
        "body": "我启动了demos的前后端，但是里面的功能无法使用\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/87591236/fd3b4032-4df0-451f-a194-db2741da6437)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/87591236/7520284f-6275-4f2a-a39f-12f3d5b0c897)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/87591236/c627f06d-1074-4b7d-805f-f3914f49bcdb)",
        "state": "open",
        "user": "HaSaKiYasuooo",
        "closed_by": null,
        "created_at": "2023-06-30T09:57:41+00:00",
        "updated_at": "2023-07-04T03:22:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3370,
        "title": "语音合成 使用POST /paddlespeech/tts返回的base64编码的音频字符串在C#端解密有问题",
        "body": "我将返回的audio字符串和报存的wav加载后用base64编码，两边是不一样的，同样是”你好“的语音wav格式的编码\r\n![QQ截图20230630135902](https://github.com/PaddlePaddle/PaddleSpeech/assets/86875542/204dfd47-cce0-47ef-ac22-11359ed74bde)\r\naudio在C#端解码base64会有电流声，加载保存的wav就没有\r\n![QQ截图20230630175857](https://github.com/PaddlePaddle/PaddleSpeech/assets/86875542/7023df2e-af41-4eb6-b02e-ce1d1607ad46)\r\n\r\n我测试了一下，python的base64编码和C#的base64编码是一致的，音频的字节不一样，是个怎么个问题？",
        "state": "closed",
        "user": "qianmo0609",
        "closed_by": "stale[bot]",
        "created_at": "2023-06-30T11:09:03+00:00",
        "updated_at": "2025-06-27T02:33:10+00:00",
        "closed_at": "2025-06-27T02:33:10+00:00",
        "comments_count": [
            "zh794390558",
            "qianmo0609",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3375,
        "title": "如何解决",
        "body": "audio, audio_len = get_kaldi_feat(wav_file)\r\ncfg = st_config.decoding\r\nres = model.decode(audio,\r\n            audio_len,\r\n            text_feature=text_feature,\r\n            decoding_method=cfg.decoding_method,\r\n            beam_size=cfg.beam_size,\r\n            word_reward=cfg.word_reward,\r\n            decoding_chunk_size=cfg.decoding_chunk_size,\r\n            num_decoding_left_chunks=cfg.num_decoding_left_chunks,\r\n            simulate_streaming=cfg.simulate_streaming)\r\nprint(\"对应英文: {}\".format(transcript))\r\nprint(\"翻译结果: {}\".format(\"\".join(res[0].split())))\r\n报错：\r\nlast)/tmp/ipykernel_99/1766970101.py in <module>\r\n      9             decoding_chunk_size=cfg.decoding_chunk_size,\r\n     10             num_decoding_left_chunks=cfg.num_decoding_left_chunks,\r\n---> 11             simulate_streaming=cfg.simulate_streaming)\r\n     12 print(\"对应英文: {}\".format(transcript))\r\n     13 print(\"翻译结果: {}\".format(\"\".join(res[0].split())))\r\n<decorator-gen-403> in decode(self, feats, feats_lengths, text_feature, decoding_method, beam_size, word_reward, maxlenratio, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py in _decorate_function(func, *args, **kwargs)\r\n    349         def _decorate_function(func, *args, **kwargs):\r\n    350             with self:\r\n--> 351                 return func(*args, **kwargs)\r\n    352 \r\n    353         @decorator.decorator\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2_st/u2_st.py in decode(self, feats, feats_lengths, text_feature, decoding_method, beam_size, word_reward, maxlenratio, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)\r\n    522                 decoding_chunk_size=decoding_chunk_size,\r\n    523                 num_decoding_left_chunks=num_decoding_left_chunks,\r\n--> 524                 simulate_streaming=simulate_streaming)\r\n    525             hyps = [hyp.tolist() for hyp in hyps]\r\n    526         else:\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2_st/u2_st.py in translate(self, speech, speech_lengths, beam_size, word_reward, maxlenratio, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)\r\n    291             speech, speech_lengths, decoding_chunk_size,\r\n    292             num_decoding_left_chunks,\r\n--> 293             simulate_streaming)  # (B, maxlen, encoder_dim)\r\n    294 \r\n    295         maxlen = max(int(encoder_out.shape[1] * maxlenratio), 5)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/models/u2_st/u2_st.py in _forward_encoder(self, speech, speech_lengths, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)\r\n    250                 speech_lengths,\r\n    251                 decoding_chunk_size=decoding_chunk_size,\r\n--> 252                 num_decoding_left_chunks=num_decoding_left_chunks\r\n    253             )  # (B, maxlen, encoder_dim)\r\n    254         return encoder_out, encoder_mask\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    915 \r\n    916     def __call__(self, *inputs, **kwargs):\r\n--> 917         return self._dygraph_call_func(*inputs, **kwargs)\r\n    918 \r\n    919     def forward(self, *inputs, **kwargs):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in _dygraph_call_func(self, *inputs, **kwargs)\r\n    905             self._built = True\r\n    906 \r\n--> 907         outputs = self.forward(*inputs, **kwargs)\r\n    908 \r\n    909         for forward_post_hook in self._forward_post_hooks.values():\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/modules/encoder.py in forward(self, xs, xs_lens, decoding_chunk_size, num_decoding_left_chunks)\r\n    172             num_decoding_left_chunks)\r\n    173         for layer in self.encoders:\r\n--> 174             xs, chunk_masks, _, _ = layer(xs, chunk_masks, pos_emb, mask_pad)\r\n    175         if self.normalize_before:\r\n    176             xs = self.after_norm(xs)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    915 \r\n    916     def __call__(self, *inputs, **kwargs):\r\n--> 917         return self._dygraph_call_func(*inputs, **kwargs)\r\n    918 \r\n    919     def forward(self, *inputs, **kwargs):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in _dygraph_call_func(self, *inputs, **kwargs)\r\n    905             self._built = True\r\n    906 \r\n--> 907         outputs = self.forward(*inputs, **kwargs)\r\n    908 \r\n    909         for forward_post_hook in self._forward_post_hooks.values():\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/modules/encoder_layer.py in forward(self, x, mask, pos_emb, mask_pad, att_cache, cnn_cache)\r\n    106             x = self.norm1(x)\r\n    107 \r\n--> 108         x_att, new_att_cache = self.self_attn(x, x, x, mask, cache=att_cache)\r\n    109 \r\n    110         if self.concat_after:\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    915 \r\n    916     def __call__(self, *inputs, **kwargs):\r\n--> 917         return self._dygraph_call_func(*inputs, **kwargs)\r\n    918 \r\n    919     def forward(self, *inputs, **kwargs):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in _dygraph_call_func(self, *inputs, **kwargs)\r\n    905             self._built = True\r\n    906 \r\n--> 907         outputs = self.forward(*inputs, **kwargs)\r\n    908 \r\n    909         for forward_post_hook in self._forward_post_hooks.values():\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/modules/attention.py in forward(self, query, key, value, mask, pos_emb, cache)\r\n    195         #    k.transpose([0, 1, 3, 2])) / math.sqrt(self.d_k)\r\n    196         scores = paddle.matmul(q, k, transpose_y=True) / math.sqrt(self.d_k)\r\n--> 197         return self.forward_attention(v, scores, mask), new_cache\r\n    198 \r\n    199 \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/modules/attention.py in forward_attention(self, value, scores, mask)\r\n    116             # for last chunk, time2 might be larger than scores.size(-1)\r\n    117             mask = mask[:, :, :, :scores.shape[-1]]\r\n--> 118             scores = scores.masked_fill(mask, -float('inf'))\r\n    119             attn = paddle.softmax(\r\n    120                 scores, axis=-1).masked_fill(mask,\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlespeech/s2t/__init__.py in masked_fill(xs, mask, value)\r\n    177     #     tmp[index] = bshape[index]\r\n    178     mask = mask.broadcast_to(bshape)\r\n--> 179     trues = paddle.full_like(xs, fill_value=value)\r\n    180     xs = paddle.where(mask, trues, xs)\r\n    181     return xs\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py in full_like(x, fill_value, dtype, name)\r\n    209 \r\n    210     if in_dygraph_mode():\r\n--> 211         return _C_ops.fill_any_like(x, 'value', fill_value, 'dtype', dtype)\r\n    212 \r\n    213     helper = LayerHelper(\"full_like\", **locals())\r\nValueError: (InvalidArgument) The filled value is out of range for target type, current kernel type is f, the range should between -340282346638528859811704183484516925440.000000 and 340282346638528859811704183484516925440.000000, but now value is -inf.\r\n  [Hint: Expected (common_type_value >= static_cast<CommonType>(std::numeric_limits<T>::lowest())) && (common_type_value <= static_cast<CommonType>(std::numeric_limits<T>::max())) == true, but received (common_type_value >= static_cast<CommonType>(std::numeric_limits<T>::lowest())) && (common_type_value <= static_cast<CommonType>(std::numeric_limits<T>::max())):0 != true:1.] (at /paddle/paddle/fluid/operators/fill_any_like_op.h:55)\r\n  [operator < fill_any_like > error]",
        "state": "closed",
        "user": "liumengen3",
        "closed_by": "liumengen3",
        "created_at": "2023-07-04T16:41:14+00:00",
        "updated_at": "2023-07-05T03:13:43+00:00",
        "closed_at": "2023-07-05T03:13:43+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3371,
        "title": "执行TTSExecutor()报错AssertionError: Variable dtype not match, Variable [ embedding_1.w_0 ] need tensor with dtype paddle.float16  but load tensor with dtype paddle.float32",
        "body": "执行TTSExecutor()报错，AssertionError: Variable dtype not match, Variable [ embedding_1.w_0 ] need tensor with dtype paddle.float16  but load tensor with dtype paddle.float32，该怎么解决？\r\n",
        "state": "closed",
        "user": "dddlli",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-02T10:33:54+00:00",
        "updated_at": "2025-06-27T04:34:16+00:00",
        "closed_at": "2025-06-27T04:34:16+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3372,
        "title": "声纹怎么支持ffmpeg实时语音进行识别？",
        "body": "## Others\r\nfrom paddlespeech.cli.vector import VectorExecutor\r\n\r\n声纹怎么支持ffmpeg实时语音进行识别？我看官方案例智能传入wav文件，请教下有想过支持实时语音吗\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "lonngxiang",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-03T01:48:55+00:00",
        "updated_at": "2025-06-27T02:33:13+00:00",
        "closed_at": "2025-06-27T02:33:13+00:00",
        "comments_count": [
            "zh794390558",
            "lonngxiang",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3373,
        "title": "whisper的large模型识别过于慢了，在哪个显卡下能发挥最快速度呢？后续速度有改进计划吗",
        "body": null,
        "state": "closed",
        "user": "mrg79433283",
        "closed_by": "mrg79433283",
        "created_at": "2023-07-03T02:01:45+00:00",
        "updated_at": "2023-08-01T08:03:37+00:00",
        "closed_at": "2023-08-01T08:03:37+00:00",
        "comments_count": [
            "zxcd",
            "mrg79433283",
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3374,
        "title": "[S2T]ASR 如何使用自己的语料在预训练模型上 finetune 微调，能否不引用论坛1972那两张截图🤓",
        "body": "#1972 ，论坛这个帖子只有两张图两句话，和下面未回复的用户问题，翻了很多代码和Issue，看到大部分关于ASR模型finetune 微调 Issue的回复都是参考1972，可1972内容真谈不上详细，作为初学者，官方是否可以出一份ASR模型微调 &继续训练 的操作步骤，以及微调前后的效果，aishell或wenetspeech都可，目前如下问题：\r\n\r\n1.执行conformer_wenetspeech预训练模型微调，在哪一步需要替换哪些文件，是否有案例？(#1972 针对未回复问题：哪个是index文件？就是1、2、3.json 这种吗？这种json文件里面就几个字段，需要改什么？预训练模型只有*.pdprams，没有*.pdopt文件，只把pdparams改名放进去，没删除*.pdopt继续微调效果不好啊，有人微调成功吗？效果比预训练模型有提升吗？能不能贴一下微调前后CER成绩对比？）\r\n\r\n2.微调时修改那些脚本，如何使用脚本微调模型？（针对 #1972 未回复问题：为什么会有一个原始的和正式的manifest？有.raw和没有的有什么区别？）\r\n\r\n3.哪一步算是微调完成？微调后的模型如何推理和导出使用？(针对#3103 未回复，如何使用Python API调用训练好的微调模型进行inference)\r\n\r\n\r\n隔壁[PaddleOCR训练文档](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/recognition.md)，很完善，恳请可以关注下ASR模型微调和继续训练 这部分，出个ASR模型微调操作文档，多谢，\r\n这个项目还是很好的，引用 #523 的内容，还是希望这个项目越来越好，使用的人越来越多\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/5171651/90b9f33f-89eb-4ac2-89f9-a8e7cd7d77ad)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/5171651/3a918b1c-a9ca-487b-9ef8-a128ff05788f)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/5171651/0c42439c-ba36-48f4-a7cd-c28073e3d5a4)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/5171651/17026999-400d-4998-9b41-d702ddebd628)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/5171651/ea6de8b5-a494-4f65-bedc-ee52b0f728f3)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Chuyaoyuan",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-04T10:12:08+00:00",
        "updated_at": "2025-06-27T05:32:52+00:00",
        "closed_at": "2025-06-27T05:32:52+00:00",
        "comments_count": [
            "zh794390558",
            "Chuyaoyuan",
            "stale[bot]",
            "qingjiaozyn",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3376,
        "title": "语音服务接口定义，ASR模块一堆无效参数",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n## 代码和文档说明不对等，文档里的接口如下：\r\n<html>\r\n<body>\r\n<!--StartFragment--><h3 style=\"box-sizing: border-box; margin-top: 24px; margin-bottom: 16px; font-size: 1.25em; font-weight: var(--base-text-weight-semibold, 600); line-height: 1.25; color: rgb(173, 186, 199); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, &quot;Noto Sans&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(34, 39, 46); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;\">语音识别</h3><ul style=\"box-sizing: border-box; padding-left: 2em; margin-top: 0px; margin-bottom: 16px; color: rgb(173, 186, 199); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, &quot;Noto Sans&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(34, 39, 46); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;\"><li style=\"box-sizing: border-box;\">url:<code style=\"box-sizing: border-box; font-family: ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, &quot;Liberation Mono&quot;, monospace; font-size: 13.6px; padding: 0.2em 0.4em; margin: 0px; white-space: break-spaces; background-color: var(--bgColor-neutral-muted, var(--color-neutral-muted)); border-radius: 6px;\">POST /paddlespeech/asr</code></li><li style=\"box-sizing: border-box; margin-top: 0.25em;\">请求body参数</li></ul>\r\n\r\n字段 | 必选 | 类型 | 说明\r\n-- | -- | -- | --\r\naudio | 是 | string | 将音频文件进行 base64编码后得到的 string\r\naudio_format | 是 | string | 合成音频文件格式，可选：pcm、wav，默认值：wav\r\nsample_rate | 是 | int | 音频的采样率，值选择 [8000, 16000]，默认与模型采样率一致\r\nlang | 是 | string | 语种 zh_cn：中文; zh_tw: 台湾普通话； en_us：英文\r\npunc | 否 | bool | 是否开启标点符号添加 true：开启 false：关闭（默认值）\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>\r\n\r\n## 代码接口使用如下\r\n```python\r\n        audio_data = base64.b64decode(request_body.audio)\r\n\r\n\r\n        # get single engine from engine pool\r\n        engine_pool = get_engine_pool()\r\n        asr_engine = engine_pool['asr']\r\n\r\n\r\n        if asr_engine.engine_type == \"python\":\r\n            from paddlespeech.server.engine.asr.python.asr_engine import PaddleASRConnectionHandler\r\n        elif asr_engine.engine_type == \"inference\":\r\n            from paddlespeech.server.engine.asr.paddleinference.asr_engine import PaddleASRConnectionHandler\r\n        else:\r\n            logger.error(\"Offline asr engine only support python or inference.\")\r\n            sys.exit(-1)\r\n\r\n\r\n        connection_handler = PaddleASRConnectionHandler(asr_engine)\r\n\r\n\r\n        connection_handler.run(audio_data)\r\n```\r\n不知道是不是我理解错了，但是从文档和代码来看，audio之外的参数，都是没有任何意义的。是代码没有更新吗，还是说代码没有实现这些功能，但是未来会加上。",
        "state": "closed",
        "user": "Javacr",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-06T05:31:37+00:00",
        "updated_at": "2025-06-27T02:33:11+00:00",
        "closed_at": "2025-06-27T02:33:11+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3379
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3377,
        "title": "小数据集微调模型模型如何增加空音位置使得语音输出有抑扬顿挫的感觉？",
        "body": "自己的小数据集微调后，模型输出合成效果不错，但是在生成长序列过程中，希望能人为通过添加文本如空音、停顿符号来控制语音合成时语音的停顿，让说话有一定的节奏感，现在说话节奏和跑火车一样，末尾句号也不会停。我看了phone_id_map.txt文件中有一个单说明号的pad对应的index是0，于是我将希望停顿的位置尝试加了0、pad或者单说明号的pad，模型推理的时候都不会停。\r\n那么这个停顿的功能应该怎么实现呢？是需要在训练数据里，音频的真实停顿位置也添加单说明号的pad重新训练吗？还是说怎么个处理方法？\r\n(github上有帖子说增加concat的空音？这个空音怎么加？)\r\n![Uploading 1688622644872.jpg…]()\r\n",
        "state": "closed",
        "user": "zhuwano1",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-06T05:55:18+00:00",
        "updated_at": "2025-04-28T04:58:29+00:00",
        "closed_at": "2025-04-28T04:58:29+00:00",
        "comments_count": [
            "zh794390558",
            "hello2mao",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3378,
        "title": "将vits-csmsc导出onnx出现错误",
        "body": "## General Question\r\n在导出vits-csmsc的onnx模型时出现问题，使用的代码如下\r\n\r\nimport argparse\r\nfrom pathlib import Path\r\n\r\nimport paddle\r\nimport soundfile as sf\r\nimport yaml\r\nfrom timer import timer\r\nfrom yacs.config import CfgNode\r\nfrom paddle.static import InputSpec\r\nimport os \r\n\r\nfrom paddle import jit\r\nfrom paddlespeech.t2s.models.vits import VITS\r\nfrom paddlespeech.t2s.models.vits import VITSInference\r\nfrom paddlespeech.t2s.utils import str2bool\r\n\r\npaddle.set_device(\"cpu\")\r\n\r\nconfig = \"/home/cw/code/tts/PaddleSpeech/checkpoint/vits_csmsc_ckpt_1.4.0/default.yaml\"\r\nckpt = \"/home/cw/code/tts/PaddleSpeech/checkpoint/vits_csmsc_ckpt_1.4.0/snapshot_iter_150000.pdz\"\r\nphones_dict = (\r\n    \"/home/cw/code/tts/PaddleSpeech/checkpoint/vits_csmsc_ckpt_1.4.0/phone_id_map.txt\"\r\n)\r\n\r\nwith open(config) as f:\r\n    config = CfgNode(yaml.safe_load(f))\r\n\r\n    with open(phones_dict, \"r\") as f:\r\n        phn_id = [line.strip().split() for line in f.readlines()]\r\n    vocab_size = len(phn_id)\r\n    print(\"vocab_size:\", vocab_size)\r\n\r\n    odim = config.n_fft // 2 + 1\r\n    config[\"model\"][\"generator_params\"][\"spks\"] = None\r\n\r\n    vits = VITS(idim=vocab_size, odim=odim, **config[\"model\"])\r\n    vits.set_state_dict(paddle.load(ckpt)[\"main_params\"])\r\n    vits.eval()\r\n\r\n    vits_inference = VITSInference(vits)\r\n\r\n    # transfer dygraph to static\r\n    vits_inference = jit.to_static(\r\n        vits_inference, input_spec=[InputSpec([50], dtype=paddle.int64)]\r\n    )\r\n\r\nsave_path = \"/home/cw/code/tts/PaddleSpeech/rknn_test/test.onnx\"  # 需要保存的路径\r\nx_spec = paddle.static.InputSpec(\r\n    [50], \"int64\", \"phone_ids\"\r\n)  # 为模型指定输入的形状和数据类型，支持持 Tensor 或 InputSpec ，InputSpec 支持动态的 shape。\r\npaddle.onnx.export(vits_inference, save_path, input_spec=[x_spec], opset_version=12)`\r\n\r\n\r\n报错结果如下：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/111272125/5958ca28-1c2c-47c9-8260-df2cfcb5c603)\r\n",
        "state": "closed",
        "user": "Xwmiss",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-06T07:52:01+00:00",
        "updated_at": "2025-06-27T03:37:29+00:00",
        "closed_at": "2025-06-27T03:37:29+00:00",
        "comments_count": [
            "Xwmiss",
            "Xwmiss",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3381,
        "title": "运行时报错list index out of range",
        "body": "运行语音识别时报错：\r\n>>> from paddlespeech.cli.asr.infer import ASRExecutor\r\n>>> asr = ASRExecutor()\r\n>>> result = asr(audio_file=\"zh.wav\")\r\n>>> print(result)\r\n我认为跑步最重要的就是给我带来了身体健康\r\n\r\n\r\n[2023-07-07 08:27:47,581] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 323, in infer\r\n    simulate_streaming=cfg.simulate_streaming)\r\n  File \"/usr/local/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 826, in decode\r\n    reverse_weight=reverse_weight)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 512, in __call__\r\n    res = self.postprocess()  # Retrieve result of asr.\r\n  File \"/usr/local/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n",
        "state": "open",
        "user": "goudemaoningsir",
        "closed_by": null,
        "created_at": "2023-07-07T08:29:06+00:00",
        "updated_at": "2025-04-26T03:46:08+00:00",
        "closed_at": null,
        "comments_count": [
            "gotoolkits",
            "yaowt05",
            "gotoolkits",
            "stale[bot]",
            "sunqinbo",
            "lihuikenny",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3380,
        "title": "aishell3/vits-vc 模型推理出的语速过快的问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->你好！\r\n我使用docker拉取了最新的gpu版本镜像，在容器中对aishell3/vits-vc模型进行了训练，使用的GPU是3090TI，batch_size设置为32，max_epoch是默认的200.训练得到了380k iters的断点模型。\r\n\r\n**我在使用断点模型推理的时候遇到了问题，推理出的音频语速过快**。\r\n\r\n- 我使用了内置的speed_change函数对语速进行了处理，但是效果并不理想，我也尝试使用praat库，也没有成功。\r\n\r\n- 我一开始认为是add_blank参数设置错误的问题，导致每个语素之间没有加入<pad\\> 0，也就是停顿，使得每个音素之间没有停顿。\r\n于是，我在将preprocess部分将add_blank设置为True之后，获得了正确的dump/train/norm/metadata.jsonl 与dump/dev/norm/metadata.jsonl 文件，继续训练之后得到的模型进行推理，但仍然存在语速过快的问题。\r\n\r\n- 之后，我认为是训练步数不足的问题，但是generator_dur_loss在训练过程中是趋近收敛的。\r\n\r\n请问如何解决这个语速过快的问题，或者如果能提供官方预训练模型的话我会非常感谢！\r\n\r\n这是输出音频的demo，存在语速较快的问题https://github.com/2147483647wang/demo\r\n",
        "state": "closed",
        "user": "2147483647wang",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-07T04:01:12+00:00",
        "updated_at": "2025-06-27T03:38:36+00:00",
        "closed_at": "2025-06-27T03:38:36+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3382,
        "title": "paddlespeech 为什么当有中文英语数字时，字母读不出来？",
        "body": "可以试一下：\r\n其中：A100读成100，  1B 读成1 等等........\r\n\r\npaddlespeech tts --am fastspeech2_aishell3 --voc pwgan_aishell3 --input \"对英伟达老黄的一些建议和忠告，或是对现在算力显卡的痛点痛批。现在ai人工智能快速发展，大语言模型层出不穷，现在有个致命的缺陷，就是算力显卡的显存太小了。可能这时候会有人跳出来说，不是可以多卡一起麻，比如一张A100显卡80G显存，那我买个8张不就是640G显存了吗。对算数是这样，但是现实总是那么残酷，啪啪打脸来的总是那么快。首先多张卡显存并不会叠加并联，你还是80G。想不到吧，为什么不是640G呢。听我一一道来。比如大模型有：1B，3B，7B，14B等等多大的模型。其中1B是一亿个参数，3B是3亿个参数，我现在用一张A100显卡80G的我只能用来训练3B的模型，7B的就超显存不行了。我也试过用8个A100并联，还开启了deepspeed_stage_2_offload。但是结果显示还是能不能运行，为什么会这样呢？因为显卡显存不能叠加，显存不能叠加，重要的是说三遍。全量8张A100只能玩3B, 多卡就是单卡。 划重点：单卡能运行起来，多卡才能运行。那这个多卡有什么用呢，说实话，没多大用处。真是打脸，作用只是快一点点，多卡的作用，这个真是冤大头。我多张A100就是为了快那么一点点，那真是搞笑了。又有人跳出来说，我可以呀。我只能呵呵了，当然可以，那是你只知其一，不知其二。  你运行的是小模型，单卡本来就可以，你现在用多卡，当然是可以的。本来就可以呀。 并不是你的多呀发挥作用的。所以吐槽开始了： 大模型横行时代，硬件显卡明显掉链子！拖了ai大模型的后腿。现在特别需要单卡显存大的显卡，起码200G起步。管它什么A100 A500 ，管它个么牌子， 只要显存大就能运行起来更大的模型，假设3090搞到几百G那就是卡王，并不是说A100才是卡王，只是单卡显存大那就是。现在只想要这一张单卡几百G的才能解决我的燃眉之急，目前市面上还没有这样的卡。现在显卡被卡脖子的不是算力，而是显存，单卡一定要大。 就算是算力弱一点也能接受，毕竟是训练，无非就是多花点时间。如果显卡显存不够那直接是致命的，直接训练不了，也启动不了大模型，这个是不能接受的。只有一种特殊的情况才需要算力超强，那就是推理的时候，必须是速度快，算力强，显存不用很大，一张A100可以对所有模型进行推理。其实现在是做显卡最好的机会，啥时候谁出个单卡大显存，支持python,我们就支持谁。ai训练迫在眉睫，算力不够时间来凑，只要不是太离谱一定大卖\" --spk_id 1\r\n\r\n",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2023-07-08T01:29:02+00:00",
        "updated_at": "2023-07-19T10:13:57+00:00",
        "closed_at": "2023-07-19T10:13:57+00:00",
        "comments_count": [
            "zh794390558",
            "gg22mm",
            "zxcd",
            "gg22mm"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3383,
        "title": "流式tts",
        "body": "## 流式tts疑问\r\n请问使用流式T2S时，能否流式传入参数。比如“今天天气很好”，不是批量传入，是一个个字符的传入。这个没有看到代码里有体现呢？",
        "state": "closed",
        "user": "anrerbo",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-09T13:59:42+00:00",
        "updated_at": "2025-04-28T04:58:01+00:00",
        "closed_at": "2025-04-28T04:58:01+00:00",
        "comments_count": [
            "zh794390558",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3384,
        "title": "mfa部分，看起来要么处理中文、要么处理英文，会导致tts生成的效果在中英文交界处有较大停顿。应该怎么处理呢",
        "body": "mfa部分，看起来要么处理中文、要么处理英文，会导致tts生成的效果在中英文交界处有较大停顿。应该怎么处理呢，谢谢！",
        "state": "closed",
        "user": "litao28",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-10T03:28:38+00:00",
        "updated_at": "2025-04-28T04:58:36+00:00",
        "closed_at": "2025-04-28T04:58:36+00:00",
        "comments_count": [
            "zh794390558",
            "litao28",
            "litao28",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3385,
        "title": "[TTS]中文小样本合成训练完推理时抛出异常",
        "body": "import paddle\r\nimport yaml\r\nimport soundfile as sf\r\nfrom yacs.config import CfgNode\r\n#from paddlespeech.t2s.frontend.mix_frontend import MixFrontend\r\nfrom paddlespeech.t2s.frontend.zh_frontend import Frontend\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import run_frontend\r\n\r\nsentence = \"我有一本书，名字叫《小王子》. 这本书售价十五点八元。\"\r\n\r\n# text frontend\r\nphones_dict = \"dump/phone_id_map.txt\"\r\n#frontend = MixFrontend(phone_vocab_path=phones_dict)\r\nfrontend = Frontend(phone_vocab_path=phones_dict)\r\nprint(\"frontend done!\")\r\n\r\n# load AM\r\nam_config_file = \"pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/default.yaml\"\r\nam_ckpt = \"exp/default/checkpoints/snapshot_iter_96500.pdz\"\r\nam_stat = \"pretrained_models/fastspeech2_aishell3_ckpt_1.1.0/speech_stats.npy\"\r\nspeaker_dict = \"dump/speaker_id_map.txt\"\r\nwith open(am_config_file) as f:\r\n    am_config = CfgNode(yaml.safe_load(f))\r\nam_inference = get_am_inference(\r\n    am=\"fastspeech2_aishell3\",\r\n    am_config=am_config,\r\n    am_ckpt=am_ckpt,\r\n    am_stat=am_stat,\r\n    phones_dict=phones_dict,\r\n    tones_dict=None,\r\n    speaker_dict=speaker_dict)\r\nprint(\"acoustic model done!\")\r\n\r\n# load Voc\r\nvoc_config_file = \"pretrained_models/hifigan_aishell3_ckpt_0.2.0/default.yaml\"\r\nvoc_ckpt = \"pretrained_models/hifigan_aishell3_ckpt_0.2.0/snapshot_iter_2500000.pdz\"\r\nvoc_stat = \"pretrained_models/hifigan_aishell3_ckpt_0.2.0/feats_stats.npy\"\r\nwith open(voc_config_file) as f:\r\n    voc_config = CfgNode(yaml.safe_load(f))\r\nvoc_inference = get_voc_inference(\r\n    voc=\"hifigan_aishell3\",\r\n    voc_config=voc_config,\r\n    voc_ckpt=voc_ckpt,\r\n    voc_stat=voc_stat)\r\nprint(\"voc done!\")\r\n\r\n# get phone id\r\nfrontend_dict = run_frontend(\r\n    frontend=frontend,\r\n    text=sentence,\r\n    merge_sentences=False,\r\n    get_tone_ids=False,\r\n    lang=\"zh\")\r\nphone_ids = frontend_dict['phone_ids']\r\n\r\n# inference\r\nflags = 0\r\nfor i in range(len(phone_ids)):\r\n    part_phone_ids = phone_ids[i]\r\n    spk_id = 174  # baker:174, ljspeech:175, aishell3:0~173, vctk:176~282\r\n    spk_id = paddle.to_tensor(spk_id)\r\n    mel = am_inference(part_phone_ids, spk_id)\r\n    wav = voc_inference(mel)\r\n    if flags == 0:\r\n        wav_all = wav\r\n        flags = 1\r\n    else:\r\n        wav_all = paddle.concat([wav_all, wav])\r\nprint(\"infer successfully.\")\r\n\r\n# save audio\r\nwav = wav_all.numpy()\r\nsf.write(\"./out.wav\", wav, am_config.fs)\r\n\r\nfrontend done!\r\nacoustic model done!\r\nvoc done!\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-07-11 16:33:59] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2023-07-11 16:33:59] [DEBUG] [__init__.py:132] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.974 seconds.\r\n[2023-07-11 16:34:00] [DEBUG] [__init__.py:164] Loading model cost 0.974 seconds.\r\nPrefix dict has been built successfully.\r\n[2023-07-11 16:34:00] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\nterminate called after throwing an instance of 'phi::enforce::EnforceNotMet'\r\n  what():  (InvalidArgument) Variable value (input) of OP(fluid.layers.embedding) expected >= 0 and < 174, but got 174. Please check input value.\r\n  [Hint: Expected ids[i] < row_number, but received ids[i]:174 >= row_number:174.] (at /paddle/paddle/phi/kernels/cpu/embedding_kernel.cc:67)\r\n\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   embedding_ad_func(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, long, bool)\r\n1   paddle::experimental::embedding(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, long, bool)\r\n2   paddle::experimental::embedding_impl(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, long, bool)\r\n3   void phi::EmbeddingKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, long, phi::DenseTensor*)\r\n4   GOMP_parallel\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1689064440 (unix time) try \"date -d @1689064440\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e8000bb562) received by PID 767330 (TID 0x7f971d4a0740) from PID 767330 ***]\r\n",
        "state": "open",
        "user": "xiaoligang2000",
        "closed_by": null,
        "created_at": "2023-07-11T08:49:17+00:00",
        "updated_at": "2023-10-24T04:04:29+00:00",
        "closed_at": null,
        "comments_count": [
            "zh794390558",
            "xiaoligang2000",
            "wmlgl"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3386,
        "title": "demos中的tts流式服务启动后，通过Java写的客户端调用成功，这个能调说话人吗，默认是0，调整其他的没有效果",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "TendernessSmallBull",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-11T09:42:15+00:00",
        "updated_at": "2025-06-27T03:38:04+00:00",
        "closed_at": "2025-06-27T03:38:04+00:00",
        "comments_count": [
            "zh794390558",
            "mdys",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3388,
        "title": "请问如何进行本地语音模型训练啊,我准备好了WAV文件不知道如何本地训练",
        "body": "听说最近支持了无标注的本地语音模型训练,请问如何做啊.\r\n\r\nTTS3广东话那个 运行 ./run.sh\r\n结果就\r\n\r\nAssertionError\r\nGet features' stats ...\r\nTraceback (most recent call last):\r\n  File \"/home/taipu/TTT/PaddleSpeech/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/home/taipu/TTT/PaddleSpeech/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/taipu/anaconda3/envs/TTT/lib/python3.9/site-packages/jsonlines/jsonlines.py\", line 627, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\n\r\n这样了\r\n",
        "state": "closed",
        "user": "lckj2009",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-12T08:37:00+00:00",
        "updated_at": "2025-04-28T04:58:13+00:00",
        "closed_at": "2025-04-28T04:58:13+00:00",
        "comments_count": [
            "zh794390558",
            "lckj2009",
            "zxcd",
            "lckj2009",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3387,
        "title": "套件开发者证书发放活动 2023H1",
        "body": "各位飞桨开发者大家好～为了感谢大家近期对飞桨套件代码库，文档的贡献，我们会为在2023年1.1-6.30日之间合入飞桨套件PR的开发者发放电子版飞桨开源证书🎉🎉🎉 如果您有PR合入，请填写这张问卷补充如下信息，方便我们发放证书：\r\n\r\n* GitHubID\r\n* 邮箱\r\n* 合入PR的链接及描述信息\r\n\r\n感谢您对飞桨套件开源工作的支持！\r\n问卷链接：https://wj.qq.com/s2/12744729/af61/",
        "state": "closed",
        "user": "KevinLi43",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-12T08:25:30+00:00",
        "updated_at": "2025-04-28T04:57:58+00:00",
        "closed_at": "2025-04-28T04:57:58+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3392,
        "title": "links is broken for audio samples",
        "body": "hi, links is broken for audio samples :(\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/69077240/cafea73a-ee4c-409f-8038-d9d9533ee4c2)\r\ni received error like this:\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/69077240/18187f3f-8f8e-4253-88e5-e48e976d5a8f)\r\n",
        "state": "open",
        "user": "onlineapps-cloud",
        "closed_by": null,
        "created_at": "2023-07-13T19:47:41+00:00",
        "updated_at": "2023-07-17T02:59:05+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3391,
        "title": "两个很长的音频，如何判断他们之间重复的部分？",
        "body": "音频长度在2小时左右\r\n我先将两个音频用auditok切成不超过10s的片段，然后用paddlespeech.cli.vector import VectorExecutor将每个片段转成向量，然后计算这两个音频向量组成的矩阵的两两cosine相似度，得到相似度矩阵matrix\r\n然后我用plt显示了矩阵的样子，看不出构成区间的色块，其实这两个视频是有很大一部分是相同内容拼接的\r\n![rrr](https://github.com/PaddlePaddle/PaddleSpeech/assets/94092329/28c4bae5-2726-4d97-9133-363c5b1c2d2e)\r\n\r\n是思路不对吗，有没有其他建议？",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-13T09:19:36+00:00",
        "updated_at": "2025-04-28T04:58:07+00:00",
        "closed_at": "2025-04-28T04:58:07+00:00",
        "comments_count": [
            "zouhan6806504",
            "zouhan6806504",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3389,
        "title": "ppasr的VADPredictor，能支持自定义时间长度的切分吗？",
        "body": "```\r\nfrom ppasr.infer_utils.vad_predictor import VADPredictor\r\nvad_predictor = VADPredictor()\r\nwav, sr = soundfile.read('E:/audio/113987.wav', dtype='float32')\r\n# print(wav.shape)\r\nspeech_timestamps = vad_predictor.get_speech_timestamps(wav, sr)\r\n```\r\n看示例和接口，没有能传具体切分时间的地方，目前我希望能指定一个切分时间，每段可以有一定偏差，但尽量往这个时间上靠",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2023-07-12T08:49:26+00:00",
        "updated_at": "2023-07-13T01:09:07+00:00",
        "closed_at": "2023-07-13T01:09:07+00:00",
        "comments_count": [
            "zh794390558"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3393,
        "title": "streaming_asr_server 3060环境运行报错",
        "body": "streaming_asr_server 在1650显卡，cuda10.2，cudnn7.5环境下可以正常运行，迁移到3060显卡主机后可以正常启动，语音识别报错\r\n以下为错误日志\r\n```\r\nE0713 19:34:39.524367 15232 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\nE0713 19:34:39.526362 15232 top_k_function_cuda.h:1003] TopKOP failed as could not launch cub::DeviceSegmentedRadixSort::SortPairsDescending to calculate temp_storage_bytes, status: invalid device function\r\n[2023-07-13 19:34:39,527] [   ERROR] - <method '_getitem_index_not_tensor' of 'Tensor' objects> returned a result with an error set\r\nOverflowError: Python int too large to convert to C long\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\python\\asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\python\\asr_engine.py\", line 504, in advance_decoding\r\n    self.searcher.search(ctc_probs, self.cached_feat.place)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\ctc_search.py\", line 108, in search\r\n    ps = logp[s].item()\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\varbase_patch_methods.py\", line 753, in __getitem__\r\n    return self._getitem_index_not_tensor(item)\r\nSystemError: <method '_getitem_index_not_tensor' of 'Tensor' objects> returned a result with an error set\r\n```\r\n```\r\n[2023-07-13 19:34:57,436] [   ERROR] - offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000\r\nTraceback (most recent call last):\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\python\\asr_engine.py\", line 338, in decode\r\n    self.advance_decoding(is_finished)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\server\\engine\\asr\\online\\python\\asr_engine.py\", line 478, in advance_decoding\r\n    self.cnn_cache) = self.model.encoder.forward_chunk(\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\s2t\\modules\\encoder.py\", line 233, in forward_chunk\r\n    xs, pos_emb, _ = self.embed(xs, tmp_masks, offset=offset)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\s2t\\modules\\subsampling.py\", line 144, in forward\r\n    x, pos_emb = self.pos_enc(x, offset)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"F:\\miniconda3\\envs\\PaddleSpeech-develop\\lib\\site-packages\\paddlespeech\\s2t\\modules\\embedding.py\", line 161, in forward\r\n    assert offset + x.shape[\r\nAssertionError: offset: 4992 + x.shape[1]: 16 is larger than the max_len: 5000\r\n```\r\n我没找到相关issue，请问是否支持30系显卡",
        "state": "closed",
        "user": "seeseee",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-14T03:36:40+00:00",
        "updated_at": "2025-04-28T04:58:10+00:00",
        "closed_at": "2025-04-28T04:58:10+00:00",
        "comments_count": [
            "zxcd",
            "seeseee",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3394,
        "title": "使用流式ASR做了个语音唤醒，如何配置输出文字长度",
        "body": "使用流式ASR做了个语音唤醒，使用关键词匹配的方式，但是如果麦克风一直有说话，文字会一直追加，目前我是根据字数然后重置connection，但是这种处理在重置时会丢失chunk数据。\r\n",
        "state": "closed",
        "user": "pe1221",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-14T10:14:46+00:00",
        "updated_at": "2025-04-28T04:58:05+00:00",
        "closed_at": "2025-04-28T04:58:05+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3397,
        "title": "容器部署，前端接不上后端，websocket 链接失败，请检查Websocket 后端服务是否正确开启",
        "body": "前台后台部署在同一个容器内，通过脚本启动前端和后端服务\r\n\r\n后台通过 python main 正常启动，能打开API页面\r\n前台没有修改后台API配置保持localhost\r\n\r\n问题：\r\n\r\n前台页面一直在刷新，控制台有下面错误输出\r\n\r\n![20230717175204](https://github.com/PaddlePaddle/PaddleSpeech/assets/116550571/6458bf86-1004-400d-8279-164d90fa4eee)\r\n",
        "state": "closed",
        "user": "cdssd",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-17T09:53:05+00:00",
        "updated_at": "2025-06-27T03:38:19+00:00",
        "closed_at": "2025-06-27T03:38:19+00:00",
        "comments_count": [
            "zxcd",
            "iamfoolberg",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3395,
        "title": "搭建了一个在线finetune的服务，但是只能训练第一次请求，再次请求训练就报错AssertionError: Optimizer set error, embedding_2.w_0_moment1_0 should in state dict",
        "body": "Exception in main training loop: Optimizer set error, embedding_2.w_0_moment1_0 should in state dict\r\nTraceback (most recent call last):\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\training\\trainer.py\", line 149, in run\r\n    update()\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\training\\updaters\\standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"<decorator-gen-313>\", line 2, in step\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 319, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"<decorator-gen-311>\", line 2, in step\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\", line 26, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 534, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 550, in step\r\n    param_group_idx=0,\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 1167, in _apply_optimize\r\n    params_grads, param_group_idx=param_group_idx\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 928, in _create_optimization_pass\r\n    for p in parameters_and_grads\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 337, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 293, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 756, in _add_accumulator\r\n    var_name\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.[2023-07-14 20:35:10] [ERROR] [app.py:1742] Exception on /train_canton_clone [POST]\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\r\n  File \"C:/jisufenxiang/PaddleSpeech/examples/other/tts_finetune/tts3/main.py\", line 54, in train\r\n    local.finetune.finetune_train(pretrained_model_dir,dump_dir,output_dir)\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\examples\\other\\tts_finetune\\tts3\\local\\finetune.py\", line 276, in finetune_train\r\n    train_sp(train_args, config)\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\examples\\other\\tts_finetune\\tts3\\local\\finetune.py\", line 204, in train_sp\r\n    trainer.run()\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\training\\trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"C:\\Users\\leib.l\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\", line 703, in reraise\r\n    raise value\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\training\\trainer.py\", line 149, in run\r\n    update()\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\training\\updaters\\standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"C:\\jisufenxiang\\PaddleSpeech\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"<decorator-gen-313>\", line 2, in step\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 319, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"<decorator-gen-311>\", line 2, in step\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\", line 26, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 534, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 550, in step\r\n    param_group_idx=0,\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 1167, in _apply_optimize\r\n    params_grads, param_group_idx=param_group_idx\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 928, in _create_optimization_pass\r\n    for p in parameters_and_grads\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 337, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\adam.py\", line 293, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"C:\\Users\\leib.l\\Miniconda3\\lib\\site-packages\\paddle\\optimizer\\optimizer.py\", line 756, in _add_accumulator\r\n    var_name\r\nAssertionError: Optimizer set error, embedding_2.w_0_moment1_0 should in state dict",
        "state": "open",
        "user": "bageers0",
        "closed_by": null,
        "created_at": "2023-07-15T03:36:17+00:00",
        "updated_at": "2023-07-17T02:44:59+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3396,
        "title": "语音合成输出语音很生硬",
        "body": "## General Question\r\n如题，有解决办法嘛？\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "laoyan007",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-15T14:12:15+00:00",
        "updated_at": "2025-04-28T04:58:16+00:00",
        "closed_at": "2025-04-28T04:58:16+00:00",
        "comments_count": [
            "zxcd",
            "70557dzqc",
            "zxcd",
            "skyantao",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3401
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3398,
        "title": "[S2T]使用开源的S2模型，在最后预测阶段，输入出现问题",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n使用开源的Deepspeech2模型，在最后预测阶段，报错如下\r\nTraceback (most recent call last):\r\n  File \"/Users/hebin/PycharmProjects/asrmodeltest/work/workspace_asr_ds2/testdemo.py\", line 84, in <module>\r\n    result_transcripts = model.decode(\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 299, in decode\r\n    eouts, eouts_len, final_state_h_box, final_state_c_box = self.encoder(\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 130, in forward\r\n    x, final_state = self.rnn[i](x, init_state_list[i],\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddle/nn/layer/rnn.py\", line 1585, in forward\r\n    return self._cudnn_impl(inputs, initial_states, sequence_length)\r\n  File \"/Users/hebin/opt/anaconda3/envs/speechtest/lib/python3.10/site-packages/paddle/nn/layer/rnn.py\", line 1473, in _cudnn_impl\r\n    out, _, state = _C_ops.rnn(\r\nValueError: (InvalidArgument) The size of SequenceLength has to equal the batch_size. But received batch_size is 1 and the size of SequenceLength is 0.\r\n  [Hint: Expected in_dims[1] == seq_dims[0], but received in_dims[1]:1 != seq_dims[0]:0.] (at /Users/paddle/xly/workspace/9fc77989-de12-406f-9c25-c7ddd992fc3c/Paddle/paddle/phi/infermeta/multiary.cc:2690)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. 参考网址：(https://aistudio.baidu.com/bd-gpu-01/user/79593/6547194/notebooks/6547194.ipynb)'\r\n2. 代码路径、![Uploading image.png…]()\r\n3. 测试代码如下：\r\nimport paddle\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\nfrom yacs.config import CfgNode\r\n\r\nfrom paddlespeech.s2t.frontend.speech import SpeechSegment\r\nfrom paddlespeech.s2t.frontend.normalizer import FeatureNormalizer\r\nfrom paddlespeech.s2t.frontend.featurizer.audio_featurizer import AudioFeaturizer\r\nfrom paddlespeech.s2t.frontend.featurizer.text_featurizer import TextFeaturizer\r\nfrom paddlespeech.s2t.io.collator import SpeechCollator\r\nfrom paddlespeech.s2t.models.ds2 import DeepSpeech2Model\r\n\r\nfrom  matplotlib import pyplot as plt\r\n# %matplotlib inline\r\n# 设置预训练模型的路径\r\nconfig_path = \"conf/deepspeech2.yaml\"\r\ncheckpoint_path = \"./exp/deepspeech2/checkpoints/avg_1.pdparams\"\r\naudio_file = \"data/demo_01_03.wav\"\r\n\r\n\r\n# 读取 conf 文件并结构化\r\nds2_config = CfgNode(new_allowed=True)\r\nds2_config.merge_from_file(config_path)\r\nprint(ds2_config)\r\n\r\n# 构建音频特征提取对象\r\nfeat_config = ds2_config.collator\r\naudio_featurizer = AudioFeaturizer(\r\n    spectrum_type=feat_config.spectrum_type,\r\n    feat_dim=feat_config.feat_dim,\r\n    delta_delta=feat_config.delta_delta,\r\n    stride_ms=feat_config.stride_ms,\r\n    window_ms=feat_config.window_ms,\r\n    n_fft=feat_config.n_fft,\r\n    max_freq=feat_config.max_freq,\r\n    target_sample_rate=feat_config.target_sample_rate,\r\n    use_dB_normalization=feat_config.use_dB_normalization,\r\n    target_dB=feat_config.target_dB,\r\n    dither=feat_config.dither)\r\nfeature_normalizer = FeatureNormalizer(feat_config.mean_std_filepath) if feat_config.mean_std_filepath else None\r\n\r\n# 提取音频的特征\r\n# 'None' 只是一个占位符，因为预测的时候不需要reference\r\nspeech_segment = SpeechSegment.from_file(audio_file, \"None\")\r\naudio_feature = audio_featurizer.featurize(speech_segment)\r\naudio_feature_i = feature_normalizer.apply(audio_feature)\r\n\r\naudio_len = audio_feature_i.shape[0]\r\naudio_len = paddle.to_tensor(audio_len)\r\naudio_feature = paddle.to_tensor(audio_feature_i, dtype='float32')\r\naudio_feature = paddle.unsqueeze(audio_feature, axis=0)\r\nprint(f\"shape: {audio_feature.shape}\")\r\n\r\nplt.figure()\r\nplt.imshow(audio_feature_i.T, origin='lower')\r\nplt.show()\r\n\r\n# 构建Deepspeech2模型\r\nmodel_conf = ds2_config.model\r\n# input dim is feature size\r\nmodel_conf.input_dim = 161\r\n# output_dim is vocab size\r\nmodel_conf.output_dim = 4301\r\nmodel = DeepSpeech2Model.from_config(model_conf)\r\n\r\n# 加载预训练的模型\r\nmodel_dict = paddle.load(checkpoint_path)\r\nmodel.set_state_dict(model_dict)\r\n\r\n# 进行预测\r\n\r\ndecoding_config = ds2_config.decoding\r\ndecode_batch_size = 1\r\nprint (decoding_config)\r\ntext_feature = TextFeaturizer(unit_type='char',\r\n                            vocab=ds2_config.collator.vocab_filepath)\r\nvocab_list = text_feature.vocab_list\r\nmodel.decoder.init_decoder(\r\n            decode_batch_size, vocab_list, decoding_config.decoding_method,\r\n            decoding_config.lang_model_path, decoding_config.alpha, decoding_config.beta,\r\n            decoding_config.beam_size, decoding_config.cutoff_prob,\r\n            decoding_config.cutoff_top_n, decoding_config.num_proc_bsearch)\r\nresult_transcripts = model.decode(\r\n        audio_feature,\r\n        audio_len\r\n )\r\n\r\nprint (\"预测结果为:\")\r\nprint (result_transcripts[0])\r\n6. 运行该文件\r\n7. See error\r\n\r\n**Expected behavior**\r\n预期是输出对应的转写结果\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [Ubuntu20.04/mac0s均同样问题]\r\n - conda独立环境，python3.10\r\n - PaddlePaddle Version [2.5.0]\r\n - Model Version [e.g. 2.0.0]\r\n -模型下载：wget -nc https://paddlespeech.bj.bcebos.com/s2t/aishell/asr0/ds2.model.tar.gz\r\n - GPU/DRIVER Informationo 【cpu】\r\n - CUDA/CUDNN Version [无]\r\n - MKL Version\r\n- TensorRT Version\r\n- paddlespeech是源码安装\r\npaddlepaddle                2.5.0\r\npaddleslim                  2.4.1\r\npaddlespeech                0.0.0\r\n\r\n\r\n**Additional context**\r\n如需配合请随时联系我\r\n",
        "state": "open",
        "user": "hebin665",
        "closed_by": null,
        "created_at": "2023-07-18T03:59:33+00:00",
        "updated_at": "2023-07-19T08:02:33+00:00",
        "closed_at": null,
        "comments_count": [
            "hebin665",
            "hebin665",
            "zxcd",
            "hebin665",
            "hebin665"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3399,
        "title": "不同的预训练的声学模型和声码模型能不能自由组合",
        "body": "\r\n       我在使用PaddleSpeech/TTSArmLinux这个demo的时候发现。demo默认的预训练模型fastspeech2_csmsc_arm.nb,mb_melgan_csmsc_arm.nb改成fastspeech2_csmsc_arm.nb，hifigan_csmsc_arm.nb 这个demo还能正常的生成语音。\r\n        如果改成其他的预训练模型比如speedyspeech_csmsc_arm.nb，hifigan_csmsc_arm.nb demo就不能正常工作。这两个预训练模型都是基于csmsc数据集的。还有试了其他的预训练模型的组合都不能正常工作，不能生成音频。这个是为什么呢?\r\n      \r\n",
        "state": "closed",
        "user": "HUANGCD123456",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-18T07:40:00+00:00",
        "updated_at": "2025-04-28T04:58:28+00:00",
        "closed_at": "2025-04-28T04:58:28+00:00",
        "comments_count": [
            "zxcd",
            "HUANGCD123456",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3400,
        "title": "从音频文件(.wav 格式 或者.mp3 格式)生成字幕文件 (.srt 格式)   支不支持 识别英语，德语，日语等",
        "body": " C:\\python\\PaddleSpeech\\demos\\streaming_asr_server> **paddlespeech_server start --config_file ./conf/ws_conformer_wenetspeech_application.yaml**\r\n\r\nc:\\program files\\python38\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available. sox_io, sox_effect, kaldi raw feature is not supported!!!\r\n  warnings.warn(\r\n[2023-07-19 09:55:09,412] [    INFO] - start to init the engine\r\n[2023-07-19 09:55:09,412] [    INFO] - asr : online engine.\r\n2023-07-19 09:55:09.561 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n[2023-07-19 09:55:09,568] [   ERROR] - Failed to start server.\r\n[2023-07-19 09:55:09,568] [   ERROR] - Can't find \"conformer_online_wenetspeech-en-16k\" in resource. Model name must be one of ['conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_online_aishell-zh-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2online_aishell-zh-16k']\r\nPS C:\\python\\PaddleSpeech\\demos\\streaming_asr_server>\r\n\r\n目前只支持中文吗？有没有其他语言识别模型",
        "state": "closed",
        "user": "lvsh2012",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-19T02:49:55+00:00",
        "updated_at": "2025-04-28T04:58:37+00:00",
        "closed_at": "2025-04-28T04:58:37+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3402,
        "title": "颤音很重的问题",
        "body": "请问一下：\r\n我训练了2个人的声音，一个偏清脆，声音生成的效果也较好。一个偏沉，略沙哑，生成的声音效果颤音更重，甚至变成重叠音效果。应该怎么处理呢，感觉模型对颤音的忍耐力较低。\r\n\r\n是声码器的问题还是模型模拟能力不够的问题呢？\r\n谢谢！",
        "state": "closed",
        "user": "litao28",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-19T07:08:30+00:00",
        "updated_at": "2025-04-28T04:58:44+00:00",
        "closed_at": "2025-04-28T04:58:44+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "litao28",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3403,
        "title": "[S2T] Online ASR Server Failed to speech recognition, with \"1000\" error msg on server",
        "body": "## 环境\r\n- python==3.10 \r\n- paddlepaddle==2.5.0\r\n- paddlespeech 从develop分支编译安装\r\n\r\n## 问题描述\r\n\r\n按照[部署说明](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/server/README_cn.md)中示例部署Online ASR Server，客户端调用失败。\r\n\r\n服务端指令：`paddlespeech_server start --config_file conf/ws_conformer_application.yaml`\r\n服务端日志：\r\n```\r\n[2023-07-19 07:09:22,393] [    INFO] - start to init the engine\r\n[2023-07-19 07:09:22,393] [    INFO] - asr : online engine.\r\n2023-07-19 07:09:23.806 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-07-19 07:09:25,198] [    INFO] - Initialize ASR server engine successfully on device: cpu.\r\nINFO:     Started server process [154757]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)\r\nINFO:     ('127.0.0.1', 50494) - \"WebSocket /paddlespeech/asr/streaming\" [accepted]\r\nINFO:     connection open\r\n[2023-07-19 07:09:50,680] [    INFO] - first and second beam size: 10, 10\r\n[2023-07-19 07:09:50,680] [    INFO] - Endpont Opts: OnlineCTCEndpoingOpt(frame_shift_in_ms=10, blank=0, blank_threshold=0.8, rule1=OnlineCTCEndpointRule(must_contain_nonsilence=False, min_trailing_silence=5000, min_utterance_length=0), rule2=OnlineCTCEndpointRule(must_contain_nonsilence=True, min_trailing_silence=1000, min_utterance_length=0), rule3=OnlineCTCEndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20000))\r\n[2023-07-19 07:09:50,691] [   ERROR] - 1000\r\nINFO:     connection closed\r\n```\r\n客户端指令：`paddlespeech_client asr_online  --server_ip 127.0.0.1 --port 8090 --input output.wav`\r\n日志：\r\n```\r\n[2023-07-19 07:12:32,594] [    INFO] - asr websocket client start\r\n[2023-07-19 07:12:32,594] [    INFO] - endpoint: None\r\n[2023-07-19 07:12:32,594] [    INFO] - endpoint: ws://127.0.0.1:8090/paddlespeech/asr/streaming\r\n[2023-07-19 07:12:32,609] [    INFO] - client receive msg={\"status\":\"ok\",\"signal\":\"server_ready\"}\r\n[2023-07-19 07:12:32,610] [   ERROR] - Failed to speech recognition.\r\n[2023-07-19 07:12:32,610] [   ERROR] - \r\n```\r\n\r\n## 补充信息\r\n使用非Online模式可以正常调用返回解析内容，相关命令是：\r\n- 服务端：`paddlespeech_server start --config_file ./conf/application.yaml`\r\n- 客户端：`paddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input output.wav`\r\n\r\n## 其他\r\n- 配置或依赖问题？WS接口问题？还请帮忙",
        "state": "open",
        "user": "Scisaga",
        "closed_by": null,
        "created_at": "2023-07-19T07:43:49+00:00",
        "updated_at": "2023-08-10T09:12:15+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "FlorientHuang",
            "FlorientHuang"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3404,
        "title": " paddlespeech asr conformer_wenetspeech model  got  Out of memory error on GPU 0",
        "body": "\r\n## General Question\r\n在使用paddlespeech asr onformer_wenetspeech模型测试长语音文件时候出现如下错误：\r\n`λ b2de5ffec813 /paddle paddlespeech asr --lang zh --input audio-1600.wav --model conformer_wenetspeech\r\nW0719 07:18:53.845665  1094 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0719 07:18:53.849382  1094 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nterminate called after throwing an instance of 'paddle::memory::allocation::BadAlloc'\r\n  what():\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   scale_ad_func(paddle::experimental::Tensor const&, paddle::experimental::ScalarBase<paddle::experimental::Tensor>, float, bool)\r\n1   paddle::experimental::scale(paddle::experimental::Tensor const&, paddle::experimental::ScalarBase<paddle::experimental::Tensor> const&, float, bool)\r\n2   void phi::ScaleKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, float, bool, phi::DenseTensor*)\r\n3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const\r\n4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, paddle::experimental::DataType, unsigned long, bool) const\r\n5   phi::DenseTensor::AllocateFrom(phi::Allocator*, paddle::experimental::DataType, unsigned long)\r\n6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)\r\n7   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n8   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n9   paddle::memory::allocation::Allocator::Allocate(unsigned long)\r\n10  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)\r\n11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)\r\n12  phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nResourceExhaustedError:\r\n\r\nOut of memory error on GPU 0. Cannot allocate 648.000000MB memory on GPU 0, 3.708145GB memory has been allocated and available memory is only 298.859375MB.\r\n\r\nPlease check whether there is any other process using GPU 0.\r\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\r\n2. If no, please decrease the batch size of your model.\r\n\r\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:95)\r\n\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::pybind::ThrowExceptionToPython(std::__exception_ptr::exception_ptr)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1689751147 (unix time) try \"date -d @1689751147\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x446) received by PID 1094 (TID 0x7fa0e68f9700) from PID 1094 ***]\r\n\r\nAborted (core dumped)\r\nλ b2de5ffec813 /paddle nvidia-smi\r\nWed Jul 19 07:27:23 2023\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GRID P100-4Q        On   | 00000000:02:02.0 Off |                  N/A |\r\n| N/A   N/A    P0    N/A /  N/A |    304MiB /  4096MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+`\r\n\r\n使用其他的模型没有问题或者仅提示不能超过50秒\r\n\r\n`λ b2de5ffec813 /paddle paddlespeech asr --lang zh --input audio-1600.wav --model conformer_aishell\r\nW0719 07:33:16.532850  1183 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0719 07:33:16.536830  1183 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\n/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:277: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64\r\n  .format(lhs_dtype, rhs_dtype, lhs_dtype))\r\n那品八号我爱乐液但我也爱心片从前在家乡七八月的夜晚在庭院里那凉的时候我最爱砍贴掌秘密妈妈的烦心望了新片我就会忘记一切仿佛回到了母亲的怀丽式的则年前在南京我住的地方有一道后门没玩我打开后门便看见一个劲技的一下面是一片菜园上面是兴群密布的蓝天星光在我们的肉眼里虽然微小然玩他是我们觉得光民无处不在那时候我正在独一些缺为觉的诗也认的一些兴形好像他们就是我的朋友他们长常在和我谈话一样刘今在海上没一玩和樊兴相对我把他们任的很是无了我躺在舱面上养望天空\r\nλ b2de5ffec813 /paddle`\r\n\r\n我使用的是paddle:2.4.2-gpu-cuda10.2-cudnn7.6-trt7.0的gpu镜像，显卡使用的是tesla P100 vgpu为GRID P100-4Q 分配的显存为4G\r\n如果配置为GRID P100-8Q 也就是8G的时候可以正常运行。\r\n\r\n这是否是一个Bug 还是在那里可以调整该模型中对GPU的内存申请大小？\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "baiclamp",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-19T08:05:18+00:00",
        "updated_at": "2025-04-28T04:58:49+00:00",
        "closed_at": "2025-04-28T04:58:49+00:00",
        "comments_count": [
            "0x446",
            "baiclamp",
            "git3210",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3406,
        "title": "遇到了循环引用的问题ImportError: cannot import name 'CommonTaskResource' from partially initialized module 'paddlespeech.resource' (most likely due to a circular import) (D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\resource\\__init__.py)",
        "body": "D:\\Anaconda\\envs\\kty_paddle\\python.exe D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddle.py \r\nTraceback (most recent call last):\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddle.py\", line 14, in <module>\r\n    from paddlespeech.cli.asr.infer import ASRExecutor\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\resource\\__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\resource\\resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddle.py\", line 14, in <module>\r\n    from paddlespeech.cli.asr.infer import ASRExecutor\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\asr\\__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\asr\\infer.py\", line 32, in <module>\r\n    from ..executor import BaseExecutor\r\n  File \"D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\executor.py\", line 27, in <module>\r\n    from ..resource import CommonTaskResource\r\nImportError: cannot import name 'CommonTaskResource' from partially initialized module 'paddlespeech.resource' (most likely due to a circular import) (D:\\Onedrive\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\resource\\__init__.py)\r\n\r\nProcess finished with exit code 1\r\n",
        "state": "closed",
        "user": "2625009538",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-20T02:02:58+00:00",
        "updated_at": "2025-05-06T05:24:04+00:00",
        "closed_at": "2025-05-06T05:24:04+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3405,
        "title": "请问rhy训练的模型可以转成ONNX格式吗？",
        "body": "我收集了一批含有韵律标注的数据，准备参照\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/rhy\r\n训练韵律模型，请问如何将训练得到的模型转成ONNX格式？\r\n",
        "state": "closed",
        "user": "Tony-xubiao",
        "closed_by": "Tony-xubiao",
        "created_at": "2023-07-19T09:29:53+00:00",
        "updated_at": "2023-07-27T06:15:44+00:00",
        "closed_at": "2023-07-27T06:15:44+00:00",
        "comments_count": [
            "zxcd",
            "Tony-xubiao"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3408,
        "title": "paddlespeech_client 通信启动太慢",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n\r\n## 问题描述\r\n\r\n启动一次paddlespeech_client，即使在我自己的机器上也要7秒左右。而系统切换到paddle环境需要的时间1秒都不到。对比来看，paddlespeech_client启动该实在太慢，音频的时间大多消耗在了启动中，难以满足实时通信的需求（合成音频/推理很快，只是启动慢），不知未来能否优化，谢谢！！\r\n\r\n## Paddle模型时间实测\r\n\r\n2core2G服务器上：\r\n\r\n|option|time/s|\r\n|-|-|\r\n|conda activate base(paddlespeech)|1|\r\n|paddlespeech_client --help |15|\r\n\r\n本机上(i7-9750h 12cores)：\r\n\r\n|option|time/s|\r\n|-|-|\r\n|conda activate (paddlespeech)|1|\r\n|paddlespeech_client --help |7.6|\r\n\r\n",
        "state": "closed",
        "user": "chenovopride",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-20T05:40:41+00:00",
        "updated_at": "2025-04-27T18:52:53+00:00",
        "closed_at": "2025-04-27T18:52:53+00:00",
        "comments_count": [
            "zxcd",
            "Coldwon",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3409,
        "title": "paddleinference.asr_engine with deepspeech2online_wenetspeech model raise IndexError: list index out of range",
        "body": "model_type设置为`deepspeech2offline_aishell`推理正常，设置为`deepspeech2online_wenetspeech`就抛出异常了：IndexError: list index out of range\r\n\r\n配置文件：\r\n```\r\nasr_inference:\r\n    model_type: 'deepspeech2online_wenetspeech'\r\n    am_model: # the pdmodel file of am static model [optional]\r\n    am_params:  # the pdiparams file of am static model [optional]\r\n    lang: 'zh'\r\n    sample_rate: 16000\r\n    cfg_path: \r\n    num_decoding_left_chunks: -1\r\n    decode_method: 'attention_rescoring'\r\n    force_yes: True\r\n    am_predictor_conf:\r\n        device: 'cpu' # set 'gpu:id' or 'cpu'\r\n        switch_ir_optim: True\r\n        glog_info: False  # True -> print glog\r\n        summary: True  # False -> do not show predictor config\r\n```\r\n\r\n测试代码：\r\n```python\r\nimport numpy as np\r\nimport time\r\n\r\nfrom paddlespeech.server.engine.asr.paddleinference.asr_engine import ASREngine\r\nfrom paddlespeech.server.engine.asr.paddleinference.asr_engine import PaddleASRConnectionHandler\r\nfrom paddlespeech.server.utils.config import get_config\r\n\r\nconfig_path = 'config.yaml'\r\n\r\nasr_config = get_config(config_path)['asr_inference']\r\n\r\nengine = ASREngine()\r\nengine.init(asr_config)\r\n\r\nwith open(\"1.wav\", mode=\"rb\") as audio_file:\r\n    audio_data = audio_file.read()\r\n    \r\nconnection_handler = PaddleASRConnectionHandler(engine)\r\n\r\nt1 = time.time()\r\n\r\nconnection_handler.run(audio_data)\r\n\r\nasr_results = connection_handler.postprocess()\r\n\r\nprint(time.time() - t1, asr_results)\r\n```\r\n\r\n输出日志：\r\n```\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| Option                   | Value                                                                                                                                                                                         |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| model_file               | /home/jovyan/.paddlespeech/models/deepspeech2online_wenetspeech-zh-16k/1.0.4/asr0_deepspeech2_online_wenetspeech_ckpt_1.0.4.model.tar/exp/deepspeech2_online/checkpoints/avg_10.jit.pdmodel   |\r\n| params_file              | /home/jovyan/.paddlespeech/models/deepspeech2online_wenetspeech-zh-16k/1.0.4/asr0_deepspeech2_online_wenetspeech_ckpt_1.0.4.model.tar/exp/deepspeech2_online/checkpoints/avg_10.jit.pdiparams |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| cpu_math_thread          | 1                                                                                                                                                                                             |\r\n| enable_mkldnn            | false                                                                                                                                                                                         |\r\n| mkldnn_cache_capacity    | 10                                                                                                                                                                                            |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| use_gpu                  | false                                                                                                                                                                                         |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| use_xpu                  | false                                                                                                                                                                                         |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n| use_cinn_compiler        | false                                                                                                                                                                                         |\r\n| save_optimized_model     | false                                                                                                                                                                                         |\r\n| ir_optim                 | true                                                                                                                                                                                          |\r\n| ir_debug                 | false                                                                                                                                                                                         |\r\n| memory_optim             | false                                                                                                                                                                                         |\r\n| enable_profile           | false                                                                                                                                                                                         |\r\n| enable_log               | false                                                                                                                                                                                         |\r\n| collect_shape_range_info | false                                                                                                                                                                                         |\r\n+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n\r\n[2023-07-20 22:11:09,229] [    INFO] - Initialize ASR server engine successfully.\r\n2023-07-20 22:11:09.435 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:190 - begin to initialize the external scorer for decoding\r\n2023-07-20 22:11:09.521 | INFO     | paddlespeech.s2t.modules.ctc:_init_ext_scorer:197 - language model: is_character_based = 1, max_order = 5, dict_size = 0\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\nCell In[7], line 38\r\n     34 connection_handler = PaddleASRConnectionHandler(engine)\r\n     36 t1 = time.time()\r\n---> 38 connection_handler.run(audio_data)\r\n     40 asr_results = connection_handler.postprocess()\r\n     42 print(time.time() - t1, asr_results)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/server/engine/asr/paddleinference/asr_engine.py:243, in PaddleASRConnectionHandler.run(self, audio_data)\r\n    240 self.preprocess(self.asr_engine.config.model_type,\r\n    241                 io.BytesIO(audio_data))\r\n    242 st = time.time()\r\n--> 243 self.infer(self.asr_engine.config.model_type)\r\n    244 infer_time = time.time() - st\r\n    245 self.output = self.postprocess()  # Retrieve result of asr.\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/decorator.py:232, in decorate.<locals>.fun(*args, **kw)\r\n    230 if not kwsyntax:\r\n    231     args, kw = fix(args, kw, sig)\r\n--> 232 return caller(func, *(extras + args), **kw)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py:347, in _DecoratorContextManager.__call__.<locals>._decorate_function(func, *args, **kwargs)\r\n    344 @decorator.decorator\r\n    345 def _decorate_function(func, *args, **kwargs):\r\n    346     with self:\r\n--> 347         return func(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/server/engine/asr/paddleinference/asr_engine.py:141, in ASRServerExecutor.infer(self, model_type)\r\n    134 # init once\r\n    135 self.decoder.init_decoder(\r\n    136     decode_batch_size, self.text_feature.vocab_list,\r\n    137     cfg.decoding_method, cfg.lang_model_path, cfg.alpha, cfg.beta,\r\n    138     cfg.beam_size, cfg.cutoff_prob, cfg.cutoff_top_n,\r\n    139     cfg.num_proc_bsearch)\r\n--> 141 output_data = run_model(self.am_predictor,\r\n    142                         [audio.numpy(), audio_len.numpy()])\r\n    144 probs = output_data[0]\r\n    145 eouts_len = output_data[1]\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/server/utils/paddle_predictor.py:87, in run_model(predictor, input)\r\n     85 for i, name in enumerate(input_names):\r\n     86     input_handle = predictor.get_input_handle(name)\r\n---> 87     input_handle.copy_from_cpu(input[i])\r\n     88 # do the inference\r\n     89 predictor.run()\r\n\r\nIndexError: list index out of range\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/server/restful/asr_api.py\", line 83, in asr\r\n    connection_handler.run(audio_data)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/server/engine/asr/paddleinference/asr_engine.py\", line 243, in run\r\n    self.infer(self.asr_engine.config.model_type)\r\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/server/engine/asr/paddleinference/asr_engine.py\", line 141, in infer\r\n    output_data = run_model(self.am_predictor,\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/server/utils/paddle_predictor.py\", line 87, in run_model\r\n    input_handle.copy_from_cpu(input[i])\r\nIndexError: list index out of range\r\n````",
        "state": "closed",
        "user": "Scisaga",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-20T22:22:06+00:00",
        "updated_at": "2025-04-28T04:58:51+00:00",
        "closed_at": "2025-04-28T04:58:51+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3413
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3415
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3410,
        "title": "Multi-thread call paddlespeech_client asr, server raise Exception: You need to initialize the beam_search_decoder firstly",
        "body": "## 重现步骤\r\n\r\n1. 启动服务端\r\n   ```\r\n   paddlespeech_server start --config_file config.yaml\r\n   ```\r\n   - 配置文件：\r\n   ```\r\n   host: 0.0.0.0\r\n   port: 5000\r\n   protocol: 'http'\r\n   engine_list: ['asr_python', 'text_python']\r\n   \r\n   asr_python:\r\n       model: 'deepspeech2online_wenetspeech'\r\n       lang: 'zh'\r\n       sample_rate: 16000\r\n       cfg_path: # [optional]\r\n       ckpt_path: # [optional]\r\n       decode_method: 'attention_rescoring'\r\n       num_decoding_left_chunks: -1\r\n       force_yes: True\r\n       device: 'cpu'\r\n   \r\n   text_python:\r\n       task: punc\r\n       model_type: 'ernie_linear_p3_wudao'\r\n       lang: 'zh'\r\n       sample_rate: 16000\r\n       cfg_path: # [optional]\r\n       ckpt_path: # [optional]\r\n       vocab_file: # [optional]\r\n       device: 'cpu' # set 'gpu:id' or 'cpu'\r\n   ```\r\n2. 在两个shell中同时运行\r\n   ```\r\n   paddlespeech_client asr --server_ip 127.0.0.1 --port 5000 --input cache/AxC9es3hCYFfiauh-0000.wav\r\n   ```\r\n3. shell1正确获得识别结果，shell2报错\r\n4. 服务端异常\r\n```\r\n[2023-07-20 23:59:38,693] [    INFO] - You need to initialize the beam_search_decoder firstly\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/server/engine/asr/python/asr_engine.py\", line 120, in run\r\n    self.infer(self.asr_engine.config.model)\r\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 306, in infer\r\n    result_transcripts = self.model.decode(audio, audio_len)\r\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/s2t/models/ds2/deepspeech2.py\", line 303, in decode\r\n    self.decoder.reset_decoder(batch_size=batch_size)\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddlespeech/s2t/modules/ctc.py\", line 463, in reset_decoder\r\n    raise Exception(\r\nException: You need to initialize the beam_search_decoder firstly\r\n```\r\n\r\n通过什么方式进行配置可以有效的进行多线程调用？是否与以下信息有关？\r\n```\r\n!!! Since PaddlePaddle support 0-D tensor from 2.5.0, PaddleSpeech Static model will not work for it, please re-export static model.\r\n```",
        "state": "closed",
        "user": "Scisaga",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-21T00:36:42+00:00",
        "updated_at": "2025-05-06T05:24:05+00:00",
        "closed_at": "2025-05-06T05:24:05+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3411,
        "title": "paddlespeech - list index out of range",
        "body": "# 环境\r\n1. win11\r\n2. conda Python 3.10.11\r\n3. pip 23.1.2\r\n4. paddlepaddle==2.5.0\r\n5. paddlespeech==1.4.1\r\n6. paddleaudio==1.0.1\r\n7. vs 2022\r\n\r\n# 使用\r\n> 参照源 `https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/speech_recognition/README_cn.md`\r\n\r\n## 代码\r\n\r\n```\r\nimport paddle\r\nfrom paddlespeech.cli.asr import ASRExecutor\r\n\r\nasr_executor = ASRExecutor()\r\ntext = asr_executor(\r\n    model='conformer_wenetspeech',\r\n    lang='zh',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='./zh.wav',\r\n    force_yes=False,\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n```\r\n\r\n# 错误详情\r\n```\r\n2023-07-21 11:09:44.658 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2023-07-21 11:09:44.734 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-07-21 11:09:48,553] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"F:\\Program\\anaconda3\\envs\\paddle.1\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"F:\\Program\\anaconda3\\envs\\paddle.1\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"F:\\Program\\anaconda3\\envs\\paddle.1\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"F:\\Program\\anaconda3\\envs\\paddle.1\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"F:\\Program\\anaconda3\\envs\\paddle.1\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\nTraceback (most recent call last):\r\n```\r\n\r\n# 报错源码\r\n\r\n```\r\n    def attention_rescoring(self,\r\n                            speech: paddle.Tensor,\r\n                            speech_lengths: paddle.Tensor,\r\n                            beam_size: int,\r\n                            decoding_chunk_size: int=-1,\r\n                            num_decoding_left_chunks: int=-1,\r\n                            ctc_weight: float=0.0,\r\n                            simulate_streaming: bool=False,\r\n                            reverse_weight: float=0.0) -> List[int]:\r\n\r\n        assert speech.shape[0] == speech_lengths.shape[0]\r\n```\r\n\r\n",
        "state": "closed",
        "user": "zhanghzong",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-21T03:15:53+00:00",
        "updated_at": "2025-05-06T05:24:07+00:00",
        "closed_at": "2025-05-06T05:24:07+00:00",
        "comments_count": [
            "Chuyaoyuan",
            "zhanghzong",
            "zhanghzong",
            "zhanghzong",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3412,
        "title": "请教个关于流式tts的问题",
        "body": "请问流式tts和离线tts的区别在哪呢？\r\n我试了一下，流式tts也是一段文本进去，一段音频出来\r\n除了速度确实快之外，其它的感觉和离线tts没啥区别啊",
        "state": "closed",
        "user": "I-am-little-curly-hair",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-21T03:23:23+00:00",
        "updated_at": "2025-04-28T04:58:54+00:00",
        "closed_at": "2025-04-28T04:58:54+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3414,
        "title": "[TTS]声音克隆停顿标记sp为什么会发声",
        "body": "在使用声音克隆时发现使用中文句号“。”延长停顿会导致有声音产生，请问如何避免？\r\n\r\n\r\n音素截图：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/10766926/7d5ddbbb-39ad-455c-85e8-c151de502d3d)\r\n\r\n\r\n生成的音频文件：\r\nhttps://ai-digital.oss-cn-hangzhou.aliyuncs.com/%E4%B8%AD%E6%96%87%E5%8F%A5%E5%8F%B7%E3%80%82%E9%9F%B3%E9%A2%91.wav\r\n",
        "state": "open",
        "user": "fidding",
        "closed_by": null,
        "created_at": "2023-07-21T07:43:50+00:00",
        "updated_at": "2023-07-26T09:33:34+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "fidding"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3416,
        "title": "[S2T] [ASRExecutor] list index out of range || The size of SequenceLength has to equal the batch_size",
        "body": "python==3.10\r\npaddlepaddle==2.5.0 \r\npaddlespeech=1.4.1\r\n\r\n错误信息1：\r\n```\r\nKeyError                                  Traceback (most recent call last)\r\nCell In[4], line 11\r\n      4 # 读取wav\r\n      5 # 格式要求： 16k 16 bit 1 channel\r\n      6 # 音频时长 < 200s\r\n      7 # default_model = conformer_u2pp_online_wenetspeech\r\n      8 # better_model = deepspeech2online_wenetspeech\r\n      9 asr = ASRExecutor()\r\n---> 11 result = asr(\r\n     12     audio_file='1.wav', \r\n     13     force_yes=True\r\n     14 )\r\n     16 print(asr._outputs)\r\n     18 # 给输出文本加上标点\r\n     19 # 使用 ernie_linear_p3_wudao 提升效果\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/utils.py:328, in stats_wrapper.<locals>._warpper(self, *args, **kwargs)\r\n    326 except Exception:\r\n    327     pass\r\n--> 328 return executor_func(self, *args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py:512, in ASRExecutor.__call__(self, audio_file, model, lang, codeswitch, sample_rate, config, ckpt_path, decode_method, num_decoding_left_chunks, force_yes, rtf, device)\r\n    510 self.preprocess(model, audio_file)\r\n    511 self.infer(model)\r\n--> 512 res = self.postprocess()  # Retrieve result of asr.\r\n    514 if rtf:\r\n    515     CLI_TIMER[k]['end'].append(time.time())\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py:335, in ASRExecutor.postprocess(self)\r\n    331 def postprocess(self) -> Union[str, os.PathLike]:\r\n    332     \"\"\"\r\n    333         Output postprocess and return human-readable results such as texts and audio files.\r\n    334     \"\"\"\r\n--> 335     return self._outputs[\"result\"]\r\n\r\nKeyError: 'result'\r\n```\r\n\r\n错误信息2：\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[5], line 11\r\n      4 # 读取wav\r\n      5 # 格式要求： 16k 16 bit 1 channel\r\n      6 # 音频时长 < 200s\r\n      7 # default_model = conformer_u2pp_online_wenetspeech\r\n      8 # better_model = deepspeech2online_wenetspeech\r\n      9 asr = ASRExecutor()\r\n---> 11 result = asr(\r\n     12     audio_file='1.wav', \r\n     13     force_yes=True, \r\n     14     rtf=True,\r\n     15     model='deepspeech2online_wenetspeech'\r\n     16 )\r\n     18 print(asr._outputs)\r\n     20 # 给输出文本加上标点\r\n     21 # 使用 ernie_linear_p3_wudao 提升效果\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/utils.py:328, in stats_wrapper.<locals>._warpper(self, *args, **kwargs)\r\n    326 except Exception:\r\n    327     pass\r\n--> 328 return executor_func(self, *args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py:511, in ASRExecutor.__call__(self, audio_file, model, lang, codeswitch, sample_rate, config, ckpt_path, decode_method, num_decoding_left_chunks, force_yes, rtf, device)\r\n    508     CLI_TIMER[k]['start'].append(time.time())\r\n    510 self.preprocess(model, audio_file)\r\n--> 511 self.infer(model)\r\n    512 res = self.postprocess()  # Retrieve result of asr.\r\n    514 if rtf:\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/decorator.py:232, in decorate.<locals>.fun(*args, **kw)\r\n    230 if not kwsyntax:\r\n    231     args, kw = fix(args, kw, sig)\r\n--> 232 return caller(func, *(extras + args), **kw)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py:347, in _DecoratorContextManager.__call__.<locals>._decorate_function(func, *args, **kwargs)\r\n    344 @decorator.decorator\r\n    345 def _decorate_function(func, *args, **kwargs):\r\n    346     with self:\r\n--> 347         return func(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py:306, in ASRExecutor.infer(self, model_type)\r\n    299 decode_batch_size = audio.shape[0]\r\n    300 self.model.decoder.init_decoder(\r\n    301     decode_batch_size, self.text_feature.vocab_list,\r\n    302     cfg.decoding_method, cfg.lang_model_path, cfg.alpha, cfg.beta,\r\n    303     cfg.beam_size, cfg.cutoff_prob, cfg.cutoff_top_n,\r\n    304     cfg.num_proc_bsearch)\r\n--> 306 result_transcripts = self.model.decode(audio, audio_len)\r\n    307 self.model.decoder.del_decoder()\r\n    308 self._outputs[\"result\"] = result_transcripts[0]\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/decorator.py:232, in decorate.<locals>.fun(*args, **kw)\r\n    230 if not kwsyntax:\r\n    231     args, kw = fix(args, kw, sig)\r\n--> 232 return caller(func, *(extras + args), **kw)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py:347, in _DecoratorContextManager.__call__.<locals>._decorate_function(func, *args, **kwargs)\r\n    344 @decorator.decorator\r\n    345 def _decorate_function(func, *args, **kwargs):\r\n    346     with self:\r\n--> 347         return func(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/s2t/models/ds2/deepspeech2.py:299, in DeepSpeech2Model.decode(self, audio, audio_len)\r\n    295 @paddle.no_grad()\r\n    296 def decode(self, audio, audio_len):\r\n    297     # decoders only accept string encoded in utf-8\r\n    298     # Make sure the decoder has been initialized\r\n--> 299     eouts, eouts_len, final_state_h_box, final_state_c_box = self.encoder(\r\n    300         audio, audio_len, None, None)\r\n    301     probs = self.decoder.softmax(eouts)\r\n    302     batch_size = probs.shape[0]\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/nn/layer/layers.py:1254, in Layer.__call__(self, *inputs, **kwargs)\r\n   1245 if (\r\n   1246     (not in_declarative_mode())\r\n   1247     and (not self._forward_pre_hooks)\r\n   (...)\r\n   1251     and (not in_profiler_mode())\r\n   1252 ):\r\n   1253     self._build_once(*inputs, **kwargs)\r\n-> 1254     return self.forward(*inputs, **kwargs)\r\n   1255 else:\r\n   1256     return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddlespeech/s2t/models/ds2/deepspeech2.py:130, in CRNNEncoder.forward(self, x, x_lens, init_state_h_box, init_state_c_box)\r\n    128 final_chunk_state_list = []\r\n    129 for i in range(0, self.num_rnn_layers):\r\n--> 130     x, final_state = self.rnn[i](x, init_state_list[i],\r\n    131                                  x_lens)  #[B, T, D]\r\n    132     final_chunk_state_list.append(final_state)\r\n    133     x = self.layernorm_list[i](x)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/nn/layer/layers.py:1254, in Layer.__call__(self, *inputs, **kwargs)\r\n   1245 if (\r\n   1246     (not in_declarative_mode())\r\n   1247     and (not self._forward_pre_hooks)\r\n   (...)\r\n   1251     and (not in_profiler_mode())\r\n   1252 ):\r\n   1253     self._build_once(*inputs, **kwargs)\r\n-> 1254     return self.forward(*inputs, **kwargs)\r\n   1255 else:\r\n   1256     return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/nn/layer/rnn.py:1580, in RNNBase.forward(self, inputs, initial_states, sequence_length)\r\n   1570     initial_states = (\r\n   1571         [initial_states]\r\n   1572         if isinstance(initial_states, paddle.static.Variable)\r\n   1573         else initial_states\r\n   1574     )\r\n   1576 if self.could_use_cudnn and (\r\n   1577     not paddle.device.is_compiled_with_rocm() or sequence_length is None\r\n   1578 ):\r\n   1579     # Add CPU kernel and dispatch in backend later\r\n-> 1580     return self._cudnn_impl(inputs, initial_states, sequence_length)\r\n   1582 states = split_states(\r\n   1583     initial_states, self.num_directions == 2, self.state_components\r\n   1584 )\r\n   1585 final_states = []\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/paddle/nn/layer/rnn.py:1470, in RNNBase._cudnn_impl(self, inputs, initial_states, sequence_length)\r\n   1467     inputs = paddle.tensor.transpose(inputs, [1, 0, 2])\r\n   1469 if in_dygraph_mode():\r\n-> 1470     out, _, state = _C_ops.rnn(\r\n   1471         inputs,\r\n   1472         initial_states,\r\n   1473         self._all_weights,\r\n   1474         sequence_length,\r\n   1475         self._dropout_state,\r\n   1476         self.dropout,\r\n   1477         self.num_directions == 2,\r\n   1478         self.input_size,\r\n   1479         self.hidden_size,\r\n   1480         self.num_layers,\r\n   1481         self.mode,\r\n   1482         0,\r\n   1483         not self.training,\r\n   1484     )\r\n   1485 elif in_dynamic_mode():\r\n   1486     _, _, out, state = _legacy_C_ops.rnn(\r\n   1487         inputs,\r\n   1488         initial_states,\r\n   (...)\r\n   1506         not self.training,\r\n   1507     )\r\n\r\nValueError: (InvalidArgument) The size of SequenceLength has to equal the batch_size. But received batch_size is 1 and the size of SequenceLength is 0.\r\n  [Hint: Expected in_dims[1] == seq_dims[0], but received in_dims[1]:1 != seq_dims[0]:0.] (at ../paddle/phi/infermeta/multiary.cc:2690)\r\n```\r\n\r\n直接编译dev分支就没有上述问题，还是尽快发布新版本吧",
        "state": "open",
        "user": "Scisaga",
        "closed_by": null,
        "created_at": "2023-07-21T19:45:51+00:00",
        "updated_at": "2023-12-06T08:17:26+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "zhanghzong",
            "danyow-cheung",
            "qingjiaozyn"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3417,
        "title": "[S2T]使用examples/wenetspeech/asr1/中脚本训练报错，提示No such file or directory: 'data/mean_std.json'",
        "body": "环境\r\npython==3.8\r\npaddlepaddle==0.0.0（2.5.0开发版）\r\npaddlespeech==0.0.0 从develop分支编译安装\r\n问题描述\r\n按照[https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/wenetspeech/asr1)中示例训练wenetspeech数据集，数据处理已完毕，执行训练报错，提示No such file or directory: 'data/mean_std.json'。\r\n\r\n指令：bash run.sh --gpus 0,1 --stage 1 --stop_stage 1\r\n训练脚本：https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/wenetspeech/asr1/local/train.sh\r\n日志：\r\n\r\n```\r\n[2023-07-24 02:08:58,102] [    INFO] - paddlespeech.audio.text.text_featurizer | EOS id: 5537\r\n[2023-07-24 02:08:58,102] [    INFO] - paddlespeech.audio.text.text_featurizer | SOS id: 5537\r\n[2023-07-24 02:08:58,102] [    INFO] - paddlespeech.audio.text.text_featurizer | SPACE id: -1\r\n[2023-07-24 02:08:58,102] [    INFO] - paddlespeech.audio.text.text_featurizer | MASKCTC id: -1\r\n2023-07-24 02:08:58.108 | INFO     | paddlespeech.s2t.io.dataloader:__init__:143 - update_n_iter_processes 3\r\nTraceback (most recent call last):\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 46, in <module>\r\n    2023-07-24 02:08:58.108 | INFO     | paddlespeech.s2t.io.dataloader:__init__:146 - change nun_workers to 3\r\n2023-07-24 02:08:58.108 | INFO     | paddlespeech.s2t.exps.u2.model:setup_dataloader:251 - Setup train/valid Dataloader!\r\npr.runcall(main, config, args)\r\n  File \"/usr/lib/python3.8/cProfile.py\", line 124, in runcall\r\n    return func(*args, **kw)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 32, in main\r\n    main_sp(config, args)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 27, in main_sp\r\n    exp.setup()\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/training/trainer.py\", line 167, in setup\r\n    self.setup_model()\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/model.py\", line 273, in setup_model\r\n    model = U2Model.from_config(model_conf)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 959, in from_config\r\n    model = cls(configs)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 861, in __init__\r\n    vocab_size, encoder, decoder, ctc = U2Model._init_from_config(\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/models/u2/u2.py\", line 885, in _init_from_config\r\n    mean, istd = load_cmvn(configs['cmvn_file'],\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/frontend/utility.py\", line 334, in load_cmvn\r\n    cmvn = _load_json_cmvn(cmvn_file)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/frontend/utility.py\", line 260, in _load_json_cmvn\r\n    with open(json_cmvn_file) as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'data/mean_std.json'\r\nI0724 02:08:58.440701  5310 tcp_store.cc:273] receive shutdown event and so quit from MasterDaemon run loop\r\nLAUNCH INFO 2023-07-24 02:08:58,847 Exit code 1\r\n```\r\n\r\n进入examples/wenetspeech/asr1/data/目录，确实没有mean_std.json，在各个子文件夹中发现mean_std.json，以下是examples/wenetspeech/asr1/data/结构\r\n\r\n```\r\ndata/\r\n|-- corpus\r\n|   `-- dev_utt_list\r\n|   `-- reco2dur\r\n|   `-- segments\r\n|   `-- test_meeting_utt_list\r\n|   `-- test_net_utt_list\r\n|   `-- train_l_utt_list\r\n|   `-- utt2dur\r\n|   `-- utt2subsets\r\n|   `-- wav.scp\r\n|-- lang_char\r\n|   `-- vocab.txt\r\n|-- dev\r\n|   `-- 、、、\r\n|-- test_meeting\r\n|   `-- 、、、\r\n|-- test_net\r\n|   `-- 、、、\r\n|-- train_config\r\n|   `-- 、、、\r\n|-- train_l\r\n|   `-- mean_std.json\r\n|   `-- wav.scp.sampled\r\n|   `-- data.list\r\n|   `-- wav.scp\r\n|   `-- utt2dur\r\n|   `-- text\r\n|   `-- segments\r\n```\r\n\r\n之前也跑过examples/aishell/asr1/流程，发现wenetspeech和aishell的脚本以及生成文件相差好多，麻烦帮看下如何完整执行wenetspeech/asr1的训练，多谢\r\n",
        "state": "open",
        "user": "Chuyaoyuan",
        "closed_by": null,
        "created_at": "2023-07-24T02:49:35+00:00",
        "updated_at": "2023-10-20T05:45:32+00:00",
        "closed_at": null,
        "comments_count": [
            "Chuyaoyuan",
            "bigmisspanda"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3418,
        "title": "aishell语音识别，采样率16k转8k训练200个epoch不收敛，并且测试词错率0.917776",
        "body": "paddlenlp==2.5.2\r\npaddlepaddle-gpu==2.5.0rc0\r\npaddleslim==2.4.1\r\npaddlespeech==1.4.1\r\npaddlespeech-feat==0.1.0\r\n\r\n我把/home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav 目录下所有子目录的wav文件重采样为8K\r\n\r\nfile /home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/train/S0002/BAC009S0002W0122.wav\r\n/home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/train/S0002/BAC009S0002W0122.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 8000 Hz\r\n\r\nfile /home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/dev/S0724/BAC009S0724W0121.wav\r\n/home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/dev/S0724/BAC009S0724W0121.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 8000 Hz\r\n\r\nfile /home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/test/S0770/BAC009S0770W0121.wav\r\n/home/aistudio/work/PaddleSpeech/dataset/aishell/data_aishell/wav/test/S0770/BAC009S0770W0121.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 8000 Hz\r\n\r\n\r\n\r\n\r\n然后执行\r\ncd ~/work/PaddleSpeech/examples/aishell/asr1\r\nrun.sh --stage 1 --stop_stage 1 --gpus 0\r\n正常训练完毕。\r\n\r\n然后执行测试:\r\nrun.sh --stage 3 --stop_stage 3 --gpus 0\r\n\r\n词错率非常的高，这是为啥？一般需要训练多少个epoch？就算我是用了16的检查点作为了初始参数，可我是训练了200epoch怎么着也更新参数了吧，词错率咋会这么高？\r\n\r\n输出效果如下：\r\n23-07-24 10:33:15.424 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:492 - Utt: BAC009S0770W0413\r\n2023-07-24 10:33:15.425 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:493 - Ref: 据香港媒体报道\r\n2023-07-24 10:33:15.425 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:494 - Hyp: 隐喝万的不爸爸\r\n2023-07-24 10:33:15.426 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:496 - One example error rate [cer] = 1.000000\r\n2023-07-24 10:33:15.427 | INFO     | paddlespeech.s2t.exps.u2.model:test:531 - RTF: 0.000427, Error rate [cer] (352/?) = 0.917679\r\n2023-07-24 10:33:15.639 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.640 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.641 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.642 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 6, out_tensor [10, 6], tensor [6]\r\n2023-07-24 10:33:15.642 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 6, out_tensor [10, 6], tensor [6]\r\n2023-07-24 10:33:15.643 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 6, out_tensor [10, 6], tensor [6]\r\n2023-07-24 10:33:15.644 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.644 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.645 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 6, out_tensor [10, 6], tensor [6]\r\n2023-07-24 10:33:15.645 | INFO     | paddlespeech.s2t.utils.tensor_utils:pad_sequence:97 - length 5, out_tensor [10, 6], tensor [5]\r\n2023-07-24 10:33:15.902 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:492 - Utt: BAC009S0770W0420\r\n2023-07-24 10:33:15.903 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:493 - Ref: 谢贤怒打曾江\r\n2023-07-24 10:33:15.904 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:494 - Hyp: 走回落的公光\r\n2023-07-24 10:33:15.904 | INFO     | paddlespeech.s2t.exps.u2.model:compute_metrics:496 - One example error rate [cer] = 1.000000\r\n2023-07-24 10:33:15.905 | INFO     | paddlespeech.s2t.exps.u2.model:test:531 - RTF: 0.000427, Error rate [cer] (353/?) = 0.917776\r\n2023-07-24 10:33:15.945 | INFO     | paddlespeech.s2t.exps.u2.model:test:540 - Test: epoch: 0, step: 0, RTF: 0.00042674670569451913, Final error rate [cer] (353/353) = 0.917776",
        "state": "closed",
        "user": "xiaoligang2000",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-24T03:43:54+00:00",
        "updated_at": "2025-05-06T05:24:04+00:00",
        "closed_at": "2025-05-06T05:24:04+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3419,
        "title": "[Hint: 'CUFFT_INTERNAL_ERROR'. Driver or internal cuFFT library error] 多卡时指定非0卡报错",
        "body": "paddle-bfloat                0.1.7\r\npaddle2onnx                  1.0.6\r\npaddleaudio                  1.1.0\r\npaddlefsl                    1.1.0\r\npaddlenlp                    2.5.2\r\npaddlepaddle-gpu             2.5.0.post117\r\npaddleslim                   2.4.1\r\npaddlespeech                 0.0.0\r\npaddlespeech-ctcdecoders     0.2.1\r\npaddlespeech-feat            0.1.0\r\n\r\n问题描述：\r\n非流式ASR服务启动；\r\n当服务器上有多张卡时，不修改默认参数即使用paddlespeech/server/conf/application_diy.yaml，是运行再gpu上；\r\n当指定gpu:3 时，起服务时在3号卡上；当推理时调用到paddlespeech/audio/transform/transformation.py 下 Transformation的 __call__方法时，会调用到paddlespeech/audio/transform/spectrogram.py 下LogMelSpectrogramKaldi的 __call__方法，\r\n最终调用到_**kaldi.fbank时，会自动挂在0号上，导致报错**_，而且即使在前面指定 paddle.device.set_device('gpu:3') 或者 os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" 或者 启动程序前 export CUDA_VISIBLE_DEVICES=3 都是一样报错。\r\n\r\n解决办法：\r\npaddlespeech/cli/asr/infer.py 下preprocess方法中， \r\n```python\r\n\r\n``` paddle.device.set_device('cpu') # 尝试fft不报错，在cpu上跑\r\n    audio = preprocessing(audio, **preprocess_args)\r\n    paddle.device.set_device('gpu:3')\r\n\r\n在“audio = preprocessing(audio, **preprocess_args)” 前后分别指定位置——计算fft在cpu上，然后再指定回gpu上。\r\n解决",
        "state": "closed",
        "user": "PC-god",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-24T06:23:59+00:00",
        "updated_at": "2025-05-06T05:24:06+00:00",
        "closed_at": "2025-05-06T05:24:06+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3420,
        "title": "[Hint: 'CUFFT_INTERNAL_ERROR'. Driver or internal cuFFT library error] 多卡时指定非0卡报错",
        "body": "paddle-bfloat                0.1.7\r\npaddle2onnx                  1.0.6\r\npaddleaudio                  1.1.0\r\npaddlefsl                    1.1.0\r\npaddlenlp                    2.5.2\r\npaddlepaddle-gpu             2.5.0.post117\r\npaddleslim                   2.4.1\r\npaddlespeech                 0.0.0\r\npaddlespeech-ctcdecoders     0.2.1\r\npaddlespeech-feat            0.1.0\r\n\r\n问题描述：\r\n非流式ASR服务启动；\r\n当服务器上有多张卡时，不修改默认参数即使用paddlespeech/server/conf/application_diy.yaml，是运行再cpu上；\r\n当指定gpu:3 时，起服务时在3号卡上；当推理时调用到paddlespeech/audio/transform/transformation.py 下 Transformation的 __call__方法时，会调用到paddlespeech/audio/transform/spectrogram.py 下LogMelSpectrogramKaldi的 __call__方法，\r\n最终调用到_**kaldi.fbank时，会自动挂在0号上，导致报错**_，而且即使在前面指定 paddle.device.set_device('gpu:3') 或者 os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" 或者 启动程序前 export CUDA_VISIBLE_DEVICES=3 都是一样报错。\r\n\r\n解决办法：\r\npaddlespeech/cli/asr/infer.py 下preprocess方法中， \r\n```python\r\n\r\n``` paddle.device.set_device('cpu') # 尝试fft不报错，在cpu上跑\r\n    audio = preprocessing(audio, **preprocess_args)\r\n    paddle.device.set_device('gpu:3')\r\n\r\n在“audio = preprocessing(audio, **preprocess_args)” 前后分别指定位置——计算fft在cpu上，然后再指定回gpu上。\r\n解决",
        "state": "closed",
        "user": "PC-god",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-24T06:27:35+00:00",
        "updated_at": "2025-04-28T04:58:41+00:00",
        "closed_at": "2025-04-28T04:58:41+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3421,
        "title": "[TTS]XXXX",
        "body": "当我使用examples/other/tts-finetune时，运行run.sh报错：\r\n../input/csmsc_mini/:Is a /directory\r\n\r\n![run_bug](https://github.com/PaddlePaddle/PaddleSpeech/assets/91247260/912b8667-234c-45f7-8bd1-c1fefdfa2076)\r\n",
        "state": "closed",
        "user": "LayBrick",
        "closed_by": "LayBrick",
        "created_at": "2023-07-25T01:19:26+00:00",
        "updated_at": "2023-07-25T01:47:17+00:00",
        "closed_at": "2023-07-25T01:47:17+00:00",
        "comments_count": [
            "LayBrick",
            "LayBrick",
            "LayBrick"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3422,
        "title": "小样本微调得到的模型能否根据文本生成有情绪和停顿的语音？",
        "body": "在/home/Paddle/speech/PaddleSpeech/examples/other/tts_finetune/tts3 目录下，通过小样本微调出来的模型，没有修改配置参数，直接运行  ./run.sh --stage 6 --stop-stage 6 ，得到的语音没有情绪，在文本中加入，和。等标点符号，在语音中也没有暂停，情绪和停顿可以通过修改配置或者加入数据训练实现吗？",
        "state": "closed",
        "user": "JiadiLee",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-25T10:39:41+00:00",
        "updated_at": "2025-04-28T04:57:58+00:00",
        "closed_at": "2025-04-28T04:57:58+00:00",
        "comments_count": [
            "zxcd",
            "JiadiLee",
            "zxcd",
            "ppy2017",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3423,
        "title": "hifigan_aishell3.onnx   inputs [-1,80]     这个模型onnx文件是怎么生成的？",
        "body": "我用hifigan_aishell3_ckpt_0.2.0/snapshot_iter_2500000.pdz 转换成pdmodel，pdiparams  再转成onnx.  在netron里看input是name: logmel\r\ntype: float32[p2o.DynamicDimension.0,80]\r\n\r\n\r\n但是直接从git上下载的hifigan_aishell3.onnx   ，在netron里看input是\r\nlogmel\r\nname: logmel\r\ntype: float32[-1,80]\r\n\r\n\r\n我想请教一下，git上下载的hifigan_aishell3.onnx  是怎么生成的，为什么input是-1而不是dynamic",
        "state": "closed",
        "user": "23michael45",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-25T12:07:21+00:00",
        "updated_at": "2025-05-06T05:24:11+00:00",
        "closed_at": "2025-05-06T05:24:11+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3425,
        "title": "在TTS模型中，使用多说话人模型时总会报以下错误",
        "body": "ValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[256].\r\n  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at /paddle/paddle/phi/infermeta/unary.cc:2763)\r\n\u0000\r\n例如\r\npaddlespeech tts --am fastspeech2_aishell3 --voc pwgan_aishell3 --input \"你好，欢迎使用百度飞桨深度学习框架！\" --spk_id 0\r\npaddlespeech tts --am fastspeech2_vctk --voc pwgan_vctk --input \"hello, boys\" --lang en --spk_id 0\r\n等等均会报同样的错误\r\n",
        "state": "closed",
        "user": "lizzzzzz1",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-26T07:45:21+00:00",
        "updated_at": "2025-06-27T04:34:28+00:00",
        "closed_at": "2025-06-27T04:34:28+00:00",
        "comments_count": [
            "zxcd",
            "Coldwon",
            "houzimm",
            "ShineWellSnake",
            "whtwhtw",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3426,
        "title": "为什么英文模型 Paddle Lite 推理很慢",
        "body": "尝试了 vctk，ljspeech 的模型，都非常缓慢，只有中文模型可以做到实时。\r\n\r\n- ljspeech 的 RTF 在 4-6 （fastspeech2_ljspeech_static_1.1.0 + pwgan_ljspeech_static_1.1.0）     \r\n- vctk 的 RTF 在 1.5 左右  （fastspeech2_vctk_static_1.1.0 + hifigan_vctk_static_1.1.0）     \r\n\r\n看了Server部分的python 代码，  Onnx  配置非常多，如果移植到  c++ 工作量很大。\r\n\r\nX86 环境有快一点的 C++ 的推理方案吗？或者如何进一步加速 PaddleLite 推理？pwgan 和 hifigan 都很慢？ 英文哪个声码器性能最好？\r\n\r\n\r\n",
        "state": "closed",
        "user": "endink",
        "closed_by": "endink",
        "created_at": "2023-07-26T08:09:24+00:00",
        "updated_at": "2023-07-28T06:17:15+00:00",
        "closed_at": "2023-07-28T06:17:14+00:00",
        "comments_count": [
            "endink",
            "endink"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3427,
        "title": "安装上了，也提示成功了，为啥paddlespeech_server命令工具不能用",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/18072177/3df93da9-d20d-42f2-b35f-e9fa39ebeb50)\r\n\r\n安装上了，也提示成功了，为啥paddlespeech_server命令工具不能用，怎么排查下哪里有问题",
        "state": "closed",
        "user": "z1060932884",
        "closed_by": "z1060932884",
        "created_at": "2023-07-26T12:43:36+00:00",
        "updated_at": "2023-07-28T09:26:15+00:00",
        "closed_at": "2023-07-28T09:26:14+00:00",
        "comments_count": [
            "zhanghzong",
            "z1060932884"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3428,
        "title": "[TTS]XXXX",
        "body": "我使用了paddle官网教程（https://aistudio.baidu.com/aistudio/projectdetail/6572581）的代码：\r\nimport paddle\r\nimport yaml\r\nimport soundfile as sf\r\nfrom yacs.config import CfgNode\r\nfrom paddlespeech.t2s.frontend.mix_frontend import MixFrontend\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import run_frontend\r\n\r\nsentence = \"我有一本书，名字叫《The Little Prince》. 这本书售价15.8元。\"\r\n\r\n# text frontend\r\nphones_dict = \"download/fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt\"\r\nfrontend = MixFrontend(phone_vocab_path=phones_dict)\r\nprint(\"frontend done!\")\r\n\r\n# load AM\r\nam_config_file = \"download/fastspeech2_mix_ckpt_1.2.0/default.yaml\"\r\nam_ckpt = \"download/fastspeech2_mix_ckpt_1.2.0/snapshot_iter_99200.pdz\"\r\nam_stat = \"download/fastspeech2_mix_ckpt_1.2.0/speech_stats.npy\"\r\nspeaker_dict = \"download/fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt\"\r\nwith open(am_config_file) as f:\r\n    am_config = CfgNode(yaml.safe_load(f))\r\nam_inference = get_am_inference(\r\n    am=\"fastspeech2_mix\",\r\n    am_config=am_config,\r\n    am_ckpt=am_ckpt,\r\n    am_stat=am_stat,\r\n    phones_dict=phones_dict,\r\n    tones_dict=None,\r\n    speaker_dict=speaker_dict)\r\nprint(\"acoustic model done!\")\r\n\r\n# load Voc\r\nvoc_config_file = \"download/hifigan_aishell3_ckpt_0.2.0/default.yaml\"\r\nvoc_ckpt = \"download/hifigan_aishell3_ckpt_0.2.0/snapshot_iter_2500000.pdz\"\r\nvoc_stat = \"download/hifigan_aishell3_ckpt_0.2.0/feats_stats.npy\"\r\nwith open(voc_config_file) as f:\r\n    voc_config = CfgNode(yaml.safe_load(f))\r\nvoc_inference = get_voc_inference(\r\n    voc=\"hifigan_aishell3\",\r\n    voc_config=voc_config,\r\n    voc_ckpt=voc_ckpt,\r\n    voc_stat=voc_stat)\r\nprint(\"voc done!\")\r\n\r\n# get phone id\r\nfrontend_dict = run_frontend(\r\n    frontend=frontend,\r\n    text=sentence,\r\n    merge_sentences=False,\r\n    get_tone_ids=False,\r\n    lang=\"mix\")\r\nphone_ids = frontend_dict['phone_ids']\r\n\r\n# inference\r\nflags = 0\r\nfor i in range(len(phone_ids)):\r\n    part_phone_ids = phone_ids[i]\r\n    spk_id = 174  # baker:174, ljspeech:175, aishell3:0~173, vctk:176~282\r\n    spk_id = paddle.to_tensor(spk_id)\r\n    mel = am_inference(part_phone_ids, spk_id)\r\n    wav = voc_inference(mel)\r\n    if flags == 0:\r\n        wav_all = wav\r\n        flags = 1\r\n    else:\r\n        wav_all = paddle.concat([wav_all, wav])\r\nprint(\"infer successfully.\")\r\n\r\n# save audio\r\nwav = wav_all.numpy()\r\nsf.write(\"./out.wav\", wav, am_config.fs)\r\n\r\n# play audio\r\nimport IPython.display as dp\r\ndp.Audio(wav.T, rate=am_config.fs)\r\n\r\n为什么程序运行后会出现下面这个错误？\r\nTraceback (most recent call last):\r\n  File \"E:\\deepLearning\\paddleLearnning\\TTS\\trainModel\\mix\\script.py\", line 64, in <module>\r\n    mel = am_inference(part_phone_ids, spk_id)\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 895, in forward\r\n    normalized_mel, d_outs, p_outs, e_outs = self.acoustic_model.inference(\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 786, in inference\r\n    _, outs, d_outs, p_outs, e_outs = self._forward(\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 594, in _forward\r\n    hs = self._integrate_with_spk_embed(hs, spk_emb)\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 815, in _integrate_with_spk_embed\r\n    spk_emb = F.normalize(spk_emb).unsqueeze(1).expand(\r\n  File \"D:\\Anaconda\\envs\\wuzhuangbu\\lib\\site-packages\\paddle\\nn\\functional\\norm.py\", line 82, in normalize\r\n    out = _C_ops.p_norm(x, float(p), axis, epsilon, True, False)\r\nValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[256].\r\n  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at ..\\paddle\\phi\\infermeta\\unary.cc:2763)\r\n\r\n",
        "state": "open",
        "user": "WanwanLinLin",
        "closed_by": null,
        "created_at": "2023-07-26T13:34:00+00:00",
        "updated_at": "2023-08-01T12:48:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3429,
        "title": "我在训练一个自己的TTS模型的时候遇到的问题",
        "body": "AssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]       我在训练一个自己的TTS模型的时候遇到的问题\r\n",
        "state": "closed",
        "user": "drinkerwhz",
        "closed_by": "drinkerwhz",
        "created_at": "2023-07-27T07:15:08+00:00",
        "updated_at": "2023-09-19T02:58:26+00:00",
        "closed_at": "2023-07-27T09:30:42+00:00",
        "comments_count": [
            "drinkerwhz",
            "zhdovelie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3431,
        "title": "[TTS]运行不起来",
        "body": "Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/core.py\", line 356, in <module>\r\n    raise e\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: libssl.so.1.1: cannot open shared object file: No such file or directory",
        "state": "open",
        "user": "chenghaojie10006",
        "closed_by": null,
        "created_at": "2023-07-27T15:59:51+00:00",
        "updated_at": "2023-08-01T12:58:26+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3430,
        "title": "where is the spk_id list for pre-trained model?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "centny",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-27T09:09:18+00:00",
        "updated_at": "2025-05-06T05:24:10+00:00",
        "closed_at": "2025-05-06T05:24:10+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3432,
        "title": "Dependencies in `setup.py` have module conflicts.",
        "body": "### What are you trying to achieve?\r\n\r\nThere are two dependencies mentioned in the `setup.py` file: \r\n```\r\n    \"opencc\",\r\n    \"opencc-python-reimplemented\",\r\n```\r\nTo my knowledge, there appears to be a conflict between these two packages. Due to their origin from different projects, [opencc-python-reimplemented](https://pypi.org/project/opencc-python-reimplemented/#description) and the [opencc-python 0.1](https://pypi.org/project/opencc-python/#description) project. Both of these projects contain the module `opencc/__init__.py` with differing contents.\r\n\r\nDuring the pip installation process, both of these packages are installed simultaneously. However, pip does not isolate these two packages, but rather installs them both in the `site-packages` folder. This results in the `opencc/__init__.py` module from the latter installed package overwriting the one installed by the previous package.\r\n\r\n### Steps to reproduce the problem\r\n\r\n`pip install paddlepaddle`\r\n\r\n### What did you expect to happen?\r\n\r\nDue to my lack of understanding of the project at the source code level, I have only analyzed its dependencies. However, I speculate whether it would be possible to eliminate unnecessary dependencies. It appears that these two conflicting projects offer similar functionality.\r\n\r\nIndeed, it is not an ideal behavior for modules to be overwritten, even if they are not actively used or if the overwritten module is the one being called. It introduces uncertainty and can cause issues in the long run, especially if there are changes or updates to the overwritten modules in future development. It is generally recommended to avoid such conflicts and ensure that only the necessary and compatible dependencies are declared in the requirements to maintain a stable and predictable environment for the project. \r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Environment\r\npython 3.8.10",
        "state": "closed",
        "user": "unsatisfying",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-28T03:16:56+00:00",
        "updated_at": "2025-05-06T05:24:12+00:00",
        "closed_at": "2025-05-06T05:24:12+00:00",
        "comments_count": [
            "zxcd",
            "unsatisfying",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3434,
        "title": "tts_finetune/ tts3 根据 md 文档走出现了问题",
        "body": "当我 ./run_mix.sh --stage 0 --stop-stage 5出现了AssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]报错，然后当我删除exp/default 文件之后，再去执行 ./run_mix.sh --stage 5 --stop-stage 5就好了，这是为什么？\r\n",
        "state": "closed",
        "user": "drinkerwhz",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-28T07:41:42+00:00",
        "updated_at": "2025-05-06T05:24:08+00:00",
        "closed_at": "2025-05-06T05:24:08+00:00",
        "comments_count": [
            "dfsong",
            "drinkerwhz",
            "dfsong",
            "drinkerwhz",
            "dfsong",
            "drinkerwhz",
            "drinkerwhz",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3435,
        "title": "[S2T]wenetspeech数据集训练报错，(Fatal) Blocking queue is killed because the data reader raises an exception.",
        "body": "### 环境\r\npython==3.8\r\npaddlepaddle==0.0.0（2.5.0开发版）\r\npaddlespeech==0.0.0 从develop分支编译安装\r\n### 问题描述\r\n按照 [wenetspeech/asr1](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/wenetspeech/asr1)中示例训练wenetspeech数据集，epoch ：0 已完毕，执行 epoch：1 训练报错，提示 (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n\r\n### 指令：\r\n`bash run.sh --gpus 0,1 --stage 1 --stop_stage 1`\r\n训练脚本：https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/wenetspeech/asr1/local/train.sh\r\n### 日志：\r\n\r\n\r\n```\r\n2023-07-28 06:32:17.457 | INFO     | paddlespeech.s2t.exps.u2.model:do_train:214 - Train: Rank: 0, epoch: 1, step: 15723, lr: 0.00056392, loss: 63.29914856, att_loss: 51.07065582, ctc_loss: 91.83230591, batch_size: 16, accum: 32, step_cost: 0.31190991, iter: 46900, reader_cost: 0.00034237, batch_cost: 0.31225228, samples: 16, ips: 51.24061814 samples/s\r\n2023-07-28 06:32:56.869 | INFO     | paddlespeech.s2t.exps.u2.model:do_train:214 - Train: Rank: 0, epoch: 1, step: 15726, lr: 0.00056387, loss: 127.69183350, att_loss: 100.78931427, ctc_loss: 190.46438599, batch_size: 16, accum: 32, step_cost: 0.69754767, iter: 47000, reader_cost: 0.00041556, batch_cost: 0.69796324, samples: 16, ips: 22.92384346 samples/s\r\nLAUNCH INFO 2023-07-28 06:33:48,632 Pod failed\r\nLAUNCH ERROR 2023-07-28 06:33:48,632 Container failed !!!\r\nContainer rank 1 status failed cmd ['/usr/local/bin/python3', '-u', '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py', '--ngpu', '2', '--seed', '0', '--config', 'conf/conformer.yaml', '--output', 'exp/conformer', '--profiler-options', '', '--benchmark-batch-size', '0', '--benchmark-max-step', '0'] code 1 log log/workerlog.1 \r\nenv {'NCCL_SOCKET_IFNAME': 'eth0', 'GREP_COLOR': '1;31', 'CPLUS_INCLUDE_PATH': '/usr/local/python3.7.0/include/python3.7:', 'CUDNN_VERSION': '7.6.5.32', 'HOSTNAME': '4756b3140789', 'NVIDIA_REQUIRE_CUDA': 'cuda>=10.2 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441', 'TERM': 'xterm', 'CLICOLOR': '1', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'LC_ALL': 'C', 'PYTHONIOENCODING': 'UTF-8', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/usr/local/python3.7.0/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib/', 'BIN_DIR': '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin', 'WITH_AVX': 'ON', 'MAIN_ROOT': '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'FLAGS_allocator_strategy': 'naive_best_fit', 'PATH': '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop:/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/utils:/usr/local/python3.7.0/bin:/usr/local/python3.7.0/include:/home/cmake-3.16.0-Linux-x86_64/bin:/usr/local/gcc-8.2/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin:/root/gopath/bin', 'PWD': '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/examples/wenetspeech/asr1', 'CUDA_VISIBLE_DEVICES': '0,1', 'LANG': 'en_US.UTF-8', 'CUDA_PKG_VERSION': '10-2=10.2.89-1', 'CUDA_VERSION': '10.2.89', 'PYTHONDONTWRITEBYTECODE': '1', 'SHLVL': '3', 'HOME': '/root', 'LANGUAGE': 'en_US.UTF-8', 'GOROOT': '/usr/local/go', 'GREP_OPTIONS': '--color=auto', 'NCCL_VERSION': '2.8.3', 'PYTHONPATH': '/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop:', 'GOPATH': '/root/gopath', 'WITH_GPU': 'ON', '_': '/usr/local/bin/python3', 'CUSTOM_DEVICE_ROOT': '', 'OMP_NUM_THREADS': '1', 'POD_NAME': 'ipvtqs', 'PADDLE_MASTER': '172.17.0.5:41620', 'PADDLE_GLOBAL_SIZE': '2', 'PADDLE_LOCAL_SIZE': '2', 'PADDLE_GLOBAL_RANK': '1', 'PADDLE_LOCAL_RANK': '1', 'PADDLE_NNODES': '1', 'PADDLE_CURRENT_ENDPOINT': '172.17.0.5:41622', 'PADDLE_TRAINER_ID': '1', 'PADDLE_TRAINERS_NUM': '2', 'PADDLE_RANK_IN_NODE': '1', 'PADDLE_TRAINER_ENDPOINTS': '172.17.0.5:41621,172.17.0.5:41622', 'FLAGS_selected_gpus': '1'}\r\nLAUNCH INFO 2023-07-28 06:33:48,633 ------------------------- ERROR LOG DETAIL -------------------------\r\n (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 693, in _get_data\r\n    data = self._data_queue.get(timeout=self._timeout)\r\n  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 108, in get\r\n2023-07-28 06:33:45.265 | ERROR    | paddlespeech.s2t.exps.u2.model:do_train:217 - (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at ../paddle/fluid/operators/reader/blocking_queue.h:175)\r\n\r\n    raise Empty2023-07-28 06:33:45.276 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Epoch-Train Time Cost: 4:25:36.522684\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 46, in <module>\r\n_queue.Empty2023-07-28 06:33:45.276 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Training Done: 4:25:43.693273\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    pr.runcall(main, config, args)\r\n  File \"/usr/lib/python3.8/cProfile.py\", line 124, in runcall\r\n    self.run()\r\n  File \"/usr/lib/python3.8/threading.py\", line 870, in run\r\n        return func(*args, **kw)self._target(*self._args, **self._kwargs)\r\n\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 32, in main\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 604, in _thread_loop\r\n    main_sp(config, args)\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/bin/train.py\", line 28, in main_sp\r\n    batch = self._get_data()\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 708, in _get_data\r\n    exp.run()\r\n      File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/training/trainer.py\", line 351, in run\r\nraise RuntimeError(\r\nRuntimeError: DataLoader 1 workers exit unexpectedly, pids: 151\r\n    self.do_train()\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/model.py\", line 218, in do_train\r\n    raise e\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/s2t/exps/u2/model.py\", line 184, in do_train\r\n    for batch_index, batch in enumerate(self.train_loader):\r\n  File \"/home/PaddleSpeech/4756b3140789/PaddleSpeech-develop/paddlespeech/audio/streamdata/pipeline.py\", line 67, in iterator\r\n    for sample in self.iterator1():\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 826, in __next__\r\n    self._reader.read_next_list()[0]\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at ../paddle/fluid/operators/reader/blocking_queue.h:175)\r\n\r\nLAUNCH INFO 2023-07-28 06:33:49,234 Exit code -15\r\n```\r\n\r\n### 其他\r\n是我的数据集问题？还是环境硬件问题？还请帮忙，多谢",
        "state": "open",
        "user": "Chuyaoyuan",
        "closed_by": null,
        "created_at": "2023-07-31T01:03:08+00:00",
        "updated_at": "2023-08-22T03:15:43+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "Chuyaoyuan",
            "Tian14267",
            "ainndejj11",
            "Chuyaoyuan",
            "Chuyaoyuan",
            "ainndejj11"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3436,
        "title": "[ASR语音识别] 微调问题,样本如何构造,文本样本如何切词,如 BAC009S0002W0125 各地 政府 便 纷纷 跟进",
        "body": "## Others\r\n\r\n<!--\r\n请问语音识别微调,使用自己的样本,我看文本都是切词的,比如:BAC009S0002W0125 各地 政府 便 纷纷 跟进\r\n那文本应该怎样切词呢?jieba可行吗?有啥demo吗?\r\n-->\r\n",
        "state": "closed",
        "user": "tiandao011",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-31T01:31:28+00:00",
        "updated_at": "2025-05-06T05:24:09+00:00",
        "closed_at": "2025-05-06T05:24:09+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3437,
        "title": "[TTS]当训练example/csmsc/vits时报错，目前issues中好像还没看到有这个报错",
        "body": "[2023-07-31 09:23:40] [INFO] [trainer.py:167]  iter: 456/350000, Rank: 0, real_loss: 1.465525, fake_loss: 0.950992, discriminator_loss: 2.416517, generator_loss: 48.644768, generator_mel_loss: 37.432968, generator_kl_loss: 2.080599, generator_dur_loss: 2.605819, generator_adv_loss: 2.705353, generator_feat_match_loss: 3.820032, avg_reader_cost: 0.00022 sec, avg_batch_cost: 1.10522 sec, avg_samples: 8, avg_ips: 7.23835 sequences/sec\r\n[2023-07-31 09:23:40] [INFO] [trainer.py:167]  iter: 460/350000, Rank: 1, real_loss: 1.823982, fake_loss: 0.803789, discriminator_loss: 2.627771, generator_loss: 55.005493, generator_mel_loss: 41.993717, generator_kl_loss: 2.693164, generator_dur_loss: 2.472222, generator_adv_loss: 3.187515, generator_feat_match_loss: 4.658873, avg_reader_cost: 0.00018 sec, avg_batch_cost: 1.03553 sec, avg_samples: 8, avg_ips: 7.72554 sequences/sec\r\nException in main training loop: (InvalidArgument) \r\n\r\nWhen step > 0, end should be greater than start, but received end = 31, start = 33.\r\n\r\n  [Hint: Expected end >= start, but received end:31 < start:33.] (at /paddle/paddle/phi/kernels/funcs/slice_utils.h:74)\r\n  [operator < slice > error]\r\nTraceback (most recent call last):\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/models/vits/vits_updater.py\", line 109, in update_core\r\n    outs = self.model(\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/models/vits/vits.py\", line 262, in forward\r\n    return self._forward_discrminator(\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/models/vits/vits.py\", line 358, in _forward_discrminator\r\n    outs = self.generator(\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/models/vits/generator.py\", line 416, in forward\r\n    z_segments, z_start_idxs = get_random_segments(\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 314, in get_random_segments\r\n    segments = get_segments(x, start_idxs, segment_size)\r\n  File \"/home/user/xiewenbiao/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 337, in get_segments\r\n    segments[i] = x[i, :, start_idx:start_idx + segment_size]\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 736, in __getitem__\r\n    return _getitem_impl_(self, item)\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/variable_index.py\", line 486, in _getitem_impl_\r\n    target_block.append_op(\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3599, in append_op\r\n    _dygraph_tracer().trace_op(type,\r\n  File \"/home/user/anaconda3/envs/PadSpe/lib/python3.8/site-packages/paddle/fluid/dygraph/tracer.py\", line 307, in trace_op\r\n    self.trace(type, inputs, outputs, attrs,\r\n[2023-07-31 09:23:41] [INFO] [trainer.py:167]  iter: 457/350000, Rank: 0, real_loss: 1.316723, fake_loss: 1.039383, discriminator_loss: 2.356106, generator_loss: 50.838497, generator_mel_loss: 40.326233, generator_kl_loss: 1.498949, generator_dur_loss: 2.676625, generator_adv_loss: 2.627703, generator_feat_match_loss: 3.708988, avg_reader_cost: 0.00022 sec, avg_batch_cost: 1.10919 sec, avg_samples: 8, avg_ips: 7.21250 sequences/sec\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.[2023-07-31 09:23:42] [INFO] [trainer.py:167]  iter: 458/350000, Rank: 0, real_loss: 1.545704, fake_loss: 0.938184, discriminator_loss: 2.483888, generator_loss: 50.400703, generator_mel_loss: 39.265820, generator_kl_loss: 2.878182, generator_dur_loss: 2.736290, generator_adv_loss: 2.225367, generator_feat_match_loss: 3.295045, avg_reader_cost: 0.00027 sec, avg_batch_cost: 1.11008 sec, avg_samples: 8, avg_ips: 7.20667 sequences/sec\r\n[2023-07-31 09:23:43] [INFO] [trainer.py:167]  iter: 459/350000, Rank: 0, real_loss: 1.157993, fake_loss: 1.243261, discriminator_loss: 2.401254, generator_loss: 48.529289, generator_mel_loss: 38.890598, generator_kl_loss: 1.199729, generator_dur_loss: 2.618741, generator_adv_loss: 2.403082, generator_feat_match_loss: 3.417137, avg_reader_cost: 0.00023 sec, avg_batch_cost: 1.11112 sec, avg_samples: 8, avg_ips: 7.19996 sequences/sec\r\n\r\n\r\n报错为：When step > 0, end should be greater than start, but received end = 31, start = 33.  报错结束后依然打印了3次迭代，后面就不动了\r\n",
        "state": "open",
        "user": "Vebrun",
        "closed_by": null,
        "created_at": "2023-07-31T01:37:41+00:00",
        "updated_at": "2023-08-02T11:51:45+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "Vebrun",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3440,
        "title": "CLS使用自定义数据集和标签在CNN6的基础上进行再训练，使用训练好的模型对指定音频进行分类预测，如何输出自己定义好的标签类型",
        "body": "相关训练参数为：\r\nsample_rate = 32000\r\nfeat_conf = {\r\n    'sr': sample_rate,\r\n    'n_fft': 1024,\r\n    'hop_length': 320,\r\n    'window': 'hann',\r\n    'win_length': 1024,\r\n    'f_min': 50.0,\r\n    'f_max': 14000.0,\r\n    'n_mels': 64,\r\n}    \r\n\r\nlabel_list = [\r\n        'discuss_in_room',\r\n        'girl_speak',\r\n        'woman_speak'\r\n    ]\r\n\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_400_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_87_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_63_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_295_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_184_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_330_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_322_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_717_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_662_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_122_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_290_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_466_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/paddle_train/audio_cut/segment_1_paragraph_229_cut.wav discuss_in_room\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_563_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_375_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/girl_speak/segment_1_paragraph_308_cut.wav girl_speak\r\nC:/Users/Athurrrr/Desktop/train_data1/woman_speak/segment_1_paragraph_688_cut.wav woman_speak\r\nC:/Users/Athurrrr/Desktop/paddle_train/audio_cut/segment_1_paragraph_238_cut.wav discuss_in_room\r\nC:/Users/Athurrrr/Desktop/paddle_train/audio_cut/segment_1_paragraph_275_cut.wav discuss_in_room\r\nC:/Users/Athurrrr/Desktop/paddle_train/audio_cut/segment_1_paragraph_264_cut.wav discuss_in_room\r\n\r\n一共训练了十轮，部分输出结果为：\r\nEpoch=9/10, Step=7/10 loss=0.0114 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=8/10 loss=0.0357 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=9/10 loss=0.0262 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=10/10 loss=0.1711 acc=0.9000 lr=0.001000\r\nEpoch=10/10, Step=1/10 loss=0.0151 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=2/10 loss=0.0843 acc=0.9375 lr=0.001000\r\nEpoch=10/10, Step=3/10 loss=0.0626 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=4/10 loss=0.0170 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=5/10 loss=0.0118 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=6/10 loss=0.1323 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=7/10 loss=0.0190 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=8/10 loss=0.1876 acc=0.9375 lr=0.001000\r\nEpoch=10/10, Step=9/10 loss=0.0608 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=10/10 loss=0.0088 acc=1.0000 lr=0.001000\r\n\r\n``\r\n``\r\n``\r\n``\r\n在执行语音分类时使用下列代码加载训练好的权重模型：\r\n\r\nmodel_type = 'paddlespeech.cls.models:cnn6'  # 指定要加载的模型类型\r\nckpt_path = 'C:/Users/Athurrrr/Desktop/train_data1/class_speech1.pdparams'  # 指定训练好的模型的权重文件路径\r\nnum_classes = 10  # 数据集的类别数量\r\n\r\n# 创建 CLSExecutor 实例并加载模型\r\nexecutor = CLSExecutor()\r\naudio_file = 'C:/Users/Athurrrr/Desktop/train_data1/disscuss_in_room/segment_1_paragraph_236_cut.wav'  # 指定音频文件路径\r\nres = executor.__call__(audio_file=audio_file,model='panns_cnn6',ckpt_path=ckpt_path,topk=5)\r\n\r\n最后输出的",
        "state": "closed",
        "user": "Arthurrrrking",
        "closed_by": "Arthurrrrking",
        "created_at": "2023-07-31T07:56:40+00:00",
        "updated_at": "2023-07-31T07:57:15+00:00",
        "closed_at": "2023-07-31T07:57:15+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3441,
        "title": "CLS使用自定义数据集和标签在CNN6的基础上进行再训练，使用训练好的模型对指定音频进行分类预测，如何输出自己定义好的标签类型 ",
        "body": "### 相关训练参数为：\r\nsample_rate = 32000\r\nfeat_conf = {\r\n'sr': sample_rate,\r\n'n_fft': 1024,\r\n'hop_length': 320,\r\n'window': 'hann',\r\n'win_length': 1024,\r\n'f_min': 50.0,\r\n'f_max': 14000.0,\r\n'n_mels': 64,\r\n}\r\n\r\n### 标签信息\r\nlabel_list = [\r\n'discuss_in_room',\r\n'girl_speak',\r\n'woman_speak'\r\n]\r\n\r\n### 部分训练数据集信息\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_400_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_87_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_63_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_295_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_184_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_330_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_322_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_717_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_662_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_122_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_290_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_466_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/paddle_train/audio_cut/segment_1_paragraph_229_cut.wav discuss_in_room\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_563_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_375_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/girl_speak/segment_1_paragraph_308_cut.wav girl_speak\r\nC:/Users/ttr/Desktop/train_data1/woman_speak/segment_1_paragraph_688_cut.wav woman_speak\r\nC:/Users/ttr/Desktop/paddle_train/audio_cut/segment_1_paragraph_238_cut.wav discuss_in_room\r\nC:/Users/ttr/Desktop/paddle_train/audio_cut/segment_1_paragraph_275_cut.wav discuss_in_room\r\nC:/Users/ttr/Desktop/paddle_train/audio_cut/segment_1_paragraph_264_cut.wav discuss_in_room\r\n\r\n### 一共训练了十轮，部分输出结果为：\r\nEpoch=9/10, Step=7/10 loss=0.0114 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=8/10 loss=0.0357 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=9/10 loss=0.0262 acc=1.0000 lr=0.001000\r\nEpoch=9/10, Step=10/10 loss=0.1711 acc=0.9000 lr=0.001000\r\nEpoch=10/10, Step=1/10 loss=0.0151 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=2/10 loss=0.0843 acc=0.9375 lr=0.001000\r\nEpoch=10/10, Step=3/10 loss=0.0626 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=4/10 loss=0.0170 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=5/10 loss=0.0118 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=6/10 loss=0.1323 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=7/10 loss=0.0190 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=8/10 loss=0.1876 acc=0.9375 lr=0.001000\r\nEpoch=10/10, Step=9/10 loss=0.0608 acc=1.0000 lr=0.001000\r\nEpoch=10/10, Step=10/10 loss=0.0088 acc=1.0000 lr=0.001000\r\n\r\n### 最终得到的权重模型文件为：\r\n testpd.pdparams\r\n\r\n### 在执行语音分类时使用下列代码加载训练好的权重模型，并对指定音频文件进行分类预测：\r\n\r\nmodel_type = 'paddlespeech.cls.models:cnn6' # 指定要加载的模型类型\r\nckpt_path = 'C:/Users/ttr/Desktop/train_data1/testpd.pdparams' # 指定训练好的模型的权重文件路径\r\nnum_classes = 10 # 数据集的类别数量\r\n\r\nexecutor = CLSExecutor()\r\naudio_file = 'C:/Users/ttr/Desktop/train_data1/disscuss_in_room/segment_1_paragraph_236_cut.wav' # 指定音频文件路径\r\nres = executor.call(audio_file=audio_file,model='panns_cnn6',ckpt_path=ckpt_path,topk=5)\r\n\r\n### 最后输出的结果为：\r\nSpeech 0.6448656320571899 Chatter 0.466450572013855 Crowd 0.24360215663909912 Music 0.17972928285598755 Inside, public space 0.1773214191198349 \r\n\r\n### 没有我训练时指定的标签信息。\r\nlabel_list = [\r\n'discuss_in_room',\r\n'girl_speak',\r\n'woman_speak'\r\n]\r\n\r\n### 现在的问题是：想要在使用训练好的模型对指定音频文件进行分类预测时，提高模型训练时自定义的标签权重，并在最后的识别结果时输出自定义的分类标签，及其匹配度，应该如何操作呢？",
        "state": "closed",
        "user": "Arthurrrrking",
        "closed_by": "Arthurrrrking",
        "created_at": "2023-07-31T08:18:17+00:00",
        "updated_at": "2023-08-01T07:07:20+00:00",
        "closed_at": "2023-08-01T07:07:20+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3438,
        "title": "使用wisper进行asr的时候，输出全是繁体字，有什么参数可以设置输出简体吗？",
        "body": "如题",
        "state": "closed",
        "user": "chenfuckthesky",
        "closed_by": "stale[bot]",
        "created_at": "2023-07-31T03:46:35+00:00",
        "updated_at": "2025-06-27T06:33:38+00:00",
        "closed_at": "2025-06-27T06:33:38+00:00",
        "comments_count": [
            "yeyupiaoling",
            "chenfuckthesky",
            "yeyupiaoling",
            "zxcd",
            "stale[bot]",
            "zhangqiqi1228",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3439,
        "title": "[TTS]执行训练run.sh命令后报错AssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]",
        "body": "**Describe the bug**\r\n想要进行微调训练\r\n进入\"/examples/other/tts_finetune/tts3\"目录，执行 \"./run.sh\" ，执行后报错\r\n\r\n`check oov\r\nget mfa result\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 198.0\r\n/data/tts/paddle/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nCreating dictionary information...\r\nSetting up training data...\r\nCalculating MFCCs...\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 198.0\r\nDone with setup.\r\n100%|#####################################################################################################################| 2/2 [00:09<00:00,  4.61s/it]\r\nDone! Everything took 36.63117694854736 seconds\r\ngenerate durations.txt\r\nextract feature\r\n196 1\r\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 196/196 [00:13<00:00, 14.22it/s]\r\nDone\r\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 196/196 [00:00<00:00, 791.87it/s]\r\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.73it/s]\r\nDone\r\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 554.88it/s]\r\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s]\r\nDone\r\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 504.79it/s]\r\ncreate finetune env\r\nfinetune...\r\nrank: 0, pid: 2214138, parent_pid: 2211780\r\nmultiple speaker fastspeech2!\r\nspk_num: 174\r\nsamplers done!\r\ndataloaders done!\r\nvocab_size: 306\r\nW0731 14:28:58.117866 2214138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 12.0\r\nW0731 14:28:58.118633 2214138 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nI0731 14:28:58.215528 2214138 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nI0731 14:28:58.215838 2214138 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nmodel done!\r\noptimizer done!\r\n/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/nn/layer/norm.py:777: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\nException in main training loop: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\nTraceback (most recent call last):\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 335, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1243, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 995, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 800, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/data/tts/paddle/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 335, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1243, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 995, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 800, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nAssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape \r\n\r\n> [1]`\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [Ubuntu]\r\n - Python Version [3.8.2]\r\n - PaddlePaddle Version [2.5.0]\r\n PaddlePaddle-gpu-2.5.0-120\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n NVIDIA-SMI 535.54.03              Driver Version: 535.54.03  \r\n\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\nCUDA Version: 12.2 \r\n\r\n nvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:07:16_PDT_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "linzchan",
        "closed_by": null,
        "created_at": "2023-07-31T06:49:35+00:00",
        "updated_at": "2023-08-04T09:25:41+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "alongzhen"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3442,
        "title": "[S2T] paddlespeech 1.4.1 在Paddle 2.5.1环境中 示例跑不通",
        "body": "换了三台机器，捣鼓了一天时间\r\n\r\n环境：\r\nWindows10 / 11\r\nPython 3.10\r\nPaddle 2.5.1 GPU版 （conda install paddlepaddle-gpu==2.5.1 cudatoolkit=11.7 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/ -c conda-forge）\r\npaddlespeech 1.4.1 （pip install paddlespeech）\r\n\r\n问题：\r\n\r\n1\r\n运行 paddlespeech asr --input zh.wav，先是抛出了一个numpy异常：module 'numpy' has no attribute 'complex'\r\n卸掉1.24，重装1.23解决。\r\n\r\n2\r\n继续paddlespeech asr --input zh.wav，另一个问题：\r\nTraceback (most recent call last):\r\n  File \"D:\\Python\\envs\\Paddle_GPU\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"D:\\Python\\envs\\Paddle_GPU\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"D:\\Python\\envs\\Paddle_GPU\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Python\\envs\\Paddle_GPU\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"D:\\Python\\envs\\Paddle_GPU\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\nKeyError: 'result'\r\n\r\npaddlespeech 1.4.1在paddle 2.4.2.post117下是能跑通示例的。但是还有其他乱七八糟依赖库的不兼容问题。",
        "state": "open",
        "user": "geniuszxd",
        "closed_by": null,
        "created_at": "2023-08-01T14:55:17+00:00",
        "updated_at": "2024-10-22T06:54:33+00:00",
        "closed_at": null,
        "comments_count": [
            "momei123",
            "cooolinx",
            "zxcd",
            "cooolinx",
            "cjjcn",
            "pangdahua",
            "450586509",
            "yi1z",
            "ys830",
            "lihuikenny"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3443,
        "title": "如何获取语音分类预训练模型的标签列表，比如CNN14，CNN10，CNN6",
        "body": "如何获取语音分类预训练模型的标签列表，比如CNN14，CNN10，CNN6",
        "state": "closed",
        "user": "Arthurrrrking",
        "closed_by": "Arthurrrrking",
        "created_at": "2023-08-02T06:28:54+00:00",
        "updated_at": "2023-08-03T03:26:08+00:00",
        "closed_at": "2023-08-03T03:26:08+00:00",
        "comments_count": [
            "zxcd",
            "Arthurrrrking"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3444,
        "title": "ModuleNotFoundError: No module named 'paddlespeech.s2t.transform'",
        "body": "paddlepaddle==2.5.0rc0\r\npaddleslim==2.4.1\r\npaddlespeech==1.4.1\r\n\r\n报错如下：\r\npwd\r\nPaddleSpeech/examples/wenetspeech/asr1\r\n(venvPaddle) [root@localhost asr1]# ./local/data.sh --stage 2 --stop_stage 2\r\nCompute cmvn\r\nTraceback (most recent call last):\r\n  File \"utils/compute_cmvn_stats.py\", line 8, in <module>\r\n    from paddlespeech.s2t.transform.transformation import Transformation\r\nModuleNotFoundError: No module named 'paddlespeech.s2t.transform'\r\n\r\n\r\npaddlespeech.s2t.transform.transformation 这个要挪到哪里去了？要咋改改？\r\n\r\n\r\n",
        "state": "closed",
        "user": "xiaoligang2000",
        "closed_by": "zxcd",
        "created_at": "2023-08-03T02:12:08+00:00",
        "updated_at": "2024-06-04T02:34:40+00:00",
        "closed_at": "2024-06-04T02:34:40+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3445,
        "title": "asr语音识别任务，样本构造：wav文件一个人录和多个人录是否对训练结果影响较大",
        "body": "想训练一些专业名词，一个人读多段数据和多个人分工合作，理论上应该是多个人较好吧？效果大约能差多少呢？",
        "state": "closed",
        "user": "tiandao011",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-03T08:35:28+00:00",
        "updated_at": "2025-04-27T18:51:42+00:00",
        "closed_at": "2025-04-27T18:51:42+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3447,
        "title": "目前paddlespeech支持粤语语音识别吗？",
        "body": "目前paddlespeech支持粤语语音识别吗？",
        "state": "closed",
        "user": "AI-Mart",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-03T12:42:09+00:00",
        "updated_at": "2025-04-27T18:51:47+00:00",
        "closed_at": "2025-04-27T18:51:47+00:00",
        "comments_count": [
            "zxcd",
            "AI-Mart",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3450,
        "title": "你好，请问phoneme的中间加sil或者sp增加提顿时长疑问",
        "body": "你好，能请问下具体的操作是怎样吗？是需要重新训练，还是直接改代码即可实现呢？我浏览了好多issue都没找到答案",
        "state": "closed",
        "user": "laishujie",
        "closed_by": "laishujie",
        "created_at": "2023-08-04T09:26:42+00:00",
        "updated_at": "2023-08-29T07:42:56+00:00",
        "closed_at": "2023-08-29T07:42:56+00:00",
        "comments_count": [
            "zxcd",
            "laishujie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3448,
        "title": "前端服务 [vite] http proxy error:",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n> yarn dev --port 8011 启动前端\r\n\r\n能正常看到界面，但是控制台报错连接断开，无限重定向回主页\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/40909658/a6920534-4bdb-45f6-a6fa-12eb6019d38c)\r\n\r\n > yarn 后台日志\r\n\r\n3:50:24 PM [vite] http proxy error:\r\nError: aborted\r\n    at connResetException (node:internal/errors:631:14)\r\n    at abortIncoming (node:_http_server:583:25)\r\n    at socketOnEnd (node:_http_server:600:5)\r\n    at Socket.emit (node:events:388:22)\r\n    at endReadableNT (node:internal/streams/readable:1294:12)\r\n    at processTicksAndRejections (node:internal/process/task_queues:80:21) (x24)\r\n\r\n> vc.py 或 mai.py 或 paddlespeech_server start --config_file conf/application.yaml 日志都有问题。\r\n\r\nINFO:     127.0.0.1:56584 - \"GET /vpr/list HTTP/1.1\" 404 Not Found\r\nINFO:     127.0.0.1:56590 - \"GET /vc/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56604 - \"POST /finetune/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56610 - \"GET /sat/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56262 - \"GET /vpr/list HTTP/1.1\" 404 Not Found\r\nINFO:     127.0.0.1:56274 - \"GET /vc/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56284 - \"POST /finetune/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56290 - \"GET /sat/list HTTP/1.1\" 200 OK\r\nINFO:     127.0.0.1:56300 - \"GET /vpr/list HTTP/1.1\" 404 Not Found\r\n\r\n\r\n> 我的后端开启的姿势不对？有ws服务没启动的原因？\r\n\r\n> 都安装在docker中，不知为何映射了端口但没法访问，只好加了个 nginx 用15000反代了前端 其他机器才能正常访问。\r\n\r\n\r\n非常抱歉，没有找到相关资料，不确定该如何配置。",
        "state": "open",
        "user": "Uzibird",
        "closed_by": null,
        "created_at": "2023-08-03T16:05:28+00:00",
        "updated_at": "2025-06-27T02:32:33+00:00",
        "closed_at": null,
        "comments_count": [
            "wmlgl",
            "xiangtuocloud",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3446,
        "title": "专家您好，Paddle有没有类似ECNR或者RNC降噪算法代码?若声音源带有噪音和回声，paddle如何处理噪音和回声？",
        "body": "## General Question\r\n专家您好，Paddle有没有类似ECNR或者RNC降噪算法代码?若声音源带有噪音和回声，paddle如何处理噪音和回声？\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "lixiangMindSpore",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-03T09:27:26+00:00",
        "updated_at": "2025-04-27T18:52:05+00:00",
        "closed_at": "2025-04-27T18:52:04+00:00",
        "comments_count": [
            "zxcd",
            "lixiangMindSpore",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3451,
        "title": "[S2T]streaming asr server in docker tag develop-cpu-52c7c1 doesn't work",
        "body": "**Describe the bug**\r\nStart streaming asr service by default conf file failed in docker tag develop-cpu-52c7c1.\r\nError message: declarative() got an unexpected keyword argument 'property'\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. pull docker image of tag develop-cpu-52c7c1\r\n2. run the docker and enter the streaming_asr_server folder and either execute run.sh or server.sh\r\n\r\n**Expected behavior**\r\nThe server can start normally\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\nnot applicable\r\nthe docker run on windows11\r\n\r\n**Additional context**\r\n\r\n",
        "state": "open",
        "user": "xingda",
        "closed_by": null,
        "created_at": "2023-08-04T11:07:45+00:00",
        "updated_at": "2023-08-04T11:36:30+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3452,
        "title": "[S2T]Mac 系统运行 S2T 报错",
        "body": "Traceback (most recent call last):\r\n  File \"/Users/x/Library/Python/3.8/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\r\n    import librosa\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/librosa/__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/librosa/core/__init__.py\", line 9, in <module>\r\n    from .constantq import *  # pylint: disable=wildcard-import\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/librosa/core/constantq.py\", line 1059, in <module>\r\n    dtype=np.complex,\r\n  File \"/Users/x/Library/Python/3.8/lib/python/site-packages/numpy/__init__.py\", line 305, in __getattr__\r\n    raise AttributeError(__former_attrs__[attr])\r\nAttributeError: module 'numpy' has no attribute 'complex'.\r\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
        "state": "open",
        "user": "0xBayMax",
        "closed_by": null,
        "created_at": "2023-08-06T00:19:17+00:00",
        "updated_at": "2023-08-15T07:02:03+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3453,
        "title": "[ASR]调用ASRExecutor语音转文字时报错OSError: (External) CUFFT error(5)",
        "body": "\r\n**错误信息**\r\n```\r\n  File \"api_v2.py\", line 331, in speech2textOfflineFile\r\n    asr_res = chatbot.speech2text(out_file_path)\r\n  File \"/server/pp-tts/src/robot.py\", line 48, in speech2text\r\n    res = self.asr_model(audio_file=audio_file)\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 496, in __call__\r\n    self.preprocess(model, audio_file)\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 264, in preprocess\r\n    audio = preprocessing(audio, **preprocess_args)\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/audio/transform/transformation.py\", line 147, in __call__\r\n    xs = [func(x, **_kwargs) for x in xs]\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/audio/transform/transformation.py\", line 147, in <listcomp>\r\n    xs = [func(x, **_kwargs) for x in xs]\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/audio/transform/spectrogram.py\", line 373, in __call__\r\n    mat = kaldi.fbank(\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddlespeech/audio/compliance/kaldi.py\", line 472, in fbank\r\n    spectrum = paddle.fft.rfft(strided_input).abs()\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddle/fft.py\", line 340, in rfft\r\n    return fft_r2c(x, n, axis, norm, forward=True, onesided=True, name=name)\r\n  File \"/usr/local/anaconda3/envs/pp-tts-3.8.16/lib/python3.8/site-packages/paddle/fft.py\", line 1468, in fft_r2c\r\n    out = _C_ops.fft_r2c(x, axes, norm, forward, onesided)\r\nOSError: (External) CUFFT error(5).\r\n  [Hint: Please search for the error code(5) on website (https://docs.nvidia.com/cuda/cufft/index.html#cufftresult) to get Nvidia's official solution and advice about CUFFT Error.] (at /paddle/paddle/phi/kernels/funcs/cufft_util.h:127)\r\n\r\n```\r\n\r\n**相关代码**\r\n```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nself.asr_model = ASRExecutor()\r\nres = self.asr_model(audio_file=audio_file)\r\n```\r\n\r\n\r\n**项目环境:**\r\n - OS: [CentOS Linux release 7.9.2009 (Core)]\r\n - GCC/G++ Version [gcc version 9.3.1 20200408 (Red Hat 9.3.1-2) (GCC)]\r\n - Python Version [ 3.8.16]\r\n - PaddlePaddle Version [paddlepaddle-gpu==2.4.2.post117]\r\n - GPU/DRIVER Informationo [4090]\r\n - CUDA/CUDNN Version [cuda_11.7.r11.7/compiler.31294372_0]\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "imxiongying",
        "closed_by": null,
        "created_at": "2023-08-07T08:54:56+00:00",
        "updated_at": "2023-09-11T11:57:20+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "cgychn",
            "cgychn"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3454,
        "title": "关于推理时，openssl的报错问题",
        "body": "anaconda创建的python=3.8的虚拟环境  默认openssl是3.x的版本。执行推理命令paddlespeech asr --lang zh --input zh.wav\r\n然后会出现以下报错：\r\n\r\nError: Can not import paddle core while this file exists: /home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/fluid/core.py\", line 356, in <module>\r\n    raise e\r\n  File \"/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\r\n\r\n\r\n然后重新创建虚拟环境，指定openssl版本： conda create -n test python=3.8 openssl=1.1.1  后，查询openssl version   显示确实是1.1.1v 版本了   但是执行命令  还是报这个错 。请问这个openssl的该如何解决呀",
        "state": "closed",
        "user": "ainndejj11",
        "closed_by": "ainndejj11",
        "created_at": "2023-08-07T08:56:22+00:00",
        "updated_at": "2023-12-26T01:08:50+00:00",
        "closed_at": "2023-08-07T11:01:40+00:00",
        "comments_count": [
            "lgscfronz",
            "ainndejj11",
            "linuxdevopscn",
            "meoqi"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3459,
        "title": "训练ASR模型，自己的数据集都需要准备什么呢",
        "body": "我想训练一个ASR的语音转文字模型，deepspeech2     \r\n在examples/aishell/asr0  下   bash run.sh --stage 0 --stop_stage 0 \r\n这个是下载aishell-1  数据集\r\n\r\n但是随便准备一个数据集，目前有.wav  和  .txt   txt内容如下：\r\na1 我 想要 寻找 一个 古老 的 树\r\na2 传说 中 的 故事\r\n\r\n想训练模型还需要什么嘛。现在不知道数据集该如何处理了，只需要wav和分词后的txt么\r\n（下载的data_sishell的数据集还有个resource_aishell/lexicon.txt   这个是否需要）\r\n\r\n该如何处理获取自己数据集的mean_std  和 词汇表，bash run.sh 都是默认下载那个data_aishell",
        "state": "closed",
        "user": "ainndejj11",
        "closed_by": "ainndejj11",
        "created_at": "2023-08-08T10:44:22+00:00",
        "updated_at": "2023-08-12T02:44:36+00:00",
        "closed_at": "2023-08-12T02:44:36+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3455,
        "title": "测试deepspeech2 代码报错 example/aishell/asr0下 train报错",
        "body": "## 报错信息\r\n\r\n2023-08-07 17:14:18.057 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Epoch-Train Time Cost: 0:00:05.856052\r\n2023-08-07 17:14:18.058 | INFO     | paddlespeech.s2t.training.timer:__exit__:44 - Training Done: 0:00:08.406099\r\nTraceback (most recent call last):\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/train.py\", line 49, in <module>\r\n    main(config, args)\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/train.py\", line 29, in main\r\n    main_sp(config, args)\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/train.py\", line 25, in main_sp\r\n    exp.run()\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 351, in run\r\n    self.do_train()\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 316, in do_train\r\n    raise e\r\n  File \"/root/hwt/demo-ml/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 286, in do_train\r\n    for batch_index, batch in enumerate(self.train_loader):\r\n  File \"/root/hwt/py3env/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 745, in __next__\r\n    self._reader.read_next_list()[0])\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:175)\r\n\r\n\r\n## 环境\r\nPython 3.8.6 (default, Jun 12 2023, 10:59:46) \r\n\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.0.8\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.5.2\r\npaddlepaddle-gpu            2.4.2\r\npaddleslim                  2.4.1\r\npaddlespeech                1.4.0\r\npaddlespeech-ctcdecoders    0.2.1\r\npaddlespeech-feat           0.1.0\r\n\r\n## 额外\r\ntrain之前报错过deepspeech2.yaml 的Dataloader少了属性参数，我就把online 的复制过来了。可能是这个问题。能不能提供一份完整的yaml模型配置。此外，文档中提供的模型ASR结果明显错误，可能是和模型yaml decode.yaml不适配的原因\r\n\r\n## deepspeech2.yaml \r\n# https://yaml.org/type/float.html\r\n###########################################\r\n#                   Data                  #\r\n###########################################\r\ntrain_manifest: data/manifest.train\r\ndev_manifest: data/manifest.dev\r\ntest_manifest: data/manifest.test\r\nmin_input_len: 0.0\r\nmax_input_len: 27.0 # second\r\nmin_output_len: 0.0\r\nmax_output_len: .inf\r\nmin_output_input_ratio: 0.00\r\nmax_output_input_ratio: .inf\r\n\r\n###########################################\r\n#              Dataloader                 #\r\n###########################################\r\nbatch_size: 64 # one gpu\r\nmaxlen_in: 512  # if input length  > maxlen-in, batchsize is automatically reduced\r\nmaxlen_out: 150  # if output length > maxlen-out, batchsize is automatically reduced\r\nminibatches: 0 # for debug\r\nmean_std_filepath: data/mean_std.json\r\nunit_type: char\r\nbatch_count: auto\r\nbatch_bins: 0 \r\nbatch_frames_in: 0\r\nbatch_frames_out: 0\r\nbatch_frames_inout: 0\r\nvocab_filepath: data/lang_char/vocab.txt \r\naugmentation_config: conf/augmentation.json\r\npreprocess_config: conf/preprocess.yaml\r\nrandom_seed: 0\r\nspm_model_prefix: \r\nspectrum_type: linear\r\nfeat_dim: 161\r\ndelta_delta: False\r\nstride_ms: 10.0\r\nwindow_ms: 20.0\r\nn_fft: None\r\nmax_freq: None\r\ntarget_sample_rate: 16000\r\nuse_dB_normalization: True\r\ntarget_dB: -20\r\ndither: 1.0\r\nkeep_transcription_text: False\r\nsortagrad: True\r\nshuffle_method: batch_shuffle\r\nnum_workers: 2\r\nsubsampling_factor: 1\r\nnum_encs: 1\r\n\r\n############################################\r\n#           Network Architecture           #\r\n############################################\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 3\r\nrnn_layer_size: 1024\r\nuse_gru: True \r\nshare_rnn_weights: False\r\nblank_id: 0\r\nctc_grad_norm_type: instance \r\nrnn_direction: forward # [forward, bidirect]\r\nnum_fc_layers: 0\r\nfc_layers_size_list: -1,\r\n\r\n###########################################\r\n#                Training                 #\r\n###########################################\r\nn_epoch: 80\r\naccum_grad: 1\r\nlr: 2.0e-3\r\nlr_decay: 0.83\r\nweight_decay: 1.0e-6\r\nglobal_grad_clip: 3.0\r\nlog_interval: 100\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\n",
        "state": "closed",
        "user": "huangwentao123",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-07T09:23:51+00:00",
        "updated_at": "2025-04-27T18:51:55+00:00",
        "closed_at": "2025-04-27T18:51:55+00:00",
        "comments_count": [
            "huangwentao123",
            "huangwentao123",
            "huangwentao123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3456,
        "title": "paddlespeech_server 一键部署  流式ASR报错",
        "body": "使用 paddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input input_16k.wav   可正常启用客户端推理\r\n\r\n但是使用流式的ASR    paddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input input_16k.wav   就会报错（服务端可正常开启）\r\n\r\n错误信息如下：\r\n[2023-08-07 18:59:48,898] [    INFO] - asr websocket client start\r\n[2023-08-07 18:59:48,898] [    INFO] - endpoint: None\r\n[2023-08-07 18:59:48,898] [    INFO] - endpoint: ws://127.0.0.1:8090/paddlespeech/asr/streaming\r\n[2023-08-07 18:59:48,908] [    INFO] - client receive msg={\"status\":\"ok\",\"signal\":\"server_ready\"}\r\n[2023-08-07 18:59:48,908] [   ERROR] - Failed to speech recognition.\r\n[2023-08-07 18:59:48,908] [   ERROR] -\r\n\r\n请问这是什么原因呢",
        "state": "closed",
        "user": "ainndejj11",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-07T11:01:30+00:00",
        "updated_at": "2025-04-27T18:52:21+00:00",
        "closed_at": "2025-04-27T18:52:21+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3457,
        "title": "deepspeech2 执行训练报错   AttributeError: module 'distutils' has no attribute 'util'",
        "body": "conda虚拟环境python=3.8\r\n\r\n在examples/aishell/asr0下   首先第一步处理数据完成\r\n然后执行第二步骤训练时，命令：bash run.sh --gpus 0 --stage 1 --stop_stage 1\r\n\r\n报错信息如下：\r\ncheckpoint name deepspeech2\r\nusing 1 gpus...\r\nLAUNCH INFO 2023-08-08 14:07:53,618 -----------  Configuration  ----------------------\r\nLAUNCH INFO 2023-08-08 14:07:53,618 auto_parallel_config: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 devices: 0\r\nLAUNCH INFO 2023-08-08 14:07:53,618 elastic_level: -1\r\nLAUNCH INFO 2023-08-08 14:07:53,618 elastic_timeout: 30\r\nLAUNCH INFO 2023-08-08 14:07:53,618 gloo_port: 6767\r\nLAUNCH INFO 2023-08-08 14:07:53,618 host: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 ips: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 job_id: default\r\nLAUNCH INFO 2023-08-08 14:07:53,618 legacy: False\r\nLAUNCH INFO 2023-08-08 14:07:53,618 log_dir: log\r\nLAUNCH INFO 2023-08-08 14:07:53,618 log_level: INFO\r\nLAUNCH INFO 2023-08-08 14:07:53,618 log_overwrite: False\r\nLAUNCH INFO 2023-08-08 14:07:53,618 master: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 max_restart: 3\r\nLAUNCH INFO 2023-08-08 14:07:53,618 nnodes: 1\r\nLAUNCH INFO 2023-08-08 14:07:53,618 nproc_per_node: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 rank: -1\r\nLAUNCH INFO 2023-08-08 14:07:53,618 run_mode: collective\r\nLAUNCH INFO 2023-08-08 14:07:53,618 server_num: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 servers: \r\nLAUNCH INFO 2023-08-08 14:07:53,618 start_port: 6070\r\nLAUNCH INFO 2023-08-08 14:07:53,618 trainer_num: None\r\nLAUNCH INFO 2023-08-08 14:07:53,618 trainers: \r\nLAUNCH INFO 2023-08-08 14:07:53,618 training_script: /media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/train.py\r\nLAUNCH INFO 2023-08-08 14:07:53,618 training_script_args: ['--ngpu', '1', '--config', 'conf/deepspeech2.yaml', '--output', 'exp/deepspeech2', '--seed', '10086']\r\nLAUNCH INFO 2023-08-08 14:07:53,619 with_gloo: 1\r\nLAUNCH INFO 2023-08-08 14:07:53,619 --------------------------------------------------\r\nLAUNCH INFO 2023-08-08 14:07:53,619 Job: default, mode collective, replicas 1[1:1], elastic False\r\nLAUNCH INFO 2023-08-08 14:07:53,619 Run Pod: nnxsnj, replicas 1, status ready\r\nLAUNCH INFO 2023-08-08 14:07:53,627 Watching Pod: nnxsnj, replicas 1, status running\r\n/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nTraceback (most recent call last):\r\n  File \"/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/train.py\", line 33, in <module>\r\n    parser = default_argument_parser()\r\n  File \"/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/training/cli.py\", line 76, in default_argument_parser\r\n    type=distutils.util.strtobool,\r\nAttributeError: module 'distutils' has no attribute 'util'\r\nLAUNCH INFO 2023-08-08 14:08:02,637 Pod failed\r\nLAUNCH ERROR 2023-08-08 14:08:02,637 Container failed !!!\r\nContainer rank 0 status failed cmd ['/home/alex/anaconda3/envs/paddle_speech/bin/python3', '-u', '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/train.py', '--ngpu', '1', '--config', 'conf/deepspeech2.yaml', '--output', 'exp/deepspeech2', '--seed', '10086'] code 1 log log/workerlog.0 \r\nenv {'XDG_VTNR': '7', 'LC_PAPER': 'zh_CN.UTF-8', 'LC_ADDRESS': 'zh_CN.UTF-8', 'XDG_SESSION_ID': 'c2', 'XDG_GREETER_DATA_DIR': '/var/lib/lightdm-data/alex', 'LC_MONETARY': 'zh_CN.UTF-8', 'CLUTTER_IM_MODULE': 'xim', 'SESSION': 'ubuntu', 'GPG_AGENT_INFO': '/home/alex/.gnupg/S.gpg-agent:0:1', 'TERM': 'xterm-256color', 'VTE_VERSION': '4205', 'XDG_MENU_PREFIX': 'gnome-', 'SHELL': '/bin/bash', 'CONDA_SHLVL': '2', 'LIBRARY_PATH': ':/usr/local/lib:/usr/local/cuda-10.2/lib64', 'QT_LINUX_ACCESSIBILITY_ALWAYS_ON': '1', 'CONDA_PROMPT_MODIFIER': '(paddle_speech) ', 'WINDOWID': '44040202', 'LC_NUMERIC': 'zh_CN.UTF-8', 'UPSTART_SESSION': 'unix:abstract=/com/ubuntu/upstart-session/1000/15943', 'GNOME_KEYRING_CONTROL': '', 'GTK_MODULES': 'gail:atk-bridge:unity-gtk-module', 'LC_ALL': 'C', 'PYTHONIOENCODING': 'UTF-8', 'USER': 'alex', 'CUDA_HOME': '/usr/local/lib:/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2:', 'JRE_HOME': '/usr/local/jdk1.8.0_11/jre', 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'QT_ACCESSIBILITY': '1', 'LC_TELEPHONE': 'zh_CN.UTF-8', 'LD_LIBRARY_PATH': '/opt/TensorRT-7.2.2.3/lib:/opt/ffmpeg3.4.5/lib:/usr/local/cuda-10.2/lib64:/usr/lib/x86_64-linux-gnu::/opt/TensorRT-7.2.3.4/lib:/usr/local/lib/:/usr/local/lib/', 'BIN_DIR': '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin', 'CONDA_EXE': '/home/alex/anaconda3/bin/conda', 'XDG_SESSION_PATH': '/org/freedesktop/DisplayManager/Session0', 'XDG_SEAT_PATH': '/org/freedesktop/DisplayManager/Seat0', 'MAIN_ROOT': '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop', 'SSH_AUTH_SOCK': '/run/user/1000/keyring/ssh', 'SESSION_MANAGER': 'local/alex-System-Product-Name:@/tmp/.ICE-unix/16181,unix/alex-System-Product-Name:/tmp/.ICE-unix/16181', 'DEFAULTS_PATH': '/usr/share/gconf/ubuntu.default.path', 'FLAGS_allocator_strategy': 'naive_best_fit', '_CE_CONDA': '', 'XDG_CONFIG_DIRS': '/etc/xdg/xdg-ubuntu:/usr/share/upstart/xdg:/etc/xdg', 'CONDA_PREFIX_1': '/home/alex/anaconda3', 'DESKTOP_SESSION': 'ubuntu', 'PATH': '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop:/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/utils:/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop:/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/utils:/home/alex/anaconda3/envs/paddle_speech/bin:/home/alex/anaconda3/condabin:/home/alex/bin:/home/alex/.local/bin:/usr/local/jdk1.8.0_11/bin:/usr/local/cuda-10.2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/lib:/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2:.', 'QT_IM_MODULE': 'fcitx', 'QT_QPA_PLATFORMTHEME': 'appmenu-qt5', 'CONDA_PREFIX': '/home/alex/anaconda3/envs/paddle_speech', 'LC_IDENTIFICATION': 'zh_CN.UTF-8', 'XDG_SESSION_TYPE': 'x11', 'PWD': '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/examples/aishell/asr0', 'JOB': 'dbus', 'XMODIFIERS': '@im=fcitx', 'JAVA_HOME': '/usr/local/jdk1.8.0_11', 'CUDA_VISIBLE_DEVICES': '0', 'GNOME_KEYRING_PID': '', 'LANG': 'zh_CN.UTF-8', 'GDM_LANG': 'zh_CN', 'MANDATORY_PATH': '/usr/share/gconf/ubuntu.mandatory.path', 'LC_MEASUREMENT': 'zh_CN.UTF-8', 'COMPIZ_CONFIG_PROFILE': 'ubuntu', 'IM_CONFIG_PHASE': '1', 'PYTHONDONTWRITEBYTECODE': '1', 'PAPERSIZE': 'a4', 'GDMSESSION': 'ubuntu', '_CE_M': '', 'SESSIONTYPE': 'gnome-session', 'GTK2_MODULES': 'overlay-scrollbar', 'SHLVL': '3', 'HOME': '/home/alex', 'XDG_SEAT': 'seat0', 'LANGUAGE': 'zh_CN:en_US:en', 'FLAGS_cudnn_deterministic': 'True', 'LIBGL_ALWAYS_SOFTWARE': '1', 'GNOME_DESKTOP_SESSION_ID': 'this-is-deprecated', 'PYTHONPATH': '/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop:/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop:', 'CONDA_PYTHON_EXE': '/home/alex/anaconda3/bin/python', 'XDG_SESSION_DESKTOP': 'ubuntu', 'LOGNAME': 'alex', 'DBUS_SESSION_BUS_ADDRESS': 'unix:abstract=/tmp/dbus-xgenrfmput', 'XDG_DATA_DIRS': '/usr/share/ubuntu:/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'CLASSPATH': '.:/usr/local/jdk1.8.0_11/lib:/usr/local/jdk1.8.0_11/jre/lib', 'QT4_IM_MODULE': 'fcitx', 'CONDA_DEFAULT_ENV': 'paddle_speech', 'LESSOPEN': '| /usr/bin/lesspipe %s', 'PKG_CONFIG_PATH': ':/usr/local/lib/pkgconfig', 'INSTANCE': '', 'XDG_RUNTIME_DIR': '/run/user/1000', 'DISPLAY': ':0', 'XDG_CURRENT_DESKTOP': 'Unity', 'GTK_IM_MODULE': 'fcitx', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LC_TIME': 'zh_CN.UTF-8', 'LC_NAME': 'zh_CN.UTF-8', 'XAUTHORITY': '/home/alex/.Xauthority', '_': '/home/alex/anaconda3/envs/paddle_speech/bin/python3', 'CUSTOM_DEVICE_ROOT': '', 'OMP_NUM_THREADS': '1', 'POD_NAME': 'nnxsnj', 'PADDLE_MASTER': '127.0.1.1:43240', 'PADDLE_GLOBAL_SIZE': '1', 'PADDLE_LOCAL_SIZE': '1', 'PADDLE_GLOBAL_RANK': '0', 'PADDLE_LOCAL_RANK': '0', 'PADDLE_NNODES': '1', 'PADDLE_TRAINER_ENDPOINTS': '127.0.1.1:43241', 'PADDLE_CURRENT_ENDPOINT': '127.0.1.1:43241', 'PADDLE_TRAINER_ID': '0', 'PADDLE_TRAINERS_NUM': '1', 'PADDLE_RANK_IN_NODE': '0', 'FLAGS_selected_gpus': '0'}\r\nLAUNCH INFO 2023-08-08 14:08:02,637 ------------------------- ERROR LOG DETAIL -------------------------\r\n/home/alex/anaconda3/envs/paddle_speech/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nTraceback (most recent call last):\r\n  File \"/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/exps/deepspeech2/bin/train.py\", line 33, in <module>\r\n    parser = default_argument_parser()\r\n  File \"/media/alex/e815e6bf-29c6-44df-a535-184ead5b3f96/PaddleSpeech-develop/paddlespeech/s2t/training/cli.py\", line 76, in default_argument_parser\r\n    type=distutils.util.strtobool,\r\nAttributeError: module 'distutils' has no attribute 'util'\r\nLAUNCH INFO 2023-08-08 14:08:02,638 Exit code 1\r\n\r\n请问如何解决",
        "state": "closed",
        "user": "ainndejj11",
        "closed_by": "ainndejj11",
        "created_at": "2023-08-08T06:49:26+00:00",
        "updated_at": "2024-07-26T02:25:58+00:00",
        "closed_at": "2023-08-12T02:50:13+00:00",
        "comments_count": [
            "qingjiaozyn",
            "w5688414"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3458,
        "title": "在飞浆官网BML CodeLab平台 中克隆好的自己的声音模型，如何用于已在本地平台布署的speech_web/speech_server 中 /tts/offline （端到端 文转音api）中",
        "body": "在飞浆官网BML CodeLab平台 中克隆好的自己的声音模型，如何用于已在本地平台布署的speech_web/speech_server 中 /tts/offline （端到端 文转音api）中？\r\nspeech_web/speech_server 中 /tts/offline 接口，目前只支持文本参数，如何指定或替换不同人的声音来合成语音文件？",
        "state": "closed",
        "user": "soup-zhang",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-08T07:23:32+00:00",
        "updated_at": "2025-04-27T18:51:58+00:00",
        "closed_at": "2025-04-27T18:51:58+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3460,
        "title": "部署流式 tts 时遇到的问题",
        "body": "当使用长文本的时候，RTF 都是小于 1 的，但是在 front time 耗时很长，首包响应时间也很长，不知道是为什么la\r\n\r\n以下是服务器配置⬇️\r\n<img width=\"1159\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/61266390/41b9fbba-a9f0-426c-b584-0f5c9f50a53c\">\r\n\r\n\r\n这是服务器反应的\r\n<img width=\"843\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/61266390/377ebe16-f4de-421d-b50f-2c5a911222e4\">\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "drinkerwhz",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-09T02:29:48+00:00",
        "updated_at": "2025-04-27T18:51:14+00:00",
        "closed_at": "2025-04-27T18:51:14+00:00",
        "comments_count": [
            "Coldwon",
            "stale[bot]",
            "Grasscats",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3462
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3461,
        "title": "您好，请问飞桨框架寒武纪 MLU 版什么时候会支持PaddleSpeech内的模型呀？",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "leeshion11",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-09T07:27:29+00:00",
        "updated_at": "2025-06-27T03:38:13+00:00",
        "closed_at": "2025-06-27T03:38:13+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3471
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3467,
        "title": "ASR模型训练多轮次时，为了节省空间，开始新的训练前可以把之前训练的模型删掉吗",
        "body": "ASR模型训练多轮次时，为了节省空间，开始新的训练前可以把之前训练的模型删掉吗？\r\n\r\n比如下面列表中已生成的模型文件想将第1-5个模型删掉，是否可以直接删除？如果删除是否涉及其他配置文件修改？\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/137430307/f93901a4-f857-4a16-97df-bb31ceb822a5)",
        "state": "closed",
        "user": "Arthurrrrking",
        "closed_by": "Arthurrrrking",
        "created_at": "2023-08-11T03:04:09+00:00",
        "updated_at": "2023-08-11T07:43:19+00:00",
        "closed_at": "2023-08-11T07:43:19+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3464,
        "title": "Deepspeech2：Stage3出错！argparse.ArgumentError: argument --result_file: conflicting option string: --result_file",
        "body": "【过程】\r\n0 Process data -> 1 Train the mode -> 2 Get the final model -> 3 Test the final model performance\r\n\r\n【错误描述】\r\n通过命令 bash run.sh --stage 3 --stop_stage 3进行Stage3。\r\n无法正确执行，尝试各种方法无果，请求协助！\r\n\r\n【环境变量】\r\ncuda11.2\r\npaddleaudio 1.0.2\r\npaddlepaddle-gpu 2.5.0\r\npaddlespeech 0.0.0\r\n\r\n【具体报错如下】\r\n(asr38) root@station-Super-Server:/home/chenwh/ai/PaddleSpeech/examples/aishell/asr0# bash run.sh --stage 3 --stop_stage 3\r\ncheckpoint name deepspeech2\r\nusing 1 gpus...\r\nStart downloading the language model. The language model is large, please wait for a moment ...\r\nDownload the language model sucessfully\r\n----------- format_rsl.py Configuration Arguments -----------\r\norigin_hyp: \r\norigin_ref: data/manifest.test.raw\r\ntrans_hyp: \r\ntrans_hyp_sclite: \r\ntrans_ref: data/manifest.test.text\r\ntrans_ref_sclite: \r\ntransform_hyp output: data/manifest.test.text\r\nTraceback (most recent call last):\r\n  File \"/home/chenwh/ai/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test.py\", line 36, in <module>\r\n    parser.add_argument(\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1386, in add_argument\r\n    return self._add_action(action)\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1749, in _add_action\r\n    self._optionals._add_action(action)\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1590, in _add_action\r\n    action = super(_ArgumentGroup, self)._add_action(action)\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1400, in _add_action\r\n    self._check_conflict(action)\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1539, in _check_conflict\r\n    conflict_handler(action, confl_optionals)\r\n  File \"/root/anaconda3/envs/asr38/lib/python3.8/argparse.py\", line 1548, in _handle_conflict_error\r\n    raise ArgumentError(action, message % conflict_string)\r\nargparse.ArgumentError: argument --result_file: conflicting option string: --result_file\r\nFailed in evaluation!\r\n",
        "state": "closed",
        "user": "policemanxxx",
        "closed_by": "policemanxxx",
        "created_at": "2023-08-10T07:41:09+00:00",
        "updated_at": "2023-08-10T13:37:35+00:00",
        "closed_at": "2023-08-10T09:14:43+00:00",
        "comments_count": [
            "policemanxxx",
            "policemanxxx",
            "ainndejj11"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3466,
        "title": "[TTS]tts server config set “lang: 'mix'” ",
        "body": "这个项目非常棒，但是我遇到了一些问题，想请教一下\r\n在例子中我能顺利启动TTS server 的'zh'模型\r\n现在我想启动TTS server的mix模式，替换了对应的频谱模型以及voc模型，确定了这两个模型存在并自动下载了(fastspeech2_mix-mix,hifigan_male-mix)，但是运行报错：\r\n' Failed to warm up on tts engine.'TTSServerExecutor' object has no attribute 'frontend''\r\n我想启动TTS的‘mix’模式，我该如何配置？\r\n\r\n![5b4f2c4a8d06cabfccf4d075ab53c52](https://github.com/PaddlePaddle/PaddleSpeech/assets/32932670/5b40e6a8-1f4a-43f7-b591-1599461ac4f9)\r\n",
        "state": "open",
        "user": "damon-93",
        "closed_by": null,
        "created_at": "2023-08-10T10:15:08+00:00",
        "updated_at": "2023-10-24T10:48:35+00:00",
        "closed_at": null,
        "comments_count": [
            "damon-93",
            "lixikun"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3463,
        "title": "声音分类ESC50：模型部署出错！TypeError: only size-1 arrays can be converted to Python scalars",
        "body": "【过程】\r\n模型训练->模型预测->动转静->模型部署\r\n\r\n【错误描述】\r\n通过命令 ./run.sh 4 gpu ./export /audio/dog.wav 进行第4步骤。\r\n无法正确执行，尝试各种方法无果，请求协助！\r\n\r\n【环境变量】\r\ncuda11.2\r\npaddleaudio 1.0.2\r\npaddlepaddle-gpu 2.5.0\r\npaddlespeech 0.0.0\r\n\r\n【具体报错如下】\r\nI0809 15:22:10.513600 24904 analysis_predictor.cc:1660] ======= optimize end =======\r\nI0809 15:22:10.513777 24904 naive_executor.cc:164] --- skip [feed], feed -> x\r\nI0809 15:22:10.514379 24904 naive_executor.cc:164] --- skip [linear_4.tmp_1], fetch -> fetch\r\nW0809 15:22:10.516772 24904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.4, Runtime API Version: 11.2\r\nW0809 15:22:10.518486 24904 gpu_resources.cc:149] device: 0, cuDNN Version: 8.1.\r\nTraceback (most recent call last):\r\nFile \"/home/workstation/chenwh/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 144, in\r\nresults = predictor.predict(wavs)\r\nFile \"/home/workstation/chenwh/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 120, in predict\r\nfeats = extract_features(wavs)\r\nFile \"/home/workstation/chenwh/PaddleSpeech/paddlespeech/cls/exps/panns/deploy/predict.py\", line 58, in extract_features\r\nfeat = MelSpectrogram(waveforms[i], sr, **kwargs).transpose()\r\nFile \"/root/anaconda3/envs/cwh-test/lib/python3.8/site-packages/paddle/audio/features/layers.py\", line 181, in init\r\nself.fbank_matrix = compute_fbank_matrix(\r\nFile \"/root/anaconda3/envs/cwh-test/lib/python3.8/site-packages/paddle/audio/functional/functional.py\", line 227, in compute_fbank_matrix\r\nfftfreqs = fft_frequencies(sr=sr, n_fft=n_fft, dtype=dtype)\r\nFile \"/root/anaconda3/envs/cwh-test/lib/python3.8/site-packages/paddle/audio/functional/functional.py\", line 183, in fft_frequencies\r\nreturn paddle.linspace(0, float(sr) / 2, int(1 + n_fft // 2), dtype=dtype)\r\nTypeError: only size-1 arrays can be converted to Python scalars\r\n",
        "state": "closed",
        "user": "policemanxxx",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-10T07:26:46+00:00",
        "updated_at": "2025-06-27T04:34:50+00:00",
        "closed_at": "2025-06-27T04:34:50+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "Heavenbest",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3468,
        "title": "paddlespeech_server如何指定使用自己训练的模型",
        "body": "本人直接使用demos下有一个paddle_server开启了一个web服务，问题：现在想要使ASR使用我这边训练好的模型对音频进行识别，应该如何操作呢？\r\n\r\n感谢！~\r\n\r\n另外经过查看paddlespeech_server支持的模型得到如下列表：\r\n<img width=\"576\" alt=\"222\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/137430307/ebfc8ff6-070f-46c8-89a3-a8c9166dd7db\">\r\n\r\n是否可以将自定义模型注册到zh这个列表中呢？",
        "state": "open",
        "user": "Arthurrrrking",
        "closed_by": null,
        "created_at": "2023-08-11T07:42:44+00:00",
        "updated_at": "2025-06-27T02:32:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "ainndejj11",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3469,
        "title": "TTS中英文内存使用过高，应该怎么解决",
        "body": "`# -*- coding:utf-8 -*-\r\nimport paddle\r\nimport yaml\r\nimport soundfile as sf\r\nfrom yacs.config import CfgNode\r\nfrom paddlespeech.t2s.frontend.mix_frontend import MixFrontend\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_inference\r\nfrom paddlespeech.t2s.exps.syn_utils import run_frontend\r\n# from memory_profiler import profile\r\n\r\nsentence = \"\"\"\r\n800多年前的今天，北京市丰台区的卢沟桥遭遇了一场猛烈的暴雨，但令人惊讶的是，这座古老的桥梁却安然无恙地屹立在这里，见证了时光的流转和历史的变迁。\r\n卢沟桥是中国历史上著名的古桥之一，建于元代至正年间，距今已有800多年的历史。这座桥梁位于北京市丰台区卢沟镇境内，横跨于卢沟河之上，全长266.5米，宽9.3米，是一座典型的石拱桥。。\r\n在800多年的历史中，卢沟桥经历了无数次风雨洗礼和战火炮烙，但每一次都能够奇迹般地幸免于难。其中最为著名的一次就是1937年的七七事变，日军侵华之际，卢沟桥成为了中日两军之间的战场。\r\n在激战中，卢沟桥被毁坏殆尽，但在抗战胜利后经过修复后又恢复了原貌。而这次暴雨，则是近年来卢沟桥所遭遇的一次自然灾害。据当地居民介绍，这场暴雨是他们近几十年来见过的最大暴雨之一，\r\n整个卢沟镇被淹没在水中，许多房屋和道路都被冲毁。但令人欣慰的是，卢沟桥并没有受到任何损害，仍然安然无恙地屹立在卢沟河之上。专家介绍说，卢沟桥之所以能够幸免于难，\r\n主要是因为它在建造时就考虑到了防洪防涝的问题。在桥梁两侧设置了多个洪水泄洪口和堤坝，能够有效地控制卢沟河的水位和流量。此外，在修缮时也一直坚持使用传统工艺和材料，\r\n保证了卢沟桥的稳固和耐久性。卢沟桥的安然无恙，不仅是一种幸运和奇迹，更是对我们传统文化和历史遗产的珍视和保护。我们应该更加重视和保护这些历史文化遗产，让它们能够继续传承下去，\r\n成为我们民族文化的瑰宝和精神财富。\r\n\"\"\"\r\n\r\n\r\nphones_dict = \"./fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt\"\r\n\r\nam_config_file = \"./fastspeech2_mix_ckpt_1.2.0/default.yaml\"\r\nam_ckpt = \"./fastspeech2_mix_ckpt_1.2.0/snapshot_iter_99200.pdz\"\r\nam_stat = \"./fastspeech2_mix_ckpt_1.2.0/speech_stats.npy\"\r\nspeaker_dict = \"./fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt\"\r\n\r\nvoc_config_file = \"./hifigan_aishell3_ckpt_0.2.0/default.yaml\"\r\nvoc_ckpt = \"./hifigan_aishell3_ckpt_0.2.0/snapshot_iter_2500000.pdz\"\r\nvoc_stat = \"./hifigan_aishell3_ckpt_0.2.0/feats_stats.npy\"\r\n\r\n\r\n# voc_config_file = \"./pwg_aishell3_ckpt_0.5/default.yaml\"\r\n# voc_ckpt = \"./pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz\"\r\n# voc_stat = \"./pwg_aishell3_ckpt_0.5/feats_stats.npy\"\r\n\r\n# text frontend\r\n# @profile(precision=5)\r\ndef text_frontend():\r\n    frontend = MixFrontend(phone_vocab_path=phones_dict)\r\n    print(\"frontend done!\")\r\n    return frontend\r\n\r\n\r\nwith open(am_config_file) as f:\r\n    am_config = CfgNode(yaml.safe_load(f))\r\n\r\n\r\n# load AM\r\n# @profile(precision=5)\r\ndef load_am():\r\n    am_inference = get_am_inference(\r\n        am=\"fastspeech2_mix\",\r\n        am_config=am_config,\r\n        am_ckpt=am_ckpt,\r\n        am_stat=am_stat,\r\n        phones_dict=phones_dict,\r\n        tones_dict=None,\r\n        speaker_dict=speaker_dict)\r\n    print(\"acoustic model done!\")\r\n    return am_inference\r\n\r\n\r\nwith open(voc_config_file) as f:\r\n    voc_config = CfgNode(yaml.safe_load(f))\r\n\r\n\r\n# load Voc\r\n# @profile(precision=5)\r\ndef load_voc():\r\n    voc_inference = get_voc_inference(\r\n        voc=\"hifigan_aishell3\",\r\n        voc_config=voc_config,\r\n        voc_ckpt=voc_ckpt,\r\n        voc_stat=voc_stat)\r\n    # voc_inference = get_voc_inference(\r\n    #     voc=\"pwgan_aishell3\",\r\n    #     voc_config=voc_config,\r\n    #     voc_ckpt=voc_ckpt,\r\n    #     voc_stat=voc_stat)\r\n    print(\"voc done!\")\r\n    return voc_inference\r\n\r\n\r\n# get phone id\r\n# @profile(precision=5)\r\ndef get_phone_id():\r\n    frontend = text_frontend()\r\n\r\n    frontend_dict = run_frontend(\r\n        frontend=frontend,\r\n        text=sentence,\r\n        merge_sentences=False,\r\n        get_tone_ids=False,\r\n        lang=\"mix\")\r\n    phone_ids = frontend_dict['phone_ids']\r\n    return phone_ids\r\n\r\n\r\nphone_ids = get_phone_id()\r\nam_inference = load_am()\r\nvoc_inference = load_voc()\r\n\r\n\r\n# inference\r\nflags = 0\r\nprint(f\"len phone ids : {len(phone_ids)}\")\r\nprint(phone_ids)\r\nfor i in range(len(phone_ids)):\r\n    part_phone_ids = phone_ids[i]\r\n    spk_id = 174  # baker:174, ljspeech:175, aishell3:0~173, vctk:176~282\r\n    spk_id = paddle.to_tensor(spk_id)\r\n    tracemalloc.start()\r\n    with paddle.no_grad():\r\n        mel = am_inference(part_phone_ids, spk_id)\r\n        wav = voc_inference(mel)\r\n\r\n    if flags == 0:\r\n        wav_all = wav\r\n        flags = 1\r\n    else:\r\n        wav_all = paddle.concat([wav_all, wav])\r\n    tracemalloc.stop()\r\nprint(\"infer successfully.\")\r\n\r\n# save audio\r\nwav = wav_all.numpy()\r\nsf.write(\"./out.wav\", wav, am_config.fs)\r\nprint(\"write successfully.\")\r\n`\r\n\r\n执行转译任务时，文字越多占用内存越高，1200多字算上加载模型大概能占用快到16G，且随着字数增多，内存仍在上涨。\r\n想请问下，是我使用的问题吗，还是它本来就是这种表现\r\n",
        "state": "closed",
        "user": "mrg79433283",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-13T08:58:32+00:00",
        "updated_at": "2025-04-27T18:52:08+00:00",
        "closed_at": "2025-04-27T18:52:08+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3470,
        "title": "[TTS]cudaError on Nvidia Jetson Orin NX",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nWhen run the example on [https://aistudio.baidu.com/aistudio/modelsdetail?modelId=26](https://aistudio.baidu.com/aistudio/modelsdetail?modelId=26) on Orin NX, an error occured:\r\n**_terminate called after throwing an instance of 'thrust::system::system_error'\r\nwhat():  after determining tmp storage requirements for inclusive_scan: cudaErrorInvalidDeviceFunction: invalid device function\r\nAborted (core dumped)_**\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n> from paddlespeech.cli.tts import TTSExecutor\r\ntts_executor = TTSExecutor()\r\nwav_file = tts_executor(\r\n    text=\"热烈欢迎您在 Discussions 中提交问题，并在 Issues 中指出发现的 bug。此外，我们非常希望您参与到 Paddle Speech 的开发中！\",\r\n    output='output.wav',\r\n    am='fastspeech2_mix',\r\n    voc='hifigan_csmsc',\r\n    lang='mix',\r\n    spk_id=174)\r\n\r\n**Expected behavior**\r\nRun normally\r\n\r\n**Screenshots**\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/99521008/084387e1-85c6-499a-9255-a29dfb974920)\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu 20.04\r\n - GCC/G++ Version 9.4\r\n - Python Version 3.8.10\r\n - PaddlePaddle Version 2.4.1\r\n - Model Version Default\r\n - GPU/DRIVER Information JetPack 5.1\r\n - CUDA/CUDNN Version 11.4/8.6.0\r\n - MKL Version \r\n- TensorRT Version 5.1\r\n\r\n",
        "state": "open",
        "user": "CHNtentes",
        "closed_by": null,
        "created_at": "2023-08-14T03:06:54+00:00",
        "updated_at": "2024-05-06T12:53:04+00:00",
        "closed_at": null,
        "comments_count": [
            "xjtu-cs-gao"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3473,
        "title": "[S2T]asr 案例演示demo出错",
        "body": "环境为docker pull paddlepaddle/paddle:2.5.1-gpu-cuda12.0-cudnn8.9-trt8.6\r\n然后就是常规的paddlespeech的下载\r\n运行`paddlespeech asr --lang zh --input zh.wav`报错，错误信息如下:\r\n```\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nW0815 02:11:20.922868 41699 gpu_resources.cc:96] The GPU architecture in your current machine is Pascal, which is not compatible with Paddle installation with arch: 70 75 80 86 , it is recommended to install the corresponding wheel package according to the installation information on the official Paddle website.\r\nW0815 02:11:20.922920 41699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.2, Runtime API Version: 12.0\r\nW0815 02:11:20.923902 41699 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nRuntimeError: (PreconditionNotMet) The meta data must be valid when call the mutable data function.\r\n  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:118)\r\n```\r\n不知道怎么解决，尝试将paddle的版本降为了2.4.2，但是又出现了protobuf和paddlenlp的版本冲突。求大佬指导！",
        "state": "closed",
        "user": "ScottXiao233",
        "closed_by": "ScottXiao233",
        "created_at": "2023-08-15T02:40:17+00:00",
        "updated_at": "2024-02-01T03:02:43+00:00",
        "closed_at": "2023-08-16T08:59:32+00:00",
        "comments_count": [
            "zxcd",
            "kenlive"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3472,
        "title": "声音区分怎样实现那，根据声纹",
        "body": "首先这个问题我觉得很难用一两句说明白，所以在这里具体说明一下，希望给些建议或关键词。\r\n问题背景：我有一段两个人的对话语音，我使用音频切分模块去进行切分，然后对每段音频进行识别并获得其声纹，根据每段话的声纹来分辨出两个人各自说的话(但这个方法是我自己创造的，即对比每一段声音音频再根据思相似度聚类)。\r\n问题提出：根据声纹区分出两个人的对话有比较有理论支持的方法吗\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "chenkang404",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-14T10:03:58+00:00",
        "updated_at": "2025-04-27T18:52:13+00:00",
        "closed_at": "2025-04-27T18:52:13+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3476,
        "title": "unable to install paddlespeech in windows powershell",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nwhile running the below command getting the error shown below:\r\n**pip install paddlespeech**\r\n\r\n**Error:**\r\nCollecting onnx<=1.9.0 (from paddle2onnx->paddlenlp->paddlespeech)\r\n  Using cached onnx-1.9.0.tar.gz (9.8 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Getting requirements to build wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [22 lines of output]\r\n      fatal: not a git repository (or any of the parent directories): .git\r\n      Traceback (most recent call last):\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-build-env-qbb57_h0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=['wheel'])\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-build-env-qbb57_h0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 323, in _get_build_requires\r\n          self.run_setup()\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-build-env-qbb57_h0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 488, in run_setup\r\n          self).run_setup(setup_script=setup_script)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-build-env-qbb57_h0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 338, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 86, in <module>\r\n      AssertionError: Could not find \"cmake\" executable!\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× Getting requirements to build wheel did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/133914755/03a5eaee-ac6e-4527-a217-f64ba5ad5701)\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu] windows 11 powershell\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7] : 3.11.4\r\n - PaddlePaddle Version [e.g. 2.0.0]: 2.5.1\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "clonesangram87",
        "closed_by": null,
        "created_at": "2023-08-15T09:39:05+00:00",
        "updated_at": "2023-08-15T09:39:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3474,
        "title": "numpy包提示有问题但是的确是低于1.24的ImportError: Numba needs NumPy 1.24 or less",
        "body": "已经搜了，没看到有一样的问题。\r\n\r\n报错：\r\nTraceback (most recent call last):\r\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 972, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\r\n  File \"D:\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\asr\\__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"D:\\Study\\postgraduate\\project\\KongTianYuan\\PaddleSpeech\\paddlespeech\\cli\\asr\\infer.py\", line 24, in <module>\r\n    import librosa\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\core\\__init__.py\", line 5, in <module>\r\n    from .convert import *  # pylint: disable=wildcard-import\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\core\\convert.py\", line 7, in <module>\r\n    from . import notation\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\core\\notation.py\", line 8, in <module>\r\n    from ..util.exceptions import ParameterError\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\util\\__init__.py\", line 83, in <module>\r\n    from .utils import *  # pylint: disable=wildcard-import\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\librosa\\util\\utils.py\", line 10, in <module>\r\n    import numba\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\numba\\__init__.py\", line 55, in <module>\r\n    _ensure_critical_deps()\r\n  File \"D:\\Anaconda\\envs\\kty_paddle\\lib\\site-packages\\numba\\__init__.py\", line 42, in _ensure_critical_deps\r\n    raise ImportError(\"Numba needs NumPy 1.24 or less\")\r\nImportError: Numba needs NumPy 1.24 or less\r\npython-BaseException\r\n\r\n我的包：\r\nnltk                      3.8.1                    pypi_0    pypi\r\nnumba                     0.57.1                   pypi_0    pypi\r\nnumpy                     1.23.5                   pypi_0    pypi\r\nonnxruntime               1.15.1                   pypi_0    pypi\r\nopencc                    1.1.1                    pypi_0    pypi\r\nopencc-python-reimplemented 0.1.7                    pypi_0    pypi\r\nopencv-python             4.5.5.64                 pypi_0    pypi\r\nopenjpeg                  2.5.0                ha2aaf27_2    conda-forge\r\nopenssl                   3.1.1                hcfcfb64_1    conda-forge\r\nopt-einsum                3.3.0                    pypi_0    pypi\r\npackaging                 23.1               pyhd8ed1ab_0    conda-forge\r\npaddle-bfloat             0.1.7                    pypi_0    pypi\r\npaddle2onnx               1.0.6                    pypi_0    pypi\r\npaddleaudio               1.1.0                    pypi_0    pypi\r\npaddledet                 2.6.0                    pypi_0    pypi\r\n我的numpy已经是低于1.24的呀，是1.23.5的，但是依旧报错？\r\n",
        "state": "closed",
        "user": "2625009538",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-15T03:30:46+00:00",
        "updated_at": "2025-06-27T03:38:11+00:00",
        "closed_at": "2025-06-27T03:38:11+00:00",
        "comments_count": [
            "zxcd",
            "2625009538",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3475,
        "title": "[S2T]使用自己录制的音频进行stream asr报错",
        "body": "环境为：`registry.baidubce.com/paddlepaddle/paddle:2.4.2-gpu-cuda11.7-cudnn8.4-trt8.4`\r\n录制的音频已经通过Adobe Audition把sample rate改为了16000\r\n已经成功运行了`punc_server.py`和`streaming_asr_server.py`，配置文件中也都是16000的sample_rate\r\n将websocket_client.py中的”--wavfile“的路径写的就是我自己录制的音频。运行后报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"websocket_client.py\", line 88, in <module>\r\n    main(args)\r\n  File \"websocket_client.py\", line 40, in main\r\n    result = loop.run_until_complete(handler.run(args.wavfile))\r\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 587, in run_until_complete\r\n    return future.result()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/utils/audio_handler.py\", line 166, in run\r\n    for chunk_data in self.read_wave(wavfile_path):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/server/utils/audio_handler.py\", line 121, in read_wave\r\n    padded_x = np.concatenate([samples, padding], axis=0)\r\n  File \"<__array_function__ internals>\", line 6, in concatenate\r\nValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\r\n```",
        "state": "closed",
        "user": "ScottXiao233",
        "closed_by": "ScottXiao233",
        "created_at": "2023-08-15T08:38:39+00:00",
        "updated_at": "2023-08-15T09:25:37+00:00",
        "closed_at": "2023-08-15T09:25:37+00:00",
        "comments_count": [
            "ScottXiao233"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3477,
        "title": "MFA怎么处理中英文混合数据啊？有没有详细一点的例子",
        "body": "我在网上看到“MFA 的时候把文本处理成 拼音+英文+拼音 的形式，MFA 的发音字典把 中文字典（simple.lexion） + 英文字典（cmudict）拼接后处理”，但我实在不知道具体怎么做，有人可以给我举一个具体一些的例子吗",
        "state": "closed",
        "user": "WanwanLinLin",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-15T13:54:23+00:00",
        "updated_at": "2025-04-27T18:52:44+00:00",
        "closed_at": "2025-04-27T18:52:43+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3478,
        "title": "[TTS] 无法使用 multi-speaker 生成音频",
        "body": "参考 https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/text_to_speech 的 multi-speaker 命令，但是遇到以下错误\r\n\r\n**Describe the bug**\r\n(venv) λ paddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input \"热烈欢迎您在 Discussions 中提交问题，并在 Issues 中指出发现的 bug。此外，我们非常希望您参与到 Paddle Speech 的开发中！\" --spk_id 174 --output mix_spk1\r\n74.wav\r\nI0816 02:24:36.038482 38216 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nI0816 02:24:36.039484 38216 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nC:\\Users\\Administrator\\Desktop\\sd\\paddle\\venv\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:1897: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\nC:\\Users\\Administrator\\Desktop\\sd\\paddle\\venv\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:1897: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\nValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[256].\r\n  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at ..\\paddle\\phi\\infermeta\\unary.cc:2763)\r\n\r\n**To Reproduce**\r\n命令：paddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input \"热烈欢迎您在 Discussions 中提交问题，并在 Issues 中指出发现的 bug。此外，我们非常希望您参与到 Paddle Speech 的开发中！\" --spk_id 174 --output mix_spk1\r\n74.wav\r\n\r\n**Expected behavior**\r\n可以顺利生成音频\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Window 11\r\n - Python Version: 3.9.5\r\n - PaddlePaddle Version: 2.5.0\r\n - PaddleSpeech Version: 1.4.1\r\n - Model Version:均为默认下载\r\n - GPU/DRIVER Information: CPU\r\n - \r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.0.6\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.0\r\npaddlepaddle                2.5.0\r\npaddleslim                  2.4.1\r\npaddlespeech                1.4.1\r\npaddlespeech-feat           0.1.0\r\n",
        "state": "open",
        "user": "kaka1909",
        "closed_by": null,
        "created_at": "2023-08-15T18:26:53+00:00",
        "updated_at": "2023-11-02T06:29:19+00:00",
        "closed_at": null,
        "comments_count": [
            "kaka1909",
            "name2023well",
            "whtwhtw",
            "mrzjl"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3479,
        "title": "[S2T]流式ASR麦克风识别---中英文---['asr_online']---需求",
        "body": "成功运行了\r\n[PaddleSpeech-Streaming-ASR-Client](https://github.com/xiaomingnio/PaddleSpeech-Streaming-ASR-Client/tree/db6787e5da75e3948c9120b8af6659a71ec8146f)\r\n/websocket_client.py\r\n\r\n发现并不支持`pretrained_models.py`中的`conformer_talcs-codeswitch_zh_en-16k`模型，\r\n\r\n\r\n`Can't find \"conformer_talcs-codeswitch-zh_en-16k\" in resource. Model name must be one of ['conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_online_aishell-zh-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2online_aishell-zh-16k']`\r\n\r\n\r\n找到了`conformer_talcs_application.yaml`中发现`protocol`并不支持`websocket`，`engine_list`也不支持`asr_online`。有大佬知道在哪儿修改吗？",
        "state": "open",
        "user": "ScottXiao233",
        "closed_by": null,
        "created_at": "2023-08-16T08:51:09+00:00",
        "updated_at": "2024-03-27T06:37:52+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "yzypals"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3481,
        "title": "[TTS]TTS Streaming server running smoothly at first, but after a while TTS client report Errno 111 Connection refused",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nNot sure if the server is crashed because of some reasons or what really happens.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to 'docker', Type 'sudo docker exec -it dev /bin/bash'\r\n2. Type 'paddlespeech_client tts_online --server_ip 127                                                                                                                                                             .0.0.1 --port 8092 --protocol http --input \"您好，欢迎使用综合语音合成服务。\" --                                                                                                                                                             output output2.wav'\r\n3. Wait few seconds\r\n4. See error\r\n\r\n**Expected behavior**\r\nRunning smoothly as usual.\r\n\r\n**Screenshots**\r\nTake a look of the picture and I don't really get clue about it.\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/93806820/690f63b1-e35e-4925-8d5a-1609eceae816)\r\nHere is the info msg it returns from picture above,\r\npaddlespeech_client tts_online --server_ip 127                                                                                                                                                             .0.0.1 --port 8092 --protocol http --input \"您好，欢迎使用综合语音合成服务。\" --                                                                                                                                                             output output2.wav\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: Deprecati                                                                                                                                                             onWarning: `np.complex` is a deprecated alias for the builtin `complex`. To sile                                                                                                                                                             nce this warning, use `complex` by itself. Doing this will not modify any behavi                                                                                                                                                             or and is safe. If you specifically wanted the numpy scalar type, use `np.comple                                                                                                                                                             x128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdo                                                                                                                                                             cs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n[2023-08-17 15:30:46,843] [    INFO] - tts http client start\r\n[2023-08-17 15:30:46,843] [    INFO] - endpoint: http://127.0.0.1:8092/paddlespe                                                                                                                                                             ech/tts/streaming\r\n[2023-08-17 15:30:46,846] [   ERROR] - Failed to synthesized audio.\r\n[2023-08-17 15:30:46,846] [   ERROR] - HTTPConnectionPool(host='127.0.0.1', port                                                                                                                                                             =8092): Max retries exceeded with url: /paddlespeech/tts/streaming (Caused by Ne                                                                                                                                                             wConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0fb2e7b710>:                                                                                                                                                              Failed to establish a new connection: [Errno 111] Connection refused'))\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu 20.04 \r\n - GCC/G++ Version: Same as Docker\r\n - Python Version: 3.7\r\n - PaddlePaddle Version: Same as Docker\r\n - Model Version: Same as Docker\r\n - GPU/DRIVER Informationo: None\r\n - CUDA/CUDNN Version: None\r\n - MKL Version: Same as Docker\r\n- TensorRT Version:Same as Docker\r\nUSE CPU\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "WorldPeaceSteven",
        "closed_by": null,
        "created_at": "2023-08-17T15:57:59+00:00",
        "updated_at": "2023-08-17T15:57:59+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3480,
        "title": "cuda 12.1 ，运行时报错",
        "body": "我的是cuda 是12.1 ，官网文档最新是12.0 ，所以我安装了cuda 12.0 ，导入的时候报错。\r\nPython 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:20:04) [GCC 11.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddle\r\nError: Can not import paddle core while this file exists: /home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/core.py\", line 356, in <module>\r\n    raise e\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\r\n",
        "state": "closed",
        "user": "linuxdevopscn",
        "closed_by": "linuxdevopscn",
        "created_at": "2023-08-17T07:21:02+00:00",
        "updated_at": "2023-08-17T08:00:30+00:00",
        "closed_at": "2023-08-17T08:00:30+00:00",
        "comments_count": [
            "linuxdevopscn"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3483,
        "title": "训练中途卡主，如何继续最后的模型断点训练",
        "body": "训练第五个epoch时候，卡住了，训练停止，电脑也卡了，就强制关机了。\r\n请问如何用第五个epoch的模型继续训练",
        "state": "closed",
        "user": "ainndejj11",
        "closed_by": "ainndejj11",
        "created_at": "2023-08-18T05:11:16+00:00",
        "updated_at": "2023-08-21T02:30:20+00:00",
        "closed_at": "2023-08-21T02:30:20+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3482,
        "title": "  PreconditionNotMetError: The third-party dynamic library (libcublas.so) that Paddle depends on is not configured correctly. (error code is libcublas.so: cannot open shared object file: No such file or directory)",
        "body": "(paddlespeech) quanlian@quanlian3060:~/aigc/PaddleSpeech$ python\r\nPython 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:20:04) [GCC 11.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ...\r\nI0817 17:37:56.241706 2912090 interpretercore.cc:237] New Executor is Running.\r\nW0817 17:37:56.241897 2912090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.1, Runtime API Version: 12.0\r\nW0817 17:37:56.242406 2912090 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/utils/install_check.py\", line 249, in run_check\r\n    _run_static_single(use_cuda, use_xpu)\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/utils/install_check.py\", line 147, in _run_static_single\r\n    exe.run(\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/executor.py\", line 1392, in run\r\n    res = self._run_impl(\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/executor.py\", line 1618, in _run_impl\r\n    ret = new_exe.run(\r\n  File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/executor.py\", line 654, in run\r\n    tensors = self._new_exe.run(\r\nRuntimeError: In user code:\r\n\r\n    File \"<stdin>\", line 1, in <module>\r\n\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/utils/install_check.py\", line 249, in run_check\r\n      _run_static_single(use_cuda, use_xpu)\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/utils/install_check.py\", line 133, in _run_static_single\r\n      input, out, weight = _simple_network()\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/utils/install_check.py\", line 37, in _simple_network\r\n      linear_out = paddle.nn.functional.linear(x=input, weight=weight, bias=bias)\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/nn/functional/common.py\", line 1860, in linear\r\n      helper.append_op(\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/layer_helper.py\", line 45, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 4013, in append_op\r\n      op = Operator(\r\n    File \"/home/quanlian/mambaforge/envs/paddlespeech/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 2781, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    PreconditionNotMetError: The third-party dynamic library (libcublas.so) that Paddle depends on is not configured correctly. (error code is libcublas.so: cannot open shared object file: No such file or directory)\r\n      Suggestions:\r\n      1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\r\n      2. Configure third-party dynamic library environment variables as follows:\r\n      - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n      - Windows: set PATH by `set PATH=XXX; (at ../paddle/phi/backends/dynload/dynamic_loader.cc:300)\r\n      [operator < matmul_v2 > error]\r\n",
        "state": "open",
        "user": "linuxdevopscn",
        "closed_by": null,
        "created_at": "2023-08-18T01:31:12+00:00",
        "updated_at": "2023-08-18T01:32:14+00:00",
        "closed_at": null,
        "comments_count": [
            "linuxdevopscn"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3484,
        "title": "如果使用gpu版本的话，内存是不是会降低一些",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/3361399/969ae137-8fee-4420-96d6-769deecd3e7c)\r\n\r\n\r\n使用场景windows, paddlespeech_server启动后，默认的话python.exe使用了3.5G的内存，想问一下，如果是gpu版本的话，内存占用是不是会少一些，用gpu使用的兄弟，麻烦给个内存使用图，给个参考，谢谢。",
        "state": "closed",
        "user": "yaoweilei",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-18T08:00:42+00:00",
        "updated_at": "2025-04-27T18:53:22+00:00",
        "closed_at": "2025-04-27T18:53:22+00:00",
        "comments_count": [
            "yaoweilei",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3487,
        "title": "训练asr的deepspeech2 模型  如何指定加载预训练模型",
        "body": "deepspeech的训练配置文件为：\r\n\r\n###########################################\r\n#                   Data                  #\r\n###########################################\r\ntrain_manifest: data/manifest.train\r\ndev_manifest: data/manifest.dev\r\ntest_manifest: data/manifest.test\r\nmin_input_len: 0.0\r\nmax_input_len: 27.0 # second\r\nmin_output_len: 0.0\r\nmax_output_len: .inf\r\nmin_output_input_ratio: 0.00\r\nmax_output_input_ratio: .inf\r\n\r\n###########################################\r\n#              Dataloader                 #\r\n###########################################\r\nvocab_filepath: data/lang_char/vocab.txt \r\nspm_model_prefix: ''\r\nunit_type: 'char'\r\npreprocess_config: conf/preprocess.yaml\r\nfeat_dim: 161\r\nstride_ms: 10.0\r\nwindow_ms: 25.0\r\nsortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs \r\nbatch_size: 64\r\nmaxlen_in: 512  # if input length  > maxlen-in, batchsize is automatically reduced\r\nmaxlen_out: 150  # if output length > maxlen-out, batchsize is automatically reduced\r\nminibatches: 0 # for debug\r\nbatch_count: auto\r\nbatch_bins: 0 \r\nbatch_frames_in: 0\r\nbatch_frames_out: 0\r\nbatch_frames_inout: 0\r\nnum_workers: 8\r\nsubsampling_factor: 1\r\nnum_encs: 1\r\n\r\n############################################\r\n#           Network Architecture           #\r\n############################################\r\nnum_conv_layers: 2\r\nnum_rnn_layers: 5\r\nrnn_layer_size: 1024\r\nrnn_direction: bidirect # [forward, bidirect]\r\nnum_fc_layers: 0\r\nfc_layers_size_list: -1,\r\nuse_gru: False \r\nblank_id: 0\r\n  \r\n  \r\n###########################################\r\n#                Training                 #\r\n###########################################\r\nn_epoch: 50\r\naccum_grad: 1\r\nlr: 5.0e-4\r\nlr_decay: 0.93\r\nweight_decay: 1.0e-6\r\nglobal_grad_clip: 3.0\r\ndist_sampler: False\r\nlog_interval: 1\r\ncheckpoint:\r\n  kbest_n: 50\r\n  latest_n: 5\r\n\r\n\r\n请问如何加载指定一个预训练模型呢？",
        "state": "open",
        "user": "ainndejj11",
        "closed_by": null,
        "created_at": "2023-08-22T01:53:19+00:00",
        "updated_at": "2023-08-22T01:53:19+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3485,
        "title": "ModuleNotFoundError: No module named 'paddle.nn.layer.layers'",
        "body": "paddlepaddle:2.4.2\r\npaddlespeech:1.4.1\r\n\r\n运行：\"paddlespeech_server start --help\" \r\n出现错误：ModuleNotFoundError: No module named 'paddle.nn.layer.layers'\r\n\r\n使用paddlespeech asr命令没有问题\r\n",
        "state": "open",
        "user": "z070204z",
        "closed_by": null,
        "created_at": "2023-08-21T06:49:16+00:00",
        "updated_at": "2025-04-26T03:46:20+00:00",
        "closed_at": null,
        "comments_count": [
            "kobe24o",
            "z070204z",
            "diaojinlong",
            "gbnj2004",
            "hjhcos",
            "qinhuangdaoStation",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3486,
        "title": "我在使用TextExecutor()时，报了很多以下信息",
        "body": "## General Question\r\n\r\nStartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443StartingnewHTTPSconnection(1):paddlepaddle.org.cn:443https://paddlepaddle.org.cn:443\"GET/paddlehub/stat?task=text&version=0.0.0&from=ppspeech&model=ernie_linear_p7_wudao&extra={\"paddle_version\":+\"0.0.0\",+\"sub_task\":+\"punc\",+\"lang\":+\"zh\",+\"cache_info\":+\"fa30b095ee54403805afe32d1b169e6b-1692597639\"}HTTP/1.1\"20013https://paddlepaddle.org.cn:443\"GET/paddlehub/stat?task=text&version=0.0.0&from=ppspeech&model=ernie_linear_p7_wudao&extra={\"paddle_version\":+\"0.0.0\",+\"sub_task\":+\"punc\",+\"lang\":+\"zh\",+\"cache_info\":+\"fa30b095ee54403805afe32d1b169e6b-1692597639\"}HTTP/1.1\"20013https://paddlepaddle.org.cn:443\"GET/paddlehub/stat?task=text&version=0.0.0&from=ppspeech&model=ernie_linear_p7_wudao&extra={\"paddle_version\":+\"0.0.0\",+\"sub_task\":+\"punc\",+\"lang\":+\"zh\",+\"cache_info\":+\"fa30b095ee54403805afe32d1b169e6b-1692597639\"}HTTP/1.1\"20013https://paddlepaddle.org.cn:443\"GET/paddlehub/stat?task=text&version=0.0.0&from=ppspeech&model=ernie_linear_p7_wudao&extra={\"paddle_version\":+\"0.0.0\",+\"sub_task\":+\"punc\",+\"lang\":+\"zh\",+\"cache_info\":+\"fa30b095ee54403805afe32d1b169e6b-1692597639\"}HTTP/1.1\"20013",
        "state": "closed",
        "user": "450586509",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-21T09:12:05+00:00",
        "updated_at": "2025-06-27T03:37:55+00:00",
        "closed_at": "2025-06-27T03:37:55+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3488,
        "title": "[TTS]我运行语音专文本的示例代码报错",
        "body": "\r\n我运行示例代码直接报错\r\n```\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\nprint(result)\r\n````\r\n\r\n错误信息如下\r\n```\r\n/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/bin/python /Users/xiaobing5/Documents/code/gitlab/AIGC_GPT_2_Video/AIGC_GPT_2_Video/voice2Text/aigc_voice_to_text.py \r\n2023-08-23 12:52:29.369 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-08-23 12:52:30,605] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"<decorator-gen-493>\", line 2, in decode\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\nTraceback (most recent call last):\r\n  File \"/Users/xiaobing5/Documents/code/gitlab/AIGC_GPT_2_Video/AIGC_GPT_2_Video/voice2Text/aigc_voice_to_text.py\", line 36, in <module>\r\n    result = asr(audio_file=\"/Users/xiaobing5/Documents/code/gitlab/AIGC_GPT_2_Video/AIGC_GPT_2_Video/voice2Text/zh.wav\")\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 512, in __call__\r\n    res = self.postprocess()  # Retrieve result of asr.\r\n  File \"/Users/xiaobing5/Documents/Developer/Workspace/AIGC_GPT_2_Video/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n我的环境配置\r\n\r\n```\r\n ~/Documents/code/gitlab/AIGC_GPT_2_Video/AIGC_GPT_2_Video/models/voice_to_text  $ pip list\r\nPackage                     Version\r\n--------------------------- ---------\r\naiohttp                     3.8.5\r\naiosignal                   1.3.1\r\nannotated-types             0.5.0\r\nanyio                       3.7.1\r\nastor                       0.8.1\r\nasync-timeout               4.0.2\r\nattrs                       23.1.0\r\naudioread                   3.0.0\r\nBabel                       2.12.1\r\nbce-python-sdk              0.8.90\r\nbeautifulsoup4              4.12.2\r\nblinker                     1.6.2\r\nBottleneck                  1.3.7\r\nbraceexpand                 0.1.7\r\nbs4                         0.0.1\r\ncertifi                     2023.5.7\r\ncffi                        1.15.1\r\ncharset-normalizer          3.2.0\r\nclick                       8.1.7\r\ncolorama                    0.4.6\r\ncoloredlogs                 15.0.1\r\ncolorlog                    6.7.0\r\ncontourpy                   1.1.0\r\ncycler                      0.11.0\r\nCython                      3.0.0\r\ndatasets                    2.14.4\r\ndecorator                   4.4.2\r\ndill                        0.3.4\r\nDistance                    0.1.3\r\neditdistance                0.6.2\r\neinops                      0.6.1\r\net-xmlfile                  1.1.0\r\nexceptiongroup              1.1.2\r\nfastapi                     0.101.1\r\nfilelock                    3.12.2\r\nFlask                       2.3.3\r\nflask-babel                 3.1.0\r\nflatbuffers                 23.5.26\r\nfonttools                   4.42.1\r\nfrozenlist                  1.4.0\r\nfsspec                      2023.6.0\r\nftfy                        6.1.1\r\nfuture                      0.18.3\r\ng2p-en                      2.1.0\r\ng2pM                        0.1.2.5\r\ngensim                      4.3.1\r\ngradio_client               0.3.0\r\nh11                         0.14.0\r\nh5py                        3.9.0\r\nhttpcore                    0.17.3\r\nhttpx                       0.24.1\r\nhuggingface-hub             0.16.4\r\nhumanfriendly               10.0\r\nHyperPyYAML                 1.2.1\r\nidna                        3.4\r\nimageio                     2.31.1\r\nimageio-ffmpeg              0.4.8\r\ninflect                     7.0.0\r\ninstall                     1.3.5\r\nitsdangerous                2.1.2\r\njieba                       0.42.1\r\nJinja2                      3.1.2\r\njoblib                      1.3.1\r\njsonlines                   3.1.0\r\nkaldiio                     2.18.0\r\nkiwisolver                  1.4.4\r\nlazy_loader                 0.3\r\nlibrosa                     0.8.1\r\nllvmlite                    0.40.1\r\nloguru                      0.7.0\r\nlxml                        4.9.3\r\nmarkdown-it-py              3.0.0\r\nMarkupSafe                  2.1.3\r\nmatplotlib                  3.7.2\r\nmdurl                       0.1.2\r\nmock                        5.1.0\r\nmoviepy                     1.0.3\r\nmpmath                      1.3.0\r\nmultidict                   6.0.4\r\nmultiprocess                0.70.12.2\r\nnara-wpe                    0.0.9\r\nnetworkx                    3.1\r\nnltk                        3.8.1\r\nnumba                       0.57.1\r\nnumpy                       1.23.5\r\nonnx                        1.14.0\r\nonnxruntime                 1.15.1\r\nopenai                      0.27.8\r\nOpenCC                      0.2\r\nopencc-python-reimplemented 0.1.7\r\nopencv-python               4.8.0.74\r\nopenpyxl                    3.1.2\r\nopt-einsum                  3.3.0\r\npackaging                   23.1\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.0.9\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.0\r\npaddlepaddle                2.5.1\r\npaddleslim                  2.4.1\r\npaddlespeech                1.4.1\r\npaddlespeech-ctcdecoders    0.2.0\r\npaddlespeech-feat           0.1.0\r\npandas                      2.0.3\r\nparameterized               0.9.0\r\npathos                      0.2.8\r\npattern-singleton           1.2.0\r\nPillow                      10.0.0\r\npip                         23.1.2\r\nplatformdirs                3.10.0\r\npooch                       1.7.0\r\nportalocker                 2.7.0\r\npox                         0.3.3\r\nppdiffusers                 0.16.3\r\nppft                        1.7.6.7\r\npraatio                     5.1.1\r\nprettytable                 3.8.0\r\nproglog                     0.1.10\r\nprotobuf                    3.20.2\r\npsutil                      5.9.5\r\npyarrow                     12.0.1\r\npybind11                    2.11.1\r\npycparser                   2.21\r\npycryptodome                3.18.0\r\npydantic                    2.2.1\r\npydantic_core               2.6.1\r\nPygments                    2.16.1\r\npygtrie                     2.5.0\r\npyparsing                   3.0.9\r\npypinyin                    0.44.0\r\npypinyin-dict               0.6.0\r\npytest-runner               6.0.0\r\npython-dateutil             2.8.2\r\npytz                        2023.3\r\nPyWavelets                  1.4.1\r\npyworld                     0.3.4\r\nPyYAML                      6.0.1\r\npyzmq                       25.1.1\r\nrarfile                     4.0\r\nregex                       2023.6.3\r\nrequests                    2.31.0\r\nresampy                     0.4.2\r\nrich                        13.5.2\r\nruamel.yaml                 0.17.28\r\nruamel.yaml.clib            0.2.7\r\nsacrebleu                   2.3.1\r\nsafetensors                 0.3.1\r\nscikit-image                0.21.0\r\nscikit-learn                1.3.0\r\nscipy                       1.11.1\r\nscs-sdk                     1.1.6\r\nsentencepiece               0.1.99\r\nseqeval                     1.2.2\r\nsetuptools                  67.8.0\r\nsix                         1.16.0\r\nsmart-open                  6.3.0\r\nsniffio                     1.3.0\r\nsoundfile                   0.12.1\r\nsoupsieve                   2.4.1\r\nstarlette                   0.27.0\r\nswig                        4.1.1\r\nsympy                       1.12\r\ntabulate                    0.9.0\r\nTextGrid                    1.5\r\nthreadpoolctl               3.2.0\r\ntifffile                    2023.7.18\r\ntimer                       0.2.2\r\nToJyutping                  0.2.3\r\ntokenizers                  0.13.3\r\ntorch                       2.0.1\r\ntqdm                        4.65.0\r\ntransformers                4.31.0\r\ntypeguard                   2.13.3\r\ntyper                       0.9.0\r\ntyping_extensions           4.7.1\r\ntzdata                      2023.3\r\nurllib3                     2.0.4\r\nuvicorn                     0.23.2\r\nvisualdl                    2.5.3\r\nwcwidth                     0.2.6\r\nwebrtcvad                   2.0.10\r\nwebsockets                  11.0.3\r\nWerkzeug                    2.3.7\r\nwheel                       0.40.0\r\nxxhash                      3.3.0\r\nyacs                        0.1.8\r\nyarl                        1.9.2\r\nzhon                        2.0.2\r\n```\r\n",
        "state": "open",
        "user": "sixTiger",
        "closed_by": null,
        "created_at": "2023-08-23T06:08:44+00:00",
        "updated_at": "2024-08-03T11:38:31+00:00",
        "closed_at": null,
        "comments_count": [
            "HorseArcher567",
            "diaojinlong",
            "wudenggang",
            "wudenggang",
            "yaleimeng",
            "sunfan1997",
            "getting107"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3489,
        "title": "我在ubuntu的conda环境下运行语音转文本出错了，求帮助",
        "body": "## General Question\r\n\r\npaddlespeech asr --lang zh --input zh.wav 当我运行实例中的这句时，报错：\r\n\r\n非法指令 (核心已转储)\r\n\r\n我是按照 paddlespeech 教程来的，为何会出现这种错误，conda都开了好几个新环境了，还是这样。求帮忙",
        "state": "closed",
        "user": "lckj2009",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-23T09:25:52+00:00",
        "updated_at": "2025-06-27T04:34:20+00:00",
        "closed_at": "2025-06-27T04:34:20+00:00",
        "comments_count": [
            "lckj2009",
            "beixiang-l",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3493,
        "title": "中英文混合的TTS有问题",
        "body": "中英文混合的TTS要么英文乱说的，要么直接跳过，有的模型直接生成TTS失败。",
        "state": "open",
        "user": "lilongwei5054",
        "closed_by": null,
        "created_at": "2023-08-26T02:23:48+00:00",
        "updated_at": "2024-05-31T06:35:36+00:00",
        "closed_at": null,
        "comments_count": [
            "linuxonly801",
            "cywjava",
            "bardenthenry",
            "chaosact"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3492,
        "title": "streaming TTS cannot use GPU on jetson",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\nI'm using the demo in [https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_tts_server/README.md](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_tts_server/README.md) on Jetson Orin NX.\r\n\r\nHere is my code:\r\n\r\nserver.py\r\n_**from paddlespeech.server.bin.paddlespeech_server import ServerExecutor\r\nserver_executor = ServerExecutor()\r\nserver_executor(config_file=\"./conf/tts_online_application.yaml\", log_file=\"./log/tts.log\")**_\r\n\r\nclient.py\r\n_**from paddlespeech.server.bin.paddlespeech_client import TTSOnlineClientExecutor\r\ntts_executor = TTSOnlineClientExecutor()\r\ntts_executor(input=\"现有的点云推理模型为基于开源数据集训练的模型。\", server_ip=\"127.0.0.1\", port=8092, protocol=\"http\")**_\r\n\r\nAnd this is my config file:\r\n[tts_online_application.yaml.txt](https://github.com/PaddlePaddle/PaddleSpeech/files/12435082/tts_online_application.yaml.txt)\r\n\r\nThe issue is, it can yield results, but there's no load on GPU, while CPU usage is high.\r\nWhen I run server.py, it showed TTS server is running on gpu:0, which is weird since GPU has no load at all.\r\n![批注 2023-08-25 111205](https://github.com/PaddlePaddle/PaddleSpeech/assets/99521008/de4d19ec-818b-4b29-a389-c6f3af2a1f4b)\r\n\r\nWhat can I do to further analyse the issue? Thanks in advance.",
        "state": "closed",
        "user": "CHNtentes",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-25T03:15:30+00:00",
        "updated_at": "2025-06-27T03:37:54+00:00",
        "closed_at": "2025-06-27T03:37:54+00:00",
        "comments_count": [
            "CHNtentes",
            "stale[bot]",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3494,
        "title": "asr 识别数字串的时候可以不加单位吗？",
        "body": "\r\n例如110，会被识别成一百一十，这个可以设置吗？",
        "state": "closed",
        "user": "liuli7700",
        "closed_by": "stale[bot]",
        "created_at": "2023-08-29T03:00:45+00:00",
        "updated_at": "2025-06-27T05:32:50+00:00",
        "closed_at": "2025-06-27T05:32:50+00:00",
        "comments_count": [
            "ScottXiao233",
            "qingjiaozyn",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3497,
        "title": "训练ASR模型  基于词为建模单元不收敛",
        "body": "deepspeech2模型训练  aishell1数据集\r\n分别验证基于字为建模单元和基于词为建模单元，训练参数一样\r\n\r\n基于字收敛正常，val_loss=4   可正常预测\r\n但是基于词就不收敛了，val_loss=15。 \r\n分词方法是使用jieba包。    词汇表很大，并且有的词分的不是很准确。\r\n\r\n请问如何解决基于词为建模单元的情况，该用什么方法正确分词呢，或者有什么模型或参数优化的方案么",
        "state": "open",
        "user": "ainndejj11",
        "closed_by": null,
        "created_at": "2023-09-01T01:35:47+00:00",
        "updated_at": "2023-09-01T01:35:48+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3496,
        "title": "how to convert  binary file to arpa",
        "body": "\r\nhow to convert binary file to arpa",
        "state": "closed",
        "user": "wwfcnu",
        "closed_by": "wwfcnu",
        "created_at": "2023-08-31T07:21:17+00:00",
        "updated_at": "2025-04-27T03:45:30+00:00",
        "closed_at": "2025-04-27T03:45:30+00:00",
        "comments_count": [
            "stale[bot]",
            "wwfcnu",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3495,
        "title": "因为speechX目录移动，多处涉及到speechx或ASR deploy的链接已失效。",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n\r\n因为speechX目录的移动，现在项目中多处涉及到speechx或ASR deploy的链接已失效。希望及时处理。\r\n",
        "state": "closed",
        "user": "yaleimeng",
        "closed_by": "yaleimeng",
        "created_at": "2023-08-30T01:57:40+00:00",
        "updated_at": "2023-10-16T00:58:50+00:00",
        "closed_at": "2023-10-16T00:58:50+00:00",
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3503
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3498,
        "title": "'ErnieModel' object has no attribute 'config'",
        "body": "## Others\r\n\r\n<!--\r\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\r\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\r\n-->\r\n",
        "state": "closed",
        "user": "tianclll",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-02T02:11:13+00:00",
        "updated_at": "2025-06-27T03:38:19+00:00",
        "closed_at": "2025-06-27T03:38:19+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3499,
        "title": "docker paddle-> 2.5.1镜像安装 paddleSpeech 1.4.0 版本 启动demos/speech_web/speech_server/main.py 报错，求助",
        "body": "采用docker paddle-> 2.5.1镜像安装编译 paddleSpeech 1.4.0 版本的，启动 demos/speech_web/speech_server/main.py 的时候，报如下错误，求助原因：\r\n\r\n[2023-09-05 01:14:41,309] [ WARNING] - The sample rate of the input file is not 16000.\r\n                             The program will resample the wav file to 16000.\r\n                             If the result does not meet your expectations，\r\n                             Please input the 16k 16 bit 1 channel wav file.                         \r\n[2023-09-05 01:14:41,917] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/asr/infer.py\", line 323, in infer\r\n    simulate_streaming=cfg.simulate_streaming)\r\n  File \"/usr/local/lib/python3.7/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 826, in decode\r\n    reverse_weight=reverse_weight)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 66, in <module>\r\n    asr_config, tts_config, asr_init_path, ie_model_path=ie_model_path)\r\n  File \"/opt/paddle/PaddleSpeech/demos/speech_web/speech_server/src/robot.py\", line 26, in __init__\r\n    self.warm_up_asrmodel(asr_init_path)\r\n  File \"/opt/paddle/PaddleSpeech/demos/speech_web/speech_server/src/robot.py\", line 44, in warm_up_asrmodel\r\n    force_yes=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/asr/infer.py\", line 512, in __call__\r\n    res = self.postprocess()  # Retrieve result of asr.\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddlespeech/cli/asr/infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n",
        "state": "open",
        "user": "shujuncernet",
        "closed_by": null,
        "created_at": "2023-09-05T01:29:45+00:00",
        "updated_at": "2023-11-09T05:25:33+00:00",
        "closed_at": null,
        "comments_count": [
            "liduang",
            "diaojinlong",
            "achaosss"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3500,
        "title": "请问tts的Android demo出来了，asr的会出来吗？",
        "body": "我想尝试实现asr的安卓demo，但是失败了，有没有大佬可以提供一下思路和方法？感激不尽\r\n",
        "state": "closed",
        "user": "hzlirz",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-05T01:45:24+00:00",
        "updated_at": "2025-06-27T06:33:44+00:00",
        "closed_at": "2025-06-27T06:33:44+00:00",
        "comments_count": [
            "csukuangfj",
            "hzlirz",
            "csukuangfj",
            "fantasysea",
            "csukuangfj",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3501,
        "title": "如何使用流式部署自己微调好的语音合成(tts)模型",
        "body": "## General Question\r\n如何使用流式部署自己微调好的语音合成(tts)模型\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "GZ315200",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-05T07:08:12+00:00",
        "updated_at": "2025-06-27T03:38:21+00:00",
        "closed_at": "2025-06-27T03:38:21+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3504,
        "title": "麻烦提供下paddleaudio 1.1.0的Python 3.11版本",
        "body": "麻烦提供下paddleaudio 1.1.0的Python 3.11版本，谢谢了。",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2023-09-07T02:20:42+00:00",
        "updated_at": "2024-02-02T08:50:43+00:00",
        "closed_at": "2024-02-02T08:50:43+00:00",
        "comments_count": [
            "yaowt05"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3506,
        "title": "centos 按照安装文档Medium 安装报错",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n\r\n\r\nERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requi\r\nres-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11ERROR: Could not find a version that satisfies the requirement paddleaudio>=1.1.0 (from paddlespeech) (from versions: 0.1.0a0, 0.1.0, 0.2.0, 0.2.1, 1.0.0a0, 1.0.0, 1.0.1, 1.0.2)\r\nERROR: No matching distribution found for paddleaudio>=1.1.0\r\n\r\n\r\n# 使用环境如下\r\n# python3.11.0\r\n# paddlepaddle==2.5.1\r\n# pip 23.2.1\r\n",
        "state": "closed",
        "user": "beixiang-l",
        "closed_by": "beixiang-l",
        "created_at": "2023-09-08T08:12:56+00:00",
        "updated_at": "2023-09-18T03:47:21+00:00",
        "closed_at": "2023-09-18T03:47:21+00:00",
        "comments_count": [
            "young1lin",
            "beixiang-l"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3508,
        "title": "用 CSMSC 数据集训练 FastSpeech2 模型, Cannot import name 'MSRA' from 'paddle.fluid.initializer (..../site-package/fluid/initializer.py)'",
        "body": "hi there,\r\n\r\nBased on the documents, the steps have been followed below:\r\n\r\n1.\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/mfa\r\n\r\n10000 records have been downloaded via https://test.data-baker.com/data/index/TNtts/\r\nThen run ./run.sh successfully.\r\n\r\n2.\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/csmsc/tts3/README_cn.md\r\n\r\n[baker_alignment_tone.tar.gz](https://paddlespeech.bj.bcebos.com/MFA/BZNSYP/with_tone/baker_alignment_tone.tar.gz) Downloaded successfully and run these configs based on the doc.\r\n'假设数据集的路径是 ~/datasets/BZNSYP. 假设CSMSC的MFA结果路径为 ./baker_alignment_tone. 运行下面的命令会进行如下操作...'\r\n\r\n\r\n3.\r\nRun each stage based on docs:\r\n\r\n./run.sh --stage 0 --stop-stage 0  -- successfully\r\n./run.sh --stage 1 --stop-stage 1   -- successfully\r\n./run.sh --stage 2 --stop-stage 2  -- failed, needs to change on file name as the ***.pdz file does not exist, after changing the file name, then re-run successfully\r\n./run.sh --stage 3 --stop-stage 3  -- successfully\r\n./run.sh --stage 4 --stop-stage 4  -- successfully\r\n./run.sh --stage 5 --stop-stage 5  -- successfully\r\n./run.sh --stage 6 --stop-stage 6  -- successfully\r\n./run.sh --stage 7 --stop-stage 7  -- successfully\r\n./run.sh --stage 8 --stop-stage 8  -- successfully\r\n./run.sh --stage 9 --stop-stage 9  -- failed\r\n./run.sh --stage 10 --stop-stage 10  -- failed\r\n\r\nBoth stages 9 and 10 failed with the below error:\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/8235746/285e06cd-d558-4e4d-ade9-b951b9d95af9)\r\n\r\n\r\nAnd versions of paddle packages installed as below:\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/8235746/81225a49-2ced-4f50-a3f8-6fc36072abdd)\r\n\r\n\r\nWill you please have a look at the issue, If any update please let me know.\r\n\r\nBR\r\nKimi\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "quzhixue-Kimi",
        "closed_by": "quzhixue-Kimi",
        "created_at": "2023-09-11T01:32:47+00:00",
        "updated_at": "2023-09-13T07:57:33+00:00",
        "closed_at": "2023-09-13T07:57:32+00:00",
        "comments_count": [
            "quzhixue-Kimi"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3507,
        "title": "paddlespeech唤醒词实例运行",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n运行hey_snips模型，需要有hey_snip的数据集，数据集现在无法下载，请问有没有分享的hey_snip数据集。如果要做自定义唤醒词，应该怎么制造数据集。\r\n",
        "state": "closed",
        "user": "wubo2180",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-10T08:49:17+00:00",
        "updated_at": "2025-06-27T05:32:54+00:00",
        "closed_at": "2025-06-27T05:32:54+00:00",
        "comments_count": [
            "Change0028",
            "xs818818",
            "qingjiaozyn",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3511,
        "title": "[TTS]跟着ljsspeech/tts3/readmd.md将原始数据集分为train,dev,test步骤出错",
        "body": "\r\n**Describe the bug**\r\n根据 https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/ljspeech/tts3#data-preprocessing 描述，在数据预处理部分 命令`./local/preprocess.sh ${conf_path}` **当脚本运行结束，dump会在当前目前创建一个文件夹。**\r\n```\r\ndump\r\n├── dev\r\n│   ├── norm\r\n│   └── raw\r\n├── phone_id_map.txt\r\n├── speaker_id_map.txt\r\n├── test\r\n│   ├── norm\r\n│   └── raw\r\n└── train\r\n    ├── energy_stats.npy\r\n    ├── norm\r\n    ├── pitch_stats.npy\r\n    ├── raw\r\n    └── speech_stats.npy\r\n```\r\n实际运行情况是报错\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/hs/TTS/PaddleSpeech-develop/utils/compute_statistics.py\", line 109, in <module>\r\n    main()\r\n  File \"/home/hs/TTS/PaddleSpeech-develop/utils/compute_statistics.py\", line 84, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/home/hs/TTS/paddlespeech_venv/lib/python3.10/site-packages/jsonlines/jsonlines.py\", line 643, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/train/raw/metadata.jsonl'\r\n```\r\n在本地也无法找到内容文件夹。\r\n**Additional context**\r\n使用的是自己的数据集，靠硬找脚本里面的python文件，已经生成了一个 `durations.txt` 。**我的需求是，指条明路去找音频的包含标准化的特征`*.npy`文件的方法。**\r\n\r\n我的数据集排列也如下格式 \r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/76671016/8ab76d7e-7eeb-4588-9ebc-c6905fc217a7)\r\n",
        "state": "open",
        "user": "danyow-cheung",
        "closed_by": null,
        "created_at": "2023-09-11T09:12:32+00:00",
        "updated_at": "2023-09-11T09:12:32+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3509,
        "title": "流式语音识别服务为什么客户端还是以.wav文件进行请求呢？",
        "body": "## General Question\r\n如题，这个流式语音识别也还是上传.wav文件，我理解的流式语音识别应该是在实时监听话筒的声音这样的形式，请问这个该如何理解呢，期待解惑，感谢感谢？\r\n",
        "state": "closed",
        "user": "yangyuke001",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-11T05:56:03+00:00",
        "updated_at": "2025-06-27T05:32:37+00:00",
        "closed_at": "2025-06-27T05:32:37+00:00",
        "comments_count": [
            "yaleimeng",
            "LiWeisuper",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3510,
        "title": "Request requrements.txt for paddlespeech traning period ",
        "body": "## Feature Request\r\n\r\n在Ubuntu系统中，编译的paddlepaddle-gpu版本，然后直接 install paddlespeech，但是在后期想用paddlespeech框架做训练的，发现conda虚拟环境缺这个包缺那个包，可否提供训练所需的requrements.txt ",
        "state": "closed",
        "user": "danyow-cheung",
        "closed_by": "danyow-cheung",
        "created_at": "2023-09-11T07:00:44+00:00",
        "updated_at": "2023-09-11T08:51:35+00:00",
        "closed_at": "2023-09-11T08:51:35+00:00",
        "comments_count": [
            "danyow-cheung"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3512,
        "title": "关于符号生成语音的问题",
        "body": "大家好，我这里有一个疑问，我想生成这样一段语音，文本中有#号，我想最终得到的语音里把#号，读成井号，应该怎么实现？",
        "state": "closed",
        "user": "cywjava",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-12T01:18:56+00:00",
        "updated_at": "2025-06-27T04:34:13+00:00",
        "closed_at": "2025-06-27T04:34:13+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3513,
        "title": " cannot import name 'libpaddle' from partially initialized module 'paddle.fluid' ",
        "body": "(venv_ocr) (base) miaog001@C02DWCXFMD6M Downloads % paddlespeech asr --lang zh --input zh.wav\r\nTraceback (most recent call last):\r\n  File \"/Users/miaog001/opt/anaconda3/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/fluid/core.py\", line 356, in <module>\r\n    raise e\r\n  File \"/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: cannot import name 'libpaddle' from partially initialized module 'paddle.fluid' (most likely due to a circular import) (/Users/miaog001/opt/anaconda3/lib/python3.9/site-packages/paddle/fluid/__init__.py)\r\n",
        "state": "open",
        "user": "xiaoyaoamiao",
        "closed_by": null,
        "created_at": "2023-09-12T02:53:46+00:00",
        "updated_at": "2025-04-26T03:46:05+00:00",
        "closed_at": null,
        "comments_count": [
            "xiaoyaoamiao",
            "imomoe233",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3515,
        "title": "请问docker镜像是否包含TTS男生语音模型呢？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "houzimm",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-12T03:13:12+00:00",
        "updated_at": "2025-06-27T03:38:25+00:00",
        "closed_at": "2025-06-27T03:38:25+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3516,
        "title": "前端接不上后端，websocket 链接失败，请检查Websocket 后端服务是否正确开启 ",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/53518009/8562117c-5eca-4cf6-a0ae-376eec066ff5)请问有解决方法吗？vue3连接不了websocket，python写的websocket客户端能连接并返回所需结果",
        "state": "closed",
        "user": "aiquanpeng",
        "closed_by": "aiquanpeng",
        "created_at": "2023-09-12T07:14:51+00:00",
        "updated_at": "2023-09-12T09:15:51+00:00",
        "closed_at": "2023-09-12T09:15:50+00:00",
        "comments_count": [
            "aiquanpeng"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3518,
        "title": "请问tts_finetune怎么训练多音色",
        "body": "tts_finetune训练多音色时，怎么存放多人的数据集，\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/111211084/df6590dc-96e8-4a64-b889-f35517b17010)\r\n在案例中只有csmsc_mini，并且在run_mix.sh中直接指向了该目录，是不是还得修改run_mix.sh中的文件\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/111211084/eb9189d9-c88f-419e-8ace-44cabf4848ae)\r\n",
        "state": "closed",
        "user": "liuxuanfeng3364",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-14T01:53:40+00:00",
        "updated_at": "2025-06-27T03:38:26+00:00",
        "closed_at": "2025-06-27T03:38:26+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3519,
        "title": "哪位大佬帮忙看看这是什么问题啊",
        "body": "Collecting pyworld==0.2.12 (from paddlespeech==1.2.0)\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/af/88/003eef396c966cf00088900167831946b80b8e7650843905cb9590c2d9ca/pyworld-0.2.12.tar.gz (222 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Installing backend dependencies ... done\r\n  Preparing metadata (pyproject.toml) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × Preparing metadata (pyproject.toml) did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [70 lines of output]\r\n      running dist_info\r\n      creating /tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info\r\n      writing /tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info/PKG-INFO\r\n      writing dependency_links to /tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info/dependency_links.txt\r\n      writing requirements to /tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info/requires.txt\r\n      writing top-level names to /tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info/top_level.txt\r\n      writing manifest file '/tmp/pip-modern-metadata-r0nxf4uv/pyworld.egg-info/SOURCES.txt'\r\n      /tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\r\n      !!\r\n      \r\n              ********************************************************************************\r\n              Usage of dash-separated 'description-file' will not be supported in future\r\n              versions. Please use the underscore name 'description_file' instead.\r\n      \r\n              By 2023-Sep-26, you need to update your project and remove deprecated calls\r\n              or your builds will no longer be supported.\r\n      \r\n              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\r\n              ********************************************************************************\r\n      \r\n      !!\r\n        opt = self.warn_dash_deprecation(opt, section)\r\n      Traceback (most recent call last):\r\n        File \"/usr/local/python3/lib/python3.8/site-packages/pip-23.2.1-py3.8.egg/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"/usr/local/python3/lib/python3.8/site-packages/pip-23.2.1-py3.8.egg/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n        File \"/usr/local/python3/lib/python3.8/site-packages/pip-23.2.1-py3.8.egg/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 149, in prepare_metadata_for_build_wheel\r\n          return hook(metadata_directory, config_settings)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 396, in prepare_metadata_for_build_wheel\r\n          self.run_setup()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 507, in run_setup\r\n          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 341, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 43, in <module>\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/__init__.py\", line 103, in setup\r\n          return distutils.core.setup(**attrs)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n          return run_commands(dist)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n          dist.run_commands()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n          self.run_command(cmd)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/dist.py\", line 989, in run_command\r\n          super().run_command(command)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n          cmd_obj.run()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/dist_info.py\", line 107, in run\r\n          self.egg_info.run()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 318, in run\r\n          self.find_sources()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 326, in find_sources\r\n          mm.run()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 548, in run\r\n          self.add_defaults()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 586, in add_defaults\r\n          sdist.add_defaults(self)\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/command/sdist.py\", line 113, in add_defaults\r\n          super().add_defaults()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/command/sdist.py\", line 251, in add_defaults\r\n          self._add_defaults_ext()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/command/sdist.py\", line 335, in _add_defaults_ext\r\n          build_ext = self.get_finalized_command('build_ext')\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 305, in get_finalized_command\r\n          cmd_obj.ensure_finalized()\r\n        File \"/tmp/pip-build-env-y483rx0l/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 111, in ensure_finalized\r\n          self.finalize_options()\r\n        File \"<string>\", line 29, in finalize_options\r\n      AttributeError: 'dict' object has no attribute '__NUMPY_SETUP__'\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n× Encountered error while generating package metadata.\r\n╰─> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.",
        "state": "closed",
        "user": "itxiaoou",
        "closed_by": "itxiaoou",
        "created_at": "2023-09-14T09:36:51+00:00",
        "updated_at": "2023-11-28T08:52:36+00:00",
        "closed_at": "2023-09-15T07:24:08+00:00",
        "comments_count": [
            "thinkboy"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3524
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3520,
        "title": "ImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers'",
        "body": "系统：windows\r\nPython 3.11.5\r\n\r\n安装的CPU版本\r\npython -m pip install paddlepaddle==2.5.1 -i https://mirror.baidu.com/pypi/simple\r\n\r\n然后\r\npip install paddlespeech -i https://pypi.tuna.tsinghua.edu.cn/simple\r\n\r\n**此时numpy 版本为numpy-1.24.4**\r\n\r\n运行 paddlespeech cls --input zh.wav\r\n\r\nPS D:\\work\\mgsdk\\doc> paddlespeech cls --input zh.wav\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts\\paddlespeech.exe\\__main__.py\", line 4, in <module>\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\paddlespeech\\cli\\__init__.py\", line 16, in <module>\r\n    from .asr import ASRExecutor\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\paddlespeech\\cli\\asr\\__init__.py\", line 14, in <module>\r\n    from .infer import ASRExecutor\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 22, in <module>\r\n    import librosa\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\__init__.py\", line 9, in <module>\r\n    from .constantq import *  # pylint: disable=wildcard-import\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\constantq.py\", line 1059, in <module>\r\n    dtype=np.complex,\r\n          ^^^^^^^^^^\r\n  File \"C:\\Users\\mghua\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\__init__.py\", line 305, in __getattr__\r\n    raise AttributeError(__former_attrs__[attr])\r\nAttributeError: module 'numpy' has no attribute 'complex'.\r\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'complex_'?\r\n\r\n**将constantq.py中的np.complex， 改为 complex后，就又显示 \r\n\r\nImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers'**\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "openersoft",
        "closed_by": "openersoft",
        "created_at": "2023-09-14T11:04:20+00:00",
        "updated_at": "2025-03-17T04:21:32+00:00",
        "closed_at": "2024-03-04T03:52:31+00:00",
        "comments_count": [
            "BoredWait",
            "yaleimeng",
            "secext2022",
            "sunqinbo",
            "happywch",
            "openersoft",
            "pdxrlj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3521,
        "title": "[S2T] Index error: list index out of range",
        "body": "I tried an inference with ReadMe's guide.\r\nWhile doing inference, got the following error.\r\n\r\n```terminal\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Elsa\\anaconda3\\envs\\pytorch\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"C:\\Users\\Elsa\\anaconda3\\envs\\pytorch\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"C:\\Users\\Elsa\\anaconda3\\envs\\pytorch\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Elsa\\anaconda3\\envs\\pytorch\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"C:\\Users\\Elsa\\anaconda3\\envs\\pytorch\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\n```\r\nIt seems the package wants the matched batch size. But while debugging, found even their type mismatched.\r\n\r\n**To Reproduce**\r\n\r\n```python\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\n```\r\n**Environment**\r\n - OS: Win 10\r\n - Python Version 3.10.12\r\n - PaddlePaddle Version 2.5.1\r\n\r\n",
        "state": "open",
        "user": "Yoloex",
        "closed_by": null,
        "created_at": "2023-09-14T15:28:49+00:00",
        "updated_at": "2023-10-30T09:41:26+00:00",
        "closed_at": null,
        "comments_count": [
            "1416924176",
            "neuxys",
            "yaowt05",
            "OOXXXXOO",
            "mrzjl"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3522,
        "title": "为啥我安装后没有paddlespeech_server这个命令？",
        "body": "![1694762572038](https://github.com/PaddlePaddle/PaddleSpeech/assets/45225964/e2e0ef75-f4c3-4915-8324-2e33544d9354)\r\n",
        "state": "closed",
        "user": "itxiaoou",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-15T07:23:37+00:00",
        "updated_at": "2025-06-27T05:32:38+00:00",
        "closed_at": "2025-06-27T05:32:38+00:00",
        "comments_count": [
            "ghost",
            "agclqq",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3523,
        "title": "[TTS] Aborted (core dumped) after determining tmp storage requirements for inclusive_scan: cudaErrorInvalidDeviceFunction: invalid device function",
        "body": "Can anyone help me?\r\n\r\nERROR: \r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/7b425240-5232-413f-9858-4c9b167979e1)\r\n\r\n\r\n\r\nEnvironment\r\n - OS:\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/af0cfe1e-faef-4442-9e79-3a5d0dfac5b4)\r\n\r\n - GCC/G++ Version \r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/b8f16130-0108-4c9c-858b-6e10453911d6)\r\n\r\n - Python Version \r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/d6016341-55b6-412a-abfc-d519ebb7136d)\r\n\r\n - PaddlePaddle Version\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/84d94c34-562c-4ab4-9983-63cfe4598c32)\r\n\r\n - Model Version [default]\r\n\r\n - GPU/DRIVER Informationo \r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/89de24be-fa11-4f6b-969b-bec7babd133f)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/64fe5822-3944-44c7-9a6f-0029d6258d88)\r\n\r\n - CUDA/CUDNN Version\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/7507589/691124ab-6ba1-4c8c-af44-2af876273e15)\r\n\r\n - MKL Version [unused]\r\n\r\n- TensorRT Version [unused]\r\n\r\n",
        "state": "closed",
        "user": "neuxys",
        "closed_by": "neuxys",
        "created_at": "2023-09-15T14:57:40+00:00",
        "updated_at": "2023-09-21T06:59:15+00:00",
        "closed_at": "2023-09-21T06:59:14+00:00",
        "comments_count": [
            "neuxys",
            "neuxys",
            "neuxys",
            "neuxys",
            "neuxys",
            "neuxys",
            "neuxys",
            "neuxys"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3525,
        "title": "如何从直播流提取声音并实时将语言转换成文本",
        "body": "[2023-09-18 02:44:45,433] [    INFO] - client receive msg={'result': '我有'}\r\n[2023-09-18 02:44:45,438] [    INFO] - client receive msg={'result': '我有'}\r\n[2023-09-18 02:44:45,446] [    INFO] - client receive msg={'result': '我有'}\r\n[2023-09-18 02:44:45,452] [    INFO] - client receive msg={'result': '我有'}\r\n[2023-09-18 02:44:45,461] [    INFO] - client receive msg={'result': '我有'}\r\n[2023-09-18 02:44:45,920] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,936] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,945] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,952] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,960] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,971] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,979] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:45,990] [    INFO] - client receive msg={'result': '我有截图有真需'}\r\n[2023-09-18 02:44:46,529] [    INFO] - client receive msg={'result': '我有截图有真需要好的'}\r\n[2023-09-18 02:44:46,537] [    INFO] - client receive msg={'result': '我有截图有真需要好的'}\r\n[2023-09-18 02:44:46,550] [    INFO] - client receive msg={'result': '我有截图有真需要好的'}\r\n[2023-09-18 02:44:46,556] [    INFO] - client receive msg={'result': '我有截图有真需要好的'}\r\n搭建的服务可以输出这些log但是python无法实时读取这些处理结果，要等到一个几十分钟的mp4播放完成才能输出完整的结果，显然是有问题\r\n\r\n想问下如何拉取一个直播视频流然后实时提取音频并实时返回音频识别后的文字内容。\r\n\r\n谢谢",
        "state": "closed",
        "user": "jackbbhua",
        "closed_by": "jackbbhua",
        "created_at": "2023-09-17T18:51:26+00:00",
        "updated_at": "2025-01-05T11:47:26+00:00",
        "closed_at": "2025-01-05T11:47:26+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3529,
        "title": "[TTS]在使用中英文混合模型fastspeech2_male 不会报错，而fastspeech2_mix时一直报错！",
        "body": "具体代码为：\r\n`import paddle\r\nfrom paddlespeech.cli.tts import TTSExecutor\r\n\r\ndef tts(text,output):\r\n    #paddle.device.set_device('gpu:0')\r\n    tts_executor = TTSExecutor()\r\n    wav_file = tts_executor(\r\n        text=text,\r\n        output=output,\r\n        am='fastspeech2_mix',\r\n        am_config=None,\r\n        am_ckpt=None,\r\n        am_stat=None,\r\n        spk_id=0,\r\n        phones_dict=None,\r\n        tones_dict=None,\r\n        speaker_dict=None,\r\n        voc='hifigan_aishell3',\r\n        voc_config=None,\r\n        voc_ckpt=None,\r\n        voc_stat=None,\r\n        lang='mix',\r\n        device=paddle.get_device())\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    text = \"你好我的名字是Peter，你好\"\r\n    path  = \"test中英文混合.wav\"\r\n    tts(text, path)`\r\n\r\n其他的voc都尝试了，只要是mix就会报这个错误\r\n\r\n报错信息为：\r\nTraceback (most recent call last):\r\n  File \"/home/hsy/test中英.py\", line 30, in <module>\r\n    tts(text, path)\r\n  File \"/home/hsy/test中英.py\", line 7, in tts\r\n    wav_file = tts_executor(\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py\", line 710, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py\", line 493, in infer\r\n    mel = self.am_inference(\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 920, in forward\r\n    normalized_mel, d_outs, p_outs, e_outs = self.acoustic_model.inference(\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 810, in inference\r\n    _, outs, d_outs, p_outs, e_outs, _ = self._forward(\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 618, in _forward\r\n    hs = self._integrate_with_spk_embed(hs, spk_emb)\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 840, in _integrate_with_spk_embed\r\n    spk_emb = F.normalize(spk_emb).unsqueeze(1).expand(\r\n  File \"/home/Lyx/Software/anaconda3/envs/langchain/lib/python3.8/site-packages/paddle/nn/functional/norm.py\", line 82, in normalize\r\n    out = _C_ops.p_norm(x, float(p), axis, epsilon, True, False)\r\nValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[256].\r\n  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at ../paddle/phi/infermeta/unary.cc:2763)\r\n\r\n请问该怎么办呢？",
        "state": "open",
        "user": "FavoriteStar",
        "closed_by": null,
        "created_at": "2023-09-20T07:58:51+00:00",
        "updated_at": "2024-07-30T06:17:43+00:00",
        "closed_at": null,
        "comments_count": [
            "whtwhtw",
            "sujianwei1",
            "zqkou"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3528,
        "title": "Suggestions for using different PaddleSpeech versions",
        "body": "For now that users currently have many version management issues when using PaddleSpeech, given some suggestions for using different versions are provided here.\r\n\r\nPaddleSpeech == develop --> PaddlePaddle == 2.5.0/2.5.1\r\nPaddleSpeech <= 1.4.1 --> PaddlePaddle <= 2.4.2",
        "state": "open",
        "user": "zxcd",
        "closed_by": null,
        "created_at": "2023-09-19T03:57:23+00:00",
        "updated_at": "2025-04-26T03:46:23+00:00",
        "closed_at": null,
        "comments_count": [
            "BoredWait",
            "sunqinbo",
            "zxcd",
            "hjhcos",
            "wukaikailive",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3530,
        "title": "[TTS] The base64 data returned by the tts interface is faulty.  tts语音合成接口返回base64数据有误。",
        "body": "English\r\nbase64 data returned by a webSocket connection cannot be played in the <audio> tag of the browser, nor can it be played locally after being saved as an mp3 file. \r\nHowever, my local mp3 file can be played normally on the browser after being converted to base64 data. And I don't see any difference between the two base64 data. \r\nSo I suspect that the data returned by the interface is wrong, and I hope it can be solved. \r\nIn the end, I don't think it's the parameters, because I'm using sample parameters. It's also not a problem with the interface address, because I can receive all the data normally.\r\n\r\nInterface address:   ws://{server}:{port}/paddlespeech/tts/streaming\r\n\r\n中文：\r\n使用tts接口，通过webSocket连接返回的base64数据无法在浏览器的<audio>标签上播放，保存为mp3文件后也无法在本地播放，但是我本地的mp3文件转为base64数据后，可以在浏览器上正常播放，而且我没有发现这两个base64数据有什么区别。\r\n所以我怀疑是接口返回的数据错了，希望能得到解决。\r\n最后，我认为不是参数的问题，因为我使用的是示例参数。同时也并非接口地址的问题，因为我能正常接收到所有数据。\r\n\r\n接口地址： ws://{server}:{port}/paddlespeech/tts/streaming\r\n\r\n",
        "state": "open",
        "user": "AnnCY1",
        "closed_by": null,
        "created_at": "2023-09-21T03:05:29+00:00",
        "updated_at": "2024-03-15T07:33:30+00:00",
        "closed_at": null,
        "comments_count": [
            "AnnCY1",
            "bchengwang",
            "GiterRUOK"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3533,
        "title": "Windows conda paddlespeech_server 启动错误",
        "body": "win10下,conda 创建的python3.10环境,\r\n安装官网的默认安装:\r\npip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\r\npip install pytest-runner\r\npip install paddlespeech\r\ngit 最新的paddlspeech,到目录下执行\r\npaddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\r\n1:启动后报告一个numpy错误,修改为 1.23.5版本,错误消失.\r\n2:继续启动,出现如下错误,搜索不到具体的问题.\r\n\r\nC:\\Users\\u\\.conda\\envs\\ppspeech2\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\n  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\n[2023-09-26 12:59:07,776] [    INFO] - start to init the engine\r\n[2023-09-26 12:59:07,777] [    INFO] - asr : python engine.\r\n2023-09-26 12:59:12.950 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2023-09-26 12:59:13.166 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2023-09-26 12:59:20,762] [    INFO] - Initialize ASR server engine successfully on device: cpu.\r\n[2023-09-26 12:59:20,763] [    INFO] - tts : python engine.\r\n[2023-09-26 12:59:29,504] [   ERROR] - Failed to get model related files.\r\n[2023-09-26 12:59:29,505] [   ERROR] - Initialize TTS server engine Failed on device: cpu.\r\n[2023-09-26 12:59:29,506] [   ERROR] - This ORT build has ['AzureExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['AzureExecutionProvider', 'CPUExecutionProvider'], ...)\r\n\r\n\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/6842094/2200f04a-5af2-4e37-9cc4-ad4cef1e0a6a)\r\n\r\n这里有一个错误,但是我没有自己整合,只是想运行官网server,提供http服务.\r\nhttps://blog.csdn.net/qq_23953717/article/details/128657301 \r\n\r\n如果是重复问题抱歉啦,搜索不到!\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "matakk",
        "closed_by": "matakk",
        "created_at": "2023-09-26T05:17:27+00:00",
        "updated_at": "2023-09-27T13:45:06+00:00",
        "closed_at": "2023-09-27T13:45:06+00:00",
        "comments_count": [
            "winlinvip",
            "matakk"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3534,
        "title": "[TTS]Please search for the error code(7) on website (https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus_t) to get Nvidia's official solution and advice about CUBLAS Error.] (at /paddle/paddle/phi/backends/gpu/gpu_context.cc:593)",
        "body": "大神们好。我再训练TTS的时候，出现这个错误：\r\n```\r\nException in main training loop: (External) CUBLAS error(7). \r\n  [Hint: Please search for the error code(7) on website (https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus_t) to get Nvidia's official solution and advice about CUBLAS Error.] (at /paddle/paddle/phi/backends/gpu/gpu_context.cc:593)\r\n  [operator < linear > error]\r\nTraceback (most recent call last):\r\nException in main training loop: (External) CUBLAS error(7). \r\n  [Hint: Please search for the error code(7) on website (https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus_t) to get Nvidia's official solution and advice about CUBLAS Error.] (at /paddle/paddle/phi/backends/gpu/gpu_context.cc:593)\r\n  [operator < linear > error]\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 86, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens, spk_logits = self.model(\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py\", line 774, in forward\r\n    outputs = self._layers(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 573, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, spk_logits = self._forward(\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 608, in _forward\r\n    hs, _ = self.encoder(xs, x_masks)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 86, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens, spk_logits = self.model(\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py\", line 774, in forward\r\n    outputs = self._layers(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/encoder.py\", line 424, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 573, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, spk_logits = self._forward(\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 608, in _forward\r\n    hs, _ = self.encoder(xs, x_masks)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/encoder.py\", line 424, in forward\r\n    xs, masks = self.encoders(xs, masks)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 99, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/repeat.py\", line 25, in forward\r\n    args = m(*args)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/attention.py\", line 140, in forward\r\n    q, k, v = self.forward_qkv(query, key, value)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/attention.py\", line 72, in forward_qkv\r\n    self.linear_q(query), [n_batch, -1, self.h, self.d_k])\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/encoder_layer.py\", line 99, in forward\r\n    x = residual + self.dropout(self.self_attn(x_q, x, x, mask))\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/nn/layer/common.py\", line 175, in forward\r\n    out = F.linear(\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/attention.py\", line 140, in forward\r\n    q, k, v = self.forward_qkv(query, key, value)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/nn/functional/common.py\", line 1882, in linear\r\n    return _C_ops.linear(x, weight, bias)\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/modules/transformer/attention.py\", line 72, in forward_qkv\r\n    self.linear_q(query), [n_batch, -1, self.h, self.d_k])\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/nn/layer/common.py\", line 175, in forward\r\n    out = F.linear(\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/nn/functional/common.py\", line 1882, in linear\r\n    return _C_ops.linear(x, weight, bias)\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Trainer extensions will try to handle the extension. Then all extensions will finalize.I0926 17:10:01.418354  6365 tcp_store.cc:257] receive shutdown event and so quit from MasterDaemon run loop\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/train.py\", line 234, in <module>\r\n    main()\r\n  File \"/ultra/fffan/0_TTS/00_relevant_experiment/PaddleSpeech-develop/paddlespeech/t2s/exps/fastspeech2/train.py\", line 228, in main\r\n    dist.spawn(train_sp, (args, config), nprocs=args.ngpu)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/distributed/spawn.py\", line 606, in spawn\r\n    while not context.join():\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/distributed/spawn.py\", line 413, in join\r\n    self._throw_exception(error_index)\r\n  File \"/root/anaconda3/envs/paddle_py38/lib/python3.8/site-packages/paddle/distributed/spawn.py\", line 431, in _throw_exception\r\n    raise Exception(msg)\r\nException: \r\n\r\n----------------------------------------------\r\nProcess 0 terminated with the following error:\r\n----------------------------------------------\r\n\r\n```\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: **centos7**\r\n - GCC/G++ Version\r\n - Python Version：**python 3.8**\r\n - PaddlePaddle Version：**2.4.1.post11.6**\r\n - GPU/DRIVER Informationo：**Tesla V100**\r\n - CUDA/CUDNN Version ：**cuda-11.6**\r\n\r\n请问这个错误是啥情况啊\r\n",
        "state": "open",
        "user": "Tian14267",
        "closed_by": null,
        "created_at": "2023-09-26T09:15:55+00:00",
        "updated_at": "2023-09-26T09:34:23+00:00",
        "closed_at": null,
        "comments_count": [
            "Tian14267",
            "Tian14267"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3531,
        "title": "asr restful 参数中除了audio外，其他的好像都没使用",
        "body": "![Snip20230922_2](https://github.com/PaddlePaddle/PaddleSpeech/assets/7626261/f02b813d-0baa-4571-8e07-34b2e1c69deb)\r\n这是paddlespeech/server/restful/asr_api.py的代码，文档中关于这个接口的传参格式是这样的：\r\ndata = {\r\n    'audio': base64_data,\r\n    'audio_format': 'wav',\r\n    'lang': 'zh_cn',\r\n    'sample_rate': 16000,\r\n    'punc': 1\r\n}\r\n接口代码里ASRRequest也确实限定了参数格式。但是接口逻辑里仅使用了request_body中的audio参数，那audio_format、lang、punc、sample_rate 到底起了什么作用呢。我在使用restful 请求这个接口时，除了audio参数外，设置了其他参数是没作用的",
        "state": "closed",
        "user": "hbo-lambda",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-22T03:19:34+00:00",
        "updated_at": "2025-06-27T04:34:21+00:00",
        "closed_at": "2025-06-27T04:34:21+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3535,
        "title": "tts_finetue run.sh stage 5 报错",
        "body": "install paddlepaddle >=2.50, I ger follow error:\r\n```\r\n/root/miniconda3/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/root/miniconda3/lib/python3.8/site-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/root/miniconda3/lib/python3.8/site-packages/paddle/nn/layer/norm.py:777: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\nException in main training loop: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\nTraceback (most recent call last):\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 335, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1243, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 995, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 800, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 118, in update_core\r\n    optimizer.step()\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 335, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 462, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 446, in step\r\n    optimize_ops = self._apply_optimize(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 1243, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 995, in _create_optimization_pass\r\n    self._create_accumulators(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 278, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/adam.py\", line 231, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/optimizer/optimizer.py\", line 800, in _add_accumulator\r\n    var.set_value(self._accumulators_holder.pop(var_name))\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 196, in set_value\r\n    assert self.shape == list(\r\nAssertionError: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\n```\r\ninstall paddlepaddle  == 2.4.2 , I ger follow error:\r\n```\r\nError: Can not import paddle core while this file exists: /root/miniconda3/lib/python3.8/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"local/finetune.py\", line 23, in <module>\r\n    import paddle\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 37, in <module>\r\n    from . import core\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/core.py\", line 338, in <module>\r\n    raise e\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/core.py\", line 274, in <module>\r\n    from . import libpaddle\r\nImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory\r\n```\r\nwhen export LD_LIBRARY_PATH=/root/work1/miniconda3/lib/:$LD_LIBRARY_PATH,  with paddlepaddle==2.4.2 and libcudart.so.10.2 is in the path of \"/root/work1/miniconda3/lib\",  get follow  error:\r\n```\r\nException in main training loop: (InvalidArgument) The value (1059020352) of the non-singleton dimension does not match the corresponding value (1074197479) in shape for expand_v2 op.\r\n  [Hint: Expected vec_in_dims[i] == expand_shape[i], but received vec_in_dims[i]:1059020352 != expand_shape[i]:1074197479.] (at /paddle/paddle/phi/kernels/impl/expand_kernel_impl.h:61)\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 86, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens, spk_logits = self.model(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 573, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, spk_logits = self._forward(\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 606, in _forward\r\n    x_masks = self._source_mask(ilens)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 896, in _source_mask\r\n    x_masks = make_non_pad_mask(ilens)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 296, in make_non_pad_mask\r\n    return paddle.logical_not(make_pad_mask(lengths, xs, length_dim))\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 192, in make_pad_mask\r\n    seq_range_expand = seq_range.unsqueeze(0).expand([bs, maxlen])\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 3397, in expand\r\n    return _C_ops.expand(x, shape)\r\nTrainer extensions will try to handle the extension. Then all extensions will finalize.Traceback (most recent call last):\r\n  File \"local/finetune.py\", line 269, in <module>\r\n    train_sp(train_args, config)\r\n  File \"local/finetune.py\", line 202, in train_sp\r\n    trainer.run()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 198, in run\r\n    six.reraise(*exc_info)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/trainer.py\", line 149, in run\r\n    update()\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/training/updaters/standard_updater.py\", line 110, in update\r\n    self.update_core(batch)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2_updater.py\", line 86, in update_core\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, ys, olens, spk_logits = self.model(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 573, in forward\r\n    before_outs, after_outs, d_outs, p_outs, e_outs, spk_logits = self._forward(\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 606, in _forward\r\n    x_masks = self._source_mask(ilens)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 896, in _source_mask\r\n    x_masks = make_non_pad_mask(ilens)\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 296, in make_non_pad_mask\r\n    return paddle.logical_not(make_pad_mask(lengths, xs, length_dim))\r\n  File \"/root/work1/ybZhang/PaddleSpeech/paddlespeech/t2s/modules/nets_utils.py\", line 192, in make_pad_mask\r\n    seq_range_expand = seq_range.unsqueeze(0).expand([bs, maxlen])\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 3397, in expand\r\n    return _C_ops.expand(x, shape)\r\nValueError: (InvalidArgument) The value (1059020352) of the non-singleton dimension does not match the corresponding value (1074197479) in shape for expand_v2 op.\r\n  [Hint: Expected vec_in_dims[i] == expand_shape[i], but received vec_in_dims[i]:1059020352 != expand_shape[i]:1074197479.] (at /paddle/paddle/phi/kernels/impl/expand_kernel_impl.h:61)\r\n```",
        "state": "closed",
        "user": "ben-8878",
        "closed_by": "ben-8878",
        "created_at": "2023-09-27T09:02:12+00:00",
        "updated_at": "2025-07-02T09:45:02+00:00",
        "closed_at": "2025-07-02T09:45:02+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3539
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3536,
        "title": "paddlespeech r1.4.1 附带的 paddleaudio 构建 wheel 报错",
        "body": "## 构建时报错信息\r\n\r\n```bash\r\n# 在 PaddleSpeech/audio 目录下执行该命令\r\n$ python setup.py bdist_wheel\r\n...\r\n[75/84] /usr/bin/c++ -DCOMPILE_WITHOUT_OPENFST -DINCLUDE_KALDI -DINCLUDE_SOX -D_paddleaudio_EXPORTS -I/home/orangepi/Downloads/PaddleSpeech/audio/fc_patch/pybind11/include -I/home/orangepi/miniconda3/envs/mplug_owl/include/python3.10 -I/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/third_party -I/home/orangepi/Downloads/PaddleSpeech/audio -I/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/third_party/sox/../install/include -O3 -DNDEBUG -fPIC -std=gnu++14 -MD -MT paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o -MF paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o.d -o paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o -c /home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.cpp\r\nFAILED: paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o \r\n/usr/bin/c++ -DCOMPILE_WITHOUT_OPENFST -DINCLUDE_KALDI -DINCLUDE_SOX -D_paddleaudio_EXPORTS -I/home/orangepi/Downloads/PaddleSpeech/audio/fc_patch/pybind11/include -I/home/orangepi/miniconda3/envs/mplug_owl/include/python3.10 -I/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/third_party -I/home/orangepi/Downloads/PaddleSpeech/audio -I/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/third_party/sox/../install/include -O3 -DNDEBUG -fPIC -std=gnu++14 -MD -MT paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o -MF paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o.d -o paddleaudio/src/CMakeFiles/_paddleaudio.dir/pybind/sox/types.cpp.o -c /home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.cpp\r\nIn file included from /home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.cpp:3:\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:23:42: error: ‘string’ in namespace ‘std’ does not name a type\r\n   23 | Format get_format_from_string(const std::string& format);\r\n      |                                          ^~~~~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:6:1: note: ‘std::string’ is defined in header ‘<string>’; did you forget to ‘#include <string>’?\r\n    5 | #include \"paddleaudio/src/optional/optional.hpp\"\r\n  +++ |+#include <string>\r\n    6 | \r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:41:6: error: ‘string’ in namespace ‘std’ does not name a type\r\n   41 | std::string to_string(Encoding v);\r\n      |      ^~~~~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:41:1: note: ‘std::string’ is defined in header ‘<string>’; did you forget to ‘#include <string>’?\r\n   41 | std::string to_string(Encoding v);\r\n      | ^~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:42:59: error: ‘string’ is not a member of ‘std’\r\n   42 | Encoding get_encoding_from_option(const tl::optional<std::string> encoding);\r\n      |                                                           ^~~~~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:42:59: note: ‘std::string’ is defined in header ‘<string>’; did you forget to ‘#include <string>’?\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:42:59: error: ‘string’ is not a member of ‘std’\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:42:59: note: ‘std::string’ is defined in header ‘<string>’; did you forget to ‘#include <string>’?\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:42:65: error: template argument 1 is invalid\r\n   42 | Encoding get_encoding_from_option(const tl::optional<std::string> encoding);\r\n      |                                                                 ^\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:53:55: error: ‘int64_t’ was not declared in this scope\r\n   53 | BitDepth get_bit_depth_from_option(const tl::optional<int64_t> bit_depth);\r\n      |                                                       ^~~~~~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:6:1: note: ‘int64_t’ is defined in header ‘<cstdint>’; did you forget to ‘#include <cstdint>’?\r\n    5 | #include \"paddleaudio/src/optional/optional.hpp\"\r\n  +++ |+#include <cstdint>\r\n    6 | \r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:53:62: error: template argument 1 is invalid\r\n   53 | BitDepth get_bit_depth_from_option(const tl::optional<int64_t> bit_depth);\r\n      |                                                              ^\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:55:6: error: ‘string’ in namespace ‘std’ does not name a type\r\n   55 | std::string get_encoding(sox_encoding_t encoding);\r\n      |      ^~~~~~\r\n/home/orangepi/Downloads/PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h:55:1: note: ‘std::string’ is defined in header ‘<string>’; did you forget to ‘#include <string>’?\r\n   55 | std::string get_encoding(sox_encoding_t encoding);\r\n      | ^~~\r\n```\r\n\r\n## 修复建议\r\n\r\n在 PaddleSpeech/audio/paddleaudio/src/pybind/sox/types.h 中添加 `#include <string>`可解决。",
        "state": "open",
        "user": "xushangning",
        "closed_by": null,
        "created_at": "2023-09-28T07:55:59+00:00",
        "updated_at": "2025-04-26T04:45:27+00:00",
        "closed_at": null,
        "comments_count": [
            "kk-2000",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3537,
        "title": "tts服务正常启动，post报错。",
        "body": "tts服务在Docker中启动服务正常，但post报错：\r\n`Offline tts engine only support python or inference`\r\n查找后发现readme中有简短说明：\r\n`目前引擎类型支持两种形式：python 及 inference (Paddle Inference) 注意： 如果在容器里可正常启动服务，但客户端访问 ip 不可达，可尝试将配置文件中 host 地址换成本地 ip 地址。`\r\n尝试把tts_online_application.yaml中hostip修改为docker的和宿主的都不行，请问该如何修改？",
        "state": "closed",
        "user": "0902081008",
        "closed_by": "stale[bot]",
        "created_at": "2023-09-29T05:08:48+00:00",
        "updated_at": "2025-06-27T04:34:39+00:00",
        "closed_at": "2025-06-27T04:34:39+00:00",
        "comments_count": [
            "Gsonovb",
            "polarisNoSnow",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3541,
        "title": "多卡并发同时进行TXT2WAV，是否可以实现",
        "body": "def listener(cudaidx):\r\n    tts_executor = TTSExecutor()\r\n    tts_executor(text='你好',\r\n        output='',\r\n        am=\"fastspeech2_mix\",\r\n        am_config=\"tts_model/fastspeech2_mix_ckpt_1.2.0/default.yaml\",\r\n        am_ckpt=\"tts_model/snapshot_iter_176176.pdz\",\r\n        am_stat=\"tts_model/fastspeech2_mix_ckpt_1.2.0/speech_stats.npy\",\r\n        phones_dict=\"tts_model/fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt\",\r\n        tones_dict=None,\r\n        speaker_dict=\"tts_model/fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt\",\r\n        voc=vocarg,\r\n        voc_config=None,\r\n        voc_ckpt=None,\r\n        voc_stat=None,\r\n        lang=langarg,\r\n        device=\"gpu:\"+cudaidx)\r\n\r\nthread = threading.Thread(target=listener,args=('0',))\r\nthread = threading.Thread(target=listener,args=('1',))\r\nthread = threading.Thread(target=listener,args=('2',))\r\nthread = threading.Thread(target=listener,args=('3',))\r\nthread = threading.Thread(target=listener,args=('4',))\r\nthread = threading.Thread(target=listener,args=('5',))\r\nthread = threading.Thread(target=listener,args=('6',))\r\n\r\n意思就是7张GPU用多线程的方式同时进行TTS语音合成，因为paddle的限制，是无法实现的，因为GPU是通过paddle.set_device(device)来切换的，而不是像torch的模型一样GPU ID是带在模型的实例里面的。我用多进程的方式，让每个进程绑定了1个GPU，在windows下程序是可以跑通，但是在ubuntu下面，就出现cuda error（3）无法初始化。",
        "state": "open",
        "user": "ray1a1",
        "closed_by": null,
        "created_at": "2023-10-08T20:14:00+00:00",
        "updated_at": "2023-10-08T20:14:00+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3542,
        "title": "你好！想问下 一个batch里wav文件大小不一样，怎么padding？",
        "body": "如截图路径第98行，应该怎么设置？\r\n![2](https://github.com/PaddlePaddle/PaddleSpeech/assets/75681041/de3c9ccc-91c8-4e89-baf6-1519a6cd4016)\r\n\r\n",
        "state": "closed",
        "user": "Kitzzaaa",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-09T02:24:01+00:00",
        "updated_at": "2025-06-27T04:34:52+00:00",
        "closed_at": "2025-06-27T04:34:52+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3540,
        "title": "demos/streaming_asr_server/web的演示是使用不带标点的，如何才能让它返回有标点的文本？",
        "body": "demos/streaming_asr_server/web的演示是使用不带标点的，如何才能让它返回有标点的文本？\r\n我运行了server.sh脚本。它有两个服务，按理是可以处理标点的。但：\r\n127.0.0.1:8090/paddlespeech/asr/streaming中的8090改成8190，并不能起效果。如何做到可以处理标点？",
        "state": "closed",
        "user": "tms2003",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-08T03:46:30+00:00",
        "updated_at": "2025-06-27T04:34:40+00:00",
        "closed_at": "2025-06-27T04:34:40+00:00",
        "comments_count": [
            "skkk256",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3544,
        "title": "[TTS]安装完成后，调用示例报错   paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav",
        "body": "\r\n[TTS]安装完成后，调用示例报错   \r\n\r\npaddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n显示错误为ort相关错误\r\n\r\n![img_v2_53de1859-4f71-4da5-936e-d35be46584ag](https://github.com/PaddlePaddle/PaddleSpeech/assets/35764637/81d46adb-5fc9-476a-82cc-413facc49165)\r\n\r\n调用paddlespeech asr --lang zh --input zh.wav 也报错\r\n![img_v2_ac1da18b-d7e1-4e89-8e09-c867b9a904ag](https://github.com/PaddlePaddle/PaddleSpeech/assets/35764637/1c7c708a-22a5-486f-affd-af864e1bf53c)\r\n\r\n",
        "state": "open",
        "user": "SuTn",
        "closed_by": null,
        "created_at": "2023-10-10T05:52:27+00:00",
        "updated_at": "2023-10-11T07:13:37+00:00",
        "closed_at": null,
        "comments_count": [
            "sjtuaiyong",
            "ChengsongLu",
            "yaleimeng",
            "ChengsongLu"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3543,
        "title": "[TTS] cuda问题",
        "body": "$ paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno 111] Connection refused>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno 111]\r\n[nltk_data]     Connection refused>\r\n/home/luchengsong/anaconda3/envs/paddle/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nW1010 09:50:56.247031  1756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 11.8\r\nW1010 09:50:56.247234  1756 dynamic_loader.cc:303] The third-party dynamic library (libcudnn.so) that Paddle depends on is not configured correctly. (error code is /usr/local/cuda/lib64/libcudnn.so: cannot open shared object file: No such file or directory)\r\n  Suggestions:\r\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure third-party dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX;\r\nRuntimeError: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\r\n  [Hint: cudnn_dso_handle should not be null.] (at ../paddle/phi/backends/dynload/cudnn.cc:64)\r\n\r\n\r\nCUDA版本：12.2\r\npaddlepaddle-gpu: 2.5.1.post120\r\n",
        "state": "open",
        "user": "ChengsongLu",
        "closed_by": null,
        "created_at": "2023-10-10T01:56:06+00:00",
        "updated_at": "2024-07-03T01:41:02+00:00",
        "closed_at": null,
        "comments_count": [
            "syg1996419",
            "qingjiaozyn",
            "lxowalle",
            "ZHUHF123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3545,
        "title": "[S2T]distutils not work on python 3.10",
        "body": "\r\n**Describe the bug**\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\", line 36, in <module>\r\n    parser = default_argument_parser()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/training/cli.py\", line 76, in default_argument_parser\r\n    type=distutils.util.strtobool,\r\nAttributeError: module 'distutils' has no attribute 'util'\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\non paddlepaddle==2.5, python 3.10\r\nrun: \r\ncd /home/aistudio/PaddleSpeech/examples/aishell/asr1\r\nbash run.sh --stage 1 --stop_stage 1\r\nsee error.\r\n**Expected behavior**\r\naishell asr exaple run.sh run normal\r\n\r\n**Screenshots**\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/u2/bin/train.py\", line 36, in <module>\r\n    parser = default_argument_parser()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/training/cli.py\", line 76, in default_argument_parser\r\n    type=distutils.util.strtobool,\r\nAttributeError: module 'distutils' has no attribute 'util'\r\n\r\n**Environment (please complete the following information):**\r\n - OS: aistudio.baidu.com\r\n - GCC/G++ Version unknown\r\n - Python Version 3.10\r\n - PaddlePaddle Version 2.5\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100 16G\r\n - CUDA/CUDNN Version 11.2\r\n - MKL Version :unknown\r\n- TensorRT Version: unknown\r\n\r\n",
        "state": "closed",
        "user": "hohohacn",
        "closed_by": "hohohacn",
        "created_at": "2023-10-11T09:11:13+00:00",
        "updated_at": "2023-12-04T03:58:43+00:00",
        "closed_at": "2023-10-11T12:58:55+00:00",
        "comments_count": [
            "qingjiaozyn"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3548,
        "title": "tts微调， 不使用官方提供的libfstscript.so.13，自己安装openfst后微调报错",
        "body": "这个文件依赖glib 2.23, 今天把系统搞蹦了两次-_-||。\r\n第一次直接安装glib 2.23，导致系统崩溃，恢复了。\r\n然后第二次指定prefix安装，也崩溃了，然后又恢复。\r\n对c++不熟，centos7的系统，只能用glib2 2.17。\r\n然后搜索看网上说用conda安装glib也会导致conda环境崩溃。\r\n所以只能直接编译一个libfstscript.so才行了\r\n\r\n",
        "state": "closed",
        "user": "wmlgl",
        "closed_by": "wmlgl",
        "created_at": "2023-10-12T11:11:24+00:00",
        "updated_at": "2023-10-13T11:22:52+00:00",
        "closed_at": "2023-10-13T11:22:51+00:00",
        "comments_count": [
            "wmlgl",
            "wmlgl",
            "wmlgl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3547,
        "title": "安装PaddleSpeech后无法使用",
        "body": "## Others\r\n\r\n执行命令\r\n` paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav`\r\n可以正常运行\r\n\r\n但是使用程序\r\n```python\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\ntts(text=\"今天天气十分不错。\", output=\"output.wav\")\r\n```\r\n\r\n报错\r\n```bash\r\nModuleNotFoundError: No module named 'paddlespeech.cli'; 'paddlespeech' is not a package\r\n```",
        "state": "closed",
        "user": "nemoiee",
        "closed_by": "nemoiee",
        "created_at": "2023-10-11T09:45:02+00:00",
        "updated_at": "2023-10-19T09:41:48+00:00",
        "closed_at": "2023-10-11T09:49:39+00:00",
        "comments_count": [
            "sym19991125",
            "nemoiee",
            "sym19991125",
            "nemoiee",
            "sym19991125"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3550,
        "title": "Error",
        "body": "SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at ../paddle/fluid/operators/reader/blocking_queue.h:175)\r\n",
        "state": "closed",
        "user": "AbhishekPSI7042",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-16T05:18:18+00:00",
        "updated_at": "2025-06-27T04:34:26+00:00",
        "closed_at": "2025-06-27T04:34:26+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3549,
        "title": "ASR_ONLINE默认只支持16000采样率的音频，请问有没有支持24或者32的模型？",
        "body": "ASR_ONLINE默认只支持16000采样率的音频，请问有没有支持24000或者32000的模型？",
        "state": "closed",
        "user": "0902081008",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-13T12:29:45+00:00",
        "updated_at": "2025-06-27T05:32:31+00:00",
        "closed_at": "2025-06-27T05:32:31+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3551,
        "title": "如何进行这样的大项目的调试？",
        "body": "比如，我想通过运行paddlespeech_server.py 来进行代码调试工作：\r\n结果，无论 是在哪一级目录下：\r\n\r\n python paddlespeech_server.py \r\n或\r\npython ./bin/paddlespeech_server.py \r\n或\r\n python ./paddlespeech/server/bin/paddlespeech_server.py \r\n都会遇到错误：\r\nTraceback (most recent call last):\r\n  File \"/workspace/PaddleSpeech/paddlespeech/server/./bin/paddlespeech_server.py\", line 32, in <module>\r\n    from ..executor import BaseExecutor\r\nImportError: attempted relative import with no known parent package\r\n\r\n其对应的代码为：\r\n```\r\nfrom ..executor import BaseExecutor\r\n```\r\n很明显路径不对，但这么一个复杂的项目，如何进行调试？",
        "state": "closed",
        "user": "tms2003",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-16T07:35:48+00:00",
        "updated_at": "2025-06-27T05:32:35+00:00",
        "closed_at": "2025-06-27T05:32:35+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3552,
        "title": "可以装在Windows下么",
        "body": "你好,可以装在Windows下么",
        "state": "closed",
        "user": "adamp4",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-17T01:12:05+00:00",
        "updated_at": "2025-06-27T04:34:35+00:00",
        "closed_at": "2025-06-27T04:34:35+00:00",
        "comments_count": [
            "Haroldhy",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3553,
        "title": "[TTS]import error",
        "body": "安装好paddlepaddle与paddlespeech后在python中输入from paddlespeech.cli.tts.infer import TTSExecutor出现下面错误\r\nImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/likai/miniconda3/envs/paddlespeech/lib/python3.8/site-packages/opencc/clib/opencc_clib.cpython-38-x86_64-linux-gnu.so)\r\n![1697535374090](https://github.com/PaddlePaddle/PaddleSpeech/assets/14877573/4f84c6ff-e0b3-4dfb-9ef6-010a254358c1)\r\n\r\n - OS: Ubuntu18.04\r\n - GCC/G++ Version 7.5.0\r\n - Python Version 3.8.18\r\n - PaddlePaddle Version 2.5.1\r\n - CUDA/CUDNN Version [e.g. cuda-11.1]\r\n",
        "state": "closed",
        "user": "kli017",
        "closed_by": "kli017",
        "created_at": "2023-10-17T09:38:14+00:00",
        "updated_at": "2024-04-15T06:54:22+00:00",
        "closed_at": "2024-04-15T06:54:22+00:00",
        "comments_count": [
            "HsiangLeekwok",
            "oswen",
            "AlvinAi96",
            "AlvinAi96",
            "AngelLiang",
            "thinkboy",
            "DIO385"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3554,
        "title": "采用docker部署paddlespeech，那么在音频检索的demo中如何再通过docker启用Milvus和MySQL服务",
        "body": "/PaddleSpeech/demos/audio_searching/src中是通过docker启用了Milvus和MySQL服务，请问我是通过docker部署的paddlespeech，那么在想运行音频检索的demo时，如何再通过docker启动Milvus和MySQL服务呢\r\n",
        "state": "closed",
        "user": "Future-FC",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-18T08:45:54+00:00",
        "updated_at": "2025-06-27T05:32:55+00:00",
        "closed_at": "2025-06-27T05:32:55+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3555,
        "title": "微调的中文，用xpinyin处理后的样本只有几个被复制到了newdir里，训练出来的是杂音",
        "body": "用xpinyin处理的后的labels.txt内容如下：\r\n```\r\n463|wa4n shi4 wa4n wu4 da4 du1 shi4 co2ng wu2 da4o yo3u co2ng xia3o da4o da4 xu2n xu4 jia4n ji4n\r\n464|n2 zhe4 pia4n cha3ng di4 wo3 yi3 ji1ng zu1 jie4 xia4 la5i ka1i shi3 ji4n xi2ng yi2 shi4 de5 cho2u be4i le5\r\n465|n2 zhe4 xie1 hua1 ba4n yo3u dia3n yi4 si1\r\n466|qi1ng ce4 zhua1ng sha1n qi1ng shui3 lv4 tia2n ji4ng yi2 re2n shi4 bu4 ke3 duo1 de2 de5 li2ng xiu4 zhi1 de5\r\n467|ba4o qia4n shu4 wo3 me5n we4i ne2ng wa2n che2ng qi4 yue1 mi2ng we2i ye1 ya2ng de5 ba4n xia1n zhi1 sho4u wo3 me5n shi2 za4i me2i yo3u to2u xu4\r\n468|me2i cuo4 zhe4 jiu4 shi4 we4i he2 wo3 jia1ng she2n zhi1 xi1n ba3o liu2 da4o le5 xia4n za4i\r\n469|qia1n nia2n de5 gu4 shi4 yi1 shi2 ba4n hui4 e5r ke3 shuo1 bu4 wa2n\r\n470|zhe4n sho3u ci3 di4 zhi4 gua1n zho4ng ya4o\r\n471|ji2 shi4 yi3 sho1u xua1n na4o de5 ma3 to2u ye3 yi3 che2n shui4 qu4 xiu1 xi1 ba5\r\n472|bu4 guo4 zhe4 ci4 ma3i sa1n zho3ng ni2 cha2ng hua1 da4o bu2 shi4 chu1 yu2 wo3 de5 re2n she1ng xi4n tia2o\r\n473|zhe4 ke3 bu4 mia4o\r\n474|zhe4ng shi4\r\n475|ya4o shi4 jia4n da4o ta1 bu4 fa2ng ye3 da4o yi1 she1ng jie2 ri4 kua4i le4\r\n476|ke3 xi1\r\n477|xia4 qu4 xiu1 xi1 zhe4 li3 jia1o ge3i wo3\r\n478|n2 zhe4 xie1 be4i yo4ng ca2i lia4o yi1ng ga1i ke3 yi3 pa4i sha4ng yo4ng cha3ng le5\r\n479|bu4 guo4 zhe4 zho3ng gu3 za3o shi2 qi1 de5 jia3ng jiu5 he2 yi1 xie1 guo4 yu2 fu4 za2 de5 chua2n to3ng do1u yi3 ji1ng zhu2 jia4n be4i jia3n hua4 le5\r\n480|fe1n we2i yi2 re2n he3n he2 wo3 yi4\r\n481|ye4 cha1 yi1 zu2 shi4 li2 yue4 de5 go1ng che2n ta1 me5n li4 ji1ng zha4n shi4 xi1 she1ng lia2ng duo1 ji4n zhi4 ha3i ga3ng yua3n zhi4 ce2ng ya2n yi1 zhi2 yi3 la2i li2 yue4 do1u yi1n ta1 me5n de5\r\nbi4 yo4u e2r pi2ng a1n\r\n482|da1ng da4i ta2ng zhu3 n2 na4 ha2i zi5 wo3 yi4ng fu4 bu4 la2i\r\n483|da4n zhe4 li3 suo3 shuo1 de5 hua2n ji4ng yu3 ti2 wa3 te4 yo2u la3n zhi3 na2n li3 pi2ng pa4n da4 jiu3 lo2u de5 hua2n ji4ng jiu4 shi4 lia3ng zho3ng yi4 si1 le5\r\n484|si1 ha3o no2ng de5 jiu3 qi4 na4 ge4 shi1 re2n ga1ng ga5ng la2i guo4 ba5 na4 ge4 he2 fe1ng ya3 e4r zi4 da1 bu4 sha4ng yi4 dia3n gua1n xi4 de5 jiu3 gui3 shi1 re2n ni3 zhe4 li3 wu2 be4i ta1 yo4u p\r\nia4n zhe5 gua4n le5 jiu3 hua4 ye3 shuo1 bu4 qi1ng le5 me5 ni3 de3ng yi1 xia4 wo3 qu4 qi1 yi1 hu2 xi3ng she2n cha2 zhi3 xu1 sa1n ge4 shi2 che2n bia4n ha3o ni3 de3ng yi1 xia4\r\n486|zhi3 ne2ng shuo1 mi2ng qi1 xi1ng yi3 ji1ng xi1n li3 yo3u shu4 huo4 zhe3 yi3 ji1ng que4 di4ng xia4n cha3ng de5 xia4n suo3 do1u zha3o qi2 le5 ba5\r\n487|yua2n la2i ru2 ci3 ni3 shi4 zhe4 zho3ng le4i xi2ng de5 yo2u re2n na4 ye3 bu4 cuo4\r\n488|mo2 la1 tia1n ra2n shi4 huo4 bi4 da4n huo4 bi4 tia1n ra2n bu2 shi4 mo2 la1\r\n489|bu4 guo4 wo3 shi3 zho1ng re4n we2i qia3o go1ng ga1o yu2 qi2 shi2 zhe1n zhe4ng de5 mi2ng jia4ng jue2 bu4 hui4 ju1 ni4 yu2 xi1 yo3u kua4ng shi2\r\n490|yo3u xie1 cha2 we2n qi3 la5i shi1 ni4 jia1o xia1ng guo4 zho4ng yi4ng shi4 ci4 pi3n li4ng yo3u yi1 xie1 we2n qi3 la5i ga1n chu2n dia3n ya3 yo1u xia1ng pu1 mia4n zhe4 le4i cha2 duo1 we2i sha4ng p\r\ni3n\r\n491|ha3o le5 ha2i xia3ng zhi1 da4o xie1 bie2 de5 she2n me5 shi4 ma5\r\n492|ri4 zi5 guo4 de2 za4i qi1ng ku3 qia2n ji4n de5 jia3o bu4 ye3 co2ng we4i ti2ng xia4\r\n493|shi2 jie2 ga1ng ha3o li3 yi1ng wa4i chu1 zo3u zo3u de3ng yi1 zhuo1 me3i shi2\r\n\r\n```\r\n\r\nnewdir下的内容如下：\r\n```\r\n(base) [root@localhost input]# more ./zhongli_mini1/newdir/*.txt\r\n::::::::::::::\r\n./zhongli_mini1/newdir/476.txt\r\n::::::::::::::\r\nke3 xi1\r\n::::::::::::::\r\n./zhongli_mini1/newdir/527.txt\r\n::::::::::::::\r\ne4\r\n::::::::::::::\r\n./zhongli_mini1/newdir/569.txt\r\n::::::::::::::\r\nda4 yi4 le5 ma5\r\n::::::::::::::\r\n./zhongli_mini1/newdir/606.txt\r\n::::::::::::::\r\nge2 xia4 shi4\r\n::::::::::::::\r\n./zhongli_mini1/newdir/638.txt\r\n::::::::::::::\r\nzhe4 shi4\r\n::::::::::::::\r\n./zhongli_mini1/newdir/670.txt\r\n::::::::::::::\r\no2\r\n::::::::::::::\r\n./zhongli_mini1/newdir/695.txt\r\n::::::::::::::\r\nshi4 ni3 a5\r\n::::::::::::::\r\n./zhongli_mini1/newdir/700.txt\r\n::::::::::::::\r\nbu4 cuo4\r\n\r\n```",
        "state": "closed",
        "user": "wmlgl",
        "closed_by": "wmlgl",
        "created_at": "2023-10-18T11:07:28+00:00",
        "updated_at": "2023-10-20T10:17:29+00:00",
        "closed_at": "2023-10-20T10:17:28+00:00",
        "comments_count": [
            "wmlgl",
            "wmlgl"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3556,
        "title": "websocket 服务识别长音频-报错：sent 1011，keepalive ping timeout; no close frame received",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n长音频ASR识别，流式处理报错：sent 1011 (unexpected error) keepalive ping timeout; no close frame received\r\n请教下，这个错误该如何处理",
        "state": "closed",
        "user": "sunjinguo",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-19T03:24:43+00:00",
        "updated_at": "2025-06-27T05:32:33+00:00",
        "closed_at": "2025-06-27T05:32:33+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3557,
        "title": "如何使用自己训练的模型生成TTS?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n我看代码目前是只支持fastspeech2_csmsc_onnx和fastspeech2_cnndecoder_csmsc_onnx这两个模型做TTS，目前支持使用自己训练的模型做TTS吗？",
        "state": "closed",
        "user": "HONGYI-SD",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-23T10:06:43+00:00",
        "updated_at": "2025-06-27T04:34:30+00:00",
        "closed_at": "2025-06-27T04:34:29+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3558,
        "title": "请问哪个可以小样本克隆音乐？",
        "body": "请问哪个可以小样本克隆音乐？",
        "state": "closed",
        "user": "ymmbb8882ymmbb",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-24T05:51:58+00:00",
        "updated_at": "2025-06-27T04:34:31+00:00",
        "closed_at": "2025-06-27T04:34:31+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3559,
        "title": "cuda",
        "body": "## General Question\r\n\r\nW1024 10:07:50.310557 266636 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW1024 10:07:50.312556 266636 dynamic_loader.cc:278] Note: [Recommend] copy cudnn into CUDA installation directory.\r\n For instance, download cudnn-10.0-windows10-x64-v7.6.5.32.zip from NVIDIA's official website,\r\nthen, unzip it and copy it into C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\r\nYou should do this according to your CUDA installation directory and CUDNN version.\r\nTraceback (most recent call last):\r\n  File \"dect.py\", line 14, in <module>\r\n    result = asr(audio_file='./video/zh.wav')\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\cli\\asr\\infer.py\", line 504, in __call__\r\n    self._init_from_path(model, lang, codeswitch, sample_rate, config,\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\cli\\asr\\infer.py\", line 211, in _init_from_path\r\n    model_class = self.task_resource.get_model_class(model_name)\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\resource\\resource.py\", line 115, in get_model_class\r\n    ret.append(dynamic_import(import_path))\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\utils\\dynamic_import.py\", line 37, in dynamic_import\r\n    m = importlib.import_module(module_name)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlespeech\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\s2t\\models\\u2\\__init__.py\", line 14, in <module>\r\n    from .u2 import U2InferModel\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 43, in <module>\r\n    from paddlespeech.s2t.modules.decoder import BiTransformerDecoder\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\s2t\\modules\\decoder.py\", line 30, in <module>\r\n    from paddlespeech.s2t.modules.attention import MultiHeadedAttention\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\s2t\\modules\\attention.py\", line 40, in <module>\r\n    class MultiHeadedAttention(nn.Layer):\r\n  File \"F:\\paddleSpeech_develop\\paddlespeech\\s2t\\modules\\attention.py\", line 96, in MultiHeadedAttention\r\n    mask: paddle.Tensor=paddle.ones([0, 0, 0], dtype=paddle.bool)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddle\\tensor\\creation.py\", line 750, in ones\r\n    return fill_constant(value=1.0, shape=shape, dtype=dtype, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlespeech\\lib\\site-packages\\paddle\\fluid\\layers\\tensor.py\", line 832, in fill_constant\r\n    out = _C_ops.full(shape, float(value), dtype, place)\r\nRuntimeError: (PreconditionNotMet) The third-party dynamic library (cudnn64_7.dll) that Paddle depends on is not configured correctly. (error code is 126)\r\n  Suggestions:\r\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure third-party dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX; (at D:\\home\\workspace\\Paddle\\paddle\\phi\\backends\\dynload\\dynamic_loader.cc:305)",
        "state": "closed",
        "user": "syg1996419",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-24T07:20:07+00:00",
        "updated_at": "2025-06-27T04:34:41+00:00",
        "closed_at": "2025-06-27T04:34:41+00:00",
        "comments_count": [
            "RechinW",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3560,
        "title": "[S2T] keyerror paddlespeech asr --lang zh --input zh.wav",
        "body": "我按照安装教程，环境都配好了，执行这个asr服务报错\r\nW1025 11:49:38.739352 41545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.6, Runtime API Version: 11.6\r\nW1025 11:49:38.740468 41545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\r\n[2023-10-25 11:49:44,056] [   ERROR] - too many positional arguments\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddle/base/dygraph/base.py\", line 350, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 543, in attention_rescoring\r\n    hyps, encoder_out = self._ctc_prefix_beam_search(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 424, in _ctc_prefix_beam_search\r\n    encoder_out, encoder_mask = self._forward_encoder(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 229, in _forward_encoder\r\n    encoder_out, encoder_mask = self.encoder(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/modules/encoder.py\", line 189, in forward\r\n    xs, chunk_masks, _, _ = layer(xs, chunk_masks, pos_emb, mask_pad)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/modules/encoder_layer.py\", line 242, in forward\r\n    x_att, new_att_cache = self.self_attn(\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/modules/attention.py\", line 324, in forward\r\n    q, k, v = self.forward_qkv(query, key, value)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/paddlespeech/s2t/modules/attention.py\", line 82, in forward_qkv\r\n    q = self.linear_q(query).view(n_batch, -1, self.h, self.d_k)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/decorator.py\", line 231, in fun\r\n    args, kw = fix(args, kw, sig)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/site-packages/decorator.py\", line 203, in fix\r\n    ba = sig.bind(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/inspect.py\", line 3037, in bind\r\n    return self._bind(args, kwargs)\r\n  File \"/root/anaconda3/envs/tts/lib/python3.8/inspect.py\", line 2958, in _bind\r\n    raise TypeError('too many positional arguments') from None\r\nTypeError: too many positional arguments\r\nKeyError: 'result'\r\n\r\n",
        "state": "open",
        "user": "Popukar0421",
        "closed_by": null,
        "created_at": "2023-10-25T03:50:55+00:00",
        "updated_at": "2023-11-30T11:51:07+00:00",
        "closed_at": null,
        "comments_count": [
            "Popukar0421",
            "zxcd",
            "luyao-cv"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3561,
        "title": "安装报错  无法打开文件包括 “Python.h”",
        "body": "python  3.10.11\r\npaddlepaddle  2.5.0\r\ngcc   1.17\r\n安装时，重复出现下图错误；重新安装最新的gcc环境仍不能解决。\r\n<img width=\"861\" alt=\"2\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/140780477/631ed78b-45df-4b33-8d1e-ad6afc48d8ea\">\r\n",
        "state": "closed",
        "user": "zhutaotao-ai",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-25T06:29:38+00:00",
        "updated_at": "2025-06-27T05:32:35+00:00",
        "closed_at": "2025-06-27T05:32:35+00:00",
        "comments_count": [
            "zxcd",
            "zhutaotao-ai",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3563,
        "title": "[TTS] 使用paddle 2.5.1版本时 transformer tts 模型推理有问题",
        "body": "1. [transformer tts](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/ljspeech/tts1) \r\n2. 使用paddle2.4.2+(develop or r1.4.1)，进行transformer tts预训练模型推理的结果语音正常\r\n3. 使用paddle2.5.1+(develop or 1.4.1)，进行transformer tts预训练模型推理的结果语音非正常(发音不清楚，断断续续)\r\n不清楚是不是paddlespeech没有适配到2.5.1版本还是其他问题\r\n\r\n环境：\r\n```bash\r\nPackage                     Version\r\n--------------------------- ---------------\r\nabsl-py                     2.0.0\r\naiohttp                     3.8.5\r\naiosignal                   1.3.1\r\nannotated-types             0.5.0\r\nantlr4-python3-runtime      4.9.3\r\nanyio                       3.7.1\r\naspy.yaml                   1.3.0\r\nastor                       0.8.1\r\nastroid                     2.12.10\r\nasync-timeout               4.0.3\r\nasynctest                   0.13.0\r\nattrs                       22.1.0\r\naudioread                   3.0.1\r\nBabel                       2.12.1\r\nbce-python-sdk              0.8.87\r\nbokeh                       2.4.3\r\nboltons                     23.0.0\r\nBottleneck                  1.3.7\r\ncached-property             1.5.2\r\ncertifi                     2022.9.14\r\ncffi                        1.15.1\r\ncfgv                        3.3.1\r\ncharset-normalizer          2.1.1\r\nclick                       8.1.4\r\ncolorama                    0.4.6\r\ncoloredlogs                 15.0.1\r\ncolorlog                    6.7.0\r\ncycler                      0.11.0\r\nCython                      3.0.3\r\ndatasets                    2.13.2\r\ndecorator                   5.1.1\r\ndill                        0.3.4\r\nDistance                    0.1.3\r\ndistlib                     0.3.6\r\neditdistance                0.6.2\r\neinops                      0.6.1\r\nentrypoints                 0.4\r\net-xmlfile                  1.1.0\r\nexceptiongroup              1.1.3\r\nfastapi                     0.103.1\r\nfilelock                    3.8.0\r\nFlask                       2.2.5\r\nflask-babel                 3.1.0\r\nflatbuffers                 23.5.26\r\nfonttools                   4.38.0\r\nfrozenlist                  1.3.3\r\nfsspec                      2023.1.0\r\nftfy                        6.1.1\r\nfuture                      0.18.3\r\ng2p-en                      2.1.0\r\ng2pM                        0.1.2.5\r\nh11                         0.14.0\r\nh5py                        3.8.0\r\nhttpcore                    0.17.3\r\nhttpx                       0.24.1\r\nhuggingface-hub             0.16.4\r\nhumanfriendly               10.0\r\nHyperPyYAML                 1.2.2\r\nidentify                    2.5.5\r\nidna                        3.4\r\nimportlib-metadata          4.12.0\r\ninflect                     6.0.5\r\niniconfig                   1.1.1\r\nintervaltree                3.1.0\r\nipykernel                   4.6.0\r\nipython                     5.3.0\r\nisort                       5.10.1\r\nitsdangerous                2.1.2\r\njieba                       0.42.1\r\nJinja2                      3.1.2\r\njoblib                      1.3.1\r\njsonlines                   3.1.0\r\njupyter_client              7.3.5\r\njupyter-core                4.11.1\r\nkaldiio                     2.18.0\r\nkiwisolver                  1.4.4\r\nlazy-object-proxy           1.7.1\r\nlibrosa                     0.8.1\r\nllvmlite                    0.39.1\r\nloguru                      0.7.2\r\nlxml                        4.9.3\r\nmarkdown-it-py              2.2.0\r\nMarkupSafe                  2.1.3\r\nmatplotlib                  3.5.3\r\nmccabe                      0.7.0\r\nmdurl                       0.1.2\r\nmido                        1.3.0\r\nmock                        5.1.0\r\nmpmath                      1.3.0\r\nmultidict                   6.0.4\r\nmultiprocess                0.70.12.2\r\nnara-wpe                    0.0.9\r\nnest-asyncio                1.5.5\r\nnltk                        3.8.1\r\nnodeenv                     1.7.0\r\nnote-seq                    0.0.3\r\nnumba                       0.56.4\r\nnumpy                       1.21.6\r\nomegaconf                   2.3.0\r\nonnx                        1.14.1\r\nonnxruntime                 1.14.1\r\nOpenCC                      1.1.6\r\nopencc-python-reimplemented 0.1.7\r\nopencv-python               4.5.5.64\r\nopenpyxl                    3.1.2\r\nopt-einsum                  3.3.0\r\npackaging                   23.2\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.0.9\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.0\r\npaddlepaddle-gpu            2.5.1.post117\r\npaddlesde                   0.2.5\r\npaddleseg                   2.8.0\r\npaddleslim                  2.4.1\r\npaddlespeech                1.4.1\r\npaddlespeech-ctcdecoders    0.2.1\r\npaddlespeech-feat           0.1.0\r\npandas                      1.3.5\r\nparameterized               0.9.0\r\npathos                      0.2.8\r\npattern-singleton           1.2.0\r\npexpect                     4.8.0\r\npickleshare                 0.7.5\r\nPillow                      9.2.0\r\npip                         22.3.1\r\nplatformdirs                2.5.2\r\npluggy                      1.0.0\r\npooch                       1.7.0\r\nportalocker                 2.7.0\r\npox                         0.3.3\r\nppdiffusers                 0.19.3\r\nppft                        1.7.6.7\r\npraatio                     5.1.1\r\npre-commit                  1.10.4\r\npretty-midi                 0.2.10\r\nprettytable                 3.7.0\r\nprompt-toolkit              1.0.18\r\nprotobuf                    4.24.4\r\npsutil                      5.9.5\r\nptyprocess                  0.7.0\r\npy                          1.11.0\r\npyarrow                     12.0.1\r\npybind11                    2.11.1\r\npycparser                   2.21\r\npycryptodome                3.18.0\r\npydantic                    1.10.13\r\npydantic_core               2.6.3\r\npydub                       0.25.1\r\nPygments                    2.13.0\r\nPyGObject                   3.26.1\r\npygtrie                     2.5.0\r\npylint                      2.15.3\r\npyparsing                   3.0.9\r\npypinyin                    0.44.0\r\npypinyin-dict               0.6.0\r\npytest                      7.1.3\r\npytest-runner               6.0.0\r\npython-apt                  1.6.5+ubuntu0.7\r\npython-dateutil             2.8.2\r\npytz                        2023.3\r\npyworld                     0.3.4\r\nPyYAML                      6.0\r\npyzmq                       24.0.1\r\nrarfile                     4.0\r\nregex                       2023.10.3\r\nrequests                    2.28.1\r\nrequests-mock               1.11.0\r\nresampy                     0.4.2\r\nrich                        13.5.2\r\nruamel.yaml                 0.17.35\r\nruamel.yaml.clib            0.2.8\r\nsacrebleu                   2.3.1\r\nsafetensors                 0.3.3\r\nscikit-learn                1.0.2\r\nscipy                       1.7.3\r\nsentencepiece               0.1.99\r\nseqeval                     1.2.2\r\nsetuptools                  50.3.2\r\nsetuptools-scm              7.1.0\r\nsimplegeneric               0.8.1\r\nsix                         1.16.0\r\nsniffio                     1.3.0\r\nsortedcontainers            2.4.0\r\nsoundfile                   0.12.1\r\nstarlette                   0.27.0\r\nswig                        4.1.1\r\nsympy                       1.10.1\r\ntabulate                    0.9.0\r\nTextGrid                    1.5\r\nthreadpoolctl               3.1.0\r\ntimer                       0.2.2\r\nToJyutping                  0.2.3\r\ntoml                        0.10.2\r\ntomli                       2.0.1\r\ntomlkit                     0.11.4\r\ntornado                     6.2\r\ntqdm                        4.65.0\r\ntraitlets                   5.4.0\r\ntrampoline                  0.1.2\r\ntyped-ast                   1.5.4\r\ntypeguard                   2.13.3\r\ntyper                       0.9.0\r\ntyping_extensions           4.7.1\r\nunattended-upgrades         0.1\r\nurllib3                     1.26.12\r\nuvicorn                     0.22.0\r\nvirtualenv                  20.16.5\r\nvisualdl                    2.5.3\r\nwcwidth                     0.2.5\r\nwebrtcvad                   2.0.10\r\nwebsockets                  11.0.3\r\nWerkzeug                    2.2.3\r\nwheel                       0.37.1\r\nwrapt                       1.14.1\r\nxxhash                      3.3.0\r\nyacs                        0.1.8\r\nyarl                        1.9.2\r\nzhon                        2.0.2\r\nzipp                        3.8.1\r\n```",
        "state": "open",
        "user": "layne01291",
        "closed_by": null,
        "created_at": "2023-10-26T08:54:43+00:00",
        "updated_at": "2024-01-16T08:35:28+00:00",
        "closed_at": null,
        "comments_count": [
            "JiadiLee"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3562,
        "title": "Vocoder推理慢，效果差",
        "body": "运行：CPU\r\n引擎：tts_python\r\nam：fastspeech2_aishell3\r\nvoc：pwgan_aishell3/hifigan_aishell3\r\n\r\nvocoder无论选择pwgan_aishell3还是hifigan_aishell3推理速度都很慢，而且出来的效果比较差。\r\n但是在fastspeech2_csmsc+mb_melgan_csmsc组合上，在cpu上运行速度也一样很快。\r\n",
        "state": "closed",
        "user": "ChengsongLu",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-25T09:55:07+00:00",
        "updated_at": "2025-06-27T04:34:34+00:00",
        "closed_at": "2025-06-27T04:34:34+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3564,
        "title": "[S2T] paddlespeech st --input en.wav has error: KeyError: '_tmp', no other message.",
        "body": "(paddle) [root@localhost sample]# ll\r\nTotal 2376\r\n-rw-r--r--. 1 root root 1267244 10月 23 09:54 01.wav\r\n-rw-r--r--. 1 root root  105644 11月  5 2021 en.wav\r\ndrwxr-xr-x. 3 root root      17 10月 27 15:44 exp\r\n-rw-r--r--. 1 root root  718844 10月 27 14:44 male_mixfs2_dickens.wav\r\n-rw-r--r--. 1 root root  169844 10月 27 16:18 output.wav\r\n-rw-r--r--. 1 root root  159942 11月  5 2021 zh.wav\r\n\r\n_# 问题在这里(conda 环境 python=3.10.13，paddlepaddle=2.5.2 cpu)：_\r\n(paddle) [root@localhost sample]# paddlespeech st --input en.wav\r\nKeyError: '_tmp'\r\n\r\n(paddle) [root@localhost sample]# pip list | grep paddle\r\npaddle2onnx                 1.1.0\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.5.2\r\n**paddlepaddle                2.5.2**\r\npaddlesde                   0.2.5\r\npaddleslim                  2.4.1\r\n**paddlespeech                0.0.0**\r\npaddlespeech-ctcdecoders    0.2.0\r\npaddlespeech-feat           0.1.0",
        "state": "open",
        "user": "HsiangLeekwok",
        "closed_by": null,
        "created_at": "2023-10-27T08:50:40+00:00",
        "updated_at": "2023-11-02T03:20:11+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3566,
        "title": "训练 FastSpeech2 模型，执行run.sh时报错No such file or directory: 'pwg_baker_ckpt_0.4/pwg_default.yaml'",
        "body": "训练集拆分及训练语音模型已完成，\r\n已生成dump和exp目录\r\n\r\n执行语音合成报错\r\n:~/PaddleSpeech/examples/csmsc/tts3# ./run.sh --stage 2 --stop-stage 2\r\nTraceback (most recent call last):\r\n  File \"/root/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 257, in <module>\r\n    main()\r\n  File \"/root/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 253, in main\r\n    evaluate(args)\r\n  File \"/root/PaddleSpeech/paddlespeech/t2s/exps/fastspeech2/../synthesize.py\", line 43, in evaluate\r\n    with open(args.voc_config) as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'pwg_baker_ckpt_0.4/pwg_default.yaml'\r\n\r\n\r\n且已按要求将baker_alignment_tone解压至run.sh同级目录\r\n:~/PaddleSpeech/examples/csmsc/tts3# ll \r\ntotal 2136\r\ndrwxr-xr-x  7 root root    4096 10月 30 13:42 ./\r\ndrwxr-xr-x 13 root root    4096 10月 29 11:21 ../\r\ndrwxr-xr-x  3 root root    4096 10月 30 13:53 baker_alignment_tone/\r\ndrwxr-xr-x  2 root root    4096 10月 30 12:17 conf/\r\ndrwxr-xr-x  5 root root    4096 10月 30 13:26 dump/\r\n-rw-r--r--  1 root root 2097388 10月 30 13:26 durations.txt\r\ndrwxr-xr-x  3 root root    4096 10月 30 13:42 exp/\r\ndrwxr-xr-x  2 root root    4096 10月 29 11:21 local/\r\n-rwxr-xr-x  1 root root     377 10月 29 11:21 path.sh*\r\n-rw-r--r--  1 root root   13807 10月 29 11:21 README_cn.md\r\n-rw-r--r--  1 root root   16431 10月 29 11:21 README.md\r\n-rwxr-xr-x  1 root root    5587 10月 29 11:21 run_cnndecoder.sh*\r\n-rwxr-xr-x  1 root root    3696 10月 29 11:21 run.sh*\r\n-rw-r--r--  1 root root    1403 10月 29 11:21 run_xpu.sh\r\n\r\n\r\n请问是什么问题导致？",
        "state": "closed",
        "user": "shadowlkx",
        "closed_by": "shadowlkx",
        "created_at": "2023-10-30T06:44:21+00:00",
        "updated_at": "2023-10-30T06:53:15+00:00",
        "closed_at": "2023-10-30T06:53:15+00:00",
        "comments_count": [
            "shadowlkx"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3565,
        "title": "解决：ImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory",
        "body": "1. 直接获取 libcudart.so.10.2\r\n链接: https://pan.baidu.com/s/1JctSCWNLkuO44LkmH3hqeA?pwd=cbh8 提取码: cbh8\r\n\r\n2. 存放到（例如）'/usr/local/cuda/cuda-10.2/lib64/'下，‘cuda/cuda-10.2/lib64/’这些文件夹可能不存在，可以直接自己创建\r\n\r\n3. 添加'LD_LIBRARY_PATH'到'~/.bashrc'\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/cuda-10.2/lib64\r\n\r\n4. source ~/.bashrc\r\n\r\n5.随后可能出现的cudnn问题也一样",
        "state": "closed",
        "user": "ChengsongLu",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-28T21:13:08+00:00",
        "updated_at": "2025-06-27T04:34:43+00:00",
        "closed_at": "2025-06-27T04:34:43+00:00",
        "comments_count": [
            "ChengsongLu",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3570
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3569,
        "title": "[TTS]运行t2s时遇到问题：xml.parsers.expat.ExpatError: mismatched tag: line 1, column 35",
        "body": "当进行t2s时，文本内容为：此外，DeepSpark开源社区主要致力于百大应用开放平台的打造和推广。\"></指令>\r\n使用的是paddlespeech r1.4版本\r\n报以下错误：\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 471, in infer\r\n    frontend_dict = run_frontend(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 318, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/mix_frontend.py\", line 163, in get_input_ids\r\n    input_ids = self.zh_frontend.get_input_ids_ssml(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 587, in get_input_ids_ssml\r\n    l_inputs = MixTextProcessor.get_pinyin_split(sentence)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 69, in get_pinyin_split\r\n    dom = DomXml(in_xml)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 102, in __init__\r\n    self.tdom = parseString(xmlstr)  #Document\r\n  File \"/usr/local/lib/python3.9/xml/dom/minidom.py\", line 1998, in parseString\r\n    return expatbuilder.parseString(string)\r\n  File \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 925, in parseString\r\n    return builder.parseString(string)\r\n  File \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 223, in parseString\r\n    parser.Parse(string, True)\r\nxml.parsers.expat.ExpatError: mismatched tag: line 1, column 35\r\n",
        "state": "open",
        "user": "G1017",
        "closed_by": null,
        "created_at": "2023-10-31T02:19:26+00:00",
        "updated_at": "2023-10-31T02:19:26+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3567,
        "title": "[TTS]Windows10 CPU fastspeech2_mix_onnx_0.2.0遇到am_sess.run(None, input_feed=am_input_feed)时不报错，直接结束运行代码",
        "body": "环境：windows10 CPU Core i7\r\n\r\n```\r\nconda create -n audio python=3.9 libuv\r\nconda activate audio\r\npip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\r\npip install pytest-runner paddlespeech==1.4.1  或者 paddlespeech==1.4.0\r\npip install langid==1.1.6 zhconv==1.4.3 transformers==4.31.0 SpeechRecognition==3.10.0\r\npip install onnx==1.14.1\r\npip install accelerate sentencepiece protobuf py-cpuinfo\r\npip install scipy pyaudio wave soundfile\r\npip install numpy==1.23\r\n```\r\n\r\n模型下载：https://paddlespeech.bj.bcebos.com/t2s/chinse_english_mixed/models/fastspeech2_mix_onnx_0.2.0.zip\r\n参考代码来自：https://github.com/PaddlePaddle/PaddleSpeech/blob/1dc67f96e0d083adb291589cecb28c9181914a07/paddlespeech/t2s/exps/ort_predict.py#L28\r\n\r\n在Windows CPU运行脚本test_tts_win.py如下：在am_sess.run(None, input_feed=am_input_feed)时不报错，直接结束运行脚本test_tts_win.py\r\n\r\n```\r\ndef load_tts_model2(model_path, device):\r\n    print(\"loading tts fastspeech2_mix---------\") \r\n    t4 = time.time()\r\n    cpu_threads = 4\r\n    spk_id = 174\r\n\r\n    #am = 'fastspeech2_mix'\r\n    phones_dict= model_path + \"fastspeech2_mix_onnx_0.2.0/phone_id_map.txt\"   \r\n    am_model_path = model_path + \"fastspeech2_mix_onnx_0.2.0/fastspeech2_mix.onnx\"   \r\n    voc_model_path = model_path + \"fastspeech2_mix_onnx_0.2.0/hifigan_csmsc.onnx\"\r\n    show_memory_info(\"before loading tts 1 \")\r\n\r\n    tts_frontend = MixFrontend(phone_vocab_path=phones_dict)\r\n\r\n    providers = ['CPUExecutionProvider']\r\n    sess_options = ort.SessionOptions()\r\n    \r\n    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\r\n\r\n    sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\r\n    sess_options.intra_op_num_threads = cpu_threads\r\n\r\n    am_sess = ort.InferenceSession(am_model_path, providers=providers, sess_options=sess_options)\r\n\r\n    voc_sess = ort.InferenceSession(voc_model_path, providers=providers, sess_options=sess_options)\r\n    print(\"tts fastspeech2_mix load model done! Warmup start----\")\r\n    merge_sentences = True\r\n\r\n    # frontend warmup\r\n    # Loading model cost 0.5+ seconds\r\n    tts_frontend.get_input_ids(\r\n                \"hello, thank you, thank you very much\",\r\n                merge_sentences=merge_sentences)\r\n    print(\"tts fastspeech2_mix load model done! Warmup start  am warmup ----\")\r\n    ## am warmup\r\n    spk_id = [spk_id]\r\n    for T in [27, 38, 54]:\r\n        am_input_feed = {}\r\n        phone_ids = np.random.randint(1, 266, size=(T, ))\r\n        am_input_feed.update({'text': phone_ids})\r\n        am_input_feed.update({'spk_id': spk_id})\r\n        print(\" am warmup 1----\")\r\n        am_sess.run(None, input_feed=am_input_feed)    #### skip！！！！！！！！！！！！！！\r\n        print(\" am warmup 2----\")\r\n    print(\"tts fastspeech2_mix load model done! Warmup start  voc warmup ----\")\r\n    # voc warmup\r\n    for T in [227, 308, 544]:\r\n        data = np.random.rand(T, 80).astype(\"float32\")\r\n        voc_sess.run(None, input_feed={\"logmel\": data})\r\n    print(\"tts warm up done!\")\r\n    t5 = time.time()\r\n    print(\"loading TTS fastspeech2_mix---------Done, cost time(s): \", t5-t4)\r\n\r\n    print(\"loading TTS tacotron2-DDC---------\")\r\n\r\nload_tts_model2(\"./models/\", \"cpu\")\r\n```",
        "state": "open",
        "user": "biyuehuang",
        "closed_by": null,
        "created_at": "2023-10-30T10:02:18+00:00",
        "updated_at": "2024-02-07T15:38:53+00:00",
        "closed_at": null,
        "comments_count": [
            "wyzhe"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3568,
        "title": "运行t2s时遇到问题：xml.parsers.expat.ExpatError: mismatched tag: line 1, column 35",
        "body": "当运行文本为：此外，DeepSpark开源社区主要致力于百大应用开放平台的打造和推广。\"></指令>\r\n出现以下错误：\r\n File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 710, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"/usr/local/corex/lib64/python3/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 471, in infer\r\n    frontend_dict = run_frontend(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 318, in run_frontend\r\n    input_ids = frontend.get_input_ids(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/mix_frontend.py\", line 163, in get_input_ids\r\n    input_ids = self.zh_frontend.get_input_ids_ssml(\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 587, in get_input_ids_ssml\r\n    l_inputs = MixTextProcessor.get_pinyin_split(sentence)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 69, in get_pinyin_split\r\n    dom = DomXml(in_xml)\r\n  File \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 102, in __init__\r\n    self.tdom = parseString(xmlstr)  #Document\r\n  File \"/usr/local/lib/python3.9/xml/dom/minidom.py\", line 1998, in parseString\r\n    return expatbuilder.parseString(string)\r\n  File \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 925, in parseString\r\n    return builder.parseString(string)\r\n  File \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 223, in parseString\r\n    parser.Parse(string, True)\r\nxml.parsers.expat.ExpatError: mismatched tag: line 1, column 35\r\n\r\n\r\n\r\n麻烦帮忙解决一下，谢谢",
        "state": "open",
        "user": "G1017",
        "closed_by": "G1017",
        "created_at": "2023-10-30T12:06:26+00:00",
        "updated_at": "2025-06-27T02:32:36+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "G1017",
            "G1017",
            "G1017",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3571,
        "title": "[S2T]语音转文字时提示系统找不到指定文件",
        "body": "Traceback (most recent call last):\r\n  File \"D:\\kzj\\PaddleSpeech-develop\\kzj\\test3.py\", line 3, in <module>\r\n    result = st(audio_file=\"en.wav\")\r\n  File \"D:\\kzj\\PaddleSpeech-develop\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"D:\\kzj\\PaddleSpeech-develop\\paddlespeech\\cli\\st\\infer.py\", line 347, in __call__\r\n    self.preprocess(audio_file, model)\r\n  File \"D:\\kzj\\PaddleSpeech-develop\\paddlespeech\\cli\\st\\infer.py\", line 206, in preprocess\r\n    fbank_extract_process = subprocess.Popen(\r\n  File \"C:\\Users\\keith\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py\", line 853, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"C:\\Users\\keith\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py\", line 1306, in _execute_child\r\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\r\nFileNotFoundError: [WinError 2] 系统找不到指定的文件。\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [6.3.0]\r\n - Python Version [3.8.5]\r\n - PaddlePaddle Version [2.4.1]\r\n - Model Version [e.g. 2.0.0]\r\n\r\n**Additional context**\r\nfrom paddlespeech.cli.st.infer import STExecutor\r\nst = STExecutor()\r\nresult = st(audio_file=\"en.wav\")\r\nprint(result)\r\n",
        "state": "closed",
        "user": "chn112211",
        "closed_by": "chn112211",
        "created_at": "2023-10-31T06:34:54+00:00",
        "updated_at": "2023-10-31T06:55:51+00:00",
        "closed_at": "2023-10-31T06:55:22+00:00",
        "comments_count": [
            "chn112211"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3573,
        "title": "TTS中文文本前端的add_blank参数",
        "body": "请问中文文本前端中的add_blank参数的作用是什么？\r\n在选择pypinyin作为g2p模型，blank_token为<pad>的情况下，开启add_blank前后的合成效果没有变化\r\n",
        "state": "closed",
        "user": "RechinW",
        "closed_by": "stale[bot]",
        "created_at": "2023-10-31T08:10:19+00:00",
        "updated_at": "2025-06-27T04:34:44+00:00",
        "closed_at": "2025-06-27T04:34:44+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3574,
        "title": "[TTS]Android端Demo输入文本过长 libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR)",
        "body": "输入文本达到一定长度崩溃\r\n输入:\r\n            {262, 44, 151, 74, 182, 82, 240, 177, 213, 37, 184, 40, 202, 180, 175, 52, 154, 55, 71, 54, 37, 186, 40, 42, 40, 7, 261, 10, 151, 77, 153, 74, 37, 186, 39, 183, 154, 52,\r\n                    262, 44, 151, 74, 182, 82, 240, 177, 213, 37, 184, 40, 202, 180, 175, 52, 154, 55, 71, 54, 37, 186, 40, 42, 40, 7, 261, 10, 151, 77, 153, 74, 37, 186, 39, 183, 154, 52,\r\n                    262, 44, 151, 74, 182, 82, 240, 177, 213, 37, 184, 40, 202, 180, 175, 52, 154, 55, 71, 54, 37, 186, 40, 42, 40, 7, 261, 10, 151, 77, 153, 74, 37, 186, 39, 183, 154, 52,\r\n                    262, 44, 151, 74, 182, 82, 240, 177, 213, 37, 184, 40, 202, 180, 175, 52, 154, 55, 71, 54, 37, 186, 40, 42, 40, 7, 261, 10, 151, 77, 153, 74, 37, 186, 39, 183, 154, 52}\r\n\r\nnative error:\r\nlibc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0x7ddb954b40 in tid 17194 (Predictor Worke), pid 17140 (e.lite.demo.tts)\r\n\r\n",
        "state": "open",
        "user": "litong11451",
        "closed_by": null,
        "created_at": "2023-10-31T09:18:22+00:00",
        "updated_at": "2024-03-26T00:58:33+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "jonkxdd",
            "jonkxdd",
            "litong11451",
            "litong11451",
            "MrZhangX"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3575,
        "title": "我想用paddlespeech  的docker镜像运行在arm64架构的linux服务器上，但是我找不到合适的docker镜像包。",
        "body": "\r\n我想运行paddlespeech的docker镜像，用来给其它服务直接调用它的语音识别和语音合成功能，但是我找不到合适的docker镜像，和启动服务的步骤。",
        "state": "closed",
        "user": "zhutaotao-ai",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-02T06:13:41+00:00",
        "updated_at": "2025-06-27T05:32:36+00:00",
        "closed_at": "2025-06-27T05:32:36+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3576,
        "title": "asr server 录制空白声音post过去后，也会request回来一些文字",
        "body": "```\r\nasr_python:\r\n    model: 'conformer_wenetspeech'\r\n    lang: 'zh'\r\n    sample_rate: 16000\r\n    cfg_path: # [optional]\r\n    ckpt_path: # [optional]\r\n    decode_method: 'attention_rescoring'\r\n    num_decoding_left_chunks: -1\r\n    force_yes: True\r\n    device:  # set 'gpu:id' or 'cpu'\r\n\r\n\r\n################### speech task: asr; engine_type: inference #######################\r\nasr_inference:\r\n    # model_type choices=['deepspeech2offline_aishell']\r\n    model_type: 'deepspeech2offline_aishell'\r\n    am_model: # the pdmodel file of am static model [optional]\r\n    am_params:  # the pdiparams file of am static model [optional]\r\n    lang: 'zh'\r\n    sample_rate: 16000\r\n    cfg_path: \r\n    num_decoding_left_chunks: -1\r\n    decode_method: \r\n    force_yes: True\r\n\r\n    am_predictor_conf:\r\n        device:  # set 'gpu:id' or 'cpu'\r\n        switch_ir_optim: True\r\n        glog_info: False  # True -> print glog\r\n        summary: True  # False -> do not show predictor config\r\n```\r\n\r\n请问如何能做到，声音中没有人声的时候，可以返回空白，而不是随机的一些文字？",
        "state": "open",
        "user": "0902081008",
        "closed_by": null,
        "created_at": "2023-11-05T10:21:52+00:00",
        "updated_at": "2025-06-27T02:32:40+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3577,
        "title": "[S2T]安装未报错，使用就报错，这个问题折腾了3天了，真不夸张",
        "body": "我在docker中安装好了paddle2.5.0 paddlespeech1.4.1 过程无报错 也使用了官方提供的示例zh.wav文件，\r\n执行paddlespeech asr --lang zh --input ./zh.wav    ，直接报如下错误，不管我重装还是怎么回事都这样，docker容器系统是ubuntu20.04,cuda11.7 cudnn8.4.1\r\n\r\nroot@8ea5a783c6ce:/paddle/asr/test# paddlespeech asr --lang zh --input ./zh.wav    \r\nW1106 20:15:33.654063  5856 gpu_resources.cc:96] The GPU architecture in your current machine is Pascal, which is not compatible with Paddle installation with arch: 70 75 80 86 , it is recommended to install the corresponding wheel package according to the installation information on the official Paddle website.\r\nW1106 20:15:33.654111  5856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.7\r\nW1106 20:15:33.660698  5856 gpu_resources.cc:149] device: 0, cuDNN Version: 8.4.\r\n[2023-11-06 20:15:35,755] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/usr/local/lib/python3.8/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range",
        "state": "open",
        "user": "linglin506",
        "closed_by": null,
        "created_at": "2023-11-06T12:21:36+00:00",
        "updated_at": "2024-03-26T03:18:01+00:00",
        "closed_at": null,
        "comments_count": [
            "yaleimeng",
            "zxcd",
            "linglin506",
            "sunqinbo",
            "yaleimeng",
            "linglin506",
            "sinopec",
            "klzhong69"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3578,
        "title": "如何判断一个音频是否是静音（无人说话或者纯周围噪音）的情况，尽量速度快，不使用gpu资源",
        "body": "文件格式wav 单声道 16k采样",
        "state": "closed",
        "user": "zouhan6806504",
        "closed_by": "zouhan6806504",
        "created_at": "2023-11-07T03:21:04+00:00",
        "updated_at": "2023-11-07T13:32:58+00:00",
        "closed_at": "2023-11-07T13:32:58+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3579,
        "title": "声纹识别能制定加载离线模型路径吗",
        "body": "声纹识别能制定加载离线模型路径吗\r\n\r\n",
        "state": "open",
        "user": "lonngxiang",
        "closed_by": null,
        "created_at": "2023-11-07T08:50:10+00:00",
        "updated_at": "2024-04-15T07:43:19+00:00",
        "closed_at": null,
        "comments_count": [
            "lonngxiang",
            "chenzhen2018"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3580,
        "title": "[TTS] paddlespeech不再支持中英双语模型了吗？",
        "body": "列表里没有双语模型，只包含单语模型\r\nAssertionError: The model \"fastspeech2-mix\" you want to use has not been supported, please choose other models.\r\nThe support models includes:\r\n\t\tspeedyspeech_csmsc-zh\r\n\t\tfastspeech2_csmsc-zh\r\n\t\tfastspeech2_ljspeech-en\r\n\t\tfastspeech2_aishell3-zh\r\n\t\tfastspeech2_vctk-en\r\n\t\ttacotron2_csmsc-zh\r\n\t\ttacotron2_ljspeech-en\r\n\t\tpwgan_csmsc-zh\r\n\t\tpwgan_ljspeech-en\r\n\t\tpwgan_aishell3-zh\r\n\t\tpwgan_vctk-en\r\n\t\tmb_melgan_csmsc-zh\r\n\t\tstyle_melgan_csmsc-zh\r\n\t\thifigan_csmsc-zh\r\n\t\thifigan_ljspeech-en\r\n\t\thifigan_aishell3-zh\r\n\t\thifigan_vctk-en\r\n\t\twavernn_csmsc-zh\r\n",
        "state": "closed",
        "user": "hehexiong",
        "closed_by": "zxcd",
        "created_at": "2023-11-07T09:51:20+00:00",
        "updated_at": "2023-12-05T11:50:16+00:00",
        "closed_at": "2023-12-05T11:50:16+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3582,
        "title": "paddlespeech  声纹识别输入wav任何采样都可以吗",
        "body": "整体效果，自己用实时ffmpeg采样wav音频，声纹相似比较感受效果很差，不知道是采样wav原因还是",
        "state": "closed",
        "user": "lonngxiang",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-08T08:37:04+00:00",
        "updated_at": "2025-06-27T05:32:43+00:00",
        "closed_at": "2025-06-27T05:32:43+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3581,
        "title": "这个模型是否可以对人的英语单词发音评分？",
        "body": "这个模型是否可以实现对人的英语单词发音评分？\r\n\r\n比如现在有单词 good 的标准美式发音，用户发音后，利用这个模型给用户的发音总体打分，并且单词的每个音也要对其进行打分。比如good这个单词，其实发音是 g o d3个发音。能做到给用户展示正确的发音，并且还能对每个发音告知标准程度有多少。\r\n\r\n这种需求可以实现吗",
        "state": "closed",
        "user": "no13bus",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-07T20:31:25+00:00",
        "updated_at": "2025-06-27T05:32:40+00:00",
        "closed_at": "2025-06-27T05:32:40+00:00",
        "comments_count": [
            "zxcd",
            "no13bus",
            "no13bus",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3583,
        "title": "[TTS] example/aishell3/tts3/  怎么处理aishell3 的数据呢？",
        "body": "./run.sh --stage 0 --stop_stage 0\r\n执行至 /workspace/paddlespeech/paddlespeech/t2s/exps/fastspeech2/preprocess.py  287行，提示aishell3 路径缺少/aishell3/train/wav路径，aishell3数据集是从官网下载的，需要怎么样进行划分呢？ 这个preprocess.py 之前的也没处理啊\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/55222575/369e2893-1492-41a6-a8ae-98e6830443d3)\r\n",
        "state": "open",
        "user": "hexianbin1994",
        "closed_by": null,
        "created_at": "2023-11-09T06:08:23+00:00",
        "updated_at": "2023-12-05T11:57:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3584,
        "title": "xml解析错误，规范输入的文本格式：<>需要搭配出现仍然报错xml.parsers.expat.ExpatError: not well-formed (invalid token): line 1, column 14",
        "body": "搭配使用仍然报错\r\n以下为示例：\r\n示例1：<此外，DeepSpark开源社区主要致力于百大应用开放平台的打造和推广。\"></指令>\r\n报错：\r\nFile \"/root/apps/metahuman/creator/test.py\", line 54, in use_historical_model\r\ntts_historical(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\nreturn executor_func(self, *args, **kwargs)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 710, in call\r\nself.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\nFile \"/usr/local/corex/lib64/python3/dist-packages/decorator.py\", line 232, in fun\r\nreturn caller(func, *(extras + args), **kw)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\nreturn func(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 471, in infer\r\nfrontend_dict = run_frontend(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 318, in run_frontend\r\ninput_ids = frontend.get_input_ids(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/mix_frontend.py\", line 162, in get_input_ids\r\ninput_ids = self.zh_frontend.get_input_ids_ssml(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 587, in get_input_ids_ssml\r\nl_inputs = MixTextProcessor.get_pinyin_split(sentence)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 69, in get_pinyin_split\r\ndom = DomXml(in_xml)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 102, in init\r\nself.tdom = parseString(xmlstr) #Document\r\nFile \"/usr/local/lib/python3.9/xml/dom/minidom.py\", line 1998, in parseString\r\nreturn expatbuilder.parseString(string)\r\nFile \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 925, in parseString\r\nreturn builder.parseString(string)\r\nFile \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 223, in parseString\r\nparser.Parse(string, True)\r\nxml.parsers.expat.ExpatError: not well-formed (invalid token): line 1, column 10\r\n\r\n示例2：<指令><此外，DeepSpark开源社区主要致力于百大应用开放平台的打造和推广。\"></指令>\r\nFile \"/root/apps/metahuman/creator/test.py\", line 54, in use_historical_model\r\ntts_historical(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 328, in _warpper\r\nreturn executor_func(self, *args, **kwargs)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 710, in call\r\nself.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\nFile \"/usr/local/corex/lib64/python3/dist-packages/decorator.py\", line 232, in fun\r\nreturn caller(func, *(extras + args), **kw)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\nreturn func(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 471, in infer\r\nfrontend_dict = run_frontend(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 318, in run_frontend\r\ninput_ids = frontend.get_input_ids(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/mix_frontend.py\", line 162, in get_input_ids\r\ninput_ids = self.zh_frontend.get_input_ids_ssml(\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 587, in get_input_ids_ssml\r\nl_inputs = MixTextProcessor.get_pinyin_split(sentence)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 69, in get_pinyin_split\r\ndom = DomXml(in_xml)\r\nFile \"/usr/local/lib/python3.9/site-packages/paddlespeech/t2s/ssml/xml_processor.py\", line 102, in init\r\nself.tdom = parseString(xmlstr) #Document\r\nFile \"/usr/local/lib/python3.9/xml/dom/minidom.py\", line 1998, in parseString\r\nreturn expatbuilder.parseString(string)\r\nFile \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 925, in parseString\r\nreturn builder.parseString(string)\r\nFile \"/usr/local/lib/python3.9/xml/dom/expatbuilder.py\", line 223, in parseString\r\nparser.Parse(string, True)\r\nxml.parsers.expat.ExpatError: not well-formed (invalid token): line 1, column 14\r\n",
        "state": "closed",
        "user": "G1017",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-09T08:39:14+00:00",
        "updated_at": "2025-06-27T05:32:43+00:00",
        "closed_at": "2025-06-27T05:32:43+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3585,
        "title": "paddlespeech语音识别是否能获取到逐字或逐音素的音频数据？",
        "body": "paddlespeech 语音识别是否能获取到逐字或逐音素的音频数据？",
        "state": "closed",
        "user": "worldback",
        "closed_by": "worldback",
        "created_at": "2023-11-09T09:43:39+00:00",
        "updated_at": "2024-01-11T06:23:37+00:00",
        "closed_at": "2024-01-11T06:23:37+00:00",
        "comments_count": [
            "zxcd",
            "worldback",
            "bigmisspanda"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3586,
        "title": "MacOS Python crash",
        "body": "MacOS: Ventura \r\n\r\npaddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/4213973/2a82c8a1-897a-48eb-a058-03a593fd007f)",
        "state": "open",
        "user": "neobie",
        "closed_by": null,
        "created_at": "2023-11-09T16:34:17+00:00",
        "updated_at": "2023-12-05T12:22:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3587,
        "title": "[TTS] --speed 报错",
        "body": "paddlespeech_client tts --server_ip 127.0.0.1 --port 8090 --input \"您好，欢迎使用百度飞桨语音合成服务。测试123\" --speed 0.9 --output output.wav\r\n[2023-11-10 06:48:34,817] [   ERROR] - Failed to synthesized audio.\r\n[2023-11-10 06:48:34,817] [   ERROR] - 'result'\r\n\r\n如果 speed 1.0 就没问题。",
        "state": "open",
        "user": "neobie",
        "closed_by": null,
        "created_at": "2023-11-10T06:53:36+00:00",
        "updated_at": "2023-12-05T12:22:48+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3588,
        "title": "tts_online_ws_application 403错误，为什么？",
        "body": "## General Question\r\n\r\n我的示例：\r\npaddlespeech_server start --config_file ./conf/tts_online_ws_application.yaml\r\n结果如下：\r\n```\r\n[2023-11-11 09:01:37,518] [    INFO] - endpoint: http://127.0.0.1:8190/paddlespeech/text\r\n[2023-11-11 09:01:37,529] [    INFO] - start to init the engine\r\n[2023-11-11 09:01:37,529] [    INFO] - tts : online-onnx engine.\r\n[2023-11-11 09:01:48,073] [    INFO] - Already cached /root/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\r\n[2023-11-11 09:01:48,083] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\r\n[2023-11-11 09:01:48,083] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\r\n[2023-11-11 09:01:48,215] [    INFO] - Initialize TTS server engine successfully on device: cpu.\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-11-11 09:01:48,216] [   DEBUG] __init__.py:113 - Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2023-11-11 09:01:48,216] [   DEBUG] __init__.py:132 - Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.556 seconds.\r\n[2023-11-11 09:01:48,772] [   DEBUG] __init__.py:164 - Loading model cost 0.556 seconds.\r\nPrefix dict has been built successfully.\r\n[2023-11-11 09:01:48,772] [   DEBUG] __init__.py:166 - Prefix dict has been built successfully.\r\nINFO:     Started server process [2234]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8192 (Press CTRL+C to quit)\r\nINFO:     ('10.147.20.80', 60927) - \"WebSocket /ws/tts/online\" 403\r\nINFO:     connection failed (403 Forbidden)\r\nINFO:     connection closed\r\n\r\n```\r\n\r\n我使用的是客户端webclient发送ws请求。但没有 找到任何与监权相关的内容，直接出错。请问是bug吗？",
        "state": "closed",
        "user": "tms2003",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-11T09:07:47+00:00",
        "updated_at": "2025-06-27T05:32:45+00:00",
        "closed_at": "2025-06-27T05:32:45+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3589,
        "title": "普通话轻音和儿化音不标注，文本转因素能识别出来吗？",
        "body": "## 如果不能，轻音、儿化音、包括一些常见的口语化怎么标注数据?\r\n\r\n<!--\r\n轻音举例：\r\n    \"filename\": \"AC00061014.wav\",\r\n    \"filepath\": \"/home/aistudio/work/station/AC00061014.wav\",\r\n    \"asr_result\": \"丈夫有工夫跟师父去看大夫\",\r\n　　\"pinyin\": \"zhang4 fu you3 gong1 fu gen1 shi1 fu qu4 kan4 dai4 fu\"\r\n\r\n这里边丈夫的夫、工夫的夫、师父的父、大夫的夫都是轻音，应该怎么标注呢？是不标声调序号，还是有特殊标注方式？\r\n\r\n类似的还有：\r\n {\r\n    \"filename\": \"AC00061015.wav\",\r\n    \"filepath\": \"/home/aistudio/work/station/AC00061015.wav\",\r\n    \"asr_result\": \"寡妇时时提防被街坊欺负\",\r\n　　\"pinyin\": \"gua fu shi shi di fang bei jie fang qi fu\"\r\n  },\r\n\r\n儿化音举例：\r\n {\r\n    \"filename\": \"AC00041025.wav\",\r\n    \"filepath\": \"/home/aistudio/work/station/AC00041025.wav\",\r\n    \"asr_result\": \"大杂院儿好人缘儿送手绢儿赠烟卷儿\",\r\n　　\"pinyin\": \"da4 za2 yuan4 er4 hao3 ren2 yuan2 er2 song4 shou3 juan4 er4 zeng4 yan1 juan3 er3\"\r\n  },\r\n请问以上这种标注方法是否正确？如果不对请指正，本人北京人儿化音占比很高，非常感谢\r\n\r\n口语化举例：\r\n {\r\n    \"filename\": \"BD00031003.wav\",\r\n    \"filepath\": \"/home/aistudio/work/station/BD00031003.wav\",\r\n    \"asr_result\": \"这条街这座楼俯瞰这座城\",\r\n　　\"pinyin\": \"zhe4 e4 tiao2 jie1 zhe4 e4 zuo4 lou2 fu3 kan4 zhe4 e4 zuo4 cheng2\"\r\n  },\r\n\r\n {\r\n    \"filename\": \"BD00031010.wav\",\r\n    \"filepath\": \"/home/aistudio/work/station/BD00031010.wav\",\r\n    \"asr_result\": \"那谁家那小谁喝了谁的酒醉在谁的床\",\r\n　　\"pinyin\": \"nei4 e4 shui2 e2 jia1 nei4 xiao3 shui2 ei2 he1 le4 shui2 e2 de4 jiu3 zui4 zai4 shui2 e2 de4 chuang2\"\r\n  },\r\n\r\n像【这】【那】【谁】口语和书面拼音的区别怎么处理？\r\n书面：zhe4、na4、shui2，但很多整句按拼音读出来就很怪\r\n\r\n口语zhei4、nei4、shei2，但这种音标方式汉语拼音是没有的，那怎么标呢？谢谢\r\n\r\n\r\n-->\r\n",
        "state": "closed",
        "user": "woshinidaye777",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-12T12:12:49+00:00",
        "updated_at": "2025-06-27T05:32:45+00:00",
        "closed_at": "2025-06-27T05:32:45+00:00",
        "comments_count": [
            "woshinidaye777",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3590,
        "title": "如何实现实时的语音转文字？",
        "body": "## General Question\r\n我想在麦克风输入音频，然后实时输出。请问怎么实现呢\r\n",
        "state": "closed",
        "user": "qingfuliu",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-13T03:18:33+00:00",
        "updated_at": "2025-06-27T05:32:47+00:00",
        "closed_at": "2025-06-27T05:32:47+00:00",
        "comments_count": [
            "pifeifei",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3591,
        "title": "[TTS] 模型已经下载，运行 paddlespeech tts 没有默认加载本地模型",
        "body": "paddlespeech版本1.4\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/40717349/d2593113-4194-4c65-ad58-84c0f10e301c)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/40717349/a5e8a9b9-8cd3-46d1-8a61-58cf0bf6e541)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/40717349/d7189f43-2370-4249-9a6f-5eb8a484b0fc)\r\n",
        "state": "closed",
        "user": "lonngxiang",
        "closed_by": "lonngxiang",
        "created_at": "2023-11-13T03:41:10+00:00",
        "updated_at": "2023-11-13T04:18:25+00:00",
        "closed_at": "2023-11-13T04:18:25+00:00",
        "comments_count": [
            "G1017",
            "lonngxiang",
            "G1017",
            "G1017",
            "lonngxiang"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3592,
        "title": "docker部署 paddlecloud/paddlespeech:develop-cpu-latest，启动时，报zipfile.BadZipFile: File is not a zip file",
        "body": "docker部署 paddlecloud/paddlespeech:develop-cpu-latest，启动时，报zipfile.BadZipFile: File is not a zip file\r\n\r\n启动命令：  paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\r\n\r\n报错页面：\r\n<img width=\"730\" alt=\"微信图片_20231113141906\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/140780477/798258e4-f88f-4e86-b83d-8c4475d765e8\">\r\n\r\n",
        "state": "open",
        "user": "zhutaotao-ai",
        "closed_by": null,
        "created_at": "2023-11-13T06:19:35+00:00",
        "updated_at": "2025-06-27T02:32:42+00:00",
        "closed_at": null,
        "comments_count": [
            "zhutaotao-ai",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3595,
        "title": "包依赖太多，尤其是需要实时编译的包",
        "body": "如webrtcvad windows编译不通过",
        "state": "open",
        "user": "williamlzw",
        "closed_by": null,
        "created_at": "2023-11-14T09:13:24+00:00",
        "updated_at": "2023-11-14T09:13:24+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3594,
        "title": "训练中断，如何从checkpoint恢复[TTS]XXXX",
        "body": "您好，请问在跑PaddleSpeech/examples/csmsc/tts3中的示例时，训练意外中断，想要从上一次的checkpoint中恢复，该如何操作？\r\n",
        "state": "open",
        "user": "leeshion11",
        "closed_by": null,
        "created_at": "2023-11-14T03:48:01+00:00",
        "updated_at": "2023-12-05T12:38:07+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3593,
        "title": "docker启动报错，declarative() got an unexpected keyword argument 'property'",
        "body": "docker启动paddlespeech，报declarative() got an unexpected keyword argument 'property'，且启动不成功。\r\n<img width=\"842\" alt=\"微信图片_20231113141906\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/140780477/be057822-aec0-4582-ab85-45f2f2174804\">\r\n\r\n",
        "state": "closed",
        "user": "zhutaotao-ai",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-13T07:46:45+00:00",
        "updated_at": "2025-06-27T05:32:47+00:00",
        "closed_at": "2025-06-27T05:32:47+00:00",
        "comments_count": [
            "zhutaotao-ai",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3596,
        "title": "Permission denied: 'git'",
        "body": "在linux环境安装paddleSpeech1.4.1版本，使用了pyhton1.8和3.10都会报这样的错误。\r\n`Building wheels for collected packages: paddlespeech\r\n  Building wheel for paddlespeech (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × python setup.py bdist_wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [25 lines of output]\r\n      \r\n      __version__ = '0.0.0'\r\n      \r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"/app/paddle/PaddleSpeech/setup.py\", line 331, in <module>\r\n          with version_info():\r\n        File \"/app/anconda3/conda/envs/paddle38/lib/python3.8/contextlib.py\", line 113, in __enter__\r\n          return next(self.gen)\r\n        File \"/app/paddle/PaddleSpeech/setup.py\", line 247, in version_info\r\n          write_version_py()\r\n        File \"/app/paddle/PaddleSpeech/setup.py\", line 225, in write_version_py\r\n          COMMITID = check_output(\"git rev-parse HEAD\")\r\n        File \"/app/paddle/PaddleSpeech/setup.py\", line 115, in check_output\r\n          out_bytes = sp.check_output(cmd.split())\r\n        File \"/app/anconda3/conda/envs/paddle38/lib/python3.8/subprocess.py\", line 415, in check_output\r\n          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\r\n        File \"/app/anconda3/conda/envs/paddle38/lib/python3.8/subprocess.py\", line 493, in run\r\n          with Popen(*popenargs, **kwargs) as process:\r\n        File \"/app/anconda3/conda/envs/paddle38/lib/python3.8/subprocess.py\", line 858, in __init__\r\n          self._execute_child(args, executable, preexec_fn, close_fds,\r\n        File \"/app/anconda3/conda/envs/paddle38/lib/python3.8/subprocess.py\", line 1720, in _execute_child\r\n          raise child_exception_type(errno_num, err_msg, err_filename)\r\n      PermissionError: [Errno 13] Permission denied: 'git'\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for paddlespeech\r\n  Running setup.py clean for paddlespeech\r\nFailed to build paddlespeech\r\nERROR: Could not build wheels for paddlespeech, which is required to install pyproject.toml-based projects`\r\n\r\n\r\n",
        "state": "open",
        "user": "xxch",
        "closed_by": null,
        "created_at": "2023-11-14T10:26:07+00:00",
        "updated_at": "2023-11-16T07:25:53+00:00",
        "closed_at": null,
        "comments_count": [
            "xxch",
            "skyboooox"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3597,
        "title": "使用Python接口生成英文语音出错",
        "body": "使用Python接口生成英文语音提示模型找不到，这个是怎么回事，有大佬可以解答下吗，感谢🙏\r\n<img width=\"1113\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/24642960/469223b7-dff9-4690-be6f-88dc1012d849\">",
        "state": "closed",
        "user": "hylinux1024",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-15T16:02:01+00:00",
        "updated_at": "2025-06-27T05:32:48+00:00",
        "closed_at": "2025-06-27T05:32:48+00:00",
        "comments_count": [
            "hylinux1024",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3598,
        "title": "TTSCppFrontend front_demo崩溃",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n在windows上用vs2022跑TTSCppFrontend 中的front_demo运行崩溃，崩溃函数为GetSentenceIds(s_sentence, &phoneids, &toneids)，其中s_sentence为\"你好，\"且为utf8格式的std::string，截图如下：\r\n![捕获1](https://github.com/PaddlePaddle/PaddleSpeech/assets/51219602/c5e08f19-3b2b-423f-abed-8cb7e82f886e)\r\n\r\n\r\n\r\n具体到崩溃的地方查明崩溃原因是数组越界，截图如下：\r\n![捕获2](https://github.com/PaddlePaddle/PaddleSpeech/assets/51219602/cbc9d531-0a60-4ca7-80e5-926066c2bb12)\r\n\r\n以下是我的分析：\r\nGetPhone(word, &phone);  //获取字词对应的音素，这里word是utf8 std::string格式的\"你好，\"，执行完后phone为空，并没有成功获取音素，进而导致后面的phone_vec.size为1，用索引值1访问就越界了。\r\n进而分析获取不到音素的原因，查找音素会去遍历word_phone_map，这个应该是读取自配置文件word2phone_fs2.dict，项目里是没有这个文件的，我用word2phones.py脚本来得到这个文件的过程中发生了一些错误，我稍加修改才成功得到了它，比如将jieba_part.dict.utf8修改为jieba.dict.utf8因为我没有找到带part的文件，还有编码问题则按照https://github.com/PaddlePaddle/PaddleSpeech/issues/2955 来解决。\r\n\r\n究竟是因为我这个文件的问题还是哪里的问题导致demo崩溃？",
        "state": "closed",
        "user": "tuotuoshao",
        "closed_by": "tuotuoshao",
        "created_at": "2023-11-16T08:48:23+00:00",
        "updated_at": "2023-11-20T04:11:03+00:00",
        "closed_at": "2023-11-20T04:11:02+00:00",
        "comments_count": [
            "tuotuoshao",
            "tuotuoshao"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3600,
        "title": "请问有支持英语Streaming语音ASR的模型吗？",
        "body": "## General Question\r\n从文件名看 deepspeech2offline_librispeech 模型是不支持Streaming服务的。\r\ntransformer_librispeech 模型是否支持Streaming服务呢？\r\n@zh794390558 \r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "mzgcz",
        "closed_by": "mzgcz",
        "created_at": "2023-11-18T03:02:36+00:00",
        "updated_at": "2023-12-06T01:45:18+00:00",
        "closed_at": "2023-12-06T01:45:18+00:00",
        "comments_count": [
            "zxcd",
            "mzgcz"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3599,
        "title": "语音格式支持的范围\".wav\", \".mp3\", \".ogg\", \".flac\", \".m4a\" ",
        "body": "看着说明是支持这些格式的supported_formats = [\".wav\", \".mp3\", \".ogg\", \".flac\", \".m4a\"]\r\n但是我在调用的时候报错\r\ndef paddlespeech_request(url, data):\r\n    \"\"\"\r\n    构造PaddleSpeech所需的post请求\r\n    \"\"\"\r\n    res = requests.post(\r\n        url=url,\r\n        data=json.dumps(data)\r\n    )\r\n    if res.status_code == 200:\r\n        res = res.json()\r\n    else:\r\n        print(\"请求失败，错误代码：\", res.status_code)\r\n        res = None\r\n    return res\r\nif __name__ == '__main__':\r\n    wav_file = \"zh.wav\"\r\n    asr_url = \"http://127.0.0.1:8090/paddlespeech/asr\"\r\n    # 将wav转成base64\r\n    with open(wav_file, 'rb') as f:\r\n        base64_bytes = base64.b64encode(f.read())\r\n        base64_string = base64_bytes.decode('utf-8')\r\n    data = {\r\n        \"audio\": base64_string,\r\n        \"audio_format\": \"wav\",\r\n        \"sample_rate\": 16000,\r\n        \"lang\": \"zh_cn\",\r\n        \"punc\": 0\r\n    }\r\n    res = paddlespeech_request(asr_url, data)\r\n    print(res)\r\n但是报错\r\n\r\nsoundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x000001DC326F6A70>: Format not recognised.\r\n[2023-11-17 16:12:56,509] [   ERROR] - can not open the audio file, please check the audio file(<_io.BytesIO object at 0x000001DC326F6A70>) format is 'wav'.\r\n                  you can try to use sox to change the file format.\r\n                  For example:\r\n                  sample rate: 16k\r\n                  sox input_audio.xx --rate 16k --bits 16 --channels 1 output_audio.wav\r\n                  sample rate: 8k\r\n是需要修改什么参数吗？",
        "state": "open",
        "user": "xxch",
        "closed_by": null,
        "created_at": "2023-11-17T08:18:44+00:00",
        "updated_at": "2023-12-05T12:45:32+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3602,
        "title": "[TTS]微调实验other/tts_finetune/tts3的bug",
        "body": "最近在调用other/tts_finetune/tts3下的代码进行人声微调的过程中，我发现一个问题——当数据已经处理好了以后，运行./run.sh --stage 5 --stop-stage 5，除了第一次调用训练的时候iter是从99200开始，即微调；除此之后的每一次运行都是从0开始，即从头训练，这是个什么情况",
        "state": "closed",
        "user": "Xwmiss",
        "closed_by": "Xwmiss",
        "created_at": "2023-11-20T09:46:23+00:00",
        "updated_at": "2023-11-20T10:08:54+00:00",
        "closed_at": "2023-11-20T10:08:54+00:00",
        "comments_count": [
            "Xwmiss",
            "Xwmiss",
            "Xwmiss"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3601,
        "title": "Ubuntu中白报错",
        "body": "## Others\r\n\r\n<!--\r\n(/home/python/tools/venv) python@lk-ai-sheb:~/PaddleSpeech$ paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\nTraceback (most recent call last):\r\n  File \"/home/python/tools/venv/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/cli/tts/infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 37, in <module>\r\n    from paddlespeech.t2s.frontend.en_frontend import English\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/t2s/frontend/en_frontend.py\", line 14, in <module>\r\n    from .phonectic import English\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/paddlespeech/t2s/frontend/phonectic.py\", line 20, in <module>\r\n    from g2p_en import G2p\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/g2p_en/__init__.py\", line 1, in <module>\r\n    from .g2p import G2p\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/g2p_en/g2p.py\", line 22, in <module>\r\n    nltk.data.find('taggers/averaged_perceptron_tagger.zip')\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/nltk/data.py\", line 542, in find\r\n    return ZipFilePathPointer(p, zipentry)\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/nltk/data.py\", line 394, in __init__\r\n    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/nltk/compat.py\", line 41, in _decorator\r\n    return init_func(*args, **kwargs)\r\n  File \"/home/python/tools/venv/lib/python3.8/site-packages/nltk/data.py\", line 935, in __init__\r\n    zipfile.ZipFile.__init__(self, filename)\r\n  File \"/home/python/tools/venv/lib/python3.8/zipfile.py\", line 1269, in __init__\r\n    self._RealGetContents()\r\n  File \"/home/python/tools/venv/lib/python3.8/zipfile.py\", line 1336, in _RealGetContents\r\n    raise BadZipFile(\"File is not a zip file\")\r\nzipfile.BadZipFile: File is not a zip file\r\n(/home/python/tools/venv) python@lk-ai-sheb:~/PaddleSpeech$\r\n\r\n-->\r\n",
        "state": "closed",
        "user": "CrushLSG",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-18T05:38:13+00:00",
        "updated_at": "2025-06-27T05:32:56+00:00",
        "closed_at": "2025-06-27T05:32:56+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3603,
        "title": "English TTS in streaming of paddlespeech",
        "body": "I am running paddlespeech tts streaming server on my ubuntu 22.04\r\nI can't convert english text to speech.\r\nHow to resolve this?",
        "state": "open",
        "user": "billdevmaster",
        "closed_by": null,
        "created_at": "2023-11-20T16:34:49+00:00",
        "updated_at": "2024-01-02T11:14:08+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3605,
        "title": "[TTS]windows下启动报错",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nwindows下启动`online-onnx`报错\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n```\r\n# -*- coding: utf-8 -*-\r\n\r\nfrom paddlespeech.server.bin.paddlespeech_server import ServerExecutor\r\n\r\nserver_executor = ServerExecutor()\r\nserver_executor(\r\n    config_file=\"./application.yaml\", \r\n    log_file=\"./paddlespeech.log\")\r\n```\r\n\r\n```\r\npython main.py -X utf8\r\n```\r\n\r\n**Expected behavior**\r\n```\r\nPS E:\\temp_code\\server> python main.py -X utf8\r\nE:\\environment\\python\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\n  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\n[2023-11-22 10:10:19,579] [    INFO] - start to init the engine\r\n[2023-11-22 10:10:19,580] [    INFO] - tts : online-onnx engine.\r\n[2023-11-22 10:10:23,437] [   ERROR] - Failed to get model related files.\r\n[2023-11-22 10:10:23,437] [   ERROR] - Initialize TTS server engine Failed on device: cpu.\r\nTraceback (most recent call last):\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\engine\\tts\\online\\onnx\\tts_engine.py\", line 235, in init      \r\n    self.executor._init_from_path(\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\engine\\tts\\online\\onnx\\tts_engine.py\", line 158, in _init_from_path\r\n    phn_id = [line.strip().split() for line in f.readlines()]\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0x8c in position 2088: illegal multibyte sequence\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\temp_code\\server\\main.py\", line 6, in <module>\r\n    server_executor(\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\util.py\", line 365, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\bin\\paddlespeech_server.py\", line 116, in __call__\r\n    if self.init(config):\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\bin\\paddlespeech_server.py\", line 89, in init\r\n    if not init_engine_pool(config):\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\engine\\engine_pool.py\", line 38, in init_engine_pool\r\n    if not ENGINE_POOL[engine].init(config=config[engine_and_type]):\r\n  File \"E:\\environment\\python\\lib\\site-packages\\paddlespeech\\server\\engine\\tts\\online\\onnx\\tts_engine.py\", line 254, in init      \r\n    logger(e)\r\nTypeError: Logger.__call__() missing 1 required positional argument: 'msg'\r\n```\r\n\r\n**Screenshots**\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Windoes\r\n - GCC/G++ Version 无\r\n - Python Version 3.10\r\n - PaddlePaddle Version 最新\r\n - Model Version 最新\r\n - GPU/DRIVER Informationo 无\r\n - CUDA/CUDNN Version 无\r\n - MKL Version 无\r\n- TensorRT Version 无\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "Coloryr",
        "closed_by": "zxcd",
        "created_at": "2023-11-22T02:13:37+00:00",
        "updated_at": "2024-01-16T12:11:26+00:00",
        "closed_at": "2024-01-16T12:11:25+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3608,
        "title": "ASR 语音识别 在windows本地测试 服务端已经启动 客户端怎么能够在进行转换的同时 还能加上标点预测？",
        "body": "背景\r\n首先 代码是最新的\r\npython版本是3.8  \r\npaddlepaddle 版本也是最新的\r\n环境是window10\r\n\r\n问题描述\r\nASR 语音识别 在windows本地测试 服务端已经启动  是通过命令行的方式启动的\r\n命令如下\r\npaddlespeech_server start  --config_file   ./speech_server/conf/application.yaml\r\n效果图如下\r\n![图片](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/5da70867-dc53-4a2a-9d70-78148965b10f)\r\n\r\n客户端测试命令如下\r\npaddlespeech_client asr  --server_ip 127.0.0.1  --port 8090 --input 123.wav  | paddlespeech text --task punc\r\n上述命令的输出结果是没有标点符号的\r\n\r\n效果图如下\r\n![图片](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/aaf43ab7-2205-415d-bcf9-8eb921941f77)\r\n\r\n通过阅读文档 发现下边的命令在执行以后是有标点符号的\r\n命令如下\r\npaddlespeech asr  --input ./123.wav  | paddlespeech text --task punc\r\n效果图如下\r\n![图片](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/51088d61-6400-4e47-ae74-ad060d42ce30)\r\n\r\n期望结果\r\n\r\n所以有没有相关的操作 或者命令 可以在服务端启动的情况下 使用客户端的asr可以完成转换的同时 还能加上标点预测",
        "state": "closed",
        "user": "777sfdf",
        "closed_by": "777sfdf",
        "created_at": "2023-11-22T08:51:40+00:00",
        "updated_at": "2024-01-05T09:03:09+00:00",
        "closed_at": "2024-01-05T09:03:09+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3607,
        "title": "ImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers'  这个错误遇到过没",
        "body": "我的环境是Windows 10 python3.7 在运行PaddleSpeech就报下面的错误\r\nFile \"generate_audio.py\", line 15, in <module>                                                     \r\n    from parakeet.models.fastspeech2 import FastSpeech2, FastSpeech2Inference\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\__init__.py\", line 20, in <module>\r\n    from . import models\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\models\\__init__.py\", line 15, in <module>\r\n    from .fastspeech2 import *\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\models\\fastspeech2\\__init__.py\", line 15, in <module>\r\n    from .fastspeech2 import *\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\models\\fastspeech2\\fastspeech2.py\", line 24, in <module>\r\n    from parakeet.modules.fastspeech2_predictor.duration_predictor import DurationPredictor\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\modules\\__init__.py\", line 18, in <module>\r\n    from .losses import *\r\n  File \"H:\\PaddlePaddle-DeepSpeech\\venv\\lib\\site-packages\\parakeet\\modules\\losses.py\", line 15, in <module>\r\n    from paddle.fluid.layers import sequence_mask\r\nImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers' ",
        "state": "closed",
        "user": "bao17634",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-22T06:44:13+00:00",
        "updated_at": "2025-06-27T05:32:49+00:00",
        "closed_at": "2025-06-27T05:32:49+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3612
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3609,
        "title": "是否可以在執行ASR的命令時直接輸出拼音",
        "body": "我正在按照下列頁面嘗試使用`paddlespeech asr`指令進行語音轉文字\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_recognition\r\n但我想要讓他可以直接輸出拼音，請問我可以怎麼做？\r\n例如上面頁面中的範例：\r\n```\r\npaddlespeech asr --input ./zh.wav -v\r\n```\r\n輸出「我认为跑步最重要的就是给我带来了身体健康」\r\n但我想要的結果類似「wo3 ren4 wei2 pao3 bu4 zui4 zhong4 yao4 de5 jiu4 shi4 gei3 wo3 dai4 lai2 le5 shen1 ti3 jian4 kang1」\r\n\r\n會想要這樣的主要原因是想要直接取得對的音，而不是將輸出漢字轉成拼音再去校對像是一字多音等問題\r\n如果CLI指令無法做到的話，python的腳本也可以，還是有其他更好的做法也請給我參考，謝謝",
        "state": "closed",
        "user": "yjlin0224",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-22T16:03:51+00:00",
        "updated_at": "2025-06-27T05:32:57+00:00",
        "closed_at": "2025-06-27T05:32:57+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3610,
        "title": "错误提示：ValueError: Not support x: [Time, Channel]",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n基于paddlespeech example/tal_cs中使用自定义的语音集训练时，会出现如下错误，请帮忙看下原因？\r\n<img width=\"1261\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/15249755/65b5c6c2-0e76-49a2-b480-34d8dcb44b98\">",
        "state": "closed",
        "user": "atalia",
        "closed_by": "atalia",
        "created_at": "2023-11-23T07:48:58+00:00",
        "updated_at": "2023-12-03T02:24:00+00:00",
        "closed_at": "2023-12-03T02:24:00+00:00",
        "comments_count": [
            "atalia"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3611,
        "title": "是否有办法绕过glibc_2.23的依赖",
        "body": "我是本地部署的。执行到该步骤的时候没有在exp_demo/mfa/下生成new_dir。我本地的glibc是2.17版本。但是又不太方便升级这么底层的包，请问是否有办法绕过呢？\r\n```\r\nmfa_align /home/aistudio/work/exp_demo/new_dir tools/aligner/simple.lexicon tools/aligner/aishell3_model.zip /home/aistudio/work/exp_demo/mfa\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nSetting up corpus information...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 5.0\r\n/home/data/aistudio/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nCreating dictionary information...\r\nfstcompile: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/data/aistudio/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstarcsort: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/data/aistudio/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstcompile: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/data/aistudio/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nfstarcsort: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/data/aistudio/PaddleSpeech/examples/other/tts_finetune/tts3/tools/montreal-forced-aligner/lib/thirdparty/bin/libfstscript.so.13)\r\nSetting up training data...\r\nCalculating MFCCs...\r\nCalculating CMVN...\r\nNumber of speakers in corpus: 1, average number of utterances per speaker: 5.0\r\nDone with setup.\r\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.24it/s]\r\nDone! Everything took 3.8951380252838135 seconds\r\n```",
        "state": "closed",
        "user": "thinkboy",
        "closed_by": "thinkboy",
        "created_at": "2023-11-23T09:32:22+00:00",
        "updated_at": "2024-03-08T08:36:52+00:00",
        "closed_at": "2023-11-28T09:42:10+00:00",
        "comments_count": [
            "thinkboy",
            "mzgcz",
            "thinkboy",
            "fancyerii"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3613,
        "title": "[S2T]使用Python API进行语音转文字的时候，发现会连接外部网站",
        "body": "执行以下代码时，会连接`http://paddlepaddle.org.cn/paddlehub/stat`，即便在本地已存在模型的情况下也是如此\r\n```python\r\nasr_executor(model='conformer_u2pp_online_wenetspeech',\r\n                           lang='zh',\r\n                           sample_rate=16000,\r\n                           config=None,\r\n                           ckpt_path=None,\r\n                           audio_file=fname)\r\n```",
        "state": "open",
        "user": "mzgcz",
        "closed_by": null,
        "created_at": "2023-11-24T04:14:04+00:00",
        "updated_at": "2024-03-06T05:22:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "mzgcz",
            "fancyerii"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3616,
        "title": "centos 7.9系统，安装speech没有错误，但是在执行命令时提示：非法指令(吐核)",
        "body": "环境：\r\n centos 7.9系统\r\npaddlepaddle==2.4.1\r\npaddlespeech==1.4.1(1.4.0也试过)\r\n安装过程没有出现问题，\r\n执行命令 paddlespeech_server start --config_file ./conf/application.yaml &> server.log &\r\n\r\npaddlespeech_server 有执行的权限。但是报错 **非法指令(吐核)**",
        "state": "open",
        "user": "xxch",
        "closed_by": null,
        "created_at": "2023-11-25T10:45:28+00:00",
        "updated_at": "2023-11-25T10:45:28+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3614,
        "title": "[S2T]基于Paddle nvidia-docker 启动时，无法正常检测到gpu",
        "body": "下载paddle cuda 11.2 的docker，并在有gpu的机器上运行，发现容器运行时，可以查询到cuda信息\r\nλ d5eeecb237fe /paddle/examples/tal_cs/asr1 nvcc -V\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Thu_Jan_28_19:32:09_PST_2021\r\nCuda compilation tools, release 11.2, V11.2.142\r\nBuild cuda_11.2.r11.2/compiler.29558016_0\r\n\r\n但是paddle speech训练时，会报错“You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.”：\r\n<img width=\"1534\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/15249755/5ea04233-c9f9-47cd-9904-87d47abe67de\">\r\n",
        "state": "closed",
        "user": "atalia",
        "closed_by": "atalia",
        "created_at": "2023-11-24T06:25:34+00:00",
        "updated_at": "2023-11-29T14:09:54+00:00",
        "closed_at": "2023-11-29T14:09:54+00:00",
        "comments_count": [
            "beixiang-l",
            "atalia"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3615,
        "title": "[TTS]Docker develop-gpu-cuda10.2-cudnn7-latest 启动tts服务报错  CUDA error(100), no CUDA-capable device is detected",
        "body": "**环境配置**\r\n环境window系统安装的ubuntu20.4虚拟机\r\nLinux 024b4fd43ccc 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nnvcc\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Wed_Oct_23_19:24:38_PDT_2019\r\nCuda compilation tools, release 10.2, V10.2.89\r\n\r\nnvidia-smi\r\nFri Nov 24 09:43:58 2023\r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 545.29.01              Driver Version: 546.01       CUDA Version: 10.2     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  NVIDIA GeForce RTX 2060        On  | 00000000:02:00.0  On |                  N/A |\r\n|  0%   31C    P8              23W / 184W |    432MiB / 12288MiB |     13%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n\r\n+---------------------------------------------------------------------------------------+\r\n| Processes:                                                                            |\r\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n|        ID   ID                                                             Usage      |\r\n|=======================================================================================|\r\n|  No running processes found                                                           |\r\n+---------------------------------------------------------------------------------------+\r\n\r\napplication.yaml配置文件\r\ntts_python:\r\n    # am (acoustic model) choices=['speedyspeech_csmsc', 'fastspeech2_csmsc',\r\n    #                             'fastspeech2_ljspeech', 'fastspeech2_aishell3',\r\n    #                             'fastspeech2_vctk', 'fastspeech2_mix',\r\n    #                             'tacotron2_csmsc', 'tacotron2_ljspeech']\r\n    am: 'fastspeech2_csmsc'\r\n    am_config:\r\n    am_ckpt:\r\n    am_stat:\r\n    phones_dict:\r\n    tones_dict:\r\n    speaker_dict:\r\n\r\n\r\n    # voc (vocoder) choices=['pwgan_csmsc', 'pwgan_ljspeech', 'pwgan_aishell3',\r\n    #                        'pwgan_vctk', 'mb_melgan_csmsc', 'style_melgan_csmsc',\r\n    #                        'hifigan_csmsc', 'hifigan_ljspeech', 'hifigan_aishell3',\r\n    #                        'hifigan_vctk', 'wavernn_csmsc']\r\n    voc: 'mb_melgan_csmsc'\r\n    voc_config:\r\n    voc_ckpt:\r\n    voc_stat:\r\n\r\n    # others\r\n    lang: 'zh'\r\n    device: gpu:0 # set 'gpu:id' or 'cpu'\r\n\r\n执行启动命令：\r\n paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/python3.7.0/lib/python3.7/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n/usr/local/python3.7.0/lib/python3.7/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/python3.7.0/lib/python3.7/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\nW1124 09:39:31.652143   202 init.cc:179] Compiled with WITH_GPU, but no GPU found in runtime.\r\n/usr/local/python3.7.0/lib/python3.7/site-packages/paddle/fluid/framework.py:517: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  \"You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\"\r\n[2023-11-24 09:39:34,481] [    INFO] - start to init the engine\r\n[2023-11-24 09:39:34,481] [    INFO] - tts : python engine.\r\n[2023-11-24 09:39:39,022] [   ERROR] - Set device failed, please check if device is already used and the parameter 'device' in the yaml file\r\n[2023-11-24 09:39:39,022] [   ERROR] - Initialize TTS server engine Failed on device: gpu:0.\r\n[2023-11-24 09:39:39,022] [   ERROR] - (External) CUDA error(100), no CUDA-capable device is detected.\r\n  [Hint: 'cudaErrorNoDevice'. This indicates that no CUDA-capable devices were detected by the installed CUDA driver. ] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:66)\r\n\r\n这个改怎么解决？",
        "state": "open",
        "user": "beixiang-l",
        "closed_by": null,
        "created_at": "2023-11-24T09:47:08+00:00",
        "updated_at": "2024-01-02T11:21:01+00:00",
        "closed_at": null,
        "comments_count": [
            "beixiang-l",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3617,
        "title": "能不能固定一下opencc的版本，centos上import提示找不到glibc-2.32，小白真的会去升级的",
        "body": "ImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found \r\n目前解决方案是opencc降级\r\npip install opencc-python-reimplemented==0.1.6\r\n但是你一旦想着要升级glibc，就是无尽的麻烦\r\n希望能直接固定opencc版本，避免后面更多人遇到这个问题",
        "state": "open",
        "user": "Deasoso",
        "closed_by": null,
        "created_at": "2023-11-25T11:32:00+00:00",
        "updated_at": "2024-02-15T09:22:47+00:00",
        "closed_at": null,
        "comments_count": [
            "thinkboy",
            "tpoisonooo"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3623
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3618,
        "title": "paddle的numpy库版本和paddlespeech冲突",
        "body": "按照文档，在conda虚拟环境先安装了paddle-gpu版本，再安装了paddlespeech。调用PaddleSpeech/examples/aishell3/vits/local/preprocess.sh预处理shell处理数据时，报错。根据报错应该是paddle的numpy和paddlespeech需要的版本不一致，我也不敢贸然修改numpy的版本，因为可能导致paddle出什么问题。有什么解决方法吗?\r\npython:3.9 numpy版本是1.26.2。\r\npaddlepaddle版本: paddlepaddle-gpu  2.5.1.post112        paddlespeech版本:paddlespeech  1.4.1\r\n除了numpy冲突外，还有一个[nltk_data] 错误。\r\n报错如下:\r\nFile \"/home/inspur/ly416100210174/proj/PaddleSpeech/utils/gen_duration_from_textgrid.py\", line 18, in <module>\r\n    import librosa\r\n  File \"/home/inspur/ly416100210174/miniconda3/envs/paddlepaddle/lib/python3.8/site-packages/librosa/__init__.py\", line 211, in <module>\r\n    from . import core\r\n  File \"/home/inspur/ly416100210174/miniconda3/envs/paddlepaddle/lib/python3.8/site-packages/librosa/core/__init__.py\", line 9, in <module>\r\n    from .constantq import *  # pylint: disable=wildcard-import\r\n  File \"/home/inspur/ly416100210174/miniconda3/envs/paddlepaddle/lib/python3.8/site-packages/librosa/core/constantq.py\", line 1059, in <module>\r\n    dtype=np.complex,\r\n  File \"/home/inspur/ly416100210174/miniconda3/envs/paddlepaddle/lib/python3.8/site-packages/numpy/__init__.py\", line 305, in __getattr__\r\n    raise AttributeError(__former_attrs__[attr])\r\nAttributeError: module 'numpy' has no attribute 'complex'.\r\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno -2] Name or service not known>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno -2] Name or\r\n[nltk_data]     service not known>\r\n",
        "state": "open",
        "user": "alittlenico",
        "closed_by": null,
        "created_at": "2023-11-27T05:10:09+00:00",
        "updated_at": "2024-11-14T04:55:08+00:00",
        "closed_at": null,
        "comments_count": [
            "zhaojigang",
            "alittlenico",
            "alittlenico",
            "alittlenico",
            "alittlenico",
            "Douflamingo666",
            "mlick",
            "zhouhao27",
            "chenmj201601"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3621,
        "title": "[TTS]TTS ARM Linux uses the speedyspeech_csmsc_pdlite_1.3.0.nb model and reports errors to a Segmentation fault. The localization problem is on the acoustic_model_predictor_->Run(), In fastspeech2_csmsc_pdlite_1.3.0... The nb model doesn't use questions. Why is that?",
        "body": "[TTS]TTS ARM Linux uses the speedyspeech_csmsc_pdlite_1.3.0.nb model and reports errors to a Segmentation fault. The localization problem is on the acoustic_model_predictor_->Run(), In fastspeech2_csmsc_pdlite_1.3.0... The nb model doesn't use questions. Why is that?",
        "state": "open",
        "user": "Insensiblee",
        "closed_by": null,
        "created_at": "2023-11-28T07:45:45+00:00",
        "updated_at": "2023-11-28T07:45:45+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3619,
        "title": "fastspeech2转ONNX，有相关示例代码吗~ 谢谢！",
        "body": "fastspeech2转ONNX，有相关示例代码吗~ 谢谢！",
        "state": "closed",
        "user": "litao28",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-27T07:00:40+00:00",
        "updated_at": "2025-06-27T05:32:41+00:00",
        "closed_at": "2025-06-27T05:32:41+00:00",
        "comments_count": [
            "stale[bot]",
            "litao28",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3620,
        "title": "TTSCppFrontend",
        "body": "**Describe the bug**\r\n函数FrontEngineInterface::ThreeSandhi(const std::string &word,\r\n                                      std::vector<std::string> *finals)\r\n的实现中有finals = new std::vector<std::string>();这样的代码明显是错误的\r\n\r\n**To Reproduce**\r\n”美好生活“作为输入，‘美’字的音调应该从3声被修改为2声，代码逻辑确实修改了，但是由于上述写法，修改结果未能成功返回到finals参数中\r\n\r\n**Environment (please complete the following information):**\r\n - OS: windows\r\n - GCC/G++ Version：vs2022\r\n\r\n",
        "state": "closed",
        "user": "tuotuoshao",
        "closed_by": "tuotuoshao",
        "created_at": "2023-11-27T09:57:00+00:00",
        "updated_at": "2024-05-23T14:30:46+00:00",
        "closed_at": "2024-05-22T09:35:30+00:00",
        "comments_count": [
            "kk-2000"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3628
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3629
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3625,
        "title": "other/tts_finetune/tts3 开始训练时报错，trainer.extend(Snapshot）后再 trainer.run()就报错",
        "body": "**Describe the bug**\r\n参考Finetune your own AM based on FastSpeech2 with multi-speakers dataset.进行小量数据训练，到第五finetune阶段，执行python local/finetune.py时报错，报错信息如下：\r\n![捕获](https://github.com/PaddlePaddle/PaddleSpeech/assets/51219602/101850ef-bf6d-4821-bc81-a09a4af25e3d)\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.将finetune.py中的第200行注掉就不报错了，# trainer.extend(\r\n        Snapshot(max_size=config.num_snapshots), trigger=(1, 'epoch'))\r\n2.注掉后发现训练完没有生成新模型，所以此句可能就是保存训练结果模型的功能，不能去掉\r\n\r\n**Environment (please complete the following information):**\r\n - OS: windows\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version : 3.9\r\n",
        "state": "closed",
        "user": "tuotuoshao",
        "closed_by": "tuotuoshao",
        "created_at": "2023-11-30T03:17:47+00:00",
        "updated_at": "2024-05-22T09:35:05+00:00",
        "closed_at": "2024-05-22T09:35:05+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3622,
        "title": "如何源码安装生成paddlespeech命令文件？",
        "body": "通过“pip install . -i https://mirror.baidu.com/pypi/simple”命令源码安装不会生成可执行的paddlespeech命令文件吗？如果不能该如何生成？\r\nPS: 该安装指令后，没有任何报错。",
        "state": "closed",
        "user": "thinkboy",
        "closed_by": "stale[bot]",
        "created_at": "2023-11-28T09:44:53+00:00",
        "updated_at": "2025-06-27T05:32:59+00:00",
        "closed_at": "2025-06-27T05:32:59+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3624,
        "title": "请问 tts男性声音训练，机械音比较重如何调整",
        "body": "以下是环境：\r\n\r\nMFA1.1\r\n\r\ntts am :\r\nfastspeech2_mix\r\nfastspeech2_mix_ckpt_1.2.0\r\n\r\nvoc:\r\nhifigan_aishell3\r\nhifigan_aishell3_ckpt_0\r\n\r\ntrain fun:\r\npaddlespeech->t2s->training->trainer.py ->run\r\n\r\n[Uploading sample.mp3.zip…]()\r\n",
        "state": "open",
        "user": "15101629450",
        "closed_by": null,
        "created_at": "2023-11-29T10:13:37+00:00",
        "updated_at": "2023-11-29T10:20:20+00:00",
        "closed_at": null,
        "comments_count": [
            "15101629450"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3626,
        "title": "[S2T] ImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers' ",
        "body": "\r\n - OS: Ubuntu 22.04\r\n - Python Version  3.11\r\n - PaddlePaddle Version   2.5.2\r\n\r\n\r\n~/code/PaddleSpeech$ paddlespeech asr --lang zh --input zh.wav\r\nTraceback (most recent call last):\r\n  File \"/home/lihuan/anaconda3/bin/paddlespeech\", line 5, in <module>\r\n    from paddlespeech.cli.entry import _execute\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/cli/__init__.py\", line 23, in <module>\r\n    from .tts import TTSExecutor\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/cli/tts/infer.py\", line 36, in <module>\r\n    from paddlespeech.t2s.frontend import English\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/__init__.py\", line 19, in <module>\r\n    from . import models\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/models/__init__.py\", line 14, in <module>\r\n    from .fastspeech2 import *\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/models/fastspeech2/__init__.py\", line 14, in <module>\r\n    from .fastspeech2 import *\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 28, in <module>\r\n    from paddlespeech.t2s.modules.nets_utils import initialize\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/modules/__init__.py\", line 16, in <module>\r\n    from .losses import *\r\n  File \"/home/lihuan/anaconda3/lib/python3.11/site-packages/paddlespeech/t2s/modules/losses.py\", line 20, in <module>\r\n    from paddle.fluid.layers import sequence_mask\r\nImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers' (/home/lihuan/anaconda3/lib/python3.11/site-packages/paddle/fluid/layers/__init__.py)\r\n(base) lihuan@lihuan:~/code/PaddleSpeech$ \r\n\r\n\r\n",
        "state": "open",
        "user": "bestlee666",
        "closed_by": null,
        "created_at": "2023-11-30T06:21:24+00:00",
        "updated_at": "2023-12-08T03:14:54+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3627,
        "title": "[S2T] ERROR: No matching distribution found for paddleaudio>=1.1.0",
        "body": "\r\n - OS: [Ubuntu 22.04]\r\n - Python Version  3.11\r\n - PaddlePaddle Version [2.5.2]\r\n\r\n\r\n pip install .\r\n\r\nProcessing /home/lihuan/code/PaddleSpeech\r\n  Preparing metadata (setup.py) ... done\r\nCollecting braceexpand (from paddlespeech==0.0.0)\r\n  Using cached braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\r\nRequirement already satisfied: editdistance in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (0.6.2)\r\nRequirement already satisfied: g2p_en in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (2.1.0)\r\nRequirement already satisfied: g2pM in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (0.1.2.5)\r\nRequirement already satisfied: h5py in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (3.9.0)\r\nCollecting hyperpyyaml (from paddlespeech==0.0.0)\r\n  Obtaining dependency information for hyperpyyaml from https://files.pythonhosted.org/packages/33/c9/751b6401887f4b50f9307cc1e53d287b3dc77c375c126aeb6335aff73ccb/HyperPyYAML-1.2.2-py3-none-any.whl.metadata\r\n  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\r\nRequirement already satisfied: inflect in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (7.0.0)\r\nRequirement already satisfied: jsonlines in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (4.0.0)\r\nCollecting numpy==1.23.5 (from paddlespeech==0.0.0)\r\n  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\nRequirement already satisfied: librosa==0.8.1 in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (0.8.1)\r\nRequirement already satisfied: scipy>=1.4.0 in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (1.9.3)\r\nRequirement already satisfied: loguru in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (0.7.2)\r\nRequirement already satisfied: matplotlib in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (3.7.2)\r\nRequirement already satisfied: nara_wpe in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (0.0.9)\r\nRequirement already satisfied: onnxruntime>=1.11.0 in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (1.16.3)\r\nCollecting opencc (from paddlespeech==0.0.0)\r\n  Obtaining dependency information for opencc from https://files.pythonhosted.org/packages/18/a2/9ccfc1e1c49f6643b2bc090ba2a5bca5df6a2754e5049caa1909609bdccd/OpenCC-1.1.7-cp311-cp311-manylinux1_x86_64.whl.metadata\r\n  Using cached OpenCC-1.1.7-cp311-cp311-manylinux1_x86_64.whl.metadata (12 kB)\r\nCollecting opencc-python-reimplemented (from paddlespeech==0.0.0)\r\n  Using cached opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\r\nRequirement already satisfied: pandas in /home/lihuan/anaconda3/lib/python3.11/site-packages (from paddlespeech==0.0.0) (2.0.3)\r\nINFO: pip is looking at multiple versions of paddlespeech to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\r\nERROR: Could not find a version that satisfies the requirement paddleaudio>=1.1.0 (from paddlespeech) (from versions: 0.1.0a0, 0.1.0, 0.2.0, 0.2.1, 1.0.0a0, 1.0.0, 1.0.1, 1.0.2)\r\nERROR: No matching distribution found for paddleaudio>=1.1.0\r\n",
        "state": "open",
        "user": "bestlee666",
        "closed_by": null,
        "created_at": "2023-11-30T07:30:52+00:00",
        "updated_at": "2023-12-08T03:13:44+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3632,
        "title": "请问有无将不同发声人分离出来的应用",
        "body": "如两个人的一段对话录音，需要将两人声音识别出来并且分离\r\n",
        "state": "closed",
        "user": "Fmaj7",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-01T09:29:23+00:00",
        "updated_at": "2025-06-27T05:32:59+00:00",
        "closed_at": "2025-06-27T05:32:59+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3631,
        "title": "[S2T] PaddleSpeech-Server-RESTful-API 不识别 pcm 格式，punc 参数不起作用",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n[PaddleSpeech-Server](https://github.com/PaddlePaddle/PaddleSpeech/wiki/PaddleSpeech-Server-RESTful-API#22-%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB)描述说语音识别服务支持pcm和wav两种格式，但输入pcm格式文件时，报以下错误：\r\n\r\n> raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\r\n> soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x7f9bc43d1b30>: Format not recognised.\r\n> [2023-12-01 15:54:05,375] [   ERROR] - can not open the audio file, please check the audio file(<_io.BytesIO object at 0x7f9bc43d1b30>) format is 'wav'. \r\n>                  you can try to use sox to change the file format.\r\n>                  For example: \r\n>                  sample rate: 16k \r\n>                  sox input_audio.xx --rate 16k --bits 16 --channels 1 output_audio.wav \r\n>                  sample rate: 8k \r\n>                  sox input_audio.xx --rate 8k --bits 16 --channels 1 output_audio.wav \r\n>                  \r\n> [2023-12-01 15:54:05,375] [   ERROR] - file check failed!\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "mzgcz",
        "closed_by": null,
        "created_at": "2023-12-01T08:23:05+00:00",
        "updated_at": "2024-12-11T08:00:30+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "beixiang-l",
            "mzgcz",
            "warkcod",
            "Alex37882388"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3637,
        "title": "没有中文ASR基于预训练模型微调的代码，只有从头训练的代码",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "qingjiaozyn",
        "closed_by": "qingjiaozyn",
        "created_at": "2023-12-07T08:31:18+00:00",
        "updated_at": "2023-12-09T06:14:41+00:00",
        "closed_at": "2023-12-09T06:14:41+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3635,
        "title": "TTSAndroid编译armv7版本后运行报错",
        "body": "## 操作过程如下：\r\n\r\n**1.下载docker镜像**\r\n```bash\r\ndocker pull paddlepaddle/paddle-lite:2.0.0_beta\r\n```\r\n\r\n\r\n**2.克隆代码**\r\n```bash\r\ngit clone https://github.com/PaddlePaddle/Paddle-Lite.git\r\n```\r\n\r\n**3.运行容器**\r\n```bash\r\ndocker run -it --name paddlelite_docker  -v $PWD/Paddle-Lite:/Paddle-Lite  --net=host paddlepaddle/paddle-lite /bin/bash\r\n```\r\n  \r\n  \r\n **4.编译opt工具**\r\n  ```bash\r\ncd Paddle-Lite\r\n./lite/tools/build.sh build_optimize_tool --with_extra=ON\r\n ```\r\n\r\n**下载模型**\r\n\r\n```bash\r\nhttps://paddlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_cnndecoder_csmsc_static_1.0.0.zip\r\n\r\nhttps://paddlespeech.bj.bcebos.com/Parakeet/released_models/mb_melgan/mb_melgan_csmsc_static_0.1.1.zip\r\n```\r\n\r\n**5.模型转换**\r\n```bash\r\ncd /Paddle-Lite/build.opt/lite/api\r\n./opt --model_file=/Paddle-Lite/models/fastspeech2_cnndecoder_csmsc_static_1.0.0/fastspeech2_csmsc.pdmodel --param_file=/Paddle-Lite/models/fastspeech2_cnndecoder_csmsc_static_1.0.0/fastspeech2_csmsc.pdiparams --valid_targets=arm --optimize_out_type=naive_buffer --optimize_out=/Paddle-Lite/models/fastspeech2_csmsc_arm\r\n\r\n./opt --model_file=/Paddle-Lite/models/mb_melgan_csmsc_static_0.1.1/mb_melgan_csmsc.pdmodel --param_file=/Paddle-Lite/models/mb_melgan_csmsc_static_0.1.1/mb_melgan_csmsc.pdiparams --valid_targets=arm --optimize_out_type=naive_buffer --optimize_out=/Paddle-Lite/models/mb_melgan_csmsc_arm\r\n```\r\n\r\n\r\n**6.编译动态库**\r\n```bash\r\n./lite/tools/build_android.sh --arch=armv7 --toolchain=gcc --android_stl=c++_static --with_java=ON --with_extra=ON\r\n```\r\n\r\n## 报错代码\r\n\r\n```\r\n public Tensor getAMOutput(long[] phones, PaddlePredictor am_predictor) {\r\n        Tensor phones_handle = am_predictor.getInput(0);\r\n        long[] dims = {phones.length};\r\n        phones_handle.resize(dims);\r\n        phones_handle.setData(phones);\r\n        am_predictor.run();//此处报错\r\n        Tensor am_output_handle = am_predictor.getOutput(0);\r\n        float[] am_output_data = am_output_handle.getFloatData();\r\n        return am_output_handle;\r\n    }\r\n```\r\n\r\n\r\n\r\n## 运行日志\r\n\r\n```\r\n--------- beginning of main\r\n--------- beginning of system\r\n2023-12-05 19:51:43.360 13005-13005 art                     com.baidu.paddle.lite.demo.tts       I  Late-enabling -Xcheck:jni\r\n2023-12-05 19:51:43.389 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.390 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.392 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.393 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.419 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.466 13005-13005 art                     com.baidu.paddle.lite.demo.tts       W  Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable\r\n2023-12-05 19:51:43.472 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.479 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.479 13005-13005 PhoneWindow             com.baidu.paddle.lite.demo.tts       D  DecorView - SCREEN_WEITH = 800 - SCREE_HEIGHT = 1232\r\n2023-12-05 19:51:43.498 13005-13005 art                     com.baidu.paddle.lite.demo.tts       I  Rejecting re-init on previously-failed class java.lang.Class<android.support.v4.view.ViewCompat$OnUnhandledKeyEventListenerWrapper>\r\n2023-12-05 19:51:43.498 13005-13005 art                     com.baidu.paddle.lite.demo.tts       I  Rejecting re-init on previously-failed class java.lang.Class<android.support.v4.view.ViewCompat$OnUnhandledKeyEventListenerWrapper>\r\n2023-12-05 19:51:43.522 13005-13020 art                     com.baidu.paddle.lite.demo.tts       W  Suspending all threads took: 10.542ms\r\n2023-12-05 19:51:43.526 13005-13020 art                     com.baidu.paddle.lite.demo.tts       I  Background sticky concurrent mark sweep GC freed 2752(303KB) AllocSpace objects, 0(0B) LOS objects, 12% free, 2MB/2MB, paused 12.024ms total 34.226ms\r\n2023-12-05 19:51:43.582 13005-13005 ListPopupWindow         com.baidu.paddle.lite.demo.tts       I  Could not find method setEpicenterBounds(Rect) on PopupWindow. Oh well.\r\n2023-12-05 19:51:43.604 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.604 13005-13005 PhoneWindow             com.baidu.paddle.lite.demo.tts       D  DecorView - SCREEN_WEITH = 800 - SCREE_HEIGHT = 1232\r\n2023-12-05 19:51:43.620 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.621 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.624 13005-13032 OpenGLRenderer          com.baidu.paddle.lite.demo.tts       D  Use EGL_SWAP_BEHAVIOR_PRESERVED: false\r\n2023-12-05 19:51:43.626 13005-13005 Atlas                   com.baidu.paddle.lite.demo.tts       D  Validating map...\r\n2023-12-05 19:51:43.626 13005-13005 Atlas                   com.baidu.paddle.lite.demo.tts       W  Pointer 0x0, not in getPreloadedDrawables?\r\n2023-12-05 19:51:43.626 13005-13005 Atlas                   com.baidu.paddle.lite.demo.tts       W  Pointer 0x0, not in getPreloadedDrawables?\r\n2023-12-05 19:51:43.632 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:43.639 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onAttachToWindow register content observer attrs=WM.LayoutParams{(0,0)(wrapxwrap)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#ffffffff sim=#120 ty=2 fl=#1860002 fmt=-3 wanim=0x103046a surfaceInsets=Rect(32, 32 - 32, 32) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:43.654 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  576<<<<<< BACK FROM relayoutWM.LayoutParams{(0,0)(wrapxwrap)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#ffffffff sim=#120 ty=2 fl=#1860002 fmt=-3 wanim=0x103046a surfaceInsets=Rect(32, 32 - 32, 32) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:43.656 13005-13032 mali_so                 com.baidu.paddle.lite.demo.tts       I  [File] : hardware/arm/maliT760/driver/product/base/src/mali_base_kbase.c; [Line] : 929; [Func] : base_context_deal_with_version_affairs_rk_ext;\r\n                                                                                                    arm_release_ver of this mali_so is 'r12p0-04rel0', rk_so_ver is 'r1_for_defect_124538', built at '16:37:05', on 'Jun 29 2017'.\r\n2023-12-05 19:51:43.656 13005-13032 mali_so                 com.baidu.paddle.lite.demo.tts       I  [File] : hardware/arm/maliT760/driver/product/base/src/mali_base_kbase.c; [Line] : 956; [Func] : base_context_deal_with_version_affairs_rk_ext;\r\n                                                                                                    mali_ver_property has been set to 'r12p0-04rel0-13-r1_for_defect_124538', to return.\r\n2023-12-05 19:51:43.659 13005-13032 OpenGLRenderer          com.baidu.paddle.lite.demo.tts       I  Initialized EGL, version 1.4\r\n2023-12-05 19:51:43.663 13005-13032 OpenGLRenderer          com.baidu.paddle.lite.demo.tts       D  Enabling debug mode 0\r\n2023-12-05 19:51:43.664 13005-13032 mali_winsys             com.baidu.paddle.lite.demo.tts       D  EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\r\n2023-12-05 19:51:43.669 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onAttachToWindow register content observer attrs=WM.LayoutParams{(0,0)(fillxfill)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=318 sim=#100 ty=1 fl=#81810100 wanim=0x1030469 surfaceInsets=Rect(0, 0 - 0, 0) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:43.746 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  800<<<<<< BACK FROM relayoutWM.LayoutParams{(0,0)(fillxfill)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=318 sim=#110 ty=1 fl=#81810100 wanim=0x1030469 surfaceInsets=Rect(0, 0 - 0, 0) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:43.747 13005-13032 mali_winsys             com.baidu.paddle.lite.demo.tts       D  EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\r\n2023-12-05 19:51:46.217 13005-13031 Predictor               com.baidu.paddle.lite.demo.tts       E  File:/data/data/com.baidu.paddle.lite.demo.tts/cache/models/cpu/fastspeech2_csmsc_arm.nb\r\n2023-12-05 19:51:46.218 13005-13031 linker                  com.baidu.paddle.lite.demo.tts       W  libpaddle_lite_jni.so: unused DT entry: type 0x6ffffffe arg 0x99cc\r\n2023-12-05 19:51:46.218 13005-13031 linker                  com.baidu.paddle.lite.demo.tts       W  libpaddle_lite_jni.so: unused DT entry: type 0x6fffffff arg 0x3\r\n2023-12-05 19:51:46.229 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.229 /Paddle-Lite/lite/core/device_info.cc get_cpu_arch:283] Unknow cpu arch: 3085\r\n2023-12-05 19:51:46.229 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.229 /Paddle-Lite/lite/core/device_info.cc get_cpu_arch:283] Unknow cpu arch: 3085\r\n2023-12-05 19:51:46.229 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.229 /Paddle-Lite/lite/core/device_info.cc get_cpu_arch:283] Unknow cpu arch: 3085\r\n2023-12-05 19:51:46.229 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.229 /Paddle-Lite/lite/core/device_info.cc get_cpu_arch:283] Unknow cpu arch: 3085\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1330] ARM multiprocessors name: MODEL NAME\t: ARMV7 PROCESSOR REV 1 (V7L)\r\n                                                                                                    HARDWARE\t: ROCKCHIP RK3288 (FLATTENED DEVICE TREE)\r\n                                                                                                    _RK30SDK_RK3288_\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1331] ARM multiprocessors number: 4\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1333] ARM multiprocessors ID: 0, max freq: 1608, min freq: 1608, cluster ID: 0, CPU ARCH: A-1\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1333] ARM multiprocessors ID: 1, max freq: 1608, min freq: 1608, cluster ID: 0, CPU ARCH: A-1\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1333] ARM multiprocessors ID: 2, max freq: 1608, min freq: 1608, cluster ID: 0, CPU ARCH: A-1\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1333] ARM multiprocessors ID: 3, max freq: 1608, min freq: 1608, cluster ID: 0, CPU ARCH: A-1\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1339] L1 DataCache size is: \r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1341] 32 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1341] 32 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1341] 32 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1341] 32 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1343] L2 Cache size is: \r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1345] 512 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1345] 512 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1345] 512 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1345] 512 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1347] L3 Cache size is: \r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1349] 0 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1349] 0 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1349] 0 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1349] 0 KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1351] Total memory: 2060532KB\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1352] SVE2 support: 0\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1353] SVE2 f32mm support: 0\r\n2023-12-05 19:51:46.231 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       I  [I 12/ 5 19:51:46.231 /Paddle-Lite/lite/core/device_info.cc Setup:1354] SVE2 i8mm support: 0\r\n2023-12-05 19:51:49.707 13005-13031 Predictor               com.baidu.paddle.lite.demo.tts       E  File:/data/data/com.baidu.paddle.lite.demo.tts/cache/models/cpu/mb_melgan_csmsc_arm.nb\r\n2023-12-05 19:51:49.765 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onDetachedFromWindow ungister contentObserver\r\n2023-12-05 19:51:51.549 13005-13005 art                     com.baidu.paddle.lite.demo.tts       W  Before Android 4.1, method int android.support.v7.widget.DropDownListView.lookForSelectablePosition(int, boolean) would have incorrectly overridden the package-private method in android.widget.ListView\r\n2023-12-05 19:51:51.558 13005-13005 PopupWindow             com.baidu.paddle.lite.demo.tts       D  findDropDownPosition mDrawingLocation(0,299) xoff=0 yOff=-48 anchroHeight=48\r\n2023-12-05 19:51:51.558 13005-13005 PopupWindow             com.baidu.paddle.lite.demo.tts       D  ----displayFrame=Rect(0, 25 - 800, 1232)\r\n2023-12-05 19:51:51.558 13005-13005 PopupWindow             com.baidu.paddle.lite.demo.tts       D  root.getWidth=800screenY=299 anchorHeight=48mPopupWidth=384\r\n2023-12-05 19:51:51.558 13005-13005 PopupWindow             com.baidu.paddle.lite.demo.tts       D  final p.x=0 p.y=299\r\n2023-12-05 19:51:51.560 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:51.565 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onAttachToWindow register content observer attrs=WM.LayoutParams{(0,299)(384x528)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#10000033 sim=#1 ty=1002 fl=#41860200 fmt=-3 wanim=0x10302e1 surfaceInsets=Rect(32, 32 - 32, 32)packageName=com.baidu.paddle.lite.demo.ttstoken=android.view.ViewRootImpl$W@e280c4e}\r\n2023-12-05 19:51:51.584 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  384<<<<<< BACK FROM relayoutWM.LayoutParams{(0,299)(384x528)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#10000033 sim=#11 ty=1002 fl=#41860200 fmt=-3 wanim=0x10302e1 surfaceInsets=Rect(32, 32 - 32, 32)packageName=com.baidu.paddle.lite.demo.ttstoken=android.view.ViewRootImpl$W@e280c4e}\r\n2023-12-05 19:51:51.585 13005-13032 mali_winsys             com.baidu.paddle.lite.demo.tts       D  EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\r\n2023-12-05 19:51:53.327 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onDetachedFromWindow ungister contentObserver\r\n2023-12-05 19:51:53.339 13005-13005 InputEventReceiver      com.baidu.paddle.lite.demo.tts       W  Attempted to finish an input event but the input event receiver has already been disposed.\r\n2023-12-05 19:51:53.403 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:53.403 13005-13005 PhoneWindow             com.baidu.paddle.lite.demo.tts       D  DecorView - SCREEN_WEITH = 800 - SCREE_HEIGHT = 1232\r\n2023-12-05 19:51:53.418 13005-13005 DisplayManager          com.baidu.paddle.lite.demo.tts       D  getDisplayInfo: displayId=0, info=DisplayInfo{\"内置屏幕\", uniqueId \"local:0\", app 800 x 1232, real 800 x 1280, largest app 1280 x 1207, smallest app 800 x 727, 54.477 fps, supportedRefreshRates [54.477], rotation 0, density 160 (160.0 x 160.15764) dpi, layerStack 0, appVsyncOff 0, presDeadline 19356370, type BUILT_IN, state ON, FLAG_SECURE, FLAG_SUPPORTS_PROTECTED_BUFFERS}\r\n2023-12-05 19:51:53.424 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  onAttachToWindow register content observer attrs=WM.LayoutParams{(0,0)(wrapxwrap)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#ffffffff sim=#120 ty=2 fl=#1860002 fmt=-3 wanim=0x103046a surfaceInsets=Rect(32, 32 - 32, 32) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:53.438 13005-13005 ViewRootImpl            com.baidu.paddle.lite.demo.tts       D  576<<<<<< BACK FROM relayoutWM.LayoutParams{(0,0)(wrapxwrap)mPosX=0mPosY=0mHScale=1.0mVScale=1.0 align=UNDEFINE taskId=-1 gr=#ffffffff sim=#120 ty=2 fl=#1860002 fmt=-3 wanim=0x103046a surfaceInsets=Rect(32, 32 - 32, 32) needsMenuKey=2packageName=com.baidu.paddle.lite.demo.ttstoken=android.os.BinderProxy@36bf2bcf}\r\n2023-12-05 19:51:53.440 13005-13032 mali_winsys             com.baidu.paddle.lite.demo.tts       D  EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\r\n--------- beginning of crash\r\n2023-12-05 19:51:54.022 13005-13031 Paddle-Lite             com.baidu.paddle.lite.demo.tts       A  [F 12/ 5 19:51:54. 22 ...e-Lite/lite/kernels/arm/slice_compute.cc:71 get_new_data_from_tensorlist] Check failed: (tensor->dims() == DDim({1})): {}!=={1} shape of dim tensor should be [1]\r\n2023-12-05 19:51:54.022 13005-13031 libc                    com.baidu.paddle.lite.demo.tts       A  Fatal signal 6 (SIGABRT), code -6 in tid 13031 (Predictor Worke)\r\n\r\n```",
        "state": "closed",
        "user": "dota2015",
        "closed_by": "dota2015",
        "created_at": "2023-12-05T11:46:54+00:00",
        "updated_at": "2023-12-13T01:32:52+00:00",
        "closed_at": "2023-12-13T01:32:38+00:00",
        "comments_count": [
            "dota2015"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3639,
        "title": "训练vits代码报错，配置文件里没有这个属性，但核对了是有的",
        "body": "报错内容如下:\r\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\r\n[nltk_data]     [Errno -2] Name or service not known>\r\n[nltk_data] Error loading cmudict: <urlopen error [Errno -2] Name or\r\n[nltk_data]     service not known>\r\nW1209 01:22:45.509446 39834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.4, Runtime API Version: 11.7\r\nW1209 01:22:45.511700 39834 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nTraceback (most recent call last):\r\n  File \"/home/inspur/myPath/proj/PaddleSpeech/paddlespeech/t2s/exps/vits/train.py\", line 292, in <module>\r\n    main()\r\n  File \"/home/inspur/myPath/proj/PaddleSpeech/paddlespeech/t2s/exps/vits/train.py\", line 288, in main\r\n    train_sp(args, config)\r\n  File \"/home/inspur/myPath/proj/PaddleSpeech/paddlespeech/t2s/exps/vits/train.py\", line 237, in train_sp\r\n    evaluator, trigger=(config.eval_interval_epochs, 'epoch'))\r\n  File \"/home/inspur/myPath/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/yacs/config.py\", line 141, in __getattr__\r\n    raise AttributeError(name)\r\nAttributeError: eval_interval_epochs\r\n",
        "state": "closed",
        "user": "alittlenico",
        "closed_by": "alittlenico",
        "created_at": "2023-12-10T04:51:39+00:00",
        "updated_at": "2023-12-10T05:19:50+00:00",
        "closed_at": "2023-12-10T05:19:50+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3636,
        "title": "测试http模式的tts流式转换提示错误",
        "body": "(pp_env) tb14:~/era/tmp_test/jupyter/pp/server$ **paddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol http --input \"您好，欢迎使用百度飞桨语音合成服务。\" --play True**\r\n[2023-12-07 15:44:23,927] [    INFO] - **tts http client start**\r\n[2023-12-07 15:44:23,956] [   **ERROR**] - **Failed to synthesized audio.**\r\n[2023-12-07 15:44:23,956] [   **ERROR**] - **Expecting value: line 1 column 1 (char 0)**\r\n\r\nUbuntu20.04的系统，测试了普通的转换没有问题，但是测试流式转换报出这样的错误，没有发现相关log，请问有知道是什么原因或怎么解决吗？",
        "state": "closed",
        "user": "ComeBackTo2016",
        "closed_by": "ComeBackTo2016",
        "created_at": "2023-12-07T07:51:58+00:00",
        "updated_at": "2023-12-07T08:00:13+00:00",
        "closed_at": "2023-12-07T07:59:30+00:00",
        "comments_count": [
            "ComeBackTo2016"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3638,
        "title": "ValueError: (InvalidArgument) 'begin_norm_axis' in Op(LayerNorm) should begreater than zero. But received [0].   [Hint: Expected begin_norm_axis > 0, but received begin_norm_axis:0 <= 0:0.] (at ../paddle/phi/infermeta/ternary.cc:537)",
        "body": "执行asr训练的时候，报错\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/140772087/65966cf2-9890-477e-a851-18ed3359b3e8)\r\n\r\n",
        "state": "open",
        "user": "qingjiaozyn",
        "closed_by": null,
        "created_at": "2023-12-09T07:30:27+00:00",
        "updated_at": "2024-01-02T12:43:58+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3640,
        "title": "vits训练报错",
        "body": "--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   egr::Backward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool)\r\n1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)\r\n2   Conv2dGradNodeFinal::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)\r\n3   paddle::experimental::conv2d_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, paddle::Tensor*, paddle::Tensor*)\r\n4   void phi::ConvCudnnGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, std::vector<int, std::allocator<int> > const&, int, std::string const&, phi::DenseTensor*, phi::DenseTensor*)\r\n5   phi::SearchResult<cudnnConvolutionBwdFilterAlgo_t> phi::SearchAlgorithm<(phi::ConvKind)3>::Find<float>(phi::GPUContext const&, phi::ConvArgsBase<cudnnContext*, cudnnDataType_t> const&, bool, bool, bool)\r\n6   cudnnGetConvolutionBackwardFilterAlgorithm_v7\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1702185320 (unix time) try \"date -d @1702185320\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x7d6f00003f2b) received by PID 16171 (TID 0x2b75a9be7d00) from PID 16171 ***]\r\n",
        "state": "closed",
        "user": "alittlenico",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-10T05:20:29+00:00",
        "updated_at": "2025-06-27T05:33:00+00:00",
        "closed_at": "2025-06-27T05:33:00+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3641,
        "title": "paddlespeech_server中使用asr服务，如何限制显存使用？",
        "body": "这是我的application.yaml\r\nprotocol: 'http'\r\nengine_list: ['asr_python', 'text_python']\r\nasr_python:\r\n    model: 'conformer_wenetspeech'\r\n    lang: 'zh'\r\n    sample_rate: 16000\r\n    cfg_path: # [optional]\r\n    ckpt_path: # [optional]\r\n    decode_method: 'attention_rescoring'\r\n    force_yes: True\r\n    device:  # set 'gpu:id' or 'cpu'\r\ntext_python:\r\n    task: punc\r\n    model_type: 'ernie_linear_p7_wudao'\r\n    lang: 'zh'\r\n    sample_rate: 16000\r\n    cfg_path: # [optional]\r\n    ckpt_path: # [optional]\r\n    vocab_file: # [optional]\r\n    device:  # set 'gpu:id' or 'cpu'\r\n\r\n这个paddlespeech_server服务运行起来后，显存占用高达20个G，有没有什么办法限制paddlespeech_server的显存？\r\n",
        "state": "closed",
        "user": "z070204z",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-11T01:27:18+00:00",
        "updated_at": "2025-06-27T06:33:23+00:00",
        "closed_at": "2025-06-27T06:33:23+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3642,
        "title": "[TTS]中英混合流式语音合成推理时卡顿感严重",
        "body": "参考 examples/zh_en_tts/tts3 中的语音合成示例，下载了示例中的模型文件，把相关配置改成流式语音的配置项后，调用流式合成能进行部分字母及单词的合成，但有两个问题：\r\n1、部分字母发音不准缺，如A，M，N，I，Z等\r\n2、有非常明显的卡顿感，\r\n这个如何解决？\r\n\r\nconf 文件：\r\n```sh\r\n# This is the parameter configuration file for streaming tts server.\r\n\r\n#################################################################################\r\n#                             SERVER SETTING                                    #\r\n#################################################################################\r\nhost: 0.0.0.0\r\nport: 8190\r\n\r\n# The task format in the engin_list is: <speech task>_<engine type>\r\n# engine_list choices = ['tts_online', 'tts_online-onnx'], the inference speed of tts_online-onnx is faster than tts_online.\r\n# protocol choices = ['websocket', 'http'] \r\nprotocol: 'websocket'\r\nengine_list: ['tts_online']\r\n\r\n\r\n#################################################################################\r\n#                                ENGINE CONFIG                                  #\r\n#################################################################################\r\n\r\n################################### TTS #########################################\r\n################### speech task: tts; engine_type: online #######################\r\ntts_online: \r\n    # am (acoustic model) choices=['fastspeech2_csmsc', 'fastspeech2_cnndecoder_csmsc']   \r\n    # fastspeech2_cnndecoder_csmsc support streaming am infer.     \r\n    am: 'fastspeech2_mix'\r\n    am_config: 'pretrain/fastspeech2_mix_ckpt_1.2.0/default.yaml'\r\n    am_ckpt:  'pretrain/fastspeech2_mix_ckpt_1.2.0/snapshot_iter_99200.pdz'\r\n    am_stat: 'pretrain/fastspeech2_mix_ckpt_1.2.0/speech_stats.npy'\r\n    phones_dict: 'pretrain/fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt'\r\n    tones_dict: \r\n    speaker_dict: 'pretrain/fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt'\r\n        \r\n\r\n    # voc (vocoder) choices=['mb_melgan_csmsc, hifigan_csmsc']\r\n    # Both mb_melgan_csmsc and hifigan_csmsc support streaming voc inference\r\n    voc: 'hifigan_csmsc'\r\n    voc_config: 'pretrain/hifigan_csmsc_ckpt_0.1.1/default.yaml'\r\n    voc_ckpt: 'pretrain/hifigan_csmsc_ckpt_0.1.1/snapshot_iter_2500000.pdz'\r\n    voc_stat: 'pretrain/hifigan_csmsc_ckpt_0.1.1/feats_stats.npy'\r\n\r\n    # others\r\n    lang: 'mix'\r\n    device: 'cpu' # set 'gpu:id' or 'cpu'\r\n    # am_block and am_pad only for fastspeech2_cnndecoder_onnx model to streaming am infer,\r\n    # when am_pad set 12, streaming synthetic audio is the same as non-streaming synthetic audio\r\n    am_block: 72\r\n    am_pad: 12\r\n    # voc_pad and voc_block voc model to streaming voc infer,\r\n    # when voc model is mb_melgan_csmsc, voc_pad set 14, streaming synthetic audio is the same as non-streaming synthetic audio; The minimum value of pad can be set to 7, streaming synthetic audio sounds normal\r\n    # when voc model is hifigan_csmsc, voc_pad set 19, streaming synthetic audio is the same as non-streaming synthetic audio; voc_pad set 14, streaming synthetic audio sounds normal\r\n    voc_block: 36\r\n    voc_pad: 19\r\n    \r\n\r\n\r\n#################################################################################\r\n#                                ENGINE CONFIG                                  #\r\n#################################################################################\r\n\r\n################################### TTS #########################################\r\n################### speech task: tts; engine_type: online-onnx #######################\r\ntts_online-onnx: \r\n    # am (acoustic model) choices=['fastspeech2_csmsc_onnx', 'fastspeech2_cnndecoder_csmsc_onnx']\r\n    # fastspeech2_cnndecoder_csmsc_onnx support streaming am infer.        \r\n    am: 'fastspeech2_cnndecoder_csmsc_onnx' \r\n    # am_ckpt is a list, if am is fastspeech2_cnndecoder_csmsc_onnx, am_ckpt = [encoder model, decoder model, postnet model];\r\n    # if am is fastspeech2_csmsc_onnx, am_ckpt = [ckpt model];\r\n    am_ckpt:   # list\r\n    am_stat: \r\n    phones_dict: \r\n    tones_dict: \r\n    speaker_dict: \r\n    am_sample_rate: 24000\r\n    am_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 4\r\n\r\n    # voc (vocoder) choices=['mb_melgan_csmsc_onnx, hifigan_csmsc_onnx']\r\n    # Both mb_melgan_csmsc_onnx and hifigan_csmsc_onnx support streaming voc inference\r\n    voc: 'mb_melgan_csmsc_onnx'\r\n    voc_ckpt: \r\n    voc_sample_rate: 24000\r\n    voc_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 4\r\n\r\n    # others\r\n    lang: 'zh'\r\n    # am_block and am_pad only for fastspeech2_cnndecoder_onnx model to streaming am infer,\r\n    # when am_pad set 12, streaming synthetic audio is the same as non-streaming synthetic audio\r\n    am_block: 72\r\n    am_pad: 12\r\n    # voc_pad and voc_block voc model to streaming voc infer,\r\n    # when voc model is mb_melgan_csmsc_onnx, voc_pad set 14, streaming synthetic audio is the same as non-streaming synthetic audio; The minimum value of pad can be set to 7, streaming synthetic audio sounds normal\r\n    # when voc model is hifigan_csmsc_onnx, voc_pad set 19, streaming synthetic audio is the same as non-streaming synthetic audio; voc_pad set 14, streaming synthetic audio sounds normal\r\n    voc_block: 36\r\n    voc_pad: 14\r\n    # voc_upsample should be same as n_shift on voc config.\r\n    voc_upsample: 300\r\n    \r\n```\r\n",
        "state": "open",
        "user": "hexianbin1994",
        "closed_by": null,
        "created_at": "2023-12-11T03:01:04+00:00",
        "updated_at": "2024-11-13T06:16:48+00:00",
        "closed_at": null,
        "comments_count": [
            "jobsjiang",
            "Ankh-L",
            "hexianbin1994",
            "Ankh-L",
            "hexianbin1994",
            "Ankh-L",
            "jianghuakun",
            "jianghuakun",
            "jianghuakun",
            "jianghuakun",
            "jianghuakun",
            "jianghuakun",
            "AaronWanng",
            "mx305"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3643,
        "title": "请教一下语音识别关键字提取",
        "body": "请问一下,PaddleSpeech如何实现语音识别关键字?有相关的方案吗?最好是能够识别方言",
        "state": "open",
        "user": "DEWUIW",
        "closed_by": null,
        "created_at": "2023-12-11T07:00:32+00:00",
        "updated_at": "2024-01-02T12:46:28+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3645,
        "title": "[TTS]改变采用频率后，合成的语音音色差别很大",
        "body": "用tts 的python api测试语音合成时，其它参数不变的情况下，只将采样频率由默认的24000hz改为16000hz，结果发现，合成的语音由原来的女音变成了男音，不知道为什么会这样？\r\ntts(text=text_str, am='fastspeech2_aishell3', voc='pwgan_aishell3', spk_id=spk_id, output=output_name)",
        "state": "open",
        "user": "aidenyao",
        "closed_by": null,
        "created_at": "2023-12-13T07:12:20+00:00",
        "updated_at": "2023-12-13T07:12:20+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3648,
        "title": "运行synthesize_streaming.py报错，请问可能是什么原因",
        "body": "synthesize_e2e 可以正常跑通\r\n这是报错：\r\n```[2023-12-14 13:49:24,172] [    INFO] - Already cached C:\\Users\\92357\\.paddlenlp\\\r\nmodels\\bert-base-chinese\\bert-base-chinese-vocab.txt\r\n[2023-12-14 13:49:24,195] [    INFO] - tokenizer config file saved in C:\\Users\\9\r\n2357\\.paddlenlp\\models\\bert-base-chinese\\tokenizer_config.json\r\n[2023-12-14 13:49:24,196] [    INFO] - Special tokens file saved in C:\\Users\\923\r\n57\\.paddlenlp\\models\\bert-base-chinese\\special_tokens_map.json\r\nvocab_size: 268\r\nW1214 13:49:24.485235 12312 gpu_resources.cc:61] Please NOTE: device: 0, GPU Com\r\npute Capability: 6.1, Driver API Version: 12.2, Runtime API Version: 11.6\r\nW1214 13:49:24.490222 12312 gpu_resources.cc:91] device: 0, cuDNN Version: 8.6.\r\nBuilding prefix dict from the default dictionary ...\r\n[2023-12-14 13:49:28,709] [   DEBUG] __init__.py:113 - Building prefix dict from\r\n the default dictionary ...\r\nLoading model from cache C:\\Users\\92357\\AppData\\Local\\Temp\\jieba.cache\r\n[2023-12-14 13:49:28,710] [   DEBUG] __init__.py:132 - Loading model from cache\r\nC:\\Users\\92357\\AppData\\Local\\Temp\\jieba.cache\r\nLoading model cost 0.546 seconds.\r\n[2023-12-14 13:49:29,255] [   DEBUG] __init__.py:164 - Loading model cost 0.546\r\nseconds.\r\nPrefix dict has been built successfully.\r\n[2023-12-14 13:49:29,255] [   DEBUG] __init__.py:166 - Prefix dict has been buil\r\nt successfully.\r\nTraceback (most recent call last):\r\n  File \"E:\\AiSound\\PaddleSpeech-New\\PaddleSpeech-WebUI\\python\\Lib\\site-packages\\\r\npaddlespeech\\t2s\\exps\\synthesize_streaming.py\", line 305, in <module>\r\n    main()\r\n  File \"E:\\AiSound\\PaddleSpeech-New\\PaddleSpeech-WebUI\\python\\Lib\\site-packages\\\r\npaddlespeech\\t2s\\exps\\synthesize_streaming.py\", line 301, in main\r\n    evaluate(args)\r\n  File \"E:\\AiSound\\PaddleSpeech-New\\PaddleSpeech-WebUI\\python\\Lib\\site-packages\\\r\npaddlespeech\\t2s\\exps\\synthesize_streaming.py\", line 181, in evaluate\r\n    before_outs = am_decoder(orig_hs)\r\n  File \"E:\\AiSound\\PaddleSpeech-New\\PaddleSpeech-WebUI\\python\\Lib\\site-packages\\\r\npaddle\\fluid\\dygraph\\layers.py\", line 1012, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\nTypeError: TransformerEncoder.forward() missing 1 required positional argument:\r\n'masks'\r\n```\r\n这是参数和配置：\r\n```========Args========\r\nam: fastspeech2_csmsc\r\nam_ckpt: download_csmsc_ver/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000\r\n.pdz\r\nam_config: download_csmsc_ver/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\nam_stat: download_csmsc_ver/fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy\r\nam_streaming: false\r\nblock_size: 42\r\ninference_dir: null\r\nlang: zh\r\nngpu: 1\r\noutput_dir: output\r\npad_size: 12\r\nphones_dict: download_csmsc_ver/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.tx\r\nt\r\ntext: output/wenben.txt\r\ntones_dict: null\r\nvoc: pwgan_csmsc\r\nvoc_ckpt: download_csmsc_ver/pwg_baker_ckpt_0.4/pwg_snapshot_iter_400000.pdz\r\nvoc_config: download_csmsc_ver/pwg_baker_ckpt_0.4/pwg_default.yaml\r\nvoc_stat: download_csmsc_ver/pwg_baker_ckpt_0.4/pwg_stats.npy\r\n\r\n========Config========\r\nbatch_size: 64\r\nf0max: 400\r\nf0min: 80\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\nmax_epoch: 1000\r\nmodel:\r\n  adim: 384\r\n  aheads: 2\r\n  decoder_normalize_before: True\r\n  dlayers: 4\r\n  dunits: 1536\r\n  duration_predictor_chans: 256\r\n  duration_predictor_kernel_size: 3\r\n  duration_predictor_layers: 2\r\n  elayers: 4\r\n  encoder_normalize_before: True\r\n  energy_embed_dropout: 0.0\r\n  energy_embed_kernel_size: 1\r\n  energy_predictor_chans: 256\r\n  energy_predictor_dropout: 0.5\r\n  energy_predictor_kernel_size: 3\r\n  energy_predictor_layers: 2\r\n  eunits: 1536\r\n  init_dec_alpha: 1.0\r\n  init_enc_alpha: 1.0\r\n  init_type: xavier_uniform\r\n  pitch_embed_dropout: 0.0\r\n  pitch_embed_kernel_size: 1\r\n  pitch_predictor_chans: 256\r\n  pitch_predictor_dropout: 0.5\r\n  pitch_predictor_kernel_size: 5\r\n  pitch_predictor_layers: 5\r\n  positionwise_conv_kernel_size: 3\r\n  positionwise_layer_type: conv1d\r\n  postnet_chans: 256\r\n  postnet_filts: 5\r\n  postnet_layers: 5\r\n  reduction_factor: 1\r\n  stop_gradient_from_energy_predictor: False\r\n  stop_gradient_from_pitch_predictor: True\r\n  transformer_dec_attn_dropout_rate: 0.2\r\n  transformer_dec_dropout_rate: 0.2\r\n  transformer_dec_positional_dropout_rate: 0.2\r\n  transformer_enc_attn_dropout_rate: 0.2\r\n  transformer_enc_dropout_rate: 0.2\r\n  transformer_enc_positional_dropout_rate: 0.2\r\n  use_scaled_pos_enc: True\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_snapshots: 5\r\nnum_workers: 4\r\noptimizer:\r\n  learning_rate: 0.001\r\n  optim: adam\r\nseed: 10086\r\nupdater:\r\n  use_masking: True\r\nwin_length: 1200\r\nwindow: hann\r\nallow_cache: True\r\nbatch_max_steps: 25500\r\nbatch_size: 6\r\ndiscriminator_grad_norm: 1\r\ndiscriminator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ndiscriminator_params:\r\n  bias: True\r\n  conv_channels: 64\r\n  in_channels: 1\r\n  kernel_size: 3\r\n  layers: 10\r\n  nonlinear_activation: LeakyReLU\r\n  nonlinear_activation_params:\r\n    negative_slope: 0.2\r\n  out_channels: 1\r\n  use_weight_norm: True\r\ndiscriminator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 5e-05\r\n  step_size: 200000\r\ndiscriminator_train_start_steps: 100000\r\neval_interval_steps: 1000\r\nfmax: 7600\r\nfmin: 80\r\nfs: 24000\r\ngenerator_grad_norm: 10\r\ngenerator_optimizer_params:\r\n  epsilon: 1e-06\r\n  weight_decay: 0.0\r\ngenerator_params:\r\n  aux_channels: 80\r\n  aux_context_window: 2\r\n  bias: True\r\n  dropout: 0.0\r\n  freq_axis_kernel_size: 1\r\n  gate_channels: 128\r\n  in_channels: 1\r\n  interpolate_mode: nearest\r\n  kernel_size: 3\r\n  layers: 30\r\n  nonlinear_activation: None\r\n  nonlinear_activation_params:\r\n\r\n  out_channels: 1\r\n  residual_channels: 64\r\n  skip_channels: 64\r\n  stacks: 3\r\n  upsample_scales: [4, 5, 3, 5]\r\n  use_causal_conv: False\r\n  use_weight_norm: True\r\ngenerator_scheduler_params:\r\n  gamma: 0.5\r\n  learning_rate: 0.0001\r\n  step_size: 200000\r\nlambda_adv: 4.0\r\nn_fft: 2048\r\nn_mels: 80\r\nn_shift: 300\r\nnum_save_intermediate_results: 4\r\nnum_snapshots: 10\r\nnum_workers: 4\r\npin_memory: True\r\nremove_short_samples: True\r\nsave_interval_steps: 5000\r\nseed: 42\r\nstft_loss_params:\r\n  fft_sizes: [1024, 2048, 512]\r\n  hop_sizes: [120, 240, 50]\r\n  win_lengths: [600, 1200, 240]\r\n  window: hann\r\ntop_db: 60\r\ntrain_max_steps: 400000\r\ntrim_frame_length: 2048\r\ntrim_hop_length: 512\r\ntrim_silence: False\r\nwin_length: 1200\r\nwindow: hann\r\n```\r\n十分感谢帮助",
        "state": "closed",
        "user": "923571390",
        "closed_by": "923571390",
        "created_at": "2023-12-14T05:52:05+00:00",
        "updated_at": "2024-01-05T06:31:19+00:00",
        "closed_at": "2024-01-05T06:31:19+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3644,
        "title": "Format not recognised",
        "body": "While trying to upload a wav file per Webrequest im getting the following error\r\n\r\n {\"error\":\"Error opening '/tmp/Goodevening.wav': Format not recognised.\"}\r\n \r\n my api_service.py looks like \r\n \r\n from flask import Flask, request, jsonify\r\nimport os\r\nimport logging\r\nfrom paddlespeech.cli.st.infer import STExecutor\r\nimport tempfile\r\nimport shutil\r\n\r\napp = Flask(__name__)\r\nlogging.basicConfig(level=logging.INFO)\r\n\r\n# Initialize the Speech Translation model\r\nst_executor = STExecutor()\r\n\r\n@app.route('/translate', methods=['POST'])\r\ndef translate_audio():\r\n    if 'file' not in request.files:\r\n        return jsonify({'error': 'No file part'}), 400\r\n\r\n    file = request.files['file']\r\n\r\n    if file.filename == '':\r\n        return jsonify({'error': 'No selected file'}), 400\r\n\r\n    if file and allowed_file(file.filename):\r\n        # Save the file to a temporary location\r\n        temp_dir = tempfile.mkdtemp()\r\n        filename = os.path.join(temp_dir, file.filename)\r\n        file.save(filename)\r\n\r\n        try:\r\n            # Translate the audio\r\n            result = st_executor(audio_file=filename)\r\n            return jsonify({'translation': result})\r\n        except Exception as e:\r\n            logging.error(f\"Error during processing: {e}\")\r\n            return jsonify({'error': str(e)}), 500\r\n        finally:\r\n            # Clean up temporary files\r\n            shutil.rmtree(temp_dir)\r\n    else:\r\n        return jsonify({'error': 'Invalid file format'}), 400\r\n\r\ndef allowed_file(filename):\r\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'wav'}\r\n\r\nif __name__ == '__main__':\r\n    app.run(host='0.0.0.0', port=5000)\r\n    \r\n    any ideas how to overcome that issue ?",
        "state": "closed",
        "user": "Phalanx-01",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-11T11:39:55+00:00",
        "updated_at": "2025-06-27T06:33:21+00:00",
        "closed_at": "2025-06-27T06:33:21+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3646,
        "title": "声音分类ESC50：模型部署出错！TypeError: only size-1 arrays can be converted to Python scalars",
        "body": "看到之前有人也遇到这个问题，\r\n[https://github.com/PaddlePaddle/PaddleSpeech/issues/3463)](url)\r\n底下有回复建议使用较低版本的的paddlepaddle-gpu，我降低版本试过并不能解决这个问题，请问有人遇到这个问题并且成功解决的吗？",
        "state": "open",
        "user": "Heavenbest",
        "closed_by": null,
        "created_at": "2023-12-13T07:59:10+00:00",
        "updated_at": "2025-06-27T02:32:45+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3647,
        "title": "用ECAPA-TDNN实现藏语上的多说话人合成",
        "body": "\r\n看了ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis这篇论文，我想在藏语上用ECAPA-TDNN实现多说话人的合成。但是我只有40个说话人，总共35小时的数据集。我看都是在英文和中文这样大的数据集下做的，那我可以用中文上的预训练的模型，然后在我的藏语上做微调，还是使用藏语数据集完全从头训练一个ECAPA-TDNN模型。不知道我的想法是否可行。希望大佬们给出一些建议！！！",
        "state": "closed",
        "user": "zhoufqing",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-13T13:44:31+00:00",
        "updated_at": "2025-06-27T05:32:51+00:00",
        "closed_at": "2025-06-27T05:32:51+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3656
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3650,
        "title": "请问phone_map_id 的特殊 id 的意义在哪里查看？",
        "body": "感谢百忙之中查看这个问题。\r\n\r\n我使用了 examples\\zh_en_tts\\tts3 的模型，我想写一个自定义的代码来直接生成音素ID数列。\r\n我发现里面有个 phone_id_map.txt 的文件，应该记录了音素对应ID表。\r\n但有一些看上去不是拼音或者英文发音符号的关系对， 我找不到详细的说明。请问里面如：\r\n~~~\r\n<pad> 0\r\n<unk> 1\r\np 271\r\nq 272\r\nr 273\r\ns 274\r\nsh 275\r\nsil 276\r\nsp 277\r\nspl 278\r\nspn 279\r\nt 280\r\n, 383\r\n. 384\r\n? 385\r\n! 386\r\n<eos> 387\r\n~~~\r\n这些看不出是拼音的一些特殊符号，它们是在什么情况下使用的？或者哪里有关于这些符号的说明？\r\n能否详细告之，谢谢！\r\n",
        "state": "closed",
        "user": "yzznw",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-19T00:53:32+00:00",
        "updated_at": "2025-06-27T06:33:22+00:00",
        "closed_at": "2025-06-27T06:33:22+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3649,
        "title": "版本问题参考：https://github.com/PaddlePaddle/PaddleSpeech/issues/3528",
        "body": " 版本问题参考：https://github.com/PaddlePaddle/PaddleSpeech/issues/3528\r\n\r\n_Originally posted by @zxcd in https://github.com/PaddlePaddle/PaddleSpeech/issues/3607#issuecomment-1846487548_\r\n    你好，按这个https://github.com/PaddlePaddle/PaddleSpeech/issues/3528 提供的两个版本，安装后是可以解决ImportError: cannot import name 'sequence_mask' from 'paddle.fluid.layers'问题，但是新问题又来\r\n\r\n![image](https://user-images.githubusercontent.com/1428540/290734186-bad01f1b-ae05-4fe5-a713-deffadeb99b0.png)\r\n",
        "state": "closed",
        "user": "sunqinbo",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-15T05:34:25+00:00",
        "updated_at": "2025-06-27T06:33:18+00:00",
        "closed_at": "2025-06-27T06:33:18+00:00",
        "comments_count": [
            "sunqinbo",
            "zxcd",
            "zxcd",
            "happywch",
            "zxcd",
            "sunqinbo",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3651,
        "title": "关于pad3d函数错误 ,如何解决",
        "body": "RuntimeError: (NotFound) The kernel with key (GPU, Undefined(AnyLayout), int16) of kernel `pad3d` is not registered and fail to fallback to CPU one. Selected wrong DataType `int16`. Paddle support following DataTypes: float64, complex128, float16, float32, complex64, bfloat16, int32, int64.\r\n  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at ../paddle/phi/core/kernel_factory.cc:259)\r\n\r\n",
        "state": "open",
        "user": "toby911",
        "closed_by": null,
        "created_at": "2023-12-20T08:43:46+00:00",
        "updated_at": "2024-01-16T12:11:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3653,
        "title": "[S2T] bug crash",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nquick start crash\r\n\r\n**To Reproduce**\r\n(5d25475b9480) root@5d25475b9480:/opt/quick-start# paddlespeech tts --input \"hello\" --output output.wav\r\nW1220 14:30:21.064070   724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.3, Runtime API Version: 11.8\r\nW1220 14:30:21.066586   724 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\nI1220 14:30:21.533761   724 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\nI1220 14:30:21.534078   724 eager_method.cc:140] Warning:: 0D Tensor cannot be used as 'Tensor.numpy()[0]' . In order to avoid this problem, 0D Tensor will be changed to 1D numpy currently, but it's not correct and will be removed in release 2.6. For Tensor contain only one element, Please modify  'Tensor.numpy()[0]' to 'float(Tensor)' as soon as possible, otherwise 'Tensor.numpy()[0]' will raise error in release 2.6.\r\n/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/layers.py:1897: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\nKeyError: 'phone_ids'\r\n\r\n(5d25475b9480) root@5d25475b9480:/opt/quick-start# paddlespeech asr --lang zh --input zh.wav\r\nW1220 14:35:27.887745   802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.3, Runtime API Version: 11.8\r\nW1220 14:35:27.889140   802 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\n[2023-12-20 14:35:29,613] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/usr/local/lib/python3.10/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\nroot@5d25475b9480:/opt/quick-start# pip list |grep -i paddle\r\npaddle2onnx                 1.1.0\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.1\r\npaddlepaddle-gpu            2.5.2\r\npaddlesde                   0.2.5\r\npaddleslim                  2.4.1\r\npaddlespeech                1.4.1\r\npaddlespeech-ctcdecoders    0.2.0\r\npaddlespeech-feat           0.1.0\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "idreamerhx",
        "closed_by": null,
        "created_at": "2023-12-20T14:40:28+00:00",
        "updated_at": "2023-12-25T10:52:13+00:00",
        "closed_at": null,
        "comments_count": [
            "idreamerhx",
            "idreamerhx"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3652,
        "title": "[TTS]merge_yi function's bug",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nmerge_yi这个方法的实现有问题，如果一句话中出现了多个 <动词，一，动词>组合的话，会有溢出错误。\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\ncase:\r\nseg = [('奶嘴', 'n'), ('儿', 'n'), ('是不是', 'l'), ('平常', 'a'), ('咱', 'r'), ('煮', 'v'), ('一', 'm'), ('煮', 'v'), ('烫', 'v'), ('一', 'm'), ('烫', 'v'), ('啥', 'r'), ('的', 'uj'), ('沙', 'n'), ('杀', 'v'), ('小菌', 'n'), ('菌用', 'n'), ('的', 'uj'), ('干净', 'a'), (',', 'x')]\r\n\r\n\r\n> fixed version：\r\n\r\n      def _merge_yi(seg):\r\n          new_seg = []\r\n          skip_next = False\r\n          # function 1\r\n          for i, (word, pos) in enumerate(seg):\r\n              if skip_next:\r\n                  skip_next = False\r\n                  continue\r\n              if i - 1 >= 0 and word == \"一\" and i + 1 < len(seg) and seg[i - 1][0] == seg[i + 1][0] and seg[i - 1][1] == \"v\":\r\n                  new_seg[-1] = (new_seg[-1][0] + \"一\" + seg[i + 1][0], new_seg[-1][1])\r\n                  skip_next = True\r\n              else:\r\n                  new_seg.append((word, pos))\r\n          seg = new_seg\r\n          new_seg = []\r\n          # function 2\r\n          for i, (word, pos) in enumerate(seg):\r\n              if new_seg and new_seg[-1][0] == \"一\":\r\n                  new_seg[-1] = (new_seg[-1][0] + word, new_seg[-1][1])\r\n              else:\r\n                  new_seg.append((word, pos))\r\n          return new_seg\r\n  \r\n      res = _merge_yi(seg)\r\n      print(res)\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "lanyuer",
        "closed_by": "zxcd",
        "created_at": "2023-12-20T12:39:47+00:00",
        "updated_at": "2024-06-05T02:41:34+00:00",
        "closed_at": "2024-06-05T02:41:33+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3655,
        "title": "pip install paddlespeech报错",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\npip install paddlespeech报错：\r\nERROR: Cannot install paddlespeech==0.0.1a0, paddlespeech==0.0.2a0, paddlespeech==0.1.0a0, paddlespeech==0.1.0a1, paddlespeech==0.1.0a2, paddlespeech==0.1.0a3, paddlespeech==0.1.0a4, paddlespeech==0.1.0a5 and paddlespeech==0.1.0a6 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    paddlespeech 0.1.0a6 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a5 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a4 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a3 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a2 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a1 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.1.0a0 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.0.2a0 depends on paddlespeech-ctcdecoders\r\n    paddlespeech 0.0.1a0 depends on paddlespeech-ctcdecoders\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict\r\n\r\nERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\r\n",
        "state": "closed",
        "user": "PearlDzzz",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-22T10:29:57+00:00",
        "updated_at": "2025-06-27T05:32:53+00:00",
        "closed_at": "2025-06-27T05:32:53+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3654,
        "title": "流式并发问题",
        "body": "请问下现在的流式 ASR 和 TTS 服务，websocket 和 http 是否都是支持并发调用的呢？\r\n",
        "state": "closed",
        "user": "wawaa",
        "closed_by": "wawaa",
        "created_at": "2023-12-20T16:26:56+00:00",
        "updated_at": "2024-01-25T02:32:40+00:00",
        "closed_at": "2024-01-25T02:32:40+00:00",
        "comments_count": [
            "zxcd",
            "wawaa"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3657,
        "title": "关于speaker diarization问题",
        "body": "## General Question\r\n\r\n\r\n/PaddleSpeech/paddlespeech/vector/exps/ecapa_tdnn/  ，想使用这个开源的sv0_ecapa_tdnn_voxceleb12_ckpt_0_1_1模型测试自己的数据，应该怎么实现呢？该工程下只能对下面这个开源的数据集进行测试，\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/22997054/f1222cea-fed9-4804-bef9-4df3681976a7)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/22997054/61f408de-2c10-44df-bed4-95ed743f3fb2)\r\n",
        "state": "closed",
        "user": "Heavenbest",
        "closed_by": "stale[bot]",
        "created_at": "2023-12-26T08:47:11+00:00",
        "updated_at": "2025-06-27T06:33:19+00:00",
        "closed_at": "2025-06-27T06:33:19+00:00",
        "comments_count": [
            "zxcd",
            "Heavenbest",
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3662
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3658,
        "title": "[S2T]argparse.ArgumentError: argument --audio_file: conflicting option string: --audio_file",
        "body": "Traceback (most recent call last):\r\n  File \"/raid/ASR/paddlespeech/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py\", line 174, in <module>\r\n    parser.add_argument(\"--audio_file\", type=str, help='audio file path')\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1386, in add_argument\r\n    return self._add_action(action)\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1749, in _add_action\r\n    self._optionals._add_action(action)\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1590, in _add_action\r\n    action = super(_ArgumentGroup, self)._add_action(action)\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1400, in _add_action\r\n    self._check_conflict(action)\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1539, in _check_conflict\r\n    conflict_handler(action, confl_optionals)\r\n  File \"/home/shj/miniconda3/envs/Paddlenv/lib/python3.8/argparse.py\", line 1548, in _handle_conflict_error\r\n    raise ArgumentError(action, message % conflict_string)\r\nargparse.ArgumentError: argument --audio_file: conflicting option string: --audio_file\r\n",
        "state": "open",
        "user": "xdchuan011209",
        "closed_by": null,
        "created_at": "2024-01-04T01:54:19+00:00",
        "updated_at": "2024-01-16T11:41:36+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3659,
        "title": "语音转文字时，最大支持多长时间",
        "body": "当语音时长为1分47秒时程序报错，并且直接当掉了。\r\nToken indices sequence length is longer than the specified maximum sequence length for this model (515 > 513). Running this sequence through the model will\r\nresult in indexing errors已放弃(吐核)\r\n问题1、\r\n    如何修改配置可以改变时长？\r\n问题2、\r\n   程序报错的时候不应该直接当掉，如何捕获异常？\r\n",
        "state": "open",
        "user": "xxch",
        "closed_by": null,
        "created_at": "2024-01-04T10:01:33+00:00",
        "updated_at": "2024-01-16T11:22:02+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3660,
        "title": "windows10  Broadcast dimension mismatch.",
        "body": "测试环境\r\nwin10\r\n依赖版本\r\n![Snipaste_2024-01-05_16-54-08](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/42c10ffa-0d3d-473b-839e-71cc95488023)\r\n\r\npython版本\r\n3.9.18\r\n\r\n测试代码如下\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\n\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\")\r\nprint(result)\r\n\r\n报错信息如下:\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ..\\paddle/phi/kernels/funcs/common_shape.h:84)\r\n\r\nTraceback (most recent call last):\r\n  File \"G:\\ASRFromPaddle\\PaddleSpeech-develop\\004.py\", line 4, in <module>\r\n    result = asr(audio_file=\"zh.wav\")\r\n  File \"G:\\ASRFromPaddle\\PaddleSpeech-develop\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"G:\\ASRFromPaddle\\PaddleSpeech-develop\\paddlespeech\\cli\\asr\\infer.py\", line 512, in __call__\r\n    res = self.postprocess()  # Retrieve result of asr.\r\n  File \"G:\\ASRFromPaddle\\PaddleSpeech-develop\\paddlespeech\\cli\\asr\\infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n\r\n期望结果:\r\n我看其他issue有提到这个问题 说的是paddlespeech版本问题 但是我看他们的是在Linux上 而且我这个paddle speech的版本是1.4.1\r\n应该怎么修改才能可以正常运行 因为还用到流式语音服务器 streaming _asr_server 希望这两个都可以正常运行 谢谢!!!",
        "state": "closed",
        "user": "777sfdf",
        "closed_by": "777sfdf",
        "created_at": "2024-01-05T09:00:44+00:00",
        "updated_at": "2025-01-07T06:55:28+00:00",
        "closed_at": "2024-01-17T07:02:01+00:00",
        "comments_count": [
            "zxcd",
            "777sfdf",
            "mimzzzz"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3663,
        "title": "[TTS]UnicodeDecodeError: 'gbk' codec can't decode byte 0x96 in position 2: illegal multibyte sequence",
        "body": "**Describe the bug**\r\nTraceback (most recent call last):\r\nFile \"D:\\lvyaodong\\python3\\lib\\runpy.py\", line 196, in run_module_as_main\r\nexec(code, run_globals)\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\Scripts\\paddlespeech.exe_main.py\", line 7, in\r\nsys.exit(execute())\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\paddlespeech\\cli\\entry.py\", line 40, in execute\r\nexec(\"from {} import {}\".format(module, cls))\r\nFile \"\", line 1, in\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\paddlespeech\\cli\\tts_init.py\", line 14, in\r\nfrom .infer import TTSExecutor\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py\", line 33, in\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_inference\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\paddlespeech\\t2s\\exps\\syn_utils.py\", line 36, in\r\nfrom paddlespeech.t2s.frontend.canton_frontend import CantonFrontend\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\paddlespeech\\t2s\\frontend\\canton_frontend.py\", line 19, in\r\nimport ToJyutping\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\ToJyutping_init.py\", line 3, in\r\nfrom .ToJyutping import *\r\nFile \"D:\\aiworkspace\\PaddleSpeech.venv\\lib\\site-packages\\ToJyutping\\ToJyutping.py\", line 9, in\r\nfor line in f:\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0x96 in position 2: illegal multibyte sequence\r\n\r\n\r\n**To Reproduce**\r\n`\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\n\r\nTEXT = str('今天天气十分不错。', 'utf-8')\r\n\r\ntts = TTSExecutor()\r\ntts(encodings='utf-8', text=TEXT, output=\"output.wav\")\r\n`\r\n\r\n**Expected behavior**\r\n\r\n**Screenshots**\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/20541921/5af0bace-d0cc-481f-9c44-d6bf41e0db06)\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Windows10\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version 3.10\r\n - PaddlePaddle Version 2.6-gpu\r\n - Model Version \r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version  11.7/8.4.1\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\n\r\nset PYTHONUTF8=1 没有用",
        "state": "closed",
        "user": "Darksiderlyd",
        "closed_by": "zxcd",
        "created_at": "2024-01-17T07:03:41+00:00",
        "updated_at": "2024-01-23T11:45:35+00:00",
        "closed_at": "2024-01-23T11:45:35+00:00",
        "comments_count": [
            "Darksiderlyd",
            "Darksiderlyd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3661,
        "title": "请问语音合成的时候如何增加停顿",
        "body": "比如我需要倒计时3、2、1\r\n每次在中间停顿1秒钟这种，我应该如何在输入文本里面增加标记让合成语音的时候能够按照要求停顿\r\n",
        "state": "closed",
        "user": "nine-city",
        "closed_by": "stale[bot]",
        "created_at": "2024-01-10T02:04:49+00:00",
        "updated_at": "2025-06-27T05:33:01+00:00",
        "closed_at": "2025-06-27T05:33:01+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3664,
        "title": "fastspeech2_aishell3效果很差",
        "body": "采用fastspeech2_aishell3和pwgan_aishell3合成音频，指定spk_id后仍然出现多个人声音，而且有些字读不清晰，请问是什么原因呢？\r\n代码如下：\r\nsource path.sh\r\nFLAGS_allocator_strategy=naive_best_fit \\\r\nFLAGS_fraction_of_gpu_memory_to_use=0.01 \\\r\npython3 ${BIN_DIR}/../synthesize_e2e.py \\\r\n  --am fastspeech2_aishell3 \\\r\n  --am_config fastspeech2_aishell3_ckpt_1.1.0/default.yaml \\\r\n  --am_ckpt fastspeech2_aishell3_ckpt_1.1.0/snapshot_iter_96400.pdz \\\r\n  --am_stat fastspeech2_aishell3_ckpt_1.1.0/speech_stats.npy \\\r\n  --voc pwgan_aishell3 \\\r\n  --voc_config pwg_aishell3_ckpt_0.5/default.yaml \\\r\n  --voc_ckpt pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz \\\r\n  --voc_stat pwg_aishell3_ckpt_0.5/feats_stats.npy \\\r\n  --lang zh \\\r\n  --text paddlespeech/t2s/assets/sentences.txt \\\r\n  --output_dir examples/aishell3/tts3/exp/default/test_e2e \\\r\n  --phones_dict fastspeech2_aishell3_ckpt_1.1.0/phone_id_map.txt \\\r\n  --speaker_dict fastspeech2_aishell3_ckpt_1.1.0/speaker_id_map.txt \\\r\n  --spk_id 0 \\\r\n  --inference_dir examples/aishell3/tts3/exp/default/inference \\",
        "state": "closed",
        "user": "William-HTP",
        "closed_by": "stale[bot]",
        "created_at": "2024-01-17T12:00:32+00:00",
        "updated_at": "2025-06-27T06:33:26+00:00",
        "closed_at": "2025-06-27T06:33:26+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3665,
        "title": "请帮忙分析下报错：IndexError: (OutOfRange) The starting index 0 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [0, 0). (at ..\\paddle/fluid/pybind/slice_utils.h:214)",
        "body": "## General Question\r\n\r\nE:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n[2024-01-18 13:51:22,092] [    INFO] - Already cached C:\\Users\\47053\\.paddlenlp\\models\\bert-base-chinese\\bert-base-chinese-vocab.txt\r\n[2024-01-18 13:51:22,105] [    INFO] - tokenizer config file saved in C:\\Users\\47053\\.paddlenlp\\models\\bert-base-chinese\\tokenizer_config.json\r\n[2024-01-18 13:51:22,105] [    INFO] - Special tokens file saved in C:\\Users\\47053\\.paddlenlp\\models\\bert-base-chinese\\special_tokens_map.json\r\nE:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\nE:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\nBuilding prefix dict from the default dictionary ...\r\n[2024-01-18 13:51:31,117] [   DEBUG] __init__.py:113 - Building prefix dict from the default dictionary ...\r\nDumping model to file cache C:\\Users\\47053\\AppData\\Local\\Temp\\jieba.cache\r\n[2024-01-18 13:51:31,822] [   DEBUG] __init__.py:146 - Dumping model to file cache C:\\Users\\47053\\AppData\\Local\\Temp\\jieba.cache\r\nLoading model cost 0.757 seconds.\r\n[2024-01-18 13:51:31,875] [   DEBUG] __init__.py:164 - Loading model cost 0.757 seconds.\r\nPrefix dict has been built successfully.\r\n[2024-01-18 13:51:31,875] [   DEBUG] __init__.py:166 - Prefix dict has been built successfully.\r\nTraceback (most recent call last):\r\n  File \"D:\\Develop\\Python\\Audio\\PaddleSpeech\\demo.py\", line 6, in <module>\r\n    tts(text=\"今天天气十分不错。\", output=\"output.wav\")\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py\", line 710, in __call__\r\n    self.infer(text=text, lang=lang, am=am, spk_id=spk_id)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddle\\base\\dygraph\\base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\cli\\tts\\infer.py\", line 496, in infer\r\n    mel = self.am_inference(part_phone_ids)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 920, in forward\r\n    normalized_mel, d_outs, p_outs, e_outs = self.acoustic_model.inference(\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 810, in inference\r\n    _, outs, d_outs, p_outs, e_outs, _ = self._forward(\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 601, in _forward\r\n    x_masks = self._source_mask(ilens)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\models\\fastspeech2\\fastspeech2.py\", line 891, in _source_mask\r\n    x_masks = make_non_pad_mask(ilens)\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\modules\\nets_utils.py\", line 258, in make_non_pad_mask\r\n    return paddle.logical_not(make_pad_mask(lengths, xs, length_dim))\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddlespeech\\t2s\\modules\\nets_utils.py\", line 146, in make_pad_mask\r\n    bs = paddle.shape(lengths)[0]\r\n  File \"E:\\Anaconda\\installation\\envs\\Audio\\lib\\site-packages\\paddle\\base\\dygraph\\tensor_patch_methods.py\", line 896, in __getitem__\r\n    return self._getitem_dygraph(item)\r\nIndexError: (OutOfRange) The starting index 0 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [0, 0). (at ..\\paddle/fluid/pybind/slice_utils.h:214)\r\n\r\n",
        "state": "open",
        "user": "quantbruce",
        "closed_by": null,
        "created_at": "2024-01-18T06:16:39+00:00",
        "updated_at": "2025-06-02T07:39:34+00:00",
        "closed_at": null,
        "comments_count": [
            "zyk-miao",
            "zyk-miao",
            "zxcd",
            "zyk-miao",
            "zyk-miao",
            "lijianxin520",
            "zyk-miao",
            "lixiaoxiangzhi",
            "stale[bot]",
            "lixiaoxiangzhi",
            "quantbruce",
            "lixiaoxiangzhi"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3666,
        "title": "请问windowns是否可以训练模型？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "pony5551",
        "closed_by": null,
        "created_at": "2024-01-18T19:17:50+00:00",
        "updated_at": "2025-04-26T03:46:10+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "sealofyou",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3671
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3667,
        "title": "[TTS]小样本微调，参考一句PaddleSpeech/examples/other/tts_finetune /tts3/在thchs30数据集上微调，loss降到1.5就不降了，且推理时候能学到微调数据集的声色，但是生成的语音有沙沙的杂声，请问是哪里出现了问题呢",
        "body": "基于PaddleSpeech/examples/other/tts_finetune /tts3/的readme，在中英混合模型上，如果从BZNSYP中选出来3k条语音微调am模型，loss可以下降到0.7左右，且用微调模型合成语音，声音比较清晰，同样用aishell3的数据集的某个人的声音的多条数据微调，推理模型合成的声音也很清晰，没有沙沙的声音；\r\n但是用上述方法，在thchs30上选了250个同一个人的语音进行微调，微调后推理模型合成的语音存在沙沙的声音，又从thchs30中选出1000条同一个人的音色的数据微调，微调后loss仍然在1.5左右，且推理合成的声音中存在沙沙的声音，但是能学到微调数据中的音色。\r\n\r\n\r\n请问大佬们，上述是哪里出现了问题呢\r\n",
        "state": "open",
        "user": "balicheng",
        "closed_by": null,
        "created_at": "2024-01-19T06:41:13+00:00",
        "updated_at": "2024-12-26T02:47:14+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "balicheng",
            "Ankh-L"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3668,
        "title": "[S2T] 转静态模型遇到错误：AttributeError: checkpoint",
        "body": "根据`examples/wenetspeech/asr1/README.md`说明，对`asr1_chunk_conformer_u2pp_wenetspeech_ckpt_1.3.0.model.tar.gz`中的模型进行转化。\r\n\r\n步骤如下：\r\n1.进入转化脚本所在目录：`cd examples/wenetspeech/asr1/`\r\n2.解压下载的模型文件压缩包至当前目录。\r\n3.运行转化脚本：`./local/export.sh asr1_chunk_conformer_u2pp_wenetspeech_ckpt_1.3.0.model/model.yaml asr1_chunk_conformer_u2pp_wenetspeech_ckpt_1.3.0.model/exp/chunk_conformer_u2pp/checkpoints/avg_10 ./export.ji`\r\n\r\n报错如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/PaddleSpeech-r1.4/paddlespeech/s2t/exps/u2/bin//export.py\", line 53, in <module>\r\n    main(config, args)\r\n  File \"/home/PaddleSpeech-r1.4/paddlespeech/s2t/exps/u2/bin//export.py\", line 30, in main\r\n    main_sp(config, args)\r\n  File \"/home/PaddleSpeech-r1.4/paddlespeech/s2t/exps/u2/bin//export.py\", line 23, in main_sp\r\n    exp = Tester(config, args)\r\n  File \"/home/root/anaconda3/envs/speech_test/lib/python3.7/site-packages/paddlespeech/s2t/exps/u2/model.py\", line 313, in __init__\r\n    super().__init__(config, args)\r\n  File \"/home/root/anaconda3/envs/speech_test/lib/python3.7/site-packages/paddlespeech/s2t/exps/u2/model.py\", line 48, in __init__\r\n    super().__init__(config, args)\r\n  File \"/home/root/anaconda3/envs/speech_test/lib/python3.7/site-packages/paddlespeech/s2t/training/trainer.py\", line 130, in __init__\r\n    kbest_n=self.config.checkpoint.kbest_n,\r\n  File \"/home/root/anaconda3/envs/speech_test/lib/python3.7/site-packages/yacs/config.py\", line 141, in __getattr__\r\n    raise AttributeError(name)\r\nAttributeError: checkpoint\r\n2024-01-19 17:44:08.242 | INFO     | paddlespeech.s2t.training.trainer:__init__:116 - Rank: 0/1\r\nFailed in export!\r\n```\r\n\r\n",
        "state": "open",
        "user": "great-wind",
        "closed_by": null,
        "created_at": "2024-01-19T10:07:38+00:00",
        "updated_at": "2024-01-24T01:23:53+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "great-wind"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3670,
        "title": "list index out range",
        "body": "环境：\r\nubuntu20.04\r\ncuda 12.0\r\ncudatookit 8.9\r\npaddlepaddle-gpu==2.5.2.post120\r\n\r\n![微信图片_20240121151605](https://github.com/PaddlePaddle/PaddleSpeech/assets/36878412/d9cfd3a3-63cc-4352-b90e-7c16f13ebaaf)\r\n`File \"/hone/intel/.conda/envs/speech10/lib/python3.10/site-packages/paddlespeech/cl1/asr/infer ,py\", line 303, in inferresult transcripts = self.model.decode(File \"/home/intel/.conda/envs/speech10/lib/python3.10/site-packages/decorator.py\", line 232, in funreturn caller(func.*(extras +args)File \"/home/intel/.conda/envs/speech10/lib/python3.10/site-packages/paddle/fluid/dygraph/base.py\", line 347, in _decorate functionreturn funC(*args，**kwargs)File \"/home/intel/.conda/envs/speech10/lib/python3.10/site-packages/paddlespeech/s2t/models/u2/u2.py\"，line 818，in decodehyp = self.attention rescoring(File \"/home/intel/.conda/envs/speech10/lib/python3.10/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention rescoringassert speech.shape[o] speech lengths.shaperoIndexError: list index out of range2024-01-21 15:09:16,837]INFOT-'result!raceback (most recent call last):File\"/home/intel/.conda/envs/speech10/lib/python3.10/site-packageserver/engine/asr/python/asrengine.py\", line 116,in rself.output = self.postprocess()# Retrieve result of asrFile \"/home/intel/.conda/envs/speech10/lib/python3.10/site-packages/paline 324,in postprocessreturn self.outputs[\"result\"7<eyError:'result\r\nDuring handling of the above exception, another exception occurred:\r\nraceback (most recent call last)File \"/home/intel/.conda/envs/speech10/lib/pvthon3,10/site-packages/paddlespeech/server/restful/asr api,py\".line 83. in asrconnection handler.run(audio dataFile \"/hone/intel/.conda/envs/speech10/lib/python3,10/site-packages/paddlespeech/server/engine/asr/python/asr_enginepy\", line 125, in rusys.exit(-1)`\r\n\r\n不知道该怎么调整了，\r\n感觉版本对应的特别复杂，部署太难了",
        "state": "open",
        "user": "xxch",
        "closed_by": null,
        "created_at": "2024-01-21T07:22:44+00:00",
        "updated_at": "2024-01-26T03:05:41+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "xxch",
            "zxcd",
            "xxch",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3669,
        "title": "利用paddlespeech预训练模型进行声音分类模型调优",
        "body": "利用paddlespeech预训练模型进行声音分类模型调优\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/tutorial/cls/cls_tutorial.ipynb\r\n1、发现同样的测试样本，特征提取也一样，但多次预测，每次预测的结果对应的分类类型都不一样\r\na、有尝试过固定随机种子，问题没解决\r\nb、尝试导出静态模型进行推理，但predict时提示找不出lod_audio包（脚本参考https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/esc50/cls0/local/infer.sh）\r\n问题情况：paddleaudio 1.01 load_audio包找不到，帮忙确认一下哪个版本有，谢谢\r\nfrom paddleaudio.backends import soundfile_load as load_audio报错\r\nImportError                               Traceback (most recent call last)\r\nCell In[12], line 21\r\n     19 import yaml\r\n     20 from paddle.audio.features import LogMelSpectrogram\r\n---> 21 from paddleaudio.backends import soundfile_load as load_audio\r\n     22 #import paddle.audio.load as load_audio\r\n     24 from paddleaudio.utils import logger\r\n\r\nImportError: cannot import name 'soundfile_load' from 'paddleaudio.backends' (C:\\Users\\JM\\.conda\\envs\\pg\\lib\\site-packages\\paddleaudio\\backends\\__init__.py)",
        "state": "closed",
        "user": "XiaoqingWang",
        "closed_by": "stale[bot]",
        "created_at": "2024-01-19T11:18:34+00:00",
        "updated_at": "2025-06-27T06:33:25+00:00",
        "closed_at": "2025-06-27T06:33:25+00:00",
        "comments_count": [
            "zxcd",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3672,
        "title": "请问有比较明确的能跑起 demo 的安装环境的详细步骤或推荐的步骤嘛",
        "body": "有比较明确的能跑起 demo 的安装环境的详细步骤或推荐的步骤嘛，搞了二天了没搞定。。。不是依赖报错，就是运行时有问题。。。\r\n\r\n目前运行官方的 Automatic Speech Recognition 示例后，报这个错。\r\n\r\n2024-01-22 19:21:14.135 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n[1]    76255 segmentation fault  python3 ./src/pp.py\r\n/Users/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n\r\nmac m2\r\n使用 pyenv，切了 python 3.10.13\r\n指定安装了 paddlepaddle 2.5.1 ， paddle speech 使用源码安装 develop 版本。\r\n安装过程中都没有报错。\r\n\r\n",
        "state": "closed",
        "user": "cyqresig",
        "closed_by": "stale[bot]",
        "created_at": "2024-01-22T11:41:21+00:00",
        "updated_at": "2025-06-27T06:33:27+00:00",
        "closed_at": "2025-06-27T06:33:27+00:00",
        "comments_count": [
            "zxcd",
            "cyqresig",
            "cyqresig",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3673,
        "title": "British accent is too different from real people https://www.youtube.com/@EnglishwithLucy",
        "body": "Maybe we can make her British Accent for training https://www.youtube.com/@EnglishwithLucy",
        "state": "closed",
        "user": "Pantyhose-X",
        "closed_by": "zxcd",
        "created_at": "2024-01-29T13:47:32+00:00",
        "updated_at": "2024-02-29T07:48:38+00:00",
        "closed_at": "2024-02-29T07:48:38+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3674,
        "title": "你好，请问为什么现在粤语模型标点符号前面的一个字都读还没有读完就结束了呢？",
        "body": "## General Question\r\n我以前用的时候还是正常的，最近都是这样了。比如「关关雎鸠，在河之洲」，最后那个“鸠”一定还没读完就结束了。其他句子也是同理，句号、感叹号，都有这种情况。不知道你们有没有发现。\r\n我的参数设置:\r\n```python\r\nwav_file = tts_executor(\r\n        text=txt_contents,\r\n        am='fastspeech2_canton',\r\n        voc='hifigan_csmsc',\r\n        lang='canton',\r\n        spk_id=10,\r\n        use_onnx=True,\r\n        output='api_1.wav',\r\n        cpu_threads=0\r\n    )\r\n```\r\n\r\n\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "zx-lhb",
        "closed_by": "zxcd",
        "created_at": "2024-02-04T08:04:28+00:00",
        "updated_at": "2024-02-29T07:48:45+00:00",
        "closed_at": "2024-02-29T07:48:45+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3676,
        "title": "在win10上启动demos中的speech_web进行实时语音识别 如何提高实时语音转写速度",
        "body": "页面图片\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/45e7fae6-d422-424d-866d-63222a632fe9)\r\n\r\n\r\n测试环境\r\nwin10 使用cpu\r\n依赖版本\r\n![Snipaste_2024-02-06_16-32-12](https://github.com/PaddlePaddle/PaddleSpeech/assets/118660349/e659bfbb-51e2-4966-9d93-7f4b15f895cb)\r\n\r\npython版本\r\n3.8.18\r\n\r\n需求:\r\n在不使用gpu的情况下 如何调整可以能让实时语音转写速度加快 因为现在的语音转写 还是有些延迟的  思路应该往哪个方面考虑\r\n\r\n如果在 使用gpu的情况下 又该往哪个方面考虑取调整优化\r\n\r\n期待回复 谢谢!!!\r\n\r\n\r\n",
        "state": "closed",
        "user": "777sfdf",
        "closed_by": "zxcd",
        "created_at": "2024-02-06T08:38:24+00:00",
        "updated_at": "2024-02-29T08:18:17+00:00",
        "closed_at": "2024-02-29T08:18:17+00:00",
        "comments_count": [
            "Ray961123",
            "Ray961123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3675,
        "title": "mac install paddlespeech_ctcdecoders 找不到匹配的包",
        "body": "Mac M2 上\r\n安装了 paddlepaddle 2.4.2， paddlespeech 2.4.1。\r\n跑官方的第一个示例（语音转文本）时，报错提示paddlespeech_ctcdecoders 找不到，没有安装 \r\n\r\n下面是错误信息：\r\npython3 ./src/pp.py                            \r\n/Users/ccc/.pyenv/versions/3.8.18/lib/python3.8/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\n/Users/ccc/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pip/_vendor/packaging/version.py:111: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  warnings.warn(\r\n/Users/ccc/.pyenv/versions/3.8.18/lib/python3.8/site-packages/pip/_vendor/packaging/version.py:111: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\r\n  warnings.warn(\r\nERROR: Could not find a version that satisfies the requirement paddlespeech_ctcdecoders (from versions: none)\r\nERROR: No matching distribution found for paddlespeech_ctcdecoders\r\n\r\n[notice] A new release of pip is available: 23.0.1 -> 24.0\r\n[notice] To update, run: pip install --upgrade pip\r\n2024-02-05 23:23:51.915 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2024-02-05 23:23:52.017 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[1]    24004 segmentation fault  python3 ./src/pp.py\r\n/Users/ccc/.pyenv/versions/3.8.18/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n\r\n然后尝试安装，但提示找不到匹配的版本。。。，错误信息如下\r\npip3 install paddlespeech_ctcdecoders\r\nERROR: Could not find a version that satisfies the requirement paddlespeech_ctcdecoders (from versions: none)\r\nERROR: No matching distribution found for paddlespeech_ctcdecoders\r\n\r\n\r\n",
        "state": "closed",
        "user": "cyqresig",
        "closed_by": "zxcd",
        "created_at": "2024-02-05T15:37:46+00:00",
        "updated_at": "2024-02-29T11:02:48+00:00",
        "closed_at": "2024-02-29T07:50:02+00:00",
        "comments_count": [
            "Ray961123",
            "jzhang533"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3677,
        "title": "Feature Request - CommonVoice recipe",
        "body": null,
        "state": "closed",
        "user": "allandclive",
        "closed_by": "zxcd",
        "created_at": "2024-02-17T18:08:34+00:00",
        "updated_at": "2024-02-29T08:18:23+00:00",
        "closed_at": "2024-02-29T08:18:23+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3681
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3678,
        "title": "有可适配cpu不支持avx的版本吗",
        "body": null,
        "state": "closed",
        "user": "xhshdjdk",
        "closed_by": "zxcd",
        "created_at": "2024-02-20T10:43:08+00:00",
        "updated_at": "2024-02-29T08:18:27+00:00",
        "closed_at": "2024-02-29T08:18:27+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3684
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3683
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3680,
        "title": "流式ASR支持多并发吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n如果支持的话，同时可以支持多少个并发",
        "state": "closed",
        "user": "xiaolei543",
        "closed_by": "xiaolei543",
        "created_at": "2024-02-23T03:05:32+00:00",
        "updated_at": "2024-02-29T07:17:41+00:00",
        "closed_at": "2024-02-29T07:17:41+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3679,
        "title": "能否新增粤语的语音识别功能？应该如何训练粤语的语音识别模型？",
        "body": "如题。\r\n\r\n背景：我想寻找一个能离线运行的粤语的语音识别（Speech2Text）解决方案，不需要Text2Speech功能。\r\n\r\n请问之后会更新粤语的语音识别的功能吗？\r\n另外，如果我想使用自己的语音数据，训练一个自己的粤语的语音识别模型，应该如何做呢？\r\n可以直接使用PaddleSpeech的框架进行训练吗？\r\n",
        "state": "open",
        "user": "zhangqiqi1228",
        "closed_by": null,
        "created_at": "2024-02-21T02:47:09+00:00",
        "updated_at": "2024-02-22T02:20:28+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3682,
        "title": "语音合成tts，使用不用方式调用，运行的时间不一样尼？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/28383188/f60de590-7cf0-467c-93d1-3d6eb070007f)\r\n\r\n我用这种方式，am模型运行时间大概0.4s左右\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/28383188/eeb77175-088d-4ec9-9663-06018f213299)\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/28383188/fc34e9c3-1bed-43c4-bee2-4cbba9f5f5f9)\r\n\r\n我用api的方式调用的时间am模型1.1s左右，\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/28383188/dda4f4a5-a1fc-4da3-a952-2a38b6bee10f)\r\n\r\n我很奇怪，他们模型都是一样的，怎么运行时间不一样尼\r\n\r\n\r\n使用的都是默认参数，模型也是默认模型'fastspeech2_csmsc' ，请大佬帮忙解答下，这到底是怎么回事尼？\r\n",
        "state": "closed",
        "user": "LeFuGang",
        "closed_by": "LeFuGang",
        "created_at": "2024-02-26T06:30:20+00:00",
        "updated_at": "2024-03-01T08:00:28+00:00",
        "closed_at": "2024-03-01T08:00:28+00:00",
        "comments_count": [
            "Ray961123",
            "LeFuGang"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3690
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3686,
        "title": "Docker 配置CPU 无法正常启动",
        "body": "/home/PaddleSpeech/demos/speech_web/speech_server 目录下\r\n启动：python main.py --port 8091\r\n报错：\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py:595: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  \"You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\"\r\n\r\nE0228 09:52:21.514371   141 place.cc:342] Cannot use GPU because there is no GPU detected on your machine.\r\n/arrow/cpp/src/arrow/filesystem/s3fs.cc:2598:  arrow::fs::FinalizeS3 was not called even though S3 was initialized.  This could lead to a segmentation fault at exit\r\n\r\n\r\n配置\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/44686916/8cada92b-2eff-4540-9930-1db1ab15b198)\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/44686916/e519eb2a-8d2d-4173-9310-57d6ef4a21ad)\r\n",
        "state": "open",
        "user": "springbootyp",
        "closed_by": null,
        "created_at": "2024-02-28T10:11:44+00:00",
        "updated_at": "2024-02-29T07:45:26+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3685,
        "title": "[TTS]文字转语音，一直被killed",
        "body": "当前环境：\r\n```\r\nCentOS Linux release 7.9.2009 (Core)\r\npython==3.9.18\r\npaddlepaddle==2.4.2\r\npaddlespeech==1.3.0\r\nOpenCC==1.1.6\r\nnumpy==1.23.5\r\n```\r\n\r\n这是当前服务器的cpu信息：\r\n```\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                1\r\nOn-line CPU(s) list:   0\r\nThread(s) per core:    1\r\nCore(s) per socket:    1\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 94\r\nModel name:            Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz\r\nStepping:              3\r\nCPU MHz:               2394.374\r\nBogoMIPS:              4788.74\r\nHypervisor vendor:     KVM\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              4096K\r\nL3 cache:              28160K\r\n```\r\n\r\n这是当前服务器的内存信息：\r\n```\r\n(paddle_env) [root@VM-16-13-centos ~]# free -h\r\n              total        used        free      shared  buff/cache   available\r\nMem:           2.0G        211M        1.5G        552K        242M        1.6G\r\nSwap:            0B          0B          0B\r\n```\r\n\r\n执行命令：\r\n```shell\r\npaddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\n```\r\n\r\n一直被killed，报错信息如下：\r\n```shell\r\n/root/anaconda3/envs/paddle_env/lib/python3.9/site-packages/setuptools/sandbox.py:13: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n  import pkg_resources\r\n/root/anaconda3/envs/paddle_env/lib/python3.9/site-packages/pkg_resources/__init__.py:2846: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/root/anaconda3/envs/paddle_env/lib/python3.9/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/root/anaconda3/envs/paddle_env/lib/python3.9/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nKilled\r\n```\r\n\r\n提问：\r\n```\r\n**是否我当前服务器配置太低，内存只有2G太小了？**\r\n```",
        "state": "open",
        "user": "qianze10078",
        "closed_by": null,
        "created_at": "2024-02-28T06:21:22+00:00",
        "updated_at": "2024-03-22T02:34:57+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "GDbbq"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3687,
        "title": "[S2T]Outputs text to chinese even when I set it to english. ",
        "body": "**Describe the bug**\r\nOutputs text to chinese even when I set it to english. \r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. run `paddlespeech_server start --config_file ./paddlespeech/server/conf/application.yaml` on  PaddleSpeech repo\r\n2. run\r\n```\r\nfrom paddlespeech.server.bin.paddlespeech_client import ASRClientExecutor\r\n\r\nasrclient_executor = ASRClientExecutor()\r\nres = asrclient_executor(\r\n    input=\"processed_audio.wav\",\r\n    server_ip=\"127.0.0.1\",\r\n    port=8090,\r\n    sample_rate=16000,\r\n    lang=\"en_us\",\r\n    audio_format=\"wav\")\r\n\r\nprint(res)\r\n```\r\nThe output will be in Chinese even when the entire video is is in english\r\n\r\n**Expected behavior**\r\nIt should provide english transcriptions. \r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu 22.04\r\n - GCC/G++ 12.1\r\n - Python Version 3.10.12\r\n - PaddlePaddle Version 2.5.1\r\n - Model Version \r\n - GPU/DRIVER Information RTX4090/NVIDIA-SMI 535.161.07   \r\n - CUDA/CUDNN Version Cuda 12.2\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n\r\n",
        "state": "open",
        "user": "LaiWeiQuan",
        "closed_by": null,
        "created_at": "2024-02-29T00:55:57+00:00",
        "updated_at": "2024-02-29T07:34:43+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3689,
        "title": "请问可以实现离线实时的英文语音识别吗",
        "body": "请问可以将此模型加入到我的程序中，实现离线的实时英文语音识别并转换文字吗？\r\n我的程序中需要一个能够实时语音识别转文字的模块，不知道该模型是否能够实现。",
        "state": "closed",
        "user": "JustWinWin",
        "closed_by": "stale[bot]",
        "created_at": "2024-02-29T12:38:28+00:00",
        "updated_at": "2025-06-27T06:33:42+00:00",
        "closed_at": "2025-06-27T06:33:42+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3688,
        "title": "ImportError: /home/fit/anaconda3/envs/qwen/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /home/fit/anaconda3/envs/qwen/lib/python3.9/site-packages/opencc/clib/opencc_clib.cpython-39-x86_64-linux-gnu.so)",
        "body": "## General Question\r\n我已经安装好了paddlepaddle==2.5.1，paddlespeech==1.4.1，但在ubuntu上使用paddlespeech时报gcc的错，我按照报错要求将ubuntu上的gcc版本调整到11.1.0后仍然报错\r\n\r\n![0cbcc2c432dd3c250b4cac21eb589230](https://github.com/PaddlePaddle/PaddleSpeech/assets/126341483/8cd7a6f6-e850-4be5-a43a-128bc576874e)\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "FAUST-BENCHOU",
        "closed_by": "FAUST-BENCHOU",
        "created_at": "2024-02-29T09:27:44+00:00",
        "updated_at": "2024-03-01T08:42:10+00:00",
        "closed_at": "2024-03-01T08:42:10+00:00",
        "comments_count": [
            "FAUST-BENCHOU",
            "FAUST-BENCHOU"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3691,
        "title": "有没有一个pip的版本依赖文件？",
        "body": "折腾很久，最简单的demo也跑不起来，有点崩溃，各种冲突与错误，照理说，我用最新的pip安装最新的stable release 应该就能正常work吧，希望至少能给个requirement.txt把依赖的库与版本都能明确下来\r\n新功能跟其他的bugfix都可以暂停一下，我觉得这个才是更重要的需求...",
        "state": "open",
        "user": "sinopec",
        "closed_by": null,
        "created_at": "2024-03-01T03:07:51+00:00",
        "updated_at": "2025-04-26T04:45:35+00:00",
        "closed_at": null,
        "comments_count": [
            "jzhang533",
            "Ray961123",
            "ljh-coder",
            "fancyerii",
            "woshisx",
            "wukonggeo",
            "woshisx",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3692,
        "title": "按照文档安装过程中没有任何报错，但是执行语音识别命令报错，重装好几次都是一样",
        "body": "## General Question\r\npip list：\r\n`Package                     Version\r\n--------------------------- -----------\r\nabsl-py                     2.1.0\r\naiohttp                     3.9.3\r\naiosignal                   1.3.1\r\nannotated-types             0.6.0\r\nantlr4-python3-runtime      4.9.3\r\nanyio                       4.3.0\r\nastor                       0.8.1\r\nasttokens                   2.4.1\r\nasync-timeout               4.0.3\r\nattrs                       23.2.0\r\naudioread                   3.0.1\r\nBabel                       2.14.0\r\nbce-python-sdk              0.9.4\r\nblinker                     1.7.0\r\nbokeh                       3.3.4\r\nboltons                     23.1.1\r\nBottleneck                  1.3.8\r\nbraceexpand                 0.1.7\r\ncertifi                     2024.2.2\r\ncffi                        1.16.0\r\ncharset-normalizer          3.3.2\r\nclick                       8.1.7\r\ncolorama                    0.4.6\r\ncoloredlogs                 15.0.1\r\ncolorlog                    6.8.2\r\ncontourpy                   1.2.0\r\ncycler                      0.12.1\r\nCython                      3.0.8\r\ndatasets                    2.18.0\r\ndecorator                   5.1.1\r\ndill                        0.3.4\r\nDistance                    0.1.3\r\neditdistance                0.8.1\r\neinops                      0.7.0\r\nexceptiongroup              1.2.0\r\nexecuting                   2.0.1\r\nfastapi                     0.110.0\r\nfilelock                    3.13.1\r\nFlask                       3.0.2\r\nflask-babel                 4.0.0\r\nflatbuffers                 23.5.26\r\nfonttools                   4.49.0\r\nfrozenlist                  1.4.1\r\nfsspec                      2024.2.0\r\nftfy                        6.1.3\r\nfuture                      1.0.0\r\ng2p-en                      2.1.0\r\ng2pM                        0.1.2.5\r\nh11                         0.14.0\r\nh5py                        3.10.0\r\nhttpcore                    1.0.4\r\nhttpx                       0.27.0\r\nhuggingface-hub             0.21.3\r\nhumanfriendly               10.0\r\nHyperPyYAML                 1.2.2\r\nidna                        3.6\r\ninflect                     7.0.0\r\nintervaltree                3.1.0\r\nipython                     8.22.1\r\nitsdangerous                2.1.2\r\njedi                        0.19.1\r\njieba                       0.42.1\r\nJinja2                      3.1.3\r\njoblib                      1.3.2\r\njsonlines                   4.0.0\r\nkaldiio                     2.18.0\r\nkiwisolver                  1.4.5\r\nlibrosa                     0.8.1\r\nllvmlite                    0.42.0\r\nloguru                      0.7.2\r\nlxml                        5.1.0\r\nmarkdown-it-py              3.0.0\r\nMarkupSafe                  2.1.5\r\nmatplotlib                  3.8.3\r\nmatplotlib-inline           0.1.6\r\nmdurl                       0.1.2\r\nmido                        1.3.2\r\nmock                        5.1.0\r\nmpmath                      1.3.0\r\nmultidict                   6.0.5\r\nmultiprocess                0.70.12.2\r\nnara-wpe                    0.0.9\r\nnltk                        3.8.1\r\nnote-seq                    0.0.3\r\nnumba                       0.59.0\r\nnumpy                       1.23.5\r\nomegaconf                   2.3.0\r\nonnx                        1.15.0\r\nonnxruntime                 1.17.1\r\nOpenCC                      1.1.7\r\nopencc-python-reimplemented 0.1.7\r\nopencv-python               4.6.0.66\r\nopt-einsum                  3.3.0\r\npackaging                   23.2\r\npaddle2onnx                 1.0.6\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.1\r\npaddlepaddle-gpu            2.6.0\r\npaddlesde                   0.2.5\r\npaddleslim                  2.6.0\r\npaddlespeech                0.0.0\r\npaddlespeech-feat           0.1.0\r\npandas                      2.2.1\r\nparameterized               0.9.0\r\nparso                       0.8.3\r\npathos                      0.2.8\r\npattern-singleton           1.2.0\r\npillow                      10.2.0\r\npip                         23.3.1\r\nplatformdirs                4.2.0\r\npooch                       1.8.1\r\nportalocker                 2.8.2\r\npox                         0.3.4\r\nppdiffusers                 0.19.4\r\nppft                        1.7.6.8\r\npraatio                     5.1.1\r\npretty-midi                 0.2.10\r\nprettytable                 3.10.0\r\nprompt-toolkit              3.0.43\r\nprotobuf                    3.20.2\r\npsutil                      5.9.8\r\npure-eval                   0.2.2\r\npyarrow                     15.0.0\r\npyarrow-hotfix              0.6\r\npybind11                    2.11.1\r\npycparser                   2.21\r\npycryptodome                3.20.0\r\npydantic                    2.6.3\r\npydantic_core               2.16.3\r\npydub                       0.25.1\r\nPygments                    2.17.2\r\npygtrie                     2.5.0\r\npyparsing                   3.1.1\r\npypinyin                    0.44.0\r\npypinyin-dict               0.7.0\r\npyreadline3                 3.4.1\r\npytest-runner               6.0.1\r\npython-dateutil             2.9.0.post0\r\npytz                        2024.1\r\npywin32                     306\r\npyworld                     0.3.4\r\nPyYAML                      6.0.1\r\npyzmq                       25.1.2\r\nrarfile                     4.1\r\nregex                       2023.12.25\r\nrequests                    2.31.0\r\nrequests-mock               1.11.0\r\nresampy                     0.4.2\r\nrich                        13.7.1\r\nruamel.yaml                 0.18.6\r\nruamel.yaml.clib            0.2.8\r\nsacrebleu                   2.4.0\r\nsafetensors                 0.4.2\r\nscikit-learn                1.4.1.post1\r\nscipy                       1.12.0\r\nsentencepiece               0.2.0\r\nseqeval                     1.2.2\r\nsetuptools                  68.2.2\r\nsix                         1.16.0\r\nsniffio                     1.3.1\r\nsortedcontainers            2.4.0\r\nsoundfile                   0.12.1\r\nstack-data                  0.6.3\r\nstarlette                   0.36.3\r\nswig                        4.2.1\r\nsympy                       1.12\r\ntabulate                    0.9.0\r\nTextGrid                    1.6.1\r\nthreadpoolctl               3.3.0\r\ntimer                       0.2.2\r\nToJyutping                  0.2.1\r\ntornado                     6.4\r\ntqdm                        4.66.2\r\ntraitlets                   5.14.1\r\ntrampoline                  0.1.2\r\ntypeguard                   2.13.3\r\ntyper                       0.9.0\r\ntyping_extensions           4.10.0\r\ntzdata                      2024.1\r\nurllib3                     1.26.18\r\nuvicorn                     0.27.1\r\nvisualdl                    2.5.3\r\nwcwidth                     0.2.13\r\nwebrtcvad                   2.0.10\r\nwebsockets                  12.0\r\nWerkzeug                    3.0.1\r\nwheel                       0.41.2\r\nwin32-setctime              1.1.0\r\nxxhash                      3.4.1\r\nxyzservices                 2023.10.1\r\nyacs                        0.1.8\r\nyarl                        1.9.4\r\nzhon                        2.0.2`\r\n\r\n\r\npowershell执行： paddlespeech asr --lang zh --input zh.wav\r\n`(paddle_test) PS E:\\AI_WorkSpace> paddlespeech asr --lang zh --input zh.wav\r\nC:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\r\n  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\nC:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2024-03-03 10:39:49.952 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\nW0303 10:39:49.955922 31980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.3, Runtime API Version: 11.8\r\nW0303 10:39:49.970871 31980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\r\n2024-03-03 10:39:50.355 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n[2024-03-03 10:39:52,263] [   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ..\\paddle/phi/kernels/funcs/common_shape.h:86)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddle\\base\\dygraph\\base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 543, in attention_rescoring\r\n    hyps, encoder_out = self._ctc_prefix_beam_search(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 424, in _ctc_prefix_beam_search\r\n    encoder_out, encoder_mask = self._forward_encoder(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\models\\u2\\u2.py\", line 229, in _forward_encoder\r\n    encoder_out, encoder_mask = self.encoder(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\modules\\encoder.py\", line 184, in forward\r\n    chunk_masks = add_optional_chunk_mask(\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddlespeech\\s2t\\modules\\mask.py\", line 202, in add_optional_chunk_mask\r\n    chunk_masks = masks.logical_and(chunk_masks)  # (B, L, L)\r\n  File \"C:\\Users\\an\\.conda\\envs\\paddle_test\\lib\\site-packages\\paddle\\tensor\\logic.py\", line 143, in logical_and\r\n    return _C_ops.logical_and(x, y)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ..\\paddle/phi/kernels/funcs/common_shape.h:86)\r\n\r\nKeyError: 'result'`",
        "state": "open",
        "user": "LjPro",
        "closed_by": null,
        "created_at": "2024-03-03T02:54:44+00:00",
        "updated_at": "2025-04-26T04:45:15+00:00",
        "closed_at": null,
        "comments_count": [
            "18721688783",
            "Ray961123",
            "ljh-coder",
            "ljh-coder",
            "18721688783",
            "hbjhyhb",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3693,
        "title": "Failed to customize PaddleSpeech service for PaddleHub",
        "body": "### env:\r\n#### OS:\r\n- Windows 10\r\n\r\n#### Python:\r\n- 3.8.10\r\n\r\n#### Requirements:\r\n- paddlepaddle==2.4.2\r\n- paddlenlp==2.5.2\r\n- paddlehub==2.3.1\r\n- paddlespeech==1.4.1\r\n\r\n\r\n### File Structure:\r\n![image](https://github.com/PaddlePaddle/PaddleHub/assets/65639657/a746dfd9-fb13-46eb-be7a-68e6d5cb652c)\r\n#### module.py:\r\n``` python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport base64\r\nimport io\r\nimport sys\r\nimport time\r\nimport paddlehub as hub\r\nfrom paddlehub.module.module import moduleinfo, runnable, serving\r\nfrom paddlehub.utils.log import logger\r\n\r\n# from paddlespeech.cli.asr.infer import ASRExecutor\r\nfrom paddlespeech.server.engine.asr.python.asr_engine import ASREngine\r\nfrom paddlespeech.server.engine.asr.python.asr_engine import PaddleASRConnectionHandler\r\nfrom yacs.config import CfgNode\r\n\r\n\r\ndef base64_to_audio(b64str) -> io.BytesIO:\r\n    data = base64.b64decode(b64str.encode('utf8'))\r\n    # return io.BytesIO(data)\r\n    return data\r\n\r\n@moduleinfo(\r\n    name=\"ASR\",\r\n    version=\"1.0.0\",\r\n    summary=\"This is a PaddleHub Self-Custom Module for Automatic Speech Recognition. Powered By Mercedes-Benz RDCP/SI Team.\",\r\n    author=\"ruitian\",\r\n    author_email=\"\",\r\n    type=\"audio/asr\"\r\n)\r\nclass ASR(hub.Module):\r\n    def _initialize(self):\r\n        _config = dict()\r\n        _config['device'] = 'gpu'\r\n        _config['model'] = 'conformer_online_aishell'\r\n        _config['lang'] = 'zh'\r\n        _config['sample_rate'] = 16000\r\n        _config['cfg_path'] = None\r\n        _config['decode_method'] = 'attention_rescoring'\r\n        _config['ckpt_path'] = None\r\n        _config['force_yes'] = False\r\n        config = CfgNode(_config)\r\n        asr_engine = ASREngine()\r\n        asr_engine.init(config)\r\n        self.connection_handler = PaddleASRConnectionHandler(asr_engine)\r\n\r\n    @serving\r\n    def speech_recognize(self, audios, **kwargs):\r\n        def predict(audios, **kwargs):\r\n            res = []\r\n            if isinstance(audios, io.BytesIO):\r\n                # if not self.asr._check(audios, sample_rate=16000):\r\n                #     sys.exit(-1)\r\n\r\n                # self.asr.preprocess(self.model, audios)\r\n                # self.asr.infer(self.model)\r\n                # _result = self.asr.postprocess()\r\n                self.connection_handler.run(audios)\r\n                asr_results = self.connection_handler.postprocess()\r\n                res.append(asr_results)\r\n\r\n            elif isinstance(audios, list):\r\n                for audio in audios:\r\n                    # if not self.asr._check(audio, sample_rate=16000):\r\n                    #     sys.exit(-1)\r\n\r\n                    # self.asr.preprocess(self.model, audio)\r\n                    # self.asr.infer(self.model)\r\n                    self.connection_handler.run(audio)\r\n                    asr_results = self.connection_handler.postprocess()\r\n                    res.append(asr_results)\r\n            else:\r\n                raise RuntimeError('The audio format cannot be used in serving. make sure the base64 data converted by audio file.')\r\n\r\n            return res\r\n        audio_decode = [base64_to_audio(audio) for audio in audios]\r\n        starttime = time.time()\r\n        results = predict(audio_decode, **kwargs)\r\n        elapse = time.time() - starttime\r\n        logger.info(\"Predict time: {}\".format(elapse))\r\n        return [{\"results\": results, \"elapse\": elapse}]\r\n\r\nif __name__ == '__main__':\r\n    lib = ASR()\r\n    lib._initialize()\r\n    def readwav2base64(wav_file):\r\n        \"\"\"\r\n        read wave file and covert to base64 string\r\n        \"\"\"\r\n        with open(wav_file, 'rb') as f:\r\n            base64_bytes = base64.b64encode(f.read())\r\n            base64_string = base64_bytes.decode('utf-8')\r\n        return base64_string\r\n\r\n    file_path = r\"C:\\Users\\user\\Desktop\\zh.wav\"\r\n    b64_data = readwav2base64(file_path)\r\n    a = lib.speech_recognize([b64_data])\r\n    # a = lib.speech_recognize([b64_data])\r\n    print(a)\r\n```\r\n\r\n\r\n### Run \"__main__\" error logs:\r\n```\r\n2024-01-11 15:31:57.691 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2024-01-11 15:31:57.803 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\r\n[2024-01-11 15:32:00,635] [    INFO] - Initialize ASR server engine successfully on device: gpu.\r\n[2024-01-11 15:32:00] [CRITICAL] [transformation.py:149] Catch a exception from 0th func: LogMelSpectrogramKaldi(fs=16000, n_mels=80, n_frame_shift=10.0, n_frame_length=25.0, dither=0.1))\r\n[2024-01-11 15:32:00,642] [    INFO] - When the type of 'input' in assign is numpy.ndarray, the data type of 'input' must be bool, float32, int32 or int64, but received int16.\r\n```\r\nNOTE:\r\n### If \"@moduleinfo\" is commented out, then the main method executes successfully",
        "state": "closed",
        "user": "pinnnkman",
        "closed_by": "stale[bot]",
        "created_at": "2024-01-11T07:43:07+00:00",
        "updated_at": "2025-06-27T06:33:41+00:00",
        "closed_at": "2025-06-27T06:33:41+00:00",
        "comments_count": [
            "pinnnkman",
            "w5688414",
            "pinnnkman",
            "pinnnkman",
            "w5688414",
            "pinnnkman",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3700
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3694,
        "title": "TTS 微调自己的数据出错",
        "body": "W0305 06:05:18.573375 124766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.2, Runtime API Version: 11.3\r\nW0305 06:05:18.579509 124766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.2.\r\nmodel done!\r\noptimizer done!\r\n/home/python_venvs/paddlespeech/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/home/python_venvs/paddlespeech/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\r\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n/home/python_venvs/paddlespeech/lib/python3.10/site-packages/paddle/nn/layer/norm.py:824: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\nException in main training loop: Variable Shape not match, Variable [ create_parameter_3.w_0_moment1_0 ] need tensor with shape [] but load set tensor with shape [1]\r\n\r\n",
        "state": "open",
        "user": "zdj97",
        "closed_by": null,
        "created_at": "2024-03-05T06:26:34+00:00",
        "updated_at": "2024-03-22T02:27:48+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "GDbbq"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3695,
        "title": "能不能 边录边转换文字？  像讯飞听见那样",
        "body": "能不能 边录边转换文字？  像讯飞听见那样",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2024-03-06T01:55:40+00:00",
        "updated_at": "2024-03-08T07:00:53+00:00",
        "closed_at": "2024-03-08T07:00:53+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3696,
        "title": "中英混合模型效果很差",
        "body": "我是使用的paddlespeech-r1.4.1，代码为：\r\n\r\n```python\r\nfrom paddlespeech.cli.tts.infer import TTSExecutor\r\ntts = TTSExecutor()\r\nam = \"fastspeech2_mix\"\r\nvoc = \"hifigan_aishell3\"\r\noutput = f\"{am}-{voc}.wav\"\r\ntts(text=\"今天天气十分good。I am jack, What's your name?\", \r\n    output=output,\r\n    lang=\"mix\",\r\n    am=am,\r\n    voc=voc)\r\n\r\nprint(f\"output: {output}\")\r\n```\r\n\r\n尝试了fastspeech2_mix-hifigan_aishell3; fastspeech2_mix-hifigan_csmsc和fastspeech2_mix-pwgan_aishell3，效果都不太好。请问是我的设置有问题吗？\r\n\r\nwav文件在下面的zip包里：\r\n\r\n[output.zip](https://github.com/PaddlePaddle/PaddleSpeech/files/14504926/output.zip)\r\n",
        "state": "closed",
        "user": "fancyerii",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-06T05:16:58+00:00",
        "updated_at": "2025-06-27T06:33:51+00:00",
        "closed_at": "2025-06-27T06:33:51+00:00",
        "comments_count": [
            "Ray961123",
            "GDbbq",
            "jianghuakun",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3697,
        "title": "处理使用 PaddleSpeech 过程中出现的报错 ValueError (InvalidArgument) Broadcast dimension mismatch",
        "body": "运行在百度 `AiStudio` ，相关依赖包：\r\n```\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.1.0\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.5.2\r\npaddlepaddle                2.4.2\r\npaddlesde                   0.2.5\r\npaddleslim                  2.6.0\r\npaddlespeech                1.4.1\r\npaddlespeech-ctcdecoders    0.2.1\r\npaddlespeech-feat           0.1.0\r\n\r\nppdiffusers                 0.19.4\r\nPython                      3.8.18\r\n```\r\n\r\n问题描述：\r\n\r\n使用 语音识别 和 视频字幕 生成的 Python API 时出现报错。\r\n\r\n出现以下报错：\r\n\r\n```\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n\r\nTraceback (most recent call last):\r\n  File \"test1.py\", line 3, in <module>\r\n    result = asr(audio_file=\"zh.wav\")\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/cli/utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 512, in __call__\r\n    res = self.postprocess()  # Retrieve result of asr.\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/cli/asr/infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n```\r\n参考 语言识别 功能相关文档时发现其中的 Python API 运行时不报错。\r\n参考链接：<https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/speech_recognition/README_cn.md>\r\n\r\n经测试发现 `asr_executor()` 方法时还需要指定模型。\r\n\r\n例：\r\n\r\n```py\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"zh.wav\",model='conformer_wenetspeech')\r\nprint(result)     \r\n```\r\n运行结果：\r\n\r\n![2](https://github.com/PaddlePaddle/PaddleSpeech/assets/62947861/c315e9fb-2f8c-44a3-b64e-0d59c63bcf5b)\r\n\r\n写了两篇博客记录了相关过程，希望可以帮助到各位：\r\n\r\n- 在百度 AiStudio 平台中使用 PaddleSpeech：<https://blog.csdn.net/qq_45897239/article/details/136572991>\r\n- 处理使用 PaddleSpeech 过程中出现的报错 ValueError (InvalidArgument) Broadcast dimension mismatch：<https://blog.csdn.net/qq_45897239/article/details/136573149>",
        "state": "open",
        "user": "ljh-coder",
        "closed_by": null,
        "created_at": "2024-03-08T14:25:45+00:00",
        "updated_at": "2024-03-13T03:15:10+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "ljh-coder"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3698,
        "title": "英文标点恢复",
        "body": "请问标点恢复不支持英文吗，还是模型需要自己训练\r\n\r\n现在只有两个可选的中文模型吗：\r\n![1](https://github.com/PaddlePaddle/PaddleSpeech/assets/62947861/c66b58ee-11c9-4357-aec1-6dc5ec2b4fa4)\r\n",
        "state": "closed",
        "user": "ljh-coder",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-09T13:23:39+00:00",
        "updated_at": "2025-06-27T06:33:44+00:00",
        "closed_at": "2025-06-27T06:33:44+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3699,
        "title": "能够使用小样本英文语料对中英混合模型进行微调吗？",
        "body": "需要一个能够对中英文混合推理的tts模型，尤其是支持一些英文专有名词，如CUDA、ChatGPT、AIGC等单词。想问下我能用少量的英文专有名词语料，对模型进行微调，从而支持对英文专有名词的合成吗？",
        "state": "closed",
        "user": "aidway",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-11T07:54:47+00:00",
        "updated_at": "2025-06-27T06:33:45+00:00",
        "closed_at": "2025-06-27T06:33:45+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3702,
        "title": "请问如何把paddleSpeech打包成exe文件",
        "body": "如题",
        "state": "closed",
        "user": "swift-fs",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-11T11:03:44+00:00",
        "updated_at": "2025-06-27T06:33:47+00:00",
        "closed_at": "2025-06-27T06:33:47+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3705,
        "title": "请问是否能提供一个飞桨的语音识别模型呢？我在首页没找到",
        "body": "麻烦给个飞桨的语音识别模型，要求能准确识别语音的模型",
        "state": "open",
        "user": "lckj2009",
        "closed_by": null,
        "created_at": "2024-03-13T02:02:49+00:00",
        "updated_at": "2024-03-18T03:03:49+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "lckj2009",
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3703,
        "title": "Win11 系统下，使用报错，期待更新支持",
        "body": "## 当前环境依赖情况：\r\ncuda 版本 v12.3 \r\ncudnn 版本 cudnn-windows-x86_64-8.9.7.29_cuda12-archive\r\nTensorRT 版本 8.6.1.6.Windows10.x86_64.cuda-12.0\r\npaddlepaddle 版本 2.5.1\r\ngcc 版本 \r\n```\r\nUsing built-in specs.\r\nCOLLECT_GCC=C:\\w64devkit\\bin\\gcc.exe\r\nCOLLECT_LTO_WRAPPER=C:/w64devkit/bin/../libexec/gcc/x86_64-w64-mingw32/13.2.0/lto-wrapper.exe\r\nTarget: x86_64-w64-mingw32\r\nConfigured with: /gcc-13.2.0/configure --prefix=/w64devkit --with-sysroot=/w64devkit/x86_64-w64-mingw32 --with-native-system-header-dir=/include --target=x86_64-w64-mingw32 --host=x86_64-w64-mingw32 --enable-static --disable-shared --with-pic --with-gmp-include=/deps/include --with-gmp-lib=/deps/lib --with-mpc-include=/deps/include --with-mpc-lib=/deps/lib --with-mpfr-include=/deps/include --with-mpfr-lib=/deps/lib --enable-languages=c,c++ --enable-libgomp --enable-threads=posix --enable-version-specific-runtime-libs --disable-dependency-tracking --disable-multilib --disable-nls --disable-win32-registry --enable-mingw-wildcard CFLAGS_FOR_TARGET=-Os CXXFLAGS_FOR_TARGET=-Os LDFLAGS_FOR_TARGET=-s CFLAGS=-Os CXXFLAGS=-Os LDFLAGS=-s\r\nThread model: posix\r\nSupported LTO compression algorithms: zlib\r\ngcc version 13.2.0 (GCC)\r\n```\r\npython 版本 3.10.11\r\n操作系统  Windows 11 家庭版\r\n\r\n安装后，运行\r\n```\r\npaddlespeech asr --lang zh --input zh.wav\r\n```\r\n## 报错:\r\n```\r\nRuntimeError: (PreconditionNotMet) The third-party dynamic library (cufft64_120.dll;cufft64_12.dll;cufft64_10.dll) that Paddle depends on is not configured correctly. (error code is 126)\r\n  Suggestions:\r\n  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\r\n  2. Configure third-party dynamic library environment variables as follows:\r\n  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\r\n  - Windows: set PATH by `set PATH=XXX; (at ..\\paddle\\phi\\backends\\dynload\\dynamic_loader.cc:312)\r\n```",
        "state": "open",
        "user": "sinajia",
        "closed_by": null,
        "created_at": "2024-03-12T01:08:48+00:00",
        "updated_at": "2024-03-13T13:34:29+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "sinajia"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3704,
        "title": "流式ASR，支持8kHz的wav音频吗？",
        "body": "我解析出来结果不正确，我用的conformer_online_wenetspeech模型，把原来是16000改成了8000，以下是我的配置文件：\r\n`asr_online:\r\n    model_type: 'conformer_online_wenetspeech'\r\n    am_model: # the pdmodel file of am static model [optional]\r\n    am_params:  # the pdiparams file of am static model [optional]\r\n    lang: 'zh'\r\n    sample_rate: 8000\r\n    cfg_path:\r\n    decode_method:\r\n    force_yes: True\r\n    device: 'cpu' # cpu or gpu:id\r\n    decode_method: \"attention_rescoring\"\r\n    continuous_decoding: True # enable continue decoding when endpoint detected\r\n    num_decoding_left_chunks: -1\r\n    am_predictor_conf:\r\n        device:  # set 'gpu:id' or 'cpu'\r\n        switch_ir_optim: True\r\n        glog_info: False  # True -> print glog\r\n        summary: True  # False -> do not show predictor config\r\n\r\n    chunk_buffer_conf:\r\n        window_n: 7     # frame\r\n        shift_n: 4      # frame\r\n        window_ms: 25   # ms\r\n        shift_ms: 10    # ms\r\n        sample_rate: 8000\r\n        sample_width: 2`\r\n\r\n        \r\n我该如何进行调整？？",
        "state": "closed",
        "user": "z070204z",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-12T09:32:01+00:00",
        "updated_at": "2025-06-27T06:33:30+00:00",
        "closed_at": "2025-06-27T06:33:30+00:00",
        "comments_count": [
            "Ray961123",
            "gooloosk",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3706,
        "title": "请问一下，现在的飞桨有能直接把麦克风语音转文字的方法吗？期望能给予指点一下",
        "body": "因为业务需要，追求速度和准确性。期望能有直接将麦克风语音转文字的方案。代码是python。中文语音",
        "state": "open",
        "user": "lckj2009",
        "closed_by": null,
        "created_at": "2024-03-13T02:04:44+00:00",
        "updated_at": "2024-03-13T03:27:57+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3707,
        "title": "请问。No module named 'paddle.framework' 怎么解决啊",
        "body": "  warnings.warn(\"paddleaudio C++ extension is not available.\")\r\nC:\\Users\\ww\\anaconda3\\envs\\PaddleSpeechceshi\\lib\\site-packages\\_distutils_hack\\__init__.py:26: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2024-03-14 11:57:08.630 | INFO     | paddlespeech.s2t.modules.ctc:<module>:45 - paddlespeech_ctcdecoders not installed!\r\n2024-03-14 11:57:08.785 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000\r\n[2024-03-14 11:57:14,810] [   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ..\\paddle/phi/kernels/funcs/common_shape.h:86)\r\n\r\n\r\n请问该错误怎么解决",
        "state": "open",
        "user": "lckj2009",
        "closed_by": null,
        "created_at": "2024-03-14T03:21:12+00:00",
        "updated_at": "2024-03-18T02:39:14+00:00",
        "closed_at": null,
        "comments_count": [
            "lckj2009",
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3708,
        "title": "请大佬帮忙看一下，用流式语音合成paddlespeech/tts/streaming，将返回音频的base64转换成音频，却无法打开",
        "body": "### Discussed in https://github.com/PaddlePaddle/PaddleSpeech/discussions/3700\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **Ryder-Xu** March 11, 2024</sup>\r\n我们在内网服务器上搭建了服务，并且根据[PaddleSpeech Server RESTful API的wiki](https://github.com/PaddlePaddle/PaddleSpeech/wiki/PaddleSpeech-Server-RESTful-API)成功的使用http方式合成了语音。\r\n\r\n但是跟着[流式语音服务](https://github.com/PaddlePaddle/PaddleSpeech/wiki/PaddleSpeech-Server-WebSocket-API)的语音合成接口尝试的时候，发现base64转换的音频无法打开。\r\n\r\n1、创建连接\r\n\r\n2、开始请求\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/35769330/5d2dce26-15fe-4c73-827a-bd6fe2b4098c)\r\n\r\n3、数据传送\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/35769330/8e290e87-4793-49ee-a987-df8d7489041e)\r\n\r\n4、结束请求\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/35769330/d19a23d6-c166-4b6d-96b3-2cccde465176)\r\n\r\n5、将第二步的音频base64转化成音频文件\r\n`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`\r\n\r\n但是播放转化后的音频，被提示文件损坏了\r\n![Snipaste_2024-03-11_16-41-27](https://github.com/PaddlePaddle/PaddleSpeech/assets/35769330/1aaacbe7-c948-4db0-912b-6558efd6cb3d)\r\n\r\n</div>",
        "state": "closed",
        "user": "Ryder-Xu",
        "closed_by": "Ryder-Xu",
        "created_at": "2024-03-14T08:46:20+00:00",
        "updated_at": "2024-03-18T05:45:13+00:00",
        "closed_at": "2024-03-15T08:04:00+00:00",
        "comments_count": [
            "Ryder-Xu",
            "Ryder-Xu",
            "GiterRUOK"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3712,
        "title": "No module named 'paddlespeech.t2s','paddlespeech' is not a package",
        "body": "按照说明安装paddlespeech之后，\r\nfrom paddlespeech.t2s.exps.syn_utils import get_am_output  \r\nfrom paddlespeech.t2s.exps.syn_utils import get_frontend  \r\nfrom paddlespeech.t2s.exps.syn_utils import get_predictor  \r\nfrom paddlespeech.t2s.exps.syn_utils import get_voc_output\r\n定义会出现该错误，我该如何解决？",
        "state": "closed",
        "user": "Shaun-Wong",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-15T06:06:02+00:00",
        "updated_at": "2025-06-27T06:33:47+00:00",
        "closed_at": "2025-06-27T06:33:47+00:00",
        "comments_count": [
            "Shaun-Wong",
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3713,
        "title": "cannot import name 'clip_grad_norm_' from 'paddle.nn.utils'",
        "body": "我在使用官方镜像进行以下实验时 https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1 ，出现错误cannot import name 'clip_grad_norm_' from 'paddle.nn.utils'。\r\n官方镜像\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/45581281/05525f60-a049-421a-a060-0a4fb0fa1872)\r\n这有可能是paddlepaddle版本的问题，可以说明一下哪个版本合适吗\r\n",
        "state": "closed",
        "user": "estuday",
        "closed_by": "estuday",
        "created_at": "2024-03-18T03:36:52+00:00",
        "updated_at": "2024-06-28T01:03:16+00:00",
        "closed_at": "2024-03-18T07:04:20+00:00",
        "comments_count": [
            "xjz-ai"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3719
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3714,
        "title": "ASR Websocket方式是否支持mp3音频",
        "body": "\r\n使用ASR Websocket方式（ws://{server}:{port}/paddlespeech/asr/streaming）传入MP3音频数据返回一两次result:“”后websocket直接断开，{status:1006, reason: \"\"}。\r\n但是发送{ \"name\": \"test.mp3\", \"signal\": \"start\", \"nbest\": 1 } 又是返回 {status: 'ok', signal: 'server_ready' }。\r\n同样方式，换成 .wav，没有问题。\r\n所以是不支持 mp3，还是bug？\r\n\r\n相关关键代码如下（uniapp小程序）\r\n```\r\nthis.recorder.start({\r\n\tduration: 20000,\r\n\tnumberOfChannels: 1,\r\n\tformat: 'mp3',\r\n\tframeSize: 5, // 乱取的\r\n\tsampleRate: 16000\r\n})\r\n```\r\n```\r\nrd.onFrameRecorded(res => {\r\n\tconsole.log('recorder frame', res)\r\n\tif (!this.asrUseHttp) {\r\n\t\tconst { isLastFrame, frameBuffer } = res\r\n\t\tthis.wsSendData(this.asrWs,\r\n\t\t\tframeBuffer,\r\n\t\t\tisLastFrame\r\n\t\t)\r\n\t}\r\n})\r\n```\r\n```\r\nthis.wsSendData(this.asrWs, {\r\n\tname: '123.mp3',\r\n\tsignal: 'end',\r\n\tnbset: 1\r\n})\r\n```\r\n```\r\nthis.wsSendData(this.asrWs, {\r\n        task: '123.mp3',\r\n\tsignal: 'start',\r\n\tnbset: 1,\r\n})\r\n```",
        "state": "open",
        "user": "GiterRUOK",
        "closed_by": null,
        "created_at": "2024-03-18T07:44:57+00:00",
        "updated_at": "2025-06-27T02:32:52+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3716,
        "title": "Not find any valid checkpoints",
        "body": "你好！\r\n我在进行这个实验时https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1 在stage1提前结束了训练，再进行stage2获取最佳模型时，出现如题的错误。\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/45581281/1cbf9994-0fe7-4d31-aadc-7fa9a2707ecc)\r\n\r\n我查看了路径下是有保存模型的\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/45581281/fd5326fd-3063-4e69-93c6-d1b940dddb40)\r\n请问有什么方法可以解决吗",
        "state": "open",
        "user": "estuday",
        "closed_by": null,
        "created_at": "2024-03-19T14:01:22+00:00",
        "updated_at": "2025-06-27T02:32:54+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3717,
        "title": "导出模型后，本地部署，运行没报错，但也没输出结果，这是为什么啊？",
        "body": "\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/58422800/6262b94d-c25b-4c2c-825b-43be7338432d)\r\n",
        "state": "open",
        "user": "swingfer",
        "closed_by": null,
        "created_at": "2024-03-20T04:21:00+00:00",
        "updated_at": "2025-06-27T02:32:45+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3718,
        "title": "[BUG]目前语音转文字急需解决的BUG",
        "body": "代码是：\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"./zh.wav\")\r\nprint(result)\r\n \r\n\r\n\r\n File \"C:\\Users\\ww\\anaconda3\\envs\\pps\\lib\\site-packages\\paddlespeech\\cli\\asr\\infer.py\", line 335, in postprocess\r\n    return self._outputs[\"result\"]\r\nKeyError: 'result'\r\n\r\n这个报错很多人都提了，请问什么时候能解决呢？",
        "state": "open",
        "user": "lckj2009",
        "closed_by": null,
        "created_at": "2024-03-20T08:26:41+00:00",
        "updated_at": "2024-05-28T01:25:29+00:00",
        "closed_at": null,
        "comments_count": [
            "ljh-coder",
            "lckj2009",
            "lckj2009",
            "ljh-coder",
            "Ray961123",
            "lckj2009",
            "lckj2009",
            "ljh-coder",
            "lckj2009",
            "ljh-coder",
            "ljh-coder",
            "777sfdf",
            "lckj2009",
            "lckj2009",
            "lckj2009",
            "pzchu",
            "vivisol",
            "lckj2009",
            "achaosss"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3720,
        "title": "Are there any plans to launch vits in Chinese TTS?",
        "body": "Are there any plans to launch vits in Chinese TTS?",
        "state": "open",
        "user": "AlphaMind123",
        "closed_by": null,
        "created_at": "2024-03-20T14:34:20+00:00",
        "updated_at": "2024-03-25T08:08:07+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3721,
        "title": "How can I obtain the interim results from a streaming ASR service?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\nHi, paddle paddle!\r\nI have attempted to utilize this [documentation](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/streaming_asr_server/README.md) to start a streaming ASR service.\r\n\r\n My objective is to access the intermediate results of the ASR service(like {'w': '我', 'bg': 0.0, 'ed': 0.7000000000000001}, {'w': '认', 'bg': 0.7000000000000001, 'ed': 0.84}), but it looks like it only shows up in the log. How can I get these results using a Python script?\r\n\r\nLooking forward to your reply. :)\r\n\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "amznero",
        "closed_by": null,
        "created_at": "2024-03-21T10:40:03+00:00",
        "updated_at": "2025-06-27T02:32:47+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "777sfdf",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3722,
        "title": "[S2T]Absurd basic bug",
        "body": "```\r\n(cad) (deepspeech-venv) root@8ikb0p7c24u18-0:/bjzhyai03/bohan/PaddleSpeech# paddlespeech asr --lang zh --input zh.wav\r\n/root/miniconda3/envs/cad/lib/python3.8/site-packages/setuptools/sandbox.py:14: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n  import pkg_resources\r\n/root/miniconda3/envs/cad/lib/python3.8/site-packages/pkg_resources/__init__.py:2832: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/root/miniconda3/envs/cad/lib/python3.8/site-packages/pkg_resources/__init__.py:2832: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/root/miniconda3/envs/cad/lib/python3.8/site-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddle/fluid/dygraph/math_op_patch.py:275: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.int64, the right dtype will convert to paddle.float32\r\n  warnings.warn(\r\n[2024-03-21 14:01:24,841] [   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 375, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 543, in attention_rescoring\r\n    hyps, encoder_out = self._ctc_prefix_beam_search(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 424, in _ctc_prefix_beam_search\r\n    encoder_out, encoder_mask = self._forward_encoder(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 229, in _forward_encoder\r\n    encoder_out, encoder_mask = self.encoder(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 948, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/modules/encoder.py\", line 184, in forward\r\n    chunk_masks = add_optional_chunk_mask(\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddlespeech/s2t/modules/mask.py\", line 202, in add_optional_chunk_mask\r\n    chunk_masks = masks.logical_and(chunk_masks)  # (B, L, L)\r\n  File \"/root/miniconda3/envs/cad/lib/python3.8/site-packages/paddle/tensor/logic.py\", line 122, in logical_and\r\n    return _C_ops.logical_and(x, y)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n```",
        "state": "open",
        "user": "Imbernoulli",
        "closed_by": null,
        "created_at": "2024-03-21T14:02:43+00:00",
        "updated_at": "2024-03-25T08:17:26+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3723,
        "title": "请问是否能把一个中文音频直接转成英文音频呢？",
        "body": "conformer_talcs  是否能做到。conformer_talcs支持的语音转换到底是什么意思呢？",
        "state": "open",
        "user": "lckj2009",
        "closed_by": null,
        "created_at": "2024-03-22T09:17:05+00:00",
        "updated_at": "2024-03-25T08:27:43+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3724,
        "title": "标点添加部分报错cuda不可用",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "alanshaoTT",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-22T11:31:32+00:00",
        "updated_at": "2025-06-27T06:33:29+00:00",
        "closed_at": "2025-06-27T06:33:29+00:00",
        "comments_count": [
            "alanshaoTT",
            "alanshaoTT",
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3725,
        "title": "官方的例子不能成功运行",
        "body": "《【PaddleSpeech】一键预测，快速上手Speech开发任务》  这个官方例子使用aistudio都不能成功运行。",
        "state": "closed",
        "user": "klzhong69",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-26T02:14:40+00:00",
        "updated_at": "2025-06-27T06:33:32+00:00",
        "closed_at": "2025-06-27T06:33:32+00:00",
        "comments_count": [
            "klzhong69",
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3726,
        "title": "【飞桨护航计划集训营招募】Paddle Speech 套件能力建设方向",
        "body": "大家好，非常高兴地告诉大家，第六期 PaddlePaddle Hackathon 正式开始。活动详细信息可参考 [PaddlePaddle Hackathon 说明](https://github.com/PaddlePaddle/docs/blob/develop/docs/guides/10_contribution/hackathon_cn.md)。\r\n\r\n\r\n本次活动也包含了**飞桨护航计划集训营**赛道：开发者提交简历&通过面试后，以远程的方式深度参与飞桨开源项目开发课题，成果以 PR（Pull Requests）的形式贡献到指定代码仓库，实训期 3 个月（每周开发时间至少 25h），奖金 3-5 🌟。详情见[第六期黑客松护航计划集训营活动说明](https://github.com/PaddlePaddle/docs/blob/develop/docs/guides/10_contribution/hackathon_cn.md#2-飞桨护航计划集训营)\r\n\r\n其中，**飞桨护航计划集训营**中新增了一个项目：[PaddleSpeech 套件能力建设](https://github.com/PaddlePaddle/community/blob/master/hackathon/hackathon_6th/【Hackathon%206th】飞桨护航计划集训营项目合集.md#项目二十七paddlespeech-套件能力建设)，旨在招募 2 名有志之士对参与 Paddle Speech 套件维护与升级。若有兴趣，可直接在 https://github.com/PaddlePaddle/Paddle/issues/62906 下报名。",
        "state": "closed",
        "user": "sunzhongkai588",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-26T03:45:42+00:00",
        "updated_at": "2025-06-27T06:33:48+00:00",
        "closed_at": "2025-06-27T06:33:48+00:00",
        "comments_count": [
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3727,
        "title": "tts python服务怎样设置cpu_threads",
        "body": "rt, 在application.yaml中添加了cpu_threads: 但是不起作用\r\n",
        "state": "closed",
        "user": "kli017",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-26T07:32:59+00:00",
        "updated_at": "2025-06-27T06:33:32+00:00",
        "closed_at": "2025-06-27T06:33:32+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3732
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3728,
        "title": "请问为什么使用流式语音识别服务的时候，识别速度越来越慢？",
        "body": "\r\n比如我输入50s的语音，在40s之后显然感觉到识别结果刷新更慢了。",
        "state": "closed",
        "user": "gooloosk",
        "closed_by": "stale[bot]",
        "created_at": "2024-03-28T01:59:35+00:00",
        "updated_at": "2025-06-27T06:33:33+00:00",
        "closed_at": "2025-06-27T06:33:33+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3729,
        "title": "[TTS]没有设置参数但使用了该参数的值",
        "body": "在vits模型文件下的wavenet 文件中的residual_block.py文件中的第127行的下面代码中，\r\nx = F.dropout(x, p=self.dropout_rate, training=self.training)\r\n参数training使用的self.training,没有在该py文件的任何地方定义，导致报错。\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/108966996/39a02136-c8cb-4796-aa3d-e2ec8eca1cf2)\r\n",
        "state": "open",
        "user": "AlphaMind123",
        "closed_by": null,
        "created_at": "2024-03-28T08:48:08+00:00",
        "updated_at": "2024-03-29T09:27:58+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3730,
        "title": "【有手就行】使用你自己的声音做语音合成-这项目有跑起来的吗?",
        "body": "## General Question\r\n【有手就行】使用你自己的声音做语音合成-这项目有跑起来的吗? https://aistudio.baidu.com/projectdetail/5003396\r\n感觉改了一大堆东西什么用都没有,各种环境报错.无力吐槽\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "fantasysea",
        "closed_by": null,
        "created_at": "2024-03-28T09:21:33+00:00",
        "updated_at": "2025-04-26T04:45:20+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "zouhan6806504",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3731,
        "title": "调用 asr = ASRExecutor()gpu一直增加",
        "body": "调用 asr = ASRExecutor()                     current_result = asr(audio_file=audio_path_output, lang=\"en\", model=\"transformer_librispeech\")后gpu内存没有被释放掉，每调用一次，gpu内存都会增加，最后导致gpu崩溃[S2T]XXXX",
        "state": "open",
        "user": "hjj-lmx",
        "closed_by": null,
        "created_at": "2024-03-29T04:05:56+00:00",
        "updated_at": "2024-03-29T09:32:24+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3733,
        "title": "【TTS】启动英文流式服务报错",
        "body": "根据中文的demo改了一下am和voc，启动失败，看报错好像只支持中文流式？下面是我的配置：\r\n``\r\n#################################################################################\r\n#                             SERVER SETTING                                    #\r\n#################################################################################\r\nhost: 0.0.0.0\r\nport: 8888\r\n\r\n# The task format in the engin_list is: <speech task>_<engine type>\r\n# engine_list choices = ['tts_online', 'tts_online-onnx'], the inference speed of tts_online-onnx is faster than tts_online.\r\n# protocol choices = ['websocket', 'http']\r\nprotocol: 'websocket'\r\nengine_list: ['tts_online-onnx']\r\n#################################################################################\r\n#                                ENGINE CONFIG                                  #\r\n#################################################################################\r\n\r\n################################### TTS #########################################\r\n################### speech task: tts; engine_type: online-onnx #######################\r\ntts_online-onnx:\r\n    # am (acoustic model) choices=['fastspeech2_csmsc_onnx', 'fastspeech2_cnndecoder_csmsc_onnx']\r\n    # fastspeech2_cnndecoder_csmsc_onnx support streaming am infer.\r\n    am: 'fastspeech2_ljspeech_onnx'\r\n    # am_ckpt is a list, if am is fastspeech2_cnndecoder_csmsc_onnx, am_ckpt = [encoder model, decoder model, postnet model];\r\n    # if am is fastspeech2_csmsc_onnx, am_ckpt = [ckpt model];\r\n    am_ckpt:   # list\r\n    am_stat:\r\n    phones_dict:\r\n    tones_dict:\r\n    speaker_dict:\r\n    am_sample_rate: 24000\r\n    am_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 4\r\n\r\n    # voc (vocoder) choices=['mb_melgan_csmsc_onnx, hifigan_csmsc_onnx']\r\n    # Both mb_melgan_csmsc_onnx and hifigan_csmsc_onnx support streaming voc inference\r\n    voc: 'hifigan_ljspeech_onnx'\r\n    voc_ckpt:\r\n    voc_sample_rate: 24000\r\n    voc_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 4\r\n\r\n    # others\r\n    lang: 'en'\r\n    # am_block and am_pad only for fastspeech2_cnndecoder_onnx model to streaming am infer,\r\n    # when am_pad set 12, streaming synthetic audio is the same as non-streaming synthetic audio\r\n    am_block: 72\r\n    am_pad: 10\r\n    # voc_pad and voc_block voc model to streaming voc infer,\r\n    # when voc model is mb_melgan_csmsc_onnx, voc_pad set 14, streaming synthetic audio is the same as non-streaming synthetic audio; The minimum value of pad can be set to 7, streaming synthetic audio sounds normal\r\n    # when voc model is hifigan_csmsc_onnx, voc_pad set 19, streaming synthetic audio is the same as non-streaming synthetic audio; voc_pad set 14, streaming synthetic audio sounds normal\r\n    voc_block: 36\r\n    voc_pad: 7\r\n    # voc_upsample should be same as n_shift on voc config.\r\n    voc_upsample: 300\r\n``\r\n\r\n报错信息：\r\n[2024-04-01 07:29:24,459] [   ERROR] - Please check config, am support: fastspeech2, voc support: hifigan_csmsc-zh or mb_melgan_csmsc.",
        "state": "closed",
        "user": "Ankh-L",
        "closed_by": "Ankh-L",
        "created_at": "2024-04-01T07:41:04+00:00",
        "updated_at": "2025-04-23T14:58:25+00:00",
        "closed_at": "2024-05-24T08:07:14+00:00",
        "comments_count": [
            "Ray961123",
            "jianghuakun",
            "Ankh-L",
            "jianghuakun",
            "ddbegun"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3734,
        "title": "[TTS] Python API experience：huggingface Runtime error",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/50574730/491834a2-7126-409a-8bb3-e1f78f36f9fd)\r\n",
        "state": "open",
        "user": "jaysonteng",
        "closed_by": null,
        "created_at": "2024-04-03T02:30:01+00:00",
        "updated_at": "2024-04-03T10:03:13+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3735,
        "title": "请问，音频转文字时候，目前是否可以输出开始和结束时间戳和这个时间段对应的文本？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "xztzmr",
        "closed_by": "stale[bot]",
        "created_at": "2024-04-07T08:24:28+00:00",
        "updated_at": "2025-06-27T06:33:35+00:00",
        "closed_at": "2025-06-27T06:33:35+00:00",
        "comments_count": [
            "Ray961123",
            "777sfdf",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3737,
        "title": "TTS多音字问题",
        "body": "我在使用paddlespeech来合成语音时，遇到了下面问题：\r\n用`paddlespeech_server start --config_file application.yaml`启动服务，用`http://127.0.0.1:8090/paddlespeech/tts`来调用服务，当文本是“是否有我行人员或其他人员向你收取手续费？”时，发现行的发音为xing，正确的应该是hang。\r\n请问这个问题该怎么处理？谢谢。",
        "state": "closed",
        "user": "think4j",
        "closed_by": "think4j",
        "created_at": "2024-04-10T09:17:27+00:00",
        "updated_at": "2024-04-12T09:36:04+00:00",
        "closed_at": "2024-04-12T09:36:04+00:00",
        "comments_count": [
            "Ray961123",
            "think4j"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3739,
        "title": "mac系统使用文本转语音，存在漏字的问题",
        "body": "安装到在mac上之后，使用命令行或 python api的调用方式，根据文字生成语音时，生成的语音存在漏字的问题。例如：\r\n文本：请按照职责分⼯ 认真做好电信⽹络诈骗和跨境赌博资⾦链治理⼯作\r\n生成的语音：会漏掉 ”分工“中的工、”网络“中的网等几个字\r\n\r\n请问这是什么原因呢？",
        "state": "closed",
        "user": "huangtaosdt",
        "closed_by": "stale[bot]",
        "created_at": "2024-04-12T01:07:30+00:00",
        "updated_at": "2025-06-27T06:33:37+00:00",
        "closed_at": "2025-06-27T06:33:37+00:00",
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3738,
        "title": "流式的websocket tts 能够支持多并发吗",
        "body": "目前好像不管有多少个websocket的请求都会在下面这段代码里阻塞\r\n                while True:\r\n                    try:\r\n                        tts_results = next(wav_generator)\r\n                        resp = {\"status\": 1, \"audio\": tts_results}\r\n                        await websocket.send_json(resp)\r\n                    except StopIteration as e:\r\n                        resp = {\"status\": 2, \"audio\": ''}\r\n                        await websocket.send_json(resp)\r\n                        logger.info(\r\n                            \"Complete the synthesis of the audio streams\")\r\n                        break\r\n                    except Exception as e:\r\n                        resp = {\"status\": -1, \"audio\": ''}\r\n                        await websocket.send_json(resp)\r\n                        break\r\n                 \r\n                        ",
        "state": "open",
        "user": "QAQyy",
        "closed_by": null,
        "created_at": "2024-04-11T14:49:55+00:00",
        "updated_at": "2025-04-26T04:45:10+00:00",
        "closed_at": null,
        "comments_count": [
            "Ankh-L",
            "ximply",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3740,
        "title": "ASR GPU算力消耗",
        "body": "## General Question\r\n\r\n使用nvidia Tesla T4 16G算力卡 部署ASR服务，\r\n请问一路ASR请求消耗多少算力，有没有可参考值。\r\n",
        "state": "open",
        "user": "beixiang-l",
        "closed_by": null,
        "created_at": "2024-04-12T03:51:01+00:00",
        "updated_at": "2025-06-27T02:32:48+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3741,
        "title": "生成语音后内存不释放，导致gpu占用不存增加，直至爆内存",
        "body": "生成语音后内存不释放，导致gpu占用不存增加，直至爆内存",
        "state": "open",
        "user": "xiaofeicn",
        "closed_by": null,
        "created_at": "2024-04-12T10:16:58+00:00",
        "updated_at": "2025-06-27T02:32:50+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3742,
        "title": "README里面蜡笔小新例子是什么参数调出来的",
        "body": null,
        "state": "open",
        "user": "XDFN19930328",
        "closed_by": null,
        "created_at": "2024-04-14T13:20:45+00:00",
        "updated_at": "2025-06-27T02:32:50+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3744,
        "title": "为什么asr的预训练模型和微调后的模型文件大小不一样大？",
        "body": "我从模型列表中下载了 [Conformer Online Wenetspeech ASR1 Model] 的预训练模型，使用自己的aishell-1格式的数据按照examples/aishell/asr1对该模型进行微调，微调之前修改了conf保证模型结构一致。\r\n\r\n微调后的模型可以正常使用，但是有一点比较好奇，微调后的模型文件大小为492762490，大概469MB，预训练模型的文件大小为517951837，大概493MB。为什么不一样大？",
        "state": "open",
        "user": "gooloosk",
        "closed_by": null,
        "created_at": "2024-04-15T07:16:48+00:00",
        "updated_at": "2025-06-27T02:32:52+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3745,
        "title": "paddlespeech",
        "body": ".py:141: UserWarning: paddleaudio C++ extension is not available. sox_io, sox_effect, kaldi raw feature is not supported!!!\r\n  warnings.warn(\r\n[2024-04-15 17:55:56,623] [    INFO] - Here is the table of ASR pretrained models supported in the service.\r\n[2024-04-15 17:55:56,623] [   ERROR] - Failed to get the table of ASR pretrained models supported in the service.",
        "state": "open",
        "user": "tangzhihu",
        "closed_by": null,
        "created_at": "2024-04-15T09:57:36+00:00",
        "updated_at": "2025-04-26T04:45:38+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "kyn817046",
            "tangzhihu",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3748,
        "title": "[TTS]使用change_speed更改speed 每次都会报错xmalloc: out of memory",
        "body": "**Describe the bug**\r\n使用change_speed更改speed 每次都会报错xmalloc: out of memory\r\n\r\n**To Reproduce**\r\n```python\r\nfrom paddlespeech.server.utils.audio_process import change_speed\r\nimport os\r\nimport soundfile as sf\r\n\r\ntts = TTSExecutor()\r\n\r\n\r\ntts(\r\n    text=\"\"\"你好啊,我叫某某某\"\"\",\r\n    am=\"fastspeech2_male\",\r\n    lang=\"mix\",\r\n    voc=\"pwgan_male\",\r\n    output=\"output.wav\",\r\n)\r\nwav_speed = change_speed(tts._outputs[\"wav\"].numpy(), 1.2, 1)\r\noutput = os.path.abspath(os.path.expanduser(\"output.wav\"))\r\nsf.write(output, wav_speed)\r\n```\r\n\r\n**Expected behavior**\r\n成功转换\r\n\r\n**Screenshots**\r\n<img width=\"1121\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/38812912/04d9f397-3f79-42fc-9d01-1f8c124eb519\">\r\n\r\n**Environment (please complete the following information):**\r\n macOS python 3.9 paddle 2.5.2 paddlespeech 1.4.1 sox 1.5.0\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "xiaohundun",
        "closed_by": null,
        "created_at": "2024-04-17T08:07:29+00:00",
        "updated_at": "2025-02-17T03:36:55+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "ZICXR"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3747,
        "title": "报错",
        "body": "TypeError: Descriptors cannot not be created directly.\r\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\r\n 1. Downgrade the protobuf package to 3.20.x or lower.\r\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\n\r\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
        "state": "open",
        "user": "20246688",
        "closed_by": null,
        "created_at": "2024-04-17T02:55:47+00:00",
        "updated_at": "2024-04-19T10:06:35+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3750,
        "title": "Windows运行报错看这里",
        "body": "首先，我是按照官方的步骤进行安装，结果运行报了错。我在Issue中找了很久，也看了别人的解决方案，发现太混乱了。所以决心让后来者直接一步到位不要重新踩坑。\r\n\r\n经过我一天的折腾，终于找到了相对稳定的版本组合，请看下面：\r\nPython 版本：3.8\r\npaddlepaddle 版本：2.4.1\r\nnumpy 版本：1.23.5\r\npaddlenlp 版本：2.5.2\r\n\r\n你们完全可以新建一个项目，然后依次安装上面版本的库就行了。虽然最后运行语音识别和语音合成会有一些警告，但是完全能正常运行。\r\n",
        "state": "closed",
        "user": "mp075496706",
        "closed_by": "stale[bot]",
        "created_at": "2024-04-19T06:11:33+00:00",
        "updated_at": "2025-06-27T06:33:50+00:00",
        "closed_at": "2025-06-27T06:33:50+00:00",
        "comments_count": [
            "lckj2009",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3749,
        "title": "win10 迁移Miniconda 创建的env 会提示Fatal error in launcher: Unable to create process using ",
        "body": "测试环境:win10\r\n操作:\r\n把电脑A上Miniconda 创建的env通过conda pack的方式迁移到另外一台电脑B上 \r\nB电脑同样是win10 并且安装的Miniconda版本给A电脑版本一致\r\n把A电脑打包好的env环境 复制到B电脑上 解压以后  可以正常激活环境 \r\nconda  env list  也能显示该环境\r\n但是 使用命令paddlespeech asr --lang zh --input D:/PaddleSpeech/zh.wav会提示下方错误\r\n\r\n报错信息:\r\nFatal error in launcher: Unable to create process using '\"D:\\CondaSPACE\\envs\\paddle_speech\\python.exe\"  \"D:\\CondaSpaceSoft\\envs\\Scripts\\paddlespeech.exe\" asr --lang zh --input D:/PaddleSpeech/zh.wav': ???????????\r\n\r\n\r\n其中\"D:\\CondaSPACE\\envs\\paddle_speech\\python.exe\"    是A电脑上安装Miniconda 对应的安装目录\r\n\r\n\"D:\\CondaSpaceSoft\\envs\\Scripts\\paddlespeech.exe\"是B电脑迁移后的Miniconda 对应的安装目录\r\n\r\n\r\n期望:\r\n这个解决思路 应该往哪里考虑 因为翻了很大资料 好像都没有这个问题\r\n期待回复 谢谢!!!\r\n",
        "state": "closed",
        "user": "777sfdf",
        "closed_by": "777sfdf",
        "created_at": "2024-04-19T01:10:47+00:00",
        "updated_at": "2024-08-07T07:06:42+00:00",
        "closed_at": "2024-04-19T05:40:09+00:00",
        "comments_count": [
            "777sfdf",
            "gaohuayang",
            "777sfdf"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3751,
        "title": "为什么安装完后，显示command not found?",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n\r\n运行`python -m pip install paddlepaddle==2.6.0 -i https://mirror.baidu.com/pypi/simple`后，显示安装成功。但当我运行`paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav`时，显示“Command not found: paddlespeech”。文件没有安装到路径上？",
        "state": "closed",
        "user": "zhouhao27",
        "closed_by": "zhouhao27",
        "created_at": "2024-04-21T12:15:55+00:00",
        "updated_at": "2024-04-21T12:42:26+00:00",
        "closed_at": "2024-04-21T12:42:26+00:00",
        "comments_count": [
            "zhouhao27"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3752,
        "title": "[TTS] FileNotFoundError: [Errno 2] No such file or directory: 'dump/test/raw/metadata.jsonl'",
        "body": "\r\n(PaddleSpeech) root@45ee9542141a:/zyyo/code/PaddleSpeech/examples/ljspeech/tts0# ./run.sh \r\nGenerate durations.txt from MFA results ...\r\nExtract features ...\r\n100%|████████████████████████████████████████████████████████████████████████████████| 4434/4434 [00:30<00:00, 145.98it/s]\r\nDone\r\nGet features' stats ...\r\n100%|███████████████████████████████████████████████████████████████████████████████| 4434/4434 [00:01<00:00, 2252.59it/s]\r\nNormalize ...\r\n100%|███████████████████████████████████████████████████████████████████████████████| 4434/4434 [00:02<00:00, 1916.70it/s]\r\nTraceback (most recent call last):\r\n  File \"/zyyo/code/PaddleSpeech/paddlespeech/t2s/exps/tacotron2/normalize.py\", line 124, in <module>\r\n    main()\r\n  File \"/zyyo/code/PaddleSpeech/paddlespeech/t2s/exps/tacotron2/normalize.py\", line 62, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/root/miniconda3/envs/PaddleSpeech/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 643, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/dev/raw/metadata.jsonl'\r\nTraceback (most recent call last):\r\n  File \"/zyyo/code/PaddleSpeech/paddlespeech/t2s/exps/tacotron2/normalize.py\", line 124, in <module>\r\n    main()\r\n  File \"/zyyo/code/PaddleSpeech/paddlespeech/t2s/exps/tacotron2/normalize.py\", line 62, in main\r\n    with jsonlines.open(args.metadata, 'r') as reader:\r\n  File \"/root/miniconda3/envs/PaddleSpeech/lib/python3.8/site-packages/jsonlines/jsonlines.py\", line 643, in open\r\n    fp = builtins.open(file, mode=mode + \"t\", encoding=encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'dump/test/raw/metadata.jsonl'",
        "state": "open",
        "user": "Zzmes",
        "closed_by": null,
        "created_at": "2024-04-24T07:28:52+00:00",
        "updated_at": "2024-05-18T10:41:40+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "wytyl13"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3753,
        "title": "paddlespeech asr --lang zh --input zh.wav 报错: InvalidArgument",
        "body": " - OS: [Ubuntu 22.4]\r\n - GCC 11.4.0\r\n - Python Version 3.10\r\n - PaddlePaddle 2.61\r\n - GPU  Tesla P40\r\n - CUDA/CUDNN 12.0\r\n\r\n 选源码下载编译安装\r\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git\r\ncd PaddleSpeech\r\npip install pytest-runner\r\npip install .\r\n\r\n运行  paddlespeech asr --lang zh --input zh.wav 会报如下的错误:\r\n\r\nW0425 10:54:48.787741 584456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 12.0\r\nW0425 10:54:48.788694 584456 gpu_resources.cc:164] device: 0, cuDNN Version: 9.1.\r\n[2024-04-25 10:54:50,736] [   ERROR] - (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:73)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/usr/local/lib/python3.10/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/base/dygraph/base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 543, in attention_rescoring\r\n    hyps, encoder_out = self._ctc_prefix_beam_search(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 424, in _ctc_prefix_beam_search\r\n    encoder_out, encoder_mask = self._forward_encoder(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/models/u2/u2.py\", line 229, in _forward_encoder\r\n    encoder_out, encoder_mask = self.encoder(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/modules/encoder.py\", line 184, in forward\r\n    chunk_masks = add_optional_chunk_mask(\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddlespeech/s2t/modules/mask.py\", line 202, in add_optional_chunk_mask\r\n    chunk_masks = masks.logical_and(chunk_masks)  # (B, L, L)\r\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/tensor/logic.py\", line 143, in logical_and\r\n    return _C_ops.logical_and(x, y)\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1, 1, 0, 498] and the shape of Y = [1, 123, 123]. Received [498] in X is not equal to [123] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:73)\r\n\r\n\r\n",
        "state": "closed",
        "user": "mjx1999",
        "closed_by": "mjx1999",
        "created_at": "2024-04-25T02:56:09+00:00",
        "updated_at": "2024-04-26T04:43:11+00:00",
        "closed_at": "2024-04-26T04:43:10+00:00",
        "comments_count": [
            "mjx1999"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3758
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3754,
        "title": "使用时，报错: IndexError: list index out of range",
        "body": "环境\r\npython 3.9\r\npaddlepaddle 2.6.1\r\npaddlespeech 1.4.1\r\n\r\n安装期间，已经解决了\r\n1、setuptools_scm 报错问题\r\n2、numpy 版本过高问题 : module 'numpy' has no attribute 'complex'  \r\n\r\n使用时，报了下面错误: \r\npaddlespeech   asr --lang zh --input zh.wav\r\n[2024-04-25 13:39:18,021] [   ERROR] - list index out of range\r\nTraceback (most recent call last):\r\n  File \"/root/tools/venv/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\r\n    result_transcripts = self.model.decode(\r\n  File \"/root/tools/venv/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/root/tools/venv/lib/python3.9/site-packages/paddle/base/dygraph/base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"/root/tools/venv/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\r\n    hyp = self.attention_rescoring(\r\n  File \"/root/tools/venv/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\r\n    assert speech.shape[0] == speech_lengths.shape[0]\r\nIndexError: list index out of range\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "hgguyu",
        "closed_by": null,
        "created_at": "2024-04-25T05:42:58+00:00",
        "updated_at": "2025-04-26T04:45:20+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "yaowt05",
            "yousun4688",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3756,
        "title": "请问怎么修改conformer_talcs_application.yaml文件让它支持websocket",
        "body": "请问asr混合模型能修改conformer_talcs_application.yaml文件支持websocket不？",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-04-29T09:07:59+00:00",
        "updated_at": "2025-04-26T04:45:36+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3755,
        "title": "混合模型报错Please check config, am support: fastspeech2, voc support: hifigan_csmsc-zh or mb_melgan_csmsc.",
        "body": "我下载模型[fastspeech2_mix_onnx_0.2.0.zip](https://paddlespeech.bj.bcebos.com/t2s/chinse_english_mixed/models/fastspeech2_mix_onnx_0.2.0.zip)，\r\n然后将tts_online_ws_application.yaml中模型名称改为fastspeech2_mix，voc改为hifigan_csmsc。报错如下：\r\n[2024-04-29 08:39:32,162] [   ERROR] - Failed to start server.\r\n[2024-04-29 08:39:32,162] [   ERROR] - Please check config, am support: fastspeech2, voc support: hifigan_csmsc-zh or mb_melgan_csmsc.\r\n\r\n使用命令行正常：paddlespeech tts --am fastspeech2_mix --voc hifigan_csmsc --lang mix --input \"我们的声学模型使用了 Fast Speech Two, 声码器使用了 Parallel Wave GAN and Hifi GAN.\" --spk_id 175 --output mix_spk175.wav\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-04-29T08:40:30+00:00",
        "updated_at": "2025-04-26T04:45:37+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3757,
        "title": "ASR和TTS的streaming server无法同时开启",
        "body": "环境：\r\nPaddlePaddle 2.2.0\r\nPython 3.8(ubuntu18.04)\r\nCuda 11.2\r\n\r\nASR和TTS在开启第一个后，再打开另一个后报错，该怎么处理？\r\nroot@autodl-container-085311853c-b00a9bac:~/PaddleSpeech# paddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml\r\nWARNING: OMP_NUM_THREADS set to 12, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\r\nPLEASE USE OMP_NUM_THREADS WISELY.\r\n[2024-04-30 10:35:16,341] [    INFO] - start to init the engine\r\n[2024-04-30 10:35:16,341] [    INFO] - asr : online engine.\r\nW0430 10:35:21.184901  1193 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.2\r\nW0430 10:35:21.188336  1193 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\n[2024-04-30 10:35:23,950] [   ERROR] - Failed to start server.\r\n[2024-04-30 10:35:23,951] [   ERROR] - __init__() got an unexpected keyword argument 'negative_slope'\r\n2024-04-30 10:35:23.950 | INFO     | paddlespeech.s2t.modules.embedding:__init__:153 - max len: 5000",
        "state": "open",
        "user": "488283943",
        "closed_by": null,
        "created_at": "2024-04-30T05:59:24+00:00",
        "updated_at": "2025-04-26T04:45:34+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "buffge",
            "488283943",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3762
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3759,
        "title": "asr http服务报错",
        "body": "## General Question\r\ntts服务是成功的，asr报错 509\r\n<img width=\"794\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleSpeech/assets/5810939/2fe074af-d8d8-4129-993c-16376c60aae2\">\r\n\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "sunway86",
        "closed_by": null,
        "created_at": "2024-05-07T09:32:26+00:00",
        "updated_at": "2025-04-26T04:45:29+00:00",
        "closed_at": null,
        "comments_count": [
            "jianghuakun",
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3760,
        "title": "完全按照流程进行训练，并且使用了官方数据集，loss值2.x，请问哪里出现问题了     https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3",
        "body": "https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/other/tts_finetune/tts3",
        "state": "open",
        "user": "1477823267",
        "closed_by": null,
        "created_at": "2024-05-08T07:41:54+00:00",
        "updated_at": "2025-04-26T04:45:31+00:00",
        "closed_at": null,
        "comments_count": [
            "1477823267",
            "1477823267",
            "1477823267",
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3761,
        "title": "字母A老是读成 a ，就是a pen 那个 a",
        "body": "我使用的模型是fastspeech2_mix_ckpt_1.2.0，现在我想读AI这两个字母，可它老读成儿爱\r\n",
        "state": "open",
        "user": "WanwanLinLin",
        "closed_by": null,
        "created_at": "2024-05-08T13:20:01+00:00",
        "updated_at": "2025-04-26T04:45:32+00:00",
        "closed_at": null,
        "comments_count": [
            "jianghuakun",
            "jianghuakun",
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3763,
        "title": "自定义语料训练报错",
        "body": "调用./run.sh报错如下\r\nget mfa result\r\nalign.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\nTraceback (most recent call last):\r\n  File \"aligner/command_line/align.py\", line 186, in <module>\r\n  File \"aligner/command_line/align.py\", line 142, in validate_args\r\n  File \"aligner/command_line/align.py\", line 69, in align_corpus\r\nTypeError: 'NoneType' object is not subscriptable\r\n[10918] Failed to execute script align",
        "state": "open",
        "user": "wytyl13",
        "closed_by": null,
        "created_at": "2024-05-11T01:39:11+00:00",
        "updated_at": "2024-05-18T10:37:42+00:00",
        "closed_at": null,
        "comments_count": [
            "jianghuakun",
            "Ray961123",
            "wytyl13",
            "wytyl13"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3764,
        "title": "whisper_executor    TypeError: too many positional arguments",
        "body": "反复试了很多版本speech、panddle-gpu cpu 的版本 都会出现以下问题，还请高手指点\r\n\r\n————————————————————和paddle相关的包的版本——————————————————\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.0.6\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.6.0\r\npaddleocr                   2.7.3\r\npaddlepaddle-gpu            2.6.1.post120\r\npaddlesde                   0.2.5\r\npaddleslim                  2.3.4\r\npaddlespeech                1.4.0\r\npaddlespeech-feat           0.1.0\r\n\r\n\r\n————————————————————————代码————————————————————————\r\nimport paddle\r\nfrom paddlespeech.cli.whisper import WhisperExecutor\r\n\r\nwhisper_executor = WhisperExecutor()\r\ntext = whisper_executor(\r\n    model='whisper',\r\n    task='transcribe',\r\n    sample_rate=16000,\r\n    config=None,  # Set `config` and `ckpt_path` to None to use pretrained model.\r\n    ckpt_path=None,\r\n    audio_file='./zh.wav',\r\n    device=paddle.get_device())\r\nprint('ASR Result: \\n{}'.format(text))\r\n\r\n\r\n————————————————————————运行情况（正常部分）————————————————————————\r\nC:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nW0515 16:36:08.184197  7104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.3, Runtime API Version: 12.0\r\nW0515 16:36:08.191708  7104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\r\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\r\n[2024-05-15 16:36:12,921] [    INFO] - Assigning ['<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|iw|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nospeech|>', '<|notimestamps|>'] to the additional_special_tokens key of the tokenizer\r\n[2024-05-15 16:36:12,921] [    INFO] - Adding <|startoftranscript|> to the vocabulary\r\n[2024-05-15 16:36:12,931] [    INFO] - Adding <|en|> to the vocabulary\r\n[2024-05-15 16:36:12,931] [    INFO] - Adding <|zh|> to the vocabulary\r\n[2024-05-15 16:36:12,931] [    INFO] - Adding <|de|> to the vocabulary\r\n[2024-05-15 16:36:12,931] [    INFO] - Adding <|es|> to the vocabulary\r\n[2024-05-15 16:36:12,931] [    INFO] - Adding <|ru|> to the vocabulary\r\n....\r\n....\r\n—————————————————————运行情况（开始出问题了）—————————————————————\r\nTraceback (most recent call last):\r\n  File \"c:/Users/willi/Desktop/speechtest/4.py\", line 7, in <module>\r\n    text = whisper_executor(\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\utils.py\", line 328, in _warpper\r\n    return executor_func(self, *args, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\whisper\\infer.py\", line 477, in __call__\r\n    self.infer(model)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddle\\base\\dygraph\\base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\cli\\whisper\\infer.py\", line 279, in infer\r\n    self._outputs[\"result\"] = self.model.transcribe(\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 488, in transcribe\r\n    _, probs = model.detect_language(segment, resource_path)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddle\\base\\dygraph\\base.py\", line 352, in _decorate_function\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 392, in detect_language\r\n    mel = model.encoder(mel)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 207, in forward\r\n    x = block(x)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 148, in forward\r\n    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 100, in forward\r\n    wv = self.qkv_attention(q, k, v, mask)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\paddlespeech\\s2t\\models\\whisper\\whipser.py\", line 111, in qkv_attention\r\n    q.view(*q.shape[:2], self.n_head, -1), (0, 2, 1, 3)) * scale\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\decorator.py\", line 231, in fun\r\n    args, kw = fix(args, kw, sig)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\site-packages\\decorator.py\", line 203, in fix\r\n    ba = sig.bind(*args, **kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\inspect.py\", line 3037, in bind\r\n    return self._bind(args, kwargs)\r\n  File \"C:\\Users\\willi\\miniconda3\\envs\\py38\\lib\\inspect.py\", line 2958, in _bind\r\n    raise TypeError('too many positional arguments') from None\r\nTypeError: too many positional arguments\r\n\r\n",
        "state": "open",
        "user": "yanming499",
        "closed_by": null,
        "created_at": "2024-05-15T08:39:50+00:00",
        "updated_at": "2024-05-17T11:12:42+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3767,
        "title": "训练PaddleSpeech/examples/iwslt2012 /punc0，gpu不能得到利用",
        "body": "给定了gpu的参数，但是gpu没得到利用，并且batch_size为128，12小时训练了iter 800/6420，这是常规的速度吗？",
        "state": "closed",
        "user": "abcdbosh",
        "closed_by": "abcdbosh",
        "created_at": "2024-05-19T07:00:06+00:00",
        "updated_at": "2024-05-27T10:11:30+00:00",
        "closed_at": "2024-05-27T10:11:30+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3766,
        "title": "Python3.12 support",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nI tried to use `paddlespeech` on my python 3.12, and it depend on `paddlepaddle` which support python 3.12. But the `paddlespeech` seems only support 3.9, it's too old. Could you update this package to work with `paddlepaddle` on python 3.12.\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/969f33999fd6116a69831d098c1ab6f1e125129a/setup.py#L317-L321\r\n\r\nSee also https://pypi.org/project/paddlespeech/, https://pypi.org/project/paddlepaddle/.\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n1. Support python 3.12 like `paddlepaddle` does.\r\n2. Install `paddlepaddle` automaticly when installing `paddlespeech` as an explict dependence.\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n",
        "state": "open",
        "user": "liudonghua123",
        "closed_by": null,
        "created_at": "2024-05-17T06:35:46+00:00",
        "updated_at": "2024-11-15T05:30:59+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "tofutim"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3765,
        "title": "关于安卓模型的大小",
        "body": "我用普通话的TTS，但觉得模型太大了，请问有小一点的模型可用吗？",
        "state": "open",
        "user": "watersoft123",
        "closed_by": null,
        "created_at": "2024-05-16T05:13:28+00:00",
        "updated_at": "2025-04-26T04:45:29+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3770,
        "title": "[TTS]内存溢出",
        "body": "**Describe the bug**\r\n我下载了vocmodel，HiFiGAN with AISHELL-3 onnx模型，在c++中的onnx.Run，会出现内存爆炸的情况。\r\n输入的维度都是和input tensor保持一致的。\r\nSegmentation fault (core dumped)\r\n",
        "state": "closed",
        "user": "linlongrd",
        "closed_by": "linlongrd",
        "created_at": "2024-05-22T03:00:01+00:00",
        "updated_at": "2024-05-22T03:10:53+00:00",
        "closed_at": "2024-05-22T03:10:53+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3769,
        "title": "使用vits_csmsc_ckpt_1.4.0预训练模型时报错ValueError: (InvalidArgument) expand(): argument (position 2) must be list of int, but got Tensor at pos 0 ",
        "body": "**环境:**\r\n - OS: Windows 11\r\n - GCC 10.3.0\r\n - Python Version 3.8.19\r\n - PaddlePaddle Version 2.6.1\r\n - GPU/DRIVER Information NVIDIA GeForce RTX3060 Laptop\r\n - CUDA/CUDNN Version 12.0\r\n\r\n遵循 /examples/csmsc/vits/README.md 的介绍，使用以下命令：\r\n\r\n`python ~/paddlespeech/t2s/exps/vits/synthesize_e2e.py --config=vits_csmsc_ckpt_1.4.0/default.yaml --ckpt=vits_csmsc_ckpt_1.4.0/snapshot_iter_150000.pdz --phones_dict=vits_csmsc_ckpt_1.4.0/phone_id_map.txt --output_dir=exp/default/test_e2e --text=~/paddlespeech/t2s/assets/sentences.txt --add-blank=true`\r\n\r\n出现以下报错：\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/45178/OneDrive/TTS_Project/PaddleSpeech/paddlespeech/t2s/exps/vits/synthesize_e2e.py\", line 198, in <module>\r\n    main()\r\n  File \"C:/Users/45178/OneDrive/TTS_Project/PaddleSpeech/paddlespeech/t2s/exps/vits/synthesize_e2e.py\", line 194, in main\r\n    evaluate(args)\r\n  File \"C:/Users/45178/OneDrive/TTS_Project/PaddleSpeech/paddlespeech/t2s/exps/vits/synthesize_e2e.py\", line 111, in evaluate\r\n    wav = vits_inference(part_phone_ids)\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\models\\vits\\vits.py\", line 542, in forward\r\n    out = self.acoustic_model.inference(\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\models\\vits\\vits.py\", line 444, in inference\r\n    wav, att_w, dur = self.generator.inference(\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\models\\vits\\generator.py\", line 482, in inference\r\n    x, m_p, logs_p, x_mask = self.text_encoder(text, text_lengths)\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddle\\nn\\layer\\layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\models\\vits\\text_encoder.py\", line 157, in forward\r\n    x_mask = make_non_pad_mask(x_lengths).unsqueeze(1)\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\modules\\nets_utils.py\", line 296, in make_non_pad_mask\r\n    return paddle.logical_not(make_pad_mask(lengths, xs, length_dim))\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddlespeech\\t2s\\modules\\nets_utils.py\", line 192, in make_pad_mask\r\n    seq_range_expand = seq_range.unsqueeze(0).expand([bs, maxlen])\r\n  File \"C:\\Users\\45178\\OneDrive\\TTS_Project\\PaddleSpeech\\tools\\venv\\lib\\site-packages\\paddle\\tensor\\manipulation.py\", line 3741, in expand\r\n    return _C_ops.expand(x, shape)\r\nValueError: (InvalidArgument) expand(): argument (position 2) must be list of int, but got Tensor at pos 0 (at ..\\paddle\\fluid\\pybind\\op_function_common.cc:470)\r\n```\r\n",
        "state": "closed",
        "user": "KevinFOS",
        "closed_by": "KevinFOS",
        "created_at": "2024-05-21T15:28:37+00:00",
        "updated_at": "2024-05-22T23:45:21+00:00",
        "closed_at": "2024-05-22T23:45:21+00:00",
        "comments_count": [
            "KevinFOS"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3768,
        "title": "[TTS]微调报错现存不足",
        "body": "![Snipaste_2024-05-20_10-47-37](https://github.com/PaddlePaddle/PaddleSpeech/assets/109673094/137ba39a-5105-4001-8635-16a726e0a6be)\r\n\r\n![Snipaste_2024-05-20_10-49-16](https://github.com/PaddlePaddle/PaddleSpeech/assets/109673094/6c6a1e20-c1b3-42b5-80e9-1caf7858a2e8)\r\n\r\n![Snipaste_2024-05-20_10-50-24](https://github.com/PaddlePaddle/PaddleSpeech/assets/109673094/4b661e76-dc29-47eb-afa3-1612190f654e)\r\n\r\n\r\n微调训练语料1000条  batch_size是16 epoch是30\r\n请问下1000条语料内存占用大概多大呢，是基于fastspeech2_mix权重的微调\r\n",
        "state": "open",
        "user": "wytyl13",
        "closed_by": null,
        "created_at": "2024-05-20T02:51:36+00:00",
        "updated_at": "2024-06-05T03:42:12+00:00",
        "closed_at": null,
        "comments_count": [
            "wytyl13",
            "Ray961123",
            "jianghuakun"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3771,
        "title": "【问题解决】解决PaddleSpeech历史问题和BUG",
        "body": "### 背景\npaddlespeech目前存在一些历史问题以及长期issue，对这些问题和issue进行修复。\n\n### 现状\n\n1. 对2023.4.10~2024.4.10的issue进行统计和分类，对其中**未解决的BUG**进行处理。\n2. 基于paddlepaddle-gpu\\=\\=2.6.1 paddlespeech\\=\\=develop对demos进行验证，对发现的问题进行修复。\n\n### issue列表\n\n| 序号 | issue                                                    | 说明                                               | 认领人/状态/PR号 |\n| ---- | -------------------------------------------------------- |  -------- | ---------------- |\n| 1 | #3777 | demos/audio_content_search的readme问题 | @kk-2000 <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#3778](https://github.com/PaddlePaddle/PaddleSpeech/pull/3778)<br> | \n| 2 | #3376 | 文档落后于代码 | @kk-2000 <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 3 | #3697 | asr命令未显式指定model报错KeyError | @kk-2000 <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br>@zxcd <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#3794](https://github.com/PaddlePaddle/PaddleSpeech/pull/3794)<br> | \n| 4 | #3620 | ~~函数FrontEngineInterface存在bug~~ |  | \n| 5 | #3444 | paddlespeech.s2t.transform.transformation引入报错 | @kk-2000 <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#3779](https://github.com/PaddlePaddle/PaddleSpeech/pull/3779)<br> | \n| 6 | #3536 | ~~paddleaudio构建wheel报错~~ | @kk-2000 <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 7 | #3157 | utils/make_filted_shard_list.py 脚本不存在（hold） |  | \n| 8 | #3652 | merge_yi函数存在bug | @mattheliu <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#3786](https://github.com/PaddlePaddle/PaddleSpeech/pull/3786)<br> | \n| 9 | #3544 | gpu版本出错但是cpu版本可运行 | @mattheliu <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br>@zxcd <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#3795](https://github.com/PaddlePaddle/PaddleSpeech/pull/3795)<br> | \n| 10 | #3530 | tts语音合成接口返回base64数据有误 | @mattheliu <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 11 | #3339 | 连续点号导致Bug | @kk-2000 <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 12 | #3158 | docker镜像bug（hold） |  | \n\n#### 1. 认领方式\n请大家以 comment 的形式认领任务，如：\n\n```\n【报名】：1、3、12-13\n```\n多个任务之间需要使用中文顿号分隔，报名多个连续任务可用横线表示，如 2-5\n\n#### 2. PR提交\n- PR名称需要加前缀 **【Fix Speech Issue No.XXX】**\n- PR描述中需要附上本issue\n- 评论里或者 review request @zxcd  研发会进行审核\n\n### 看板信息\n| 任务方向 | 任务数量 | 提交作品 / 任务认领 | 提交率 | 完成 | 完成率 |\n| :----: | :----: | :----:  | :----: | :----: | :----: |\n|  【问题解决】解决PaddleSpeech历史问题和BUG  |  12  | 5 / 9 | 41.67% |  4  | 33.33% |\n#####\n\n## 统计信息 \n> 排名不分先后 @zxcd (2) @kk-2000 (1) @mattheliu (1) \n#####\n",
        "state": "closed",
        "user": "kk-2000",
        "closed_by": "luotao1",
        "created_at": "2024-05-23T01:19:00+00:00",
        "updated_at": "2024-07-16T07:30:47+00:00",
        "closed_at": "2024-07-16T07:30:47+00:00",
        "comments_count": [
            "kk-2000",
            "mattheliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3777,
        "title": "[S2T]audio_content_search的readme存在问题",
        "body": "**Describe the bug**\r\ndemos/audio_content_search的readme存在问题\r\n1. 缺少server启动的步骤描述\r\n2. client启动的命令行端口错误\r\n\r\n",
        "state": "open",
        "user": "kk-2000",
        "closed_by": null,
        "created_at": "2024-05-26T14:04:19+00:00",
        "updated_at": "2024-05-29T08:01:39+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3775,
        "title": "【asr】处理使用 PaddleSpeech 英文语音识别中出现的报错 ValueError (InvalidArgument) Broadcast dimension mismatch",
        "body": "官网示例中都是中文语音识别\r\n```\r\n>>> from paddlespeech.cli.asr.infer import ASRExecutor\r\n>>> asr = ASRExecutor()\r\n>>> result = asr(audio_file=\"zh.wav\")\r\n>>> print(result)\r\n我认为跑步最重要的就是给我带来了身体健康\r\n```\r\n当然用这份代码跑中文也会报错，需要result = asr(audio_file=\"zh.wav\")加上指定的model模型\r\n这里感谢提出bug和修复的#3697\r\n但是在应用到英文语音识别是会发现找不到模型，将infer.py文件中所有的“zh”替换成“en”也没用，在生成tag时还是会变成zh后缀\r\n因此需要将/PaddleSpeech/paddlespeech/cli/asr/infer.py文件159行\r\n```\r\n# tag = model_type + '-' + lang + '-' + sample_rate_str\r\n tag = model_type + '-' + 'en' + '-' + sample_rate_str\r\n```\r\n\r\n同时\r\n`result = asr(audio_file=audio_file, model='transformer_librispeech')`\r\n改为英文模型\r\n",
        "state": "open",
        "user": "chenzf11",
        "closed_by": null,
        "created_at": "2024-05-24T09:44:25+00:00",
        "updated_at": "2024-06-06T02:01:45+00:00",
        "closed_at": null,
        "comments_count": [
            "chenzf11",
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3776,
        "title": "unexpected result when loading baidu_en8k",
        "body": "my code is as follows:\r\n```python\r\nimport paddle\r\nfrom paddlespeech.s2t.models.ds2 import DeepSpeech2Model\r\n\r\nconfig = './conf/deepspeech2.yaml'\r\nmodel = DeepSpeech2Model.from_config(config)\r\nmodel_param_path = './baidu_en8k/params.pdparams'\r\nmodel_dict = paddle.load(model_param_path)\r\nprint(model_dict)\r\nmodel.set_state_dict(model_dict)\r\n```\r\n\r\nThe error when running is as follows:\r\nTensor(shape=[32], dtype=float32, place=Place(gpu:0), stop_gradient=True,\r\n       [-0.13427278, -0.55235499, -1.24842834,  0.20777903,  0.27952033,\r\n         0.16212732, -0.99394548, -0.01013480, -0.40001720,  0.04474913,\r\n         0.24409334, -0.24370413,  0.12284821, -0.28940210,  0.27778339,\r\n         0.44302204,  0.49736398, -0.96350390, -1.41964650,  0.61999571,\r\n         0.22443774, -1.09316063,  0.38835990,  0.44136432,  0.09003256,\r\n        -0.32678720, -0.18228465, -0.29467481, -1.33099961, -0.45747182,\r\n         0.34930611,  0.15642692])\r\n File \"test.py\", line 9, in <module>\r\n    model.set_state_dict(model_dict)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 486, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 1480, in set_state_dict\r\n    match_res = _check_match(key_name, param)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 1455, in _check_match\r\n    state = state_dict.get(key, None)\r\nAttributeError: 'Tensor' object has no attribute 'get'\r\n\r\nwhen i run the same code to load a model trained by myself according to the tutorial, it load the model parameters successfully, and the model_dict is a very big dict. What could be causing this?\r\n\r\nThe code is run in the official docker container (paddlecloud/paddlespeech:develop-gpu-cuda11.2-cudnn8-latest)\r\npaddlepaddle-gpu            2.3.0.post112\r\npaddleslim                  2.4.1\r\npaddlespeech                0.0.0\r\npaddlespeech-ctcdecoders    0.2.1\r\n",
        "state": "open",
        "user": "firdota",
        "closed_by": null,
        "created_at": "2024-05-25T07:52:50+00:00",
        "updated_at": "2025-04-26T04:45:28+00:00",
        "closed_at": null,
        "comments_count": [
            "firdota",
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3782,
        "title": "有没有声音识别的例子",
        "body": "## General Question\r\n\r\n想咨询下 PaddleSpeech 是否能预测声音的说话者的性别、年龄呢？",
        "state": "open",
        "user": "wanglunhui2012",
        "closed_by": null,
        "created_at": "2024-05-29T09:21:44+00:00",
        "updated_at": "2025-04-26T04:45:23+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3783,
        "title": "【问题解决】待提测和待修复的命令和目录",
        "body": "### 背景\n对paddlespeech的demos和example进行验证，对验证通过的命令进行提测，对验证未通过的命令进行修复，详细信息见 [适配验证表](https://doc.weixin.qq.com/sheet/e3_AakAbwboADEmvF8fzDaSqulw0fXi8?scode=AHAA0Qc9AFo1Z909DDAakAbwboADE&tab=wd6qi3)。\n\n### 验证环境\n- cuda11.7\n- paddlepaddle-gpu==2.6.1\n- paddlespeech==develop\n\n### 已验证可提测\n| 序号 | 命令                                                         | 目录                             | 结果 | 认领人/状态/PR号 |\n| ---- | ------------------------------------------------------------ | -------------------------------- | ---- | ---- |\n| 1 | paddlespeech cls --input ./cat.wav --topk 10 | demos/audio_tagging | ![Snipaste_2024-05-14_22-00-10](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/dc8cbaaa-dd94-427f-8e1b-4460228cf9d1) |  | \n| 2 | - | demos/automatic_video_subtitiles | ![Snipaste_2024-05-14_21-32-54](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/41d0162a-7e7f-400b-b9dc-e6d8a138df40) |  | \n| 3 | - | demos/custom_streaming_asr | ![client](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/bd425718-996a-40f5-8d59-7dac2bd74f7e) |  | \n| 4 | paddlespeech kws --input ./hey_snips.wav paddlespeech kws --input ./non-keyword.wav | demos/keyword_spotting | ![Snipaste_2024-05-03_20-39-38](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/a735a044-2a72-482c-9ad9-f06a24763652) |  | \n| 5 | paddlespeech text --input 今天的天气真不错啊你下午有空吗我想约你一起去吃饭 | demos/punctuation_restoration | ![Snipaste_2024-05-03_20-44-20](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/59303319-e64d-4d14-8c68-0da679617bcd) |  | \n| 6 | paddlespeech vector --task spk --input 85236145389.wav | demos/speaker_verification | ![声纹识别](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/b4dd1287-5624-4f2c-aeb1-9f6836a7618f) |  | \n| 7 | - | demos/speech_web | ![Snipaste_2024-06-03_09-22-44](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/8a0f7d61-0fad-4a5e-b932-2d7b85cd40c5) |  | \n| 8 | paddlespeech ssl --task asr --lang en --input ./en.wav | demos/speech_ssl | ![Snipaste_2024-05-03_20-54-43](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/f8a57047-02a8-48dc-9eb8-7877501a90e4) |  | \n| 9 | - | demos/speech_translation | ![docker](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/d662bc02-3a38-41f8-892d-833cdbcb4ab6) |  | \n| 10 | - | demos/streaming_asr_server | ![asr_result](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/25fc3a75-d4c9-4f70-bcf4-3eac49749afe) |  | \n| 11 | - | demos/audio_searching | ![Snipaste_2024-06-04_00-45-19](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/aa49bcb3-ded9-4876-b527-bce6c3a92428) |  | \n\n### 待修复\n\n| 序号|命令                                                         | 目录                                   | 报错     | 认领人/状态/PR号 |\n| ---- |------------------------------------------------------------ | -------------------------------------- | ---- | ---- |\n| 12 | - | demos/audio_content_search | #3777 | @kk-2000 <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" />  [#3778](https://github.com/PaddlePaddle/PaddleSpeech/pull/3778)<br> | \n| 13 | - | demos/metaverse | 报错glibc |  | \n| 14 | paddlespeech asr --input ./zh.wav -v | demos/speech_recognition | #3697 |  | \n| 15 | - | demos/speech_server | 报错glibc |  | \n| 16 | - | demos/whisper | ![Snipaste_2024-05-14_21-50-57](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/0acb8db4-1a15-40f3-b969-030ab946190f) |  | \n| 17 | - | demos/text_to_speech | 报错glibc |  | \n| 18 | - | demos/streaming_tts_server | 报错glibc |  | \n| 19 | - | demos/streaming_tts_serving_fastdeploy | ![微信图片_20240604214429](https://github.com/PaddlePaddle/PaddleSpeech/assets/52824616/b0e96a90-db7b-4ff5-826e-44a5463f9671) |  | \n| 20 | - | demos/style_fs2 | 报错glibc |  | \n#### 1. 认领方式\n请大家以 comment 的形式认领任务，如：\n\n```\n【报名】：1、3、12-13\n```\n多个任务之间需要使用中文顿号分隔，报名多个连续任务可用横线表示，如 2-5\n\n#### 2. PR提交\n- PR名称需要加前缀 **【Speech Demo 2.6.1 No.XXX】**\n- PR描述中需要附上本issue，提测文档请放到：https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/tests/unit/cli\n- 评论里或者 review request @zxcd  研发会进行审核\n## 看板信息 \n| 任务方向 | 任务数量 | 提交作品 / 任务认领 | 提交率 | 完成 | 完成率 |\n| :----: | :----: | :----:  | :----: | :----: | :----: |\n|  已验证可提测  |  20  | 1 / 1 | 5.0% |  0  | 0.0% |\n#####\n\n## 统计信息 \n> 排名不分先后 \n#####\n",
        "state": "closed",
        "user": "kk-2000",
        "closed_by": "luotao1",
        "created_at": "2024-05-31T01:07:07+00:00",
        "updated_at": "2024-07-16T07:31:54+00:00",
        "closed_at": "2024-07-16T07:31:53+00:00",
        "comments_count": [
            "jianghuakun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3785,
        "title": "[TTS]libc.so.6: version `GLIBC_2.32' not found ",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nIt gives out error: libc.so.6: version `GLIBC_2.32' not found\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n```bash\r\n>>> from paddlespeech.cli.tts.infer import TTSExecutor\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/t2s/exps/syn_utils.py\", line 35, in <module>\r\n    from paddlespeech.t2s.frontend.mix_frontend import MixFrontend\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/t2s/frontend/mix_frontend.py\", line 22, in <module>\r\n    from paddlespeech.t2s.frontend.zh_frontend import Frontend\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 31, in <module>\r\n    from paddlespeech.t2s.frontend.g2pw import G2PWOnnxConverter\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/t2s/frontend/g2pw/__init__.py\", line 1, in <module>\r\n    from .onnx_api import G2PWOnnxConverter\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/paddlespeech/t2s/frontend/g2pw/onnx_api.py\", line 27, in <module>\r\n    from opencc import OpenCC\r\n  File \"/root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/opencc/__init__.py\", line 6, in <module>\r\n    from opencc.clib import opencc_clib\r\nImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /root/miniconda3/envs/tts_py39/lib/python3.9/site-packages/opencc/clib/opencc_clib.cpython-39-x86_64-linux-gnu.so)\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]: ubuntu 20.04.6\r\n - GCC/G++ Version [e.g. 8.3] 9.4.0\r\n - Python Version [e.g. 3.7] 3.9\r\n - PaddlePaddle Version [e.g. 2.0.0] 2.5.1\r\n - Model Version [e.g. 2.0.0] 不确定\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00] A40 / Driver Version: 530.30.02    \r\n - CUDA/CUDNN Version [e.g. cuda-10.2] CUDA Version: 12.1\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "charliedream1",
        "closed_by": null,
        "created_at": "2024-06-03T11:40:31+00:00",
        "updated_at": "2024-06-06T02:06:23+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3788,
        "title": "[S2T]XXXX",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n运行示例代码exit code\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n# 调用语音识别\r\nfrom paddlespeech.cli.asr.infer import ASRExecutor\r\nasr = ASRExecutor()\r\nresult = asr(audio_file=\"ie.wav\", force_yes=True) # 支持16k，其它采样率强制转换\r\nprint(result)\r\n报错\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::pybind::ThrowExceptionToPython(std::__exception_ptr::exception_ptr)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1717486951 (unix time) try \"date -d @1717486951\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e80000203d) received by PID 8253 (TID 0x707b0c9a9440) from PID 8253 ***]\r\n\r\n\r\nProcess finished with exit code 134 (interrupted by signal 6:SIGABRT)\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [11.4.0]\r\n - Python Version [3.9]\r\n - PaddlePaddle Version [2.4.2-gpu]\r\n - Model Version [1.4.1]\r\n - GPU/DRIVER Informationo [NVIDIA GeForce RTX 3060 ]\r\n - CUDA/CUDNN Version [cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "open",
        "user": "Olg1erdzz",
        "closed_by": null,
        "created_at": "2024-06-04T07:48:35+00:00",
        "updated_at": "2024-06-06T02:11:08+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3787,
        "title": "【问题解决】Paddlespeech develop版本待提测和待修复的命令和目录",
        "body": "## 背景\n对paddlespeech的demos和example进行验证，对验证通过的命令进行提测，对验证未通过的命令进行修复，详细信息见[适配验证表](https://doc.weixin.qq.com/sheet/e3_AakAbwboADEmvF8fzDaSqulw0fXi8?scode=AHAA0Qc9AFo1Z909DDAakAbwboADE&tab=wd6qi3)\n\n### 验证环境\n- cuda11.7\n- paddlepaddle-gpu==develop\n- paddlespeech==develop\n\n### 已验证可提测\n| 序号  | 命令                                                                                  | 目录                               | 结果  | 认领人/状态/PR号 |\n| --- | ----------------------------------------------------------------------------------- | -------------------------------- | --- | ---------- |\n| 1 | paddlespeech cls --input ./cat.wav --topk 10 | demos/audio_tagging | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/1349640b-dbe2-475c-a38c-321978e4288d) |   | \n| 2 | - | demos/automatic_video_subtitiles | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/e83598f3-d4b9-49ac-882c-5ef561b85ac1) |   | \n| 3 | - | demos/custom_streaming_asr |    ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/cb71b49e-ad06-4ffc-be53-fd275b40a4e6) |   | \n| 4 | paddlespeech kws --input ./hey_snips.wav paddlespeech kws --input ./non-keyword.wav | demos/keyword_spotting | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/04a3e430-2c25-41ca-b584-9ae1fa32a4c4)  |   | \n| 5 | paddlespeech text --input 今天的天气真不错啊你下午有空吗我想约你一起去吃饭 | demos/punctuation_restoration |  ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/465e27cc-a57a-4915-8ee1-64e489aea6f4) |   | \n| 6 | paddlespeech vector --task spk --input 85236145389.wav | demos/speaker_verification |    ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/3bd46636-2bc4-431a-b930-fda15f76e6f8) |   | \n| 7 | paddlespeech asr --input ./zh.wav -v | demos/speech_recognition | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/0dd10113-c068-4c67-a7db-f7dae1a05a9a) |  | \n| 8 | - | demos/speech_translation | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/36215f46-f963-45ca-a26b-6b69ff26f730) |  | \n| 9 | - | demos/speech_web | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/edbd10fa-c3f3-42fe-a2ae-c937e805e200) |  | \n| 10 | - | demos/streaming_asr_server | ![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/102272920/b63e1d4b-daa0-47c8-a999-3718cce346ce) |  | \n\n### 待修复\n| 序号  | 命令                                                                         | 目录                                     | 结果  | 认领人/状态/PR号 |\n| --- | -------------------------------------------------------------------------- | -------------------------------------- | --- | ---------- |\n| 11 | paddlespeech_client acs --server_ip 127.0.0.1 --port 8090 --input ./zh.wav | demos/audio_content_search | -   |  @mattheliu <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 12 | - | demos/audio_searching | -   |  @mattheliu <img src=\"https://img.shields.io/badge/状态-报名-2ECC71\" /> <br> | \n| 13 | - | demos/metaverse | - |   | \n| 14 | paddlespeech_server start --config_file ./conf/application.yaml | demos/speech_server | -   |   | \n| 15 | paddlespeech ssl --task asr --lang en --input ./en.wav | demos/speech_ssl | -   |   | \n| 16 | - | demos/whisper | - |   | \n| 17 | - | demos/text_to_speech | - |   | \n| 18 | - | demos/streaming_tts_server | - |   | \n| 19 | - | demos/streaming_tts_serving_fastdeploy | -   |   | \n| 20 | - | demos/style_fs2 | - |   | \n| 21 | - | demos/story_talker | - |  | \n\n\n\n#### 1. 认领方式\n请大家以 comment 的形式认领任务，如：\n\n```\n【报名】：1、3、12-13\n```\n多个任务之间需要使用中文顿号分隔，报名多个连续任务可用横线表示，如 2-5\n\n#### 2. PR提交\nPR名称需要加前缀 **【Speech Demo develop No.XXX】**\nPR描述中需要附上本issue，提测文档请放到：\nhttps://github.com/PaddlePaddle/PaddleSpeech/tree/develop/tests/unit/cli\n评论里或者 review request @zxcd 研发会进行审核\n\n## 看板信息 \n| 任务方向 | 任务数量 | 提交作品 / 任务认领 | 提交率 | 完成 | 完成率 |\n| :----: | :----: | :----:  | :----: | :----: | :----: |\n|  已验证可提测  |  21  | 0 / 2 | 0.0% |  0  | 0.0% |\n#####\n\n## 统计信息 \n> 排名不分先后 \n#####\n",
        "state": "closed",
        "user": "mattheliu",
        "closed_by": "luotao1",
        "created_at": "2024-06-04T05:07:30+00:00",
        "updated_at": "2024-07-16T07:31:26+00:00",
        "closed_at": "2024-07-16T07:31:26+00:00",
        "comments_count": [
            "mattheliu",
            "jianghuakun",
            "zxcd",
            "jianghuakun",
            "jianghuakun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3789,
        "title": "飞桨开源社区交流频道和这一样，问题没人回复",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-06-05T03:26:24+00:00",
        "updated_at": "2025-04-26T04:45:18+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "jianghuakun",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3797
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3790,
        "title": "tts server 不支持混合语音模型（websocket)什么时候修复",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-06-05T03:31:15+00:00",
        "updated_at": "2025-04-26T04:45:21+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3791,
        "title": "tts server websocket源码不支持fastspeech2_mix模型什么时候修复",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-06-05T03:32:52+00:00",
        "updated_at": "2025-04-26T04:45:22+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3792,
        "title": "asr server 不支持混合语音模型什么时候修复",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-06-05T03:33:48+00:00",
        "updated_at": "2025-04-26T04:45:18+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "zxcd",
            "jianghuakun",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3796,
        "title": "paddlepaddle not have 2.5.1?",
        "body": "\r\n\r\n```\r\n(paddlespeech) root@nvidia-desktop:/# pip install paddlepaddle==2.5.1 -i https://mirror.baidu.com/pypi/simple\r\nLooking in indexes: https://mirror.baidu.com/pypi/simple\r\nERROR: Could not find a version that satisfies the requirement paddlepaddle==2.5.1 (from versions: 2.5.2, 2.6.0, 2.6.1)\r\nERROR: No matching distribution found for paddlepaddle==2.5.1\r\n```",
        "state": "open",
        "user": "ngc7292",
        "closed_by": null,
        "created_at": "2024-06-07T15:22:10+00:00",
        "updated_at": "2025-04-26T03:45:54+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "tofutim",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3800,
        "title": "[S2T] paddlecloud/paddlespeech:develop-gpu-cuda11.2-cudnn8-latest 最简单的例子也没法跑",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n最简单的例子也没法跑\r\n\r\n**To Reproduce**\r\npaddlespeech asr --lang zh --input zh.wav\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n```\r\n paddlespeech asr --lang zh --input zh.wav\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\r\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\r\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n  declare_namespace(pkg)\r\n/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py:1059: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  dtype=np.complex,\r\n/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py:1104: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  elif dtype == np.bool:\r\nW0613 08:46:25.913857 30879 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.2\r\nW0613 08:46:25.918004 30879 gpu_context.cc:306] device: 0, cuDNN Version: 8.1.\r\nTypeError: declarative() got an unexpected keyword argument 'property'\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n\r\n\r\n",
        "state": "open",
        "user": "zhaoying9105",
        "closed_by": null,
        "created_at": "2024-06-13T08:57:25+00:00",
        "updated_at": "2024-06-13T09:26:11+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3808
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3799,
        "title": "[TTS]中英混合流式语音合成推理时无声音",
        "body": "yaml文件如下：\r\n# This is the parameter configuration file for streaming tts server.\r\n\r\n#################################################################################\r\n#                             SERVER SETTING                                    #\r\n#################################################################################\r\nhost: 0.0.0.0\r\nport: 8090\r\n\r\n# The task format in the engin_list is: <speech task>_<engine type>\r\n# engine_list choices = ['tts_online', 'tts_online-onnx'], the inference speed of tts_online-onnx is faster than tts_online.\r\n# protocol choices = ['websocket', 'http'] \r\nprotocol: 'websocket'\r\n#engine_list: ['tts_online-onnx']\r\nengine_list: ['tts_online']\r\n\r\n\r\n#################################################################################\r\n#                                ENGINE CONFIG                                  #\r\n#################################################################################\r\n\r\n################################### TTS #########################################\r\n################### speech task: tts; engine_type: online #######################\r\ntts_online: \r\n    # am (acoustic model) choices=['fastspeech2_csmsc', 'fastspeech2_cnndecoder_csmsc']   \r\n    # fastspeech2_cnndecoder_csmsc support streaming am infer.     \r\n    am: 'fastspeech2_mix'   \r\n    am_config:  #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/fastspeech2_mix_ckpt_1.2.0/default.yaml' #/root/.paddlespeech/models/fastspeech2_csmsc-zh/1.0/fastspeech2_nosil_baker_ckpt_0.4/default.yaml\r\n    am_ckpt: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/fastspeech2_mix_ckpt_1.2.0/snapshot_iter_99200.pdz'\r\n    am_stat: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/fastspeech2_mix_ckpt_1.2.0/speech_stats.npy'\r\n    phones_dict: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/fastspeech2_mix_ckpt_1.2.0/phone_id_map.txt'\r\n    tones_dict: \r\n    speaker_dict:  #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/fastspeech2_mix_ckpt_1.2.0/speaker_id_map.txt'\r\n    #spk_id: 175\r\n\r\n    # voc (vocoder) choices=['mb_melgan_csmsc, hifigan_csmsc']\r\n    # Both mb_melgan_csmsc and hifigan_csmsc support streaming voc inference\r\n    voc: 'hifigan_csmsc'\r\n    voc_config: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/hifigan_csmsc_ckpt_0.1.1/default.yaml'\r\n    voc_ckpt: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/hifigan_csmsc_ckpt_0.1.1/snapshot_iter_1000000.pdz'\r\n    voc_stat: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/data/hifigan_csmsc_ckpt_0.1.1/feats_stats.npy'\r\n    # others\r\n    lang: 'mix'\r\n    device: 'cpu' # set 'gpu:id' or 'cpu'\r\n    # am_block and am_pad only for fastspeech2_cnndecoder_onnx model to streaming am infer,\r\n    # when am_pad set 12, streaming synthetic audio is the same as non-streaming synthetic audio\r\n    am_block: 72\r\n    am_pad: 12\r\n    # voc_pad and voc_block voc model to streaming voc infer,\r\n    # when voc model is mb_melgan_csmsc, voc_pad set 14, streaming synthetic audio is the same as non-streaming synthetic audio; The minimum value of pad can be set to 7, streaming synthetic audio sounds normal\r\n    # when voc model is hifigan_csmsc, voc_pad set 19, streaming synthetic audio is the same as non-streaming synthetic audio; voc_pad set 14, streaming synthetic audio sounds normal\r\n    voc_block: 36\r\n    voc_pad: 19\r\n    \r\n\r\n\r\n#################################################################################\r\n#                                ENGINE CONFIG                                  #\r\n#################################################################################\r\n\r\n################################### TTS #########################################\r\n################### speech task: tts; engine_type: online-onnx #######################\r\ntts_online-onnx: \r\n    # am (acoustic model) choices=['fastspeech2_csmsc_onnx', 'fastspeech2_cnndecoder_csmsc_onnx']\r\n    # fastspeech2_cnndecoder_csmsc_onnx support streaming am infer.        \r\n    am: 'fastspeech2_csmsc_onnx' \r\n    # am_ckpt is a list, if am is fastspeech2_cnndecoder_csmsc_onnx, am_ckpt = [encoder model, decoder model, postnet model];\r\n    # if am is fastspeech2_csmsc_onnx, am_ckpt = [ckpt model];\r\n    #am_config: 'fastspeech2_csmsc_onnx/fastspeech2_nosil_baker_ckpt_0.4/'\r\n    am_ckpt: #['/root/.paddlespeech/models/fastspeech2_csmsc_onnx-zh/1.0/fastspeech2_csmsc_onnx_0.2.0/fastspeech2_csmsc.onnx'] #['/home/PaddleSpeech/examples/zh_en_tts/tts3/fastspeech2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/fastspeech2_csmsc_am_encoder_infer.onnx',\r\n    #'/home/PaddleSpeech/examples/zh_en_tts/tts3/fastspeech2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/fastspeech2_csmsc_am_decoder.onnx',\r\n    #'/home/PaddleSpeech/examples/zh_en_tts/tts3/fastspeech2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/fastspeech2_csmsc_am_postnet.onnx'] #'fastspeech2_csmsc_onnx/fastspeech2_nosil_baker_ckpt_0.4/snapshot_iter_76000.pdz'    # list\r\n    am_stat: #'/home/PaddleSpeech/examples/zh_en_tts/tts3/fastspeech2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/speech_stats.npy' #'fastspeech2_csmsc_onn2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/speech_stats.npy' #/fastspeech2_nosil_baker_ckpt_0.4/speech_stats.npy'\r\n    phones_dict: #'/root/.paddlespeech/models/fastspeech2_csmsc_onnx-zh/1.0/fastspeech2_csmsc_onnx_0.2.0/phone_id_map.txt' #'/home/PaddleSpeech/examples/zh_en_tts/tts3/fastspeech2_cnndecoder_csmsc_onnx/fastspeech2_cnndecoder_csmsc_streaming_onnx_1.0.0/phone_id_map.txt' #'fastspeech2_csmsc_onnx/fastspeech2_nosil_baker_ckpt_0.4/phone_id_map.txt'\r\n    tones_dict: \r\n    speaker_dict: #'fastspeech2_csmsc_onnx/fastspeech2_nosil_baker_ckpt_0.4/'\r\n    am_sample_rate: 24000\r\n    am_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 12\r\n\r\n    # voc (vocoder) choices=['mb_melgan_csmsc_onnx, hifigan_csmsc_onnx']\r\n    # Both mb_melgan_csmsc_onnx and hifigan_csmsc_onnx support streaming voc inference\r\n    voc: 'mb_melgan_csmsc_onnx'\r\n    voc_ckpt: \r\n    voc_sample_rate: 24000\r\n    voc_sess_conf:\r\n        device: \"cpu\" # set 'gpu:id' or 'cpu'\r\n        use_trt: False\r\n        cpu_threads: 12\r\n\r\n    # others\r\n    lang: 'zh'\r\n    # am_block and am_pad only for fastspeech2_cnndecoder_onnx model to streaming am infer,\r\n    # when am_pad set 12, streaming synthetic audio is the same as non-streaming synthetic audio\r\n    am_block: 72\r\n    am_pad: 12\r\n    # voc_pad and voc_block voc model to streaming voc infer,\r\n    # when voc model is mb_melgan_csmsc_onnx, voc_pad set 14, streaming synthetic audio is the same as non-streaming synthetic audio; The minimum value of pad can be set to 7, streaming synthetic audio sounds normal\r\n    # when voc model is hifigan_csmsc_onnx, voc_pad set 19, streaming synthetic audio is the same as non-streaming synthetic audio; voc_pad set 14, streaming synthetic audio sounds normal\r\n    voc_block: 36\r\n    voc_pad: 14\r\n    # voc_upsample should be same as n_shift on voc config.\r\n    voc_upsample: 300\r\n\r\n\r\ntts_engine.py增加mix源码：\r\nelif am_dataset == \"mix\":\r\n                # am\r\n                spk_id = 174\r\n                spk_id = [spk_id]\r\n                mel = self.executor.am_inference(\r\n                        part_phone_ids)\r\n                if first_flag == 1:\r\n                    first_am_et = time.time()\r\n                    self.first_am_infer = first_am_et - frontend_et\r\n                # voc streaming\r\n                mel_chunks = get_chunks(mel, self.voc_block, self.voc_pad,\r\n                                        \"voc\")\r\n                voc_chunk_num = len(mel_chunks)\r\n                voc_st = time.time()\r\n                for i, mel_chunk in enumerate(mel_chunks):\r\n                    sub_wav = self.executor.voc_inference(mel_chunk)\r\n                    sub_wav = self.depadding(sub_wav, voc_chunk_num, i,\r\n                                             self.voc_block, self.voc_pad,\r\n                                             self.voc_upsample)\r\n                    if first_flag == 1:\r\n                        first_voc_et = time.time()\r\n                        self.first_voc_infer = first_voc_et - first_am_et\r\n                        self.first_response_time = first_voc_et - frontend_st\r\n                        first_flag = 0\r\n\r\n                    yield sub_wav\r\n\r\n其他判断增加了混合模型\r\n",
        "state": "open",
        "user": "jianghuakun",
        "closed_by": null,
        "created_at": "2024-06-13T06:55:26+00:00",
        "updated_at": "2025-04-26T04:45:17+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "jianghuakun",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3801,
        "title": "有没有涵盖所有汉语发音的一篇文章，多篇也行",
        "body": "做语音克隆，如果所有音节都涉及到了，那效果应该不错吧？",
        "state": "open",
        "user": "zouhan6806504",
        "closed_by": null,
        "created_at": "2024-06-18T02:39:01+00:00",
        "updated_at": "2025-04-26T04:45:15+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3805,
        "title": "[TTS]我看官网说paddle.fluid已经被废弃了，可是我通过pip install paddlespeech发现官方包却还在用",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/98244381/62c28dff-0744-4fdd-9062-56ae30e1d0d0)\r\n这种情况应该怎么处理呢，只能降低paddlepaddle的版本吗",
        "state": "open",
        "user": "zx-lhb",
        "closed_by": null,
        "created_at": "2024-06-21T08:41:53+00:00",
        "updated_at": "2024-06-26T02:17:55+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3806,
        "title": "Voice cloning in English",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\nHi \r\n\r\nI want to ask does paddlespeech supports voice cloning in English. I have tried and configured english (am & voc and ge2e) models but unable to get voice cloning.Its generating english voice but in the same accent for any input.I am using voicecloning.py script for text to speech\r\n\r\nKindly answer the question/query.",
        "state": "open",
        "user": "GHUFRAN-HYDER",
        "closed_by": null,
        "created_at": "2024-06-24T13:14:30+00:00",
        "updated_at": "2025-04-26T04:45:14+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3802,
        "title": "语音分类example运行报错",
        "body": "按照https://github.com/PaddlePaddle/PaddleSpeech/tree/r1.4/examples/esc50中描述，进行模型1、训练/2、推理/3、模型导出/4、导出模型推理运行，前三步都能成功，运行第四步报错如下：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/69777965/a40033ef-89e5-4b96-82f6-9892d30b3828)\r\n环境：\r\nubuntu18\r\npython3.8\r\nabsl-py                     2.1.0\r\naiohttp                     3.9.5\r\naiosignal                   1.3.1\r\naistudio-sdk                0.2.4\r\nannotated-types             0.7.0\r\nantlr4-python3-runtime      4.9.3\r\nanyio                       4.4.0\r\nastor                       0.8.1\r\nasttokens                   2.4.1\r\nasync-timeout               4.0.3\r\nattrs                       23.2.0\r\naudioread                   3.0.1\r\nav                          12.1.0\r\nBabel                       2.15.0\r\nbackcall                    0.2.0\r\nbce-python-sdk              0.9.14\r\nblinker                     1.8.2\r\nbokeh                       3.1.1\r\nboltons                     24.0.0\r\nBottleneck                  1.3.8\r\nbraceexpand                 0.1.7\r\ncertifi                     2024.6.2\r\ncffi                        1.16.0\r\ncharset-normalizer          3.3.2\r\nclick                       8.1.7\r\ncolorama                    0.4.6\r\ncoloredlogs                 15.0.1\r\ncolorlog                    6.8.2\r\ncontourpy                   1.1.1\r\ncycler                      0.12.1\r\nCython                      3.0.10\r\ndatasets                    2.20.0\r\ndecorator                   5.1.1\r\ndill                        0.3.4\r\nDistance                    0.1.3\r\ndnspython                   2.6.1\r\neditdistance                0.8.1\r\neinops                      0.8.0\r\nemail_validator             2.1.2\r\nexceptiongroup              1.2.1\r\nexecuting                   2.0.1\r\nfastapi                     0.111.0\r\nfastapi-cli                 0.0.4\r\nfilelock                    3.15.1\r\nFlask                       3.0.3\r\nflask-babel                 4.0.0\r\nflatbuffers                 24.3.25\r\nfonttools                   4.53.0\r\nfrozenlist                  1.4.1\r\nfsspec                      2024.5.0\r\nftfy                        6.2.0\r\nfuture                      1.0.0\r\ng2p-en                      2.1.0\r\ng2pM                        0.1.2.5\r\nh11                         0.14.0\r\nh5py                        3.11.0\r\nhttpcore                    1.0.5\r\nhttptools                   0.6.1\r\nhttpx                       0.27.0\r\nhuggingface-hub             0.23.4\r\nhumanfriendly               10.0\r\nHyperPyYAML                 1.2.2\r\nidna                        3.7\r\nimportlib_metadata          7.1.0\r\nimportlib_resources         6.4.0\r\ninflect                     7.0.0\r\nintervaltree                3.1.0\r\nipython                     8.12.3\r\nitsdangerous                2.2.0\r\njedi                        0.19.1\r\njieba                       0.42.1\r\nJinja2                      3.1.4\r\njoblib                      1.4.2\r\njsonlines                   4.0.0\r\nkaldiio                     2.18.0\r\nkiwisolver                  1.4.5\r\nlibrosa                     0.8.1\r\nligo-segments               1.4.0\r\nllvmlite                    0.41.1\r\nloguru                      0.7.2\r\nlxml                        5.2.2\r\nmarkdown-it-py              3.0.0\r\nMarkupSafe                  2.1.5\r\nmatplotlib                  3.7.5\r\nmatplotlib-inline           0.1.7\r\nmdurl                       0.1.2\r\nmido                        1.3.2\r\nmock                        5.1.0\r\nmpmath                      1.3.0\r\nmultidict                   6.0.5\r\nmultiprocess                0.70.12.2\r\nnara-wpe                    0.0.9\r\nnltk                        3.8.1\r\nnote-seq                    0.0.5\r\nnumba                       0.58.1\r\nnumpy                       1.23.5\r\nomegaconf                   2.3.0\r\nonnx                        1.16.1\r\nonnxruntime                 1.16.3\r\nOpenCC                      1.1.6\r\nopencc-python-reimplemented 0.1.7\r\nopencv-python               4.6.0.66\r\nopt-einsum                  3.3.0\r\norjson                      3.10.5\r\npackaging                   23.2\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.2.3\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.8.0\r\npaddlepaddle-gpu            2.4.1\r\npaddlesde                   0.2.5\r\npaddleslim                  2.6.0\r\npaddlespeech                1.4.0\r\npaddlespeech-feat           0.1.0\r\npandas                      2.0.3\r\nparameterized               0.9.0\r\nparso                       0.8.4\r\npathos                      0.2.8\r\npattern_singleton           1.2.0\r\npexpect                     4.9.0\r\npickleshare                 0.7.5\r\npillow                      10.3.0\r\npip                         24.0\r\nplatformdirs                4.2.2\r\npooch                       1.8.2\r\nportalocker                 2.8.2\r\npox                         0.3.4\r\nppdiffusers                 0.24.0\r\nppft                        1.7.6.8\r\npraatio                     5.1.1\r\npretty_midi                 0.2.10\r\nprettytable                 3.10.0\r\nprompt_toolkit              3.0.47\r\nprotobuf                    3.20.0\r\npsutil                      5.9.8\r\nptyprocess                  0.7.0\r\npure-eval                   0.2.2\r\npyarrow                     16.1.0\r\npyarrow-hotfix              0.6\r\npybind11                    2.12.0\r\npycparser                   2.22\r\npycryptodome                3.20.0\r\npydantic                    2.7.4\r\npydantic_core               2.18.4\r\npydub                       0.25.1\r\nPygments                    2.18.0\r\npygtrie                     2.5.0\r\npyparsing                   3.1.2\r\npypinyin                    0.44.0\r\npypinyin-dict               0.8.0\r\npytest-runner               6.0.1\r\npython-dateutil             2.9.0.post0\r\npython-dotenv               1.0.1\r\npython-multipart            0.0.9\r\npytz                        2024.1\r\npyworld                     0.3.4\r\nPyYAML                      6.0.1\r\npyzmq                       26.0.3\r\nrarfile                     4.2\r\nregex                       2024.5.15\r\nrequests                    2.32.3\r\nrequests-mock               1.12.1\r\nresampy                     0.4.3\r\nrich                        13.7.1\r\nruamel.yaml                 0.18.6\r\nruamel.yaml.clib            0.2.8\r\nsacrebleu                   2.4.2\r\nsafetensors                 0.4.3\r\nscikit-learn                1.3.2\r\nscipy                       1.10.1\r\nsentencepiece               0.2.0\r\nseqeval                     1.2.2\r\nsetuptools                  69.5.1\r\nshellingham                 1.5.4\r\nsix                         1.16.0\r\nsniffio                     1.3.1\r\nsortedcontainers            2.4.0\r\nsoundfile                   0.12.1\r\nstack-data                  0.6.3\r\nstarlette                   0.37.2\r\nswig                        4.2.1\r\nsympy                       1.12.1\r\ntabulate                    0.9.0\r\nTextGrid                    1.6.1\r\nthreadpoolctl               3.5.0\r\ntimer                       0.3.0\r\nToJyutping                  0.2.3\r\ntool-helpers                0.1.1\r\ntornado                     6.4.1\r\ntqdm                        4.66.4\r\ntraitlets                   5.14.3\r\ntrampoline                  0.1.2\r\ntypeguard                   2.13.3\r\ntyper                       0.12.3\r\ntyping_extensions           4.12.2\r\ntzdata                      2024.1\r\nujson                       5.10.0\r\nurllib3                     1.26.18\r\nuvicorn                     0.30.1\r\nuvloop                      0.19.0\r\nvisualdl                    2.5.3\r\nwatchfiles                  0.22.0\r\nwcwidth                     0.2.13\r\nwebrtcvad                   2.0.10\r\nwebsockets                  12.0\r\nWerkzeug                    3.0.3\r\nwheel                       0.43.0\r\nxxhash                      3.4.1\r\nxyzservices                 2024.6.0\r\nyacs                        0.1.8\r\nyarl                        1.9.4\r\nzhon                        2.0.2\r\nzipp                        3.19.2\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "quanzhang2020",
        "closed_by": null,
        "created_at": "2024-06-18T10:34:27+00:00",
        "updated_at": "2024-06-20T10:01:42+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3809,
        "title": "pip 报错了",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/29285431/caf66737-131c-423a-a1be-83524c3cd77f)\r\n",
        "state": "open",
        "user": "suxuanning",
        "closed_by": null,
        "created_at": "2024-06-28T05:24:10+00:00",
        "updated_at": "2025-04-26T04:45:13+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3810,
        "title": "中英文混合语音识别模型（数据集talcs)，使用官方的权重测试，测试结果很差，几乎全错，和官方写的精度差距很大。",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "xing-bing",
        "closed_by": null,
        "created_at": "2024-06-28T07:01:41+00:00",
        "updated_at": "2025-04-26T04:45:11+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3811,
        "title": "tool-helpers安装报错",
        "body": "安装paddlenlp和paddlespeech时，报错tool-helpers没有可安装的包：\r\n![image](https://github.com/PaddlePaddle/PaddleSpeech/assets/37332773/7d9d24dd-8403-497a-a750-38f13e931487)\r\n\r\n系统信息：ubuntu20.04\r\n系统架构：arm64\r\npaddle版本：2.4.2\r\n\r\n请问是不是tool-helpers没有arm64架构的安装包？",
        "state": "open",
        "user": "peiwenYe",
        "closed_by": null,
        "created_at": "2024-07-01T12:22:22+00:00",
        "updated_at": "2025-04-26T04:45:10+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3812,
        "title": "[TTS]ImportError: cannot import name 'get_cmap' from 'matplotlib.cm'",
        "body": "Traceback (most recent call last):\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/bin/paddlespeech\", line 8, in <module>\r\n    sys.exit(_execute())\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\r\n    exec(\"from {} import {}\".format(module, cls))\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 33, in <module>\r\n    from paddlespeech.t2s.exps.syn_utils import get_am_inference\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/__init__.py\", line 19, in <module>\r\n    from . import models\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/models/__init__.py\", line 14, in <module>\r\n    from .ernie_sat import *\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/models/ernie_sat/__init__.py\", line 15, in <module>\r\n    from .ernie_sat_updater import *\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/models/ernie_sat/ernie_sat_updater.py\", line 24, in <module>\r\n    from paddlespeech.t2s.training.extensions.evaluator import StandardEvaluator\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/training/__init__.py\", line 15, in <module>\r\n    from .experiment import *\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/training/experiment.py\", line 23, in <module>\r\n    from paddlespeech.t2s.utils import checkpoint\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/utils/__init__.py\", line 15, in <module>\r\n    from . import display\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/paddlespeech/t2s/utils/display.py\", line 14, in <module>\r\n    import librosa.display\r\n  File \"/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/librosa/display.py\", line 48, in <module>\r\n    from matplotlib.cm import get_cmap\r\nImportError: cannot import name 'get_cmap' from 'matplotlib.cm' (/home/puaiuc/.conda/envs/paddle_tts/lib/python3.9/site-packages/matplotlib/cm.py)\r\n\r\n\r\n\r\n使用语音合成指令paddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav  报错如上\r\n没发现有什么问题   按照说明装的环境  应该是哪个包的版本不匹配，有大佬解答一下吗\r\n当前python 3.9     paddlepaddle-gpu 2.5.1      CUDA12.0      gcc7.5.0  \r\npip list如下\r\nabsl-py                     2.1.0\r\naiohttp                     3.9.5\r\naiosignal                   1.3.1\r\naistudio-sdk                0.2.4\r\nannotated-types             0.7.0\r\nantlr4-python3-runtime      4.9.3\r\nanyio                       4.4.0\r\nastor                       0.8.1\r\nasttokens                   2.4.1\r\nasync-timeout               4.0.3\r\nattrs                       23.2.0\r\naudioread                   3.0.1\r\nav                          12.2.0\r\nBabel                       2.15.0\r\nbce-python-sdk              0.9.17\r\nblinker                     1.8.2\r\nbokeh                       3.4.2\r\nboltons                     24.0.0\r\nBottleneck                  1.4.0\r\nbraceexpand                 0.1.7\r\ncertifi                     2024.6.2\r\ncffi                        1.16.0\r\ncharset-normalizer          3.3.2\r\nclick                       8.1.7\r\ncolorama                    0.4.6\r\ncoloredlogs                 15.0.1\r\ncolorlog                    6.8.2\r\ncontourpy                   1.2.1\r\ncycler                      0.12.1\r\nCython                      3.0.10\r\ndatasets                    2.20.0\r\ndecorator                   5.1.1\r\ndill                        0.3.4\r\nDistance                    0.1.3\r\ndnspython                   2.6.1\r\neditdistance                0.8.1\r\neinops                      0.8.0\r\nemail_validator             2.2.0\r\nexceptiongroup              1.2.1\r\nexecuting                   2.0.1\r\nfastapi                     0.111.0\r\nfastapi-cli                 0.0.4\r\nfilelock                    3.15.4\r\nFlask                       3.0.3\r\nflask-babel                 4.0.0\r\nflatbuffers                 24.3.25\r\nfonttools                   4.53.0\r\nfrozenlist                  1.4.1\r\nfsspec                      2024.5.0\r\nftfy                        6.2.0\r\nfuture                      1.0.0\r\ng2p-en                      2.1.0\r\ng2pM                        0.1.2.5\r\nh11                         0.14.0\r\nh5py                        3.11.0\r\nhttpcore                    1.0.5\r\nhttptools                   0.6.1\r\nhttpx                       0.27.0\r\nhuggingface-hub             0.23.4\r\nhumanfriendly               10.0\r\nHyperPyYAML                 1.2.2\r\nidna                        3.7\r\nimportlib_metadata          8.0.0\r\nimportlib_resources         6.4.0\r\ninflect                     7.0.0\r\nintervaltree                3.1.0\r\nipython                     8.18.1\r\nitsdangerous                2.2.0\r\njedi                        0.19.1\r\njieba                       0.42.1\r\nJinja2                      3.1.4\r\njoblib                      1.4.2\r\njsonlines                   4.0.0\r\nkaldiio                     2.18.0\r\nkiwisolver                  1.4.5\r\nlibrosa                     0.8.1\r\nligo-segments               1.4.0\r\nllvmlite                    0.43.0\r\nloguru                      0.7.2\r\nlxml                        5.2.2\r\nmarkdown-it-py              3.0.0\r\nMarkupSafe                  2.1.5\r\nmatplotlib                  3.9.0\r\nmatplotlib-inline           0.1.7\r\nmdurl                       0.1.2\r\nmido                        1.3.2\r\nmock                        5.1.0\r\nmpmath                      1.3.0\r\nmultidict                   6.0.5\r\nmultiprocess                0.70.12.2\r\nnara-wpe                    0.0.10\r\nnltk                        3.8.1\r\nnote-seq                    0.0.5\r\nnumba                       0.60.0\r\nnumpy                       1.23.5\r\nomegaconf                   2.3.0\r\nonnx                        1.16.1\r\nonnxruntime                 1.18.1\r\nOpenCC                      1.1.6\r\nopencc-python-reimplemented 0.1.7\r\nopencv-python               4.6.0.66\r\nopt-einsum                  3.3.0\r\norjson                      3.10.5\r\npackaging                   23.2\r\npaddle-bfloat               0.1.7\r\npaddle2onnx                 1.2.4\r\npaddleaudio                 1.1.0\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.8.1\r\npaddlepaddle-gpu            2.5.1\r\npaddlesde                   0.2.5\r\npaddleslim                  2.6.0\r\npaddlespeech                0.0.0\r\npaddlespeech-feat           0.1.0\r\npandas                      2.2.2\r\nparameterized               0.9.0\r\nparso                       0.8.4\r\npathos                      0.2.8\r\npattern_singleton           1.2.0\r\npexpect                     4.9.0\r\npillow                      10.4.0\r\npip                         24.0\r\nplatformdirs                4.2.2\r\npooch                       1.8.2\r\nportalocker                 2.10.0\r\npox                         0.3.4\r\nppdiffusers                 0.24.0\r\nppft                        1.7.6.8\r\npraatio                     5.1.1\r\npretty_midi                 0.2.10\r\nprettytable                 3.10.0\r\nprompt_toolkit              3.0.47\r\nprotobuf                    5.27.2\r\npsutil                      6.0.0\r\nptyprocess                  0.7.0\r\npure-eval                   0.2.2\r\npyarrow                     16.1.0\r\npyarrow-hotfix              0.6\r\npybind11                    2.13.1\r\npycparser                   2.22\r\npycryptodome                3.20.0\r\npydantic                    2.8.0\r\npydantic_core               2.20.0\r\npydub                       0.25.1\r\nPygments                    2.18.0\r\npygtrie                     2.5.0\r\npyparsing                   3.1.2\r\npypinyin                    0.44.0\r\npypinyin-dict               0.8.0\r\npytest-runner               6.0.1\r\npython-dateutil             2.9.0.post0\r\npython-dotenv               1.0.1\r\npython-multipart            0.0.9\r\npytz                        2024.1\r\npyworld                     0.3.4\r\nPyYAML                      6.0.1\r\npyzmq                       26.0.3\r\nrarfile                     4.2\r\nregex                       2024.5.15\r\nrequests                    2.32.3\r\nrequests-mock               1.12.1\r\nresampy                     0.4.3\r\nrich                        13.7.1\r\nruamel.yaml                 0.18.6\r\nruamel.yaml.clib            0.2.8\r\nsacrebleu                   2.4.2\r\nsafetensors                 0.4.3\r\nscikit-learn                1.5.0\r\nscipy                       1.13.1\r\nsentencepiece               0.2.0\r\nseqeval                     1.2.2\r\nsetuptools                  69.5.1\r\nshellingham                 1.5.4\r\nsix                         1.16.0\r\nsniffio                     1.3.1\r\nsortedcontainers            2.4.0\r\nsoundfile                   0.12.1\r\nstack-data                  0.6.3\r\nstarlette                   0.37.2\r\nswig                        4.2.1\r\nsympy                       1.12.1\r\ntabulate                    0.9.0\r\nTextGrid                    1.6.1\r\nthreadpoolctl               3.5.0\r\ntimer                       0.3.0\r\nToJyutping                  0.2.1\r\ntool-helpers                0.1.1\r\ntornado                     6.4.1\r\ntqdm                        4.66.4\r\ntraitlets                   5.14.3\r\ntrampoline                  0.1.2\r\ntypeguard                   2.13.3\r\ntyper                       0.12.3\r\ntyping_extensions           4.12.2\r\ntzdata                      2024.1\r\nujson                       5.10.0\r\nurllib3                     1.26.19\r\nuvicorn                     0.30.1\r\nuvloop                      0.19.0\r\nvisualdl                    2.5.3\r\nwatchfiles                  0.22.0\r\nwcwidth                     0.2.13\r\nwebrtcvad                   2.0.10\r\nwebsockets                  12.0\r\nWerkzeug                    3.0.3\r\nwheel                       0.43.0\r\nxxhash                      3.4.1\r\nxyzservices                 2024.6.0\r\nyacs                        0.1.8\r\nyarl                        1.9.4\r\nzhon                        2.0.2\r\nzipp                        3.19.2",
        "state": "closed",
        "user": "ZHUHF123",
        "closed_by": "zxcd",
        "created_at": "2024-07-02T09:11:35+00:00",
        "updated_at": "2024-09-05T09:07:32+00:00",
        "closed_at": "2024-09-05T09:07:32+00:00",
        "comments_count": [
            "Ray961123",
            "ReturnTR",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3813,
        "title": "[TTS]ImportError: cannot import name 'CommonTaskResource' from partially initialized module 'paddlespeech.resource'",
        "body": "Traceback (most recent call last):\r\n  File \"/home/ubuntu/yavar/PoC/text-to-speech/paddle.py\", line 1, in <module>\r\n    from paddlespeech.cli.tts.infer import TTSExecutor\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\r\n    from .base_commands import BaseCommand\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\r\n    from ..resource import CommonTaskResource\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\r\n    from .resource import CommonTaskResource\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\r\n    from ..cli.utils import download_and_decompress\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/utils.py\", line 26, in <module>\r\n    import paddle\r\n  File \"/home/ubuntu/yavar/PoC/text-to-speech/paddle.py\", line 1, in <module>\r\n    from paddlespeech.cli.tts.infer import TTSExecutor\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/tts/__init__.py\", line 14, in <module>\r\n    from .infer import TTSExecutor\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/tts/infer.py\", line 29, in <module>\r\n    from ..executor import BaseExecutor\r\n  File \"/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/cli/executor.py\", line 27, in <module>\r\n    from ..resource import CommonTaskResource\r\nImportError: cannot import name 'CommonTaskResource' from partially initialized module 'paddlespeech.resource' (most likely due to a circular import) (/home/ubuntu/miniconda3/envs/paddlespeech/lib/python3.9/site-packages/paddlespeech/resource/__init__.py)",
        "state": "open",
        "user": "Kanishkvijay",
        "closed_by": null,
        "created_at": "2024-07-05T10:07:26+00:00",
        "updated_at": "2024-07-11T02:43:59+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3814,
        "title": "asr支持带时间戳返回的吗，可以识别到哪些字，在音频中的时间戳",
        "body": "## Feature Request\r\n\r\n**Is your feature request related to a problem? Please describe:**\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the feature you'd like:**\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered:**\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n",
        "state": "open",
        "user": "thb10086",
        "closed_by": null,
        "created_at": "2024-07-08T09:48:18+00:00",
        "updated_at": "2024-07-11T02:46:32+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3815,
        "title": "🌟 安装PaddleSpeech相关问题讨论（Windows，mac），以及命令行使用问题",
        "body": "### Discussed in https://github.com/PaddlePaddle/PaddleSpeech/discussions/1195\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **Jackwaterveg** December 22, 2021</sup>\r\n大家有什么Windows安装的问题可以在这里讨论。\r\n\r\nWin安装必须条件：\r\n1. C++ 编译环境。 推荐Visual stuido build tools。\r\n  官方链接:\r\n  https://visualstudio.microsoft.com/visual-cpp-build-tools/\r\n\r\nWin安装出现的问题：\r\n1. paddlespeech-ctcdecoders 没有安装成功不要紧，这个包不是必须的。</div>",
        "state": "open",
        "user": "cuiyanzhuo",
        "closed_by": null,
        "created_at": "2024-07-16T01:05:30+00:00",
        "updated_at": "2025-04-26T03:46:25+00:00",
        "closed_at": null,
        "comments_count": [
            "cuiyanzhuo",
            "megemini",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3820,
        "title": "Aborted connection 11 to db when running the code of demos/audio_searching/src/test_audio_search.py",
        "body": "## 音频查找demo中无法与mysql database通信\r\n我已经按照教程安装了paddlepaddle-gpu版以及paddlespeech，并且安装好了对应的docker依赖并且成功启动他们：\r\n`[+] Running 5/0\r\n ✔ Container milvus-etcd        Running                                                                                            0.0s \r\n ✔ Container milvus-minio       Running                                                                                            0.0s \r\n ✔ Container audio-mysql        Running                                                                                            0.0s \r\n ✔ Container audio-webclient    Running                                                                                            0.0s \r\n ✔ Container milvus-standalone  Running                                                                                            0.0s`\r\n\r\n紧接着我运行python src/audio_search.py\r\n可以输出如下：\r\n`INFO:     Started server process [22764]\r\nINFO:     Waiting for application startup.\r\nINFO:     Application startup complete.\r\nINFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)`\r\n\r\n然后我运行python ./src/test_audio_search.py\r\n得到的输出如下\r\n`Downloading https://paddlespeech.bj.bcebos.com/vector/audio/example_audio.tar.gz ...\r\n--2024-07-21 14:25:41--  https://paddlespeech.bj.bcebos.com/vector/audio/example_audio.tar.gz\r\n正在解析主机 paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)... 113.200.2.111, 119.249.103.5, 2409:8c04:1001:1203:0:ff:b0bb:4f27\r\n正在连接 paddlespeech.bj.bcebos.com (paddlespeech.bj.bcebos.com)|113.200.2.111|:443... 已连接。\r\n已发出 HTTP 请求，正在等待回应... 200 OK\r\n长度： 440320 (430K) [application/x-gzip]\r\n正在保存至: “./example_audio.tar.gz”\r\n\r\nexample_audio.tar.gz              100%[=============================================================>] 430.00K  1.67MB/s    用时 0.3s  \r\n\r\n2024-07-21 14:25:42 (1.67 MB/s) - 已保存 “./example_audio.tar.gz” [440320/440320])\r\n\r\n\r\nMD5 Chesksum ./example_audio.tar.gz ...\r\nUnpacking ./example_audio.tar.gz ...\r\nW0721 14:25:42.517747 22295 gpu_resources.cc:96] The GPU architecture in your current machine is Pascal, which is not compatible with Paddle installation with arch: 70 75 80 86 , it is recommended to install the corresponding wheel package according to the installation information on the official Paddle website.\r\nW0721 14:25:42.517772 22295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.6, Runtime API Version: 11.6\r\nW0721 14:25:42.522830 22295 gpu_resources.cc:149] device: 0, cuDNN Version: 8.4.\r\nExtracting feature from audio No. 1 , 20 audios in total\r\nExtracting feature from audio No. 2 , 20 audios in total\r\nExtracting feature from audio No. 3 , 20 audios in total\r\nExtracting feature from audio No. 4 , 20 audios in total\r\nExtracting feature from audio No. 5 , 20 audios in total\r\nExtracting feature from audio No. 6 , 20 audios in total\r\n/home/wjh/PaddleSpeech/demos/audio_searching/src/encode.py:29: RuntimeWarning: divide by zero encountered in true_divide\r\n  embedding = embedding / np.linalg.norm(embedding)\r\nExtracting feature from audio No. 7 , 20 audios in total\r\nExtracting feature from audio No. 8 , 20 audios in total\r\nExtracting feature from audio No. 9 , 20 audios in total\r\nExtracting feature from audio No. 10 , 20 audios in total\r\nExtracting feature from audio No. 11 , 20 audios in total\r\nExtracting feature from audio No. 12 , 20 audios in total\r\nExtracting feature from audio No. 13 , 20 audios in total\r\nExtracting feature from audio No. 14 , 20 audios in total\r\nExtracting feature from audio No. 15 , 20 audios in total\r\nExtracting feature from audio No. 16 , 20 audios in total\r\nExtracting feature from audio No. 17 , 20 audios in total\r\nExtracting feature from audio No. 18 , 20 audios in total\r\nExtracting feature from audio No. 19 , 20 audios in total\r\nExtracting feature from audio No. 20 , 20 audios in total\r\nTraceback (most recent call last):\r\n  File \"./src/test_audio_search.py\", line 93, in <module>\r\n    test_count()\r\n  File \"./src/test_audio_search.py\", line 69, in test_count\r\n    assert response.json() == 20\r\nAssertionError`\r\n\r\n然后进一步查看docker日志发现我的主机和docker mysql database之间无法建立通信\r\n`2024-07-21T05:30:47.979844Z 0 [Note] Event Scheduler: Loaded 0 events\r\n2024-07-21T05:30:47.980370Z 0 [Note] mysqld: ready for connections.\r\nVersion: '5.7.36'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)\r\n2024-07-21T05:33:18.806576Z 3 [Note] Aborted connection 3 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T05:37:00.441137Z 2 [Note] Aborted connection 2 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T05:51:02.611489Z 5 [Note] Aborted connection 5 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T05:56:15.535693Z 4 [Note] Aborted connection 4 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:04:52.530018Z 7 [Note] Aborted connection 7 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:08:12.158312Z 6 [Note] Aborted connection 6 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:08:36.623535Z 9 [Note] Aborted connection 9 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:10:42.144944Z 8 [Note] Aborted connection 8 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:15:36.477397Z 11 [Note] Aborted connection 11 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:24:59.187555Z 10 [Note] Aborted connection 10 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:25:48.302426Z 13 [Note] Aborted connection 13 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)\r\n2024-07-21T06:26:30.303252Z 12 [Note] Aborted connection 12 to db: 'mysql' user: 'root' host: '172.16.23.1' (Got an error reading communication packets)`\r\n\r\n请问这可能是因为什么原因呢？我都是在我这台电脑上运行的所以config.py中的端口和ip都没有修改\r\n\r\n",
        "state": "open",
        "user": "laliwang",
        "closed_by": null,
        "created_at": "2024-07-21T06:33:22+00:00",
        "updated_at": "2025-04-26T03:46:22+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3819,
        "title": "🌟 安装PaddleSpeech相关问题讨论（Windows，mac），以及命令行使用问题",
        "body": "### Discussed in https://github.com/PaddlePaddle/PaddleSpeech/discussions/1195\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **Jackwaterveg** December 22, 2021</sup>\r\n大家有什么Windows安装的问题可以在这里讨论。\r\n\r\nWin安装必须条件：\r\n1. C++ 编译环境。 推荐Visual stuido build tools。\r\n  官方链接:\r\n  https://visualstudio.microsoft.com/visual-cpp-build-tools/\r\n\r\nWin安装出现的问题：\r\n1. paddlespeech-ctcdecoders 没有安装成功不要紧，这个包不是必须的。</div>",
        "state": "closed",
        "user": "cuiyanzhuo",
        "closed_by": "stale[bot]",
        "created_at": "2024-07-20T05:09:53+00:00",
        "updated_at": "2025-06-27T03:38:37+00:00",
        "closed_at": "2025-06-27T03:38:37+00:00",
        "comments_count": [
            "cuiyanzhuo",
            "chenmj201601",
            "liu33333",
            "stale[bot]",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3822,
        "title": "自己训练后的模型怎么部署到服务器上，使用tts流式服务",
        "body": "想问一下需要修改哪个文件，才能将我训练好的fastspeech2_mix模型部署到服务器上然后运行\r\n",
        "state": "open",
        "user": "YOUZI36",
        "closed_by": null,
        "created_at": "2024-07-27T09:28:52+00:00",
        "updated_at": "2025-04-26T03:46:21+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3825,
        "title": "fastspeech2训练multiple speaker TTS模型问题",
        "body": "利用AISHELL-3训练fastspeech2 multiple speaker TTS模型,在fastspeech2.py初始化中\r\n```python\r\nif spk_num and self.spk_embed_dim:\r\n    self.spk_embedding_table = nn.Embedding(\r\n      num_embeddings=spk_num,\r\n      embedding_dim=self.spk_embed_dim,\r\n      padding_idx=self.padding_idx)\r\n```\r\nself.spk_embed_dim默认为None ,self.spk_embedding_table = None\r\n\r\n```python\r\n# integrate speaker embedding\r\nif self.spk_embed_dim is not None:\r\n    # spk_emb has a higher priority than spk_id\r\n    if spk_emb is not None:\r\n        hs = self._integrate_with_spk_embed(hs, spk_emb)\r\n    elif spk_id is not None:\r\n        spk_emb = self.spk_embedding_table(spk_id)\r\n        hs = self._integrate_with_spk_embed(hs, spk_emb)\r\n```\r\nPS:在配置文件中指定了spk_embed_dim\r\n",
        "state": "closed",
        "user": "JiaoPaner",
        "closed_by": "JiaoPaner",
        "created_at": "2024-08-08T09:12:23+00:00",
        "updated_at": "2024-08-08T09:15:23+00:00",
        "closed_at": "2024-08-08T09:14:37+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3823,
        "title": "既然都支持SSML了，能否给/paddlespeech/tts/streaing接口新增speed和SSML功能呢？",
        "body": "既然都支持SSML了，能否给/paddlespeech/tts/streaing接口新增speed和SSML功能呢？",
        "state": "open",
        "user": "cn-fanfare",
        "closed_by": null,
        "created_at": "2024-07-28T12:11:37+00:00",
        "updated_at": "2024-08-05T06:31:08+00:00",
        "closed_at": null,
        "comments_count": [
            "cn-fanfare",
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3824,
        "title": "语音识别自训练模型导出提示'cnn_cache' doesn't exist in pruned",
        "body": "cd ~/PaddleSpeech/examples/tiny/asr1\r\n依次执行\r\nbash run.sh --stage 0 --stop_stage 0\r\nbash run.sh --stage 1 --stop_stage 1\r\nbash run.sh --stage 2 --stop_stage 2\r\nbash run.sh --stage 3 --stop_stage 3\r\nbash run.sh --stage 4 --stop_stage 4\r\nbash run.sh --stage 51 --stop_stage 51\r\n\r\n0-4都没问题，最后51报如下错误：\r\nValueError: The feeded_var_names[3]: 'cnn_cache' doesn't exist in pruned inference program. \r\n",
        "state": "open",
        "user": "colinlwz",
        "closed_by": null,
        "created_at": "2024-08-07T07:14:08+00:00",
        "updated_at": "2025-04-26T03:46:19+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3827,
        "title": "【语音合成】大佬们，请问下民族语言（维、藏）MFA的标注文件【TextGrid】如何批量生成或者维藏语言读音如何转国际音标？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "ljmphp",
        "closed_by": null,
        "created_at": "2024-08-13T03:15:59+00:00",
        "updated_at": "2025-04-26T03:46:19+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3829,
        "title": "语音识别后处理",
        "body": "## 流式语音识别后处理\r\n\r\n各位大佬，我想实现语音中中文名字的准确识别，如何在识别之后根据系统内的姓名列表进行一个姓名的替换效果，求指导！\r\n",
        "state": "open",
        "user": "sunbigdog",
        "closed_by": null,
        "created_at": "2024-08-21T03:38:57+00:00",
        "updated_at": "2025-04-26T03:46:17+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3831,
        "title": "[TTS]流式tts客户端web client 对最新的代码服务不适配，参数不对",
        "body": "PaddleSpeech\\demos\\speech_web\\web_client\\src\\components\\SubMenu\\TTS\\TTST.vue        \r\n\r\n// 基于WS的流式合成\r\n        async getTtsChunkWavWS(){\r\n            if(this.ws.readyState != this.ws.OPEN){\r\n                this.$message.error(\"websocket 链接失败，请检查 Websocket 后端服务是否正确开启\")\r\n                return\r\n            }\r\n            // 初始化 chunks\r\n            chunks = []\r\n            chunk_index = 0\r\n            reciveOver = false\r\n            _reset()\r\n            \r\n            this.streamingOnInit = false\r\n            this.streamingStopStatus = true\r\n            this.streamingContinueStatus = true\r\n\r\n            this.streamingSendStamp = Date.now()\r\n            this.ws.send(this.textarea)   ---这里访问服务端报错， 需要是一个json 就算该对了流程也不对，需要start end之类的 需要改进\r\n        },",
        "state": "open",
        "user": "forever1dream",
        "closed_by": null,
        "created_at": "2024-08-21T12:41:58+00:00",
        "updated_at": "2024-08-23T10:05:33+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3832,
        "title": "如何让TTS生成女性声音",
        "body": "## General Question\r\n\r\n目前TTS默认的是男性声音。如何让TTS生成女性声音，需要改哪里，大伙有懂得可以指导一下，",
        "state": "open",
        "user": "WeiguangHan",
        "closed_by": null,
        "created_at": "2024-08-23T08:29:48+00:00",
        "updated_at": "2025-04-26T03:46:16+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "WeiguangHan",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3833,
        "title": "nano运行报错 KeyError: 'result'",
        "body": "在Nono板端，python版本3.7\r\n![1](https://github.com/user-attachments/assets/29ce2beb-ccaf-449e-84ba-28ea313df569)\r\n![0](https://github.com/user-attachments/assets/5cf6c8b9-0927-4d54-821a-945eb0a577e3)\r\n",
        "state": "open",
        "user": "wzd129",
        "closed_by": null,
        "created_at": "2024-08-27T06:03:00+00:00",
        "updated_at": "2025-04-26T03:46:14+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3834,
        "title": "请问Paddlespeech有支持Intel的GPU吗[e.g. Arc 770]",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "WeiguangHan",
        "closed_by": null,
        "created_at": "2024-08-27T13:15:05+00:00",
        "updated_at": "2025-04-26T03:46:15+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3838,
        "title": "ModuleNotFoundError: No module named 'swig' on CentOS9 when install M2Crypto",
        "body": "I get below printout when running  pip install M2Crypto, seems swig could not be found, but actually it was installed sucessfully, I can found them in path /usr/local/bin/. What should I do to resolve this issue?\r\n\r\n**********************************************************\r\n    INFO:spawn:swig -python -I/usr/lib/gcc/x86_64-redhat-linux/11/include -I/usr/local/include -I/usr/include -D__x86_64__ -I/usr/include/python3.9 -I/usr/include/openssl -includeall -builtin -outdir build/lib.linux-x86_64-cpython-39/M2Crypto -o src/SWIG/_m2crypto_wrap.c src/SWIG/_m2crypto.i\r\n      Traceback (most recent call last):\r\n        File \"/usr/local/bin/swig\", line 5, in <module>\r\n          from swig import swig\r\n      ModuleNotFoundError: No module named 'swig'\r\n      error: command '/usr/local/bin/swig' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for M2Crypto\r\nFailed to build M2Crypto\r\nERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (M2Crypto)\r\n***************************************************************\r\n\r\nroot@vultr ~]# pip list | grep swig\r\nswig                4.2.1\r\n\r\n[root@vultr ~]# ls /usr/local/bin/swig\r\n/usr/local/bin/swig\r\n[root@vultr ~]# ls /usr/local/bin/\r\npip  pip3  pip3.9  swig  swig4.0\r\n[root@vultr ~]# \r\n",
        "state": "open",
        "user": "Fenglinhsh",
        "closed_by": null,
        "created_at": "2024-09-03T15:19:50+00:00",
        "updated_at": "2025-04-26T03:46:13+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3839,
        "title": "[TTS] 示例能成功运行，但启动服务调用接口无法成功返回结果",
        "body": "我的padllepaddle-gpu 版本为2.5.1 paddlespeech为develop版\r\n\r\n采用示例paddlespeech asr --lang zh --input zh.wav 能成功运行并输出结果\r\n<img width=\"1055\" alt=\"af73bad789661de88febafc8c718613\" src=\"https://github.com/user-attachments/assets/18967a37-b3e3-4441-9d5c-6e69d35f4003\">\r\n但启动服务paddlespeech_server start --config_file ./paddlespeech/server/conf/application.yaml后报错\r\n<img width=\"1035\" alt=\"d3f15e3300656c5add2359fd9461c45\" src=\"https://github.com/user-attachments/assets/7ca9678c-9ae4-46fc-8a4b-4487969a9d9b\">\r\n \r\n\r\n",
        "state": "open",
        "user": "pphgood",
        "closed_by": null,
        "created_at": "2024-09-04T03:38:36+00:00",
        "updated_at": "2024-09-14T06:05:10+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "ximply"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3840,
        "title": "移动端适配",
        "body": "## Feature Request\r\n\r\n进行移动端适配，隔壁paddleOCR有这个工作，speech这边有相关工作嘛\r\n",
        "state": "closed",
        "user": "JameWade",
        "closed_by": "JameWade",
        "created_at": "2024-09-05T06:46:38+00:00",
        "updated_at": "2024-09-05T06:52:08+00:00",
        "closed_at": "2024-09-05T06:52:07+00:00",
        "comments_count": [
            "JameWade"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 3853
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3849,
        "title": "如何在android上使用asr",
        "body": "## Feature Request\r\n\r\n在demo中只找到了tts，是否可以把模型转化为nb格式然后使用paddle lite，如果可以的话要如何转化呢\r\n",
        "state": "open",
        "user": "JameWade",
        "closed_by": null,
        "created_at": "2024-09-18T06:20:55+00:00",
        "updated_at": "2024-09-26T09:36:59+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3850,
        "title": "关于fastspeech2流式推理的疑问",
        "body": "1. fastspeech2推理时的batch size设置为1，这是否意味着一个请求处理结束，模型才会处理下一个请求？还是说因为async，模型能够同时对多个请求进行推理？如果是后者，与真正的batch推理在性能上是否仍有一定的差距？\r\n2. 我也查看了其它开源的TTS项目，似乎都不支持按batch进行推理。这是否是因为TTS模型相比于LLM，在batch推理上实现比较困难？还是说batch推理会增大响应时间，导致实时性更差？\r\n",
        "state": "open",
        "user": "world1tree",
        "closed_by": null,
        "created_at": "2024-09-18T08:09:37+00:00",
        "updated_at": "2025-04-26T03:46:12+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3851,
        "title": "安装问题",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n有没有一个标准的环境，我去试试，我用了py3.8 py3.9都是安装报错",
        "state": "closed",
        "user": "dididiskq",
        "closed_by": "dididiskq",
        "created_at": "2024-09-19T05:46:36+00:00",
        "updated_at": "2024-09-20T06:18:48+00:00",
        "closed_at": "2024-09-20T06:18:48+00:00",
        "comments_count": [
            "dididiskq",
            "dididiskq"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3852,
        "title": "昇腾910B低版本paddlepaddle安装适配问题",
        "body": "目前在高版本paddlepaddle上执行train.py时遇到 https://github.com/PaddlePaddle/PaddleSpeech/issues/3442 相同问题。\r\n但是在华为昇腾910B上无法安装paddlepaddle==2.4.2版本的库，是否有对应的安装方法。\r\n",
        "state": "open",
        "user": "zhangxiangchn",
        "closed_by": null,
        "created_at": "2024-09-23T02:44:04+00:00",
        "updated_at": "2025-04-26T03:46:11+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3855,
        "title": "想要在iOS和android平台上实现离线语音识别和语音合成功能",
        "body": "请问能够提供相应的示例，或者编译步骤。",
        "state": "open",
        "user": "labolado",
        "closed_by": null,
        "created_at": "2024-09-26T06:20:38+00:00",
        "updated_at": "2025-04-26T03:46:07+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "zxcd",
            "csukuangfj",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3859,
        "title": "ASR模型测试异常",
        "body": "## General Question\r\n环境和相关包：\r\n昇腾910B，安装的paddle相关包如下\r\npaddle2onnx                 1.2.9\r\npaddleaudio                 1.0.2\r\npaddlefsl                   1.1.0\r\npaddlenlp                   2.5.2\r\npaddlepaddle                2.5.2\r\npaddleslim                  2.3.4\r\npaddlespeech                1.3.0\r\npaddlespeech-feat           0.1.0\r\n\r\n![image](https://github.com/user-attachments/assets/81134ad2-4cc4-4bc4-be6c-577a2fff810d)\r\npaddlespeech asr --lang zh --input zh.wav 可以正确进行语音识别\r\n\r\n根据/examples/aishell/asr1/README.md 中的步骤可以正常训练，在执行模型测试的时候出现如下异常\r\n<img width=\"1049\" alt=\"image\" src=\"https://github.com/user-attachments/assets/c4bddd8b-19b9-48b4-a984-bfc1f39b82cb\">\r\n除了上述报错还有一个问题，上述./local/test.sh脚本只传了两个参数，但是test.sh 脚本中接收了3个参数？\r\n![image](https://github.com/user-attachments/assets/35166e6c-14ad-4132-a34b-81cba4314513)\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "zhangxiangchn",
        "closed_by": "zhangxiangchn",
        "created_at": "2024-10-09T08:37:21+00:00",
        "updated_at": "2024-10-10T02:36:48+00:00",
        "closed_at": "2024-10-10T02:36:48+00:00",
        "comments_count": [
            "zhangxiangchn"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3861,
        "title": "请问语音识别项目支持的最低Linux内核版本，我在4.9.0-8-linx-security-amd64系统中运行语音识别例子报错",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\npaddlepaddle==2.5.2\r\npaddlespeech==1.4.0\r\npython==3.9\r\nGLIBC：2.19\r\nimport paddlespeech.cli会直接报错非法指令。\r\n查看logs显示trap invalid opcode。\r\n请问是Linux内核版本问题还是硬件问题。\r\n",
        "state": "open",
        "user": "Heaven-zeng",
        "closed_by": null,
        "created_at": "2024-10-16T05:57:19+00:00",
        "updated_at": "2025-04-26T03:46:09+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3862,
        "title": "pip 都下不下来 你要干啥？",
        "body": null,
        "state": "open",
        "user": "5204AIO",
        "closed_by": null,
        "created_at": "2024-10-17T12:48:31+00:00",
        "updated_at": "2024-11-14T04:31:19+00:00",
        "closed_at": null,
        "comments_count": [
            "5204AIO",
            "5204AIO",
            "Ray961123",
            "yuhldr",
            "5204AIO",
            "chenmj201601"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3863,
        "title": "跑kws demo 获取fbank时候总是卡在 AssertionError: choose a window size 400 that is [2, 1]",
        "body": "## Others\r\n```\r\n    feat_func = lambda waveform, sr: fbank(\r\n        waveform=paddle.to_tensor(waveform).unsqueeze(0),\r\n        sr=sr,\r\n        frame_shift=10,\r\n        frame_length=25,\r\n        n_mels=80)\r\n\r\n    keword_hi = feat_func(*paddleaudio.load('/home/test/nn_workspace/mine_keyword/hey_snips.wav'))\r\n```\r\n总是会报错  AssertionError: choose a window size 400 that is [2, 1]\r\n\r\n这是版本\r\n```\r\npackaging                 23.2                     pypi_0    pypi\r\npaddle-bfloat             0.1.7                    pypi_0    pypi\r\npaddle2onnx               1.2.11                   pypi_0    pypi\r\npaddleaudio               1.1.0                    pypi_0    pypi\r\npaddlefsl                 1.1.0                    pypi_0    pypi\r\npaddlenlp                 2.7.2                    pypi_0    pypi\r\npaddlepaddle-gpu          2.5.1                    pypi_0    pypi\r\npaddlesde                 0.2.5                    pypi_0    pypi\r\npaddleslim                2.6.0                    pypi_0    pypi\r\npaddlespeech              0.0.0                    pypi_0    pypi\r\npaddlespeech-feat         0.1.0                    pypi_0    pypi\r\npandas                    2.2.3                    pypi_0    pypi\r\nparameterized             0.9.0                    pypi_0    pypi\r\nparso                     0.8.4                    pypi_0    pypi\r\npathos                    0.2.8                    pypi_0    pypi\r\npattern-singleton         1.2.0                    pypi_0    pypi\r\n```\r\n\r\n",
        "state": "closed",
        "user": "razor7788",
        "closed_by": "razor7788",
        "created_at": "2024-10-17T18:29:32+00:00",
        "updated_at": "2024-10-21T08:54:57+00:00",
        "closed_at": "2024-10-21T08:54:56+00:00",
        "comments_count": [
            "Ray961123",
            "razor7788"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3864,
        "title": "mb_melgan训练",
        "body": "目前测试下来mb_melgan_csmsc的推理速度满足离线环境下CPU实时推理，其他的VOC模型都太慢，但是我用fastspeech2_mix微调克隆了一个男生音色后，使用mb_melgan_csmsc推理音色就不对，只能使用aishell3数据集训练的VOC模型，而mb_melgan只有csmsc数据集训练的模型，问题来了，如何使用aishell3数据训练一个mb_melgan模型，求指点\r\n",
        "state": "open",
        "user": "cjpnice",
        "closed_by": null,
        "created_at": "2024-10-22T13:57:34+00:00",
        "updated_at": "2025-06-27T02:32:54+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "elliotzheng",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3866,
        "title": "ctc_decoders arm环境编译失败",
        "body": "ctc_decoders arm环境编译失败",
        "state": "open",
        "user": "youngdream11",
        "closed_by": null,
        "created_at": "2024-11-01T07:41:17+00:00",
        "updated_at": "2024-11-06T02:08:58+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3867,
        "title": "语音识别本地文件的时候每次都要加载模型",
        "body": "识别一个简短的音频也需要4s多，原因是加载模型需要这么长时间，为什么这个不能像其他的算法框架一样，可以预加载模型，然后直接去识别文件呢？",
        "state": "open",
        "user": "Alex86706",
        "closed_by": null,
        "created_at": "2024-11-01T08:00:05+00:00",
        "updated_at": "2025-04-26T03:46:05+00:00",
        "closed_at": null,
        "comments_count": [
            "Liyulingyue",
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3868,
        "title": "TTS流式服务如何设置并发，为什么建立多个连接的session是一样的。",
        "body": "## General Question\r\n![image](https://github.com/user-attachments/assets/74f6c2b3-949d-47e2-9acf-af647b4cb3f1)\r\n\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "Dollhan",
        "closed_by": null,
        "created_at": "2024-11-02T00:51:27+00:00",
        "updated_at": "2025-04-26T03:46:04+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3870,
        "title": "【Hackathon 7th】Fundable Projects No.7",
        "body": "# 说明\r\nPaddleSpeech 是基于飞桨 PaddlePaddle 的语音方向的开源套件，囊括语音识别、语音合成、语音唤醒、声纹识别等多种语音常用功能的支持。由于近期 Paddle 新版本的升级存在不兼容部分（如 paddle.fluid API 全面退场，PIR + predictor 升级， 0-d tensor，view 行为修改等），需要重新对 PaddleSpeech 中的模型进行适配开发与回归测试，保证套件正常运转。\r\n\r\n本Issue说明关了PaddleSpeech的改动，现有教程、文档、模型的验证和支持等情况。\r\n\r\n## Docker改进\r\n为了适配最新版本Paddlepaddle(版本3.0.0)，对Docker进行升版 https://github.com/PaddlePaddle/PaddleSpeech/pull/3871\r\n\r\n## Demos\r\n本节记录了demos运行验证记录，标识中，N为无故障，E为存在问题，W为存在警告，U为未运行。\r\n### 测试方法\r\n1. 在Aistudio V100 32G 环境下，paddlepaddle-gpu版本为3.0，clone本仓库\r\n2. 手动删除 setup.py 中对paddlepaddle-gpu的依赖\r\n3. 通过 pip install . --user 安装PaddleSpeech\r\n4. 运行Demos中相关命令\r\n\r\n### 测试结论与记录\r\n大部分Python API调用正常，部分问题如下：\r\n1. 执行speech_ssl demo时，有错误 TypeError: Wav2vec2ASR.forward() missing 3 required positional arguments: 'wavs_lens_rate', 'target', and 'target_lens'\r\n2. 执行style_fs2 demo时，存在0-D tensor的warning\r\n3. 执行whisper demo时，如果输入文件采样率不是16000，会因Paddle侧算子不支持的数据类型报错。\r\n\r\n|名称|说明|问题标识|PR|\r\n|---|---|---|---|\r\n|TTSAndroid|无相关环境，未运行|U|\r\n|TTSArmLinux|Aistudio环境不好，Cmake未成功|U|\r\n|TTSCppFrontend|Aistudio环境不好，Cmake未成功|U|\r\n|asr_deployment|基于SpeechX，暂不验证|U|\r\n|audio_content_search|未运行|U|\r\n|audio_searching|未运行|U|\r\n|audio_tagging|Python 成功运行|N|\r\n|automatic_video_subtitiles|Python 成功运行|N|\r\n|custom_streaming_asr|未运行|U|\r\n|keyword_spotting|Python 成功运行|N|\r\n|metaverse|未运行，该脚本和 PaddleGAN 绑定，可能会冲突|U|\r\n|punctuation_restoration|Python 成功运行|N|\r\n|speaker_verification|Python 成功运行|N|\r\n|speech_recognition|Python 成功运行|N|\r\n|speech_server|未运行|U|\r\n|speech_ssl|TypeError: Wav2vec2ASR.forward() missing 3 required positional arguments: 'wavs_lens_rate', 'target', and 'target_lens'|E|https://github.com/PaddlePaddle/PaddleSpeech/pull/3872|\r\n|speech_translation|Python 运行成功|N|\r\n|speech_web|未运行|U|\r\n|story_talker|Numpy版本导致了错误，AttributeError: module 'numpy' has no attribute 'complex'.|E|\r\n|streaming_asr_server|未运行|U|\r\n|streaming_tts_server|未运行|U|\r\n|streaming_tts_serving_fastdeploy|未运行|U|\r\n|style_fs2|成功运行，存在warning /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2082: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].|W|\r\n|text_to_speech|Python 成功运行|N|\r\n|whisper|未配置好16000的wav导致没运行成功，此外转码后代码会由于Paddle算子报错|E|\r\n\r\n## Examples\r\n待补充\r\n\r\n## Models\r\n待补充",
        "state": "closed",
        "user": "Liyulingyue",
        "closed_by": "Liyulingyue",
        "created_at": "2024-11-03T10:05:06+00:00",
        "updated_at": "2025-01-15T13:25:26+00:00",
        "closed_at": "2025-01-15T13:25:26+00:00",
        "comments_count": [
            "yinfan98",
            "yinfan98",
            "GreatV",
            "Liyulingyue"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3873,
        "title": "[TTS] Occasionally, there are noise issues with synthesized voices on Android",
        "body": "I'm using paddlespeech for speech synthesis on Android, but I'm finding that I get noise issues frequently\r\n\r\nhere https://github.com/ZTMIDGO/TTS",
        "state": "open",
        "user": "ZTMIDGO",
        "closed_by": null,
        "created_at": "2024-11-05T18:44:26+00:00",
        "updated_at": "2024-11-06T02:14:12+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3879,
        "title": "【Hackathon 7th】运行 Examples 脚本与导出模型到 PIR 说明",
        "body": "# 简述\r\n本文以 DeepSpeech2 为例说明如何在 Paddle 3.0 下，导出 PIR格式 的新静态图。虽然本文主要关注如何进行导出PIR，但验证 Example 文件夹下的脚本的流程与遇到的问题基本与本文类似，可以在测试前，先阅读本Issue。\r\n\r\n本文的主要说明内容如下\r\n- 如何将 DeepSpeech2 运行测试、导出、验证导出的流程\r\n- 问题说明1：Example中存在说明文档和脚本不匹配的问题，应参考脚本重新写命令，修复见 https://github.com/PaddlePaddle/PaddleSpeech/pull/3878\r\n- 问题说明2：py文件存在 字段解析重复添加问题，删除对应代码即可，修复见 https://github.com/PaddlePaddle/PaddleSpeech/pull/3878\r\n- 问题说明3：部分历史代码已经不兼容，直接移除即可\r\n- 问题说明4：导出PIR后，当前代码可能存在问题，导致无法加载【需要讨论】\r\n\r\n# 补充\r\n经验证，能够成功导出，但读取逻辑仍有一些问题，待修复。\r\n\r\n# 步骤\r\n## 准备环境\r\n```\r\n# 安装Paddle 3.0\r\n# 可以直接在Aistudio创建一个3.0的环境\r\n\r\n# 克隆本仓库\r\n# 如果Python版本为3.10，需要等待 https://github.com/PaddlePaddle/PaddleSpeech/pull/3877 合入后克隆\r\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git\r\n\r\n# 检查setup.py，如果存在对paddle版本的依赖，去除该依赖\r\n\r\ncd PaddleSpeech\r\n# 在Aistudio环境中，需要使用 pip install . --user，安装后将 /home/aistudio/.local/bin 加入环境变量\r\npip install .\r\n```\r\n\r\n## 准备运行数据\r\n```\r\n# 确保当前目录为 PaddleSpeech\r\n# 进入deepspeech的脚本页面\r\ncd examples/aishell/asr0\r\n\r\n# 配置环境\r\nsource path.sh\r\nsource ${MAIN_ROOT}/utils/parse_options.sh\r\n\r\n# 数据预处理，最好执行这一步\r\n# 如果在 PaddleSpeech/dataset/aishell/下没有 data_aishell.tgz，会自动下载，建议手动从更快的链接下载后放在此文件夹 \r\nbash ./local/data.sh\r\n``` \r\n\r\n## 下载模型\r\n从 https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/resource/pretrained_models.py 下载对应的模型，并解压\r\n```\r\n# 当前目录 PaddleSpeech/examples/aishell/asr0\r\n# 以 deepspeech2offline_aishell-zh-16k 为例，可以resource 文件中获取对应的下载链接\r\nwget https://paddlespeech.bj.bcebos.com/s2t/aishell/asr0/asr0_deepspeech2_offline_aishell_ckpt_1.0.1.model.tar.gz\r\n# 有一些文件解压时会覆盖原有文件，不是每个tar.gz包里的内容都是好的，处理其他模型时建议将原有文件夹（此处为asr0）内容做好备份\r\ntar xzvf asr0_deepspeech2_offline_aishell_ckpt_1.0.1.model.tar.gz\r\n```\r\n\r\n## 运行测试\r\n### 推理\r\n推理采用动态图推理，会遇到重复添加控制台变量的问题，将对应脚本中 parser.add_argument 删除即可。\r\n以 PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test_wav.py 为例，按如下所示注释即可。修复PR见 https://github.com/PaddlePaddle/PaddleSpeech/pull/3878\r\n```\r\nif __name__ == \"__main__\":\r\n    # 在这里已经添加了 audio_file\r\n    parser = default_argument_parser()\r\n    # 下面几行如果不注释，就会报错\r\n    # parser.add_argument(\"--audio_file\", type=str, help='audio file path')\r\n    # save asr result to\r\n    # parser.add_argument(\r\n    #     \"--result_file\", type=str, help=\"path of save the asr result\")\r\n    args = parser.parse_args()\r\n    print_arguments(args, globals())\r\n    if not os.path.isfile(args.audio_file):\r\n        print(\"Please input the audio file path\")\r\n        sys.exit(-1)\r\n    check(args.audio_file)\r\n```\r\n\r\n推理部分的执行命令如下\r\n```\r\nwget -nc https://paddlespeech.bj.bcebos.com/datasets/single_wav/zh/demo_01_03.wav -P data/\r\nCUDA_VISIBLE_DEVICES= ./local/test_wav.sh conf/deepspeech2.yaml conf/tuning/decode.yaml exp/deepspeech2/checkpoints/avg_10 data/demo_01_03.wav\r\n```\r\n\r\n## 静态图导出\r\n会遇到的问题是\r\n1. 见推理部分的问题描述，解决方法一致\r\n2. logger.info(f\"Export code: {static_model.forward.code}\") 执行报错，直接注释此语句即可，在 PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py 333行附近。\r\n3. README和脚本执行逻辑不匹配。查阅脚本代码，重新配置命令即可。\r\n\r\n可执行的命令如下：\r\n```\r\n# 如果你希望在PIR模式下导出，执行：\r\n# export FLAGS_enable_pir_api=1\r\n\r\n./local/export.sh conf/deepspeech2.yaml exp/deepspeech2/checkpoints/avg_10 exp/deepspeech2/checkpoints/avg_10.jit\r\n```\r\n\r\n不配置 FLAGS_enable_pir_api=1，导出结果为pdmodel，pdiparams。\r\n\r\n配置了 FLAGS_enable_pir_api=1，导出结果为json，pdiparams。\r\n\r\n## 静态图测试\r\n会遇到的问题是\r\n1. 见推理部分的问题描述，解决方法一致\r\n2. README和脚本执行逻辑不匹配。查阅脚本代码，重新配置命令即可。\r\n3. 现有脚本只支持老版本静态图模型\r\n\r\n对于前两个问题，修改py文件，更改控制台命令如下\r\n```\r\nCUDA_VISIBLE_DEVICES= ./local/test_export.sh conf/deepspeech2.yaml conf/tuning/decode.yaml exp/deepspeech2/checkpoints/avg_10.jit\r\n```\r\n\r\n对于第三个问题，需要更改 /home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py 函数 setup_model(self) (在末尾部分)，修改方案有两个，都会报C++错误，应该与本次任务无关，是Paddle侧的问题。\r\n\r\n方案1：\r\n```\r\n    def setup_model(self):\r\n        super().setup_model()\r\n\r\n        # 如果存在新IR，以新IR格式加载\r\n        if os.path.exists(self.args.export_path + \".json\"):\r\n          deepspeech_config = inference.Config(\r\n              self.args.export_path + \".json\",\r\n              self.args.export_path + \".pdiparams\")\r\n        else:\r\n          deepspeech_config = inference.Config(\r\n              self.args.export_path + \".pdmodel\",\r\n              self.args.export_path + \".pdiparams\")\r\n\r\n        if (os.environ['CUDA_VISIBLE_DEVICES'].strip() != ''):\r\n            deepspeech_config.enable_use_gpu(100, 0)\r\n            deepspeech_config.enable_memory_optim()\r\n        deepspeech_predictor = inference.create_predictor(deepspeech_config)\r\n        self.predictor = deepspeech_predictor\r\n```\r\n\r\n方法2：\r\n```\r\n    def setup_model(self):\r\n        super().setup_model()\r\n        model_dir = os.path.dirname(self.args.export_path)\r\n        model_prefix = os.path.basename(self.args.export_path)\r\n        deepspeech_config = inference.Config(model_dir, model_prefix)\r\n\r\n        if (os.environ['CUDA_VISIBLE_DEVICES'].strip() != ''):\r\n            deepspeech_config.enable_use_gpu(100, 0)\r\n            deepspeech_config.enable_memory_optim()\r\n        deepspeech_predictor = inference.create_predictor(deepspeech_config)\r\n        self.predictor = deepspeech_predictor\r\n```\r\n\r\n方法1报错如下\r\n```\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle_infer::Predictor::Predictor(paddle::AnalysisConfig const&)\r\n1   std::unique_ptr<paddle::PaddlePredictor, std::default_delete<paddle::PaddlePredictor> > paddle::CreatePaddlePredictor<paddle::AnalysisConfig, (paddle::PaddleEngineKind)2>(paddle::AnalysisConfig const&)\r\n2   paddle::AnalysisPredictor::Init(std::shared_ptr<paddle::framework::Scope> const&, std::shared_ptr<paddle::framework::ProgramDesc> const&)\r\n3   paddle::AnalysisPredictor::PrepareProgram(std::shared_ptr<paddle::framework::ProgramDesc> const&)\r\n4   paddle::framework::NaiveExecutor::CreateVariables(paddle::framework::ProgramDesc const&, int, bool, paddle::framework::Scope*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1731192005 (unix time) try \"date -d @1731192005\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x0) received by PID 29222 (TID 0x7f6c61c9b740) from PID 0 ***]\r\n\r\n./local/test_export.sh: line 26: 29222 Segmentation fault      (core dumped) python3 -u ${BIN_DIR}/test_export.py --ngpu ${ngpu} --config ${config_path} --decode_cfg ${decode_config_path} --result_file ${jit_model_export_path}.rsl --export_path ${jit_model_export_path}\r\n```\r\n\r\n方法2报错如下\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test_export.py\", line 62, in <module>\r\n    main(config, args)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test_export.py\", line 30, in main\r\n    main_sp(config, args)\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/test_export.py\", line 25, in main_sp\r\n    exp.setup()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/training/trainer.py\", line 167, in setup\r\n    self.setup_model()\r\n  File \"/home/aistudio/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py\", line 640, in setup_model\r\n    deepspeech_predictor = inference.create_predictor(deepspeech_config)\r\nValueError: basic_string::_M_replace_aux\r\n```",
        "state": "closed",
        "user": "Liyulingyue",
        "closed_by": "Liyulingyue",
        "created_at": "2024-11-09T23:55:15+00:00",
        "updated_at": "2025-01-15T13:25:22+00:00",
        "closed_at": "2025-01-15T13:25:22+00:00",
        "comments_count": [
            "megemini",
            "Liyulingyue",
            "enkilee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3885,
        "title": "折腾了两天，安装不了，不是这依赖有问题，就是那莫名奇妙报个错，没法用",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "chenmj201601",
        "closed_by": "zxcd",
        "created_at": "2024-11-14T04:11:11+00:00",
        "updated_at": "2025-04-11T02:32:29+00:00",
        "closed_at": "2024-11-19T11:44:58+00:00",
        "comments_count": [
            "TianQi7723",
            "chenmj201601",
            "chenmj201601",
            "wukongbuku",
            "TianQi7723",
            "TianQi7723",
            "chenmj201601",
            "chenmj201601",
            "chenmj201601",
            "Ray961123",
            "zxcd",
            "chenmj201601",
            "DazzlingGalaxy",
            "yangzheng119"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3888,
        "title": "[TTS]XXXX",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [e.g. Ubuntu]\r\n - GCC/G++ Version [e.g. 8.3]\r\n - Python Version [e.g. 3.7]\r\n - PaddlePaddle Version [e.g. 2.0.0]\r\n - Model Version [e.g. 2.0.0]\r\n - GPU/DRIVER Informationo [e.g. Tesla V100-SXM2-32GB/440.64.00]\r\n - CUDA/CUDNN Version [e.g. cuda-10.2]\r\n - MKL Version\r\n- TensorRT Version\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "state": "closed",
        "user": "fatiya987jajn",
        "closed_by": "zxcd",
        "created_at": "2024-11-14T18:45:54+00:00",
        "updated_at": "2024-11-20T04:08:16+00:00",
        "closed_at": "2024-11-20T04:08:16+00:00",
        "comments_count": [
            "Ray961123"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3899,
        "title": "按照源码安装问题：paddlepaddle版本以及依赖版本问题",
        "body": "按照源码安装有三个问题：\r\n1.README中相关依赖要求paddlepaddle <= 2.5.1，实际上能找到的最低版本是2.5.2，安装方法中先决条件是最新版本的 paddlepaddle，到底是用最早版本还是最新版本？\r\n2.昇腾NPU只有一个对应版本paddlepaddle==3.0.0b2，对应的paddlespeech版本是多少？\r\n3.python3.8/3.9/3.10 安装pip install pytest-runner之后，到pip install .这一步，各种报错python版本不符合、没有相应版本的依赖，有没有最新的setup.py文件？\r\n\r\n_Originally posted by @can-glan in https://github.com/PaddlePaddle/PaddleSpeech/issues/2150#issuecomment-2487807366_\r\n            ",
        "state": "open",
        "user": "can-glan",
        "closed_by": null,
        "created_at": "2024-11-20T08:10:48+00:00",
        "updated_at": "2025-04-26T03:45:58+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "Liyulingyue",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3893,
        "title": "可以CPU环境安装吗？",
        "body": "## General Question\r\n\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "open",
        "user": "chenmj201601",
        "closed_by": null,
        "created_at": "2024-11-16T09:25:15+00:00",
        "updated_at": "2025-04-26T03:45:59+00:00",
        "closed_at": null,
        "comments_count": [
            "chenmj201601",
            "Liyulingyue",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3902,
        "title": "在Paddle 3.0 下无法加载导出的Pir模型进行推理",
        "body": "复现流程：\r\n1. git clone https://github.com/PaddlePaddle/PaddleSpeech.git\r\n2. 修改 PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/model.py 函数 setup_model(self)(在末尾部分)为\r\n```\r\n    def setup_model(self):\r\n        super().setup_model()\r\n\r\n        # 如果存在新IR，以新IR格式加载\r\n        if os.path.exists(self.args.export_path + \".json\"):\r\n          deepspeech_config = inference.Config(\r\n              self.args.export_path + \".json\",\r\n              self.args.export_path + \".pdiparams\")\r\n        else:\r\n          deepspeech_config = inference.Config(\r\n              self.args.export_path + \".pdmodel\",\r\n              self.args.export_path + \".pdiparams\")\r\n\r\n        if (os.environ['CUDA_VISIBLE_DEVICES'].strip() != ''):\r\n            deepspeech_config.enable_use_gpu(100, 0)\r\n            deepspeech_config.enable_memory_optim()\r\n        deepspeech_predictor = inference.create_predictor(deepspeech_config)\r\n        self.predictor = deepspeech_predictor\r\n```\r\n3. 以源码形式安装paddlespeech 和 paddlepaddle\r\n4. cd PaddleSpeech/examples/aishell/asr0\r\n5. 运行如下命令（默认的数据集处理可能比较耗时，另行获取链接下载数据放在指定路径更快一点）\r\n```\r\nsource path.sh\r\nsource ${MAIN_ROOT}/utils/parse_options.sh\r\nbash ./local/data.sh\r\nwget https://paddlespeech.bj.bcebos.com/s2t/aishell/asr0/asr0_deepspeech2_offline_aishell_ckpt_1.0.1.model.tar.gz\r\ntar xzvf asr0_deepspeech2_offline_aishell_ckpt_1.0.1.model.tar.gz\r\nsource path.sh\r\n./local/export.sh conf/deepspeech2.yaml exp/deepspeech2/checkpoints/avg_10 exp/deepspeech2/newir/avg_10.jit\r\nCUDA_VISIBLE_DEVICES=0 ./local/test_export.sh conf/deepspeech2.yaml conf/tuning/decode.yaml exp/deepspeech2/newir/avg_10.jit\r\n```\r\n\r\n运行环境为Aistudio框架开发环境，Paddle 3.0+Python 3.8+CUDA 12.0\r\n\r\n报错如下：\r\n![974FC61F3A4334C63DD230FD7DCDF990](https://github.com/user-attachments/assets/7e34c80d-4cd3-487a-a3b4-be6a4ee7c9f9)\r\n",
        "state": "closed",
        "user": "Liyulingyue",
        "closed_by": "Liyulingyue",
        "created_at": "2024-11-22T11:37:53+00:00",
        "updated_at": "2025-01-15T13:24:33+00:00",
        "closed_at": "2025-01-15T13:24:33+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3908,
        "title": "开启asr流服务，客户端访问服务端报错",
        "body": " [   ERROR] - <method '_getitem_index_not_tensor' of 'Tensor' objects> returned a result with an exception set\r\nOverflowError: Python int too large to convert to C long",
        "state": "open",
        "user": "l64262631",
        "closed_by": null,
        "created_at": "2024-11-23T09:29:20+00:00",
        "updated_at": "2025-04-26T03:45:57+00:00",
        "closed_at": null,
        "comments_count": [
            "Ray961123",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3909,
        "title": "源码安装paddlespeech报错",
        "body": "![image](https://github.com/user-attachments/assets/82d83197-6c41-4a1e-945b-9373b0dd998c)\r\n\r\n源码安装，\r\n\r\n`pip install -e .`\r\n\r\n这个报错是怎么回事，g++安装了\r\n\r\n![image](https://github.com/user-attachments/assets/43da1857-dd3b-4b2a-8769-f6d73ae17b69)\r\n",
        "state": "closed",
        "user": "chenmj201601",
        "closed_by": "zxcd",
        "created_at": "2024-11-26T05:25:37+00:00",
        "updated_at": "2025-02-05T07:03:11+00:00",
        "closed_at": "2025-02-05T07:03:11+00:00",
        "comments_count": [
            "druphliu",
            "chenmj201601",
            "Ray961123"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3910,
        "title": "实时语音识别环境干扰降噪处理",
        "body": "如题，测试时候发现识别能力不错，但是容易被环境内的其他声音干扰，这个怎么解决呢",
        "state": "closed",
        "user": "druphliu",
        "closed_by": "zxcd",
        "created_at": "2024-11-26T07:52:14+00:00",
        "updated_at": "2025-02-05T07:03:21+00:00",
        "closed_at": "2025-02-05T07:03:21+00:00",
        "comments_count": [
            "Ray961123",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3922,
        "title": "如何在实际应用中提升模型效率？",
        "body": "## General Question\r\n在实际应用中要怎样提升在线模型（Streaming）的效率呢？\r\n语言模型可以通过batch size进行批量推理，来提升推理效率；可以使用多实例来应对推理请求并发的情况；可以使用TensorRT来优化推理速度。\r\n请问对于PaddleSpeech在线模型，上面哪些措施是可行的，有没有更好的推荐？\r\n<!--\r\nBefore asking a question, make sure you have:\r\n- Baidu/Google your question.\r\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\r\n- Read the documentation:\r\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\r\n  - [Doc](https://paddlespeech.readthedocs.io/)\r\n-->\r\n",
        "state": "closed",
        "user": "mzgcz",
        "closed_by": "zxcd",
        "created_at": "2024-12-03T00:58:29+00:00",
        "updated_at": "2025-02-05T07:02:45+00:00",
        "closed_at": "2025-02-05T07:02:45+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3929,
        "title": "请问paddlespeech啥时候支持paddle大于2.5.1的版呀",
        "body": "请问paddlespeech啥时候支持paddle大于2.5.1的版本呀，现在paddle都已经3.0了，跟不上呀",
        "state": "closed",
        "user": "chenmj201601",
        "closed_by": "zxcd",
        "created_at": "2024-12-04T08:44:22+00:00",
        "updated_at": "2025-01-23T03:07:42+00:00",
        "closed_at": "2025-01-23T03:07:42+00:00",
        "comments_count": [
            "yinfan98",
            "wangdach",
            "sxzd1473",
            "Liyulingyue"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3938,
        "title": "[S2T]deepspeech模型数据处理报错",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\r\n\r\nIf you've found a bug then please create an issue with the following information:\r\n\r\n**Describe the bug**\r\n### 环境1 PaddleSpeech-dev分支\r\n基于PaddleSpeech的develop分支，搭建paddle 环境，py3.10 + paddle-dev分支whl包\r\nPaddleSpeech/examples/librispeech/asr0/下指导执行数据处理操作\r\n最终的train-500会失败报错\r\n\r\n\r\n```\r\n/workspace/PaddleSpeech/examples/librispeech/asr0 {develop *} bash \r\nrun.sh --stage 0 --stop_stage 0 \r\ncheckpoint name deepspeech2\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/test-clean.\r\nCreating manifest data/manifest.test-clean ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/dev-clean.\r\nCreating manifest data/manifest.dev-clean ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/train-clean-100.\r\nCreating manifest data/manifest.train-clean-100 ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/test-other.\r\nCreating manifest data/manifest.test-other ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/dev-other.\r\nCreating manifest data/manifest.dev-other ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/train-clean-360.\r\nCreating manifest data/manifest.train-clean-360 ...\r\nSkip downloading and unpacking. Data already exists in /workspace/PaddleSpeech/dataset/librispeech/train-other-500.\r\nCreating manifest data/manifest.train-other-500 ...\r\nCreating manifest data/manifest.train-other-500 ...\r\nmultiprocessing.pool.RemoteTraceback: \r\n\"\"\"\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\r\n    result = (True, func(*args, **kwds))\r\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\r\n    return list(itertools.starmap(args[0], args[1]))\r\n  File \"/workspace/PaddleSpeech/dataset/librispeech/librispeech.py\", line 146, in prepare_dataset\r\n    create_manifest(target_dir, manifest_path)\r\n  File \"/workspace/PaddleSpeech/dataset/librispeech/librispeech.py\", line 98, in create_manifest\r\n    audio_data, samplerate = soundfile.read(audio_filepath)\r\n  File \"/usr/local/lib/python3.10/dist-packages/soundfile.py\", line 285, in read\r\n    with SoundFile(file, 'r', samplerate, channels,\r\n  File \"/usr/local/lib/python3.10/dist-packages/soundfile.py\", line 658, in __init__\r\n    self._file = self._open(file, mode_int, closefd)\r\n  File \"/usr/local/lib/python3.10/dist-packages/soundfile.py\", line 1216, in _open\r\n    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\r\nsoundfile.LibsndfileError: Error opening '/workspace/PaddleSpeech/dataset/librispeech/train-other-500/LibriSpeech/train-other-500/5480/41791/5480-41791-0000.flac': System error.\r\n\"\"\"\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/workspace/PaddleSpeech/dataset/librispeech/librispeech.py\", line 186, in <module>\r\n    main()\r\n  File \"/workspace/PaddleSpeech/dataset/librispeech/librispeech.py\", line 180, in main\r\n    pool.starmap(prepare_dataset, tasks)\r\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 375, in starmap\r\n    return self._map_async(func, iterable, starmapstar, chunksize).get()\r\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 774, in get\r\n    raise self._value\r\nsoundfile.LibsndfileError: Error opening '/workspace/PaddleSpeech/dataset/librispeech/train-other-500/LibriSpeech/train-other-500/5480/41791/5480-41791-0000.flac': System error.\r\nPrepare LibriSpeech failed. Terminated.\r\nλ tjdm-isa-ai-p800node13 /workspace/PaddleSpeech/examples/librisp\r\n```\r\n![image](https://github.com/user-attachments/assets/0ae5ca24-4e67-4f28-a12d-1f6b273c293e)\r\n\r\n\r\n\r\n### 环境2 PaddleSpeech-tag v2.1.1分支\r\n作为对比，在paddlespeech的tag v2.1.1进行了同样的尝试，当然只能使用paddle的老版本。没有遇到这个问题，数据处理成功且能正常训练deepspeech模型。\r\n将此处的librispeech数据处理的manifest数据导出给 环境1。启动训练会报错。\r\n\r\n```\r\n# 启动命令\r\npython3 -u  /workspace/PaddleSpeech/paddlespeech/s2t/exps/deepspeech2/bin/train.py --nxpu 1 --ngpu 0 --config conf/deepspeech2.yaml --output exp/deepspeech2 --seed 0\r\n\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/0bfe93e2-5916-4203-a487-571d57d67a24)\r\n\r\n",
        "state": "closed",
        "user": "wangdach",
        "closed_by": "zxcd",
        "created_at": "2024-12-06T09:13:43+00:00",
        "updated_at": "2025-02-05T07:02:21+00:00",
        "closed_at": "2025-02-05T07:02:21+00:00",
        "comments_count": [
            "wangdach",
            "Ray961123",
            "zxcd",
            "megemini"
        ],
        "labels": [
            "Bug",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3952,
        "title": "phone_id_map有什么代码方式或便捷方式将汉字转为phone_id吗？英语咋办",
        "body": "使用的demo：[https://github.com/chaos-zhou/PaddleSpeech/tree/develop/demos/TTSAndroid](https://github.com/chaos-zhou/PaddleSpeech/tree/develop/demos/TTSAndroid)\r\n想添加自定义的句子，需要使用phone_id_map逐个翻译拼音然后找对应编号吗？有没有快捷方式或者代码处理。\r\n\r\npaddle有没有简单api，如：paddle.toS(\"要转换的句子\")。\r\n\r\n刚接触。走过路过的大佬指点两下，谢谢",
        "state": "closed",
        "user": "zhaoyongjiang",
        "closed_by": "zxcd",
        "created_at": "2024-12-14T09:08:29+00:00",
        "updated_at": "2025-01-23T03:05:32+00:00",
        "closed_at": "2025-01-23T03:05:32+00:00",
        "comments_count": [
            "Ray961123",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3937,
        "title": "paddlespeech支持NPU训练吗？",
        "body": "我用paddlespeech在华为昇腾的服务器上进行语音识别的实验，该服务器有NPU环境，报错如下：\r\n![image](https://github.com/user-attachments/assets/7a39dcad-d869-4c3f-b5e4-fb7afae8d501)\r\n",
        "state": "closed",
        "user": "wenhuiwwh",
        "closed_by": "zxcd",
        "created_at": "2024-12-06T07:48:22+00:00",
        "updated_at": "2025-01-21T03:18:55+00:00",
        "closed_at": "2025-01-21T03:18:55+00:00",
        "comments_count": [
            "Ray961123",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3953,
        "title": "QuickStart paddlepaddle version",
        "body": "## Others\r\nIn attempting the Quick Start, I am finding \r\n```\r\n$ pip install paddlepaddle==2.4.1 -i https://mirror.baidu.com/pypi/simple\r\nLooking in indexes: https://mirror.baidu.com/pypi/simple\r\nERROR: Could not find a version that satisfies the requirement paddlepaddle==2.4.1 (from versions: none)\r\nERROR: No matching distribution found for paddlepaddle==2.4.1\r\n$ pip install paddlepaddle==2.5.1 -i https://mirror.baidu.com/pypi/simple\r\nLooking in indexes: https://mirror.baidu.com/pypi/simple\r\nERROR: Could not find a version that satisfies the requirement paddlepaddle==2.5.1 (from versions: none)\r\nERROR: No matching distribution found for paddlepaddle==2.5.1\r\n```\r\nIs there another recommended place to find a compatible paddlepaddle version? I looks like work continues to make paddlespeech compatible with paddlepaddle 3.\r\n```\r\n$ pip install paddlepaddle==2.5.1\r\nERROR: Could not find a version that satisfies the requirement paddlepaddle==2.5.1 (from versions: 2.6.0, 2.6.1, 2.6.2, 3.0.0b0, 3.0.0b1, 3.0.0b2)\r\nERROR: No matching distribution found for paddlepaddle==2.5.1\r\n$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 24.04.1 LTS\r\nRelease:        24.04\r\nCodename:       noble\r\n```\r\n**Update.** Furthermore, on installing paddlespeech, at the install for wheel I get\r\n```\r\n  Getting requirements to build wheel ... done\r\nERROR: Exception:\r\nTraceback (most recent call last):\r\n  File \"paddlespeech-env/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\r\n    status = run_func(*args)\r\n             ^^^^^^^^^^^^^^^\r\n```",
        "state": "closed",
        "user": "tofutim",
        "closed_by": "zxcd",
        "created_at": "2024-12-17T00:21:33+00:00",
        "updated_at": "2025-03-17T03:12:18+00:00",
        "closed_at": "2025-03-17T03:12:18+00:00",
        "comments_count": [
            "zxcd",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3957,
        "title": "use VectorExecutor() on GPU will stuck",
        "body": "在 GPU 模式下，使用VectorExecutor（） 串行提取音频特征时，会在提取第二首歌时卡住。\r\n\r\nVectorExecutor 实例化对象为同一个，\r\n\r\nGPU 为 NVIDIA T4，  \r\ncuda 版本信息如下\r\n\r\nW1225 08:43:29.520332 3224690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.2, Runtime API Version: 11.8",
        "state": "closed",
        "user": "DoItWithMe",
        "closed_by": "zxcd",
        "created_at": "2024-12-25T08:46:08+00:00",
        "updated_at": "2025-02-05T07:01:50+00:00",
        "closed_at": "2025-02-05T07:01:50+00:00",
        "comments_count": [
            "DoItWithMe",
            "DoItWithMe",
            "Ray961123",
            "zxcd",
            "DoItWithMe",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3977,
        "title": "🎉🎉PaddleSpeech already support Paddle3.0🎉🎉",
        "body": "PaddleSpeech develop already supports Paddle 3.0, and we welcome everyone to actively try it out. \nIf you have any questions, please feel free to raise them and help us improve XD.",
        "state": "open",
        "user": "zxcd",
        "closed_by": null,
        "created_at": "2025-01-23T03:10:37+00:00",
        "updated_at": "2025-04-26T03:45:55+00:00",
        "closed_at": null,
        "comments_count": [
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3983,
        "title": "[S2T]Wav2vec2多条语音推理，只能得到最后一条语音的预测结果",
        "body": "执行以下代码，只能得到最后一条语音的结果：\n```python\nresult_transcripts, result_tokenids = model.decode(\n        audio_tensor,\n        text_feature=text_feature,\n        decoding_method=decode_config.decoding_method,\n        beam_size=decode_config.beam_size,\n        tokenizer=w2w_config.tokenizer, )\n```\n查看源代码`paddlespeech\\s2t\\models\\wav2vec2\\wav2vec2_ASR.py`发现是由于该段代码的问题：\n```python\nfor sequence in hyps:\n    # Decode token terms to words \n    predicted_tokens = text_feature.convert_ids_to_tokens(\n        sequence)\ntmp_res = []\ntmp_res_tokenids = []\nfor c in predicted_tokens:\n    if c == \"[CLS]\":\n        continue\n    elif c == \"[SEP]\" or c == \"[PAD]\":\n        break\n    else:\n        tmp_res.append(c)\n        tmp_res_tokenids.append(text_feature.vocab[c])\nres.append(''.join(tmp_res))\nres_tokenids.append(tmp_res_tokenids)\n```\n\n从tmp_res = []开始就把他写出了循环外，所以最后只能得到最后一条语音的结果。将该部分代码移入循环内即可解决。想提PR但是网有点不好，总是报错time out",
        "state": "closed",
        "user": "kongdebug",
        "closed_by": "zxcd",
        "created_at": "2025-01-29T04:32:50+00:00",
        "updated_at": "2025-02-06T08:02:05+00:00",
        "closed_at": "2025-02-06T08:02:05+00:00",
        "comments_count": [
            "zxcd",
            "kongdebug",
            "zxcd",
            "kongdebug",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3987,
        "title": "PaddleSpeech 1.4.2 Requires Non-Existent opencc==1.1.6",
        "body": "Attempting to install `paddlespeech==1.4.2` fails because it depends on `opencc==1.1.6`, which does not exist.  \n\n#### **Steps to Reproduce**\n```bash\npython -m venv venv\nsource venv/Scripts/activate\npip install paddlepaddle\npip install paddlespeech==1.4.2\n```\n#### **Error Message**\n```\nERROR: Could not find a version that satisfies the requirement opencc==1.1.6 (from paddlespeech) (from versions: 0.1, 0.2, 1.1.0.post1, 1.1.1, 1.1.7, 1.1.8, 1.1.9)\nERROR: No matching distribution found for opencc==1.1.6\n```\n\n- `pip index versions opencc` shows that `opencc==1.1.6` **does not exist**.\n- The latest available versions are: `1.1.9, 1.1.8, 1.1.7, 1.1.1, etc.`\n\n```console\n$ pip index versions opencc\nWARNING: pip index is currently an experimental command. It may be removed/changed in a future release without prior warning.\nopencc (1.1.9)\nAvailable versions: 1.1.9, 1.1.8, 1.1.7, 1.1.1, 1.1.0.post1, 0.2, 0.1\n  INSTALLED: 1.1.7\n  LATEST:    1.1.9\n(venv) \n```\n#### **Environment**\n- OS: **Windows 11**\n- Python Version: **3.8**\n- Pip Version: **Latest (Upgraded)**\n- PaddleSpeech Version: **1.4.2**",
        "state": "closed",
        "user": "ayushkr12",
        "closed_by": "ayushkr12",
        "created_at": "2025-02-09T02:17:18+00:00",
        "updated_at": "2025-02-19T12:44:21+00:00",
        "closed_at": "2025-02-19T12:44:21+00:00",
        "comments_count": [
            "zxcd",
            "ayushkr12",
            "zxcd",
            "ayushkr12",
            "zxcd",
            "ayushkr12",
            "zxcd",
            "ayushkr12",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3990,
        "title": "能否写个好点的文档吗",
        "body": "不管用源码还是镜像源安装有各种依赖冲突",
        "state": "closed",
        "user": "chenzhen1120",
        "closed_by": "zxcd",
        "created_at": "2025-02-20T03:34:53+00:00",
        "updated_at": "2025-02-26T06:26:15+00:00",
        "closed_at": "2025-02-26T06:26:15+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3991,
        "title": "服务化遇到的",
        "body": "环境：\npaddlepaddle: 2.4.2\npaddlespeech：1.4.1\npytest-runner：6.0.1\nnumpy：1.22.4\nscipy：1.7.3\n\n使用命令可以识别成功：\n\n![Image](https://github.com/user-attachments/assets/4be972a4-73ba-4778-b364-5ef43046e1cc)\n\n但是服务化出错：\n\n<!-- Failed to upload \"image.png\" -->\n",
        "state": "closed",
        "user": "chenzhen1120",
        "closed_by": "zxcd",
        "created_at": "2025-02-20T05:50:05+00:00",
        "updated_at": "2025-02-26T06:26:07+00:00",
        "closed_at": "2025-02-26T06:26:07+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3992,
        "title": "服务化遇到的",
        "body": "环境：\npaddlepaddle: 2.4.2\npaddlespeech：1.4.1\npytest-runner：6.0.1\nnumpy：1.22.4\nscipy：1.7.3\n\n使用命令可以识别成功：\n\n![Image](https://github.com/user-attachments/assets/4be972a4-73ba-4778-b364-5ef43046e1cc)\n\n但是服务化出错：\n\n<!-- Failed to upload \"image.png\" -->\n",
        "state": "closed",
        "user": "chenzhen1120",
        "closed_by": "zxcd",
        "created_at": "2025-02-20T05:50:40+00:00",
        "updated_at": "2025-02-20T12:34:00+00:00",
        "closed_at": "2025-02-20T12:33:42+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3993,
        "title": "[TTS] fastspeech2 to static error",
        "body": "**Describe the bug**\nwhen i try to run examples/ljspeech/tts3/run.sh with stage 3. Which is ./local/synthesize_e2e.sh to get the static pdmodel. It is throwing error. I have trained the model on ljspeech format data.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to examples/ljspeech/tts3/\n2. and prepare the data accordingly \n3. run examples/ljspeech/tts3/run.sh with stage 0 to prep the data\n4. run examples/ljspeech/tts3/run.sh with stage 1 to train the data\n5. run examples/ljspeech/tts3/run.sh with stage 3 to convert the model to pdmodel format\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/98e93953-e143-41d0-a974-6d67db5e6a0e)\n\n**Environment (please complete the following information):**\n - OS: ubuntu 22.04\n - GCC/G++ Version 9.4.0\n - Python Version 3.9.21\n - PaddlePaddle Version 2.6.2 (paddlepaddle-gpu )\n - Model Version [e.g. 2.0.0]\n - GPU/DRIVER Information NVIDIA GeForce RTX 4090/550.144.03\n - CUDA/CUDNN Version cuda_12.6.r12.6/compiler.34714021_0\n - MKL Version\n- TensorRT Version\n\n**Additional context**\nAdd any other context about the problem here.\n",
        "state": "closed",
        "user": "ixtiyoruz",
        "closed_by": "ixtiyoruz",
        "created_at": "2025-02-23T15:29:15+00:00",
        "updated_at": "2025-02-25T10:54:23+00:00",
        "closed_at": "2025-02-25T10:54:23+00:00",
        "comments_count": [
            "zxcd",
            "ixtiyoruz",
            "zxcd",
            "ixtiyoruz"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3996,
        "title": "PaddleSpeech 1.5.0 Release Note",
        "body": "Full Changelog: https://github.com/PaddlePaddle/PaddleSpeech/compare/748a5f9...develop 18 contributors\n\n# Version Adaptation\nUpgrade and adapt PaddleSpeech from Paddle 2.5.1 to Paddle 3.0.0-beta. Address incompatibility issues caused by the new version upgrade of Paddle, perform adaptation development and regression testing on the models in PaddleSpeech, and ensure the suite operates normally without loss of model functionality or accuracy.\n \n- Ensure the adaptation of 80+ existing models in the demo and example directories.\n- Ensure the adaptation and accuracy alignment of 10+ core models in the example directory.\n- Support the re-export of 20+ dynamic-to-static models using the PIR + predictor approach and ensure successful inference.\n\n# New Features\n- Implement the third-party library audio tools used in DAC (Descript-Audio-Codec) training.\n- Reproduce the losses required for DAC training: MultiScaleSTFTLoss, GANLoss, and SISDRLoss.\n\n# Bug Fix\n\n\n\n# Others\n- Clean up dependencies and support using PaddleSpeech in Python>3.8 environments\n\n\n\n# Acknowledgements\nSpecial thanks to contributors including @wanx7130 @warrentdrew @DrRyanHuang @cchenhaifeng @undefined-ux @zxcd @GreatV @yinfan98 @Liyulingyue @megemini @SuiYunsy @Netrvin @enkilee @tianshuo78520a and others for their support.\n\n\n# New Contributors\n- @wanx7130 made their first contribution in #3875\n- @cchenhaifeng made their first contribution in #3988\n- @undefined-ux made their first contribution in #3837\n- @DrRyanHuang made their first contribution in #3900\n- @SuiYunsy made their first contribution in #3865\n- @Netrvin made their first contribution in #3715\n- @guspan-tanadi made their first contribution in #3958\n- @enkilee made their first contribution in #3889\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "zxcd",
        "created_at": "2025-02-27T06:55:45+00:00",
        "updated_at": "2025-05-23T06:54:51+00:00",
        "closed_at": "2025-05-23T06:54:51+00:00",
        "comments_count": [
            "GreatV",
            "stale[bot]"
        ],
        "labels": [
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 3997,
        "title": "PaddleSpeech 快乐开源活动 (2025 H1)",
        "body": " # 📣PaddleSpeech 快乐开源活动\n\n旨在鼓励更多的开发者参与到飞桨大模型套件的开源建设中，帮助社区修复 bug 或贡献 feature，共建飞桨。\n\n## 任务目标\n目前由于版本问题，文档已经跟不上代码啦！\n* 按照readme操作可以完全跑通\n* 文档与代码一致\n* 文档书写错误\n\n## 任务一：修正合成vocoder中的synthesize_e2e.sh中参数错误\n\n| 序号 | 待修改文件 | 认领人/状态/PR 号 |\n| -- | -- | --|\n| 1 | examples/csmsc/voc1/local/synthesize_e2e.sh |  @ZJhorseloudly <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4036](https://github.com/PaddlePaddle/PaddleSpeech/pull/4036)<br>@Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4047](https://github.com/PaddlePaddle/PaddleSpeech/pull/4047)<br> | \n| 2 | examples/csmsc/voc3/local/synthesize_e2e.sh | @ZJhorseloudly <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4036](https://github.com/PaddlePaddle/PaddleSpeech/pull/4036)<br>@Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4050](https://github.com/PaddlePaddle/PaddleSpeech/pull/4050)<br> | \n| 3 | examples/csmsc/voc5/local/synthesize_e2e.sh | @ZJhorseloudly <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4036](https://github.com/PaddlePaddle/PaddleSpeech/pull/4036)<br>@Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4051](https://github.com/PaddlePaddle/PaddleSpeech/pull/4051)<br> | \n\n\n## 任务二：补全合成系列中的脚本中参数缺失\n\n| 序号 | 待修改文件 | 认领人/状态/PR 号 |\n| -- | -- | -- |\n| 4 | examples/aishell3/tts3/run.sh <br> examples/aishell3/tts3/README.md |  @enkilee <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#3998](https://github.com/PaddlePaddle/PaddleSpeech/pull/3998)<br> | \n| 5 | examples/aishell3_vctk/ernie_sat/run.sh </br> examples/aishell3_vctk/ernie_sat/README.md |  @rich04lin <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4005](https://github.com/PaddlePaddle/PaddleSpeech/pull/4005)<br>@Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4042](https://github.com/PaddlePaddle/PaddleSpeech/pull/4042)<br> | \n| 6 | examples/canton/tts3/run.sh <br> examples/canton/tts3/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4004](https://github.com/PaddlePaddle/PaddleSpeech/pull/4004)<br> | \n| 7 | examples/csmsc/tts0/run.sh <br> examples/csmsc/tts0/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4008](https://github.com/PaddlePaddle/PaddleSpeech/pull/4008) [#4043](https://github.com/PaddlePaddle/PaddleSpeech/pull/4043)<br>@rich04lin <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4007](https://github.com/PaddlePaddle/PaddleSpeech/pull/4007)<br> | \n| 8 | examples/csmsc/tts2/run.sh <br> examples/csmsc/tts2/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4008](https://github.com/PaddlePaddle/PaddleSpeech/pull/4008) [#4044](https://github.com/PaddlePaddle/PaddleSpeech/pull/4044)<br>@rich04lin <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4009](https://github.com/PaddlePaddle/PaddleSpeech/pull/4009)<br> | \n| 9 | examples/csmsc/tts3/run.sh </br> examples/csmsc/tts3/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4008](https://github.com/PaddlePaddle/PaddleSpeech/pull/4008) [#4045](https://github.com/PaddlePaddle/PaddleSpeech/pull/4045)<br> | \n| 10 | examples/csmsc/tts3_rhy/run.sh </br> examples/csmsc/tts3_rhy/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4008](https://github.com/PaddlePaddle/PaddleSpeech/pull/4008) [#4049](https://github.com/PaddlePaddle/PaddleSpeech/pull/4049)<br> | \n| 11 | examples/ljspeech/tts3/run.sh </br> examples/ljspeech/tts3/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4010](https://github.com/PaddlePaddle/PaddleSpeech/pull/4010) [#4038](https://github.com/PaddlePaddle/PaddleSpeech/pull/4038)<br> | \n| 12 | examples/opencpop/svs1/run.sh </br> examples/opencpop/svs1/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4012](https://github.com/PaddlePaddle/PaddleSpeech/pull/4012) [#4037](https://github.com/PaddlePaddle/PaddleSpeech/pull/4037)<br> | \n| 13 | examples/vctk/ernie_sat/run.sh </br> examples/vctk/ernie_sat/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4013](https://github.com/PaddlePaddle/PaddleSpeech/pull/4013)<br> | \n| 14 | examples/vctk/tts3/run.sh </br> examples/vctk/tts3/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4013](https://github.com/PaddlePaddle/PaddleSpeech/pull/4013)<br> | \n\n## 任务三：修正文本书写错误（随时更新）\n\n| 序号 | 待修改文件 | 认领人/状态/PR 号 | \n| -- | -- | -- | \n| 15 | examples/csmsc/voc3/README.md |  @Echo-Nie <img src=\"https://img.shields.io/badge/状态-提交PR-F39C12\" /> [#4012](https://github.com/PaddlePaddle/PaddleSpeech/pull/4012)<br>@rich04lin <img src=\"https://img.shields.io/badge/状态-完成任务-9B59B6\" /> [#4011](https://github.com/PaddlePaddle/PaddleSpeech/pull/4011)<br> | \n\n\n### 任务一修改示例\n修正目标：`examples/*/voc*/local/synthesize_e2e.sh` 例如：`examples/csmsc/voc1/local/synthesize_e2e.sh`\n```\nsynthesize_e2e.sh 中代码如下：\npython3 ${BIN_DIR}/../synthesize.py \\\n    --am=tacotron2_aishell3 \\\n    --am_config=${config_path} \\\n    --am_ckpt=${train_output_path}/checkpoints/${ckpt_name} \\\n    --am_stat=dump/train/speech_stats.npy \\\n    --voc=pwgan_aishell3 \\\n    --voc_config=pwg_aishell3_ckpt_0.5/default.yaml \\\n    --voc_ckpt=pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz \\\n    --voc_stat=pwg_aishell3_ckpt_0.5/feats_stats.npy \\\n    --test_metadata=dump/test/norm/metadata.jsonl \\\n    --output_dir=${train_output_path}/test \\\n    --phones_dict=dump/phone_id_map.txt \\\n    --speaker_dict=dump/speaker_id_map.txt \\\n    --voice-cloning=True\n```\n由于合成时训练的是 voc 而非 am， 因此包含`train_output_path`的应该是 --voc， --voc_config 等 voc 相关部分，--am 相关部分按照 `examples/csmsc/voc1/README.md` 中的描述修改为 `fastspeech2_nosil_baker_ckpt_0.4` 文件夹下的相关文件。\n\n\n### 任务二修改示例\n修正目标：`examples/*/*/local/run.sh`，`examples/*/*/README.md`\n在部分 `synthesize_e2e.sh` 和 `synthesize.sh` 中，通过对 stage 的修改支持多种模型的推理，但该参数未在对应的 `run.sh` 和 `README.md` 中暴露，需要将参数和对应的说明添加补充全。\n例如 ：`examples/aishell3/tts3/local/synthesize_e2e.sh` 中通过 stage 控制分别使用 pwgan，hifigan 进行推理。\n* 在 `run.sh` 中修改：\n```\nif [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then\n    # synthesize, vocoder is pwgan by default stage 0, stage 1 will use hifigan as vocoder\n    CUDA_VISIBLE_DEVICES=${gpus} ./local/synthesize.sh --stage 0 ${conf_path} ${train_output_path} ${ckpt_name} || exit -1\nfi\n\nif [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then\n    # synthesize_e2e, vocoder is pwgan by default stage 0, stage 1 will use hifigan as vocoder\n    CUDA_VISIBLE_DEVICES=${gpus} ./local/synthesize_e2e.sh --stage 0 ${conf_path} ${train_output_path} ${ckpt_name} || exit -1\nfi\n```\n\n* 在 `README.md` 中修改：\n```\n`./local/synthesize.sh` calls `${BIN_DIR}/../synthesize.py`, which can synthesize waveform from `metadata.jsonl`. \n\nCUDA_VISIBLE_DEVICES=${gpus} ./local/synthesize.sh --stage 0 ${conf_path} ${train_output_path} ${ckpt_name}\n\n`--stage` controls the vocoder model during synthesis, which can be `0` or `1`, use `pwgan` or `hifigan` model as vocoder.\n```\n\n### 任务三修改示例\n修改`examples/csmsc/voc3/README.md`\n\n```\nHiFiGAN checkpoint contains files listed below.\nmb_melgan_csmsc_ckpt_0.1.1\n├── default.yaml                    # default config used to train MultiBand MelGAN\n├── feats_stats.npy                 # statistics used to normalize spectrogram when training MultiBand MelGAN\n└── snapshot_iter_1000000.pdz       # generator parameters of MultiBand MelGAN\n```\n该 `README.md` 中模型下载 MultiBand MelGAN 模型，但文件列表写的是 HiFiGAN 。\n\n### 认领方式\n\n请大家以 comment 的形式认领任务，如：\n\n```\n【报名】：1、3、2-3\n```\n\n- 多个任务之间需要使用**中文顿号**分隔，报名多个连续任务可用横线表示，如 1-2 \n- PR 提交格式：在 PR 的标题中以 **【PaddleSpeech No.xxx】** 开头，注明任务编号\n\n## 看板信息\n| 任务方向 | 任务数量 | 提交作品 / 任务认领 | 提交率 | 完成 | 完成率 |\n| :----: | :----: | :----:  | :----: | :----: | :----: |\n|  PaddleSpeech 快乐开源活动  |  15  | 15 / 15 | 100.0% |  15  | 100.0% |\n#####\n\n## 统计信息 \n> 排名不分先后 @Echo-Nie (13) @enkilee (1) @rich04lin (1) \n#####\n",
        "state": "closed",
        "user": "zxcd",
        "closed_by": "luotao1",
        "created_at": "2025-02-27T07:44:23+00:00",
        "updated_at": "2025-04-16T07:53:49+00:00",
        "closed_at": "2025-04-16T07:53:44+00:00",
        "comments_count": [
            "enkilee",
            "Echo-Nie",
            "rich04lin",
            "ZJhorseloudly",
            "Echo-Nie",
            "Echo-Nie",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4023,
        "title": "[TTS]单模块出错玩意，浪费时间！",
        "body": "不多说了，我已经弃用了",
        "state": "closed",
        "user": "Jin-OK",
        "closed_by": "Jin-OK",
        "created_at": "2025-03-20T06:04:47+00:00",
        "updated_at": "2025-03-20T06:06:20+00:00",
        "closed_at": "2025-03-20T06:06:20+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4002,
        "title": "如何训练自己的语音转文字模型？有说明文档吗",
        "body": "## Others\n如何训练自己的语音转文字模型？有说明文档吗\n<!--\n你可以在这里提出任何前面几类模板不适用的问题，包括但不限于：优化性建议、框架使用体验反馈、版本兼容性问题、报错信息不清楚等。\nYou can report any issues that are not applicable to the previous types of templates, including but not limited to: enhancement suggestions, feedback on the use of the framework, version compatibility issues, unclear error information, etc.\n-->\n",
        "state": "closed",
        "user": "huangboyua",
        "closed_by": "zxcd",
        "created_at": "2025-03-11T09:43:23+00:00",
        "updated_at": "2025-03-17T03:11:56+00:00",
        "closed_at": "2025-03-17T03:11:56+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4014,
        "title": "修正文本书写错误CI-PaddleSpeech-Linux",
        "body": "## General Question\n\n<!--\nBefore asking a question, make sure you have:\n- Baidu/Google your question.\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\n- Read the documentation:\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\n  - [Doc](https://paddlespeech.readthedocs.io/)\n-->\n\n![Image](https://github.com/user-attachments/assets/e40a25aa-6ae0-4a55-9778-52b2539b7e18)\n\n在进行CI-PaddleSpeech-Linux检查时，Python 环境中没有找到 paddle 模块，这是为什么？之前修改其他任务的时候都可以all checks passed，但是只要对 `examples/csmsc/voc3/README.md` 进行修改后，都会报错如上。\n\nPR链接：https://github.com/PaddlePaddle/PaddleSpeech/pull/4012",
        "state": "closed",
        "user": "Echo-Nie",
        "closed_by": "Echo-Nie",
        "created_at": "2025-03-16T06:02:41+00:00",
        "updated_at": "2025-03-17T02:53:18+00:00",
        "closed_at": "2025-03-17T02:53:18+00:00",
        "comments_count": [
            "zxcd",
            "Echo-Nie"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4016,
        "title": "浪费时间",
        "body": "## Others\n\n连接自己的demo都跑不起来，这个仓库还是删了吧",
        "state": "closed",
        "user": "pdxrlj",
        "closed_by": "zxcd",
        "created_at": "2025-03-17T05:11:37+00:00",
        "updated_at": "2025-03-20T06:14:36+00:00",
        "closed_at": "2025-03-20T06:14:36+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4022,
        "title": "pdz怎么转pdmodel",
        "body": "我想使用punc模型，将其转为onnx，但发现下载的[ernie-tiny.tar.gz](https://paddlespeech.cdn.bcebos.com/punc_restore/ernie-tiny.tar.gz)\n模型，打开是pdz格式，不知道要怎么转pdmodel呢？",
        "state": "closed",
        "user": "DrewdropLife",
        "closed_by": "zxcd",
        "created_at": "2025-03-20T03:29:58+00:00",
        "updated_at": "2025-06-03T08:37:12+00:00",
        "closed_at": "2025-06-03T08:37:12+00:00",
        "comments_count": [
            "zxcd",
            "DrewdropLife",
            "zxcd",
            "stale[bot]"
        ],
        "labels": [
            "Question",
            "Stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4025,
        "title": "demo audio_search pip install 有个库的名字写错",
        "body": "## Others\n\n<!--\n\n![Image](https://github.com/user-attachments/assets/c12a0087-b6c8-44e6-86d4-05c64b2326df)\n应该是dtaidistance\n-->\n",
        "state": "closed",
        "user": "moviewang",
        "closed_by": "moviewang",
        "created_at": "2025-03-20T08:30:16+00:00",
        "updated_at": "2025-03-25T06:45:51+00:00",
        "closed_at": "2025-03-25T06:45:51+00:00",
        "comments_count": [
            "zxcd",
            "moviewang",
            "zxcd"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4026,
        "title": "does TTSAndroid support int8 infer?",
        "body": "## General Question\nI Quantify speedyspeech and mb_melban models using paddle-lite with the following command.\n./opt_linux_x86 --model_file=speedyspeech_csmsc.pdmodel --param_file=speedyspeech_csmsc.pdiparams --valid_targets=arm --optimize_out_type=naive_buffer --optimize_out=./speedyspeech_csmsc_int8.nb --quant_model=true --quant_type=QUANT_INT8\nand copy the two models to TTSAndroid/app/src/main/assets/models/cpu/, then change model names in mainactivity.java, finally change input tensor type from float to long.\nBut no decrease of cpu usage or infer time is seen on my armv8 cpu phone. \nSo I want to ask whether int8 infer is supported or not? \nAny help is appreciated.\n\n<!--\nBefore asking a question, make sure you have:\n- Baidu/Google your question.\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\n- Read the documentation:\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\n  - [Doc](https://paddlespeech.readthedocs.io/)\n-->\n",
        "state": "closed",
        "user": "elliotzheng",
        "closed_by": "elliotzheng",
        "created_at": "2025-03-20T08:53:14+00:00",
        "updated_at": "2025-04-22T07:33:45+00:00",
        "closed_at": "2025-04-22T07:33:45+00:00",
        "comments_count": [
            "zxcd",
            "elliotzheng"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4028,
        "title": "fastspeech2_mix 无法下载，没有权限",
        "body": "## General Question\n\n>paddlespeech tts --input \"you take the autumn water to take the galaxy\" --output output.wav --am fastspeech2_mix  \nC:\\Users\\a01\\.conda\\envs\\paddlegpu\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n  warnings.warn(\nRuntimeError: Downloading from https://paddlespeech.bj.bcebos.com/t2s/chinse_english_mixed/models/fastspeech2_mix_ckpt_0.2.0.zip failed with code 403!",
        "state": "closed",
        "user": "dissipator",
        "closed_by": "dissipator",
        "created_at": "2025-03-23T13:39:24+00:00",
        "updated_at": "2025-03-23T13:49:54+00:00",
        "closed_at": "2025-03-23T13:49:54+00:00",
        "comments_count": [],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4027,
        "title": "语音合成支持C++吗？x64 Linux 平台",
        "body": "你好：语音合成支持C++吗？x64 Linux 平台",
        "state": "closed",
        "user": "yourengod",
        "closed_by": "zxcd",
        "created_at": "2025-03-21T13:36:25+00:00",
        "updated_at": "2025-06-03T08:37:22+00:00",
        "closed_at": "2025-06-03T08:37:22+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 4053
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4034,
        "title": "[TTS]华为昇腾服务器 910B 错误 ACL error, the error code is : 100000",
        "body": "# 服务器信息\n\n* 镜像 PyTorch  2.1.0 Python  3.10(ubuntu22.04) CANN  8.0.0\n* GPU：910B2x鲲鹏920(64GB) * 1\n* CPU：24 vCPU Kunpeng-920\n\n安装代码：\n```\npython -m pip install paddlepaddle==3.0.0rc1 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/\npython -m pip install paddle-custom-npu==3.0.0rc1 -i https://www.paddlepaddle.org.cn/packages/stable/npu/\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git ./speech\npip install pytest-runner\npip install -e . --use-pep517\n```\n\n执行测试代码TTS错误：\n```\nimport paddle\nfrom paddlespeech.cli.tts.infer import TTSExecutor\n \nprint(f\"Current device: {paddle.device.get_device()}\")\n\ntts = TTSExecutor()\n\ntts(text=\"今天天气十分不错。\", output=\"output.wav\")\n```\n\n错误提示：\n\n```\nTraceback (most recent call last):\n  File \"/root/speech/tts.py\", line 9, in <module>\n    tts(text=\"今天天气十分不错。\", output=\"output.wav\")\n  File \"/root/speech/paddlespeech/cli/utils.py\", line 328, in _warpper\n    return executor_func(self, *args, **kwargs)\n  File \"/root/speech/paddlespeech/cli/tts/infer.py\", line 696, in __call__\n    self._init_from_path(\n  File \"/root/speech/paddlespeech/cli/tts/infer.py\", line 337, in _init_from_path\n    self.am_inference = get_am_inference(\n  File \"/root/speech/paddlespeech/t2s/exps/syn_utils.py\", line 405, in get_am_inference\n    am = am_class(\n  File \"/root/speech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 516, in __init__\n    self._reset_parameters(\n  File \"/root/speech/paddlespeech/t2s/models/fastspeech2/fastspeech2.py\", line 908, in _reset_parameters\n    init_enc_alpha = paddle.to_tensor(init_enc_alpha).reshape([1])\n  File \"/root/miniconda3/lib/python3.10/site-packages/paddle/tensor/manipulation.py\", line 4988, in reshape\n    out = _C_ops.reshape(x, new_shape)\nOSError: (External)  ACL error, the error code is : 100000.  (at /paddle/backends/npu/kernels/funcs/npu_op_runner.cc:225)\n```\n\n",
        "state": "closed",
        "user": "lezhizhe",
        "closed_by": "zxcd",
        "created_at": "2025-03-25T12:34:19+00:00",
        "updated_at": "2025-06-03T08:37:46+00:00",
        "closed_at": "2025-06-03T08:37:46+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4039,
        "title": "[TTS] Downloading from https://paddlespeech.cdn.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip failed with code 404!",
        "body": "我在使用tts功能测试的时候出现了这个错误，并且无法手动访问该地址，asr模型倒是可以下载，我不知道这是啥原因导致的，希望可以得到帮助，如果是下载的网址改变了请提供一个准确的下载地址。\n\n![Image](https://github.com/user-attachments/assets/9f2f9284-b360-4a63-bdc2-a3fe316bd3d1)\n",
        "state": "closed",
        "user": "ddbegun",
        "closed_by": "ddbegun",
        "created_at": "2025-03-30T12:09:55+00:00",
        "updated_at": "2025-03-31T04:51:56+00:00",
        "closed_at": "2025-03-31T04:51:56+00:00",
        "comments_count": [
            "91geek",
            "maintell",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4048,
        "title": "在初始化fastspeech2_vctk前端的时候失败，显示G2PWModel_1.1.zip failed",
        "body": "Traceback (most recent call last):\n  File \"/home/aistudio/process_4.py\", line 12, in <module>\n    frontend = Frontend(phone_vocab_path='fastspeech2_vctk/phone_id_map.txt')\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/t2s/frontend/zh_frontend.py\", line 149, in __init__\n    self.g2pW_model = G2PWOnnxConverter(\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/t2s/frontend/g2pw/onnx_api.py\", line 73, in __init__\n    uncompress_path = download_and_decompress(\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/cli/utils.py\", line 148, in download_and_decompress\n    uncompress_path = download.get_path_from_url(archive['url'], path,\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/cli/download.py\", line 102, in get_path_from_url\n    fullpath = _download(url, root_dir, md5sum, method=method)\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/cli/download.py\", line 201, in _download\n    if not _download_methods[method](url, fullname):\n  File \"/home/aistudio/.local/lib/python3.10/site-packages/paddlespeech/cli/download.py\", line 126, in _get_download\n    raise RuntimeError(\"Downloading from {} failed with code \"\nRuntimeError: Downloading from https://paddlespeech.bj.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip failed with code 404!",
        "state": "closed",
        "user": "H-rz",
        "closed_by": "zxcd",
        "created_at": "2025-04-04T15:10:00+00:00",
        "updated_at": "2025-06-03T08:38:04+00:00",
        "closed_at": "2025-06-03T08:38:04+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4046,
        "title": "ASR 语音转文字 list index out of range",
        "body": "错误信息如下。\n\nERROR] - list index out of range\nTraceback (most recent call last):\n  File \"/Users/lolicon/.conda/envs/duoduo-speech/lib/python3.9/site-packages/paddlespeech/cli/asr/infer.py\", line 314, in infer\n    result_transcripts = self.model.decode(\n  File \"/Users/lolicon/.conda/envs/duoduo-speech/lib/python3.9/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/Users/lolicon/.conda/envs/duoduo-speech/lib/python3.9/site-packages/paddle/base/dygraph/base.py\", line 400, in _decorate_function\n    return func(*args, **kwargs)\n  File \"/Users/lolicon/.conda/envs/duoduo-speech/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 818, in decode\n    hyp = self.attention_rescoring(\n  File \"/Users/lolicon/.conda/envs/duoduo-speech/lib/python3.9/site-packages/paddlespeech/s2t/models/u2/u2.py\", line 532, in attention_rescoring\n    assert speech.shape[0] == speech_lengths.shape[0]\nIndexError: list index out of range\n\n代码如下。\n\nasr = ASRExecutor()\nresult = asr(audio_file=Path(audio_path), model='conformer_online_wenetspeech', force_yes=True)\nprint(result)\n\n环境信息如下。\n\npip list\nPackage                     Version\n--------------------------- -----------\nabsl-py                     2.2.1\naiohappyeyeballs            2.6.1\naiohttp                     3.11.16\naiosignal                   1.3.2\nannotated-types             0.7.0\nantlr4-python3-runtime      4.9.3\nanyio                       4.6.2\nastor                       0.8.1\nasttokens                   3.0.0\nasync-timeout               5.0.1\nattrs                       25.3.0\naudioread                   3.0.1\nbabel                       2.17.0\nbce-python-sdk              0.9.29\nblinker                     1.9.0\nbokeh                       3.4.3\nboltons                     25.0.0\nBottleneck                  1.4.2\nbraceexpand                 0.1.7\ncertifi                     2025.1.31\ncffi                        1.17.1\ncharset-normalizer          3.4.1\nclick                       8.1.8\ncolorama                    0.4.6\ncoloredlogs                 15.0.1\ncolorlog                    6.9.0\ncontourpy                   1.3.0\ncycler                      0.12.1\ndatasets                    3.5.0\ndecorator                   5.1.1\ndill                        0.3.4\nDistance                    0.1.3\ndnspython                   2.7.0\neditdistance                0.8.1\neinops                      0.8.1\nemail_validator             2.2.0\nexceptiongroup              1.2.0\nexecuting                   2.2.0\nfastapi                     0.115.12\nfastapi-cli                 0.0.7\nfilelock                    3.18.0\nFlask                       3.1.0\nflask-babel                 4.0.0\nflatbuffers                 25.2.10\nfonttools                   4.56.0\nfrozenlist                  1.5.0\nfsspec                      2024.12.0\nftfy                        6.3.1\nfuture                      1.0.0\ng2p-en                      2.1.0\ng2pM                        0.1.2.5\nh11                         0.14.0\nh5py                        3.13.0\nhttpcore                    1.0.2\nhttptools                   0.6.4\nhttpx                       0.27.0\nhuggingface-hub             0.30.1\nhumanfriendly               10.0\nHyperPyYAML                 1.2.2\nidna                        3.7\nimportlib_metadata          8.6.1\nimportlib_resources         6.5.2\ninflect                     7.0.0\nintervaltree                3.1.0\nipython                     8.18.1\nitsdangerous                2.2.0\njedi                        0.19.2\njieba                       0.42.1\nJinja2                      3.1.6\njoblib                      1.4.2\njsonlines                   4.0.0\nkaldiio                     2.18.1\nkiwisolver                  1.4.7\nlibrosa                     0.8.1\nllvmlite                    0.43.0\nloguru                      0.7.3\nlxml                        5.3.1\nmarkdown-it-py              3.0.0\nMarkupSafe                  3.0.2\nmatplotlib                  3.9.4\nmatplotlib-inline           0.1.7\nmdurl                       0.1.2\nmido                        1.3.3\nmock                        5.2.0\nmpmath                      1.3.0\nmultidict                   6.2.0\nmultiprocess                0.70.12.2\nnara-wpe                    0.0.11\nnetworkx                    3.2.1\nnltk                        3.9.1\nnote-seq                    0.0.3\nnumba                       0.60.0\nnumpy                       1.23.5\nomegaconf                   2.3.0\nonnx                        1.17.0\nonnxruntime                 1.19.2\nOpenCC                      1.1.9\nopencc-python-reimplemented 0.1.7\nopencv-python               4.6.0.66\nopt-einsum                  3.3.0\npackaging                   24.2\npaddle2onnx                 1.3.1\npaddleaudio                 1.1.0\npaddlefsl                   1.1.0\npaddlenlp                   2.6.1\npaddlepaddle                3.0.0\npaddlesde                   0.2.5\npaddleslim                  2.6.0\npaddlespeech                1.4.1\npaddlespeech-feat           0.1.0\npandas                      2.2.3\nparameterized               0.9.0\nparso                       0.8.4\npathos                      0.2.8\npattern_singleton           1.2.0\npexpect                     4.9.0\npillow                      11.1.0\npip                         25.0\nplatformdirs                4.3.7\npooch                       1.8.2\nportalocker                 3.1.1\npox                         0.3.5\nppdiffusers                 0.19.4\nppft                        1.7.6.9\npraatio                     5.1.1\npretty_midi                 0.2.10\nprettytable                 3.16.0\nprompt_toolkit              3.0.50\npropcache                   0.3.1\nprotobuf                    3.20.2\npsutil                      7.0.0\nptyprocess                  0.7.0\npure_eval                   0.2.3\npyarrow                     19.0.1\npybind11                    2.13.6\npycparser                   2.22\npycryptodome                3.22.0\npydantic                    2.11.1\npydantic_core               2.33.0\npydub                       0.25.1\nPygments                    2.19.1\npyparsing                   3.2.3\npypinyin                    0.44.0\npypinyin-dict               0.9.0\npython-dateutil             2.9.0.post0\npython-dotenv               1.1.0\npython-multipart            0.0.20\npytz                        2025.2\npyworld                     0.3.5\nPyYAML                      6.0.2\npyzmq                       26.3.0\nrarfile                     4.2\nregex                       2024.11.6\nrequests                    2.32.3\nrequests-mock               1.12.1\nresampy                     0.4.3\nrich                        14.0.0\nrich-toolkit                0.14.1\nruamel.yaml                 0.18.10\nruamel.yaml.clib            0.2.12\nsacrebleu                   2.5.1\nsafetensors                 0.5.3\nscikit-learn                1.6.1\nscipy                       1.13.1\nsentencepiece               0.2.0\nseqeval                     1.2.2\nsetuptools                  75.8.0\nshellingham                 1.5.4\nsix                         1.17.0\nsniffio                     1.3.0\nsortedcontainers            2.4.0\nsoundfile                   0.13.1\nstack-data                  0.6.3\nstarlette                   0.46.1\nswig                        4.3.0\nsympy                       1.13.3\ntabulate                    0.9.0\nTextGrid                    1.6.1\nthreadpoolctl               3.6.0\ntimer                       0.3.0\nToJyutping                  3.2.0\ntornado                     6.4.2\ntqdm                        4.67.1\ntraitlets                   5.14.3\ntrampoline                  0.1.2\ntypeguard                   2.13.3\ntyper                       0.15.2\ntyping_extensions           4.12.2\ntyping-inspection           0.4.0\ntzdata                      2025.2\nurllib3                     1.26.20\nuvicorn                     0.34.0\nuvloop                      0.21.0\nvisualdl                    2.5.3\nwatchfiles                  1.0.4\nwcwidth                     0.2.13\nwebrtcvad                   2.0.10\nwebsockets                  15.0.1\nWerkzeug                    3.1.3\nwheel                       0.45.1\nxxhash                      3.5.0\nxyzservices                 2025.1.0\nyacs                        0.1.8\nyarl                        1.18.3\nzhon                        2.1.1\nzipp                        3.21.0",
        "state": "closed",
        "user": "easylolicon",
        "closed_by": "zxcd",
        "created_at": "2025-04-03T07:51:17+00:00",
        "updated_at": "2025-06-03T08:37:56+00:00",
        "closed_at": "2025-06-03T08:37:56+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4052,
        "title": "文本转语音时模型层形状不匹配",
        "body": "进行语音合成时(xhtPython) C:\\Users\\15156>paddlespeech tts --input \"你好，欢迎光临！\" --output out.wav\nD:\\conda\\envs\\xhtPython\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n  warnings.warn(\nW0407 23:49:31.735687 33816 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.6, Runtime API Version: 12.0\nW0407 23:49:31.747190 33816 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.\nD:\\conda\\envs\\xhtPython\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for encoder.embed.1.alpha. encoder.embed.1.alpha receives a shape [1], but the expected shape is [].\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\nD:\\conda\\envs\\xhtPython\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for decoder.embed.0.alpha. decoder.embed.0.alpha receives a shape [1], but the expected shape is [].\n  warnings.warn(f\"Skip loading for {key}. \" + str(err))\nIndexError: (OutOfRange) The starting index 0 of slice is out of bounds in tensor 0-th axis, it shound be in the range of [0, 0). (at ..\\paddle/fluid/pybind/slice_utils.h:216)",
        "state": "closed",
        "user": "aaa56789",
        "closed_by": "zxcd",
        "created_at": "2025-04-07T16:00:09+00:00",
        "updated_at": "2025-06-03T08:38:11+00:00",
        "closed_at": "2025-06-03T08:38:11+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4054,
        "title": "paddlespeech tts支持rknn吗？",
        "body": "paddlespeech的语音合成支持RKNN 是瑞芯微（Rockchip）推出的针对其芯片平台的神经网络推理框架吗？可以跑在npu上吗？",
        "state": "closed",
        "user": "yourengod",
        "closed_by": "yourengod",
        "created_at": "2025-04-10T07:11:11+00:00",
        "updated_at": "2025-04-26T06:35:20+00:00",
        "closed_at": "2025-04-26T06:35:20+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4055,
        "title": "TTS模型下载报错",
        "body": " paddlespeech_server start --config_file ./paddlespeech/server/conf/application.yaml\n[2025-04-11 16:32:39,641] [    INFO] - start to init the engine\n[2025-04-11 16:32:39,641] [    INFO] - asr : python engine.\nW0411 16:32:43.912498 2273126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8\nW0411 16:32:43.913061 2273126 gpu_resources.cc:149] device: 0, cuDNN Version: 90.8.\n2025-04-11 16:32:44.085 | INFO     | paddlespeech.s2t.modules.embedding:__init__:150 - max len: 5000\n[2025-04-11 16:32:45,143] [    INFO] - Initialize ASR server engine successfully on device: gpu:0.\n[2025-04-11 16:32:45,143] [    INFO] - tts : python engine.\n[2025-04-11 16:32:49,805] [   ERROR] - Failed to get model related files.\n[2025-04-11 16:32:49,805] [   ERROR] - Initialize TTS server engine Failed on device: gpu:0.\n[2025-04-11 16:32:49,805] [   ERROR] - Downloading from https://paddlespeech.bj.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip failed with code 404!\n请问是模型路径有修改吗\n",
        "state": "closed",
        "user": "yangzijiang98",
        "closed_by": "zxcd",
        "created_at": "2025-04-11T08:38:09+00:00",
        "updated_at": "2025-06-03T08:38:21+00:00",
        "closed_at": "2025-06-03T08:38:21+00:00",
        "comments_count": [
            "zxcd",
            "yangzijiang98"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4056,
        "title": "armTTS（cpu）有没有可供选择的音色？",
        "body": null,
        "state": "closed",
        "user": "drq123456",
        "closed_by": "zxcd",
        "created_at": "2025-04-12T07:34:45+00:00",
        "updated_at": "2025-06-03T08:38:35+00:00",
        "closed_at": "2025-06-03T08:38:35+00:00",
        "comments_count": [
            "zxcd",
            "drq123456",
            "zxcd",
            "drq123456",
            "drq123456",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4058,
        "title": "NPU的paddle的镜像出现(Unimplemented) npu npu only support mode=constant right now,but received mode is reflect .   [Hint: Expected mode == \"constant\", but received mode:reflect != \"constant\":constant.] (at /paddle/backends/npu/kernels/pad3d_kernel.cc:43)的报错",
        "body": "硬件环境：昇腾910B4-1，单机8张NPU卡，每张卡64G显存\n\n使用docker镜像：https://www.paddlepaddle.org.cn/install/quick?docurl=undefined\n\n执行步骤如下：\n拉取镜像：\ndocker pull ccr-2vdh3abv-pub.cnc.bj.baidubce.com/device/paddle-npu:cann80RC2-ubuntu20-npu-base-x86_64-gcc84 # X86 架构\n\ndocker pull ccr-2vdh3abv-pub.cnc.bj.baidubce.com/device/paddle-npu:cann80RC2-ubuntu20-npu-base-aarch64-gcc84 # ARM 架构\n\n参考如下命令启动容器，ASCEND_RT_VISIBLE_DEVICES 可指定可见的 NPU 卡号：\ndocker run -it --name paddle-npu-dev -v $(pwd):/work \\\n    --privileged --network=host --shm-size=128G -w=/work \\\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n    -v /usr/local/dcmi:/usr/local/dcmi \\\n    -e ASCEND_RT_VISIBLE_DEVICES=\"0,1,2,3,4,5,6,7\"\\\n    ccr-2vdh3abv-pub.cnc.bj.baidubce.com/device/paddle-npu:cann80RC2-ubuntu20-$(uname -m)-gcc84-py39 /bin/bash\n\n安装PaddlePaddle。该命令会自动安装飞桨主框架的3.0版本：\npython -m pip install paddlepaddle==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/\n\nλ  /work/PaddleSpeech {develop} python -m pip install paddlepaddle==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/\nLooking in indexes: https://www.paddlepaddle.org.cn/packages/stable/cpu/\nRequirement already satisfied: paddlepaddle==3.0.0 in /usr/local/lib/python3.9/dist-packages (3.0.0)\nRequirement already satisfied: httpx in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (0.27.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (1.26.4)\nCollecting protobuf>=3.20.2 (from paddlepaddle==3.0.0)\n  Downloading https://paddle-whl.bj.bcebos.com/stable/cpu/protobuf/protobuf-6.30.1-cp39-abi3-manylinux2014_aarch64.whl (317 kB)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (10.3.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (5.1.1)\nRequirement already satisfied: astor in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (0.8.1)\nRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (3.3.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (3.2.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from paddlepaddle==3.0.0) (4.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.9/dist-packages (from httpx->paddlepaddle==3.0.0) (4.3.0)\nRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->paddlepaddle==3.0.0) (2019.11.28)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.9/dist-packages (from httpx->paddlepaddle==3.0.0) (1.0.5)\nRequirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->paddlepaddle==3.0.0) (2.8)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->paddlepaddle==3.0.0) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/dist-packages (from httpcore==1.*->httpx->paddlepaddle==3.0.0) (0.14.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from anyio->httpx->paddlepaddle==3.0.0) (1.2.1)\nInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.0\n    Uninstalling protobuf-3.20.0:\n      Successfully uninstalled protobuf-3.20.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nppdiffusers 0.29.0 requires paddlenlp>=2.7.2, but you have paddlenlp 2.5.2 which is incompatible.\nwandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.15.0; python_version == \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n\n安装CustomDevice。该命令会自动安装飞桨Custom Device的3.0版本：\npython -m pip install paddle-custom-npu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/npu/\n\n\npip install pytest-runner -i https://pypi.tuna.tsinghua.edu.cn/simple\n\npip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple\n\nλ /work/PaddleSpeech {develop} pip install paddlenlp==2.7.2\n\nDownloading paddlenlp-2.7.2-py3-none-any.whl (2.8 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 5.1 MB/s eta 0:00:00\nInstalling collected packages: paddlenlp\n  Attempting uninstall: paddlenlp\n    Found existing installation: paddlenlp 2.5.2\n    Uninstalling paddlenlp-2.5.2:\n      Successfully uninstalled paddlenlp-2.5.2\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npaddlespeech 0.0.0 requires librosa>=0.9, but you have librosa 0.8.1 which is incompatible.\npaddlespeech 0.0.0 requires praatio>=6.0.0, but you have praatio 5.0.0 which is incompatible.\n\n\npip install librosa==0.9\n\nCollecting librosa==0.9\n\n  Downloading librosa-0.9.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (3.0.1)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (1.13.0)\nRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (1.4.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (1.4.0)\nRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (5.1.1)\nRequirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (0.2.2)\nRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (0.59.1)\nRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (1.8.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9) (24.0)\nRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa==0.9) (0.42.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa==0.9) (4.2.1)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa==0.9) (2.32.3)\nRequirement already satisfied: six>=1.3 in /usr/lib/python3/dist-packages (from resampy>=0.2.2->librosa==0.9) (1.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->librosa==0.9) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.10.2->librosa==0.9) (1.16.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9) (1.26.20)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9) (2019.11.28)\nDownloading librosa-0.9.0-py3-none-any.whl (211 kB)\nInstalling collected packages: librosa\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.8.1\n    Uninstalling librosa-0.8.1:\n      Successfully uninstalled librosa-0.8.1\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npaddlespeech 0.0.0 requires praatio>=6.0.0, but you have praatio 5.0.0 which is incompatible.\n\npip install praatio==6.0.0\n\nCollecting praatio==6.0.0\n  Downloading praatio-6.0.0-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from praatio==6.0.0) (4.13.2)\nDownloading praatio-6.0.0-py3-none-any.whl (79 kB)\nInstalling collected packages: praatio\n  Attempting uninstall: praatio\n    Found existing installation: praatio 5.0.0\n    Uninstalling praatio-5.0.0:\n      Successfully uninstalled praatio-5.0.0\nSuccessfully installed praatio-6.0.0\n\n\npushd tools\nbash extras/install_openblas.sh\nbash extras/install_kaldi.sh\npopd\n\n执行单机推理指令没有问题：\npaddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\n\n但是执行起服务的脚本就会出现问题：\npaddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\n\n终端打印如下：\nλ  /work/PaddleSpeech {develop} paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\nI0414 15:31:43.033342 40448 init.cc:237] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.9/dist-packages/paddle_custom_device\nI0414 15:31:43.033416 40448 init.cc:146] Try loading custom device libs from: [/usr/local/lib/python3.9/dist-packages/paddle_custom_device]\nI0414 15:31:43.711776 40448 custom_device_load.cc:52] Succeed in loading custom runtime in lib: /usr/local/lib/python3.9/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\nI0414 15:31:43.711849 40448 custom_device_load.cc:59] Skipped lib [/usr/local/lib/python3.9/dist-packages/paddle_custom_device/libpaddle-custom-npu.so]: no custom engine Plugin symbol in this lib.\nI0414 15:31:43.721235 40448 custom_kernel.cc:63] Succeed in loading 358 custom kernel(s) from loaded lib(s), will be used like native ones.\nI0414 15:31:43.721439 40448 init.cc:158] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.9/dist-packages/paddle_custom_device]\nI0414 15:31:43.721496 40448 init.cc:243] CustomDevice: npu, visible devices count: 8\n[2025-04-14 15:31:52,452] [    INFO] - start to init the engine\n[2025-04-14 15:31:52,452] [    INFO] - asr : python engine.\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 478M/478M [02:02<00:00, 3.90MB/s]\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\nERROR: Could not find a version that satisfies the requirement paddlespeech_ctcdecoders (from versions: none)\nERROR: No matching distribution found for paddlespeech_ctcdecoders\nW0414 15:34:21.756860 40448 dygraph_functions.cc:84820] got different data type, run type promotion automatically, this may cause data type been changed.\ndlsym aclnnStridedSliceAssignV2GetWorkspaceSize from libopapi.so failed, error:/usr/local/Ascend/ascend-toolkit/latest/lib64/libopapi.so: undefined symbol: aclnnStridedSliceAssignV2GetWorkspaceSize.dlsym[2025-04-14 15:34:36,395] [    INFO] - Initialize ASR server engine successfully on device: npu:0.lib64/libopapi.so: undefined symbol: aclnnStridedSliceAssignV2.-\n[2025-04-14 15:34:36,396] [    INFO] - tts : python engine.\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72.8M/72.8M [00:17<00:00, 4.15MB/s]\n[2025-04-14 15:35:06,334] [    INFO] - Already cached /root/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\n[2025-04-14 15:35:06,349] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\n[2025-04-14 15:35:06,350] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\n[2025-04-14 15:35:39,799] [    INFO] - Initialize TTS server engine successfully on device: npu:0.\n[2025-04-14 15:35:39,799] [    INFO] - cls : python engine.\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 366M/366M [01:28<00:00, 4.12MB/s]\n[2025-04-14 15:37:26,438] [    INFO] - Initialize CLS server engine successfully on device: npu:0.\n[2025-04-14 15:37:26,439] [    INFO] - text : python engine.\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 366M/366M [01:41<00:00, 3.59MB/s]\n[2025-04-14 15:39:21,417] [    INFO] - Loading configuration file /root/.paddlespeech/models/ernie_linear_p3_wudao-punc-zh/1.0/ernie_linear_p3_wudao-punc-zh.tar/ckpt/model_config.json\n[2025-04-14 15:39:21,419] [    INFO] - Configuration saved in /root/.paddlespeech/models/ernie_linear_p3_wudao-punc-zh/1.0/ernie_linear_p3_wudao-punc-zh.tar/ckpt/config.json\n[2025-04-14 15:39:21,420] [    INFO] - Loading weights file /root/.paddlespeech/models/ernie_linear_p3_wudao-punc-zh/1.0/ernie_linear_p3_wudao-punc-zh.tar/ckpt/model_state.pdparams\n[2025-04-14 15:39:21,760] [    INFO] - Loaded weights file from disk, setting weights to model.\n[2025-04-14 15:39:34,028] [    INFO] - All model checkpoint weights were used when initializing ErnieForTokenClassification.\n\n[2025-04-14 15:39:34,029] [    INFO] - All the weights of ErnieForTokenClassification were initialized from the model checkpoint at /root/.paddlespeech/models/ernie_linear_p3_wudao-punc-zh/1.0/ernie_linear_p3_wudao-punc-zh.tar/ckpt.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieForTokenClassification for predictions without further training.\n[2025-04-14 15:39:34,033] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie/vocab.txt and saved to /root/.paddlenlp/models/ernie-1.0\n[2025-04-14 15:39:34,600] [    INFO] - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie/vocab.txt\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 89.5k/89.5k [00:00<00:00, 870kB/s]\n[2025-04-14 15:39:34,965] [    INFO] - tokenizer config file saved in /root/.paddlenlp/models/ernie-1.0/tokenizer_config.json\n[2025-04-14 15:39:34,965] [    INFO] - Special tokens file saved in /root/.paddlenlp/models/ernie-1.0/special_tokens_map.json\n[2025-04-14 15:39:34,966] [    INFO] - Using model: ernie_linear_p3_wudao.\n[2025-04-14 15:39:34,966] [    INFO] - Initialize Text server engine successfully on device: npu:0.\n[2025-04-14 15:39:34,966] [    INFO] - vector : python engine.\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 266M/266M [01:04<00:00, 4.11MB/s]\n[2025-04-14 15:40:43,137] [    INFO] - Initialize Vector server engine successfully on device: npu:0.\nBuilding prefix dict from the default dictionary ...\nLoading model from cache /tmp/jieba.cache\nLoading model cost 0.850 seconds.\nPrefix dict has been built successfully.\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\nWarning: tiling offset out of range, index: 32\n[2025-04-14 15:42:29,955] [   ERROR] - Failed to warm up on tts engine.\n[2025-04-14 15:42:29,955] [   ERROR] - (Unimplemented) npu npu only support mode=constant right now,but received mode is reflect .\n  [Hint: Expected mode == \"constant\", but received mode:reflect != \"constant\":constant.] (at /paddle/backends/npu/kernels/pad3d_kernel.cc:43)\n\n\n没有Traceback信息，也不知道哪个模块出的问题，从而导致的这个报错。搜索了一下paddlespeech中有哪些模块使用了mode='reflect'字段。\nλ /work/PaddleSpeech {develop} grep -R 'mode=\"reflect\"' .\n./build/lib/paddlespeech/vector/models/ecapa_tdnn.py:            padding_mode=\"reflect\", ):\n./build/lib/paddlespeech/t2s/exps/gan_vocoder/preprocess.py:                y, (0, num_frames * config.n_shift - y.size), mode=\"reflect\")\n./build/lib/paddlespeech/t2s/exps/jets/preprocess.py:                mode=\"reflect\")\n./build/lib/paddlespeech/t2s/exps/vits/preprocess.py:                mode=\"reflect\")\n./build/lib/paddlespeech/t2s/audio/audio.py:                 pad_mode=\"reflect\",\n./build/lib/paddlespeech/audio/transform/spectrogram.py:         pad_mode=\"reflect\"):\n./build/lib/paddlespeech/audio/transform/spectrogram.py:        pad_mode=\"reflect\", ):\n./build/lib/paddlespeech/audio/transform/spectrogram.py:            pad_mode=\"reflect\", ):\n./build/lib/paddlespeech/audiotools/core/audio_signal.py:            mode=\"reflect\",\ngrep: ./examples/voxceleb/sv0/utils: No such file or directory\ngrep: ./examples/librispeech/asr2/steps: No such file or directory\ngrep: ./runtime/examples/u2pp_ol/wenetspeech/utils: No such file or directory\ngrep: ./runtime/examples/text_lm/utils: No such file or directory\ngrep: ./tools/kaldi/src/nnet2bin/raw-nnet-init: No such file or directory\n./paddlespeech/vector/models/ecapa_tdnn.py:            padding_mode=\"reflect\", ):\n./paddlespeech/t2s/exps/gan_vocoder/preprocess.py:                y, (0, num_frames * config.n_shift - y.size), mode=\"reflect\")\n./paddlespeech/t2s/exps/jets/preprocess.py:                mode=\"reflect\")\n./paddlespeech/t2s/exps/vits/preprocess.py:                mode=\"reflect\")\n./paddlespeech/t2s/audio/audio.py:                 pad_mode=\"reflect\",\n./paddlespeech/audio/transform/spectrogram.py:         pad_mode=\"reflect\"):\n./paddlespeech/audio/transform/spectrogram.py:        pad_mode=\"reflect\", ):\n./paddlespeech/audio/transform/spectrogram.py:            pad_mode=\"reflect\", ):\n./paddlespeech/audiotools/core/audio_signal.py:            mode=\"reflect\",\ngrep: ./demos/TTSArmLinux/build-depends.sh: No such file or directory\ngrep: ./demos/TTSArmLinux/src/third-party: No such file or directory\ngrep: ./demos/TTSArmLinux/src/TTSCppFrontend: No such file or directory\ngrep: ./env/bin/python: No such file or directory\ngrep: ./env/bin/python3.10: No such file or directory\ngrep: ./env/bin/python3: No such file or directory\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                  output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                           output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                          output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_morphology.py:                 mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/tests/test_filters.py:                       mode=\"reflect\", cval=0, ):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def correlate1d(input, weights, axis=-1, output=None, mode=\"reflect\",\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def convolve1d(input, weights, axis=-1, output=None, mode=\"reflect\",\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                      mode=\"reflect\", cval=0.0, truncate=4.0, *, radius=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                    mode=\"reflect\", cval=0.0, truncate=4.0, *, radius=None,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def prewitt(input, axis=-1, output=None, mode=\"reflect\", cval=0.0):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def sobel(input, axis=-1, output=None, mode=\"reflect\", cval=0.0):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def generic_laplace(input, derivative2, output=None, mode=\"reflect\",\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def laplace(input, output=None, mode=\"reflect\", cval=0.0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def gaussian_laplace(input, sigma, output=None, mode=\"reflect\",\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                               mode=\"reflect\", cval=0.0,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                                mode=\"reflect\", cval=0.0, *, axes=None,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:def uniform_filter(input, size=3, output=None, mode=\"reflect\",\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                   mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                   mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                 mode=\"reflect\", cval=0.0, origin=0, operation='rank',\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                  mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                      output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                     output=None, mode=\"reflect\", cval=0.0, origin=0,\n./env/lib64/python3.10/site-packages/scipy/ndimage/_filters.py:                   output=None, mode=\"reflect\", cval=0.0, origin=0,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                  output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                           output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                          output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                 output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_morphology.py:                 mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/tests/test_filters.py:                       mode=\"reflect\", cval=0, ):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def correlate1d(input, weights, axis=-1, output=None, mode=\"reflect\",\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def convolve1d(input, weights, axis=-1, output=None, mode=\"reflect\",\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                      mode=\"reflect\", cval=0.0, truncate=4.0, *, radius=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                    mode=\"reflect\", cval=0.0, truncate=4.0, *, radius=None,\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def prewitt(input, axis=-1, output=None, mode=\"reflect\", cval=0.0):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def sobel(input, axis=-1, output=None, mode=\"reflect\", cval=0.0):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def generic_laplace(input, derivative2, output=None, mode=\"reflect\",\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def laplace(input, output=None, mode=\"reflect\", cval=0.0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def gaussian_laplace(input, sigma, output=None, mode=\"reflect\",\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                               mode=\"reflect\", cval=0.0,\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                                mode=\"reflect\", cval=0.0, *, axes=None,\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:def uniform_filter(input, size=3, output=None, mode=\"reflect\",\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                     mode=\"reflect\", cval=0.0, origin=0):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                   mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                   mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                 mode=\"reflect\", cval=0.0, origin=0, operation='rank',\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                  mode=\"reflect\", cval=0.0, origin=0, *, axes=None):\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                      output=None, mode=\"reflect\", cval=0.0, origin=0, *,\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                     output=None, mode=\"reflect\", cval=0.0, origin=0,\n./env/lib/python3.10/site-packages/scipy/ndimage/_filters.py:                   output=None, mode=\"reflect\", cval=0.0, origin=0,\n\n\n\n所以我写了一个脚本，准备将paddlespeech的所有关联模块中的mode='reflect'改为mode='constant'，执行完下面这个脚本之后依然报上面的错误\n\nimport os\n\n# 查找和替换字符串，仅关注 mode\nsearch_texts = [\n    'mode=\"reflect\"'\n]\nreplace_texts = [\n    'mode=\"constant\", constant_values=0'\n]\n\n# 指定目录（根据实际路径调整）\ndirectory_to_search = './paddlespeech'\n\ndef replace_in_file(file_path):\n    \"\"\"替换文件中的mode参数\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            file_content = file.read()\n        \n        # 检查并替换模式\n        for search_text, replace_text in zip(search_texts, replace_texts):\n            if search_text in file_content:\n                file_content = file_content.replace(search_text, replace_text)\n                \n        # 写回修改后的内容\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(file_content)\n                \n        print(f'Modified: {file_path}')\n    except Exception as e:\n        print(f\"Failed to modify {file_path}. Error: {e}\")\n\ndef walk_and_replace(directory):\n    \"\"\"遍历目录并在文件中替换模式\"\"\"\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                replace_in_file(file_path)\n\n# 运行替换操作\nwalk_and_replace(directory_to_search)\n\n\n现在我就不知道怎么解决了，还请百度的官方工作技术人员帮忙解决下，要在NPU上成功起服务，谢谢！\n",
        "state": "closed",
        "user": "Deuteronomy6",
        "closed_by": "zxcd",
        "created_at": "2025-04-14T09:32:12+00:00",
        "updated_at": "2025-06-05T10:27:49+00:00",
        "closed_at": "2025-06-03T08:39:47+00:00",
        "comments_count": [
            "zxcd",
            "Tracy-git",
            "yzztin",
            "yzztin"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4059,
        "title": "PaddleSpeech支持端侧部署吗",
        "body": "PaddleSpeech支持端侧部署吗，即在手机端部署离线包实现语音相关任务",
        "state": "closed",
        "user": "sdemon915gh",
        "closed_by": "zxcd",
        "created_at": "2025-04-15T04:03:43+00:00",
        "updated_at": "2025-06-03T08:39:58+00:00",
        "closed_at": "2025-06-03T08:39:58+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4060,
        "title": "[TTS]Out of memory with fastspeech2_csmsc",
        "body": "参考https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/csmsc/tts3\n运行代码，环境配置如下：\npython3 -m pip install paddlepaddle-gpu==2.5.2.post117 paddlespeech  -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n\n显卡配置：H800 80G cuda 11.8\n\nBuilding prefix dict from the default dictionary ...\n[2025-04-16 14:33:00,898] [   DEBUG] __init__.py:113 - Building prefix dict from the default dictionary ...\nLoading model from cache /tmp/jieba.cache\n[2025-04-16 14:33:00,899] [   DEBUG] __init__.py:132 - Loading model from cache /tmp/jieba.cache\nLoading model cost 0.505 seconds.\n[2025-04-16 14:33:01,403] [   DEBUG] __init__.py:164 - Loading model cost 0.505 seconds.\nPrefix dict has been built successfully.\n[2025-04-16 14:33:01,403] [   DEBUG] __init__.py:166 - Prefix dict has been built successfully.\nW0416 14:33:12.098174  5426 interpreter_util.cc:838] range raises an exception paddle::memory::allocation::BadAlloc, \n\n--------------------------------------\nC++ Traceback (most recent call last):\n--------------------------------------\n0   run_program_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor*, std::allocator<paddle::Tensor*> >&, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, std::vector<paddle::Tensor*, std::allocator<paddle::Tensor*> >&, paddle::framework::AttributeMap const&)\n1   RunProgramAPI(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor*, std::allocator<paddle::Tensor*> >&, std::vector<paddle::framework::Scope*, std::allocator<paddle::framework::Scope*> >&, std::vector<paddle::Tensor*, std::allocator<paddle::Tensor*> >&, bool, paddle::framework::AttributeMap const&)\n2   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)\n3   paddle::framework::interpreter::BuildOpFuncList(phi::Place const&, paddle::framework::BlockDesc const&, std::set<std::string, std::less<std::string >, std::allocator<std::string > > const&, std::vector<paddle::framework::OpFuncNode, std::allocator<paddle::framework::OpFuncNode> >*, paddle::framework::VariableScope*, paddle::framework::interpreter::ExecutionConfig const&, bool, bool)\n4   void phi::ArangeKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)\n5   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const\n6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const\n7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)\n8   paddle::memory::allocation::Allocator::Allocate(unsigned long)\n9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)\n10  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n11  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n12  paddle::memory::allocation::Allocator::Allocate(unsigned long)\n13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)\n14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)\n15  phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\n\n----------------------\nError Message Summary:\n----------------------\nResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 7.019809EB memory on GPU 0, 915.187500MB memory has been allocated and available memory is only 78.426208GB.\n\n显示需要7.019809EB，修改batchsize无效",
        "state": "closed",
        "user": "DBDXSS",
        "closed_by": "zxcd",
        "created_at": "2025-04-16T06:39:53+00:00",
        "updated_at": "2025-06-03T08:40:17+00:00",
        "closed_at": "2025-06-03T08:40:17+00:00",
        "comments_count": [
            "DBDXSS",
            "zxcd",
            "DBDXSS",
            "DBDXSS",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4062,
        "title": "csmcs/voc3训练mb_melgan模型，推理结果异常",
        "body": "## General Question\n看了一圈提问，极少有人提及vocoder的训练，我这边训练结果异常，想请教下各位。\n我用csmcs/voc3里面的run.sh代码训练mb_melgan，参数和代码都没动，baker_alignment_tone.tar.gz也是直接下载官方的，没有自己做mfa，推理的时候采用如下代码\nif [ ${stage} -le 1 ] && [ ${stop_stage} -ge 1 ]; then\n    FLAGS_allocator_strategy=naive_best_fit \\\n    FLAGS_fraction_of_gpu_memory_to_use=0.01 \\\n    python3 ${BIN_DIR}/../synthesize_e2e.py \\\n        --am=speedyspeech_csmsc \\\n        --am_config=speedyspeech_csmsc_ckpt_0.2.0/default.yaml \\\n        --am_ckpt=speedyspeech_csmsc_ckpt_0.2.0/snapshot_iter_30600.pdz \\\n        --am_stat=speedyspeech_csmsc_ckpt_0.2.0/feats_stats.npy \\\n        --voc=mb_melgan_csmsc \\\n        --voc_config=mb_melgan_train/default.yaml \\\n        --voc_ckpt=mb_melgan_train/snapshot_iter_1000000.pdz\\\n        --voc_stat=mb_melgan_train/feats_stats.npy \\\n        --lang=zh \\\n        --text=${BIN_DIR}/../../assets/sentences.txt \\\n        --output_dir=${train_output_path}/test_e2e \\\n        --phones_dict=dump/phone_id_map.txt \\\n        --tones_dict=dump/tone_id_map.txt \\\nfi\n上面mb_melgan_train是我训练出来的mb_melgan，speedyspeech模型是官方下载，推理出来的音频如下，声音完全不对：\n[001_train.zip](https://github.com/user-attachments/files/19845052/001_train.zip)\n\n如果把上面推理代码里的mb_melgan_train改成官方的mb_melgan_csmsc_ckpt_0.1.1，推理结果正常，音频如下：\n[001.zip](https://github.com/user-attachments/files/19845073/001.zip)\n\n对比了下最后的eval loss，第一行是官方提供的，第二行是我训练的\n| Model   | Step              | eval/generator_loss | eval/log_stft_magnitude_loss | eval/spectral_convergence_loss | eval/sub_log_stft_magnitude_loss | eval/sub_spectral_convergence_loss |\n|---------|-------------------|---------------------|------------------------------|--------------------------------|----------------------------------|-------------------------------------|\n| default | 1(gpu) x 1000000  | 2.4851              | 0.71778                      | 0.2761                         | 0.66334                          | 0.2777                              |\n| mine    | 1(gpu) x 1000000  | 3.455973            | 0.857833                     | 0.469584                       | 0.799196                         | 0.469322                            |\n\n\n模型文件放在网盘里面了，链接: https://pan.baidu.com/s/1AGMj4Qx3FRUAxJAV_f2Rbg?pwd=j4n8 提取码: j4n8\n训练日志在这里，链接: https://pan.baidu.com/s/1Mtz_NKaDf5UWMduTksOkDw?pwd=ppme 提取码: ppme\n\n希望有相关经验的朋友帮我看看，万分感激！\n",
        "state": "closed",
        "user": "elliotzheng",
        "closed_by": "elliotzheng",
        "created_at": "2025-04-22T07:15:10+00:00",
        "updated_at": "2025-06-10T03:58:52+00:00",
        "closed_at": "2025-06-10T03:58:52+00:00",
        "comments_count": [
            "zxcd",
            "elliotzheng",
            "zxcd",
            "elliotzheng"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4063,
        "title": "源代码安装PaddleSpeech问题",
        "body": "在服务器上用源代码执行pip install .安装PaddleSpeech，为啥下载速度只有二十几kb，我在本地电脑上试的时候很快，为什么",
        "state": "closed",
        "user": "wangtai5201a",
        "closed_by": "zxcd",
        "created_at": "2025-04-22T07:18:26+00:00",
        "updated_at": "2025-06-03T08:49:32+00:00",
        "closed_at": "2025-06-03T08:49:32+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4064,
        "title": "使用demos/speech_web/speech_server示例时报错",
        "body": "使用命令 python main.py --port 8010启动时\n报错：\n[2025-04-23 09:51:39,820] [    INFO] - The inference model save in the path:source/model\\static\\inference\nTraceback (most recent call last):\n  File \"main.py\", line 65, in <module>\n    chatbot = Robot(\n  File \"D:\\work_xl\\yuyin_asr\\PaddleSpeech-r1.5\\PaddleSpeech-r1.5\\demos\\speech_web\\speech_server\\src\\robot.py\", line 17, in __init__\n    self.nlp = NLP(ie_model_path=ie_model_path)\n  File \"D:\\work_xl\\yuyin_asr\\PaddleSpeech-r1.5\\PaddleSpeech-r1.5\\demos\\speech_web\\speech_server\\src\\SpeechBase\\nlp.py\", line 8, in __init__\n    self.ie_model = Taskflow(\n  File \"C:\\Users\\xl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\paddlenlp\\taskflow\\taskflow.py\", line 804, in __init__\n    self.task_instance = task_class(\n  File \"C:\\Users\\xl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\paddlenlp\\taskflow\\information_extraction.py\", line 536, in __init__\n    self._get_inference_model()\n  File \"C:\\Users\\xl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\paddlenlp\\taskflow\\task.py\", line 371, in _get_inference_model\n    self._config = paddle.inference.Config(self._static_model_file, self._static_params_file)\nRuntimeError: (NotFound) Cannot open file source/model\\static\\inference.pdmodel, please confirm whether the file is normal.\n  [Hint: Expected paddle::inference::IsFileExists(prog_file_) == true, but received paddle::inference::IsFileExists(prog_file_):0 != true:1.] (at ..\\paddle\\fluid\\inference\\api\\analysis_config.cc:117)\n",
        "state": "open",
        "user": "xxll569",
        "closed_by": null,
        "created_at": "2025-04-23T01:58:30+00:00",
        "updated_at": "2025-06-03T09:00:01+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "KevinLoveGitHub",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4065,
        "title": "语音合成问题",
        "body": "为什么合成的语音总感觉结束的很快呢，最后那个字说完立马就结束了，要怎么处理下呢",
        "state": "closed",
        "user": "wangtai5201a",
        "closed_by": "zxcd",
        "created_at": "2025-04-23T03:32:13+00:00",
        "updated_at": "2025-06-03T09:00:35+00:00",
        "closed_at": "2025-06-03T09:00:35+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4066,
        "title": "流式语音合成该怎样支持合成英文，流式语音识别该如何支持英文呢？",
        "body": "我在使用web demo的时候发现其自带的流式tts和asr不支持英文，我想知道该怎么样才可以使它支持英文，求帮忙！！！\n",
        "state": "closed",
        "user": "ddbegun",
        "closed_by": "zxcd",
        "created_at": "2025-04-23T14:54:46+00:00",
        "updated_at": "2025-06-03T09:01:09+00:00",
        "closed_at": "2025-06-03T09:01:09+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4067,
        "title": "docker build卡住了。",
        "body": "```\ndocker buildx build --platform linux/arm64 -f Dockerfile  --progress=plain -t tts-paddlespeech-service .\n#0 building with \"desktop-linux\" instance using docker driver\n\n#1 [internal] load build definition from Dockerfile\n#1 transferring dockerfile: 621B done\n#1 DONE 0.0s\n\n#2 [internal] load metadata for registry.baidubce.com/paddlepaddle/paddle:3.0.0b1\n```\n到这里运行不动了。请问怎么一回事。用的是这个docker:ubuntu20-cpu",
        "state": "closed",
        "user": "yourengod",
        "closed_by": "zxcd",
        "created_at": "2025-04-27T01:58:24+00:00",
        "updated_at": "2025-06-03T09:00:22+00:00",
        "closed_at": "2025-06-03T09:00:22+00:00",
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4069,
        "title": "[S2T]AttributeError: module 'numpy' has no attribute 'complex'.",
        "body": "When I execute the following code：\n\n`paddlespeech asr --lang zh --input evkuv-k8d46.wav`\n\n`                                        \n/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/eashion/.pyenv/versions/piddlespeech/bin/paddlespeech\", line 5, in <module>\n    from paddlespeech.cli.entry import _execute\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/__init__.py\", line 16, in <module>\n    from .base_commands import BaseCommand\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/base_commands.py\", line 20, in <module>\n    from ..resource import CommonTaskResource\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/resource/__init__.py\", line 14, in <module>\n    from .resource import CommonTaskResource\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/resource/resource.py\", line 20, in <module>\n    from ..cli.utils import download_and_decompress\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/utils.py\", line 26, in <module>\n    import paddle\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/__init__.py\", line 91, in <module>\n    import paddle.text\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/text/__init__.py\", line 15, in <module>\n    from .datasets import (\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/text/datasets/__init__.py\", line 15, in <module>\n    from .conll05 import Conll05st  # noqa: F401\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/text/datasets/conll05.py\", line 27, in <module>\n    from paddle.dataset.common import _check_exists_and_download\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/dataset/__init__.py\", line 18, in <module>\n    from . import (  # noqa: F401\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/dataset/flowers.py\", line 36, in <module>\n    from paddle.dataset.image import load_image_bytes, simple_transform\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddle/dataset/image.py\", line 39, in <module>\n    import cv2\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/cv2/__init__.py\", line 181, in <module>\n    bootstrap()\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/cv2/__init__.py\", line 153, in bootstrap\n    native_module = importlib.import_module(\"cv2\")\n  File \"/Users/eashion/.pyenv/versions/3.10.17/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/Users/eashion/.pyenv/versions/piddlespeech/bin/paddlespeech\", line 8, in <module>\n    sys.exit(_execute())\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/entry.py\", line 40, in _execute\n    exec(\"from {} import {}\".format(module, cls))\n  File \"<string>\", line 1, in <module>\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/asr/__init__.py\", line 14, in <module>\n    from .infer import ASRExecutor\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/paddlespeech/cli/asr/infer.py\", line 24, in <module>\n    import librosa\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/librosa/__init__.py\", line 211, in <module>\n    from . import core\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/librosa/core/__init__.py\", line 9, in <module>\n    from .constantq import *  # pylint: disable=wildcard-import\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/librosa/core/constantq.py\", line 1059, in <module>\n    dtype=np.complex,\n  File \"/Users/eashion/.pyenv/versions/3.10.17/envs/piddlespeech/lib/python3.10/site-packages/numpy/__init__.py\", line 397, in __getattr__\n    raise AttributeError(__former_attrs__[attr], name=None)\nAttributeError: module 'numpy' has no attribute 'complex'.\n`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n(piddlespeech) `\n\npython --version                                                                     \nPython 3.10.17",
        "state": "closed",
        "user": "kekekekekeshi",
        "closed_by": "zxcd",
        "created_at": "2025-05-13T13:43:53+00:00",
        "updated_at": "2025-06-03T09:00:50+00:00",
        "closed_at": "2025-06-03T09:00:50+00:00",
        "comments_count": [
            "kekekekekeshi",
            "zxcd",
            "kekekekekeshi",
            "kekekekekeshi",
            "kekekekekeshi",
            "zxcd",
            "kekekekekeshi",
            "kekekekekeshi",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4070,
        "title": "[S2T]your demo file zh.wav can't be recognized",
        "body": "For support and discussions, please use our [Discourse forums](https://github.com/PaddlePaddle/DeepSpeech/discussions).\n\nIf you've found a bug then please create an issue with the following information:\n\n**Describe the bug**\nA clear and concise description of what the bug is.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Environment (please complete the following information):**\n - OS: [e.g. Ubuntu]\n - GCC/G++ Version [e.g. 8.3]\n - Python Version [e.g. 3.7]\n - PaddlePaddle Version [e.g. 2.0.0]\n - Model Version [e.g. 2.0.0]\n - GPU/DRIVER Information [e.g. Tesla V100-SXM2-32GB/440.64.00]\n - CUDA/CUDNN Version [e.g. cuda-10.2]\n - MKL Version\n- TensorRT Version\n\n**Additional context**\nAdd any other context about the problem here.\n",
        "state": "closed",
        "user": "zhiweny1122",
        "closed_by": "zxcd",
        "created_at": "2025-05-14T02:00:34+00:00",
        "updated_at": "2025-06-03T09:01:24+00:00",
        "closed_at": "2025-06-03T09:01:24+00:00",
        "comments_count": [
            "zhiweny1122",
            "zxcd",
            "zhiweny1122",
            "zxcd"
        ],
        "labels": [
            "Question",
            "S2T"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4073,
        "title": "[TTS]在TTSArmLinux基础上实现英文tts",
        "body": "使用官方给出的 fastspeech2_ljspeech_pdlite_1.3.0，hifigan_ljspeech_pdlite_1.3.0模型，paddlelite库使用68b66fd35版本，文本预处理得到的phone_id是对的，但最终生成的音频是不对的，声音像鬼畜完全没有词。\nfs=22050，请问可能的原因是什么，该怎么排查？\n谢谢！",
        "state": "open",
        "user": "nuo900617",
        "closed_by": null,
        "created_at": "2025-05-17T15:55:49+00:00",
        "updated_at": "2025-05-20T03:02:00+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "nuo900617",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4078,
        "title": "Linux下安装paddlespeech",
        "body": "安装paddlespeech其中一个依赖是pyworld  但是这个库在Linux下编译未通过，没办法安装怎么办",
        "state": "open",
        "user": "huaijiu9",
        "closed_by": null,
        "created_at": "2025-05-30T09:22:21+00:00",
        "updated_at": "2025-06-03T03:45:17+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4079,
        "title": "[TTS]模型下载失败，ImportError: cannot import name 'download' from 'aistudio_sdk.hub'",
        "body": "我发现最新版本 0.3.0 的 aistudio_sdk 出错 ImportError: cannot import name 'download' from 'aistudio_sdk.hub' ，\npy包的链接：https://pypi.org/project/aistudio-sdk/\n\n可以安装 0.2.6 版本来下载模型文件：`pip install aistudio-sdk==0.2.6`\n\n\n",
        "state": "closed",
        "user": "yzztin",
        "closed_by": "zxcd",
        "created_at": "2025-06-04T09:21:37+00:00",
        "updated_at": "2025-06-11T03:11:21+00:00",
        "closed_at": "2025-06-11T03:11:21+00:00",
        "comments_count": [
            "zxcd",
            "yzztin",
            "yzztin",
            "yzztin",
            "zxcd"
        ],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4083,
        "title": "在 npu 上启动 vector 声纹提取服务失败：ValueError: (InvalidArgument) Broadcast dimension mismatch.",
        "body": "1. 环境：npu 910b\n2. 镜像：ccr-2vdh3abv-pub.cnc.bj.baidubce.com/device/paddle-npu:cann80RC2-ubuntu20-npu-base-aarch64-gcc84\n3. 使用 `./demos/speech_server/conf/application.yaml` 中的默认配置，仅指定 `device` 为 `npu`\n\n完整的报错信息：\n```\n[2025-06-06 21:07:37,565] [    INFO] - feats shape: [1, 80, 500]\n[2025-06-06 21:07:37,565] [    INFO] - audio extract the feats success\n[2025-06-06 21:07:37,566] [    INFO] - start to extract the audio embedding\nTraceback (most recent call last):\n  File \"/work/paddlespeech/PaddleSpeech/paddlespeech/server/restful/vector_api.py\", line 76, in vector\n    audio_vec = connection_handler.run(audio_data, request_body.task)\n  File \"/usr/local/lib/python3.10/dist-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/base/dygraph/base.py\", line 400, in _decorate_function\n    return func(*args, **kwargs)\n  File \"/work/paddlespeech/PaddleSpeech/paddlespeech/server/engine/vector/python/vector_engine.py\", line 60, in run\n    embedding = self.extract_audio_embedding(audio_data)\n  File \"/usr/local/lib/python3.10/dist-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/base/dygraph/base.py\", line 400, in _decorate_function\n    return func(*args, **kwargs)\n  File \"/work/paddlespeech/PaddleSpeech/paddlespeech/server/engine/vector/python/vector_engine.py\", line 145, in extract_audio_embedding\n    embedding = self.model.backbone(feats, lengths).squeeze().numpy()\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/layers.py\", line 1567, in __call__\n    return self.forward(*inputs, **kwargs)\n  File \"/work/paddlespeech/PaddleSpeech/paddlespeech/vector/models/ecapa_tdnn.py\", line 514, in forward\n    x = self.asp(x, lengths=lengths)\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/layers.py\", line 1567, in __call__\n    return self.forward(*inputs, **kwargs)\n  File \"/work/paddlespeech/PaddleSpeech/paddlespeech/vector/models/ecapa_tdnn.py\", line 339, in forward\n    attn = paddle.where(\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/tensor/search.py\", line 787, in where\n    broadcast_shape = paddle.broadcast_shape(x_shape, y_shape)\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/tensor/math.py\", line 5427, in broadcast_shape\n    return core.broadcast_shape(x_shape, y_shape)\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [1536000] and the shape of Y = [1, 3072, 500]. Received [1536000] in X is not equal to [500] in Y at i:2.\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:85)\n```\n\n我修改了代码：将  `paddlespeech.vector.models.ecapa_tdnn.Conv1d` 的 `padding_mode` 参数的默认值从 `reflect` 改为 `constant`\n启动后出现上述报错，如果不做该修改，则会出现报错：`NotImplementedError: (Unimplemented) npu npu only support mode=constant right now,but received mode is replicate . [Hint: Expected mode == \"constant\", but received mode:replicate != \"constant\":constant.] (at /paddle/backends/npu/kernels/pad3d_kernel.cc:43)`，这与 issue https://github.com/PaddlePaddle/PaddleSpeech/issues/4058 相同",
        "state": "closed",
        "user": "yzztin",
        "closed_by": "zxcd",
        "created_at": "2025-06-06T13:21:37+00:00",
        "updated_at": "2025-06-11T03:11:02+00:00",
        "closed_at": "2025-06-11T03:11:02+00:00",
        "comments_count": [
            "zxcd",
            "yzztin",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4085,
        "title": "Inquiry About the License of Pretrained Models",
        "body": "Dear PaddleSpeech Team,\n\nFirst of all, thank you for open-sourcing such an excellent and comprehensive speech processing framework along with pretrained models. Your work greatly contributes to the advancement and application of speech technologies.\n\nI am currently considering using the pretrained models from PaddleSpeech in a commercial project. To ensure compliance, I would like to kindly ask about the licensing of the pretrained model weight files:\n\n- Are all officially released pretrained model weights licensed under the Apache 2.0 License?  \n- Do all the pretrained models explicitly include license declarations or LICENSE files?  \n- Are the datasets used to train these models all cleared for commercial use? If there are restrictions, could you please recommend datasets and corresponding models that are suitable for commercial deployment?\n\nThank you very much for your time and support. I look forward to your reply and wish the PaddleSpeech project continued success!\n\nBest regards,  \nApple-523",
        "state": "closed",
        "user": "Apple-523",
        "closed_by": "Apple-523",
        "created_at": "2025-06-22T15:43:02+00:00",
        "updated_at": "2025-06-23T11:12:00+00:00",
        "closed_at": "2025-06-23T11:12:00+00:00",
        "comments_count": [
            "zxcd",
            "Apple-523"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4089,
        "title": "Request for an iOS Demo for PaddleSpeech TTS/ASR",
        "body": "Hi PaddleSpeech team,\n\nThanks for your great work on PaddleSpeech! I'm very interested in deploying your TTS/ASR models on iOS devices.\n\nCurrently, I noticed there is no official iOS demo or guide provided. Could you kindly consider adding a basic iOS demo (even just a sample using ONNX/NCNN/Metal) for TTS or ASR inference?\n\nThis would be really helpful for developers trying to integrate PaddleSpeech into mobile apps.\n\nThank you in advance!\n\nBest regards,\nApple-523",
        "state": "open",
        "user": "Apple-523",
        "closed_by": null,
        "created_at": "2025-06-24T07:34:16+00:00",
        "updated_at": "2025-06-24T11:51:11+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd"
        ],
        "labels": [
            "feature request"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4091,
        "title": "关于TTS模型商用版权问题",
        "body": "PaddleSpeech团队\n请问https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/zh_en_tts/tts3这里面的模型是否支持商用",
        "state": "closed",
        "user": "EvanZch",
        "closed_by": "EvanZch",
        "created_at": "2025-06-30T09:43:59+00:00",
        "updated_at": "2025-07-04T09:34:30+00:00",
        "closed_at": "2025-07-04T09:34:30+00:00",
        "comments_count": [
            "zxcd",
            "EvanZch",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4092,
        "title": "tts",
        "body": "## General Question\n\n<!--\nBefore asking a question, make sure you have:\n- Baidu/Google your question.\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\n- Read the documentation:\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\n  - [Doc](https://paddlespeech.readthedocs.io/)\n-->\n\n![Image](https://github.com/user-attachments/assets/5a65fb65-057f-4326-b2d8-ef62adbd289e)asr模型能下载，服务能起起来，tts不行",
        "state": "open",
        "user": "shannonDingbai",
        "closed_by": null,
        "created_at": "2025-07-03T02:36:06+00:00",
        "updated_at": "2025-07-08T02:22:53+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "shannonDingbai"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4097,
        "title": "[TTS]小样本微调，不管是自己录制的12个语音还是官方默认的，微调完的声音都有点像机器人，一个字一个字冒出来那种。",
        "body": "\n**Describe the bug**\n遵照官方文档运行vc.py+前端\n使用了两种方式完成小数据集微调，自己录的+官方提供的\n\n发现使用两种方法训练出来的模型进行语音合成，每句话都不流畅，都是一个字一个字冒出来，很像机器人\n而后使用没有微调过的模型推理同样的文字，就很流畅\n\n请问是有什么配置文件需要更改还是代码、版本的问题？\n\n**Environment (please complete the following information):**\n - OS: Ubuntu 22\n - Python Version 3.9\n - CUDA/CUDNN Version cuda-12.6\n \n -- paddle2onnx                 2.0.1\n -- paddlefsl                   1.1.0\n -- paddlenlp                   3.0.0b4\n -- paddlepaddle-gpu            3.1.0\n -- paddlesde                   0.2.5\n -- paddleslim                  2.6.0\n -- paddlespeech                1.5.0\n -- paddlespeech-ctcdecoders    0.2.1\n -- paddlespeech-feat           0.1.0\n\n**Additional context**\n下面的zip为微调前后音色对比，微调使用默认的12句wav。\n\n[微调与否音色对比.zip](https://github.com/user-attachments/files/21121880/default.zip)\n",
        "state": "open",
        "user": "ppsohandsome",
        "closed_by": null,
        "created_at": "2025-07-08T12:37:49+00:00",
        "updated_at": "2025-07-08T12:37:49+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": [
            "Bug",
            "T2S"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4093,
        "title": "argument 'X' (position 0) must be Tensor, but got tuple (at ../paddle/fluid/pybind/eager_utils.cc",
        "body": "when i execute cmd:paddlespeech kws --input ./hey_snips.wav -v\nthe following error show up\n```\n/mnt/storage/PaddleSpeech/tools/venv/lib/python3.9/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\nW0703 17:08:06.219745 259403 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.4, Runtime API Version: 12.8\nValueError: (InvalidArgument) linear(): argument 'X' (position 0) must be Tensor, but got tuple (at ../paddle/fluid/pybind/eager_utils.cc:1343)\n```\npip show paddlepaddle-gpu,which i install on https://www.paddlepaddle.org.cn/packages/nightly/cu128/paddlepaddle-gpu/\n```\nName: paddlepaddle-gpu\nVersion: 3.0.0.dev20250702\nSummary: Parallel Distributed Deep Learning\nHome-page: https://www.paddlepaddle.org.cn/\nAuthor: \nAuthor-email: Paddle-better@baidu.com\nLicense: Apache Software License\nLocation: /mnt/storage/PaddleSpeech/tools/venv/lib/python3.9/site-packages\n```\npip show paddlespeech,which i install thr pip install -e .[develop] -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\nName: paddlespeech\nVersion: 0.0.0\nSummary: Speech tools and models based on Paddlepaddle\nHome-page: https://github.com/PaddlePaddle/PaddleSpeech\nAuthor: PaddlePaddle Speech and Language Team\nAuthor-email: paddlesl@baidu.com\nLicense: Apache 2.0\nLocation: /mnt/storage/PaddleSpeech\nEditable project location: /mnt/storage/PaddleSpeech\n```\nnvcc -V\n```\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2025 NVIDIA Corporation\nBuilt on Fri_Feb_21_20:23:50_PST_2025\nCuda compilation tools, release 12.8, V12.8.93\nBuild cuda_12.8.r12.8/compiler.35583870_0\n```\nThe error occurs in eager_utils.cc, suggesting a problem in the PaddlePaddle backend,i also try running a different PaddleSpeech example to confirm if the issue is specific to the KWS task: \n```\npaddlespeech asr --input ./hey_snips.wav --lang en --model transformer_librispeech\n/mnt/storage/PaddleSpeech/tools/venv/lib/python3.9/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\nW0703 18:09:24.280385 280131 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.4, Runtime API Version: 12.8\nW0703 18:09:24.409716 280131 dygraph_functions.cc:92042] got different data type, run type promotion automatically, this may cause data type been changed.\nhe snipped\n```",
        "state": "open",
        "user": "frankchieng1982",
        "closed_by": null,
        "created_at": "2025-07-03T09:19:27+00:00",
        "updated_at": "2025-07-07T04:35:05+00:00",
        "closed_at": null,
        "comments_count": [
            "frankchieng1982",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4094,
        "title": "启动在线推理服务失败",
        "body": "按教程构建，paddlespeech asr --lang zh --input zh.wav 可以正常运行\nroot@bms-58150179-001:/work/PaddleSpeech# paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml 运行报错如下\nroot@bms-58150179-001:/work/PaddleSpeech#  paddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\nI0703 20:14:36.429092   313 init.cc:238] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.10/dist-packages/paddle_custom_device\nI0703 20:14:36.429157   313 init.cc:146] Try loading custom device libs from: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\nI0703 20:14:37.282016   313 custom_device_load.cc:51] Succeed in loading custom runtime in lib: /usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\nI0703 20:14:37.282083   313 custom_device_load.cc:58] Skipped lib [/usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-npu.so]: no custom engine Plugin symbol in this lib.\nI0703 20:14:37.287448   313 custom_kernel.cc:68] Succeed in loading 359 custom kernel(s) from loaded lib(s), will be used like native ones.\nI0703 20:14:37.287690   313 init.cc:158] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\nI0703 20:14:37.287739   313 init.cc:244] CustomDevice: npu, visible devices count: 8\nW0703 20:14:40.191830   313 ir_context.cc:306] custom_op.my_add_n op already registered.\nW0703 20:14:40.191898   313 custom_operator.cc:967] Operator (my_add_n) has been registered.\nW0703 20:14:40.191918   313 ir_context.cc:306] custom_op.update_inputs_ op already registered.\nW0703 20:14:40.191926   313 custom_operator.cc:967] Operator (update_inputs) has been registered.\nW0703 20:14:40.191943   313 ir_context.cc:306] custom_op.get_output_ op already registered.\nW0703 20:14:40.191951   313 custom_operator.cc:967] Operator (get_output) has been registered.\nW0703 20:14:40.191962   313 ir_context.cc:306] custom_op.set_stop_value_multi_ends op already registered.\nW0703 20:14:40.191967   313 custom_operator.cc:967] Operator (set_stop_value_multi_ends) has been registered.\nW0703 20:14:40.191985   313 ir_context.cc:306] custom_op.fused_blha_layer_op op already registered.\nW0703 20:14:40.191993   313 custom_operator.cc:967] Operator (fused_blha_layer_op) has been registered.\nW0703 20:14:40.192003   313 ir_context.cc:306] custom_op.remove_padding op already registered.\nW0703 20:14:40.192009   313 custom_operator.cc:967] Operator (remove_padding) has been registered.\nW0703 20:14:40.192020   313 ir_context.cc:306] custom_op.fused_get_rotary_embedding op already registered.\nW0703 20:14:40.192026   313 custom_operator.cc:967] Operator (fused_get_rotary_embedding) has been registered.\nW0703 20:14:40.192036   313 ir_context.cc:306] custom_op.fused_rope op already registered.\nW0703 20:14:40.192044   313 ir_context.cc:306] custom_op.fused_rope_grad op already registered.\nW0703 20:14:40.192049   313 custom_operator.cc:967] Operator (fused_rope) has been registered.\nW0703 20:14:40.192059   313 ir_context.cc:306] custom_op.rms_norm_npu op already registered.\nW0703 20:14:40.192067   313 ir_context.cc:306] custom_op.rms_norm_npu_grad op already registered.\nW0703 20:14:40.192073   313 custom_operator.cc:967] Operator (rms_norm_npu) has been registered.\nW0703 20:14:40.192085   313 ir_context.cc:306] custom_op.fused_mm_reduce_scatter op already registered.\nW0703 20:14:40.192091   313 custom_operator.cc:967] Operator (fused_mm_reduce_scatter) has been registered.\nW0703 20:14:40.192102   313 ir_context.cc:306] custom_op.fused_allgather_mm op already registered.\nW0703 20:14:40.192109   313 custom_operator.cc:967] Operator (fused_allgather_mm) has been registered.\nW0703 20:14:40.192119   313 ir_context.cc:306] custom_op.rebuild_padding_v2 op already registered.\nW0703 20:14:40.192126   313 custom_operator.cc:967] Operator (rebuild_padding_v2) has been registered.\nW0703 20:14:40.192137   313 ir_context.cc:306] custom_op.flash_attention_npu op already registered.\nW0703 20:14:40.192147   313 ir_context.cc:306] custom_op.flash_attention_npu_grad op already registered.\nW0703 20:14:40.192154   313 custom_operator.cc:967] Operator (flash_attention_npu) has been registered.\nW0703 20:14:40.192163   313 ir_context.cc:306] custom_op.write_cache_kv_ op already registered.\nW0703 20:14:40.192170   313 custom_operator.cc:967] Operator (write_cache_kv) has been registered.\nW0703 20:14:40.192179   313 ir_context.cc:306] custom_op.rebuild_padding op already registered.\nW0703 20:14:40.192185   313 custom_operator.cc:967] Operator (rebuild_padding) has been registered.\nW0703 20:14:40.192194   313 ir_context.cc:306] custom_op.get_padding_offset op already registered.\nW0703 20:14:40.192201   313 custom_operator.cc:967] Operator (get_padding_offset) has been registered.\nW0703 20:14:40.192212   313 ir_context.cc:306] custom_op.fused_mm_allreduce op already registered.\nW0703 20:14:40.192219   313 custom_operator.cc:967] Operator (fused_mm_allreduce) has been registered.\nW0703 20:14:40.192229   313 ir_context.cc:306] custom_op.get_token_penalty_multi_scores_v2_ op already registered.\nW0703 20:14:40.192235   313 custom_operator.cc:967] Operator (get_token_penalty_multi_scores_v2) has been registered.\nW0703 20:14:40.192245   313 ir_context.cc:306] custom_op.get_padding_offset_v2 op already registered.\nW0703 20:14:40.192250   313 custom_operator.cc:967] Operator (get_padding_offset_v2) has been registered.\nW0703 20:14:40.192262   313 ir_context.cc:306] custom_op.lm_head op already registered.\nW0703 20:14:40.192269   313 custom_operator.cc:967] Operator (lm_head) has been registered.\nW0703 20:14:40.192279   313 ir_context.cc:306] custom_op.quant_int8 op already registered.\nW0703 20:14:40.192286   313 custom_operator.cc:967] Operator (quant_int8) has been registered.\nW0703 20:14:40.192296   313 ir_context.cc:306] custom_op.qkv_transpose_split op already registered.\nW0703 20:14:40.192302   313 custom_operator.cc:967] Operator (qkv_transpose_split) has been registered.\nW0703 20:14:40.192312   313 ir_context.cc:306] custom_op.save_with_output op already registered.\nW0703 20:14:40.192318   313 custom_operator.cc:967] Operator (save_with_output) has been registered.\nW0703 20:14:40.192327   313 ir_context.cc:306] custom_op.set_value_by_flags_and_idx op already registered.\nW0703 20:14:40.192333   313 custom_operator.cc:967] Operator (set_value_by_flags_and_idx) has been registered.\nW0703 20:14:40.192343   313 ir_context.cc:306] custom_op.save_output_ op already registered.\nW0703 20:14:40.192349   313 custom_operator.cc:967] Operator (save_output) has been registered.\nW0703 20:14:40.192363   313 ir_context.cc:306] custom_op.set_value_by_flags_and_idx_v2_ op already registered.\nW0703 20:14:40.192368   313 custom_operator.cc:967] Operator (set_value_by_flags_and_idx_v2) has been registered.\nW0703 20:14:40.192378   313 ir_context.cc:306] custom_op.dequant_int8 op already registered.\nW0703 20:14:40.192384   313 custom_operator.cc:967] Operator (dequant_int8) has been registered.\nW0703 20:14:40.192395   313 ir_context.cc:306] custom_op.get_token_penalty_multi_scores op already registered.\nW0703 20:14:40.192402   313 custom_operator.cc:967] Operator (get_token_penalty_multi_scores) has been registered.\nW0703 20:14:40.192413   313 ir_context.cc:306] custom_op.step_paddle_ op already registered.\nW0703 20:14:40.192420   313 custom_operator.cc:967] Operator (step_paddle) has been registered.\nW0703 20:14:40.192430   313 ir_context.cc:306] custom_op.set_stop_value_multi_ends_v2_ op already registered.\nW0703 20:14:40.192435   313 custom_operator.cc:967] Operator (set_stop_value_multi_ends_v2) has been registered.\nW0703 20:14:40.192445   313 ir_context.cc:306] custom_op.write_int8_cache_kv_ op already registered.\nW0703 20:14:40.192451   313 custom_operator.cc:967] Operator (write_int8_cache_kv) has been registered.\nW0703 20:14:40.192461   313 ir_context.cc:306] custom_op.encode_rotary_qk_ op already registered.\nW0703 20:14:40.192466   313 custom_operator.cc:967] Operator (encode_rotary_qk) has been registered.\nW0703 20:14:40.192474   313 ir_context.cc:306] custom_op.transpose_remove_padding op already registered.\nW0703 20:14:40.192481   313 custom_operator.cc:967] Operator (transpose_remove_padding) has been registered.\nTraceback (most recent call last):\n  File \"/usr/local/bin/paddlespeech_server\", line 5, in <module>\n    from paddlespeech.server.entry import server_execute\n  File \"/work/PaddleSpeech/paddlespeech/server/__init__.py\", line 20, in <module>\n    from .bin.paddlespeech_client import ASRClientExecutor\n  File \"/work/PaddleSpeech/paddlespeech/server/bin/__init__.py\", line 16, in <module>\n    from .paddlespeech_server import ServerExecutor\n  File \"/work/PaddleSpeech/paddlespeech/server/bin/paddlespeech_server.py\", line 26, in <module>\n    from paddlespeech.server.restful.api import setup_router as setup_http_router\n  File \"/work/PaddleSpeech/paddlespeech/server/restful/api.py\", line 23, in <module>\n    from paddlespeech.server.restful.text_api import router as text_router\n  File \"/work/PaddleSpeech/paddlespeech/server/restful/text_api.py\", line 21, in <module>\n    from paddlespeech.server.engine.text.python.text_engine import PaddleTextConnectionHandler\n  File \"/work/PaddleSpeech/paddlespeech/server/engine/text/python/text_engine.py\", line 19, in <module>\n    from paddlespeech.cli.text.infer import TextExecutor\n  File \"/work/PaddleSpeech/paddlespeech/cli/text/__init__.py\", line 14, in <module>\n    from .infer import TextExecutor\n  File \"/work/PaddleSpeech/paddlespeech/cli/text/infer.py\", line 29, in <module>\n    from paddlespeech.text.models.ernie_linear import ErnieLinear\n  File \"/work/PaddleSpeech/paddlespeech/text/models/__init__.py\", line 14, in <module>\n    from .ernie_crf import ErnieCrf\n  File \"/work/PaddleSpeech/paddlespeech/text/models/ernie_crf/__init__.py\", line 14, in <module>\n    from .model import ErnieCrf\n  File \"/work/PaddleSpeech/paddlespeech/text/models/ernie_crf/model.py\", line 16, in <module>\n    from paddlenlp.layers.crf import LinearChainCrf\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/__init__.py\", line 35, in <module>\n    from . import (\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/dataaug/__init__.py\", line 17, in <module>\n    from .sentence import *\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/dataaug/sentence.py\", line 17, in <module>\n    from ..taskflow import Taskflow\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/taskflow/__init__.py\", line 15, in <module>\n    from .taskflow import Taskflow\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/taskflow/taskflow.py\", line 26, in <module>\n    from .information_extraction import GPTask, UIETask\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/taskflow/information_extraction.py\", line 31, in <module>\n    from ..utils.ie_utils import map_offset, pad_image_data\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/utils/ie_utils.py\", line 22, in <module>\n    from ..metrics import SpanEvaluator\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/metrics/__init__.py\", line 16, in <module>\n    from .chunk import ChunkEvaluator\n  File \"/usr/local/lib/python3.10/dist-packages/paddlenlp/metrics/chunk.py\", line 20, in <module>\n    from seqeval.metrics.sequence_labeling import get_entities\n  File \"/usr/local/lib/python3.10/dist-packages/seqeval/metrics/__init__.py\", line 1, in <module>\n    from seqeval.metrics.sequence_labeling import (accuracy_score,\n  File \"/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py\", line 14, in <module>\n    from seqeval.metrics.v1 import SCORES, _precision_recall_fscore_support\n  File \"/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py\", line 5, in <module>\n    from sklearn.exceptions import UndefinedMetricWarning\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/__init__.py\", line 74, in <module>\n    from .utils._show_versions import show_versions  # noqa: E402\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_show_versions.py\", line 16, in <module>\n    from ._openmp_helpers import _openmp_parallelism_enabled\nImportError: /usr/local/lib/python3.10/dist-packages/sklearn/utils/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block\n声明export LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1 仍然报错，请问是为什么？",
        "state": "open",
        "user": "bottleofwater11",
        "closed_by": null,
        "created_at": "2025-07-03T12:18:10+00:00",
        "updated_at": "2025-07-04T09:04:59+00:00",
        "closed_at": null,
        "comments_count": [
            "bottleofwater11",
            "starmountain1997",
            "bottleofwater11",
            "bottleofwater11",
            "zxcd",
            "bottleofwater11",
            "zxcd",
            "bottleofwater11",
            "zxcd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4095,
        "title": "Question about whisper server.",
        "body": "## General Question\n\n<!--\nBefore asking a question, make sure you have:\n- Baidu/Google your question.\n- Searched open and closed [GitHub issues](https://github.com/PaddlePaddle/PaddleSpeech/issues?q=is%3Aissue)\n- Read the documentation:\n  - [Readme](https://github.com/PaddlePaddle/PaddleSpeech)\n  - [Doc](https://paddlespeech.readthedocs.io/)\n-->\n\n<img width=\"986\" height=\"107\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ed21ce3d-41e3-436f-9efe-66782ca50fa9\" />\n\nAs shown in the figure, the whisper-large service I deployed often outputs an exclamation mark \"!\" in the ASR. What may cause this situation?\nThe ckpt of whisper-large used comes from https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/resource/pretrained_models.py#L588\nIf whisper-tiny is used, this situation is almost not found. The tiny ckpt comes from\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/resource/pretrained_models.py#L748\n\nLooking forward to your reply!\n\n中文翻译：\n\n如图所示，我部署的whisper-large服务经常ASR出来的内容就是一个感叹号\"!\"，请问有什么可能会导致这种情况呢？\n使用的whisper-large的ckpt来源于https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/resource/pretrained_models.py#L588\n如果使用whisper-tiny倒几乎无发现这种情况，tiny ckpt来源于\nhttps://github.com/PaddlePaddle/PaddleSpeech/blob/develop/paddlespeech/resource/pretrained_models.py#L748\n\n期待您的回复！",
        "state": "open",
        "user": "handsomelys",
        "closed_by": null,
        "created_at": "2025-07-05T06:02:29+00:00",
        "updated_at": "2025-07-08T06:47:29+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "handsomelys",
            "zxcd",
            "handsomelys",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSpeech",
        "number": 4096,
        "title": "粤语输出",
        "body": "我看到语音输出Sample里面有输出为粤语的，请问代码中要如何调整才会输出为粤语呢\n",
        "state": "open",
        "user": "BarryPansy",
        "closed_by": null,
        "created_at": "2025-07-07T01:12:44+00:00",
        "updated_at": "2025-07-08T03:58:09+00:00",
        "closed_at": null,
        "comments_count": [
            "zxcd",
            "BarryPansy",
            "zxcd"
        ],
        "labels": [
            "Question"
        ]
    }
]