[
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 98,
        "title": "PaddleTS第一个issues提问者,哈哈哈哈,三生有幸",
        "body": "1.千呼万唤始出来,终于有了飞桨框架的时间序列预测了.\r\n2.我进入时间序列预测领域,都是由于获得AAAI2021最佳论文奖的那篇论文引起我的兴趣的.AAAI 2021最佳论文：比Transformer更有效的长时间序列预测.看到这个标题,竟然比Transformer更牛逼,万分吃惊.请问PaddleTS大佬,几时复现这篇论文呢?或者是复现2022年比较牛逼的时间序列预测的论文.如果我记得不错的话,AAAI2021最佳论文,是有pytorch的复现版本的,就在github.其实多数论文都有pytorch的复现版本,毕竟科研者写论文,超过80%以上的论文就是使用pytorch框架.使用飞桨框架复现,可以参考参考.\r\n3.看到大佬们对于未来的工作的概括,小弟最感兴趣的就是概率模型,希望早日复现该领域最牛逼的论文.我听说有人使用概率模型炒股,发了大财,不知道真假,哈哈哈哈.\r\n4.图像分类的数据集,有一个很大的imagenet数据集,请问时间序列预测,有什么很大的数据集吗?目前PaddleTS提供了很多模型,请问你们认为哪个模型效果最好呢?哪个模型适用于短时间序列预测,哪个模型适用于长时间序列预测?哪个模型适用于小数据集,哪个模型适用于大数据集?\r\n5.我是看了飞桨视觉的负责人的一篇微信朋友圈,才知道PaddleTS这个仓库.朋友圈中介绍,时间序列预测可以用于股价预测,请问你们认同时间序列预测可以用于股价预测这种观点吗?祝你们炒股赚大钱,发大财.",
        "state": "closed",
        "user": "yuwoyizhan",
        "closed_by": "yangs16",
        "created_at": "2022-08-09T19:05:48+00:00",
        "updated_at": "2022-08-11T02:28:58+00:00",
        "closed_at": "2022-08-11T02:28:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 99,
        "title": "PaddleTS第一个issues提问者,哈哈哈哈,三生有幸",
        "body": "1.千呼万唤始出来,终于有了飞桨框架的时间序列预测了.\r\n2.我进入时间序列预测领域,都是由于获得AAAI2021最佳论文奖的那篇论文引起我的兴趣的.AAAI 2021最佳论文：比Transformer更有效的长时间序列预测.看到这个标题,竟然比Transformer更牛逼,万分吃惊.请问PaddleTS大佬,几时复现这篇论文呢?或者是复现2022年比较牛逼的时间序列预测的论文.如果我记得不错的话,AAAI2021最佳论文,是有pytorch的复现版本的,就在github.其实多数论文都有pytorch的复现版本,毕竟科研者写论文,超过80%以上的论文就是使用pytorch框架.使用飞桨框架复现,可以参考参考.\r\n3.看到大佬们对于未来的工作的概括,小弟最感兴趣的就是概率模型,希望早日复现该领域最牛逼的论文.我听说有人使用概率模型炒股,发了大财,不知道真假,哈哈哈哈.\r\n4.图像分类的数据集,有一个很大的imagenet数据集,请问时间序列预测,有什么很大的数据集吗?目前PaddleTS提供了很多模型,请问你们认为哪个模型效果最好呢?哪个模型适用于短时间序列预测,哪个模型适用于长时间序列预测?哪个模型适用于小数据集,哪个模型适用于大数据集?\r\n5.我是看了飞桨视觉的负责人的一篇微信朋友圈,才知道PaddleTS这个仓库.朋友圈中介绍,时间序列预测可以用于股价预测,请问你们认同时间序列预测可以用于股价预测这种观点吗?祝你们炒股赚大钱,发大财.",
        "state": "closed",
        "user": "yuwoyizhan",
        "closed_by": "yangs16",
        "created_at": "2022-08-09T19:12:02+00:00",
        "updated_at": "2022-08-15T06:05:13+00:00",
        "closed_at": "2022-08-11T02:33:46+00:00",
        "comments_count": [
            "yangs16",
            "bianchuanxin",
            "yuwoyizhan",
            "yangs16",
            "yuwoyizhan",
            "yuwoyizhan",
            "yangs16",
            "bianchuanxin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 110,
        "title": "如何用多组时间序列数据构建数据集",
        "body": null,
        "state": "closed",
        "user": "daizzhisheng",
        "closed_by": "a10210532",
        "created_at": "2022-08-18T10:02:31+00:00",
        "updated_at": "2023-06-02T02:49:10+00:00",
        "closed_at": "2022-11-09T06:16:33+00:00",
        "comments_count": [
            "daizzhisheng",
            "daizzhisheng",
            "LinWencong",
            "LinWencong",
            "daizzhisheng",
            "LinWencong",
            "lyiuy",
            "a10210532",
            "pvalue31415936",
            "a10210532",
            "pvalue31415936",
            "DaPenggg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 101,
        "title": " [paddlets] [ERROR] ValueError: attr: shape doesn't exist!",
        "body": "import paddlets\r\nfrom paddlets.datasets.repository import get_dataset, dataset_list\r\n\r\nprint(paddlets.__version__)\r\n0.1.0\r\n\r\nprint(f\"built-in datasets:{dataset_list()}\")\r\nbuilt-in datasets:['UNI_WTH', 'ETTh1', 'ETTm1', 'ECL', 'WTH']\r\n\r\ndataset = get_dataset('WTH')\r\n执行到 dataset = get_dataset('WTH') 这行时提示\r\n[2022-08-11 14:07:44,459] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-08-11 14:07:44,487] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!",
        "state": "closed",
        "user": "pk5557367",
        "closed_by": "pk5557367",
        "created_at": "2022-08-11T06:10:35+00:00",
        "updated_at": "2023-01-07T02:26:06+00:00",
        "closed_at": "2022-08-12T07:20:51+00:00",
        "comments_count": [
            "tongbaiming"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 231,
        "title": "使用GPU设备进行模型训练、预测代码报错",
        "body": "我按照官方文档[https://paddlets.readthedocs.io/zh_CN/latest/source/get_started/run_on_gpu.html](url)运行GPU实验代码：\r\n```python\r\nimport numpy as np\r\n\r\nfrom paddlets.datasets.repository import get_dataset\r\nfrom paddlets.transform.normalization import StandardScaler\r\nfrom paddlets.models.forecasting import MLPRegressor\r\n\r\nnp.random.seed(2022)\r\n\r\n# prepare data\r\ntsdataset = get_dataset(\"WTH\")\r\nts_train, ts_val_test = ts.split(\"2012-03-31 23:00:00\")\r\nts_val, ts_test = ts_val_test.split(\"2013-02-28 23:00:00\")\r\n\r\n# transform\r\nscaler = StandardScaler()\r\nscaler.fit(ts_train)\r\nts_train_scaled = scaler.transform(ts_train)\r\nts_val_scaled = scaler.transform(ts_val)\r\nts_test_scaled = scaler.transform(ts_test)\r\nts_val_test_scaled = scaler.transform(ts_val_test)\r\n\r\n# model\r\nmodel = MLPRegressor(\r\n     in_chunk_len=7 * 24,\r\n     out_chunk_len=24,\r\n     skip_chunk_len=0,\r\n     sampling_stride=24,\r\n     eval_metrics=[\"mse\", \"mae\"],\r\n     batch_size=32,\r\n     max_epochs=1000,\r\n     patience=100,\r\n     use_bn=True,\r\n     seed=2022\r\n)\r\n\r\nmodel.fit(ts_train_scaled, ts_val_scaled)\r\n\r\npredicted_tsdataset = model.predict(ts_val_test_scaled)\r\n\r\nprint(predicted_tsdataset)\r\n\r\n#                      WetBulbCelsius\r\n# 2014-01-01 00:00:00       -0.124221\r\n# 2014-01-01 01:00:00       -0.184970\r\n# 2014-01-01 02:00:00       -0.398122\r\n# 2014-01-01 03:00:00       -0.500016\r\n# 2014-01-01 04:00:00       -0.350443\r\n# 2014-01-01 05:00:00       -0.580986\r\n# 2014-01-01 06:00:00       -0.482264\r\n# 2014-01-01 07:00:00       -0.413248\r\n# 2014-01-01 08:00:00       -0.451982\r\n# 2014-01-01 09:00:00       -0.471430\r\n# 2014-01-01 10:00:00       -0.427212\r\n# 2014-01-01 11:00:00       -0.264509\r\n# 2014-01-01 12:00:00       -0.308266\r\n# 2014-01-01 13:00:00       -0.386270\r\n# 2014-01-01 14:00:00       -0.261341\r\n# 2014-01-01 15:00:00       -0.492441\r\n# 2014-01-01 16:00:00       -0.497322\r\n# 2014-01-01 17:00:00       -0.628926\r\n# 2014-01-01 18:00:00       -0.528971\r\n# 2014-01-01 19:00:00       -0.588881\r\n# 2014-01-01 20:00:00       -0.860580\r\n# 2014-01-01 21:00:00       -0.742121\r\n# 2014-01-01 22:00:00       -0.819053\r\n# 2014-01-01 23:00:00       -0.875322\r\n```\r\n\r\n遇到了一些Bug：\r\n\r\n1.\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"old.py\", line 4, in <module>\r\n    from paddlets.transform.normalization import StandardScaler\r\nModuleNotFoundError: No module named 'paddlets.transform.normalization'\r\n```\r\n\r\n2.\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"old.py\", line 11, in <module>\r\n    ts_train, ts_val_test = ts.split(\"2012-03-31 23:00:00\")\r\nNameError: name 'ts' is not defined\r\n```\r\n我已经在PR中解决了上述Bug。[https://github.com/PaddlePaddle/PaddleTS/pull/230](url)",
        "state": "closed",
        "user": "wenzhaojie",
        "closed_by": "kehuo",
        "created_at": "2022-11-07T05:08:18+00:00",
        "updated_at": "2022-11-07T06:04:26+00:00",
        "closed_at": "2022-11-07T06:04:26+00:00",
        "comments_count": [
            "kehuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 112,
        "title": "Transformer模型报错",
        "body": "W0915 12:02:58.731670  1250 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7\r\nW0915 12:02:58.744315  1250 gpu_resources.cc:91] device: 0, cuDNN Version: 8.5.\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 34, in <module>\r\n    model.fit(train_dataset, val_dataset)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlets/models/dl/paddlepaddle/paddle_base_impl.py\", line 321, in fit\r\n    self._fit(train_dataloader, valid_dataloaders)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlets/models/dl/paddlepaddle/paddle_base_impl.py\", line 347, in _fit\r\n    self._train_epoch(train_dataloader)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlets/models/dl/paddlepaddle/paddle_base_impl.py\", line 415, in _train_epoch\r\n    batch_logs = self._train_batch(X, y)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlets/models/dl/paddlepaddle/paddle_base_impl.py\", line 434, in _train_batch\r\n    output = self._network(X)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddlets/models/dl/paddlepaddle/transformer.py\", line 196, in forward\r\n    out = self._transformer(src, tgt)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/nn/layer/transformer.py\", line 1628, in forward\r\n    memory = self.encoder(src, src_mask=src_mask)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/nn/layer/transformer.py\", line 971, in forward\r\n    src_mask = _convert_attention_mask(src_mask, src.dtype,\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/nn/layer/transformer.py\", line 108, in _convert_attention_mask\r\n    mha_meta = _prepare_mha_meta(attn_mask, enable_cudnn)\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/nn/layer/transformer.py\", line 134, in _prepare_mha_meta\r\n    assert attn_mask is not None, \\\r\nAssertionError: The attention mask should be given for MultiHeadAttention  when enable_cudnn=True. But received attn_mask = None",
        "state": "closed",
        "user": "bitsk",
        "closed_by": "bitsk",
        "created_at": "2022-09-15T12:04:48+00:00",
        "updated_at": "2023-12-20T20:25:04+00:00",
        "closed_at": "2023-12-20T20:25:04+00:00",
        "comments_count": [
            "willionZS",
            "Annnnnnnnnnnnn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 106,
        "title": "不支持paddle版本为2.3.1",
        "body": "之前使用过飞浆的cv和nlp，偶然看到发布的paddlets，可实现对时间序列的预测，刚好未来有这方面的需求，马上来体验下！\r\n运行mlp.fit(train_dataset, val_dataset)报错：\r\nValueError: only the following paddle versions are supported: {'2.2.0', '2.3.0'}, current paddle version: 2.3.1",
        "state": "closed",
        "user": "qthui6",
        "closed_by": "kehuo",
        "created_at": "2022-08-18T04:25:23+00:00",
        "updated_at": "2022-10-26T09:53:08+00:00",
        "closed_at": "2022-10-26T09:53:08+00:00",
        "comments_count": [
            "LinWencong",
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 111,
        "title": "设置的协变量是observed_cov_cols，但是报错known_cov长度不够。",
        "body": "报错具体信息：ValueError: known_cov length is too short to build known_cov chunk feature. \r\n                    It needs at least 1 extra Timestamps after known_timeseries.time_index[6:]\r\n数据集构建：\r\ncustom_dataset = TSDataset.load_from_dataframe(\r\n    result,  #Also can be path to the CSV file\r\n    time_col='time',\r\n    target_cols=['A'\t,'B'\t,'C'],\r\n    freq='1d',\r\n    observed_cov_cols='D',\r\n    fill_missing_dates=True,\r\n    fillna_method='zero' #max, min, avg, median, pre, back, zero\r\n)\r\ncustom_dataset.plot()",
        "state": "closed",
        "user": "Nefefilibata",
        "closed_by": "Nefefilibata",
        "created_at": "2022-09-01T01:36:04+00:00",
        "updated_at": "2022-09-02T07:25:32+00:00",
        "closed_at": "2022-09-02T06:10:09+00:00",
        "comments_count": [
            "a10210532",
            "Nefefilibata"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 103,
        "title": "PaddleTS 是否支持时序数据的聚类？",
        "body": "您好，请教一个问题，现在有一系列无标签的时序数据，也不清楚这些数据有几个类别，请问PaddleTS是否有模型能够对这样的数据进行聚类？是否有相关的示例代码？",
        "state": "closed",
        "user": "ArcherShirou",
        "closed_by": "ArcherShirou",
        "created_at": "2022-08-16T14:46:54+00:00",
        "updated_at": "2022-08-17T13:29:51+00:00",
        "closed_at": "2022-08-17T13:29:51+00:00",
        "comments_count": [
            "a10210532",
            "ArcherShirou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 232,
        "title": "使用backtest时报错",
        "body": "代码如下：\r\nfrom paddlets.utils import backtest\r\n\r\nq_loss, quantiles = backtest(data=ts_test_scaled,\r\n                             model=deepar,\r\n                             start=\"2021/9/24 19:00\",\r\n                             metric=QuantileLoss([0.1, 0.5, 0.9]),\r\n                             predict_window=30**6,\r\n                             stride=30**6,\r\n                             return_predicts=True\r\n                             )\r\n\r\nquantiles.plot(\r\n    add_data=ts_test_scaled,\r\n    low_quantile=0.05,\r\n    high_quantile=0.95\r\n)\r\nplt.show()\r\n报错如下：\r\n[2022-11-07 16:10:23,106] [paddlets.models.common.callbacks.callbacks] [INFO] Best weights from best epoch are automatically used!\r\n[2022-11-07 16:10:23,119] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,155] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,207] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,217] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,227] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,241] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,262] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,280] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:23,300] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,822] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,822] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,822] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,823] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,823] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,823] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,823] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,823] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,885] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,905] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,908] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,934] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,948] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,954] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,956] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,956] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,963] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,963] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,964] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,964] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,968] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:31,968] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,000] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,004] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,034] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,080] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,084] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,120] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,123] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,142] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,159] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:32,180] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,758] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,758] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,758] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,758] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,758] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,759] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,759] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,759] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,817] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,821] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,844] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,861] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,911] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,913] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,917] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:34,935] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,653] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,653] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,653] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,653] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,654] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,654] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,654] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,654] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,736] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,748] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,754] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,756] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,795] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,797] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,814] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:35,831] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,401] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,401] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,401] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,401] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,401] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,402] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,402] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,402] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,437] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,464] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,501] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,504] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,538] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,541] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,560] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:36,578] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,085] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,085] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,085] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,085] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,085] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,086] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,086] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,086] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,133] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,167] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,184] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,190] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,241] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,245] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,248] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,264] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,746] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,746] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,746] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,746] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,747] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,747] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,747] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,747] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,788] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,828] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,846] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,863] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,871] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,887] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,907] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:37,923] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,344] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,344] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,344] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,344] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,344] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,345] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,345] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,345] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,387] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,423] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,430] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,447] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,467] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,499] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,503] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:38,521] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,035] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,035] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,035] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,035] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,035] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,036] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,036] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,036] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,086] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,123] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,137] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,139] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,139] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,142] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,144] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,145] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,146] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,146] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,147] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,148] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,168] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,199] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,217] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,221] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,244] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,286] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,306] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,311] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,327] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,347] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,367] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:39,383] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\automl\\searcher.py:4: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\r\n  from ray.tune.suggest import BasicVariantGenerator\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\automl\\searcher.py:5: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\r\n  from ray.tune.suggest.optuna import OptunaSearch\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\flaml\\tune\\__init__.py:5: DeprecationWarning: The module `ray.tune.sample` has been moved to `ray.tune.search.sample` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.sample` with `ray.tune.search.sample`.\r\n  from ray.tune import (\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\flaml\\tune\\space.py:6: DeprecationWarning: The module `ray.tune.suggest.variant_generator` has been moved to `ray.tune.search.variant_generator` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.variant_generator` with `ray.tune.search.variant_generator`.\r\n  from ray.tune.suggest.variant_generator import generate_variants\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\automl\\searcher.py:6: DeprecationWarning: The module `ray.tune.suggest.flaml` has been moved to `ray.tune.search.flaml` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.flaml` with `ray.tune.search.flaml`.\r\n  from ray.tune.suggest.flaml import CFO\r\nC:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\automl\\searcher.py:8: DeprecationWarning: The module `ray.tune.suggest.bohb` has been moved to `ray.tune.search.bohb` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.bohb` with `ray.tune.search.bohb`.\r\n  from ray.tune.suggest.bohb import TuneBOHB\r\nBacktest Progress:   0%|          | 0/9 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddle\\fluid\\layers\\tensor.py:657: UserWarning: paddle.assign doesn't support float64 input now due to current platform protobuf data limitation, we convert it to float32\r\n  warnings.warn(\r\nBacktest Progress:   0%|          | 0/9 [00:01<?, ?it/s]\r\n[2022-11-07 16:10:57,802] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,802] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,803] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,843] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,867] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,902] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,904] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,953] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,959] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,962] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2022-11-07 16:10:57,983] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py\", line 1483, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"E:/Paddle-release-2.2/PaddleTS/demos/fit_deepar_model.py\", line 46, in <module>\r\n    q_loss, quantiles = backtest(data=ts_test_scaled,\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\utils\\backtest.py\", line 150, in backtest\r\n    score_dict = metric(real, predict)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\metrics\\base.py\", line 262, in __call__\r\n    res_array = self._build_prob_metrics_data(tsdataset_true, tsdataset_pred, self._TYPE)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\metrics\\base.py\", line 104, in _build_prob_metrics_data\r\n    target_true, target_pred = self._reindex_data(target_true, target_pred)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\paddlets\\metrics\\base.py\", line 197, in _reindex_data\r\n    merge_index = pd.merge(target_true.time_index.to_frame(index=False), target_pred.time_index.to_frame(index=False))\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 106, in merge\r\n    op = _MergeOperation(\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 681, in __init__\r\n    self._validate_specification()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddlets\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 1346, in _validate_specification\r\n    raise MergeError(\r\npandas.errors.MergeError: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
        "state": "closed",
        "user": "jiangxinufo",
        "closed_by": "a10210532",
        "created_at": "2022-11-07T08:29:11+00:00",
        "updated_at": "2022-11-09T06:17:07+00:00",
        "closed_at": "2022-11-09T06:17:07+00:00",
        "comments_count": [
            "QGN123",
            "jiangxinufo",
            "QGN123",
            "jiangxinufo",
            "QGN123",
            "QGN123",
            "jiangxinufo",
            "QGN123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 236,
        "title": "多时序数据导入，如何添加其他static_cov_cols变量",
        "body": "        1、问题询问：多时序数据导入时，无法加入其他static_cov_cols变量，因为TSDataset.load中限制了len(np.unique(df[col])) != 1\r\n2、报错信息：raise_if( col not in df.columns or len(np.unique(df[col])) != 1,\"static cov cals data is not in columns or schema is not right!\")\r\n3、截图示范：见下图\r\n<img width=\"839\" alt=\"image\" src=\"https://user-images.githubusercontent.com/25128883/200454956-4af7dc2f-82b0-441b-a243-6e1262846120.png\">\r\n\r\n_Originally posted by @pvalue31415936 in https://github.com/PaddlePaddle/PaddleTS/issues/110#issuecomment-1306505402_\r\n      ",
        "state": "closed",
        "user": "pvalue31415936",
        "closed_by": "a10210532",
        "created_at": "2022-11-08T02:02:43+00:00",
        "updated_at": "2022-11-09T06:16:24+00:00",
        "closed_at": "2022-11-09T06:16:24+00:00",
        "comments_count": [
            "a10210532",
            "pvalue31415936"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 250,
        "title": "autots 模型测试阶段发生报错",
        "body": "ImportError: cannot import name 'hparams' from 'tensorboardX.summary' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tensorboardX/summary.py)\r\n\r\n`import pandas as pd\r\nimport os\r\n\r\nimport shutil\r\nfrom paddlets.models.forecasting import MLPRegressor\r\nfrom paddlets.automl.autots import AutoTS\r\n# 通过pandas读取数据并显示前三条，与上图一一对应\r\n# csv_path = \"tu_share_data_day/688388.SH.csv\"\r\ntu_share_data_day = os.listdir(\"tu_share_data_day\")\r\nfor one in tu_share_data_day:\r\n    csv_path = os.path.join(\"tu_share_data_day\", one)\r\n\r\n    dam_data = pd.read_csv(csv_path).values.tolist()\r\n    if len(dam_data) < 100:\r\n        continue\r\n    dam_data.reverse()\r\n    for i in range(len(dam_data) - 1):\r\n        dam_data[i].append(dam_data[i + 1][4])\r\n        dam_data[i].append(dam_data[i + 1][5])\r\n\r\n        dam_data[i].append(dam_data[i + 1][6])\r\n        dam_data[i].append(int(i + 1))\r\n    # print(dam_data)\r\n    dam_data = pd.DataFrame(dam_data[:-1],\r\n                            columns=['ts_code', 'trade_date', 'open', 'high', 'low', 'close',\r\n                                     'pre_close', 'change', 'pct_chg', 'vol', 'amount', 'next_high',\r\n                                     'next_low',\r\n                                     'next_close', 'index_new'])\r\n    from paddlets.datasets import TSDataset\r\n\r\n    # 构建数据集\r\n    dataset = TSDataset.load_from_dataframe(\r\n        dam_data,  # pd.DataFrame\r\n        time_col=\"index_new\",  # 索引\r\n        target_cols=['next_high', 'next_low',\r\n                     'next_close'],  # 需要预测的结果\r\n        observed_cov_cols=['open', 'high', 'low', 'close',\r\n                           'pre_close', 'change', 'pct_chg', 'vol', 'amount']  # 观测协变量\r\n    )\r\n    # 划分训练集和验证集\r\n    train_dataset, val_dataset = dataset.split(0.8)  # 8:2\r\n    \r\n    autots_model = AutoTS(MLPRegressor, 96, 2)\r\n    autots_model.fit(train_dataset, val_dataset)`",
        "state": "closed",
        "user": "natureLanguageQing",
        "closed_by": "a10210532",
        "created_at": "2022-11-10T05:07:25+00:00",
        "updated_at": "2022-11-14T05:54:51+00:00",
        "closed_at": "2022-11-14T05:54:51+00:00",
        "comments_count": [
            "natureLanguageQing",
            "natureLanguageQing",
            "natureLanguageQing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 244,
        "title": "load模型失败",
        "body": "ubuntu 20.04 \r\npaddlets 1.0.1\r\n##########################################################################################\r\n\r\nts2vec_params = {\"segment_size\": 200,\r\n             \"repr_dims\": 320,\r\n             \"batch_size\": 32,\r\n             \"sampling_stride\": 200,\r\n             \"max_epochs\": 20}\r\nmodel = ReprForecasting(in_chunk_len=200,\r\n                        out_chunk_len=24,\r\n                        sampling_stride=1,\r\n                        repr_model=TS2Vec,\r\n                        repr_model_params=ts2vec_params)\r\nmodel.fit(train_data)\r\nmodel.save(\"/weights/models1\")\r\nmodel=load(\"/weights/models1\")\r\n\r\n发生异常: ValueError\r\npath must be a file path, not a directory: /home/kylin/pythondevelop/paddle_tutorial/ts/trade/weights/models1",
        "state": "closed",
        "user": "tendrillion",
        "closed_by": "a10210532",
        "created_at": "2022-11-09T02:12:19+00:00",
        "updated_at": "2022-11-14T05:54:58+00:00",
        "closed_at": "2022-11-14T05:54:58+00:00",
        "comments_count": [
            "QGN123",
            "QGN123",
            "QGN123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 233,
        "title": "关于异常检测模块有一处小问题",
        "body": "首先感谢分享！我目前主要研究异常检测学习。\r\n在如下链接：\r\nhttps://paddlets.readthedocs.io/zh_CN/latest/source/modules/models/anomaly.html\r\n其中  5. 模型预测和评估  的指标计算，未见 res 从哪里来？应该是 pred_label  的吧？\r\n`pred_label = model.predict(test_data_scaled)\r\nlable_name = pred_label.target.data.columns[0]\r\nf1 = F1()(test_tsdata, **res**)\r\nprecision = Precision()(test_tsdata, **res**)\r\nrecall = Recall()(test_tsdata, **res**)`",
        "state": "closed",
        "user": "sczhai",
        "closed_by": "sczhai",
        "created_at": "2022-11-07T13:57:40+00:00",
        "updated_at": "2022-11-08T09:10:29+00:00",
        "closed_at": "2022-11-08T09:10:29+00:00",
        "comments_count": [
            "wangdong2222",
            "wangdong2222",
            "sczhai"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 235,
        "title": "代码注释存在笔误",
        "body": "[ml_base.py](https://github.com/PaddlePaddle/PaddleTS/blob/main/paddlets/models/forecasting/ml/ml_base.py) \r\n\r\n第101行：\r\n\r\n`# b.modelname = \"a\"`\r\n\r\n应该是：\r\n\r\n`# b.modelname = \"b\"`\r\n\r\n我提交了[PR](https://github.com/PaddlePaddle/PaddleTS/pull/234)。",
        "state": "closed",
        "user": "2Bear",
        "closed_by": "2Bear",
        "created_at": "2022-11-07T15:26:50+00:00",
        "updated_at": "2022-11-08T02:16:08+00:00",
        "closed_at": "2022-11-08T02:16:08+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 243,
        "title": "LSTnet运行fit函数报错",
        "body": "我用PaddleTS的LSTnet进行预测。在模型fit那里，pycharm报错[paddlets] [ERROR] ValueError: attr: shape doesn't exist!；jupyter notebook内核直接挂掉。但是在飞桨平台就可以正常运行。请问这是什么原因呢？我用MLP和RNN拟合却没问题。",
        "state": "closed",
        "user": "Morcjy",
        "closed_by": "Sunting78",
        "created_at": "2022-11-08T12:19:42+00:00",
        "updated_at": "2024-02-06T03:32:59+00:00",
        "closed_at": "2024-02-06T03:32:59+00:00",
        "comments_count": [
            "Morcjy",
            "a10210532",
            "Morcjy",
            "Morcjy",
            "a10210532",
            "zyn-sinde"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 251,
        "title": "import paddlets报错",
        "body": "系统版本：Ubuntu 22.04\r\n电脑配置： i7-12700 + Nvidia RTX 3070\r\n在conda环境中安装正常，import时报错\r\n```\r\n(pdts) ncg@ncg-pc:~$ pip list | grep paddlets\r\npaddlets           1.0.1\r\n(pdts) ncg@ncg-pc:~$ pip list | grep paddlepaddle\r\npaddlepaddle-gpu   2.3.2.post111\r\n(pdts) ncg@ncg-pc:~$ python\r\nPython 3.8.13 (default, Oct 21 2022, 23:50:54) \r\n[GCC 11.2.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from paddlets import TSDataset\r\nError: Can not import avx core while this file exists: /home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/core_avx.so\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/__init__.py\", line 5, in <module>\r\n    from paddlets.pipeline import Pipeline\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/pipeline/__init__.py\", line 4, in <module>\r\n    from paddlets.pipeline.pipeline import Pipeline\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/pipeline/pipeline.py\", line 16, in <module>\r\n    from paddlets.utils.utils import get_tsdataset_max_len, split_dataset\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/utils/__init__.py\", line 8, in <module>\r\n    from paddlets.utils.backtest import backtest\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/utils/backtest.py\", line 12, in <module>\r\n    from paddlets.metrics import Metric, MSE\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/metrics/__init__.py\", line 7, in <module>\r\n    from paddlets.metrics.metrics import (\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddlets/metrics/metrics.py\", line 8, in <module>\r\n    import paddle\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 37, in <module>\r\n    from . import core\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/core.py\", line 298, in <module>\r\n    raise e\r\n  File \"/home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/core.py\", line 256, in <module>\r\n    from . import core_avx\r\nImportError: /home/ncg/anaconda3/envs/pdts/lib/python3.8/site-packages/paddle/fluid/core_avx.so: undefined symbol: _dl_sym, version GLIBC_PRIVATE\r\n```",
        "state": "closed",
        "user": "newne",
        "closed_by": "a10210532",
        "created_at": "2022-11-10T06:00:21+00:00",
        "updated_at": "2022-11-14T05:55:37+00:00",
        "closed_at": "2022-11-14T05:55:37+00:00",
        "comments_count": [
            "QGN123",
            "QGN123",
            "newne"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 254,
        "title": "概率预测模型报错 No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
        "body": "`from paddlets.utils import backtest\r\nq_loss, quantiles = backtest(data=ts_test_scaled,\r\n     model=deepar,\r\n     start=\"2013-11-01 00:00:00\",\r\n     metric=QuantileLoss([0.1, 0.5, 0.9]),\r\n     predict_window=24,\r\n     stride=24,\r\n     return_predicts=True\r\n)`\r\n\r\nMergeError: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
        "state": "closed",
        "user": "mutou12",
        "closed_by": "Sunting78",
        "created_at": "2022-11-11T02:14:21+00:00",
        "updated_at": "2024-02-06T03:38:41+00:00",
        "closed_at": "2024-02-06T03:38:41+00:00",
        "comments_count": [
            "QGN123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 260,
        "title": "AutoTS运行fit()报错；KeyError: 'C'; FileNotFoundError: [Errno 2] No such file or directory;",
        "body": "运行文档https://github.com/PaddlePaddle/PaddleTS/blob/main/examples/autots_example.ipynb到autots_model.fit(tsdataset)这一步的时候出现以下报错：\r\n(pid=30292) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:4: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\r\n(pid=30292)   from ray.tune.suggest import BasicVariantGenerator\r\n(pid=30292) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:5: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\r\n(pid=30292)   from ray.tune.suggest.optuna import OptunaSearch\r\n(pid=30292) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:6: DeprecationWarning: The module `ray.tune.suggest.flaml` has been moved to `ray.tune.search.flaml` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.flaml` with `ray.tune.search.flaml`.\r\n(pid=30292)   from ray.tune.suggest.flaml import CFO\r\n(pid=30292) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:8: DeprecationWarning: The module `ray.tune.suggest.bohb` has been moved to `ray.tune.search.bohb` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.bohb` with `ray.tune.search.bohb`.\r\n(pid=30292)   from ray.tune.suggest.bohb import TuneBOHB\r\n(pid=30292) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\search_space_configer.py:8: DeprecationWarning: The module `ray.tune.sample` has been moved to `ray.tune.search.sample` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.sample` with `ray.tune.search.sample`.\r\n(pid=30292)   from ray.tune.sample import Float, Integer, Categorical\r\n(run_trial pid=30292) [2022-11-14 01:01:15,022] [paddlets.automl.optimize_runner] [INFO] trial config: {'hidden_config': 'Choice_0: [64]', 'use_bn': True, 'batch_size': 112, 'max_epochs': 330, 'optimizer_params': {'learning_rate': 0.009473699093873009}, 'patience': 15}\r\n(run_trial pid=30292) [2022-11-14 01:01:15,022] [paddlets.automl.optimize_runner] [INFO] setup_estimator: init model. Params: {'hidden_config': [64], 'use_bn': True, 'batch_size': 112, 'max_epochs': 330, 'optimizer_params': {'learning_rate': 0.009473699093873009}, 'patience': 15, 'in_chunk_len': 96, 'out_chunk_len': 2, 'skip_chunk_len': 0, 'sampling_stride': 1, 'seed': 2022}\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py in open_file(path)\r\n     57         prefix = path.split(':')[0]\r\n---> 58         factory = REGISTERED_FACTORIES[prefix]\r\n     59         return factory.open(path)\r\n\r\nKeyError: 'C'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nFileNotFoundError                         Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py in _wait_and_handle_event(self, next_trial)\r\n    832             if event.type == _ExecutorEventType.PG_READY:\r\n--> 833                 self._on_pg_ready(next_trial)\r\n    834             elif event.type == _ExecutorEventType.NO_RUNNING_TRIAL_TIMEOUT:\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py in _on_pg_ready(self, next_trial)\r\n    922         logger.debug(f\"Trying to start trial: {next_trial}\")\r\n--> 923         if not _start_trial(next_trial) and next_trial.status != Trial.ERROR:\r\n    924             # Only try to start another trial if previous trial startup\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py in _start_trial(trial)\r\n    914                 if self.trial_executor.start_trial(trial):\r\n--> 915                     self._callbacks.on_trial_start(\r\n    916                         iteration=self._iteration, trials=self._trials, trial=trial\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\callback.py in on_trial_start(self, **info)\r\n    316         for callback in self._callbacks:\r\n--> 317             callback.on_trial_start(**info)\r\n    318 \r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\logger\\logger.py in on_trial_start(self, iteration, trials, trial, **info)\r\n    134     ):\r\n--> 135         self.log_trial_start(trial)\r\n    136 \r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\logger\\tensorboardx.py in log_trial_start(self, trial)\r\n    178         trial.init_logdir()\r\n--> 179         self._trial_writer[trial] = self._summary_writer_cls(\r\n    180             trial.logdir, flush_secs=30\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py in __init__(self, logdir, comment, purge_step, max_queue, flush_secs, filename_suffix, write_to_disk, log_dir, comet_config, **kwargs)\r\n    300         self.file_writer = self.all_writers = None\r\n--> 301         self._get_file_writer()\r\n    302 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py in _get_file_writer(self)\r\n    348         if self.all_writers is None or self.file_writer is None:\r\n--> 349             self.file_writer = FileWriter(logdir=self.logdir,\r\n    350                                           max_queue=self._max_queue,\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py in __init__(self, logdir, max_queue, flush_secs, filename_suffix)\r\n    104         logdir = str(logdir)\r\n--> 105         self.event_writer = EventFileWriter(\r\n    106             logdir, max_queue, flush_secs, filename_suffix)\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\event_file_writer.py in __init__(self, logdir, max_queue_size, flush_secs, filename_suffix)\r\n    105         self._event_queue = multiprocessing.Queue(max_queue_size)\r\n--> 106         self._ev_writer = EventsWriter(os.path.join(\r\n    107             self._logdir, \"events\"), filename_suffix)\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\event_file_writer.py in __init__(self, file_prefix, filename_suffix)\r\n     42         self._num_outstanding_events = 0\r\n---> 43         self._py_recordio_writer = RecordWriter(self._file_name)\r\n     44         # Initialize an event instance.\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py in __init__(self, path)\r\n    178         self._writer = None\r\n--> 179         self._writer = open_file(path)\r\n    180 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py in open_file(path)\r\n     60     except KeyError:\r\n---> 61         return open(path, 'wb')\r\n     62 \r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Administrator\\\\ray_results\\\\run_trial_2022-11-14_01-01-08\\\\run_trial_c88b9bca_2_batch_size=120,hidden_config=Choice_5_128_128_128,max_epochs=180,learning_rate=0.0042,patience=45,use_bn=Fals_2022-11-14_01-01-15\\\\events.out.tfevents.1668358875.SK-20200101ELSU'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTuneError                                 Traceback (most recent call last)\r\n<ipython-input-6-a461d0f691de> in <module>\r\n----> 1 autots_model.fit(tsdataset)\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\logger\\logger.py in wrapper(*args, **kwargs)\r\n     25         logger = Logger(module_name)\r\n     26         logger.debug(\"function:%s\" % func_name)\r\n---> 27         result = f(*args, **kwargs)\r\n     28         return result\r\n     29 \r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\autots.py in fit(self, train_tsdataset, valid_tsdataset, n_trails, cpu_resource, gpu_resource)\r\n    205             if valid_tsdataset is None:\r\n    206                 raise NotImplementedError(\"When the train_tsdataset is a list, valid_tsdataset is required!\")\r\n--> 207         analysis = self._optimize_runner.optimize(self._estimator,\r\n    208                                                   self._in_chunk_len,\r\n    209                                                   self._out_chunk_len,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\optimize_runner.py in optimize(self, paddlets_estimator, in_chunk_len, out_chunk_len, train_tsdataset, valid_tsdataset, sampling_stride, skip_chunk_len, search_space, metric, mode, resampling_strategy, split_ratio, k_fold, n_trials, cpu_resource, gpu_resource, local_dir)\r\n    202         self._track_choice_mapping = self._preprocess_search_space(running_search_space)\r\n    203 \r\n--> 204         return tune.run(run_trial, num_samples=n_trials, config=running_search_space,\r\n    205                         metric=self.report_metric,\r\n    206                         mode=mode,\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\tune.py in run(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\r\n    739     )\r\n    740     while not runner.is_finished() and not state[\"signal\"]:\r\n--> 741         runner.step()\r\n    742         if has_verbosity(Verbosity.V1_EXPERIMENT):\r\n    743             _report_progress(runner, progress_reporter)\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py in step(self)\r\n    884             logger.debug(f\"Got new trial to run: {next_trial}\")\r\n    885 \r\n--> 886         self._wait_and_handle_event(next_trial)\r\n    887 \r\n    888         self._stop_experiment_if_needed()\r\n\r\n~\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py in _wait_and_handle_event(self, next_trial)\r\n    863                 raise e\r\n    864             else:\r\n--> 865                 raise TuneError(traceback.format_exc())\r\n    866 \r\n    867     def step(self):\r\n\r\nTuneError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py\", line 58, in open_file\r\n    factory = REGISTERED_FACTORIES[prefix]\r\nKeyError: 'C'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py\", line 833, in _wait_and_handle_event\r\n    self._on_pg_ready(next_trial)\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py\", line 923, in _on_pg_ready\r\n    if not _start_trial(next_trial) and next_trial.status != Trial.ERROR:\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\execution\\trial_runner.py\", line 915, in _start_trial\r\n    self._callbacks.on_trial_start(\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\callback.py\", line 317, in on_trial_start\r\n    callback.on_trial_start(**info)\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\logger\\logger.py\", line 135, in on_trial_start\r\n    self.log_trial_start(trial)\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\logger\\tensorboardx.py\", line 179, in log_trial_start\r\n    self._trial_writer[trial] = self._summary_writer_cls(\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py\", line 301, in __init__\r\n    self._get_file_writer()\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py\", line 349, in _get_file_writer\r\n    self.file_writer = FileWriter(logdir=self.logdir,\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\writer.py\", line 105, in __init__\r\n    self.event_writer = EventFileWriter(\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\event_file_writer.py\", line 106, in __init__\r\n    self._ev_writer = EventsWriter(os.path.join(\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\event_file_writer.py\", line 43, in __init__\r\n    self._py_recordio_writer = RecordWriter(self._file_name)\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py\", line 179, in __init__\r\n    self._writer = open_file(path)\r\n  File \"C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorboardX\\record_writer.py\", line 61, in open_file\r\n    return open(path, 'wb')\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Administrator\\\\ray_results\\\\run_trial_2022-11-14_01-01-08\\\\run_trial_c88b9bca_2_batch_size=120,hidden_config=Choice_5_128_128_128,max_epochs=180,learning_rate=0.0042,patience=45,use_bn=Fals_2022-11-14_01-01-15\\\\events.out.tfevents.1668358875.SK-20200101ELSU'\r\n\r\n\r\n(run_trial pid=30292) [2022-11-14 01:01:15,572] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: 3.339083| val_0_mae: 0.883445| 0:00:00s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:15,993] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 001| loss: 1.339651| val_0_mae: 0.780203| 0:00:00s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:16,418] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 002| loss: 1.073304| val_0_mae: 0.742995| 0:00:01s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:16,830] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 003| loss: 1.000667| val_0_mae: 0.761179| 0:00:01s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:17,249] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 004| loss: 0.964694| val_0_mae: 0.707594| 0:00:02s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:17,678] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 005| loss: 0.972320| val_0_mae: 0.850871| 0:00:02s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:18,108] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 006| loss: 0.966438| val_0_mae: 0.885582| 0:00:02s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:18,520] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 007| loss: 0.896922| val_0_mae: 0.909875| 0:00:03s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:18,943] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 008| loss: 0.932748| val_0_mae: 0.702189| 0:00:03s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:19,355] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 009| loss: 0.883199| val_0_mae: 0.681072| 0:00:04s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(pid=42476) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:4: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\r\n(pid=42476)   from ray.tune.suggest import BasicVariantGenerator\r\n(run_trial pid=30292) [2022-11-14 01:01:19,774] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 010| loss: 0.942490| val_0_mae: 0.726340| 0:00:04s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(pid=42476) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:5: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\r\n(pid=42476)   from ray.tune.suggest.optuna import OptunaSearch\r\n(run_trial pid=30292) [2022-11-14 01:01:20,197] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 011| loss: 0.863567| val_0_mae: 0.679934| 0:00:05s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(pid=42476) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:6: DeprecationWarning: The module `ray.tune.suggest.flaml` has been moved to `ray.tune.search.flaml` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.flaml` with `ray.tune.search.flaml`.\r\n(pid=42476)   from ray.tune.suggest.flaml import CFO\r\n(run_trial pid=30292) [2022-11-14 01:01:20,627] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 012| loss: 0.920713| val_0_mae: 0.684235| 0:00:05s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(pid=42476) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\searcher.py:8: DeprecationWarning: The module `ray.tune.suggest.bohb` has been moved to `ray.tune.search.bohb` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.bohb` with `ray.tune.search.bohb`.\r\n(pid=42476)   from ray.tune.suggest.bohb import TuneBOHB\r\n(pid=42476) C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\search_space_configer.py:8: DeprecationWarning: The module `ray.tune.sample` has been moved to `ray.tune.search.sample` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.sample` with `ray.tune.search.sample`.\r\n(pid=42476)   from ray.tune.sample import Float, Integer, Categorical\r\n(run_trial pid=30292) [2022-11-14 01:01:21,056] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 013| loss: 0.847748| val_0_mae: 0.739015| 0:00:05s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:21,147] [paddlets.automl.optimize_runner] [INFO] trial config: {'hidden_config': 'Choice_5: [128, 128, 128]', 'use_bn': False, 'batch_size': 120, 'max_epochs': 180, 'optimizer_params': {'learning_rate': 0.004155371012314867}, 'patience': 45}\r\n(run_trial pid=42476) [2022-11-14 01:01:21,147] [paddlets.automl.optimize_runner] [INFO] setup_estimator: init model. Params: {'hidden_config': [128, 128, 128], 'use_bn': False, 'batch_size': 120, 'max_epochs': 180, 'optimizer_params': {'learning_rate': 0.004155371012314867}, 'patience': 45, 'in_chunk_len': 96, 'out_chunk_len': 2, 'skip_chunk_len': 0, 'sampling_stride': 1, 'seed': 2022}\r\n(run_trial pid=30292) [2022-11-14 01:01:21,477] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 014| loss: 0.877982| val_0_mae: 0.915531| 0:00:06s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:21,839] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: 2.250421| val_0_mae: 0.866377| 0:00:00s\r\n(run_trial pid=30292) [2022-11-14 01:01:21,898] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 015| loss: 0.865720| val_0_mae: 1.103737| 0:00:06s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:22,317] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 016| loss: 0.882259| val_0_mae: 0.690138| 0:00:07s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:22,436] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 001| loss: 1.000779| val_0_mae: 0.903012| 0:00:01s\r\n(run_trial pid=30292) [2022-11-14 01:01:22,734] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 017| loss: 0.853780| val_0_mae: 0.726888| 0:00:07s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:23,041] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 002| loss: 0.970277| val_0_mae: 0.745609| 0:00:01s\r\n(run_trial pid=30292) [2022-11-14 01:01:23,157] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 018| loss: 0.864675| val_0_mae: 0.746551| 0:00:08s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:23,573] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 019| loss: 0.852602| val_0_mae: 0.806146| 0:00:08s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:23,761] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 003| loss: 0.924974| val_0_mae: 0.824449| 0:00:02s\r\n(run_trial pid=30292) [2022-11-14 01:01:23,990] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 020| loss: 0.865885| val_0_mae: 0.668478| 0:00:08s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:24,421] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 021| loss: 0.822864| val_0_mae: 0.782634| 0:00:09s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:24,499] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 004| loss: 0.923414| val_0_mae: 0.789935| 0:00:03s\r\n(run_trial pid=30292) [2022-11-14 01:01:24,829] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 022| loss: 0.854838| val_0_mae: 0.668849| 0:00:09s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:25,238] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 023| loss: 0.832975| val_0_mae: 0.848204| 0:00:10s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:25,267] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 005| loss: 0.884985| val_0_mae: 0.797978| 0:00:04s\r\n(run_trial pid=30292) [2022-11-14 01:01:25,646] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 024| loss: 0.803786| val_0_mae: 0.771176| 0:00:10s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:26,063] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 025| loss: 0.831367| val_0_mae: 0.755703| 0:00:10s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:26,054] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 006| loss: 0.846988| val_0_mae: 0.720191| 0:00:04s\r\n(run_trial pid=30292) [2022-11-14 01:01:26,473] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 026| loss: 0.809912| val_0_mae: 0.741790| 0:00:11s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:26,881] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 027| loss: 0.813126| val_0_mae: 0.743538| 0:00:11s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:26,853] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 007| loss: 0.790365| val_0_mae: 0.783437| 0:00:05s\r\n(run_trial pid=30292) [2022-11-14 01:01:27,289] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 028| loss: 0.798136| val_0_mae: 0.682494| 0:00:12s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:27,680] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 008| loss: 0.816146| val_0_mae: 0.837121| 0:00:06s\r\n(run_trial pid=30292) [2022-11-14 01:01:27,698] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 029| loss: 0.816031| val_0_mae: 0.689467| 0:00:12s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:28,115] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 030| loss: 0.798248| val_0_mae: 0.810028| 0:00:13s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:28,521] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 009| loss: 0.844155| val_0_mae: 0.773559| 0:00:07s\r\n(run_trial pid=30292) [2022-11-14 01:01:28,536] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 031| loss: 0.782819| val_0_mae: 0.675081| 0:00:13s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:28,941] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 032| loss: 0.830348| val_0_mae: 0.703546| 0:00:13s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:29,344] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 033| loss: 0.787820| val_0_mae: 0.671389| 0:00:14s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:29,361] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 010| loss: 0.800365| val_0_mae: 0.769280| 0:00:08s\r\n(run_trial pid=30292) [2022-11-14 01:01:29,764] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 034| loss: 0.812075| val_0_mae: 0.731617| 0:00:14s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=30292) [2022-11-14 01:01:30,184] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 035| loss: 0.808069| val_0_mae: 0.674505| 0:00:15s\r\n(run_trial pid=30292) [2022-11-14 01:01:30,185] [paddlets.models.common.callbacks.callbacks] [INFO] \r\n(run_trial pid=30292) Early stopping occurred at epoch 35 with best_epoch = 20 and best_val_0_mae = 0.668478\r\n(run_trial pid=30292) [2022-11-14 01:01:30,185] [paddlets.models.common.callbacks.callbacks] [INFO] Best weights from best epoch are automatically used!\r\n(run_trial pid=42476) [2022-11-14 01:01:30,183] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 011| loss: 0.814131| val_0_mae: 0.712737| 0:00:08s\r\n(run_trial pid=42476) [2022-11-14 01:01:31,032] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 012| loss: 0.808135| val_0_mae: 0.739639| 0:00:09s\r\n(run_trial pid=42476) [2022-11-14 01:01:31,897] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 013| loss: 0.814179| val_0_mae: 0.755509| 0:00:10s\r\n(run_trial pid=42476) [2022-11-14 01:01:32,795] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 014| loss: 0.815168| val_0_mae: 0.766864| 0:00:11s\r\n(run_trial pid=42476) [2022-11-14 01:01:33,732] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 015| loss: 0.753962| val_0_mae: 0.690585| 0:00:12s\r\n(run_trial pid=42476) [2022-11-14 01:01:34,675] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 016| loss: 0.801936| val_0_mae: 0.709537| 0:00:13s\r\n(run_trial pid=42476) [2022-11-14 01:01:35,645] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 017| loss: 0.794926| val_0_mae: 0.749197| 0:00:14s\r\n(run_trial pid=42476) [2022-11-14 01:01:36,600] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 018| loss: 0.762111| val_0_mae: 0.678700| 0:00:15s\r\n(run_trial pid=42476) [2022-11-14 01:01:37,540] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 019| loss: 0.745253| val_0_mae: 0.922469| 0:00:16s\r\n(run_trial pid=42476) [2022-11-14 01:01:38,506] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 020| loss: 0.787604| val_0_mae: 0.700718| 0:00:17s\r\n(run_trial pid=42476) [2022-11-14 01:01:39,488] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 021| loss: 0.732736| val_0_mae: 0.741522| 0:00:18s\r\n(run_trial pid=42476) [2022-11-14 01:01:40,478] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 022| loss: 0.756187| val_0_mae: 0.687385| 0:00:19s\r\n(run_trial pid=42476) [2022-11-14 01:01:41,501] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 023| loss: 0.751891| val_0_mae: 0.690699| 0:00:20s\r\n(run_trial pid=42476) [2022-11-14 01:01:42,519] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 024| loss: 0.727448| val_0_mae: 0.682869| 0:00:21s\r\n(run_trial pid=42476) [2022-11-14 01:01:43,555] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 025| loss: 0.755604| val_0_mae: 0.895392| 0:00:22s\r\n(run_trial pid=42476) [2022-11-14 01:01:44,597] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 026| loss: 0.792194| val_0_mae: 0.706429| 0:00:23s\r\n(run_trial pid=42476) [2022-11-14 01:01:45,655] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 027| loss: 0.744930| val_0_mae: 0.791593| 0:00:24s\r\n(run_trial pid=30292) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\session.py:229: DeprecationWarning: `tune.report` and `tune.checkpoint_dir` APIs are deprecated in Ray 2.0, and is replaced by `ray.air.session`. This will provide an easy-to-use API across Tune session and Data parallel worker sessions.The old APIs will be removed in the future. \r\n(run_trial pid=30292)   warnings.warn(\r\n(run_trial pid=42476) [2022-11-14 01:01:46,718] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 028| loss: 0.748070| val_0_mae: 0.791396| 0:00:25s\r\n(run_trial pid=42476) [2022-11-14 01:01:47,765] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 029| loss: 0.728586| val_0_mae: 0.787615| 0:00:26s\r\n(run_trial pid=42476) [2022-11-14 01:01:48,822] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 030| loss: 0.729428| val_0_mae: 0.750572| 0:00:27s\r\n(run_trial pid=42476) [2022-11-14 01:01:49,869] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 031| loss: 0.711299| val_0_mae: 0.708207| 0:00:28s\r\n(run_trial pid=42476) [2022-11-14 01:01:50,932] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 032| loss: 0.735087| val_0_mae: 0.711936| 0:00:29s\r\n(run_trial pid=42476) [2022-11-14 01:01:52,010] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 033| loss: 0.730024| val_0_mae: 0.741676| 0:00:30s\r\n(run_trial pid=42476) [2022-11-14 01:01:53,085] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 034| loss: 0.703183| val_0_mae: 0.755382| 0:00:31s\r\n(run_trial pid=42476) [2022-11-14 01:01:54,170] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 035| loss: 0.704181| val_0_mae: 0.686618| 0:00:32s\r\n(run_trial pid=42476) [2022-11-14 01:01:55,267] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 036| loss: 0.704718| val_0_mae: 0.724146| 0:00:34s\r\n(run_trial pid=42476) [2022-11-14 01:01:56,361] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 037| loss: 0.693106| val_0_mae: 0.697631| 0:00:35s\r\n(run_trial pid=42476) [2022-11-14 01:01:57,466] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 038| loss: 0.727850| val_0_mae: 0.662641| 0:00:36s\r\n(run_trial pid=42476) [2022-11-14 01:01:58,583] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 039| loss: 0.688710| val_0_mae: 0.698511| 0:00:37s\r\n(run_trial pid=42476) [2022-11-14 01:01:59,692] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 040| loss: 0.685247| val_0_mae: 0.702356| 0:00:38s\r\n(run_trial pid=42476) [2022-11-14 01:02:00,810] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 041| loss: 0.702037| val_0_mae: 0.677072| 0:00:39s\r\n(run_trial pid=42476) [2022-11-14 01:02:01,935] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 042| loss: 0.675219| val_0_mae: 0.693985| 0:00:40s\r\n(run_trial pid=42476) [2022-11-14 01:02:03,079] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 043| loss: 0.665016| val_0_mae: 0.688647| 0:00:41s\r\n(run_trial pid=42476) [2022-11-14 01:02:04,227] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 044| loss: 0.714889| val_0_mae: 0.741173| 0:00:42s\r\n(run_trial pid=42476) [2022-11-14 01:02:05,384] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 045| loss: 0.692830| val_0_mae: 0.690192| 0:00:44s\r\n(run_trial pid=42476) [2022-11-14 01:02:06,557] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 046| loss: 0.674419| val_0_mae: 0.760584| 0:00:45s\r\n(run_trial pid=42476) [2022-11-14 01:02:07,734] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 047| loss: 0.694529| val_0_mae: 0.695555| 0:00:46s\r\n(run_trial pid=42476) [2022-11-14 01:02:08,914] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 048| loss: 0.670605| val_0_mae: 0.821415| 0:00:47s\r\n(run_trial pid=42476) [2022-11-14 01:02:10,092] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 049| loss: 0.666438| val_0_mae: 0.755908| 0:00:48s\r\n(run_trial pid=42476) [2022-11-14 01:02:11,287] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 050| loss: 0.699248| val_0_mae: 0.679514| 0:00:50s\r\n(run_trial pid=42476) [2022-11-14 01:02:12,483] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 051| loss: 0.636179| val_0_mae: 0.672630| 0:00:51s\r\n(run_trial pid=42476) [2022-11-14 01:02:13,704] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 052| loss: 0.654464| val_0_mae: 0.702088| 0:00:52s\r\n(run_trial pid=42476) [2022-11-14 01:02:14,950] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 053| loss: 0.701259| val_0_mae: 0.688155| 0:00:53s\r\n(run_trial pid=42476) [2022-11-14 01:02:16,178] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 054| loss: 0.666418| val_0_mae: 0.683142| 0:00:54s\r\n(run_trial pid=42476) [2022-11-14 01:02:17,413] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 055| loss: 0.680250| val_0_mae: 0.683969| 0:00:56s\r\n(run_trial pid=42476) [2022-11-14 01:02:18,641] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 056| loss: 0.668339| val_0_mae: 0.695880| 0:00:57s\r\n(run_trial pid=42476) [2022-11-14 01:02:19,877] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 057| loss: 0.692120| val_0_mae: 0.701301| 0:00:58s\r\n(run_trial pid=42476) [2022-11-14 01:02:21,113] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 058| loss: 0.665579| val_0_mae: 0.690541| 0:00:59s\r\n(run_trial pid=42476) [2022-11-14 01:02:22,363] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 059| loss: 0.656419| val_0_mae: 0.765069| 0:01:01s\r\n(run_trial pid=42476) [2022-11-14 01:02:23,606] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 060| loss: 0.682641| val_0_mae: 0.802213| 0:01:02s\r\n(run_trial pid=42476) [2022-11-14 01:02:24,863] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 061| loss: 0.643246| val_0_mae: 0.765911| 0:01:03s\r\n(run_trial pid=42476) [2022-11-14 01:02:26,120] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 062| loss: 0.657356| val_0_mae: 0.743121| 0:01:04s\r\n(run_trial pid=42476) [2022-11-14 01:02:27,378] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 063| loss: 0.704962| val_0_mae: 0.681874| 0:01:06s\r\n(run_trial pid=42476) [2022-11-14 01:02:28,625] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 064| loss: 0.627800| val_0_mae: 0.684119| 0:01:07s\r\n(run_trial pid=42476) [2022-11-14 01:02:29,886] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 065| loss: 0.635989| val_0_mae: 0.716252| 0:01:08s\r\n(run_trial pid=42476) [2022-11-14 01:02:31,157] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 066| loss: 0.647488| val_0_mae: 0.694206| 0:01:09s\r\n(run_trial pid=42476) [2022-11-14 01:02:32,441] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 067| loss: 0.667528| val_0_mae: 0.684332| 0:01:11s\r\n(run_trial pid=42476) [2022-11-14 01:02:33,729] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 068| loss: 0.626634| val_0_mae: 0.667108| 0:01:12s\r\n(run_trial pid=42476) [2022-11-14 01:02:35,006] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 069| loss: 0.627659| val_0_mae: 0.675814| 0:01:13s\r\n(run_trial pid=42476) [2022-11-14 01:02:36,276] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 070| loss: 0.646840| val_0_mae: 0.710005| 0:01:15s\r\n(run_trial pid=42476) [2022-11-14 01:02:37,545] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 071| loss: 0.630839| val_0_mae: 0.758983| 0:01:16s\r\n(run_trial pid=42476) [2022-11-14 01:02:38,811] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 072| loss: 0.648888| val_0_mae: 0.736240| 0:01:17s\r\n(run_trial pid=42476) [2022-11-14 01:02:40,079] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 073| loss: 0.635487| val_0_mae: 0.685271| 0:01:18s\r\n(run_trial pid=42476) [2022-11-14 01:02:41,345] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 074| loss: 0.632486| val_0_mae: 0.720887| 0:01:20s\r\n(run_trial pid=42476) [2022-11-14 01:02:42,615] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 075| loss: 0.646977| val_0_mae: 0.705984| 0:01:21s\r\n(run_trial pid=42476) [2022-11-14 01:02:43,889] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 076| loss: 0.667855| val_0_mae: 0.678300| 0:01:22s\r\n(run_trial pid=42476) [2022-11-14 01:02:45,162] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 077| loss: 0.642378| val_0_mae: 0.680050| 0:01:23s\r\n(run_trial pid=42476) [2022-11-14 01:02:46,444] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 078| loss: 0.606339| val_0_mae: 0.718853| 0:01:25s\r\n(run_trial pid=42476) [2022-11-14 01:02:47,736] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 079| loss: 0.610563| val_0_mae: 0.696663| 0:01:26s\r\n(run_trial pid=42476) [2022-11-14 01:02:49,010] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 080| loss: 0.624385| val_0_mae: 0.738892| 0:01:27s\r\n(run_trial pid=42476) [2022-11-14 01:02:50,293] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 081| loss: 0.650479| val_0_mae: 0.785787| 0:01:29s\r\n(run_trial pid=42476) [2022-11-14 01:02:51,577] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 082| loss: 0.630244| val_0_mae: 0.725113| 0:01:30s\r\n(run_trial pid=42476) [2022-11-14 01:02:52,875] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 083| loss: 0.596762| val_0_mae: 0.722377| 0:01:31s\r\n(run_trial pid=42476) [2022-11-14 01:02:52,876] [paddlets.models.common.callbacks.callbacks] [INFO] \r\n(run_trial pid=42476) Early stopping occurred at epoch 83 with best_epoch = 38 and best_val_0_mae = 0.662641\r\n(run_trial pid=42476) [2022-11-14 01:02:52,876] [paddlets.models.common.callbacks.callbacks] [INFO] Best weights from best epoch are automatically used!\r\n(run_trial pid=42476) C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\session.py:229: DeprecationWarning: `tune.report` and `tune.checkpoint_dir` APIs are deprecated in Ray 2.0, and is replaced by `ray.air.session`. This will provide an easy-to-use API across Tune session and Data parallel worker sessions.The old APIs will be removed in the future. \r\n(run_trial pid=42476)   warnings.warn(",
        "state": "closed",
        "user": "liusiying0910",
        "closed_by": "LinWencong",
        "created_at": "2022-11-13T17:07:52+00:00",
        "updated_at": "2023-01-10T12:43:09+00:00",
        "closed_at": "2022-12-08T07:19:50+00:00",
        "comments_count": [
            "zyn-sinde",
            "LinWencong",
            "LinWencong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 258,
        "title": "几个建议",
        "body": "1.支持目标变量分类,先实现所有模型和算法,单目标变量分类功能,再实现多目标变量都是整型数的功能,再实现多目标变量有的是整形术,有的是浮点数的功能.\r\n2.支持单机多卡GPU训练,能支持分布式训练就更好了,但是单机多卡训练是最重要的,很多人没钱买机器,租用八卡3090ti进行训练,真心爽歪歪.对于paddlets来说,如果已经选定模型,设置好超参数,或许不用太多GPU资源,但是如果刚开始一个项目,所有模型都要测试一遍,甚至超参数都要多测试,单机多卡GPU训练是很重要的,一个模型训练1天,测试一遍所有模型+超参数那就是一个月的事情了,慢啊.\r\n3.支持C++推理,我指的是,使用VS2022,C++20标准写代码,能准确运行程序.当然了,支持CUDA,OPENCL也是需求之一,这样做可以大幅度提高训练和推理的速度吧.AMD的显卡没什么需求,算了吧,真没想到,谁会买AMD显卡.\r\n4.在ai studio加点项目或案例\r\n5.能不能弄个大数据集.\r\n6.我之前花时间,看了paddlets所有文档,没看代码.给我的感觉就是,预测目标变量的未来值,基本依靠目标变量的过去值,协变量只是起到辅助作用,如果目标变量的未来值,就是靠协变量预测,跟目标变量的过去值没什么关系,还能用paddlets吗?比如y=2*x,y的未来值,是由协变量x决定的,跟y的过去值毫无关系,这时候,能用paddlets吗?\r\n7.我没看过paddlets的模型代码,但我估计这个领域的模型都不大,换句话说,不太清楚paddleslim是否有用.但以我的经验,PaddleSlim用于paddlets,还是能降低使用者推理成本的,比如原来推理需要3090ti,就可以换成2070.拿图像分类来说,有些图像分类不难,只使用很小的神经网络就可以达到99准确率,用了paddleclas的最小模型进行分类的训练,然后用PaddleSlim剪枝量化等,生产出来的模型,相同机器下,推理速度大幅提升,或者是,推理速度不变,GPU,CPU成本大幅下降.总结,paddlets支持PaddleSlim还是很有用的,哈哈哈哈.",
        "state": "closed",
        "user": "yuwoyizhan",
        "closed_by": "Sunting78",
        "created_at": "2022-11-12T03:43:17+00:00",
        "updated_at": "2024-02-28T08:52:23+00:00",
        "closed_at": "2024-02-28T08:52:22+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 263,
        "title": "AutoTS.fit()遇到的相关问题",
        "body": "去运行时提示这些未能完成\r\nTraceback (most recent call last):\r\n  File \"/Users/susheng/PycharmProjects/paddleTest/AutoTS.py\", line 124, in <module>\r\n    autots_tcn.fit(ts_train, ts_val)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/logger/logger.py\", line 27, in wrapper\r\n    result = f(*args, **kwargs)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/automl/autots.py\", line 207, in fit\r\n    analysis = self._optimize_runner.optimize(self._estimator,\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/automl/optimize_runner.py\", line 204, in optimize\r\n    return tune.run(run_trial, num_samples=n_trials, config=running_search_space,\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/tune.py\", line 771, in run\r\n    raise TuneError(\"Trials did not complete\", incomplete_trials)\r\nray.tune.error.TuneError: ('Trials did not complete', [run_trial_732b269c, run_trial_88119474, run_trial_7c009fba, run_trial_94cc868a, run_trial_ab0a0170, run_trial_a7e53298, run_trial_afbec2c2, run_trial_be90113e])\r\n\r\n然后我去看快ray-result对应trail的报错文档，发现他们基本显示的\r\nFailure # 1 (occurred at 2022-11-17_19-39-14)\r\n\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=30278, ip=127.0.0.1, repr=run_trial)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\r\n    raise skipped from exception_cause(skipped)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\r\n    return self._trainable_func(\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\r\n    output = fn()\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/automl/optimize_runner.py\", line 174, in run_trial\r\n    score = fit_and_score(train_data=train_tsdataset,\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/utils/validation.py\", line 127, in fit_and_score\r\n    estimator.fit(train_data, valid_data)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/models/forecasting/dl/paddle_base_impl.py\", line 346, in fit\r\n    self._fit(train_dataloader, valid_dataloaders)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/models/forecasting/dl/paddle_base_impl.py\", line 363, in _fit\r\n    self._network = self._init_network()\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/models/forecasting/dl/tcn.py\", line 341, in _init_network\r\n    return _TCNModule(\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/models/forecasting/dl/tcn.py\", line 126, in __init__\r\n    raise_if_not(\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/logger/logger.py\", line 135, in raise_if_not\r\n    raise ValueError(message)\r\nValueError: The valid range of `kernel_size` is (1, in_chunk_len], got kernel_size:1 <= 1 or kernel_size:1 > in_chunk_len:24.\r\n\r\n看起来像kernel-size不合规导致的，请问这该如何修改呢？\r\n",
        "state": "closed",
        "user": "sly111",
        "closed_by": "sly111",
        "created_at": "2022-11-18T02:46:59+00:00",
        "updated_at": "2022-11-25T07:22:07+00:00",
        "closed_at": "2022-11-25T07:22:07+00:00",
        "comments_count": [
            "sly111",
            "LinWencong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 264,
        "title": "AutoTS参数metric设置",
        "body": "修改metric参数为mse，但实际训练评估使用的仍是mae。\r\nmetric (str) – metric的名字。metric 会被用于计算在 validation 数据集上的 loss，并反馈给超参优化算法。\r\n<img width=\"989\" alt=\"捕获\" src=\"https://user-images.githubusercontent.com/82440069/203050644-9520bfd9-50f0-4ab8-b4ef-cee7af498288.PNG\">\r\n",
        "state": "closed",
        "user": "Chase-brightstar",
        "closed_by": "LinWencong",
        "created_at": "2022-11-21T12:11:01+00:00",
        "updated_at": "2022-12-08T07:19:36+00:00",
        "closed_at": "2022-12-08T07:19:36+00:00",
        "comments_count": [
            "LinWencong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 266,
        "title": "关于TSDataset.load_from_dataframe方法参数的一些问题",
        "body": "我是一个时序数据方面的新手，通过官方文档load自己的数据(数据时间间隔是不固定的)，输出的结果如下图所示。经过阅读源码发现是freq参数没有理解到位。我觉得pandas中的asfreq()方法其他参数也应该提供用户使用(例如：method和fill_value)这样可以让我这样的新手避免出现数据全是NAN的情况。\r\n![d846c24d-42b4-439d-ba0d-24da37aacd2b](https://user-images.githubusercontent.com/41312357/203485634-766e782d-6b3b-472e-b928-f05c7708bc82.png)\r\n\r\n",
        "state": "closed",
        "user": "bupt906",
        "closed_by": "Sunting78",
        "created_at": "2022-11-23T06:34:07+00:00",
        "updated_at": "2024-02-28T08:52:44+00:00",
        "closed_at": "2024-02-28T08:52:44+00:00",
        "comments_count": [
            "a10210532",
            "Hoogck",
            "weibo021"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 267,
        "title": "非常想学习PaddleTS，能不能开通下回放权限？",
        "body": "今天才报名PaddleTS课程学习，报名成功没法看课程回放，显示没有权限，特别想学习PaddleTS，能不能把回放的权限开启，或者怎有没有其他的途径去学习前面的课程？？",
        "state": "closed",
        "user": "XSheng001",
        "closed_by": "LinWencong",
        "created_at": "2022-11-24T16:29:28+00:00",
        "updated_at": "2022-12-13T09:31:27+00:00",
        "closed_at": "2022-12-13T09:31:27+00:00",
        "comments_count": [
            "zyn-sinde",
            "XSheng001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 275,
        "title": "AutoTS不支持Informer和DeepAR模型吗？",
        "body": "一使用`autots_informer=AutoTS(InformerModel, 24, 6)\r\nautots_informer.fit(ts_train, ts_val)`\r\n就提示`NotImplementedError: Unknown estimator`",
        "state": "closed",
        "user": "sly111",
        "closed_by": "sly111",
        "created_at": "2022-12-02T06:20:58+00:00",
        "updated_at": "2022-12-07T07:11:46+00:00",
        "closed_at": "2022-12-07T07:11:46+00:00",
        "comments_count": [
            "zyn-sinde",
            "sly111"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 265,
        "title": "月度数据用AutoTS训练时，utils.py中119行调用的pd.to_timedelta(train_index.freq))报错",
        "body": "问题：utils.py中119行调用的pd.to_timedelta(train_index.freq))方法似乎不支持以月为频率，当我尝试用paddlets对颗粒度为月的数据进行训练时，TSDataset中的freq自动转成<MonthBegin>或者<MonthEnd>，导致出现下面的报错信息。\r\n\r\nts = TSDataset.load_from_dataframe(\r\n    data,  #Also can be path to the CSV file\r\n    time_col='time_col',\r\n    target_cols=target_field,\r\n    known_cov_cols=data.columns.drop(['time_col', target_field]).tolist(),\r\n)\r\n'''\r\n中国沿海煤炭运价指数  国际波罗的海干散货海运总和指数   PMI          矿石           焦炭  \\\r\ntime_col                                                                 \r\n2018-01-01     1.49331      1242.000000  51.0   72.227273  2169.090909   \r\n2018-02-01     1.09641      1126.157895  50.0   72.769231  1960.000000   \r\n2018-03-01     1.05876      1154.238095  52.0   68.136364  1930.454545   \r\n2018-04-01     1.08231      1128.900000  51.0   64.764706  1725.500000   \r\n2018-05-01     1.26693      1293.095238  52.0   65.523810  1842.045455   \r\n2018-06-01     1.21853      1351.619048  52.0   64.500000  2220.000000 \r\n......\r\n'''\r\n\r\nfrom paddlets.automl.autots import AutoTS\r\nfrom paddlets.models.forecasting import MLPRegressor\r\nfrom ray.tune import uniform, qrandint, choice\r\nfrom paddlets.transform import Fill\r\n\r\nts_train_val, ts_test = ts.split(0.8)\r\nts_train, ts_val = ts_train_val.split(0.8)\r\nautots_model = AutoTS(NBEATSModel, 3, 1)\r\nautots_model.fit(train_tsdataset=ts_train_scaled, valid_tsdataset=ts_val_scaled, n_trials=1)\r\nsp = autots_model.search_space()\r\npredicted = autots_model.predict(ts_test_scaled)\r\n\r\n报错信息如下：\r\nFailure # 1 (occurred at 2022-11-21_14-41-47)\r\n\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=9724, ip=127.0.0.1, repr=run_trial)\r\n  File \"python\\ray\\_raylet.pyx\", line 859, in ray._raylet.execute_task\r\n  File \"python\\ray\\_raylet.pyx\", line 863, in ray._raylet.execute_task\r\n  File \"python\\ray\\_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\r\n    return method(__ray_actor, *args, **kwargs)\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\r\n    return method(self, *_args, **_kwargs)\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 355, in train\r\n    raise skipped from exception_cause(skipped)\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 325, in entrypoint\r\n    return self._trainable_func(\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\r\n    return method(self, *_args, **_kwargs)\r\n  File \"D:\\Anaconda\\envs\\time_series_py38\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 651, in _trainable_func\r\n    output = fn()\r\n  File \"C:\\Users\\ouyeel\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\automl\\optimize_runner.py\", line 174, in run_trial\r\n    score = fit_and_score(train_data=train_tsdataset,\r\n  File \"C:\\Users\\ouyeel\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\utils\\validation.py\", line 135, in fit_and_score\r\n    and check_train_valid_continuity(train_data, valid_data):\r\n  File \"C:\\Users\\ouyeel\\AppData\\Roaming\\Python\\Python38\\site-packages\\paddlets\\utils\\utils.py\", line 119, in check_train_valid_continuity\r\n    continuious = (valid_index[0] - train_index[-1] == pd.to_timedelta(train_index.freq))\r\n  File \"C:\\Users\\ouyeel\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\tools\\timedeltas.py\", line 142, in to_timedelta\r\n    return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors)\r\n  File \"C:\\Users\\ouyeel\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\tools\\timedeltas.py\", line 150, in _coerce_scalar_to_timedelta_type\r\n    result = Timedelta(r, unit)\r\n  File \"pandas\\_libs\\tslibs\\timedeltas.pyx\", line 1315, in pandas._libs.tslibs.timedeltas.Timedelta.__new__\r\nValueError: Value must be Timedelta, string, integer, float, timedelta or convertible, not MonthEnd",
        "state": "closed",
        "user": "lg-ustb",
        "closed_by": "QGN123",
        "created_at": "2022-11-22T01:10:55+00:00",
        "updated_at": "2022-12-08T12:43:13+00:00",
        "closed_at": "2022-12-08T12:43:13+00:00",
        "comments_count": [
            "a10210532",
            "LinWencong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 272,
        "title": "如何用模型输出长时间的预测",
        "body": "我的out_chunk_len设置为7，predict方法输出为7，怎么才能获得更多时间的预测",
        "state": "closed",
        "user": "yanglonghu",
        "closed_by": "a10210532",
        "created_at": "2022-11-29T10:26:34+00:00",
        "updated_at": "2022-12-28T03:28:32+00:00",
        "closed_at": "2022-12-28T03:28:32+00:00",
        "comments_count": [
            "yangs16"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 287,
        "title": "关于DeepAr AutoTS的后续问题",
        "body": "在#issue280中，通过相关部分修改能够成功运行，但是我发现运行结果绘图时，正式值和原来的真实值出现了偏差。\r\n这是默认版本的deeper绘制的效果图\r\n<img width=\"809\" alt=\"image\" src=\"https://user-images.githubusercontent.com/44394895/206611827-9570eec6-f5f4-4a32-aeef-554ec86371e6.png\">\r\n然后我使用了自动调参,获取到了一个最优参数，然后绘制的结果图如下：\r\n<img width=\"1176\" alt=\"image\" src=\"https://user-images.githubusercontent.com/44394895/206612509-8c7cc801-2777-4dfe-a89b-c5c65e21d9ae.png\">\r\n这里可以看到truth值，也就是真实值都发生了变化，和原来的真实值不符合，请问这是什么情况呢？\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "sly111",
        "closed_by": "sly111",
        "created_at": "2022-12-09T02:47:00+00:00",
        "updated_at": "2022-12-09T03:34:43+00:00",
        "closed_at": "2022-12-09T03:34:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 276,
        "title": " 苹果macOS M1 arm64安装报错",
        "body": "PaddlePaddle官方已经支持 Mac M1芯片的运行。但是，PaddleTS却不能支持。\r\n我看到PaddleTS中numpy依赖的版本是1.19.5，但是1.19.5并没有macOS的arm64的版本。",
        "state": "closed",
        "user": "wenzhaojie",
        "closed_by": "Sunting78",
        "created_at": "2022-12-02T07:05:36+00:00",
        "updated_at": "2024-02-28T08:53:35+00:00",
        "closed_at": "2024-02-28T08:53:35+00:00",
        "comments_count": [
            "QGN123",
            "wenzhaojie",
            "wenzhaojie",
            "QGN123",
            "wenzhaojie",
            "QGN123",
            "QGN123",
            "wenzhaojie",
            "QGN123",
            "QGN123",
            "QGN123",
            "wenzhaojie",
            "QGN123",
            "xonze"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 280,
        "title": "AutoTS中Deepar的相关问题",
        "body": "看当前版本中DeepAR model没有在`paddlets_default_search_space`中，我自定义了一个search_space，\r\n```                        \"DeepARModel\":{\r\n                            \"rnn_type_or_module\": choice([\"GRU\",\"LSTM\"]),\r\n                            \"hidden_size\": qrandint(32, 512, q=32),\r\n                            \"num_layers_recurrent\": randint(1, 4),\r\n                            \"dropout\": quniform(0, 1, 0.05),\r\n                            \"skip_chunk_len\":0,\r\n                            \"regression_mode\":choice([\"mean\", \"sampling\"]),\r\n                            \"batch_size\":qrandint(8,128,q=8),\r\n                            \"max_epochs\":qrandint(30,600,q=30),\r\n                            \"patience\":qrandint(5,50,q=5),\r\n                            \"optimizer_params\": {\r\n                                \"learning_rate\": uniform(1e-4, 1e-2)\r\n                            },\r\n                            \"seed\":42\r\n                        }\r\n```\r\n但是实际使用时提示\r\n```2022-12-07 15:03:39,246\tERROR trial_runner.py:993 -- Trial run_trial_33e5883e: Error processing event.\r\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=38826, ip=127.0.0.1, repr=run_trial)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\r\n    raise skipped from exception_cause(skipped)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\r\n    return self._trainable_func(\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\r\n    output = fn()\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/automl/optimize_runner.py\", line 174, in run_trial\r\n    score = fit_and_score(train_data=train_tsdataset,\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/utils/validation.py\", line 144, in fit_and_score\r\n    score_dict, predicts = backtest(data,\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/utils/backtest.py\", line 150, in backtest\r\n    score_dict = metric(real, predict)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/metrics/base.py\", line 261, in __call__\r\n    res_array = self._build_metrics_data(tsdataset_true, tsdataset_pred)\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/metrics/base.py\", line 54, in _build_metrics_data\r\n    raise_if_not(\r\n  File \"/Users/susheng/opt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddlets/logger/logger.py\", line 135, in raise_if_not\r\n    raise ValueError(message)\r\nValueError: In `normal` mode, only point forecasting data is supported!\r\n```\r\n请问这该如何修改呀",
        "state": "closed",
        "user": "sly111",
        "closed_by": "sly111",
        "created_at": "2022-12-07T07:15:28+00:00",
        "updated_at": "2022-12-08T06:23:55+00:00",
        "closed_at": "2022-12-08T06:23:55+00:00",
        "comments_count": [
            "QGN123",
            "sly111"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 277,
        "title": "AutoTS自动寻参的最佳模型如何保存？",
        "body": "`AutoTS自动寻参完成的模型如何保存精度最高的模型，用.save()方法暂不支持，用 best_param 返回的最佳参数去加载一个新的模型训练完保存吗",
        "state": "closed",
        "user": "yanglonghu",
        "closed_by": "LinWencong",
        "created_at": "2022-12-05T06:36:22+00:00",
        "updated_at": "2022-12-08T07:19:05+00:00",
        "closed_at": "2022-12-08T07:19:05+00:00",
        "comments_count": [
            "LinWencong",
            "LinWencong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 288,
        "title": "单元测试 test_MinMaxScaler 无法通过",
        "body": "```\r\npaddlets\\tests\\transform\\test_normalization.py\r\n```\r\n\r\n第50行：\r\n\r\n```python\r\nself.assertTrue(inverse1.get_known_cov().data.astype('int').equals(input1.get_known_cov().data))\r\n```\r\n\r\n`inverse1.get_known_cov().data.astype('int')` 与 `input1.get_known_cov().data` 永远不相等，\r\n\r\n因为前者的dtype是`int32`，而后者是`int64`。如果修改成：\r\n\r\n```python\r\nself.assertTrue(inverse1.get_known_cov().data.astype('int').equals(input1.get_known_cov().data.astype('int')))\r\n```\r\n\r\n则可以顺利通过。\r\n\r\n该单元测试中`test_MinMax`与`test_StandardScaler`这行代码出现了8次，都存在这个情况。\r\n\r\nPython3.8 64bit\r\n\r\n---\r\n\r\n另外我发现该单元测试中`test_with_sklearn`也有类似的相等判断，但是两侧已经都加了`.astype('int')`，所以可以顺利通过。",
        "state": "closed",
        "user": "2Bear",
        "closed_by": "2Bear",
        "created_at": "2022-12-13T05:53:12+00:00",
        "updated_at": "2022-12-13T09:41:29+00:00",
        "closed_at": "2022-12-13T09:41:29+00:00",
        "comments_count": [
            "LinWencong",
            "2Bear"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 304,
        "title": "TSDataset数据定义加载出错",
        "body": "spyder 运行官网例子代码：\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom paddlets import TSDataset\r\n\r\nx = np.linspace(-np.pi, np.pi, 200)\r\nsinx = np.sin(x) * 4 + np.random.randn(200)\r\ndf = pd.DataFrame(\r\n    {\r\n        'time_col': pd.date_range('2022-01-01', periods=200, freq='1h'),\r\n        'value': sinx,\r\n        'known_cov_1': sinx + 4,\r\n        'known_cov_2': sinx + 5,\r\n        'observed_cov': sinx + 8,\r\n        'static_cov': [1 for i in range(200)],\r\n    }\r\n)\r\n\r\ntarget_dataset = TSDataset.load_from_dataframe(\r\n    df,  #Also can be path to the CSV file\r\n    time_col='time_col',\r\n    target_cols='value',\r\n    freq='1h'\r\n)\r\n\r\n输出：\r\n[2022-12-16 18:45:10,564] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!",
        "state": "closed",
        "user": "tongbaiming",
        "closed_by": "tongbaiming",
        "created_at": "2022-12-16T10:50:46+00:00",
        "updated_at": "2023-01-07T02:32:16+00:00",
        "closed_at": "2023-01-07T02:32:16+00:00",
        "comments_count": [
            "zyn-sinde",
            "tongbaiming"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 290,
        "title": "inverse_transform 方法的 inplace 参数是无效的",
        "body": "```\r\npaddlets\\transform\\base.py\r\n```\r\n\r\n第219行：\r\n\r\n```python\r\nreturn self.inverse_transform_one(dataset)\r\n```\r\n\r\n没有传入 inplace 参数，这个参数不起作用。\r\n\r\nPR #286 ",
        "state": "closed",
        "user": "2Bear",
        "closed_by": "2Bear",
        "created_at": "2022-12-13T06:28:17+00:00",
        "updated_at": "2023-01-07T02:28:49+00:00",
        "closed_at": "2022-12-13T09:41:12+00:00",
        "comments_count": [
            "LinWencong",
            "2Bear",
            "tongbaiming"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 293,
        "title": "升级 chinese-calendar 版本来支持2023年节假日安排",
        "body": "chinese-calendar 最近更新到了1.8.0，支持了2023年中国法定节假日安排。\r\n\r\nhttps://github.com/LKI/chinese-calendar/releases/tag/1.8.0\r\n\r\nPR #291",
        "state": "closed",
        "user": "2Bear",
        "closed_by": "2Bear",
        "created_at": "2022-12-13T06:56:43+00:00",
        "updated_at": "2022-12-13T09:39:27+00:00",
        "closed_at": "2022-12-13T09:39:27+00:00",
        "comments_count": [
            "2Bear"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 281,
        "title": "多路时序组成训练数据时 groupid 是否支持乱序输入？",
        "body": "这个例子中，假如 id的顺序 是0，1交叉的，就报错了。不支持这种吗？\r\n\r\nsample = pd.DataFrame(np.random.randn(200, 3), columns=['a', 'c', 'd'])\r\nsample['id'] = pd.Series([0]*80 + [1]*120, name='id')\r\n\r\n#Load TSDatasets by group_id\r\nfrom paddlets import TSDataset\r\ntsdatasets = TSDataset.load_from_dataframe(\r\n    df=sample,\r\n    group_id='id',\r\n    target_cols='a',\r\n    observed_cov_cols=['c', 'd'],\r\n    #static_cov_cols='id'\r\n)",
        "state": "closed",
        "user": "JDanielWu",
        "closed_by": "a10210532",
        "created_at": "2022-12-07T08:35:39+00:00",
        "updated_at": "2022-12-28T03:29:06+00:00",
        "closed_at": "2022-12-28T03:29:05+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 326,
        "title": "表征模型是否支持多变量",
        "body": "请问一下表征模型是否支持多变量，在dataset中设置了known_cov_cols，然后使用CoST表征模型，但似乎没起作用，请问表征模型是否支持进行多变量训练，如果没有的话，如何才能在表征模型中使用多变量呢？",
        "state": "closed",
        "user": "lim-0",
        "closed_by": "lim-0",
        "created_at": "2022-12-26T08:34:01+00:00",
        "updated_at": "2022-12-28T02:29:14+00:00",
        "closed_at": "2022-12-28T02:29:13+00:00",
        "comments_count": [
            "Annnnnnnnnnnnn",
            "lim-0"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 329,
        "title": "TCNRegressor回测存在偏移",
        "body": "代码如下：\r\n```python\r\nix_dataset2 = TSDataset.load_from_dataframe(\r\n    data3,\r\n    time_col='time',\r\n    target_cols='ix',\r\n    freq='1d',\r\n    known_cov_cols=['work_day','holiday']\r\n)\r\n\r\nfrom paddlets.models.forecasting import MLPRegressor,LSTNetRegressor,TCNRegressor\r\nmd = TCNRegressor(\r\n    in_chunk_len = 7,\r\n    out_chunk_len = 1,\r\n    max_epochs=100,\r\n)\r\n\r\ntrain_dataset, val_test_dataset = ix_dataset2.split(0.7)\r\nval_dataset, test_dataset = val_test_dataset.split(0.5)\r\n# train_dataset.plot(add_data=[val_dataset,test_dataset], labels=['Val', 'Test'])\r\n\r\nmd.fit(train_dataset, val_dataset)\r\n\r\nfrom paddlets.utils import backtest\r\nscore, preds_data= backtest(\r\n    data=test_dataset,\r\n    model=md,\r\n    return_predicts = True)\r\ntest_dataset.plot(add_data=preds_data,labels=\"backtest\")\r\n```\r\n结果如下：\r\n![image](https://user-images.githubusercontent.com/35923416/209530499-8d56813a-ec2f-4f56-92a9-2df9b5f2eadb.png)\r\n预测趋势相当不错，但是存在明显偏移，请问这个是什么原因？求解答",
        "state": "closed",
        "user": "lim-0",
        "closed_by": "lim-0",
        "created_at": "2022-12-26T09:14:35+00:00",
        "updated_at": "2022-12-29T06:22:11+00:00",
        "closed_at": "2022-12-29T06:22:11+00:00",
        "comments_count": [
            "StevenL2017",
            "bianchuanxin",
            "Annnnnnnnnnnnn",
            "lim-0"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 333,
        "title": "AutoTS报错和运行异常",
        "body": "## 执行代码\r\n官方示例\r\n\r\nfrom paddlets.datasets.repository import get_dataset\r\ntsdataset = get_dataset(\"UNI_WTH\")\r\nfrom paddlets.models.forecasting import MLPRegressor\r\nfrom paddlets.automl.autots import AutoTS\r\nautots_model = AutoTS(MLPRegressor, 96, 2)\r\nautots_model.fit(tsdataset)\r\n\r\n## 运行得到输出如下\r\n加粗部分为报错，然后程序不终止，一直不断打印==Status==之后的内容，Number of trials也不变，这个是什么原因呢？\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\automl\\searcher.py:4: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\r\n  from ray.tune.suggest import BasicVariantGenerator\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\automl\\searcher.py:5: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.  \r\n  from ray.tune.suggest.optuna import OptunaSearch\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\automl\\searcher.py:6: DeprecationWarning: The module `ray.tune.suggest.flaml` has been moved to `ray.tune.search.flaml` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.flaml` with `ray.tune.search.flaml`.      \r\n  from ray.tune.suggest.flaml import CFO\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\automl\\searcher.py:8: DeprecationWarning: The module `ray.tune.suggest.bohb` has been moved to `ray.tune.search.bohb` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.bohb` with `ray.tune.search.bohb`.\r\n  from ray.tune.suggest.bohb import TuneBOHB\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\automl\\search_space_configer.py:8: DeprecationWarning: The module `ray.tune.sample` has been moved to `ray.tune.search.sample` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.sample` with `ray.tune.search.sample`.     \r\n  from ray.tune.sample import Float, Integer, Categorical\r\n2022-12-27 14:21:00,844 INFO worker.py:1538 -- Started a local Ray instance.\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ray\\tune\\search\\optuna\\optuna_search.py:694: FutureWarning: IntUniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.IntDistribution` instead.\r\n  return ot.distributions.IntUniformDistribution(\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ray\\tune\\search\\optuna\\optuna_search.py:682: FutureWarning: UniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.FloatDistribution` instead.\r\n  return ot.distributions.UniformDistribution(\r\n[I 2022-12-27 14:21:02,351] A new study created in memory with name: optuna\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\distributions.py:766: FutureWarning: IntUniformDistribution(high=128, low=8, step=8) is deprecated and internally converted to IntDistribution(high=128, log=False, low=8, step=8). See https://github.com/optuna/optuna/issues/2941.\r\n  warnings.warn(message, FutureWarning)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\distributions.py:766: FutureWarning: IntUniformDistribution(high=600, low=30, step=30) is deprecated and internally converted to IntDistribution(high=600, log=False, low=30, step=30). See https://github.com/optuna/optuna/issues/2941.\r\n  warnings.warn(message, FutureWarning)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\distributions.py:766: FutureWarning: IntUniformDistribution(high=50, low=5, step=5) is deprecated and internally converted to IntDistribution(high=50, log=False, low=5, step=5). See https://github.com/optuna/optuna/issues/2941.\r\n  warnings.warn(message, FutureWarning)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\distributions.py:766: FutureWarning: UniformDistribution(high=0.01, low=0.0001) is deprecated and internally converted to FloatDistribution(high=0.01, log=False, low=0.0001, step=None). See https://github.com/optuna/optuna/issues/2941.\r\n  warnings.warn(message, FutureWarning)\r\n== Status ==\r\nCurrent time: 2022-12-27 14:21:07 (running for 00:00:05.18)\r\nMemory usage on this node: 12.3/31.7 GiB\r\nUsing FIFO scheduling algorithm.\r\nResources requested: 0/20 CPUs, 0/1 GPUs, 0.0/12.44 GiB heap, 0.0/6.22 GiB objects (0.0/1.0 accelerator_type:G)\r\nResult logdir: C:\\Users\\Steven\\ray_results\\run_trial_2022-12-27_14-21-02   \r\nNumber of trials: 1/20 (1 PENDING)\r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+       \r\n| Trial name         | status   | loc   |   batch_size | hidden_config        |   max_epochs |   optimizer_params/lea |   patience | use_bn   |       \r\n|                    |          |       |              |                   \r\n   |              |             rning_rate |            |          |       \r\n|--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------|       \r\n| run_trial_41b3f5c7 | PENDING  |       |          104 | Choice_2: [64, _66c0 |          300 |             0.00969596 |         45 | False    |       \r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+       \r\n\r\n\r\n**2022-12-27 14:21:12,864 WARNING worker.py:1851 -- This worker was asked to execute a function that has not been registered ({type=PythonFunctionDescriptor, module_name=ray.util.placement_group, class_name=, function_name=_export_bundle_reservation_check_method_if_needed.<locals>.bundle_reservation_check_func, function_hash=c0f5d1653dc84f95bbeed36cb66471cd}, node=127.0.0.1, worker_id=e226e520eafc567ab1ccf4e297e0559f5116718dbeda073aa17dee4a, pid=9048). You may have to restart Ray.\r\n(pid=9048) 2022-12-27 14:21:12,863      ERROR function_manager.py:415 -- This worker was asked to execute a function that has not been registered ({type=PythonFunctionDescriptor, module_name=ray.util.placement_group, class_name=, function_name=_export_bundle_reservation_check_method_if_needed.<locals>.bundle_reservation_check_func, function_hash=c0f5d1653dc84f95bbeed36cb66471cd}, node=127.0.0.1, worker_id=e226e520eafc567ab1ccf4e297e0559f5116718dbeda073aa17dee4a, pid=9048). You may have to restart Ray.**\r\n== Status ==\r\nCurrent time: 2022-12-27 14:21:12 (running for 00:00:10.23)\r\nMemory usage on this node: 12.3/31.7 GiB\r\nUsing FIFO scheduling algorithm.\r\nResources requested: 0/20 CPUs, 0/1 GPUs, 0.0/12.44 GiB heap, 0.0/6.22 GiB objects (0.0/1.0 accelerator_type:G)\r\nResult logdir: C:\\Users\\Steven\\ray_results\\run_trial_2022-12-27_14-21-02   \r\nNumber of trials: 1/20 (1 PENDING)\r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+       \r\n| Trial name         | status   | loc   |   batch_size | hidden_config        |   max_epochs |   optimizer_params/lea |   patience | use_bn   |       \r\n|                    |          |       |              |                   \r\n   |              |             rning_rate |            |          |       \r\n|--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------|       \r\n| run_trial_41b3f5c7 | PENDING  |       |          104 | Choice_2: [64, _66c0 |          300 |             0.00969596 |         45 | False    |       \r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+       \r\n\r\n\r\n== Status ==\r\nCurrent time: 2022-12-27 14:21:18 (running for 00:00:15.30)\r\nMemory usage on this node: 12.3/31.7 GiB\r\nUsing FIFO scheduling algorithm.\r\nResources requested: 0/20 CPUs, 0/1 GPUs, 0.0/12.44 GiB heap, 0.0/6.22 GiB objects (0.0/1.0 accelerator_type:G)\r\nResult logdir: C:\\Users\\Steven\\ray_results\\run_trial_2022-12-27_14-21-02   \r\nNumber of trials: 1/20 (1 PENDING)\r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+       \r\n| Trial name         | status   | loc   |   batch_size | hidden_config        |   max_epochs |   optimizer_params/lea |   patience | use_bn   |       \r\n|                    |          |       |              |                   \r\n   |              |             rning_rate |            |          |       \r\n|--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------|       \r\n| run_trial_41b3f5c7 | PENDING  |       |          104 | Choice_2: [64, _66c0 |          300 |             0.00969596 |         45 | False    |       \r\n+--------------------+----------+-------+--------------+----------------------+--------------+------------------------+------------+----------+  \r\n\r\n## 运行环境\r\nwindows 11 vscode powershell\r\npaddlepaddle-gpu           2.4.1\r\npaddlets                           1.0.2",
        "state": "closed",
        "user": "StevenL2017",
        "closed_by": "Sunting78",
        "created_at": "2022-12-27T06:25:46+00:00",
        "updated_at": "2024-02-28T08:56:06+00:00",
        "closed_at": "2024-02-28T08:56:05+00:00",
        "comments_count": [
            "LinWencong",
            "StevenL2017",
            "LinWencong",
            "mendjks",
            "huayuocean",
            "akari0216",
            "wazjajl",
            "jiaohuix",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 338,
        "title": "请问应该怎么处理很多个比较短的序列的预测",
        "body": "我现在在处理的问题是有很多个比较短的序列，需要对每个序列分别预测他的未来的值，但是我阅读paddlets的文档后似乎没有找到相关的api，请问我可以通过什么方法来解决这样的问题呢？\r\n我的数据可以看成是假设有1000只股票的数据，每只股票有过去30个星期的数据，我需要预测未来10个星期每个股票的走势，请问paddlets是否提供了相应的api？或者我可以通过什么方法来解决这一问题？",
        "state": "closed",
        "user": "xiehuanyi",
        "closed_by": "Sunting78",
        "created_at": "2022-12-29T01:55:18+00:00",
        "updated_at": "2024-02-28T08:57:29+00:00",
        "closed_at": "2024-02-28T08:57:29+00:00",
        "comments_count": [
            "QGN123",
            "weibo021"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 341,
        "title": "Paddle Inference 进行部署推理，build_ts_infer_input方法出错！",
        "body": "# 加载已保存的模型    \r\ndef load_model(self,\r\n                   load_pdmodel: str = '../model/save_model.pdmodel',\r\n                   load_pdiparams: str = '../model/save_model.pdiparams'\r\n                   ):\r\n        config = paddle_infer.Config(load_pdmodel, load_pdiparams)\r\n        self.predictor = paddle_infer.create_predictor(config)\r\n        input_names = self.predictor.get_input_names()\r\n        print(f\"input_name: f{input_names}\")\r\n        import json\r\n        with open(\"../model/save_model_model_meta\") as f:\r\n            self.json_data = json.load(f)\r\n            print(self.json_data)\r\n\r\n# 预测推理\r\n    def predict_ts(self,\r\n                   pre_tsdataset: TSDataset,\r\n                   cols,\r\n                   recursive: bool = False):\r\n        val_dataset = self.data_transform(tsdataset=pre_tsdataset,\r\n                                          cols=cols)\r\n        from paddlets.utils.utils import build_ts_infer_input\r\n        input_data = build_ts_infer_input(val_dataset, \"../model/save_model_model_meta\")\r\n\r\n        for key, value in self.json_data['input_data'].items():\r\n            input_handle1 = self.predictor.get_input_handle(key)\r\n            # set batch_size=1\r\n            value[0] = 1\r\n            input_handle1.reshape(value)\r\n            input_handle1.copy_from_cpu(input_data[key])\r\n\r\n        self.predictor.run()\r\n        output_names = self.predictor.get_output_names()\r\n        output_handle = self.predictor.get_output_handle(output_names[0])\r\n        output_data = output_handle.copy_to_cpu()\r\n        print(output_data)\r\n##############################################################################################\r\n# 调用过程：\r\n# # 模型加载\r\nfit_lstnet.load_model(load_pdmodel='../model/LSTNet.pdmodel',\r\n                      load_pdiparams='../model/LSTNet.pdiparams')\r\n# # 预测推理\r\nfit_lstnet.predict_ts(pre_tsdataset=fit_lstnet.val_dataset, cols=target_cols)\r\n\r\n执行load_model保存模型成功\r\n执行predict_ts函数时build_ts_infer_input报错，报错信息如下：\r\ne[1me[35m--- Running analysis [ir_graph_build_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_graph_clean_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_analysis_pass]e[0m\r\ne[32m--- Running IR pass [simplify_with_basic_ops_pass]e[0m\r\ne[32m--- Running IR pass [layer_norm_fuse_pass]e[0m\r\ne[37m---    Fused 0 subgraphs into layer_norm op.e[0m\r\ne[32m--- Running IR pass [attention_lstm_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]e[0m\r\ne[32m--- Running IR pass [mul_lstm_fuse_pass]e[0m\r\ne[32m--- Running IR pass [fc_gru_fuse_pass]e[0m\r\ne[37m---    fused 0 pairs of fc gru patternse[0m\r\ne[32m--- Running IR pass [mul_gru_fuse_pass]e[0m\r\ne[32m--- Running IR pass [seq_concat_fc_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]e[0m\r\ne[32m--- Running IR pass [matmul_v2_scale_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]e[0m\r\nI1230 08:59:19.689038 23564 fuse_pass_base.cc:57] ---  detected 2 subgraphs\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]e[0m\r\ne[32m--- Running IR pass [matmul_scale_fuse_pass]e[0m\r\ne[32m--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]e[0m\r\ne[32m--- Running IR pass [fc_fuse_pass]e[0m\r\nI1230 08:59:19.691967 23564 fuse_pass_base.cc:57] ---  detected 2 subgraphs\r\ne[32m--- Running IR pass [repeated_fc_relu_fuse_pass]e[0m\r\ne[32m--- Running IR pass [squared_mat_sub_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_transpose_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]e[0m\r\ne[32m--- Running IR pass [is_test_pass]e[0m\r\ne[32m--- Running IR pass [runtime_context_cache_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_params_sync_among_devices_pass]e[0m\r\ne[1me[35m--- Running analysis [adjust_cudnn_workspace_size_pass]e[0m\r\ne[1me[35m--- Running analysis [inference_op_replace_pass]e[0m\r\ne[1me[35m--- Running analysis [ir_graph_to_program_pass]e[0m\r\nI1230 08:59:19.704661 23564 analysis_predictor.cc:1035] ======= optimize end =======\r\nI1230 08:59:19.704661 23564 naive_executor.cc:102] ---  skip [feed], feed -> past_target\r\nI1230 08:59:19.705637 23564 naive_executor.cc:102] ---  skip [tmp_0], fetch -> fetch\r\ninput_name: f['past_target']\r\n{'model_type': 'forecasting', 'ancestor_classname_set': ['LSTNetRegressor', 'PaddleBaseModelImpl', 'PaddleBaseModel', 'BaseModel', 'Trainable', 'ABC', 'object'], 'modulename': 'paddlets.models.forecasting.dl.lstnet', 'size': {'in_chunk_len': 3600, 'out_chunk_len': 3600, 'skip_chunk_len': 0}, 'input_data': {'past_target': [None, 3600, 1]}}\r\nTraceback (most recent call last):\r\n  File \"E:/Paddle-release-2.2/PaddleTS/examples_self/fit_forecasting_model.py\", line 410, in <module>\r\n    fit_lstnet.predict_ts(pre_tsdataset=fit_lstnet.val_dataset, cols=target_cols)\r\n  File \"E:/Paddle-release-2.2/PaddleTS/examples_self/fit_forecasting_model.py\", line 284, in predict_ts\r\n    input_data = build_ts_infer_input(val_dataset, \"../model/LSTNet_model_meta\")\r\n  File \"E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\utils\\utils.py\", line 439, in build_ts_infer_input\r\n    sample = next(iter(dataloader))\r\n  File \"F:\\CondaData\\envs\\paddlets\\lib\\site-packages\\paddle\\fluid\\dataloader\\dataloader_iter.py\", line 298, in __next__\r\n    six.reraise(*sys.exc_info())\r\n  File \"F:\\CondaData\\envs\\paddlets\\lib\\site-packages\\six.py\", line 719, in reraise\r\n    raise value\r\n  File \"F:\\CondaData\\envs\\paddlets\\lib\\site-packages\\paddle\\fluid\\dataloader\\dataloader_iter.py\", line 272, in __next__\r\n    data = self._reader.read_next_var_list()\r\nStopIteration\r\n",
        "state": "closed",
        "user": "jiangxinufo",
        "closed_by": "Sunting78",
        "created_at": "2022-12-30T01:00:52+00:00",
        "updated_at": "2024-02-28T08:57:54+00:00",
        "closed_at": "2024-02-28T08:57:54+00:00",
        "comments_count": [
            "jiangxinufo",
            "a10210532",
            "jiangxinufo",
            "jiangxinufo",
            "a10210532",
            "jiangxinufo",
            "jiangxinufo",
            "jiangxinufo",
            "a10210532",
            "jiangxinufo",
            "gitmhg",
            "gitmhg"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 348,
        "title": "Does TSDataset support slicing like dataframe? ",
        "body": "Does TSDataset support slicing like dataframe? What I what to do is get a sub ts of a TSDataset object, the only way I found is to transform the TSDataset object to a DataFrame, then use .loc() to get a sub dataframe, and finally transform the dataframe to TSDataset again. It seems a liitle tedious. ",
        "state": "closed",
        "user": "sysublackstar",
        "closed_by": "Sunting78",
        "created_at": "2023-01-06T09:35:33+00:00",
        "updated_at": "2024-02-28T08:58:21+00:00",
        "closed_at": "2024-02-28T08:58:21+00:00",
        "comments_count": [
            "QGN123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 344,
        "title": "anomaly_example中模型训练报ModuleNotFoundError: No module named 'more_itertools'错误",
        "body": "相关环境如下：\r\n# Name                    Version                   Build  Channel\r\naiosignal                 1.2.0                    pypi_0    pypi\r\nalembic                   1.8.1                    pypi_0    pypi\r\namqp                      5.1.1                    pypi_0    pypi\r\nanyio                     3.6.2                    pypi_0    pypi\r\nargon2-cffi               21.3.0                   pypi_0    pypi\r\nargon2-cffi-bindings      21.2.0                   pypi_0    pypi\r\nastor                     0.8.1                    pypi_0    pypi\r\nasttokens                 2.1.0                    pypi_0    pypi\r\nattrs                     22.1.0                   pypi_0    pypi\r\nautopage                  0.5.1                    pypi_0    pypi\r\nbackcall                  0.2.0                    pypi_0    pypi\r\nbeautifulsoup4            4.11.1                   pypi_0    pypi\r\nbilliard                  3.6.4.0                  pypi_0    pypi\r\nbleach                    5.0.1                    pypi_0    pypi\r\nca-certificates           2022.07.19           haa95532_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\ncelery                    5.2.7                    pypi_0    pypi\r\ncertifi                   2022.9.14        py38haa95532_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\ncffi                      1.15.1                   pypi_0    pypi\r\ncharset-normalizer        2.1.1                    pypi_0    pypi\r\nchinese-calendar          1.8.0                    pypi_0    pypi\r\nclick                     8.0.4                    pypi_0    pypi\r\nclick-didyoumean          0.3.0                    pypi_0    pypi\r\nclick-plugins             1.1.1                    pypi_0    pypi\r\nclick-repl                0.2.0                    pypi_0    pypi\r\ncliff                     4.0.0                    pypi_0    pypi\r\ncloudpickle               2.2.0                    pypi_0    pypi\r\ncmaes                     0.8.2                    pypi_0    pypi\r\ncmd2                      2.4.2                    pypi_0    pypi\r\ncolorama                  0.4.5                    pypi_0    pypi\r\ncolorlog                  6.7.0                    pypi_0    pypi\r\nconfigspace               0.6.0                    pypi_0    pypi\r\ncontourpy                 1.0.5                    pypi_0    pypi\r\ncycler                    0.11.0                   pypi_0    pypi\r\ncython                    0.29.32                  pypi_0    pypi\r\ndebugpy                   1.6.3                    pypi_0    pypi\r\ndecorator                 5.1.1                    pypi_0    pypi\r\ndefusedxml                0.7.1                    pypi_0    pypi\r\ndistlib                   0.3.6                    pypi_0    pypi\r\nentrypoints               0.4                      pypi_0    pypi\r\nexecuting                 1.2.0                    pypi_0    pypi\r\nfastjsonschema            2.16.2                   pypi_0    pypi\r\nfilelock                  3.8.0                    pypi_0    pypi\r\nflaml                     1.0.12                   pypi_0    pypi\r\nflask                     2.2.2                    pypi_0    pypi\r\nflask-cors                3.0.10                   pypi_0    pypi\r\nfonttools                 4.37.3                   pypi_0    pypi\r\nfrozenlist                1.3.1                    pypi_0    pypi\r\ngreenlet                  1.1.3                    pypi_0    pypi\r\ngrpcio                    1.43.0                   pypi_0    pypi\r\nhpbandster                0.7.4                    pypi_0    pypi\r\nidna                      3.4                      pypi_0    pypi\r\nimportlib-metadata        4.12.0                   pypi_0    pypi\r\nimportlib-resources       5.9.0                    pypi_0    pypi\r\nipykernel                 6.17.0                   pypi_0    pypi\r\nipython                   8.6.0                    pypi_0    pypi\r\nipython-genutils          0.2.0                    pypi_0    pypi\r\nipywidgets                8.0.2                    pypi_0    pypi\r\nitsdangerous              2.1.2                    pypi_0    pypi\r\njedi                      0.18.1                   pypi_0    pypi\r\njinja2                    3.1.2                    pypi_0    pypi\r\njoblib                    1.2.0                    pypi_0    pypi\r\njsonschema                4.16.0                   pypi_0    pypi\r\njupyter                   1.0.0                    pypi_0    pypi\r\njupyter-client            7.4.4                    pypi_0    pypi\r\njupyter-console           6.4.4                    pypi_0    pypi\r\njupyter-core              4.11.2                   pypi_0    pypi\r\njupyter-server            1.21.0                   pypi_0    pypi\r\njupyterlab-pygments       0.2.2                    pypi_0    pypi\r\njupyterlab-widgets        3.0.3                    pypi_0    pypi\r\nkiwisolver                1.4.4                    pypi_0    pypi\r\nkombu                     5.2.4                    pypi_0    pypi\r\nlightgbm                  3.3.2                    pypi_0    pypi\r\nllvmlite                  0.39.1                   pypi_0    pypi\r\nlxml                      4.9.1                    pypi_0    pypi\r\nmako                      1.2.2                    pypi_0    pypi\r\nmarkupsafe                2.1.1                    pypi_0    pypi\r\nmatplotlib                3.6.0                    pypi_0    pypi\r\nmatplotlib-inline         0.1.6                    pypi_0    pypi\r\nmistune                   2.0.4                    pypi_0    pypi\r\nmore-itertools            8.14.0                   pypi_0    pypi\r\nmpmath                    1.2.1                    pypi_0    pypi\r\nmsgpack                   1.0.4                    pypi_0    pypi\r\nnbclassic                 0.4.8                    pypi_0    pypi\r\nnbclient                  0.7.0                    pypi_0    pypi\r\nnbconvert                 7.2.3                    pypi_0    pypi\r\nnbformat                  5.7.0                    pypi_0    pypi\r\nnest-asyncio              1.5.6                    pypi_0    pypi\r\nnetifaces                 0.11.0                   pypi_0    pypi\r\nnotebook                  6.5.2                    pypi_0    pypi\r\nnotebook-shim             0.2.2                    pypi_0    pypi\r\nnumba                     0.56.4                   pypi_0    pypi\r\nnumpy                     1.19.5                   pypi_0    pypi\r\nopenssl                   1.1.1q               h2bbff1b_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nopt-einsum                3.3.0                    pypi_0    pypi\r\noptuna                    3.0.3                    pypi_0    pypi\r\npackaging                 21.3                     pypi_0    pypi\r\npaddle-bfloat             0.1.7                    pypi_0    pypi\r\npaddlepaddle-gpu          2.3.2                    pypi_0    pypi\r\npaddlets                  1.1.0                    pypi_0    pypi\r\npandas                    1.3.5                    pypi_0    pypi\r\npandocfilters             1.5.0                    pypi_0    pypi\r\nparso                     0.8.3                    pypi_0    pypi\r\npatsy                     0.5.2                    pypi_0    pypi\r\npbr                       5.10.0                   pypi_0    pypi\r\npickleshare               0.7.5                    pypi_0    pypi\r\npillow                    9.2.0                    pypi_0    pypi\r\npip                       22.1.2           py38haa95532_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\npkgutil-resolve-name      1.3.10                   pypi_0    pypi\r\nplatformdirs              2.5.2                    pypi_0    pypi\r\nprettytable               3.4.1                    pypi_0    pypi\r\nprometheus-client         0.15.0                   pypi_0    pypi\r\nprompt-toolkit            3.0.32                   pypi_0    pypi\r\nprotobuf                  3.20.0                   pypi_0    pypi\r\npsutil                    5.9.3                    pypi_0    pypi\r\npure-eval                 0.2.2                    pypi_0    pypi\r\npycparser                 2.21                     pypi_0    pypi\r\npygments                  2.13.0                   pypi_0    pypi\r\npyod                      1.0.6                    pypi_0    pypi\r\npyparsing                 3.0.9                    pypi_0    pypi\r\npyperclip                 1.8.2                    pypi_0    pypi\r\npyreadline3               3.4.1                    pypi_0    pypi\r\npyro4                     4.82                     pypi_0    pypi\r\npyrsistent                0.18.1                   pypi_0    pypi\r\npython                    3.8.13               h6244533_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\npython-dateutil           2.8.2                    pypi_0    pypi\r\npython-docx               0.8.11                   pypi_0    pypi\r\npytz                      2022.2.1                 pypi_0    pypi\r\npywavelets                1.3.0                    pypi_0    pypi\r\npywin32                   304                      pypi_0    pypi\r\npywinpty                  2.0.9                    pypi_0    pypi\r\npyyaml                    6.0                      pypi_0    pypi\r\npyzmq                     24.0.1                   pypi_0    pypi\r\nqtconsole                 5.4.0                    pypi_0    pypi\r\nqtpy                      2.2.1                    pypi_0    pypi\r\nray                       2.1.0                    pypi_0    pypi\r\nrequests                  2.28.1                   pypi_0    pypi\r\nscikit-learn              1.1.2                    pypi_0    pypi\r\nscipy                     1.7.3                    pypi_0    pypi\r\nseaborn                   0.12.1                   pypi_0    pypi\r\nsend2trash                1.8.0                    pypi_0    pypi\r\nserpent                   1.41                     pypi_0    pypi\r\nsetuptools                63.4.1           py38haa95532_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nshap                      0.41.0                   pypi_0    pypi\r\nsix                       1.16.0                   pypi_0    pypi\r\nslicer                    0.0.7                    pypi_0    pypi\r\nsniffio                   1.3.0                    pypi_0    pypi\r\nsoupsieve                 2.3.2.post1              pypi_0    pypi\r\nsqlalchemy                1.4.41                   pypi_0    pypi\r\nsqlite                    3.39.2               h2bbff1b_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nstack-data                0.6.0                    pypi_0    pypi\r\nstatsmodels               0.12.2                   pypi_0    pypi\r\nstevedore                 4.0.0                    pypi_0    pypi\r\nsympy                     1.11.1                   pypi_0    pypi\r\ntabulate                  0.8.10                   pypi_0    pypi\r\ntensorboardx              2.5.1                    pypi_0    pypi\r\nterminado                 0.17.0                   pypi_0    pypi\r\nthreadpoolctl             3.1.0                    pypi_0    pypi\r\ntinycss2                  1.2.1                    pypi_0    pypi\r\ntornado                   6.2                      pypi_0    pypi\r\ntqdm                      4.64.1                   pypi_0    pypi\r\ntraitlets                 5.5.0                    pypi_0    pypi\r\ntyping-extensions         4.3.0                    pypi_0    pypi\r\nurllib3                   1.26.12                  pypi_0    pypi\r\nvc                        14.2                 h21ff451_1    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nvine                      5.0.0                    pypi_0    pypi\r\nvirtualenv                20.16.5                  pypi_0    pypi\r\nvs2015_runtime            14.27.29016          h5e58377_2    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nwcwidth                   0.2.5                    pypi_0    pypi\r\nwebencodings              0.5.1                    pypi_0    pypi\r\nwebsocket-client          1.4.2                    pypi_0    pypi\r\nwerkzeug                  2.2.2                    pypi_0    pypi\r\nwheel                     0.37.1             pyhd3eb1b0_0    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nwidgetsnbextension        4.0.3                    pypi_0    pypi\r\nwincertstore              0.2              py38haa95532_2    https://mirrors.aliyun.com/anaconda/pkgs/main\r\nxgboost                   1.6.2                    pypi_0    pypi\r\nzipp                      3.8.1                    pypi_0    pypi\r\n# 报错部分代码：\r\nimport paddle\r\nimport numpy as np\r\n\r\n# 固定随机随机种子，保证训练结果可复现\r\nseed = 2022\r\npaddle.seed(seed)\r\nnp.random.seed(seed)\r\n\r\n#建模与训练\r\nfrom paddlets.models.anomaly import AutoEncoder\r\nmodel = AutoEncoder(\r\n    in_chunk_len=2, # 样本数据窗口大小\r\n    max_epochs=100  # 最大epoch设为100\r\n)\r\nmodel.fit(train_data_scaled)\r\n\r\n\r\n#报错内容如下\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nCell In [6], line 10\r\n      7 np.random.seed(seed)\r\n      9 #建模与训练\r\n---> 10 from paddlets.models.anomaly import AutoEncoder\r\n     11 model = AutoEncoder(\r\n     12     in_chunk_len=2, # 样本数据窗口大小\r\n     13     max_epochs=100  # 最大epoch设为100\r\n     14 )\r\n     15 model.fit(train_data_scaled)\r\n\r\nFile E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\models\\anomaly\\__init__.py:8\r\n      1 # !/usr/bin/env python3\r\n      2 # -*- coding:utf-8 -*-\r\n      4 \"\"\"\r\n      5 paddlets anomaly.\r\n      6 \"\"\"\r\n----> 8 from paddlets.models.anomaly.dl.autoencoder import AutoEncoder\r\n      9 from paddlets.models.anomaly.dl.anomaly_transformer import AnomalyTransformer\r\n     10 from paddlets.models.anomaly.dl.vae import VAE\r\n\r\nFile E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\models\\anomaly\\dl\\autoencoder.py:15\r\n     13 from paddlets.models.anomaly.dl._ed.ed import MLP, CNN\r\n     14 from paddlets.models.common.callbacks import Callback\r\n---> 15 from paddlets.models.anomaly.dl import utils as U\r\n     16 from paddlets.datasets import TSDataset\r\n     17 from paddlets.logger import raise_if, raise_if_not\r\n\r\nFile E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\models\\anomaly\\dl\\utils.py:11\r\n      9 import paddle\r\n     10 import paddle.nn.functional as F\r\n---> 11 import more_itertools as mit\r\n     13 from paddlets.logger import raise_if_not, raise_if, raise_log, Logger\r\n     14 from paddlets.datasets import TSDataset\r\n\r\nModuleNotFoundError: No module named 'more_itertools'",
        "state": "closed",
        "user": "jiangxinufo",
        "closed_by": "jiangxinufo",
        "created_at": "2023-01-05T03:25:11+00:00",
        "updated_at": "2023-01-05T07:21:47+00:00",
        "closed_at": "2023-01-05T07:21:47+00:00",
        "comments_count": [
            "wangdong2222",
            "jiangxinufo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 346,
        "title": "TFT model can't be saved ",
        "body": "Traceback (most recent call last):\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\models\\forecasting\\dl\\paddle_base.py\", line 233, in save\r\n    pickle.dump(self, f)\r\nTypeError: cannot pickle 'Tensor' object\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\work\\py\\dossen-alg-api\\paddle_tft.py\", line 220, in <module>\r\n    main()\r\n  File \"D:\\work\\py\\dossen-alg-api\\paddle_tft.py\", line 198, in main\r\n    model = train(train_dataset, valid_dataset)\r\n  File \"D:\\work\\py\\dossen-alg-api\\paddle_tft.py\", line 162, in train\r\n    model.save(RNN_MODEL_PATH)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\models\\forecasting\\dl\\paddle_base.py\", line 235, in save\r\n    raise_log(ValueError(\"error occurred while saving %s, err: %s\" % (abs_model_path, str(e))))\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddlets\\logger\\logger.py\", line 112, in raise_log\r\n    raise exception\r\nValueError: error occurred while saving D:\\work\\py\\dossen-alg-api\\model\\tft\\tft_model, err: cannot pickle 'Tensor' object",
        "state": "closed",
        "user": "raygeAI",
        "closed_by": "kehuo",
        "created_at": "2023-01-06T02:52:25+00:00",
        "updated_at": "2023-02-03T01:36:20+00:00",
        "closed_at": "2023-02-03T01:36:20+00:00",
        "comments_count": [
            "kehuo",
            "kehuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 345,
        "title": "异常检测创建完数据集后，使用plot_anoms可视化数据报错。",
        "body": "# 加载数据集\r\nts_data = load_datasets.load_datasets_anomaly(time_col='Date',\r\n                                        feature_cols=[\"L#SVR4_VAR830_A\",\"L#SVR4_VAR833_A\",\"L#SVR4_VAR476_A\",\"L#SVR4_VAR350_A\",\"L#SVR4_VAR340_A\",\"L#SVR4_VAR342_A\",\"L#SVR4_VAR344_A\"]\r\n)\r\n# 可视化数据集\r\nfrom paddlets.utils.utils import plot_anoms\r\nplot_anoms(origin_data=ts_data, feature_name=\"L#SVR4_VAR830_A\")\r\n\r\n# 报错如下：\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In [16], line 4\r\n      2 matplotlib.use('TkAgg') #加上，不然显示图表有问题\r\n      3 import matplotlib.pyplot as plt\r\n----> 4 ts_data.plot(add_data=[\"L#SVR4_VAR830_A\",\"L#SVR4_VAR833_A\",\"L#SVR4_VAR476_A\",\"L#SVR4_VAR350_A\",\"L#SVR4_VAR340_A\",\"L#SVR4_VAR342_A\",\"L#SVR4_VAR344_A\"])\r\n      5 plt.show()\r\n      6 # from paddlets.utils.utils import plot_anoms\r\n      7 #\r\n      8 # plot_anoms(origin_data=ts_data, feature_name=\"L#SVR4_VAR830_A\")\r\n\r\nFile E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\datasets\\tsdataset.py:1689, in TSDataset.plot(self, columns, add_data, labels, low_quantile, high_quantile, central_quantile, **kwargs)\r\n   1656 def plot(self, \r\n   1657          columns:Union[List[str], str] = None, \r\n   1658          add_data:Union[List[\"TSDataset\"], \"TSDataset\"] = None,\r\n   (...)\r\n   1662          central_quantile:float = 0.5,\r\n   1663          **kwargs) -> \"pyplot\":\r\n   1664     \"\"\"\r\n   1665     plot function, a wrapper for Dataframe.plot()\r\n   1666     \r\n   (...)\r\n   1687 \r\n   1688     \"\"\"\r\n-> 1689     quantile_cols = self._get_quantile_cols_origin_names()\r\n   1690     if not columns:\r\n   1691         if len(quantile_cols) == 0:\r\n\r\nFile E:\\Paddle-release-2.2\\PaddleTS\\paddlets\\datasets\\tsdataset.py:1849, in TSDataset._get_quantile_cols_origin_names(self)\r\n   1841 \"\"\"\r\n   1842 Get quantile cols origin names\r\n   1843 \r\n   (...)\r\n   1846 \r\n   1847 \"\"\"\r\n   1848 origin_columns = []\r\n-> 1849 for name in self.target.columns:\r\n   1850     tmp = name.split(\"@quantile\")\r\n   1851     if tmp[0] not in origin_columns and len(tmp) > 1:\r\n\r\nAttributeError: 'NoneType' object has no attribute 'columns'",
        "state": "closed",
        "user": "jiangxinufo",
        "closed_by": "Sunting78",
        "created_at": "2023-01-05T05:20:43+00:00",
        "updated_at": "2024-02-28T08:58:11+00:00",
        "closed_at": "2024-02-28T08:58:11+00:00",
        "comments_count": [
            "jiangxinufo",
            "QGN123",
            "jiangxinufo",
            "wangdong2222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 349,
        "title": "OneHot inverse_transform 不起作用",
        "body": "用OneHot对tsdataset进行inverse_transform不起作用，无法复原被分解的列，无论drop是True还是False ",
        "state": "closed",
        "user": "tongbaiming",
        "closed_by": "Sunting78",
        "created_at": "2023-01-07T02:48:36+00:00",
        "updated_at": "2024-02-28T08:58:28+00:00",
        "closed_at": "2024-02-28T08:58:28+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 358,
        "title": "paddlets.datasets.repository.get_dataset()方法获取到的数据里面包含NAN，fillna_method参数好像不起作用？",
        "body": null,
        "state": "closed",
        "user": "Hoogck",
        "closed_by": "Hoogck",
        "created_at": "2023-01-29T09:09:40+00:00",
        "updated_at": "2023-01-29T09:09:49+00:00",
        "closed_at": "2023-01-29T09:09:49+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 351,
        "title": "paddlets.datasets.tsdataset.TSDataset.concat方法使用时好像有bug",
        "body": "我有一个predict_result_list，这个list中所有的数据都是有效的。但是，经过paddlets.datasets.tsdataset.TSDataset.concat方法把他们结合起来之后，这里除了第一条数据是正确的之外，剩下的数据都变成了NAN，没有报任何错误。\r\n下面是我的代码：\r\n`\r\n# 使用test_data预测\r\n\r\npredict_result_list = []\r\nfor i in paddletsData_list_X:\r\n    predicted_dataset = model.predict(i)  # 将归一化后的数据集放进去预测\r\n    predict_result_list.append(predicted_dataset)\r\n\r\nprint(predict_result_list[1])\r\n\r\n\r\n# 将列表转化为一个paddlets_dataset\r\ntotal_minmax_result = paddlets.datasets.tsdataset.TSDataset.concat(predict_result_list,axis=1)\r\ntotal_minmax_result\r\n`\r\n\r\n这里面predict_result_list 里面的所有的数据都是有效的，但是使用paddlets.datasets.tsdataset.TSDataset.concat操作之后，得到的结果里面只有第一条数据是正常的，剩下的数据全部都是NAN，时间索引也是正常且连续的。\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Renxg150",
        "closed_by": "a10210532",
        "created_at": "2023-01-10T08:47:48+00:00",
        "updated_at": "2023-01-30T08:36:42+00:00",
        "closed_at": "2023-01-30T08:36:42+00:00",
        "comments_count": [
            "Renxg150",
            "a10210532",
            "Renxg150",
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 359,
        "title": "paddlets.datasets.repository.get_dataset()方法获取到的数据里面包含NAN，fillna_method参数好像不起作用？",
        "body": "model:AutoEncoder recall:  1.0\r\n[2023-01-29 17:05:19,919] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: inf| val_0_mse: 0.000000| 0:00:06s\r\nTraceback (most recent call last):\r\n  File \"anomaly_detect.py\", line 35, in <module>\r\n    model.fit(train_tsdata_scaled,val_tsdata_scaled)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/models/anomaly/dl/anomaly_base.py\", line 378, in fit\r\n    self._fit(train_dataloader, valid_dataloaders)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/models/anomaly/dl/anomaly_base.py\", line 414, in _fit\r\n    self._predict_epoch(eval_name, valid_dataloader)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/models/anomaly/dl/anomaly_base.py\", line 593, in _predict_epoch\r\n    metrics_logs = self._metric_container_dict[name](y_pred, y_true)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/metrics/metrics.py\", line 395, in __call__\r\n    res = metric.metric_fn(y_true, y_score)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/metrics/utils.py\", line 42, in wrapper\r\n    return func(obj, y_true, y_score, **kwargs)\r\n  File \"/****/workspace/ts/PaddleTS/paddlets/metrics/metrics.py\", line 55, in metric_fn\r\n    return metrics.mean_squared_error(y_true, y_score)\r\n  File \"/home/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 439, in mean_squared_error\r\n    y_true, y_pred, multioutput\r\n  File \"/home/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 95, in _check_reg_targets\r\n    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\r\n  File \"/home/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 800, in check_array\r\n    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\r\n  File \"/home/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\r\n    type_err, msg_dtype if msg_dtype is not None else X.dtype\r\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\r\n",
        "state": "closed",
        "user": "Hoogck",
        "closed_by": "Hoogck",
        "created_at": "2023-01-29T09:11:38+00:00",
        "updated_at": "2023-01-29T09:44:23+00:00",
        "closed_at": "2023-01-29T09:44:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 352,
        "title": "请问下PaddleTS具体哪些模型支持协变量？",
        "body": "想问下PaddleTS具体哪些模型是支持协变量的，从文档里面没找到很好的说明\r\n然后用MLPRegressor模型测试了下，训练用的TSDataset是包含observed_cov_cols，但是预测的时候传递的TSDataset不包含observed_cov_cols，还是能正确推理，例如下面这段代码：\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport paddlets\r\n\r\nif __name__ == \"__main__\":\r\n    x = np.linspace(-np.pi, np.pi, 200)\r\n    sinx = np.sin(x) * 4 + np.random.randn(200)\r\n\r\n    df1 = pd.DataFrame(\r\n        {\r\n            \"time_col1\": pd.date_range(\"2022-01-01\", periods=200, freq=\"1h\"),\r\n            \"value_col1\": sinx,\r\n            \"observed_col1\": sinx + 1,\r\n        }\r\n    )\r\n    ts1 = paddlets.TSDataset.load_from_dataframe(\r\n        df1,\r\n        time_col=\"time_col1\",\r\n        target_cols=\"value_col1\",\r\n        observed_cov_cols=[\"observed_col1\"],\r\n    )\r\n\r\n    # 训练模型\r\n    train_ts, val_ts = ts1.split(0.8)\r\n    from paddlets.models.forecasting import MLPRegressor\r\n\r\n    mlp = MLPRegressor(in_chunk_len=20, out_chunk_len=10, max_epochs=500)\r\n    mlp.fit(train_ts, val_ts)\r\n\r\n    # 预测模型\r\n    df2 = pd.DataFrame(\r\n        {\r\n            \"time_col2\": pd.date_range(\"2022-01-01\", periods=200, freq=\"1h\"),\r\n            \"value_col2\": sinx,\r\n        }\r\n    )\r\n    ts2 = paddlets.TSDataset.load_from_dataframe(\r\n        df2, time_col=\"time_col2\", target_cols=\"value_col2\", freq=\"1h\"\r\n    )\r\n    predict_result_2 = mlp.predict(ts2)\r\n    print(\"predict results: \", predict_result_2)\r\n```",
        "state": "closed",
        "user": "markluofd",
        "closed_by": "Sunting78",
        "created_at": "2023-01-11T05:38:38+00:00",
        "updated_at": "2024-02-28T08:58:36+00:00",
        "closed_at": "2024-02-28T08:58:36+00:00",
        "comments_count": [
            "bianchuanxin",
            "markluofd",
            "kehuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 353,
        "title": "NBEATSModel推理的时候协变量名字和训练时候协变量名字不一致，而且交换多个协变量顺序预测结果不发生改变",
        "body": "NBEATSModel推理的时候指定的协变量名字和训练时候的协变量名字不一致，模型可以完成推理，这个还算可以理解，可以假设predict时候构造TSDataset填的observed_cov_cols列表是顺序相关的\r\n但是，我主动改变observed_cov_cols协变量名字的顺序，预测结果没发生改变，这个似乎不太合理，参考如下代码\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport paddlets\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    x = np.linspace(-np.pi, np.pi, 200)\r\n    sinx = np.sin(x) * 4 + np.random.randn(200)\r\n\r\n    df1 = pd.DataFrame(\r\n        {\r\n            \"time_col1\": pd.date_range(\"2022-01-01\", periods=200, freq=\"1h\"),\r\n            \"value_col1\": sinx,\r\n            \"observed_col11\": sinx + 1,\r\n            \"observed_col12\": sinx + 2,\r\n        }\r\n    )\r\n    ts1 = paddlets.TSDataset.load_from_dataframe(\r\n        df1,\r\n        time_col=\"time_col1\",\r\n        target_cols=\"value_col1\",\r\n        observed_cov_cols=[\"observed_col11\", \"observed_col12\"],\r\n    )\r\n\r\n    # 训练模型\r\n    train_ts, val_ts = ts1.split(0.8)\r\n    from paddlets.models.forecasting import NBEATSModel\r\n\r\n    nbeast = NBEATSModel(in_chunk_len=20, out_chunk_len=10, max_epochs=500)\r\n    nbeast.fit(train_ts, val_ts)\r\n\r\n    # 预测一，协变量的名字和训练时候协变量名字不同\r\n    np.random.seed(1)\r\n    df21 = pd.DataFrame(\r\n        {\r\n            \"time_col2\": pd.date_range(\"2022-01-01\", periods=200, freq=\"1h\"),\r\n            \"value_col2\": sinx,\r\n            \"observed_col21\": sinx - 20 * np.random.randn(200),\r\n            \"observed_col22\": sinx + 30 * np.random.randn(200),\r\n        }\r\n    )\r\n    ts21 = paddlets.TSDataset.load_from_dataframe(\r\n        df21,\r\n        time_col=\"time_col2\",\r\n        target_cols=\"value_col2\",\r\n        observed_cov_cols=[\"observed_col21\", \"observed_col22\"],\r\n        freq=\"1h\",\r\n    )\r\n    predict_result_21 = nbeast.predict(ts21)\r\n\r\n    # 预测二，重新生成TSDataset对象，但是指定observed_cov_cols的时候把名字对调\r\n    ts22 = paddlets.TSDataset.load_from_dataframe(\r\n        df21,\r\n        time_col=\"time_col2\",\r\n        target_cols=\"value_col2\",\r\n        observed_cov_cols=[\"observed_col22\", \"observed_col21\"],\r\n        freq=\"1h\",\r\n    )\r\n    predict_result_22 = nbeast.predict(ts22)\r\n\r\n    # 打印两次预测结果\r\n    print(\"predict 1:\")\r\n    print(predict_result_21)\r\n    print(\"predict 2:\")\r\n    print(predict_result_22)\r\n    print(\"预测用的ts的observed_cov_cols列名称和训练对不上，而且名称的顺序不影响预测结果，有点奇怪\")\r\n```\r\n这边得到的结果如下：\r\n```\r\npredict 1:\r\n                     value_col2\r\n2022-01-09 08:00:00   29.420271\r\n2022-01-09 09:00:00   30.838749\r\n2022-01-09 10:00:00    4.161640\r\n2022-01-09 11:00:00   24.282003\r\n2022-01-09 12:00:00   30.760273\r\n2022-01-09 13:00:00   -1.353035\r\n2022-01-09 14:00:00   57.743870\r\n2022-01-09 15:00:00   44.322231\r\n2022-01-09 16:00:00   -2.120617\r\n2022-01-09 17:00:00   16.197647\r\npredict 2:\r\n                     value_col2\r\n2022-01-09 08:00:00   29.420271\r\n2022-01-09 09:00:00   30.838749\r\n2022-01-09 10:00:00    4.161640\r\n2022-01-09 11:00:00   24.282003\r\n2022-01-09 12:00:00   30.760273\r\n2022-01-09 13:00:00   -1.353035\r\n2022-01-09 14:00:00   57.743870\r\n2022-01-09 15:00:00   44.322231\r\n2022-01-09 16:00:00   -2.120617\r\n2022-01-09 17:00:00   16.197647\r\n```",
        "state": "closed",
        "user": "markluofd",
        "closed_by": "QGN123",
        "created_at": "2023-01-11T11:52:35+00:00",
        "updated_at": "2023-01-13T03:19:06+00:00",
        "closed_at": "2023-01-13T03:19:06+00:00",
        "comments_count": [
            "markluofd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 357,
        "title": "Could not load library libcublasLt.so.10. Error",
        "body": "**已经安装好paddle库：**\r\npaddle-bfloat==0.1.7\r\npaddlepaddle-gpu==2.3.2.post110\r\npaddlets==1.1.0\r\n\r\n**nvidia-smi 查看显卡信息如下：**\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.191.01   Driver Version: 450.191.01   CUDA Version: 11.0     |\r\n\r\n**根据网站提示验证安装是成功：**\r\nhttps://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html#old-version-anchor-7-%E4%B8%89%E3%80%81%E9%AA%8C%E8%AF%81%E5%AE%89%E8%A3%85\r\n>>> import paddle\r\n>>> paddle.utils.run_check()\r\nRunning verify PaddlePaddle program ... \r\nW0118 12:01:07.216766  1307 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 11.0\r\nW0118 12:01:07.218919  1307 gpu_resources.cc:91] device: 0, cuDNN Version: 8.7.\r\nPaddlePaddle works well on 1 GPU.\r\nPaddlePaddle works well on 1 GPUs.\r\n**PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.**\r\n>>> import paddlets\r\n>>> paddlets.__version__\r\n'1.1.0'\r\n\r\n**执行DEMO报错：**\r\nhttps://paddlets.readthedocs.io/zh_CN/latest/source/get_started/run_on_gpu.html\r\n/usr/local/lib/python3.7/dist-packages/paddlets/utils/backtest.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import defaultdict, Iterable\r\nW0117 17:57:11.007817   856 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 11.0\r\nW0117 17:57:11.010010   856 gpu_resources.cc:91] device: 0, cuDNN Version: 8.7.\r\n/usr/local/lib/python3.7/dist-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n**Could not load library libcublasLt.so.10. Error: libcublasLt.so.10: cannot open shared object file: No such file or directory**\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)\r\n1   void paddle::imperative::Tracer::TraceOpImpl<paddle::imperative::VarBase>(std::string const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::imperative::details::NameVarMapTrait<paddle::imperative::VarBase>::Type const&, paddle::framework::AttributeMap&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, paddle::framework::AttributeMap*, bool)\r\n2   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&, paddle::framework::AttributeMap const&)\r\n3   phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, float, float, std::string const&, bool, bool, bool, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::BatchNormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, float, float, std::string const&, bool, bool, bool, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::Compute(phi::KernelContext*)\r\n4   void phi::BatchNormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, float, float, std::string const&, bool, bool, bool, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)\r\n5   phi::GPUContext::Impl::GetDnnHandle()\r\n6   phi::InitDnnHandle(cudnnContext**, CUstream_st*, phi::Place)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1673949432 (unix time) try \"date -d @1673949432\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x358) received by PID 856 (TID 0x7f30f4919b80) from PID 856 ***]\r\n\r\nAborted (core dumped)\r\n",
        "state": "closed",
        "user": "peterz3g",
        "closed_by": "Sunting78",
        "created_at": "2023-01-18T04:04:15+00:00",
        "updated_at": "2024-02-28T09:01:03+00:00",
        "closed_at": "2024-02-28T09:01:03+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 360,
        "title": "使用AnomalyTransformer训练时序异常检测模型时出现问题。",
        "body": "1.环境：centos7  paddlepaddle-gpu==2.3.2  paddlets== 1.1.0  cuda11.2  nvidia-driver460.39  \r\n\r\n2.问题描述：\r\n   使用paddlets自带数据NAB_TEMP训练时序异常检测模型报错\r\n   其中AutoEncoder、VAE训练正常，使用AnomalyTransformer训练报错，错误信息提示输入中有NaN值：\r\nW0130 16:10:13.515244 53384 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW0130 16:10:13.518093 53384 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\n[2023-01-30 16:10:14,805] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: 0.000000| val_0_mse: 0.000000| 0:00:01s\r\n[2023-01-30 16:10:15,530] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 001| loss: -0.041732| val_0_mse: 0.000000| 0:00:01s\r\n[2023-01-30 16:10:16,260] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 002| loss: -0.039907| val_0_mse: 0.000000| 0:00:02s\r\n[2023-01-30 16:10:17,004] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 003| loss: -0.040051| val_0_mse: 0.000000| 0:00:03s\r\n[2023-01-30 16:10:17,789] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 004| loss: -0.043504| val_0_mse: 0.000000| 0:00:04s\r\n[2023-01-30 16:10:18,632] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 005| loss: -0.042415| val_0_mse: 0.000000| 0:00:05s\r\n[2023-01-30 16:10:19,405] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 006| loss: -0.039770| val_0_mse: 0.000000| 0:00:05s\r\n[2023-01-30 16:10:20,047] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 007| loss: -0.040144| val_0_mse: 0.000000| 0:00:06s\r\n[2023-01-30 16:10:20,691] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 008| loss: -0.040011| val_0_mse: 0.000000| 0:00:07s\r\n[2023-01-30 16:10:21,333] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 009| loss: -0.040603| val_0_mse: 0.000000| 0:00:07s\r\n[2023-01-30 16:10:22,034] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 010| loss: -0.047260| val_0_mse: 0.000000| 0:00:08s\r\n[2023-01-30 16:10:22,037] [paddlets.models.common.callbacks.callbacks] [INFO] \r\nEarly stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_mse = 0.000000\r\n[2023-01-30 16:10:22,037] [paddlets.models.common.callbacks.callbacks] [INFO] Best weights from best epoch are automatically used!\r\n[2023-01-30 16:10:22,589] [paddlets.metrics.base] [WARNING] Tsdataset true's and pred's time_index do not match, the result will be calculated according to the intersection!\r\nmodel:AutoEncoder f1:  0.049204052098408106\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:25,481] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: 29.800358| val_0_mse: 0.311698| 0:00:02s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:27,665] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 001| loss: 24.403154| val_0_mse: 0.311698| 0:00:05s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:29,726] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 002| loss: 35.839511| val_0_mse: 0.673310| 0:00:07s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:31,828] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 003| loss: 31.323491| val_0_mse: 0.311699| 0:00:09s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:34,021] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 004| loss: 17.868246| val_0_mse: 0.311697| 0:00:11s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:36,139] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 005| loss: 52.115227| val_0_mse: 0.311697| 0:00:13s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:38,255] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 006| loss: 56.577546| val_0_mse: 0.311697| 0:00:15s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:40,470] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 007| loss: 52.143328| val_0_mse: 0.311698| 0:00:17s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:42,456] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 008| loss: 58.133194| val_0_mse: 0.311698| 0:00:19s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:44,506] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 009| loss: 56.605193| val_0_mse: 0.671903| 0:00:21s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:46,533] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 010| loss: 54.171396| val_0_mse: 0.311697| 0:00:23s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:48,609] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 011| loss: 65.563436| val_0_mse: 0.311698| 0:00:25s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:50,706] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 012| loss: 53.648452| val_0_mse: 0.311698| 0:00:28s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:52,738] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 013| loss: 49.160785| val_0_mse: 0.311697| 0:00:30s\r\n/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\r\n  \"When training, we now always track global mean and variance.\")\r\n[2023-01-30 16:10:54,891] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 014| loss: 59.601553| val_0_mse: 0.311698| 0:00:32s\r\n[2023-01-30 16:10:54,906] [paddlets.models.common.callbacks.callbacks] [INFO] \r\nEarly stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 0.311697\r\n[2023-01-30 16:10:54,906] [paddlets.models.common.callbacks.callbacks] [INFO] Best weights from best epoch are automatically used!\r\n[2023-01-30 16:10:56,156] [paddlets.metrics.base] [WARNING] Tsdataset true's and pred's time_index do not match, the result will be calculated according to the intersection!\r\nmodel:VAE f1:  0.2502206531332745\r\n[2023-01-30 16:11:09,499] [paddlets.models.anomaly.dl.utils] [INFO] epoch: 0, Updating learning rate to 0.0002\r\n[2023-01-30 16:11:13,823] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 000| loss: 505.360534| val_0_mse: 0.311697| 0:00:17s\r\n[2023-01-30 16:11:26,160] [paddlets.models.anomaly.dl.utils] [INFO] epoch: 1, Updating learning rate to 0.0001\r\n[2023-01-30 16:11:30,438] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 001| loss: 2401649.044474| val_0_mse: 0.321708| 0:00:34s\r\n[2023-01-30 16:11:42,506] [paddlets.models.anomaly.dl.utils] [INFO] epoch: 2, Updating learning rate to 5e-05\r\n[2023-01-30 16:11:47,047] [paddlets.models.common.callbacks.callbacks] [INFO] epoch 002| loss: 10089118.069477| val_0_mse: 0.575549| 0:00:50s\r\n[2023-01-30 16:11:58,801] [paddlets.models.anomaly.dl.utils] [INFO] epoch: 3, Updating learning rate to 2.5e-05\r\nTraceback (most recent call last):\r\n  File \"anomaly_detect.py\", line 48, in <module>\r\n    model.fit(train_tsdata_scaled,val_tsdata_scaled)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/models/anomaly/dl/anomaly_transformer.py\", line 406, in fit\r\n    self._fit(train_dataloader, valid_dataloaders)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/models/anomaly/dl/anomaly_transformer.py\", line 435, in _fit\r\n    self._predict_epoch(eval_name, valid_dataloader)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/models/anomaly/dl/anomaly_base.py\", line 593, in _predict_epoch\r\n    metrics_logs = self._metric_container_dict[name](y_pred, y_true)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/metrics/metrics.py\", line 395, in __call__\r\n    res = metric.metric_fn(y_true, y_score)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/metrics/utils.py\", line 42, in wrapper\r\n    return func(obj, y_true, y_score, **kwargs)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/paddlets/metrics/metrics.py\", line 55, in metric_fn\r\n    return metrics.mean_squared_error(y_true, y_score)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 439, in mean_squared_error\r\n    y_true, y_pred, multioutput\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\r\n    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 800, in check_array\r\n    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\r\n  File \"/****/toolkit/anaconda3/envs/fx/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\r\n    type_err, msg_dtype if msg_dtype is not None else X.dtype\r\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\r\n\r\n\r\n3.训练代码如下：\r\nimport os\r\nimport paddle\r\nimport numpy as np\r\nfrom paddlets.models.anomaly import AutoEncoder,AnomalyTransformer,VAE,USAD,MTADGAT\r\nfrom paddlets.datasets.tsdataset import TSDataset\r\nfrom paddlets.datasets.repository import get_dataset\r\nfrom paddlets.utils.utils import plot_anoms\r\nfrom paddlets.metrics import F1,ACC,Precision,Recall\r\nfrom paddlets.transform  import Fill,StandardScaler\r\nfrom paddlets.metrics import MAE,MSE,QuantileLoss\r\nfrom paddlets.transform import TimeFeatureGenerator\r\nos.environ['CUDA_VISIBLE_DEVICES']=\"1\"\r\n\r\nts_data = get_dataset('NAB_TEMP') # label_col: 'label', feature_cols: 'value'\r\n#ts_data =  TSDataset.load_from_csv(csv_file,time_col=\"timestamp\",label_col=\"label\",feature_cols=\"value\",freq=\"5min\")\r\n\r\n#fill  nan\r\nfill =  Fill(cols=[\"label\",\"value\"],method=\"pre\")\r\nts_data = fill.transform_one(ts_data)\r\n\r\n#time_f = TimeFeatureGenerator([\"month\", \"weekday\", \"hour\", \"dayofyear\", \"weekofyear\"])\r\n#ts_gen = time_f.fit_transform(ts_data)\r\n#ts_data = TSDataset.concat([ts_data,ts_gen])\r\n\r\nprint(f\"#####The input ts_data.target:{ts_data.target}\")\r\nprint(f\"#####The input ts_data.known_cov:{ts_data.known_cov}\")\r\nprint(f\"#####The input ts_data.observed_cov:{ts_data.observed_cov}\")\r\n\r\n#plot_anoms(origin_data=ts_data, feature_name='value')\r\n\r\n#set seed\r\nseed = 2022\r\npaddle.seed(seed)\r\nnp.random.seed(seed)\r\ntrain_tsdata, val_test_tsdata = ts_data.split(0.3)\r\nval_tsdata, test_tsdata = val_test_tsdata.split(0.5)\r\n\r\n#standardize\r\nscaler = StandardScaler(\"value\")\r\nscaler.fit(train_tsdata)\r\ntrain_tsdata_scaled = scaler.transform(train_tsdata)\r\nval_tsdata_scaled = scaler.transform(val_tsdata)\r\ntest_tsdata_scaled = scaler.transform(test_tsdata)\r\n\r\nmodel_list = {\"AutoEncoder\":AutoEncoder,\"VAE\":VAE,\"AnomalyTransformer\":AnomalyTransformer}\r\nfor name,model in model_list.items():\r\n\tmodel = model(in_chunk_len=10, max_epochs=50)\r\n\tmodel.fit(train_tsdata_scaled,val_tsdata_scaled)\r\n\t\r\n\tpred_label = model.predict(test_tsdata_scaled)\r\n\tlable_name = pred_label.target.data.columns[0]\r\n\t\r\n\tf1 = F1()(test_tsdata, pred_label)\r\n\tprecision = Precision()(test_tsdata, pred_label)\r\n\trecall = Recall()(test_tsdata, pred_label)\r\n\tprint(f'model:{name} f1: ', f1[lable_name])\r\n\tprint(f'model:{name} precision: ', precision[lable_name])\r\n\tprint(f'model:{name} recall: ', recall[lable_name])\r\n\t\r\n\t#plot_anoms(origin_data=test_tsdata, predict_data=pred_label, feature_name=\"value\")\r\n\t\r\n\t#pred_score = model.predict_score(test_data_scaled)\r\n    #plot_anoms(origin_data=test_tsdata, predict_data=pred_score, feature_name=\"value\").figure.savefig(f\"{name}_predict_result.png\")\r\n\t\r\n   \r\n   \r\n",
        "state": "closed",
        "user": "Hoogck",
        "closed_by": "Sunting78",
        "created_at": "2023-01-30T08:36:13+00:00",
        "updated_at": "2024-02-28T09:01:19+00:00",
        "closed_at": "2024-02-28T09:01:19+00:00",
        "comments_count": [
            "willionZS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 354,
        "title": "PaddleTS增加NLinear时序预测模型的提案",
        "body": "## 综述\r\n\r\n本提案旨在建议将NLinear时序预测模型加入PaddleTS模型库。\r\n\r\n👉[NLinear原作论文](https://arxiv.org/pdf/2205.13504v3.pdf)\r\n👉[基于PaddleTS的NLinear实现](https://github.com/2Bear/PaddleTS/blob/linear/paddlets/models/forecasting/dl/nlinear.py)\r\n\r\n本实现立足于原作设计，亦做出了以下改进：\r\n\r\n⭐支持已知协变量与观测协变量。\r\n⭐Linear结构可以按需增加隐层。\r\n\r\n本提案将NLinear与结构类似的MLP以及主流的NBEATS进行了效果比较（见`有效性验证`一节）。\r\n实验证明NLinear能以极低的模型复杂度实现较优异的效果。本实现做出的改进则进一步提升了NLinear的效果和泛用性。\r\n\r\n## NLinear模型介绍\r\n\r\nNLinear是一个非常简单的线性模型，仅将历史输入通过一个线性层，就得到预测输出。\r\n\r\n![linear](https://user-images.githubusercontent.com/20450255/212222892-afb160fb-a98a-4824-8c3d-55f4187ee82c.png)\r\n\r\n为了解决时序数据的分布漂移问题，NLinear又对输入输出做了一次非常简单的Normalization。以历史输入的最后一个数作为尾数。历史输入先减去尾数，然后通过线性层，得到的输出再加回尾数，作为模型的预测输出。\r\n\r\n## 本实现做出的改进\r\n\r\n### 支持已知协变量与观测协变量\r\n\r\n原作设计虽然简单高效，但是并不能利用TSDataset中包含的协变量信息，对于协变量至关重要的任务并不适用，为了解决这个问题，本实现做了相应改进。在构建输入张量时，将`PAST_TARGET`、`KNOWN_COV`与`OBSERVED_COV`一维展平，然后横向拼接作为输入，得到一维输出后，再重新折叠成所需要的张量形状。\r\n\r\n```python\r\n# concat backcast, known_cov, observed_cov if any\r\nfeature = [backcast.reshape((batch_size, 1, -1))]\r\nif known_cov is not None:\r\n    feature.append(known_cov.reshape((batch_size, 1, -1)))\r\nif observed_cov is not None:\r\n    feature.append(observed_cov.reshape((batch_size, 1, -1)))\r\nout = paddle.concat(x=feature, axis=2)\r\n\r\n# forward\r\nout = self._nn(out)\r\nout = out.reshape([batch_size, -1, self._target_dim])\r\n```\r\n\r\n### Linear结构可以按需增加隐层\r\n\r\n协变量增加了输入张量的复杂性，单线性层可能无法充分学习特征，导致欠拟合。为了解决这个问题，本实现也做了相应改进。增加了与MLP类似的`hidden_config`属性，允许开发者按需增加隐层。\r\n\r\n```python\r\n# Unlike MLP, `hidden_config` is empty by default, so there can be no hidden layer.\r\nlayers = []\r\ndims = [in_chunk_len_multi] + hidden_config + [out_chunk_len_multi]\r\nfor i in range(len(dims) - 2):\r\n    layers.append(paddle.nn.Linear(dims[i], dims[i + 1]))\r\n    if use_bn:\r\n        layers.append(paddle.nn.BatchNorm1D(1))\r\n    layers.append(paddle.nn.ReLU())\r\nlayers.append(paddle.nn.Linear(dims[-2], dims[-1]))\r\nself._nn = paddle.nn.Sequential(*layers)\r\n```\r\n\r\n## 有效性验证\r\n\r\n以下是NLinear与其它模型在主流数据集的实验结果，考虑到MLP并不支持协变量，且数据集中协变量不一定对预测有正向作用，所以每个数据集都做了有协变量与无协变量两遍测试。\r\n\r\n![result](https://user-images.githubusercontent.com/20450255/212227499-4b53a09d-dd09-4c51-9ef1-e68cba7f4742.png)\r\n\r\n### `隐层`的有效性\r\n\r\n从实验结果可知，虽然单线性层的NLinear效果不错，但是有隐层的NLinear更优，尤其当协变量多导致输入复杂时，效果尤为明显。因此可以认为本实现的`可增加隐层`改进是有效的。\r\n\r\n### `Normalization`的有效性\r\n\r\n有隐层的NLinear换种角度看，可以被认为是一种增加了Normalization的MLP。从实验结果可知，当输入相同（都没有协变量），且网络结构一致（都有一个相同的隐层）时，NLinear均优于MLP。因此可以认为原作的`Normalization`特性是一个有效的特性。\r\n\r\n### `协变量`的有效性\r\n\r\n并不是所有数据集的协变量都对预测有正向作用。通过与同样支持协变量的NBEATS对比可知，当协变量有助益时，NLinear模型可以从协变量中学习有效特征，实现比无协变量时更好的效果。因此可以认为本实现的`支持协变量`改进是有效的。（而MLP完全不支持协变量，对此类任务无适用性。）\r\n\r\n## 结论\r\n\r\n总的来说，NLinear简单好用，而本实现的NLinear模型在原作设计的基础上，进一步提升了效果和泛用性。NLinear的模型复杂程度并不比MLP高，却能实现比某些复杂模型更好的效果。模型调参简单，训练快，可以迅速地得出结论，适合作为各种任务的入手模型。\r\n\r\n另外从PaddleTS自身发展的角度来看，NLinear无疑是对现有模型库的有益补充。考虑到开源社区内已有顶流时序建模库（5K+⭐）支持了该模型，PaddleTS吸纳NLinear亦有利于提高自身竞争力。\r\n\r\n所以，建议PaddleTS加入NLinear时序预测模型。",
        "state": "closed",
        "user": "2Bear",
        "closed_by": "2Bear",
        "created_at": "2023-01-13T03:53:18+00:00",
        "updated_at": "2023-01-30T03:28:30+00:00",
        "closed_at": "2023-01-30T03:28:30+00:00",
        "comments_count": [
            "yangs16",
            "LinWencong",
            "2Bear",
            "2Bear",
            "2Bear",
            "bianchuanxin",
            "QGN123",
            "2Bear"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 362,
        "title": "模型保存再训练问题",
        "body": "您好\r\n在使用时序预测模型对自有数据集fit后，如何在之前训练的基础上对新数据进行再训练？还是说每次都需要使用全部的数据重新训练",
        "state": "closed",
        "user": "yutong12",
        "closed_by": "Sunting78",
        "created_at": "2023-02-01T09:38:20+00:00",
        "updated_at": "2024-02-28T09:01:35+00:00",
        "closed_at": "2024-02-28T09:01:35+00:00",
        "comments_count": [
            "a10210532",
            "yutong12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 365,
        "title": "verbose存储问题",
        "body": "看目前的文档，对模型训练过程中的信息，如epoch、loss、val_loss 都是直接打印在命令行，请问是否有相关的接口能获取到模型训练的信息，如果没有的话，当前情况下要实现这些的需求有何建议的方法呢？",
        "state": "closed",
        "user": "lim-0",
        "closed_by": "lim-0",
        "created_at": "2023-02-07T02:23:11+00:00",
        "updated_at": "2023-02-07T02:43:50+00:00",
        "closed_at": "2023-02-07T02:43:26+00:00",
        "comments_count": [
            "lim-0"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 361,
        "title": "使用自定义数据集时出现问题",
        "body": "您好，我的数据集格式如下\r\n![企业微信截图_167512756938](https://user-images.githubusercontent.com/59248260/215633608-66122674-4683-4bcc-969f-337a86302985.png)\r\n我想LSTNet网络进行预测运算，这里是执行的代码\r\n![企业微信截图_16751276581901](https://user-images.githubusercontent.com/59248260/215633829-a2901c29-74ae-40fe-9e67-3df30cbe69e3.png)\r\n他报了一个valueerror\r\n![企业微信截图_16751276902327](https://user-images.githubusercontent.com/59248260/215633921-7c5758d0-efce-477f-b27d-fdb226583910.png)\r\n我检查了我的数据集格式与示例数据集格式，其完全相同，唯有我的数据集最小为0，我想知道是否是我的数据集过少的原因以及我该怎么解决这个问题？",
        "state": "closed",
        "user": "yutong12",
        "closed_by": "yutong12",
        "created_at": "2023-01-31T01:15:53+00:00",
        "updated_at": "2023-02-01T09:34:33+00:00",
        "closed_at": "2023-02-01T09:34:33+00:00",
        "comments_count": [
            "yutong12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 366,
        "title": "Paddlets使用时，数据集日期是否必须是连续的日期，中间能否出现日期的中断",
        "body": "\r\n![image](https://user-images.githubusercontent.com/87561504/217259824-334960e7-d66e-466d-b27a-26b4a3f5bd22.png)\r\n\r\n![image](https://user-images.githubusercontent.com/87561504/217259946-a6809d5a-d156-44e2-8d1d-0a93c018286d.png)\r\n![image](https://user-images.githubusercontent.com/87561504/217260088-2ea421a2-e22b-466a-8d21-62090905813a.png)\r\n![image](https://user-images.githubusercontent.com/87561504/217261342-e225588b-2cb6-4dc4-bb9f-946d968371ea.png)\r\n![image](https://user-images.githubusercontent.com/87561504/217261361-3f13fdd9-0f07-4c05-9d4f-8d9cff8c9c64.png)\r\n![image](https://user-images.githubusercontent.com/87561504/217261375-f50d6c76-cf23-4674-9b8c-bfe4d4d9ae51.png)\r\n在使用中我使用我自己的数据集，因为数据采样的问题，数据集中2018年和2020年某个时间段的数据无法使用（如第一张图所示，为我读取数据集的代码），导致数据集里的日期并不是完整的，除去无法利用的数据，共有34134条数据。当我完成数据可视化后，我想剔除的日期也被生成，但数据为空值，这些数据不能被利用于模型训练，并且划分好数据及后，数据集可视化也会显示出缺失数据的那段时间（如第二至四图，为数据可视化，其中原本不想被采用的日期也出现了，而不是直接从2017结束跳到2019）。最后使用模型训练时直接报错，错误是Input contains NaN（如图五图六）.我怀疑是缺失数据的那些日期也被划分进数据集中，导致这些日期中的各特征值为空值。如何避免这些问题，使得那些缺失数据的日期不被利用，还有划分数据集时这些缺失数据日期也不会被考虑。还是使用paddlets库时，必须是日期连续的数据集，不能出现日期的中断。",
        "state": "closed",
        "user": "fadedol",
        "closed_by": "Sunting78",
        "created_at": "2023-02-07T13:50:04+00:00",
        "updated_at": "2024-02-28T09:01:52+00:00",
        "closed_at": "2024-02-28T09:01:51+00:00",
        "comments_count": [
            "weibo021"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 367,
        "title": "__init__() got an unexpected keyword argument 'pred_adjust'",
        "body": "from paddlets.models.anomaly import AutoEncoder\r\n\r\nmodel = AutoEncoder(in_chunk_len=2, max_epochs=4,pred_adjust=True)\r\nmodel.fit(No6_train_scaled)\r\n\r\n\r\n在调用异常检测模块，想使用pred_adjust参数进行模型优化时，报错",
        "state": "closed",
        "user": "aizaizai1989",
        "closed_by": "Sunting78",
        "created_at": "2023-02-10T06:48:04+00:00",
        "updated_at": "2024-02-28T09:02:02+00:00",
        "closed_at": "2024-02-28T09:02:02+00:00",
        "comments_count": [
            "wangdong2222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 368,
        "title": "使用load上来的informer模型预测数据，每次结果均不同",
        "body": "##### 训练代码包括存储和预测\r\n```python\r\nfrom paddlets.models.forecasting.dl.informer import InformerModel as Informer\r\nfrom paddlets import TSDataset\r\nfrom paddlets.transform.sklearn_transforms import StandardScaler\r\n\r\nimport pandas as pd\r\nfrom typing import List\r\n\r\ndef data_process(df:pd.DataFrame,scaler,time_col_name:str,target_col_list:List,observed_col_list:List,freq:str):\r\n    data = TSDataset.load_from_dataframe(\r\n        df,\r\n        time_col=time_col_name,\r\n        target_cols=target_col_list,\r\n        observed_cov_cols=observed_col_list,\r\n        freq=freq)\r\n\r\n    train_data, test_data = data.split(0.8)\r\n    scaler.fit(train_data)\r\n    scaler_train_data = scaler.transform(train_data)\r\n    scaler_test_data = scaler.transform(test_data)\r\n    return scaler_train_data, scaler_test_data, scaler\r\n\r\nif __name__ == \"__main__\":\r\n    model = Informer(in_chunk_len=28,\r\n                      out_chunk_len= 28,\r\n                      eval_metrics=[\"mse\",\"mae\"],\r\n                      max_epochs=3)\r\n    df = pd.read_csv(\"/Informer/train/traindata.csv\")\r\n    scaler = StandardScaler()\r\n    train_data, test_data ,scaler= data_process(df,scaler,\"date\",'y',None,\"1d\")\r\n    model.fit(train_data,test_data)\r\n    res = model.predict(test_data)\r\n    inverse_transform_res = scaler.inverse_transform(res)\r\n    model.save(\"informer.savedmodel\")\r\n    print(inverse_transform_res)\r\n```\r\n##### 预测结果为\r\n```bash\r\n                      y\r\n2023-02-07  1425.993652\r\n2023-02-08  1424.377930\r\n2023-02-09  1421.871216\r\n2023-02-10  1418.660522\r\n2023-02-11  1418.290039\r\n2023-02-12  1422.693726\r\n2023-02-13  1424.804688\r\n2023-02-14  1423.174194\r\n2023-02-15  1422.863525\r\n2023-02-16  1417.690918\r\n2023-02-17  1416.067017\r\n2023-02-18  1422.147583\r\n2023-02-19  1424.315552\r\n2023-02-20  1424.332520\r\n2023-02-21  1419.405273\r\n2023-02-22  1419.088623\r\n2023-02-23  1413.171265\r\n2023-02-24  1409.463013\r\n2023-02-25  1409.834229\r\n2023-02-26  1414.650269\r\n2023-02-27  1409.096558\r\n2023-02-28  1416.881958\r\n2023-03-01  1416.226440\r\n2023-03-02  1419.820190\r\n2023-03-03  1417.339355\r\n2023-03-04  1410.086182\r\n2023-03-05  1419.711792\r\n2023-03-06  1415.859253\r\n```\r\n##### 加载模型及预测代码为\r\n```python\r\nfrom paddlets.models.model_loader import load\r\nimport pandas as pd\r\nfrom typing import List\r\nfrom paddlets import TSDataset\r\nfrom paddlets.transform.sklearn_transforms import StandardScaler\r\n\r\ndef data_process(df:pd.DataFrame,scaler,time_col_name:str,target_col_list:List,observed_col_list:List,freq:str):\r\n    data = TSDataset.load_from_dataframe(\r\n        df,\r\n        time_col=time_col_name,\r\n        target_cols=target_col_list,\r\n        observed_cov_cols=observed_col_list,\r\n        freq=freq)\r\n\r\n    train_data, test_data = data.split(0.8)\r\n    scaler.fit(train_data)\r\n    scaler_train_data = scaler.transform(train_data)\r\n    scaler_test_data = scaler.transform(test_data)\r\n    return scaler_train_data, scaler_test_data, scaler\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    df = pd.read_csv(\"/Informer/train/traindata.csv\")\r\n\r\n    scaler = StandardScaler()\r\n    \r\n    train_data, test_data ,scaler= data_process(df,scaler,\"date\",'y',None,\"1d\")\r\n    trained_model = load(\"./informer.savedmodel\")\r\n    load_model_predres = trained_model.predict(test_data)\r\n    print(test_data)\r\n    inverse_transform_res = scaler.inverse_transform(load_model_predres)\r\n    print(inverse_transform_res)\r\n```\r\n##### 预测结果\r\n```bash\r\n# 测试数据\r\n                   y\r\ndate                \r\n2022-09-30  1.259896\r\n2022-10-01  1.547872\r\n2022-10-02  1.455891\r\n2022-10-03  1.478457\r\n2022-10-04  1.543245\r\n...              ...\r\n2023-02-02  2.189494\r\n2023-02-03  2.167281\r\n2023-02-04  2.259263\r\n2023-02-05  1.973050\r\n2023-02-06  1.993500\r\n\r\n[130 rows x 1 columns]\r\n# 预测结果\r\n                      y\r\n2023-02-07  1421.905273\r\n2023-02-08  1421.521362\r\n2023-02-09  1423.071899\r\n2023-02-10  1422.876709\r\n2023-02-11  1415.927734\r\n2023-02-12  1421.687500\r\n2023-02-13  1419.604492\r\n2023-02-14  1417.005981\r\n2023-02-15  1419.268433\r\n2023-02-16  1427.177124\r\n2023-02-17  1423.654419\r\n2023-02-18  1419.297363\r\n2023-02-19  1421.166626\r\n2023-02-20  1421.554077\r\n2023-02-21  1416.492432\r\n2023-02-22  1417.657349\r\n2023-02-23  1414.936523\r\n2023-02-24  1415.555908\r\n2023-02-25  1418.315308\r\n2023-02-26  1413.397705\r\n2023-02-27  1411.110596\r\n2023-02-28  1411.677124\r\n2023-03-01  1417.716919\r\n2023-03-02  1414.239746\r\n2023-03-03  1417.350220\r\n2023-03-04  1419.005615\r\n2023-03-05  1416.818115\r\n2023-03-06  1419.117310\r\n```",
        "state": "closed",
        "user": "H4Njx",
        "closed_by": "Sunting78",
        "created_at": "2023-02-13T07:17:13+00:00",
        "updated_at": "2024-02-28T09:02:11+00:00",
        "closed_at": "2024-02-28T09:02:11+00:00",
        "comments_count": [
            "zy07604"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 370,
        "title": "时间序列间隔小于1S如何生成",
        "body": "在振动信号中，振动信号的采样频率非常高，1秒中有4096个点，这时如何生成序列time_col\r\n\r\n#!coding=utf8\r\n\r\n#导入其他库\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom scipy import loadmat\r\nfrom matplotlib import pyplot as plt\r\nfrom paddlets import TSDataset\r\n\r\n#加载并解析mat文件\r\n# loadmat函数能够载入mat数据，该数据是字典格式，以105为例，包括：['X105_DE_time','X105_FE_time','X105_BA_time','X102RPM']，分别为驱动端、风扇等数据\r\nmat_data = loadmat(\"cwru_dataset/105.mat\")['X105_DE_time'].squeeze()\r\n# 生成时间序列，假设频率为4096Hz\r\nshijian = np.linspace(0, (mat_data.size-1)/4096, mat_data.size)\r\n# 转化为DataFrame格式\r\ndf = pd.DataFrame(\r\n    {\r\n        'time_col':shijian,\r\n        'value': mat_data\r\n    }\r\n)\r\n #可以顺利实现\r\n# 保存为csv格式文件\r\n\r\ntarget_dataset = TSDataset.load_from_dataframe(\r\n    df,  #Also can be path to the CSV file\r\n    target_cols='value'\r\n,time_col=\"time_col\"\r\n)\r\n #这里报错，time_col处错误，删除该部分即正常运行。但带来的结果是索引是1,2,3，……\r\n因此，对于采样频率非常高的情况下，如何生成time_col\r\n",
        "state": "closed",
        "user": "qiyuezhiguang",
        "closed_by": "Sunting78",
        "created_at": "2023-02-16T12:34:00+00:00",
        "updated_at": "2024-02-28T09:03:22+00:00",
        "closed_at": "2024-02-28T09:03:22+00:00",
        "comments_count": [
            "wangdong2222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 371,
        "title": "known_cov使用方法的问题",
        "body": "仔细阅读了源码，产生了关于known_cov列使用方法的疑惑。文档中指出known_cov是指可在预测未来时间已知的变量，例如天气预报。\r\n\r\n为什么在数据采样时用，known_cov列的长度取left和right两段长度（源码见paddlets.models.data_adapter.py 1286行至1310行），而在实际使用中其实只用到了和in_chunk_len一样长的数据（见paddlets.models.forecasting.dl.transformer.py 163行至182行）。\r\n\r\npaddlets.models.data_adapter.py 1286行至1310行源码如下：\r\ndef _build_known_cov_for_single_sample(\r\n        self,\r\n        curr_sample_tail: int,\r\n        timeindex_offset: int,\r\n        known_cov_ndarray: np.ndarray\r\n    ) -> np.ndarray:\r\n        # known_cov can be combined with parts: left + right, while the skip_chunk will be SKIPPED.\r\n        right_end = timeindex_offset + curr_sample_tail + 1\r\n        right_start = (right_end - 1) - self._out_chunk_len + 1\r\n\r\n        left_end = (right_end - 1) - self._out_chunk_len - self._skip_chunk_len + 1\r\n        left_start = (left_end - 1) - self._in_chunk_len + 1\r\n        return np.vstack(tup=(known_cov_ndarray[left_start:left_end], known_cov_ndarray[right_start:right_end]))\r\n\r\npaddlets.models.forecasting.dl.transformer.py 163行至182行源码如下：\r\ndef _create_transformer_inputs(\r\n        self, \r\n        X: Dict[str, paddle.Tensor]\r\n    ) -> Tuple[paddle.Tensor, paddle.Tensor]:\r\n        covs = [\r\n            X[cov][:, :self._in_chunk_len, :] for cov in COVS if cov in X\r\n        ]\r\n        feats = [X[PAST_TARGET]] + covs\r\n        src = paddle.concat(feats, axis=-1)\r\n        tgt = src[:, -1:, :]\r\n        return src, tgt\r\n\r\n另外我看了好几个官方实现的算法示例，也都没有用到known_cov采样时的右段数据，不知道这个known_cov的意义在哪？",
        "state": "closed",
        "user": "Anyon123",
        "closed_by": "Sunting78",
        "created_at": "2023-02-19T06:26:33+00:00",
        "updated_at": "2024-02-28T09:03:13+00:00",
        "closed_at": "2024-02-28T09:03:13+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 369,
        "title": "Does in TSdataset we have option to set freq based on sum or mean ?",
        "body": "I am using tsdataset.load_from_dataset function and providing pandas dataframe as input and when I applied freq=“MS” , I got new dataframe , but could not able to understand  on which basis the values are normalised ? Can you please help me with that ? Can we apply pandas like resample function inside tsdataset ?\r\n\r\nThanks  ",
        "state": "closed",
        "user": "rvipandey",
        "closed_by": "Sunting78",
        "created_at": "2023-02-16T11:04:03+00:00",
        "updated_at": "2024-03-01T06:08:03+00:00",
        "closed_at": "2024-03-01T06:08:03+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 378
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 372,
        "title": "Pipline是否支持时序分类？能否将时序分类等模块一并涵盖在pipline中？",
        "body": "如题，Pipline是否支持时序分类？能否将时序分类等模块一并涵盖在pipline中？谢谢\r\n\r\n以下根据示例改的代码运行报错：`  File \"C:\\miniconda3\\lib\\site-packages\\paddlets\\pipeline\\pipeline.py\", line 88, in fit\r\n    if valid_tsdataset:\r\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\nimport paddlets\r\nfrom paddlets import Pipeline\r\nfrom paddlets import TSDataset\r\nfrom paddlets.transform import MinMaxScaler\r\nfrom paddlets.transform import TimeFeatureGenerator#KSigma, \r\nfrom paddlets.models.forecasting import MLPRegressor\r\n# from paddlets.models.classify.dl.cnn import CNNClassifier\r\nfrom paddlets.models.classify.dl.inception_time import InceptionTimeClassifier\r\nfrom paddlets.datasets.repository import get_dataset\r\nfrom sklearn.metrics import accuracy_score, f1_score\r\n\r\nimport warnings \r\nwarnings.filterwarnings('ignore')\r\n\r\n###Data###\r\nts_x_train, y_train = get_dataset(\"BasicMotions_Train\")\r\nts_x_test, y_test = get_dataset(\"BasicMotions_Test\")\r\nprint(f'>>>ts_x_train:\\n{ts_x_train}')\r\nprint(f'>>>y_train:\\n{y_train}')\r\n\r\n###Train###\r\nmodel_params = {'max_epochs':200, 'batch_size':32, 'patience':50}\r\n# kernel_size=40, block_out_size=128, block_depth=6, use_bottleneck=True, use_residual=True, \r\n# patience=10, activation='ReLU', batch_size=32, max_epochs=100\r\npipeline = Pipeline([\r\n    (MinMaxScaler, {}),\r\n    (TimeFeatureGenerator, {}), \r\n    (InceptionTimeClassifier, model_params)\r\n])\r\npipeline.fit(ts_x_train, y_train)\r\n#(KSigma, {\"cols\":[\"observed_a\", \"observed_b\", \"known_c\", \"known_d\"], \"k\": 1}), \r\n\r\n###Save&Load###\r\npipeline.save(path=\"./\")\r\nprint(f'>>>pipeline saved.')\r\n#pipeline.load(path=\"./\")\r\n\r\n###Test Metric###\r\ntest_preds = pipeline.predict(ts_x_test)\r\nprint(f'>>>test_preds:\\n{test_preds}')\r\n\r\nscore = accuracy_score(y_test, test_preds)\r\nprint(f'>>>accuracy_score:{score}')\r\nf1 = f1_score(y_test, test_preds, average=\"macro\")\r\nprint(f'>>>f1_score:{f1}')\r\n\r\n###Predict###\r\ntest_recursive_preds = pipeline.recursive_predict(ts_x_test, predict_length=4)\r\nprint(f'>>>test_recursive_preds:\\n{test_recursive_preds}')\r\n```",
        "state": "closed",
        "user": "forhonourlx",
        "closed_by": "Sunting78",
        "created_at": "2023-02-19T16:23:34+00:00",
        "updated_at": "2024-02-28T09:03:06+00:00",
        "closed_at": "2024-02-28T09:03:06+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 374,
        "title": "加载第三方模型出错",
        "body": "我尝试使用make_ml_model来加载XGBRegressor，但是出现了如下错误：\r\n```\r\n[2023-02-25 15:35:32,529] [paddlets] [ERROR] ValueError: Unable to make ml model for <class 'xgboost.sklearn.XGBRFRegressor'>.\r\n```\r\n\r\n我的代码：\r\n```\r\nmodel = make_ml_model(\r\n    in_chunk_len=6, \r\n    out_chunk_len=4, \r\n    model_class=xgb.XGBRFRegressor\r\n)\r\n```\r\n\r\n\r\n我的相关包的版本：\r\n```\r\npaddlepaddle-gpu               2.4.0.post112\r\npaddlets                                1.1.0\r\nxgboost                                 1.3.3\r\n```\r\n\r\n详细报错：\r\n```\r\n[2023-02-25 15:35:32,529] [paddlets] [ERROR] ValueError: Unable to make ml model for <class 'xgboost.sklearn.XGBRFRegressor'>.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_10906/3092094233.py in <module>\r\n      2     in_chunk_len=6,\r\n      3     out_chunk_len=4,\r\n----> 4     model_class=xgb.XGBRFRegressor\r\n      5 )\r\n\r\n~/external-libraries/paddlets/models/ml_model_wrapper.py in make_ml_model(model_class, in_chunk_len, out_chunk_len, skip_chunk_len, sampling_stride, model_init_params, fit_params, predict_params, udf_ml_dataloader_to_fit_ndarray, udf_ml_dataloader_to_predict_ndarray)\r\n    941             udf_ml_dataloader_to_predict_ndarray=udf_ml_dataloader_to_predict_ndarray\r\n    942         )\r\n--> 943     raise_log(ValueError(f\"Unable to make ml model for {model_class}.\"))\r\n\r\n~/external-libraries/paddlets/logger/logger.py in raise_log(exception, logger)\r\n    110     logger.error(exception_type + \": \" + message)\r\n    111 \r\n--> 112     raise exception\r\n    113 \r\n    114 \r\n\r\nValueError: Unable to make ml model for <class 'xgboost.sklearn.XGBRFRegressor'>.\r\n```",
        "state": "closed",
        "user": "xiehuanyi",
        "closed_by": "Sunting78",
        "created_at": "2023-02-25T08:46:21+00:00",
        "updated_at": "2024-03-04T10:49:20+00:00",
        "closed_at": "2024-03-04T10:49:20+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 373,
        "title": "MacOS 13.2.1 报错numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject",
        "body": "系统环境 MacOS 13.2.1 \r\ncpu Apple M1\r\npaddlets 版本为 1.1.0\r\n报错信息为：\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/huchunliang/Documents/py/paddlets_test/main.py\", line 3, in <module>\r\n    import pandas as pd\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/__init__.py\", line 22, in <module>\r\n    from pandas.compat import (\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/compat/__init__.py\", line 15, in <module>\r\n    from pandas.compat.numpy import (\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/compat/numpy/__init__.py\", line 7, in <module>\r\n    from pandas.util.version import Version\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/util/__init__.py\", line 1, in <module>\r\n    from pandas.util._decorators import (  # noqa\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 14, in <module>\r\n    from pandas._libs.properties import cache_readonly  # noqa\r\n  File \"/Users/huchunliang/opt/anaconda3/envs/paddlets_test/lib/python3.8/site-packages/pandas/_libs/__init__.py\", line 13, in <module>\r\n    from pandas._libs.interval import Interval\r\n  File \"pandas/_libs/interval.pyx\", line 1, in init pandas._libs.interval\r\nValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n代码为：\r\n\r\n```\r\ndef get_train_dataset():\r\n    df = pd.read_csv('/Users/huchunliang/time_CZ_I_A.csv')\r\n    cols = df.columns.tolist()\r\n    cols.remove('SJ_RIQI')\r\n    print(cols)\r\n    ts = TSDataset.load_from_dataframe(\r\n        df,  # Also can be path to the CSV file\r\n        time_col='SJ_RIQI',\r\n        target_cols=cols,\r\n        freq=1\r\n    )\r\n    print(ts)\r\n    model = RNNBlockRegressor(in_chunk_len=6, out_chunk_len=4)\r\n\r\n# Press the green button in the gutter to run the script.\r\nif __name__ == '__main__':\r\n    # print_hi('PyCharm')\r\n    # get_train_dataset()\r\n    data = get_dataset('ETTh1') #公开数据集，电力行业，多变量时间序列\r\n    data, _ = data.split('2016-08-22 00:00:00')\r\n    train_data, test_data = data.split('2016-08-20 23:00:00')\r\n    print(data)\r\n```",
        "state": "closed",
        "user": "davichi11",
        "closed_by": "Sunting78",
        "created_at": "2023-02-22T05:43:49+00:00",
        "updated_at": "2024-03-04T08:24:21+00:00",
        "closed_at": "2024-03-04T08:24:21+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 375,
        "title": "paddle inference相关错误",
        "body": "# 1.input_data = build_ts_infer_input(dataset, \"./rnn_model_meta\")报错\r\n如果严格按照\r\nhttps://paddlets.readthedocs.io/zh_CN/latest/source/modules/models/paddle_inference.html\r\n如下；\r\n```python\r\n\r\nfrom paddlets.datasets.repository import get_dataset\r\nfrom paddlets.models.forecasting.dl.rnn import RNNBlockRegressor\r\n\r\n# prepare data\r\ndataset = get_dataset(\"WTH\")\r\n\r\nrnn = RNNBlockRegressor(\r\n    in_chunk_len=4,\r\n    out_chunk_len=2,\r\n    max_epochs=10\r\n)\r\n\r\n#fit\r\nrnn.fit(dataset)\r\n\r\n#predict\r\nrnn.predict(dataset)\r\n\r\nrnn.save(\"./rnn\", network_model=True, dygraph_to_static=True)\r\n\r\nimport paddle.inference as paddle_infer\r\nconfig = paddle_infer.Config(\"./rnn.pdmodel\", \"./rnn.pdiparams\")\r\npredictor = paddle_infer.create_predictor(config)\r\ninput_names = predictor.get_input_names()\r\nprint(f\"input_name: f{input_names}\")\r\n\r\nimport json\r\nwith open(\"./rnn_model_meta\") as f:\r\n    json_data = json.load(f)\r\n    print(json_data)\r\nfrom paddlets.utils.utils import build_ts_infer_input\r\n\r\ninput_data = build_ts_infer_input(dataset, \"./rnn_model_meta\")\r\n\r\nfor key, value in json_data['input_data'].items():\r\n    input_handle1 = predictor.get_input_handle(key)\r\n    #set batch_size=1\r\n    value[0] = 1\r\n    input_handle1.reshape(value)\r\n    input_handle1.copy_from_cpu(input_data[key])\r\n\r\npredictor.run()\r\noutput_names = predictor.get_output_names()\r\noutput_handle = predictor.get_output_handle(output_names[0])\r\noutput_data = output_handle.copy_to_cpu()\r\nprint(output_data)\r\n```\r\n的教程操作，结果输出正确。但如果去掉该教程中的模型训练阶段，直接载入离线静态模型，如下：\r\n```python\r\n\r\nfrom paddlets.datasets.repository import get_dataset\r\nfrom paddlets.models.forecasting.dl.rnn import RNNBlockRegressor\r\n\r\n# prepare data\r\ndataset = get_dataset(\"WTH\")\r\n\r\nimport paddle.inference as paddle_infer\r\nconfig = paddle_infer.Config(\"./rnn.pdmodel\", \"./rnn.pdiparams\")\r\npredictor = paddle_infer.create_predictor(config)\r\ninput_names = predictor.get_input_names()\r\nprint(f\"input_name: f{input_names}\")\r\n\r\n# input_name: f['observed_cov_numeric', 'past_target']\r\n\r\nimport json\r\nwith open(\"./rnn_model_meta\") as f:\r\n    json_data = json.load(f)\r\n    print(json_data)\r\n\r\nfrom paddlets.utils.utils import build_ts_infer_input\r\n\r\ninput_data = build_ts_infer_input(dataset, \"./rnn_model_meta\")\r\n\r\nfor key, value in json_data['input_data'].items():\r\n    input_handle1 = predictor.get_input_handle(key)\r\n    #set batch_size=1\r\n    value[0] = 1\r\n    input_handle1.reshape(value)\r\n    input_handle1.copy_from_cpu(input_data[key])\r\n\r\npredictor.run()\r\noutput_names = predictor.get_output_names()\r\noutput_handle = predictor.get_output_handle(output_names[0])\r\noutput_data = output_handle.copy_to_cpu()\r\nprint(output_data)\r\n\r\n```\r\n则build_ts_infer_input会报错，应该是代码中某个bug。\r\n\r\n本人将该代码中的input_data的生成直接使用numpy函数，则可以正常运行，即将\r\n`input_data = build_ts_infer_input(dataset, \"./rnn_model_meta\")\r\n`\r\n使用：\r\n```python\r\ndata=np.random.random((168)).astype(np.float32)\r\ninput_data = data[0: self.json_data[\"size\"][\"in_chunk_len\"]].reshape((1, self.json_data[\"size\"][\"in_chunk_len\"], 1))\r\n```\r\n并将\r\n`input_handle1.copy_from_cpu(input_data[key])`修改为：\r\n`input_handle1.copy_from_cpu(input_data)`\r\n则代码正常运行。所以可知bug位于build_ts_infer_input。\r\n\r\n# 2. deepar静态模型部署中的数据读取bug\r\n将上述代码中的rnn模型更改为deepar，则出现静态模型能够保存成功，但build_ts_infer_input数据读取依然报错。\r\n本人还尝试了其他几个模型，按照`1.`的方面都是正确运行的。比如：TCN，informer，NHITS等等\r\n\r\n# 3. TS2VEC无法保存为静态模型，通过查看源代码发现源码不支持，望早日支持paddle inference。\r\nts2vec.save(\"./ts2vec_dong\") #动态模型保存成功\r\nts2vec.save(\"./ts2vec\", network_model=True, dygraph_to_static=True) #静态模型保存失败\r\n\r\n感谢您的答复。\r\n",
        "state": "closed",
        "user": "qiyuezhiguang",
        "closed_by": "Sunting78",
        "created_at": "2023-02-25T10:34:30+00:00",
        "updated_at": "2024-02-28T09:02:47+00:00",
        "closed_at": "2024-02-28T09:02:47+00:00",
        "comments_count": [
            "a10210532"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 376,
        "title": "预测阶段调用build_ts_infer_input发生报错",
        "body": "用自己的数据创建了一个TSDataset，读取训练好的模型后，使用build_ts_infer_input传入验证集的时候出现报错：ValueError: The tsdataset is not match with the meta_file, past_target is required! The tsdataset only have dict_keys(['observed_cov_categorical'])。但是我在构建TSDataset的时候是指定了observed_cov_cols和target_cols的，且训练集和验证集都是从构建的同一个TSDataset里分割的。请问，这个报错应该如何处理呀？",
        "state": "closed",
        "user": "ClassmateXiaoyu",
        "closed_by": "ClassmateXiaoyu",
        "created_at": "2023-03-02T03:54:50+00:00",
        "updated_at": "2023-03-02T06:49:36+00:00",
        "closed_at": "2023-03-02T06:49:36+00:00",
        "comments_count": [
            "a10210532",
            "ClassmateXiaoyu",
            "a10210532",
            "ClassmateXiaoyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 377,
        "title": "[ERROR] 使用 recursive_predict报错",
        "body": "报错如下：\r\n```\r\nValueError: (InvalidArgument) The cudnn rnn and setting weight size should be same.\r\n  [Hint: Expected weights_size_ == sizeof(T) * weight_numel_, but received weights_size_:1148928 != sizeof(T) * weight_numel_:993792.] (at .[.\\paddle/phi/kernels/gpu/rnn_functor.h:186](https://file+.vscode-resource.vscode-cdn.net/d%3A/user_datas/qianjipeng/code/wind_speed/paddle/phi/kernels/gpu/rnn_functor.h:186))\r\n  [operator < rnn > error]\r\n```",
        "state": "closed",
        "user": "mokeeqian",
        "closed_by": "Sunting78",
        "created_at": "2023-03-15T08:27:10+00:00",
        "updated_at": "2024-03-28T03:06:34+00:00",
        "closed_at": "2024-03-28T03:06:34+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 379,
        "title": "deepar训练完模型后, 调用backtest得到quantiles, quantiles.plot时报错: TypeError: invalid type promotion",
        "body": "from paddlets.utils import backtest\r\nfrom paddlets.metrics import QuantileLoss\r\nq_loss, quantiles = backtest(data=ts_val_scaled[1],\r\n     model=model,\r\n     start=\"2022-06-09\",\r\n     metric=QuantileLoss([0.1, 0.5, 0.9]),\r\n     predict_window=1,\r\n     stride=1,\r\n     return_predicts=True\r\n)\r\n\r\n%matplotlib notebook\r\nquantiles.plot(\r\n     add_data= validation_dataset[1],\r\n     low_quantile=0.05,\r\n     high_quantile=0.95\r\n)\r\n\r\n报错如下:\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-25-6427fc862f86> in <module>\r\n     11 \r\n     12 get_ipython().run_line_magic('matplotlib', 'notebook')\r\n---> 13 quantiles.plot(\r\n     14      add_data= validation_dataset[1],\r\n     15      low_quantile=0.05,\r\n\r\n~/.local/lib/python3.8/site-packages/paddlets/datasets/tsdataset.py in plot(self, columns, add_data, labels, low_quantile, high_quantile, central_quantile, **kwargs)\r\n   1734                 df = self.__getitem__(column + central_quantile_str)\r\n   1735                 plot = df.plot(**kwargs, label = column)\r\n-> 1736                 self._fill_between_quantiles(column, low_quantile, high_quantile, **kwargs)\r\n   1737             # normal plot\r\n   1738             else:\r\n\r\n~/.local/lib/python3.8/site-packages/paddlets/datasets/tsdataset.py in _fill_between_quantiles(self, column, low_quantile, high_quantile, **kwargs)\r\n   1827         high_quantile_str = \"@quantile\" + str(float(high_quantile * 100))\r\n   1828 \r\n-> 1829         plt.fill_between(self.target.data.index,\r\n   1830                          self[column + low_quantile_str].values,\r\n   1831                          self[column + high_quantile_str].values,\r\n\r\n~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py in fill_between(x, y1, y2, where, interpolate, step, data, **kwargs)\r\n   2532         x, y1, y2=0, where=None, interpolate=False, step=None, *,\r\n   2533         data=None, **kwargs):\r\n-> 2534     return gca().fill_between(\r\n   2535         x, y1, y2=y2, where=where, interpolate=interpolate, step=step,\r\n   2536         **({\"data\": data} if data is not None else {}), **kwargs)\r\n\r\n~/.local/lib/python3.8/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs)\r\n   1431     def inner(ax, *args, data=None, **kwargs):\r\n   1432         if data is None:\r\n-> 1433             return func(ax, *map(sanitize_sequence, args), **kwargs)\r\n   1434 \r\n   1435         bound = new_sig.bind(ax, *args, **kwargs)\r\n\r\n~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py in fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)\r\n   5371     def fill_between(self, x, y1, y2=0, where=None, interpolate=False,\r\n   5372                      step=None, **kwargs):\r\n-> 5373         return self._fill_between_x_or_y(\r\n   5374             \"x\", x, y1, y2,\r\n   5375             where=where, interpolate=interpolate, step=step, **kwargs)\r\n\r\n~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py in _fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs)\r\n   5360 \r\n   5361         # now update the datalim and autoscale\r\n-> 5362         pts = np.row_stack([np.column_stack([ind[where], dep1[where]]),\r\n   5363                             np.column_stack([ind[where], dep2[where]])])\r\n   5364         if ind_dir == \"y\":\r\n\r\n<__array_function__ internals> in column_stack(*args, **kwargs)\r\n\r\n~/.local/lib/python3.8/site-packages/numpy/lib/shape_base.py in column_stack(tup)\r\n    654             arr = array(arr, copy=False, subok=True, ndmin=2).T\r\n    655         arrays.append(arr)\r\n--> 656     return _nx.concatenate(arrays, 1)\r\n    657 \r\n    658 \r\n\r\n<__array_function__ internals> in concatenate(*args, **kwargs)\r\n\r\nTypeError: invalid type promotion\r\n\r\n_____________________________________________________________________________________________________________\r\n补充信息\r\n\r\n模型训练如下:\r\nfrom paddlets.models.forecasting import DeepARModel\r\nIN_CHUNK_LEN=7\r\nOUT_CHUNK_LEN=1\r\nHIDDEN_SIZE=128\r\nRECURRENT_LAYERS=1\r\nMAX_EPOCHS=100\r\nPATIENCE=10\r\noptimizer_params={'learning_rate': 1,'beta1':0.9,'beta2':0.99}\r\nmodel = DeepARModel(\r\n    in_chunk_len=IN_CHUNK_LEN,\r\n    out_chunk_len=OUT_CHUNK_LEN,\r\n    hidden_size=HIDDEN_SIZE,\r\n    num_layers_recurrent=RECURRENT_LAYERS,\r\n    max_epochs=MAX_EPOCHS,\r\n    patience=PATIENCE)\r\nmodel.fit(train_tsdataset=ts_train_scaled,valid_tsdataset=ts_val_scaled)\r\n\r\n用来做测试的数据如下:\r\n![image](https://user-images.githubusercontent.com/19497769/225991880-c333bede-005f-4e56-a50b-4a5de0d4352f.png)\r\n",
        "state": "closed",
        "user": "kaichenzhu",
        "closed_by": "Sunting78",
        "created_at": "2023-03-17T18:49:39+00:00",
        "updated_at": "2024-02-28T09:02:58+00:00",
        "closed_at": "2024-02-28T09:02:58+00:00",
        "comments_count": [
            "kaichenzhu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 380,
        "title": "请问PaddleTS如何设定实现让输出预测序列中每个点的间隔时间步数?",
        "body": "请问PaddleTS如何设定实现让输出预测序列中每个点的间隔时间步数?\r\n比如,使用7*24小时的连续数据序列为输入,输出预测序列长度接下来24个小时内的为4时间点的预测值,也就是说该序列表示接下每隔6小时一个点共4个点(时间范围24小时)的输出结果.\r\ninput:[t1,t2,t3,...,t168],outpu:[t174,t180,t186,t192]",
        "state": "closed",
        "user": "chunyisong",
        "closed_by": "Sunting78",
        "created_at": "2023-03-19T02:46:49+00:00",
        "updated_at": "2024-02-28T13:07:39+00:00",
        "closed_at": "2024-02-28T13:07:39+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 381,
        "title": "安装paddlets后无法画图",
        "body": "运行了如下的官方实例代码，没有任何反应，只有一堆deprecate warning。\r\npython版本3.7，paddlets版本1.1.0，paddle版本2.4.2\r\n`import pandas as pd\r\nimport numpy as np\r\nfrom paddlets import TSDataset\r\n\r\nx = np.linspace(-np.pi, np.pi, 200)\r\nsinx = np.sin(x) * 4 + np.random.randn(200)\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        'time_col': pd.date_range('2022-01-01', periods=200, freq='1h'),\r\n        'value': sinx\r\n    }\r\n)\r\ncustom_dataset = TSDataset.load_from_dataframe(\r\n    df,  #Also can be path to the CSV file\r\n    time_col='time_col',\r\n    target_cols='value',\r\n    freq='1h'\r\n)\r\ncustom_dataset.plot()`",
        "state": "closed",
        "user": "losnild",
        "closed_by": "losnild",
        "created_at": "2023-03-22T09:46:39+00:00",
        "updated_at": "2023-03-23T06:17:47+00:00",
        "closed_at": "2023-03-23T06:17:47+00:00",
        "comments_count": [
            "losnild"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 382,
        "title": "请问PaddleTS会支持使用TS2Vec等表征模型进行异常检测吗",
        "body": null,
        "state": "closed",
        "user": "losnild",
        "closed_by": "Sunting78",
        "created_at": "2023-03-23T06:36:30+00:00",
        "updated_at": "2024-03-04T10:50:52+00:00",
        "closed_at": "2024-03-04T10:50:52+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 383,
        "title": "我的数据集是每天7点到下午17点的统计数据,chunk可以怎么设置？",
        "body": "     in_chunk_len=7 * 24,\r\n     out_chunk_len=24,",
        "state": "closed",
        "user": "herbiel",
        "closed_by": "Sunting78",
        "created_at": "2023-03-28T03:02:22+00:00",
        "updated_at": "2024-03-04T10:40:13+00:00",
        "closed_at": "2024-03-04T10:40:12+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 384,
        "title": "时序数据的预测需不需要，在测试集中需不需要label或target。",
        "body": "使用Informer模型，在训练集中是存在协变量和label，要求在测试集中进行预测，不过测试集中无label，只有协变量，请问可以进行时序预测吗",
        "state": "closed",
        "user": "marcocst",
        "closed_by": "Sunting78",
        "created_at": "2023-04-01T08:56:34+00:00",
        "updated_at": "2024-02-28T09:15:00+00:00",
        "closed_at": "2024-02-28T09:15:00+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 386,
        "title": "啥时候加入“五边形战士”TimesNet？还有FEDformer和Autoformer等",
        "body": "啥时候扩充新模型呢",
        "state": "closed",
        "user": "lmqhello",
        "closed_by": "Sunting78",
        "created_at": "2023-04-03T13:26:50+00:00",
        "updated_at": "2024-03-04T10:57:32+00:00",
        "closed_at": "2024-03-04T10:57:32+00:00",
        "comments_count": [
            "Sunting78",
            "lmqhello",
            "wghxiuyuan",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 385,
        "title": "[BUG] Informer模型fit时程序崩溃",
        "body": null,
        "state": "closed",
        "user": "mokeeqian",
        "closed_by": "Sunting78",
        "created_at": "2023-04-02T12:29:45+00:00",
        "updated_at": "2024-03-04T10:46:23+00:00",
        "closed_at": "2024-03-04T10:46:23+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 387,
        "title": "SCINetModel和NLinearModel模型导入提示没有这个模块？",
        "body": "from paddlets.models.forecasting.dl import SCINetModel\r\nfrom paddlets.models.forecasting.dl import NLinearModel\r\n\r\n这两个执行的时候提示\r\nImportError: cannot import name 'SCINetModel' from 'paddlets.models.forecasting.dl' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/forecasting/dl/__init__.py)\r\n\r\n进去看的话明明有这个文件啊\r\n\r\npaddlepaddle版本2.4  paddlets版本1.1.0\r\n请问是什么原因呢",
        "state": "closed",
        "user": "lmqhello",
        "closed_by": "Sunting78",
        "created_at": "2023-04-06T12:59:06+00:00",
        "updated_at": "2024-03-04T10:50:10+00:00",
        "closed_at": "2024-03-04T10:50:10+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 388,
        "title": "官方文档中Paddle Inference Support样例报错RuntimeError",
        "body": "RuntimeError: (Unavailable) LoadCombine operator fails to open file ./rnn.pdiparams, please check whether the model file is complete or damaged.\r\n  [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] (at ..\\paddle/fluid/operators/load_combine_op.h:55)\r\n  [operator < load_combine > error]\r\n\r\n使用版本：\r\npaddle: 2.4.1\r\npaddlets: 1.1.0",
        "state": "closed",
        "user": "Husky1999",
        "closed_by": "Husky1999",
        "created_at": "2023-04-07T07:58:48+00:00",
        "updated_at": "2023-04-10T05:01:52+00:00",
        "closed_at": "2023-04-10T05:01:52+00:00",
        "comments_count": [
            "Husky1999"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 389,
        "title": "求助TS模型使用这里为什么会报错（仿造中国软件杯”大学生软件设计大赛——龙源风电赛道基线）",
        "body": "![image](https://user-images.githubusercontent.com/130541990/231380992-db796490-8bfe-46c4-a7fc-f2ec9888adcb.png)\r\n[000.csv](https://github.com/PaddlePaddle/PaddleTS/files/11208295/000.csv)\r\n第一图为报错内容，第二文件为我的实验文件。",
        "state": "closed",
        "user": "kuqiliya",
        "closed_by": "Sunting78",
        "created_at": "2023-04-12T07:17:43+00:00",
        "updated_at": "2023-08-08T03:26:11+00:00",
        "closed_at": "2023-08-08T03:26:11+00:00",
        "comments_count": [
            "Ni-Mr",
            "Ni-Mr",
            "kuqiliya",
            "kuqiliya",
            "Ni-Mr",
            "kuqiliya",
            "kuqiliya",
            "Ni-Mr",
            "kuqiliya"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 390,
        "title": "如何让模型具有持续学习能力",
        "body": "我使用PaddleTS训练好一个预测模型后，随着时间推移，后面会产生新的数据。所以，想请教下怎么在原来模型的基础上利用这些数据，并使得模型不断优化？",
        "state": "closed",
        "user": "GitHubTJW",
        "closed_by": "Sunting78",
        "created_at": "2023-04-17T13:05:06+00:00",
        "updated_at": "2024-02-28T09:55:35+00:00",
        "closed_at": "2024-02-28T09:55:35+00:00",
        "comments_count": [
            "allentern"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 396,
        "title": "[paddlets] [ERROR] ValueError: In anomaly detection scenario, the dtype of label must be integer, but recevid float64",
        "body": "![图片](https://github.com/PaddlePaddle/PaddleTS/assets/128353785/145148aa-ca12-4b2f-a783-c8e9317c58ff)\r\n",
        "state": "closed",
        "user": "ynzzxc",
        "closed_by": "ynzzxc",
        "created_at": "2023-05-10T06:30:13+00:00",
        "updated_at": "2023-05-10T07:24:11+00:00",
        "closed_at": "2023-05-10T07:23:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 391,
        "title": "PaddleTS案例模型",
        "body": "最近PaddleTS能否多出一些案例典型教程呢？\r\n最好能囊括较多常见的时序预测情况：\r\n比如：\r\n1. 在时序预测方面、表征学习方面、异常检测方面都能有几个典型案例，且案例的数据最好是能直接在PaddleTS的官方Github能下载到；\r\n2. 在负荷预测和设备故障检测方面同上；\r\n3. 案例最好能尽量多的囊括关键和基础的知识点，如果一个案例囊括不了想要表达的全部内容，那么可以在同一方面的多个案例之间有所互补表达；\r\n4. 最后，预祝PaddleTS越做越好。",
        "state": "closed",
        "user": "TheKingTao",
        "closed_by": "Sunting78",
        "created_at": "2023-04-19T15:54:40+00:00",
        "updated_at": "2024-03-01T06:15:10+00:00",
        "closed_at": "2024-03-01T06:15:10+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 392,
        "title": "TypeError: CCompiler_spawn() got an unexpected keyword argument 'env'",
        "body": "您好！\r\n\r\n我使用pip install paddlets安装库，出现如下报错，请问该如何解决呢？谢谢！\r\n\r\n```\r\nCollecting paddlets\r\n  Using cached paddlets-1.1.0-py3-none-any.whl (572 kB)\r\nCollecting numpy<=1.19.5,>=1.17.0 (from paddlets)\r\n  Using cached numpy-1.19.5.zip (7.3 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Preparing metadata (pyproject.toml) did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [282 lines of output]\r\n      setup.py:67: RuntimeWarning: NumPy 1.19.5 may not yet support Python 3.11.\r\n        warnings.warn(\r\n      Running from numpy source directory.\r\n      setup.py:480: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\r\n        run_build = parse_setuppy_commands()\r\n      Processing numpy/random\\_bounded_integers.pxd.in\r\n      Processing numpy/random\\bit_generator.pyx\r\n      Processing numpy/random\\mtrand.pyx\r\n      Processing numpy/random\\_bounded_integers.pyx.in\r\n      Processing numpy/random\\_common.pyx\r\n      Processing numpy/random\\_generator.pyx\r\n      Processing numpy/random\\_mt19937.pyx\r\n      Processing numpy/random\\_pcg64.pyx\r\n      Processing numpy/random\\_philox.pyx\r\n      Processing numpy/random\\_sfc64.pyx\r\n      Cythonizing sources\r\n      blas_opt_info:\r\n      blas_mkl_info:\r\n      No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\r\n      customize MSVCCompiler\r\n        libraries mkl_rt not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      blis_info:\r\n        libraries blis not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      openblas_info:\r\n        libraries openblas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n      get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\r\n      customize GnuFCompiler\r\n      Could not locate executable g77\r\n      Could not locate executable f77\r\n      customize IntelVisualFCompiler\r\n      Could not locate executable ifort\r\n      Could not locate executable ifl\r\n      customize AbsoftFCompiler\r\n      Could not locate executable f90\r\n      customize CompaqVisualFCompiler\r\n      Could not locate executable DF\r\n      customize IntelItaniumVisualFCompiler\r\n      Could not locate executable efl\r\n      customize Gnu95FCompiler\r\n      Could not locate executable gfortran\r\n      Could not locate executable f95\r\n      customize G95FCompiler\r\n      Could not locate executable g95\r\n      customize IntelEM64VisualFCompiler\r\n      customize IntelEM64TFCompiler\r\n      Could not locate executable efort\r\n      Could not locate executable efc\r\n      customize PGroupFlangCompiler\r\n      Could not locate executable flang\r\n      don't know how to compile Fortran code on platform 'nt'\r\n        NOT AVAILABLE\r\n\r\n      atlas_3_10_blas_threads_info:\r\n      Setting PTATLAS=ATLAS\r\n        libraries tatlas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      atlas_3_10_blas_info:\r\n        libraries satlas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      atlas_blas_threads_info:\r\n      Setting PTATLAS=ATLAS\r\n        libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      atlas_blas_info:\r\n        libraries f77blas,cblas,atlas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      accelerate_info:\r\n        NOT AVAILABLE\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\system_info.py:1914: UserWarning:\r\n          Optimized (vendor) Blas libraries are not found.\r\n          Falls back to netlib Blas library which has worse performance.\r\n          A better performance should be easily gained by switching\r\n          Blas library.\r\n        if self._calc_info(blas):\r\n      blas_info:\r\n        libraries blas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\system_info.py:1914: UserWarning:\r\n          Blas (http://www.netlib.org/blas/) libraries not found.\r\n          Directories to search for the libraries can be specified in the\r\n          numpy/distutils/site.cfg file (section [blas]) or by setting\r\n          the BLAS environment variable.\r\n        if self._calc_info(blas):\r\n      blas_src_info:\r\n        NOT AVAILABLE\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\system_info.py:1914: UserWarning:\r\n          Blas (http://www.netlib.org/blas/) sources not found.\r\n          Directories to search for the sources can be specified in the\r\n          numpy/distutils/site.cfg file (section [blas_src]) or by setting\r\n          the BLAS_SRC environment variable.\r\n        if self._calc_info(blas):\r\n        NOT AVAILABLE\r\n\r\n      non-existing path in 'numpy\\\\distutils': 'site.cfg'\r\n      lapack_opt_info:\r\n      lapack_mkl_info:\r\n        libraries mkl_rt not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      openblas_lapack_info:\r\n        libraries openblas not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      openblas_clapack_info:\r\n        libraries openblas,lapack not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      flame_info:\r\n        libraries flame not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      atlas_3_10_threads_info:\r\n      Setting PTATLAS=ATLAS\r\n        libraries lapack_atlas not found in C:\\Python311\\lib\r\n        libraries tatlas,tatlas not found in C:\\Python311\\lib\r\n        libraries lapack_atlas not found in C:\\\r\n        libraries tatlas,tatlas not found in C:\\\r\n        libraries lapack_atlas not found in C:\\Python311\\libs\r\n        libraries tatlas,tatlas not found in C:\\Python311\\libs\r\n      <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\r\n        NOT AVAILABLE\r\n\r\n      atlas_3_10_info:\r\n        libraries lapack_atlas not found in C:\\Python311\\lib\r\n        libraries satlas,satlas not found in C:\\Python311\\lib\r\n        libraries lapack_atlas not found in C:\\\r\n        libraries satlas,satlas not found in C:\\\r\n        libraries lapack_atlas not found in C:\\Python311\\libs\r\n        libraries satlas,satlas not found in C:\\Python311\\libs\r\n      <class 'numpy.distutils.system_info.atlas_3_10_info'>\r\n        NOT AVAILABLE\r\n\r\n      atlas_threads_info:\r\n      Setting PTATLAS=ATLAS\r\n        libraries lapack_atlas not found in C:\\Python311\\lib\r\n        libraries ptf77blas,ptcblas,atlas not found in C:\\Python311\\lib\r\n        libraries lapack_atlas not found in C:\\\r\n        libraries ptf77blas,ptcblas,atlas not found in C:\\\r\n        libraries lapack_atlas not found in C:\\Python311\\libs\r\n        libraries ptf77blas,ptcblas,atlas not found in C:\\Python311\\libs\r\n      <class 'numpy.distutils.system_info.atlas_threads_info'>\r\n        NOT AVAILABLE\r\n\r\n      atlas_info:\r\n        libraries lapack_atlas not found in C:\\Python311\\lib\r\n        libraries f77blas,cblas,atlas not found in C:\\Python311\\lib\r\n        libraries lapack_atlas not found in C:\\\r\n        libraries f77blas,cblas,atlas not found in C:\\\r\n        libraries lapack_atlas not found in C:\\Python311\\libs\r\n        libraries f77blas,cblas,atlas not found in C:\\Python311\\libs\r\n      <class 'numpy.distutils.system_info.atlas_info'>\r\n        NOT AVAILABLE\r\n\r\n      lapack_info:\r\n        libraries lapack not found in ['C:\\\\Python311\\\\lib', 'C:\\\\', 'C:\\\\Python311\\\\libs']\r\n        NOT AVAILABLE\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\system_info.py:1748: UserWarning:\r\n          Lapack (http://www.netlib.org/lapack/) libraries not found.\r\n          Directories to search for the libraries can be specified in the\r\n          numpy/distutils/site.cfg file (section [lapack]) or by setting\r\n          the LAPACK environment variable.\r\n        return getattr(self, '_calc_info_{}'.format(name))()\r\n      lapack_src_info:\r\n        NOT AVAILABLE\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\system_info.py:1748: UserWarning:\r\n          Lapack (http://www.netlib.org/lapack/) sources not found.\r\n          Directories to search for the sources can be specified in the\r\n          numpy/distutils/site.cfg file (section [lapack_src]) or by setting\r\n          the LAPACK_SRC environment variable.\r\n        return getattr(self, '_calc_info_{}'.format(name))()\r\n        NOT AVAILABLE\r\n\r\n      numpy_linalg_lapack_lite:\r\n        FOUND:\r\n          language = c\r\n          define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]\r\n\r\n      C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\r\n        warnings.warn(msg)\r\n      running dist_info\r\n      running build_src\r\n      build_src\r\n      building py_modules sources\r\n      creating build\r\n      creating build\\src.win-amd64-3.11\r\n      creating build\\src.win-amd64-3.11\\numpy\r\n      creating build\\src.win-amd64-3.11\\numpy\\distutils\r\n      building library \"npymath\" sources\r\n      Traceback (most recent call last):\r\n        File \"C:\\Users\\LSTM\\AppData\\Roaming\\Python\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"C:\\Users\\LSTM\\AppData\\Roaming\\Python\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Roaming\\Python\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\r\n          return hook(metadata_directory, config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 157, in prepare_metadata_for_build_wheel\r\n          self.run_setup()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 249, in run_setup\r\n          self).run_setup(setup_script=setup_script)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\r\n          exec(compile(code, __file__, 'exec'), locals())\r\n        File \"setup.py\", line 508, in <module>\r\n          setup_package()\r\n        File \"setup.py\", line 500, in setup_package\r\n          setup(**metadata)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\core.py\", line 169, in setup\r\n          return old_setup(**new_attr)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 165, in setup\r\n          return distutils.core.setup(**attrs)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 148, in setup\r\n          dist.run_commands()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 967, in run_commands\r\n          self.run_command(cmd)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\r\n          cmd_obj.run()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\command\\dist_info.py\", line 31, in run\r\n          egg_info.run()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\egg_info.py\", line 24, in run\r\n          self.run_command(\"build_src\")\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 313, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\r\n          cmd_obj.run()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\build_src.py\", line 144, in run\r\n          self.build_sources()\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\build_src.py\", line 155, in build_sources\r\n          self.build_library_sources(*libname_info)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\build_src.py\", line 288, in build_library_sources\r\n          sources = self.generate_sources(sources, (lib_name, build_info))\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\build_src.py\", line 378, in generate_sources\r\n          source = func(extension, build_dir)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"numpy\\core\\setup.py\", line 658, in get_mathlib_info\r\n          st = config_cmd.try_link('int main(void) { return 0;}')\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\config.py\", line 243, in try_link\r\n          self._link(body, headers, include_dirs,\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\config.py\", line 162, in _link\r\n          return self._wrap_method(old_config._link, lang,\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\config.py\", line 96, in _wrap_method\r\n          ret = mth(*((self,)+args))\r\n                ^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\config.py\", line 137, in _link\r\n          (src, obj) = self._compile(body, headers, include_dirs, lang)\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\config.py\", line 105, in _compile\r\n          src, obj = self._wrap_method(old_config._compile, lang,\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\command\\config.py\", line 96, in _wrap_method\r\n          ret = mth(*((self,)+args))\r\n                ^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\config.py\", line 132, in _compile\r\n          self.compiler.compile([src], include_dirs=include_dirs)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 401, in compile\r\n          self.spawn(args)\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-build-env-2ufy7yaa\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 505, in spawn\r\n          return super().spawn(cmd, env=env)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\LSTM\\AppData\\Local\\Temp\\pip-install-6n2x0g4v\\numpy_0256d0197b1544709fcc393c15633235\\numpy\\distutils\\ccompiler.py\", line 90, in <lambda>\r\n          m = lambda self, *args, **kw: func(self, *args, **kw)\r\n                                        ^^^^^^^^^^^^^^^^^^^^^^^\r\n      TypeError: CCompiler_spawn() got an unexpected keyword argument 'env'\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n× Encountered error while generating package metadata.\r\n╰─> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.\r\n```",
        "state": "closed",
        "user": "ahbon123",
        "closed_by": "Sunting78",
        "created_at": "2023-04-23T08:15:52+00:00",
        "updated_at": "2024-03-04T10:49:02+00:00",
        "closed_at": "2024-03-04T10:49:01+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 395,
        "title": "urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>",
        "body": "Hello,\r\nI get the following error when extracting data from paddlets, what should I do? Thanks.\r\n\r\n```\r\nfrom paddlets.datasets.repository import get_dataset\r\nts_data = get_dataset('NAB_TEMP') # label_col: 'label', feature_cols: 'value'\r\n```\r\n\r\nOut:\r\n\r\n```\r\n/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 /Users/x/Documents/tjd/exchange-rate-prediction_2023-05-09/code.py\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 1346, in do_open\r\n    h.request(req.get_method(), req.selector, req.data, headers,\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1253, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1299, in _send_request\r\n    self.endheaders(body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1248, in endheaders\r\n    self._send_output(message_body, encode_chunked=encode_chunked)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1008, in _send_output\r\n    self.send(msg)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 948, in send\r\n    self.connect()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1422, in connect\r\n    self.sock = self._context.wrap_socket(self.sock,\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 500, in wrap_socket\r\n    return self.sslsocket_class._create(\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1040, in _create\r\n    self.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1309, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/x/Documents/tjd/exchange-rate-prediction_2023-05-09/code.py\", line 31, in <module>\r\n    from paddlets.datasets.repository import get_dataset\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/__init__.py\", line 5, in <module>\r\n    from paddlets.pipeline import Pipeline\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/pipeline/__init__.py\", line 4, in <module>\r\n    from paddlets.pipeline.pipeline import Pipeline\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/pipeline/pipeline.py\", line 16, in <module>\r\n    from paddlets.utils.utils import get_tsdataset_max_len, split_dataset\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/utils/__init__.py\", line 6, in <module>\r\n    from paddlets.utils.utils import get_uuid\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/utils/utils.py\", line 18, in <module>\r\n    from paddlets.models.data_adapter import DataAdapter\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/models/data_adapter.py\", line 4, in <module>\r\n    import paddle\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/__init__.py\", line 25, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 52, in <module>\r\n    from . import io\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/io.py\", line 31, in <module>\r\n    from paddle.fluid import layers\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/layers/__init__.py\", line 29, in <module>\r\n    from . import math_op_patch\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/layers/math_op_patch.py\", line 24, in <module>\r\n    from paddle.fluid.dygraph.base import in_declarative_mode\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/dygraph/__init__.py\", line 35, in <module>\r\n    from . import checkpoint\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/dygraph/checkpoint.py\", line 26, in <module>\r\n    from paddle.fluid.dygraph.jit import _SaveLoadConfig\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/dygraph/jit.py\", line 34, in <module>\r\n    from paddle.fluid.dygraph.dygraph_to_static import logging_utils\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/dygraph/dygraph_to_static/__init__.py\", line 32, in <module>\r\n    from . import convert_call_func\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_call_func.py\", line 22, in <module>\r\n    import pdb\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pdb.py\", line 77, in <module>\r\n    import code\r\n  File \"/Users/x/Documents/tjd/exchange-rate-prediction_2023-05-09/code.py\", line 33, in <module>\r\n    ts_data = get_dataset('NAB_TEMP') # label_col: 'label', feature_cols: 'value'\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddlets/datasets/repository/base.py\", line 67, in get_dataset\r\n    df = pd.read_csv(path)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\r\n    return _read(filepath_or_buffer, kwds)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\r\n    parser = TextFileReader(filepath_or_buffer, **kwds)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\r\n    self._engine = self._make_engine(self.engine)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\r\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\r\n    self._open_handles(src, kwds)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\r\n    self.handles = get_handle(\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py\", line 609, in get_handle\r\n    ioargs = _get_filepath_or_buffer(\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py\", line 312, in _get_filepath_or_buffer\r\n    with urlopen(req_info) as req:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py\", line 212, in urlopen\r\n    return urllib.request.urlopen(*args, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 214, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 517, in open\r\n    response = self._open(req, data)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 534, in _open\r\n    result = self._call_chain(self.handle_open, protocol, protocol +\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 494, in _call_chain\r\n    result = func(*args)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 1389, in https_open\r\n    return self.do_open(http.client.HTTPSConnection, req,\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\", line 1349, in do_open\r\n    raise URLError(err)\r\nurllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>\r\n```",
        "state": "closed",
        "user": "ahbon123",
        "closed_by": "Sunting78",
        "created_at": "2023-05-09T07:53:04+00:00",
        "updated_at": "2024-03-04T10:41:55+00:00",
        "closed_at": "2024-03-04T10:41:54+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 397,
        "title": "异常检测要求label必须是int，但无法将数据转换为int",
        "body": "构建TSDataset后，int类型数据发生变化，变成了float\r\n![图片](https://github.com/PaddlePaddle/PaddleTS/assets/128353785/7f1ef65f-1994-426b-811d-095175223457)\r\n无法转换为int\r\n![图片](https://github.com/PaddlePaddle/PaddleTS/assets/128353785/223cc956-945f-4804-964e-78c93234a52c)\r\n",
        "state": "closed",
        "user": "ynzzxc",
        "closed_by": "ynzzxc",
        "created_at": "2023-05-10T08:57:16+00:00",
        "updated_at": "2024-04-09T10:02:37+00:00",
        "closed_at": "2023-05-12T02:55:35+00:00",
        "comments_count": [
            "kachadx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 398,
        "title": "PaddleTS中的TFT模型有大佬用过吗，或有没有这个模型的项目推荐",
        "body": "为什么我用这个模型在生成预测曲线图时总是出现报错’ValueError: The specified columns don't exist!’\r\n\r\n其他PaddleTS中的模型就不会",
        "state": "closed",
        "user": "mendjks",
        "closed_by": "Sunting78",
        "created_at": "2023-05-11T08:27:18+00:00",
        "updated_at": "2024-03-21T07:36:28+00:00",
        "closed_at": "2024-03-21T07:36:28+00:00",
        "comments_count": [
            "mendjks",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 399,
        "title": "paddlets == 1.0.2 不支持一键动态转静态图",
        "body": "我是直接使用官方文档（https://paddlets.readthedocs.io/zh_CN/latest/source/get_started/get_started.html）中的操作安装paddlets\r\n```shell\r\npip install paddlets[all]\r\n``` \r\npip使用阿里镜像，应该不存在和PYPI版本错位的问题。但是当我准备按照官方文档所说的，使用save方法一键将动态图转静态图时，发生错误如下：\r\n```shell\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[161], line 1\r\n----> 1 lstm.save(\"./lstm\", network_model=True, dygraph_to_static=True)\r\n\r\nTypeError: save() got an unexpected keyword argument 'network_model'\r\n``` \r\n我将github源码拷贝下来，全局查看，两个参数都是存在的。但是我所安装的paddlets中没有，请问是否存在上传到PYPI中的安装文件和github版本存在错位？",
        "state": "closed",
        "user": "VocabVictor",
        "closed_by": "Sunting78",
        "created_at": "2023-05-16T14:22:39+00:00",
        "updated_at": "2024-03-04T08:28:25+00:00",
        "closed_at": "2024-03-04T08:28:25+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 400,
        "title": "paddlets   classification   docs dome  error",
        "body": "    out = getattr(_C_ops, l_type)(\r\nValueError: (InvalidArgument) The type of data we are trying to retrieve does not match the type of data currently contained in the container. (at ..\\paddle\\phi\\core\\dense_tensor.cc:154)\r\n",
        "state": "closed",
        "user": "dongdong2023",
        "closed_by": "Sunting78",
        "created_at": "2023-05-22T01:38:20+00:00",
        "updated_at": "2024-03-04T08:29:35+00:00",
        "closed_at": "2024-03-04T08:29:35+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 413
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 405,
        "title": "拆分运行完成后出现如下所示的错误",
        "body": "--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::platform::MKLDNNDeviceContextThreadLocals::Body::~Body()\r\n1   paddle::platform::MKLDNNDeviceContext::ResetBlobMap(void*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1685674949 (unix time) try \"date -d @1685674949\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x15cb9) received by PID 89273 (TID 0x7f17c8938740) from PID 89273 ***]\r\n\r\nAborted\r\n\r\n\r\n问题背景：\r\n使用分组联合训练进行训练，将所有代码放到一个py文件执行时未出现该错误；成功执行完毕；\r\n将上述py文件拆分成predict.py；analysizes.py，main.py和conf.py后出现这个bug;程序执行完成的时候出现这个问题\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "yuxiaotongshenzhen",
        "closed_by": "Sunting78",
        "created_at": "2023-06-02T03:27:47+00:00",
        "updated_at": "2024-03-21T07:39:16+00:00",
        "closed_at": "2024-03-21T07:39:16+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 404,
        "title": "group id不支持列表",
        "body": "group id为什么不能是列表？我有多个组怎么办?",
        "state": "closed",
        "user": "DaPenggg",
        "closed_by": "Sunting78",
        "created_at": "2023-06-02T02:49:59+00:00",
        "updated_at": "2024-03-04T08:27:22+00:00",
        "closed_at": "2024-03-04T08:27:22+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 407,
        "title": "TSDataset的split()方法无法和NHiTSModel结合使用",
        "body": "尝试在aistudio上使用NHiTSModel模型，代码如下：\r\n`\r\nfrom paddlets.datasets.repository import get_dataset\r\n\r\ndataset = get_dataset(\"UNI_WTH\")\r\ntrain_dataset, val_test_dataset = dataset.split(0.7)\r\nval_dataset, test_dataset = val_test_dataset.split(0.5)\r\n\r\nfrom paddlets.models.forecasting import NHiTSModel\r\nmodel = NHiTSModel(\r\n    in_chunk_len = 7 * 24,\r\n    out_chunk_len = 24,\r\n    max_epochs=100\r\n)\r\n\r\nmodel.fit(train_dataset, val_dataset)\r\n`\r\n\r\n然而报错：\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_4864/1383395577.py in <module>\r\n----> 1 model.fit(train_dataset, val_dataset)\r\n\r\n~/external-libraries/paddlets/models/forecasting/dl/paddle_base_impl.py in fit(self, train_tsdataset, valid_tsdataset)\r\n    344             self._check_multi_tsdataset(valid_tsdataset)\r\n    345         train_dataloader, valid_dataloaders = self._init_fit_dataloaders(train_tsdataset, valid_tsdataset)\r\n--> 346         self._fit(train_dataloader, valid_dataloaders)\r\n    347 \r\n    348     def _fit(\r\n\r\n~/external-libraries/paddlets/models/forecasting/dl/paddle_base_impl.py in _fit(self, train_dataloader, valid_dataloaders)\r\n    374             # Predict for each eval set.\r\n    375             for eval_name, valid_dataloader in zip(valid_names, valid_dataloaders):\r\n--> 376                 self._predict_epoch(eval_name, valid_dataloader)\r\n    377 \r\n    378             # Call the `on_epoch_end` method of each callback at the end of the epoch.\r\n\r\n~/external-libraries/paddlets/models/forecasting/dl/paddle_base_impl.py in _predict_epoch(self, name, loader)\r\n    487             list_y_score.append(scores)\r\n    488         y_true, scores = np.vstack(list_y_true), np.vstack(list_y_score)\r\n--> 489         metrics_logs = self._metric_container_dict[name](y_true, scores)\r\n    490         self._history._epoch_metrics.update(metrics_logs)\r\n    491         self._network.train()\r\n\r\n~/external-libraries/paddlets/metrics/metrics.py in __call__(self, y_true, y_score)\r\n    393         logs = {}\r\n    394         for metric in self._metrics:\r\n--> 395             res = metric.metric_fn(y_true, y_score)\r\n    396             logs[self._prefix + metric._NAME] = res\r\n    397         return logs\r\n\r\n~/external-libraries/paddlets/metrics/utils.py in wrapper(obj, y_true, y_score, **kwargs)\r\n     40         y_true = np.reshape(y_true, (batch_nd_true, -1))\r\n     41         y_score = np.reshape(y_score, (batch_nd_score, -1))\r\n---> 42         return func(obj, y_true, y_score, **kwargs)\r\n     43     return wrapper\r\n     44 \r\n\r\n~/external-libraries/paddlets/metrics/metrics.py in metric_fn(self, y_true, y_score)\r\n     93         \"\"\"\r\n     94 \r\n---> 95         return metrics.mean_absolute_error(y_true, y_score)\r\n     96 \r\n     97 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs)\r\n     61             extra_args = len(args) - len(all_args)\r\n     62             if extra_args <= 0:\r\n---> 63                 return f(*args, **kwargs)\r\n     64 \r\n     65             # extra_args > 0\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/metrics/_regression.py in mean_absolute_error(y_true, y_pred, sample_weight, multioutput)\r\n    181     \"\"\"\r\n    182     y_type, y_true, y_pred, multioutput = _check_reg_targets(\r\n--> 183         y_true, y_pred, multioutput)\r\n    184     check_consistent_length(y_true, y_pred, sample_weight)\r\n    185     output_errors = np.average(np.abs(y_pred - y_true),\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/metrics/_regression.py in _check_reg_targets(y_true, y_pred, multioutput, dtype)\r\n     88     check_consistent_length(y_true, y_pred)\r\n     89     y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\r\n---> 90     y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\r\n     91 \r\n     92     if y_true.ndim == 1:\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs)\r\n     61             extra_args = len(args) - len(all_args)\r\n     62             if extra_args <= 0:\r\n---> 63                 return f(*args, **kwargs)\r\n     64 \r\n     65             # extra_args > 0\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\r\n    719         if force_all_finite:\r\n    720             _assert_all_finite(array,\r\n--> 721                                allow_nan=force_all_finite == 'allow-nan')\r\n    722 \r\n    723     if ensure_min_samples > 0:\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in _assert_all_finite(X, allow_nan, msg_dtype)\r\n    104                     msg_err.format\r\n    105                     (type_err,\r\n--> 106                      msg_dtype if msg_dtype is not None else X.dtype)\r\n    107             )\r\n    108     # for object dtype data, we only check for NaNs (GH-13254)\r\n\r\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\r\n\r\n\r\n查看了一下，TSDataset的split()方法会对非target部分用nan进行mask， 该方式分割的数据在其他模型上均能正常跑通（如TCN，MLP等）。故请问该问题是否可以解决呢？谢谢！\r\n环境：\r\npaddlepaddle-gpu 2.4.0.post112\r\npaddlets 1.1.0",
        "state": "closed",
        "user": "akari0216",
        "closed_by": "Sunting78",
        "created_at": "2023-06-14T04:54:20+00:00",
        "updated_at": "2024-04-22T02:32:30+00:00",
        "closed_at": "2024-04-22T02:32:30+00:00",
        "comments_count": [
            "suntao2015005848",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 408,
        "title": "[bug]当前main分支上的dataset缺个SMDTrainDataset 训练数据集的定义",
        "body": "当前main分支上的dataset缺个SMDTrainDataset 训练数据集的定义，使用会报下面的错误\r\nImportError: cannot import name 'SMDTrainDataset' from 'paddlets.datasets.repository._data_config'",
        "state": "closed",
        "user": "xonze",
        "closed_by": "Sunting78",
        "created_at": "2023-06-14T08:38:30+00:00",
        "updated_at": "2024-03-04T10:57:44+00:00",
        "closed_at": "2024-03-04T10:57:43+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 420,
        "title": "套件开发者证书发放活动 2023H1",
        "body": "各位飞桨开发者大家好～为了感谢大家近期对飞桨套件代码库，文档的贡献，我们会为在2023年1.1-6.30日之间合入飞桨套件PR的开发者发放电子版飞桨开源证书🎉🎉🎉 如果您有PR合入，请填写这张问卷补充如下信息，方便我们发放证书：\r\n\r\n* GitHubID\r\n* 邮箱\r\n* 合入PR的链接及描述信息\r\n\r\n感谢您对飞桨套件开源工作的支持！\r\n问卷链接：https://wj.qq.com/s2/12744729/af61/",
        "state": "closed",
        "user": "KevinLi43",
        "closed_by": "Sunting78",
        "created_at": "2023-07-12T08:15:47+00:00",
        "updated_at": "2024-02-28T11:49:28+00:00",
        "closed_at": "2024-02-28T11:49:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 410,
        "title": "安装运行示例代码报warrning",
        "body": null,
        "state": "closed",
        "user": "freedomaswind94",
        "closed_by": "Sunting78",
        "created_at": "2023-06-21T07:20:25+00:00",
        "updated_at": "2024-03-21T07:37:07+00:00",
        "closed_at": "2024-03-21T07:37:07+00:00",
        "comments_count": [
            "freedomaswind94",
            "freedomaswind94",
            "freedomaswind94",
            "freedomaswind94",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 411,
        "title": "依赖更新建议",
        "body": "目前使用的 paddlets==1.1.0，paddlepaddle-gpu==2.4.2.post117，python 版本 3.8，能够友好共存的最高版本 numpy==1.19.5，pandas==1.3.5，而一些 package 例如 Prophet 的最低依赖要求 numpy > 1.21，希望能够更新一下依赖问题。",
        "state": "closed",
        "user": "Miracle0x0",
        "closed_by": "Sunting78",
        "created_at": "2023-06-23T09:51:35+00:00",
        "updated_at": "2024-03-01T06:09:06+00:00",
        "closed_at": "2024-03-01T06:09:06+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 417,
        "title": "表征模型报错",
        "body": "在运行ts2vec和CoST模型时，fit函数正常运行，但在进行encode时报错\r\n\r\nAttributeError: '_DataLoaderIterSingleProcess' object has no attribute 'next'",
        "state": "closed",
        "user": "Erling-J",
        "closed_by": "Sunting78",
        "created_at": "2023-07-05T09:34:19+00:00",
        "updated_at": "2024-04-22T02:33:09+00:00",
        "closed_at": "2024-04-22T02:33:08+00:00",
        "comments_count": [
            "WKangei",
            "leo-bot",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 422,
        "title": "Crossformer模型训练失败",
        "body": "`\r\nimport paddlets\r\nfrom paddlets.datasets.repository import get_dataset, dataset_list\r\nfrom paddlets.datasets import TSDataset\r\n\r\ndataset = get_dataset('UNI_WTH')\r\ntrain_dataset, val_test_dataset = dataset.split(0.7)\r\nval_dataset, test_dataset = val_test_dataset.split(0.5)\r\ntrain_dataset.plot(add_data=[val_dataset,test_dataset], labels=['Val', 'Test'])\r\n\r\nfrom paddlets.models.forecasting import Crossformer\r\n\r\ncf = Crossformer(\r\n    c_in = 5, \r\n    factor = 10, \r\n    in_chunk_len = 24,\r\n    out_chunk_len = 24,\r\n    max_epochs=10, \r\n)\r\ncf.fit(train_dataset, val_dataset)\r\n`\r\n\r\n运行以上代码后报错：\r\n`\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_266/260518010.py in <module>\r\n      8     max_epochs=10,\r\n      9 )\r\n---> 10 cf.fit(train_dataset, val_dataset)\r\n\r\n~/paddlets/models/forecasting/dl/paddle_base_impl.py in fit(self, train_tsdataset, valid_tsdataset)\r\n    347         train_dataloader, valid_dataloaders = self._init_fit_dataloaders(\r\n    348             train_tsdataset, valid_tsdataset)\r\n--> 349         self._fit(train_dataloader, valid_dataloaders)\r\n    350 \r\n    351     def _fit(self,\r\n\r\n~/paddlets/models/forecasting/dl/paddle_base_impl.py in _fit(self, train_dataloader, valid_dataloaders)\r\n    371             # Call the `on_epoch_begin` method of each callback before the epoch starts.\r\n    372             self._callback_container.on_epoch_begin(epoch_idx)\r\n--> 373             self._train_epoch(train_dataloader)\r\n    374             # Predict for each eval set.\r\n    375             for eval_name, valid_dataloader in zip(valid_names,\r\n\r\n~/paddlets/models/forecasting/dl/paddle_base_impl.py in _train_epoch(self, train_loader)\r\n    433             self._callback_container.on_batch_begin(batch_idx)\r\n    434             X, y = self._prepare_X_y(data)\r\n--> 435             batch_logs = self._train_batch(X, y)\r\n    436             self._callback_container.on_batch_end(batch_idx, batch_logs)\r\n    437         epoch_logs = {\"lr\": self._optimizer.get_lr()}\r\n\r\n~/paddlets/models/forecasting/dl/paddle_base_impl.py in _train_batch(self, X, y)\r\n    449             Dict[str, Any]: Dict of logs.\r\n    450         \"\"\"\r\n--> 451         output = self._network(X)\r\n    452         loss = self._compute_loss(output, y)\r\n    453         loss.backward()\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    946             and (not self._forward_post_hooks) and (not self._built) and in_dygraph_mode() and (not in_profiler_mode()):\r\n    947             self._build_once(*inputs, **kwargs)\r\n--> 948             return self.forward(*inputs, **kwargs)\r\n    949         else:\r\n    950             return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\n~/paddlets/models/forecasting/dl/Crossformer.py in forward(self, x)\r\n     85         x_seq += self.enc_pos_embedding\r\n     86         x_seq = self.pre_norm(x_seq)\r\n---> 87         enc_out = self.encoder(x_seq)\r\n     88         dec_in = repeat(self.dec_pos_embedding,\r\n     89             'b ts_d l d -> (repeat b) ts_d l d', repeat=batch_size)\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    946             and (not self._forward_post_hooks) and (not self._built) and in_dygraph_mode() and (not in_profiler_mode()):\r\n    947             self._build_once(*inputs, **kwargs)\r\n--> 948             return self.forward(*inputs, **kwargs)\r\n    949         else:\r\n    950             return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\n~/paddlets/models/forecasting/dl/_crossformer/encoder.py in forward(self, x)\r\n     87         encode_x.append(x)\r\n     88         for block in self.encode_blocks:\r\n---> 89             x = block(x)\r\n     90             encode_x.append(x)\r\n     91         return encode_x\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    946             and (not self._forward_post_hooks) and (not self._built) and in_dygraph_mode() and (not in_profiler_mode()):\r\n    947             self._build_once(*inputs, **kwargs)\r\n--> 948             return self.forward(*inputs, **kwargs)\r\n    949         else:\r\n    950             return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\n~/paddlets/models/forecasting/dl/_crossformer/encoder.py in forward(self, x)\r\n     61         _, ts_dim, _, _ = x.shape\r\n     62         if self.merge_layer is not None:\r\n---> 63             x = self.merge_layer(x)\r\n     64         for layer in self.encode_layers:\r\n     65             x = layer(x)\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in __call__(self, *inputs, **kwargs)\r\n    946             and (not self._forward_post_hooks) and (not self._built) and in_dygraph_mode() and (not in_profiler_mode()):\r\n    947             self._build_once(*inputs, **kwargs)\r\n--> 948             return self.forward(*inputs, **kwargs)\r\n    949         else:\r\n    950             return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\n~/paddlets/models/forecasting/dl/_crossformer/encoder.py in forward(self, x)\r\n     31         seg_to_merge = []\r\n     32         for i in range(self.win_size):\r\n---> 33             seg_to_merge.append(x[:, :, i::self.win_size, :])\r\n     34         x = paddle.concat(x=seg_to_merge, axis=-1)\r\n     35         x = self.norm(x)\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py in __getitem__(self, item)\r\n    751         else:\r\n    752             # 2. Call c++ func getitem_index_not_tensor to speedup.\r\n--> 753             return self._getitem_index_not_tensor(item)\r\n    754 \r\n    755     def __setitem__(self, item, value):\r\n\r\nValueError: (InvalidArgument) The start index and end index are invalid for their corresponding stride.\r\n  [Hint: Expected neg_dim_condition == false, but received neg_dim_condition:1 != false:0.] (at /paddle/paddle/phi/kernels/funcs/strided_slice.h:100)\r\n`\r\n\r\n环境：\r\nAistudio, python == 3.7.4, paddlepaddle-gpu == 2.4.0.post112\r\n",
        "state": "closed",
        "user": "akari0216",
        "closed_by": "Sunting78",
        "created_at": "2023-07-14T03:20:13+00:00",
        "updated_at": "2024-02-28T09:30:09+00:00",
        "closed_at": "2024-02-28T09:30:09+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 429,
        "title": "运行informer时碰到TSDataset.target.time_index[time_window[1]]越界报错",
        "body": "具体报错是这样，在运行.predict(test_dataset)函数时，碰到这样的问题\r\n[paddlets] [ERROR] ValueError: The inequality must hold: TSDataset.known_cov.start_time (2013-02-01 00:00:00) <= TSDataset.target.time_index[(time_window[0] - out_chunk_len - skip_chunk_len - in_chunk_len + 1)] (2013-02-28 21:00:00) <= TSDataset.target.time_index[time_window[1]] (2013-03-01 00:00:00) <= TSDataset.known_cov.end_time (2013-02-28 23:00:00).\r\n\r\n然后我就去查time_window是啥玩意，在paddle_base_impl.py文件中，定义是这样的：\r\nboundary = (len(tsdataset.get_target().data) - 1 + self._skip_chunk_len\r\n                    + self._out_chunk_len)\r\ntime_window=(boundary, boundary)\r\n\r\n那么有疑问的就来了，boundary肯定会大于len(tsdataset.get_target().data)，也就是比tsdataset长度要长，那么TSDataset.target.time_index[time_window[1]]必定会越界啊\r\n\r\n求大佬捞捞。\r\n---------------------------------------------------------------------------------------------------------------------------------\r\n具体代码：from paddlets.models.forecasting import InformerModel\r\nInF = InformerModel(\r\n    in_chunk_len=3,\r\n    out_chunk_len=1,\r\n    max_epochs=2)\r\nInF.fit(train_dataset, val_dataset)\r\nsubset_test_pred_dataset = InF.predict(test_dataset)#模型预测\r\nsubset_test_dataset, _ = test_dataset.split(len(subset_test_pred_dataset.target))#截取某天进行预测\r\nsubset_test_dataset.plot(add_data=subset_test_pred_dataset, labels=['Pred'])\r\nfrom paddlets.utils import backtest\r\nscore, preds_data= backtest(\r\n    data=test_dataset,\r\n    model=InF,\r\n    return_predicts = True)\r\nprint(f\"mae: {score}\")\r\ntest_dataset.plot(add_data=preds_data,labels=\"backtest\")\r\n---------------------------------------------------------------------------------------------------------------------------------------\r\n具体报错：---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_181/2058596484.py in <module>\r\n      5     max_epochs=3)\r\n      6 InF.fit(train_dataset, val_dataset)\r\n----> 7 subset_test_pred_dataset = InF.predict(test_dataset)#模型预测\r\n      8 subset_test_dataset, _ = test_dataset.split(len(subset_test_pred_dataset.target))#截取某天进行预测\r\n      9 subset_test_dataset.plot(add_data=subset_test_pred_dataset, labels=['Pred'])\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/utils.py in wrapper(obj, tsdataset, **kwargs)\r\n    113             )\r\n    114 \r\n--> 115             results = func(obj, tsdataset, **kwargs)\r\n    116             if scenario == \"anomaly_label\" or scenario == \"anomaly_score\":\r\n    117                 # Generate target cols\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in predict(self, tsdataset)\r\n    400             TSDataset.\r\n    401         \"\"\"\r\n--> 402         dataloader = self._init_predict_dataloader(tsdataset)\r\n    403         return self._predict(dataloader)\r\n    404 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in _init_predict_dataloader(self, tsdataset)\r\n    261             skip_chunk_len=self._skip_chunk_len,\r\n    262             sampling_stride=self._sampling_stride,\r\n--> 263             time_window=(boundary, boundary)\r\n    264         )\r\n    265         dataloader = data_adapter.to_paddle_dataloader(dataset, self._batch_size)\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/data_adapter.py in to_sample_dataset(self, rawdataset, in_chunk_len, out_chunk_len, skip_chunk_len, sampling_stride, fill_last_value, time_window)\r\n   1512             sampling_stride=sampling_stride,\r\n   1513             time_window=time_window,\r\n-> 1514             fill_last_value=fill_last_value\r\n   1515         )\r\n   1516 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/data_adapter.py in __init__(self, rawdataset, in_chunk_len, out_chunk_len, skip_chunk_len, sampling_stride, fill_last_value, time_window)\r\n    341         # perform the rest of the timeseries validation.\r\n    342         self._validate_target_timeseries()\r\n--> 343         self._validate_known_cov_timeseries()\r\n    344         self._validate_observed_cov_timeseries()\r\n    345 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/models/data_adapter.py in _validate_known_cov_timeseries(self)\r\n   1005                 f\"TSDataset.{self._std_timeseries_name}.time_index[time_window[1]] \" +\r\n   1006                 f\"({sample_end_std_time}) <= \" +\r\n-> 1007                 f\"TSDataset.known_cov.end_time ({known_cov_ts.end_time}).\"\r\n   1008             )\r\n   1009 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/logger/logger.py in raise_if_not(condition, message, logger)\r\n    133     if not condition:\r\n    134         logger.error(\"ValueError: \" + message)\r\n--> 135         raise ValueError(message)\r\n    136 \r\n    137 \r\n\r\nValueError: The inequality must hold: TSDataset.known_cov.start_time (2013-02-01 00:00:00) <= TSDataset.target.time_index[(time_window[0] - out_chunk_len - skip_chunk_len - in_chunk_len + 1)] (2013-02-28 21:00:00) <= TSDataset.target.time_index[time_window[1]] (2013-03-01 00:00:00) <= TSDataset.known_cov.end_time (2013-02-28 23:00:00).",
        "state": "closed",
        "user": "voyagebio",
        "closed_by": "Sunting78",
        "created_at": "2023-07-20T06:46:25+00:00",
        "updated_at": "2024-03-04T13:06:08+00:00",
        "closed_at": "2024-03-04T13:06:08+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 423,
        "title": "duplicated values in the time column",
        "body": "这个报错没太看懂，我设置了时间字段",
        "state": "closed",
        "user": "xxllp",
        "closed_by": "xxllp",
        "created_at": "2023-07-16T14:36:11+00:00",
        "updated_at": "2023-11-17T09:32:22+00:00",
        "closed_at": "2023-11-12T02:25:56+00:00",
        "comments_count": [
            "akari0216",
            "xiaoyao123456789",
            "jiaohuix",
            "jiaohuix"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 430,
        "title": "Images",
        "body": "tide\r\n<img width=\"470\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/d2b0ea80-cf20-4a40-8cf1-3cd1325827b7\">\r\n<img width=\"786\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/b3f1b91a-6dda-482c-a4ca-7dff4da07490\">\r\n\r\n\r\npatchtst\r\n<img width=\"615\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/d4094fcd-7b85-4b6b-a120-28209f41f464\">\r\n<img width=\"980\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/6bc77f30-f8b8-4a2b-bc49-039328090f9d\">\r\n<img width=\"914\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/4b352ab8-f7ed-45ee-a6a6-e2b163a0a829\">\r\n\r\n\r\nnon-stationary\r\n<img width=\"558\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/268274ac-095c-40fa-9758-b71c5b455afa\">\r\n<img width=\"879\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/004c36a8-6824-4fdc-8678-1cc4ee548c29\">\r\n\r\n\r\ntimesnet\r\n<img width=\"547\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/4344cd2f-2564-4180-87f5-f8eba2866028\">\r\n<img width=\"736\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/052af41d-c8cf-42d5-a9a4-c3a576b4f06f\">\r\n\r\n\r\nLinear Are Transformers Effective for Time Series Forecasting?\r\n<img width=\"420\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/12b636f6-eed7-45c2-b860-8af8afae03f7\">\r\n<img width=\"611\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/18344247/44813b05-6cf1-475f-83fe-724b3037f124\">\r\n\r\n\r\n",
        "state": "closed",
        "user": "Sunting78",
        "closed_by": "Sunting78",
        "created_at": "2023-07-24T07:41:45+00:00",
        "updated_at": "2023-11-01T02:37:58+00:00",
        "closed_at": "2023-08-01T09:43:07+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 438,
        "title": "为什么我在使用TSDataset.load_from_dataframe后报错",
        "body": "[2023-08-04 10:51:18,067] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n[2023-08-04 10:51:18,114] [paddlets] [ERROR] ValueError: attr: shape doesn't exist!\r\n\r\n使用TSDataset.load_from_dataframe一直报这个错误，model.fit() 直接提示Process finished with exit code -1073741819 (0xC0000005)终止",
        "state": "closed",
        "user": "YuboCoco",
        "closed_by": "Sunting78",
        "created_at": "2023-08-04T02:56:55+00:00",
        "updated_at": "2024-03-28T08:01:15+00:00",
        "closed_at": "2024-03-28T08:01:15+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 441,
        "title": "examples下算法示例补充请求",
        "body": "能否在examples下补充一些新加进去的时序算法的应用示例呢？，比如TiDE、TimesNet和Crossformer等，谢谢！",
        "state": "closed",
        "user": "guang7400613",
        "closed_by": "Sunting78",
        "created_at": "2023-08-08T13:24:10+00:00",
        "updated_at": "2024-01-18T09:57:30+00:00",
        "closed_at": "2024-01-18T09:57:30+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 444,
        "title": "表征模型中对标签列数据处理bug",
        "body": "你好,我在使用中发现表征模型中对标签列数据直接使用了当前时间的值,我认为这存在严重的数据泄露问题\r\n\r\n",
        "state": "closed",
        "user": "lz-xinlin",
        "closed_by": "Sunting78",
        "created_at": "2023-08-10T07:40:18+00:00",
        "updated_at": "2024-04-22T02:34:06+00:00",
        "closed_at": "2024-04-22T02:34:06+00:00",
        "comments_count": [
            "lz-xinlin",
            "lz-xinlin",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 445,
        "title": "如何在多步预测时预测周末的情况呢？",
        "body": "我在训练模型的时候Observed_col加入了是否为周末的标签，训练时使用了前48个小时去预测后24个小时，在预测时使用recursive_predict去预测后72个小时，但是我注意到预测出来的数据不具有周末特征，有什么办法可以预测周末特征吗？",
        "state": "closed",
        "user": "YuboCoco",
        "closed_by": "Sunting78",
        "created_at": "2023-08-16T07:18:11+00:00",
        "updated_at": "2024-02-28T09:19:23+00:00",
        "closed_at": "2024-02-28T09:19:23+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 447,
        "title": "项目代码拉下来就有冲突",
        "body": "nlinear.py和NLinear.py\r\n<img width=\"629\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/10610290/70e8e77a-1e76-418d-a1a1-8287886bf05e\">\r\n",
        "state": "closed",
        "user": "kingwpf",
        "closed_by": "Sunting78",
        "created_at": "2023-08-25T07:05:14+00:00",
        "updated_at": "2024-02-28T09:29:45+00:00",
        "closed_at": "2024-02-28T09:28:58+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 449,
        "title": "timeseries有个小问题",
        "body": "在timeseries的load_from_dataframe方法里面\r\n        #Try to convert to string and generate DatetimeIndex\r\n        if np.issubdtype(time_col_vals.dtype, np.integer) and isinstance(freq, str):\r\n            time_col_vals = time_col_vals.astype(str)\r\n这里跟之后的代码好像冲突了",
        "state": "closed",
        "user": "Kaiakaiakai",
        "closed_by": "Sunting78",
        "created_at": "2023-09-13T07:16:32+00:00",
        "updated_at": "2024-02-28T09:28:40+00:00",
        "closed_at": "2024-02-28T09:28:40+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 452,
        "title": "请问内置模型的性能对比结果有吗",
        "body": "内置模型如下：DeepARModel、InformerModel、LSTNetRegressor、MLPRegressor、NHiTSModel、NBEATSModel、RNNBLockRegressor、SCINetModel、TCNRegressor、TFTModel ",
        "state": "closed",
        "user": "Liang-feng",
        "closed_by": "Sunting78",
        "created_at": "2023-09-19T08:09:18+00:00",
        "updated_at": "2024-02-28T09:28:28+00:00",
        "closed_at": "2024-02-28T09:28:28+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 451,
        "title": "经过带已知协变量训练后，模型预测却失效的问题。",
        "body": "在LSTNetRegressor训练的时序模型中，经过带已知协变量训练后，模型预测却失效的问题\r\n版本信息：\r\nPaddlePaddle: 2.3.2.post112\r\npaddleTs: 1.1.0 \r\n模型训练代码：\r\n```\r\nimport pandas as pd\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\r\nimport datetime\r\nimport paddlets\r\nfrom paddlets import TSDataset\r\nfrom paddlets import TimeSeries\r\nfrom paddlets.models.forecasting.dl import * #引入了全部预测模型\r\nfrom paddlets.models.forecasting import * #引入了全部预测模型\r\nfrom paddlets.transform import Fill, StandardScaler\r\nfrom paddlets.metrics import MSE, MAE\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\nfrom paddlets.automl.autots import AutoTS\r\nimport os \r\nfrom paddlets.automl.autots import SearchSpaceConfiger\r\nfrom ray.tune import uniform, qrandint, choice,quniform\r\nfrom paddlets.transform import TimeFeatureGenerator\r\n\r\n# 读取CSV文件\r\ndf = pd.read_csv('/home/aistudio/ydl/fh_power_data_expend.csv')\r\ndf = df.filter(items=['monitorTime', 'presentValue'])\r\nprint(len(df))\r\n\r\ntarget_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)    \r\n# 是否是工作日\r\ntime_feature_generator = TimeFeatureGenerator(feature_cols=['is_workday'])\r\ntarget_cov_dataset = time_feature_generator.fit_transform(target_cov_dataset)\r\n\r\ntrain_dataset, val_test_dataset = target_cov_dataset.split(0.8)\r\nval_dataset, test_dataset = val_test_dataset.split(0.5)\r\ntrain_dataset.plot(add_data=[val_dataset,test_dataset], labels=['Val', 'Test'])\r\n\r\nlstm = LSTNetRegressor(\r\n    in_chunk_len = 288,\r\n    out_chunk_len = 6,\r\n    max_epochs=3\r\n)\r\nlstm.fit(train_dataset, val_dataset) \r\n\r\nlstm.save(path=\"/home/aistudio/ydl/mode_fh_expend/lsnet\")\r\n```\r\n模型预测的测试代码：\r\n```\r\ndf = pd.read_csv('/home/aistudio/ydl/test.csv')\r\ndf = df.filter(items=['monitorTime', 'presentValue'])\r\n\r\ntarget_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)    \r\n# print('没有任何协变量：-------------------------------------------------------->')\r\n# print(target_cov_dataset.get_all_cov())\r\n\r\n# 是否是工作日\r\ntime_feature_generator = TimeFeatureGenerator(feature_cols=['is_workday'])\r\ntarget_cov_dataset = time_feature_generator.fit_transform(target_cov_dataset)\r\nprint('加入时间协变量：---------------------------------------------------------->')\r\nprint(target_cov_dataset.get_all_cov())\r\n\r\nmod = LSTNetRegressor.load(path=\"/home/aistudio/ydl/mode_fh_expend/lsnet\")\r\nda1 ,da2 = target_cov_dataset.split('2023-09-11 00:05:00')\r\nprint('预测数据：---------------------------------------------------------->')\r\nprint(da1)\r\nres = mod.predict(da1)\r\nprint('不加协变量预测结果：---------------------------------------------------------->')\r\nprint(res)\r\n```\r\nLSTNetRegressor模型参数：\r\n![116e8f0fa652452133668215542321a](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/d7fdf30f-585f-4ee5-abbb-41278fd9f4fe)\r\n有is_workday已知协变量的预测结果：\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/6acf385c-e025-486d-99ac-12e31681c1d4)\r\n无is_workday已知协变量的预测结果：\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/9f4a3f39-a236-402a-b0f8-2c65b3f9df01)\r\n两次预测结果在有协变量和无限量的情况下相同。LSTNetRegressor协变量对模型预测并未产生影响是什么问题？\r\n而在测试NBEATSModel模型时候，协变量的变化会影响模型输出的结果。\r\nNBEATSModel模型参数：\r\n![cf25f4f514b45771cbfce4e6e5ccba3](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/0062d119-4d23-4034-8537-b6424625bf0f)\r\n",
        "state": "closed",
        "user": "suntao2015005848",
        "closed_by": "Sunting78",
        "created_at": "2023-09-18T02:48:11+00:00",
        "updated_at": "2024-03-01T06:10:37+00:00",
        "closed_at": "2024-03-01T06:10:37+00:00",
        "comments_count": [
            "Sunting78",
            "suntao2015005848",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 454,
        "title": "Pipline的recursive_predict的IndexError: list index out of range bug",
        "body": "在使用Pipline训练NBEATSModel模型后：\r\n`{\"model_type\": \"forecasting\", \"ancestor_classname_set\": [\"NBEATSModel\", \"PaddleBaseModelImpl\", \"PaddleBaseModel\", \"BaseModel\", \"Trainable\", \"ABC\", \"object\"], \"modulename\": \"paddlets.models.forecasting.dl.nbeats\", \"size\": {\"in_chunk_len\": 288, \"out_chunk_len\": 24, \"skip_chunk_len\": 0}, \"input_data\": {\"target_dim\": 1, \"known_cov_dim\": 3}}`\r\n递归预测测试代码：\r\n\r\n```\r\n#模型直接预测\r\nimport pandas as pd\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nimport datetime\r\nimport paddlets\r\nfrom paddlets import TSDataset\r\nfrom paddlets import TimeSeries\r\nfrom paddlets.models.forecasting.dl import * #引入了全部预测模型\r\nfrom paddlets.models.forecasting import * #引入了全部预测模型\r\nfrom paddlets.transform import Fill, StandardScaler\r\nfrom paddlets.metrics import MSE, MAE\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\nimport os \r\nfrom paddlets.transform import TimeFeatureGenerator\r\nfrom paddlets.pipeline.pipeline import Pipeline\r\n\r\ndf = pd.read_csv('/home/aistudio/ydl/fh_power_data.csv')\r\ndf = df.filter(items=['monitorTime', 'presentValue'])\r\ntarget_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    known_cov_cols ='monitorTime',\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)    \r\n\r\n\r\n# 是否是工作日\r\ntime_feature_generator = TimeFeatureGenerator(feature_cols=['is_workday','weekday','hour'])\r\ntarget_cov_dataset_1 = time_feature_generator.fit_transform(target_cov_dataset)\r\n\r\ndf_cov = target_cov_dataset_1.to_dataframe()\r\n\r\n# 转为df后重新处理为tsdataset\r\ntarget_cov_dataset_2 = TSDataset.load_from_dataframe(\r\n    df_cov,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    known_cov_cols =['is_workday','weekday','hour'],\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)    \r\n\r\nloaded_model = Pipeline.load(\"/home/aistudio/ydl/model_nbeats/in288_out24/\")\r\nprint(len(loaded_model._transform_list))\r\nda1 ,da2 = target_cov_dataset_2.split('2023-09-08 23:55:00')\r\nda3 ,da4 = da2.split('2023-09-09 23:55:00')\r\nprint('预测数据：---------------------------------------------------------->')\r\nprint(da3.get_target())\r\nprint(da3.get_known_cov())\r\n\r\n# res = mod.predict(da1)\r\nloaded_model.recursive_predict(da3, predict_length=24)\r\n\r\n```\r\n输出结果报错：\r\n```\r\n0\r\n预测数据：---------------------------------------------------------->\r\n                     presentValue\r\nmonitorTime                      \r\n2023-09-09 00:00:00           6.2\r\n2023-09-09 00:05:00           6.4\r\n2023-09-09 00:10:00           6.2\r\n2023-09-09 00:15:00           7.0\r\n2023-09-09 00:20:00           7.0\r\n...                           ...\r\n2023-09-09 23:35:00           6.3\r\n2023-09-09 23:40:00           6.1\r\n2023-09-09 23:45:00           6.4\r\n2023-09-09 23:50:00           6.9\r\n2023-09-09 23:55:00           6.2\r\n\r\n[288 rows x 1 columns]\r\n                     is_workday  weekday  hour\r\nmonitorTime                                   \r\n2023-09-09 00:00:00         0.0        5     0\r\n2023-09-09 00:05:00         0.0        5     0\r\n2023-09-09 00:10:00         0.0        5     0\r\n2023-09-09 00:15:00         0.0        5     0\r\n2023-09-09 00:20:00         0.0        5     0\r\n...                         ...      ...   ...\r\n2023-09-13 17:20:00         1.0        2    17\r\n2023-09-13 17:25:00         1.0        2    17\r\n2023-09-13 17:30:00         1.0        2    17\r\n2023-09-13 17:35:00         1.0        2    17\r\n2023-09-13 17:40:00         1.0        2    17\r\n\r\n[1365 rows x 3 columns]\r\n\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n/tmp/ipykernel_13721/4072872998.py in <module>\r\n     58 \r\n     59 # res = mod.predict(da1)\r\n---> 60 loaded_model.recursive_predict(da3, predict_length=24)\r\n     61 \r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/pipeline/pipeline.py in recursive_predict(self, tsdataset, predict_length)\r\n    280             TSDataset: Predicted results.\r\n    281         \"\"\"\r\n--> 282         return self._recursive_predict(tsdataset, predict_length)\r\n    283 \r\n    284     def recursive_predict_proba(\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/pipeline/pipeline.py in _recursive_predict(self, tsdataset, predict_length, need_proba)\r\n    404             pre_data = tsdataset_copy\r\n    405         data_pre_transformed, data_pre_transformed_caches = self.transform(tsdataset=pre_data,\r\n--> 406                                                                            cache_transform_steps=True)\r\n    407 \r\n    408         results = []\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlets/pipeline/pipeline.py in transform(self, tsdataset, inplace, cache_transform_steps, previous_caches)\r\n    143         transform_caches = [None] * tansform_list_length\r\n    144         # the first transformer's cache is the origin data\r\n--> 145         if cache_transform_steps and self._transform_list[0].need_previous_data:\r\n    146             transform_caches[0] = tsdataset_transformed\r\n    147 \r\n\r\nIndexError: list index out of range\r\n```",
        "state": "closed",
        "user": "suntao2015005848",
        "closed_by": "Sunting78",
        "created_at": "2023-10-13T03:36:15+00:00",
        "updated_at": "2024-04-22T02:35:24+00:00",
        "closed_at": "2024-04-22T02:35:24+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 455,
        "title": "AutoTS中ray包报错问题",
        "body": "paddlepaddle2.3.0的cpu版本，paddlets1.1.0，ray2.4.0，导入AutoTS时出现no module named \"ray.exceptions\"问题",
        "state": "closed",
        "user": "AndyLu523",
        "closed_by": "AndyLu523",
        "created_at": "2023-10-16T07:17:48+00:00",
        "updated_at": "2023-10-25T06:10:53+00:00",
        "closed_at": "2023-10-25T06:10:53+00:00",
        "comments_count": [
            "suntao2015005848"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 457,
        "title": "The time_col can't be the type of numpy.integer, and it must be the type of numpy.datetime64",
        "body": "指令\r\n`%cd /home/aistudio/PaddleTS-main`\r\n`!python3 train.py --config configs/classification/timesnet_Heartbeat.yaml --task classification --time_feat `\r\n\r\n报错\r\n/home/aistudio/PaddleTS-main\r\n/home/aistudio/PaddleTS-main/paddlets/utils/backtest.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import defaultdict, Iterable\r\n[2023-10-21 14:23:29,419] [__main__] [INFO] {'dic': {'batch_size': 16, 'seq_len': 96, 'predict_len': 0, 'label_len': 0, 'do_eval': True, 'epoch': 30, 'training': True, 'eval_metrics': ['acc'], 'dataset': {'name': 'Heartbeat'}, 'model': {'name': 'TimesNetModel', 'model_cfg': {'e_layers': 2, 'num_kernels': 6, 'd_model': 64, 'd_ff': 64, 'top_k': 1, 'window_sampling_limit': None, 'optimizer_params': {'learning_rate': 0.001}}}, 'loss': 'CE', 'test': {'stride': 1}, 'output': 'output/'}}\r\n[2023-10-21 14:24:29,459] [__main__] [INFO] data scale done!\r\n[2023-10-21 14:24:29,459] [__main__] [INFO] generate times feature\r\n[2023-10-21 14:24:29,550] [paddlets] [ERROR] ValueError: The time_col can't be the type of numpy.integer, and it must be the type of numpy.datetime64\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 171, in <module>\r\n    main(args)\r\n  File \"train.py\", line 137, in main\r\n    ts_train = time_feature_generator.fit_transform(ts_train)\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/transform/base.py\", line 180, in fit_transform\r\n    return self.fit(dataset).transform(dataset, inplace)\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/transform/base.py\", line 112, in transform\r\n    return [self.transform_one(data, inplace) for data in dataset]\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/transform/base.py\", line 112, in <listcomp>\r\n    return [self.transform_one(data, inplace) for data in dataset]\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/logger/logger.py\", line 26, in wrapper\r\n    result = f(*args, **kwargs)\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/transform/time_feature.py\", line 320, in transform_one\r\n    \"The time_col can't be the type of numpy.integer, and it must be the type of numpy.datetime64\"\r\n  File \"/home/aistudio/PaddleTS-main/paddlets/logger/logger.py\", line 110, in raise_log\r\n    raise exception\r\nValueError: The time_col can't be the type of numpy.integer, and it must be the type of numpy.datetime64\r\n",
        "state": "closed",
        "user": "yonuyeung",
        "closed_by": "Sunting78",
        "created_at": "2023-10-21T06:44:55+00:00",
        "updated_at": "2024-03-04T13:05:22+00:00",
        "closed_at": "2024-03-04T13:05:22+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 458,
        "title": "NHiTSModel模型fit时候加入验证集报错。",
        "body": "```\r\n#Pipeline训练\r\n\r\nimport pandas as pd\r\n\r\nfrom paddlets.pipeline.pipeline import Pipeline\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport datetime\r\nimport paddlets\r\nfrom paddlets import TSDataset\r\nfrom paddlets import TimeSeries\r\nfrom paddlets.models.forecasting.dl import * #引入了全部预测模型\r\nfrom paddlets.models.forecasting import * #引入了全部预测模型\r\nfrom paddlets.transform import OneHot, StandardScaler,TimeFeatureGenerator ,KSigma,MinMaxScaler\r\nfrom paddlets.metrics import MSE, MAE\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\nfrom paddlets.automl.autots import AutoTS\r\nimport os \r\nfrom paddlets.automl.autots import SearchSpaceConfiger\r\nfrom ray.tune import uniform, qrandint, choice,quniform\r\nfrom paddlets.transform import TimeFeatureGenerator\r\n\r\n# 读取CSV文件\r\ndf = pd.read_csv('/home/aistudio/ydl/fh_power_data.csv')\r\ndf = df.filter(items=['monitorTime', 'presentValue'])\r\n\r\ntarget_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    known_cov_cols=['monitorTime'],\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)    \r\n# 是否是工作日\r\ntime_feature_generator = TimeFeatureGenerator(feature_cols=['is_workday','weekday','hour'])\r\ntarget_cov_dataset = time_feature_generator.fit_transform(target_cov_dataset)\r\n\r\n\r\n\r\ndf_2 =  target_cov_dataset.to_dataframe()\r\ndf_2['weekday'] = df_2['weekday'].astype(float)\r\ndf_2['hour'] = df_2['hour'].astype(float)\r\n\r\ntarget_cov_dataset_1 = TSDataset.load_from_dataframe(\r\n    df_2,\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    known_cov_cols=['is_workday','weekday','hour'],\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)  \r\n\r\n\r\nval_dataset = TSDataset.load_from_csv(\r\n    filepath_or_buffer=\"/home/aistudio/ydl/val_test.csv\",\r\n    time_col='monitorTime',\r\n    target_cols='presentValue',\r\n    known_cov_cols=['is_workday','weekday','hour'],\r\n    freq='5min',\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)  \r\n\r\npipeline_list = [\r\n    (NHiTSModel , {\r\n    'eval_metrics': [\"mse\", \"mae\"],\r\n    'batch_size': 256, \r\n    'max_epochs': 10, \r\n    'patience': 10,\r\n    'sampling_stride': 12,\r\n    'in_chunk_len': 288,# 输入序列的长度\r\n    'out_chunk_len':288,# 输出序列的长度\r\n    'verbose':1,# 打印日志的详细程度，这里设置为1\r\n    })\r\n]\r\n\r\n\r\npipeline =  Pipeline(pipeline_list)\r\n\r\npipeline.fit(target_cov_dataset_1)\r\npipeline.save(path=\"/home/aistudio/ydl/model_nhits/in288_out288_autots/\")\r\n\r\n```\r\n报错：\r\n```\r\nopt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\r\n    719         if force_all_finite:\r\n    720             _assert_all_finite(array,\r\n--> 721                                allow_nan=force_all_finite == 'allow-nan')\r\n    722 \r\n    723     if ensure_min_samples > 0:\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py in _assert_all_finite(X, allow_nan, msg_dtype)\r\n    104                     msg_err.format\r\n    105                     (type_err,\r\n--> 106                      msg_dtype if msg_dtype is not None else X.dtype)\r\n    107             )\r\n    108     # for object dtype data, we only check for NaNs (GH-13254)\r\n\r\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\r\n```",
        "state": "closed",
        "user": "suntao2015005848",
        "closed_by": "Sunting78",
        "created_at": "2023-10-26T08:21:39+00:00",
        "updated_at": "2024-03-01T06:10:49+00:00",
        "closed_at": "2024-03-01T06:10:49+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 460,
        "title": "训练无报错，自动关闭程序",
        "body": "import socket\r\nimport pandas as pd\r\nimport json\r\nfrom paddlets import TSDataset\r\nfrom paddlets.models.forecasting import MLPRegressor\r\nimport paddlets\r\nprint(paddlets.__version__)\r\n\r\nmlp = MLPRegressor(in_chunk_len=30, out_chunk_len=1, max_epochs=100)\r\ndata = pd.read_excel(r\"D:\\Yy\\Downloads\\Newflow.xls\")\r\ndata['flow'] = data['flow'].astype('float64')\r\ncustom_dataset = TSDataset.load_from_dataframe(data, time_col='time_flag', target_cols='flow', freq='1min')\r\nmlp.fit(custom_dataset)\r\nsubset_test_pred_dataset = mlp.recursive_predict(custom_dataset, 30)\r\n\r\n\r\nprint(\"subset_test_pred_dataset     ↓↓↓  \\n      \")\r\nprint(subset_test_pred_dataset)\r\n# Get the predictions as a JSON-formatted string\r\nprint(\"--------------------------------------------------------------------\")\r\nsubset_test_pred_dataset.target.data.reset_index(inplace=True)\r\nsubset_test_pred_dataset.target.data.columns = [\"time_flag\", \"flow\"]\r\n\r\nprint(subset_test_pred_dataset.target.data)\r\n\r\nformatted_predictions = str({\"predict\": [{\"time_flag\": str(entry[\"time_flag\"]), \"flow\": int(entry[\"flow\"])} for _, entry in subset_test_pred_dataset.target.data.iterrows()]}) + \"\\r\\n\"\r\nprint(formatted_predictions)\r\n\r\n\r\n没有报错，打印了数据信息后  到了fit以后就打印了如下信息就自动关闭程序了\r\n[2023-11-03 14:36:58,262] [paddlets.models.forecasting.dl.paddle_base_impl] [WARNING] No early stopping will be performed, last training weights will be used.\r\nW1103 14:36:58.309204 25456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.1, Runtime API Version: 11.7\r\nW1103 14:36:58.371068 25456 gpu_resources.cc:149] device: 0, cuDNN Version: 8.4.",
        "state": "closed",
        "user": "xiaoyao123456789",
        "closed_by": "Sunting78",
        "created_at": "2023-11-03T06:37:49+00:00",
        "updated_at": "2024-02-28T09:30:22+00:00",
        "closed_at": "2024-02-28T09:30:22+00:00",
        "comments_count": [
            "JackieLieu",
            "JackieLieu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 461,
        "title": "[paddlets.__call__():89] [ERROR] ValueError: attr: shape doesn't exist!",
        "body": "paddlepaddle 版本 2.4.2   paddlets 版本1.1.0  python 版本 3.8\r\n\r\n运行官网demo时总是报以下警告：\r\n1、  [paddlets.__call__():89] [ERROR] ValueError: attr: shape doesn't exist!\r\n2、\r\n\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\pandas.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  version = LooseVersion(pd.__version__)\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\pandas.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  pandas_lt_1_0_0 = version < LooseVersion('1.0.0')\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\pandas.py:15: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  pandas_lt_25_0 = version < LooseVersion('0.25.0')\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\pandas.py:16: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  pandas_gte_23_0 = version >= LooseVersion('0.23.0')\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\scipy.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  SP_VERSION = LooseVersion(scipy.__version__)\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\scipy.py:7: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  SCIPY_11 = SP_VERSION < LooseVersion(\"1.2.0\")\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\scipy.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  SCIPY_GT_14 = SP_VERSION >= LooseVersion(\"1.5\")\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\scipy.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  SP_LT_15 = SP_VERSION < LooseVersion(\"1.5\")\r\nC:\\Users\\wyd_h\\.conda\\envs\\python3.8\\lib\\site-packages\\statsmodels\\compat\\numpy.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  NP_LT_114 = LooseVersion(np.__version__) < LooseVersion('1.14')",
        "state": "closed",
        "user": "JackieLieu",
        "closed_by": "Sunting78",
        "created_at": "2023-11-12T13:56:02+00:00",
        "updated_at": "2024-03-04T13:04:01+00:00",
        "closed_at": "2024-03-04T13:04:01+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 424,
        "title": "项目组什么时候发布新版本更新？",
        "body": "paddlets易用性很好，不过相比其它同类库功能还不够强大，请问项目组什么时候发布新版本更新？",
        "state": "closed",
        "user": "cgd139",
        "closed_by": "Sunting78",
        "created_at": "2023-07-17T02:20:13+00:00",
        "updated_at": "2024-03-04T10:57:52+00:00",
        "closed_at": "2024-03-04T10:57:52+00:00",
        "comments_count": [
            "Sunting78",
            "HaveF",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 435,
        "title": "mac M2芯片无法安装",
        "body": "paddlets要求的statsmodels为0.12.2，mac M2环境无法安装改版本的statsmodels",
        "state": "closed",
        "user": "m729448362",
        "closed_by": "Sunting78",
        "created_at": "2023-08-01T09:12:06+00:00",
        "updated_at": "2024-03-01T06:16:33+00:00",
        "closed_at": "2024-03-01T06:16:33+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 443,
        "title": "plot()方法无法显示图片，命令行报错shape doesn't exist!",
        "body": "环境是我新建的一个conda环境，运行了如下命令：\r\nconda create -n pts python=3.8 # 创建环境\r\npython -m pip install paddlepaddle==2.5.1 -i https://mirror.baidu.com/pypi/simple # 部署paddle\r\npip install paddlets -i https://mirror.baidu.com/pypi/simple # 部署paddlets\r\n\r\n程序是paddlets官方文档中2.2 构建自定义数据集的例子\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/33619303/439f9204-2f1f-4e87-8309-99cc98d02827)\r\n",
        "state": "closed",
        "user": "IAmMsx",
        "closed_by": "Sunting78",
        "created_at": "2023-08-09T09:16:53+00:00",
        "updated_at": "2024-05-07T03:55:59+00:00",
        "closed_at": "2024-05-07T03:55:59+00:00",
        "comments_count": [
            "IAmMsx",
            "IAmMsx",
            "Sunting78",
            "dsqzhou",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 456,
        "title": "请问一下TSDataset中的 features_cols 和 观测协变量有什么区别？",
        "body": "加入features_cols是否就是进行MS任务？\r\n哪些模型支持加入Features_cols呢？",
        "state": "closed",
        "user": "YuboCoco",
        "closed_by": "Sunting78",
        "created_at": "2023-10-19T01:40:01+00:00",
        "updated_at": "2024-03-04T10:55:08+00:00",
        "closed_at": "2024-03-04T10:55:08+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 453,
        "title": "模型集成到Flask框架中去预测时候，每次启动项目报错。No stack trace in paddle, may be caused by external reasons.",
        "body": "docker环境中运行：\r\npaddlets：1.1.0\r\npaddlepaddle: 2.4.0\r\naiosignal            1.3.1\r\nalembic              1.11.2\r\naniso8601            9.0.1\r\nAPScheduler          3.10.4\r\nastor                0.8.1\r\nattrs                23.1.0\r\nbackcall             0.2.0\r\nbackports.zoneinfo   0.2.1\r\ncachelib             0.9.0\r\ncertifi              2023.7.22\r\ncharset-normalizer   3.2.0\r\nchinese-calendar     1.8.0\r\nclick                8.0.4\r\ncloudpickle          2.2.1\r\ncmaes                0.10.0\r\ncolorama             0.4.6\r\ncolorlog             6.7.0\r\nConfigSpace          0.7.1\r\ncycler               0.11.0\r\nDBUtils              3.0.3\r\ndecorator            5.1.1\r\ndistlib              0.3.7\r\nfilelock             3.12.2\r\nFLAML                1.2.4\r\nFlask                2.2.5\r\nFlask-Caching        2.0.2\r\nFlask-Cors           4.0.0\r\nflask-restx          1.1.0\r\nfonttools            4.38.0\r\nfrozenlist           1.3.3\r\ngreenlet             2.0.2\r\ngrpcio               1.43.0\r\nhpbandster           0.7.4\r\nidna                 3.4\r\nimportlib-metadata   6.7.0\r\nimportlib-resources  5.12.0\r\nipython              7.34.0\r\nitsdangerous         2.1.2\r\nJayDeBeApi           1.2.3\r\njedi                 0.19.0\r\nJinja2               3.1.2\r\njoblib               1.3.2\r\nJPype1               1.4.1\r\njsonschema           4.17.3\r\nkiwisolver           1.4.4\r\nlightgbm             4.0.0\r\nllvmlite             0.39.1\r\nlxml                 4.9.3\r\nMako                 1.2.4\r\nMarkupSafe           2.1.3\r\nmatplotlib           3.5.3\r\nmatplotlib-inline    0.1.6\r\nmore-itertools       9.1.0\r\nmsgpack              1.0.5\r\nnetifaces            0.11.0\r\nnumba                0.56.4\r\nnumpy                1.19.5\r\nopt-einsum           3.3.0\r\noptuna               3.3.0\r\npackaging            23.1\r\npaddle-bfloat        0.1.7\r\npandas               1.3.5\r\nparso                0.8.3\r\npatsy                0.5.3\r\npexpect              4.8.0\r\npickleshare          0.7.5\r\nPillow               9.5.0\r\npip                  23.2.1\r\npkgutil_resolve_name 1.3.10\r\nplatformdirs         3.10.0\r\nprompt-toolkit       3.0.39\r\nprotobuf             3.20.0\r\nptyprocess           0.7.0\r\nPygments             2.16.1\r\npyod                 1.1.0\r\npyparsing            3.1.1\r\nPyro4                4.82\r\npyrsistent           0.19.3\r\npython-dateutil      2.8.2\r\npython-docx          0.8.11\r\npytz                 2023.3\r\nPyWavelets           1.3.0\r\nPyYAML               6.0.1\r\nray                  1.13.0\r\nrequests             2.31.0\r\nscikit-learn         1.0.2\r\nscipy                1.7.3\r\nseaborn              0.12.2\r\nserpent              1.41\r\nsetuptools           41.6.0\r\nshap                 0.42.1\r\nsix                  1.16.0\r\nslicer               0.0.7\r\nSQLAlchemy           2.0.19\r\nstatsmodels          0.12.2\r\ntabulate             0.9.0\r\ntensorboardX         2.6.2\r\nthreadpoolctl        3.1.0\r\ntqdm                 4.66.1\r\ntraitlets            5.9.0\r\ntyping_extensions    4.7.1\r\ntzdata               2023.3\r\ntzlocal              5.0.1\r\nurllib3              2.0.4\r\nvirtualenv           20.24.2\r\nwcwidth              0.2.6\r\nWerkzeug             2.2.3\r\nwheel                0.33.6\r\nxgboost              1.6.2\r\nzipp                 3.15.0\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/0c89d847-1db4-4d02-869d-6b6514368f00)\r\n报错后，会在项目根目录下出现一个core文件，大约占用2.3g。\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/49387197/07309506-ea81-4311-93a9-8d018b0833ea)\r\n",
        "state": "closed",
        "user": "suntao2015005848",
        "closed_by": "Sunting78",
        "created_at": "2023-09-22T08:30:37+00:00",
        "updated_at": "2024-03-28T08:02:15+00:00",
        "closed_at": "2024-03-28T08:02:14+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 446,
        "title": "ensemble模型保存成文件后再加载预测报错",
        "body": "保存方式:\r\n<img width=\"751\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/10610290/cde6d45f-ac10-4dce-8438-406dacf0a2a3\">\r\n\r\n加载方式:\r\n<img width=\"662\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleTS/assets/10610290/04aee46d-a9d3-46e0-9a53-51b6b38e54bd\">\r\n\r\n\r\nline 125, in _predict_estimators\r\n    for estimator in self._estimators:\r\nTypeError: 'int' object is not iterable",
        "state": "closed",
        "user": "kingwpf",
        "closed_by": "kingwpf",
        "created_at": "2023-08-24T06:30:12+00:00",
        "updated_at": "2023-09-18T02:11:28+00:00",
        "closed_at": "2023-09-18T02:11:28+00:00",
        "comments_count": [
            "kingwpf",
            "kingwpf",
            "BowenFF",
            "kingwpf"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 459,
        "title": "3D点云训练报错",
        "body": "------------------------------------------------\r\nD:\\JJH\\PaddleX_DeskTop\\resources\\codelab\\lib\\site-packages\\paddle\\io\\reader.py:433: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\r\n  warnings.warn(\r\n2023-11-01 12:46:31,104 -  WARNING - No custom op voxelize found, try JIT build\r\n[2023-11-01 12:46:32,062] [    INFO] dist.py:985 - running build\r\n[2023-11-01 12:46:32,063] [    INFO] dist.py:985 - running build_ext\r\nD:\\JJH\\PaddleX_DeskTop\\resources\\codelab\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:1438: UserWarning: Failed to check compiler version for cl: [WinError 2] ϵͳ�Ҳ���ָ�����ļ���\r\n  warnings.warn(\r\n2023-11-01 12:46:32,192 -     INFO - voxelize builded success!\r\nTraceback (most recent call last):\r\n  File \"d:\\JJH\\Paddle_workspace\\7115943\\1\\run_paddlex.py\", line 98, in <module>\r\n    runner.run()\r\n  File \"d:\\JJH\\Paddle_workspace\\7115943\\1\\base\\base_run_paddlex.py\", line 402, in run\r\n    self.run_train()\r\n  File \"d:\\JJH\\Paddle_workspace\\7115943\\1\\run_paddlex.py\", line 50, in run_train\r\n    self.uapi_model.train(\r\n  File \"uapi\\cv_uapi\\paddle3d_uapi\\pc_det\\model.py\", line 102, in uapi.cv_uapi.paddle3d_uapi.pc_det.model.PCDetModel.train\r\n  File \"uapi\\cv_uapi\\paddle3d_uapi\\pc_det\\model.py\", line 104, in uapi.cv_uapi.paddle3d_uapi.pc_det.model.PCDetModel.train\r\n  File \"uapi\\cv_uapi\\paddle3d_uapi\\pc_det\\model.py\", line 115, in uapi.cv_uapi.paddle3d_uapi.pc_det.model.PCDetModel.train\r\n  File \"uapi\\cv_uapi\\paddle3d_uapi\\pc_det\\runner.py\", line 29, in uapi.cv_uapi.paddle3d_uapi.pc_det.runner.PCDetRunner.train\r\n  File \"uapi\\base\\runner.py\", line 343, in uapi.base.runner.BaseRunner.run_cmd\r\nuapi.base.utils.errors.CalledProcessError: Command ['D:\\\\JJH\\\\PaddleX_DeskTop\\\\resources\\\\codelab\\\\python.exe', 'tools/train.py', '--do_eval', '--config', 'C:\\\\Users\\\\Administrator\\\\.paddle_uapi\\\\tmpwfncvzbu\\\\pcdetmodel_CenterPoint_pillars_02voxel.yml', '--batch_size', '4', '--model', 'https://paddle-model-ecology.bj.bcebos.com/uapi/infer_fd/centerpoint_pillars_02voxel/centerpoint_pillars_02voxel_nuscenes_10sweep.pdparams', '--save_dir', 'D:\\\\JJH\\\\Paddle_workspace\\\\7115943\\\\1\\\\output'] returned non-zero exit status 3221225477.\r\nPS D:\\JJH\\Paddle_workspace\\7115943\\1>",
        "state": "closed",
        "user": "LeeGeong",
        "closed_by": "Sunting78",
        "created_at": "2023-11-01T04:57:04+00:00",
        "updated_at": "2024-01-18T09:58:00+00:00",
        "closed_at": "2024-01-18T09:58:00+00:00",
        "comments_count": [
            "LeeGeong",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 462,
        "title": "使用python 3.10 时 import paddlets报错",
        "body": "### 环境\r\nos: `Ubuntu 22.04.1 LTS`\r\npython: `3.10.13`\r\npaddlepaddle-gpu: `2.5.2.post117`\r\npaddlets: `1.1.0`\r\n\r\n### 复现\r\n```python\r\nfrom paddlets import TSDataset\r\n```\r\n报错：\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nCell In[1], line 1\r\n----> 1 from paddlets import TSDataset\r\n\r\nFile ~/miniconda3/envs/mdm_py310/lib/python3.10/site-packages/paddlets/__init__.py:5\r\n      1 \"\"\"\r\n      2 paddlets\r\n      3 \"\"\"\r\n      4 from paddlets.datasets import TimeSeries, TSDataset\r\n----> 5 from paddlets.pipeline import Pipeline\r\n      7 __version__=\"1.1.0\"\r\n\r\nFile ~/miniconda3/envs/mdm_py310/lib/python3.10/site-packages/paddlets/pipeline/__init__.py:4\r\n      1 \"\"\"\r\n      2 pipeline\r\n      3 \"\"\"\r\n----> 4 from paddlets.pipeline.pipeline import Pipeline\r\n\r\nFile ~/miniconda3/envs/mdm_py310/lib/python3.10/site-packages/paddlets/pipeline/pipeline.py:16\r\n     14 from paddlets.logger.logger import log_decorator\r\n     15 from paddlets.models.model_loader import load as paddlets_model_load\r\n---> 16 from paddlets.utils.utils import get_tsdataset_max_len, split_dataset\r\n     18 logger = Logger(__name__)\r\n     21 class Pipeline(Trainable):\r\n\r\nFile ~/miniconda3/envs/mdm_py310/lib/python3.10/site-packages/paddlets/utils/__init__.py:8\r\n      6 from paddlets.utils.utils import get_uuid\r\n      7 from paddlets.utils.utils import check_model_fitted, check_train_valid_continuity, split_dataset\r\n----> 8 from paddlets.utils.backtest import backtest\r\n      9 from paddlets.utils.validation import cross_validate, fit_and_score\r\n     10 from paddlets.utils.utils import plot_anoms\r\n\r\nFile ~/miniconda3/envs/mdm_py310/lib/python3.10/site-packages/paddlets/utils/backtest.py:6\r\n      4 from typing import List, Dict, Any, Callable, Optional, Tuple, Union\r\n      5 import math\r\n----> 6 from collections import defaultdict, Iterable\r\n      8 import pandas as pd\r\n      9 import numpy as np\r\n\r\nImportError: cannot import name 'Iterable' from 'collections' (/home/hxx/miniconda3/envs/mdm_py310/lib/python3.10/collections/__init__.py)\r\n```\r\n\r\n经查，发现在python 3.10中已经将Iterable从collections移至collections.abc：\r\n[https://docs.python.org/3/whatsnew/3.10.html#removed](https://docs.python.org/3/whatsnew/3.10.html#removed)\r\n\r\nRemove deprecated aliases to [Collections Abstract Base Classes](https://docs.python.org/3/library/collections.abc.html#collections-abstract-base-classes) from the [collections](https://docs.python.org/3/library/collections.html#module-collections) module. (Contributed by Victor Stinner in [bpo-37324](https://bugs.python.org/issue?@action=redirect&bpo=37324).)\r\n\r\n\r\n是时候进行一些兼容性修复工作了？",
        "state": "closed",
        "user": "hxxxxh",
        "closed_by": "Sunting78",
        "created_at": "2023-11-17T08:17:51+00:00",
        "updated_at": "2024-03-04T10:51:54+00:00",
        "closed_at": "2024-03-04T10:51:54+00:00",
        "comments_count": [
            "Sunting78",
            "jzhang533",
            "Sunting78",
            "jzhang533"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 450,
        "title": "模型协变量已知列对预测没有影响。",
        "body": "<b>用MLP/LSTNet等模型进行paddlets训练时添加了已知列（known_cols），但在调用模型预测时，发现已知列的数据对预测结果没有任何影响，甚至待预测数据中没有已知列也不会报错。</b>\r\n\r\n\r\n`\r\n\r\ntsDataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='monitorTime', target_cols='power', freq='5min',\r\n    # known_cov_cols=['fushe'],\r\n    fill_missing_dates=True,\r\n    fillna_method='pre'\r\n)\r\nmod = LSTNetRegressor.load(\"work/lstm_lxh/LSTNetRegressor\")\r\npredict_result = mod.predict(predicted_data)\r\n\r\n`\r\n\r\n<b>known_cov_cols=['fushe'], 该行注释与否对运行和预测结果毫无影响</b>\r\n\r\n\r\n而相同的错误情况，在pipeline训练和预测中就不存在。",
        "state": "closed",
        "user": "Chouett",
        "closed_by": "Sunting78",
        "created_at": "2023-09-15T08:00:57+00:00",
        "updated_at": "2024-03-28T06:29:58+00:00",
        "closed_at": "2024-03-28T06:29:58+00:00",
        "comments_count": [
            "Sunting78",
            "YuboCoco",
            "Sunting78",
            "YuboCoco",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 464,
        "title": "支持序列到序列的预测么",
        "body": "在做地震动力响应问题的预测，本项目如何实现seq2seq的预测呢",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2023-12-16T11:56:04+00:00",
        "updated_at": "2024-02-28T09:30:32+00:00",
        "closed_at": "2024-02-28T09:30:32+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 463,
        "title": "ubuntu 18 + python3.10.10 , pip install paddlets 失败！！！",
        "body": "Collecting statsmodels<=0.12.2,>=0.10.2\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/10/26/0fd61f95667e56fd597ecca715dff3623ed1122b6f895ed2b4dfb54afc04/statsmodels-0.12.2.tar.gz (17.5 MB)\r\n  Installing build dependencies ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × pip subprocess to install build dependencies did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [3592 lines of output]\r\n      Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n      Ignoring numpy: markers 'python_version == \"3.6\"' don't match your environment\r\n      Ignoring numpy: markers 'python_version == \"3.7\"' don't match your environment\r\n      Collecting setuptools\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bb/26/7945080113158354380a12ce26873dd6c1ebd88d47f5bc24e2c5bb38c16a/setuptools-68.2.2-py3-none-any.whl (807 kB)\r\n      Collecting wheel\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fa/7f/4c07234086edbce4a0a446209dc0cb08a19bb206a3ea53b2f56a403f983b/wheel-0.41.3-py3-none-any.whl (65 kB)\r\n      Collecting cython>=0.29.14\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/db/33/7fb241cdb3499078fbd3b0e5f87af1a3114a437e6b75bce80cd2f644cc5a/Cython-3.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n      Collecting numpy==1.17.5\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d9/09/8e89c05abc450ea347f40b4fa917ec5c69b5228da344487f178586a3187c/numpy-1.17.5.zip (6.4 MB)\r\n        Preparing metadata (setup.py): started\r\n        Preparing metadata (setup.py): finished with status 'done'\r\n      Collecting scipy>=1.2\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/18/44/7e8d208eb59a8224fcc474415104f13be9b378be8da63f76dfde12ec2b44/scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a8/cc/c36f3439f5d47c3b13833ce6687b43a040cc7638c502ac46b41e2d4f3d6f/scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/14/f2/10fa23f0a6b9b2439c01579ae4a9b1849d4822e972515c8f92584bfda5e9/scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1f/4b/3bacad9a166350cb2e518cea80ab891016933cc1653f15c90279512c5fa9/scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/22/287d06df9b359ba6df3f986e83267f240132379e4181c43cead3c5d41227/scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/59/0b/8a9acfc5c36bbf6e18d02f3a08db5b83bebba510be2df3230f53852c74a4/scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e9/05/3ce7e813ee0666fc10ede875da17d8d5671b774491dcfb4be176c3a880e2/scipy-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c2/89/37b6e11bfe24e96a375fc39e6ffb6c2f27ff795cfb735ae83130e0bf78b5/scipy-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e7/cc/82a1ce76bb5b6177fdd5d0f98e2953436abcdfdaa4412d45b54e75821bad/scipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\r\n        Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/fe/72b611ba221c3367b06163992af4807515d6e0e09b3b9beee8ec22162d6f/scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\r\n      Building wheels for collected packages: numpy\r\n        Building wheel for numpy (setup.py): started\r\n        Building wheel for numpy (setup.py): finished with status 'error'\r\n        error: subprocess-exited-with-error\r\n      \r\n        × python setup.py bdist_wheel did not run successfully.\r\n        │ exit code: 1\r\n        ╰─> [3082 lines of output]\r\n            Running from numpy source directory.\r\n            blas_opt_info:\r\n            blas_mkl_info:\r\n            customize UnixCCompiler\r\n              FOUND:\r\n                libraries = ['mkl_rt', 'pthread']\r\n                library_dirs = ['/home/grow/anaconda3/envs/diffusionenv/lib']\r\n                define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\r\n                include_dirs = ['/usr/local/include', '/usr/include', '/home/grow/anaconda3/envs/diffusionenv/include']\r\n      \r\n              FOUND:\r\n                libraries = ['mkl_rt', 'pthread']\r\n                library_dirs = ['/home/grow/anaconda3/envs/diffusionenv/lib']\r\n                define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\r\n                include_dirs = ['/usr/local/include', '/usr/include', '/home/grow/anaconda3/envs/diffusionenv/include']\r\n      \r\n            /bin/sh: 1: svnversion: not found\r\n            non-existing path in 'numpy/distutils': 'site.cfg'\r\n            lapack_opt_info:\r\n            lapack_mkl_info:\r\n            customize UnixCCompiler\r\n              FOUND:\r\n                libraries = ['mkl_rt', 'pthread']\r\n                library_dirs = ['/home/grow/anaconda3/envs/diffusionenv/lib']\r\n                define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\r\n                include_dirs = ['/usr/local/include', '/usr/include', '/home/grow/anaconda3/envs/diffusionenv/include']\r\n      \r\n              FOUND:\r\n                libraries = ['mkl_rt', 'pthread']\r\n                library_dirs = ['/home/grow/anaconda3/envs/diffusionenv/lib']\r\n                define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\r\n                include_dirs = ['/usr/local/include', '/usr/include', '/home/grow/anaconda3/envs/diffusionenv/include']\r\n      \r\n            /home/grow/anaconda3/envs/diffusionenv/lib/python3.10/site-packages/setuptools/_distutils/dist.py:265: UserWarning: Unknown distribution option: 'define_macros'\r\n              warnings.warn(msg)\r\n            running bdist_wheel\r\n            running build\r\n            running config_cc\r\n            unifing config_cc, config, build_clib, build_ext, build commands --compiler options\r\n            running config_fc\r\n            unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\r\n            running build_src\r\n            build_src\r\n            building py_modules sources\r\n            creating build\r\n            creating build/src.linux-x86_64-3.1\r\n            creating build/src.linux-x86_64-3.1/numpy\r\n            creating build/src.linux-x86_64-3.1/numpy/distutils\r\n            building library \"npymath\" sources\r\n            get_default_fcompiler: matching types: '['gnu95', 'intel', 'lahey', 'pg', 'absoft', 'nag', 'vast', 'compaq', 'intele', 'intelem', 'gnu', 'g95', 'pathf95', 'nagfor']'\r\n            customize Gnu95FCompiler\r\n            Could not locate executable gfortran\r\n            Could not locate executable f95\r\n            customize IntelFCompiler\r\n            Could not locate executable ifort\r\n            Could not locate executable ifc\r\n            customize LaheyFCompiler\r\n            Could not locate executable lf95\r\n            customize PGroupFCompiler\r\n            Could not locate executable pgfortran\r\n            customize AbsoftFCompiler\r\n            Could not locate executable f90\r\n            Could not locate executable f77\r\n            customize NAGFCompiler\r\n            customize VastFCompiler\r\n            customize CompaqFCompiler\r\n            Could not locate executable fort\r\n            customize IntelItaniumFCompiler\r\n            Could not locate executable efort\r\n            Could not locate executable efc\r\n            customize IntelEM64TFCompiler\r\n            customize GnuFCompiler\r\n            Could not locate executable g77\r\n            customize G95FCompiler\r\n            Could not locate executable g95\r\n            customize PathScaleFCompiler\r\n            Could not locate executable pathf95\r\n            customize NAGFORCompiler\r\n            Could not locate executable nagfor\r\n            don't know how to compile Fortran code on platform 'posix'\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat _configtest.o -o _configtest\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d _configtest\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’ [-Wbuiltin-declaration-mismatch]\r\n             int exp (void);\r\n                 ^~~\r\n            gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat _configtest.o -o _configtest\r\n            /home/grow/anaconda3/envs/diffusionenv/compiler_compat/ld: _configtest.o: in function `main':\r\n            _configtest.c:(.text.startup+0x5): undefined reference to `exp'\r\n            collect2: error: ld returned 1 exit status\r\n            failure.\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’ [-Wbuiltin-declaration-mismatch]\r\n             int exp (void);\r\n                 ^~~\r\n            gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat _configtest.o -lm -o _configtest\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d _configtest\r\n            creating build/src.linux-x86_64-3.1/numpy/core\r\n            creating build/src.linux-x86_64-3.1/numpy/core/src\r\n            creating build/src.linux-x86_64-3.1/numpy/core/src/npymath\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npymath/npy_math_internal.h\r\n              adding 'build/src.linux-x86_64-3.1/numpy/core/src/npymath' to include_dirs.\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npymath/ieee754.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npymath/npy_math_complex.c\r\n            None - nothing done with h_files = ['build/src.linux-x86_64-3.1/numpy/core/src/npymath/npy_math_internal.h']\r\n            building library \"npysort\" sources\r\n            creating build/src.linux-x86_64-3.1/numpy/core/src/common\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/common/npy_sort.h\r\n              adding 'build/src.linux-x86_64-3.1/numpy/core/src/common' to include_dirs.\r\n            creating build/src.linux-x86_64-3.1/numpy/core/src/npysort\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/quicksort.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/mergesort.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/timsort.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/heapsort.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/radixsort.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/common/npy_partition.h\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/selection.c\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/common/npy_binsearch.h\r\n            conv_template:> build/src.linux-x86_64-3.1/numpy/core/src/npysort/binsearch.c\r\n            None - nothing done with h_files = ['build/src.linux-x86_64-3.1/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.1/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.1/numpy/core/src/common/npy_binsearch.h']\r\n            building extension \"numpy.core._dummy\" sources\r\n            Generating build/src.linux-x86_64-3.1/numpy/core/include/numpy/config.h\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c:1:10: fatal error: sys/endian.h: No such file or directory\r\n             #include <sys/endian.h>\r\n                      ^~~~~~~~~~~~~~\r\n            compilation terminated.\r\n            failure.\r\n            removing: _configtest.c _configtest.o\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 4)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            success!\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];\r\n                            ^~~~~~~~~~\r\n            removing: _configtest.c _configtest.o _configtest.o.d\r\n            C compiler: gcc -pthread -B /home/grow/anaconda3/envs/diffusionenv/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC -O2 -isystem /home/grow/anaconda3/envs/diffusionenv/include -fPIC\r\n      \r\n            compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/grow/anaconda3/envs/diffusionenv/include/python3.10 -c'\r\n            gcc: _configtest.c\r\n            _configtest.c: In function ‘main’:\r\n            _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]\r\n                 static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];\r\n                            ^~~~~~~~~~\r\n。。。。。",
        "state": "closed",
        "user": "david-95",
        "closed_by": "Sunting78",
        "created_at": "2023-11-18T13:34:59+00:00",
        "updated_at": "2024-02-28T09:32:56+00:00",
        "closed_at": "2024-02-28T09:32:56+00:00",
        "comments_count": [
            "Sunting78",
            "tinycen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 465,
        "title": "无法安装PaddleTS库",
        "body": "报错如下:\r\n            gcc: numpy/core/src/common/ufunc_override.c\r\n            gcc: numpy/core/src/common/numpyos.c\r\n            gcc: numpy/core/src/umath/cpuid.c\r\n            gcc: numpy/core/src/umath/ufunc_type_resolution.c\r\n            gcc: numpy/core/src/umath/override.c\r\n            gcc: numpy/core/src/multiarray/mapping.c\r\n            gcc: numpy/core/src/multiarray/methods.c\r\n            gcc: build/src.linux-x86_64-3.1/numpy/core/src/umath/matmul.c\r\n            gcc: build/src.linux-x86_64-3.1/numpy/core/src/umath/clip.c\r\n            error: Command \"gcc -pthread -B /opt/conda/envs/python35-paddle120-env/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/python35-paddle120-env/include -fPIC -O2 -isystem /opt/conda/envs/python35-paddle120-env/include -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.1/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.1/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/envs/python35-paddle120-env/include/python3.10 -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64\r\n            [end of output]\r\n      \r\n        note: This error originates from a subprocess, and is likely not a problem with pip.\r\n        ERROR: Failed building wheel for numpy\r\n        Running setup.py clean for numpy\r\n        error: subprocess-exited-with-error\r\n      \r\n        × python setup.py clean did not run successfully.\r\n        │ exit code: 1\r\n        ╰─> [10 lines of output]\r\n            Running from numpy source directory.\r\n           \r\n            `setup.py clean` is not supported, use one of the following instead:\r\n           \r\n              - `git clean -xdf` (cleans all files)\r\n              - `git clean -Xdf` (cleans all versioned files, doesn't touch\r\n                                  files that aren't checked into the git repo)\r\n           \r\n            Add `--force` to your command to use it anyway if you must (unsupported).\r\n           \r\n            [end of output]\r\n      \r\n        note: This error originates from a subprocess, and is likely not a problem with pip.\r\n        ERROR: Failed cleaning build dir for numpy\r\n      Failed to build numpy\r\n      ERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\r\n      \r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× pip subprocess to install build dependencies did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\nNote: you may need to restart the kernel to use updated packages.\r\n\r\n看提示是numpy的问题,但是实际上感觉不是numpy的问题,单独安装numpy也不行.大部分的环境都测试了.还是有问题,包括mac, linux下的3.8.13的python和3.10的python, 包括AI Studio上的GPU和CPU环境都不行,看了一下python的版本是3.10.10,paddle的cpu和gpu版本都是2.5.2\r\n",
        "state": "closed",
        "user": "fireinwind",
        "closed_by": "Sunting78",
        "created_at": "2023-12-18T09:07:54+00:00",
        "updated_at": "2024-02-28T09:31:30+00:00",
        "closed_at": "2024-02-28T09:31:30+00:00",
        "comments_count": [
            "allentern",
            "rsj123",
            "Sunting78",
            "fireinwind",
            "tinycen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 468,
        "title": "None",
        "body": null,
        "state": "closed",
        "user": "zhizhuaa",
        "closed_by": "zhizhuaa",
        "created_at": "2023-12-27T02:40:41+00:00",
        "updated_at": "2023-12-27T02:42:54+00:00",
        "closed_at": "2023-12-27T02:41:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 466,
        "title": "paddlets的模型怎么通过named_layers获取神经网络的层呢",
        "body": "paddlets的模型怎么通过named_layers获取神经网络的层呢，直接用named_layers函数报错没有这个attribute，请问应该用什么呢？",
        "state": "closed",
        "user": "Laurazlj",
        "closed_by": "Sunting78",
        "created_at": "2023-12-22T08:00:28+00:00",
        "updated_at": "2024-05-07T03:57:00+00:00",
        "closed_at": "2024-05-07T03:57:00+00:00",
        "comments_count": [
            "Sunting78",
            "Laurazlj",
            "Sunting78",
            "Laurazlj",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 469,
        "title": "建议把iTransformer也加入进来",
        "body": "有段时间没有更新了，建议把iTransformer也纳入进来，体现ppts的持续进化",
        "state": "closed",
        "user": "allentern",
        "closed_by": "Sunting78",
        "created_at": "2024-01-04T10:59:14+00:00",
        "updated_at": "2024-02-28T09:33:48+00:00",
        "closed_at": "2024-02-28T09:33:48+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 471,
        "title": "具体哪些模型支持静态协变量？",
        "body": "具体哪些模型支持静态协变量呢？是只有rnn支持么",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "IgnoranceSmile",
        "created_at": "2024-02-19T02:45:41+00:00",
        "updated_at": "2024-03-01T01:33:27+00:00",
        "closed_at": "2024-03-01T01:33:27+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 470,
        "title": "支持多变量时间序列预测吗",
        "body": "如题",
        "state": "closed",
        "user": "weidongzhou1994",
        "closed_by": "Sunting78",
        "created_at": "2024-02-06T08:32:56+00:00",
        "updated_at": "2024-03-04T10:51:07+00:00",
        "closed_at": "2024-03-04T10:51:07+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 472,
        "title": "静态变量的使用",
        "body": "有人使用静态变量并成功运行过么\r\n我的代码如下：\r\nimport pandas as pd\r\nfrom paddlets import TSDataset\r\n\r\nx = np.linspace(-np.pi, np.pi, 200)\r\nsinx = np.sin(x) * 4 + np.random.randn(200)\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        'time_col': pd.date_range('2022-01-01', periods=200, freq='1h'),\r\n        'value': sinx,\r\n        'known_cov_1': sinx + 4,\r\n        'known_cov_2': sinx + 5,\r\n        'observed_cov': sinx + 8,\r\n        'static_cov': [1 for i in range(200)],\r\n    }\r\n)\r\ntarget_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='time_col',\r\n    target_cols='value',\r\n    known_cov_cols=['known_cov_1', 'known_cov_2'],\r\n    observed_cov_cols='observed_cov',\r\n    static_cov_cols='static_cov',\r\n    freq='1h'\r\n)\r\n\r\ntemporal_fusion_transformer = TFTModel(\r\n    in_chunk_len = in_chunk_len,\r\n    out_chunk_len = out_chunk_len,\r\n    max_epochs=800,\r\n    patience=100\r\n)\r\n\r\ntemporal_fusion_transformer.fit(target_cov_dataset)\r\n报错：\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_43360/875506061.py in <module>\r\n     32 )\r\n     33 \r\n---> 34 temporal_fusion_transformer.fit(target_cov_dataset)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in fit(self, train_tsdataset, valid_tsdataset)\r\n    344             self._check_multi_tsdataset(valid_tsdataset)\r\n    345         train_dataloader, valid_dataloaders = self._init_fit_dataloaders(train_tsdataset, valid_tsdataset)\r\n--> 346         self._fit(train_dataloader, valid_dataloaders)\r\n    347 \r\n    348     def _fit(\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in _fit(self, train_dataloader, valid_dataloaders)\r\n    370             # Call the `on_epoch_begin` method of each callback before the epoch starts.\r\n    371             self._callback_container.on_epoch_begin(epoch_idx)\r\n--> 372             self._train_epoch(train_dataloader)\r\n    373 \r\n    374             # Predict for each eval set.\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in _train_epoch(self, train_loader)\r\n    438             self._callback_container.on_batch_begin(batch_idx)\r\n    439             X, y = self._prepare_X_y(data)\r\n--> 440             batch_logs = self._train_batch(X, y)\r\n...\r\n    208         helper = LayerHelper('embedding', **locals())\r\n\r\nValueError: (InvalidArgument) Variable value (input) of OP(fluid.layers.embedding) expected >= 0 and < 1, but got 1. Please check input value.\r\n  [Hint: Expected ids[i] < row_number, but received ids[i]:1 >= row_number:1.] (at /paddle/paddle/phi/kernels/cpu/embedding_kernel.cc:63)\r\n  [operator < lookup_table_v2 > error]",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2024-02-22T13:17:22+00:00",
        "updated_at": "2024-02-28T09:27:40+00:00",
        "closed_at": "2024-02-28T09:27:40+00:00",
        "comments_count": [
            "Sunting78",
            "IgnoranceSmile",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 473,
        "title": "TFT可以使用XAI中的SHAP方法么？",
        "body": "项目中的TFT是否只能支持区间预测没法改成点预测，在使用TFT模型进行SHAP分析时：\r\nse = ShapExplainer(model, train_data)\r\n会显示报错：\r\n[2024-03-01 01:26:49,864] [paddlets] [ERROR] ValueError: Only support point prediction but not probability prediction!\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_53563/2232659875.py in <module>\r\n      1 # se = ShapExplainer(model, train_data, background_sample_number=100, keep_index=True, use_paddleloader=False)\r\n----> 2 se = ShapExplainer(model, train_data)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/xai/post_hoc/shap_explainer.py in __init__(self, model, background_data, background_sample_number, shap_method, task_type, seed, use_paddleloader, **kwargs)\r\n     77         # Judge whether it is probability prediction\r\n     78         if hasattr(_model_obj, \"_output_mode\"):\r\n---> 79             raise_if(_model_obj._output_mode == 'quantiles', 'Only support point prediction but not probability prediction!')\r\n     80 \r\n     81         # Base parameter\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/logger/logger.py in raise_if(condition, message, logger)\r\n    154 \r\n    155     \"\"\"\r\n--> 156     raise_if_not(not condition, message, logger)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/logger/logger.py in raise_if_not(condition, message, logger)\r\n    133     if not condition:\r\n    134         logger.error(\"ValueError: \" + message)\r\n--> 135         raise ValueError(message)\r\n    136 \r\n    137 \r\n\r\nValueError: Only support point prediction but not probability prediction!\r\n\r\n但是没有找到将TFT改成点预测的方法",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2024-03-01T01:35:45+00:00",
        "updated_at": "2024-06-13T04:10:27+00:00",
        "closed_at": "2024-06-13T04:10:27+00:00",
        "comments_count": [
            "Sunting78",
            "IgnoranceSmile"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 474,
        "title": "XAI模块是不可以分析static_cov的么",
        "body": "代码：\r\nse = ShapExplainer(model, train_data)\r\nshap_value = se.explain(train_data, nsamples=100)\r\nse.summary_plot(out_chunk_indice=1, sample_index=0)\r\n报错：\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n/tmp/ipykernel_79237/4214853139.py in <module>\r\n----> 1 se.summary_plot(out_chunk_indice=1, sample_index=0)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/xai/post_hoc/shap_explainer.py in summary_plot(self, out_chunk_indice, sample_index, **kwargs)\r\n    407             for j in range(self.shap_value.shape[3]):\r\n    408                 feature_names.append('%s:%s_lag_%d' % (self.unique_cols[j], \r\n--> 409                                                        self.key_feature[self.unique_cols[j]].split('_')[0],\r\n    410                                                        i - self._in_chunk_len + 1))\r\n    411         if self.shap_method == 'kernel':\r\n\r\nKeyError: 'static_cov'",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2024-03-01T07:19:00+00:00",
        "updated_at": "2024-03-28T08:03:11+00:00",
        "closed_at": "2024-03-28T08:03:11+00:00",
        "comments_count": [
            "a31413510",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 475,
        "title": "corssformer",
        "body": "我在训练corssformer过程中出现了win_size的错误",
        "state": "closed",
        "user": "kangning476",
        "closed_by": "Sunting78",
        "created_at": "2024-03-03T13:36:16+00:00",
        "updated_at": "2024-03-28T08:03:32+00:00",
        "closed_at": "2024-03-28T08:03:31+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 476,
        "title": "TFT模型可以修改为点预测么？",
        "body": "请问，目前TFT是否只能支持区间预测而不能修改为点预测，进而无法使用仓库内的AutoTS和XAI模块？",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "IgnoranceSmile",
        "created_at": "2024-03-04T02:45:41+00:00",
        "updated_at": "2024-03-20T05:16:50+00:00",
        "closed_at": "2024-03-20T05:16:50+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 477,
        "title": "model.save",
        "body": "使用configs.longterm_forecast下的Crossformer_ECL.yml配置文件，运行train.py脚本，执行训练。发现没有保存模型的代码。在model.fit(ts_train,ts_val)代码后加入model.save(\"./Crossformer\",network_model=Ture,dygraph_to_static=True).运行报错：[ERROR] ValueError: error occurred while saving or dygraph_to_static network_model: Crossformer, err: In transformed code:\r\n    File \"/home/PaddleTS-main/paddlets/models/forecasting/dl/Crossformer.py\", line 84, in forward\r\n        x_seq = self.enc_value_embedding(x_seq)\r\n    File \"/home/PaddleTS-main/paddlets/models/forecasting/dl/_crossformer/embedding.py\", line 16, in forward\r\n        'b (seg_num seg_len) d -> (b d seg_num) seg_len', seg_len=self.\r\n    File \"/usr/local/lib/python3.7/dist-packages/einops/einops.py\", line 483, in rearrange\r\n                raise TypeError(\"Rearrange can't be applied to an empty list\")\r\n            tensor = get_backend(tensor[0]).stack_on_zeroth_dimension(tensor)\r\n        return reduce(cast(Tensor, tensor), pattern, reduction='rearrange', **axes_lengths)\r\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_call_func.py\", line 214, in convert_call\r\n        converted_call = convert_to_static(func)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 140, in convert_to_static\r\n        static_func = _FUNCTION_CACHE.convert_with_cache(function)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 77, in convert_with_cache\r\n        static_func = self._convert(func)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 119, in _convert\r\n        static_func, file_name = ast_to_func(root_wrapper.node, func)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/utils.py\", line 500, in ast_to_func\r\n        module = SourceFileLoader(module_name, f.name).load_module()\r\n    File \"<frozen importlib._bootstrap_external>\", line 407, in _check_name_wrapper\r\n    File \"<frozen importlib._bootstrap_external>\", line 907, in load_module\r\n    File \"<frozen importlib._bootstrap_external>\", line 732, in load_module\r\n    File \"<frozen importlib._bootstrap>\", line 265, in _load_module_shim\r\n    File \"<frozen importlib._bootstrap>\", line 696, in _load\r\n    File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n    File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n    File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n    File \"/tmp/tmpqb2sr_q0.py\", line 6, in <module>\r\n        def reduce(tensor: Tensor, pattern: str, reduction: Reduction, **\r\n    NameError: name 'Reduction' is not defined",
        "state": "closed",
        "user": "Wenqianqian123",
        "closed_by": "Sunting78",
        "created_at": "2024-03-19T06:18:03+00:00",
        "updated_at": "2024-04-22T02:34:29+00:00",
        "closed_at": "2024-04-22T02:34:29+00:00",
        "comments_count": [
            "Wenqianqian123",
            "Wenqianqian123",
            "Sunting78",
            "Wenqianqian123",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 479,
        "title": "PaddleTS多时序数据导入怎么获取group_id",
        "body": "#Load TSDatasets by group_id\r\nfrom paddlets import TSDataset\r\ntsdatasets = TSDataset.load_from_dataframe(\r\n    df=sample,\r\n    group_id='id',\r\n    target_cols='a',\r\n    observed_cov_cols=['c', 'd'],\r\n    #static_cov_cols='id'\r\n)\r\n使用group_id导入数据，得到的是个TSDataset集合，怎么知道每个集和对应的group_id值是多少，没找到对应的方法和属性，而且预测后也不知道对应的是哪个group_id的预测值",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-03-23T13:03:41+00:00",
        "updated_at": "2024-05-07T03:56:07+00:00",
        "closed_at": "2024-05-07T03:56:07+00:00",
        "comments_count": [
            "kachadx",
            "Sunting78",
            "kachadx",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 478,
        "title": "如何保存模型，并能够使用保存的模型进行推理？",
        "body": "运行train.py脚本可执行训练，请问如何保存训练后的模型，并在新的脚本中，使用训练好的模型进行推理，比如使用configs.longterm_forecast下的Crossformer_ECL.yaml配置文件，执行train.py。",
        "state": "closed",
        "user": "Wenqianqian123",
        "closed_by": "Sunting78",
        "created_at": "2024-03-19T06:29:21+00:00",
        "updated_at": "2024-03-27T06:42:28+00:00",
        "closed_at": "2024-03-27T06:42:28+00:00",
        "comments_count": [
            "Sunting78",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 480,
        "title": "使用TFT模型进行时序预测的output_quantiles维度问题",
        "body": "是否output_quantiles只支持长度为1和3，测试在其他长度下均会报错。\r\n-------------------------------------------------------------------\r\n示例代码：\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom paddlets import TSDataset\r\n\r\nx = np.linspace(-np.pi, np.pi, 200)\r\nsinx = np.sin(x) * 4 + np.random.randn(200)\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        'time_col': pd.date_range('2022-01-01', periods=200, freq='1h'),\r\n        'value': sinx\r\n    }\r\n)\r\ntarget_dataset = TSDataset.load_from_dataframe(\r\n    df,  #Also can be path to the CSV file\r\n    time_col='time_col',\r\n    target_cols='value',\r\n    freq='1h'\r\n)\r\nnew_line = pd.Series(\r\n     np.array(range(210)),\r\n     index=pd.date_range('2022-01-01', periods=210, freq='1h')\r\n)\r\ntarget_dataset.set_column(\r\n     column='new_b',\r\n     value=new_line,\r\n     type='known_cov'\r\n)\r\ntrain_ts, val_ts = target_dataset.split(0.7)\r\n\r\nfrom paddlets.models.forecasting import TransformerModel, TFTModel, RNNBlockRegressor\r\n\r\nmodel = TFTModel(\r\n    in_chunk_len = 10,\r\n    out_chunk_len = 10,\r\n    output_quantiles = [0.1, 0.2]\r\n)\r\nmodel.fit(train_ts)\r\n-------------------------------------------------------------------\r\n报错：\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_20005/1436158038.py in <module>\r\n      6     output_quantiles = [0.1, 0.2]\r\n      7 )\r\n----> 8 model.fit(train_ts)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in fit(self, train_tsdataset, valid_tsdataset)\r\n    344             self._check_multi_tsdataset(valid_tsdataset)\r\n    345         train_dataloader, valid_dataloaders = self._init_fit_dataloaders(train_tsdataset, valid_tsdataset)\r\n--> 346         self._fit(train_dataloader, valid_dataloaders)\r\n    347 \r\n    348     def _fit(\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in _fit(self, train_dataloader, valid_dataloaders)\r\n    370             # Call the `on_epoch_begin` method of each callback before the epoch starts.\r\n    371             self._callback_container.on_epoch_begin(epoch_idx)\r\n--> 372             self._train_epoch(train_dataloader)\r\n    373 \r\n    374             # Predict for each eval set.\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/models/forecasting/dl/paddle_base_impl.py in _train_epoch(self, train_loader)\r\n    438             self._callback_container.on_batch_begin(batch_idx)\r\n    439             X, y = self._prepare_X_y(data)\r\n--> 440             batch_logs = self._train_batch(X, y)\r\n...\r\n    301         comment = OpProtoHolder.instance().get_op_proto(op_type).comment\r\n\r\nValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3] and the shape of Y = [121, 10, 1, 2]. Received [3] in X is not equal to [2] in Y at i:3.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\r\n  [operator < elementwise_mul > error]",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "IgnoranceSmile",
        "created_at": "2024-03-24T04:52:57+00:00",
        "updated_at": "2024-04-08T12:04:18+00:00",
        "closed_at": "2024-04-08T12:04:18+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 481,
        "title": "如果不需要填充呢，因为有些场景本来就是缺数据的，像股票价格存在休盘和节假日的情况，怎么将缺失的两个时间点拼在一起？避免在训练过程中产生错误，比如：",
        "body": "              如果不需要填充呢，因为有些场景本来就是缺数据的，像股票价格存在休盘和节假日的情况，怎么将缺失的两个时间点拼在一起？避免在训练过程中产生错误，比如：\r\n1.ValueError: The `point` is out of the valid range\r\n2.ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\r\n。\r\n\r\n_Originally posted by @Hoogck in https://github.com/PaddlePaddle/PaddleTS/issues/266#issuecomment-1407619481_\r\n            ",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "kachadx",
        "created_at": "2024-03-28T08:04:33+00:00",
        "updated_at": "2024-04-12T04:09:42+00:00",
        "closed_at": "2024-04-12T04:09:42+00:00",
        "comments_count": [
            "Sunting78",
            "kachadx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 482,
        "title": "SHAP方法能用于多变量预测的DeepAR吗？",
        "body": "SHAP方法不支持多变量预测，请问有什么解决方案？\r\n\r\n代码如下：\r\nimport numpy as np\r\nimport pandas as pd\r\nimport paddle\r\n\r\nfrom paddlets.datasets.tsdataset import TSDataset\r\nfrom paddlets.models.forecasting import DeepARModel\r\nfrom paddlets.transform.sklearn_transforms import StandardScaler\r\nfrom paddlets.xai.post_hoc.shap_explainer import ShapExplainer\r\n\r\nx = np.linspace(-np.pi, np.pi, 2000)\r\n\r\ndata = pd.DataFrame(\r\n{\r\n'time_col': pd.date_range('2022-01-01', periods=2000, freq='1h'),\r\n'y1': np.sin(x) * 1 + np.random.randn(2000),\r\n'y2': np.sin(x) * 2 + np.random.randn(2000),\r\n'y3': np.sin(x) * 3 + np.random.randn(2000),\r\n'y4': np.sin(x) * 4 + np.random.randn(2000),\r\n'y5': np.sin(x) * 5 + np.random.randn(2000),\r\n'y6': np.sin(x) * 6 + np.random.randn(2000),\r\n'y7': np.sin(x) * 7 + np.random.randn(2000)}\r\n)\r\n\r\nts = TSDataset.load_from_dataframe(\r\n    data,\r\n    time_col='time_col',\r\n    target_cols=['y1','y2','y3','y4','y5','y6','y7'],\r\n    freq='1h',\r\n    fillna_method='pre'\r\n    )\r\n\r\ntrain, val = ts.split(0.8)\r\nscaler = StandardScaler()\r\nscaler.fit(train)\r\nscaled = scaler.transform(ts)\r\ntrain_scaled = scaler.transform(train)\r\nval_scaled = scaler.transform(val)\r\n\r\ndeepar = DeepARModel(\r\n     in_chunk_len = 13,\r\n     out_chunk_len = 1,\r\n     max_epochs=100,\r\n     optimizer_params = dict(learning_rate=0.0002),\r\n     dropout = 0.15,\r\n     batch_size = 32, # 批量大小\r\n     patience=20,\r\n     num_samples = 101,\r\n     regression_mode=\"sampling\",\r\n     output_mode=\"quantiles\",\r\n     rnn_type_or_module = 'LSTM'\r\n )\r\nnp.random.seed(2023)\r\npaddle.seed(2023)\r\n# 模型训练\r\ndeepar.fit(train_scaled, val_scaled)\r\nse = ShapExplainer(deepar, train_scaled, background_sample_number=100, keep_index=True, use_paddleloader=False)\r\nshap_value = se.explain(val_scaled, nsamples=100)\r\n\r\n报错如下：\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_35604/1646252647.py in <module>\r\n     54 # 模型训练\r\n     55 deepar.fit(train_scaled, val_scaled)\r\n---> 56 se = ShapExplainer(deepar, train_scaled, background_sample_number=100, keep_index=True, use_paddleloader=False)\r\n     57 shap_value = se.explain(val_scaled, nsamples=100)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/xai/post_hoc/shap_explainer.py in __init__(self, model, background_data, background_sample_number, shap_method, task_type, seed, use_paddleloader, **kwargs)\r\n     62         raise_if(shap_method not in ['kernel', 'deep'], 'Only support kernel shap and deep shap!')\r\n     63         raise_if_not(isinstance(background_data.freq, str), 'Only support timeindex data!')\r\n---> 64         raise_if(len(background_data.get_target().columns) > 1, 'Only support univariate output!')\r\n     65 \r\n     66         self._model = model\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/logger/logger.py in raise_if(condition, message, logger)\r\n    154 \r\n    155     \"\"\"\r\n--> 156     raise_if_not(not condition, message, logger)\r\n\r\n/usr/local/lib/python3.7/dist-packages/paddlets/logger/logger.py in raise_if_not(condition, message, logger)\r\n    133     if not condition:\r\n    134         logger.error(\"ValueError: \" + message)\r\n--> 135         raise ValueError(message)\r\n    136 \r\n    137 \r\n\r\nValueError: Only support univariate output!",
        "state": "closed",
        "user": "bingshuangchalan",
        "closed_by": "Sunting78",
        "created_at": "2024-04-02T12:56:38+00:00",
        "updated_at": "2024-04-22T02:37:09+00:00",
        "closed_at": "2024-04-22T02:37:09+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 483,
        "title": " 哪个新手把master分支里的各个__init__.py文件干掉了",
        "body": null,
        "state": "closed",
        "user": "arcral",
        "closed_by": "Sunting78",
        "created_at": "2024-04-03T02:56:42+00:00",
        "updated_at": "2024-04-22T02:32:15+00:00",
        "closed_at": "2024-04-22T02:32:15+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 484,
        "title": "多输入-单输出的修改方式",
        "body": "目前很多模型，比如LSTNet等目前都不支持协变量，这些模型有办法实现多时序信息输入然后只有其中一个作为target么？",
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2024-04-08T12:03:59+00:00",
        "updated_at": "2024-05-07T03:55:35+00:00",
        "closed_at": "2024-05-07T03:55:35+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 485,
        "title": "PaddleTS模型库里面哪些是回归类，哪些可以做分类",
        "body": null,
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-04-09T09:59:02+00:00",
        "updated_at": "2024-04-17T07:36:14+00:00",
        "closed_at": "2024-04-17T07:36:14+00:00",
        "comments_count": [
            "Sunting78",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 486,
        "title": "使用LSTNet模型训练时，报错ValueError: Input contains NaN.",
        "body": "使用LSTNet模型训练，有时会报错ValueError: Input contains NaN，有时不会。使用其它模型没有问题，这是什么原因？",
        "state": "closed",
        "user": "JackLRR",
        "closed_by": "Sunting78",
        "created_at": "2024-04-12T07:39:35+00:00",
        "updated_at": "2024-05-07T03:57:47+00:00",
        "closed_at": "2024-05-07T03:57:46+00:00",
        "comments_count": [
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 487,
        "title": "https://github.com/PaddlePaddle/PaddleTS/blob/18accdedae896405a4d245b084655fbb1fdfd10a/paddlets/models/data_adapter.py#L961",
        "body": "data_adapter的_validate_known_cov_timeseries方法RangeIndex是不是逻辑上面有问题\r\n               else:\r\n                    # RangeIndex\r\n                    # Note: RangeIndex.stop is right-opened, but time_window is right-closed, so stop param must + 1.\r\n                    step = self._std_timeindex.step\r\n                    exceeded_timeindex = pd.RangeIndex(\r\n                        start=self._std_timeindex[-1],\r\n                        stop=(self._time_window[1] + 1) * step,\r\n                        step=step\r\n                    )\r\n                    sample_end_std_time = exceeded_timeindex[-1]\r\n start=self._std_timeindex[-1]的取值为什么取的是RangeIndex的stop值，导致exceeded_timeindexs的size为0，sample_end_std_time = exceeded_timeindex[-1]这行代码报IndexError: index -1 is out of bounds for axis 0 with size 0\r\n",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-04-15T13:13:58+00:00",
        "updated_at": "2024-05-07T03:56:19+00:00",
        "closed_at": "2024-05-07T03:56:19+00:00",
        "comments_count": [
            "kachadx",
            "kachadx",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 488,
        "title": "TFT方法有办法修改损失函数为MAE、MSE之类的其他函数么",
        "body": null,
        "state": "closed",
        "user": "IgnoranceSmile",
        "closed_by": "Sunting78",
        "created_at": "2024-04-16T01:05:23+00:00",
        "updated_at": "2024-05-07T03:57:08+00:00",
        "closed_at": "2024-05-07T03:57:07+00:00",
        "comments_count": [
            "IgnoranceSmile",
            "Sunting78",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 490,
        "title": "请问有哪些算法支持未来特征呢？",
        "body": null,
        "state": "closed",
        "user": "YuboCoco",
        "closed_by": "Sunting78",
        "created_at": "2024-04-29T01:39:38+00:00",
        "updated_at": "2024-10-10T03:16:07+00:00",
        "closed_at": "2024-10-10T03:16:07+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 491,
        "title": "autots出现这个错误，请问原因是什么呢？我按照文档中进行了安装，会出现警告",
        "body": "![image](https://github.com/PaddlePaddle/PaddleTS/assets/27758135/11e82844-243e-4972-8edf-c2be6cd0a9fc)\r\n![image](https://github.com/PaddlePaddle/PaddleTS/assets/27758135/3f070136-dde9-4ade-be8c-90b4910f8bb8)\r\n\r\n",
        "state": "closed",
        "user": "zsczszsc",
        "closed_by": "zsczszsc",
        "created_at": "2024-05-08T03:24:09+00:00",
        "updated_at": "2024-05-09T01:23:39+00:00",
        "closed_at": "2024-05-09T01:23:39+00:00",
        "comments_count": [
            "zsczszsc",
            "zsczszsc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 493,
        "title": "AttributeError: 'InformerModel' object has no attribute '_use_revin'",
        "body": "使用from paddlets.models.model_loader import load\r\nload（）方法加载InformerModel报错\r\nAttributeError: 'InformerModel' object has no attribute '_use_revin'，为什么只有加载模型的时候用RevinWrapper，训练的时候好像没用到\r\ndef revin_norm(func):\r\n    @functools.wraps(func)\r\n    def wrapper(obj: BaseModel, *args, **kwargs):\r\n        \"\"\"\r\n        The core logic. The base modelout is been wrappered by the RevinWrapper.\r\n        \"\"\"\r\n        model = func(obj, *args, **kwargs)\r\n        if obj._use_revin:\r\n            logger.warning(\r\n                \"Using reversible instance normalization (revin) to remove and restore the statistical information of a time-series instance\"\r\n            )\r\n            model = RevinWrapper(model, obj._fit_params['target_dim'], **\r\n                                 obj._revin_params)\r\n        return model\r\n\r\n    return wrapper",
        "state": "open",
        "user": "kachadx",
        "closed_by": null,
        "created_at": "2024-05-09T11:39:26+00:00",
        "updated_at": "2024-05-09T12:02:32+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 492,
        "title": "TSDataset.load_from_dataframe使用过程中报错",
        "body": "target_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='time',\r\n    target_cols=['windspeed','power'],\r\n    observed_cov_cols=['10m平均风速(m/s)','10m平均风向(°)','30m平均风速(m/s)','30m平均风向(°)',\r\n                       '50m平均风速(m/s)','50m平均风向(°)','70m平均风速(m/s)','70m平均风向(°)',\r\n                       '80m平均风速(m/s)','80m平均风向(°)','测风塔气温(°C)','测风塔气压(hPa)','测风塔湿度(%)'],\r\n    freq='15min',\r\n    fill_missing_dates=True,\r\n    fillna_method = 'avg'\r\n)\r\n\r\n\r\n报错\r\n[paddlets] [ERROR] ValueError: The specified filling method doesn't exist.\r\n\r\n我查看官方文档里面fillna_method是有7种，为什么把'pre'改为'avg'会报错？",
        "state": "closed",
        "user": "sculyd",
        "closed_by": "sculyd",
        "created_at": "2024-05-09T08:49:28+00:00",
        "updated_at": "2024-05-09T08:55:01+00:00",
        "closed_at": "2024-05-09T08:55:01+00:00",
        "comments_count": [
            "sculyd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 495,
        "title": "请问进行XAI分析，有没有更详细的解释？",
        "body": "![image](https://github.com/PaddlePaddle/PaddleTS/assets/27758135/06a63ad4-85f2-4a98-81ba-a6a0b4008e0b)\r\n例如这个参数是什么意思？能否找到更详细的文档",
        "state": "closed",
        "user": "zsczszsc",
        "closed_by": "Sunting78",
        "created_at": "2024-05-13T02:24:09+00:00",
        "updated_at": "2024-10-10T03:16:31+00:00",
        "closed_at": "2024-10-10T03:16:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 496,
        "title": "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd",
        "body": "numpy1.19.4版本还出现这个问题",
        "state": "closed",
        "user": "xgxiaog",
        "closed_by": "xgxiaog",
        "created_at": "2024-05-15T01:46:34+00:00",
        "updated_at": "2024-05-15T08:36:07+00:00",
        "closed_at": "2024-05-15T08:36:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 494,
        "title": "PaddleTS中的模型特征影响分析",
        "body": "PaddleTS中的模型有支持特征影响分析工具吗？如果没有，有没有可以用的第三方工具可以支持，比如shap库，captum",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "kachadx",
        "created_at": "2024-05-10T12:05:20+00:00",
        "updated_at": "2024-06-07T13:55:07+00:00",
        "closed_at": "2024-06-07T13:54:30+00:00",
        "comments_count": [
            "kachadx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 497,
        "title": "使用AutoTS的时候message 过大有什么处理方案吗",
        "body": "ray.tune.error.TuneError: The Trainable/training function is too large for grpc resource limit. Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use tune.with_parameters() to put large objects in the Ray object store. \r\nOriginal exception: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\tune\\experiment\\experiment.py\", line 150, in __init__\r\n    self._run_identifier = Experiment.register_if_needed(run)\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\tune\\experiment\\experiment.py\", line 352, in register_if_needed\r\n    register_trainable(name, run_object)\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\tune\\registry.py\", line 112, in register_trainable\r\n    _global_registry.register(TRAINABLE_CLASS, name, trainable)\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\tune\\registry.py\", line 239, in register\r\n    self.flush_values()\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\tune\\registry.py\", line 277, in flush_values\r\n    _internal_kv_put(\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ProgramData\\anaconda3\\envs\\myenv\\lib\\site-packages\\ray\\experimental\\internal_kv.py\", line 94, in _internal_kv_put\r\n    return global_gcs_client.internal_kv_put(key, value, overwrite, namespace) == 0\r\n  File \"python\\ray\\_raylet.pyx\", line 2690, in ray._raylet._auto_reconnect.wrapper\r\n  File \"python\\ray\\_raylet.pyx\", line 2667, in ray._raylet._auto_reconnect.wrapper\r\n  File \"python\\ray\\_raylet.pyx\", line 2804, in ray._raylet.GcsClient.internal_kv_put\r\n  File \"python\\ray\\_raylet.pyx\", line 580, in ray._raylet.check_status\r\nray.exceptions.RpcError: Sent message larger than max (845965369 vs. 536870912)",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "kachadx",
        "created_at": "2024-05-27T12:53:06+00:00",
        "updated_at": "2024-06-07T13:59:33+00:00",
        "closed_at": "2024-06-07T13:59:33+00:00",
        "comments_count": [
            "kachadx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 499,
        "title": "关于TFTExplainer只对TFT模型做了实现吗",
        "body": "关于TFTExplainer只对TFT模型做了实现吗？其他时间序列模型没有实现对应的功能么",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-06-08T11:21:54+00:00",
        "updated_at": "2024-10-10T03:19:40+00:00",
        "closed_at": "2024-10-10T03:19:40+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 503,
        "title": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果最为输入",
        "body": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果作为输入，但是实际代码中的逻辑下一次预测的输入好像是包含上一次的预测结果，也就是说下一次的预测输入值包含的是上一次预测结果值而不是真实的数据值，是不是文档描述和代码逻辑不一致还是我对文档理解错误",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-06-17T05:25:34+00:00",
        "updated_at": "2024-10-10T03:19:03+00:00",
        "closed_at": "2024-10-10T03:19:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 501,
        "title": "xai的shap分析为什么都是返回0",
        "body": "   xai的shap分析为什么都是返回0，不管是用kernel还是deep，所有特征都是返回0,\r\n shap_explainer = ShapExplainer(model, train_t, shap_method=\"kernel\", n_jobs=4)\r\n    shap_values = shap_explainer.explain(test_t, nsamples=100)",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-06-15T13:08:39+00:00",
        "updated_at": "2024-10-10T03:16:40+00:00",
        "closed_at": "2024-10-10T03:16:40+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 502,
        "title": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果最为输入",
        "body": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果作为输入，但是实际代码中的逻辑下一次预测的输入好像是包含上一次的预测结果，也就是说下一次的预测输入值包含的是上一次预测结果值而不是真实的数据值，是不是文档描述和代码逻辑不一致还是我对文档理解错误",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-06-17T05:24:36+00:00",
        "updated_at": "2024-10-10T03:19:50+00:00",
        "closed_at": "2024-10-10T03:19:50+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 514,
        "title": "PaddleTS PatchTST模型是否支持协变量？",
        "body": "PatchTST模型是否支持协变量，如：观测协变量、已知未来协变量、静态协变量等。\r\n我拟通过协变量提升时序模型的精度。\r\n\r\n若支持，是否通过类似如下方式构建各协变量：\r\n`known_cov_dataset = TSDataset.load_from_dataframe(\r\n    df,\r\n    time_col='time_col',\r\n    known_cov_cols=['known_cov_1', 'known_cov_2'],\r\n    freq='1h'\r\n)`",
        "state": "closed",
        "user": "TommysLee",
        "closed_by": "Sunting78",
        "created_at": "2024-07-12T02:04:21+00:00",
        "updated_at": "2024-10-10T03:18:53+00:00",
        "closed_at": "2024-10-10T03:18:53+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 504,
        "title": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果最为输入",
        "body": "paddlets.utils.backtest看文档表达意思是循环预测的时候下次预测的输入应该是不包含上一次预测结果作为输入，但是实际代码中的逻辑下一次预测的输入好像是包含上一次的预测结果，也就是说下一次的预测输入值包含的是上一次预测结果值而不是真实的数据值，是不是文档描述和代码逻辑不一致还是我对文档理解错误",
        "state": "closed",
        "user": "kachadx",
        "closed_by": "Sunting78",
        "created_at": "2024-06-17T05:33:42+00:00",
        "updated_at": "2024-10-10T03:19:16+00:00",
        "closed_at": "2024-10-10T03:19:16+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 516,
        "title": " [Hint: Expected k <= input_width, but received k:5 > input_width:2.] (at ..\\paddle\\phi\\kernels\\cpu\\top_k_kernel.cc:40)",
        "body": "运行环境：\r\n操作系统：Windows 10 64位\r\nPython：3.7.16\r\nPaddleTS：默认分支（release_v1.1）最新的代码，用 python setup.py install 安装\r\nJupyter Lab ： 3.6.7\r\n\r\n代码来源：\r\n按照 PaddleTS 官方文档：[集成异常检测](https://paddlets.readthedocs.io/zh-cn/latest/source/modules/ensemble/ensemble_anomaly.html) ，代码复制了一份，在 Jupyter Lab 中运行。\r\n\r\n运行到：\r\n\r\n```\r\nfrom paddlets.ensemble import WeightingEnsembleAnomaly\r\nmodel = WeightingEnsembleAnomaly(\r\nin_chunk_len=2,\r\nestimators=[(AutoEncoder, ae_params),(VAE, vae_params)],\r\nmode = \"voting\")\r\nmodel.fit(train_tsdata_scaled)\r\n```\r\n\r\n出现了错误：\r\n\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp\\ipykernel_21328\\3319269003.py in <module>\r\n      7 mode = \"voting\")\r\n      8 \r\n----> 9 model.fit(train_tsdata_scaled)\r\n\r\n略……\r\n\r\nD:\\Programs\\anaconda3\\envs\\ppts-code\\lib\\site-packages\\paddle\\tensor\\search.py in topk(x, k, axis, largest, sorted, name)\r\n    911         if axis is None:\r\n    912             axis = -1\r\n--> 913         out, indices = _C_ops.topk(x, k, axis, largest, sorted)\r\n    914         return out, indices\r\n    915     else:\r\n\r\nValueError: (InvalidArgument) The rank (5) of the input 'k' for topk op must be less than or equal to 2.\r\n  [Hint: Expected k <= input_width, but received k:5 > input_width:2.] (at ..\\paddle\\phi\\kernels\\cpu\\top_k_kernel.cc:40)\r\n\r\n```\r\n\r\n这个小白没能力修了，求助！！\r\n\r\n",
        "state": "closed",
        "user": "lichenliang666",
        "closed_by": "Sunting78",
        "created_at": "2024-07-24T05:17:58+00:00",
        "updated_at": "2024-10-10T03:18:13+00:00",
        "closed_at": "2024-10-10T03:18:13+00:00",
        "comments_count": [
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 515,
        "title": "使用 WeightingEnsembleAnomaly 的时候出现了 KeyError: 'train_run_cost' ",
        "body": "运行环境：\r\n操作系统：Windows 10 64位\r\nPython：3.7.16\r\nPaddleTS：默认分支（release_v1.1）最新的代码，用 python setup.py install 安装\r\nJupyter Lab ： 3.6.7 \r\n\r\n代码来源：\r\n按照  PaddleTS 官方文档：[集成异常检测](https://paddlets.readthedocs.io/zh-cn/latest/source/modules/ensemble/ensemble_anomaly.html) ，代码复制了一份，在 Jupyter Lab 中运行。\r\n\r\n运行到：\r\n```\r\nfrom paddlets.ensemble import WeightingEnsembleAnomaly\r\nmodel = WeightingEnsembleAnomaly(\r\nin_chunk_len=2,\r\nestimators=[(AutoEncoder, ae_params),(VAE, vae_params)],\r\nmode = \"voting\")\r\nmodel.fit(train_tsdata_scaled)\r\n```\r\n出现了错误：\r\n\r\n```\r\nD:\\anaconda3\\envs\\ppts-code\\lib\\site-packages\\paddlets-1.1.0-py3.7.egg\\paddlets\\models\\common\\callbacks\\callbacks.py in on_batch_end(self, batch, logs)\r\n    375         ) / (self._samples_seen + batch_size)\r\n    376         self._samples_seen += batch_size\r\n--> 377         self._train_run_cost += logs['train_run_cost']\r\n    378 \r\n\r\nKeyError: 'train_run_cost'\r\n```\r\n\r\n其他小伙伴也有遇到这个问题的吗。\r\n\r\n请问如何处理。\r\n\r\n",
        "state": "closed",
        "user": "lichenliang666",
        "closed_by": "Sunting78",
        "created_at": "2024-07-22T09:56:11+00:00",
        "updated_at": "2024-10-10T03:21:34+00:00",
        "closed_at": "2024-10-10T03:21:33+00:00",
        "comments_count": [
            "lichenliang666",
            "Sunting78"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 522,
        "title": "在A100服务器使用Paddlepaddle2.6在PaddleTS 套件中训练DLinear_ECL模型，loss降不下去不收敛",
        "body": "1、希望可以提供一下时间序列预测，异常检测，分类所使用的数据集（并非原始数据集，是否可以提供文档中训练出精度所使用的数据集）\r\n2、DLinear_ECL模型，loss降不下去不收敛训练日志如下：\r\n[DLinear_ECL.txt](https://github.com/user-attachments/files/16757074/DLinear_ECL.txt)\r\n",
        "state": "closed",
        "user": "duqimeng",
        "closed_by": "TingquanGao",
        "created_at": "2024-08-27T05:49:18+00:00",
        "updated_at": "2024-09-29T12:01:57+00:00",
        "closed_at": "2024-09-29T12:01:57+00:00",
        "comments_count": [
            "Sunting78",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 530,
        "title": "执行 example中的 anomaly_example 案例，结果不一致",
        "body": "用的是master分支，模型训练完之后的指标都是0，应该怎么解决呀。\r\n\r\n系统：mac m1芯片\r\n\r\n\r\n![WeChatd14e3159d310933d14227f1e4184a33a](https://github.com/user-attachments/assets/8c3cdc99-a6da-4046-819f-d2b16936cfd6)\r\n",
        "state": "closed",
        "user": "liuzhipengchd",
        "closed_by": "TingquanGao",
        "created_at": "2024-10-08T08:56:00+00:00",
        "updated_at": "2024-11-21T12:03:38+00:00",
        "closed_at": "2024-11-21T12:03:38+00:00",
        "comments_count": [
            "liuzhipengchd",
            "liu-jiaxuan",
            "Sunting78",
            "liuzhipengchd",
            "liu-jiaxuan",
            "liuzhipengchd",
            "liu-jiaxuan",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 531,
        "title": "mac M3 安装失败",
        "body": "mac环境pip install paddlets 失败，具体如下：\r\n1、环境：mac M3、conda 24.9.1、python3.9、paddlepaddle==2.6.1\r\n2、报错：\r\n(test) xxxx@bogon test % pip install paddlets                                                                 \r\nLooking in indexes: https://mirrors.aliyun.com/pypi/simple\r\nCollecting paddlets\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/28/3e/ff538c1adf83ce9479c956141ce2dde833e10cb63aa7dea433fbfaff07fa/paddlets-1.1.0-py3-none-any.whl (572 kB)\r\nCollecting numpy<=1.19.5,>=1.17.0 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/51/60/3f0fe5b7675a461d96b9d6729beecd3532565743278a9c3fe6dd09697fa7/numpy-1.19.5.zip (7.3 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting pandas<=1.3.5,>=0.25.0 (from paddlets)\r\n  Using cached pandas-1.3.5-cp39-cp39-macosx_11_0_arm64.whl\r\nCollecting scikit-learn>=0.24.1 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/1b/be/386ef63d9d5e2ddf8308f6a164e4b388d5c5aecc0504d25acc6b33d8b09e/scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\r\nCollecting chinese-calendar==1.8.0 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/d3/8a/feaef2cf0aa05d13dfab540770718467ec348b6e71a700197fbd4224e922/chinese_calendar-1.8.0-py2.py3-none-any.whl (11 kB)\r\nCollecting python-docx (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl (244 kB)\r\nCollecting matplotlib>=3.1.2 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/46/87/5f567fda78130a8394f9dcf3accb1b7b0c9baf0384307ef59032f5b1d17c/matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\r\nCollecting PyWavelets<=1.3.0,>=1.1.0 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/7d/d4/2fd75d3d69047fc6eac05b77c3d343b4c2ec9d7c0b8057c53d3bfd964c18/PyWavelets-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (4.3 MB)\r\nCollecting statsmodels<=0.12.2,>=0.10.2 (from paddlets)\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/10/26/0fd61f95667e56fd597ecca715dff3623ed1122b6f895ed2b4dfb54afc04/statsmodels-0.12.2.tar.gz (17.5 MB)\r\n  Installing build dependencies ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  × pip subprocess to install build dependencies did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [80 lines of output]\r\n      Looking in indexes: https://mirrors.aliyun.com/pypi/simple\r\n      Ignoring numpy: markers 'python_version == \"3.6\"' don't match your environment\r\n      Ignoring numpy: markers 'python_version == \"3.7\"' don't match your environment\r\n      Collecting setuptools\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/ff/ae/f19306b5a221f6a436d8f2238d5b80925004093fa3edea59835b514d9057/setuptools-75.1.0-py3-none-any.whl (1.2 MB)\r\n      Collecting wheel\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/1b/d1/9babe2ccaecff775992753d8686970b1e2755d21c8a63be73aba7a4e7d77/wheel-0.44.0-py3-none-any.whl (67 kB)\r\n      Collecting cython>=0.29.14\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/43/39/bdbec9142bc46605b54d674bf158a78b191c2b75be527c6dcf3e6dfe90b8/Cython-3.0.11-py2.py3-none-any.whl (1.2 MB)\r\n      Collecting numpy==1.17.5\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/d9/09/8e89c05abc450ea347f40b4fa917ec5c69b5228da344487f178586a3187c/numpy-1.17.5.zip (6.4 MB)\r\n        Preparing metadata (setup.py): started\r\n        Preparing metadata (setup.py): finished with status 'done'\r\n      Collecting scipy>=1.2\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/5c/c0/e71b94b20ccf9effb38d7147c0064c08c622309fd487b1b677771a97d18c/scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\r\n      INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/b2/33/cd6ae14e861e3f1ea1440c62bd3d16cc3654d77d79666f348ad0176afde8/scipy-1.13.0-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/32/48/f605bad3e610efe05a51b56698578f7a98f900513a4bad2c9f12df845cd6/scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl (31.4 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/d1/3a/0ab839bb67043ab35e5dcf8b611ca9e08e5a8933b0bc7506eedcec664aae/scipy-1.11.4-cp39-cp39-macosx_12_0_arm64.whl (29.7 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/6f/d9/d10111b008fabab4aea0f98274d3f5db4bd33baadf30c782b6e659ec7708/scipy-1.11.3-cp39-cp39-macosx_12_0_arm64.whl (29.7 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/77/31/b063f21370c6050a663aae5a9868d2fe112b21caeface3c248016dfea092/scipy-1.11.2-cp39-cp39-macosx_12_0_arm64.whl (29.6 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/d8/97/3a15209262cf523dab38de372ff814f8fb7815f98ccc07c7996e77910612/scipy-1.11.1-cp39-cp39-macosx_12_0_arm64.whl (29.6 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/e7/f0/55d81813b1a4cb79ce7dc8290eac083bf38bfb36e1ada94ea13b7b1a5f79/scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl (28.9 MB)\r\n      INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/2b/54/7536dbfcbea26ca2c11d3c55b0c2d806d4349b5852318e12b98ffee27bd8/scipy-1.10.0-cp39-cp39-macosx_12_0_arm64.whl (28.9 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/c8/0f/d9f8c50be8670b7ba6f002679e84cd18f46a23faf62c1590f4d1bbec0c8c/scipy-1.9.3-cp39-cp39-macosx_12_0_arm64.whl (28.6 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/ec/7b/bf1cb24ba269d5911ba723a17e4c10f64c727798d74be0ac87c5fd9201ca/scipy-1.9.2-cp39-cp39-macosx_12_0_arm64.whl (28.6 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/fe/de/caec3ae06f5380b8c91518f119f9b113a2da0619f7d8d8937b8ee517a29e/scipy-1.9.1-cp39-cp39-macosx_12_0_arm64.whl (29.9 MB)\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/37/c6/eeecc4c9699605ed4bd00cce6c7cf945f5eb7aa3b3ae9f8f6aeadbb0a59b/scipy-1.9.0-cp39-cp39-macosx_12_0_arm64.whl (29.9 MB)\r\n      INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n        Using cached https://mirrors.aliyun.com/pypi/packages/66/d0/faf1d69525836cd4b6a51407b39836f77de266777d073ce5698b3a5244e3/scipy-1.8.1-cp39-cp39-macosx_12_0_arm64.whl (28.7 MB)\r\n      Building wheels for collected packages: numpy\r\n        Building wheel for numpy (setup.py): started\r\n        Building wheel for numpy (setup.py): finished with status 'error'\r\n        error: subprocess-exited-with-error\r\n      \r\n        × python setup.py bdist_wheel did not run successfully.\r\n        │ exit code: 1\r\n        ╰─> [15 lines of output]\r\n            Running from numpy source directory.\r\n            Traceback (most recent call last):\r\n              File \"<string>\", line 2, in <module>\r\n              File \"<pip-setuptools-caller>\", line 34, in <module>\r\n              File \"/private/var/folders/qn/nywglnps1fdg9k6physbwgg40000gn/T/pip-install-wx3ynzx1/numpy_5bddbd2d87144ec18f9aa3ee8de1048d/setup.py\", line 444, in <module>\r\n                setup_package()\r\n              File \"/private/var/folders/qn/nywglnps1fdg9k6physbwgg40000gn/T/pip-install-wx3ynzx1/numpy_5bddbd2d87144ec18f9aa3ee8de1048d/setup.py\", line 423, in setup_package\r\n                from numpy.distutils.core import setup\r\n              File \"/private/var/folders/qn/nywglnps1fdg9k6physbwgg40000gn/T/pip-install-wx3ynzx1/numpy_5bddbd2d87144ec18f9aa3ee8de1048d/numpy/distutils/core.py\", line 26, in <module>\r\n                from numpy.distutils.command import config, config_compiler, \\\r\n              File \"/private/var/folders/qn/nywglnps1fdg9k6physbwgg40000gn/T/pip-install-wx3ynzx1/numpy_5bddbd2d87144ec18f9aa3ee8de1048d/numpy/distutils/command/config.py\", line 20, in <module>\r\n                from numpy.distutils.mingw32ccompiler import generate_manifest\r\n              File \"/private/var/folders/qn/nywglnps1fdg9k6physbwgg40000gn/T/pip-install-wx3ynzx1/numpy_5bddbd2d87144ec18f9aa3ee8de1048d/numpy/distutils/mingw32ccompiler.py\", line 34, in <module>\r\n                from distutils.msvccompiler import get_build_version as get_build_msvc_version\r\n            ModuleNotFoundError: No module named 'distutils.msvccompiler'\r\n            [end of output]\r\n      \r\n        note: This error originates from a subprocess, and is likely not a problem with pip.\r\n        ERROR: Failed building wheel for numpy\r\n        Running setup.py clean for numpy\r\n        error: subprocess-exited-with-error\r\n      \r\n        × python setup.py clean did not run successfully.\r\n        │ exit code: 1\r\n        ╰─> [10 lines of output]\r\n            Running from numpy source directory.\r\n      \r\n            `setup.py clean` is not supported, use one of the following instead:\r\n      \r\n              - `git clean -xdf` (cleans all files)\r\n              - `git clean -Xdf` (cleans all versioned files, doesn't touch\r\n                                  files that aren't checked into the git repo)\r\n      \r\n            Add `--force` to your command to use it anyway if you must (unsupported).\r\n      \r\n            [end of output]\r\n      \r\n        note: This error originates from a subprocess, and is likely not a problem with pip.\r\n        ERROR: Failed cleaning build dir for numpy\r\n      Failed to build numpy\r\n      ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numpy)\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× pip subprocess to install build dependencies did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
        "state": "closed",
        "user": "125793014",
        "closed_by": "TingquanGao",
        "created_at": "2024-10-09T11:00:29+00:00",
        "updated_at": "2024-11-11T12:03:27+00:00",
        "closed_at": "2024-11-11T12:03:27+00:00",
        "comments_count": [
            "125793014",
            "Sunting78",
            "125793014",
            "Sunting78",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 523,
        "title": "【建议】PPTS训练时 每个step打印一次log，太频繁了，建议降低Log的频率",
        "body": "之前clone的PPTS  每个Epoch打印一次Log  挺好的，也便于查阅log，抓取重要信息。\r\n\r\n而现在clone的PPTS项目，每个step打印一次log，太频繁了，内容太多，找关键日志犹如大海捞针。建议采用之前的log策略。",
        "state": "closed",
        "user": "TommysLee",
        "closed_by": "TingquanGao",
        "created_at": "2024-08-28T07:56:33+00:00",
        "updated_at": "2024-09-29T03:02:01+00:00",
        "closed_at": "2024-09-29T03:02:01+00:00",
        "comments_count": [
            "Bobholamovic",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 537,
        "title": "训练模型时如何使用多线程",
        "body": "使用cpu模式训练模型，现在看只有1个cpu线程在跑，请问如何能够利用多线程来做模型训练？",
        "state": "closed",
        "user": "menglingjie",
        "closed_by": "menglingjie",
        "created_at": "2024-11-07T08:26:29+00:00",
        "updated_at": "2024-11-23T07:46:52+00:00",
        "closed_at": "2024-11-23T07:46:52+00:00",
        "comments_count": [
            "cuicheng01",
            "menglingjie",
            "cuicheng01",
            "menglingjie"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 549,
        "title": "类似股票的多路数据集，如何划分各个股票的最后一天的数据作为测试集",
        "body": "我将所有股票数据合到一个excel里面，并将group_id传入df的code列，希望训练是以前5天数据预测后一天的，每支股票只需要留下最后一天的数据作为验证数据。这个要如何设置？",
        "state": "open",
        "user": "zouhan6806504",
        "closed_by": null,
        "created_at": "2024-12-25T02:25:54+00:00",
        "updated_at": "2024-12-31T09:56:35+00:00",
        "closed_at": null,
        "comments_count": [
            "zouhan6806504"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 550,
        "title": "我是真的蚌埠住了，注释都能粘贴错来",
        "body": "![e8c1f9485502e59e2facbc27292da4c](https://github.com/user-attachments/assets/6f18bb44-c4cc-4b6c-9869-35a7f74aabb2)\r\n",
        "state": "closed",
        "user": "mike-egg123",
        "closed_by": "TingquanGao",
        "created_at": "2024-12-29T02:42:42+00:00",
        "updated_at": "2025-01-30T12:03:02+00:00",
        "closed_at": "2025-01-30T12:03:02+00:00",
        "comments_count": [
            "changdazhou",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 557,
        "title": "时序分类任务示例",
        "body": "paddlets有完善的时序分类任务示例吗，包括自定义数据集、构建模型、训练和推理；目前的资料太少了，而且https://github.com/PaddlePaddle/PaddleTS/issues/457\n这里的timesnet_Heartbeat的训练示例也跑不通。",
        "state": "closed",
        "user": "Cocoaxx",
        "closed_by": "TingquanGao",
        "created_at": "2025-04-16T12:01:06+00:00",
        "updated_at": "2025-06-29T12:10:10+00:00",
        "closed_at": "2025-06-29T12:10:10+00:00",
        "comments_count": [
            "Sunting78",
            "TingquanGao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleTS",
        "number": 558,
        "title": "python 3.12环境无法安装 paddlets",
        "body": "我按照你们的帮助文档 \n python -m pip install paddlepaddle-gpu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/\n这个可以安装成功了\n\n pip install paddlets 已经无法安装成功了\n\nC:\\Users\\Administrator>pip install paddlets\nLooking in indexes: https://mirrors.aliyun.com/pypi/simple\nCollecting paddlets\n  Using cached https://mirrors.aliyun.com/pypi/packages/28/3e/ff538c1adf83ce9479c956141ce2dde833e10cb63aa7dea433fbfaff07fa/paddlets-1.1.0-py3-none-any.whl (572 kB)\nCollecting numpy<=1.19.5,>=1.17.0 (from paddlets)\n  Using cached https://mirrors.aliyun.com/pypi/packages/51/60/3f0fe5b7675a461d96b9d6729beecd3532565743278a9c3fe6dd09697fa7/numpy-1.19.5.zip (7.3 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\nERROR: Exception:\nTraceback (most recent call last):\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n    status = _inner_run()\n             ^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n    return self.run(options, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 68, in wrapper\n    return func(self, options, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 387, in run\n    requirement_set = resolver.resolve(\n                      ^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 96, in resolve\n    result = self._result = resolver.resolve(\n                            ^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 515, in resolve\n    state = resolution.resolve(requirements, max_rounds=max_rounds)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 444, in resolve\n    failure_criterion = self._attempt_to_pin_criterion(name)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 211, in _attempt_to_pin_criterion\n    criteria = self._get_updated_criteria(candidate)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 202, in _get_updated_criteria\n    self._add_to_criteria(criteria, requirement, parent=candidate)\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 141, in _add_to_criteria\n    if not criterion.candidates:\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 194, in __bool__\n    return bool(self._sequence)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 163, in __bool__\n    self._bool = any(self)\n                 ^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 147, in <genexpr>\n    return (c for c in iterator if id(c) not in self._incompatible_ids)\n                       ^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 37, in _iter_built\n    candidate = func()\n                ^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 187, in _make_candidate_from_link\n    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 233, in _make_base_candidate_from_link\n    self._link_candidate_cache[link] = LinkCandidate(\n                                       ^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 306, in __init__\n    super().__init__(\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 159, in __init__\n    self.dist = self._prepare()\n                ^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 236, in _prepare\n    dist = self._prepare_distribution()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 317, in _prepare_distribution\n    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 532, in prepare_linked_requirement\n    return self._prepare_linked_requirement(req, parallel_builds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 647, in _prepare_linked_requirement\n    dist = _get_prepared_distribution(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 71, in _get_prepared_distribution\n    abstract_dist.prepare_distribution_metadata(\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 56, in prepare_distribution_metadata\n    self._install_build_reqs(finder)\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 126, in _install_build_reqs\n    build_reqs = self._get_build_requires_wheel()\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 103, in _get_build_requires_wheel\n    return backend.get_requires_for_build_wheel()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 702, in get_requires_for_build_wheel\n    return super().get_requires_for_build_wheel(config_settings=cs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 196, in get_requires_for_build_wheel\n    return self._call_hook(\n           ^^^^^^^^^^^^^^^^\n  File \"J:\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 402, in _call_hook\n    raise BackendUnavailable(\npip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'\n请问怎么解决",
        "state": "closed",
        "user": "liaojiededepan",
        "closed_by": "TingquanGao",
        "created_at": "2025-05-10T03:04:43+00:00",
        "updated_at": "2025-06-14T12:10:02+00:00",
        "closed_at": "2025-06-14T12:10:02+00:00",
        "comments_count": [
            "zhangyubo0722",
            "TingquanGao"
        ],
        "labels": []
    }
]