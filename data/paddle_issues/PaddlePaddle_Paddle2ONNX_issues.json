[
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 2,
        "title": "Add design doc reference to home README",
        "body": "",
        "state": "closed",
        "user": "varunarora",
        "closed_by": "varunarora",
        "created_at": "2018-04-04T22:40:26+00:00",
        "updated_at": "2018-05-22T18:59:01+00:00",
        "closed_at": "2018-05-22T18:59:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 14,
        "title": "Need check whether protoc existed.",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-04-10T07:47:43+00:00",
        "updated_at": "2018-04-10T12:05:21+00:00",
        "closed_at": "2018-04-10T12:05:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 7,
        "title": "Need add CI for the repo",
        "body": "",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-04-07T08:36:24+00:00",
        "updated_at": "2018-04-09T07:33:50+00:00",
        "closed_at": "2018-04-09T07:33:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1,
        "title": "Update the supported set of models",
        "body": "Instead of doing an RNN model initially, we instead focus on image recognition models with ResNet or VGG architectures",
        "state": "closed",
        "user": "varunarora",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-04T22:39:30+00:00",
        "updated_at": "2024-05-22T04:50:56+00:00",
        "closed_at": "2024-05-22T04:50:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 4,
        "title": "Map the graph of fit_a_line to ONNX",
        "body": null,
        "state": "closed",
        "user": "varunarora",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-04T22:46:00+00:00",
        "updated_at": "2024-05-22T04:50:47+00:00",
        "closed_at": "2024-05-22T04:50:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 10,
        "title": "Need develop branch.",
        "body": "New feature or hot-fix should be pushed to `develop` branch first. The `master` branch should maintain the stable version. We can polish the conversion for `fit_a_line` model and when the model is well supported we can ship it to `master` branch. Please vote for this proposal.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-04-09T05:37:30+00:00",
        "updated_at": "2018-04-10T07:11:52+00:00",
        "closed_at": "2018-04-10T07:11:52+00:00",
        "comments_count": [
            "varunarora",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 5,
        "title": "Validation for converted models for accuracy",
        "body": "The goal would be to get identical inference results to Paddle models and inference. @kuke has more thoughts. And here is a notebook on the topic: https://github.com/onnx/tutorials/blob/master/tutorials/CorrectnessVerificationAndPerformanceComparison.ipynb.\r\n\r\nQ: what runtime would we use for ONNX: TensorRT?",
        "state": "closed",
        "user": "varunarora",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-04T22:46:32+00:00",
        "updated_at": "2024-05-22T04:51:20+00:00",
        "closed_at": "2024-05-22T04:51:20+00:00",
        "comments_count": [
            "kuke",
            "varunarora",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 6,
        "title": "Revise the design again for final review ",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "varunarora",
        "created_at": "2018-04-05T15:57:48+00:00",
        "updated_at": "2018-05-22T18:58:40+00:00",
        "closed_at": "2018-05-22T18:58:40+00:00",
        "comments_count": [
            "varunarora",
            "kuke",
            "varunarora"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 3,
        "title": "Loading Paddle parameters",
        "body": "We need to figure out whether Paddle params will be read:\r\n- in C++ using an executor run, \r\n- in C++ using a new interface just for reading\r\n- in Python, with logic identical to C++ logic\r\n\r\nAdditionally, we need to get on the same page with populating the graph with parameters",
        "state": "closed",
        "user": "varunarora",
        "closed_by": "varunarora",
        "created_at": "2018-04-04T22:42:19+00:00",
        "updated_at": "2018-04-09T18:56:02+00:00",
        "closed_at": "2018-04-09T18:56:02+00:00",
        "comments_count": [
            "kuke",
            "varunarora"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 16,
        "title": "Fix travis-ci problems",
        "body": "Travis-ci always failed",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-10T09:32:49+00:00",
        "updated_at": "2018-04-10T10:00:11+00:00",
        "closed_at": "2018-04-10T10:00:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 18,
        "title": "Convert the recognize_digits models",
        "body": "Two models included: ```recognize_digits_conv``` and ```recognize_digits_mlp```\r\n\r\nhttps://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/book/test_recognize_digits.py",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-12T03:11:46+00:00",
        "updated_at": "2018-04-16T01:36:39+00:00",
        "closed_at": "2018-04-16T01:36:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 25,
        "title": "Need Add exception checker for operator conversion.",
        "body": null,
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-15T10:44:32+00:00",
        "updated_at": "2024-07-15T03:53:39+00:00",
        "closed_at": "2024-07-15T03:53:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 23,
        "title": "Need consider compatibility",
        "body": "Please add the following `import` at the head of each python file.\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\n```",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-13T05:45:09+00:00",
        "updated_at": "2024-05-22T04:51:32+00:00",
        "closed_at": "2024-05-22T04:51:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 28,
        "title": "Design the unit test framework to test operators‘ conversion",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-17T05:08:48+00:00",
        "updated_at": "2018-04-21T02:59:04+00:00",
        "closed_at": "2018-04-21T02:59:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 22,
        "title": "Seems we need add unit test to make sure onnx work properly.",
        "body": "I execute `sh setup.sh` and all python dependencies are installed successfully. However, I can't run `convert.py` and the error message is:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"convert.py\", line 18, in <module>\r\n    from onnx import helper, checker\r\n  File \"/usr/local/lib/python2.7/dist-packages/onnx/__init__.py\", line 10, in <module>\r\n    import onnx.helper  # noqa\r\n  File \"/usr/local/lib/python2.7/dist-packages/onnx/helper.py\", line 15, in <module>\r\n    import onnx.defs as defs\r\n  File \"/usr/local/lib/python2.7/dist-packages/onnx/defs/__init__.py\", line 6, in <module>\r\n    import onnx.onnx_cpp2py_export.defs as C\r\nImportError: /usr/local/lib/python2.7/dist-packages/onnx/onnx_cpp2py_export.so: undefined symbol: _ZNK6google8protobuf7Message13SpaceUsedLongEv\r\n```",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-13T03:07:51+00:00",
        "updated_at": "2024-05-22T04:51:46+00:00",
        "closed_at": "2024-05-22T04:51:46+00:00",
        "comments_count": [
            "kuke",
            "pkuyym"
        ],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 31,
        "title": "Enable the conversion of vgg16 & resnet model",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-24T08:12:05+00:00",
        "updated_at": "2018-04-26T23:57:34+00:00",
        "closed_at": "2018-04-26T23:57:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 24,
        "title": "Some important feedforward models to be supported at first stage",
        "body": "We are going to support  the conversion of models as follows at first stage. They all can be found in our models bank, some maybe only need to be verified after #19 merged, and some lack of necessary operators. \r\n\r\n- [x]  [recognize_digits](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/book/test_recognize_digits.py) ( #19 @kuke)\r\n- [x]  [ResNet50](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/book/test_image_classification.py#L27)  (#30 #32  @kuke)\r\n- [x]  [VGG16](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/book/test_image_classification.py#L69) (#30 #32  @kuke)\r\n- [x]  [MobileNet](https://github.com/PaddlePaddle/models/blob/develop/fluid/image_classification/mobilenet.py) (#30 #33  @kuke)\r\n- [x]  [SE-ResNeXt](https://github.com/PaddlePaddle/models/blob/develop/fluid/image_classification/se_resnext.py) (#30 #33  @kuke)\r\n- [x]  Inception-v4 (first add the Fluid config in [models/fluid/image_classification](https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification)) ([#900](https://github.com/PaddlePaddle/models/pull/900) [#49](https://github.com/PaddlePaddle/paddle-onnx/pull/49) @kuke)\r\n\r\nEven all the models above are supported, only a small subset of [operators](https://github.com/onnx/onnx/blob/master/docs/Operators.md)  are used and verified. So for the rest operators, we may need another task:\r\n\r\n- [x] Design the unit test framework to test every operator's conversion (#29 @kuke)\r\n\r\nHints:\r\n- Choose one task every time and assign yourself when you are really ready for working on it; \r\n- Please append the model to the **supported models** section in README like #19 after its conversion being validated.",
        "state": "closed",
        "user": "kuke",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-04-14T04:41:20+00:00",
        "updated_at": "2024-07-15T03:53:32+00:00",
        "closed_at": "2024-07-15T03:53:32+00:00",
        "comments_count": [
            "pkuyym",
            "sidgoyal78",
            "kuke",
            "varunarora",
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 27,
        "title": "We need distinguish persistable vars and const op",
        "body": "Currently, we simply use a `Constant` operator to handle persistable variables. I think instead we should use \r\n``initializes`` field of onnx graph proto. Since in fluid, we have constant operators, please consider this case:\r\n```\r\n        cell_init = fluid.layers.fill_constant_batch_size_like(\r\n            input=decoder_boot,\r\n            value=0.0,\r\n            shape=[-1, decoder_size],\r\n            dtype='float32')\r\n        cell_init.stop_gradient = False\r\n\r\n        with rnn.block():\r\n            current_word = rnn.step_input(target_embedding)\r\n            encoder_vec = rnn.static_input(encoder_vec)\r\n            encoder_proj = rnn.static_input(encoder_proj)\r\n```\r\n```cell_init``` should be the constant op which is not trainable.",
        "state": "closed",
        "user": "pkuyym",
        "closed_by": "pkuyym",
        "created_at": "2018-04-17T03:08:46+00:00",
        "updated_at": "2018-05-17T03:30:11+00:00",
        "closed_at": "2018-05-17T03:30:11+00:00",
        "comments_count": [
            "varunarora",
            "pkuyym"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 34,
        "title": "Enable the conversion of MobileNet & SE_ResNeXt model",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-25T15:22:14+00:00",
        "updated_at": "2018-04-26T23:57:34+00:00",
        "closed_at": "2018-04-26T23:57:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 39,
        "title": "Add some common used operators' conversion ",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-04-27T17:50:12+00:00",
        "updated_at": "2018-04-29T12:21:35+00:00",
        "closed_at": "2018-04-29T12:21:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 41,
        "title": "Refine quotes' format and comments & add new operators",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-05-02T17:38:56+00:00",
        "updated_at": "2018-05-04T06:30:03+00:00",
        "closed_at": "2018-05-04T06:30:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 44,
        "title": "Fix the fetch var bug when the arg is renamed",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-05-04T09:35:39+00:00",
        "updated_at": "2018-05-06T05:57:57+00:00",
        "closed_at": "2018-05-06T05:57:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 37,
        "title": "Support DS2 model",
        "body": "Do you plan to support the conversion for [DeepSpeech](https://github.com/PaddlePaddle/DeepSpeech)?",
        "state": "closed",
        "user": "VictorBebnev",
        "closed_by": "VictorBebnev",
        "created_at": "2018-04-27T09:35:27+00:00",
        "updated_at": "2018-05-03T07:27:15+00:00",
        "closed_at": "2018-05-03T07:27:14+00:00",
        "comments_count": [
            "kuke",
            "VictorBebnev",
            "kuke",
            "VictorBebnev",
            "kuke",
            "VictorBebnev",
            "kuke",
            "VictorBebnev",
            "kuke",
            "VictorBebnev"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 36,
        "title": "import paddle.fluid as fluid ImportError: No module named fluid",
        "body": "Using `pip install paddlepaddle`, I get the paddlepaddle (0.11.0).\r\nAfter that I tried `python convert.py --modeldir inception_v1/`, I get the error: `import paddle.fluid as fluid ImportError: No module named fluid`.\r\n\r\nThen I tried to change `import paddle.v2.fluid as fluid`, it works.\r\n\r\nRerunning the converter and get the following error:\r\n\r\n```Traceback (most recent call last):\r\n  File \"/home/haifeng/Synopsys/paddle-onnx/convert.py\", line 21, in <module>\r\n    import fluid_onnx.ops as ops\r\n  File \"/home/haifeng/Synopsys/paddle-onnx/fluid_onnx/ops.py\", line 17, in <module>\r\n    from paddle.fluid.executor import fetch_var\r\nImportError: No module named fluid.executor\r\n```\r\n\r\nIt seems the converter use different paddlepaddle version.\r\nCould you look into it?\r\n\r\nThanks",
        "state": "closed",
        "user": "haifenghan",
        "closed_by": "haifenghan",
        "created_at": "2018-04-26T10:53:46+00:00",
        "updated_at": "2018-08-02T08:07:10+00:00",
        "closed_at": "2018-08-02T08:07:10+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 50,
        "title": "ONNX operators used in image classification models",
        "body": "- recognize_digits: `Conv`, `Add`, `Relu`, `MaxPool`, `BatchNormalization`, `Reshape`, `MatMul`, `Softmax`, `Tanh`\r\n\r\n- ResNet: `Conv`, `Add`, `Relu`, `AveragePool`, `Reshape`, `MatMul`, `Softmax`\r\n\r\n- VGG: `Conv`, `Add`, `Relu`, `Dropout`, `Constant`, `Mul`, `MaxPool`, `Reshape`, `MatMul`, `BatchNormalization`, `Softmax`\r\n\r\n- MobileNet: `Conv`, `BatchNormalization`, `Relu`, `GlobalAveragePool`, `Reshape`, `MatMul`, `Add`, `Softmax`\r\n\r\n- SE_ResNeXt: `Conv`, `BatchNormalization`, `Relu`, `MaxPool`, `GlobalAveragePool`, `Reshape`, `MatMul`, `Add`, `Sigmoid`, `Mul`, `Dropout`, `Constant`, `Softmax`\r\n\r\n- Inception V4: `Conv`, `BatchNormalization`, `MaxPool`, `Concat`, `AveragePool`, `Dropout`, `Constant`, `Mul`, `Reshape`, `MatMul`, `Add`, `Softmax`\r\n\r\nONNX == `1.0.1`, Data layout == `NCHW`\r\n",
        "state": "closed",
        "user": "kuke",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-05-18T12:15:19+00:00",
        "updated_at": "2024-05-22T04:49:30+00:00",
        "closed_at": "2024-05-22T04:49:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 46,
        "title": "Adapt the convertor to tensorrt backend ",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "kuke",
        "created_at": "2018-05-09T09:21:29+00:00",
        "updated_at": "2018-05-16T01:29:19+00:00",
        "closed_at": "2018-05-16T01:29:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 42,
        "title": "Remind users to install caffe2 if they want to run unit test or validation ",
        "body": "",
        "state": "closed",
        "user": "kuke",
        "closed_by": "varunarora",
        "created_at": "2018-05-03T02:10:25+00:00",
        "updated_at": "2018-05-16T21:14:40+00:00",
        "closed_at": "2018-05-16T21:14:40+00:00",
        "comments_count": [
            "varunarora"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 52,
        "title": "Issues using paddle onnx convert models",
        "body": "We ran into the following issues and would like to get direction from paddle-onnx dev.\r\n\r\n**1.  assertion error : dims.nbDims == 3**\r\n\r\nI can convert paddle paddle models to onnx using the fluid_to_onnx.py script, e.g.\r\n \r\n(venv) root@c33e4b787188:~/paddle-onnx# python fluid_to_onnx.py --fluid_model extras/fit_a_line.inference.model --onnx_model extras/fit_a_line.onnx.inference.model --to_print_model > extras/fit_a_line_onnx.inference.model.out \r\n(venv) root@c33e4b787188:~/paddle-onnx# cd extras\r\n(venv) root@c33e4b787188:~/paddle-onnx/extras# ls\r\nfit_a_line.inference.model  fit_a_line.onnx.inference.model  fit_a_line_onnx.inference.model.out\r\n \r\n \r\nbut when I try to validate the resulting onnx model using the validate.py script I get the following error when using the tensorrt backend:\r\n \r\n(venv) root@c33e4b787188:~/paddle-onnx# deactivate\r\nroot@c33e4b787188:~/paddle-onnx# python validate.py --fluid_model extras/fit_a_line.inference.model --onnx_model extras/fit_a_line.onnx.inference.model --backend tensorrt\r\n-----------  Configuration Arguments -----------\r\na: 0.0\r\nb: 1.0\r\nbackend: tensorrt\r\nbatch_size: 10\r\nexpected_decimal: 5\r\nfluid_model: extras/fit_a_line.inference.model\r\nonnx_model: extras/fit_a_line.onnx.inference.model\r\n------------------------------------------------\r\nInference results for fluid model:\r\n[array([[15.874767],\r\n       [17.174097],\r\n       [14.951813],\r\n       [14.069194],\r\n       [13.003316],\r\n       [17.782452],\r\n       [16.204231],\r\n       [13.260891],\r\n       [15.537827],\r\n       [13.720056]], dtype=float32)]\r\n \r\n \r\nTraceback (most recent call last):\r\n  File \"validate.py\", line 129, in <module>\r\n    validate(args)\r\n  File \"validate.py\", line 113, in validate\r\n    rep = backend.prepare(onnx_model, device='CUDA:0')\r\n  File \"build/bdist.linux-x86_64/egg/onnx_tensorrt/backend.py\", line 166, in prepare\r\n  File \"build/bdist.linux-x86_64/egg/onnx_tensorrt/backend.py\", line 71, in __init__\r\nRuntimeError: While parsing node number 1:\r\n/root/onnx-tensorrt/builtin_op_importers.cpp:539 In function importFlatten:\r\n[8] Assertion failed: dims.nbDims == 3\r\n\r\n\r\n**2. Issue 2 : dim_value 0**\r\n\r\nWe see some dim_value of 0 in the generated model. Is this expected and how those should be interpreted. \r\n\r\nWhen I look at the human readable onnx model, i.e. fit_a_line_onnx.inference.model.out that was generated by the fluid_to_onnx.py script there are nodes with dim_value of 0:\r\n \r\n(venv) root@c33e4b787188:~/paddle-onnx/extras# cat fit_a_line_onnx.inference.model.out | more\r\n \r\n-----------  Configuration Arguments -----------\r\nfluid_model: extras/fit_a_line.inference.model\r\nonnx_model: extras/fit_a_line.onnx.inference.model\r\nto_print_model: True\r\n------------------------------------------------\r\nThe converted model is:\r\nir_version: 3\r\nproducer_name: \"PaddlePaddle\"\r\ngraph {\r\n  node {\r\n    input: \"x\"\r\n    output: \"x@flatten_0\"\r\n    op_type: \"Flatten\"\r\n    attribute {\r\n      name: \"axis\"\r\n      i: 1\r\n      type: INT\r\n    }\r\n  }\r\n  node {\r\n    input: \"fc_0.w_0\"\r\n    output: \"fc_0.w_0@flatten_0\"\r\n    op_type: \"Flatten\"\r\n    attribute {\r\n      name: \"axis\"\r\n      i: 1\r\n      type: INT\r\n    }\r\n  }\r\n  node {\r\n    input: \"x@flatten_0\"\r\n    input: \"fc_0.w_0@flatten_0\"\r\n    output: \"fc_0.tmp_0@matmul_0\"\r\n    op_type: \"MatMul\"\r\n  }\r\nnode {\r\n    output: \"fc_0.tmp_0@shape_0\"\r\n    op_type: \"Constant\"\r\n    attribute {\r\n      name: \"value\"\r\n      t {\r\n        dims: 2\r\n        data_type: INT64\r\n        int64_data: 0\r\n        int64_data: 1\r\n        name: fc_0.tmp_0@shape_0\r\n      }\r\n      type: TENSOR\r\n    }\r\n  }\r\n  node {\r\n    input: \"fc_0.tmp_0@matmul_0\"\r\n    input: \"fc_0.tmp_0@shape_0\"\r\n    output: \"fc_0.tmp_0\"\r\n    op_type: \"Reshape\"\r\n  }\r\n  node {\r\n    input: \"fc_0.tmp_0\"\r\n    input: \"fc_0.b_0\"\r\n    output: \"fc_0.tmp_1\"\r\n    op_type: \"Add\"\r\n    attribute {\r\n      name: \"axis\"\r\n      i: 1\r\n      type: INT\r\n    }\r\n    attribute {\r\n      name: \"broadcast\"\r\n      i: 1\r\n      type: INT\r\n    }\r\n  }\r\n  name: \"fit_a_line\"\r\n  initializer {\r\n    dims: 1\r\n    data_type: FLOAT\r\n    float_data: 19.3055801392\r\n    name: \"fc_0.b_0\"\r\n  }\r\n  initializer {\r\n    dims: 13\r\n    dims: 1\r\n    data_type: FLOAT\r\n    float_data: -0.235716566443\r\n    float_data: 1.50793659687\r\n    float_data: -1.37839913368\r\n    float_data: 0.587660908699\r\n    float_data: -1.62691628933\r\n    float_data: 1.94002008438\r\n    float_data: -1.5584435463\r\n    float_data: 1.01809895039\r\n    float_data: -2.47688126564\r\n    float_data: -2.48663592339\r\n    float_data: -2.72155380249\r\n    float_data: 1.01887917519\r\n    float_data: -2.73560881615\r\n    name: \"fc_0.w_0\"\r\n  }\r\n  input {\r\n    name: \"x\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: FLOAT\r\n        shape {\r\n          dim {\r\n            dim_value: 0\r\n          }\r\n          dim {\r\n            dim_value: 13\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  input {\r\n    name: \"fc_0.b_0\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: FLOAT\r\n        shape {\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  input {\r\n    name: \"fc_0.w_0\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: FLOAT\r\n        shape {\r\n          dim {\r\n            dim_value: 13\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  output {\r\n    name: \"fc_0.tmp_1\"\r\n    type {\r\n      tensor_type {\r\n        elem_type: FLOAT\r\n        shape {\r\n          dim {\r\n            dim_value: 0\r\n          }\r\n          dim {\r\n            dim_value: 1\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nopset_import {\r\n  version: 7\r\n}\r\n \r\nSaved converted model to path: extras/fit_a_line.onnx.inference.model\r\n \r\n \r\nI get the same results after converting the recognize_digits_mlp.inference.model from the paddle paddle repo’s /path-to-repo/paddle-paddle/python/paddle/fluid/tests/book directory…",
        "state": "closed",
        "user": "baojun-nervana",
        "closed_by": "baojun-nervana",
        "created_at": "2018-06-05T21:37:16+00:00",
        "updated_at": "2018-06-12T17:55:03+00:00",
        "closed_at": "2018-06-12T17:55:03+00:00",
        "comments_count": [
            "baojun-nervana",
            "varunarora",
            "varunarora",
            "baojun-nervana",
            "varunarora",
            "kuke",
            "varunarora",
            "kuke",
            "varunarora",
            "kuke",
            "baojun-nervana",
            "kuke",
            "baojun-nervana",
            "kuke",
            "raramer01",
            "varunarora",
            "raramer01",
            "varunarora",
            "baojun-nervana"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 53,
        "title": "Undefined shape value in paddle generated onnx model",
        "body": "Paddle-ONNX generated model set dim_value=0 as placeholder for parameters to be set by the user, such as batch size. It seems there is no facility in ONNX to store undefined shape value, such as 0. \r\n\r\nThe undefined value broke ngraph-onnx importer and this thread is to open a discuss to seek a solution. \r\n\r\nThere is patch developed by @arogowie-intel which can be submitted to review. That is one the option.\r\n\r\nSee more info here: https://github.com/PaddlePaddle/paddle-onnx/issues/52\r\n\r\nCC @kuke @varunarora @postrational @raramer01",
        "state": "closed",
        "user": "baojun-nervana",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-06-12T17:49:50+00:00",
        "updated_at": "2024-05-22T04:49:55+00:00",
        "closed_at": "2024-05-22T04:49:55+00:00",
        "comments_count": [
            "postrational",
            "kuke",
            "postrational",
            "baojun-nervana",
            "varunarora",
            "varunarora",
            "postrational",
            "varunarora",
            "kuke",
            "postrational",
            "varunarora",
            "kuke",
            "winston-zillow"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 61,
        "title": "When will paddle-onnx support conversion of `depthwise_conv2d_transpose` used in PyramidBox?",
        "body": null,
        "state": "closed",
        "user": "yxchng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-03-28T06:48:23+00:00",
        "updated_at": "2024-07-15T03:53:44+00:00",
        "closed_at": "2024-07-15T03:53:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 57,
        "title": "Fluid2ONNX conversion on the example",
        "body": "Hello, I met an issue on conversion from fluid to ONNX model on the example. Anyone can help?\r\n\r\n-----------  Configuration Arguments -----------\r\nfluid_model: extras/fit_a_line.inference.model/\r\nonnx_model: test.onnx\r\nto_print_model: False\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"fluid_to_onnx.py\", line 143, in <module>\r\n    convert(args)\r\n  File \"fluid_to_onnx.py\", line 67, in convert\r\n    var=var, scope=inference_scope)\r\n  File \"/home/test/paddle-onnx/fluid_onnx/variables.py\", line 39, in paddle_onnx_weight\r\n    data = _fetch_var(var.name, scope)\r\n  File \"/home/test/.local/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 191, in _fetch_var\r\n    assert isinstance(name, str)\r\nAssertionError\r\n\r\nONNX version: 1.2.2+ (pip install on centos 7.2)\r\nPaddle: github Aug 28th\r\n",
        "state": "closed",
        "user": "hshen14",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2018-08-30T12:19:44+00:00",
        "updated_at": "2024-05-22T05:07:49+00:00",
        "closed_at": "2024-05-22T05:07:49+00:00",
        "comments_count": [
            "kuke"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 63,
        "title": "依赖的环境问题",
        "body": "根据requirements.txt尝试了几种环境组合，依然报错，请问拿release的1.0版本来说，下面的环境是哪个版本啊\r\nprotobuf==?\r\nonnx==?\r\npaddlepaddle==?\r\n",
        "state": "closed",
        "user": "CanJie",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-06-11T08:46:06+00:00",
        "updated_at": "2024-05-22T05:05:47+00:00",
        "closed_at": "2024-05-22T05:05:47+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "Doc"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 62,
        "title": "个别op目前暂不支持",
        "body": "我把ernie的inference model存下来后, 作为paddle-onnx的输入, 然后就报了这样的错：\r\n![image](https://user-images.githubusercontent.com/13281461/55929170-593ce900-5bd0-11e9-99ec-374170d3f473.png)\r\n请问有什么解决方案吗? 十分感谢！",
        "state": "closed",
        "user": "GeminiHu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-04-11T03:37:25+00:00",
        "updated_at": "2024-05-22T05:06:03+00:00",
        "closed_at": "2024-05-22T05:06:03+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 59,
        "title": "ImportError: cannot import name fetch_var",
        "body": "\r\n\r\n![_ _20181125113011](https://user-images.githubusercontent.com/22513244/48975195-30470c00-f0a6-11e8-8739-f532f62b7125.png)\r\n",
        "state": "closed",
        "user": "liyungithub",
        "closed_by": "liyungithub",
        "created_at": "2018-11-25T03:35:36+00:00",
        "updated_at": "2019-02-05T04:52:57+00:00",
        "closed_at": "2018-11-30T12:21:35+00:00",
        "comments_count": [
            "FrankWork",
            "liyungithub",
            "sicarioakki"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 60,
        "title": "paddle1.3.0隐藏了fetch_var接口，无法使用paddle-onnx",
        "body": "paddle1.3.0隐藏了fetch_var接口，无法使用paddle-onnx。。。",
        "state": "closed",
        "user": "daiwk",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-03-15T20:36:23+00:00",
        "updated_at": "2024-05-22T05:06:19+00:00",
        "closed_at": "2024-05-22T05:06:19+00:00",
        "comments_count": [
            "daiwk",
            "yxchng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 71,
        "title": "Have it support convert pretrained nlp model from PaddlePaddle to tensorflow ?",
        "body": "I want to convert pretrained nlp model from PaddlePaddle to tensorflow ?\r\nlike bert or elmo (https://github.com/PaddlePaddle/LARK/tree/develop/BERT).\r\nIs that have been supported and tested?",
        "state": "closed",
        "user": "312shan",
        "closed_by": "wawltor",
        "created_at": "2019-08-26T13:07:44+00:00",
        "updated_at": "2019-08-28T12:19:14+00:00",
        "closed_at": "2019-08-28T12:19:14+00:00",
        "comments_count": [
            "wawltor"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 86,
        "title": "import paddle.fluid & import onnx will be core_dump",
        "body": "microsoft/onnxruntime#1541\r\npybind/pybind11#1262\r\nhttps://github.com/onnx/onnx/issues/2339\r\n\r\nUpdate pybind to the latest version can solve this.",
        "state": "closed",
        "user": "snnn",
        "closed_by": "snnn",
        "created_at": "2019-09-19T17:30:43+00:00",
        "updated_at": "2020-05-16T21:29:55+00:00",
        "closed_at": "2020-05-16T21:29:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 100,
        "title": "转化yolov3 mobilenet backbone 出错。",
        "body": "使用configs/yolov3_mobilenet_v1.yml 配置文件，其中按照自己数据集的相关信息，修改配置文件，训练好的模型采用 paddledetection库中的tools/export_model.py把模型进行导出，而后使用paddle2onnx\r\n准备导出onnx模型，出错信息如下：\r\n使用的相关软件包的版本为:\r\n paddlepaddle-gpu     1.6.1.post107 \r\npaddle2onnx          0.2\r\n \r\n![Screenshot from 2019-12-23 16-39-24-2](https://user-images.githubusercontent.com/8900080/71347420-512da980-25a5-11ea-9494-03dd44f88a7f.png)\r\n",
        "state": "closed",
        "user": "dragon515",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-12-23T09:02:27+00:00",
        "updated_at": "2024-05-22T05:07:23+00:00",
        "closed_at": "2024-05-22T05:07:18+00:00",
        "comments_count": [],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 94,
        "title": "Paddle2onnx支持DeepASRmodel吗",
        "body": "你好，Paddle2onnx支持DeepASRmodel吗？或者有没有什么方法可以进行这样的转换？",
        "state": "closed",
        "user": "MornJ",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-10-23T02:18:10+00:00",
        "updated_at": "2024-07-15T03:53:25+00:00",
        "closed_at": "2024-07-15T03:53:19+00:00",
        "comments_count": [
            "wawltor",
            "MornJ",
            "MornJ",
            "cjt222"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 95,
        "title": "转换yolov3报错的问题",
        "body": "使用paddlepaddle1.5版本，下载了model_zoo中的yolov3_darknet_voc，使用PaddlePaddle中PaddleDetection中的infer.py生成__model__和参数文件，再使用paddle2onnx进行转换，碰到了leaky_relu层的输入参数不匹配的问题，可能是什么原因？\r\n![image](https://user-images.githubusercontent.com/57127805/67744414-65996e00-fa5c-11e9-8449-c103fe24aadc.png)\r\n",
        "state": "closed",
        "user": "spiritsky123",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-10-29T06:57:22+00:00",
        "updated_at": "2024-05-22T05:07:56+00:00",
        "closed_at": "2024-05-22T05:07:56+00:00",
        "comments_count": [
            "spiritsky123",
            "cjt222",
            "spiritsky123",
            "spiritsky123",
            "cjt222",
            "spiritsky123",
            "spiritsky123",
            "cjt222",
            "spiritsky123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 103,
        "title": "Implement stack, layer_norm, gelu, lookup_table operators",
        "body": "Pull request at https://github.com/PaddlePaddle/paddle2onnx/pull/105",
        "state": "closed",
        "user": "winston-zillow",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-01-06T18:06:37+00:00",
        "updated_at": "2024-05-22T05:04:44+00:00",
        "closed_at": "2024-05-22T05:04:44+00:00",
        "comments_count": [],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 93,
        "title": "FileNotFoundError: [Errno 2] No such file or directory: '/home/work/******params/__model__'",
        "body": "-----------  Configuration Arguments -----------\r\ncheck_task: image_classification\r\ndebug: False\r\nfluid_model: /home/work/luqiankun/tools_for_renfeng/qt_batchlist_31w_bak/params/\r\nfluid_model_name:\r\nfluid_params_name:\r\nimage_path:\r\nname_prefix:\r\nonnx_model: ERNIE2.0\r\nreturn_variable: False\r\nto_print_model: False\r\n------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/ssd1/share/python36/bin/paddle2onnx\", line 11, in <module>\r\n    load_entry_point('paddle2onnx==0.1', 'console_scripts', 'paddle2onnx')()\r\n  File \"/ssd1/share/python36/lib/python3.6/site-packages/paddle2onnx-0.1-py3.6.egg/fluid_onnx/fluid_to_onnx.py\", line 230, in main\r\n  File \"/ssd1/share/python36/lib/python3.6/site-packages/paddle2onnx-0.1-py3.6.egg/fluid_onnx/fluid_to_onnx.py\", line 99, in convert\r\n  File \"/ssd1/share/python36/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1199, in load_inference_model\r\n    with open(model_filename, \"rb\") as f:\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/work/******/params/__model__'\r\n\r\n运行代码报错 __model__文件是什么？我再paddle里下的ernie模型里也没有这个文件呀",
        "state": "closed",
        "user": "geniusSDNexplorer",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2019-10-22T03:59:36+00:00",
        "updated_at": "2024-05-22T05:07:44+00:00",
        "closed_at": "2024-05-22T05:07:44+00:00",
        "comments_count": [
            "guoshengCS",
            "wawltor",
            "shoegazerstella",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 99,
        "title": "转stnet报错",
        "body": "将stnet训练的模型，想转onnx，但是却报错了\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Nodes in a graph must be topologically sorted, however input 'conv3d_0.tmp_0' of node: \r\ninput: \"conv3d_0.tmp_0\" input: \"conv3d_0.tmp_1@reshape_y\" output: \"conv3d_0.tmp_1\" op_type: \"Add\"\r\n is not output of any previous nodes.\r\n\r\n环境：ubuntu 16.04\r\npaddle版本： paddlepaddle-gpu       1.6.1.post107\r\nonnx版本:       onnx                   1.5.0",
        "state": "closed",
        "user": "thunder95",
        "closed_by": "cjt222",
        "created_at": "2019-11-27T09:42:03+00:00",
        "updated_at": "2020-06-10T06:41:14+00:00",
        "closed_at": "2020-02-26T08:53:54+00:00",
        "comments_count": [
            "thunder95",
            "cjt222",
            "amandazw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 101,
        "title": "paddle模型转换为onnx，上线出现错误。",
        "body": "现象：一个最基本的乘法，转换为onnx文件后，上线报错。错误信息：\r\n\r\n![441188a12e273f99aa4c9c2cf](https://user-images.githubusercontent.com/19485646/71468099-da401d00-27ff-11ea-8f3f-b26806f06bab.png)\r\n\r\n\r\n环境：paddle环境是1.5 ，paddle2onnx 是0.2\r\n\r\npaddle部分的代码：\r\n\r\n```python\r\nimport paddle.fluid.layers as layers\r\ndataX = fluid.layers.data(name=\"dataX\", append_batch_size = False, shape=[2, 5],dtype=\"float32\")\r\nw = layers.create_parameter(shape=[5, 3], dtype='float32', is_bias=False)\r\noutput = fluid.layers.mul(dataX, w,\r\n                          x_num_col_dims = 1,\r\n                          y_num_col_dims = 1)\r\n\r\nplace = fluid.CUDAPlace(0)\r\nexe = fluid.Executor(place)\r\nexe.run(fluid.default_startup_program())\r\ninfer_path = os.path.join('./', 'ckp-infer2')\r\nif not os.path.isdir(infer_path):\r\n    os.makedirs(infer_path)\r\nfluid.io.save_inference_model(main_program=fluid.default_main_program(),\r\n                              dirname=infer_path,\r\n                              feeded_var_names=[dataX.name],\r\n                              target_vars=[output],\r\n                              executor=exe)\r\n```\r\n\r\n然后转换为onnx的命令：\r\n\r\n```bash\r\npaddle2onnx --fluid_model ckp-infer2/  --onnx_model paddle2onnx_test\r\n```\r\n看onnx文件，发现里面确实有一个reshape的操作。不清楚为什么\r\n![image](https://user-images.githubusercontent.com/19485646/71468898-7b2fd780-2802-11ea-9e70-56d5627fda20.png)\r\n",
        "state": "closed",
        "user": "ForFishes",
        "closed_by": "cjt222",
        "created_at": "2019-12-26T08:44:22+00:00",
        "updated_at": "2020-02-25T02:33:45+00:00",
        "closed_at": "2020-02-25T02:33:45+00:00",
        "comments_count": [
            "cjt222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 106,
        "title": "Operator unit tests broken",
        "body": "Many unit tests seem to be broken for me on the `develop` branch.\r\n\r\nIn particular, the hard-coding of output var type is problematic:\r\n```python\r\n    def append_input_output(self, block, op_proto, np_list, persistable_list, is_input):\r\n        ...\r\n        def create_var(block, name, np_list, var_proto):\r\n            ...\r\n            return block.create_var(\r\n                dtype='float32',\r\n                shape=shape,\r\n                persistable=persistable,\r\n                lod_level=lod_level,\r\n                name=name)\r\n```\r\nHowever, making the type from `np_val` will fix some tests but break many others.\r\n",
        "state": "closed",
        "user": "winston-zillow",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-01-17T01:33:43+00:00",
        "updated_at": "2024-05-22T05:08:01+00:00",
        "closed_at": "2024-05-22T05:08:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 114,
        "title": "Face Mask Detection model of baidu 2 onnx ,paddleHub2onnx, pyramidbox_lite_server_mask==1.1.0  ",
        "body": "onnx.onnx_cpp2py_export.checker.ValidationError: Graph must be in single static assignment (SSA) form, however '@HUB_pyramidbox_lite_server_mask@conv2d_52.tmp_2@flatten_0' has been used as output names multiple times.\r\n",
        "state": "closed",
        "user": "xxixi2009",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-03-05T08:36:54+00:00",
        "updated_at": "2024-07-15T03:53:12+00:00",
        "closed_at": "2024-07-15T03:53:03+00:00",
        "comments_count": [],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 110,
        "title": "stargan预训练模型怎样转换成onnx",
        "body": "这个是paddlepaddle的stargan的预训练模型：https://paddle-gan-models.bj.bcebos.com/stargan_G.tar.gz\r\n怎样转成onnx模型？\r\npaddle2onnx --fluid_model_name .DS_Store --fluid_model stargan --onnx_model .\r\n用以上命令行老是显示没有错误：FileNotFoundError: [Errno 2] No such file or directory: 'stargan\\\\__model__'\r\n这个预训练模型名字是什么？",
        "state": "closed",
        "user": "githubusr2",
        "closed_by": "githubusr2",
        "created_at": "2020-02-13T16:54:43+00:00",
        "updated_at": "2020-02-22T01:09:34+00:00",
        "closed_at": "2020-02-22T01:09:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 108,
        "title": "转yolov3  paddle1.5.1",
        "body": "aistudio@jupyter-83877-140942:~$ paddle2onnx --fluid_model freeze_model/  --onnx_model onnxyolov3.onnx/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n-----------  Configuration Arguments -----------\r\ncheck_task: image_classification\r\ndebug: False\r\nfluid_model: freeze_model/\r\nfluid_model_name: \r\nfluid_params_name: \r\nimage_path: \r\nname_prefix: \r\nonnx_model: onnxyolov3.onnx\r\nreturn_variable: False\r\nto_print_model: False\r\n------------------------------------------------\r\nload the model parameter done.\r\nThe operator sets to run test case.\r\n{'nearest_interp', 'yolo_box', 'shape', 'batch_norm', 'multiclass_nms', 'conv2d', 'transpose2', 'cast', 'concat', 'fill_constant', 'leaky_relu', 'slice', 'elementwise_mul', 'scale', 'elementwise_add'}\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 230, in main\r\n    convert(args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 194, in convert\r\n    checker.check_model(onnx_model)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/onnx/checker.py\", line 91, in check_model\r\n    C.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Node () has input size 2 not in range [min=3, max=4].\r\n\r\n==> Context: Bad node spec: input: \"leaky_relu_58.tmp_0\" input: \"nearest_interp_0.tmp_0@scales\" output: \"nearest_interp_0.tmp_0\" op_type: \"Resize\" attribute { name: \"mode\" s: \"nearest\" type: STRING }",
        "state": "closed",
        "user": "zengxianyugithub",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-02-04T09:22:10+00:00",
        "updated_at": "2024-05-22T04:52:22+00:00",
        "closed_at": "2024-05-22T04:52:14+00:00",
        "comments_count": [
            "zengxianyugithub",
            "cjt222",
            "aixier",
            "aixier",
            "zengxianyugithub",
            "aixier",
            "cjt222",
            "cjt222"
        ],
        "labels": [
            "Bug",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 107,
        "title": "paddle2onnx ssd_mobilnet_v1",
        "body": "使用paddleDetection的ssd_mobilnet_v1训练获得的模型，使用此工具转换为onnx模型后，使用onnxruntime调用onnx模型检测不到正确的框，概率分数也较低，与真实相差很远。",
        "state": "closed",
        "user": "daigang896",
        "closed_by": "cjt222",
        "created_at": "2020-01-20T11:48:59+00:00",
        "updated_at": "2020-02-25T02:32:54+00:00",
        "closed_at": "2020-02-25T02:32:54+00:00",
        "comments_count": [
            "cjt222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 113,
        "title": "fluid_to_onnx show error",
        "body": "### i don't know what happens and how to solve it\r\n```\r\n-----------  Configuration Arguments -----------\r\ncheck_task: image_classification\r\ndebug: False\r\nfluid_model: ../mask_detector/\r\nfluid_model_name: __model__\r\nfluid_params_name: __param__\r\nimage_path: \r\nname_prefix: \r\nonnx_model: ./model.onnx\r\nreturn_variable: False\r\nto_print_model: False\r\n------------------------------------------------\r\nload the model parameter done.\r\nTraceback (most recent call last):\r\n  File \"fluid_to_onnx.py\", line 234, in <module>\r\n    main()\r\n  File \"fluid_to_onnx.py\", line 230, in main\r\n    convert(args)\r\n  File \"fluid_to_onnx.py\", line 141, in convert\r\n    block=block)\r\n  File \"/home/tu/anaconda3/envs/occlusion_face_paddle/lib/python3.7/site-packages/fluid_onnx/ops.py\", line 192, in conv2d_op\r\n    kernel_shape = block.vars[get_old_name(inputs['Filter'][0])].shape\r\nKeyError: ''\r\n```\r\n",
        "state": "closed",
        "user": "phamkhactu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-02-28T16:10:31+00:00",
        "updated_at": "2024-05-22T04:50:37+00:00",
        "closed_at": "2024-05-22T04:50:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 115,
        "title": "blazeface ? yolov3_prune578_distill ?",
        "body": "直接吐槽，看在百度在那打广告，facedetection和yolo看了下效果是挺好，训练自己数据应该也不难，对国产框架也寄予希望，但是这paddle真是难玩儿，下载的模型居然是文件夹反人类需要export才能是模型和参数，想在其他平台用也是难，现在主流芯片不应该都是支持caffe,onnx这些吗，难道非得用paddlelite才能用？，转换onnx还要有不同版本ops还不支持，终于找对了版本转换成了onnx，对比看了下结构差距也太大了吧和__model__中的结构。。。，对于一个封闭的框架是没有出路的，国产框架努努努力，奥再吐槽下，见过哪个框架的model不能用文本打开直接看内容的么，对就paddle的我看不懂",
        "state": "closed",
        "user": "Tim4AI",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-03-17T08:35:22+00:00",
        "updated_at": "2024-05-22T05:03:54+00:00",
        "closed_at": "2024-05-22T05:03:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 109,
        "title": "paddle转onnx出错",
        "body": "Python：Python 3.7\r\n转换框架版本：PaddlePaddle 1.5.1\r\npaddledetecton0.1:  darnet yolov3  训练的模型\r\npaddle2onnx： 0.2\r\n****训练参数和模型***：*https://github.com/PaddlePaddle/PaddleDetection/blob/release/0.1/configs/yolov3_darknet_voc.yml\r\n\r\n**使用转换命令**：paddle2onnx --fluid_model mj_yolov3_darknet/ --fluid_model_name mj_yolov3_darknet/model --fluid_params_name mj_yolov3_darknet/params --onnx_model mjy3\r\n**得到的结果,出错信息**\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\nimport imp\r\n----------- Configuration Arguments -----------\r\ncheck_task: image_classification\r\ndebug: False\r\nfluid_model: mj_yolov3_darknet/\r\nfluid_model_name: mj_yolov3_darknet/model\r\nfluid_params_name: mj_yolov3_darknet/params\r\nimage_path:\r\nname_prefix:\r\nonnx_model: mjy3\r\nreturn_variable: False\r\nto_print_model: False\r\n\r\nload the model parameter done.\r\nThe operator sets to run test case.\r\n{'concat', 'multiclass_nms', 'scale', 'conv2d', 'leaky_relu', 'batch_norm', 'yolo_box', 'nearest_interp', 'elementwise_add', 'transpose2'}\r\nTraceback (most recent call last):\r\nFile \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 10, in \r\nsys.exit(main())\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 230, in main\r\nconvert(args)\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 194, in convert\r\nchecker.check_model(onnx_model)\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/onnx/checker.py\", line 91, in check_model\r\nC.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Node () has input size 0 not in range [min=1, max=1].\r\n\r\n==> Context: Bad node spec: output: \"nearest_interp_0.tmp_0@out_size_f\" op_type: \"Cast\" attribute { name: \"to\" i: 1 type: INT }\r\n@cjt222 ",
        "state": "closed",
        "user": "aixier",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-02-08T06:50:19+00:00",
        "updated_at": "2024-05-22T05:04:13+00:00",
        "closed_at": "2024-05-22T05:04:07+00:00",
        "comments_count": [
            "aixier",
            "aixier",
            "cjt222",
            "leeburt",
            "cjt222",
            "leeburt",
            "cjt222"
        ],
        "labels": [
            "Bug",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 116,
        "title": "转模型一直失败，使用的是PaddleDetectionV1.6，转的是yolov3模型，测试过yolov3_darknet_voc和yolov3_mobilenet_v1_voc",
        "body": "错误信息：\r\n------------------------------------------------\r\nload the model parameter done.\r\nThe operator sets to run test case.\r\n{'yolo_box', 'concat', 'nearest_interp', 'multiclass_nms', 'leaky_relu', 'scale', 'elementwise_add', 'batch_norm', 'conv2d', 'transpose2'}\r\nTraceback (most recent call last):\r\n  File \"d:\\users\\administrator\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\users\\administrator\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Users\\Administrator\\Anaconda3\\Scripts\\paddle2onnx.exe\\__main__.py\", line 9, in <module>\r\n  File \"d:\\users\\administrator\\anaconda3\\lib\\site-packages\\fluid_onnx\\fluid_to_onnx.py\", line 230, in main\r\n    convert(args)\r\n  File \"d:\\users\\administrator\\anaconda3\\lib\\site-packages\\fluid_onnx\\fluid_to_onnx.py\", line 194, in convert\r\n    checker.check_model(onnx_model)\r\n  File \"d:\\users\\administrator\\anaconda3\\lib\\site-packages\\onnx\\checker.py\", line 91, in check_model\r\n    C.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Node () has input size 0 not in range [min=1, max=1].\r\n\r\n==> Context: Bad node spec: output: \"nearest_interp_0.tmp_0@out_size_f\" op_type: \"Cast\" attribute { name: \"to\" i: 1 type: INT }\r\n\r\n使用export_model.py导出模型的时候没有问题，检测模型是直接从这里下载的\r\n![image](https://user-images.githubusercontent.com/19625405/77242638-80eb5c80-6c3b-11ea-9fab-c971d6df53ea.png)\r\n输出为：\r\n2020-03-22 12:41:41,083-INFO: Loading parameters from output/yolov3_mobilenet_v1_voc...\r\n2020-03-22 12:41:41,084-WARNING: output/yolov3_mobilenet_v1_voc.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-22 12:41:41,084-WARNING: output/yolov3_mobilenet_v1_voc.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\r\n2020-03-22 12:41:41,457-INFO: save_inference_model pruned unused feed variables im_id\r\n2020-03-22 12:41:41,457-INFO: Export inference model to ./output\\yolov3_mobilenet_v1_voc, input: ['image', 'im_size'], output: ['multiclass_nms_0.tmp_0']...\r\n将导出后的模型转onnx的时候就一直失败，测试过最新的PaddleDetection和V1.6版本，都会出现相同的错误",
        "state": "closed",
        "user": "wssywh",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-03-22T02:48:17+00:00",
        "updated_at": "2024-07-15T03:52:56+00:00",
        "closed_at": "2024-07-15T03:52:56+00:00",
        "comments_count": [
            "wawltor",
            "JerryDeepl"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 117,
        "title": "paddleSeg模型转换支持",
        "body": "您好，请问paddle图像分割模型目前是否支持paddle2onnx转换？\r\n\r\n目前使用的模型是FAST_SCNN和DEEPLABV3+.",
        "state": "closed",
        "user": "Magsun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-03-30T03:01:46+00:00",
        "updated_at": "2024-05-22T04:40:34+00:00",
        "closed_at": "2024-05-22T04:40:29+00:00",
        "comments_count": [
            "jiangjiajun",
            "InternetMaster1",
            "jiangjiajun",
            "maingene",
            "jiangjiajun"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 119,
        "title": "fluid_params_name 问题",
        "body": "在使用paddle2onnx时，导出模型只包含__model__和__params__，于是我指定\r\n`--fluid_params_name $PATH_TO_MODELDIR$/__params__`\r\n但仍会提示\r\n`Cannot open file $PATH_TO_MODELDIR$/conv6_depthwise_bn_offset for load op at (/paddle/paddle/fluid/operators/load_op.h:38)\r\n`",
        "state": "closed",
        "user": "komejisatori",
        "closed_by": "komejisatori",
        "created_at": "2020-04-07T04:00:03+00:00",
        "updated_at": "2020-05-06T01:48:30+00:00",
        "closed_at": "2020-05-06T01:48:29+00:00",
        "comments_count": [
            "JerryDeepl",
            "komejisatori"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 124,
        "title": "paddleocr模型转onnx",
        "body": "load the model parameter done.\r\nTraceback (most recent call last):\r\n  File \"D:/work/video/beauty_ocr_sdk/paddle2onnx-develop/paddle2onnx-develop/fluid_onnx/fluid_to_onnx.py\", line 235, in <module>\r\n    main()\r\n  File \"D:/work/video/beauty_ocr_sdk/paddle2onnx-develop/paddle2onnx-develop/fluid_onnx/fluid_to_onnx.py\", line 231, in main\r\n    convert(args)\r\n  File \"D:/work/video/beauty_ocr_sdk/paddle2onnx-develop/paddle2onnx-develop/fluid_onnx/fluid_to_onnx.py\", line 141, in convert\r\n    node_proto = ops.node_maker[str(op.type)](op, block)\r\nTypeError: 'str' object is not callable\r\n\r\n请问这是什么问题呢？",
        "state": "open",
        "user": "amandazw",
        "closed_by": null,
        "created_at": "2020-06-09T08:55:14+00:00",
        "updated_at": "2020-06-17T06:57:23+00:00",
        "closed_at": null,
        "comments_count": [
            "amandazw",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 120,
        "title": "pyramidbox_lite_mobile_mask模型能否支持转化",
        "body": "pyramidbox_lite_mobile_mask模型能否支持转化",
        "state": "open",
        "user": "sunrong0511",
        "closed_by": null,
        "created_at": "2020-04-09T08:30:04+00:00",
        "updated_at": "2020-05-07T08:29:56+00:00",
        "closed_at": null,
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 123,
        "title": "什么模型都转不过",
        "body": "onnx.onnx_cpp2py_export.checker.ValidationError: Nodes in a graph must be topologically sorted, however input 't_46' of node: \r\ninput: \"t_46\" input: \"t_47@reshape_y\" output: \"t_47\" op_type: \"Add\"\r\n is not output of any previous nodes.\r\n为什么所有的模型转换都报这个错呢",
        "state": "closed",
        "user": "lly8752",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-06-08T02:53:53+00:00",
        "updated_at": "2024-05-22T04:21:45+00:00",
        "closed_at": "2024-05-22T04:21:44+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 121,
        "title": "请问一下现在是还不支持分割模型的转化吗？",
        "body": "我用的分割模型是deeplabv3p_mobilenet\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 230, in main\r\n    convert(args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 99, in convert\r\n    ] = fluid.io.load_inference_model(args.fluid_model, exe)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1193, in load_inference_model\r\n    load_persistables(executor, load_dirname, program, params_filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 645, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 650, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 748, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator load error.\r\nPython Callstacks: \r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 630, in load_vars\r\n    'file_path': os.path.join(load_dirname, new_var.name)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 608, in load_vars\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 742, in load_persistables\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1193, in load_inference_model\r\n    load_persistables(executor, load_dirname, program, params_filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 99, in convert\r\n    ] = fluid.io.load_inference_model(args.fluid_model, exe)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/fluid_onnx/fluid_to_onnx.py\", line 230, in main\r\n    convert(args)\r\n  File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 10, in <module>\r\n    sys.exit(main())\r\nC++ Callstacks: \r\nCannot open file /home/aistudio/freeze_model/conv4_2_expand_weights for load op at [/paddle/paddle/fluid/operators/load_op.h:37]",
        "state": "closed",
        "user": "ljx111",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-04-18T08:02:07+00:00",
        "updated_at": "2024-07-15T03:52:45+00:00",
        "closed_at": "2024-07-15T03:52:38+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 122,
        "title": "模型转换出错",
        "body": "tensor version 1904018048 in not supported, only version 0 is supported",
        "state": "closed",
        "user": "lgcy",
        "closed_by": "lgcy",
        "created_at": "2020-06-05T07:54:43+00:00",
        "updated_at": "2020-10-13T12:30:30+00:00",
        "closed_at": "2020-06-11T09:25:36+00:00",
        "comments_count": [
            "zky001",
            "Channingss",
            "trikim"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 125,
        "title": "使用paddlehub下载的module finetune之后，如何转化为onnx模型呢？",
        "body": "使用paddlehub下载的module ('shufflenet_v2_imagenet') finetune之后，如何转化为onnx模型呢？\r\n想要用intel 神经棒做边缘计算，需要将paddle模型转为onnx，onnx再转为IR",
        "state": "closed",
        "user": "libingbingdev",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-06-12T14:13:10+00:00",
        "updated_at": "2024-07-15T03:52:30+00:00",
        "closed_at": "2024-07-15T03:52:30+00:00",
        "comments_count": [
            "jiangjiajun",
            "juzuo",
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 127,
        "title": "Paddle2ONNX功能迁移至X2Paddle，请前往X2Paddle提issue",
        "body": "详见 https://github.com/PaddlePaddle/paddle2onnx/blob/develop/README.md",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "jiangjiajun",
        "created_at": "2020-06-17T06:54:56+00:00",
        "updated_at": "2020-09-21T09:27:03+00:00",
        "closed_at": "2020-09-21T09:27:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 132,
        "title": "Hello, with the help of Paddle2onNx, can the mobilenet_v2_VOC format data set model trained by myself be converted to ONNX?",
        "body": null,
        "state": "closed",
        "user": "dongyangli-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-10-02T08:29:32+00:00",
        "updated_at": "2024-07-15T03:52:15+00:00",
        "closed_at": "2024-07-15T03:52:11+00:00",
        "comments_count": [
            "dongyangli-del",
            "Channingss",
            "dongyangli-del"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 144
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 136,
        "title": "尝试将ssdlite_mobilenet_v3_small转成onnx格式，成功了但是onnx推理报错",
        "body": "报错如下：\r\n`onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node () Op (Mul) [ShapeInferenceError] Incompatible dimensions`\r\n说的应该是Mul在推理时的维度不匹配。\r\n查看了一下转换后的模型结构，这里的INPUTS A和B是不是运算顺序反了，导致计算维度不匹配？",
        "state": "closed",
        "user": "ruyijidan",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-10-25T05:45:57+00:00",
        "updated_at": "2024-05-22T04:50:24+00:00",
        "closed_at": "2024-05-22T04:50:21+00:00",
        "comments_count": [
            "ruyijidan",
            "Channingss",
            "ruyijidan",
            "Channingss"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 135,
        "title": "There's 3 ops are not supported yet",
        "body": "hi,\r\n\r\ni am using ch_ppocr_mobile_v1.1_rec_train.tar model and exported to fluid model and wanted to convert to onnx model. but failes with below error:\r\n\r\npaddle.__version__ = 1.8.5\r\nNow, paddle2onnx support convert paddle model to onnx opset_verison [9, 10, 11], opset_verison be seted as 9, automatically treated as opset_version: 9.\r\nTranslating PaddlePaddle to ONNX...\r\n\r\nTotal:198, Current:1 : feed image\r\nTotal:198, Current:176 : im2sequence add  \r\n\r\n\"==========Importance Notice===========\r\nSince im2sequence operator is used in your paddlepaddle model, the translated onnx model only support input data with batch_size=1.\r\n======================================\"\r\n\r\nTotal:198, Current:198 : fetch x n e_add \r\nThere's 3 ops are not supported yet\r\n=========== ctc_align ===========\r\n=========== top_k ===========\r\n=========== lstm ===========\r\n\r\nplease let me know  if i need to do any woraround.\r\n\r\nThanks\r\nVijay\r\nskypeid: vijayky88",
        "state": "closed",
        "user": "vijayky88",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-10-24T12:56:12+00:00",
        "updated_at": "2024-05-22T04:38:58+00:00",
        "closed_at": "2024-05-22T04:38:52+00:00",
        "comments_count": [
            "SWHL",
            "vijayky88",
            "Channingss",
            "SWHL",
            "vijayky88",
            "DayDayupupupup",
            "jiangjiajun",
            "kano201",
            "SWHL",
            "jiangjiajun",
            "DayDayupupupup",
            "754467737"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 137,
        "title": "pyramidbox_lite_server_mask can't be converted to onnx model",
        "body": "mapyramidbo_lite has an error \r\n\r\nand mask_detector  successsed but the architecture is wrong by being visualized by Netron\r\n",
        "state": "closed",
        "user": "lunasdejavu",
        "closed_by": "lunasdejavu",
        "created_at": "2020-10-29T06:41:58+00:00",
        "updated_at": "2020-10-30T08:42:16+00:00",
        "closed_at": "2020-10-30T08:42:16+00:00",
        "comments_count": [
            "Channingss",
            "Channingss",
            "lunasdejavu",
            "Channingss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 139,
        "title": "pamodel",
        "body": "How Can convert my model to onnx, when my model files are model.pdmodel  model.pdopt  model.pdparams",
        "state": "closed",
        "user": "ouyangpingbu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-11-03T06:16:07+00:00",
        "updated_at": "2024-05-22T04:49:11+00:00",
        "closed_at": "2024-05-22T04:49:08+00:00",
        "comments_count": [
            "Channingss",
            "Channingss"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 146,
        "title": "转换PaddleX GUI训练导出的模型ResNet18，网络输入size出错",
        "body": "转换Paddle X训练导出的模型ResNet18，能正常转换，但转换后的ONNX模型输入size出错(type: float32[-1,3,-1,-1])\r\n![image](https://user-images.githubusercontent.com/16093087/98490892-0c1e6e80-226e-11eb-86bc-3ff6b2e231f6.png)\r\npaddle2onnx版本\r\n1.8.5.post107\r\nPaddleX版本 1.1.6\r\nPaddleX GUI版本1.1.4\r\nPaddleX 飞浆版本 1.8.4\r\n![image](https://user-images.githubusercontent.com/16093087/98490965-45ef7500-226e-11eb-8c1f-b7aa324cd205.png)\r\n\r\n![image](https://user-images.githubusercontent.com/16093087/98490939-2f491e00-226e-11eb-9ad2-9744c0044171.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "hedilong",
        "closed_by": "hedilong",
        "created_at": "2020-11-09T01:35:55+00:00",
        "updated_at": "2020-11-09T02:24:58+00:00",
        "closed_at": "2020-11-09T02:24:26+00:00",
        "comments_count": [
            "hedilong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 148,
        "title": "ppocr 转onnx",
        "body": "@Channingss 你好，尝试使用这个工具paddle2onnx将mbv3-db ocr检测部分转为onnx，出现了如下的错误\r\n`~$　paddle2onnx --model_dir ./Desktop/ch_det_mv3_db_infer/ch_det_mv3_db/ -s ./output --opset_version 11`\r\n\r\n* model\r\n\r\n![截图录屏_选择区域_20201112003556](https://user-images.githubusercontent.com/62579216/98838498-5165ba80-247f-11eb-959a-186df4dc338c.png)\r\n\r\n\r\n```sh\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nUnavailableError: Load operator fail to open file Desktop/ch_det_mv3_db_infer/ch_det_mv3_db/conv3_expand_bn_variance, please check whether the model file is complete or damaged.\r\n  [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] at (/paddle/paddle/fluid/operators/load_op.h:41)\r\n  [operator < load > error]\r\n```\r\n看issue里有人用x2paddle转成过mbv3-db的文本检测，我使用x2paddle，推荐使用这个paddle2onnx的repo，所以请问下我这里出了什么问题",
        "state": "closed",
        "user": "PureHing",
        "closed_by": "PureHing",
        "created_at": "2020-11-11T16:40:22+00:00",
        "updated_at": "2020-11-12T13:43:11+00:00",
        "closed_at": "2020-11-12T13:43:10+00:00",
        "comments_count": [
            "Channingss",
            "PureHing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 152,
        "title": "paddle2onnx支持ppyolo吗？",
        "body": "使用paddlex训练的ppyolo模型，然后报错：\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/server/miniconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/server/miniconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py\", line 803, in load_vars\r\n    'model_from_memory': vars_from_memory\r\n  File \"/home/server/miniconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py\", line 751, in load_vars\r\n    filename=filename)\r\n  File \"/home/server/miniconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py\", line 928, in load_persistables\r\n    filename=filename)\r\n  File \"/home/server/miniconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py\", line 1402, in load_inference_model\r\n    load_persistables(executor, load_dirname, program, params_filename)\r\n  File \"/d/hulei/paddle2onnx/paddle2onnx/command.py\", line 105, in program2onnx\r\n    params_filename=params_filename)\r\n  File \"/d/hulei/paddle2onnx/paddle2onnx/command.py\", line 139, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/home/server/miniconda3/envs/paddle/bin/paddle2onnx\", line 11, in <module>\r\n    load_entry_point('paddle2onnx==0.4', 'console_scripts', 'paddle2onnx')()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: tensor version 1904018048 is not supported, Only version 0 is supported\r\n  [Hint: Expected version == 0U, but received version:1904018048 != 0U:0.] at (/paddle/paddle/fluid/framework/lod_tensor.cc:287)\r\n  [operator < load_combine > error]\r\n",
        "state": "closed",
        "user": "thunder95",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-11-20T10:16:07+00:00",
        "updated_at": "2024-05-22T04:42:16+00:00",
        "closed_at": "2024-05-22T04:42:16+00:00",
        "comments_count": [
            "Channingss",
            "saxon-gao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 154,
        "title": "关于转换paddleocr中的文字检测模型出现的问题",
        "body": "![image](https://user-images.githubusercontent.com/33384210/99962889-e5af1600-2dcb-11eb-8b27-bc4277865a56.png)\r\n用的是这三个文字检测模型\r\n三个模型的报错的op都是一样的：\r\npaddle2onnx --model_dir ./ --model_filename 'model' --params_filename 'params' --save_file ch_mobile_v1.1 --opset_version 10 --enable_onnx_checker True\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python2.7.15/bin/paddle2onnx\", line 11, in <module>\r\n    load_entry_point('paddle2onnx==0.4', 'console_scripts', 'paddle2onnx')()\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/command.py\", line 139, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/command.py\", line 111, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/convert.py\", line 30, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 162, in build\r\n    status = OpMapper.mapping(onnx_graph, node)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 96, in mapping\r\n    format(node.layer_name, node.type, node.inputs, node.outputs))\r\nException: Error happened when mapping node ['nearest_interp@0'] to onnx, which op_type is 'nearest_interp' with inputs: {u'OutSize': [], u'X': [u'conv2d_32.tmp_0'], u'SizeTensor': [], u'Scale': []} and outputs: {u'Out': [u'nearest_interp_0.tmp_0']}\r\n\r\n这个要怎么去修改 才能转换成功？",
        "state": "closed",
        "user": "ZHR1997",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-11-23T12:40:22+00:00",
        "updated_at": "2024-07-15T03:52:04+00:00",
        "closed_at": "2024-07-15T03:51:53+00:00",
        "comments_count": [
            "Channingss",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "Channingss",
            "ZHR1997",
            "Channingss",
            "zrl4836"
        ],
        "labels": [
            "Bug",
            "Paddle(Version)",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 155,
        "title": "PaddleOCR 识别模型转换问题",
        "body": "采用官方给出的模型rec_crnn进行转换，三种算子不支持转换：lstm, ctc_align, top_k，请问这些算子后续可以添加吗？或者自己怎么定义这些算子的转换？谢谢~",
        "state": "closed",
        "user": "LucySha",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-11-25T08:02:21+00:00",
        "updated_at": "2024-07-15T03:51:44+00:00",
        "closed_at": "2024-07-15T03:51:33+00:00",
        "comments_count": [
            "Channingss"
        ],
        "labels": [
            "Bug",
            "Paddle(Version)",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 165,
        "title": "paddleseg导出的hrnet模型转onnx的时候遇到了失败",
        "body": "![image](https://user-images.githubusercontent.com/39080886/103256078-d0c73300-49c6-11eb-9632-ee13275e372e.png)\r\n",
        "state": "closed",
        "user": "wangyuan111",
        "closed_by": "wangyuan111",
        "created_at": "2020-12-29T03:13:08+00:00",
        "updated_at": "2021-01-05T07:06:26+00:00",
        "closed_at": "2021-01-05T07:06:26+00:00",
        "comments_count": [
            "wangyuan111"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 160,
        "title": "blazeface_keypoint模型转ONNX失败",
        "body": "0.4版本，命令和错误如下\r\n```\r\n(paddle) BDSZYF000132754:dcn jiangjiajun$ paddle2onnx --model_dir /Users/jiangjiajun/Downloads/inference_model/blazeface_keypoint/ --model_filename __model__.paddle --params_filename __params__ --save_file solov2.onnx --opset_version 10\r\nTraceback (most recent call last):\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 91, in mapping\r\n    mapper_func(graph, node, **kw)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/op_mapper/detection/prior_box.py\", line 89, in opset_9\r\n    out_boxes = np.zeros(out_dim).astype('float32')\r\nValueError: negative dimensions are not allowed\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/command.py\", line 139, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/command.py\", line 111, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 30, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 162, in build\r\n    status = OpMapper.mapping(onnx_graph, node)\r\n  File \"/Users/jiangjiajun/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 96, in mapping\r\n    format(node.layer_name, node.type, node.inputs, node.outputs))\r\nException: Error happened when mapping node ['prior_box@0'] to onnx, which op_type is 'prior_box' with inputs: {'Image': ['image'], 'Input': ['elementwise_add_7.tmp_1']} and outputs: {'Boxes': ['prior_box_0.tmp_0'], 'Variances': ['prior_box_0.tmp_1']}\r\n```\r\n\r\n模型文件\r\n链接: https://pan.baidu.com/s/1LRzTSJwsLOul99Tj5_43wQ  密码: d3dg\r\n--来自百度网盘超级会员V5的分享",
        "state": "open",
        "user": "jiangjiajun",
        "closed_by": null,
        "created_at": "2020-12-10T02:33:59+00:00",
        "updated_at": "2021-01-07T08:09:56+00:00",
        "closed_at": null,
        "comments_count": [
            "Channingss"
        ],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 164,
        "title": "得到onnx的IR version为7，这个跟onnx版本有关么？如何得到IR version为3的模型",
        "body": "",
        "state": "closed",
        "user": "Z-Xiong",
        "closed_by": "Z-Xiong",
        "created_at": "2020-12-21T08:31:36+00:00",
        "updated_at": "2020-12-30T07:52:45+00:00",
        "closed_at": "2020-12-30T07:52:45+00:00",
        "comments_count": [
            "Channingss",
            "Z-Xiong",
            "Channingss",
            "Z-Xiong",
            "Channingss",
            "Z-Xiong",
            "Channingss",
            "Z-Xiong",
            "Z-Xiong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 158,
        "title": "剪枝后的模型如何转onnx",
        "body": "请问，paddlesim剪枝后保存模型 __shapes__和__params__，怎么转到onnx？谢谢",
        "state": "closed",
        "user": "JerryDeepl",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-11-27T08:15:01+00:00",
        "updated_at": "2024-05-22T05:23:03+00:00",
        "closed_at": "2024-05-22T05:23:03+00:00",
        "comments_count": [
            "Channingss",
            "JerryDeepl",
            "Channingss",
            "Shixiaowei02",
            "JerryDeepl",
            "Shixiaowei02",
            "JerryDeepl",
            "Shixiaowei02",
            "Channingss",
            "Shixiaowei02"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 167,
        "title": "什么时候可以支持ppyolo导出onnx?",
        "body": "![image](https://user-images.githubusercontent.com/44191778/103339510-82945b80-4abc-11eb-8ab9-2051fdfc8735.png)\r\n",
        "state": "closed",
        "user": "francislinker",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2020-12-30T08:31:58+00:00",
        "updated_at": "2024-05-22T04:58:28+00:00",
        "closed_at": "2024-05-22T04:58:14+00:00",
        "comments_count": [
            "Channingss",
            "francislinker",
            "Channingss"
        ],
        "labels": [
            "Operator(New)",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 168,
        "title": "paddle2onnx需要模型目录下有 ‘__model__’是什么东西？",
        "body": "paddle2onnx 0.4版本\r\n转换命令：paddle2onnx --model_dir D:/work/PaddleOCR-dygraph/inference/rec/ --save_file 1.onnx\r\n提示\r\nFileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\work\\\\PaddleOCR-dygraph\\\\inference\\\\rec\\\\__model__'\r\n文档是这么写的：\r\n参数被保存为多个文件（not combined），只需要指定--model_dir，该目录下面需要包含了'__model__'，以及多个参数文件。\r\n我是直接下的官方的推理模型，有三个模型文件，inference.pdiparams，inference.pdiparams.info，inference.pdmodel，可以正常推理，__model__去哪弄？",
        "state": "open",
        "user": "ingale726",
        "closed_by": null,
        "created_at": "2020-12-31T05:55:42+00:00",
        "updated_at": "2025-07-04T02:58:11+00:00",
        "closed_at": null,
        "comments_count": [
            "jiangjiajun",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 171,
        "title": "unsupported ops",
        "body": "There's 5 ops are not supported yet\r\n=========== top_k ===========\r\n=========== fake_quantize_moving_average_abs_max ===========\r\n=========== ctc_align ===========\r\n=========== lstm ===========\r\n=========== fake_channel_wise_dequantize_max_abs ===========\r\n\r\n\r\nThere's 2 ops are not supported yet\r\n=========== fake_channel_wise_dequantize_max_abs ===========\r\n=========== fake_quantize_moving_average_abs_max ===========\r\n\r\n",
        "state": "open",
        "user": "znsoftm",
        "closed_by": null,
        "created_at": "2021-01-06T08:57:53+00:00",
        "updated_at": "2025-07-02T02:58:03+00:00",
        "closed_at": null,
        "comments_count": [
            "Channingss",
            "znsoftm",
            "Channingss",
            "znsoftm",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 190
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 176,
        "title": "paddleseg中的shufflenetv2模型转onnx,batch_size不定项",
        "body": "paddleseg中的shufflenetv2模型转onnx,batch_size不默认==1",
        "state": "closed",
        "user": "wsy1991",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-01-14T12:13:33+00:00",
        "updated_at": "2024-05-22T05:06:50+00:00",
        "closed_at": "2024-05-22T05:06:50+00:00",
        "comments_count": [
            "wsy1991",
            "Channingss"
        ],
        "labels": [
            "Bug",
            "PaddleSeg"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 177,
        "title": "PaddleOCR2.0文本识别模型转换可动态输入的onnx模型报错",
        "body": "#### 说明\r\n- 尝试转换PaddleOCR 2.0动态图下文本识别模型l\r\n- 固定文本识别模型输入尺寸为(3, 32, 100),可以转换成功，\r\n- 但是文本识别模型一般都不会固定宽的（如果固定的话，对于长文本识别会很差）\r\n\r\n#### 转换环境：\r\n- python 3.7\r\n- PaddleOCR-dygraph\r\n- Paddle2ONNX 最新版\r\n\r\n#### 转换代码(部分)：\r\n```python\r\nconfig = load_config(FLAGS.config)\r\nmerge_config(FLAGS.opt)\r\nlogger = get_logger()\r\n# build post process\r\n\r\npost_process_class = build_post_process(config['PostProcess'],\r\n                                        config['Global'])\r\n\r\n# build model\r\n# for rec algorithm\r\nif hasattr(post_process_class, 'character'):\r\n    char_num = len(getattr(post_process_class, 'character'))\r\n    config['Architecture'][\"Head\"]['out_channels'] = char_num\r\nmodel = build_model(config['Architecture'])\r\nprint('build model...')\r\ninit_model(config, model, logger)\r\nmodel.eval()\r\n\r\nsave_path = 'test.onnx'\r\nx_spec = InputSpec([1, 3, 32, None], 'float32', 'x')  # 这里最后一维为None,想这里可以是不定的，动态输入的\r\npaddle.onnx.export(model, save_path, input_spec=[x_spec])\r\n```\r\n#### 执行以上代码，报错如下：\r\n```text\r\nTraceback (most recent call last):\r\n  File \"export_model_onnx.py\", line 49, in <module>\r\n    main()\r\n  File \"export_model_onnx.py\", line 45, in main\r\n    paddle.onnx.export(model, save_path, input_spec=[x_spec])\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle/onnx/export.py\", line 105, in export\r\n    **configs)\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle2onnx-0.4-py3.7.egg/paddle2onnx/convert.py\", line 145, in dygraph2onnx\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle2onnx-0.4-py3.7.egg/paddle2onnx/convert.py\", line 31, in export_onnx\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle2onnx-0.4-py3.7.egg/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle2onnx-0.4-py3.7.egg/paddle2onnx/graph/onnx_graph.py\", line 165, in build_op_nodes\r\n  File \"/home/xxxxxxx/anaconda3/envs/Paddle/lib/python3.7/site-packages/paddle2onnx-0.4-py3.7.egg/paddle2onnx/op_mapper/op_mapper.py\", line 115, in mapping\r\nException: Error happened when mapping node ['pool2d@0'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['relu_1.tmp_0']} and outputs: {'Out': ['pool2d_0.tmp_0']}, specific error: Converting this model to ONNX need with static input shape, please fix input shape of this model, see doc Q2 in https://github.com/PaddlePaddle/paddle2onnx/blob/develop/docs/en/FAQ.md.\r\n```\r\n\r\n#### 困惑：\r\n- 根据报错信息可得，不支持动态shape，但是根据[文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/guides/02_paddle2.0_develop/09_model_to_onnx_cn.html)是支持动态输入的？\r\n\r\n希望可以得到你们的解答",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "SWHL",
        "created_at": "2021-01-18T14:06:42+00:00",
        "updated_at": "2021-08-04T02:32:47+00:00",
        "closed_at": "2021-01-19T06:00:26+00:00",
        "comments_count": [
            "Channingss",
            "WangFengtu1996",
            "SWHL",
            "WangFengtu1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 179,
        "title": "模型转换后输入顺序变动",
        "body": "需修复",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "jiangjiajun",
        "created_at": "2021-01-20T03:48:44+00:00",
        "updated_at": "2021-02-01T03:55:19+00:00",
        "closed_at": "2021-02-01T03:55:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 195,
        "title": "自定义Paddle算子目前无法全局做support checker",
        "body": null,
        "state": "closed",
        "user": "Channingss",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-02-24T02:03:07+00:00",
        "updated_at": "2024-07-15T03:55:42+00:00",
        "closed_at": "2024-07-15T03:55:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 192,
        "title": "关于对PyramidBox从paddle转成onnx的支持",
        "body": "首先非常感谢官方出的paddle2onnx的工具！\r\n\r\n我有一个需求是要将PyramidBox转成ONNX格式进行一些Profiling，我首先尝试用Paddle2ONNX，但是报错说`depthwise_conv2d_transpose`算子还不支持。于是我就参考`nn.py`里面`Conv`的实现，把以下的代码：\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/5dc318a5ddf2c34245e5231266dc1797ebcc060b/paddle2onnx/op_mapper/nn.py#L58-L73\r\n\r\n改成了\r\n```python\r\n@op_mapper(['conv2d_transpose', 'depthwise_conv2d_transpose'])\r\nclass ConvTranspose():\r\n    support_opset_verison_range = (1, 12)\r\n\r\n    @classmethod\r\n    def opset_1(cls, graph, node, **kw):\r\n        kernel_shape = node.input_shape('Filter', 0)\r\n        dilations = node.attr('dilations')\r\n        kernel_shape = kernel_shape[-2:]\r\n        strides = node.attr('strides')\r\n        group = node.attr('groups')\r\n        pads = node.attr('paddings') + node.attr('paddings')\r\n        attrs = {\r\n            'dilations': dilations,\r\n            'kernel_shape': kernel_shape,\r\n            'strides': strides,\r\n            'group': group\r\n        }\r\n        auto_pad = node.attr('padding_algorithm')\r\n        if auto_pad == 'SAME':\r\n            attrs['auto_pad'] = 'SAME_UPPER'\r\n        elif auto_pad == 'VALID':\r\n            attrs['auto_pad'] = 'VALID'\r\n        else:\r\n            attrs['pads'] = pads\r\n\r\n        node = graph.make_node(\r\n            'ConvTranspose',\r\n            inputs=node.input('Input') + node.input('Filter'),\r\n            outputs=node.output('Output'),\r\n            attrs=attrs)\r\n```\r\n\r\n现在算子支持有了，但是在box_coder这里报错了：\r\n```shell\r\n$ paddle2onnx --model_dir ./models/PyramidBox_WiderFace --save_file pyramidbox.onnx --opset_version 12 --enable_onnx_checker True\r\nTraceback (most recent call last):\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 110, in mapping\r\n    mapper_func(graph, node, **kw)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/op_mapper/detection/box_coder.py\", line 44, in opset_7\r\n    axis = int(node.attr('axis'))\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/command.py\", line 142, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 31, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 165, in build_op_nodes\r\n    OpMapper.mapping(self, node)\r\n  File \"/home/tau/anaconda3/envs/PyramidBox/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 115, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['box_coder@0'] to onnx, which op_type is 'box_coder' with inputs: {'PriorBox': ['concat_17.tmp_0'], 'PriorBoxVar': ['concat_18.tmp_0'], 'TargetBox': ['concat_13.tmp_0']} and outputs: {'OutputBox': ['box_coder_2.tmp_0']}, specific error: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\r\n```\r\n\r\n这个错误该如何解决？我猜这个是和最后priorbox的生成和decode相关，但我这边其实可以用不到这个步骤，只需要转换出来的模型完成前向过程就可以了（输出loc和conf的特征图，decode可以自己写）。请问有什么解决办法吗？\r\n\r\n附上PaddlePaddle/Models中face_detection（PyramidBox）提供的模型下载地址：\r\nhttp://paddlemodels.bj.bcebos.com/PyramidBox_WiderFace.tar.gz",
        "state": "closed",
        "user": "fengyuentau",
        "closed_by": "fengyuentau",
        "created_at": "2021-02-17T12:58:41+00:00",
        "updated_at": "2022-03-06T04:15:01+00:00",
        "closed_at": "2022-03-06T04:15:01+00:00",
        "comments_count": [
            "Channingss",
            "fengyuentau",
            "Channingss",
            "fengyuentau",
            "Channingss",
            "fengyuentau",
            "Channingss",
            "fengyuentau",
            "fengyuentau",
            "fengyuentau",
            "Channingss",
            "fengyuentau",
            "fengyuentau",
            "fengyuentau"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 191,
        "title": "请问怎么转换有三个model directory的PaddleOCR？",
        "body": "现在的model是一个PaddleOCR class, 有三个model_dir，请问是要分开转换成ONNX吗？转换之后怎么combine起来，还有怎么用onnxruntime呢？",
        "state": "open",
        "user": "yxyphoebe",
        "closed_by": null,
        "created_at": "2021-02-16T02:27:29+00:00",
        "updated_at": "2025-07-01T03:12:51+00:00",
        "closed_at": null,
        "comments_count": [
            "Channingss",
            "yxyphoebe",
            "yxyphoebe",
            "Channingss",
            "MagicCodess",
            "daixiangzi",
            "SWHL",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 194,
        "title": "ppocr模型怎么设置输入维度可变",
        "body": "请问怎么将模型的输入维度设置为可变？\r\n我使用paddleocr提供的dbnet推理模型进行转化，获得的onnx模型输入维度固定为[-1，3，640，640]。请问这个宽高维度怎么设为不固定的？\r\n我转化的命令如下：\r\npaddle2onnx -m ch_ppocr_mobile_v2.0_det_infer/ --model_filename inference.pdmodel --params_filename inference.pdiparams -s onnx/det_db/ppocr_dbnet.onnx --opset_version 11\r\n模型地址：\r\nhttps://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_infer.tar\r\n",
        "state": "closed",
        "user": "MachineVision123",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-02-18T07:16:41+00:00",
        "updated_at": "2024-05-22T03:49:29+00:00",
        "closed_at": "2024-05-22T03:49:29+00:00",
        "comments_count": [
            "Channingss"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 199,
        "title": "支持导出ONNX模型的网络结构和参数分开为两个文件存储",
        "body": "由于ONNX限制这个模型不能超过2GB，遇到大模型需要支持该功能，比如：resnext101_32x48d_wsl(paddlehub)",
        "state": "open",
        "user": "Channingss",
        "closed_by": null,
        "created_at": "2021-03-01T12:43:24+00:00",
        "updated_at": "2025-06-29T03:10:53+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 201,
        "title": "支持ultra_light_fast_generic_face_detector_1mb_640(PaddleHub)，缺少assign",
        "body": "Traceback (most recent call last):\r\n  File \"test_cv_module.py\", line 91, in <module>\r\n    module.export_onnx_model('output/{}.onnx'.format(module.name))\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/compat/paddle_utils.py\", line 220, in runner\r\n    return func(*args, **kwargs)\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/module/module.py\", line 201, in export_onnx_model\r\n    **kwargs\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 31, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 162, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 1 ops are not supported yet\r\n=========== assign ===========",
        "state": "closed",
        "user": "Channingss",
        "closed_by": "jiangjiajun",
        "created_at": "2021-03-01T12:44:51+00:00",
        "updated_at": "2021-03-29T11:48:19+00:00",
        "closed_at": "2021-03-29T11:48:19+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 198,
        "title": "载入转换后的onnx模型失败：Error in Node:ScatterND@1 : No Op registered for ScatterND with domain_version of 9",
        "body": "训练的模型是识别模型：CRNN（mobilenetv3_small+bilstm+ctc)\r\n\r\npaddle转onnx命令：\r\n\r\n`paddle2onnx --model_dir inference/rec_crnn/  --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file onxx_model/test.onnx \r\n`\r\n\r\nonnxruntime加载onnx模型报错：\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"mn_rec.py\", line 60, in <module>\r\n    text_recognizer = TextRecognizer()\r\n  File \"mn_rec.py\", line 12, in __init__\r\n    self.session = onnxruntime.InferenceSession(rec_model_path)\r\n  File \"/data01/wanming/paddle_env/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 206, in __init__\r\n    self._create_inference_session(providers, provider_options)\r\n  File \"/data01/wanming/paddle_env/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 226, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from /data01/wanming/paddle2/onnx/rec/weights/test.onnx failed:This is an invalid model. Error in Node:ScatterND@1 : No Op registered for ScatterND with domain_version of 9\r\n```\r\n\r\n已经尝试过的方法：\r\n\r\n设置 --opset_version 12，报错无变化\r\n设置 --opset_version 11，报错无变化\r\n设置 --opset_version 10，显示有算子不支持 建议>=11\r\n加载其他onnx模型：可以正常加载\r\npip uninstall paddle2onnx，在十分钟前下载源码 python setup.py intstall 安装paddle2onnx: 报错无变化\r\n\r\n环境：\r\npaddle2onnx: 0.5\r\npaddlepaddle-gpu: 2.0.0.post100\r\nonnxruntime: 1.6.0\r\n",
        "state": "closed",
        "user": "damengdameng",
        "closed_by": "damengdameng",
        "created_at": "2021-02-24T11:27:56+00:00",
        "updated_at": "2021-02-24T11:50:30+00:00",
        "closed_at": "2021-02-24T11:50:30+00:00",
        "comments_count": [
            "damengdameng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 200,
        "title": "支持pyramidbox_lite_server(PaddleHub)，缺少density_prior_box",
        "body": "Traceback (most recent call last):\r\n  File \"test_cv_module.py\", line 91, in <module>\r\n    module.export_onnx_model('output/{}.onnx'.format(module.name))\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/compat/paddle_utils.py\", line 220, in runner\r\n    return func(*args, **kwargs)\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/module/module.py\", line 201, in export_onnx_model\r\n    **kwargs\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 31, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 162, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 1 ops are not supported yet\r\n=========== density_prior_box ===========",
        "state": "closed",
        "user": "Channingss",
        "closed_by": "jiangjiajun",
        "created_at": "2021-03-01T12:44:18+00:00",
        "updated_at": "2021-03-29T11:48:35+00:00",
        "closed_at": "2021-03-29T11:48:35+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 202,
        "title": "转换deeplabv3p_xception65_humanseg(PaddleHub)报错",
        "body": "Traceback (most recent call last):\r\n  File \"test_cv_module.py\", line 153, in <module>\r\n    module.export_onnx_model('output/{}.onnx'.format(module.name), opset_version=11)\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/compat/paddle_utils.py\", line 220, in runner\r\n    return func(*args, **kwargs)\r\n  File \"/mnt/wuzewu/code/PaddleHub/paddlehub/module/module.py\", line 201, in export_onnx_model\r\n    **kwargs\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 31, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 165, in build_op_nodes\r\n    OpMapper.mapping(self, node)\r\n  File \"/mnt/wuzewu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 115, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['bilinear_interp@0'] to onnx, which op_type is 'bilinear_interp' with inputs: {'OutSize': [], 'X': ['relu_68.tmp_0']} and outputs: {'Out': ['bilinear_interp_0.tmp_0']}, specific error: object of type 'NoneType' has no len()",
        "state": "closed",
        "user": "Channingss",
        "closed_by": "jiangjiajun",
        "created_at": "2021-03-01T12:45:21+00:00",
        "updated_at": "2021-03-29T11:34:42+00:00",
        "closed_at": "2021-03-29T11:34:42+00:00",
        "comments_count": [
            "Channingss",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 203,
        "title": "弱弱的问一句： “手把手教你使用ONNXRunTime部署PP-OCR实现”   里面代码位于onnx_inference/目录下面",
        "body": "抱歉。onnx_inference文件夹在哪里，我怎么找不到。。。\r\n",
        "state": "closed",
        "user": "HongChow",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-02T08:43:33+00:00",
        "updated_at": "2024-05-22T05:10:26+00:00",
        "closed_at": "2024-05-22T05:10:16+00:00",
        "comments_count": [
            "Channingss",
            "HongChow",
            "Channingss",
            "HongChow",
            "HongChow",
            "HongChow",
            "Channingss",
            "HongChow",
            "HongChow",
            "Channingss",
            "HongChow",
            "HongChow",
            "Channingss",
            "Channingss",
            "HongChow",
            "HongChow"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 205,
        "title": "导出paddleDetection中mask_rcnn为ONNX出错",
        "body": "先使用PaddleDetection 中自带export_model 代码导出为inference_model\r\n![image](https://user-images.githubusercontent.com/52873355/110198245-0dfae600-7e8c-11eb-84c6-48853451fa57.png)\r\n\r\n然后使用下面命令转onnx：\r\n`paddle2onnx --model_dir mask_rcnn_r50_fpn_2x  --model_filename mask_rcnn_r50_fpn_2x/__model__ --params_filename mask_rcnn_r50_fpn_2x\\__params__ --save_file  onnx_file.onnx --opset_version 12 --enable_onnx_checker True`\r\n\r\n报错为:raise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 4 ops are not supported yet\r\n=========== less_than ===========\r\n=========== logical_not ===========\r\n=========== conditional_block ===========\r\n=========== assign ===========\r\n是我命令用的不对吗",
        "state": "open",
        "user": "PhilCuriosity",
        "closed_by": "PhilCuriosity",
        "created_at": "2021-03-06T06:55:19+00:00",
        "updated_at": "2025-06-27T02:58:40+00:00",
        "closed_at": null,
        "comments_count": [
            "PhilCuriosity",
            "Channingss",
            "PhilCuriosity",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 206,
        "title": "YOLOv3 ResNet50_vd DCN DropBlock IoULoss 检测模型转onnx提示错误",
        "body": "paddle: 1.8.5\r\nException: Error happened when mapping node ['deformable_conv@0'] to onnx, which op_type is 'deformable_conv' with inputs: {'Filter': ['res5a_branch2b_weights'], 'Input': ['bn5a_branch2a.output.1.tmp_3'], 'Mask': ['sigmoid_0.tmp_0'], 'Offset': ['split_0.tmp_0']} and outputs: {'Output': ['res5a_branch2b.conv2d.output.1.tmp_0']}, specific error: module 'paddle' has no attribute 'static'",
        "state": "closed",
        "user": "peace-zy",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-08T05:13:52+00:00",
        "updated_at": "2024-07-15T03:55:12+00:00",
        "closed_at": "2024-07-15T03:55:04+00:00",
        "comments_count": [
            "Channingss"
        ],
        "labels": [
            "Bug",
            "Operator(Update)",
            "Paddle(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 204,
        "title": "ONNX2TRT 输入形状为多少",
        "body": "通过“手把手教你使用ONNXRunTime部署PP-OCR”教程将模型转为ONNX后，按照模型对应的.yml 中  ` Eval[RecResizeImg][image_shape: [3, 32, 320]]` 在jetosnagx xavier ONNX转trt时会报 `ttributeError:'NoneType' object has no attribute 'serialize'`的错误，请问是打包ONNX时的占位数据的形状是什么",
        "state": "closed",
        "user": "PhilCuriosity",
        "closed_by": "PhilCuriosity",
        "created_at": "2021-03-05T03:50:12+00:00",
        "updated_at": "2021-03-06T06:54:16+00:00",
        "closed_at": "2021-03-06T06:54:16+00:00",
        "comments_count": [
            "PhilCuriosity",
            "Channingss",
            "PhilCuriosity"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 208,
        "title": "ONNX2TRT： ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin ScatterND version 1",
        "body": "使用icdar数据集（筛选出英文和数字进行训练的）训练出来的PPOCR，将export_model.py输入设置为[1,3,32,320]\r\n![微信截图_20210310104646](https://user-images.githubusercontent.com/52873355/110568487-0a1ddb00-818e-11eb-8784-9a6c4e416185.png)\r\n使用`python export_model.py -c D:\\PyProject\\PaddleOCR-dygraph\\configs\\rec\\multi_language/rec_en_number_lite_train.yml -o Global.pretrained_model=D:\\PyProject\\PaddleOCR-dygraph\\tools\\output\\rec_en_number_lite/best_accuracy Global.load_static_weights=False Global.save_inference_dir=D:\\PyProject\\PaddleOCR-dygraph\\tools\\myicdr_320\r\n`转换为inference模型\r\n使用`paddle2onnx --model_dir myicdar_320 --model_filename inference.pdmodel  --params_filename  inference.pdiparams   --save_file ppocr_rec.onnx  --opset_version 11 --enable_onnx_checker True`转换为onnx模型。在Jetson AGX 上ONNX2TRT报错如下：\r\n[TensorRT] INFO: ModelImporter.cpp:135: No importer registered for op: ScatterND. Attempting to import as plugin.\r\n[TensorRT] INFO: builtin_op_importers.cpp:3659: Searching for plugin: ScatterND, plugin_version: 1, plugin_namespace: \r\n[TensorRT] **ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin ScatterND version 1**\r\nIn node -1 (importFallbackPluginImporter): UNSUPPORTED_NODE: Assertion failed: creator && \"Plugin not found, are the plugin name, version, and namespace correct?\"\r\nCompleted parsing of ONNX file\r\nBuilding an engine from file ./ppocr_rec_sim.onnx; this may take a while...\r\nnum layers: 252\r\n=================> batch_size 1\r\n[TensorRT] ERROR: Network must have at least one output\r\n[TensorRT] ERROR: Network validation failed.\r\nengine: None\r\nCompleted creating Engine\r\nTraceback (most recent call last):\r\n  File \"export.py\", line 54, in <module>\r\n    ONNX_build_engine()\r\n  File \"export.py\", line 38, in ONNX_build_engine\r\n    f.write(engine.serialize())\r\nAttributeError: 'NoneType' object has no attribute 'serialize'\r\n 使用【手把手教你使用ONNXRunTime部署PP-OCR】教程中直接导出的ONNX去转换为TRT却不会出现这个错误。我想问一下【ScatterND version 1】这个插件是你们后来自己嵌入的嘛，还有ONNX2TRT有没有办法解决这个问题？",
        "state": "closed",
        "user": "PhilCuriosity",
        "closed_by": "PhilCuriosity",
        "created_at": "2021-03-10T02:54:05+00:00",
        "updated_at": "2021-04-12T02:36:27+00:00",
        "closed_at": "2021-04-12T02:36:27+00:00",
        "comments_count": [
            "PhilCuriosity",
            "PhilCuriosity"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 213,
        "title": "paddle2onnx对NLP的常用算子的支持",
        "body": "您好，\r\n\r\n目前在项目支持列表中，看到所支持的模型多是CV的。对NLP中常用的lstm/gru/crf等序列模型的支持很少。用paddle2onnx用静态图的方式转换nlp中的[lac项目](https://github.com/baidu/lac), bigru-crf架构，发现不支持gru和crf-decoding两个算子\r\n细节：\r\npaddle2的版本:2.0.1\r\nlac版本：2.1.0\r\npaddle2onnx的版本：0.5\r\nonnx的版本:1.8.1\r\n\r\n错误日志如下\r\nTraceback (most recent call last):\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/command.py\", line 142, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 74, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 31, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 208, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 162, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/home/gsliu/anaconda3/envs/paddle2/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 2 ops are not supported yet\r\n=========== gru ===========\r\n=========== crf_decoding ===========\r\n\r\n\r\n-----\r\n1 后续对NLP相关的序列架构的算子支持有无确定的时间计划呢？\r\n2 是否有一些简明教程，支持自定制op加入到paddle2onnx中加快开发进度？\r\n\r\n谢谢，祝好\r\n\r\n",
        "state": "closed",
        "user": "wdhxek",
        "closed_by": "wdhxek",
        "created_at": "2021-03-15T10:04:20+00:00",
        "updated_at": "2021-03-16T07:06:05+00:00",
        "closed_at": "2021-03-16T07:06:05+00:00",
        "comments_count": [
            "jiangjiajun",
            "znsoftm",
            "wdhxek"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 212,
        "title": "转换完的onnx格式 paddleOCR 识别模型(rec)无法加载，报scatterND 错误",
        "body": "在onnxruntime 1.6中正常的模型，在onnxruntime 1.7中无法加载，报无法加载scatterND 算子\r\n这个问题应该已经知道了，提个issue,备忘。\r\n\r\nonnxruntime 1.７能提速４０％以上，实在是值得升级使用。",
        "state": "closed",
        "user": "znsoftm",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-14T14:05:46+00:00",
        "updated_at": "2024-07-15T03:54:54+00:00",
        "closed_at": "2024-07-15T03:54:49+00:00",
        "comments_count": [
            "PhilCuriosity",
            "znsoftm",
            "znsoftm",
            "znsoftm",
            "jiangjiajun",
            "znsoftm",
            "williamlzw",
            "williamlzw",
            "jiangjiajun",
            "williamlzw",
            "znsoftm",
            "jiangjiajun",
            "williamlzw",
            "znsoftm",
            "Dandelion111"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 219,
        "title": "slice操作转换问题。",
        "body": "你好，我使用实现了这样一个切片操作，然后使用Paddle2ONNX进行转换。\r\n```\r\nclass Net(nn.Layer):\r\n        def forward(self, x):\r\n            return x[0, 1:3, :1, 2:]\r\n```\r\n\r\n转换出来的ONNX模型是这样的：\r\n\r\n![图片](https://user-images.githubusercontent.com/35585791/112405798-f22d8600-8d4d-11eb-96ad-cbcf937c7e94.png)\r\n\r\n可以看到ends的最后一维的数值变成了10000000，不是期望的4，希望能修复这个BUG。\r\n\r\n如果我显示的指定切片2：4，转换是没有问题的。如下：\r\n\r\n```\r\nclass Net(nn.Layer):\r\n        def forward(self, x):\r\n            return x[0, 1:3, :1, 2:]\r\n```\r\n\r\n![图片](https://user-images.githubusercontent.com/35585791/112405964-459fd400-8d4e-11eb-9c49-5e84ec1dd722.png)\r\n",
        "state": "closed",
        "user": "BBuf",
        "closed_by": "BBuf",
        "created_at": "2021-03-25T01:41:57+00:00",
        "updated_at": "2021-03-26T07:48:55+00:00",
        "closed_at": "2021-03-26T07:48:55+00:00",
        "comments_count": [
            "jiangjiajun",
            "BBuf",
            "jiangjiajun",
            "BBuf",
            "BBuf",
            "BBuf",
            "jiangjiajun",
            "BBuf"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 221,
        "title": "paddle.mean导出ONNX的问题",
        "body": "你好，当我执行下面的代码导出onnx模型时：\r\n```\r\nimport paddle.nn as nn\r\nimport paddle\r\nimport onnx\r\n\r\nclass Net(nn.Layer):\r\n        def forward(self, x):\r\n            return paddle.mean(x)\r\n\r\ninput_size = (2, 4, 3, 5)\r\npaddle_model = Net()\r\npaddle.set_device(\"cpu\")\r\ninput_names = \"x_0\"\r\npaddle_model.eval()\r\ninput_spec = paddle.static.InputSpec(\r\n    shape=input_size , dtype=\"float32\", name=input_names\r\n)\r\nmode_str = \"em\"\r\n\r\npaddle.onnx.export(\r\n    paddle_model,\r\n    mode_str,\r\n    input_spec=[input_spec],\r\n    opset_version=12,\r\n    enable_onnx_checker=True,\r\n)\r\n```\r\n导出来的ONNX模型是这样：\r\n\r\n![图片](https://user-images.githubusercontent.com/35585791/112609642-b9c59f00-8e56-11eb-9482-70d9bfde0c41.png)\r\n\r\n由于我并没有指定paddle mean op的 axis参数，所以期望导出的onnx模型的`axes` attribute参数是None，不然ONNX获得的结果是错误的，并且也无法区分paddle.mean(x, axis=0)这种情况，希望可以看看。",
        "state": "closed",
        "user": "BBuf",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-26T09:17:43+00:00",
        "updated_at": "2024-05-22T04:59:27+00:00",
        "closed_at": "2024-05-22T04:59:06+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 231,
        "title": "Paddle2ONNX的Opset版本自动升级",
        "body": null,
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-31T08:56:12+00:00",
        "updated_at": "2024-07-09T07:30:04+00:00",
        "closed_at": "2024-07-09T07:30:04+00:00",
        "comments_count": [],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 220,
        "title": "AdaptiveMaxPool2D转换问题",
        "body": "当我使用下面的代码转换ONNX时，错误发生了。\r\n```\r\nimport paddle.nn as nn\r\nimport paddle\r\nimport onnx\r\nfrom onnxsim import simplify\r\n\r\nclass Net(paddle.nn.Layer):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.pool = nn.AdaptiveMaxPool2D(output_size=(1, 1))\r\n\r\n    def forward(self, x):\r\n        x = self.pool(x)\r\n        return x\r\n\r\ninput_size = (2, 4, 3, 5)\r\npaddle_model = Net()\r\npaddle.set_device(\"cpu\")\r\ninput_names = \"x_0\"\r\npaddle_model.eval()\r\ninput_spec = paddle.static.InputSpec(\r\n    shape=input_size , dtype=\"float32\", name=input_names\r\n)\r\nmode_str = \"em\"\r\n\r\npaddle.onnx.export(\r\n    paddle_model,\r\n    mode_str,\r\n    input_spec=[input_spec],\r\n    opset_version=12,\r\n    enable_onnx_checker=True,\r\n)\r\n```\r\n\r\n错误如下：\r\n```\r\nNotImplementedError: \r\nThere's 1 ops are not supported yet\r\n=========== max_pool2d_with_index ===========\r\n```\r\n\r\n希望可以帮助解决一下。",
        "state": "closed",
        "user": "BBuf",
        "closed_by": "BBuf",
        "created_at": "2021-03-26T07:48:45+00:00",
        "updated_at": "2021-04-21T14:32:36+00:00",
        "closed_at": "2021-04-21T14:32:36+00:00",
        "comments_count": [
            "Zeref996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 232,
        "title": "PaddleOCR的模型能通过Paddle2ONNX转为ONNX吗？",
        "body": "我想把PaddleOCR的模型，例如ch_ppocr_mobile_v2.0_det_infer，转化为ONNX，然后再转为NCNN。所以能通过Paddle2ONNX能将其转化为ONNX，若可以，请问要怎么操作？",
        "state": "closed",
        "user": "YJLCV",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-04-06T02:22:35+00:00",
        "updated_at": "2025-07-08T02:59:07+00:00",
        "closed_at": "2025-07-08T02:59:07+00:00",
        "comments_count": [
            "jiangjiajun",
            "YJLCV",
            "YJLCV",
            "znsoftm",
            "jiangjiajun",
            "YJLCV",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 222,
        "title": "什么时候支持 Conv3D",
        "body": "版本 0.5\r\n目前不支持 `trilinear_interp_v2 ` 和 `conv3d` 等三维算子，希望能够尽快支持，谢谢",
        "state": "closed",
        "user": "morgan-bc",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-03-29T03:56:20+00:00",
        "updated_at": "2024-05-22T04:53:21+00:00",
        "closed_at": "2024-05-22T04:53:21+00:00",
        "comments_count": [
            "jiangjiajun",
            "morgan-bc",
            "jiangjiajun",
            "morgan-bc",
            "morgan-bc",
            "jiangjiajun"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 236,
        "title": "please check whether the model file is complete or damaged.??",
        "body": "paddle2onnx --model_dir C:\\Users\\baidu\\inference_model\\  --save_file C:\\Users\\baidu\\inference_model_ok --opset_version 11 --enable_onnx_checker True\r\n\r\nC:\\Users\\baidu\\inference_model\\    文件夹\r\n__model__\r\n__params__\r\nmodel.yml\r\n\r\n提示报错  我的模型下面也没这文件\r\nUnavailableError: Load operator fail to open file C:\\Users\\baidu\\inference_model\\bn4c_branch2c_scale, please check whether the model file is complete or damaged.\r\n      [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] (at D:\\v2.0.1\\paddle\\paddle/fluid/operators/load_op.h:41)\r\n\r\n目标检测模型 FasterRCNN",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "monkeycc",
        "created_at": "2021-04-10T14:53:51+00:00",
        "updated_at": "2021-04-12T14:50:59+00:00",
        "closed_at": "2021-04-12T14:50:59+00:00",
        "comments_count": [
            "jiangjiajun",
            "monkeycc",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 237,
        "title": "mask-rcnn转换onnx失败！？",
        "body": "AttributeError: 'MaskRCNN' object has no attribute 'eval'",
        "state": "closed",
        "user": "liufangtao",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-04-13T03:21:22+00:00",
        "updated_at": "2025-07-03T03:00:00+00:00",
        "closed_at": "2025-07-03T03:00:00+00:00",
        "comments_count": [
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 233,
        "title": "请问PPOCR官方提供的inference model在转换后只能输入100的宽度，这块如何修改为动态输入呢",
        "body": "这个链接的model\r\nhttps://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_infer.tar",
        "state": "closed",
        "user": "MagicCodess",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-06T09:39:18+00:00",
        "updated_at": "2024-05-22T05:01:53+00:00",
        "closed_at": "2024-05-22T05:01:53+00:00",
        "comments_count": [
            "jiangjiajun",
            "RyanCCC"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 238,
        "title": "PaddleOCR转为ONNX模型后无法在GPU上预测",
        "body": "运算被强制转移到了CPU，请问这种问题该如何解决呢～谢谢\r\n`2021-04-13 15:19:14.135451870 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_2\r\n2021-04-13 15:19:14.135526239 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_3\r\n2021-04-13 15:19:14.135576684 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_1\r\n2021-04-13 15:19:14.135592834 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_3\r\n2021-04-13 15:19:14.135617220 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_0\r\n2021-04-13 15:19:14.135662495 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_0\r\n2021-04-13 15:19:14.135677904 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_1\r\n2021-04-13 15:19:14.239853252 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_2\r\n2021-04-13 15:19:14.239900791 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_3\r\n2021-04-13 15:19:14.239915920 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_1\r\n2021-04-13 15:19:14.239927371 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_3\r\n2021-04-13 15:19:14.239947499 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_0\r\n2021-04-13 15:19:14.239960553 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_0\r\n2021-04-13 15:19:14.239967346 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_1\r\n2021-04-13 15:19:14.244295462 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_2\r\n2021-04-13 15:19:14.244338543 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_3\r\n2021-04-13 15:19:14.244348872 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_1\r\n2021-04-13 15:19:14.244361246 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_3\r\n2021-04-13 15:19:14.244374871 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_0\r\n2021-04-13 15:19:14.244391312 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_0\r\n2021-04-13 15:19:14.244397684 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_1\r\n2021-04-13 15:19:14.273340584 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_2\r\n2021-04-13 15:19:14.273384075 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_3\r\n2021-04-13 15:19:14.273394114 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_1\r\n2021-04-13 15:19:14.273406948 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_3\r\n2021-04-13 15:19:14.273420754 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Slice_0\r\n2021-04-13 15:19:14.273434009 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Concat_0\r\n2021-04-13 15:19:14.273440631 [W:onnxruntime:Default, fallback_cpu_capability.cc:135 GetCpuPreferredNodes] Force fallback to CPU execution for node: Cast_1`",
        "state": "closed",
        "user": "MagicCodess",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-13T07:42:16+00:00",
        "updated_at": "2024-07-15T03:51:18+00:00",
        "closed_at": "2024-07-15T03:51:01+00:00",
        "comments_count": [
            "jiangjiajun",
            "MagicCodess",
            "jiangjiajun",
            "MagicCodess"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 239,
        "title": "使用paddle2onnx0.6版本，转换paddle1.8版本的模型文件报错",
        "body": "    InvalidArgumentError: Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 1904018048 found).\r\n      [Hint: Expected version == 0U, but received version:1904018048 != 0U:0.] (at /paddle/paddle/fluid/framework/lod_tensor.cc:313)\r\n      [operator < load_combine > error]\r\n\r\n但是我的模型文件是使用paddledetection导出的.pdmodel和.pdparams，怎么会不是paddlemodel呢？",
        "state": "closed",
        "user": "Fly-hub",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-04-19T09:55:51+00:00",
        "updated_at": "2025-07-02T02:58:01+00:00",
        "closed_at": "2025-07-02T02:58:01+00:00",
        "comments_count": [
            "jiangjiajun",
            "Fly-hub",
            "jiangjiajun",
            "ChaocunChen",
            "jiangjiajun",
            "ChaocunChen",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 240,
        "title": "AdaptiveMaxPool 和 MaxPool 不支持",
        "body": "AdaptiveMaxPool3D 和 AdaptiveMaxPool3D 操作不支持\r\n报错信息\r\n```\r\nThere's 1 ops are not supported yet\r\n=========== max_pool2d_with_index ===========\r\n```\r\n版本\r\n```\r\nPaddlePaddle-gpu: 2.0.1.post110\r\nPaddle2Onnx: 0.5\r\nonnx: 1.7.0\r\n```\r\n\r\n\r\n建议把基础的2D和3D操作算子都测一遍，这里面坑也太多了",
        "state": "closed",
        "user": "morgan-bc",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-21T03:55:01+00:00",
        "updated_at": "2024-05-22T04:55:07+00:00",
        "closed_at": "2024-05-22T04:54:58+00:00",
        "comments_count": [
            "jiangjiajun",
            "morgan-bc",
            "jiangjiajun",
            "morgan-bc",
            "jiangjiajun",
            "morgan-bc"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 241,
        "title": "Different behaviors when converting PaddleOCR into Onnx with different opset version.",
        "body": "I tried to convert PaddleOCR text detector model (PP-OCR 2.0 version) into ONNX model. The conversion was successful but the output from ONNX model did not match with the output from the original model (using paddlepaddle).\r\nI also figured out by using different opset from 10-13, I got different results. It seems that using opset 10, I got pretty similar results (not sure if it's 100% similar) compared to the original model but using opset 11 12 and 13, I got completely different results.\r\n\r\nCan anyone help check and fix this strange behavior?\r\n\r\nThanks in advance.\r\n\r\n",
        "state": "closed",
        "user": "JC1DA",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-21T06:16:34+00:00",
        "updated_at": "2024-07-15T03:50:44+00:00",
        "closed_at": "2024-07-15T03:50:44+00:00",
        "comments_count": [
            "jiangjiajun",
            "JC1DA"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 247,
        "title": "multicalss_nms Operator在转换时无需先取Neg",
        "body": "https://github.com/PaddlePaddle/Paddle2ONNX/blob/71c5b1688838b48fa2c227bce511bac08fb919da/paddle2onnx/op_mapper/detection/multiclass_nms.py#L275",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-27T06:29:47+00:00",
        "updated_at": "2024-07-15T03:50:34+00:00",
        "closed_at": "2024-07-15T03:50:34+00:00",
        "comments_count": [],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 242,
        "title": "Yolo_box的clip_bbox属性为False的情况在Paddle2ONN没有考虑。",
        "body": null,
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-21T08:33:36+00:00",
        "updated_at": "2024-07-15T03:50:56+00:00",
        "closed_at": "2024-07-15T03:50:55+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 244,
        "title": "psgan model doesn't convert to onnx model",
        "body": "I use this command to convert onnx model:\r\npaddle2onnx --model_filename /home/Paddle2ONNX/model/psgan_weight.pdparams --sa\r\nve_file save_model --opset_version 10 --enable_onnx_checker True",
        "state": "closed",
        "user": "Igoslow",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-23T05:25:18+00:00",
        "updated_at": "2024-05-22T04:54:00+00:00",
        "closed_at": "2024-05-22T04:54:00+00:00",
        "comments_count": [
            "Igoslow",
            "jiangjiajun",
            "Igoslow",
            "jiangjiajun",
            "Igoslow"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 245,
        "title": "Paddle2ONNX V0.6 已经支持PaddleDetection的新版PPYOLOV2和TinyPPYOLO模型",
        "body": "正在进行中，如有相关需求，可在此issue下回复『+1』，后续支持后，会在此issue进行更新",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-04-23T08:54:52+00:00",
        "updated_at": "2024-07-13T12:38:45+00:00",
        "closed_at": "2024-05-22T04:52:46+00:00",
        "comments_count": [
            "znsoftm",
            "duolabmeng6",
            "DongChenwei2000",
            "jiangjiajun",
            "DongChenwei2000",
            "dgl547437235",
            "jiangjiajun",
            "duolabmeng6",
            "muzishen",
            "MasonSuWei",
            "jiangjiajun",
            "francislinker",
            "jiangjiajun",
            "jiangjiajun",
            "duolabmeng6",
            "printso",
            "jiangjiajun",
            "printso",
            "jiangjiajun",
            "printso",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 248,
        "title": "OCR db server 2.0 如何转动态尺度的onnx?",
        "body": "目前用该工具转换的都是固定w,h的，你们开源的都是推理模型，是不是不支持用paddle.export.onnx重新load，然后转换?",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-04-29T06:50:30+00:00",
        "updated_at": "2021-09-17T06:16:47+00:00",
        "closed_at": "2021-04-30T05:01:15+00:00",
        "comments_count": [
            "jiangjiajun",
            "daixiangzi",
            "daixiangzi",
            "daixiangzi",
            "jiangjiajun",
            "daixiangzi",
            "RyanCCC"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 249,
        "title": "有点问题请教",
        "body": "你们开源的DB检测模型，里面好像没有用变形卷积。虽然说你们现在onnx支持了该算子，下一步会开源相关版本的模型吗",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "daixiangzi",
        "created_at": "2021-04-30T05:09:20+00:00",
        "updated_at": "2021-05-08T09:58:33+00:00",
        "closed_at": "2021-05-08T09:58:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "daixiangzi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 250,
        "title": "paddle2onnx error",
        "body": "使用命令转换静态图为onnx:\r\n出现下面错误，不支持lstm 和sequence_pool\r\nThere's 2 ops are not supported yet\r\n=========== sequence_pool ===========\r\n=========== lstm ===========\r\n",
        "state": "closed",
        "user": "daixiangzi",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-08T10:00:03+00:00",
        "updated_at": "2024-06-05T06:13:08+00:00",
        "closed_at": "2024-06-05T06:13:08+00:00",
        "comments_count": [
            "daixiangzi",
            "jiangjiajun",
            "daixiangzi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 253,
        "title": "可以出一个 转ncnn模型得工具嘛",
        "body": "可以出一个 转ncnn模型得工具嘛",
        "state": "closed",
        "user": "lvzhencang",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-13T03:14:07+00:00",
        "updated_at": "2024-06-04T07:05:04+00:00",
        "closed_at": "2024-06-04T07:04:55+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 251,
        "title": "ppOCR新发布的端到端模型PGNet，是否可以转换成ONNX运行呢",
        "body": "我最近在使用ppOCR新增的PGNet，效果很好。我想把模型转换成onnx，然后使用onnx进行部署，请问这个模型可以转换吗",
        "state": "closed",
        "user": "gaooolianggg",
        "closed_by": "gaooolianggg",
        "created_at": "2021-05-11T00:37:52+00:00",
        "updated_at": "2021-05-24T08:22:20+00:00",
        "closed_at": "2021-05-24T08:22:20+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 255,
        "title": "当前(2021.05.16)请注意使用PaddleDetection的Develop分支导出PPYOLO和PPYOLO-tiny模型，注意对应的PaddlePaddle版本也为develop版本",
        "body": "当前(2021.05.16)请注意使用PaddleDetection的Develop分支导出PPYOLO和PPYOLO-tiny模型，注意对应的PaddlePaddle版本也为develop版本\r\n\r\n原因在于目前PaddleDetection的release 2.0分支在导出目标检测模型时，会导出控制流相关操作，在develop分支中解决了这个问题\r\n\r\n_Originally posted by @jiangjiajun in https://github.com/PaddlePaddle/Paddle2ONNX/issues/245#issuecomment-841807085_",
        "state": "closed",
        "user": "francislinker",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-05-18T03:38:45+00:00",
        "updated_at": "2025-07-01T03:12:48+00:00",
        "closed_at": "2025-07-01T03:12:48+00:00",
        "comments_count": [
            "francislinker",
            "jiangjiajun",
            "liuwenhua6666",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 254,
        "title": "RoadMap of Paddle2ONNX",
        "body": "# Paddle2ONNX v0.8 (2021.08)\r\n- [ ] Demo shows how to deploy Paddle model use C# through onnxruntime\r\n- [ ] Quantize Model Support\r\n\r\n# Paddle2ONNX v0.7 (2021.07)\r\n- [ ] OpenVINO/OpenCV inference support different export method\r\n- [ ] More OCR models add to Paddle2ONNX ci\r\n- [ ] OP set version auto check and update\r\n- [ ] ppyolo-tiny support deploy by opencv\r\n\r\n# Paddle2ONNX v0.6 [Released](https://github.com/PaddlePaddle/Paddle2ONNX/releases/tag/v0.6)\r\n- [x] PaddleDetection 2.0 support\r\n- - [x] YOLOv3\r\n- - [x] PPYOLO\r\n- - [x] PPYOLOv2\r\n- - [x] PPYOLO-Tiny\r\n- - [x] TTFNet\r\n- - [x] PAFNet\r\n- - [x] FCOS\r\n- - [x] SSD\r\n- - [ ] FasterRCNN (Pending due to the condition block in RCNN models)",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-17T08:17:46+00:00",
        "updated_at": "2024-07-15T03:50:28+00:00",
        "closed_at": "2024-07-15T03:50:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun",
            "znsoftm",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 256,
        "title": "paddle转onnx算子不支持assign",
        "body": "onnx模型转的paddle，然后paddle再转onnx报错\r\nThere's 1 ops are not supported yet\r\n=========== assign ===========",
        "state": "closed",
        "user": "williamlzw",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-20T07:09:39+00:00",
        "updated_at": "2024-06-24T06:33:52+00:00",
        "closed_at": "2024-06-24T06:33:52+00:00",
        "comments_count": [
            "jiangjiajun",
            "williamlzw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 260,
        "title": "paddle2onnx能否支持pixel_shuffle ？",
        "body": "进行超分辨率模型的转换时，程序报错There's 1 ops are not supported yet\r\n=========== pixel_shuffle =========== 该怎么解决呢？",
        "state": "closed",
        "user": "KKKloveQbh",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-31T18:35:24+00:00",
        "updated_at": "2024-07-15T03:50:19+00:00",
        "closed_at": "2024-07-15T03:50:19+00:00",
        "comments_count": [
            "jiangjiajun",
            "KKKloveQbh",
            "jiangjiajun",
            "jiangjiajun",
            "KKKloveQbh"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 259,
        "title": "想转换一个能够处理任意大小的模型",
        "body": "想转换一个能够处理任意大小的模型，设置InputSpec的shape为[1,3,-1,-1]时报错，Only one dimension value of 'shape' in reshape can be -1. But received shape[2] is also -1.请问应该怎么转换呢？原模型是可以处理任意大小的",
        "state": "closed",
        "user": "KKKloveQbh",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-05-31T18:17:44+00:00",
        "updated_at": "2024-06-04T07:05:19+00:00",
        "closed_at": "2024-06-04T07:05:19+00:00",
        "comments_count": [
            "jiangjiajun",
            "KKKloveQbh",
            "jiangjiajun",
            "KKKloveQbh",
            "jiangjiajun",
            "KKKloveQbh",
            "KKKloveQbh",
            "jiangjiajun",
            "KKKloveQbh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 262,
        "title": "我想把一个resnet_vd转为onnx，想请问应该用静态图还是动态图，参数该如何填",
        "body": "这个模型 https://github.com/PaddlePaddle/PaddleClas/blob/release/2.1/docs/zh_CN/application/transfer_learning.md\r\n页面里面有个.pdparams文件\r\n\r\n根据这个文档 https://github.com/PaddlePaddle/Paddle2ONNX/blob/release/0.6/README_zh.md\r\n\r\n两个都试了，都有问题\r\n```bash\r\n$ paddle2onnx \\\r\n    --model_dir /root/paddle \\\r\n    --model_filename /root/paddle/PaddleClas/ppcls/modeling/architectures/resnet_vd.py \\\r\n    --params_filename /root/paddle/ResNet50_vd_10w_pretrained.pdparams \\\r\n    --save_file onnx_file.onnx\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle2onnx/command.py\", line 136, in main\r\n    program2onnx(\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle2onnx/command.py\", line 102, in program2onnx\r\n    [program, feed_var_names, fetch_vars] = fluid.io.load_inference_model(\r\n  File \"<decorator-gen-88>\", line 2, in load_inference_model\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 234, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/io.py\", line 1538, in load_inference_model\r\n    program = Program.parse_from_string(program_desc_str)\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 5080, in parse_from_string\r\n    p.desc = core.ProgramDesc(binary_str)\r\nValueError: (InvalidArgument) Failed to parse program_desc from binary string.\r\n  [Hint: Expected desc_.ParseFromString(binary_str) == true, but received desc_.ParseFromString(binary_str):0 != true:1.] (at /paddle/paddle/fluid/framework/program_desc.cc:103)\r\n```\r\n\r\n另一个\r\n\r\n```python\r\nimport os\r\nimport time\r\nimport paddle\r\n\r\n# 从模型代码中导入模型\r\nfrom PaddleClas.ppcls.modeling.architectures.resnet_vd import ResNet50_vd\r\n\r\n# 实例化模型\r\nmodel = ResNet50_vd()\r\n# import ipdb; ipdb.set_trace()\r\n# 将模型设置为推理状态\r\nmodel.eval()\r\n\r\n# 定义输入数据\r\n# input_spec = paddle.static.InputSpec(shape=[None, 3, 320, 320], dtype='float32', name='image')\r\n\r\n# ONNX模型导出\r\n# enable_onnx_checker设置为True，表示使用官方ONNX工具包来check模型的正确性，需要安装ONNX（pip install onnx）\r\n\r\n# paddle.onnx.export(model, 'resnet50', input_spec=[input_spec], opset_version=12, enable_onnx_checker=True)\r\npaddle.onnx.export(model, 'ResNet50_vd.onnx')\r\n\r\n```\r\n\r\n得到输出\r\n\r\n```\r\nInference models that PaddleClas provides are listed as follows:\r\n+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n|       Series      |                                                                           Name                                                                           |\r\n+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n|      AlexNet      |                                                                         AlexNet                                                                          |\r\n|      DarkNet      |                                                                        DarkNet53                                                                         |\r\n|        DeiT       |     DeiT_base_distilled_patch16_224  DeiT_base_distilled_patch16_384  DeiT_base_patch16_224  DeiT_base_patch16_384  DeiT_small_distilled_patch16_224     |\r\n|                   |                                      DeiT_small_patch16_224  DeiT_tiny_distilled_patch16_224  DeiT_tiny_patch16_224                                      |\r\n|      DenseNet     |                                             DenseNet121  DenseNet161  DenseNet169  DenseNet201  DenseNet264                                              |\r\n|        DPN        |                                                           DPN68  DPN92  DPN98  DPN107  DPN131                                                            |\r\n|    EfficientNet   |   EfficientNetB0  EfficientNetB0_small  EfficientNetB1  EfficientNetB2  EfficientNetB3  EfficientNetB4  EfficientNetB5  EfficientNetB6  EfficientNetB7   |\r\n|      GhostNet     |                                             GhostNet_x0_5  GhostNet_x1_0  GhostNet_x1_3  GhostNet_x1_3_ssld                                              |\r\n|       HRNet       |              HRNet_W18_C  HRNet_W30_C  HRNet_W32_C  HRNet_W40_C  HRNet_W44_C  HRNet_W48_C  HRNet_W64_C  HRNet_W18_C_ssld  HRNet_W48_C_ssld               |\r\n|     Inception     |                                                           GoogLeNet  InceptionV3  InceptionV4                                                            |\r\n|    MobileNetV1    |                                  MobileNetV1_x0_25  MobileNetV1_x0_5  MobileNetV1_x0_75  MobileNetV1  MobileNetV1_ssld                                   |\r\n|    MobileNetV2    |                MobileNetV2_x0_25  MobileNetV2_x0_5  MobileNetV2_x0_75  MobileNetV2  MobileNetV2_x1_5  MobileNetV2_x2_0  MobileNetV2_ssld                 |\r\n|    MobileNetV3    |    MobileNetV3_small_x0_35  MobileNetV3_small_x0_5  MobileNetV3_small_x0_75  MobileNetV3_small_x1_0  MobileNetV3_small_x1_25  MobileNetV3_large_x0_35    |\r\n|                   |              MobileNetV3_large_x0_5  MobileNetV3_large_x0_75  MobileNetV3_large_x1_0  MobileNetV3_large_x1_25  MobileNetV3_small_x1_0_ssld               |\r\n|                   |                                                               MobileNetV3_large_x1_0_ssld                                                                |\r\n|       RegNet      |                                                                       RegNetX_4GF                                                                        |\r\n|      Res2Net      | Res2Net50_14w_8s  Res2Net50_26w_4s  Res2Net50_vd_26w_4s  Res2Net200_vd_26w_4s  Res2Net101_vd_26w_4s  Res2Net50_vd_26w_4s_ssld  Res2Net101_vd_26w_4s_ssld |\r\n|                   |                                                                Res2Net200_vd_26w_4s_ssld                                                                 |\r\n|      ResNeSt      |                                                            ResNeSt50  ResNeSt50_fast_1s1x64d                                                             |\r\n|       ResNet      |    ResNet18  ResNet18_vd  ResNet34  ResNet34_vd  ResNet50  ResNet50_vc  ResNet50_vd  ResNet50_vd_v2  ResNet101  ResNet101_vd  ResNet152  ResNet152_vd    |\r\n|                   |         ResNet200_vd  ResNet34_vd_ssld  ResNet50_vd_ssld  ResNet50_vd_ssld_v2  ResNet101_vd_ssld  Fix_ResNet50_vd_ssld_v2  ResNet50_ACNet_deploy         |\r\n|      ResNeXt      |          ResNeXt50_32x4d  ResNeXt50_vd_32x4d  ResNeXt50_64x4d  ResNeXt50_vd_64x4d  ResNeXt101_32x4d  ResNeXt101_vd_32x4d  ResNeXt101_32x8d_wsl           |\r\n|                   | ResNeXt101_32x16d_wsl  ResNeXt101_32x32d_wsl  ResNeXt101_32x48d_wsl  Fix_ResNeXt101_32x48d_wsl  ResNeXt101_64x4d  ResNeXt101_vd_64x4d  ResNeXt152_32x4d  |\r\n|                   |                                                ResNeXt152_vd_32x4d  ResNeXt152_64x4d  ResNeXt152_vd_64x4d                                                |\r\n|       SENet       |     SENet154_vd  SE_HRNet_W64_C_ssld  SE_ResNet18_vd  SE_ResNet34_vd  SE_ResNet50_vd  SE_ResNeXt50_32x4d  SE_ResNeXt50_vd_32x4d  SE_ResNeXt101_32x4d     |\r\n|    ShuffleNetV2   |          ShuffleNetV2_swish  ShuffleNetV2_x0_25  ShuffleNetV2_x0_33  ShuffleNetV2_x0_5  ShuffleNetV2_x1_0  ShuffleNetV2_x1_5  ShuffleNetV2_x2_0          |\r\n|     SqueezeNet    |                                                               SqueezeNet1_0  SqueezeNet1_1                                                               |\r\n|  SwinTransformer  |   SwinTransformer_large_patch4_window7_224_22kto1k  SwinTransformer_large_patch4_window12_384_22kto1k  SwinTransformer_base_patch4_window7_224_22kto1k   |\r\n|                   |           SwinTransformer_base_patch4_window12_384_22kto1k  SwinTransformer_base_patch4_window12_384  SwinTransformer_base_patch4_window7_224            |\r\n|                   |                                    SwinTransformer_small_patch4_window7_224  SwinTransformer_tiny_patch4_window7_224                                     |\r\n|        VGG        |                                                                VGG11  VGG13  VGG16  VGG19                                                                |\r\n| VisionTransformer |          ViT_base_patch16_224  ViT_base_patch16_384  ViT_base_patch32_384  ViT_large_patch16_224  ViT_large_patch16_384  ViT_large_patch32_384           |\r\n|                   |                                                                  ViT_small_patch16_224                                                                   |\r\n|      Xception     |                                        Xception41  Xception41_deeplab  Xception65  Xception65_deeplab  Xception71                                        |\r\n+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\r\nW0604 17:43:06.252307  2924 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0604 17:43:06.255980  2924 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"paddle2onnx.py\", line 21, in <module>\r\n    paddle.onnx.export(model, 'ResNet50_vd.onnx')\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/onnx/export.py\", line 90, in export\r\n    p2o = try_import('paddle2onnx')\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/utils/lazy_import.py\", line 32, in try_import\r\n    mod = importlib.import_module(module_name)\r\n  File \"/root/anaconda3/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"./paddle2onnx.py\", line 9, in <module>\r\n    model = ResNet50_vd()\r\n  File \"/root/paddle/PaddleClas/ppcls/modeling/architectures/resnet_vd.py\", line 338, in ResNet50_vd\r\n    model = ResNet_vd(layers=50, **args)\r\n  File \"/root/paddle/PaddleClas/ppcls/modeling/architectures/resnet_vd.py\", line 231, in __init__\r\n    self.conv1_1 = ConvBNLayer(\r\n  File \"/root/paddle/PaddleClas/ppcls/modeling/architectures/resnet_vd.py\", line 50, in __init__\r\n    self._conv = Conv2D(\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/nn/layer/conv.py\", line 633, in __init__\r\n    super(Conv2D, self).__init__(\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/nn/layer/conv.py\", line 132, in __init__\r\n    self.weight = self.create_parameter(\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 411, in create_parameter\r\n    return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\r\n  File \"/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/layer_helper_base.py\", line 364, in create_parameter\r\n    raise ValueError(\r\nValueError: parameter name [conv1_1_weights] have be been used. In dygraph mode, the name of parameter can't be same.Please check the parameter attr value passed to self.create_parameter or constructor of dygraph Layers\r\n```\r\n\r\n想请问正确的姿势是什么，想直接取这个模型用\r\n",
        "state": "closed",
        "user": "cww97",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-06-04T10:39:09+00:00",
        "updated_at": "2024-06-04T07:05:38+00:00",
        "closed_at": "2024-06-04T07:05:38+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 263,
        "title": "AttributeError: module 'paddle2onnx' has no attribute 'dygraph2onnx'",
        "body": "https://github.com/PaddlePaddle/Paddle2ONNX/blob/release/0.6/README_zh.md\r\n动态图，readme里面的example代码，“动态图模型导出”这一段，直接无法运行，有特殊的版本需求吗\r\n",
        "state": "closed",
        "user": "cww97",
        "closed_by": "cww97",
        "created_at": "2021-06-09T06:06:56+00:00",
        "updated_at": "2021-06-09T06:34:00+00:00",
        "closed_at": "2021-06-09T06:34:00+00:00",
        "comments_count": [
            "cww97",
            "jiangjiajun",
            "cww97",
            "jiangjiajun",
            "cww97",
            "jiangjiajun",
            "jiangjiajun",
            "cww97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 265,
        "title": "mxnet导入报错",
        "body": "报错内容    \r\n\r\nsym, arg, aux = import_model(\"./inference_model/paddle/onnx/det_db/model.onnx\")\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/mxnet/contrib/onnx/onnx2mx/import_model.py\", line 60, in import_model\r\n    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph, opset_version=model_opset_version)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/mxnet/contrib/onnx/onnx2mx/import_onnx.py\", line 117, in from_onnx\r\n    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/mxnet/contrib/onnx/onnx2mx/import_onnx.py\", line 62, in _convert_operator\r\n    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/mxnet/contrib/onnx/onnx2mx/_op_translations.py\", line 340, in conv\r\n    new_attrs = translation_utils._fix_channels('Convolution', new_attrs, inputs, proto_obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/mxnet/contrib/onnx/onnx2mx/_translation_utils.py\", line 181, in _fix_channels\r\n    raise ValueError(\"Unable to get channels/units attr from onnx graph.\")\r\nValueError: Unable to get channels/units attr from onnx graph.\r\n\r\n使用onnxruntime预测是没有问题，请问是什么问题?",
        "state": "closed",
        "user": "chenzi",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-06-11T09:59:10+00:00",
        "updated_at": "2024-06-05T06:12:57+00:00",
        "closed_at": "2024-06-05T06:12:57+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 269,
        "title": "paddleseg使用paddle2onnx转换后的onnx模型的输入为什么是type: float32[-1,3,-1,-1]这样？",
        "body": "请问：paddleseg使用paddle2onnx转换后的onnx模型的输入为什么是type: float32[-1,3,-1,-1]这样？输出是type: float32[-1,2,-1,-1]，为什么只有通道数那个参数是正常的，别的都是-1，而且转换后的onnx模型使用onnxruntime无法有效进行推理部署。我训练的是paddleseg中的unet网络。",
        "state": "closed",
        "user": "Fly-hub",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-06-21T11:33:07+00:00",
        "updated_at": "2024-07-15T03:49:31+00:00",
        "closed_at": "2024-07-15T03:49:31+00:00",
        "comments_count": [
            "jiangjiajun",
            "Fly-hub",
            "jiangjiajun",
            "Fly-hub",
            "jiangjiajun"
        ],
        "labels": [
            "Dependencies"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 267,
        "title": "NLP模型都不能转ONNX吗",
        "body": "看了一下支持列表，里面没有一个nlp模型，是NLP模型都不支持吗？如果支持如何将LAC模型转成ONNX，我看文档发现LAC模型与转ONNX需要的模型文件差别很大，好想LAC模型是旧版的paddle模型，是这样吗？如果是旧版的paddle模型，是不是无法转ONNX，还是说低版本的paddle2ONNX可以转？",
        "state": "closed",
        "user": "bigvine2",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-06-21T06:54:29+00:00",
        "updated_at": "2025-06-30T03:06:52+00:00",
        "closed_at": "2025-06-30T03:06:52+00:00",
        "comments_count": [
            "jiangjiajun",
            "bigvine2",
            "jiangjiajun",
            "bigvine2",
            "bigvine2",
            "ifromeast",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 270,
        "title": "ERNIE动态图转ONNX时输入数据类型如何知道？",
        "body": "paddle动态图转ONNX的描述非常简略，能否给出一个详细的例子，例如对现有动态图的预训练模型转换为onnx的过程？\r\n当前例子中输入数据类型是容易知道的，但是预训练模型的输入数据类型并不知道，这使得转onnx无法进行",
        "state": "closed",
        "user": "bigvine2",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-06-22T09:05:32+00:00",
        "updated_at": "2024-05-22T04:54:19+00:00",
        "closed_at": "2024-05-22T04:54:19+00:00",
        "comments_count": [
            "jiangjiajun",
            "bigvine2",
            "jiangjiajun",
            "bigvine2",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 271,
        "title": "plato-2 模型可以转成 onnx 么，官方下载的模型没有__model__",
        "body": null,
        "state": "closed",
        "user": "ifromeast",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-06-23T05:38:18+00:00",
        "updated_at": "2024-07-15T03:49:41+00:00",
        "closed_at": "2024-07-15T03:49:37+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 273,
        "title": "fom转onnx问题",
        "body": "您好，我利用paddle2onnx转换人脸动作迁移模型fom（此项目在paddleGAN中的[fom](https://github.com/PaddlePaddle/PaddleGAN/blob/develop/docs/en_US/tutorials/motion_driving.md)）时，出现以下还不支持的算子信息：\r\n![image](https://user-images.githubusercontent.com/30396038/124437704-e79d7680-dda9-11eb-853a-5bbe1f25f479.png)\r\n我将模型相关的pdmode，pdiparams文件放在了如下百度云中，请问一下目前这些算子有支持的计划吗？\r\n链接：https://pan.baidu.com/s/1SK6KryHSmFr2NI_9r5zqVQ \r\n提取码：qonf ",
        "state": "closed",
        "user": "zhoumenghan",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-07-05T08:04:36+00:00",
        "updated_at": "2025-06-29T03:10:50+00:00",
        "closed_at": "2025-06-29T03:10:50+00:00",
        "comments_count": [
            "zhoumenghan",
            "zhoumenghan",
            "jiangjiajun",
            "zhoumenghan",
            "zhoumenghan",
            "jiangjiajun",
            "zhoumenghan",
            "zhoumenghan",
            "jiangjiajun",
            "liming2464",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 275,
        "title": "你好，请问你这个是什么模型呢，除了上述UINT8问题，还存在目前未支持的GRU算子",
        "body": "你好，请问你这个是什么模型呢，除了上述UINT8问题，还存在目前未支持的GRU算子\r\n\r\n_Originally posted by @jiangjiajun in https://github.com/PaddlePaddle/Paddle2ONNX/issues/274#issuecomment-874049091_\r\n\r\n你好 。模型已经上传到 model.pdiparams.zip 。https://aistudio.baidu.com/aistudio/projectdetail/1100507?channelType=0&channel=0\r\n该项目训练得模型",
        "state": "closed",
        "user": "72min",
        "closed_by": "72min",
        "created_at": "2021-07-05T11:52:46+00:00",
        "updated_at": "2021-07-05T12:22:01+00:00",
        "closed_at": "2021-07-05T12:22:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 274,
        "title": "KeyError: VarType.UINT8",
        "body": "![QQ截图20210705163330](https://user-images.githubusercontent.com/60537262/124442378-43b6c980-ddaf-11eb-887b-f02252b98b06.png)\r\n[model.pdiparams.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/6762904/model.pdiparams.zip)\r\n!paddle2onnx -m /home/aistudio/models/ --model_filename model.pdmodel --params_filename model.pdiparams -s /home/aistudio//onnx/model.onnx --opset_version 11 \r\n报错 KeyError: VarType.UINT8",
        "state": "closed",
        "user": "72min",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-07-05T08:39:14+00:00",
        "updated_at": "2025-06-28T02:53:02+00:00",
        "closed_at": "2025-06-28T02:53:02+00:00",
        "comments_count": [
            "jiangjiajun",
            "72min",
            "72min",
            "wjj19950828",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 279,
        "title": "Cannot run global average pool on an input with dynamic spatial dimensions",
        "body": "onnx to tensorRT failed.\r\n`/home/juzheng/soft/TensorRT-7.0.0.11/bin/trtexec --onnx=0713_resnet50_smoking.onnx --saveEngine=attr.trt`\r\n\r\nerror message:\r\nERROR: builtin_op_importers.cpp:1087 In function importGlobalAveragePool:\r\n[8] Assertion failed: !isDynamic(kernelSize) && \"Cannot run global average pool on an input with dynamic spatial dimensions!\"\r\n[07/13/2021-10:01:04] [E] Failed to parse onnx file\r\n[07/13/2021-10:01:04] [E] Parsing model failed\r\n[07/13/2021-10:01:04] [E] Engine creation failed\r\n[07/13/2021-10:01:04] [E] Engine set up failed\r\n&&&& FAILED TensorRT.trtexec # /home/juzheng/soft/TensorRT-7.0.0.11/bin/trtexec --onnx=0713_resnet50_smoking.onnx --saveEngine=attr.trt\r\n",
        "state": "closed",
        "user": "ioir123ju",
        "closed_by": "ioir123ju",
        "created_at": "2021-07-13T02:29:04+00:00",
        "updated_at": "2021-07-19T07:04:10+00:00",
        "closed_at": "2021-07-19T07:04:10+00:00",
        "comments_count": [
            "jiangjiajun",
            "ioir123ju"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 278,
        "title": "请教如何读取onnx模型里的Constant",
        "body": "如题。\r\n例如reshape_4这个算子的shape是\r\n> name: Constant_190\r\nkind: Constant\r\ntype: int64[3]\r\n[\r\n    0,\r\n    0,\r\n    -1\r\n]\r\n\r\n我该在哪访问到这个`Constant_190`并修改他的值？并不在`graph.node`和`graph.initializer`里。",
        "state": "closed",
        "user": "raymondchu-z",
        "closed_by": "raymondchu-z",
        "created_at": "2021-07-07T07:18:35+00:00",
        "updated_at": "2021-08-03T01:54:54+00:00",
        "closed_at": "2021-08-03T01:54:54+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 277,
        "title": "Paddle模型转换为ONNX，用C++进行多种推理引擎部署",
        "body": "目前PaddleX中已集成ONNX部署，可以支持PaddleClas、PaddleDetection、PaddleSeg、PaddleX的模型通过转为ONNX，使用TensorRT、Triton、OpenVINO进行部署，相关文档参考\r\nhttps://github.com/PaddlePaddle/PaddleX/tree/develop/deploy/cpp#onnx%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-07-07T03:46:40+00:00",
        "updated_at": "2025-06-28T02:53:00+00:00",
        "closed_at": "2025-06-28T02:53:00+00:00",
        "comments_count": [
            "WangFengtu1996",
            "jiangjiajun",
            "xxdm",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 285,
        "title": "ppyolo tiny转onnx后，Unexpected input data type. Actual: (tensor(uint8)) , expected: (tensor(float))",
        "body": "转为onnx后，查看onnx模型的图，输入如下：\r\nim_shape\r\nname: im_shape\r\ntype: float32[-1,2]\r\nimage\r\nname: image\r\ntype: float32[-1,3,608,608]\r\nscale_factor\r\nname: scale_factor\r\ntype: float32[-1,2]\r\n\r\n代码：\r\nimg = cv2.resize(img, (608, 608))\r\nimg = img.transpose((2, 0, 1))\r\nimg = np.expand_dims(img, axis=0)\r\ninput_dict = {\"image\":img, \"im_shape\":np.array([[608, 608]],dtype=np.float32), \"scale_factor\": np.array([[1, 1]],dtype=np.float32)}\r\n\r\n运行错误信息：\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(uint8)) , expected: (tensor(float))",
        "state": "closed",
        "user": "zyl112334",
        "closed_by": "zyl112334",
        "created_at": "2021-07-19T01:48:37+00:00",
        "updated_at": "2021-07-20T09:30:31+00:00",
        "closed_at": "2021-07-20T07:41:18+00:00",
        "comments_count": [
            "jiangjiajun",
            "zyl112334",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 276,
        "title": "请教PPYOLOv2转ONNX相关问题",
        "body": "现在通过文档将PPYOLOv2转ONNX是没有问题的。\r\n但是我希望转出来的ONNX是没有NMS这一块的，应该怎么操作呢？\r\nNonMaxSuppression的输入如下，\r\n> boxes\r\nname: Concat_75\r\nscores\r\nname: concat_14.tmp_0\r\nmax_output_boxes_per_class\r\nname: Constant_1180\r\niou_threshold\r\nname: Constant_1179\r\nscore_threshold\r\nname: Constant_1178\r\n\r\n研究了下模型结构图之后，我希望ONNX的输出由如下算子的输出组成：Concat_73，Concat_74，Concat_75。\r\n请问该如何实现？",
        "state": "closed",
        "user": "raymondchu-z",
        "closed_by": "raymondchu-z",
        "created_at": "2021-07-06T02:43:48+00:00",
        "updated_at": "2021-07-07T02:38:57+00:00",
        "closed_at": "2021-07-07T02:38:57+00:00",
        "comments_count": [
            "jiangjiajun",
            "raymondchu-z",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 289,
        "title": "3个op不支持",
        "body": "你好，我在从paddle转onnx时有三个op不支持。报错信息是\r\n```\r\nTraceback (most recent call last):\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/bin/paddle2onnx\", line 33, in <module>\r\n    sys.exit(load_entry_point('paddle2onnx==0.6', 'console_scripts', 'paddle2onnx')())\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/command.py\", line 142, in main\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/command.py\", line 114, in program2onnx\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/convert.py\", line 77, in program2onnx\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/convert.py\", line 32, in export_onnx\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/graph/onnx_graph.py\", line 229, in build\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/graph/onnx_graph.py\", line 183, in build_op_nodes\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx-0.6-py3.6.egg/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\nNotImplementedError: \r\nThere's 3 ops are not supported yet\r\n=========== sum ===========\r\n=========== top_k ===========\r\n=========== gru ===========\r\n```\r\n但从支持的op list 来看至少sum是支持的，所以请问为什么会这样，以及我是否可以绕过这些问题。\r\n",
        "state": "closed",
        "user": "xk0221",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-03T06:09:17+00:00",
        "updated_at": "2024-05-22T05:05:31+00:00",
        "closed_at": "2024-05-22T05:05:24+00:00",
        "comments_count": [
            "xk0221",
            "yeliang2258",
            "xk0221",
            "jiangjiajun",
            "xk0221",
            "yeliang2258",
            "yeliang2258",
            "xk0221",
            "jiangjiajun",
            "xk0221",
            "jiangjiajun",
            "xk0221"
        ],
        "labels": [
            "Bug",
            "Operator(New)",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 290,
        "title": "Help me !!!  生成固定输入大小的ONNX 模型",
        "body": "HI,all\r\n* 在nvidia jetson xvaier nx 上部署 paddlepaddle 提供的预训练模型， 转成ONNX模型，只支持固定输入形状的ONNX模型， 但是我不知道如何生成固定输入大小的ONNX 模型，现在我这边已经可以生成ONNX模型\r\n* 下载paddlepallde 预训练模型 ``http://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_pretrained.tar``\r\n* 转换模型为 ``model``  ``params`` ,通过项目``https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/image_classification``\r\n执行下面的脚本\r\n```\r\npython infer.py \\\r\n        --model=ResNet50_vd \\\r\n        --pretrained_model=${path_to_pretrain_model} \\\r\n        --save_inference=True\r\n```\r\n具体内容的话，如下所示\r\n```\r\n    fluid.io.load_persistables(exe, args.pretrained_model)\r\n    if args.save_inference:\r\n        fluid.io.save_inference_model(\r\n            dirname=args.model,\r\n            feeded_var_names=['image'],\r\n            main_program=test_program,\r\n            target_vars=out,\r\n            executor=exe,\r\n            model_filename='model',\r\n            params_filename='params')\r\n        logger.info(\"model: {0} is already saved\".format(args.model))\r\n        exit(0)\r\n\r\n```\r\n* 我现在已经可以得到ONNX 模型，但是因为是动态输入，所以在设备上是不支持的，\r\n* 请帮我看下，我这么做是否是一条最优的路径 （使用paddlepaddle 提供的预训练模型， ——》 ONNX， 在设备上部署ONNX TensorRT）\r\n* 针对，固定输入大小，请指导我一下该如何操作（基于我这种方式）\r\n\r\n\r\n多谢。\r\n\r\n",
        "state": "closed",
        "user": "WangFengtu1996",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-03T07:46:56+00:00",
        "updated_at": "2024-05-30T09:29:55+00:00",
        "closed_at": "2024-05-30T09:29:55+00:00",
        "comments_count": [
            "WangFengtu1996",
            "WangFengtu1996",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 291,
        "title": "op的属性是string类型时，可以转成onnx吗？",
        "body": null,
        "state": "closed",
        "user": "guxuhong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-03T14:30:40+00:00",
        "updated_at": "2024-07-15T03:49:03+00:00",
        "closed_at": "2024-07-15T03:49:03+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 292,
        "title": "3个op不支持",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddle2onnx\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/command.py\", line 142, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/convert.py\", line 77, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/convert.py\", line 32, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 229, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 183, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 3 ops are not supported yet\r\n=========== sequence_pool ===========\r\n=========== lstm ===========\r\n=========== sequence_softmax ===========\r\n```\r\npaddle version : 1.8.5\r\npaddle2onnx version : 0.7\r\n\r\n模型是 paddle videotag下的 attention_lstm",
        "state": "open",
        "user": "handoku",
        "closed_by": null,
        "created_at": "2021-08-04T03:34:06+00:00",
        "updated_at": "2025-06-15T03:06:28+00:00",
        "closed_at": null,
        "comments_count": [
            "yeliang2258",
            "754467737",
            "CLIsVeryOK",
            "handoku",
            "FitzShen666",
            "yeliang2258",
            "FitzShen666",
            "github-actions[bot]",
            "CLIsVeryOK"
        ],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 294,
        "title": "top_k_v2和im2sequence",
        "body": "我的模型需要的是top_k，但是paddle2onnx支持的是top_k_v2,所以我在op_mapper.py下的search中把@op_maper('top_k_v2')改成了@op_maper('top_k')，但是会报\r\n```\r\nTraceback (most recent call last):\r\n  File \"export2onnx.py\", line 39, in <module>\r\n    export_dete()\r\n  File \"export2onnx.py\", line 37, in export_dete\r\n    paddle.onnx.export(model, 'carplate_rec', input_spec=[x_spec], opset_version=11)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle/onnx/export.py\", line 105, in export\r\n    **configs)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx/convert.py\", line 147, in dygraph2onnx\r\n    verbose)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx/convert.py\", line 32, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx/graph/onnx_graph.py\", line 229, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx/graph/onnx_graph.py\", line 186, in build_op_nodes\r\n    OpMapper.mapping(self, node)\r\n  File \"/localdata/kunx/rev/env/2.1.0+617/lib/python3.6/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 115, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['top_k_0'] to onnx, which op_type is 'top_k' with inputs: {'K': [], 'X': ['fc_2.tmp_3']} and outputs: {'Indices': ['top_k_0.tmp_1'], 'Out': ['top_k_0.tmp_0']}, specific error: value \"None\" is not valid attribute data type.\r\n```\r\n请问怎么解决以及top_k和top_k_v2差别在哪。\r\n此外im2sequence的代码有错\r\n   ```\r\nslice_node_blocks = list()\r\n        for i in range(out_h):\r\n            for j in range(out_w):\r\n                starts_node = graph.make_node(\r\n                    'Constant',\r\n                    dtype=dtypes.ONNX.INT64,\r\n                    dims=[4],\r\n                    value=[0, 0, h_steps[i][0], w_steps[j][0]])\r\n                ends_node = graph.make_node(\r\n                    'Constant',\r\n                    dtype=dtypes.ONNX.INT64,\r\n                    dims=[4],\r\n                    value=[999999, 999999, h_steps[i][1], w_steps[j][1]])\r\n                nodes.extend([starts_node, ends_node])\r\n\r\n                slice_block_node = graph.make_node(\r\n                    'Slice',\r\n                    inputs=[node.input('X', 0), starts_node, ends_node])\r\n                flatten_block_node = graph.make_node(\r\n                    \"Flatten\", inputs=[slice_block_node], axis=0)\r\n                nodes.extend([slice_block_node, flatten_block_node])\r\n        concat_block_node = graph.make_node(\r\n            \"Concat\",\r\n            inputs=slice_node_blocks,\r\n            outputs=node.output('Out'),\r\n            axis=0)\r\n```\r\n\r\nconcat_block_node = graph.make_node上面的两个nodes之前并没有定义，在转模型的时候这一点也会报错。",
        "state": "closed",
        "user": "xk0221",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-05T15:23:09+00:00",
        "updated_at": "2024-06-05T06:12:50+00:00",
        "closed_at": "2024-06-05T06:12:49+00:00",
        "comments_count": [
            "jiangjiajun",
            "xk0221"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 301,
        "title": "PaddleClas中的商品检测模型Paddle2ONNX转换完后，输入是 -1*3*224*224，这个-1是啥意思？",
        "body": "![图片](https://user-images.githubusercontent.com/40679769/129543190-9190d095-7bc8-4da3-99d2-cb41e369020a.png)\r\n",
        "state": "closed",
        "user": "xinsuinizhuan",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-16T09:37:29+00:00",
        "updated_at": "2024-11-19T08:18:31+00:00",
        "closed_at": "2024-11-19T08:18:31+00:00",
        "comments_count": [
            "jiangjiajun",
            "xinsuinizhuan",
            "jiangjiajun"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 297,
        "title": "Paddle2ONNX能够将网络权重转换为int32的？",
        "body": "我用TensorRT将Paddle2ONNX转换的yolov3.onnx做推理时，出现以下错误。\r\nYour ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n经过研究，Paddle2ONNX是将网络权重转为了int64，请问能否将网络权重转为int32？并且，请问如何转？",
        "state": "closed",
        "user": "wu-yakun",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-08-09T07:22:34+00:00",
        "updated_at": "2025-06-25T02:59:13+00:00",
        "closed_at": "2025-06-25T02:59:13+00:00",
        "comments_count": [
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 295,
        "title": "尝试转换PP-Structure中表格结构模型，9 ops不支持",
        "body": "#### 转换环境\r\n-  `OS`: CentOS\r\n- `paddle2onnx`: 0.7\r\n- `PaddleOCR`: release/2.2\r\n\r\n#### 转换模型[下载地址](https://paddleocr.bj.bcebos.com/dygraph_v2.0/table/en_ppocr_mobile_v2.0_table_structure_infer.tar)\r\n\r\n#### 转换代码\r\n```shell\r\npaddle2onnx --model_dir ${save_inference_path} \\\r\n            --model_filename inference.pdmodel \\\r\n            --params_filename inference.pdiparams \\\r\n            --save_file ${save_onnx_path} \\\r\n            --opset_version 12\r\n```\r\n\r\n#### 报错信息\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/command.py\", line 142, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 77, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 32, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 229, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 183, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/home/SWHL/miniconda3/envs/SWHL/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 9 ops are not supported yet\r\n=========== lod_array_length ===========\r\n=========== one_hot_v2 ===========\r\n=========== less_than ===========\r\n=========== logical_not ===========\r\n=========== select_input ===========\r\n=========== write_to_array ===========\r\n=========== conditional_block ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== while ===========\r\n```\r\n\r\n希望可以帮助解决一下，十分感谢！",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-08-06T01:52:09+00:00",
        "updated_at": "2025-06-27T02:58:37+00:00",
        "closed_at": "2025-06-27T02:58:37+00:00",
        "comments_count": [
            "jiangjiajun",
            "SWHL",
            "jiangjiajun",
            "SWHL",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 304,
        "title": "ernie转onnx时候，输入参数有input_ids,seg_ids,length,在InputSpec里面传入什么",
        "body": null,
        "state": "closed",
        "user": "Elite-stars",
        "closed_by": "Elite-stars",
        "created_at": "2021-08-18T08:24:45+00:00",
        "updated_at": "2021-08-18T08:36:30+00:00",
        "closed_at": "2021-08-18T08:36:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 303,
        "title": "paddleClas里面的商品识别模型检测模型ppyolov2_r50vd_dcn_mainbody_v1.0_infer，转onnx，三个操作不支持",
        "body": "使用paddleClas转换商品识别模型检测模型时，不支持其中三个操作：\r\n(paddle) xxxx>paddle2onnx --model_dir D:\\vison_software\\paddle\\Paddle2ONNX-develop\\models\\ppyolov2_r50vd_dcn_mainbody_v1.0_infer\\  --save_file onnx_models/resnet50_onnx/det_model.onnx  --opset_version 11 --enable_onnx_checker True --model_filename inference.pdmodel --params_filename inference.pdiparams\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\Scripts\\paddle2onnx-script.py\", line 33, in <module>\r\n    sys.exit(load_entry_point('paddle2onnx==0.6', 'console_scripts', 'paddle2onnx')())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\command.py\", line 142, in main\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\command.py\", line 114, in program2onnx\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\convert.py\", line 77, in program2onnx\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\convert.py\", line 32, in export_onnx\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\graph\\onnx_graph.py\", line 229, in build\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\graph\\onnx_graph.py\", line 75, in __init__\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\graph\\onnx_graph.py\", line 185, in update_opset_version\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\op_mapper\\op_mapper.py\", line 119, in get_recommend_opset_version\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle2onnx-0.6-py3.7.egg\\paddle2onnx\\op_mapper\\op_mapper.py\", line 160, in check_support_status\r\nNotImplementedError:\r\nThere's 3 ops are not supported yet\r\n=========== conditional_block ===========\r\n=========== logical_not ===========\r\n=========== select_input ===========",
        "state": "closed",
        "user": "xinsuinizhuan",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-17T01:07:20+00:00",
        "updated_at": "2024-07-13T12:50:42+00:00",
        "closed_at": "2024-07-13T12:50:42+00:00",
        "comments_count": [
            "jiangjiajun",
            "xinsuinizhuan",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 305,
        "title": "ernie预训练模型，使用ernie_crf进行信息抽取，转onnx中InputSpec（）里面输出的list是什么，模型有Input_ids,seg_ids,length,我看训练的时候这三个都是tensor",
        "body": "不知道paddle支不支持这个模型转换onnx",
        "state": "closed",
        "user": "Elite-stars",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-18T08:39:41+00:00",
        "updated_at": "2024-07-15T03:54:34+00:00",
        "closed_at": "2024-07-15T03:54:26+00:00",
        "comments_count": [
            "jiangjiajun",
            "Elite-stars",
            "jiangjiajun"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 306,
        "title": "paddle支持solov2导出onnx吗",
        "body": null,
        "state": "closed",
        "user": "Timothy-105",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-19T06:53:10+00:00",
        "updated_at": "2024-07-09T07:29:56+00:00",
        "closed_at": "2024-07-09T07:29:56+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 307,
        "title": "paddle2onnx 导出ernie训练的模型进行check，出现your model ir_version is higher than the checker's错误",
        "body": null,
        "state": "closed",
        "user": "Elite-stars",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-19T08:26:25+00:00",
        "updated_at": "2024-07-15T03:47:21+00:00",
        "closed_at": "2024-07-15T03:47:21+00:00",
        "comments_count": [
            "Elite-stars"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 308,
        "title": "Paddle模型转mnn失败",
        "body": "我在PaddleDetection中下载PP-YOLO tiny模型,https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.2/configs/ppyolo/README_cn.md\r\n使用以下方式转换成onnx后,再转换成mnn\r\n`paddle2onnx --model_dir ./ppyolo_tiny_quant/ --model_filename '__model__' --params_filename '__params__' --save_file ppyolo_tiny_quant.onnx --opset_version 11\r\n./MNNConvert -f ONNX --modelFile ./ppyolo_tiny_quant.onnx --MNNModel ./ppyolo_tiny_quant.mnn --bizCode biz`\r\n在onnx转mnn时报错:\r\n`Start to Convert Other Model Format To MNN Model...\r\n\r\n[21:45:42] ~/MNN-1.1.2/tools/converter/source/onnx/onnxConverter.cpp:31: ONNX Model ir version: 7\r\n\r\nStart to Optimize the MNN Net...\r\n\r\nCheck failed: attrs != nullptr ==> \"TopKV's attr is empty\"\r\n\r\nError while converting the model! \r\n\r\nError for onnx convert`\r\n\r\n请问有碰到过这种问题吗,麻烦给点提示",
        "state": "closed",
        "user": "chunfeng9shili",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-08-19T14:06:14+00:00",
        "updated_at": "2024-07-15T03:54:16+00:00",
        "closed_at": "2024-07-15T03:53:55+00:00",
        "comments_count": [
            "jiangjiajun",
            "hellosiri"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 312,
        "title": "ctc+cnn 文字识别 paddle模型 转onnx 13个节点不支持？",
        "body": "@yeliang2258 \r\n您好 车牌识别的文字识别 ctc + cnn模型转换出现多个节点不支持\r\n\r\nThere's 13 ops are not supported yet\r\n=========== gru_unit ===========\r\n=========== less_than ===========\r\n=========== logical_not ===========\r\n=========== sequence_softmax ===========\r\n=========== grid_sampler ===========\r\n=========== write_to_array ===========\r\n=========== top_k ===========\r\n=========== while ===========\r\n=========== increment ===========\r\n=========== is_empty ===========\r\n=========== read_from_array ===========\r\n=========== sequence_pool ===========\r\n=========== lstm ===========\r\n\r\n\r\n",
        "state": "closed",
        "user": "sky186",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-08-31T07:28:09+00:00",
        "updated_at": "2025-06-25T02:59:12+00:00",
        "closed_at": "2025-06-25T02:59:12+00:00",
        "comments_count": [
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 315,
        "title": "unstack, one_hot, diag, logical_not op 不支持",
        "body": "将D-NET的三个预训练模型(Bert, ERNIE2.0, XLNET)保存的模型文件转为onnx时，都会报错缺少op，BERT和ERNIE2.0缺少unstack，XLNET缺少one_hot, diag, top_k, logical_not。\r\n\r\npaddlepaddle==2.1.2\r\npaddle2onnx==0.7\r\n\r\n> Traceback (most recent call last):\r\n  File \"/home/common/anaconda3/envs/paddle/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/command.py\", line 142, in main\r\n    enable_onnx_checker=args.enable_onnx_checker)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    enable_onnx_checker=enable_onnx_checker)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 77, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 32, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, verbose)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 229, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 183, in build_op_nodes\r\n    OpMapper.check_support_status(node_map, self.opset_version)\r\n  File \"/home/common/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 144, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 4 ops are not supported yet\r\n=========== one_hot ===========\r\n=========== diag ===========\r\n=========== top_k ===========\r\n=========== logical_not ===========\r\n\r\n\r\n",
        "state": "closed",
        "user": "ma-biao",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-05T07:33:44+00:00",
        "updated_at": "2024-05-22T04:37:50+00:00",
        "closed_at": "2024-05-22T04:37:43+00:00",
        "comments_count": [
            "yeliang2258",
            "ma-biao",
            "yeliang2258",
            "ma-biao"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 311,
        "title": "模型导出是否支持multiclass_nms3？",
        "body": null,
        "state": "closed",
        "user": "zineos",
        "closed_by": "zineos",
        "created_at": "2021-08-26T08:36:27+00:00",
        "updated_at": "2021-08-30T03:35:03+00:00",
        "closed_at": "2021-08-30T03:35:03+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 313,
        "title": "原模型和导出的ONNX模型预测结果差距大",
        "body": "将训练好的PaddleX模型（DeepLabV3P）导出为接口，并转换成ONNX：\r\n```shell\r\n> paddle2onnx --model_dir deeplabv3p_interface_model \\\r\n                         --model_filename __model__ \\\r\n                         --params_filename __params__ \\\r\n                         --save_file deeplabv3p.onnx \\\r\n                         --opset_version 11 \\\r\n                         --enable_onnx_checker True\r\n\r\nd:\\anaconda3\\envs\\paddle\\lib\\site-packages\\win32\\lib\\pywintypes.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp, sys, os\r\n2021-09-02 11:05:00 [INFO]      ONNX model genarated is valid.\r\n2021-09-02 11:05:00 [INFO]      ONNX model saved in deeplabv3p.onnx\r\n```\r\n\r\n之后使用如下代码进行测试：\r\n```python\r\nimport cv2\r\nimport onnxruntime\r\nimport numpy as np\r\nimport paddlex as pdx\r\n\r\nimg_path = 'dataset/JPEGImages/onnx_test.jpg'\r\nimg = cv2.imread(img_path)\r\nimg = img.astype('float32')\r\nprint(img.shape)\r\n\r\n# (1) paddlex model\r\npdx_model = pdx.deploy.Predictor('deeplabv3p_interface_model')\r\npdx_predict = pdx_model.predict(img)\r\nprint(np.unique(pdx_predict['label_map'], return_counts=True))\r\n\r\n# (2) onnx model\r\nimg = np.transpose(img, [2, 0, 1])\r\nimg = np.expand_dims(img, axis=0)\r\nprint(img.shape)\r\n\r\nort_sess = onnxruntime.InferenceSession('./deeplabv3p.onnx')\r\nort_outs = ort_sess.run(None, {'image': img})\r\nprint(np.unique(ort_outs[0], return_counts=True))\r\n```\r\n\r\n输出的结果如下：\r\n```\r\n(512, 512, 3)\r\n\r\nW0902 11:53:40.652613 24988 analysis_predictor.cc:1183] Deprecated. Please use CreatePredictor instead.\r\n(PreconditionNotMet) The variable named im_info is not found in the scope of the exector.\r\n  [Hint: executor_->scope()->FindVar(name) should not be null.] (at C:\\home\\workspace\\Paddle_release3\\paddle\\fluid\\inference\\api\\analysis_predictor.cc:829)\r\n\r\n(array([0, 1], dtype=uint8), array([182792,  79352], dtype=int64))\r\n(1, 3, 512, 512)\r\n(array([0, 1], dtype=int64), array([261523,    621], dtype=int64))\r\n```\r\n可以看到，原模型的预测结果和ONNX模型预测结果差异极大。",
        "state": "closed",
        "user": "ucsk",
        "closed_by": "ucsk",
        "created_at": "2021-09-02T04:02:36+00:00",
        "updated_at": "2021-09-02T06:49:36+00:00",
        "closed_at": "2021-09-02T06:49:35+00:00",
        "comments_count": [
            "ucsk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 317,
        "title": "手把手教你使用ONNXRunTime部署PP-OCR 问题",
        "body": "你好，我在执行教程的时候，成功导出onnx模型，但是在加载onnx推理的时候出现以下错误，烦请解答一下，谢谢！\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  def convert_to_list(value, n, name, dtype=np.int):\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/sparse/sputils.py:16: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\r\n  supported_dtypes = [np.typeDict[x] for x in supported_dtypes]\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/scipy/linalg/__init__.py:217: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.\r\n  from numpy.dual import register_func\r\n\r\nTraceback (most recent call last):\r\n  File \"onnx_inference/predict_system.py\", line 190, in <module>\r\n    main(utility.parse_args())\r\n  File \"onnx_inference/predict_system.py\", line 144, in main\r\n    text_sys = TextSystem(args)\r\n  File \"onnx_inference/predict_system.py\", line 41, in __init__\r\n    self.text_detector = predict_det.TextDetector(args)\r\n  File \"/home/aistudio/onnx_inference/predict_det.py\", line 99, in __init__\r\n    args, 'det', logger)  # paddle.jit.load(args.det_model_dir)\r\n  File \"/home/aistudio/onnx_inference/utility.py\", line 107, in create_predictor\r\n    sess = ort.InferenceSession(model_file_path)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/onnxruntime/capi/session.py\", line 158, in __init__\r\n    self._load_model(providers or [])\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/onnxruntime/capi/session.py\", line 177, in _load_model\r\n    self._sess.load_model(providers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: Unknown model file format version.\r\n\r\n![image](https://user-images.githubusercontent.com/27406337/132471482-45e20c0c-20d0-4047-87cf-32823254cf83.png)\r\n",
        "state": "closed",
        "user": "RyanCCC",
        "closed_by": "RyanCCC",
        "created_at": "2021-09-08T08:09:58+00:00",
        "updated_at": "2021-09-08T08:29:40+00:00",
        "closed_at": "2021-09-08T08:29:40+00:00",
        "comments_count": [
            "RyanCCC"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 319,
        "title": "paddle2onnx, sync_batch_norm不支持",
        "body": "paddle模型转onnx，报下面的错：\r\nThere's 1 ops are not supported yet\r\n=========== sync_batch_norm ===========\r\n应该怎么解决呢？",
        "state": "closed",
        "user": "rourou8023",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-09T07:21:11+00:00",
        "updated_at": "2024-05-22T03:48:00+00:00",
        "closed_at": "2024-05-22T03:48:00+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 320,
        "title": "Operator:multiclass_nms only supports input[batch_size] == 1，出现这个警告，",
        "body": "虽然转换成功，但是我在用转换后的onnx去转换openvino格式的时候报错，总是形状不匹配，请问怎么修改模型的输入为1？",
        "state": "closed",
        "user": "gyr-kdgc",
        "closed_by": "gyr-kdgc",
        "created_at": "2021-09-10T09:07:45+00:00",
        "updated_at": "2022-01-17T02:00:16+00:00",
        "closed_at": "2021-09-16T13:35:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "gyr-kdgc",
            "jiangjiajun",
            "gyr-kdgc",
            "WooXinyi",
            "jiangjiajun",
            "WooXinyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 321,
        "title": "paddle2onnx，使用onnxruntime推理，CPU和GPU结果不同",
        "body": "使用paddle2onnx，将paddle动态图模型转为onnx模型，再使用onnxruntime推理时，\r\n使用onnxruntime-cpu,推理结果和paddle模型，结果相近；\r\n但是使用同版本的onnxruntime-gpu，推理结果与paddle结果相差很远，\r\n是什么原因造成的呢？\r\ncpu:\r\nExported model has been predicted by ONNXRuntime!\r\nONNXRuntime predict time: 5.0517 s\r\nPaddle predict time: 0.8682 s\r\nThe difference of results between ONNXRuntime and Paddle looks good!\r\nrelative_diff:  1.0463244e-06\r\nmax_abs_diff:  1.1444092e-05\r\n\r\ngpu:\r\nExported model has been predicted by ONNXRuntime!\r\nONNXRuntime predict time: 1.0025 s\r\nPaddle predict time: 0.9931 s\r\nThe difference of results between ONNXRuntime and Paddle looks bad!\r\nrelative_diff:  0.29378724\r\nmax_abs_diff:  3.240285",
        "state": "closed",
        "user": "rourou8023",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-11T02:42:02+00:00",
        "updated_at": "2024-05-22T05:09:27+00:00",
        "closed_at": "2024-05-22T05:09:17+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 323,
        "title": "paddle.onnx.export return \"not_equal \"，\"fill_zeros_like\" op not support",
        "body": "When I transform the \"ernie_gen_acrostic_poetry\" model in PaddleHub to ONNX. I got the error below:\r\n\r\nNotImplementedError: \r\nThere's 2 ops are not supported yet\r\n=========== not_equal ===========\r\n=========== fill_zeros_like ===========\r\n\r\n\r\nmy script is \"paddle.onnx.export(net, 'erine', input_spec=[q_ids], opset_version=12, enable_onnx_checker=True)\"\r\n\r\nAnd I found the op:\r\nequal | 1~12 |  \r\nfill_constant | 1~12 |  \r\nfill_constant_batch_size_like | 9~12 |  \r\nfill_any_like | 9~12\r\n\r\nwere support in paddle2ONNX.\r\n\r\nhow can I go on my transform for \"ernie_gen_acrostic_poetry \"",
        "state": "closed",
        "user": "kevinfu1717",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-13T04:23:21+00:00",
        "updated_at": "2024-07-15T03:46:52+00:00",
        "closed_at": "2024-07-15T03:46:46+00:00",
        "comments_count": [
            "kevinfu1717",
            "yeliang2258",
            "kevinfu1717",
            "yeliang2258",
            "kevinfu1717"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 322,
        "title": "paddle2onnx,使用onnxruntime-gpu验证转换的onnx与paddle模型的预测结果时，显示bad",
        "body": "1）paddleseg保存的OCRnet模型，使用paddle2onnx将paddle动态图模型转换为onnx模型；\r\n2）针对同一个输入，使用onnxruntime-gpu推理onnx模型推理结果与paddle结果差别很大；\r\n3）但是使用onnxruntime-cpu推理onnx模型，与paddle的结果很相近。\r\n麻烦问下可能是什么原因导致的呢？\r\n\r\npaddlepaddle-GPU： 2.1.2\r\nCUDA: 10.1\r\ncuDNN: 7.6.5\r\nonnxruntime: 1.4.0\r\n\r\n推理结果对比：\r\ncpu:\r\nExported model has been predicted by ONNXRuntime!\r\nONNXRuntime predict time: 5.0517 s\r\nPaddle predict time: 0.8682 s\r\nThe difference of results between ONNXRuntime and Paddle looks good!\r\nrelative_diff: 1.0463244e-06\r\nmax_abs_diff: 1.1444092e-05\r\n\r\ngpu:\r\nExported model has been predicted by ONNXRuntime!\r\nONNXRuntime predict time: 1.0025 s\r\nPaddle predict time: 0.9931 s\r\nThe difference of results between ONNXRuntime and Paddle looks bad!\r\nrelative_diff: 0.29378724\r\nmax_abs_diff: 3.240285",
        "state": "closed",
        "user": "rourou8023",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-13T03:58:08+00:00",
        "updated_at": "2024-05-22T05:09:33+00:00",
        "closed_at": "2024-05-22T05:09:20+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 327,
        "title": "[issue] Unknown model file format version.",
        "body": "```\r\nonnx                              1.10.1\r\nonnxruntime                       1.8.1\r\n```\r\nI tried onnx with both 1.10.1 and 1.7.0 as mentioned in [https://github.com/PaddlePaddle/Paddle2ONNX/issues/317](https://github.com/PaddlePaddle/Paddle2ONNX/issues/317), both versions have the same problem.\r\n\r\nwith onnx 1.7.0:\r\n```python\r\n>>> import onnx\r\n>>> import onnxruntime\r\n>>> onnx_model = onnx.load(\"../yolov3obj1.onnx\")\r\n>>> onnx.checker.check_model(onnx_model)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/data-r10/kb/anaconda3/envs/paddle/lib/python3.6/site-packages/onnx/checker.py\", line 93, in check_model\r\n    C.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Your model ir_version is higher than the checker's.\r\n>>> ort_session = onnxruntime.InferenceSession(\"../yolov3obj1.onnx\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/data-r10/kb/anaconda3/envs/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 283, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/data-r10/kb/anaconda3/envs/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 310, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from ../yolov3obj1.onnx failed:/onnxruntime_src/onnxruntime/core/graph/model.cc:111 onnxruntime::Model::Model(onnx::ModelProto&&, const PathString&, const IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&) Unknown model file format version.\r\n```\r\n\r\nwith onnx 1.10.1\r\n```python\r\n>>> import onnx\r\n>>> import onnxruntime\r\n>>> onnx_model = onnx.load(\"../yolov3obj1.onnx\")\r\n>>> onnx.checker.check_model(onnx_model)\r\n>>> ort_session = onnxruntime.InferenceSession(\"../yolov3obj1.onnx\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/data-r10/kb/anaconda3/envs/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 283, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/data-r10/kb/anaconda3/envs/paddle/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 310, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from ../yolov3obj1.onnx failed:/onnxruntime_src/onnxruntime/core/graph/model.cc:111 onnxruntime::Model::Model(onnx::ModelProto&&, const PathString&, const IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&) Unknown model file format version.\r\n```\r\n\r\nI used the command below to convert onnx model.\r\n```\r\npaddle2onnx --model_dir inference_model/yolov3_darknet53_270e_obj1_coco/ --model_filename model.pdmodel             --params_filename model.pdiparams             --opset_version 11             --save_file yolov3obj1.onnx\r\n```",
        "state": "closed",
        "user": "kaixin-bai",
        "closed_by": "kaixin-bai",
        "created_at": "2021-09-14T07:56:57+00:00",
        "updated_at": "2021-09-15T13:01:50+00:00",
        "closed_at": "2021-09-15T13:01:49+00:00",
        "comments_count": [
            "Goghzki",
            "jiangjiajun",
            "Goghzki",
            "yeliang2258",
            "Goghzki",
            "yeliang2258",
            "kaixin-bai",
            "yeliang2258",
            "kaixin-bai",
            "yeliang2258",
            "kaixin-bai"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 329,
        "title": "Paddle检测模型转ONNX，onnxruntime时报错",
        "body": "paddle2onnx --model_dir ./model/ --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./model/det_large.onnx --opset_version 10 --enable_onnx_checker True\r\n\r\n转为onnx没有报错\r\n2021-09-16 15:52:58 [INFO]\tONNX model generated is valid.\r\n2021-09-16 15:52:58 [INFO]\tONNX model saved in ./model/det_large.onnx\r\n\r\nonnx.load 成功，在这步时报错\r\nsess = ort.InferenceSession(onnx_model.SerializeToString())\r\n\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /Users/runner/work/1/s/onnxruntime/core/graph/model.cc:111 onnxruntime::Model::Model(onnx::ModelProto &&, const onnxruntime::PathString &, const onnxruntime::IOnnxRuntimeOpSchemaRegistryList *, const logging::Logger &) Unknown model file format version.\r\npython-BaseException\r\n\r\n\r\n### =======问题已解决 Problem solved======\r\n原因： onnxruntime目前不支持高版本的onnx，导致加载出错\r\n解决方案： 降低环境中onnx的版本至1.6.0~1.9.0 ，重新导出ONNX模型即可\r\n\r\nWhy: Currently, onnx>=1.10.0 is not supported by onnxruntime<=1.9.0\r\nHow to solve: downgrade `onnx` to 1.6.0~1.9.0, and convert paddle model to onnx again.\r\n\r\n```\r\npip install onnx==1.7.0\r\n``` ",
        "state": "closed",
        "user": "maximli",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-16T08:26:05+00:00",
        "updated_at": "2024-12-16T08:41:00+00:00",
        "closed_at": "2024-05-22T05:09:54+00:00",
        "comments_count": [
            "yeliang2258",
            "maximli",
            "jiangjiajun",
            "maximli",
            "maximli",
            "jindameias",
            "yeliang2258",
            "jindameias",
            "Wangyongdi",
            "jiangjiajun",
            "Wangyongdi",
            "lix19937"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 331,
        "title": "转换ch_PP-OCRv2_rec_infer模型后，模型运行耗时出现较大增长",
        "body": "转换ch_ppocr_mobile_v2.0_det_infer模型为onnx之后，使用python+onnxRuntime+cpu的时候耗时未出现较大波动。\r\n转换ppOCR最近推出的ch_PP-OCRv2_rec_infer模型为onnx之后，python+onnxRuntime+cpu的时候耗时出现翻倍情况。\r\n该模型在paddle上面是相对之前模型更快的，因为两个模型的网络结构改变了，想请教下是Paddle2ONNX或者onnxRuntime对某些新的节点操作并行化优化不太好吗？",
        "state": "closed",
        "user": "Gmgge",
        "closed_by": "Gmgge",
        "created_at": "2021-09-17T02:39:23+00:00",
        "updated_at": "2021-09-18T00:46:58+00:00",
        "closed_at": "2021-09-18T00:44:19+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 332,
        "title": "fomm model",
        "body": "NotImplementedError: \r\nThere's 7 ops are not supported yet\r\n=========== grid_sampler ===========\r\n=========== conditional_block ===========\r\n=========== logical_not ===========\r\n=========== logical_or ===========\r\n=========== inverse ===========\r\n=========== reduce_any ===========\r\n=========== select_input ===========\r\n\r\nI want to convert the fomm(first order model on mobile net) paddle model to ONNX",
        "state": "closed",
        "user": "shiyuleixia",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-09-17T03:11:28+00:00",
        "updated_at": "2025-06-23T03:08:49+00:00",
        "closed_at": "2025-06-23T03:08:49+00:00",
        "comments_count": [
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 333,
        "title": "将BERT转成ONNX是报错，There's 3 ops are not supported yet。",
        "body": "详细错误如下：\r\nNotImplementedError: \r\nThere's 3 ops are not supported yet\r\n=========== select_input ===========\r\n=========== logical_not ===========\r\n=========== conditional_block ===========\r\n\r\n采用paddlenlp的BERTModel模型，只是在模型内部增加了求解loss和if判断，导致导出onnx报错",
        "state": "closed",
        "user": "liucongg",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-17T06:11:33+00:00",
        "updated_at": "2024-07-13T12:50:12+00:00",
        "closed_at": "2024-07-13T12:50:12+00:00",
        "comments_count": [
            "liucongg",
            "yeliang2258",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 334,
        "title": "PaddleOCR转ONNX问题",
        "body": "请问如何将https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_infer.tar转换成ONNX模型？\r\n\r\n之前也有issue：https://github.com/PaddlePaddle/Paddle2ONNX/issues/248提到，能否给出具体步骤？小白表示看不懂，谢谢！",
        "state": "closed",
        "user": "RyanCCC",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-09-17T09:02:10+00:00",
        "updated_at": "2025-06-23T03:08:48+00:00",
        "closed_at": "2025-06-23T03:08:48+00:00",
        "comments_count": [
            "yeliang2258",
            "RyanCCC",
            "yeliang2258",
            "RyanCCC",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 336,
        "title": "3 ops are not supported",
        "body": "1. I got parameter file from link of PaddleDetection/configs/yolov3/README.md, as follows:\r\nhttps://paddledet.bj.bcebos.com/models/yolov3_mobilenet_v1_270e_voc.pdparams.\r\n2. then I exported models as described in PaddleDetection/deploy/EXPORT_MODEL.md, as follow instruction: \r\npython tools/export_model.py -c configs/yolov3/yolov3_mobilenet_v1_270e_voc.yml --output_dir=./inference_model // -o eights=weights/yolov3_mobilenet_v1_270e_voc.pdparams\r\nre: I put the yolov3_mobilenet_v1_270e_voc.pdparams in output/yolov3_mobilenet_v1_270e_voc/ directory and renamed the file as model_final.params.\r\n 3. Now exported four files are : infer_cfg.yml, model.pdiparams, model.pdiparams.info, and model.pdmodel in the inference_model/yolov3_mobilenet_v1_270e_voc/ directory.\r\n 4.  then I run : paddle2onnx --model_dir ./inference_mode/yolov3_mobilenet_v1_270e_voc/ --model_filename model.pdmodel --params_filename model.pdiparams --save_file detonnx/model.onnx --opset_version 11\r\n 5. I got the NotImplementedError tips as : \r\n        There's 3 ops are not supported yet\r\n        =============conditional_block=============\r\n       =============logical_not==================\r\n      =============select_input==================\r\nWhat can I do to solve the problem?  \r\n \r\n",
        "state": "closed",
        "user": "wenbbo",
        "closed_by": "jiangjiajun",
        "created_at": "2021-09-20T16:28:03+00:00",
        "updated_at": "2024-07-13T12:37:11+00:00",
        "closed_at": "2021-09-21T08:23:37+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun",
            "wenbbo",
            "jiangjiajun",
            "wenbbo",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 341,
        "title": "paddle2onnx2openvino遇到错误",
        "body": "在转到onnx之后遇到如下错误\r\n![image](https://user-images.githubusercontent.com/48303408/134451341-a2a9c6e9-f775-4f0d-942e-e7ee70ee0655.png)\r\n转onnx用的命令为\r\n![image](https://user-images.githubusercontent.com/48303408/134451386-1508477d-639e-41b8-90be-71e81b440510.png)\r\n",
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Dandelion111",
        "created_at": "2021-09-23T03:38:25+00:00",
        "updated_at": "2022-05-25T06:56:31+00:00",
        "closed_at": "2022-05-25T06:56:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 338,
        "title": "ppocr crnn paddle模型转onnx输入格式怎么设置？",
        "body": "![image](https://user-images.githubusercontent.com/48303408/134334760-089ba1d0-7de8-46c6-87a9-07c8c3427ea3.png)\r\n请问识别模型ppocr中， crnn paddle模型转onnx输入格式怎么设置？",
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Dandelion111",
        "created_at": "2021-09-22T11:21:29+00:00",
        "updated_at": "2022-05-25T06:56:00+00:00",
        "closed_at": "2022-05-25T06:56:00+00:00",
        "comments_count": [
            "yeliang2258",
            "neverstoplearn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 340,
        "title": "请问支持ppocr的openvino转换吗？",
        "body": "请问支持ppocr的openvino转换吗？ 转换为openvino是不是需要先转换为onnx，再转换为openvino",
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Dandelion111",
        "created_at": "2021-09-23T03:20:00+00:00",
        "updated_at": "2022-05-25T06:56:40+00:00",
        "closed_at": "2022-05-25T06:56:40+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 337,
        "title": "请问动态图和静态图分别代表啥意思",
        "body": "请问动态图和静态图分别代表啥意思",
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Dandelion111",
        "created_at": "2021-09-22T08:40:35+00:00",
        "updated_at": "2022-05-25T06:55:45+00:00",
        "closed_at": "2022-05-25T06:55:45+00:00",
        "comments_count": [
            "jiangjiajun",
            "Dandelion111"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 339,
        "title": "请问有没有ppocr动态图转为onnx的例子",
        "body": null,
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Dandelion111",
        "created_at": "2021-09-23T01:26:07+00:00",
        "updated_at": "2022-05-25T06:56:57+00:00",
        "closed_at": "2022-05-25T06:56:57+00:00",
        "comments_count": [
            "jiangjiajun",
            "Dandelion111",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 342,
        "title": "【PaddlePaddle Hackathon】62、在Paddle2ONNX 新增11个 Paddle 2.0 API 支持",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：Paddle2ONNX 新增11个 Paddle 2.0 API 支持\r\n\r\n- 技术标签：深度学习框架，模型转换，ONNX\r\n\r\n- 任务难度：中等\r\n\r\n- 详细描述：Paddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加11个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n  11个 API 具体为：\r\n\r\n  paddle.nn.functional.interpolate(x, size=None, scale_factor=None, mode='nearest', align_corners=False, align_mode=0, data_format='NCHW', name=None) \r\n\r\n  paddle.nn.functional.softshrink(x, threshold=0.5, name=None) \r\n\r\n  paddle.tan(x, name=None) \r\n\r\n  paddle.nn.Tanhshrink(name=None) \r\n\r\n  paddle.nn.functional.thresholded_relu(x, threshold=1.0, name=None) \r\n\r\n  paddle.unique(x, return_index=False, return_inverse=False, return_counts=False, axis=None, dtype='int64', name=None) \r\n\r\n  paddle.where(condition, x, y, name=None) \r\n\r\n  paddle.scatter(x, index, updates, overwrite=True, name=None) \r\n\r\n  paddle.scatter_nd_add(x, index, updates, name=None) \r\n\r\n  paddle.meshgrid(*args, **kargs) \r\n\r\n  paddle.masked_select(x, mask, name=None) \r\n\r\n【提交内容】\r\n\r\n- 任务 PR到 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)\r\n\r\n- 相关技术文档\r\n\r\n- 任务单测文件\r\n\r\n【技术要求】\r\n\r\n- 了解飞桨框架使用\r\n\r\n- 了解ONNX",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T08:46:11+00:00",
        "updated_at": "2024-05-22T05:08:24+00:00",
        "closed_at": "2024-05-22T05:08:24+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 344,
        "title": "【PaddlePaddle Hackathon】60、在Paddle2ONNX 新增11个 Paddle 2.0 API 支持",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：Paddle2ONNX 新增11个 Paddle 2.0 API 支持\r\n\r\n- 技术标签：深度学习框架，模型转换，ONNX\r\n\r\n- 任务难度：简单\r\n\r\n- 详细描述：Paddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加10个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n  11个 API 具体为：\r\n\r\n  paddle.log10(x, name=None) \r\n\r\n  paddle.log1p(x, name=None) \r\n\r\n  paddle.logical_xor(x, y, out=None, name=None) \r\n\r\n  paddle.nn.LogSigmoid(name=None) \r\n\r\n  paddle.all(x, axis=None, keepdim=False, name=None) \r\n\r\n  paddle.any(x, axis=None, keepdim=False, name=None) \r\n\r\n  paddle.round(x, name=None) \r\n\r\n  paddle.rsqrt(x, name=None) \r\n\r\n  paddle.nn.functional.selu(x, scale=1.0507, alpha=1.67326, name=None) \r\n\r\n  paddle.sign(x, name=None) \r\n\r\n  paddle.sin(x, name=None) \r\n\r\n【提交内容】\r\n\r\n- 任务 PR到 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)\r\n\r\n- 相关技术文档\r\n\r\n- 任务单测文件\r\n\r\n【技术要求】\r\n\r\n- 了解飞桨框架使用\r\n\r\n- 了解ONNX",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T08:46:54+00:00",
        "updated_at": "2024-05-22T05:08:32+00:00",
        "closed_at": "2024-05-22T05:08:32+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 346,
        "title": "【PaddlePaddle Hackathon】58、在Paddle2ONNX 新增10个 Paddle 2.0 API 支持",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：Paddle2ONNX 新增10个 Paddle 2.0 API 支持\r\n\r\n- 技术标签：深度学习框架，模型转换，ONNX\r\n\r\n- 任务难度：简单\r\n\r\n- 详细描述：Paddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加10个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n  10个 API 具体为：\r\n\r\n  paddle.acos(x, name=None)\r\n\r\n  paddle.argmin(x, axis=None, keepdim=False, dtype='int64', name=None) \r\n\r\n  paddle.asin(x, name=None) \r\n\r\n  paddle.atan(x, name=None)\r\n\r\n  paddle.ceil(x, name=None) \r\n\r\n  paddle.cos(x, name=None)\r\n\r\n  paddle.cosh(x, name=None) \r\n\r\n  paddle.nn.ELU(alpha=1.0, name=None) \r\n\r\n  paddle.nn.Hardshrink(threshold=0.5, name=None) \r\n\r\n  paddle.isfinite(x, name=None)\r\n\r\n【提交内容】\r\n\r\n- 任务 PR到 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)\r\n\r\n- 相关技术文档\r\n\r\n- 任务单测文件\r\n\r\n【技术要求】\r\n\r\n- 了解飞桨框架使用\r\n\r\n- 了解ONNX",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T08:50:02+00:00",
        "updated_at": "2024-05-22T05:08:37+00:00",
        "closed_at": "2024-05-22T05:08:37+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 343,
        "title": "【PaddlePaddle Hackathon】61、在Paddle2ONNX 新增11个 Paddle 2.0 API 支持",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：Paddle2ONNX 新增11个 Paddle 2.0 API 支持\r\n\r\n- 技术标签：深度学习框架，模型转换，ONNX\r\n\r\n- 任务难度：中等\r\n\r\n- 详细描述：Paddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加10个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n  11个 API 具体为：\r\n\r\n  paddle.argsort(x, axis=- 1, descending=False, name=None) \r\n\r\n  paddle.nn.functional.hardtanh(x, min=-1.0, max=1.0, name=None) \r\n\r\n  paddle.dist(x, y, p=2) \r\n\r\n  paddle.dot(x, y, name=None) \r\n\r\n  paddle.index_select(x, index, axis=0, name=None) \r\n\r\n  paddle.nn.functional.log_softmax(x, axis=- 1, dtype=None, name=None) \r\n\r\n  paddle.mv(x, vec, name=None) \r\n\r\n  paddle.nn.Pad1D(padding, mode='constant', value=0.0, data_format='NCL', name=None) \r\n\r\n  paddle.sinh(x, name=None) \r\n\r\n  paddle.numel(x) \r\n\r\n  paddle.nn.functional.softsign(x, name=None) \r\n\r\n【提交内容】\r\n\r\n- 任务 PR到 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)\r\n\r\n- 相关技术文档\r\n\r\n- 任务单测文件\r\n\r\n【技术要求】\r\n\r\n- 了解飞桨框架使用\r\n\r\n- 了解ONNX",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T08:46:35+00:00",
        "updated_at": "2024-05-22T05:08:29+00:00",
        "closed_at": "2024-05-22T05:08:29+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 345,
        "title": "【PaddlePaddle Hackathon】59、在Paddle2ONNX 新增11个 Paddle 2.0 API 支持",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：Paddle2ONNX 新增11个 Paddle 2.0 API 支持\r\n\r\n- 技术标签：深度学习框架，模型转换，ONNX\r\n\r\n- 任务难度：简单\r\n\r\n- 详细描述：Paddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加10个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n  11个 API 具体为：\r\n\r\n  paddle.erf(x, name=None) \r\n\r\n  paddle.floor_mod(x, y, name=None) \r\n\r\n  paddle.floor(x, name=None) \r\n\r\n  paddle.isinf(x, name=None) \r\n\r\n  paddle.fluid.layers.has_nan(x) \r\n\r\n  paddle.isnan(x, name=None) \r\n\r\n  paddle.less_than(x, y, name=None) \r\n\r\n  paddle.log2(x, name=None) \r\n\r\n  paddle.logical_not(x, out=None, name=None) \r\n\r\n  paddle.logical_or(x, y, out=None, name=None) \r\n\r\n  paddle.logsumexp(x, axis=None, keepdim=False, name=None) \r\n\r\n【提交内容】\r\n\r\n- 任务 PR到 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)\r\n\r\n- 相关技术文档\r\n\r\n- 任务单测文件\r\n\r\n【技术要求】\r\n\r\n- 了解飞桨框架使用\r\n\r\n- 了解ONNX\r\n\r\n#### ",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T08:48:49+00:00",
        "updated_at": "2024-05-22T05:08:51+00:00",
        "closed_at": "2024-05-22T05:08:51+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 347,
        "title": "【PaddlePaddle Hackathon】Paddle2ONNX 任务合集",
        "body": "# 【PaddlePaddle Hackathon】Paddle2ONNX 任务合集\r\n\r\nhi，大家好，非常高兴的告诉大家，首届 PaddlePaddle Hackathon 开始啦。PaddlePaddle Hackathon 是面向全球开发者的深度学习领域编程活动，鼓励开发者了解与参与 PaddlePaddle。本次共有四大方向（PaddlePaddle、Paddle Family、Paddle Friends、Paddle Anything）四大方向，共计100个任务共大家完成。详细信息可以参考 [PaddlePaddle Hackathon 说明](https://www.paddlepaddle.org.cn/contributionguide?docPath=hackathon_cn)。大家是否已经迫不及待了呢~\r\n\r\n本 ISSUE 是 Paddle Family 专区 Paddle2ONNX 方向任务合集。具体任务列表如下：\r\n\r\n| 序号 | 难度 | 任务 ISSUE                                                    |\r\n| ---- | ---- | :-----------------------------------------------------: |\r\n| 58 | ⭐️  | [在Paddle2ONNX 新增10个 Paddle 2.0 API 支持](https://github.com/PaddlePaddle/Paddle2ONNX/issues/346)           |                    |          |\r\n| 59 | ⭐️  | [在Paddle2ONNX 新增11个 Paddle 2.0 API 支持](https://github.com/PaddlePaddle/Paddle2ONNX/issues/345)           |                    |          |\r\n| 60 | ⭐️  | [在Paddle2ONNX 新增11个 Paddle 2.0 API 支持](https://github.com/PaddlePaddle/Paddle2ONNX/issues/344)           |                    |          |\r\n| 61 | ⭐️⭐️   | [在Paddle2ONNX 新增11个 Paddle 2.0 API 支持](https://github.com/PaddlePaddle/Paddle2ONNX/issues/343)           |                    |          |\r\n| 62 | ⭐️⭐️   | [在Paddle2ONNX 新增11个 Paddle 2.0 API 支持](https://github.com/PaddlePaddle/Paddle2ONNX/issues/342)           |                    |          |\r\n\r\n若想要认领本次活动任务，请至 [PaddlePaddle Hackathon Pinned ISSUE](https://github.com/PaddlePaddle/Paddle/issues/35940) 完成任务 ISSUE 认领。\r\n\r\n活动官网：[PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon?fr=paddle2onnxg)",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-23T09:49:08+00:00",
        "updated_at": "2024-05-22T05:08:41+00:00",
        "closed_at": "2024-05-22T05:08:41+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 352,
        "title": "Paddle2ONNX export model failed while using 'register_buffer`",
        "body": "This example code can use `paddle.jit.save` successfully, while `export_to_onnx` failed\r\n\r\n```\r\nimport paddle\r\nimport onnx\r\n\r\n\r\nclass MyLayer(paddle.nn.Layer):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.register_buffer(\r\n            \"my_buffer\",\r\n            paddle.to_tensor(42, dtype='float32'),\r\n            persistable=True  # <- look here\r\n        )\r\n        # self.my_buffer.persistable = True # This line has changed\r\n\r\n    def forward(self, x):\r\n        return x + self.my_buffer\r\n\r\n    def export_to_onnx(self):\r\n        spec = paddle.static.InputSpec([1])\r\n        paddle.onnx.export(self, \"/tmp/my-model\", [spec])\r\n        onnx.checker.check_model('/tmp/my-model.onnx')\r\n\r\n\r\ndef main():\r\n    my_layer = MyLayer()\r\n    print(f\"persistable: {my_layer.my_buffer.persistable}\")\r\n\r\n    x = paddle.to_tensor(1, dtype='float32')\r\n    y = my_layer(x)\r\n    print(y)\r\n\r\n    my_layer.export_to_onnx()\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-24T09:52:48+00:00",
        "updated_at": "2024-11-19T08:18:25+00:00",
        "closed_at": "2024-11-19T08:18:25+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 353,
        "title": "paddle2onnx -> Paddle-Video下的pp-TSM模型中There's 1 ops are not supported yet",
        "body": "Traceback (most recent call last):\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/bin/paddle2onnx\", line 8, in\r\nsys.exit(main())\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/command.py\", line 155, in main\r\noperator_export_type=operator_export_type)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/command.py\", line 122, in program2onnx\r\noperator_export_type=operator_export_type)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 79, in program2onnx\r\nexport_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker, operator_export_type)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 33, in export_onnx\r\nonnx_graph = ONNXGraph.build(paddle_graph, opset_version, operator_export_type, verbose)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\nonnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in init\r\nself.update_opset_version()\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\nself.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 127, in get_recommend_opset_version\r\nrecommend_opset_version = OpMapper.check_support_status(node_map, opset_version, True)\r\nFile \"/home/wangnan/anaconda3/envs/action-py3.7/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 168, in check_support_status\r\nraise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 1 ops are not supported yet\r\n=========== temporal_shift ===========\r\n\r\ntemporal_shift不支持。\r\n想请教下，怎么改才能让他支持，debug看了下temporal_shift函数，一直都是一些注册器，具体内容看的眼花缭乱！求救！help!",
        "state": "closed",
        "user": "754467737",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-09-26T02:34:57+00:00",
        "updated_at": "2025-06-23T03:08:46+00:00",
        "closed_at": "2025-06-23T03:08:46+00:00",
        "comments_count": [
            "yeliang2258",
            "754467737",
            "dengfenglai321",
            "dengfenglai321",
            "754467737",
            "754467737",
            "dengfenglai321",
            "754467737",
            "754467737",
            "754467737",
            "jiangjiajun",
            "aureosun",
            "jiangjiajun",
            "754467737",
            "754467737",
            "aureosun",
            "754467737",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 350,
        "title": "AIStudio项目如何下载？",
        "body": "![image](https://user-images.githubusercontent.com/48303408/134641859-3d5451fc-e2a6-48e5-85d9-657a51069978.png)\r\n请问AIStudio这样的项目如何下载？",
        "state": "closed",
        "user": "Dandelion111",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-24T08:17:37+00:00",
        "updated_at": "2024-06-05T06:12:33+00:00",
        "closed_at": "2024-06-05T06:12:33+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 354,
        "title": "请问现在paddle2onnx支持fastscnn了吗？转出的时候报如下错误",
        "body": "Exception: Error happened when mapping node ['pool2d_2'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['tmp_5']} and outputs: {'Out': ['pool2d_2.tmp_0']}, specific error: Cannot convert adaptive pool with input_size: (1, 128, 8, 8), output_size: (1, 128, 3, 3)",
        "state": "closed",
        "user": "chen0928622",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-09-26T03:22:51+00:00",
        "updated_at": "2025-06-20T02:56:34+00:00",
        "closed_at": "2025-06-20T02:56:34+00:00",
        "comments_count": [
            "jiangjiajun",
            "chen0928622",
            "jiangjiajun",
            "pcb9382",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 359,
        "title": "[bug]paddle2onnx.dygraph2onnx下有bug，非作者原意",
        "body": "![onnx_im_bug](https://user-images.githubusercontent.com/40812718/135263990-f4d306eb-6b26-43ea-bab2-abe2cb998ee6.png)\r\nfor循环应该减少缩进一个tab",
        "state": "closed",
        "user": "bingo789",
        "closed_by": "yeliang2258",
        "created_at": "2021-09-29T11:59:24+00:00",
        "updated_at": "2021-10-11T08:51:54+00:00",
        "closed_at": "2021-10-11T08:51:54+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 361,
        "title": "op不支持",
        "body": "[inference.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/7258385/inference.zip)\r\nThere's 3 ops are not supported yet\r\n=========== fc ===========\r\n=========== ctc_align ===========\r\n=========== lstm ===========\r\n\r\n大佬们可以帮忙处理下吗？模型在附件",
        "state": "open",
        "user": "zylo117",
        "closed_by": null,
        "created_at": "2021-09-30T09:27:19+00:00",
        "updated_at": "2025-07-06T03:08:43+00:00",
        "closed_at": null,
        "comments_count": [
            "jiangjiajun",
            "zylo117",
            "zylo117",
            "jiangjiajun",
            "zylo117",
            "jiangjiajun",
            "Danvae",
            "github-actions[bot]",
            "Smilty-z",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 360,
        "title": "支持pdiparams/pdmodel转成onnx模型吗",
        "body": "预训练下已有inference.pdiparams、inference.pdiparams.info、inference.pdmodel，是否可以根据这几个文件直接导出到onnx模型？",
        "state": "closed",
        "user": "bingo789",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-09-29T12:03:12+00:00",
        "updated_at": "2024-07-15T04:20:23+00:00",
        "closed_at": "2024-07-15T04:20:23+00:00",
        "comments_count": [
            "jiangjiajun",
            "Hunter-P",
            "yeliang2258",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 380,
        "title": "Paddle2onnx  按照官方文档转模型报错",
        "body": "import paddle\r\nfrom paddle import nn\r\nfrom paddle.static import InputSpec\r\nimport paddle2onnx as p2o\r\n\r\n\r\nclass LinearNet(nn.Layer):\r\n    def __init__(self):\r\n        super(LinearNet, self).__init__()\r\n        self._linear = nn.Linear(784, 10)\r\n\r\n    def forward(self, x):\r\n        return self._linear(x)\r\n# export to ONNX\r\nlayer = LinearNet()\r\nsave_path = './linear_net'\r\nx_spec = InputSpec([None, 784], 'float32', 'x')\r\nlayer.eval()\r\npaddle.onnx.export(layer, save_path, input_spec=[x_spec])\r\n\r\n\r\n\r\n报错：\r\n       File \"/home/xushoukai/anaconda3/envs/baidu/lib/python3.6/site-packages/paddle2onnx-0.8.1-py3.6.egg/paddle2onnx/constant/dtypes.py\", line 17, in <module>\r\n  File \"/home/xushoukai/paddle_test/onnx.py\", line 84, in <module>\r\n    paddle.onnx.export(layer, save_path, input_spec=[x_spec])\r\n  File \"/home/xushoukai/anaconda3/envs/baidu/lib/python3.6/site-packages/paddle/onnx/export.py\", line 100, in export\r\n    p2o.dygraph2onnx(\r\nAttributeError: module 'paddle2onnx' has no attribute 'dygraph2onnx'",
        "state": "closed",
        "user": "SkipAngel",
        "closed_by": "SkipAngel",
        "created_at": "2021-10-18T08:57:48+00:00",
        "updated_at": "2021-10-18T09:17:13+00:00",
        "closed_at": "2021-10-18T09:17:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 375,
        "title": "s2anet 转onnx",
        "body": null,
        "state": "closed",
        "user": "Unknown-parameters",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-10-12T09:40:29+00:00",
        "updated_at": "2025-06-17T02:57:28+00:00",
        "closed_at": "2025-06-17T02:57:28+00:00",
        "comments_count": [
            "Unknown-parameters",
            "jiangjiajun",
            "Unknown-parameters",
            "jiangjiajun",
            "DanyangYue",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 364,
        "title": "Converting SRN model from PaddleOCR to ONNX",
        "body": "Hi!\r\nThanks for this great repo :)  \r\n\r\nI trained SRN model for text recognition from PaddleOCR framework on my own dataset and tranflated to the inference format   \r\nThen I tried to convert SRN inference model to the ONNX  \r\n\r\nI used following command:  \r\n```\r\npaddle2onnx --model_dir D:\\Repositories\\PaddleOCR\\output\\rec\\srn\\inference_model  --model_filename D:\\Repositories\\PaddleOCR\\output\\rec\\srn\\inference_model\\inference.pdmodel --params_filename D:\\Repositories\\PaddleOCR\\output\\rec\\srn\\inference_model\\inference.pdiparams --save_file C:\\Users\\Reutov\\Desktop\\SRN_iso_containers.onnx --opset_version 11 --enable_onnx_checker True  \r\n``` \r\n \r\nThen when I try to make inference ONNX model via onnxruntime, I get following error:  \r\n```\r\nTraceback (most recent call last):\r\n  File \".\\paddle_ocr_onnx_test.py\", line 33, in <module>\r\n    outputs = session.run(None, {input_name: number_image})\r\n  File \"C:\\Users\\Reutov\\anaconda3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 184, in run\r\n    raise ValueError(\"Model requires {} inputs. Input Feed contains {}\".format(num_required_inputs, num_inputs))\r\nValueError: Model requires 5 inputs. Input Feed contains 1\r\n```  \r\n\r\nI checked ONNX graph of SRN model by using Netron:  \r\n![image](https://user-images.githubusercontent.com/57865736/136360725-cf272382-dd28-4b76-b08c-cef5e3382fad.png)  \r\n\r\nIt can be seen that the model has 5 inputs, one of which is responsible for the input image tensor (x), and the purpose of all the others is still unknown to me\r\n \r\nPlease tell me what should I do to execute the correct SRN model inference via onnxruntime\r\nThanks in advance for reply)",
        "state": "closed",
        "user": "susanin1970",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-10-07T09:47:55+00:00",
        "updated_at": "2024-07-15T04:20:01+00:00",
        "closed_at": "2024-07-15T04:20:01+00:00",
        "comments_count": [
            "yeliang2258",
            "susanin1970",
            "yeliang2258",
            "yeliang2258",
            "susanin1970",
            "susanin1970",
            "yeliang2258",
            "susanin1970",
            "yeliang2258",
            "divya1211",
            "susanin1970",
            "Ehteshamciitwah",
            "jiangjiajun",
            "susanin1970",
            "susanin1970",
            "Ehteshamciitwah",
            "susanin1970",
            "susanin1970",
            "Ehteshamciitwah",
            "susanin1970",
            "Ehteshamciitwah",
            "susanin1970",
            "Ehteshamciitwah",
            "susanin1970",
            "susanin1970",
            "flipson",
            "susanin1970",
            "duong0411",
            "susanin1970",
            "duong0411",
            "duong0411",
            "susanin1970",
            "susanin1970",
            "duong0411",
            "susanin1970",
            "duong0411",
            "duong0411",
            "susanin1970"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 376,
        "title": "ch_PP-OCRv2_rec_slim转onnx失败",
        "body": "使用官方的ch_PP-OCRv2_rec_slim转onnx模型失败，编译命令如下：\r\npaddle2onnx -m ./inference_model/paddlev2_slim/rec_crnn/ --model_file\r\nname inference.pdmodel --params_filename inference.pdiparams -s ./inference_model/onnx_slim/rec_crnn/model.onnx\r\n --opset_version 11 --enable_onnx_checker True\r\n错误如下：\r\nNotImplementedError:\r\nThere's 2 ops are not supported yet\r\n=========== fake_quantize_dequantize_moving_average_abs_max ===========\r\n=========== fake_channel_wise_quantize_dequantize_abs_max ===========\r\n谢谢！",
        "state": "closed",
        "user": "Gitlixiangdong",
        "closed_by": "Gitlixiangdong",
        "created_at": "2021-10-14T01:33:42+00:00",
        "updated_at": "2021-11-25T06:21:35+00:00",
        "closed_at": "2021-10-25T07:08:39+00:00",
        "comments_count": [
            "yeliang2258",
            "Gitlixiangdong",
            "yeliang2258",
            "Gitlixiangdong",
            "yeliang2258",
            "Gitlixiangdong",
            "yeliang2258",
            "jiangjiajun",
            "Gitlixiangdong",
            "Gitlixiangdong",
            "yeliang2258",
            "jiangjiajun"
        ],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 382,
        "title": "Still lack of unit tests for detection operators",
        "body": "e.g `multiclass_nms3`, `yolo_box`",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-10-19T09:35:34+00:00",
        "updated_at": "2024-07-15T03:46:30+00:00",
        "closed_at": "2024-07-15T03:46:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 381,
        "title": "Paddle2onnx 按照官方文档转模型报错",
        "body": "import paddle\r\nfrom paddle import nn\r\nfrom paddle.static import InputSpec\r\nimport paddle2onnx as p2o\r\n\r\nclass LinearNet(nn.Layer):\r\ndef init(self):\r\nsuper(LinearNet, self).init()\r\nself._linear = nn.Linear(784, 10)\r\n\r\ndef forward(self, x):\r\n    return self._linear(x)\r\nexport to ONNX\r\nlayer = LinearNet()\r\nsave_path = './linear_net'\r\nx_spec = InputSpec([None, 784], 'float32', 'x')\r\nlayer.eval()\r\npaddle.onnx.export(layer, save_path, input_spec=[x_spec])\r\n\r\n报错：\r\nFile \"/home/xushoukai/anaconda3/envs/baidu/lib/python3.6/site-packages/paddle2onnx-0.8.1-py3.6.egg/paddle2onnx/constant/dtypes.py\", line 17, in\r\nFile \"/home/xushoukai/paddle_test/onnx.py\", line 84, in\r\npaddle.onnx.export(layer, save_path, input_spec=[x_spec])\r\nFile \"/home/xushoukai/anaconda3/envs/baidu/lib/python3.6/site-packages/paddle/onnx/export.py\", line 100, in export\r\np2o.dygraph2onnx(\r\nAttributeError: module 'paddle2onnx' has no attribute 'dygraph2onnx'",
        "state": "closed",
        "user": "SkipAngel",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-10-18T09:16:31+00:00",
        "updated_at": "2024-06-04T07:05:48+00:00",
        "closed_at": "2024-06-04T07:05:48+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 387,
        "title": "如何更改ONNX模型输出的名字？",
        "body": "您好，请问paddle2ONNX可以自己定义输出节点的名字么，如果不能，该如何修改？",
        "state": "closed",
        "user": "lucky-xu-1994",
        "closed_by": "lucky-xu-1994",
        "created_at": "2021-11-03T07:03:11+00:00",
        "updated_at": "2022-06-10T01:55:16+00:00",
        "closed_at": "2021-11-20T01:16:34+00:00",
        "comments_count": [
            "jiangjiajun",
            "lucky-xu-1994",
            "jiangjiajun",
            "WooXinyi",
            "lucky-xu-1994",
            "wuyx517",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 384,
        "title": "Feature Requests",
        "body": "## Quantization Model Support\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/364\r\n\r\n## More test case\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/382\r\n\r\n### OCR\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/391 【最新的PR已解决】",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-10-25T07:08:26+00:00",
        "updated_at": "2024-07-15T03:46:24+00:00",
        "closed_at": "2024-07-15T03:46:24+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 388,
        "title": "Can't convert PGNet model to Openvino",
        "body": "Cross-posted from https://github.com/PaddlePaddle/PaddleOCR/issues/4533\r\n\r\nI'm having some troubles trying to convert the PGNet model into OpenVino.  \r\nFirst I convert the model to ONNX using this command (original model can be found in the docs here: https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.3/doc/doc_en/pgnet_en.md#Quick_Use)\r\n\r\n```\r\npaddle2onnx --model_dir e2e_server_pgnetA_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file pgnet.onnx --opset_version 12\r\n```\r\nWhich successfully complete.  \r\nThen I try to convert it to OpenVino using this command:\r\n\r\n```\r\npython mo.py --input_model path/to/pgnet.onnx --output_dir \"my/output/dir/openvino\" --input_shape [1,3,480,160]\r\n```\r\n\r\nThe shape is one that will match my images in production.  \r\nSadly I'm getting this error:\r\n\r\n```\r\n[ ERROR ]  Shape [  1 256  -1  -1] is not fully defined for output 0 of \"Add_21\". Use --input_shape with positive integers to override model input shapes.\r\n[ ERROR ]  Cannot infer shapes or values for node \"Add_21\".\r\n[ ERROR ]  Not all output shapes were inferred or fully defined for node \"Add_21\".\r\n```\r\n\r\nAny suggestions?",
        "state": "closed",
        "user": "tampe125",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-11-03T08:01:43+00:00",
        "updated_at": "2024-07-15T03:46:18+00:00",
        "closed_at": "2024-07-15T03:46:17+00:00",
        "comments_count": [
            "jiangjiajun",
            "tampe125",
            "tampe125",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 389,
        "title": "PaddleDetection deploy by OpenVINO",
        "body": "Currently, YOLOv3 serials are supported, refer to this document https://github.com/PaddlePaddle/Paddle2ONNX/blob/release/0.9/experimental/openvino_ppdet_cn.md for more details",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "jiangjiajun",
        "created_at": "2021-11-04T05:34:43+00:00",
        "updated_at": "2021-11-10T11:06:18+00:00",
        "closed_at": "2021-11-04T05:37:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 390,
        "title": "lapstyle",
        "body": "lapstyle模型可以转onnx吗？\r\n",
        "state": "closed",
        "user": "Chenhait",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-11-06T06:39:06+00:00",
        "updated_at": "2024-07-15T03:46:03+00:00",
        "closed_at": "2024-07-15T03:46:00+00:00",
        "comments_count": [
            "jiangjiajun",
            "Chenhait",
            "jiangjiajun",
            "Chenhait",
            "jiangjiajun"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 391,
        "title": "PaddleOCR中PP-OCRv2识别模型支持动态尺寸输入吗？",
        "body": null,
        "state": "closed",
        "user": "neverstoplearn",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-11-08T10:15:27+00:00",
        "updated_at": "2025-06-16T03:02:17+00:00",
        "closed_at": "2025-06-16T03:02:17+00:00",
        "comments_count": [
            "yeliang2258",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 396,
        "title": "有偏置项的卷积转换为onnx时怎么偏置项不合并到卷积里面去，而是分两步先卷积再加上偏置",
        "body": "1、有偏置项的卷积转换为onnx时怎么偏置项不合并到卷积里面去，而是分两步先卷积再加上偏置，如何像其他框架一样合并到卷积操作里面去\r\n2、add后面那两个标志有啥用能直接去掉吗，怎么去掉，onnx转tensorrt会失败的\r\n\r\n![image](https://user-images.githubusercontent.com/20138766/141874744-539a37a7-5400-4fdd-a3be-ab79cbd58dbc.png)\r\n",
        "state": "closed",
        "user": "marsbzp",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-11-16T00:42:08+00:00",
        "updated_at": "2025-06-13T02:57:13+00:00",
        "closed_at": "2025-06-13T02:57:13+00:00",
        "comments_count": [
            "jiangjiajun",
            "marsbzp",
            "marsbzp",
            "yeliang2258",
            "marsbzp",
            "yeliang2258",
            "marsbzp",
            "yeliang2258",
            "leiqing1",
            "marsbzp",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 395,
        "title": "PaddleGAN中lapstyle模型转换失败",
        "body": "输入        save_path = 'onnx.save/linear_net'\r\n               x_spec = InputSpec([None, 3, 320, 320], 'float32', 'x')\r\n               paddle.onnx.export(self.net_enc, save_path, input_spec=[x_spec])\r\n报错\r\nException: Error happened when mapping node ['pool2d_0'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['relu_1.tmp_0']} and outputs: {'Out': ['pool2d_0.tmp_0']}, specific error: Cannot convert pool with ceil_model == True to ONNX Opset version < 10\r\n",
        "state": "closed",
        "user": "Chenhait",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-11-15T08:30:21+00:00",
        "updated_at": "2025-06-13T02:57:14+00:00",
        "closed_at": "2025-06-13T02:57:14+00:00",
        "comments_count": [
            "yeliang2258",
            "Chenhait",
            "yeliang2258",
            "Chenhait",
            "yeliang2258",
            "Chenhait",
            "Chenhait",
            "yeliang2258",
            "Chenhait",
            "yeliang2258",
            "Chenhait",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 397,
        "title": "operator:matrix_nms only supports input[batch_size]==1",
        "body": "想问一下两个警告，题目是一个，另一个如下：\r\nOperator:matrix_nms is not supported completely, so we use traditional nms(nms_threshold=0.5) to instead it, which introduce some difference.\r\n在将ppyolov2转化成onnx时出现，因为我后续要转换成rknn模型的时候有关于nms的错误，想知道这个警告会不会有影响，警告的具体意思是什么",
        "state": "closed",
        "user": "jiejiangd",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-11-18T08:17:40+00:00",
        "updated_at": "2024-07-15T03:45:49+00:00",
        "closed_at": "2024-07-15T03:45:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 398,
        "title": "2 ops are not supported",
        "body": "将paddleseg中的sfnetresnet50模型导出之后，将其转化为onnx时报错，提示缺少两个算子：there‘s 2 ops are not supported yet。希望官方尽快可以帮忙修复",
        "state": "closed",
        "user": "wang971124",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-11-19T02:25:03+00:00",
        "updated_at": "2024-07-13T12:49:38+00:00",
        "closed_at": "2024-07-13T12:49:29+00:00",
        "comments_count": [
            "wang971124",
            "wang971124",
            "yeliang2258",
            "wang971124",
            "wang971124",
            "yeliang2258",
            "wang971124",
            "jiangjiajun",
            "wang971124",
            "yeliang2258",
            "wang971124",
            "yeliang2258",
            "jiangjiajun",
            "cookiewang1998",
            "Change0028",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 401,
        "title": "文档链接失效",
        "body": "Hi, \r\n链接地址: https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/FAQ.md\r\n在上述文档中提供的`文档导出`失效.",
        "state": "closed",
        "user": "Lingeer",
        "closed_by": "Lingeer",
        "created_at": "2021-11-21T13:45:04+00:00",
        "updated_at": "2021-11-22T04:33:29+00:00",
        "closed_at": "2021-11-22T04:33:29+00:00",
        "comments_count": [
            "yeliang2258",
            "Lingeer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 402,
        "title": "int8量化后的模型导出onnx时，有两个op不支持",
        "body": "fake_quantize_dequantize_moving_average_abs_max\r\nfake_channel_wise_quantize_dequantize_abs_max",
        "state": "closed",
        "user": "zhangxianjie1314",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-11-22T02:16:46+00:00",
        "updated_at": "2025-06-10T02:58:17+00:00",
        "closed_at": "2025-06-10T02:58:16+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "jiangjiajun",
            "zhangxianjie1314",
            "yeliang2258",
            "zhangxianjie1314",
            "zhangxianjie1314",
            "yeliang2258",
            "yeliang2258",
            "zhangxianjie1314",
            "edwardnguyen1705",
            "yeliang2258",
            "edwardnguyen1705",
            "edwardnguyen1705",
            "nongwoluanlai666",
            "yeliang2258",
            "nongwoluanlai666",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 404,
        "title": "做了一个视频轻量级的pdmodel，需要转一下onnx，有没有对pool3d的支持？",
        "body": "这个model里面主要依赖的paddle的API有下面两个\r\npaddle.nn.AvgPool3D\r\npaddle.nn.functional.adaptive_avg_pool3d\r\n我的paddle的版本是paddle-gpu==2.1.0\r\npaddle2onnx的版本是0.7\r\n对conv3d的支持已经在issue里面找到，现在就差一个pool3d的",
        "state": "closed",
        "user": "Stave604671",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-11-22T11:05:21+00:00",
        "updated_at": "2024-05-22T05:15:44+00:00",
        "closed_at": "2024-05-22T05:15:36+00:00",
        "comments_count": [
            "jiangjiajun",
            "Stave604671",
            "yeliang2258",
            "Stave604671",
            "yeliang2258",
            "Stave604671",
            "Stave604671",
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 411,
        "title": "ONNX to TensorRT",
        "body": "Hello, \r\n\r\nI have trained the PaddelOCR with my own data and I was able to convert the pretrained model to ONNX. My question is how can I convert the onnx file to tensorRT with fp16? is there any documentation that I can follow?\r\n\r\nThanks ",
        "state": "closed",
        "user": "Auth0rM0rgan",
        "closed_by": "Auth0rM0rgan",
        "created_at": "2021-12-01T16:44:48+00:00",
        "updated_at": "2023-10-31T10:47:55+00:00",
        "closed_at": "2022-01-28T11:42:18+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "Auth0rM0rgan",
            "yeliang2258",
            "Auth0rM0rgan",
            "yeliang2258",
            "mahesh11T"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 415,
        "title": "paddle2onnx报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**基于paddle ocr训练的表格识别模型，转成onnx时报错！！！**\r\n用paddle训练的表格识别模型，转onnx时报错，难道是不支持GRU操作。\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:tensorRT\r\n - 为什么需要转换为ONNX格式：用tensorRT加速\r\n - Paddle2ONNX版本:2.1.1\r\n - 你的联系方式(Email/Wechat/Phone):1151583746@qq.com\r\n\r\n****\r\nTraceback (most recent call last):\r\n  File \"/home/work/anaconda3/envs/torch16_py37/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/command.py\", line 184, in main\r\n    input_shape_dict=input_shape_dict)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/command.py\", line 148, in program2onnx\r\n    operator_export_type=operator_export_type)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 84, in program2onnx\r\n    enable_onnx_checker, operator_export_type)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 34, in export_onnx\r\n    operator_export_type, verbose)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n    onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n    self.update_opset_version()\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 129, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"/home/work/anaconda3/envs/torch16_py37/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 7 ops are not supported yet\r\n=========== select_input ===========\r\n=========== lod_array_length ===========\r\n=========== write_to_array ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== one_hot_v2 ===========\r\n=========== while ===========\r\n=========== conditional_block ===========\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "CV-deeplearning",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-06T11:24:29+00:00",
        "updated_at": "2024-11-19T08:18:17+00:00",
        "closed_at": "2024-11-19T08:18:17+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 407,
        "title": "SMOKE static model export to ONNX",
        "body": "Dear Author.\r\nHello! I have encountered a problem. I am using the SMOKE model and following the instructions in README.MD to export the model as a static diagram model. However, the following error occurs when converting the static diagram model to ONNX model.\r\nConfiguration environment.\r\n`onnx=1.9.0\r\nonnxruntime=1.9.0\r\npaddle2onnx=0.8.2\r\npaddledet=2.3.0\r\npaddlepaddle-gpu=2.2.0\r\n`\r\nError message\r\n```\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:45: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/home/lee/.conda/envs/paddle/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/command.py\", line 148, in main\r\n    program2onnx(\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/command.py\", line 114, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 79, in program2onnx\r\n    export_onnx(paddle_graph, save_file, opset_version, enable_onnx_checker, operator_export_type)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 33, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version, operator_export_type, verbose)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n    onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n    self.update_opset_version()\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 127, in get_recommend_opset_version\r\n    recommend_opset_version = OpMapper.check_support_status(node_map, opset_version, True)\r\n  File \"/home/lee/.conda/envs/paddle/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 168, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 9 ops are not supported yet\r\n=========== while ===========\r\n=========== set_value ===========\r\n=========== crop_tensor ===========\r\n=========== logical_not ===========\r\n=========== less_than ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== index_select ===========\r\n=========== atan ===========\r\n```\r\nThis error indicates that nine operators are not supported. After checking the list of operators, I found only 'conditional-block', 'set-value', and 'while', 'select-input' and 'crop-tensor' are not available. Here are the commands I used for the conversion.\r\n`paddle2onnx \r\n--model_dir /media/lee/DATA/project/gitproject/models/PaddleCV/3d_vision/SMOKE/inference_model             \r\n--model_filename inference.pdmodel             \r\n--params_filename inference.pdiparams             \r\n--opset_version 11            \r\n--save_file smoke.onnx\r\n`\r\nHow should I solve such a situation? I look forward to your reply!",
        "state": "closed",
        "user": "Gewaihir",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-11-26T01:00:30+00:00",
        "updated_at": "2025-06-08T03:05:36+00:00",
        "closed_at": "2025-06-08T03:05:35+00:00",
        "comments_count": [
            "yeliang2258",
            "Gewaihir",
            "yeliang2258",
            "sinopec",
            "sinopec",
            "hitbuyi",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 419,
        "title": "Due to the operator:multiclass_nms3, the converted ONNX model will only supports ",
        "body": "**问题描述**\r\n\r\nyolov3_ darknet53_ 270e_ VOC 训练出来的模型\r\n\r\nimage_shape:[3,608,608]\r\n\r\nPaddle2onnx conversion yolov3_ darknet53_ 270e_ VOC model\r\n[WARNING]   Due to the operator:multiclass_nms3, the converted ONNX model will only supports input[batch_size] == 1.\r\n\r\n paddle2onnx \r\n--model_dir D:\\PaddleDetection\\output\\yolov3_darknet53_270e_voc_OK\\yolov3_darknet53_270e_voc \r\n--model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 \r\n--save_file D:\\PaddleDetection\\output\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3.onnx\r\n\r\nD:\\anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\onnx\\helper.py:343: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  is_iterable = isinstance(value, collections.Iterable)\r\n\r\n2021-12-09 16:44:59 [WARNING]   Due to the operator:multiclass_nms3, the converted ONNX model will only supports input[batch_size] == 1.\r\n2021-12-09 16:45:01 [INFO]      ONNX model generated is valid.\r\n2021-12-09 16:45:03 [INFO]      ONNX model saved in D:\\PaddleDetection\\output\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3.onnx\r\n\r\n[WARNING]   Due to the operator:multiclass_nms3, the converted ONNX model will only supports input[batch_size] == 1.\r\n\r\n---------------------\r\n\r\n转换为  openvino\r\n报错\r\n\r\npython mo_onnx.py \r\n--input_model F:\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3.onnx \r\n--output_dir F:\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3 --input_shape [1,3,608,608]\r\n\r\n\r\nModel Optimizer arguments:\r\nCommon parameters:\r\n        - Path to the Input Model:      F:\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3.onnx\r\n        - Path for generated IR:        F:\\yolov3_darknet53_270e_voc_OK\\onnx\\yolov3\r\n        - IR output name:       yolov3\r\n        - Log level:    ERROR\r\n        - Batch:        Not specified, inherited from the model\r\n        - Input layers:         Not specified, inherited from the model\r\n        - Output layers:        Not specified, inherited from the model\r\n        - Input shapes:         [1,3,608,608]\r\n        - Mean values:  Not specified\r\n        - Scale values:         Not specified\r\n        - Scale factor:         Not specified\r\n        - Precision of IR:      FP32\r\n        - Enable fusing:        True\r\n        - Enable grouped convolutions fusing:   True\r\n        - Move mean values to preprocess section:       None\r\n        - Reverse input channels:       False\r\nONNX specific parameters:\r\n        - Inference Engine found in:    E:\\Intel\\openvino_2021.4.689\\python\\python3.8\\openvino\r\nInference Engine version:       2021.4.1-3926-14e67d86634-releases/2021/4\r\nModel Optimizer version:        2021.4.1-3926-14e67d86634-releases/2021/4\r\n\r\n[ ERROR ]  Exception occurred during running replacer \"REPLACEMENT_ID\" (<class \r\n'extensions.front.user_data_repack.UserDataRepack'>): Original placeholders: 'im_shape, image, scale_factor'. Freezing was requested for ''. --input_shape was provided without --input. Can not deduce which node shape to override\r\n\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-09T09:30:19+00:00",
        "updated_at": "2024-05-22T05:15:12+00:00",
        "closed_at": "2024-05-22T05:15:03+00:00",
        "comments_count": [
            "jiangjiajun",
            "monkeycc",
            "jiangjiajun",
            "monkeycc",
            "jiangjiajun",
            "monkeycc",
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 421,
        "title": "转onnx模型时模型输出不固定（n,w,h显示为-1）",
        "body": "感谢您们将如此优秀的框架开源，我在使用Paddle2ONNX出现了一下问题\r\n**问题描述**\r\n我在进行人像分割测试时，在尝试把fcn_hrnetw18_small_v1模型转成onnx。\r\n我希望转换成的onnx模型的输入与输出是固定不可变的，而不是动态的。\r\n我尝试了各种方法，目前只能做到对于模型的输入给予一个固定shape，但模型输出的结果中w与h仍然是-1（可变）\r\n\r\n**更多信息 :**\r\n - 为什么需要转换为ONNX格式：在硬件上测试\r\n - Paddle2ONNX版本:0.9.0\r\n - 你的联系方式(Email/Wechat/Phone):lzz773751548@gmail.com\r\n\r\n期待您的回复",
        "state": "closed",
        "user": "lzz773751548",
        "closed_by": "jiangjiajun",
        "created_at": "2021-12-10T03:18:42+00:00",
        "updated_at": "2022-07-25T08:08:56+00:00",
        "closed_at": "2022-07-25T08:08:56+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 422,
        "title": "模型转换成onnx后，是否支持c++ opencv 直接调用onnx模型",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n将模型转换成onnx之后，`cv::dnn::Net net = cv::dnn::readNetFromONNX(onn_path);` 载入模型并不会报错，但是在 推理时候报错\r\n`net.setInput(blob);  // 设置模型输入`\r\n\r\n\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/10796263/145540354-b340825a-49ad-4acb-81c0-557a273393d6.png)\r\n\r\n\r\n**其他信息**\r\n\r\n网络模型，及导成onnx的过程依照的是官方例程：https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/examples/tutorial_dygraph2onnx.ipynb\r\n用python 的 opencv 可以成功进行推理\r\n\r\n测试环境 ：vs2015(c++) + opencv450\r\n\r\n",
        "state": "closed",
        "user": "xxdm",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-12-10T08:18:23+00:00",
        "updated_at": "2025-06-08T03:05:35+00:00",
        "closed_at": "2025-06-08T03:05:34+00:00",
        "comments_count": [
            "yeliang2258",
            "xxdm",
            "yeliang2258",
            "xxdm",
            "yeliang2258",
            "xxdm",
            "geoexploring",
            "XXMxxm220",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 425,
        "title": "ppdet的yolov3模型转onnx失败",
        "body": "![image](https://user-images.githubusercontent.com/74706568/145754198-3994dbcb-a082-4050-96c5-f921d81b8ae7.png)\r\n![image](https://user-images.githubusercontent.com/74706568/145754505-bf5efea6-2668-4c17-a807-f972fd02dfc3.png)\r\n",
        "state": "closed",
        "user": "usuixingyili",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-12-13T04:53:59+00:00",
        "updated_at": "2025-06-08T03:05:34+00:00",
        "closed_at": "2025-06-08T03:05:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "usuixingyili",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 432,
        "title": "请问“paddle.onnx.export”导出时如何指定outputs节点的名字",
        "body": "![image](https://user-images.githubusercontent.com/26252750/146330902-5fde32a3-2457-4601-bcaf-545fbc60c770.png)\r\n",
        "state": "closed",
        "user": "gl94",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-16T07:57:44+00:00",
        "updated_at": "2024-05-22T05:14:50+00:00",
        "closed_at": "2024-05-22T05:14:50+00:00",
        "comments_count": [
            "yeliang2258",
            "gl94",
            "jiangjiajun",
            "gl94",
            "yeliang2258"
        ],
        "labels": [
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 429,
        "title": "官方 Paddle2.0导出ONNX模型和推理 例子运行报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n在官方例子：https://aistudio.baidu.com/aistudio/projectdetail/3243132?forkThirdPart=1  中`ONNX模型验证`\r\n![image](https://user-images.githubusercontent.com/10796263/145942124-1b623570-0346-423f-8880-05e6e7f4f764.png)\r\n\r\nInvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: Unknown model file format version.\r\n\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/10796263/145942193-85d1b54e-24e8-4826-a312-6fc8bfcf9242.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "xxdm",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-14T06:04:22+00:00",
        "updated_at": "2024-07-15T03:45:39+00:00",
        "closed_at": "2024-07-15T03:45:36+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 435,
        "title": "ppyolov2-转成onnx后，在python上 用opencv调用报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n载入模型报错\r\n\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本: 最新\r\n - opencv：4.5\r\n - python： 3.7\r\n\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/10796263/146745768-b706b779-ab83-4a58-8090-9461536303a0.png)\r\n\r\n\r\n**其他信息**\r\n是不是需要修改源码，将切片的方式改掉？\r\n",
        "state": "closed",
        "user": "xxdm",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-20T09:39:06+00:00",
        "updated_at": "2024-07-15T04:19:01+00:00",
        "closed_at": "2024-07-15T04:18:56+00:00",
        "comments_count": [
            "yeliang2258",
            "xxdm",
            "xxdm",
            "yeliang2258",
            "xxdm",
            "xxdm",
            "xxdm"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 437,
        "title": "ppyolov2模型转换为onnx后部分Clip算子没有min和max",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nppyolov2_r50vd_dcn_365e_coco模型转换为onnx后Clip_24,Clip_29,Clip_34没有min和max\r\n\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本:最新\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/31937673/146860631-65e9b704-2891-49a0-a3f0-a2d25accd834.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ChenjieXu",
        "closed_by": "ChenjieXu",
        "created_at": "2021-12-21T02:29:28+00:00",
        "updated_at": "2021-12-23T10:00:01+00:00",
        "closed_at": "2021-12-23T10:00:00+00:00",
        "comments_count": [
            "jiangjiajun",
            "ChenjieXu",
            "ChenjieXu",
            "jiangjiajun",
            "yeliang2258",
            "ChenjieXu"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 444,
        "title": "Paddle 模型转换成 ONNX 后使用 onnxruntime 推理出错",
        "body": "**问题描述**\r\n使用最新 PaddleDetection 训练了一个 FCOS 模型，然后根据 PaddleDetection 的教程导出为 onnx 格式，期间使用了 onnxsimplifier，转换过程已经完成。\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime\r\n - 为什么需要转换为ONNX格式：学习使用\r\n - Paddle2ONNX版本: 0.9.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_19' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/math/element_wise_ops.h:479 void onnxruntime::BroadcastIterator::Init(int64_t, int64_t) axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 93 by 94\r\n\r\n**其他信息**\r\n1. 使用 Paddle 该模型可以推理成功\r\n2. 使用 Netron 查看网络结构，Add_19 算子应该是 FPN 中的一个特征融合结构\r\n2. 已经尝试过降低 onnxruntime 版本，现已尝试过 1.9.0、1.8.0、1.6.0 等\r\n3. 训练模型使用的 PaddleDetection 版本是最新的，且没有改动代码\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": null,
        "created_at": "2021-12-24T01:08:04+00:00",
        "updated_at": "2021-12-25T12:01:40+00:00",
        "closed_at": "2021-12-25T12:01:40+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "ghost",
            "yeliang2258",
            "ghost",
            "yeliang2258",
            "ghost",
            "yeliang2258",
            "ghost"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 445,
        "title": "将paddleDetection的一些模型  转成 onnx格式后，用opencv调用（一些操作如切片opencv不支持）导致报错，如何修改。",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n将paddleDetection的一些模型  转成 onnx（已经成功转成onnx）格式后，用opencv调用（一些操作如切片opencv不支持）导致报错，如何修改。\r\n",
        "state": "closed",
        "user": "xxdm",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-24T02:32:55+00:00",
        "updated_at": "2024-05-22T05:14:34+00:00",
        "closed_at": "2024-05-22T05:14:29+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "xxdm",
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 452,
        "title": "ppyolov2模型mul_186两个的输入类型不一致",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nppyolov2_r50vd_dcn_365e_coco模型mul_186两个的输入类型不一致，但onnx算子定义要求这两者类型一致才行。导致在转换成其他格式时出错。\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:develop版本\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ChenjieXu",
        "closed_by": "ChenjieXu",
        "created_at": "2021-12-25T11:13:56+00:00",
        "updated_at": "2022-01-05T07:06:53+00:00",
        "closed_at": "2022-01-05T07:06:52+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "zuocebianpingmao",
            "yeliang2258",
            "zuocebianpingmao",
            "yeliang2258",
            "ChenjieXu",
            "yeliang2258",
            "ChenjieXu",
            "ChenjieXu",
            "yeliang2258",
            "ChenjieXu",
            "yeliang2258",
            "ChenjieXu",
            "jiangjiajun",
            "ChenjieXu",
            "jiangjiajun",
            "ChenjieXu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 451,
        "title": "PaddleOCR的模型转成onnx后的推理结果与原版不一致，精度差很多。",
        "body": "\r\n按照以下页面的说明，先准备环境，然后转换，接下来测试转换后的onnx推理结果，并对比pdmodel的推理结果。\r\nhttps://gitee.com/paddlepaddle/Paddle2ONNX#https://gitee.com/link?target=https%3A%2F%2Faistudio.baidu.com%2Faistudio%2Fprojectdetail%2F1461212\r\n\r\n\r\n第一步，准备conda环境：\r\n\r\n用pip安装完成后的：\r\n\r\n(ocrv2) ➜  test_onnx pip list | grep paddle\r\n\r\npaddle2onnx                       0.9.0\r\npaddleocr                         2.3.0.2\r\npaddlepaddle                      2.2.1\r\n\r\n(ocrv2) ➜  test_onnx pip list | grep onnx\r\n\r\nonnx                              1.9.0\r\npaddle2onnx                       0.9.0\r\n\r\n\r\n第二步，转换：\r\n从https://gitee.com/paddlepaddle/PaddleOCR/blob/release/2.4/doc/doc_ch/models_list.md 下载ch_PP-OCRv2_det、rec模型\r\n\r\npaddle2onnx --model_dir ch_PP-OCRv2_det_infer  --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ppocrv2_det_infer.onnx --opset_version 10 --enable_onnx_checker True\r\n\r\npaddle2onnx --model_dir ch_PP-OCRv2_rec_infer  --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ppocrv2_rec_infer.onnx --opset_version 10 --enable_onnx_checker True\r\n\r\npaddle2onnx --model_dir ch_ppocr_mobile_v2.0_cls_infer  --model_filename ch_ppocr_mobile_v2.0_cls_infer/inference.pdmodel --params_filename ch_ppocr_mobile_v2.0_cls_infer/inference.pdiparams --save_file ppocrv1_cls_infer.onnx --opset_version 10 --enable_onnx_checker True\r\n\r\n\r\n\r\n第三步，推理：\r\n在PaddleOCR目录下，推理./deploy/lite/imgs/lite_demo.png\r\n\r\n用onnx推理：\r\n\r\npython tools/infer/predict_system.py --use_gpu=False --use_onnx=True --cls_model_dir=ppocrv2_cls_infer_11.onnx --rec_model_dir=ppocrv2_rec_infer_11.onnx --det_model_dir=ppocrv2_det_infer_11.onnx --image_dir=./deploy/lite/imgs/lite_demo.png\r\n\r\n用pdmodel推理：\r\n\r\npython tools/infer/predict_system.py --use_gpu=False --cls_model_dir=./ch_ppocr_mobile_v2.0_cls_infer --rec_model_dir=./ch_PP-OCRv2_rec_infer --det_model_dir=./ch_PP-OCRv2_det_infer --image_dir=./deploy/lite/imgs/lite_demo.png\r\n\r\n\r\n现在的问题是，原版pdmodel的推理结果和转成onnx后的推理结果不一致。\r\n转换这一步的opset_version，9、10和11都试过了，用model_zoo页面多个模型排列组合测试过，都是不一致的。\r\n\r\n**报错截图**\r\n原版的效果：\r\n![lite_demo_v2](https://user-images.githubusercontent.com/7877379/147378695-bb3faf1f-5ed9-4bf6-b8e6-62b7f9f106d7.png)\r\nonnx后的效果：\r\n![lite_demo_v2_11](https://user-images.githubusercontent.com/7877379/147378774-a4393b75-b775-47a8-914a-1d49de80f872.png)\r\n\r\n\r\n我在 ocr 14 群。\r\n",
        "state": "closed",
        "user": "alatriste-lee",
        "closed_by": "alatriste-lee",
        "created_at": "2021-12-25T06:16:25+00:00",
        "updated_at": "2022-01-07T11:04:13+00:00",
        "closed_at": "2021-12-30T09:03:15+00:00",
        "comments_count": [
            "yeliang2258",
            "jiangjiajun",
            "neonhuang",
            "alatriste-lee",
            "zxl222",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 455,
        "title": "PPTiny pose模型转onnx后前向推理报错",
        "body": "sess = rt.InferenceSession(\"tinypose_256x192.onnx\")\r\nsess = rt.InferenceSession(\"tinypose_256x192.onnx\")\r\n  File \"/Users/a11080362/.local/lib/python3.6/site-packages/onnxruntime/capi/session.py\", line 25, in __init__\r\n    self._load_model(providers)\r\n  File \"/Users/a11080362/.local/lib/python3.6/site-packages/onnxruntime/capi/session.py\", line 43, in _load_model\r\n    self._sess.load_model(providers)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: Unknown model file format version.",
        "state": "closed",
        "user": "michaelfu123",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2021-12-28T12:11:42+00:00",
        "updated_at": "2024-07-15T04:19:17+00:00",
        "closed_at": "2024-07-15T04:19:17+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 462,
        "title": "Paddle2onnx 转化Paddledetection的fasterrcnn模型出现ops不支持错误",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nPaddle2onnx 转化Paddledetection的fasterrcnn模型出现ops不支持错误，不只是fasterrcnn，还有ttfnet，试了多个之后发现只有yolo模型可以转换，请问是当前版本还不支持部分操作吗，可以列出目前不支持的ops以及替代方案不，谢谢\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n1195857096@qq.com\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/38058900/147797107-07946b6e-5468-40e4-a38b-aef467489c00.png)\r\n\r\n\r\n**其他信息**\r\nThere's 9 ops are not supported yet\r\n=========== where ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== write_to_array ===========\r\n=========== lod_array_length ===========\r\n=========== meshgrid ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== while ===========\r\n=========== generate_proposals_v2 ===========",
        "state": "closed",
        "user": "HansenLYX0708",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-12-31T01:03:16+00:00",
        "updated_at": "2025-06-03T02:56:08+00:00",
        "closed_at": "2025-06-03T02:56:08+00:00",
        "comments_count": [
            "jiangjiajun",
            "HansenLYX0708",
            "jiangjiajun",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 456,
        "title": "有没有ssd的inference demo",
        "body": "有没有ssd的inference demo",
        "state": "closed",
        "user": "yangrisheng",
        "closed_by": "github-actions[bot]",
        "created_at": "2021-12-29T06:04:56+00:00",
        "updated_at": "2025-06-07T02:52:28+00:00",
        "closed_at": "2025-06-07T02:52:27+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 466,
        "title": "Paddle2ONNX报错Errno 13，permission denied",
        "body": "![2022-01-03_170740](https://user-images.githubusercontent.com/26628875/147915123-6a8b0f44-d946-4d1f-bfac-f6ab85e6b6f2.png)\r\n",
        "state": "closed",
        "user": "MacTian",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-03T09:21:04+00:00",
        "updated_at": "2024-05-22T05:14:14+00:00",
        "closed_at": "2024-05-22T05:14:11+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 472,
        "title": "SMOKE paddle not supported ",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n用动态图转换( paddle.onnx.export) SMOKE paddle模型 (https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/3d_vision/SMOKE),\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\nThere's 5 ops are not supported yet\r\n=========== crop_tensor ===========\r\n=========== while ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== set_value ===========\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n -  need for openvino \r\n - Paddle2ONNX版本: master latest\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "sinopec",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-01-05T03:41:37+00:00",
        "updated_at": "2025-06-02T03:00:26+00:00",
        "closed_at": "2025-06-02T03:00:25+00:00",
        "comments_count": [
            "yeliang2258",
            "sinopec",
            "yeliang2258",
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 471,
        "title": "如何自助解决不支持的算子",
        "body": "**问题描述**\r\n- 我正在尝试转换Paddle2Speech中的[TTS2](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/csmsc/tts2)模型到ONNX格式，其中转换`speedyspeech_csmsc.pdmodel`时，遇到有3个op不支持\r\n    ```text\r\n    Traceback (most recent call last):\r\n      File \"/data/home/xxx/.conda/envs/xxx/bin/paddle2onnx\", line 8, in <module>\r\n        sys.exit(main())\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/command.py\", line 184, in main\r\n        input_shape_dict=input_shape_dict)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/command.py\", line 148, in program2onnx\r\n        operator_export_type=operator_export_type)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 84, in program2onnx\r\n        enable_onnx_checker, operator_export_type)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 34, in export_onnx\r\n        operator_export_type, verbose)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n        onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n        self.update_opset_version()\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n        self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 129, in get_recommend_opset_version\r\n        node_map, opset_version, True)\r\n      File \"/data/home/xxx/.conda/envs/xxx/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\n        raise NotImplementedError(error_info)\r\n    NotImplementedError: \r\n    There's 3 ops are not supported yet\r\n    =========== while ===========\r\n    =========== conditional_block ===========\r\n    =========== set_value ===========\r\n    ```\r\n- 同时，我看到了[Paddle2ONNX开发指南](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/Paddle2ONNX_Development_Guide.md)这篇文章，尝试按照里面所说的方案，以`conditional_block`查找对应的Paddle OP。\r\n- 无奈暂时没有找到对应哪个Paddle OP，或者说这是Paddle搭建模型中，哪个操作引起的？不知是否可以以`conditional_block`为例，讲解一下如何自助修复不支持的OP\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: ONNXRuntime\r\n - 为什么需要转换为ONNX格式: 便于与其他ONNX模型一起整合\r\n - Paddle2ONNX版本: 0.9.0\r\n - 你的联系方式(Email/Wechat/Phone): liekkaskono@163.com\r\n\r\n**其他信息：**\r\n- 问卷调查已经填过了",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-05T02:53:36+00:00",
        "updated_at": "2024-11-19T08:18:07+00:00",
        "closed_at": "2024-11-19T08:18:07+00:00",
        "comments_count": [
            "yeliang2258",
            "yt605155624"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 474,
        "title": "uniform算子支持转换",
        "body": "**问题描述**\r\n- 请问`uniform`算子有计划提供转换吗？\r\n- 我看到测试文件中，已经有了`uniform`的单元测试，尝试跑了一下，暂时转换前后差异较大\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/b5bc153b3e75ef291a08477c7d6cbfdcdc1fdb0d/tests/test_uniform.py#L37-L49\r\n\r\n",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "SWHL",
        "created_at": "2022-01-05T09:13:46+00:00",
        "updated_at": "2022-01-05T11:59:20+00:00",
        "closed_at": "2022-01-05T11:59:19+00:00",
        "comments_count": [
            "yeliang2258",
            "SWHL",
            "yeliang2258",
            "SWHL"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 475,
        "title": "关于set_value的问题",
        "body": "我在使用paddle模型转onnx模型时，报了以下错误：\r\n\r\nNotImplementedError: \r\nThere's 2 ops are not supported yet\r\n=========== meshgrid ===========\r\n=========== set_value ===========\r\n\r\n其中“meshgrid”为paddle的op，但是这里的“set_value”是什么呢，是不是因为在模型当中存在赋值的操作，而在转换过程中不支持相关操作？",
        "state": "closed",
        "user": "C-ZR",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-05T09:31:00+00:00",
        "updated_at": "2024-06-05T06:11:51+00:00",
        "closed_at": "2024-06-05T06:11:51+00:00",
        "comments_count": [
            "yeliang2258",
            "C-ZR",
            "C-ZR",
            "yeliang2258",
            "yeliang2258",
            "yeliang2258",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 480,
        "title": "\"onnx.ModelProto exceeds maximum protobuf size of 2GB\" Error when converting PLATO-2'S NSP Model",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nI got this error when trying to convert the NSP model of PLATO-2 32L\r\n`ValueError: Message onnx.ModelProto exceeds maximum protobuf size of 2GB: 6530750548`\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: 2.2.0\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n![Screenshot 2022-01-11 145323](https://user-images.githubusercontent.com/94152606/148902568-ba26cec8-8182-420b-a207-b6b1e1031aba.png)\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "fadelma",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-01-11T07:54:16+00:00",
        "updated_at": "2025-05-29T02:53:59+00:00",
        "closed_at": "2025-05-29T02:53:58+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 485,
        "title": "hard_sigmoid问题",
        "body": "使用paddle2onnx将训练好的picodet模型转换成了onnx格式，代码如下：\r\npaddle2onnx --model_dir inference_model/picodet_s_320_voc/ \\\r\n            --model_filename model.pdmodel  \\\r\n            --params_filename model.pdiparams \\\r\n            --opset_version 11 \\\r\n            --save_file picodet_s_320_voc.onnx\r\npython -m onnxsim picodet_s_320_voc.onnx picodet_s_320_voc_f1.onnx\r\n然后使用opencv进行调用\r\nimport cv2\r\nimport onnx\r\n\r\n# 载入onnx模块\r\nmodel_ = onnx.load(\"PaddleDetection/picodet_s_320_voc_f1.onnx\")\r\n#检查IR是否良好\r\nprint(onnx.checker.check_model(model_))\r\n\r\n# opencv 推理\r\nnet = cv2.dnn.readNetFromONNX(\"PaddleDetection/picodet_s_320_voc_f1.onnx\")  # 加载训练好的识别模型\r\nprint('load successful')\r\n image = cv2.imread(\"PaddleDetection/dataset/voc/images/000003.png\")  # 读取图片\r\n blob = cv2.dnn.blobFromImage(image)  # 由图片加载数据 这里还可以进行缩放、归一化等预处理\r\n net.setInput(blob)  # 设置模型输入\r\n out = net.forward()  # 推理出结果\r\n运行然后报错：\r\nTraceback (most recent call last):\r\n  File \"opecvonnx.py\", line 10, in <module>\r\n    net = cv2.dnn.readNetFromONNX(\"PaddleDetection/picodet_s_320_voc_f1.onnx\")  # 加载训练好的识别模型\r\ncv2.error: OpenCV(4.1.1) /io/opencv/modules/dnn/src/dnn.cpp:525: error: (-2:Unspecified error) Can't create layer \"hardsigmoid_0.tmp_0\" of type \"HardSigmoid\" in function 'getLayerInstance'\r\n\r\n不能read hardsigmoid层 \r\n请问这个有啥解决办法吗？",
        "state": "closed",
        "user": "axdo",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-15T02:08:59+00:00",
        "updated_at": "2024-11-19T08:17:58+00:00",
        "closed_at": "2024-11-19T08:17:58+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun",
            "yuenshangli",
            "jiangjiajun",
            "yuenshangli",
            "GreenAvocado92"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 488,
        "title": "[待办] 单测中添加强制固定opset的测试",
        "body": "目前单测中OP转换会自动向上转换，需修改单测框架，解决后关闭此issue @yeliang2258 ",
        "state": "closed",
        "user": "jiangjiajun",
        "closed_by": "yeliang2258",
        "created_at": "2022-01-16T07:48:20+00:00",
        "updated_at": "2022-01-17T06:51:34+00:00",
        "closed_at": "2022-01-17T06:51:34+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 490,
        "title": "将yolov3剔除nms后的后处理规则",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n将yolov3剔除nms后，出来的两个输出shape分别是[-1, 22743, 4]和[-1, 4, 22743]，不清楚数据具体意义.以及具体的后处理规则实现\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "WooXinyi",
        "closed_by": "WooXinyi",
        "created_at": "2022-01-17T03:18:24+00:00",
        "updated_at": "2022-01-20T00:44:30+00:00",
        "closed_at": "2022-01-20T00:44:29+00:00",
        "comments_count": [
            "lyuwenyu",
            "WooXinyi",
            "WooXinyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 500,
        "title": "paddleSeg 训练出来的模型onnx转换报错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n作者您好，我才用paddleSeg -v0.7完成样例模型的训练，运行模型导出函数export_model.py，得到模型和参数文件，静态转换为onnx模型时报错如下：\r\n     AttributeError: module 'paddle' has no attribute 'float32'\r\n安装的paddle=1.8.5,onnx=1.9。望给以解答，万分感谢。\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "hjm0613",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-20T09:10:09+00:00",
        "updated_at": "2024-07-15T03:44:56+00:00",
        "closed_at": "2024-07-15T03:44:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "hjm0613",
            "hjm0613",
            "jiangjiajun",
            "jiangjiajun",
            "hjm0613",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 501,
        "title": "PaddleDetection模型支持保存为ONNX格式，但很多模型仅支持batch=1推理",
        "body": "如下图所示 PaddleDetection模型支持保存为ONNX格式，但很多模型仅支持batch=1推理\r\n请问 如果想导出batch=-1或者宽高都是动态尺寸的模型  现在最新版本支持吗？应该需要改哪些地方？\r\n\r\n![1642674263(1)](https://user-images.githubusercontent.com/39080886/150320674-5609e327-4eba-414c-aeca-862ae8f43c34.png)\r\n",
        "state": "closed",
        "user": "wangyuan111",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-01-20T10:27:29+00:00",
        "updated_at": "2024-07-15T03:44:38+00:00",
        "closed_at": "2024-07-15T03:44:29+00:00",
        "comments_count": [
            "jiangjiajun",
            "lofyol"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 505,
        "title": "paddlehub ultra_light_fast_generic_face_detector_1mb_640转onnx报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n![image](https://user-images.githubusercontent.com/24600584/150462925-037f1a78-c88c-4eef-b694-721795ace3d4.png)\r\n模型路径为paddlehub目录下的ultra_light_fast_generic_face_detector_1mb_640  ，是否需要进行其他转换？\r\n\r\n命令：`paddle2onnx --model_dir ./ultra_light_fast_generic_face_detector_1mb_640  --save_file onnx_file --opset_version 10 --enable_onnx_checker True`\r\n版本：paddle2onnx 0.9.0、onnx 1.9.0\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n```\r\nException: Error happened when mapping node ['conv2d_0'] to onnx, which op_type is 'conv2d' with inputs: {'Bias': [], 'Filter': ['_base_net_0_0_weight'], 'Input': ['_input'], 'ResidualData': []} and outputs: {'Output': ['_245.tmp_0']}, specific error: The conv data format should be 'NCHW' or 'NCDHW', but received data format is AnyLayout.\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "w-Bro",
        "closed_by": "w-Bro",
        "created_at": "2022-01-21T03:51:04+00:00",
        "updated_at": "2022-01-24T10:25:04+00:00",
        "closed_at": "2022-01-24T10:25:04+00:00",
        "comments_count": [
            "jiangjiajun",
            "w-Bro",
            "neonhuang",
            "w-Bro"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 516,
        "title": "模型转换成其他格式时NMS算子报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n在转换为华为模型时NMS算子报错，ONNX官方对NMS有官方实现，想请问百度的NMS实现跟这个链接中NMS的官方实现的描述有哪些不一致的地方？谢谢\r\nhttps://github.com/onnx/onnx/blob/main/docs/Operators.md#NonMaxSuppression\r\n\r\n**更多信息 :**\r\n - 为什么需要转换为ONNX格式：转成华为模型\r\n - Paddle2ONNX版本:develop\r\n\r\n**报错截图**\r\n![3cd77c30bcd5ab028156207cd88fae4](https://user-images.githubusercontent.com/31937673/151090029-a2ee6309-35b0-4921-a5fc-8c098c916fe6.jpg)\r\n\r\n\r\n**其他信息**\r\n之前相关的问题以及模型下载链接：https://github.com/PaddlePaddle/Paddle2ONNX/issues/452\r\n调查问卷已经填写",
        "state": "closed",
        "user": "ChenjieXu",
        "closed_by": "ChenjieXu",
        "created_at": "2022-01-26T02:01:00+00:00",
        "updated_at": "2022-01-30T04:09:56+00:00",
        "closed_at": "2022-01-30T04:09:56+00:00",
        "comments_count": [
            "jiangjiajun",
            "WooXinyi",
            "jiangjiajun",
            "WooXinyi",
            "jiangjiajun",
            "WooXinyi",
            "jiangjiajun",
            "WooXinyi",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 527,
        "title": "缺少算子支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n```\r\nThere's 2 ops are not supported yet\r\n=========== grid_sampler ===========\r\n=========== linspace ===========\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "geoyee",
        "closed_by": "geoyee",
        "created_at": "2022-02-05T11:44:48+00:00",
        "updated_at": "2022-04-21T01:11:06+00:00",
        "closed_at": "2022-04-21T01:11:06+00:00",
        "comments_count": [
            "yeliang2258",
            "geoyee",
            "geoyee",
            "neonhuang",
            "geoyee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 536,
        "title": "trainable_statistics should be in AttributeMap ",
        "body": "Error: trainable_statistics should be in AttributeMap at (/paddle/paddle/fluid/framework/attribute.h:177)\r\n  [operator < batch_norm > error]\r\n在paddle1.8下执行onnx_model = paddle2onnx.run_convert(inference_program, input_shape_dict = input_shape_dict, opset_version=11)的时候报错如上。\r\n这个要怎么解决",
        "state": "closed",
        "user": "wang-kangkang",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-02-11T03:38:11+00:00",
        "updated_at": "2024-07-15T04:18:35+00:00",
        "closed_at": "2024-07-15T04:18:35+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Paddle(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 540,
        "title": "fake_quantize_range_abs_max算子不支持",
        "body": "onnx模型转paddle模型，使用paddleslim可以完成离线量化，但离线量化后的paddle模型再转onnx模型存在op不支持问题\r\n报错信息：\r\n/usr/local/lib/python3.9/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/constant/dtypes.py:49: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/constant/dtypes.py:50: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/constant/dtypes.py:55: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddle2onnx\", line 33, in <module>\r\n    sys.exit(load_entry_point('paddle2onnx==0.9.0', 'console_scripts', 'paddle2onnx')())\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/command.py\", line 187, in main\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/command.py\", line 151, in program2onnx\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/convert.py\", line 87, in program2onnx\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/convert.py\", line 34, in export_onnx\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/graph/onnx_graph.py\", line 379, in build\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/graph/onnx_graph.py\", line 90, in __init__\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/graph/onnx_graph.py\", line 326, in update_opset_version\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/op_mapper/op_mapper.py\", line 128, in get_recommend_opset_version\r\n  File \"/usr/local/lib/python3.9/site-packages/paddle2onnx-0.9.0-py3.9.egg/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\nNotImplementedError: \r\nThere's 1 ops are not supported yet\r\n=========== fake_quantize_range_abs_max ===========\r\n\r\n",
        "state": "closed",
        "user": "hcms1994",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-11T08:33:55+00:00",
        "updated_at": "2025-05-29T02:53:58+00:00",
        "closed_at": "2025-05-29T02:53:57+00:00",
        "comments_count": [
            "yeliang2258",
            "hcms1994",
            "yeliang2258",
            "yeliang2258",
            "hcms1994",
            "yeliang2258",
            "ztfmars",
            "hcms1994",
            "hcms1994",
            "yeliang2258",
            "kobe24o",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 541,
        "title": "请求为cpp版本增加两个接口",
        "body": "增加两个统一的对外接口：\r\n1. 增加是否能转换的接口\r\n    bool XXXX(std::string model_file, std::string params_file) -> 返回是否能转换成功;\r\n2. 增加转换paddle模型为onnx模型的接口\r\n    std::string XXX(std::string model_file, std::string params_file)) -> 返回转换成功后并序列化为string的onnx模型",
        "state": "closed",
        "user": "heliqi",
        "closed_by": "jiangjiajun",
        "created_at": "2022-02-11T09:07:23+00:00",
        "updated_at": "2022-02-17T06:53:44+00:00",
        "closed_at": "2022-02-17T06:24:30+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 547,
        "title": "导出segnet生成onnx模型报错",
        "body": "将segnet导出onnx模型时显示There's 2 ops are not supported yet\r\n=========== max_pool2d_with_index ===========\r\n=========== unpool ===========\r\n\r\n配置文件来源：https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.4/configs/segnet\r\n导出onnx为了在tensorrt上运用\r\n Paddle2ONNX版本：paddle2onnx-0.9.0\r\n邮箱：2217177193@qq.com\r\n\r\n",
        "state": "closed",
        "user": "chitongxuean",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-02-14T03:14:52+00:00",
        "updated_at": "2024-11-19T08:17:42+00:00",
        "closed_at": "2024-11-19T08:17:42+00:00",
        "comments_count": [],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 553,
        "title": "导出onnx时修改Conv2DTranspose的输入数据类型为int32",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n导出onnx时修改Conv2DTranspose的输入数据类型为int32\r\n\r\n\r\n - 用于部署的推理引擎:\r\n \r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/99791142/154217483-d933d197-a9c3-4fd7-be49-fe97db88c43d.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "banhongjun",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-16T07:35:26+00:00",
        "updated_at": "2025-05-28T02:53:44+00:00",
        "closed_at": "2025-05-28T02:53:43+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "banhongjun",
            "jiangjiajun",
            "banhongjun",
            "jiangjiajun",
            "banhongjun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 555,
        "title": "addlex 中的 picodet_esnet_l 模型 转换为 onnx 失败",
        "body": " paddlex 中的 [picodet_esnet_l 模型](https://github.com/PaddlePaddle/PaddleX/blob/develop/tutorials/train/object_detection/picodet.py) 转换为 onnx 失败，\r\n\r\n转换命令如下\r\n```\r\npaddle2onnx --model_dir work/code/output/inference_model_picodet_esnet_l/inference_model  --model_filename model.pdmodel --params_filename model.pdiparams --save_file onnx_file --opset_version 10 --enable_onnx_checker True\r\n```\r\n报错如下\r\n```\r\nNotImplementedError:\r\nThere's 7 ops are not supported yet\r\n=========== write_to_array ===========\r\n=========== while ===========\r\n=========== lod_array_length ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== meshgrid ===========\r\n```",
        "state": "closed",
        "user": "luxu1220",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-16T09:41:40+00:00",
        "updated_at": "2025-05-28T02:53:42+00:00",
        "closed_at": "2025-05-28T02:53:41+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "luxu1220",
            "ghoshaw",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 558,
        "title": "paddle2onnx 模型转换失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n`paddle2onnx` 转化`PicoDet`轻量级检测模型，`backbone：ESNet_m`，最后转换失败，报错如下：\r\n```bash\r\nNotImplementedError:\r\nThere's 7 ops are not supported yet\r\n=========== lod_array_length ===========\r\n=========== conditional_block ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== meshgrid ===========\r\n=========== select_input ===========\r\n=========== write_to_array ===========\r\n=========== while ===========\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:paddledet 官方给出了paddlelite mnn ncnn 等推理框架的demo，自己想手动实现以下，对比一下性能优劣\r\n - 为什么需要转换为ONNX格式：当前希望测试ncnn推理框架（paddlelite 已经测试通过），对比推理速度。\r\n - Paddle2ONNX版本:Version: 0.9.0\r\n - 部分疑问：为什么官方提供了picodet 的onnx中间格式，自己转换缺提示op不支持，官方如何做的，谢谢解答。\r\n",
        "state": "closed",
        "user": "ChaoII",
        "closed_by": "ChaoII",
        "created_at": "2022-02-17T06:24:19+00:00",
        "updated_at": "2022-02-17T12:37:38+00:00",
        "closed_at": "2022-02-17T06:43:39+00:00",
        "comments_count": [
            "yeliang2258",
            "ChaoII",
            "yeliang2258",
            "ChaoII",
            "ChaoII",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 568,
        "title": "paddleslim量化之后，存在不支持OP，模型不能转化成onnx",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nRT\r\n\r\n\r\n**报错截图**\r\n\r\nλ b8dcbef621aa /workspace/PaddleSeg {release/2.3} paddle2onnx --model_dir output_quant_infer \\\r\n>    --model_filename model.pdmodel \\\r\n>    --params_filename model.pdiparams \\\r\n>    --opset_version 11 \\\r\n>    --save_file output_onnx/deeplabv3_int.onnx\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:45: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 184, in main\r\n    input_shape_dict=input_shape_dict)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 148, in program2onnx\r\n    operator_export_type=operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 84, in program2onnx\r\n    enable_onnx_checker, operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 34, in export_onnx\r\n    operator_export_type, verbose)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 240, in build\r\n    onnx_graph = ONNXGraph(paddle_graph, opset_version=opset_version, operator_export_type=operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 79, in __init__\r\n    self.update_opset_version()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 194, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(node_map, self.opset_version)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 129, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 2 ops are not supported yet\r\n=========== fake_channel_wise_quantize_dequantize_abs_max ===========\r\n=========== fake_quantize_dequantize_moving_average_abs_max ===========\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ztfmars",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-22T08:59:00+00:00",
        "updated_at": "2025-05-26T02:56:54+00:00",
        "closed_at": "2025-05-26T02:56:53+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "justld",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 562,
        "title": "paddle.onnx.export时output的name怎么修改",
        "body": "![image](https://user-images.githubusercontent.com/73732417/154678846-4827c7bd-c9a9-4b99-96b7-7a1b4b92654b.png)\r\n\r\n![image](https://user-images.githubusercontent.com/73732417/154678982-6061d164-6c5a-4af3-965e-a0819f7c9d98.png)\r\n\r\ninput的name可以这样设置为“image”，那output的name怎么设置呢？怎么把save_infer_model/scale_0.tmp_0修改成想要设置的name呢?\r\nx_spec = paddle.static.InputSpec(shape=[1, 3, 48, 192], dtype='float32', name=\"image\")\r\n\r\npytorch可以通过output_names设置，paddle的改怎么去设置呢\r\ntorch.onnx.export(model, args, f, export_params=True, verbose=False, training=False, input_names=None, output_names=None)",
        "state": "closed",
        "user": "Agino-ltp",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-18T12:01:50+00:00",
        "updated_at": "2025-05-26T02:56:55+00:00",
        "closed_at": "2025-05-26T02:56:54+00:00",
        "comments_count": [
            "jiangjiajun",
            "Agino-ltp",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 572,
        "title": "不支持视频分类模型Timesfomer的onnx转换",
        "body": "\r\n使用PaddleVideo框架训练Timesformer， 并使用Paddle2Onnx进行模型转换， 报错如下：\r\n\r\n  File \"/storage1/xxxx/anaconda/envs/py37pp/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 127, in get_recommend_opset_version\r\n    recommend_opset_version = OpMapper.check_support_status(node_map, opset_version, True)\r\n  File \"/storage1/xxxx/anaconda/envs/py37pp/lib/python3.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 168, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 4 ops are not supported yet\r\n=========== conditional_block ===========\r\n=========== logical_not ===========\r\n=========== select_input ===========\r\n=========== index_select ===========\r\n\r\n\r\n请问能解决这个问题吗",
        "state": "closed",
        "user": "dengfenglai321",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-23T06:47:29+00:00",
        "updated_at": "2025-05-24T02:46:25+00:00",
        "closed_at": "2025-05-24T02:46:24+00:00",
        "comments_count": [
            "dengfenglai321",
            "yeliang2258",
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 575,
        "title": "算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nThere's 2 ops are not supported yet\r\n=========== viterbi_decode ===========\r\n=========== linspace ===========\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "apexg",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-02-24T10:36:24+00:00",
        "updated_at": "2025-05-24T02:46:24+00:00",
        "closed_at": "2025-05-24T02:46:23+00:00",
        "comments_count": [
            "yeliang2258",
            "neonhuang",
            "Destiny-T",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 577,
        "title": "hello,我用paddle2onnx转换中文通用识别模型进行推理，发现模型只能预测出第一个位置就结束了，想问下是什么问题呢",
        "body": null,
        "state": "closed",
        "user": "Babysun-ljh",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-02-25T08:12:39+00:00",
        "updated_at": "2024-07-15T03:44:10+00:00",
        "closed_at": "2024-07-15T03:44:06+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 584,
        "title": "算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nThere's 1 ops are not supported yet\r\n=========== viterbi_decode ===========\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/42863415/156114929-87403940-9baa-415c-a390-42556bf652cd.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Destiny-T",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-03-01T06:12:25+00:00",
        "updated_at": "2025-05-23T02:51:55+00:00",
        "closed_at": "2025-05-23T02:51:54+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 588,
        "title": "picodet lcnet导出为onnx后精度降低很多",
        "body": "**问题描述**\r\n参照 https://aistudio.baidu.com/aistudio/projectdetail/3497217 教程，把epoch修改为300训练了一个picodet_lcnet_1_5x_416_coco模型。\r\n在paddledetection下  tools/infer.py 推理很准确。\r\n通过 Paddle2ONNX 导出 onnx后，摩托车精度下降一点，人体完全识别不出来，精度下降很多。\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:  onnxruntime https://gitee.com/atari/picodet-onnxruntime\r\n - Paddle2ONNX版本: paddle2onnx-0.9.1 with python>=2.7, paddlepaddle>=1.8.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n   paddledetection 下检测结果: moto 0.90   person 0.68\r\n![1595214506200933-1606467984- -motorcycle](https://user-images.githubusercontent.com/778353/156153054-70febe67-10b5-450b-ab0c-b344b97ba158.jpg)\r\n\r\n  Paddle2ONNX  转换后onnxruntime的结果:  moto 0.834 人体检测不到\r\n  \r\n![result](https://user-images.githubusercontent.com/778353/156153860-d8ab385b-a54a-4929-a75c-8c1d2b3553a3.jpg)\r\n\r\n    \r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ChungTak",
        "closed_by": "ChungTak",
        "created_at": "2022-03-01T10:39:38+00:00",
        "updated_at": "2022-03-03T08:36:28+00:00",
        "closed_at": "2022-03-03T08:36:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "ChungTak",
            "jiangjiajun",
            "ChungTak",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 598,
        "title": "what's the meaning of  \"releated\"?",
        "body": "linspace releated pull request https://github.com/PaddlePaddle/Paddle2ONNX/pull/470\r\n\r\nlike above, what's the meaning  of  releated? related ?\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "znsoftm",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-03T03:03:01+00:00",
        "updated_at": "2024-07-15T03:43:30+00:00",
        "closed_at": "2024-07-15T03:43:30+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 601,
        "title": "'BaseModel' object has no attribute 'to_static_state_dict'",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nI just upgraded from 0.9 to 0.9.1 and get the below error trace during export of my model.\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n   - paddlepaddle_gpu-2.1.2.post112-cp39-cp39-linux_x86_64.whl\r\n   - onnx==1.9.0\r\n   - onnxruntime-gpu==1.10.0\r\n - Why convert to onnx: for inference\r\n - Paddle2ONNX Version: 0.9.1\r\n - Email/Wechat/Phone: \r\n\r\n**Screenshots**\r\n\r\n```\r\n   paddle.onnx.export(\r\n    │      │    └ <function export at 0x7ff6fce4d700>\r\n    │      └ <module 'paddle.onnx' from '/usr/local/lib/python3.9/dist-packages/paddle/onnx/__init__.py'>\r\n    └ <module 'paddle' from '/usr/local/lib/python3.9/dist-packages/paddle/__init__.py'>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle/onnx/export.py\", line 100, in export\r\n    p2o.dygraph2onnx(\r\n    │   └ <function dygraph2onnx at 0x7ff56c6d0ca0>\r\n    └ <module 'paddle2onnx' from '/usr/local/lib/python3.9/dist-packages/paddle2onnx/__init__.py'>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle2onnx/convert.py\", line 167, in dygraph2onnx\r\n    paddle_graph = PaddleGraph.build_from_dygraph(layer, inner_input_spec,\r\n                   │           │                  │      └ None\r\n                   │           │                  └ BaseModel(\r\n                   │           │                      (backbone): ResNet(\r\n                   │           │                        (conv1_1): ConvBNLayer(\r\n                   │           │                          (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding=...\r\n                   │           └ <staticmethod object at 0x7ff56c71bf10>\r\n                   └ <class 'paddle2onnx.graph.paddle_graph.PaddleGraph'>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle2onnx/graph/paddle_graph.py\", line 271, in build_from_dygraph\r\n    program, feed_var_names, fetch_vars = dg_helper.get_program(\r\n                                          │         └ <function get_program at 0x7ff56c6ef0d0>\r\n                                          └ <module 'paddle2onnx.graph.dygraph_helper' from '/usr/local/lib/python3.9/dist-packages/paddle2onnx/graph/dygraph_helper.py'>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n           │      │       │        │        └ {}\r\n           │      │       │        └ (BaseModel(\r\n           │      │       │            (backbone): ResNet(\r\n           │      │       │              (conv1_1): ConvBNLayer(\r\n           │      │       │                (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding...\r\n           │      │       └ ()\r\n           │      └ <function get_program at 0x7ff56c6ef040>\r\n           └ <function wrap_decorator.<locals>.__impl__ at 0x7ff70a2f5940>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n           │             │       └ {}\r\n           │             └ (BaseModel(\r\n           │                 (backbone): ResNet(\r\n           │                   (conv1_1): ConvBNLayer(\r\n           │                     (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding...\r\n           └ <function _switch_to_static_graph_.<locals>.__impl__ at 0x7ff58a4f3ee0>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n    return func(*args, **kwargs)\r\n           │     │       └ {}\r\n           │     └ (BaseModel(\r\n           │         (backbone): ResNet(\r\n           │           (conv1_1): ConvBNLayer(\r\n           │             (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding...\r\n           └ <function get_program at 0x7ff56c6ef040>\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle2onnx/graph/dygraph_helper.py\", line 211, in get_program\r\n    dygraph_state_dict = inner_layer.to_static_state_dict()\r\n                         └ BaseModel(\r\n                             (backbone): ResNet(\r\n                               (conv1_1): ConvBNLayer(\r\n                                 (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding=...\r\n\r\n  File \"/usr/local/lib/python3.9/dist-packages/paddle/fluid/dygraph/layers.py\", line 1050, in __getattr__\r\n    return object.__getattribute__(self, name)\r\n                                   │     └ 'to_static_state_dict'\r\n                                   └ BaseModel(\r\n                                       (backbone): ResNet(\r\n                                         (conv1_1): ConvBNLayer(\r\n                                           (_pool2d_avg): AvgPool2D(kernel_size=1, stride=1, padding=...\r\n\r\nAttributeError: 'BaseModel' object has no attribute 'to_static_state_dict'\r\n```\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "SNeugber",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-04T07:32:53+00:00",
        "updated_at": "2024-07-15T03:43:46+00:00",
        "closed_at": "2024-07-15T03:43:39+00:00",
        "comments_count": [
            "yeliang2258",
            "SNeugber",
            "SNeugber"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 603,
        "title": "paddle2onnx 转 fairmot_dla34 模型时报错：ValueError: Support Offset[2] equal Offset[3], actually got Offset[2]==19, not equal Offset[3]==34",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n**使用 paddle2onnx 转 fairmot_dla34_30e_1088x608_headtracking21 模型时报错。**\r\n**版本信息如下：**\r\npaddle2onnx         0.9.1        \r\nonnx                      1.9.0          \r\nonnxruntime         1.10.0   \r\npaddlepaddle-gpu    2.2.2    \r\npaddledet             2.3.0          \r\npaddlehub            2.2.0          \r\npaddlelite             2.10 \r\n\r\n**报错信息如下：**\r\npaddle2onnx --model_dir fairmot_dla34_30e_1088x608_headtracking21  --model_filename model.pdmodel --params_filename model.pdiparams --save_file fairmot_dla34_30e_1088x608_headtracking21.onnx --opset_version 11 --enable_onnx_checker True\r\n\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n/usr/local/lib/python3.7/dist-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/usr/local/lib/python3.7/dist-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 195, in main\r\n    input_shape_dict=input_shape_dict)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/command.py\", line 159, in program2onnx\r\n    operator_export_type=operator_export_type)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 88, in program2onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/convert.py\", line 36, in export_onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 258, in build\r\n    auto_update_opset=auto_update_opset)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 85, in __init__\r\n    self.update_opset_version()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/graph/onnx_graph.py\", line 203, in update_opset_version\r\n    node_map, self.opset_version)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/op_mapper.py\", line 133, in get_recommend_opset_version\r\n    node.type](node)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/custom_paddle_op/deformable_conv.py\", line 40, in __init__\r\n    self.check_attribute(node)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/op_mapper/custom_paddle_op/deformable_conv.py\", line 34, in check_attribute\r\n    node.input_shape('Offset', 0), (2, 3), 'Offset', 'equal')\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle2onnx/utils.py\", line 126, in compare_attr_between_dims\r\n    raise ValueError(expect_info + actual_info)\r\nValueError: Support Offset[2] equal Offset[3], actually got Offset[2]==19, not equal Offset[3]==34.\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "mzxhzhp",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-03-04T09:06:44+00:00",
        "updated_at": "2025-05-23T02:51:53+00:00",
        "closed_at": "2025-05-23T02:51:53+00:00",
        "comments_count": [
            "yeliang2258",
            "mzxhzhp",
            "yeliang2258",
            "mzxhzhp",
            "yeliang2258",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 606,
        "title": "在linux把pdmodel转换成onnx失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n版本信息如下\r\npaddle2onnx 0.9.1\r\nonnx 1.9.0\r\nonnxruntime 1.10.0\r\npaddlepaddle 2.2.2\r\npaddlelite 2.10\r\n请在此处详细的描述报错信息\r\n在kali下运行shell：paddle2onnx --model_dir /home/kali  --model_filename MyCNN.pdmodel --params_filename MyCNN_.pdiparams --save_file onnx_file --opset_version 10 --enable_onnx_checker True\r\n报错\r\n/home/kali/.local/lib/python3.9/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/home/kali/.local/lib/python3.9/site-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/kali/.local/lib/python3.9/site-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/kali/.local/lib/python3.9/site-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\n/home/kali/.local/lib/python3.9/site-packages/onnx/helper.py:343: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\r\n  is_iterable = isinstance(value, collections.Iterable)\r\nKilled\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:我不知道是什么，但是我是用这个网站生成的https://aistudio.baidu.com/aistudio/projectdetail/2498526\r\n 生成模型用的是这个指令\r\nfrom x2paddle.convert import pytorch2paddle\r\npytorch2paddle(module=torch_module,\r\n               save_dir=\"./pd_model\",\r\n               jit_type=\"trace\",\r\n               input_examples=[torch_input])\r\n我用的数据库是这个https://aistudio.baidu.com/aistudio/datasetdetail/42610\r\n - 为什么需要转换为ONNX格式：为了安卓开发，需要转换成tensorflow lite\r\n - Paddle2ONNX版本:paddle2onnx 0.9.1\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n![VirtualBox_kali-linux-2022 1-virtualbox-amd64_05_03_2022_21_27_16](https://user-images.githubusercontent.com/83712510/156885101-85d07f8c-7bd7-46a4-a032-c55d8948397e.png)\r\n![VirtualBox_kali-linux-2022 1-virtualbox-amd64_05_03_2022_21_26_54](https://user-images.githubusercontent.com/83712510/156885113-11b8a13a-6944-485b-b8b9-1913bd9a3fee.png)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "liutheuniverse",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-05T13:30:20+00:00",
        "updated_at": "2024-05-22T05:20:04+00:00",
        "closed_at": "2024-05-22T05:20:04+00:00",
        "comments_count": [
            "jiangjiajun",
            "liutheuniverse",
            "liutheuniverse",
            "jiangjiajun",
            "liutheuniverse",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 612,
        "title": "【PaddlePaddle Hackathon 2】86、通过Paddle2ONNX打通6个Paddle模型到高通SNPE的部署",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 第二期活动的任务 ISSUE，更多详见 [【PaddlePaddle Hackathon 第二期】任务总览](https://github.com/PaddlePaddle/Paddle/issues/40234)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：通过Paddle2ONNX打通6个Paddle模型到高通SNPE的部署\r\n\r\n- 技术标签：Python、C++、Java\r\n\r\n- 任务难度：困难\r\n\r\n【详细描述】\r\n\r\n- 说明：将指定的6个模型部署到高通SNPE上，并出具详细部署指南。\r\n- 必要步骤，奖金根据完成度发放：\r\n  - 完成指定硬件的飞桨模型部署工作，流程包括\r\n    1. Paddle模型转ONNX格式\r\n    2. ONNX模型通过硬件厂商SDK转换为可在硬件上部署的模型文件\r\n    3. Python/C++的硬件部署模型代码（包括数据的前后处理）\r\n  - 其中第1步和第2步需要有明确的文档指引流程，参考RK文档部署指南\r\n  - 第3步根据目前Repo中model_zoo的模型列表进行部署代码开发，其中完成分类模型的适配，即达到30%的程度，在此基础上完成分割或检测，即达到50%的程度，完成所有四种任务模型的适配，即达到100%\r\n- 部署平台：高通SNPE\r\n- 部署模型：\r\n  - 3个OCR模型：ch_PP-OCRv2_det_infer、ch_PP-OCRv2_rec_infer、ch_ppocr_mobile_v2.0_cls_infer\r\n  - 1个seg模型：bisenet\r\n  - 1个det模型：picodet\r\n  - 1个classification模型：mobilenetv3\r\n- 模型下载链接可参考：https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/model_zoo\r\n\r\n【提交流程】\r\n\r\n- 模型部署相关代码和部署文档相关代码提交到 Paddle2ONNX Repo 的model_zoo分支 [Paddle2ONNX Repo](https://github.com/PaddlePaddle/Paddle2ONNX.git) \r\n- 部署模型分开提交，一个PR不超过2个模型的对齐脚本和文档\r\n\r\n【提交内容】\r\n\r\n- 部署相关代码\r\n- 部署文档\r\n\r\n【合入标准】\r\n\r\n- 模型在硬件平台上部署后的运行截图\r\n- 部署脚本和部署文档清晰明了，小白用户也可参考文档和脚本进行部署\r\n\r\n【技术要求】\r\n\r\n- 熟悉Python、C++、Java\r\n- 熟练部署基础\r\n\r\n【参考内容】\r\n\r\n- [高通SNPE的开发部署指南](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk)\r\n- [RK部署指南](https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/hardwares/rk)\r\n\r\n【答疑交流】\r\n\r\n- 如果在开发过程中对于上述任务有任何问题，欢迎在https://github.com/PaddlePaddle/Paddle2ONNX.git 上提issue\r\n- 对于开发中的共性问题，在活动过程中，会定期组织答疑，请大家关注官网&QQ群的通知，及时参与\r\n- 模型适配过程中，将会由百度的工程师全程在微信群中答疑，帮助大家解决适配过程中的问题",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:05:56+00:00",
        "updated_at": "2024-05-22T05:17:42+00:00",
        "closed_at": "2024-05-22T05:17:42+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 613,
        "title": "【PaddlePaddle Hackathon 2】85、通过Paddle2ONNX打通6个Paddle模型到苹果CoreML的部署",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 第二期活动的任务 ISSUE，更多详见 [【PaddlePaddle Hackathon 第二期】任务总览](https://github.com/PaddlePaddle/Paddle/issues/40234)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：通过Paddle2ONNX打通6个Paddle模型到苹果CoreML的部署\r\n\r\n- 技术标签：C++、Python、Object-c、Swift\r\n\r\n- 任务难度：困难\r\n\r\n【详细描述】\r\n\r\n- 说明：将指定的6个模型部署到苹果CoreML上，并出具详细部署指南。\r\n- 必要步骤，奖金根据完成度发放：\r\n  - 完成指定硬件的飞桨模型部署工作，流程包括\r\n    1. Paddle模型转ONNX格式\r\n    2. ONNX模型通过硬件厂商SDK转换为可在硬件上部署的模型文件\r\n    3. Python/C++的硬件部署模型代码（包括数据的前后处理）\r\n  - 其中第1步和第2步需要有明确的文档指引流程，参考RK文档部署指南\r\n  - 第3步根据目前Repo中model_zoo的模型列表进行部署代码开发，其中完成分类模型的适配，即达到30%的程度，在此基础上完成分割或检测，即达到50%的程度，完成所有四种任务模型的适配，即达到100%\r\n- 部署平台：苹果CoreML\r\n- 部署模型：\r\n  - 3个OCR模型：ch_PP-OCRv2_det_infer、ch_PP-OCRv2_rec_infer、ch_ppocr_mobile_v2.0_cls_infer\r\n  - 1个seg模型：bisenet\r\n  - 1个det模型：picodet\r\n  - 1个classification模型：mobilenetv3\r\n- 模型下载链接可参考：https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/model_zoo\r\n\r\n【提交流程】\r\n\r\n- 模型部署相关代码和部署文档相关代码提交到 Paddle2ONNX Repo 的model_zoo分支 [Paddle2ONNX Repo](https://github.com/PaddlePaddle/Paddle2ONNX.git) \r\n- 部署模型分开提交，一个PR不超过2个模型的对齐脚本和文档\r\n\r\n【提交内容】\r\n\r\n- 部署相关代码\r\n- 部署文档\r\n\r\n【合入标准】\r\n\r\n- 模型在硬件平台上部署后的运行截图\r\n- 部署脚本和部署文档清晰明了，小白用户也可参考文档和脚本进行部署\r\n\r\n【技术要求】\r\n\r\n- 熟悉C++、Python、Object-c、Swift\r\n- 熟练部署基础\r\n\r\n【参考内容】\r\n\r\n- [苹果CoreML的开发部署指南](https://developer.apple.com/documentation/coreml)\r\n- [RK部署指南](https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/hardwares/rk)\r\n\r\n【答疑交流】\r\n\r\n- 如果在开发过程中对于上述任务有任何问题，欢迎在https://github.com/PaddlePaddle/Paddle2ONNX.git 上提issue\r\n- 对于开发中的共性问题，在活动过程中，会定期组织答疑，请大家关注官网&QQ群的通知，及时参与\r\n- 模型适配过程中，将会由百度的工程师全程在微信群中答疑，帮助大家解决适配过程中的问题",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:07:47+00:00",
        "updated_at": "2024-05-22T05:17:37+00:00",
        "closed_at": "2024-05-22T05:17:37+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 609,
        "title": "支持asr 转 onnx model 吗",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "silencervan",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-03-07T07:37:27+00:00",
        "updated_at": "2025-05-19T02:57:57+00:00",
        "closed_at": "2025-05-19T02:57:55+00:00",
        "comments_count": [
            "yeliang2258",
            "silencervan",
            "yeliang2258",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 615,
        "title": "【PaddlePaddle Hackathon 2】83、为 Paddle2ONNX 新增25个OP",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 第二期活动的任务 ISSUE，更多详见 [【PaddlePaddle Hackathon 第二期】任务总览](https://github.com/PaddlePaddle/Paddle/issues/40234)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：为 Paddle2ONNX 新增25个OP\r\n\r\n- 技术标签：C++，Python\r\n\r\n- 任务难度：简单\r\n\r\n【详细描述】\r\n\r\nPaddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加10个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n25个 OP 具体为：\r\n\r\nlogical_and、logical_or、logical_xor、isfinite_v2、isinf_v2、isnan_v2、isnan、dot、erf、exp、log_softmax、elementwise_floordiv、mean、logsumexp、mul、affine_channel、bmm、p_norm、sum、floor、sin、sinh、log2、log10、log1p\r\n\r\n【提交流程】\r\n\r\n- OP开发和单测相关代码提交到 Paddle2ONNX Repo 的cpp分支 [Paddle2ONNX Repo](https://github.com/PaddlePaddle/Paddle2ONNX.git) 。\r\n- OP开发分开提交，每个PR不超过3个OP\r\n\r\n【提交内容】\r\n\r\n- OP开发代码文件\r\n- OP单测文件\r\n\r\n【合入标准】\r\n\r\n- 对齐Paddle2ONNX Python版本\r\n- 通过该OP的所有单测\r\n\r\n【技术要求】\r\n\r\n- 熟悉C++和Python\r\n- 熟练ONNX\r\n\r\n【参考内容】\r\n\r\n- [OP开发文档](https://github.com/PaddlePaddle/Paddle2ONNX/blob/cpp/docs/zh/Paddle2ONNX_Development_Guide.md)\r\n\r\n【答疑交流】\r\n\r\n- 如果在开发过程中对于上述任务有任何问题，欢迎在https://github.com/PaddlePaddle/Paddle2ONNX.git 上提issue\r\n- 对于开发中的共性问题，在活动过程中，会定期组织答疑，请大家关注官网&QQ群的通知，及时参与。",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:09:27+00:00",
        "updated_at": "2024-05-22T05:17:50+00:00",
        "closed_at": "2024-05-22T05:17:50+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 616,
        "title": "【PaddlePaddle Hackathon 2】82、为 Paddle2ONNX 新增25个 OP",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 第二期活动的任务 ISSUE，更多详见 [【PaddlePaddle Hackathon 第二期】任务总览](https://github.com/PaddlePaddle/Paddle/issues/40234)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：为 Paddle2ONNX 新增25个 OP\r\n\r\n- 技术标签：C++，Python\r\n\r\n- 任务难度：简单\r\n\r\n【详细描述】\r\n\r\nPaddle2ONNX为模型转换工具，负责将paddle的inference模型转换为ONNX格式，方便开发者将Paddle模型与其他基于ONNX的推理框架配合使用。Paddle2ONNX的底层将Paddle op逐一转换为ONNX对应op，最终生成ONNX格式模型。请帮助 Paddle2ONNX增加25个 OP支持。在转换过程中，支持多个ONNX版本协议，以提升飞桨模型适配硬件的能力.\r\n\r\n25个 OP 具体为：\r\n\r\nabs、acos、asin、atan、brelu、tan、ceil、cosh、cos、linspace、\r\n\r\ndist、greater_equal、not_equal、greater_than、less_equal、less_than、reciprocal、thresholded_relu、norm、round、\r\n\r\nshape、size、tile、range、square\r\n\r\n【提交流程】\r\n\r\n- OP开发和单测相关代码提交到 Paddle2ONNX Repo 的cpp分支 [Paddle2ONNX Repo](https://github.com/PaddlePaddle/Paddle2ONNX.git) 。\r\n- OP开发分开提交，每个PR不超过3个OP\r\n\r\n【提交内容】\r\n\r\n- OP开发代码文件\r\n- OP单测文件\r\n\r\n【合入标准】\r\n\r\n- 对齐Paddle2ONNX Python版本\r\n- 通过该OP的所有单测\r\n\r\n【技术要求】\r\n\r\n- 熟悉C++和Python\r\n- 熟练ONNX\r\n\r\n【参考内容】\r\n\r\n- [OP开发文档](https://github.com/PaddlePaddle/Paddle2ONNX/blob/cpp/docs/zh/Paddle2ONNX_Development_Guide.md)\r\n\r\n【答疑交流】\r\n\r\n- 如果在开发过程中对于上述任务有任何问题，欢迎在https://github.com/PaddlePaddle/Paddle2ONNX.git 上提issue\r\n- 对于开发中的共性问题，在活动过程中，会定期组织答疑，请大家关注官网&QQ群的通知，及时参与。",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:10:17+00:00",
        "updated_at": "2024-05-22T05:17:46+00:00",
        "closed_at": "2024-05-22T05:17:46+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 614,
        "title": "【PaddlePaddle Hackathon 2】84、通过Paddle2ONNX打通6个Paddle模型到RK3588的部署",
        "body": "（此 ISSUE 为 PaddlePaddle Hackathon 第二期活动的任务 ISSUE，更多详见 [【PaddlePaddle Hackathon 第二期】任务总览](https://github.com/PaddlePaddle/Paddle/issues/40234)）\r\n\r\n【任务说明】\r\n\r\n- 任务标题：通过Paddle2ONNX打通6个Paddle模型到RK3588的部署\r\n- 技术标签：Python\r\n- 任务难度：中等\r\n\r\n【详细描述】\r\n\r\n- 说明：将指定的5个模型部署到指定的平台上，并出具详细部署指南。\r\n- 必要步骤，奖金根据完成度发放：\r\n    - 完成指定硬件的飞桨模型部署工作，流程包括\r\n        1. Paddle模型转ONNX格式\r\n        2. ONNX模型通过硬件厂商SDK转换为可在硬件上部署的模型文件\r\n        3. Python/C++的硬件部署模型代码（包括数据的前后处理）\r\n        4. 跑通模型量化，提供清晰的量化指南文档，以及表格数据记录量化带来的精度损失  \r\n        5. 非量化/量化下的耗时记录\r\n    - 其中第1步和第2步需要有明确的文档指引流程，参考RK部署指导文档\r\n    - 第3步根据目前Repo中model_zoo的模型列表进行部署代码开发，在此基础上完成分割或检测，即达到30%的程度，完成所有三种任务模型的适配，即达到60%的程度，完成量化和耗时测试等记录，即达到100%\r\n- 部署平台：RK3588\r\n- 部署模型：\r\n  - 3个OCR模型：ch_PP-OCRv2_det_infer、ch_PP-OCRv2_rec_infer、ch_ppocr_mobile_v2.0_cls_infer\r\n  - 2个seg模型：bisenet、PP_HumanSeg\r\n  - 1个det模型：picodet\r\n- 模型下载链接可参考：https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/model_zoo\r\n\r\n【提交流程】\r\n\r\n- 模型部署相关代码和部署文档相关代码提交到 Paddle2ONNX Repo 的model_zoo分支 [Paddle2ONNX Repo](https://github.com/PaddlePaddle/Paddle2ONNX.git) \r\n- 部署模型分开提交，一个PR不超过2个模型的对齐脚本和文档\r\n\r\n【提交内容】\r\n\r\n- 部署相关代码\r\n- 部署文档\r\n\r\n【合入标准】\r\n\r\n- 模型在硬件平台上部署后的运行截图\r\n- 部署脚本和部署文档清晰明了，小白用户也可参考文档和脚本进行部署\r\n\r\n【技术要求】\r\n\r\n- python\r\n- 熟练部署基础\r\n\r\n【参考内容】\r\n\r\n- [RK3588开发文档](https://github.com/rockchip-linux/rknn-toolkit2)\r\n- [RK部署指南](https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/hardwares/rk)\r\n\r\n【答疑交流】\r\n\r\n- 如果在开发过程中对于上述任务有任何问题，欢迎在https://github.com/PaddlePaddle/Paddle2ONNX.git 上提issue\r\n- 对于开发中的共性问题，在活动过程中，会定期组织答疑，请大家关注官网&QQ群的通知，及时参与\r\n- 模型适配过程中，将会由百度的工程师全程在微信群中答疑，帮助大家解决适配过程中的问题",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:08:48+00:00",
        "updated_at": "2024-05-22T05:17:28+00:00",
        "closed_at": "2024-05-22T05:17:28+00:00",
        "comments_count": [
            "unseenme",
            "jiangjiajun"
        ],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 617,
        "title": "【PaddlePaddle Hackathon 2】Paddle2ONNX 任务合集 ",
        "body": "大家好，非常高兴地告诉大家，第二期 [PaddlePaddle Hackathon](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon-2022-3?fr=paddle2onnx) 开始了。PaddlePaddle Hackathon 是面向全球开发者的深度学习领域编程活动，鼓励开发者了解与参与 PaddlePaddle 开源社区。本次共有四大专区：PaddlePaddle、Paddle Family、Paddle Friends、Paddle Eval，共计100+个任务供大家认领。详细信息可以参考 [PaddlePaddle Hackathon 说明](https://www.paddlepaddle.org.cn/contributionguide?docPath=hackathon_cn)。大家是否已经迫不及待了呢~\r\n\r\n本 ISSUE 是 Paddle Family 专区 Paddle2ONNX 方向任务合集。具体任务列表如下：\r\n\r\n| 序号 | 难度 | 任务 ISSUE |\r\n| ---- | ---- | --- | \r\n| 82 | ⭐️ | [为 Paddle2ONNX 新增25个 OP](https://github.com/PaddlePaddle/Paddle2ONNX/issues/616) |\r\n| 83 | ⭐️ | [为 Paddle2ONNX 新增25个OP](https://github.com/PaddlePaddle/Paddle2ONNX/issues/615) |\r\n| 84 | ⭐️⭐️ | [通过Paddle2ONNX打通6个Paddle模型到RK3568的部署](https://github.com/PaddlePaddle/Paddle2ONNX/issues/614) |\r\n| 85 | ⭐️⭐️⭐️ | [通过Paddle2ONNX打通6个Paddle模型到苹果CoreML的部署](https://github.com/PaddlePaddle/Paddle2ONNX/issues/613) |\r\n| 86 | ⭐️⭐️⭐️ | [通过Paddle2ONNX打通6个Paddle模型到高通SNPE的部署](https://github.com/PaddlePaddle/Paddle2ONNX/issues/612) |\r\n\r\n若想要认领本次活动任务，请至 [PaddlePaddle Hackathon 2 Pinned ISSUE](https://github.com/PaddlePaddle/Paddle/issues/40234) 完成任务 ISSUE 认领。\r\n\r\n活动官网：[PaddlePaddle Hackathon 2](https://www.paddlepaddle.org.cn/PaddlePaddleHackathon-2022-3?fr=paddle2onnx)",
        "state": "closed",
        "user": "TCChenlong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-08T11:49:07+00:00",
        "updated_at": "2024-05-22T05:17:54+00:00",
        "closed_at": "2024-05-22T05:17:54+00:00",
        "comments_count": [],
        "labels": [
            "PaddlePaddle Hackathon"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 628,
        "title": "【Hackathon 2】ONNX转SNPE，有算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n以下模型存在不支持转SNPE的算子\r\n\r\n```\r\npicodet_l_640_coco.onnx \r\nmobilenetv3.onnx\r\nch_PP-OCRv2_rec_infer.onnx\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:SNPE 1.59.0\r\n - 为什么需要转换为ONNX格式：ONNX转SNPE\r\n - Paddle2ONNX版本:未知（ONNX模型下载自https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/model_zoo）\r\n - 你的联系方式(Email/Wechat/Phone):unseenme@163.com\r\n\r\n**报错截图**\r\n\r\n```\r\n    \"Op is most likely not supported by the converter.\" % op_type)\r\nKeyError: 'No translation registered for op type onnx_hardsigmoid. Op is most likely not supported by the converter.'\r\n2022-03-14 22:26:52,823 - 209 - ERROR - Node HardSigmoid_0: 'No translation registered for op type onnx_hardsigmoid. Op is most likely not supported by the converter.'\r\n```\r\n\r\n**其他信息**\r\n更换其他模型用于部署到SNPE？\r\n修改Paddle2ONNX，回避不支持算子？",
        "state": "closed",
        "user": "unseenme",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-15T00:10:35+00:00",
        "updated_at": "2024-07-15T03:42:52+00:00",
        "closed_at": "2024-07-15T03:42:47+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 627,
        "title": "导出语音合成模型 fastspeech2 存在不支持 op",
        "body": "NotImplementedError:\r\nThere's 4 ops are not supported yet\r\n=========== conditional_block ===========\r\n=========== set_value ===========\r\n=========== share_data ===========\r\n=========== while ===========\r\n\r\n同样调查 issue ，发现导出 speedyspeech 也存在不支持 op\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/471\r\n\r\n目前已实验可以直接的语音合成模型：\r\n声学模型：\r\nNone, 因为 SpeedySpeech 和 Fastspeech2 都不支持，Tacotron2 和 Transformer TTS 的控制流更加显式，肯定不支持\r\n声码器：\r\nHIFIGAN\r\n其余 GAN Vocoder 未测试，但是 WaveRNN 肯定更不支持\r\n\r\n\r\n面临的困难：\r\nfastspeech2 暂时 TRT 走不通，HIFIGAN TRT 可以走通，但是由于有很多 unsqueeze 算子，导致进 TRT 的算子很少\r\n\r\n暂时的解法：\r\n使用朴素 PaddleInference 推理 fastspeech2 + onnx run time 推理 HIFIGAN\r\n\r\n需求：\r\n希望可以考虑支持 while 等控制流，因为控制流在语音任务中很常见\r\n\r\n相关 issue:\r\n[Paddle2onnx 转化Paddledetection的fasterrcnn模型出现ops不支持错误](https://github.com/PaddlePaddle/Paddle2ONNX/issues/462)",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "yt605155624",
        "created_at": "2022-03-14T09:43:18+00:00",
        "updated_at": "2022-04-18T06:42:51+00:00",
        "closed_at": "2022-04-18T06:42:51+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 621,
        "title": "能不能支持一下paddle的模型转换的tensorflow？",
        "body": "**问题描述**\r\n请在此处详细的描述报错信息\r\n请问一下，业务中已经使用tensorflow部署了模型，但是新的模型是使用paddlepaddle进行训练的，部署想继续使用tensorflow的部署方案，想问一下有没有计划支持一下paddle模型转换为tensorflow的格式，比如saved_mode之类的\r\n\r\n",
        "state": "closed",
        "user": "thomaszheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-10T09:31:56+00:00",
        "updated_at": "2024-07-15T03:40:58+00:00",
        "closed_at": "2024-07-15T03:40:50+00:00",
        "comments_count": [
            "jiangjiajun",
            "thomaszheng",
            "jiangjiajun",
            "thomaszheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 620,
        "title": "模型转onnx报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n在转换模型的时候报错\r\n环境：\r\nonnx==1.7.0\r\npaddle2onnx==0.9.1\r\n#####\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n命令：\r\npaddle2onnx --model_dir ./output_dev18_pexp01/output/ --save_file ./convert_model_pexp01.onnx --\r\nopset_version 11\r\n报错：\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python2.7.15/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/command.py\", line 195, in main\r\n    input_shape_dict=input_shape_dict)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/command.py\", line 159, in program2onnx\r\n    operator_export_type=operator_export_type)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/convert.py\", line 88, in program2onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/convert.py\", line 36, in export_onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 262, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/graph/onnx_graph.py\", line 209, in build_op_nodes\r\n    OpMapper.mapping(self, node, self.operator_export_type)\r\n  File \"/usr/local/python2.7.15/lib/python2.7/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 124, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['pool2d_0'] to onnx, which op_type is 'pool2d' with inputs: {u'X': [u'batch_norm_0.tmp_3']} and outputs: {u'Out': [u'pool2d_0.tmp_0']}, specific error: 'module' object has no attribute 'float32'\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone): \r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "wickai",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-10T04:34:11+00:00",
        "updated_at": "2024-05-22T05:18:10+00:00",
        "closed_at": "2024-05-22T05:18:06+00:00",
        "comments_count": [
            "wickai",
            "yeliang2258",
            "shixinlishixinli",
            "jiangjiajun",
            "shixinlishixinli",
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 629,
        "title": "请问paddlehub中的模型FCN_HRNet_W18_Face_Seg怎么转成onnx格式",
        "body": "paddlepaddle-gpu==0.0.0.post110\r\npaddlehub==2.1.1\r\n\r\n以下方式都失败了：\r\n方式1：\r\nimport paddlehub as hub\r\n\r\nhuman_seg = hub.Module(name=\"FCN_HRNet_W18_Face_Seg\")\r\nhuman_seg.save_inference_model(dirname=\"output/\",\r\nmodel_filename=\"output/inference.pdmodel\",\r\nparams_filename=\"output/inference.pdiparams\")\r\n报错：RuntimeError: Module FCN_HRNet_W18_Face_Seg lacks input_spec, please specify it when calling save_inference_model.\r\n\r\n方式2：\r\nimport paddlehub as hub\r\nimport paddle\r\n\r\nhuman_seg = hub.Module(name=\"FCN_HRNet_W18_Face_Seg\")\r\nhuman_seg.save_inference_model(dirname=\"output/\",\r\nmodel_filename=\"output/inference.pdmodel\",\r\nparams_filename=\"output/inference.pdiparams\",\r\ninput_spec=[None, 3, 384, 384])\r\n报错：ValueError: The decorated function forward requires 0 arguments: [], but received 4 with (None, 3, 384, 384).\r\n\r\n方式3：\r\nimport paddlehub as hub\r\nimport paddle\r\n\r\nhuman_seg = hub.Module(name=\"FCN_HRNet_W18_Face_Seg\")\r\ninput_spec = paddle.static.InputSpec(shape=[None, 3, 384, 384], dtype='float32', name='FCN_HRNet_W18_Face_Seg')\r\npaddle.onnx.export(human_seg, 'model', input_spec=[input_spec], opset_version=11)\r\n报错：ValueError: The decorated function forward requires 0 arguments: [], but received 1 with (InputSpec(shape=(-1, 3, 384, 384), dtype=paddle.float32, name=FCN_HRNet_W18_Face_Seg),).\r\n\r\n另外也尝试过网上能找到的一些模型加载后再保存的方式都失败，请问有转换成功的可以分享下吗？\r\npaddle2onnx的转换对只有一个seg_model_384.pdparams模型文件的怎么转换呢？\r\nPaddleSeg中利用export.py转模型需要传configs的,yml文件，没有FCN_HRNet_W18_Face_Seg的。",
        "state": "closed",
        "user": "471417367",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-03-15T02:14:12+00:00",
        "updated_at": "2025-05-18T02:57:33+00:00",
        "closed_at": "2025-05-18T02:57:32+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "471417367",
            "yeliang2258",
            "471417367",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 638,
        "title": "Whether the PP-LCNET model can be onNX transformed  ",
        "body": "Whether the PP-LCNET model can be ONNX transformed  ?\r\nCould you please tell me how to carry out transformation? I am a newcomer in this field, and I hope you can guide me. Thank you very much !",
        "state": "closed",
        "user": "HDU-CarryStar",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-17T14:21:50+00:00",
        "updated_at": "2024-06-24T06:36:05+00:00",
        "closed_at": "2024-06-24T06:36:05+00:00",
        "comments_count": [
            "yeliang2258",
            "HDU-CarryStar",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 642,
        "title": "关于Paddle转ONNX暂未实现的算子",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n在准备将paddle inference模型yolov3_mobilenet_v3_large_ssld_270e_voc导出成onnx时，出现”不支持的算子“错误，总共有两个算子，分别是\r\nmulticlass_nms3\r\nnearest_interp_v2\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: paddle inference -> onnx -> openvino\r\n - 为什么需要转换为ONNX格式：准备做CPU端加速推理\r\n - Paddle2ONNX版本: 0.9.1\r\n - 你的联系方式(Email/Wechat/Phone):  1724980715@qq.com\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/52724359/159129295-0e236086-3721-48b3-a427-0240d70123a6.png)\r\n\r\n\r\n**其他信息**\r\n希望可以补上这两个算子，谢谢。",
        "state": "closed",
        "user": "RelayZ",
        "closed_by": "RelayZ",
        "created_at": "2022-03-19T16:18:41+00:00",
        "updated_at": "2022-03-20T08:22:46+00:00",
        "closed_at": "2022-03-20T08:22:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "RelayZ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 640,
        "title": "关于paddleOCR转onnx格式后的推理代码",
        "body": "在研究PaddleOCR转onnx格式过程中看到以下教程，请问哪里可以找到onnx_inference目录下的代码文件？\r\nhttps://aistudio.baidu.com/aistudio/projectdetail/1479970",
        "state": "closed",
        "user": "471417367",
        "closed_by": "471417367",
        "created_at": "2022-03-18T07:51:47+00:00",
        "updated_at": "2022-03-18T08:09:58+00:00",
        "closed_at": "2022-03-18T08:09:58+00:00",
        "comments_count": [
            "jiangjiajun",
            "471417367",
            "471417367"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 653,
        "title": "如果固定导出onnx时batch大小，目前都是-1",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n导出onnx时如果固定batch大小，目前导出detection那边的模型shape都是 [-1,c,h,w], 如何能固定batch大小，谢谢！\r\n导出时命令行如果指定 input shape 为 {'image':[1,3,256,256]}，此时导出的onnx输入是固定batch了，但输出shape还是[-1,n]\r\n\r\n**更多信息 :**\r\n无\r\n\r\n**报错截图**\r\n![图片](https://user-images.githubusercontent.com/10088733/160374545-87880266-4a30-4ccd-a5c0-a0255319b3b3.png)\r\n\r\n\r\n**其他信息**\r\n无",
        "state": "closed",
        "user": "BackT0TheFuture",
        "closed_by": "BackT0TheFuture",
        "created_at": "2022-03-28T09:44:59+00:00",
        "updated_at": "2022-08-17T06:27:29+00:00",
        "closed_at": "2022-08-17T06:27:29+00:00",
        "comments_count": [
            "yeliang2258",
            "jiangjiajun",
            "BackT0TheFuture",
            "FL77N",
            "datalee",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 654,
        "title": "地平线板端部署",
        "body": "目前PP-LCNet或者PicoDet转换的onnx模型支持在地平线开发板上部署吗？会不会模型验证不通过 ？请各位指点",
        "state": "closed",
        "user": "HDU-CarryStar",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-28T13:15:57+00:00",
        "updated_at": "2024-06-05T06:11:10+00:00",
        "closed_at": "2024-06-05T06:11:10+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 659,
        "title": "paddle2onnx导出ppyoloe",
        "body": "使用命令`paddle2onnx --model_dir output_inference/ppyoloe_crn_s_300e_voc --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file ppyoloe_crn_s_300e_voc.onnx`导出onnx，输入有两个，输出也有两个，这是否正常？该如何预测？感觉shape都不是很正常。\r\n![微信图片_20220331011216](https://user-images.githubusercontent.com/53975909/160892871-09c470ce-bbb7-4fe0-aafc-4e178e749cfa.png)\r\n![微信图片_20220331011226](https://user-images.githubusercontent.com/53975909/160892875-886335c9-2db7-4bb1-aa06-c76c1716fc41.png)\r\n",
        "state": "closed",
        "user": "Monday-Leo",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-30T17:12:51+00:00",
        "updated_at": "2024-06-24T06:35:36+00:00",
        "closed_at": "2024-06-24T06:35:36+00:00",
        "comments_count": [
            "yeliang2258",
            "Monday-Leo",
            "yeliang2258",
            "Monday-Leo",
            "jiangjiajun",
            "Monday-Leo",
            "Monday-Leo",
            "Monday-Leo",
            "yuexiayiren159aaa",
            "Monday-Leo",
            "jiangjiajun",
            "Monday-Leo",
            "jiangjiajun",
            "Monday-Leo",
            "Monday-Leo",
            "Monday-Leo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 661,
        "title": "[Question]什么时候支持OCRV2 转换ONNX?",
        "body": "我没有看到官方模型列表中支持ocr-v2 版本\r\n\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/model_zoo.md\r\n\r\n![image](https://user-images.githubusercontent.com/16729017/161016342-2f0eca8c-8051-4140-a85e-15ecc8150a98.png)\r\n\r\n\r\n请问什么时候提供支持？",
        "state": "closed",
        "user": "shelllet",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-03-31T08:52:04+00:00",
        "updated_at": "2024-06-24T06:35:58+00:00",
        "closed_at": "2024-06-24T06:35:58+00:00",
        "comments_count": [
            "jiangjiajun",
            "shelllet"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 664,
        "title": "Paddle导出onnx时候去掉后处理",
        "body": "使用\r\npython tools/export_model.py -c configs/ppyolo/ppyolo_tiny_650e_coco.yml \\\r\n                            -o weights=weights/ppyolo_tiny_650e_coco.pdparams \\\r\n                            TestReader.inputs_def.image_shape=[3,416,416] \\\r\n                            --output_dir inference_model\r\n\r\n\r\n\r\npaddle2onnx --model_dir inference_model/ppyolo_tiny_650e_coco \\\r\n --model_filename inference_model/ppyolo_tiny_650e_coco/model.pdmodel \\\r\n--params_filename inference_model/ppyolo_tiny_650e_coco/model.pdiparams \\\r\n--save_file inference_model/ppyolo_tiny_650e_coco/ppyolo3.onnx \\\r\n--enable_onnx_checker True\r\n\r\n![image](https://user-images.githubusercontent.com/102778714/161187109-1b7e3153-4c7c-474b-89a2-4f60aa8cc9b1.png)\r\n# 我想导出成下main的格式onnx\r\n![image](https://user-images.githubusercontent.com/102778714/161187176-86e98dee-d658-4428-b7db-1a6f7ceda9b5.png)\r\n",
        "state": "closed",
        "user": "yuexiayiren159aaa",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-04-01T03:04:36+00:00",
        "updated_at": "2024-06-04T07:06:44+00:00",
        "closed_at": "2024-06-04T07:06:39+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Utils(ONNX)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 665,
        "title": "Paddle导出onnx模型",
        "body": "# 这是我使用导出onnx的命令\r\npython tools/export_model.py -c configs/ppyolo/ppyolo_tiny_650e_coco.yml \\\r\n                            -o weights=weights/ppyolo_tiny_650e_coco.pdparams \\\r\n                            TestReader.inputs_def.image_shape=[3,416,416] \\\r\n                            --output_dir inference_model\r\n\r\npaddle2onnx --model_dir inference_model/ppyolo_tiny_650e_coco/ \\\r\n--model_filename ppyolo_tiny_650e_coco/model.pdmodel \\\r\n--params_filename ppyolo_tiny_650e_coco/model.pdiparams \\\r\n--save_file inference_model/ppyolo_tiny_650e_coco/ppyolo_123.onnx \\\r\n--opset_version 11 \\\r\n--enable_onnx_checker True \\\r\n--input_shape_dict \"{'image': [1, 3, 416, 416]}\"\r\n\r\n# 下面是我导出的onnx\r\n![image](https://user-images.githubusercontent.com/102778714/161190835-936bbe84-0676-4438-94b5-1780bf78c474.png)\r\n![image](https://user-images.githubusercontent.com/102778714/161190862-3d720dc4-1589-4558-a8ca-5fcdb5f72ba9.png)\r\n# 我想导出成下面格式的onnx，输出和yolo的输出是一样的。\r\n![image](https://user-images.githubusercontent.com/102778714/161190975-c3e157ac-cf08-4149-800e-16acfab42d5d.png)\r\n![image](https://user-images.githubusercontent.com/102778714/161191007-a792c607-6ade-46be-acc0-fcab26f0476d.png)\r\n\r\n",
        "state": "closed",
        "user": "yuexiayiren159aaa",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-04-01T03:42:40+00:00",
        "updated_at": "2025-05-16T02:52:54+00:00",
        "closed_at": "2025-05-16T02:52:53+00:00",
        "comments_count": [
            "HuaiguangLiu",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 666,
        "title": "Worse output in Onnx compared to Predict by Paddle",
        "body": "I have trained a new model and tested the output with paddles predict scripts as well within Onnx runtime. However I get worse results Onnx, the class prediction is much less precise and looks very bad. This is independent from the model type, ort version or opset version.\r\nThe only difference I can imagine is the input step. Maybe the input data is not normalized well enough, however I can not find any documentation how to format the input accordingly can you give an example of an input normalization step of an image? What is the expected band ordering? (RGB vs. BGR)\r\n\r\n - Inference engine for deployment: Onnx runtime for Java 1.10.0 (Opset version 15)\r\n - Paddle2ONNX Version: 0.9.2\r\n",
        "state": "closed",
        "user": "thhart",
        "closed_by": "jiangjiajun",
        "created_at": "2022-04-01T14:26:36+00:00",
        "updated_at": "2022-07-27T10:46:20+00:00",
        "closed_at": "2022-07-27T10:46:20+00:00",
        "comments_count": [
            "thhart",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 668,
        "title": "paddlenlp.transformers系列模型转ONNX报错",
        "body": "\r\n下的模型有5个文件：\r\nmodel_config.json\r\nmodel_state.pdparams\r\nsentencepiece.bpe.model\r\ntokenizer_config.json\r\ntraining_args.bin\r\n\r\n环境：\r\npaddle2onnx==0.9.1\r\n\r\n运行命令：\r\npaddle2onnx --model_dir PP-Layout_v1.0_ser_pretrained --model_filename sentencepiece.bpe.model --params_filename model_state.pdparams --save_file ser_pretrained.onnx --opset_version 12\r\n\r\n报错：\r\nTraceback (most recent call last):\r\nFile \"/usr/local/bin/paddle2onnx\", line 8, in\r\nsys.exit(main())\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/command.py\", line 195, in main\r\ninput_shape_dict=input_shape_dict)\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle2onnx/command.py\", line 120, in program2onnx\r\nparams_filename=params_filename)\r\nFile \"\", line 2, in load_inference_model\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in impl\r\nreturn wrapped_func(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/framework.py\", line 238, in impl\r\nreturn func(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/io.py\", line 1592, in load_inference_model\r\nprogram = Program.parse_from_string(program_desc_str)\r\nFile \"/usr/local/lib/python3.6/dist-packages/paddle/fluid/framework.py\", line 5312, in parse_from_string\r\np.desc = core.ProgramDesc(binary_str)\r\nValueError: (InvalidArgument) Failed to parse program_desc from binary string.\r\n[Hint: Expected desc_.ParseFromString(binary_str) == true, but received desc_.ParseFromString(binary_str):0 != true:1.] (at /paddle/paddle/fluid/framework/program_desc.cc:103)",
        "state": "closed",
        "user": "471417367",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-04-02T07:05:02+00:00",
        "updated_at": "2024-07-15T03:40:28+00:00",
        "closed_at": "2024-07-15T03:40:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "471417367",
            "Aurelius84",
            "471417367",
            "0x45f",
            "471417367"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 691,
        "title": "paddlex1.3.11 yolov3转onnx 报错",
        "body": "使用paddlex1.3.11训练的模型 然后转换成inference格式 然后使用paddle2onnx转换报错如下：\r\n![0c4c017d06af43aa619928bb5621249](https://user-images.githubusercontent.com/46195295/163600466-e6fdf5c8-3c64-4a7a-8f27-e6b72871b59a.png)\r\n详细内容：\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\nW0416 01:09:32.105561   996 init.cc:143] Compiled with WITH_GPU, but no GPU found in runtime.\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:312: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\r\n  \"You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\"\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/command.py\", line 280, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/command.py\", line 162, in program2onnx\r\n    model_dir, exe)\r\n  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-119>\", line 2, in load_inference_model\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 238, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1597, in load_inference_model\r\n    load_persistables(executor, load_dirname, program, params_filename)\r\n  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-117>\", line 2, in load_persistables\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 220, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1094, in load_persistables\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 844, in load_vars\r\n    filename=filename)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 961, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1246, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1244, in run\r\n    return_merged=return_merged)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1374, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1464, in _run_program\r\n    [fetch_var_name])\r\nRuntimeError: In user code:\r\n\r\n    File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 8, in <module>\r\n      sys.exit(main())\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/command.py\", line 280, in main\r\n      auto_update_opset=args.enable_auto_update_opset)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/command.py\", line 162, in program2onnx\r\n      model_dir, exe)\r\n    File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-119>\", line 2, in load_inference_model\r\n      \r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 238, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1597, in load_inference_model\r\n      load_persistables(executor, load_dirname, program, params_filename)\r\n    File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-117>\", line 2, in load_persistables\r\n      \r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 220, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1094, in load_persistables\r\n      filename=filename)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 844, in load_vars\r\n      filename=filename)\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py\", line 890, in load_vars\r\n      attrs={'file_path': os.path.join(dirname, new_var.name)})\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3184, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2224, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    UnavailableError: Load operator fail to open file inference_model/yolo_block.0.tip.bn.var, please check whether the model file is complete or damaged.\r\n      [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] (at /paddle/paddle/fluid/operators/load_op.h:41)\r\n      [operator < load > error]\r\n请问是咋回事 有没有什么办法？",
        "state": "closed",
        "user": "axdo",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-04-15T17:13:57+00:00",
        "updated_at": "2024-07-15T03:40:15+00:00",
        "closed_at": "2024-07-15T03:40:12+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 686,
        "title": "得到的onnx是int64的weight",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n![image](https://user-images.githubusercontent.com/53338761/163367160-737cd956-0f8b-478b-87f4-4fb5c83f9406.png)\r\n目前转出来的onnx是int64的格式是吗？有接口可以自己定义吗？\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\nzhaoxin34@baidu.com\r\n",
        "state": "closed",
        "user": "xinliyangguang",
        "closed_by": "jiangjiajun",
        "created_at": "2022-04-14T10:29:51+00:00",
        "updated_at": "2022-07-25T08:07:54+00:00",
        "closed_at": "2022-07-25T08:07:54+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 697,
        "title": "Ds2 Offline Aishell ASR0 Model转换成onnx模型失败 ",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述\r\n我试着把[Ds2 Offline Aishell ASR0 Model](https://paddlespeech.bj.bcebos.com/s2t/aishell/asr0/asr0_deepspeech2_aishell_ckpt_0.1.1.model.tar.gz)的模型转换成onnx格式，转换失败，有几个ops不支持。\r\n执行命令为：\r\n    paddle2onnx --model_dir ./deepspeech_aishell/exp/deepspeech2/checkpoints \\\r\n            --model_filename ./deepspeech_aishell/exp/deepspeech2/checkpoints/avg_1.jit.pdmodel \\\r\n            --params_filename ./deepspeech_aishell/exp/deepspeech2/checkpoints/avg_1.jit.pdiparams --save_file onnx_file\r\n结果如下：\r\n  NotImplementedError:\r\nThere's 4 ops are not supported yet\r\n=========== sequence_mask ===========\r\n=========== reverse ===========\r\n=========== rnn_memory_helper ===========\r\n=========== recurrent ===========\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:   onnx\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:   paddle2onnx ==0.9.4   paddlepaddle == 2.2.2\r\n\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n   \r\n![image](https://user-images.githubusercontent.com/101306105/163771808-6db95d40-3bcd-4f21-a02c-6d17229536b2.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "xwu55",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-04-18T07:21:01+00:00",
        "updated_at": "2025-05-14T02:51:07+00:00",
        "closed_at": "2025-05-14T02:51:06+00:00",
        "comments_count": [
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 699,
        "title": "不支持的算子是否有计划添加",
        "body": "\r\nThere's 7 ops are not supported yet\r\n=========== while ===========\r\n=========== write_to_array ===========\r\n=========== conditional_block ===========\r\n=========== lod_array_length ===========\r\n=========== select_input ===========\r\n=========== generate_proposals_v2 ===========\r\n=========== tensor_array_to_tensor ===========\r\n\r\npaddle maskrcnn转换onnx过程中提示不支持，这些后续有扩充计划吗？",
        "state": "closed",
        "user": "qfmy",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-04-19T11:18:59+00:00",
        "updated_at": "2025-05-14T02:51:06+00:00",
        "closed_at": "2025-05-14T02:51:05+00:00",
        "comments_count": [
            "jiangjiajun",
            "qfmy",
            "jiangjiajun",
            "jerrywgz",
            "qfmy",
            "jiangjiajun",
            "KaiHuangMO",
            "wobenxiaoyaoKurt",
            "zhjian831129",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 702,
        "title": "转换 tinypose 模型时丢失了split算子的 split attribute 属性",
        "body": "paddle2onnx 版本： 最新 release 版本\r\n\r\n模型信息\r\n1）tinypose 官方发布的 两种尺寸都试过 paddle lite官网链接下载的\r\n2）模型链接 https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/keypoint/tiny_pose[](https://user-images.githubusercontent.com/8407513/164242103-b54ea03b-8566-4fca-9c2b-d1d8788c5190.png)[](https://user-images.githubusercontent.com/8407513/164242280-9c57a068-e28e-4b62-aace-d61926f0dad9.png)\r\n\r\n复现信息：采用opt10 opt11 opt12 以及以上版本都可以转换出 相应的onnx ，采用opt9以及一下版本不行！\r\n重点来了，转换出来的模型split op ，明显缺少了一个 attribute 字段 “split” ，这说明在转的时候丢失了，具体如下图\r\n                    ![image](https://user-images.githubusercontent.com/8407513/164242103-b54ea03b-8566-4fca-9c2b-d1d8788c5190.png)\r\n                      正常的如上图，但是用paddle2onnx转换出来的，虽然没有错误，但是如下图\r\n![image](https://user-images.githubusercontent.com/8407513/164242280-9c57a068-e28e-4b62-aace-d61926f0dad9.png)\r\n可以看出，缺少了 一个 split 字段，这明显不对！！！ 属于严重bug吧？\r\n备注: paddle2onnx 用的也是最新版本 release的，以及上一个版本，基本都尝试过，结果一样。\r\n麻烦，请帮忙看下这个问题，感觉应该蛮重要的！！！多谢\r\nBR\r\n\r\n原issue链接：https://github.com/PaddlePaddle/Paddle-Lite/issues/8905",
        "state": "closed",
        "user": "shentanyue",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-04-20T14:03:27+00:00",
        "updated_at": "2024-07-15T03:40:02+00:00",
        "closed_at": "2024-07-15T03:39:53+00:00",
        "comments_count": [
            "2050airobert",
            "jiangjiajun",
            "2050airobert",
            "neonhuang",
            "neonhuang",
            "2050airobert",
            "2050airobert",
            "neonhuang",
            "neonhuang",
            "2050airobert",
            "neonhuang",
            "2050airobert",
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 705,
        "title": "您好，请教一下panddle2onnx转换出来的onnx文件，int类型是int64位的，这个有方法可以改成int32位的吗？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "liroda",
        "closed_by": "jiangjiajun",
        "created_at": "2022-04-21T07:06:49+00:00",
        "updated_at": "2022-07-25T08:08:07+00:00",
        "closed_at": "2022-07-25T08:08:07+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 714,
        "title": "使用paddle2onnx转换onnx格式问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用paddle2onnx_v0.9.4将paddlex_v2.1版本训练产生的faster-rcnn模型住哪换成onnx格式时，报以下错误:\r\nNotImplementedError: \r\nThere's 7 ops are not supported yet\r\n=========== tensor_array_to_tensor ===========\r\n=========== while ===========\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== generate_proposals_v2 ===========\r\n=========== write_to_array ===========\r\n=========== lod_array_length ===========\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/88013177/164965155-b08ebd3d-6c08-4d0c-92d5-7725e1be4c65.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Shengcheng-Ma",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-04-24T07:26:49+00:00",
        "updated_at": "2025-05-12T02:54:39+00:00",
        "closed_at": "2025-05-12T02:54:38+00:00",
        "comments_count": [
            "jiangjiajun",
            "xu-peng-7",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 712,
        "title": "0.9.5版本，量化算子仍不支持fake_channel_wise_dequantize_max_abs, fake_quantize_range_abs_max",
        "body": "![image](https://user-images.githubusercontent.com/100794088/164619791-05ab522a-5e71-47c7-9a16-005febbf4318.png)\r\n如图，issue339我也看了，但我是新手，不太懂怎么用github，把339的代码弄下来安装是0.9.2版本，也是上面的报错。模型是普通的CNN模型，用了静态量化为int8想转为onnx用于部署在fpga上。\r\n[model.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/8537645/model.zip)\r\n",
        "state": "closed",
        "user": "szNightFury",
        "closed_by": "szNightFury",
        "created_at": "2022-04-22T06:55:24+00:00",
        "updated_at": "2023-12-16T18:04:50+00:00",
        "closed_at": "2022-04-24T10:18:19+00:00",
        "comments_count": [
            "szNightFury",
            "szNightFury",
            "szNightFury",
            "yeliang2258",
            "szNightFury",
            "yeliang2258",
            "yeliang2258",
            "szNightFury",
            "yeliang2258",
            "szNightFury",
            "yeliang2258",
            "szNightFury",
            "Daipuwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 719,
        "title": "paddleseg转onnx模型后推理出错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\npaddleseg训练后的模型，使用paddle可以正常推理，但是换成onnx后出错，导出模型时正常无报错\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本: 0.9.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n Traceback (most recent call last):\r\n  File \"D:/code/python/PaddleSeg-release-2.5/tt_onnx.py\", line 26, in <module>\r\n    onnx_out = check_and_run_onnx(onnx_model_path, input_data)\r\n  File \"D:/code/python/PaddleSeg-release-2.5/tt_onnx.py\", line 13, in check_and_run_onnx\r\n    ort_outs = ort_sess.run(None, ort_inputs)\r\n  File \"D:\\ProgramData\\Anaconda3\\envs\\OCR2\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 192, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Conv node. Name:'batch_norm_38.tmp_2_nchwc' Status Message: Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.\r\n\r\n**其他信息**\r\n\r\n测试代码如下：\r\nimport onnx\r\nimport onnxruntime\r\nimport numpy as np\r\n\r\n\r\ndef check_and_run_onnx(onnx_model_path, input_data):\r\n    onnx_model = onnx.load(onnx_model_path)\r\n    onnx.checker.check_model(onnx_model)\r\n    print('The onnx model has been checked.')\r\n\r\n    ort_sess = onnxruntime.InferenceSession(onnx_model_path)\r\n    ort_inputs = {ort_sess.get_inputs()[0].name: input_data}\r\n    ort_outs = ort_sess.run(None, ort_inputs)\r\n    print(\"The onnx model has been predicted by ONNXRuntime.\")\r\n\r\n    return ort_outs[0]\r\n\r\n\r\nif __name__ == '__main__':\r\n    input_shape = [1, 3, 768, 768]\r\n    print(\"input shape:\", input_shape)\r\n    input_data = np.random.random(input_shape).astype('float32')\r\n\r\n    # 1. check and run onnx\r\n    onnx_model_path = r\"C:\\Users\\Administrator\\Desktop\\model.onnx\"\r\n    onnx_out = check_and_run_onnx(onnx_model_path, input_data)\r\n    print(\"output shape:\", onnx_out.shape, \"\\n\")\r\n",
        "state": "closed",
        "user": "qypf",
        "closed_by": "qypf",
        "created_at": "2022-04-26T01:57:07+00:00",
        "updated_at": "2022-05-04T10:45:30+00:00",
        "closed_at": "2022-04-26T06:02:36+00:00",
        "comments_count": [
            "qypf",
            "jiangjiajun",
            "qypf",
            "jiangjiajun",
            "qypf",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 722,
        "title": "PP-structure to Onnx error ",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nI get the below error while converting the table recognition model. Does anyone know how to resolve this error?\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nTraceback (most recent call last):\r\nFile \"bin/paddle2onnx\", line 33, in\r\nsys.exit(load_entry_point('paddle2onnx==0.9.3', 'console_scripts', 'paddle2onnx')())\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/command.py\", line 273, in main\r\nprogram2onnx(\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/command.py\", line 200, in program2onnx\r\np2o.program2onnx(\r\nFile \"lib/python3.8/site-packages/paddle2onnx/convert.py\", line 95, in program2onnx\r\nreturn export_onnx(\r\nFile \"/paddle/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 35, in export_onnx\r\nonnx_graph = ONNXGraph.build(paddle_graph, opset_version,\r\nFile \"lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 323, in build\r\nonnx_graph = ONNXGraph(\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 85, in init\r\nself.update_opset_version()\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 202, in update_opset_version\r\nself.opset_version = OpMapper.get_recommend_opset_version(\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 128, in get_recommend_opset_version\r\nrecommend_opset_version = OpMapper.check_support_status(\r\nFile \"/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 174, in check_support_status\r\nraise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 6 ops are not supported yet\r\n=========== tensor_array_to_tensor ===========\r\n=========== while ===========\r\n=========== write_to_array ===========\r\n=========== select_input ===========\r\n=========== lod_array_length ===========\r\n=========== conditional_block ===========",
        "state": "closed",
        "user": "iazdan",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-05-03T21:49:05+00:00",
        "updated_at": "2025-05-11T02:54:49+00:00",
        "closed_at": "2025-05-11T02:54:48+00:00",
        "comments_count": [
            "jiangjiajun",
            "iazdan",
            "Hossein-Chaghazardi",
            "NBd-hub",
            "nissansz",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 721,
        "title": "PaddleSeg中的Fast-SCNN转onnx出错",
        "body": "库版本：\r\n```\r\nwin10\r\npaddle2onnx        0.9.5\r\npaddlepaddle-gpu   2.2.0\r\npaddleseg          2.5.0\r\n```\r\n利用如下命令将`PaddleSeg`中的`Fast-SCNN`转`onnx`：\r\n```shell\r\npaddle2onnx --model_dir ./model_dir \\\r\n                      --model_filename ./model_dir/model.pdmodel \\\r\n                      --params_filename  ./model_dir/model.pdiparams \\\r\n                      --opset_version 11 \\\r\n                      --save_file  ./model_out_dir/\\\r\n                      --input_shape_dict \"{'x': [1, 3, 512, 512]}\"\r\n```\r\n\r\n报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\op_mapper\\op_mapper.py\", line 119, in mapping\r\n    mapper_func(graph, node, **kw)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\op_mapper\\nn.py\", line 186, in opset_1\r\n    node.input_shape('X', 0), node.output_shape('Out', 0)))\r\nException: Cannot convert adaptive pool with input_size: (-1, 128, 16, 16), output_size: (-1, 128, 6, 6)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\admin\\Desktop\\test\\venv\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\admin\\desktop\\tesr\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 283, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 210, in program2onnx\r\n    output_names=output_names)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\convert.py\", line 102, in program2onnx\r\n    output_names=output_names)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\convert.py\", line 37, in export_onnx\r\n    auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 331, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 209, in build_op_nodes\r\n    OpMapper.mapping(self, node, self.operator_export_type)\r\n  File \"c:\\users\\admin\\desktop\\test\\venv\\lib\\site-packages\\paddle2onnx\\op_mapper\\op_mapper.py\", line 124, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['pool2d_3'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['tmp_5']} and outputs: {'Out': ['pool2d_3.tmp_0']}, specific error: Cannot convert adaptive pool with input_size: (-1, 128, 16, 16), output_size: (-1, 128, 6, 6)\r\n```\r\n\r\n请问这是什么原因呢？\r\n谢谢！",
        "state": "closed",
        "user": "geoexploring",
        "closed_by": "geoexploring",
        "created_at": "2022-04-29T05:52:56+00:00",
        "updated_at": "2022-05-04T11:09:40+00:00",
        "closed_at": "2022-05-03T07:17:04+00:00",
        "comments_count": [
            "jiangjiajun",
            "geoexploring",
            "jiangjiajun",
            "geoexploring"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 729,
        "title": "BiSeNetV2转ONNX，用OpenCV调时出错",
        "body": "库版本：\r\n```\r\nwin10\r\npaddle2onnx        0.9.5\r\npaddlepaddle-gpu   2.2.0\r\npaddleseg          2.5.0\r\nopencv              4.5.5.64\r\n```\r\n\r\n利用如下命令将`PaddleSeg`中的`BiSeNetV2`转`onnx`：\r\n```shell\r\npaddle2onnx --model_dir ./model_dir \\\r\n                      --model_filename ./model_dir/model.pdmodel \\\r\n                      --params_filename  ./model_dir/model.pdiparams \\\r\n                      --opset_version 11 \\\r\n                      --save_file  ./model_out_dir/\\\r\n                      --input_shape_dict \"{'x': [1, 3, 512, 512]}\"\r\n```\r\n\r\n利用如下代码调用ONNX进行预测：\r\n```python\r\n\r\nimport cv2\r\nimport numpy as np\r\n\r\ndef load_model(onnx_model):\r\n    net = cv2.dnn.readNetFromONNX(onnx_model)\r\n    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\r\n    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\r\n    return net\r\n\r\ndef onnx_test():\r\n    img = cv2.imread(\"./demo.png\") # 是(512,512,3)大小的图片\r\n    onnx_model = \"./bisenetv2.onnx\"\r\n\r\n    net = load_model(onnx_model)\r\n    blob = cv2.dnn.blobFromImage(img, 1, (512, 512))\r\n\r\n    net.setInput(blob)\r\n    out = net.forward()\r\n\r\nif __name__ == '__main__':\r\n    onnx_test()\r\n```\r\n\r\n但是会在运行`out = net.forward()`时报`opencv-python\\opencv\\modules\\dnn\\include\\opencv2/dnn/shape_utils.hpp:171: error: (-215:Assertion failed) start <= (int)shape.size() && end <= \r\n(int)shape.size() && start <= end in function 'cv::dnn::dnn4_v20211220::total'`的错，请问这是什么原因呢？\r\n\r\n谢谢！",
        "state": "closed",
        "user": "geoexploring",
        "closed_by": "geoexploring",
        "created_at": "2022-05-10T08:50:17+00:00",
        "updated_at": "2022-05-11T03:08:07+00:00",
        "closed_at": "2022-05-11T03:08:06+00:00",
        "comments_count": [
            "yeliang2258",
            "geoexploring"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 731,
        "title": "使用Paddle2ONNX转换yolo模型出错",
        "body": "**问题描述**\r\n我在使用最新版本的paddle2ONNX转换在paddlex上训练的模型使出现导出错误，log如下：\r\n[Paddle2ONNX] Model loaded, start to converting...\r\n[Paddle2ONNX][nearest_interp_v2: nearest_interp_v2_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX][nearest_interp_v2: nearest_interp_v2_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX][yolo_box: yolo_box_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX][yolo_box: yolo_box_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX][yolo_box: yolo_box_2.tmp_0] Requires the minimal opset version of 11.\r\n[ERROR][Paddle2ONNX][multiclass_nms3: multiclass_nms3_0.tmp_1] The 2-nd and 3-rd dimension of input bboxes tensor of multiclass_nms should be fixed, but now the shape is [-1, -1, 4].\r\n[Paddle2ONNX] Due to the operator: multiclass_nms3, this model cannot be exported to ONNX.\r\n[Paddle2ONNX] Due to the operator: nearest_interp_v2, requires opset_version >= 11.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:openvino\r\n - 为什么需要转换为ONNX格式：需要使用openvino来进行cpu上的加速推理\r\n - Paddle2ONNX版本:0.9.5\r\n - 你的联系方式(Email/Wechat/Phone):1843134669@qq.com\r\n\r\n**报错截图**\r\n![捕获](https://user-images.githubusercontent.com/56796761/168030199-29d5a453-d535-430f-a392-6111fdda352a.JPG)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "shliar",
        "closed_by": "shliar",
        "created_at": "2022-05-12T08:44:32+00:00",
        "updated_at": "2022-05-12T09:46:52+00:00",
        "closed_at": "2022-05-12T09:46:52+00:00",
        "comments_count": [
            "jiangjiajun",
            "shliar",
            "jiangjiajun",
            "jiangjiajun",
            "shliar"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 737,
        "title": "转换ch_PP-OCRv2_rec_infer至ONNX模型时出错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n转换ch_PP-OCRv2_rec_infer至ONNX模型时出错\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: onnx-1.9.0 paddle2onnx-0.9.6\r\n - Email/Wechat/Phone:Wechat:13755845443\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/77143808/168769004-ed494b0f-d9f4-4a30-a806-2ee676bf2338.png)\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "PaulX1029",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-05-17T08:42:21+00:00",
        "updated_at": "2024-05-22T05:16:32+00:00",
        "closed_at": "2024-05-22T05:16:32+00:00",
        "comments_count": [
            "jiangjiajun",
            "PaulX1029",
            "PaulX1029"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 734,
        "title": "paddledetection 训练的faster rcnn模型转换为onnx",
        "body": "请问paddledetection 训练的faster rcnn模型能用paddle2onnx转换为onnx模型吗",
        "state": "closed",
        "user": "gxqnba",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-05-15T08:52:25+00:00",
        "updated_at": "2025-05-11T02:54:48+00:00",
        "closed_at": "2025-05-11T02:54:47+00:00",
        "comments_count": [
            "jiangjiajun",
            "gxqnba",
            "gxqnba",
            "jiangjiajun",
            "gxqnba",
            "jiangjiajun",
            "gxqnba",
            "jiangjiajun",
            "gxqnba",
            "zhjian831129",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 738,
        "title": "[pp-humanseg-lite] How to convert dynamic output shape to static output shape?",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nHello, I'm going to use the [Paddle Human-Seg model](https://github.com/PaddlePaddle/Paddle2ONNX/tree/model_zoo/model_zoo/segmentation) in the form of onnx that you uploaded on model_zoo branch. Unity requires static input shape to use the onnx model, so I made it (1, 3, 224, 398) through onnx_simplifier. However, the output shape is still dynamic (-1, 2, -1, -1), so it does not work on Unity. How can I make output shape into static (1, 2, 224, 398) form? The model visualization results are as follows.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: Windows 10\r\n - Why convert to onnx：For using on Unity\r\n - Paddle2ONNX Version: model zoo branch\r\n - Email/Wechat/Phone: jaehwlee@gmail.com\r\n\r\n**Screenshots**\r\n![paddle_portrait_224_398](https://user-images.githubusercontent.com/33409264/168776719-5307a26b-4e65-4b31-a0a1-ca8407f02deb.png)\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "jaehwlee",
        "closed_by": "jaehwlee",
        "created_at": "2022-05-17T09:26:06+00:00",
        "updated_at": "2023-06-30T03:35:25+00:00",
        "closed_at": "2022-05-18T02:19:42+00:00",
        "comments_count": [
            "jiangjiajun",
            "jaehwlee",
            "dganzella",
            "jaehwlee",
            "girish-d",
            "jaehwlee",
            "girish-d",
            "jaehwlee",
            "girish-d"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 741,
        "title": "paddle2onnx如何保存onnx.graph.initializer",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n我这边有一个需求，需要从onnx.graph.initializer中获取超参数；但是我使用paddle2onnx获取的onnx文件这个参数都为空\r\n```\r\nimport onnx\r\nmodel = onnx.load(\"./32_onnx_saved.onnx\")\r\nprint(model.graph.initializer)\r\n```\r\n\r\n**更多信息 :**\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/49713362/169004354-b4850665-4a5e-4880-b438-b98455f13532.png)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "BelongAl",
        "closed_by": "jiangjiajun",
        "created_at": "2022-05-18T09:17:00+00:00",
        "updated_at": "2022-05-23T11:02:33+00:00",
        "closed_at": "2022-05-18T09:56:15+00:00",
        "comments_count": [
            "jiangjiajun",
            "huajunyong123",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 742,
        "title": "使用PaddleX中的ResNet50_vd_ssld模型进行图像分类，转换模型出现下列的报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用PaddleX中的ResNet50_vd_ssld模型进行图像分类，出现下列的报错\r\nDue to the operator: pool2d, this model cannot be exported to ONNX.\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:OpenVINO\r\n - 为什么需要转换为ONNX格式：想转化到openvino模型，然后进行部署\r\n - Paddle2ONNX版本:0.9.6\r\n - 你的联系方式(Email/Wechat/Phone):2839953196@qq.com\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/63993442/169030397-3bd05f17-21c3-441f-b404-2c88843c1afd.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "leigangblog",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-05-18T11:42:37+00:00",
        "updated_at": "2024-07-15T03:39:35+00:00",
        "closed_at": "2024-07-15T03:39:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "leigangblog",
            "jiangjiajun",
            "leigangblog",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 747,
        "title": "相同模型算法训练出来的模型转为onnx后输出的shape维度以及数据格式不一致问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n我使用paddleSeg fcn_hrnet18 训练出来的模型,训练后转onnx模型, 第一次的模型预测输出的shape是 （c， h， w） 形式，里面的数据格式都是 0 或者 1，但是后来我隔了一段时间再用相同的训练代码，只是不同的训练图像去训练，转onnx输出的shape是 （c， n， h， w），而且输出的数据格式不再是0和1，而是一堆浮点数, 请问这个是什么原因导致的，我尝试了更换onnx的版本但是还是一样的问题\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:onnxruntime-gpu==1.11.0, onnx=1.9.0\r\n - 为什么需要转换为ONNX格式：速度更快环境部署更简单\r\n - Paddle2ONNX版本:0.9.5\r\n - 你的联系方式(Email/Wechat/Phone):228826582@qq.com\r\n\r\n**报错截图**\r\n第一次训练的模型转onnx后运行输出\r\n![image](https://user-images.githubusercontent.com/24561457/169678692-f2dce0a1-db74-4fbd-bf27-56ae9043d8b5.png)\r\n第二次训练的模型转onnx后运行输出\r\n![image](https://user-images.githubusercontent.com/24561457/169678879-feb9605b-abb6-4b34-b239-963408986469.png)\r\n第二次输出的数据\r\n![image](https://user-images.githubusercontent.com/24561457/169678755-ae304c32-5448-4f49-adf6-1d1fe16b9065.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "pythondever",
        "closed_by": "pythondever",
        "created_at": "2022-05-22T04:34:17+00:00",
        "updated_at": "2022-05-23T03:43:49+00:00",
        "closed_at": "2022-05-23T03:43:49+00:00",
        "comments_count": [
            "jiangjiajun",
            "pythondever"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 748,
        "title": "libpaddle2onnx.dylib (which was built for Mac OS X 12.0) ",
        "body": "Hi,\r\n我使用最新2.3.0的paddle inference在mac x64平台上。最新的2.3.0的paddle inference动态库包含libpaddle2onnx.dylib\r\n`\r\n\r\n\t@rpath/libpaddle_inference.dylib (compatibility version 0.0.0, current version 0.0.0)\r\n\t@rpath/libonnxruntime.1.10.0.dylib (compatibility version 0.0.0, current version 1.10.0)\r\n\t@rpath/libpaddle2onnx.dylib (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 1300.23.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1311.100.3)\r\n`\r\n\r\n但是当我执行时，报错\r\n`\r\ndyld: Symbol not found: __ZNKSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEE3strEv\r\n  Referenced from: /Users/wangshuai/资料夹/Git/OCR/projects/paddle_inference_2.3.0/third_party/install/paddle2onnx/lib/libpaddle2onnx.dylib (which was built for Mac OS X 12.0)\r\n  Expected in: /usr/lib/libc++.1.dylib\r\n`\r\n\r\n我使用的系统是MAC OS 10.15.7 X64.\r\n你们一定要使用这么高的版本吗？\r\n请问这个我这个在10.x的版本怎么去使用呢？",
        "state": "closed",
        "user": "ANDROIDTODO",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-05-23T07:48:25+00:00",
        "updated_at": "2024-07-15T03:39:23+00:00",
        "closed_at": "2024-07-15T03:39:19+00:00",
        "comments_count": [
            "jiangjiajun",
            "heliqi",
            "ANDROIDTODO",
            "ANDROIDTODO",
            "ANDROIDTODO",
            "heliqi",
            "ANDROIDTODO"
        ],
        "labels": [
            "Bug",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 749,
        "title": "使用paddledetection 训练faster_rcnn_r50_fpn_2x  转ONNX报错，提示Exception: ONNX model is not valid",
        "body": "使用paddledetection 训练faster_rcnn_r50_fpn_2x  转ONNX报错，提示Exception: ONNX model is not valid，是有不支持的OP吗\r\n\r\nC:\\PaddleDetection\\inference_model>paddle2onnx --model_dir haidaipianyi --model_filename model.pdmodel --params_filename model.pdiparams --save_file model.onnx  --enable_dev_version False --opset_version 16\r\nc:\\program files\\python39\\lib\\site-packages\\onnx\\mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:107\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:108\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:109\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:110\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:116\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:116\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:117\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:117\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:120\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:118\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:123\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:121\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:126\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:127\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:128\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:129\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:72\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\generate_proposals.py:73\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\framework.py:744: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  elif dtype == np.bool:\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\distribute_fpn_proposals.py:38\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\distribute_fpn_proposals.py:39\r\nThe behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:336: UserWarning: c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\op_mapper\\custom_paddle_op\\distribute_fpn_proposals.py:40\r\nThe behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nc:\\program files\\python39\\lib\\site-packages\\onnx\\helper.py:343: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\r\n  is_iterable = isinstance(value, collections.Iterable)\r\n2022-05-23 20:36:45 [WARNING]   Due to the operator:multiclass_nms3, the converted ONNX model will only supports input[batch_size] == 1.\r\n2022-05-23 20:36:48 [INFO]      ONNX model generated is valid.\r\nTraceback (most recent call last):\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\utils.py\", line 43, in check_model\r\n    onnx.checker.check_model(onnx_model)\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\onnx\\checker.py\", line 104, in check_model\r\n    C.check_model(protobuf_string)\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Nodes in a graph must be topologically sorted, however input 'S' of node:\r\nname: NonMaxSuppression_5 OpType: NonMaxSuppression\r\n is not output of any previous nodes.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\program files\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"c:\\program files\\python39\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Program Files\\Python39\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\command.py\", line 273, in main\r\n    program2onnx(\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\command.py\", line 200, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\convert.py\", line 95, in program2onnx\r\n    return export_onnx(\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\convert.py\", line 40, in export_onnx\r\n    onnx_proto = onnx_graph.export_proto(enable_onnx_checker, output_names)\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 313, in export_proto\r\n    check_model(onnx_proto)\r\n  File \"c:\\program files\\python39\\lib\\site-packages\\paddle2onnx\\utils.py\", line 45, in check_model\r\n    raise Exception('ONNX model is not valid.')\r\nException: ONNX model is not valid.",
        "state": "closed",
        "user": "memoryrobber",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-05-23T12:41:10+00:00",
        "updated_at": "2024-07-15T04:17:55+00:00",
        "closed_at": "2024-07-15T04:17:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "memoryrobber",
            "jiangjiajun",
            "memoryrobber",
            "yeliang2258",
            "yeliang2258",
            "memoryrobber",
            "yeliang2258",
            "memoryrobber"
        ],
        "labels": [
            "Operator(New)",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 752,
        "title": "ubuntu 20.04编译错误，使用cpu，cmake 3.18.0，python 3.8.10",
        "body": "编译最新的代码报错，环境为：ubuntu 20.04 ，使用cpu，cmake 3.18.0，python 3.8.10\r\n\r\n报错如下，还需要其他的环境吗\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/ubuntu/paddle/Paddle2ONNX/.setuptools-cmake-build/CMakeFiles/CMakeOutput.log\".\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 299, in <module>\r\n    setuptools.setup(\r\n  File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3/dist-packages/setuptools/command/install.py\", line 67, in run\r\n    self.do_egg_install()\r\n  File \"/usr/lib/python3/dist-packages/setuptools/command/install.py\", line 109, in do_egg_install\r\n    self.run_command('bdist_egg')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3/dist-packages/setuptools/command/bdist_egg.py\", line 172, in run\r\n    cmd = self.call_command('install_lib', warn_dir=0)\r\n  File \"/usr/lib/python3/dist-packages/setuptools/command/bdist_egg.py\", line 158, in call_command\r\n    self.run_command(cmdname)\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3/dist-packages/setuptools/command/install_lib.py\", line 23, in run\r\n    self.build()\r\n  File \"/usr/lib/python3.8/distutils/command/install_lib.py\", line 107, in build\r\n    self.run_command('build_py')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 204, in run\r\n    self.run_command('cmake_build')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 190, in run\r\n    subprocess.check_call(cmake_args)\r\n  File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['/usr/bin/cmake', '-DPYTHON_INCLUDE_DIR=/usr/include/python3.8', '-DPYTHON_EXECUTABLE=/usr/bin/python', '-DBUILD_PADDLE2ONNX_PYTHON=ON', '-DCMAKE_EXPORT_COMPILE_COMMANDS=ON', '-DONNX_NAMESPACE=paddle2onnx', '-DPY_EXT_SUFFIX=.cpython-38-x86_64-linux-gnu.so', '-DCMAKE_BUILD_TYPE=Release', '/home/ubuntu/paddle/Paddle2ONNX']' returned non-zero exit status 1.\r\n[CMakeOutput.log](https://github.com/PaddlePaddle/Paddle2ONNX/files/8761865/CMakeOutput.log)\r\n",
        "state": "closed",
        "user": "memoryrobber",
        "closed_by": "jiangjiajun",
        "created_at": "2022-05-24T10:38:14+00:00",
        "updated_at": "2022-07-27T10:46:01+00:00",
        "closed_at": "2022-07-27T10:46:01+00:00",
        "comments_count": [
            "jiangjiajun",
            "memoryrobber",
            "jiangjiajun",
            "memoryrobber",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 762,
        "title": "opencv调用转换的onnx文件出错",
        "body": "E:\\>python test.py\r\n[ERROR:0@0.653] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp (909) cv::dnn::dnn4_v20211220::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 3 inputs and 1 outputs: [Clip]:(Clip_0) from domain='ai.onnx'\r\nTraceback (most recent call last):\r\n  File \"E:\\test.py\", line 23, in <module>\r\n    net = cv2.dnn.readNetFromONNX(\"e:\\\\model.onnx\")  # 加载训练好的识别模型\r\ncv2.error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:928: error: (-2:Unspecified error) in function 'cv::dnn::dnn4_v20211220::ONNXImporter::handleNode'\r\n> Node [Clip@ai.onnx]:(Clip_0) parse error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1613: error: (-2:Unspecified error) in function 'void __cdecl cv::dnn::dnn4_v20211220::ONNXImporter::parseClip(class cv::dnn::dnn4_v20211220::LayerParams &,const class opencv_onnx::NodeProto &)'\r\n> >  (expected: 'node_proto.input_size() == 1'), where\r\n> >     'node_proto.input_size()' is 3\r\n> > must be equal to\r\n> >     '1' is 1\r\n>\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "pdlzx2018",
        "closed_by": "pdlzx2018",
        "created_at": "2022-06-02T11:09:23+00:00",
        "updated_at": "2022-06-07T16:13:59+00:00",
        "closed_at": "2022-06-07T16:13:59+00:00",
        "comments_count": [
            "pdlzx2018",
            "jiangjiajun",
            "pdlzx2018",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 772,
        "title": "GhostNet分类网络，四类和九类的onnx模型速查差别十倍",
        "body": "你好，非常感谢你们的工作，我有一些疑问如下：\r\n\r\n1.网络：使用paddle clas 的GhostNet网络，一个九类，一个是四类；\r\n2.原生paddle推理，两个速度近似。\r\n3.同样转换为onnx，则九类的耗时是四类的十倍之久。\r\n\r\n我尝试进行onnxsim，但是还是存在差距，不过缩小到两倍，相关文件在该百度云链接\r\n链接：https://pan.baidu.com/s/1178iwPcr0FP1YnplBMGiaQ?pwd=i52t \r\n提取码：i52t \r\n--来自百度网盘超级会员V5的分享\r\n",
        "state": "closed",
        "user": "Gmgge",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-06-09T09:41:23+00:00",
        "updated_at": "2024-07-15T03:39:05+00:00",
        "closed_at": "2024-07-15T03:39:05+00:00",
        "comments_count": [
            "jiangjiajun",
            "Gmgge"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 774,
        "title": "PaddleNLP中的RoBERTa模型使用Paddle2ONNX失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n![image](https://user-images.githubusercontent.com/26483581/173036344-83820f17-9081-47e9-83f6-73286eb97481.png)\r\n怀疑是红线上2个OP不支持\r\n",
        "state": "closed",
        "user": "LiuChiachi",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-06-10T09:33:00+00:00",
        "updated_at": "2025-05-09T02:51:00+00:00",
        "closed_at": "2025-05-09T02:50:59+00:00",
        "comments_count": [
            "LiuChiachi",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 779,
        "title": " Assertion failed: inputs.at(0).isInt32() && \"For range operator with dynamic inputs, this version of TensorRT only supports INT32",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n首先通过 python tools/export_model.py -c configs/ppyolo/ppyolov2_r50vd_dcn_365e_coco.yml -o weights=./ppyolov2_r50vd_dcn_365e_coco.pdparams TestReader.inputs_def.image_shape=[3,640,640] --output_dir ./inference_model生成服务端部署模型时需要的模型\r\n然后再 paddle2onnx --model_dir ./inference_model/ppyolov2_r50vd_dcn_365e_coco\r\n--model_filename model.pdmodel \r\n--params_filename model.pdiparams \r\n--opset_version 11 \r\n--save_file ./inference_model/ppyolov2_r50vd_dcn_365e_coco/ppyolov2_r50vd_dcn_365e_coco.onnx \r\n--input_shape_dict \"{'image':[1,3,640,640]}\"\t\r\n--enable_dev_version True\r\n生成onnx模型\r\n我的paddle2onnx 版本是0.9.5    \r\n\r\n然后在通过 TensorRT7.2.1.6 cuda11.1生成engine时报错，如下所示：\r\nE:\\Aware4.0\\ThirdParty\\TensorRT\\onnx-tensorrt_ori\\onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\nWhile parsing node number 721 [Range]:\r\nERROR: E:\\Aware4.0\\ThirdParty\\TensorRT\\onnx-tensorrt_ori\\builtin_op_importers.cpp:2418 In function importRange:\r\n[8] Assertion failed: inputs.at(0).isInt32() && \"For range operator with dynamic inputs, this version of TensorRT only supports INT32!\"\r\nerror: could not parse onnx engine...\r\nerror: could not deserialize or build engine\r\n\r\n请问这里的range出错怎么修改？在源码中修改什么能解决这个错误？\r\n",
        "state": "closed",
        "user": "lilin19890401",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-06-13T12:32:50+00:00",
        "updated_at": "2025-05-08T02:51:34+00:00",
        "closed_at": "2025-05-08T02:51:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "lilin19890401",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 780,
        "title": "使用paddleX训练导出的PPyolov2模型转成onnx时，报错不支持2个操作 deformable_conv,matrix_nms",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,matrix_nms,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:  RKNN\r\n - 为什么需要转换为ONNX格式：需要转为RKNN\r\n - Paddle2ONNX版本:  0.9.8rc0\r\n - 你的联系方式(Email/Wechat/Phone): 15300278668@qq.com\r\n-  python 版本是 3.7.9\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/37522937/173412029-c9fea873-f38a-4706-acc0-420b1250666d.png)\r\n![image](https://user-images.githubusercontent.com/37522937/173412092-146aac7b-90a7-404e-a568-77d1eac06018.png)\r\n\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "VineaToDo",
        "closed_by": "jiangjiajun",
        "created_at": "2022-06-13T17:39:32+00:00",
        "updated_at": "2024-03-07T02:00:27+00:00",
        "closed_at": "2022-07-25T08:07:44+00:00",
        "comments_count": [
            "jiangjiajun",
            "VineaToDo",
            "jiangjiajun",
            "Room-cs",
            "yaobaishen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 785,
        "title": "安装paddleonnx出错",
        "body": "\r\n执行!python paddle2onnx/setup.py install\r\n\r\n显示：\r\nCMake Error at CMakeLists.txt:2 (CMAKE_MINIMUM_REQUIRED):\r\n  CMake 3.16 or higher is required.  You are running version 3.12.2",
        "state": "closed",
        "user": "fan-min-97",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-06-21T14:19:24+00:00",
        "updated_at": "2024-06-05T06:10:59+00:00",
        "closed_at": "2024-06-05T06:10:59+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "fan-min-97",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 786,
        "title": "paddle inference c++ 版本使用报错",
        "body": "Hi,\r\n我使用c++ paddle inference时开启OnnxRuntime\r\n`\r\n paddle_infer::Config config;\r\n  config.SetModel(model_dir + \"/inference.pdmodel\",\r\n                  model_dir + \"/inference.pdiparams\");\r\nconfig.EnableONNXRuntime();\r\nconfig.EnableORTOptimization();\r\n`\r\n报错:\r\nW0622 16:32:11.296285 14620 analysis_predictor.cc:1780] Paddle2ONNX do't support convert the Model， fall back to using Paddle Inference.\r\n\r\n我使用的模型是 https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar\r\npaddle inference 版本是2.3.0",
        "state": "closed",
        "user": "ANDROIDTODO",
        "closed_by": "jiangjiajun",
        "created_at": "2022-06-22T09:16:25+00:00",
        "updated_at": "2022-07-27T10:45:52+00:00",
        "closed_at": "2022-07-27T10:45:52+00:00",
        "comments_count": [
            "yeliang2258",
            "ANDROIDTODO",
            "ANDROIDTODO",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 793,
        "title": "导出半精度ONNX模型",
        "body": "在torch中可以使用以下代码导出半精度ONNX模型\r\n```\r\nimg, model = img.half(), model.half()\r\ntorch.onnx.export(model, img,...)\r\n```\r\n使用paddle2onnx导出的是全精度模型，如何导出半精度模型？",
        "state": "closed",
        "user": "Monday-Leo",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-07-04T18:13:47+00:00",
        "updated_at": "2025-05-08T02:51:32+00:00",
        "closed_at": "2025-05-08T02:51:32+00:00",
        "comments_count": [
            "jiangjiajun",
            "Monday-Leo",
            "jiangjiajun",
            "jiangjiajun",
            "Monday-Leo",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 802,
        "title": "PP-structure to onnx eror",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用版面分析模型转化onnx模型报错\r\n命令行：paddle2onnx --model_dir /root/.paddledet/inference_model/ppyolov2_r50vd_dcn_365e_publaynet/ppyolov2_r50vd_dcn_365e_publaynet_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file /home/paddle_new/PaddleOCR-release-2.5/ppstructure/model.onnx --opset_version 12\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：用于写入开发版\r\n - Paddle2ONNX版本:0.98\r\n - 你的联系方式(Email/Wechat/Phone):932232681@qq.com\r\n\r\n**报错截图**\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python3.7.0/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/command.py\", line 224, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/command.py\", line 148, in program2onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/command.py\", line 210, in program2onnx\r\n    output_names=output_names)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/convert.py\", line 80, in program2onnx\r\n    operator_export_type, auto_update_opset, **configs)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/convert.py\", line 102, in program2onnx\r\n    output_names=output_names)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/convert.py\", line 37, in export_onnx\r\n    auto_update_opset)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 327, in build\r\n    auto_update_opset=auto_update_opset)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 85, in __init__\r\n    self.update_opset_version()\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 203, in update_opset_version\r\n    node_map, self.opset_version)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\", line 142, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"/usr/local/python3.7.0/lib/python3.7/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\", line 188, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError: \r\nThere's 2 ops are not supported yet\r\n=========== conditional_block ===========\r\n=========== select_input ===========\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "NBd-hub",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-07-11T06:17:35+00:00",
        "updated_at": "2025-05-07T02:50:57+00:00",
        "closed_at": "2025-05-07T02:50:56+00:00",
        "comments_count": [
            "yeliang2258",
            "NBd-hub",
            "yeliang2258",
            "yeliang2258",
            "NBd-hub",
            "NBd-hub",
            "NBd-hub",
            "an1018",
            "NBd-hub",
            "nissansz",
            "summerliubf",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 803,
        "title": "不支持Paddlex中的Deeplabv3+导出为ONNX模型",
        "body": "利用如下命令行进行转换：\r\n```\r\npaddle2onnx --model_dir C:/Users/admin/Desktop/temp --model_filename C:/Users/admin/Desktop/temp/model.pdmodel --params_filename C:/Users/admin/Desktop/temp/model.pdiparams --opset_version 11 --save_file C:/Users/admin/Desktop/temp --input_shape_dict \"{'x': [1, 3, 512, 512]}\"\r\n```\r\n\r\n加上`--input_shape_dict \"{'x': [1, 3, 512, 512]}\"`报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\admin\\Desktop\\temp\\venv\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 283, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 195, in program2onnx\r\n    program.blocks[0].var(k).desc.set_shape(v)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2938, in var\r\n    raise ValueError(\"var %s not in this block\" % name)\r\nValueError: var x not in this block\r\n```\r\n\r\n不加`--input_shape_dict \"{'x': [1, 3, 512, 512]}\"`报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\admin\\Desktop\\temp\\venv\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 283, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\command.py\", line 210, in program2onnx\r\n    output_names=output_names)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\convert.py\", line 102, in program2onnx\r\n    output_names=output_names)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\convert.py\", line 37, in export_onnx\r\n    auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 327, in build\r\n    auto_update_opset=auto_update_opset)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 85, in __init__\r\n    self.update_opset_version()\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\graph\\onnx_graph.py\", line 203, in update_opset_version\r\n    node_map, self.opset_version)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\op_mapper\\op_mapper.py\", line 129, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"c:\\users\\admin\\desktop\\temp\\venv\\lib\\site-packages\\paddle2onnx\\op_mapper\\op_mapper.py\", line 174, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 1 ops are not supported yet\r\n=========== sync_batch_norm ===========\r\n```\r\n\r\n请问目前是暂时不支持将Paddlex中的Deeplabv3+导出为ONNX模型吗？\r\n谢谢\r\n",
        "state": "closed",
        "user": "geoexploring",
        "closed_by": "geoexploring",
        "created_at": "2022-07-12T09:24:33+00:00",
        "updated_at": "2023-07-31T08:31:57+00:00",
        "closed_at": "2022-12-21T05:09:05+00:00",
        "comments_count": [
            "NBd-hub",
            "geoexploring",
            "jiangjiajun",
            "geoexploring",
            "jiangjiajun",
            "geoexploring",
            "Mickeyyyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 805,
        "title": "使用paddleX训练导出的PicoDet模型转成onnx时，报错不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n使用paddleX训练导出的PicoDet模型转成onnx时，报错不支持.\r\n[Paddle2ONNX] Only support number of inputs equals to number of outputs for operator 'while'.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本: 0.9.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![1657763724143](https://user-images.githubusercontent.com/85268397/178878554-ad77e8df-3977-4577-b53c-4e69006d7e2d.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "kylin-c7",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-07-14T01:56:11+00:00",
        "updated_at": "2025-05-07T02:50:56+00:00",
        "closed_at": "2025-05-07T02:50:55+00:00",
        "comments_count": [
            "yeliang2258",
            "kylin-c7",
            "yeliang2258",
            "kylin-c7",
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 810,
        "title": "ppyolo模型转化为onnx后infer_shapes失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nppyolo_mbv3_large_coco模型转化为onnx后infer_shapes失败，报如下错误：\r\nonnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] (op_type:Gather, node name: Gather_12): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 0: (1) vs (-1)\r\n\r\n同时，使用TVM加载转化后onnx模型，也无法通过，报如下错误：\r\nCheck failed: *axis_ptr == 1 (-1 vs. 1) : cannot squeeze axis with dimension not equal to 1\r\n\r\n但是，使用onnx的check_model对模型进行验证，一切正常。\r\n所以不知道上述问题是什么原因造成的，还是说转化过程需要什么特别操作。\r\n[转化步骤参考了EXPORT_ONNX_MODEL.md中的步骤。](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/EXPORT_ONNX_MODEL.md)\r\n其余模型如ppyolov2_r50vd_dcn_365e_coco同样存在这个问题。\r\n环境：\r\nOS：ubuntu 18.04\r\npaddle2onnx：0.9.8/1.0.0rc\r\nonnx：1.11/1.12\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "coffezhou",
        "closed_by": "coffezhou",
        "created_at": "2022-07-17T09:32:07+00:00",
        "updated_at": "2022-07-19T13:02:00+00:00",
        "closed_at": "2022-07-19T13:02:00+00:00",
        "comments_count": [
            "jiangjiajun",
            "coffezhou",
            "jiangjiajun",
            "coffezhou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 811,
        "title": "Error Converting SVTR to ONNX and OpenVINO IR",
        "body": "\r\n**Describe the bug**\r\n\r\nThe paddle SVTR model uses grid_sampler function which is prevents conversion to onnx. The grid sampler function is added in opset v16 for onnx, when will there be an addition of version16? Is there any workaround regarding this?\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: OpenVino\r\n - Why convert to onnx：To consequently convert to OpenVino IR\r\n - Paddle2ONNX Version: v1.0.0\r\n \r\n\r\n\r\n**Additional context**\r\nI have tried using an alternative custom function of grid_sampler written originally in torch. Is there any method that I could use to use torch.tensor instead of paddle.tensor for creating a static graph while converting the model to onnx? ",
        "state": "closed",
        "user": "Simardeep27",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-07-18T08:23:16+00:00",
        "updated_at": "2024-07-15T04:17:25+00:00",
        "closed_at": "2024-07-15T04:17:22+00:00",
        "comments_count": [
            "jiangjiajun",
            "Simardeep27"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 813,
        "title": "ppmatting 模型导出为onnx时报pool2d不支持export？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用下面命令转ppmatting的模型为 onnx时报错\r\npaddle2onnx --model_dir . --model_filename model.pdmodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version True --opset_version 15 \r\n[ERROR][Paddle2ONNX][pool2d: pool2d_1.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX][pool2d: pool2d_2.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n\r\n模型为https://paddleseg.bj.bcebos.com/matting/models/deploy/pp-matting-hrnet_w18-human_1024.zip \r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime\r\n - 为什么需要转换为ONNX格式：能使用现有的服务\r\n - Paddle2ONNX版本: \r\npaddle-bfloat                  0.1.7\r\npaddle2onnx                    0.9.8\r\npaddlepaddle                   2.3.1\r\npaddleseg                      2.6.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\nqingfeng454642853@163.com\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "mmxuan18",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-07-21T11:40:47+00:00",
        "updated_at": "2024-06-11T03:09:48+00:00",
        "closed_at": "2024-05-22T05:12:17+00:00",
        "comments_count": [
            "jiangjiajun",
            "LuWei6896",
            "lucasjinreal",
            "tianji2018",
            "LuWei6896",
            "Liliyaw",
            "wangkd0",
            "blakeliu"
        ],
        "labels": [
            "Bug",
            "Operator(Update)",
            "PaddleSeg"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 815,
        "title": "onnx转paddle时报错Exception: convert failed node:onnx__Shape_2099, op_type is Conv",
        "body": "onnx转paddle时报错Exception: convert failed node:onnx__Shape_2099, op_type is Conv",
        "state": "closed",
        "user": "yangshurong",
        "closed_by": "jiangjiajun",
        "created_at": "2022-07-22T16:36:57+00:00",
        "updated_at": "2022-07-25T08:07:24+00:00",
        "closed_at": "2022-07-25T08:07:24+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 812,
        "title": "paddle2onnx转PaddleClas以图搜图主体检测模型onnx中出现\"Constant\"这个额外输入怎么处理",
        "body": "我使用paddle2onnx转以图搜图的PaddleClas主体检测模型ppyolov2_r50vd_dcn_mainbody_v1.0_infer时候出现onnx中有一个“Constant”的空白输入，要怎么处理掉啊\r\n",
        "state": "closed",
        "user": "lovegit2021",
        "closed_by": "jiangjiajun",
        "created_at": "2022-07-19T05:44:57+00:00",
        "updated_at": "2022-07-27T10:45:33+00:00",
        "closed_at": "2022-07-27T10:45:33+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 824,
        "title": "A hello from your friend",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nGreat works! Keep going!\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "deepmirror-wujixiu",
        "closed_by": "deepmirror-wujixiu",
        "created_at": "2022-07-27T07:34:13+00:00",
        "updated_at": "2022-07-27T07:38:40+00:00",
        "closed_at": "2022-07-27T07:36:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 823,
        "title": "Paddleocr中的方向训练模型转化onnx模型报错",
        "body": "用PaddleOCR训了一个方向训练器，使用paddle2onnx部署后用起来报错\r\n```\r\n2022-07-26 14:39:11.503010670 [E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running Add node. Name:'Add_30' Status Message: /onnxruntime_src/onnxruntime/core\r\n/providers/cpu/math/element_wise_ops.h:505 void onnxruntime::BroadcastIterator::Append(ptrdiff_t, pt\r\nrdiff_t) axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension oth$\r\nr than 1. 3 by 4\r\n\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_30' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/math/element_wise_ops.h:505 void onnxruntime::BroadcastIterator::Append(ptrdiff_t, ptrdiff_t) axis == 1 || axis == largest was false. Attempting to broadcast anaxis by a dimension other than 1. 3 by **4**\r\n```",
        "state": "closed",
        "user": "JackieXuu",
        "closed_by": "JackieXuu",
        "created_at": "2022-07-26T06:49:16+00:00",
        "updated_at": "2022-07-29T10:03:09+00:00",
        "closed_at": "2022-07-29T10:03:09+00:00",
        "comments_count": [
            "yeliang2258",
            "JackieXuu",
            "yeliang2258",
            "yeliang2258",
            "yeliang2258",
            "JackieXuu",
            "yeliang2258",
            "JackieXuu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 820,
        "title": "paddle转的onnx模型无法使用",
        "body": "你好，我用paddle2onnx转的onnx模型使用会报错。请问是啥原因啊。\r\n原始paddle模型来源于paddlespeech，fastspeech2-pwgan。具体详情：\r\n\r\n```\r\nmodel_name: fastspeech2\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/fastspeech2_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/fastspeech2_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_119.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_119.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_44', it will rename to 'p2o.tmp_44.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_5.tmp_0', it will rename to 'p2o.fill_constant_5.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_5.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_5.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_15_', it will rename to 'p2o.auto_15_.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_121.tmp_0', it will rename to 'p2o.fill_constant_121.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_37', it will rename to 'p2o.tmp_37.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_119.tmp_0', it will rename to 'p2o.fill_constant_119.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_117.tmp_0', it will rename to 'p2o.fill_constant_117.tmp_0.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_40', it will rename to 'p2o.tmp_40.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'tmp_39', it will rename to 'p2o.tmp_39.1'.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_127.tmp_0', it will rename to 'p2o.fill_constant_127.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_127.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_127.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'auto_88_', it will rename to 'p2o.auto_88_.0'.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\nmodel_name: pwgan\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: exp/default/inference/pwgan_aishell3.pdmodel\r\n[Paddle2ONNX] Paramters file path: exp/default/inference/pwgan_aishell3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2022-07-26 08:54:34 [INFO]\t===============Make PaddlePaddle Better!================\r\n2022-07-26 08:54:34 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:110: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  long_ = _make_signed(np.long)\r\n/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/numba/types/__init__.py:111: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  ulong = _make_unsigned(np.long)\r\nfrontend done!\r\n2022-07-26 08:54:45.875347923 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.415'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875407802 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.412'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875421803 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.400'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875431503 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.418'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875448096 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.409'. It is not used by any node and should be removed from the model.\r\n2022-07-26 08:54:45.875458417 [W:onnxruntime:, graph.cc:3494 CleanUnusedInitializersAndNodeArgs] Removing initializer 'p2o.helper.constant.406'. It is not used by any node and should be removed from the model.\r\nBuilding prefix dict from the default dictionary ...\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:113] Building prefix dict from the default dictionary ...\r\nLoading model from cache /tmp/jieba.cache\r\n[2022-07-26 08:54:46] [DEBUG] [__init__.py:133] Loading model from cache /tmp/jieba.cache\r\nLoading model cost 0.677 seconds.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:165] Loading model cost 0.677 seconds.\r\nPrefix dict has been built successfully.\r\n[2022-07-26 08:54:47] [DEBUG] [__init__.py:166] Prefix dict has been built successfully.\r\n2022-07-26 08:54:47.545056644 [E:onnxruntime:, sequential_executor.cc:368 Execute] Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\nTraceback (most recent call last):\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 227, in <module>\r\n    main()\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 223, in main\r\n    ort_predict(args)\r\n  File \"/ultra/fffan/0_TTS/4_paddlespeech_experiment/00_zips/PaddleSpeech_develop_0725/paddlespeech/t2s/exps/fastspeech2/../ort_predict_e2e.py\", line 86, in ort_predict\r\n    am_sess.run(None, input_feed=am_input_feed)\r\n  File \"/root/anaconda3/envs/paddlespeech/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 200, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'p2o.Gather.0' Status Message: indices element out of data bounds, idx=221 must be within the inclusive range [-220,219]\r\n```\r\n\r\n**paddle2onxx** 版本使用了 `0.9.5` 、`0.9.8` 和 `1.0.0rc0`版本都不行.\r\n\r\n另外我在`paddlespeech`也发了issue,链接：[https://github.com/PaddlePaddle/PaddleSpeech/issues/2184]()",
        "state": "closed",
        "user": "Tian14267",
        "closed_by": "Tian14267",
        "created_at": "2022-07-26T01:34:34+00:00",
        "updated_at": "2022-07-26T02:05:06+00:00",
        "closed_at": "2022-07-26T02:05:06+00:00",
        "comments_count": [
            "jiangjiajun",
            "Tian14267"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 818,
        "title": "take_along_axis转onnx的op不支持",
        "body": "\r\n**问题描述**\r\n命令描述：./paddle2onnx --model_dir ./model_dir --save_file ./\r\n报错信息：\r\n2022﻿-﻿07﻿-﻿25 17﻿:﻿14﻿:﻿14 [WARNING]   [Deprecated] `paddle2onnx.command.program2onnx` will be deprecated in the future version, the recommended usage is `paddle2onnx.export`\r\nTraceback (most recent call last)﻿:\r\n  File \"./paddle2onnx\"﻿, line 8﻿, in <module>\r\n    sys.exit(main(﻿)﻿)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/command.py\"﻿, line 224﻿, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/command.py\"﻿, line 148﻿, in program2onnx\r\n    auto_update_opset)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/command.py\"﻿, line 210﻿, in program2onnx\r\n    output_names=output_names)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/convert.py\"﻿, line 80﻿, in program2onnx\r\n    operator_export_type, auto_update_opset, **configs)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/convert.py\"﻿, line 102﻿, in program2onnx\r\n    output_names=output_names)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/convert.py\"﻿, line 37﻿, in export_onnx\r\n    auto_update_opset)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\"﻿, line 327﻿, in build\r\n    auto_update_opset=auto_update_opset)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\"﻿, line 85﻿, in __init__\r\n    self.update_opset_version(﻿)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\"﻿, line 203﻿, in update_opset_version\r\n    node_map, self.opset_version)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\"﻿, line 142﻿, in get_recommend_opset_version\r\n    node_map, opset_version, True﻿)\r\n  File \"/home/work/.pyenv/versions/3.6.5/lib/python3.6/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\"﻿, line 188﻿, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 1 ops are not supported yet\r\n==﻿==﻿==﻿==﻿==﻿= take_along_axis ==﻿==﻿==﻿==﻿==﻿=\r\n﻿\r\n\r\n\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本: 0.9.8\r\n\r\n",
        "state": "closed",
        "user": "YuanqinLi",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-07-25T10:57:17+00:00",
        "updated_at": "2025-05-06T02:49:31+00:00",
        "closed_at": "2025-05-06T02:49:30+00:00",
        "comments_count": [
            "yeliang2258",
            "YuanqinLi",
            "yeliang2258",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 826,
        "title": "onnx ShapeInferenceError when using onnxsim",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n1、paddle2onnx导出ppyoloe模型的onnx文件\r\n2、使用onnxsim优化前述onnx模型，报错onnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] (op_type:Gather, node name: Gather_12): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 0: (1) vs (-1)\r\n3、使用paddle2onnx.optimize指定input shape，无效\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnx\r\n - 为什么需要转换为ONNX格式：部署\r\n - Paddle2ONNX版本: 0.9.8\r\n - 你的联系方式(Email/Wechat/Phone): 454047094@qq.com\r\n\r\n**报错截图**\r\n```\r\n onnxsim ppyoloe_crn_l_300e_coco.onnx ppyoloe_crn_l_300e_coco_sim.onnx                                                                                      \r\nSimplifying...                                                                                                                                                \r\nTraceback (most recent call last):                                                                                                                            \r\n  File \"/home/wx/miniconda3/envs/pd/bin/onnxsim\", line 8, in <module>                                                                                         \r\n    sys.exit(main())                                                                                                                                          \r\n  File \"/home/wx/miniconda3/envs/pd/lib/python3.7/site-packages/onnxsim/onnx_simplifier.py\", line 444, in main                                                \r\n    args.tensor_size_threshold,                                                                                                                               \r\n  File \"/home/wx/miniconda3/envs/pd/lib/python3.7/site-packages/onnxsim/onnx_simplifier.py\", line 189, in simplify                                            \r\n    tensor_size_threshold,                                                                                                                                    \r\nonnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] (op_type:Gather, node name: Gather_12): [ShapeInferenceError] Inferred shape and\r\n existing shape differ in dimension 0: (1) vs (-1)\r\n```\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "MoonBunnyZZZ",
        "closed_by": "MoonBunnyZZZ",
        "created_at": "2022-07-27T07:46:35+00:00",
        "updated_at": "2022-07-27T08:47:09+00:00",
        "closed_at": "2022-07-27T08:47:09+00:00",
        "comments_count": [
            "jiangjiajun",
            "MoonBunnyZZZ",
            "MoonBunnyZZZ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 832,
        "title": "paddleclas中multilabels模型转 onnx后精度损失太多",
        "body": "看了一些issues都不能解决我的问题：\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/451\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/772\r\n\r\n这是我的issues：\r\nhttps://github.com/PaddlePaddle/PaddleClas/issues/2174\r\n对于同一张图输入，paddle模型输出后sigmod是（最大的两个数值是0.10090836, 0.96171629）：\r\n![image](https://user-images.githubusercontent.com/25652821/181877214-62c72705-a1e5-4c0a-978d-f9ea289233de.png)\r\n而onnx模型里面带了sigmod，输出就是想要的数值（最大的两个数值是0.00439452, 0.98361409）：\r\n![image](https://user-images.githubusercontent.com/25652821/181877225-22ace330-f9f4-462b-b09b-617f8e0ff555.png)\r\n想不出来是哪里出了问题，是paddle转onnx之后精度差这么多吗？\r\n",
        "state": "closed",
        "user": "xxddccaa",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-07-30T06:10:00+00:00",
        "updated_at": "2024-05-30T09:29:39+00:00",
        "closed_at": "2024-05-30T09:29:34+00:00",
        "comments_count": [
            "jiangjiajun",
            "xxddccaa",
            "xxddccaa",
            "jiangjiajun",
            "xxddccaa",
            "xxddccaa"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 833,
        "title": "paddle2onnx导出模型失败",
        "body": "\r\n\r\nPaddleSeg版本：PaddleSeg==2.6\r\nPaddlePaddle版本：PaddlePaddle 2.1.0\r\n操作系统信息：Linux\r\nPython版本号：Python3.6.13\r\nCUDA/cuDNN版本：CUDA11.2\r\nTraceback (most recent call last):\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 119, in mapping\r\nmapper_func(graph, node, **kw)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/op_mapper/nn.py\", line 186, in opset_1\r\nnode.input_shape('X', 0), node.output_shape('Out', 0)))\r\nException: Cannot convert adaptive pool with input_size: (1, 24, 32, 32), output_size: (1, 24, 3, 3)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile \"/home/dell/anaconda3/envs/d2l/bin/paddle2onnx\", line 8, in\r\nsys.exit(main())\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/command.py\", line 195, in main\r\ninput_shape_dict=input_shape_dict)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/command.py\", line 159, in program2onnx\r\noperator_export_type=operator_export_type)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/convert.py\", line 88, in program2onnx\r\nauto_update_opset)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/convert.py\", line 36, in export_onnx\r\nauto_update_opset)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/graph/onnx_graph.py\", line 262, in build\r\nonnx_graph.build_op_nodes(paddle_graph.node_map)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/graph/onnx_graph.py\", line 209, in build_op_nodes\r\nOpMapper.mapping(self, node, self.operator_export_type)\r\nFile \"/home/dell/anaconda3/envs/d2l/lib/python3.6/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 124, in mapping\r\nnode.outputs) + str(e))\r\nException: Error happened when mapping node ['pool2d_3'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['elementwise_add_0']} and outputs: {'Out': ['pool2d_11.tmp_0']}, specific error: Cannot convert adaptive pool with input_size: (1, 24, 32, 32), output_size: (1, 24, 3, 3)\r\n\r\n导出出现了问题，使用所有的模型导出为onnx还是失败",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-07-30T10:38:07+00:00",
        "updated_at": "2024-06-24T06:34:19+00:00",
        "closed_at": "2024-06-24T06:34:19+00:00",
        "comments_count": [
            "jiangjiajun",
            "chen-del",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 841,
        "title": "zsh: command not found: paddle2caffe",
        "body": "$ paddle2caffe --model_dir ./inference/sign2 \\\r\n             --model_filename ./inference/sign2/inference.pdmodel \\\r\n             --params_filename ./inference/sign2/inference.pdiparams \\\r\n             --save_file ./inference/sign2_caffe \\\r\n             --enable_caffe_custom False\r\nzsh: command not found: paddle2caffe\r\n\r\npaddle2caffe命令无法运行。",
        "state": "closed",
        "user": "wstchhwp",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-10T04:26:41+00:00",
        "updated_at": "2024-06-05T06:10:36+00:00",
        "closed_at": "2024-06-05T06:10:36+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 838,
        "title": "转换后的onnx模型被openvion识别时提示错误",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n转换后的onnx模型被openvion2022识别时提示错误：\r\nnon_zero.cpp:43 NonZero layer with name 'NonZero_0' has incorrect number of output edges: 2\r\n\r\n转换成onnx时启用了检查，提示：ONNX model generated is valid.\r\n说明转换是成功的！\r\n\r\n请问是怎么回事？",
        "state": "closed",
        "user": "danve-fan",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-03T11:58:49+00:00",
        "updated_at": "2024-07-15T04:17:13+00:00",
        "closed_at": "2024-07-15T04:17:11+00:00",
        "comments_count": [
            "yeliang2258",
            "danve-fan",
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 837,
        "title": "paddle2onnx环境移植问题",
        "body": "我将本地win10下的python环境拷贝到另一台win10上后，paddleocr可以正常使用，包括训练、推理，但是paddle2onnx无法直接使用，网上查了一圈，说原因是paddle2onnx安装的是绝对路径，其他包是相对路径，然后我拷贝到和本机一样的目录下后，的确可以正常运行。但是我想问一下有没有其他的解决方式，有没有用相对路径安装paddle2onnx的方式？\r\n",
        "state": "closed",
        "user": "LLsmile",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-03T01:19:04+00:00",
        "updated_at": "2024-06-05T06:10:52+00:00",
        "closed_at": "2024-06-05T06:10:52+00:00",
        "comments_count": [
            "LLsmile",
            "jiangjiajun",
            "LLsmile",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 844,
        "title": "PaddleX训练的PP-Picodet无法导出，提示缺OP",
        "body": "训练环境 PaddleX 2.1\r\n导出环境 paddle2onnx-0.9.8\r\n命令`paddle2onnx --model_dir ./ -pf model.pdiparams -s output.onnx -ov 11 -mf model.pdmodel --enable_dev_version True`\r\n错误输出\r\n```\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Only support number of inputs equals to number of outputs for operator 'while'.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n```\r\n[inference_model.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/9300431/inference_model.zip)",
        "state": "closed",
        "user": "kisaragychihaya",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-10T13:31:37+00:00",
        "updated_at": "2024-10-16T09:29:33+00:00",
        "closed_at": "2024-10-16T09:29:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "kisaragychihaya",
            "jiangjiajun",
            "kisaragychihaya",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 846,
        "title": "离线静态量化后，转为onnx，onnx大小与非量化大小相当",
        "body": "离线静态量化后，转为onnx，onnx大小与非量化大小相当，理论上是不是应该比非量化的onnx要小？\r\n\r\n量化后的参数文件和模型文件比非量化时要小很多，转为onnx后，onnx模型大小与非量化前的onnx大小差不多，还要大一点点，请问是什么原因造成的，谢谢！",
        "state": "closed",
        "user": "maximli",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-12T03:15:03+00:00",
        "updated_at": "2024-05-22T05:17:08+00:00",
        "closed_at": "2024-05-22T05:16:56+00:00",
        "comments_count": [
            "jiangjiajun",
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 847,
        "title": "将paddledetection中的行人属性识别模型转换onnx，精度丢失的问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n我用官方给的paddle2onnx模版转换了strongbaseline_r50_30e_pa100k模型到onnx框架，但在测试转换后的onnx模型时，发现输出的值都是整数，而且精度差的也特别多\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：用于rknn模型的转换\r\n - Paddle2ONNX版本:0.9.8\r\n - 你的联系方式(Email/Wechat/Phone):ronghonghui@qq.com\r\n\r\n**报错截图**\r\n原数据1*26\r\n<img width=\"1378\" alt=\"image\" src=\"https://user-images.githubusercontent.com/82571598/184281332-2aeac74b-602c-45e7-96a0-3d98ca4ceb68.png\">\r\n转换后结果数据1*26\r\n<img width=\"619\" alt=\"image\" src=\"https://user-images.githubusercontent.com/82571598/184281402-9bde0130-1594-4122-9327-633b0a22be30.png\">\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ronghonghui",
        "closed_by": "ronghonghui",
        "created_at": "2022-08-12T03:45:49+00:00",
        "updated_at": "2022-08-12T07:22:28+00:00",
        "closed_at": "2022-08-12T07:22:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 849,
        "title": "转化出来的onnx结构不是官方通用的，一些算子有没有什么办法解决",
        "body": "\r\n转化出来的结构推断好像不是官方通用的输出，如resize算子转化出来不是官方通用的，这个有没有什么办法解决嘛？\r\n![image](https://user-images.githubusercontent.com/58769772/184322691-37f6bb89-4f67-4c3d-ad09-01c3046246fa.png)\r\n\r\n再使用onnxsim优化其结构时出现了一些卷积操作推断不出来，这个是不是哪里存在问题，能帮我解答一下疑惑嘛。\r\n![image](https://user-images.githubusercontent.com/58769772/184323083-6c52e458-2489-41db-b88b-a547dfb145d2.png)\r\n我是用于模型推理部署",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-12T09:10:08+00:00",
        "updated_at": "2024-06-04T07:08:35+00:00",
        "closed_at": "2024-06-04T07:08:35+00:00",
        "comments_count": [
            "jiangjiajun",
            "chen-del",
            "chen-del",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "chen-del",
            "jiangjiajun",
            "chen-del",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 848,
        "title": "smkoe 模型转换 onnx失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nsmoke 模型转换，group_norm 不支持\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:  \r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:   0.9.8\r\n - 你的联系方式(Email/Wechat/Phone):  820801454@qq.com\r\n\r\n**报错截图**\r\n![Screenshot from 2022-08-12 15-19-27](https://user-images.githubusercontent.com/26949230/184304637-173162db-865b-43cc-9313-dcbb7927514a.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "mikasazgx",
        "closed_by": "mikasazgx",
        "created_at": "2022-08-12T07:26:28+00:00",
        "updated_at": "2022-08-19T07:42:46+00:00",
        "closed_at": "2022-08-19T07:42:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "mikasazgx",
            "yeliang2258",
            "mikasazgx",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 853,
        "title": "Oops, there are some operators not supported yet, including temporal_shift",
        "body": "\r\n 我想转换ppTSM_fight中的模型为onnx,在转换的过程中遇到Oops, there are some operators not supported yet, including temporal_shift,似乎是不支持temporal_shift，请问该如何进行修改\r\n",
        "state": "closed",
        "user": "alice929",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-15T11:26:12+00:00",
        "updated_at": "2024-05-22T05:11:45+00:00",
        "closed_at": "2024-05-22T05:11:45+00:00",
        "comments_count": [
            "yeliang2258",
            "alice929",
            "yeliang2258",
            "alice929",
            "aureosun"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 850,
        "title": "离线静态量化onnx，推理速度比量化前慢了4倍",
        "body": "det模型采用离线静态量化方式量化（backbon为MobileNetV3），量化后，模型大小减小到原模型3倍，在服务器上测试，前向速度比非量化前慢了4倍，能够确定测试服务器是有avx-512和avx512_vnni指令集的，尝试了一些方式，但速度依然没有改善，请问可能的原因是什么，请帮忙分析一下，谢谢！",
        "state": "closed",
        "user": "maximli",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-14T13:20:36+00:00",
        "updated_at": "2024-06-04T07:07:28+00:00",
        "closed_at": "2024-06-04T07:07:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "maximli",
            "yeliang2258",
            "maximli",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 855,
        "title": "onnx Resize op",
        "body": "resize op双线性插值上采样，有没有一种方式导出，使用普通上采样算子替代，而不是导出来是一种变体的Resize。onnxruntime 进行推理时不支持。\r\n",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-16T03:37:43+00:00",
        "updated_at": "2024-05-30T09:28:47+00:00",
        "closed_at": "2024-05-30T09:28:43+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 852,
        "title": "Due to the operator: pool2d, this model cannot be exported to ONNX.",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式： \r\n - Paddle2ONNX版本:'1.0.0rc3\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n[ERROR][Paddle2ONNX][pool2d: pool2d_9.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX][pool2d: pool2d_10.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\nAborted (core dumped)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ouyangpingbu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-15T10:43:36+00:00",
        "updated_at": "2024-05-22T05:12:01+00:00",
        "closed_at": "2024-05-22T05:12:01+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 862,
        "title": "Deepfm 模型转换报错",
        "body": "执行命令：paddle2onnx --model_dir output_model_all_deepfm/0/ --model_filename rec.pdopt --params_filename rec.pdparams --save_file model.onnx --enable_dev_version True\r\n\r\n输出如下msg：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: output_model_all_deepfm/0/rec.pdopt\r\n[Paddle2ONNX] Paramters file path: output_model_all_deepfm/0/rec.pdparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Failed to parse paddlepaddle model from read content.\r\n[Paddle2ONNX] Failed to load program of PaddlePaddle model.\r\n[Paddle2ONNX] Paddle model parsing failed.\r\n[Paddle2ONNX] Paddle model convert failed.\r\n2022-08-18 17:22:54 [INFO]      ===============Make PaddlePaddle Better!================\r\n2022-08-18 17:22:54 [INFO]      A little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n",
        "state": "closed",
        "user": "RyanRong",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-18T09:27:21+00:00",
        "updated_at": "2024-07-15T04:16:59+00:00",
        "closed_at": "2024-07-15T04:16:54+00:00",
        "comments_count": [
            "jiangjiajun",
            "yuehui49"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 858,
        "title": "想转换PaddleSpeech到ONNX格式，但是报错",
        "body": "\r\n**问题描述**\r\n目前想转换PaddleSpeech到ONNX格式，代码如下：\r\n```\r\n# 从模型代码中导入模型\r\nimport paddle\r\n\r\n# 实例化模型\r\nmodel_for_onnx = asr_engine.executor.model.encoder\r\n# 将模型设置为推理状态\r\nmodel_for_onnx.eval()\r\n\r\ninput_spec = [\r\n    paddle.static.InputSpec(\r\n        shape=[1, 67, 80],\r\n        dtype='float32',\r\n        name='xs'),\r\n    paddle.static.InputSpec(\r\n        shape=[0],\r\n        dtype='int64',\r\n        name='offset'),\r\n    paddle.static.InputSpec(\r\n        shape=[-16],\r\n        dtype='int64',\r\n        name='required_cache_size'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 16, 512],\r\n        dtype='float32',\r\n        name='subsampling_cache'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 16, 512],\r\n        dtype='float32',\r\n        name='elayers_output_cache'),\r\n    paddle.static.InputSpec(\r\n        shape=[1, 512, 14],\r\n        dtype='float32',\r\n        name='conformer_cnn_cache'),\r\n]\r\n\r\n# ONNX模型导出\r\npaddle.onnx.export(model_for_onnx, 'deep_111', input_spec=input_spec, opset_version=12, enable_onnx_checker=True)\r\n\r\n```\r\n\r\n但是报错\r\n\r\n**报错截图**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 6889, in _dygraph_guard\r\n    yield\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/jit.py\", line 868, in save\r\n    with_hook=with_hook)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 528, in concrete_program_specify_input_spec\r\n    *desired_input_spec, with_hook=with_hook)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 436, in get_concrete_program\r\n    concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 801, in __getitem__\r\n    self._caches[item_id] = self._build_once(item)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 790, in _build_once\r\n    **cache_key.kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 740, in from_func_spec\r\n    error_data.raise_new_exception()\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 336, in raise_new_exception\r\n    six.exec_(\"raise new_exception from None\")\r\n  File \"<string>\", line 1, in <module>\r\nAssertionError: In transformed code:\r\n\r\n    File \"/github/PaddleSpeech/paddlespeech/s2t/modules/encoder.py\", line 349, in forward\r\n            pos_emb,\r\n            output_cache=attn_cache,\r\n            cnn_cache=cnn_cache)\r\n            ~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n        r_elayers_output_cache.append(xs[:, next_cache_start:, :])\r\n        r_conformer_cnn_cache.append(new_cnn_cache)\r\n\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n\treturn self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n\toutputs = self.forward(*inputs, **kwargs)\r\n    File \"/tmp/tmpgf4ex6_9.py\", line 88, in forward\r\n\toutput_cache, residual, self, x), (mask, residual, x_q))\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n\tout = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 257, in _run_py_ifelse\r\n\treturn true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/tmp/tmpgf4ex6_9.py\", line 77, in false_fn_10\r\n\tpaddle.jit.dy2static.convert_assert(output_cache.shape[0] == x.shape[0]\r\n    File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 478, in convert_assert\r\n\tassert cond, message\r\n\r\n    AssertionError\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n想请教一下是什么原因？\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhijianli",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-08-16T09:24:16+00:00",
        "updated_at": "2025-05-06T02:49:30+00:00",
        "closed_at": "2025-05-06T02:49:29+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 859,
        "title": "离线量化，模型转换失败",
        "body": "\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n模型离线量化后调用Paddle2Onnx，导出onnx模型失败\r\n\r\n - onnx\r\n - Paddle2ONNX  1.0.0rc3\r\n\r\n**报错信息**\r\n```\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [Info] The Paddle model is a quantized model. \r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including linspace,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n```",
        "state": "closed",
        "user": "Linaom1214",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-08-17T02:14:51+00:00",
        "updated_at": "2025-05-03T02:44:08+00:00",
        "closed_at": "2025-05-03T02:44:07+00:00",
        "comments_count": [
            "yeliang2258",
            "Linaom1214",
            "yeliang2258",
            "Linaom1214",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 870,
        "title": "yolox转onnx",
        "body": "paddle2onnx能支持yolox转onnx吗？paddle模型不好直接部署\r\n",
        "state": "closed",
        "user": "LLsmile",
        "closed_by": "LLsmile",
        "created_at": "2022-08-23T07:44:39+00:00",
        "updated_at": "2022-08-23T08:33:56+00:00",
        "closed_at": "2022-08-23T08:33:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 866,
        "title": "有没一种设置让导出时不带argmax",
        "body": "有没有一种方法是去掉argmax输出的，然后直接输出reshape op 例如1,3,192,192这种形式",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-20T07:20:50+00:00",
        "updated_at": "2024-05-22T04:56:42+00:00",
        "closed_at": "2024-05-22T04:56:37+00:00",
        "comments_count": [
            "jiangjiajun",
            "chen-del",
            "jiangjiajun"
        ],
        "labels": [
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 871,
        "title": "转换HumanSeg到onnx后，输出不正确",
        "body": "版本信息：\r\npaddle2onnx          1.0.0rc4\r\n\r\nroot@kep_common_server:~/project/seg_task# python3\r\nPython 3.6.13 (default, Jun 10 2021, 13:15:56) \r\n\r\n转换HumanSeg模型后，理论上输出是1 2 192 192，但是输出是1 2 -1 -1 \r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "enduringstack",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-23T12:01:47+00:00",
        "updated_at": "2024-05-22T04:48:42+00:00",
        "closed_at": "2024-05-22T04:48:42+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 877,
        "title": "动态 batchsize 下的 resize 算子无法通过 OnnxRuntime 推理",
        "body": "**问题描述**\r\n\r\n我想要把 PaddleDetection 中的 [tinypose](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/README.md#4%E7%AC%AC%E4%B8%89%E6%96%B9%E9%83%A8%E7%BD%B2mnnncnnopenvino) 用 onnxruntime 部署，通过 [README.md](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/third_engine/demo_mnn_kpts/README.md#c-library) 导出的模型可以通过 ort 执行，但是经过 onnxsim 后的模型却不可以。我发现原因是 onnxsim 会保留 Paddle2ONNX 中的 scale 属性，但是由于 tinypose 的 backbone [litehrnet](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/backbones/lite_hrnet.py#L387) 用的是 size 来指定缩放后的张量宽高的，而没有用 scale ，所以 scale 属性会变成空。在 [interpolate.cc](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/paddle2onnx/mapper/nn/interpolate.cc#L119) 中，当 size 为空时，会给参数一个空的数组占位。这个占位符就导致了动态 shape 下的报错。\r\n\r\n测试代码结果：\r\n\r\n| batchsize | use_onnxsim | 推理成功 |\r\n| :--: | :--: | :--: |\r\n| 1 | True / False | ✔️ |\r\n| -1 | True | ❌ |\r\n| -1 | False | ✔️ |\r\n\r\n请问能否通过修改 Paddle2ONNX 支持动态 shape 下 onnxsim 之后的 resize 算子也能成功推理？\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: OnnxRuntime\r\n - 为什么需要转换为ONNX格式：部署 [tinypose](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/deploy/README.md#4%E7%AC%AC%E4%B8%89%E6%96%B9%E9%83%A8%E7%BD%B2mnnncnnopenvino)\r\n - Paddle2ONNX版本: 0.9.8\r\n - 你的联系方式(Email/Wechat/Phone): bangwhe@qq.com\r\n\r\n**报错截图**\r\n\r\n![image](https://user-images.githubusercontent.com/32662175/186686937-9b3c93a0-88df-4d94-b115-cb9fa6ff35f2.png)\r\n\r\n**其他信息**\r\n\r\n``` python3\r\nimport numpy as np\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport onnxsim\r\nimport paddle\r\nimport paddle.static\r\nimport paddle.onnx\r\nimport paddle.nn as nn\r\nimport paddle.nn.functional as F\r\n\r\n\r\nclass MyInterpolate(nn.Layer):\r\n    def __init__(self, target_size=()):\r\n        super().__init__()\r\n        self.target_size = target_size\r\n    \r\n    def forward(self, x):\r\n        return F.interpolate(\r\n            x,\r\n            size=self.target_size,\r\n            mode='bilinear',\r\n            align_corners=True\r\n        )\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    origin_size, resized_size, channels = (64, 64), (128, 128), 3\r\n    model_name = \"paddle_resize\"\r\n    use_onnxsim = True\r\n    batchsize = -1\r\n\r\n    resize_op = MyInterpolate(resized_size)\r\n    x_spec = paddle.static.InputSpec(shape=(batchsize, channels, *origin_size), dtype='float32', name='input')\r\n    paddle.onnx.export(\r\n        resize_op,\r\n        model_name,\r\n        input_spec=[x_spec],\r\n        opset_version=11\r\n    )\r\n\r\n    random_input = np.random.randn(1, channels, *origin_size).astype(np.float32)\r\n    inp = {\"input\": random_input}\r\n\r\n    if use_onnxsim:\r\n        model_simp, check = onnxsim.simplify(\r\n            model=model_name+\".onnx\",\r\n            test_input_shapes={\"input\": random_input.shape},\r\n            input_data=inp)\r\n        assert check, \"Simplified ONNX model could not be validated\"\r\n        model_path = f\"{model_name}-sim.onnx\"\r\n        onnx.save_model(model_simp, model_path)\r\n        print(f\"Simplified ONNX model is saved to {model_path}.\")\r\n    else:\r\n        model_path = f\"{model_name}.onnx\"\r\n\r\n    session = ort.InferenceSession(model_path)\r\n    result = session.run(None, inp)\r\n    print(result[0].shape)\r\n```",
        "state": "closed",
        "user": "hebangwen",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-25T14:24:06+00:00",
        "updated_at": "2024-05-22T04:56:19+00:00",
        "closed_at": "2024-05-22T04:56:19+00:00",
        "comments_count": [
            "hebangwen",
            "jiangjiajun",
            "hebangwen",
            "jiangjiajun",
            "hebangwen",
            "jiangjiajun",
            "Affectionate-0"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 875,
        "title": "paddleocr 量化模型进行进行转换不支持fake_quantize_dequantize_moving_average_abs_max",
        "body": "![97a28be8c620c758793f3d99cb0240d](https://user-images.githubusercontent.com/47705677/186617810-c9c3d4a3-49d1-43cb-9055-3b92226c7ce3.png)\r\n",
        "state": "closed",
        "user": "zhangshabao",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-08-25T08:40:13+00:00",
        "updated_at": "2025-05-09T01:10:56+00:00",
        "closed_at": "2025-04-29T02:47:33+00:00",
        "comments_count": [
            "yeliang2258",
            "zhangshabao",
            "yeliang2258",
            "zhangshabao",
            "yeliang2258",
            "Sunrise723",
            "Sunrise723",
            "yeliang2258",
            "Sunrise723",
            "yeliang2258",
            "yeliang2258",
            "Sunrise723",
            "github-actions[bot]",
            "github-actions[bot]",
            "Goo-Leo"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 879,
        "title": "PicoDet转ONNX报错NotImplementedError",
        "body": "```\r\n\r\npaddle2onnx --model_dir inference_model/yolov3_darknet53_270e_coco \\\r\n            --model_filename model.pdmodel \\\r\n            --params_filename model.pdiparams \\\r\n            --opset_version 11 \\\r\n            --save_file yolov3.onnx\r\n```\r\n\r\n**Describe the bug**\r\n```\r\n\u001b[1;31;40m2022-08-29 12:23:23 [WARNING] [Deprecated] `paddle2onnx.command.program2onnx` will be deprecated in the future version, the recommended usage is `paddle2onnx.export`\u001b[0m\r\nD:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\win32\\lib\\pywintypes.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp, sys, os\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\command.py\", line 224, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\command.py\", line 148, in program2onnx\r\n    auto_update_opset)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\command.py\", line 210, in program2onnx\r\n    output_names=output_names)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\convert.py\", line 80, in program2onnx\r\n    operator_export_type, auto_update_opset, **configs)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\convert.py\", line 102, in program2onnx\r\n    output_names=output_names)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\convert.py\", line 37, in export_onnx\r\n    auto_update_opset)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\graph\\onnx_graph.py\", line 327, in build\r\n    auto_update_opset=auto_update_opset)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\graph\\onnx_graph.py\", line 85, in __init__\r\n    self.update_opset_version()\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\graph\\onnx_graph.py\", line 203, in update_opset_version\r\n    node_map, self.opset_version)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\op_mapper\\op_mapper.py\", line 142, in get_recommend_opset_version\r\n    node_map, opset_version, True)\r\n  File \"D:\\Anaconda3\\envs\\PaddleDabao11237\\lib\\site-packages\\paddle2onnx\\legacy\\op_mapper\\op_mapper.py\", line 188, in check_support_status\r\n    raise NotImplementedError(error_info)\r\nNotImplementedError:\r\nThere's 6 ops are not supported yet\r\n=========== tensor_array_to_tensor ===========\r\n=========== conditional_block ===========\r\n=========== while ===========\r\n=========== write_to_array ===========\r\n=========== select_input ===========\r\n=========== lod_array_length ===========\r\n\r\n\r\n```\r\n\r\n\r\n**Informations (please complete the following information):**\r\n```\r\nonnx                      1.12.0\r\nonnxruntime-gpu           1.12.1\r\nopencv-python             4.6.0.66\r\nopencv-python-headless    4.6.0.66\r\nopenpyxl                  3.0.10\r\nopenvino                  2022.1.0\r\nopenvino-dev              2022.1.0\r\nopenvino-telemetry        2022.1.1\r\npaddle2onnx               0.9.8\r\npaddlepaddle-gpu          2.3.2.post112\r\n```\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-08-29T04:26:23+00:00",
        "updated_at": "2025-04-22T02:44:48+00:00",
        "closed_at": "2025-04-22T02:44:47+00:00",
        "comments_count": [
            "yeliang2258",
            "monkeycc",
            "jiangjiajun",
            "monkeycc",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 872,
        "title": "Paddle3D预训练smoke模型转ONNX出错",
        "body": "对paddle3d提供的smoke模型使用paddle2onnx工具报以下错误：\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including index_select,inverse,  \r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:tensorrt\r\n - 为什么需要转换为ONNX格式:需要使用onnx转trt\r\n - Paddle2ONNX版本:1.0.0rc4\r\n - 你的联系方式(Email/Wechat/Phone):2457458939@qq.com/15115398396/15115398396\r\n\r\n**报错截图**\r\n![Screenshot from 2022-08-24 11-59-58](https://user-images.githubusercontent.com/38579312/186326028-a11de891-632d-4095-a039-067e57a191a8.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Truebazinga",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-08-24T04:01:51+00:00",
        "updated_at": "2025-05-03T02:44:06+00:00",
        "closed_at": "2025-05-03T02:44:06+00:00",
        "comments_count": [
            "yeliang2258",
            "Truebazinga",
            "yeliang2258",
            "FlyingQianMM",
            "Truebazinga",
            "FlyingQianMM",
            "A1exy",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 881,
        "title": "ppclas　语言分类模型，转出ｏｎｎｘ．",
        "body": "转出ｏｎｎｘ正常，但怎么推理呢，没看到数据处理的过程　怎么样的前处理喂进网络",
        "state": "closed",
        "user": "sssssshf",
        "closed_by": "jiangjiajun",
        "created_at": "2022-08-30T01:11:33+00:00",
        "updated_at": "2022-08-30T11:09:50+00:00",
        "closed_at": "2022-08-30T11:09:50+00:00",
        "comments_count": [
            "jiangjiajun",
            "sssssshf",
            "yeliang2258",
            "sssssshf",
            "jiangjiajun",
            "sssssshf",
            "jiangjiajun",
            "sssssshf",
            "jiangjiajun",
            "sssssshf",
            "sssssshf",
            "jiangjiajun",
            "sssssshf",
            "jiangjiajun",
            "sssssshf",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 878,
        "title": "PaddleOCR中文表格模型转onnx缺失算子支持",
        "body": "PaddleOCR新出的中文表格识别模型转onnx报错：\r\nNotImplementedError: \r\nThere's 5 ops are not supported yet\r\n=========== tensor_array_to_tensor ===========\r\n=========== lod_array_length ===========\r\n=========== while ===========\r\n=========== write_to_array ===========\r\n=========== one_hot_v2 ===========\r\n\r\n模型地址：\r\nhttps://paddleocr.bj.bcebos.com/ppstructure/models/slanet/ch_ppstructure_mobile_v2.0_SLANet_infer.tar",
        "state": "closed",
        "user": "746891300-org",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-26T14:19:18+00:00",
        "updated_at": "2024-10-16T09:18:24+00:00",
        "closed_at": "2024-10-16T09:18:24+00:00",
        "comments_count": [
            "yeliang2258",
            "746891300-org",
            "mingo-doer",
            "WenmuZhou",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 884,
        "title": "onnx ocr 推理怎么显示多个备选结果？微信nlanguage",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\nonnx ocr 推理怎么显示多个备选结果？微信nlanguage\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "nissansz",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-08-31T01:59:45+00:00",
        "updated_at": "2024-07-15T03:38:11+00:00",
        "closed_at": "2024-07-15T03:38:03+00:00",
        "comments_count": [
            "yeliang2258",
            "nissansz"
        ],
        "labels": [
            "PaddleOCR",
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 888,
        "title": "缺少算子grid_sampler和linspace",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n缺少算子支持：`grid_sampler`和`linspace`\r\n\r\n**更多信息 :**\r\n - Paddle版本：2.3.1\r\n - Paddle2ONNX版本：0.9.8\r\n - 操作系统：Win 10\r\n\r\n**报错截图**\r\n```\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: *\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: *\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including grid_sampler,linspace,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```",
        "state": "closed",
        "user": "geoyee",
        "closed_by": "geoyee",
        "created_at": "2022-09-01T05:23:58+00:00",
        "updated_at": "2022-09-02T13:46:12+00:00",
        "closed_at": "2022-09-02T13:46:12+00:00",
        "comments_count": [
            "yeliang2258",
            "geoyee",
            "yeliang2258",
            "yeliang2258",
            "geoyee",
            "geoyee",
            "geoyee",
            "yeliang2258",
            "yeliang2258",
            "geoyee",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 890,
        "title": "Paddle2ONNX：BiseNet转换问题",
        "body": "  PaddleSeg版本：PaddleSeg 2.6     PaddlePaddle版本：PaddlePaddle 2.1.0    操作系统信息：Linux\r\n    Python版本号：Python3.6   CUDA/cuDNN版本：CUDA10.2   Paddle2ONNX版本:0.9.8\r\n    onnxruntime\r\n    其他内容:\r\n    ！使用paddlaseg里bisenetv2训练的模型，paddle2onnx转onnx模型成功了，\r\npaddleseg中的predict.py能正常检测，但用onnxruntime推理没有结果，\r\n（我用同样的流程尝试了DeepLabV3P，onnxruntime能正常出结果），\r\n请问我需要检查哪里来解决这个问题，是因为Bisenet不支持转换吗\r\n\r\n",
        "state": "closed",
        "user": "zxc14751475",
        "closed_by": "zxc14751475",
        "created_at": "2022-09-02T06:26:54+00:00",
        "updated_at": "2022-09-05T03:06:02+00:00",
        "closed_at": "2022-09-05T03:06:02+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "zxc14751475"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 891,
        "title": "pyramidbox_lite_mobile_mask模型导出为ONNX协议失败",
        "body": "**问题描述**\r\n版本、环境信息\r\n1）版本：paddlehub 2.2.0，paddlepaddle-gpu 2.2.2， paddle2onnx  0.9.8\r\n2）系统环境：Windows10，python 3.7.13\r\n模型：\r\npyramidbox_lite_mobile_mask==1.3.0\r\npyramidbox_lite_mobile==1.2.0\r\n问题：\r\n已通过save_inference_model将模型从paddleHub导出，尝试使用paddle2onnx将两个模型导出为onnx协议，其中pyramidbox_lite_mobile模型导出成功，但是pyramidbox_lite_mobile_mask导出失败。\r\n命令：\r\n`paddle2onnx --model_dir mask_detector --model_filename __model__ --params_filename __params__  --save_file mask_cls.onnx --enable_onnx_checker True`\r\n报错：\r\n`Exception: Error happened when mapping node ['scale_0'] to onnx, which op_type is 'scale' with inputs: {'X': ['batch_norm_0.tmp_2']} a\r\nnd outputs: {'Out': ['scale_0.tmp_0']}, specific error: object of type 'NoneType' has no len()`\r\n\r\n*全部报错信息：*\r\nTraceback (most recent call last):\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\op_mapper\\op_mapper.py\", line 132, in mapping\r\n    mapper_func(graph, node, **kw)\r\n  File \"..\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\op_mapper\\math.py\", line 987, in opset_7\r\n    if len(node.input('ScaleTensor')) == 0 and np.fabs(\r\nTypeError: object of type 'NoneType' has no len()\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"...\\pplearn\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"...\\pplearn\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"...\\pplearn\\Scripts\\paddle2onnx.exe\\__main__.py\", line 7, in <module>\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\command.py\", line 224, in main\r\n    auto_update_opset=args.enable_auto_update_opset)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\command.py\", line 148, in program2onnx\r\n    auto_update_opset)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\command.py\", line 210, in program2onnx\r\n    output_names=output_names)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\convert.py\", line 80, in program2onnx\r\n    operator_export_type, auto_update_opset, **configs)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\convert.py\", line 102, in program2onnx\r\n    output_names=output_names)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\convert.py\", line 37, in export_onnx\r\n    auto_update_opset)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\graph\\onnx_graph.py\", line 331, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\graph\\onnx_graph.py\", line 209, in build_op_nodes\r\n    OpMapper.mapping(self, node, self.operator_export_type)\r\n  File \"...\\pplearn\\lib\\site-packages\\paddle2onnx\\legacy\\op_mapper\\op_mapper.py\", line 137, in mapping\r\n    node.outputs) + str(e))\r\nException: Error happened when mapping node ['scale_0'] to onnx, which op_type is 'scale' with inputs: {'X': ['batch_norm_0.tmp_2']} a\r\nnd outputs: {'Out': ['scale_0.tmp_0']}, specific error: object of type 'NoneType' has no len()\r\n\r\n\r\n请问问题是出在模型导出还是模型转化阶段呢？该如何解决？谢谢！\r\n\r\n转换为onnx格式的原因：开发需要，统一协议框架；\r\n\r\n联系方式：lucky_sorceress@163.com\r\n",
        "state": "closed",
        "user": "StrongandSurvive",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-06T06:12:48+00:00",
        "updated_at": "2024-07-15T03:38:40+00:00",
        "closed_at": "2024-07-15T03:38:29+00:00",
        "comments_count": [
            "yeliang2258",
            "StrongandSurvive",
            "yeliang2258",
            "StrongandSurvive",
            "rainyfly",
            "StrongandSurvive"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 893,
        "title": "转换成onnx模型后使用gpu推理速度比cpu还慢",
        "body": "\r\n系统环境/System Environment：\r\nonnxruntime-gpu==1.9.0\r\n在使用onnxruntime-gpu进行推理时发现一张图片耗时在3s以上，继续传入相同图片耗时下降到0.5s。更换图片传入耗时又在3s左右,模型是动态模型，为什么不同图片推理速度会变慢？",
        "state": "closed",
        "user": "MgArcher",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-08T03:25:28+00:00",
        "updated_at": "2024-05-22T05:13:52+00:00",
        "closed_at": "2024-05-22T05:13:52+00:00",
        "comments_count": [
            "yeliang2258",
            "xxdm"
        ],
        "labels": [
            "Bug",
            "ONNXRuntime(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 897,
        "title": "转换时提示unique op不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n\r\n拉了develop的paddle2onnx代码编译，导出模型的时候提示unique op不支持，但是看pr记录，是已经支持了来着：https://github.com/PaddlePaddle/Paddle2ONNX/pull/523/files\r\n\r\n转换代码如下\r\n\r\n```bash\r\npaddle2onnx --model_dir=./model_with_unique/ \\\r\n    --model_filename=inference.pdmodel \\\r\n    --params_filename=inference.pdiparams \\\r\n    --save_file=./model_with_unique/model_unique.onnx \\\r\n    --opset_version=13 \\\r\n    --enable_onnx_checker=True\r\n```\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n<img width=\"721\" alt=\"image\" src=\"https://user-images.githubusercontent.com/14270174/190068408-8b1ea3a1-1d2e-4d1e-828f-166112529942.png\">\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-14T05:38:22+00:00",
        "updated_at": "2024-05-22T05:11:12+00:00",
        "closed_at": "2024-05-22T05:11:06+00:00",
        "comments_count": [
            "jiangjiajun",
            "littletomatodonkey",
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 894,
        "title": "paddle2onnx不支持pixel shuffle？",
        "body": "我写了一个超分辨率网络，使用到`paddle.nn.PixelShuffle()`类，当导出模型为onnx时遇到报错。我尝试了两种方法：\r\n\r\n# 方法1\r\n在训练脚本（train.py）中使用`paddle.onnx.export()`进行导出，报错中写道：因为有一些算子不支持（包括pixel shuffle），所以转换中止。\r\n\r\n训练脚本相关代码：\r\n```python\r\npaddle.onnx.export(rtsr3, \"onnx.save/rtsr3\", input_spec=[paddle.static.InputSpec(shape=[1, 3, 180, 320], dtype='float32')], opset_version=11)\r\n```\r\n\r\n报错信息：\r\n```bash\r\n/home/zhuwk/miniconda3/envs/paddle2.3/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmpord95nw7.py:21\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n/home/zhuwk/miniconda3/envs/paddle2.3/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmpord95nw7.py:74\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n/home/zhuwk/miniconda3/envs/paddle2.3/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmpord95nw7.py:78\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n2022-09-08 17:52:26 [INFO]\tStatic PaddlePaddle model saved in onnx.save/paddle_model_static_onnx_temp_dir.\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: onnx.save/paddle_model_static_onnx_temp_dir/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: onnx.save/paddle_model_static_onnx_temp_dir/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including pixel_shuffle,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char const*, char const*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1662630746 (unix time) try \"date -d @1662630746\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e900003b15) received by PID 15125 (TID 0x7fd66c3ce0c0) from PID 15125 ***]\r\n\r\nAborted (core dumped)\r\n```\r\n\r\n# 方法2\r\n\r\n使用源码安装paddle2onnx，命令行进行转换。报错显示有一些算子不支持，应该也是pixelshuffle。\r\n```bash\r\n(paddle2.3) zhuwk@inno:~/Desktop/Nets/Neural-Networks/Super-Resolution/RTSR3/jit.save$ paddle2onnx --model_dir=. --model_filename=rtsr3.pdmodel --params_filename=rtsr3.pdiparams --save_file model.onnx --opset_version=11\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./rtsr3.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./rtsr3.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including pixel_shuffle,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n```\r\n\r\n\r\n",
        "state": "closed",
        "user": "lankning",
        "closed_by": "lankning",
        "created_at": "2022-09-08T09:58:18+00:00",
        "updated_at": "2022-09-09T08:48:30+00:00",
        "closed_at": "2022-09-09T08:48:30+00:00",
        "comments_count": [
            "yeliang2258",
            "lankning",
            "yeliang2258",
            "yeliang2258",
            "lankning",
            "yeliang2258",
            "lankning"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 896,
        "title": "是否支持faster_rcnn_swin_tiny_fpn转onnx",
        "body": "我是在paddleDetection导出的模型\r\n我的导出流程如下：\r\n1.设置配置文件 faster_rcnn_swin_tiny_fpn_3x_coco.yml\r\nexport_onnx: True\r\nbatch_size: 1\r\n2.运行paddleDetection的export_model.py\r\n!python tools/export_model.py -c configs/faster_rcnn/faster_rcnn_swin_tiny_fpn_3x_coco.yml\r\n-o weights=output/faster_rcnn_swin_tiny_fpn_3x_coco/model_final.pdparams\r\n--output_dir inference_model\r\n3.安装paddle2onnx\r\npip install paddle2onnx 版本为1.0.0\r\n4.导出ONNX\r\n!paddle2onnx --model_dir inference_model/faster_rcnn_swin_tiny_fpn_3x_coco\r\n--model_filename model.pdmodel\r\n--params_filename model.pdiparams\r\n--opset_version 16\r\n--enable_dev_version False\r\n--enable_onnx_checker True\r\n--save_file faster_rcnn.onnx\r\n5.结果报错\r\nThere's 7 ops are not supported yet\r\n=========== lod_array_length ===========\r\n=========== conditional_block ===========\r\n=========== select_input ===========\r\n=========== pad ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== while ===========\r\n=========== write_to_array ===========\r\n\r\n按照一些Issue的建议都是设置export_onnx: True就可以了，不知道我的为何依然缺少ops?\r\n请大家帮帮我，Thanks!",
        "state": "closed",
        "user": "wobenxiaoyaoKurt",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-09-13T09:02:26+00:00",
        "updated_at": "2025-04-22T02:44:46+00:00",
        "closed_at": "2025-04-22T02:44:46+00:00",
        "comments_count": [
            "yeliang2258",
            "wobenxiaoyaoKurt",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 898,
        "title": "转换时，deformable_conv算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n\r\n训练完成基于DBnet++的paddleOCR文字检测模型。在转为onnx时报算子不支持的错误。\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: work/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: work/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n但是在又看到issue https://github.com/PaddlePaddle/Paddle2ONNX/issues/167 中提到已经支持了该算子，请问该如何修改？",
        "state": "closed",
        "user": "xu-peng-7",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-09-15T02:09:08+00:00",
        "updated_at": "2025-04-21T02:50:47+00:00",
        "closed_at": "2025-04-21T02:50:47+00:00",
        "comments_count": [
            "xu-peng-7",
            "yeliang2258",
            "heyuhhh",
            "huizhang0110",
            "kingwpf",
            "apexg",
            "HawkingRadiation42",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 899,
        "title": "使用paddle2onnx转换paddle1.x模型",
        "body": "您好，我使用paddle2onnx1.0.0对paddle1.8下环境训练的模型进行转换出现以下错误：\r\n![image](https://user-images.githubusercontent.com/101849755/190304816-54b124a3-8cd5-4e0a-9c40-0429b84847f6.png)\r\n我使用的指令是这样的：\r\npaddle2onnx --model_dir output/det/model/ --model_filename best_accuracy.pdmodel --params_filename best_accuracy.pdparams --save_file output/det/onnx/ocr.onnx --opset_version 9 --enable_onnx_checker True\r\n",
        "state": "closed",
        "user": "fanxiaochen456",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-15T03:11:41+00:00",
        "updated_at": "2024-07-15T03:37:53+00:00",
        "closed_at": "2024-07-15T03:37:53+00:00",
        "comments_count": [
            "yeliang2258",
            "fanxiaochen456"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 900,
        "title": "表格识别模型 paddle inference 和  onnx 模型效果差异较大",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n表格识别模型 paddle inference 和  onnx 模型效果差异较大。\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx： 需要在X86系统上应用paddleocr的模型\r\n - Paddle2ONNX Version: 0.9.8\r\n - Email/Wechat/Phone: 18267162573\r\n\r\n**Screenshots**\r\n![278acbb837859b50bfeadf928619e62](https://user-images.githubusercontent.com/28819717/190345769-6e4e06ba-70bc-44b2-8a68-87be19727a7a.png)\r\n\r\n![12589fcb02a3854772e32243861185f](https://user-images.githubusercontent.com/28819717/190345794-b1d539e8-e301-4179-b465-9410a1f3cec2.png)\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "mingo-doer",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-15T07:45:30+00:00",
        "updated_at": "2024-07-18T08:25:12+00:00",
        "closed_at": "2024-07-15T03:37:29+00:00",
        "comments_count": [
            "mingo-doer",
            "yeliang2258",
            "mingo-doer",
            "cdycdycdy"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 901,
        "title": "onnx batch_size为-1 静态维度问题",
        "body": "def forward(self, input_ids, token_type_ids, pos_ids, att_mask):\r\n    sequence_output, pooled_output = self.encoder(\r\n        input_ids=input_ids,\r\n        token_type_ids=token_type_ids,\r\n        position_ids=pos_ids,\r\n        attention_mask=att_mask)\r\n    sequence_output = paddle.reshape(sequence_output,[-1,512,12,26])\r\n    eca_output = self.eca(sequence_output) \r\n    eca_output = paddle.reshape(eca_output,[-1,512,312])\r\n    start_logits = self.linear_start(eca_output )\r\n    start_logits = paddle.squeeze(start_logits, -1)\r\n    start_prob = self.sigmoid(start_logits)\r\n    end_logits = self.linear_end(eca_output )\r\n    end_logits = paddle.squeeze(end_logits, -1)\r\n    end_prob = self.sigmoid(end_logits)\r\n    return start_prob, end_prob\r\n\r\n针对UIE的改动，模型转静态图正常，但是在加载静态图infer时出现了以下报错（楼上-1为静态维度的问题导致不能广播）：\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Expand node. Name:'p2o.Expand.1' Status Message: p2o.Expand.1: right operand cannot broadcast on dim 0 LeftShape: {1,512,1,1}, RightShape: {-1,512,12,26}\r\n\r\n更新了 onnxsim --> Successfully installed commonmark-0.9.1 onnx-simplifier-0.4.8 rich-12.5.1\r\n通过onnxsim保存模型之后加载还是报上述错误！\r\n期待回复！",
        "state": "closed",
        "user": "Affectionate-0",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-15T10:26:10+00:00",
        "updated_at": "2024-07-15T03:37:18+00:00",
        "closed_at": "2024-07-15T03:37:15+00:00",
        "comments_count": [
            "yeliang2258",
            "Affectionate-0",
            "Affectionate-0"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 902,
        "title": "你们提供的onnx load进来为空，自己导出的也一样",
        "body": "\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/tree/develop/model_zoo/ocr\r\n\r\n![image](https://user-images.githubusercontent.com/20138766/190543711-29ee3c1f-9cf9-44c2-8c47-ff3a79b8f1fe.png)\r\n\r\n希望尽快回复",
        "state": "closed",
        "user": "marsbzp",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-16T02:29:58+00:00",
        "updated_at": "2024-07-15T03:36:12+00:00",
        "closed_at": "2024-07-15T03:36:02+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "marsbzp"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 904,
        "title": "关于paddlex导出模型后转换为onnx报错",
        "body": "·\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...                              │······················\r\n[Paddle2ONNX] Model file path: /work/code/Paddle-fire/home/aistudio/code/inferen│······················\r\nce_model/inference_model/model.pdmodel                                          │······················\r\n[Paddle2ONNX] Paramters file path: /work/code/Paddle-fire/home/aistudio/code/inf│······················\r\nerence_model/inference_model/model.pdiparams                                    │······················\r\n[Paddle2ONNX] Start to parsing Paddle model...                                  │······················\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deform│······················\r\nable_conv,matrix_nms,                                                           │······················\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.            │······················\r\nAborted (core dumped)   ",
        "state": "closed",
        "user": "321492530",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-16T08:34:28+00:00",
        "updated_at": "2024-07-15T03:37:01+00:00",
        "closed_at": "2024-07-15T03:36:57+00:00",
        "comments_count": [
            "yeliang2258",
            "Hoonly"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 905,
        "title": "关于paddlex导出模型后转换onnx报错",
        "body": "不知道是无法进行转换还是我的操作过程有问题，有大佬的话还希望能回复一下，谢谢各位了\r\n\r\n![1663317382685](https://user-images.githubusercontent.com/93509199/190595006-56653fe8-8f04-4933-9482-b4d0b0c723c5.jpg)\r\n",
        "state": "closed",
        "user": "321492530",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-09-16T08:37:35+00:00",
        "updated_at": "2025-04-21T02:50:46+00:00",
        "closed_at": "2025-04-21T02:50:46+00:00",
        "comments_count": [
            "yeliang2258",
            "lingdu-xu",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 914,
        "title": "PaddleX训练的PicoDet模型转ONNX提示少OP",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nPaddleX训练的PicoDet模型转ONNX提示少OP。\r\n\r\n导出模型指令：paddlex --export_inference --model_dir=D:\\workspace\\projects\\P0012\\T0016\\output\\epoch_140 --save_dir=E:\\model\\onnx --fixed_input_shape=[640,640]。\r\n\r\n转换指令已设置--enable_dev_version 为False。\r\n另外paddleX 训练的MaskRCNN模型也报缺少OP的错。\r\n\r\n**更多信息 :**\r\n -PaddleX版本：2.1.0\r\n -onnx版本：1.12.0\r\n - 用于部署的推理引擎:Openvino\r\n - 为什么需要转换为ONNX格式：需要转成IR格式\r\n - Paddle2ONNX版本:1.0\r\n - 你的联系方式(Email/Wechat/Phone):928583088@qq.com\r\n\r\n**报错截图**\r\nPicoDet：\r\n![image](https://user-images.githubusercontent.com/40445051/192486973-42d16d92-944f-4aa9-a6c5-982241170a8e.png)\r\n\r\nMaskRCNN：\r\n![image](https://user-images.githubusercontent.com/40445051/192487351-b0ca269b-eb74-4ed2-a3e1-597fcd9f2169.png)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "panp4n",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-27T09:21:49+00:00",
        "updated_at": "2024-11-19T08:17:25+00:00",
        "closed_at": "2024-11-19T08:17:25+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 907,
        "title": "SMOKE模型转ONNX出错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nSMOKE 模型转ONNX，转换失败\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: \r\n - 为什么需要转换为ONNX格式： 转为TRT加速\r\n - Paddle2ONNX版本: 1.0.0\r\n - 你的联系方式(Email/Wechat/Phone):  vx84214592\r\n\r\n**报错截图**\r\n\r\n(pddl) hitbuyi@hitbuyi-Dell-G15-5511:~/PycharmProjects/padlepadle|_project/SMOKE/model2onnx$ paddle2onnx --model_dir ./  --model_filename smoke_kitti.pdmodel --params_filename smoke_kitti.pdiparams --save_file smoke_kitti.onnx --enable_dev_version True\r\n\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./smoke_kitti.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./smoke_kitti.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Cannot find output:ind_0 in input tensors while converting operator 'while', Paddle2ONNX doesn't support this situation now.\r\n[Paddle2ONNX] Cannot find output:ind_0 in input tensors while converting operator 'while', Paddle2ONNX doesn't support this situation now.\r\n[Paddle2ONNX] Cannot find output:ind_0 in input tensors while converting operator 'while', Paddle2ONNX doesn't support this situation now.\r\n[Paddle2ONNX] Cannot find output:_generated_var_15 in input tensors while converting operator 'while', Paddle2ONNX doesn't support this situation now.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,crop_tensor,select_input,while,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "hitbuyi",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-09-26T08:21:41+00:00",
        "updated_at": "2025-04-20T02:49:08+00:00",
        "closed_at": "2025-04-20T02:49:07+00:00",
        "comments_count": [
            "yeliang2258",
            "hitbuyi",
            "yeliang2258",
            "yeliang2258",
            "hitbuyi",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 918,
        "title": "Paddle2ONNX可以打包成exe在没有python的环境上运行吗",
        "body": "我这边打包会提示缺少文件\r\n![error](https://user-images.githubusercontent.com/111646263/192935962-4e6d75d2-9f20-4d47-b74b-d795fe092af7.jpg)\r\n",
        "state": "closed",
        "user": "YFforever2022",
        "closed_by": "YFforever2022",
        "created_at": "2022-09-29T04:02:14+00:00",
        "updated_at": "2022-09-29T04:49:05+00:00",
        "closed_at": "2022-09-29T04:49:05+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 917,
        "title": "human_pp_humansegv2_lite_192x192_inference_model_with_softmax导出onnx出错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/81000191/192922148-29f30783-90ce-4d4e-aefa-cde95cb03d93.png)\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "zeckireck",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-29T02:06:03+00:00",
        "updated_at": "2024-07-15T04:16:33+00:00",
        "closed_at": "2024-07-15T04:16:27+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 919,
        "title": " 转ONNX提示少OP  including einsum,tril_triu,",
        "body": "您好，我在将模型转为ONNX格式的时候，报了以下问题：\r\n![image](https://user-images.githubusercontent.com/7824188/192965862-0b5d368a-d84f-4c40-ac57-08ab12082b30.png)\r\n\r\n我看了一下代码，可能是由于使用了paddle.einsum 和 paddle.tril的缘故。\r\n在想有没有什么办法解决上面的报错？ \r\n \r\n",
        "state": "closed",
        "user": "sue2xlh",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-09-29T07:20:02+00:00",
        "updated_at": "2024-07-13T01:09:05+00:00",
        "closed_at": "2024-07-12T11:47:35+00:00",
        "comments_count": [
            "yeliang2258",
            "sue2xlh",
            "sue2xlh",
            "yeliang2258",
            "sue2xlh",
            "GUSHUMING",
            "sue2xlh",
            "Vivecccccc",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 922,
        "title": "有while语句的模型，如何转ONNX？",
        "body": "能否提供一点思路？ 通过下面的方法可行？\r\n1） 用PADDLESLIM修改模型\r\n2） 在python语言层级修改模型\r\n3）自定义插件\r\n\r\n如果提供一点例子就好了",
        "state": "closed",
        "user": "hitbuyi",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-03T14:24:23+00:00",
        "updated_at": "2024-11-19T08:17:18+00:00",
        "closed_at": "2024-11-19T08:17:18+00:00",
        "comments_count": [
            "jiangjiajun",
            "hitbuyi",
            "jiangjiajun",
            "hitbuyi",
            "jiangjiajun",
            "hitbuyi",
            "jiangjiajun",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 924,
        "title": "paddle detection导出的RCNN模型转ONNX报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\npython：3.8\r\npaddle版本：2.2.2\r\npaddle detection版本：2.5\r\npaddle2onnx：1.0.1\r\n\r\n\r\npaddle detection导出的RCNN模型转ONNX报错，FasterRCNN和MaskRCNN，均使用 export_onnx=True 字段，使用opset_version 16\r\n导入inference 模型命令\r\npython tools\\export_model.py -c configs/mask_rcnn/mask_rcnn_r101_vd_fpn_1x_coco.yml -o output/mask_rcnn_r101_vd_fpn_1x_coco/model_final.pdiparams export_onnx=True\r\n使用官方文档中的预训练模型导出也是同样的问题。\r\n\r\n报错内容：缺少算子\r\nOops, there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2,\r\n\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:openvino\r\n - 为什么需要转换为ONNX格式：转IR格式\r\n - Paddle2ONNX版本:1.0.1\r\n - 你的联系方式(Email/Wechat/Phone):928583088@qq.com\r\n\r\n**报错截图**\r\n![2022-10-12 164438](https://user-images.githubusercontent.com/40445051/195296539-d3c5aa11-2da1-441b-81a9-f3f05ec025ae.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "panp4n",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-12T08:50:42+00:00",
        "updated_at": "2024-07-26T09:10:02+00:00",
        "closed_at": "2024-07-15T03:35:16+00:00",
        "comments_count": [
            "yeliang2258",
            "seejah",
            "panp4n",
            "seejah",
            "seejah",
            "panp4n",
            "panp4n",
            "seejah",
            "wxf764571829",
            "panp4n"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 923,
        "title": "AVA的slowfast没法转onnx(时空动作检测模型)",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n运行\r\npaddle2onnx  --model_dir inference_output --model_filename AVA_SlowFast_FastRcnn.pdmodel --params_filename AVA_SlowFast_FastRcnn.pdiparams --opset_version 11 --save_file lzj_slowfast_test01.onnx\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_output/AVA_SlowFast_FastRcnn.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_output/AVA_SlowFast_FastRcnn.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,lod_array_length,max_pool3d_with_index,select_input,tensor_array_to_tensor,while,write_to_array,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n电话&微信18295003249/QQ1005452649\r\n**报错截图**\r\n![图片](https://user-images.githubusercontent.com/104427626/195268623-9c8d74d6-0473-493b-af74-613211f6f20e.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "1005452649",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-10-12T06:41:47+00:00",
        "updated_at": "2025-04-20T02:49:06+00:00",
        "closed_at": "2025-04-20T02:49:06+00:00",
        "comments_count": [
            "yeliang2258",
            "ukoehler",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 925,
        "title": "目前不支持swin模型的转换吗",
        "body": "[Paddle2ONNX] Oops, there are some operators not supported yet, including roll,uniform_random\r\n\r\n请问什么时候会支持呢",
        "state": "closed",
        "user": "huilin16",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-15T13:08:04+00:00",
        "updated_at": "2024-04-13T11:32:32+00:00",
        "closed_at": "2024-04-13T11:32:32+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 927,
        "title": "ocr自训练模型转onnx可正常预测，用官方转的ch_PP-OCRv3_rec_infer识别准确率为0",
        "body": "在相同的图片下\r\nocr自训练模型转onnx可正常预测效果好，用官方转的ch_PP-OCRv3_rec_infer识别不正常\r\n如果不转onnx，用ch_PP-OCRv3_rec_infer和自训练模型预测没有问题，准确率非常好\r\n请问是不是ch_PP-OCRv3_rec_infer转onnx有问题\r\n转换命令如下：\r\npaddle2onnx --model_dir ./inference/ch_PP-OCRv3_rec_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/rec_onnx_v3/model.onnx --opset_version 10 --input_shape_dict=\"{'x':[-1,3,-1,-1]}\" --enable_onnx_checker True\r\n",
        "state": "closed",
        "user": "dengmingD",
        "closed_by": "dengmingD",
        "created_at": "2022-10-21T03:05:36+00:00",
        "updated_at": "2022-10-21T03:54:13+00:00",
        "closed_at": "2022-10-21T03:54:12+00:00",
        "comments_count": [
            "dengmingD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 926,
        "title": "PP-HumanSegV2-Lite修改coordinate_transformation_mode bug",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n![image](https://user-images.githubusercontent.com/81000191/196457560-ef6ae952-6035-468c-a494-cc39415fdfcd.png)\r\n\r\n\r\n**Additional context**\r\n我将mobileseg中的align_corners改为 align_corners=True，但是用paddle2onnx转化后，有部分resize算子的coordinate_transformation_mode依然是half_pixel，请问这个应该怎么解决",
        "state": "closed",
        "user": "zeckireck",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-10-18T14:25:12+00:00",
        "updated_at": "2025-04-20T02:49:04+00:00",
        "closed_at": "2025-04-20T02:49:04+00:00",
        "comments_count": [
            "jiangjiajun",
            "zeckireck",
            "jiangjiajun",
            "zeckireck",
            "jiangjiajun",
            "zeckireck",
            "zeckireck",
            "pxEkin",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 928,
        "title": "动态形状不应该用 -1 表示",
        "body": "用 -1 表示动态形状是很早之前 ONNX 没有原生支持动态形状时不得已的一种做法，不是被 ONNX Spec 认可的。现在 ONNX 已经原生支持了动态形状，且用 -1 表示动态形状会导致 ppyolo 在 onnxruntime 中报错：\r\n\r\n> onnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] (op_type:Transpose, node name: p2o.Transpose.1): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 0: (-300) vs (-1)",
        "state": "closed",
        "user": "daquexian",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-21T07:02:35+00:00",
        "updated_at": "2024-06-04T07:09:28+00:00",
        "closed_at": "2024-06-04T07:09:28+00:00",
        "comments_count": [
            "jiangjiajun",
            "clancylian",
            "daquexian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 930,
        "title": "Paddle2onnx hardsigmoid  参数错误。",
        "body": "### bug描述 Describe the Bug\n\nonnx的[Hardsigmoid](https://github.com/onnx/onnx/blob/main/docs/Operators.md#HardSigmoid)公式为 y = max(0, min(1, alpha * x + beta))，其中默认值 **alpha = 0.2, beta = 0.5**. Paddle2Onnx在进行转换时，应该使用了该默认值，在推理时精度掉点，望知悉。\r\n![image](https://user-images.githubusercontent.com/55774832/196848876-55a9ccb3-aec7-4a2a-b6ae-ca491a349849.png)\r\n\r\n\n\n### 其他补充信息 Additional Supplementary Information\n\n_No response_",
        "state": "closed",
        "user": "xiguadong",
        "closed_by": "xiguadong",
        "created_at": "2022-10-20T03:23:37+00:00",
        "updated_at": "2022-10-24T08:28:21+00:00",
        "closed_at": "2022-10-24T08:28:21+00:00",
        "comments_count": [
            "paddle-bot[bot]",
            "zhangbo9674",
            "jiangjiajun",
            "xiguadong",
            "jiangjiajun",
            "xiguadong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 932,
        "title": "RTFormer模型转为ONNX时不支持max_pool2d_with_index",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n训练后的RTFormer模型，转换为onnx模型时报错，转换命令：\r\n```bash\r\npaddle2onnx   --model_dir ${MODEL_EXPORT_DIR} \\\r\n              --model_filename model.pdmodel \\\r\n              --params_filename model.pdiparams \\\r\n              --opset_version 12 \\\r\n              --save_file model.onnx \\\r\n              --enable_auto_update_opset True \\\r\n              --enable_dev_version False \\\r\n              --enable_onnx_checker True\r\n```\r\nenable_dev_version=True或者False时都报错：不支持max_pool2d_with_index\r\nOops, there are some operators not supported yet, including max_pool2d_with_index\r\n\r\n不知道什么时候能增加对这个操作的支持，让RTFormer转换成功。\r\n\r\n**更多信息 :**\r\n - 为什么需要转换为ONNX格式：转Tensorrt\r\n - Paddle2ONNX版本: 1.0.1\r\n\r\n**其他信息**\r\nRTFormer: https://github.com/PaddlePaddle/PaddleSeg/tree/develop/configs/rtformer\r\n之前有人增加过这个op, 不知道为啥在develop和其他分支里没有对应代码: \r\n1. https://github.com/PaddlePaddle/Paddle2ONNX/pull/526\r\n2. https://github.com/PaddlePaddle/Paddle2ONNX/pull/682\r\n",
        "state": "closed",
        "user": "Garfield2005",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-10-25T09:42:24+00:00",
        "updated_at": "2025-04-18T02:41:13+00:00",
        "closed_at": "2025-04-18T02:41:13+00:00",
        "comments_count": [
            "RileyShe",
            "yeliang2258",
            "sunmooncode",
            "shituo123456",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 943,
        "title": "Paddle2Caffe没有明确的安装指南，使用起来有点麻烦",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n只说了简介和依赖，希望能补充下install的文档\r\n![image](https://user-images.githubusercontent.com/19891206/199026382-d3c23f39-95a6-474b-843d-e0cbb8efbe38.png)\r\n\r\n",
        "state": "closed",
        "user": "Real-Chen",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-31T14:03:34+00:00",
        "updated_at": "2024-05-22T05:12:45+00:00",
        "closed_at": "2024-05-22T05:12:45+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 936,
        "title": "转ONNX模型提示不支持pool2d",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n\r\n使用paddle2onnx.command.c_paddle_to_onnx转ONNX模型时报错\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:ONNXRuntime\r\n - 为什么需要转换为ONNX格式：混合精度推理\r\n - Paddle2ONNX版本: 1.0.1\r\n\r\n**报错截图**\r\n\r\n```python\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /root/.paddlenlp/taskflow/information_extraction/uie-layout-base/static/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: /root/.paddlenlp/taskflow/information_extraction/uie-layout-base/static/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR][Paddle2ONNX] [pool2d: pool2d_1.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\nAborted\r\n```\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "linjieccc",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-27T13:06:25+00:00",
        "updated_at": "2024-06-04T07:04:33+00:00",
        "closed_at": "2024-06-04T07:04:33+00:00",
        "comments_count": [
            "yeliang2258",
            "wangkd0"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 935,
        "title": "无法在 Python 3.10.6 中运行",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nPaddle2ONNX 依赖 ONNX 1.9.0，不支持在 Python 3.10.6 中运行 [issue#3723](https://github.com/onnx/onnx/issues/3723)\r\n手动升级 ONNX 到 1.12.0 之后无报错\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n   - Ubuntu 22.04 5.10.102.1-microsoft-standard-WSL2\r\n   - Python 3.10.6\r\n   - Paddle（nightly）```Version: 0.0.0```\r\n   - Paddle2onnx ```Version: 0.9.2```\r\n   - PaddleOCR ```release/2.6```\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n- 运行指令/Command Code：\r\n```shell\r\npaddle2onnx --model_dir ./inference/ch_PP-OCRv3_det_infer \\\r\n--model_filename inference.pdmodel \\\r\n--params_filename inference.pdiparams \\\r\n--save_file ./inference/det_onnx/model.onnx \\\r\n--opset_version 10 \\\r\n--input_shape_dict=\"{'x':[-1,3,-1,-1]}\" \\\r\n--enable_onnx_checker True\r\n```\r\n\r\n- 完整报错/Complete Error Message：\r\n```python\r\n/home/username/.local/lib/python3.10/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  int(TensorProto.STRING): np.dtype(np.object)\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\n2022-10-27 13:46:43 [WARNING]   You are use develop version of paddlepaddle\r\nI1027 13:46:43.140570  5001 interpretercore.cc:235] New Executor is Running.\r\n2022-10-27 13:46:43 [WARNING]   The model is saved by paddlepaddle v2.2.2, but now your paddlepaddle is version of 0.0.0, this difference may cause error, it is recommend you reinstall a same version of paddlepaddle for this model\r\n/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\r\n  import fnmatch, glob, traceback, errno, sys, atexit, locale, imp, stat\r\nTraceback (most recent call last):\r\n  File \"/home/username/.local/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/command.py\", line 218, in main\r\n    program2onnx(\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/command.py\", line 173, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/convert.py\", line 94, in program2onnx\r\n    return export_onnx(\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/convert.py\", line 35, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version,\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/graph/onnx_graph.py\", line 328, in build    onnx_graph.build_parameters(paddle_graph.parameters)\r\n  File \"/home/username/.local/lib/python3.10/site-packages/paddle2onnx/graph/onnx_graph.py\", line 184, in build_parameters\r\n    node = helper.make_node(\r\n  File \"/home/username/.local/lib/python3.10/site-packages/onnx/helper.py\", line 112, in make_node\r\n    node.attribute.extend(\r\n  File \"/home/username/.local/lib/python3.10/site-packages/onnx/helper.py\", line 113, in <genexpr>\r\n    make_attribute(key, value)\r\n  File \"/home/username/.local/lib/python3.10/site-packages/onnx/helper.py\", line 343, in make_attribute\r\n    is_iterable = isinstance(value, collections.Iterable)\r\nAttributeError: module 'collections' has no attribute 'Iterable'\r\n```\r\n\r\n**其他信息**\r\n\r\n出现报错时 onnx 的版本为 ```Version: 1.9.0```\r\n```shell\r\nName: onnx\r\nVersion: 1.9.0\r\nSummary: Open Neural Network Exchange\r\nHome-page: https://github.com/onnx/onnx\r\nAuthor: ONNX\r\nAuthor-email: onnx-technical-discuss@lists.lfai.foundation\r\nLicense: Apache License v2.0\r\nLocation: /home/username/.local/lib/python3.10/site-packages\r\nRequires: numpy, protobuf, six, typing-extensions\r\nRequired-by: paddle2onnx\r\n```\r\n\r\n使用 ```python -m pip install onnx --upgrade``` 更新 onnx 版本\r\n```python\r\nDefaulting to user installation because normal site-packages is not writeable\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: onnx in ./.local/lib/python3.10/site-packages (1.9.0)\r\nCollecting onnx\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/53/b7/0a595a49bd5bc9af85498cd336f98cd1eaf4783f6eeed03908b12c5d11a4/onnx-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 1.3 MB/s eta 0:00:00\r\nRequirement already satisfied: typing-extensions>=3.6.2.1 in ./.local/lib/python3.10/site-packages (from onnx) (4.4.0)\r\nRequirement already satisfied: numpy>=1.16.6 in ./.local/lib/python3.10/site-packages (from onnx) (1.23.4)\r\nRequirement already satisfied: protobuf<=3.20.1,>=3.12.2 in ./.local/lib/python3.10/site-packages (from onnx) (3.20.0)\r\nInstalling collected packages: onnx\r\n  Attempting uninstall: onnx\r\n    Found existing installation: onnx 1.9.0\r\n    Uninstalling onnx-1.9.0:\r\n      Successfully uninstalled onnx-1.9.0\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\npaddle2onnx 0.9.2 requires onnx<=1.9.0, but you have onnx 1.12.0 which is incompatible.\r\nSuccessfully installed onnx-1.12.0\r\n```\r\n\r\n之后再运行相同的命令\r\n```python\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/username/.local/lib/python3.10/site-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\n2022-10-27 13:48:37 [WARNING]   You are use develop version of paddlepaddle\r\nI1027 13:48:37.315676  5086 interpretercore.cc:235] New Executor is Running.\r\n2022-10-27 13:48:37 [WARNING]   The model is saved by paddlepaddle v2.2.2, but now your paddlepaddle is version of 0.0.0, this difference may cause error, it is recommend you reinstall a same version of paddlepaddle for this model\r\n2022-10-27 13:48:37 [INFO]      ONNX model generated is valid.\r\n2022-10-27 13:48:37 [INFO]      ONNX model saved in ./inference/det_onnx/model.onnx\r\n```\r\n\r\n---\r\n\r\n因为 PaddleOCR 本身不支持 Ubuntu 22.04 的 GCC 11.2.0 ，所以 PaddleOCR 使用的是 nightly （看 [issue#44571](https://github.com/PaddlePaddle/Paddle/issues/44571) [pr#45351](https://github.com/PaddlePaddle/Paddle/pull/45351)已经在 rc 中修复了。\r\n但是 Paddle2ONNX 依赖的 ONNX 1.9.0 不支持 Python 3.10.6 [issue#3723](https://github.com/onnx/onnx/issues/3723) ，所以在更新 ONNX 版本到 1.12.0 之后可以正常导出。",
        "state": "closed",
        "user": "KirinRyuuri",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-10-27T07:36:58+00:00",
        "updated_at": "2025-04-18T02:41:11+00:00",
        "closed_at": "2025-04-18T02:41:11+00:00",
        "comments_count": [
            "KirinRyuuri",
            "KirinRyuuri",
            "jiangjiajun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 937,
        "title": "Input shape detection in combination with PaddleSeg",
        "body": "When exporting PaddleSeg models to ONNX I have to provide --input_shape manually to PaddleSeg's export.py. In combination with the fact that widthxheight or rowsxcolumns might be given and most of the time the value is only hinted at in filenames, this means I have to go through the whole chain of exporting models, converting to ONNX and trying to apply the ONNX at least twice to be sure I get the correct results.\r\n\r\nIt would be great if that would be detected automatically. I do not know if PaddleSeg's export.py or Paddle2ONNX is the best place to do that. PaddleSeg referred me to you: https://github.com/PaddlePaddle/PaddleSeg/issues/2660",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-28T07:43:21+00:00",
        "updated_at": "2024-07-15T03:34:37+00:00",
        "closed_at": "2024-07-15T03:34:33+00:00",
        "comments_count": [
            "jiangjiajun",
            "ukoehler",
            "jiangjiajun",
            "ukoehler",
            "jiangjiajun",
            "ukoehler",
            "jiangjiajun",
            "ukoehler",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 938,
        "title": "建议跟进PP OCRV3的预转换模型的上传",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n大神们好，发现您们目前提供的预转换模型中，关于OCR的只有PPOCRV2版本。目前PPOCR已经出到了V3版本，精度据说有5-10的提升，如果可以加入预转换模型提供下载，一定可以进一步方便广大人民群众使用。一个小小的建议哈\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "youxin1996",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-31T06:33:20+00:00",
        "updated_at": "2024-05-22T05:13:24+00:00",
        "closed_at": "2024-05-22T05:13:24+00:00",
        "comments_count": [
            "jiangjiajun",
            "youxin1996"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 939,
        "title": "Attribute not found: allowzero",
        "body": "请问用TRT跑导出的onnx报这个错  怎么解决\r\n<img width=\"1182\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17582080/198966545-87cbb698-c1c7-4dec-81be-be4c6a6a1b9e.png\">\r\n\r\n\r\n",
        "state": "closed",
        "user": "lyuwenyu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-10-31T08:39:51+00:00",
        "updated_at": "2024-05-22T05:13:03+00:00",
        "closed_at": "2024-05-22T05:13:02+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 947,
        "title": "自定义输出节点名称",
        "body": "我记得某个版本是支持的，现在反而不支持了（至少不生效了），出于什么方面的考虑呢？？\r\n自定义输入节点形状，--input_shape_dict, 从paddle2onnx移到了paddle.optimize. --output_names没了",
        "state": "closed",
        "user": "lxgyChen",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-04T08:14:08+00:00",
        "updated_at": "2024-05-22T05:12:34+00:00",
        "closed_at": "2024-05-22T05:12:34+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Utils(ONNX)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 946,
        "title": "jetson安装Paddle2ONNX失败",
        "body": "``**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：系统为jetson arrch 64架构，无法安装PaddleOCR，因此尝试将模型转换为onnx格式，看是否该方式模型是否可以在该机器预测运行\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):17762693896\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n`(python36) nvidia@nvidia-desktop:~/project/Paddle2ONNX-develop$ python setup.py install\r\nfatal: 不是一个 git 仓库（或者任何父目录）：.git\r\n/home/nvidia/.local/lib/python3.6/site-packages/setuptools/dist.py:493: UserWarning: Normalizing '1.0.2rc' to '1.0.2rc0'\r\n  warnings.warn(tmpl.format(**locals()))\r\nrunning install\r\n/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n  setuptools.SetuptoolsDeprecationWarning,\r\n/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n  EasyInstallDeprecationWarning,\r\nrunning bdist_egg\r\nrunning egg_info\r\ncreating paddle2onnx.egg-info\r\nwriting paddle2onnx.egg-info/PKG-INFO\r\nwriting dependency_links to paddle2onnx.egg-info/dependency_links.txt\r\nwriting entry points to paddle2onnx.egg-info/entry_points.txt\r\nwriting requirements to paddle2onnx.egg-info/requires.txt\r\nwriting top-level names to paddle2onnx.egg-info/top_level.txt\r\nwriting manifest file 'paddle2onnx.egg-info/SOURCES.txt'\r\nreading manifest file 'paddle2onnx.egg-info/SOURCES.txt'\r\nadding license file 'LICENSE'\r\nwriting manifest file 'paddle2onnx.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.linux-aarch64/egg\r\nrunning install_lib\r\nrunning build_py\r\nrunning create_version\r\nrunning cmake_build\r\n-- The C compiler identification is GNU 7.5.0\r\n-- The CXX compiler identification is GNU 7.5.0\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\nCMake Error at CMakeLists.txt:2 (CMAKE_MINIMUM_REQUIRED):\r\n  CMake 3.16 or higher is required.  You are running version 3.10.2\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/nvidia/project/Paddle2ONNX-develop/.setuptools-cmake-build/CMakeFiles/CMakeOutput.log\".\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 320, in <module>\r\n    entry_points={'console_scripts': ['paddle2onnx=paddle2onnx.command:main']})\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/__init__.py\", line 153, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 955, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/install.py\", line 74, in run\r\n    self.do_egg_install()\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/install.py\", line 116, in do_egg_install\r\n    self.run_command('bdist_egg')\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/bdist_egg.py\", line 164, in run\r\n    cmd = self.call_command('install_lib', warn_dir=0)\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/bdist_egg.py\", line 150, in call_command\r\n    self.run_command(cmdname)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/.local/lib/python3.6/site-packages/setuptools/command/install_lib.py\", line 11, in run\r\n    self.build()\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/command/install_lib.py\", line 105, in build\r\n    self.run_command('build_py')\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 204, in run\r\n    self.run_command('cmake_build')\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 190, in run\r\n    subprocess.check_call(cmake_args)\r\n  File \"/home/nvidia/archiconda3/envs/python36/lib/python3.6/subprocess.py\", line 311, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['/usr/bin/cmake', '-DPYTHON_INCLUDE_DIR=/home/nvidia/archiconda3/envs/python36/include/python3.6m', '-DPYTHON_EXECUTABLE=/home/nvidia/archiconda3/envs/python36/bin/python', '-DBUILD_PADDLE2ONNX_PYTHON=ON', '-DCMAKE_EXPORT_COMPILE_COMMANDS=ON', '-DONNX_NAMESPACE=paddle2onnx', '-DPY_EXT_SUFFIX=.cpython-36m-aarch64-linux-gnu.so', '-DCMAKE_BUILD_TYPE=Release', '/home/nvidia/project/Paddle2ONNX-develop']' returned non-zero exit status 1.`",
        "state": "closed",
        "user": "Biaocsu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-04T01:37:49+00:00",
        "updated_at": "2024-07-15T03:34:23+00:00",
        "closed_at": "2024-07-15T03:34:23+00:00",
        "comments_count": [
            "yeliang2258",
            "Biaocsu",
            "yeliang2258",
            "Biaocsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 950,
        "title": "KIE 模型转onnx 失败",
        "body": "你好，我想要将KIE的RE模型导成onnx 支持triton 部署，想问下这些算子什么时候可以支持？\r\nNotImplementedError: \r\nThere's 8 ops are not supported yet\r\n=========== conditional_block ===========\r\n=========== select_input ===========\r\n=========== write_to_array ===========\r\n=========== bilinear_tensor_product ===========\r\n=========== lod_array_length ===========\r\n=========== while ===========\r\n=========== tensor_array_to_tensor ===========\r\n=========== empty ===========\r\n\r\n",
        "state": "closed",
        "user": "shelleyyyyu",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-09T02:42:55+00:00",
        "updated_at": "2025-04-14T02:48:00+00:00",
        "closed_at": "2025-04-14T02:48:00+00:00",
        "comments_count": [
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 955,
        "title": "如何降低paddle2onnx中的 onnx opset version",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n\r\n你好，我想把 paddle模型转换成 opset=9 的 onnx 模型，但是转换过程中遇到 `nearest_interp_v2` 算子的最小支持版本为 11，该算子理论上可以转换成 opset=9 中的 `Upsample` 算子，不知道是否有方法通过降版本或者其他方式将 paddle 模型转换成 opset=9 的 onnx 模型？如果可以通过降低版本解决问题，我应该安装什么版本的 paddle 和 paddle2onnx？\r\n\r\n谢谢\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本: 1.0.1\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ShiquanYu",
        "closed_by": "ShiquanYu",
        "created_at": "2022-11-14T01:23:50+00:00",
        "updated_at": "2022-11-14T01:39:16+00:00",
        "closed_at": "2022-11-14T01:39:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 953,
        "title": "Cannot convert PaddleSeg CCNet to ONNX",
        "body": "\r\nWhen converting PaddleSeg CCNet after export to ONNX, I get the error that some operators are not sopported:\r\n\r\n```\r\n(.venv) D:\\Local\\devel\\Python\\PaddleSeg\\PaddleSeg>paddle2onnx --model_dir CCNet\r\n--model_filename model.pdmodel --params_filename model.pdiparams --opset_version\r\n 11 --save_file CCNet/ccnet_resnet101_os8_cityscapes_769x769_60k.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: CCNet\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: CCNet\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including diag_v\r\n2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```\r\n\r\nUsed versions:\r\nPython 3.9.13\r\npaddle-bfloat      0.1.7\r\npaddle2onnx        1.0.1\r\npaddlefsl          1.1.0\r\npaddlehub          2.3.0\r\npaddlenlp          2.4.1\r\npaddlepaddle       2.3.2\r\npaddleseg          2.6.0",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-10T13:59:29+00:00",
        "updated_at": "2025-04-13T03:55:09+00:00",
        "closed_at": "2025-04-13T03:55:09+00:00",
        "comments_count": [
            "yeliang2258",
            "ukoehler",
            "ukoehler",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 961,
        "title": "Cannot convert PaddleSeg ENet to ONNX",
        "body": "When converting PaddleSeg ENet after export to ONNX, I get the error that some operators are not supported:\r\n\r\n```\r\n(.venv) D:\\Local\\devel\\Python\\PaddleSeg\\PaddleSeg>paddle2onnx --model_dir ENet -\r\n-model_filename model.pdmodel --params_filename model.pdiparams --opset_version\r\n11 --save_file ENet/enet_cityscapes_1024x512_80k.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ENet\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ENet\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including max_po\r\nol2d_with_index,unpool,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```\r\nUsed versions:\r\nPython 3.9.13\r\npaddle-bfloat 0.1.7\r\npaddle2onnx 1.0.1\r\npaddlefsl 1.1.0\r\npaddlehub 2.3.0\r\npaddlenlp 2.4.1\r\npaddlepaddle 2.3.2\r\npaddleseg 2.6.0\r\nDeploying to OpenCV",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-17T12:20:13+00:00",
        "updated_at": "2024-11-19T08:17:09+00:00",
        "closed_at": "2024-11-19T08:17:09+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "ukoehler"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 956,
        "title": "如何降低paddle2onnx中的 onnx opset version",
        "body": "**问题描述**\r\n\r\n你好，我想把 paddle模型转换成 opset=9 的 onnx 模型，但是转换过程中遇到 `nearest_interp_v2` 算子的最小支持版本为 11，该算子理论上可以转换成 opset=9 中的 `Upsample` 算子，不知道是否有方法通过降版本或者其他方式将 paddle 模型转换成 opset=9 的 onnx 模型？如果可以通过降低版本解决问题，我应该安装什么版本的 paddle 和 paddle2onnx？\r\n\r\n谢谢\r\n\r\n**更多信息 :**\r\n - 为什么需要转换为ONNX格式：部署至嵌入式小板子\r\n - Paddle2ONNX版本: 1.0.1\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ShiquanYu",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-14T01:23:50+00:00",
        "updated_at": "2025-04-13T03:55:08+00:00",
        "closed_at": "2025-04-13T03:55:07+00:00",
        "comments_count": [
            "yeliang2258",
            "ShiquanYu",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 960,
        "title": "paddleseg的rtformer转onnx时报错：Oops, there are some operators not supported yet, including max_pool2d_with_index",
        "body": "**问题描述**\r\n使用PaddleSeg的RTFormer训练，导出的paddle模型转onnx时报错\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:gpu，rknn\r\n - 为什么需要转换为ONNX格式：需要在gpu及npu部署\r\n - Paddle2ONNX版本:1.0.0rc4\r\n - 你的联系方式(Email/Wechat/Phone):微信：ST_YangMu\r\n\r\n**报错截图**\r\n![741a1184315722cb3683a11cfb166b3](https://user-images.githubusercontent.com/64970397/202404523-9f656891-9908-4d1f-a3e4-eefa94dbd327.jpg)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "shituo123456",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-17T09:12:32+00:00",
        "updated_at": "2024-11-19T08:17:02+00:00",
        "closed_at": "2024-11-19T08:17:02+00:00",
        "comments_count": [
            "yeliang2258",
            "shituo123456",
            "yeliang2258",
            "yeliang2258",
            "shituo123456",
            "sunmooncode",
            "yeliang2258",
            "shituo123456"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 962,
        "title": "PaddleOCR量化模型转onnx报错，模型如下",
        "body": "![image](https://user-images.githubusercontent.com/102579571/202637067-32524541-f681-4f35-b76a-6ccb6cfae947.png)",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-18T06:36:09+00:00",
        "updated_at": "2025-04-05T02:38:30+00:00",
        "closed_at": "2025-04-05T02:38:30+00:00",
        "comments_count": [
            "yeliang2258",
            "lilianjie111111",
            "yeliang2258",
            "lilianjie111111",
            "yeliang2258",
            "lilianjie111111",
            "lilianjie111111",
            "yeliang2258",
            "lilianjie111111",
            "yeliang2258",
            "lilianjie111111",
            "yeliang2258",
            "xdd130",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 963,
        "title": "[ERROR] Paddle2ONNX: Only support weight with lod_level = 0.",
        "body": "paddle2onnx --model_dir /XX/det_db \\\r\n            --model_filename best_accuracy.pdmodel \\\r\n            --params_filename best_accuracy.pdparams \\\r\n            --save_file /XX/dbnet.onnx \\\r\n            --enable_dev_version True \\\r\n            --opset_version 9\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Paddle2ONNX: Only support weight with lod_level = 0.\r\nAborted (core dumped)\r\n\r\n导出模型，遇到这种报错，请问有什么解决思路和建议吗",
        "state": "closed",
        "user": "hi-zhangjie",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-18T08:09:23+00:00",
        "updated_at": "2024-05-22T05:03:39+00:00",
        "closed_at": "2024-05-22T05:03:39+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 967,
        "title": "能麻烦帮忙看下这个问题的后续吗？",
        "body": "![image](https://user-images.githubusercontent.com/102579571/203461075-589ed553-e466-473e-bc49-e7a2234f0169.png)",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-23T02:55:37+00:00",
        "updated_at": "2024-11-22T03:09:17+00:00",
        "closed_at": "2024-11-22T03:09:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 965,
        "title": "Inference",
        "body": "I have a question,Please give me some help,can I use the openvino to inference  .onnx model  by PaddleSlim quantify",
        "state": "closed",
        "user": "xuefengA",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-21T15:42:06+00:00",
        "updated_at": "2024-05-22T05:02:52+00:00",
        "closed_at": "2024-05-22T05:02:49+00:00",
        "comments_count": [
            "jiangjiajun",
            "xuefengA"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 966,
        "title": "Pdmodel转onnx版本问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n在pdmodel转onnx的时候会出现版本问题，高版本（onnx==1.12.0）转换不会出现下面报错，但由于通过高版本转换的ONNX模型在转换rknn的时候会同样出现以下错误。所以只能降低onnx版本来转换pdmodel，但是低版本（onnx==1.8.0）无法转换成功，会出现以下错误。\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:RK3566\r\n - 为什么需要转换为ONNX格式：在npu端部署\r\n - Paddle2ONNX版本:1.0.1\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n```\r\nTraceback (most recent call last):\r\n  File \"tools/model/export_onnx.py\", line 121, in <module>\r\n    export_onnx(args)\r\n  File \"tools/model/export_onnx.py\", line 111, in export_onnx\r\n    onnx_out = check_and_run_onnx(onnx_model_path, input_data)\r\n  File \"tools/model/export_onnx.py\", line 72, in check_and_run_onnx\r\n    onnx.checker.check_model(onnx_model)\r\n  File \"/home/anaconda3/envs/ppseg/lib/python3.8/site-packages/onnx/checker.py\", line 102, in check_model\r\n    C.check_model(protobuf_string)\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Your model ir_version is higher than the checker's.\r\n```\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "sunmooncode",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-22T01:44:26+00:00",
        "updated_at": "2024-06-04T07:07:08+00:00",
        "closed_at": "2024-06-04T07:07:08+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 971,
        "title": "SMOKE 不同分辨率图像",
        "body": "大佬们，想问下，我在tensorrt8.5+cuda11.8下复现了smoke tensorrt 加速代码，想问下，如何变为自己相机分辨率的识别检测呢，微信18811720989欢迎交朋友，希望得到支持，感谢～",
        "state": "closed",
        "user": "Mediumcore",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-27T17:28:15+00:00",
        "updated_at": "2024-07-15T04:15:51+00:00",
        "closed_at": "2024-07-15T04:15:45+00:00",
        "comments_count": [],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 968,
        "title": "建议针对全新环境更新一下 requirements.txt ",
        "body": "你好\r\n\r\n我是刚入门的新手，\r\n虽然知道一点点内容， 但在全新环境测试时候，\r\n提示找不到 CV2 ， Paddle ， numpy\r\n\r\n我知道这些都是很常见库， 但问题是\r\n他们的安装库名和 代码名称并不一致， \r\n比如 pip install CV2 ， 就会提示找不到\r\n或者 PIP install Paddle  ，就会提示安装失败\r\n\r\n\r\n",
        "state": "closed",
        "user": "Gsonovb",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-23T09:38:06+00:00",
        "updated_at": "2024-05-22T05:19:24+00:00",
        "closed_at": "2024-05-22T05:19:24+00:00",
        "comments_count": [
            "yeliang2258",
            "Gsonovb"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 969,
        "title": "能支持多分支输出节点裁剪嘛例如像这样的输出",
        "body": "\r\n![image](https://user-images.githubusercontent.com/58769772/203744839-deb7db15-a5ff-4bf3-8199-f1be284e9077.png)\r\n",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-24T09:17:59+00:00",
        "updated_at": "2024-05-22T05:02:25+00:00",
        "closed_at": "2024-05-22T05:02:25+00:00",
        "comments_count": [
            "chen-del",
            "chen-del",
            "chen-del",
            "yeliang2258"
        ],
        "labels": [
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 972,
        "title": "结构化提取kie和re模型转onnx报错",
        "body": "\r\n![image](https://user-images.githubusercontent.com/67177370/204224368-542ec2ef-f3ba-482b-bdc7-6386a95e8bed.png)\r\n\r\n",
        "state": "closed",
        "user": "LJY6356",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-28T08:00:42+00:00",
        "updated_at": "2024-11-22T03:09:22+00:00",
        "closed_at": "2024-11-22T03:09:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 970,
        "title": "ppyoloe_r_crn_s_3x_spine 转onnx报错",
        "body": "paddle2onnx --model_dir output_inference/ppyoloe_r_crn_s_3x_spine \\\r\n>             --model_filename model.pdmodel \\\r\n>             --params_filename model.pdiparams \\\r\n>             --save_file output_inference/ppyoloe_r_crn_s_3x_spine/model.onnx \\\r\n> \r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: output_inference/ppyoloe_r_crn_s_3x_spine/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: output_inference/ppyoloe_r_crn_s_3x_spine/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_2.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_3.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_4.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [range: range_5.tmp_0] Requires the minimal opset version of 11.\r\n[ERROR][Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] The 2-nd and 3-rd dimension of input bboxes tensor of multiclass_nms should be fixed, but now the shape is [-1, -1, 8].\r\n[Paddle2ONNX] Due to the operator: multiclass_nms3, this model cannot be exported to ONNX.\r\n[Paddle2ONNX] Due to the operator: nearest_interp_v2, requires opset_version >= 11.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\n已放弃 (核心已转储)",
        "state": "closed",
        "user": "CachCheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-24T11:16:24+00:00",
        "updated_at": "2024-05-22T04:44:29+00:00",
        "closed_at": "2024-05-22T04:44:24+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 973,
        "title": "Trainer Api 裁剪量化后的模型用paddle2onnx转换成onnx测试指标全为0",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n\r\nTrainer Api 裁剪量化后的模型用paddle2onnx转换成onnx测试指标全为0\r\n\r\n转换报错：\r\n\r\n![d3186c1f2a9322a0418aa8f5ffbc710](https://user-images.githubusercontent.com/17463933/204224651-7699ccb6-9f5c-41b5-8d42-58eea58a1de3.jpg)\r\n\r\n模型：Ernie-3.0-base，序列标注任务\r\n\r\npaddle2onnx版本：1.0.3\r\n\r\n模型结构和日志：\r\n\r\n[model_log.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/10102564/model_log.zip)\r\n\r\n baseline f1: 0.9147\r\n",
        "state": "closed",
        "user": "NewToolAI",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-11-28T08:03:20+00:00",
        "updated_at": "2024-11-22T03:09:11+00:00",
        "closed_at": "2024-11-22T03:09:11+00:00",
        "comments_count": [
            "LiuChiachi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 974,
        "title": "Constant转为initializer",
        "body": "我有一个模型需要在RK3588上跑，使用RK的转换工具RKNN转换模型的时候使用ONNX格式输入，其中有些算子像Add、Mul、Div等需要与常数做运算：\r\n![image](https://user-images.githubusercontent.com/8433542/204449509-fcb28b29-ada5-473a-8782-64b77e85129e.png)\r\n但是通过Paddle2Onnx以后常数的category变成了Constant，而RKNN只能读入initializer。\r\n\r\n看了exporter的代码后发现尚未支持 use_initializer:\r\n![jtyuB8xMXy](https://user-images.githubusercontent.com/8433542/204449805-b48d1b98-5df8-415a-a7d8-65bcadee526d.jpg)\r\n请问大概什么时候可以支持？\r\n\r\n-------\r\n目前我的办法是通过onnxsim把Constant变回initializer，像这样：\r\n```\r\nonnxsim input.onnx output.onnx --skip-shape-inference\r\n```\r\n然后有可能要把ir_version改一下:\r\n```\r\nimport onnx\r\nmodel = onnx.load('output.onnx')\r\nmodel.ir_version = 4\r\nonnx.save_model(model)\r\n```\r\n",
        "state": "closed",
        "user": "ml-inory",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-29T05:57:17+00:00",
        "updated_at": "2025-04-04T02:41:06+00:00",
        "closed_at": "2025-04-04T02:41:05+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 975,
        "title": "PR #399  仍然不支持的算子",
        "body": "Oops, there are some operators not supported yet, including fake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max\r\n\r\n模型为官方车牌轻量识别模型的量化模型\r\n\r\n使用了 #399 PR仍然不支持以上两个酸字",
        "state": "closed",
        "user": "HAIMSTZL",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-11-30T10:38:13+00:00",
        "updated_at": "2025-04-03T02:41:14+00:00",
        "closed_at": "2025-04-03T02:41:13+00:00",
        "comments_count": [
            "HAIMSTZL",
            "hufangjian",
            "WenmuZhou",
            "Daipuwei",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 979,
        "title": "Oops, there are some operators not supported yet, including max_pool2d_with_index",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\npaddleseg最新rtformer算子不支持\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:nvidia tx2\r\n - 为什么需要转换为ONNX格式：用于tensorrt部署\r\n - Paddle2ONNX版本:1.0.3\r\n - 你的联系方式(Email/Wechat/Phone):\r\n709513781@qq.com\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/27891008/205002913-8b41fda4-fb89-41a2-a5d0-45c330979973.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "bigFatCatTom",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-01T08:25:57+00:00",
        "updated_at": "2024-05-22T04:41:44+00:00",
        "closed_at": "2024-05-22T04:41:44+00:00",
        "comments_count": [],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 976,
        "title": "好多算子不支持",
        "body": " - 用于部署的推理引擎:百度飞桨转onnx再转IR\r\n - 为什么需要转换为ONNX格式：过度\r\n - Paddle2ONNX版本:1.0.2\r\n:\r\n\r\n**报错截图**\r\n\r\n![image](https://user-images.githubusercontent.com/29767049/204824914-0b1521c0-96e4-426f-b107-4d08f6163a00.png)\r\n\r\n附加训练参数截图\r\n![image](https://user-images.githubusercontent.com/29767049/204825336-f7dab036-a656-48e3-9c7a-7cb8324b13cb.png)\r\n\r\n",
        "state": "open",
        "user": "ZJDATY",
        "closed_by": null,
        "created_at": "2022-11-30T14:40:24+00:00",
        "updated_at": "2025-06-23T03:08:45+00:00",
        "closed_at": null,
        "comments_count": [
            "lsm1993",
            "github-actions[bot]",
            "lsm1993",
            "github-actions[bot]",
            "lsm1993",
            "github-actions[bot]",
            "lsm1993",
            "github-actions[bot]",
            "lsm1993"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 982,
        "title": "您好，这个问题在yoloe模型的转换上也存在，请问是哪里的问题呢？",
        "body": "![image](https://user-images.githubusercontent.com/102579571/205193590-aded90b7-59ab-4255-8f95-73c9ad9e2111.png)",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-02T01:24:57+00:00",
        "updated_at": "2024-05-22T04:43:42+00:00",
        "closed_at": "2024-05-22T04:43:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 978,
        "title": "paddlespeech里面的语音转文本模型，ASR怎么转onnx",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n对于ASR模型是流式模型，怎么转onnx\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n联系方式：wang_lianglong@163.com\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Potato-wll",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-12-01T01:45:03+00:00",
        "updated_at": "2025-04-02T02:42:40+00:00",
        "closed_at": "2025-04-02T02:42:39+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 980,
        "title": "修复CI挂的问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/30516196/205009405-073e4201-1ffc-495c-be51-6fb9e69d3906.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "yeliang2258",
        "closed_by": "yeliang2258",
        "created_at": "2022-12-01T08:56:50+00:00",
        "updated_at": "2023-02-08T12:38:58+00:00",
        "closed_at": "2023-02-08T12:38:57+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 983,
        "title": "Onnx的softmax算子支持的opset有1,11,13三个，但是转换代码中只有1和13两类",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nonnx官方支持的softmax算子有3个版本(1，11，13)\r\nhttps://github.com/onnx/onnx/blob/main/docs/Operators.md\r\n![image](https://user-images.githubusercontent.com/19891206/205653549-ba13b215-93ac-4f14-8de8-ee6511bcdadc.png)\r\n但是legacy\\op_mapper\\math.py中的softmax算子只有（1，13）两类。\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/d5f88459d00717c8584aae74fddb4251608d7c54/paddle2onnx/legacy/op_mapper/math.py#L1039\r\n\r\n这就导致使用opset为11时，转换softmax层，必会在softmax层前后添加transpose算子，由于端侧设备对transpose算子支持不好，会导致性能损失严重\r\n\r\n希望softmax能支持opset11的格式\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:移动端设备\r\n - 为什么需要转换为ONNX格式：需要转onnx再转端侧加速芯片支持的文件\r\n - Paddle2ONNX版本:1.0.1\r\n - 你的联系方式(Email/Wechat/Phone):15700079221@163.com\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/19891206/205655307-fd7150a3-01fc-4352-96cd-fc55913c34f9.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Real-Chen",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-05T14:01:38+00:00",
        "updated_at": "2024-05-22T05:22:46+00:00",
        "closed_at": "2024-05-22T05:22:46+00:00",
        "comments_count": [
            "Real-Chen",
            "Real-Chen",
            "jiangjiajun"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 986,
        "title": "Cannot convert PaddleSeg Segmenter to ONNX",
        "body": "When converting PaddleSeg ENet after export to ONNX, I get the error that some operators are not supported:\r\n```\r\n(.venv) D:\\Local\\devel\\Python\\PaddleSeg\\PaddleSeg>paddle2onnx --model_dir SegMen\r\nter --model_filename model.pdmodel --params_filename model.pdiparams --opset_ver\r\nsion 11 --save_file SegMenter/segmenter_vit_base_mask_ade20k_512x512_160k.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: SegMenter\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: SegMenter\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including condit\r\nional_block,select_input,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n``` \r\n\r\nUsed versions:\r\nPython 3.9.13\r\npaddle-bfloat 0.1.7\r\npaddle2onnx 1.0.1\r\npaddlefsl 1.1.0\r\npaddlehub 2.3.0\r\npaddlenlp 2.4.1\r\npaddlepaddle 2.3.2\r\npaddleseg 2.6.0\r\nDeploying to OpenCV",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-07T13:10:36+00:00",
        "updated_at": "2024-07-13T12:44:11+00:00",
        "closed_at": "2024-07-13T12:44:07+00:00",
        "comments_count": [
            "yeliang2258",
            "ukoehler",
            "ukoehler",
            "ukoehler",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 988,
        "title": "paddle2onnx不支持op ,multinomial,softmax_with_cross_entropy",
        "body": "使用paddleREC训练的Mind模型，转Onnx格式出现不支持Op。\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including multinomial,softmax_with_cross_entropy,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted\r\n\r\n",
        "state": "closed",
        "user": "yangsuo",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-12-08T10:38:37+00:00",
        "updated_at": "2025-04-02T02:42:38+00:00",
        "closed_at": "2025-04-02T02:42:38+00:00",
        "comments_count": [
            "felixhjh",
            "yangsuo",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 987,
        "title": "PaddleDetection的PPYOLOE-R旋转框检测转onnx失败？",
        "body": "使用了PPYOLOE-R,提供的命令导出模型（模型导出正常），并将模型转为onnx格式时报错。\r\n导出命令：\r\npython tools/export_model.py -c configs/rotate/ppyoloe_r/ppyoloe_r_crn_s_3x_jiantou.yml  -o weights=output/ppyoloe_r_crn_s_3x_jiantou/best_model.pdparams  export_onnx=True\r\n转换命令：\r\npaddle2onnx --model_dir output_inference/ppyoloe_r_crn_s_3x_jiantou --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file ppyoloe_r_crn_l_3x_dota.onnx\r\n报错截图：\r\n![报错截图](https://user-images.githubusercontent.com/78832795/206328810-c11c3cd7-2f7a-4ee8-b1d9-4ebb450be606.png)\r\n报错信息：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: output_inference/ppyoloe_r_crn_s_3x_jiantou\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: output_inference/ppyoloe_r_crn_s_3x_jiantou\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR][Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] The 2-nd and 3-rd dimension of input bboxes tensor of multiclass_nms should be fixed, but now the shape is [-1, -1, 8].\r\n[Paddle2ONNX] Due to the operator: multiclass_nms3, this model cannot be exported to ONNX.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\n为什么需要转换为ONNX格式：模型要使用c#环境下推理。\r\n联系方式：1258937057@qq.com\r\n\r\n\r\n",
        "state": "closed",
        "user": "liang-stu",
        "closed_by": "liang-stu",
        "created_at": "2022-12-08T00:49:13+00:00",
        "updated_at": "2022-12-08T01:40:16+00:00",
        "closed_at": "2022-12-08T01:40:15+00:00",
        "comments_count": [
            "liang-stu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 989,
        "title": "DBNet++ 转成onnx后推理速度变慢",
        "body": "DBNet++模型在转换成onnx之后推理速度明显慢了很多，请问这个是什么原因呀？我对比了paddle自带的检测的onnx模型和db++的速度，db++推理一张图基本10s-30s 0.0，",
        "state": "closed",
        "user": "zr-icu",
        "closed_by": "zr-icu",
        "created_at": "2022-12-09T06:57:07+00:00",
        "updated_at": "2023-02-02T10:28:58+00:00",
        "closed_at": "2023-02-02T10:28:58+00:00",
        "comments_count": [
            "yeliang2258",
            "zr-icu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 990,
        "title": "Cannot found attribute iou_aware in op: yolo_box",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n[在这里下载的模型.](https://bj.bcebos.com/paddle2onnx/model_zoo/yolov3_mobilenet_v1_270e_coco.tar.gz)\r\n转换失败\r\n`\r\npaddle2onnx --model_dir ./paddle2onnx/models/yolov3_mobilenet_v1_270e_coco_paddle \\\r\n            --model_filename model.pdmodel \\\r\n            --params_filename model.pdiparams \\\r\n            --save_file yolov3_mobilenet_v1_.onnx \\\r\n            --enable_dev_version True \\\r\n            --opset_version 11\r\n`\r\n_[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./paddle2onnx/models/yolov3_mobilenet_v1_270e_coco_paddle/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./paddle2onnx/models/yolov3_mobilenet_v1_270e_coco_paddle/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Cannot found attribute iou_aware in op: yolo_box\r\nAborted (core dumped)\r\n_\r\n\r\n",
        "state": "closed",
        "user": "youngallien",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-12-12T06:15:39+00:00",
        "updated_at": "2025-04-01T02:53:50+00:00",
        "closed_at": "2025-04-01T02:53:49+00:00",
        "comments_count": [
            "yeliang2258",
            "chenqion",
            "xudaqian1",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 991,
        "title": "Request for supporting softmax_with_cross_entropy",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nFor the latest v1.0.5, it fails to convert the `softmax_with_cross_entropy` op.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: onnxruntime\r\n - Why convert to onnx：For deployment\r\n - Paddle2ONNX Version: 1.0.5 (I have also tested on 1.0.3, 1.0.2 and all of them do not work)\r\n\r\n**Screenshots**\r\n<img width=\"1227\" alt=\"截屏2022-12-12 14 59 02\" src=\"https://user-images.githubusercontent.com/25607475/207004841-5ab4c625-2255-4a68-a65d-a09179f6137a.png\">\r\n\r\n",
        "state": "closed",
        "user": "LemonNoel",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-12T09:09:14+00:00",
        "updated_at": "2024-05-22T04:25:13+00:00",
        "closed_at": "2024-05-22T04:25:13+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 993,
        "title": "PaddleOCR文字检测模型det_mv3_pse使用paddle2onnx转为onnx后速度下降",
        "body": "**问题描述**\r\n使用了PaddleOCR/configs/det/det_mv3_pse.yml和自己的数据集训练了一个文字检测模型\r\npaddle的每张图推理速度约为：GPU 0.1s, CPU 0.4s\r\nonnx的每张图推理速度约为：GPU 0.4s, CPU 1.6s\r\n\r\n**其他信息**\r\n版本： \r\nonnxruntime==1.11.0\r\npaddle2onnx==1.0.5\r\n\r\n转换命令\r\n```\r\npaddle2onnx --model_dir inference/det_mv3_pse \\\r\n            --model_filename inference.pdmodel \\\r\n            --params_filename inference.pdiparams \\\r\n            --save_file onnx_models/det_mv3_pse.onnx \\\r\n            --opset_version 11 \\\r\n            --enable_dev_version True \\\r\n            --enable_onnx_checker True \\ \r\n```\r\n\r\nonnx推理和速度计算\r\n```\r\nort_sess = onnxruntime.InferenceSession(\"PaddleOCR/onnx_models/det_mv3_pse.onnx\")\r\nort_inputs = {ort_sess.get_inputs()[0].name: x}\r\nstart = time.time()\r\nort_outs = ort_sess.run(None, ort_inputs)\r\ntime_used = time.time() - start\r\n```\r\n\r\n期待您的回复，谢谢啦。\r\n",
        "state": "closed",
        "user": "MianMianMeow",
        "closed_by": "MianMianMeow",
        "created_at": "2022-12-16T09:51:54+00:00",
        "updated_at": "2022-12-30T09:40:36+00:00",
        "closed_at": "2022-12-30T09:40:36+00:00",
        "comments_count": [
            "yeliang2258",
            "MianMianMeow"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 992,
        "title": "Cannot convert PaddleSeg SegNet to ONNX",
        "body": "When converting PaddleSeg SegNet after export to ONNX, I get the error that some operators are not supported:\r\n```\r\n(.venv) D:\\Local\\devel\\Python\\PaddleSeg\\PaddleSeg>paddle2onnx --model_dir SegNet\r\n --model_filename model.pdmodel --params_filename model.pdiparams --opset_versio\r\nn 11 --save_file SegNet/segnet_cityscapes_1024x512_80k.onnx\r\n```\r\nleads to following error:\r\n```\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: SegNet\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: SegNet\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including max_po\r\nol2d_with_index,unpool,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-12-13T10:30:52+00:00",
        "updated_at": "2025-04-01T02:53:49+00:00",
        "closed_at": "2025-04-01T02:53:48+00:00",
        "comments_count": [
            "ukoehler",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 994,
        "title": "不支持Paddlex中的BiSeNetv2导出为ONNX模型",
        "body": "**问题描述**\r\n\r\n将PaddleX训练出来的BiSeNetv2模型导出为ONNX模型出错：\r\n```\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: D:/temp/paddlex2onnx/best_infer_model/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: D:/temp/paddlex2onnx/best_infer_model/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including sync_batch_norm,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```\r\n命令行是：\r\n```\r\npaddle2onnx --model_dir D:/temp/paddlex2onnx/best_infer_model \r\n--model_filename D:/temp/paddlex2onnx/best_infer_model/model.pdmodel \r\n--params_filename D:/temp/paddlex2onnx/best_infer_model/model.pdiparams \r\n--opset_version 11 \r\n--save_file D:/temp/paddlex2onnx/best_infer_model/bisenetv2.onnx\r\n```\r\n\r\n**更多信息 :**\r\n - PaddleX: **2.1.0**\r\n - PadddlePaddle: **paddlepaddle-gpu 2.2.2**\r\n - Paddle2ONNX版本:  **1.0.5**\r\n\r\nPaddleX训练出来的DeepLabv3+同样存在该问题，这是否意味着PaddleX的代码在`sync_batch_norm`的处理上存在系统性的问题？\r\n\r\n相应的模型和配置文件请在次下载：\r\n[best_infer_model.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/10274702/best_infer_model.zip)\r\n\r\n谢谢\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "geoexploring",
        "closed_by": "geoexploring",
        "created_at": "2022-12-21T05:19:17+00:00",
        "updated_at": "2022-12-21T07:06:06+00:00",
        "closed_at": "2022-12-21T07:06:06+00:00",
        "comments_count": [
            "geoexploring",
            "geoexploring"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 995,
        "title": "paddle转换onnx，包含一些特殊算子如matmul,constant",
        "body": "将特别简单的模型如下：\r\n![image](https://user-images.githubusercontent.com/14801991/209111550-0967ccbc-c38f-4ec9-af0e-db037cacbd9a.png)\r\n使用paddle和tensorflow同时实现，均转换为onnx，paddle转换的onnx模型包含matmul,constant 等特殊算子，而tensorflow转换的不包含",
        "state": "closed",
        "user": "jiwenfei",
        "closed_by": "github-actions[bot]",
        "created_at": "2022-12-22T10:15:12+00:00",
        "updated_at": "2025-03-29T02:38:03+00:00",
        "closed_at": "2025-03-29T02:38:02+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiwenfei",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 998,
        "title": "不支持softmax_with_cross_entropy",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n使用paddleNLP训练的文本层次分类模型，转Onnx格式出现不支持的算子\r\n\r\n\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本: paddle2onnx-1.0.5\r\n\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/120088435/209309836-82ac7b8d-f9ec-47c6-9dea-004fd6970553.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "teensilenc",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-23T09:29:19+00:00",
        "updated_at": "2024-05-22T04:39:35+00:00",
        "closed_at": "2024-05-22T04:39:35+00:00",
        "comments_count": [
            "yeliang2258",
            "felixhjh",
            "yangsuo"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 996,
        "title": "可以支持翻译领域 mbart模型吗",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Amy234543",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-22T10:23:04+00:00",
        "updated_at": "2024-07-15T03:31:21+00:00",
        "closed_at": "2024-07-15T03:31:17+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1005,
        "title": "PaddleOCR onnx runtime 部署出错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n部署Paddle OCR 报参数错误\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/101111227/210594855-9c2c29ee-3975-4879-8fa7-6b39cb6ea234.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "203chenjing",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-04T15:52:32+00:00",
        "updated_at": "2024-07-15T03:30:58+00:00",
        "closed_at": "2024-07-15T03:30:58+00:00",
        "comments_count": [
            "jiangjiajun",
            "203chenjing",
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 999,
        "title": "bert_base_uncased 模型转onnx报错",
        "body": "想使用paddle2onnx讲bert_base_uncased模型转换为onnx,  报错信息为：\r\nException: Error happened when mapping node ['fill_any_like_0'] to onnx, which op_type is 'fill_any_like' with inputs: {'X': ['input_ids']} and outputs: {'Out': ['full_like_0.tmp_0']}, specific error: array(1) has type numpy.ndarray, but expected one of: int\r\n\r\n\r\n模型的链接为：https://paddlelite-demo.bj.bcebos.com/NNAdapter/models/PaddleNLP/bert_base_uncased.tgz\r\n请问我需要怎样才能转换成功呢？",
        "state": "closed",
        "user": "chenqion",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2022-12-23T10:14:53+00:00",
        "updated_at": "2024-07-15T03:31:11+00:00",
        "closed_at": "2024-07-15T03:31:11+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1006,
        "title": "关于paddle2onnx转换报错的求助",
        "body": "**问题描述**\r\n于win10使用paddle2onnx1.0.5尝试将PaddleOCR文本方向分类模型ch_ppocr_mobile_slim_v2.0_cls的部署模型向量化时出现报错:\r\n\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including \r\nfake_channel_wise_quantize_dequantize_abs_max,\r\nfake_quantize_dequantize_moving_average_abs_max,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n查询Issues发现该报错于20221130已有反馈 (https://github.com/PaddlePaddle/Paddle2ONNX/issues/975#issue-1469413313) 但未寻得解决方法，想请教下转onnx的方法\r\n\r\n**具体信息如下**\r\npaddle2onnx  --model_dir E:\\paddleModel\\cls_model\\ch_ppocr_mobile_v2.0_cls_slim_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --opset_version 11 --save_file E:\\paddleModel\\cls_model\\ch_ppocr_mobile_v2.0_cls_slim_infer\\inference.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: E:\\paddleModel\\cls_model\\ch_ppocr_mobile_v2.0_cls_slim_infer\\inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: E:\\paddleModel\\cls_model\\ch_ppocr_mobile_v2.0_cls_slim_infer\\inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [Info] The Paddle model is a quantized model.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including fake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n",
        "state": "closed",
        "user": "LimBoom",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-06T07:03:39+00:00",
        "updated_at": "2024-05-22T04:43:29+00:00",
        "closed_at": "2024-05-22T04:43:26+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1007,
        "title": "\"ernie-1.0\" requires paddle dependency running with paddle2onnx converted ONNX model",
        "body": "嘿\r\n\r\n我有一个标点符号模型并使用 paddle2onnx 转换为 ONNX，但它的预处理步骤有这个 'ernie-1.0' dependecny。\r\n这需要安装桨叶，这在树莓派上是不可能的。\r\n为此需要帮助。",
        "state": "closed",
        "user": "neso613",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-09T08:02:10+00:00",
        "updated_at": "2024-07-15T03:30:43+00:00",
        "closed_at": "2024-07-15T03:30:41+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1009,
        "title": "How to export the op not supported to onnx when I transfrom paddle model to onnx?",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：to onnx to trt\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone): liuxubit@163.com\r\n\r\nHello,\r\nHow to export the op not supported to onnx when I transfrom paddle model to onnx?\r\nfor example，I have a model with msda。The onnx doesn't has the op。 When I use torch, the op can be taken place by a fake op like this:\r\n![image](https://user-images.githubusercontent.com/39891612/211707244-39450ea3-cbe9-4475-82a2-14ec8f11cd1f.png)\r\nThen，I can export it to onnx like this:\r\n![image](https://user-images.githubusercontent.com/39891612/211707306-f37b1933-7342-45c5-8173-a83044e85dbf.png)\r\nAnd it can be used to generate a trt engine。\r\nSo if I use paddle model like rtformer，how can I reproduce the process like what I did in torch? Do you have the same function?\r\n\r\n",
        "state": "closed",
        "user": "liuxubit",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-11T02:56:14+00:00",
        "updated_at": "2024-11-19T08:16:22+00:00",
        "closed_at": "2024-11-19T08:16:22+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258"
        ],
        "labels": [
            "Enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1008,
        "title": "Cannot export deeplabv3p_xception65_humanseg to ONNX: Cannot found attribute padding_algorithm in op: conv2d",
        "body": "System\r\n=====´\r\nWindows 10\r\nPython 3.10.4\r\npaddle2onnx        1.0.5\r\npaddlefsl          1.1.0\r\npaddlehub          2.3.1\r\npaddlenlp          2.4.9\r\npaddlepaddle       2.4.1\r\npaddleseg          2.7.0     d:\\local\\devel\\python\\paddleseg_2.7.0\r\n\r\nPrepare\r\n=====\r\n```\r\nhub install deeplabv3p_xception65_\r\nhumanseg\r\nDownload https://bj.bcebos.com/paddlehub/paddlehub_dev/deeplabv3p_xception65_hum\r\nanseg_1_2_0.zip\r\n[##################################################] 100.00%\r\nDecompress C:\\Users\\ukoehler\\.paddlehub\\tmp\\tmptznv48kc\\deeplabv3p_xception65_hu\r\nmanseg_1_2_0.zip\r\n[##################################################] 100.00%\r\n[2023-01-10 12:09:39,796] [    INFO] - Successfully installed deeplabv3p_xceptio\r\nn65_humanseg-1.2.0\r\n```\r\n\r\nExport\r\n====\r\n```\r\n(.venv) D:\\Local\\devel\\Python\\PaddleSeg_2.7.0>paddle2onnx --model_dir C:\\Users\\u\r\nkoehler\\.paddlehub\\modules\\deeplabv3p_xception65_humanseg\\deeplabv3p_xception65_\r\nhumanseg_model  --model_filename model.pdmodel --params_filename model.pdiparams\r\n --save_file deeplabv3p_xception65_humanseg\\deeplabv3p_xception65_humanseg.onnx\r\n--opset_version 11 --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: C:\\Users\\ukoehler\\.paddlehub\\modules\\deeplabv3p_x\r\nception65_humanseg\\deeplabv3p_xception65_humanseg_model\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: C:\\Users\\ukoehler\\.paddlehub\\modules\\deeplabv\r\n3p_xception65_humanseg\\deeplabv3p_xception65_humanseg_model\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Cannot found attribute padding_algorithm in op: conv2d\r\n```\r\n\r\nFiles\r\n===\r\nhttps://drive.google.com/file/d/1NKmH2MDedriomeKgEIHEvQBCEh72xiez/view?usp=sharing\r\nhttps://drive.google.com/file/d/1KyaAXdfo-d0mM7-nik95e99Y9-RAutDK/view?usp=sharing",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-10T13:06:53+00:00",
        "updated_at": "2024-05-22T05:18:46+00:00",
        "closed_at": "2024-05-22T05:18:37+00:00",
        "comments_count": [
            "yeliang2258",
            "ukoehler",
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1011,
        "title": "模型转换时缺少中间节点的shape信息",
        "body": "## 设备信息\r\n\r\nSystem: Linux x86\r\nPaddle2ONNX Version: 1.0.5\r\n\r\n## bash\r\n\r\n```bash\r\n# Down\r\nwget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar\r\ntar -xvf ch_PP-OCRv3_det_infer.tar\r\n\r\n## export to onnx\r\npaddle2onnx --model_dir ch_PP-OCRv3_det_infer \\\r\n            --model_filename inference.pdmodel \\\r\n            --params_filename inference.pdiparams \\\r\n            --save_file ch_PP-OCRv3_det_infer/ch_PP-OCRv3_det_infer.onnx \\\r\n            --enable_dev_version True\r\n```\r\n\r\n## error node\r\nnode name: p2o.Add.84\r\nnode picture:\r\n<img width=\"1324\" alt=\"image\" src=\"https://user-images.githubusercontent.com/58363586/212242840-4ca9231c-2c49-41f9-ba29-30635ed65fa5.png\">\r\n",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-13T05:16:22+00:00",
        "updated_at": "2023-03-08T02:15:57+00:00",
        "closed_at": "2023-03-08T02:15:57+00:00",
        "comments_count": [
            "jiangjiajun",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "jiangjiajun",
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1010,
        "title": "there are some operators not supported yet, including deformable_conv,matrix_nms,",
        "body": "System\r\n=====\r\nubuntu20.04\r\nPython 3.8.10\r\npaddle2onnx 1.0.5\r\npaddlepaddle-gpu 2.3.1\r\n\r\nexport\r\n=====\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: output_inference/stu/ppyolov2_r50vd_dcn_voc_stu/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: output_inference/stu/ppyolov2_r50vd_dcn_voc_stu/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,matrix_nms,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n",
        "state": "closed",
        "user": "chenj133",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-01-12T03:50:16+00:00",
        "updated_at": "2025-03-29T02:38:01+00:00",
        "closed_at": "2025-03-29T02:38:00+00:00",
        "comments_count": [
            "chenj133",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1016,
        "title": "solov2导出模型转换为onnx出现不支持的算子",
        "body": "您好，我使用paddle2onnx工具转换PaddleDetection算法中的Solov2导出模型出现了不支持的算子。\r\npaddle2onnx版本：1.0.5    paddle2paddle版本：2.3.0 \r\n导出指令：\r\npaddle2onnx --model_dir tube/ --model_filename model.pdmodel --params_filename model.pdiparams --save_file tube/test_tube.onnx --enable_onnx_checker True --enable_dev_version False --opset_version 16\r\n下边是报错信息：\r\nNotImplementedError:\r\nThere's 3 ops are not supported yet\r\n=========== select_input ===========\r\n=========== conditional_block ===========\r\n=========== tril_triu ===========\r\n\r\nPaddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: tube/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: tube/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,select_input,tril_triu,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n",
        "state": "closed",
        "user": "fanxiaochen456",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-31T01:37:43+00:00",
        "updated_at": "2024-07-13T12:35:52+00:00",
        "closed_at": "2024-07-13T12:35:46+00:00",
        "comments_count": [
            "yeliang2258",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1018,
        "title": "是否考虑加入pad算子呢",
        "body": "**问题描述**\r\n当我尝试将基于paddle的blazeface模型导出为onnx时，出现了错误指示paddle2onnx不支持pad算子的映射\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: OPENVINO\r\n - 为什么需要转换为ONNX格式：需要过渡\r\n - Paddle2ONNX版本: 1.0.5\r\n - 你的联系方式(Email/Wechat/Phone): Wechat13129644949\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/80210404/216079943-eef61290-377b-41e0-8de4-07e5311a141f.png)\r\n\r\n\r\n\r\n\r\n如果没有此更新计划，是否有其他方式让我把该paddle模型部署到openvino上",
        "state": "closed",
        "user": "Yubo-Shankui",
        "closed_by": "Yubo-Shankui",
        "created_at": "2023-02-01T15:06:31+00:00",
        "updated_at": "2023-02-01T15:11:02+00:00",
        "closed_at": "2023-02-01T15:11:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1013,
        "title": "paddleocr_kie_ser模型转onnx报错",
        "body": "kie_algorithm=LayoutXLM\r\npaddle2onnx==0.9.1\r\n\r\n转onnx命令行：\r\npaddle2onnx --model_dir ./inference/ser_vi_layoutxlm_bank --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/ser_onnx/model.onnx --opset_version 11  --enable_onnx_checker True\r\n\r\n报错\r\n \r\n\r\n\r\n脚本/ppstructure/kiepredict_kie_token_ser.py  是否支持onnx推理\r\n\r\n",
        "state": "closed",
        "user": "LJY6356",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-01-16T03:27:13+00:00",
        "updated_at": "2024-07-15T04:15:27+00:00",
        "closed_at": "2024-07-15T04:15:22+00:00",
        "comments_count": [
            "yeliang2258",
            "LJY6356",
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1017,
        "title": "是否考虑加入pad算子呢",
        "body": "**问题描述**\r\n当我尝试将基于paddle的blazeface模型导出为onnx时，出现了错误指示paddle2onnx不支持pad算子的映射\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: OPENVINO\r\n - 为什么需要转换为ONNX格式：需要过渡\r\n - Paddle2ONNX版本: 1.0.5\r\n - 你的联系方式(Email/Wechat/Phone): Wechat13129644949\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/80210404/216079943-eef61290-377b-41e0-8de4-07e5311a141f.png)\r\n\r\n\r\n\r\n\r\n如果没有此更新计划，是否有其他方式让我把该paddle模型部署到openvino上",
        "state": "closed",
        "user": "Yubo-Shankui",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-01T15:06:21+00:00",
        "updated_at": "2024-05-22T04:41:00+00:00",
        "closed_at": "2024-05-22T04:40:54+00:00",
        "comments_count": [
            "jiangjiajun",
            "Yubo-Shankui",
            "jiangjiajun",
            "Yubo-Shankui",
            "jiangjiajun"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1022,
        "title": "PaddleOCR rec_mv3_tps_bilstm_ctc 模型转ONNX出错",
        "body": "对PaddleOCR提供的rec_mv3_tps_bilstm_ctc 模型使用paddle2onnx工具报以下错误：\r\n```text\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including inverse,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: ascend\r\n - Paddle2ONNX版本:paddle2onnx-1.0.5 \r\n - 你的联系方式:jadehh@live.com\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/20532462/217130009-ac1157ca-1298-4c1a-a41b-22584e1a4900.png)\r\n\r\n**模型截图**\r\n![image](https://user-images.githubusercontent.com/20532462/217130104-466493c3-3d3f-4015-9e1b-2f772e277748.png)\r\n\r\n**模型地址**\r\n[下载地址](https://github.com/jadehh/jadehh_file/releases/download/ContainerOCRModelsV1.0.3/inference.pdmodel)",
        "state": "closed",
        "user": "jadehh",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-07T02:13:01+00:00",
        "updated_at": "2025-03-28T02:41:54+00:00",
        "closed_at": "2025-03-28T02:41:54+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Enhancement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1019,
        "title": "如何将转换的onnx模型format ONNX v8转换为v7",
        "body": "\r\n![image](https://user-images.githubusercontent.com/36955510/216269457-5fd5a789-4dfc-4a83-8c7b-ff35d48423d9.png)\r\n\r\n使用paddle2onnx转换的onnx模型默认format是onnx v8，我现在需要v7 format的onnx模型，我应该如何设置。",
        "state": "closed",
        "user": "LiquorPerfect",
        "closed_by": "LiquorPerfect",
        "created_at": "2023-02-02T08:19:37+00:00",
        "updated_at": "2024-03-13T07:28:22+00:00",
        "closed_at": "2024-03-13T07:28:22+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1024,
        "title": "floating point exception both in macOS and linux",
        "body": "\"Floating point exception\" error both in linux and macOS when trying to load converted SVTR-Tiny text recognition model. SVTR-Large model which is converted to .onnx  works just fine.\r\n\r\nCode:\r\n\r\n```\r\nfrom onnxruntime import InferenceSession, SessionOptions\r\noptions = SessionOptions()\r\nsession = InferenceSession('./inference/svtr_tiny.onnx', options, providers=[\"CPUExecutionProvider\"])\r\n```\r\nOpset version is 16. Paddle2ONNX Version latest.\r\n",
        "state": "closed",
        "user": "andreybondarb",
        "closed_by": "andreybondarb",
        "created_at": "2023-02-08T15:08:44+00:00",
        "updated_at": "2023-02-10T09:30:08+00:00",
        "closed_at": "2023-02-10T08:35:39+00:00",
        "comments_count": [
            "yeliang2258",
            "andreybondarb",
            "yeliang2258",
            "andreybondarb",
            "andreybondarb"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1029,
        "title": "Where is the list of supported segmentation models?",
        "body": "I'd like to train a segmentation model. But I need to deploy it in onnx format. So I'd like to know where is the list of supported segmentation models?",
        "state": "closed",
        "user": "LLsmile",
        "closed_by": "LLsmile",
        "created_at": "2023-02-15T10:34:01+00:00",
        "updated_at": "2023-02-15T10:35:36+00:00",
        "closed_at": "2023-02-15T10:35:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1026,
        "title": "自己用Paddle2ONNX转中英文超轻量PP-OCRv2模型到onnx，与官方转好的onnx模型，输入和输出存在区别",
        "body": "自己用Paddle2ONNX转中英文超轻量PP-OCRv2模型到onnx，与官方转好的onnx模型，输入和输出存在区别。官方的onnx可以动态输入，自己转的不行，例如文本检测模型DB输入必须为[1, 3, 960，960]\r\n\r\n![image](https://user-images.githubusercontent.com/46981976/218052133-0902b4b0-0efc-42fc-b0c4-9150035e9c0e.png)\r\n上图上面为官方转的onnx，下图自己转的onnx。\r\n\r\npython infer.py --det_model_dir=./ch_PP-OCRv2_det_infer.onnx --rec_model_dir=./ch_PP-OCRv2_rec_infer.onnx --cls_model_dir=./ch_ppocr_mobile_v2.0_cls_infer.onnx --image_path=./images/lite_demo.png  执行报错：\r\n\r\nTraceback (most recent call last):\r\n  File \"H:/PaddleOcr/Paddle2ONNX-develop/model_zoo/ocr/infer.py\", line 143, in <module>\r\n    dt_boxes = text_detector(img)\r\n  File \"H:\\PaddleOcr\\Paddle2ONNX-develop\\model_zoo\\ocr\\utils\\predict_det.py\", line 332, in __call__\r\n    outputs = self.predictor.run(None, input_dict)\r\n  File \"H:\\Anaconda3\\envs\\paddle_env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 200, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: x for the following indices\r\n index: 2 Got: 288 Expected: 960\r\n index: 3 Got: 448 Expected: 960\r\n Please fix either the inputs or the model.\r\n\r\n\r\n请问怎样用paddle2ONNX转换ocr模型跟官方的一样，能实现动态输入大小？",
        "state": "closed",
        "user": "cdycdycdy",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-10T09:22:21+00:00",
        "updated_at": "2024-07-15T03:30:24+00:00",
        "closed_at": "2024-07-15T03:30:19+00:00",
        "comments_count": [
            "yeliang2258",
            "cdycdycdy"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1028,
        "title": "Error during conversion of a PaddleOCR model to ONNX ",
        "body": "Hello, I'm using paddle2onnx-1.0.5 with python>=3.6, paddlepaddle>=2.0.0 on macOS with M1 chip. \r\n\r\nI want to convert _latin_PP-OCRv3_rec_ model downloaded from [the model zoo](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md).\r\n\r\n```\r\npaddle2onnx --model_dir latin_PP-OCRv3_rec_infer \\\r\n--model_filename inference.pdmodel \\\r\n--save_file latin.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /Users/drajsel/Downloads/latin_PP-OCRv3_rec_infer/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path:\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 9 for ONNX export.\r\nTraceback (most recent call last):\r\n  File \"/Users/drajsel/.pyenv/versions/paddle2onxx/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/drajsel/.pyenv/versions/paddle2onxx/lib/python3.9/site-packages/paddle2onnx/command.py\", line 233, in main\r\n    c_paddle_to_onnx(\r\n  File \"/Users/drajsel/.pyenv/versions/paddle2onxx/lib/python3.9/site-packages/paddle2onnx/command.py\", line 143, in c_paddle_to_onnx\r\n    onnx_model_str = c_p2o.export(\r\nIndexError: Input conv2d_0.w_0 is undefined!\r\n```\r\n\r\nI haven't seen any issue with this error so far. Is it possible to convert PP-OCRv3 models to ONNX?",
        "state": "closed",
        "user": "djalusic",
        "closed_by": "djalusic",
        "created_at": "2023-02-14T09:45:03+00:00",
        "updated_at": "2023-02-14T10:59:43+00:00",
        "closed_at": "2023-02-14T10:59:42+00:00",
        "comments_count": [
            "yeliang2258",
            "djalusic"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1027,
        "title": "能否paddle2onnx支技data_formate=NHWC的模型转换成onnx",
        "body": "在有paddleocr自己训练一个rostta模理，正常的默认是 NCHW格式。具体流程是image(NCHW)-》CNN(NCHW,H=1)-》Reshape(NCW)-》Transpose(NWC)-》FC.遇到的问题是要在特定的芯片上部署，不支持Transpose算子。改成image(NHWC)-》CNN(NHWC,H=1)-》Reshape(NWC)-》FC，这样，把transpose做到了预处理当中，就不存在与模型中。paddle的动静态模型都是能保存成功的，但是转onnx时报错，提示：Conv2d:convwd_39.tmp_0 cannot support input with nhwc..ERROR Due to the operatorL conv2d,this model cannot be export ed to onnx.",
        "state": "closed",
        "user": "DLlearn",
        "closed_by": "DLlearn",
        "created_at": "2023-02-13T09:44:26+00:00",
        "updated_at": "2023-02-14T07:03:43+00:00",
        "closed_at": "2023-02-14T07:03:43+00:00",
        "comments_count": [
            "yeliang2258",
            "DLlearn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1032,
        "title": "混合量化模型转 onnx 失败",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n使用 paddleslim 对训练好的 picodet 模型进行量化，然后选择了\r\n    onnx_format=True,\r\n    activation_bits=16,\r\n然后利用 paddle2onnx 把量化得到的模型转化成 onnx 时出错。如果 activation_bits=8 则可以成功。\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: ncnn\r\n - Why convert to onnx：i need to trans the model to ncnn format\r\n - Paddle2ONNX Version: 1.0.5\r\n - Email/Wechat/Phone: 702864842@qq.com\r\n\r\n**Screenshots**\r\n![error](https://user-images.githubusercontent.com/54938217/219327613-a2550ab5-82a7-4356-8c9b-16893993e1bc.jpg)\r\n\r\n\r\n**Additional context**\r\nnone",
        "state": "closed",
        "user": "Huangdebo",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-16T09:43:02+00:00",
        "updated_at": "2025-03-27T02:40:25+00:00",
        "closed_at": "2025-03-27T02:40:25+00:00",
        "comments_count": [
            "yeliang2258",
            "Huangdebo",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1030,
        "title": "Rtformer的onnx文件无法利用openvino转为.bin和.xml文件",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n Cannot infer shapes or values for node \"p2o.MaxPool.0\".\r\nStride can not be zero in node p2o.MaxPool.0\r\n之前是有些算子不支持，现在升级了paddle2onnx，能够转onnx文件，但是不能将onnx文件转成其他文件类型。\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:openvino\r\n - 为什么需要转换为ONNX格式：支持openvino推理\r\n - Paddle2ONNX版本:1.0.5\r\n - 你的联系方式(Email/Wechat/Phone):2317677054@qq.com\r\n\r\n**报错截图**\r\n\r\n![image](https://user-images.githubusercontent.com/82746353/219259979-bd77b0b1-2c03-45de-b01d-5835d3913165.png)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "zzyy520",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-16T03:29:14+00:00",
        "updated_at": "2024-07-15T04:15:12+00:00",
        "closed_at": "2024-07-15T04:15:10+00:00",
        "comments_count": [
            "yeliang2258",
            "zzyy520",
            "yeliang2258",
            "zzyy520"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1033,
        "title": "cannot convert PP-HumanSegV1-Lite to onnx - ValueError: basic_string::resize",
        "body": "while trying to convert the [PP-HumanSegV1-Lite](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.7/contrib/PP-HumanSeg#42-general-human-segmentation-models) (checkpoint) to onnx Im getting the following error : \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/labeeb/miniconda3/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/labeeb/miniconda3/lib/python3.9/site-packages/paddle2onnx/command.py\", line 233, in main\r\n    c_paddle_to_onnx(\r\n  File \"/home/labeeb/miniconda3/lib/python3.9/site-packages/paddle2onnx/command.py\", line 143, in c_paddle_to_onnx\r\n    onnx_model_str = c_p2o.export(\r\nValueError: basic_string::resize\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/94868003/219573671-88e381b6-beda-42a1-a36a-64d01db91b9e.png)\r\n\r\nWhat can I do differently to convert the model in onnx form? Thanks\r\n\r\nSystem : pop-os (ubuntu based) 22.04\r\npaddle2onnx version : 1.0.5\r\n",
        "state": "closed",
        "user": "labeeb-7z",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-17T07:10:07+00:00",
        "updated_at": "2024-07-15T03:30:09+00:00",
        "closed_at": "2024-07-15T03:30:06+00:00",
        "comments_count": [
            "yeliang2258",
            "vvwomen"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1034,
        "title": "PaddleOCR v3 文本识别onnx模型在ort-gpu加载失败",
        "body": "**问题描述**\r\n使用onnxruntime(1.10.0)可正常加载；在onnxruntime-gpu(1.4.0)无法加载，如下图。机器是2080ti，cuda 10.2，paddle2onnx版本为1.0.5\r\n![image](https://user-images.githubusercontent.com/26057369/219607709-75446dbf-4d3e-48d9-a47b-75b95bcbbee1.png)\r\n\r\n",
        "state": "closed",
        "user": "lzj9072",
        "closed_by": "lzj9072",
        "created_at": "2023-02-17T09:37:38+00:00",
        "updated_at": "2023-02-17T09:45:59+00:00",
        "closed_at": "2023-02-17T09:45:59+00:00",
        "comments_count": [
            "jiangjiajun",
            "lzj9072"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1038,
        "title": "var  image not in this block",
        "body": null,
        "state": "closed",
        "user": "thunder95",
        "closed_by": "thunder95",
        "created_at": "2023-02-22T03:38:44+00:00",
        "updated_at": "2023-02-22T03:46:29+00:00",
        "closed_at": "2023-02-22T03:46:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1035,
        "title": "Oops, there are some operators not supported yet, including conditional_block,inverse,select_input,",
        "body": "在导出 导出onnx时出现：\r\n paddle2onnx --model_dir fom_dy2st --model_filename generator.pdmodel --params_filename generator.pdiparams --save_file fom_dy2st/generator.onnx --opset_version 11 --enable_onnx_checker True \r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: fom_dy2st/generator.pdmodel\r\n[Paddle2ONNX] Paramters file path: fom_dy2st/generator.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,inverse,select_input,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\n请问如何解决呢",
        "state": "closed",
        "user": "wojiaoyanmin",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-21T07:49:31+00:00",
        "updated_at": "2025-03-21T02:39:48+00:00",
        "closed_at": "2025-03-21T02:39:47+00:00",
        "comments_count": [
            "yeliang2258",
            "wojiaoyanmin",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1036,
        "title": "Missing support padding='same' in depthewise_conv2d",
        "body": "Forwarded the bug from PaddleSeg https://github.com/PaddlePaddle/PaddleSeg/issues/2732\r\n\r\nAccording to them there is missing support in paddle2ONNX:\r\n\r\n```\r\nThe paddle2onnx issue is because they did not support padding='same' in depthewise_conv2d, \r\nyou can try put forward an issue in paddle2onnx: https://github.com/PaddlePaddle/Paddle2ONNX.\r\n```",
        "state": "closed",
        "user": "ukoehler",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-21T08:46:16+00:00",
        "updated_at": "2024-05-22T04:23:43+00:00",
        "closed_at": "2024-05-22T04:23:43+00:00",
        "comments_count": [
            "yeliang2258",
            "ukoehler",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1039,
        "title": "Oops, there are some operators not supported yet, including diag_v2,softmax_with_cross_entropy",
        "body": "**问题描述**\r\n转化simcse模型出现不支持的算子\r\n模型为paddlenlp example中的simcse模型\r\n**报错截图**\r\n>>> [InferBackend] Creating Engine ...\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./export/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./export/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including diag_v2,softmax_with_cross_entropy,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n",
        "state": "closed",
        "user": "noobexplore",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-23T11:32:31+00:00",
        "updated_at": "2025-03-19T02:39:11+00:00",
        "closed_at": "2025-03-19T02:39:11+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "noobexplore",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1040,
        "title": " Oops, there are some operators not supported yet, including ctc_align,im2sequence,lstm",
        "body": "![image](https://user-images.githubusercontent.com/28892888/221448066-95790514-65c4-4ccc-8b7a-a4339c935118.png)\r\n",
        "state": "closed",
        "user": "YQY458",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-27T00:44:34+00:00",
        "updated_at": "2025-03-18T02:40:25+00:00",
        "closed_at": "2025-03-18T02:40:24+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1037,
        "title": "在使用ssdlite_mobilenet_v1_300_coco模型转为onnx遇到算子不支持",
        "body": "你好我使用python tools/export_model.py -c configs/ssd/ssdlite_mobilenet_v1_300_coco.yml --output_dir=./inference_model -o weights=output/ssdlite_mobilenet_v1_300_coco/best命令导出模型并且转到onnx时遇到如下问题\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_model/ssdlite_mobilenet_v1_300_coco/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_model/ssdlite_mobilenet_v1_300_coco/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including prior_box,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n已放弃 (核心已转储)\r\n\r\n请问应该如何解决？",
        "state": "closed",
        "user": "impossible5657",
        "closed_by": "impossible5657",
        "created_at": "2023-02-21T08:59:05+00:00",
        "updated_at": "2023-02-22T08:01:52+00:00",
        "closed_at": "2023-02-22T08:01:52+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1041,
        "title": " converting pp-liteseg model to onnx format for C++ deployment",
        "body": "\r\n\r\nWhen I convert the a model to onnx format for C++ deployment, an error is reported that I don't get the names of the inputs and outputs\r\n\r\n When I check the converted onnx, it says check is none\r\n\r\nThe pytorch model  can be converted with the following functions:\r\n\r\nwith torch.no_grad():\r\n    torch.onnx.export(\r\n        model, dummy_input,\r\n        output_file,\r\n        input_names=['input'],\r\n        output_names=['output'],\r\n        export_params=True,\r\n        keep_initializers_as_inputs=False,\r\n        opset_version=11,\r\n        dynamic_axes=dynamic_axes)\r\n\r\nI would like to know how input_names and output_names are specified in paddle\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime\r\n - 为什么需要转换为ONNX格式：for C++ deployment\r\n - Paddle2ONNX版本: \r\n - 你的联系方式(Email/Wechat/Phone): \r\n\r\n**报错截图**\r\n\r\ninline char* Session::GetInputName(size_t index, OrtAllocator* allocator) const {\r\n  char* out;\r\n  ThrowOnError(GetApi().SessionGetInputName(p_, index, allocator, &out));\r\n  return out;\r\n}\r\n\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "EudicL",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-27T07:55:23+00:00",
        "updated_at": "2024-07-15T03:29:09+00:00",
        "closed_at": "2024-07-15T03:28:48+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1042,
        "title": "mobileseg_shufflenetv2 导出报错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nW0228 17:40:05.151883 24972 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.4, Runtime API Version: 11.1\r\nW0228 17:40:05.173039 24972 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n2023-02-28 17:40:07 [INFO]      Loading pretrained model from https://paddleseg.bj.bcebos.com/dygraph/backbone/shufflenetv2_x1_0.zip\r\n2023-02-28 17:40:07 [INFO]      There are 275/275 variables loaded into ShuffleNet.\r\n2023-02-28 17:40:07 [INFO]      Loaded trained params of model successfully.\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmpp9nemwh5.py:26\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmp6zud28gx.py:7\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmpgrc0jysf.py:7\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /tmp/tmp5mcont17.py:7\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\n2023-02-28 17:40:11 [INFO]      Model is saved in ./output/mobilennetv3_psphead__256x256_80k/.\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  np.bool: core.VarDesc.VarType.BOOL,\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.FP32: np.float,\r\n/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/constant/dtypes.py:53: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  core.VarDesc.VarType.BOOL: np.bool\r\nTraceback (most recent call last):\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 119, in mapping\r\n    mapper_func(graph, node, **kw)\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/op_mapper/nn.py\", line 167, in opset_1\r\n    raise Exception(\r\nException: Converting this model to ONNX need with static input shape, please fix input shape of this model, see doc Q2 in https://github.com/PaddlePaddle/paddle2onnx/blob/develop/docs/en/FAQ.md.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/dell/anaconda3/envs/bagtorch/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/command.py\", line 218, in main\r\n    program2onnx(\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/command.py\", line 173, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 94, in program2onnx\r\n    return export_onnx(\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 35, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version,\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 331, in build\r\n    onnx_graph.build_op_nodes(paddle_graph.node_map)\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/graph/onnx_graph.py\", line 209, in build_op_nodes\r\n    OpMapper.mapping(self, node, self.operator_export_type)\r\n  File \"/home/dell/anaconda3/envs/bagtorch/lib/python3.8/site-packages/paddle2onnx/op_mapper/op_mapper.py\", line 121, in mapping\r\n    raise Exception(\r\nException: Error happened when mapping node ['pool2d_2'] to onnx, which op_type is 'pool2d' with inputs: {'X': ['reshape2_31.tmp_0']} and outputs: {'Out': ['pool2d_2.tmp_0']}, specific error: Converting this model to ONNX need with static input shape, please fix input shape of this model, see doc Q2 in https://github.com/PaddlePaddle/paddle2onnx/blob/develop/docs/en/FAQ.md.\r\n\r\n\r\n",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-02-28T09:49:11+00:00",
        "updated_at": "2025-03-18T02:40:23+00:00",
        "closed_at": "2025-03-18T02:40:23+00:00",
        "comments_count": [
            "yeliang2258",
            "chen-del",
            "chen-del",
            "13950182204",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleSeg",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1043,
        "title": "[Feature Request] 建议新增 bitwise_and、bitwise_not、conditional_block、empty、select_input 算子",
        "body": "## update 2023.03.23\r\n移除了 elementwise_floordiv 算子：\r\nhttps://paddlespeech.bj.bcebos.com/demos/paddle_work/vits_csmsc_ckpt_1.4.0_6.zip\r\n可能存在的问题，可能有算子输出的 0D Tensor shape 为 [] \r\n用的是 2023.03.12 的 paddle develop 导出的静态模型，已经有些算子支持了 0D Tensor\r\n<img width=\"645\" alt=\"38e6964798caf29940f3d6a5e35f6751\" src=\"https://user-images.githubusercontent.com/24568452/227108891-aafe2a35-7f8d-4ebd-b027-ccde00982c8b.png\">\r\n\r\n## update 2023.03.15\r\n\r\nLite 同学反馈某个 elemul 的输入类型是 bool，但是 lite 不支持，于是提前 cast 成 int64 了：\r\n\r\nhttps://paddlespeech.bj.bcebos.com/demos/paddle_work/vits_csmsc_ckpt_1.4.0_5.zip\r\n## update 2023.03.14\r\nLite 同学反馈最后一个 expand_v2 算子 expand shape 的 dtype 不一致，修改组网代码后重新导出模型如下：\r\n\r\nhttps://paddlespeech.bj.bcebos.com/demos/paddle_work/vits_csmsc_ckpt_1.4.0_4.zip\r\n\r\n## update 2023.03.13\r\n\r\nLite 同学反馈 reduce_sum 算子输入和输出类型不一致，输入为 bool 输出为 int64 ，修改组网代码重新导出模型如下：\r\n\r\nhttps://paddlespeech.bj.bcebos.com/demos/paddle_work/vits_csmsc_ckpt_1.4.0_3.zip\r\n\r\n## update\r\nlite 反馈 pad 算子加起来比较复杂，我把 F.pad 转成了 nn.Pad1D 和 nn.Pad2D 成功移除了 pad 算子（变成了已有的 pad3d 算子），因此不再需要实现的 pad 算子了\r\n\r\n目前的报错：\r\n![image](https://user-images.githubusercontent.com/24568452/223414921-3e87341c-558b-4d19-81cb-23f12513ae2f.png)\r\n\r\n\r\n去掉 pad 算子的模型：https://paddlespeech.bj.bcebos.com/demos/paddle_work/vits_csmsc_ckpt_1.4.0_2.zip\r\n\r\n----\r\n\r\nPaddleSpeech VITS 模型使用 Paddle2ONNX 缺少上述算子，了解到 conditional_block 算子加起来比较复杂，故这些算子新增不是强需求，提个 Feature Request 占下坑，后续如果有对 conditional_block 的新增计划，可以用 VITS 模型做测试\r\n![image](https://user-images.githubusercontent.com/24568452/221859756-e176a7df-8511-4383-b298-a2d010a48bdd.png)\r\n",
        "state": "closed",
        "user": "yt605155624",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-02-28T12:54:43+00:00",
        "updated_at": "2024-07-13T12:35:27+00:00",
        "closed_at": "2024-07-13T12:35:27+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1046,
        "title": "some operators not supported yet",
        "body": "[Paddle2ONNX] Oops, there are some operators not supported yet, including mv,\r\nmv算子还未支持对我来说很重要\r\n![1677723912799](https://user-images.githubusercontent.com/44335783/222314865-46cdae68-7700-44e7-8bef-a525e3a89e6f.png)\r\n",
        "state": "closed",
        "user": "Whatsetsthisend",
        "closed_by": "yeliang2258",
        "created_at": "2023-03-02T02:25:30+00:00",
        "updated_at": "2023-04-13T07:14:35+00:00",
        "closed_at": "2023-04-13T07:14:35+00:00",
        "comments_count": [
            "yeliang2258",
            "Whatsetsthisend",
            "Whatsetsthisend",
            "yeliang2258",
            "yeliang2258",
            "Whatsetsthisend"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1049,
        "title": "Hit Error: module paddle has no attibute ‘enable'",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n使用工具paddle_infer_shape.py修改模型输入参数出现报错：paddle has no attibute ‘enable'\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/87652697/223068338-3fa5fe1c-1e2c-47dc-94d8-6df83ee56ac0.png)\r\n\r\n\r\n**其他信息**\r\npaddle.__version__ = 1.0.2",
        "state": "closed",
        "user": "supercatking",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-03-06T09:22:12+00:00",
        "updated_at": "2024-07-15T04:14:48+00:00",
        "closed_at": "2024-07-15T04:14:39+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Paddle(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1048,
        "title": "rec_r34_vd_none_bilstm_ctc.yml 转onnx input shape要求是32，不是yml中的48，导致识别结果不对，怎么解决？",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: \r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n\r\n\r\nrec_r34_vd_none_bilstm_ctc.yml 转onnx input shape要求是32，不是yml中的48，导致识别结果不对，怎么解决？\r\n\r\nTrain:\r\n  dataset:\r\n    name: SimpleDataSet\r\n    data_dir: F:/\r\n    label_file_list: F:/paddletest.txt\r\n    transforms:\r\n      - DecodeImage: # load image\r\n          img_mode: BGR\r\n          channel_first: False\r\n      - CTCLabelEncode: # Class handling label\r\n      - RecResizeImg:\r\n          image_shape: [3, 48, 320]\r\n      - KeepKeys:\r\n          keep_keys: ['image', 'label', 'length'] # dataloader will return list in this order\r\n  loader:\r\n    shuffle: True\r\n    batch_size_per_card: 256\r\n    drop_last: True\r\n    num_workers: 8\r\n\r\n用--input_shape_dict \"{'x':[-1,3,-1,-1]}\" 转换得到的模型也报错\r\n\r\n\r\n--input_shape_dict \"{'x':[-1,3,48,-1]}\"\r\nfailed:Node (p2o.Reshape.0) Op (Reshape) [ShapeInferenceError] Invalid Target shape product of 0\r\n",
        "state": "closed",
        "user": "nissansz",
        "closed_by": "nissansz",
        "created_at": "2023-03-04T21:46:36+00:00",
        "updated_at": "2023-05-13T13:40:32+00:00",
        "closed_at": "2023-05-13T13:40:32+00:00",
        "comments_count": [
            "yeliang2258",
            "nissansz",
            "nissansz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1053,
        "title": "pp-yoloe-r导出onnx如何固定输入",
        "body": "默认方式导出的onnx为多batch状态，我想导出一个输入为1*3*640*640的onnx，按照[教程](https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle)修改输入后，只改了输入image，还有个scale参数没有修改，而且导致输出也是之前的奇怪状态：\r\n![Screenshot from 2023-03-10 14-18-33](https://user-images.githubusercontent.com/18437178/224239910-038ff296-25f1-40d6-b734-723a0e2eb7f6.png)\r\n\r\n修改输入的命令:\r\npython paddle_infer_shape.py --model_dir ../../PaddleDetection/output_inference/ppyoloe_r_crn_m_3x_dota/ --model_filename model.pdmodel --params_filename model.pdiparams --save_dir renamed.onnx --input_shape_dict=\"{'image':[1,3,640,640]}\"\r\n\r\n所以想问一下怎么固定pp-yoloe-r的输入尺寸？\r\n",
        "state": "closed",
        "user": "LLsmile",
        "closed_by": "LLsmile",
        "created_at": "2023-03-10T06:27:19+00:00",
        "updated_at": "2023-03-16T01:40:34+00:00",
        "closed_at": "2023-03-16T01:40:34+00:00",
        "comments_count": [
            "yeliang2258",
            "LLsmile",
            "LLsmile"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1050,
        "title": "Hit error when running prune_paddle_model.py: Undefined symbol: shm_unlink",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nImportError: /usr/local/lib/python3.8/dist-packages/paddle/fluid/libpaddle.so: undefined symbol: shm_unlink\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/87652697/223631256-bb03bf99-722c-4077-b296-112de0ca8a1a.png)\r\n\r\n\r\n**其他信息**\r\ngcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)",
        "state": "closed",
        "user": "supercatking",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-03-08T05:57:29+00:00",
        "updated_at": "2025-03-17T02:40:45+00:00",
        "closed_at": "2025-03-17T02:40:44+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1051,
        "title": "多batch推理",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\nppyoloe支持onnx batch>1推理么，如果不支持，具体是为什么呢？\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "bixiaopeng0",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-03-09T05:00:36+00:00",
        "updated_at": "2024-07-15T04:14:34+00:00",
        "closed_at": "2024-07-15T04:14:29+00:00",
        "comments_count": [
            "yeliang2258",
            "bixiaopeng0",
            "yeliang2258"
        ],
        "labels": [
            "Dependencies"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1052,
        "title": "关系抽取 (Relation Extraction, RE)模型不支持转onnx格式",
        "body": "**\r\n![图片](https://user-images.githubusercontent.com/67726763/223937034-c7059536-3994-41f6-bf44-eb34dd6a1616.png)\r\n**\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "ChengShuting",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-03-09T06:19:32+00:00",
        "updated_at": "2025-03-17T02:40:44+00:00",
        "closed_at": "2025-03-17T02:40:43+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1055,
        "title": "paddleOC",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Mr-Yujie",
        "closed_by": "Mr-Yujie",
        "created_at": "2023-03-15T09:35:18+00:00",
        "updated_at": "2023-03-16T02:33:10+00:00",
        "closed_at": "2023-03-16T02:33:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1056,
        "title": "paddle模型ch_ppocr_server_v1.1_rec_infer转onnx失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nch_ppocr_server_v1.1_rec_infer转onnx时，lstm和ctc_align算子不支持，且用户必须使用该版本。\r\n\r\n\r\n**更多信息 :**\r\n - 模型链接: https://paddleocr.bj.bcebos.com/20-09-22/server/rec/ch_ppocr_server_v1.1_rec_infer.tar\r\n - 为什么需要转换为ONNX格式：昇腾适配\r\n - Paddle版本:2.0.2\r\n - Paddle2ONNX版本:0.9\r\n - 你的联系方式(Email/Wechat/Phone):yangyujie17@huawei-partners.com\r\n\r\n\r\n**报错截图**\r\n![fbf6421c-8bda-4e2f-a172-fc2eb6213a4b](https://user-images.githubusercontent.com/76138284/225273441-fb0ac021-6918-4294-a5fd-ae6daff37777.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Mr-Yujie",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-03-15T09:55:41+00:00",
        "updated_at": "2025-03-17T02:40:43+00:00",
        "closed_at": "2025-03-17T02:40:42+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "Mr-Yujie",
            "Mr-Yujie",
            "yeliang2258",
            "Mr-Yujie",
            "yeliang2258",
            "Mr-Yujie",
            "yeliang2258",
            "Mr-Yujie",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1059,
        "title": "mobilenetv2文档描述和实际的网络不一致",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n文档介绍的页面描述的是mobilenetV2，但实际网络是mobileV3。我想知道mobilenetV2在哪里下载。\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/87652697/226786982-dcbe0d6d-8a30-4e74-a0b3-5ed3c85e0390.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "supercatking",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-03-22T02:35:52+00:00",
        "updated_at": "2024-07-15T03:28:00+00:00",
        "closed_at": "2024-07-15T03:27:44+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug",
            "Doc"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1062,
        "title": "Failure of paddle2onnx",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nFailed to convert model quantized by paddleslim to onnx.\r\n\r\nlog of failure:\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./save_quant_test/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./save_quant_test/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [Info] The Paddle model is a quantized model. \r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including pad,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: TensorRT\r\n - 为什么需要转换为ONNX格式：Need to deploy.\r\n - Paddle2ONNX版本: 1.0.6\r\n - PaddleSlim: 2.4.2\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Jason-wwww",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-03-27T03:01:04+00:00",
        "updated_at": "2024-10-16T09:28:41+00:00",
        "closed_at": "2024-10-16T09:28:41+00:00",
        "comments_count": [
            "yeliang2258",
            "Jason-wwww",
            "yeliang2258",
            "Jason-wwww",
            "yeliang2258",
            "Jason-wwww",
            "Jason-wwww",
            "yeliang2258",
            "Jason-wwww",
            "yeliang2258",
            "Jason-wwww",
            "yeliang2258",
            "Jason-wwww"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1063,
        "title": "ONNX 模型大于 2G生成的external_data如何加载呢",
        "body": "当导出的 ONNX 模型大于 2G 时，生成了一个inference.onnx和一个external_data文件，请问external_data文件如何加载呢？\r\n",
        "state": "closed",
        "user": "471417367",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-03-28T06:14:46+00:00",
        "updated_at": "2025-03-17T02:40:42+00:00",
        "closed_at": "2025-03-17T02:40:41+00:00",
        "comments_count": [
            "yeliang2258",
            "wojiaoyanmin",
            "yeliang2258",
            "471417367",
            "longshot-pting",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1072,
        "title": "尝试将transformer模型转为onnx时报错，目前ppadle是否支持换transformer模型",
        "body": "目前尝试将papdlenlp中uie-m-large模型转换为onnx报错，转换命令如下：\r\n\r\npaddle2onnx --model_dir ./ \\\r\n            --model_filename sentencepiece.bpe.model \\\r\n            --params_filename model_state.pdparams \\\r\n            --save_file uie_m_large.onnx \\\r\n            --enable_dev_version False\r\n\r\n<img width=\"784\" alt=\"7241af36db4580b776981bfbe31c188f\" src=\"https://user-images.githubusercontent.com/65718907/229459319-80e9f69a-125c-47e9-bf5d-40665e4f9ecf.png\">\r\n\r\n目前paddle转换是否支持transformer",
        "state": "closed",
        "user": "sparkssjj",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-04-03T08:51:12+00:00",
        "updated_at": "2024-07-15T03:27:32+00:00",
        "closed_at": "2024-07-15T03:27:25+00:00",
        "comments_count": [
            "yeliang2258",
            "sparkssjj",
            "yeliang2258",
            "sparkssjj",
            "chestnut111"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1074,
        "title": "ModuleNotFoundError: No module named 'paddle2onnx.version'",
        "body": "\r\n使用命令将输入改为静态shape\r\npython -m paddle2onnx.optimize --input_model model.onnx \\\r\n                               --output_model new_model.onnx \\\r\n                               --input_shape_dict \"{'x':[1,3,224,224]}\"\r\n\r\n**问题描述**\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda\\Anaconda\\envs\\paddle-2.4.1\\lib\\runpy.py\", line 188, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"D:\\Anaconda\\Anaconda\\envs\\paddle-2.4.1\\lib\\runpy.py\", line 111, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"D:\\python-code\\10.Paddle2ONNX-develop\\paddle2onnx\\__init__.py\", line 19, in <module>\r\n    from .version import version\r\nModuleNotFoundError: No module named 'paddle2onnx.version'\r\n\r\n版本：\r\npaddle2onnx 1.0.6\r\nonnx 1.13.0\r\n\r\n\r\n",
        "state": "closed",
        "user": "ly19940318",
        "closed_by": "ly19940318",
        "created_at": "2023-04-04T05:57:51+00:00",
        "updated_at": "2023-10-11T14:09:55+00:00",
        "closed_at": "2023-04-04T08:39:39+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "ly19940318",
            "L0LIPPOP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1075,
        "title": "Paddle2ONNX 转换成功后支持将模型转为 TRT 格式吗？",
        "body": "**问题描述**\r\n使用paddle2onnx 将maskrcnn的模型转为onnx后，利用tensorrt将onnx格式的模型转位trt时出现了下列错误\r\n\r\n[04/04/2023-15:48:09] [E] [TRT] ModelImporter.cpp:773: While parsing node number 498 [Reshape -> \"Reshape_0\"]:\r\n[04/04/2023-15:48:09] [E] [TRT] ModelImporter.cpp:774: --- Begin node ---\r\n[04/04/2023-15:48:09] [E] [TRT] ModelImporter.cpp:775: input: \"conv2d_53.b_0\"\r\ninput: \"Constant_0\"\r\noutput: \"Reshape_0\"\r\nname: \"Reshape_0\"\r\nop_type: \"Reshape\"\r\n[04/04/2023-15:48:09] [E] [TRT] ModelImporter.cpp:776: --- End node ---\r\n[04/04/2023-15:48:09] [E] [TRT] ModelImporter.cpp:779: ERROR: ModelImporter.cpp:163 In function parseGraph:\r\n[6] Invalid Node - Reshape_0\r\nAttribute not found: allowzero\r\n[04/04/2023-15:48:09] [E] Failed to parse onnx file\r\n[04/04/2023-15:48:09] [I] Finish parsing network model\r\n[04/04/2023-15:48:09] [E] Parsing model failed\r\n[04/04/2023-15:48:09] [E] Failed to create engine from model or file.\r\n[04/04/2023-15:48:09] [E] Engine set up failed\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/50402380/229724907-5e157355-73b0-4dc0-bd02-519e9d6cfdfc.png)\r\n\r\n",
        "state": "closed",
        "user": "Shrinco",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-04-04T07:58:05+00:00",
        "updated_at": "2025-03-14T02:36:23+00:00",
        "closed_at": "2025-03-14T02:36:22+00:00",
        "comments_count": [
            "yeliang2258",
            "Shrinco",
            "yeliang2258",
            "Shrinco",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1070,
        "title": "转换ONNX模型时出现量化参数不匹配的问题",
        "body": "在使用Paddle2ONNX转换模型时出现量化参数不对齐的问题\r\n\r\n模型链接: [PPOCRV3_rec_QAT.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/11117836/PPOCRV3_rec_QAT.zip)\r\n",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-03-31T03:20:48+00:00",
        "updated_at": "2023-04-02T21:47:35+00:00",
        "closed_at": "2023-04-02T21:47:35+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1076,
        "title": "[pool2d: pool2d_4.tmp_0]",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n转换模型的时候报了下面的错误，pool2d \r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:  NPU\r\n - Why convert to onnx：因为我们的推理框架只支持onnx的输入，测试一下paddlepaddle的模型\r\n - Paddle2ONNX Version:2023-04-07 16:57:54 [INFO]      paddle2onnx-1.0.6 with python>=3.6, paddlepaddle>=2.0.0  \r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n```shell\r\npaddle2onnx --model_dir . --model_filename model.pdmodel  --params_filename model.pdiparams --opset_version 11 --save_file output.onnx                                                             \r\n[Paddle2ONNX] Start to parse PaddlePaddle model...                                                                                \r\n[Paddle2ONNX] Model file path: ./model.pdmodel                                                                                    \r\n[Paddle2ONNX] Paramters file path: ./model.pdiparams                                                                              \r\n[Paddle2ONNX] Start to parsing Paddle model...                                                                                    \r\n[ERROR][Paddle2ONNX] [pool2d: pool2d_4.tmp_0] Adaptive only support static input shape.                                           \r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.                                                 \r\n[ERROR][Paddle2ONNX] [pool2d: pool2d_5.tmp_0] Adaptive only support static input shape.                                           \r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.                                                 \r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.                   \r\nAborted (core dumped)\r\n```\r\n\r\n**Additional context**\r\n\r\n模型来源：wget https://paddleseg.bj.bcebos.com/inference/pp_liteseg_infer_models/pp_liteseg_stdc1_cityscapes_1024x512_scale1.0_160k_inference_model.zip\r\n\r\n",
        "state": "closed",
        "user": "Cccccc-c",
        "closed_by": "Cccccc-c",
        "created_at": "2023-04-07T09:03:08+00:00",
        "updated_at": "2023-04-07T10:34:12+00:00",
        "closed_at": "2023-04-07T10:34:12+00:00",
        "comments_count": [
            "yeliang2258",
            "yeliang2258",
            "Cccccc-c"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1077,
        "title": "ppseg 无法转换onnx",
        "body": "```\r\npaddle2onnx --model_dir .\\human_pp_humansegv2_lite_192x192_inference_model\\ --model_filename model.pdmodel --params_filename model.pdiparams --save_file ppsegv2_lite_192x192.onnx --opset_version 11 --input_shape_dict \"{'image':[1, 3, 192, 192]}\"\r\n2023-04-08 16:08:04 [WARNING]   [Deprecated] The flag `--input_shape_dict` is deprecated, if you need to modify the input shape of PaddlePaddle model, please refer to this tool https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: .\\human_pp_humansegv2_lite_192x192_inference_model\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: .\\human_pp_humansegv2_lite_192x192_inference_model\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR][Paddle2ONNX] [pool2d: pool2d_9.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [pool2d: pool2d_10.tmp_0] Adaptive only support static input shape.\r\n[Paddle2ONNX] Due to the operator: pool2d, this model cannot be exported to ONNX.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\n```",
        "state": "closed",
        "user": "lucasjinreal",
        "closed_by": "lucasjinreal",
        "created_at": "2023-04-08T08:08:52+00:00",
        "updated_at": "2023-04-10T03:52:41+00:00",
        "closed_at": "2023-04-10T03:52:41+00:00",
        "comments_count": [
            "yeliang2258",
            "lucasjinreal",
            "yeliang2258",
            "lucasjinreal"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1078,
        "title": "PaddleSeg提供的HarDNet模型，导出成ONNX模型后精度严重下降",
        "body": "具体情况描述在下方链接，但是还没有工作人员回复\r\nhttps://github.com/PaddlePaddle/PaddleSeg/issues/3137\r\n\r\n",
        "state": "closed",
        "user": "censhallwe",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-04-09T04:54:44+00:00",
        "updated_at": "2024-07-15T04:13:57+00:00",
        "closed_at": "2024-07-15T04:13:53+00:00",
        "comments_count": [
            "yeliang2258",
            "censhallwe",
            "Louis-YanKang",
            "wangkd0",
            "censhallwe",
            "wangkd0"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1083,
        "title": "pp-shitu主体检测模型转onnx，提示有算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\npp-shitu主体检测模型转onnx，提示有算子不支持。\r\n\r\n**问题描述**\r\n(pp) PS D:\\PaddleClas\\deploy> paddle2onnx --model_dir=./models/picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer/ --model_filename=inference.pdmodel --params_filename=inference.pdiparams --save_file=./models/picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer/inference.onnx --opset_version=10 --enable_onnx_checker=True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./models/picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./models/picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,lod_array_length,reverse,select_input,tensor_array_to_tensor,while,write_to_array,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "huge3286",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-04-16T05:47:43+00:00",
        "updated_at": "2025-03-12T02:36:43+00:00",
        "closed_at": "2025-03-12T02:36:43+00:00",
        "comments_count": [
            "yeliang2258",
            "huge3286",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1079,
        "title": "plato-mini导出onnx模型失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n从paddlehub中加载plato-mini，可以执行推理，但在使用paddle.onnx.export或者model.save_inference_model导出模型时会报错\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime\r\n - 为什么需要转换为ONNX格式：进行模型部署\r\n - Paddle2ONNX版本:\r\npaddle-bfloat           0.1.7\r\npaddle2onnx             1.0.6\r\npaddlefsl               1.1.0\r\npaddlehub               2.3.1\r\npaddlenlp               2.5.2\r\npaddlepaddle            2.4.2\r\n - 你的联系方式(Email/Wechat/Phone):bobo.zhou@mthread.com\r\n\r\n**报错截图**\r\n\r\n![1681202821897_35DC9A07-E2E0-4993-9BFC-37738C6FFA64](https://user-images.githubusercontent.com/51819537/231106745-c10387b5-f05b-4eb5-ae5d-c6e9e8a0f8b4.png)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Francis235",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-04-11T08:49:13+00:00",
        "updated_at": "2025-03-13T02:38:25+00:00",
        "closed_at": "2025-03-13T02:38:24+00:00",
        "comments_count": [
            "Francis235",
            "yeliang2258",
            "Francis235",
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1080,
        "title": "您好，在实现SwinUnetr之后，进行paddle2onnx转换，报错不支持conv3d_transpose, roll",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n我是直接在AIStudio的终端上进行的转换\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: \r\n - Why convert to onnx：加速\r\n - Paddle2ONNX Version: paddle的版本是2.4\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\naistudio@jupyter-553239-5931004:~$ python to_onnx.py \r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n2023-04-12 11:20:56 [INFO]      Static PaddlePaddle model saved in onnx.save/paddle_model_static_onnx_temp_dir.\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: onnx.save/paddle_model_static_onnx_temp_dir/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: onnx.save/paddle_model_static_onnx_temp_dir/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conv3d_transpose,roll,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char const*, char const*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1681269657 (unix time) try \"date -d @1681269657\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e800000ca8) received by PID 3240 (TID 0x7f514cdf8700) from PID 3240 ***]\r\n\r\nAborted (core dumped)",
        "state": "closed",
        "user": "zx-lhb",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-04-12T03:32:05+00:00",
        "updated_at": "2025-03-13T02:38:22+00:00",
        "closed_at": "2025-03-13T02:38:22+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1084,
        "title": "paddle2onnx 导出onnx模型",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\npaddle2onnx 导出QAT量化后模型失败 fake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max  not support 不支持\r\n**更多信息 :**\r\n - 用于部署的推理引擎:onnx\r\n - 为什么需要转换为ONNX格式：需要比较在onnx上原始模型和QAT量化模型性能\r\n - Paddle2ONNX版本:1.0.6\r\n - 你的联系方式(Email/Wechat/Phone):1848621099@qq.com\r\n\r\n**报错截图**\r\nfake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max  not support\r\n**其他信息**\r\npaddle-slim 2.4.0 ",
        "state": "closed",
        "user": "sc199505",
        "closed_by": "sc199505",
        "created_at": "2023-04-17T07:07:40+00:00",
        "updated_at": "2024-04-07T03:26:52+00:00",
        "closed_at": "2023-04-18T03:27:45+00:00",
        "comments_count": [
            "sc199505",
            "sc199505",
            "sc199505",
            "sc199505",
            "sc199505",
            "yangy996",
            "Daipuwei",
            "Daipuwei",
            "1314520gu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1085,
        "title": "one_hot算子不支持转换，如何解决",
        "body": "paddlenlp 2.5.2\r\npaddlepaddle 2.4.2\r\nonnx 1.13.1\r\npaddle2onnx 1.0.6\r\n\r\n文件结构：docprompt/inference.pdmodel docprompt/inference.pdiparams\r\n使用命令：\r\npaddle2onnx --model_dir docprompt --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file docprompt.onnx --enable_onnx_checker True\r\n报错：\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including one_hot,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n请问这如何解决呢？",
        "state": "closed",
        "user": "471417367",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-04-18T06:14:44+00:00",
        "updated_at": "2024-10-16T09:28:12+00:00",
        "closed_at": "2024-10-16T09:28:12+00:00",
        "comments_count": [
            "yeliang2258",
            "Lingchen99"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1086,
        "title": "win10下训练的模型转成ONNX后，在linux上有问题",
        "body": "Traceback (most recent call last):\r\n  File \"onnx/infer.py\", line 119, in <module>\r\n    predictor = InferenceSession(FLAGS.onnx_file)\r\n  File \"/home/ljqwater/Python/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 335, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"/home/ljqwater/Python/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 368, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from /home/ljqwater/ONNX/ONNXModel/mask_rcnn.onnx failed:/onnxruntime_src/onnxruntime/core/graph/model_load_utils.h:47 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map<std::basic_string<char>, int>&, const onnxruntime::logging::Logger&, bool, const string&, int) ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 16 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain ai.onnx is till opset 15.\r\n\r\n在win10和macos上没问题，但是在Linux上就出现onnxruntime.capi.onnxruntime_pybind11_state.Fail。\r\n我的邮箱Ray7jq@qq.com",
        "state": "closed",
        "user": "ray7jq",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-04-19T06:15:43+00:00",
        "updated_at": "2024-07-15T03:26:58+00:00",
        "closed_at": "2024-07-15T03:26:55+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1087,
        "title": "ppseg2.8 MaskFormer转onnx，roll/einsum/bitwise_not算子不支持",
        "body": "**问题描述**\r\nppseg2.8 MaskFormer转onnx时，roll/einsum/bitwise_not算子不支持。\r\n指令：paddle2onnx --model_dir output/huaxian_mformer_230421/export/ --params_filename model.pdiparams --model_filename model.pdmodel --save_file output/huaxian_mformer_230421/export/model.onnx --enable_onnx_checker True --opset_version 16\r\n版本信息：\r\n![image](https://user-images.githubusercontent.com/26101192/233895228-64b8e24a-dcfc-4a39-baf1-49c88c7d38be.png)\r\n\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:triton-tensorrt或paddlelite backend\r\n - 为什么需要转换为ONNX格式：模型太大，需要trt加速。\r\n - Paddle2ONNX版本:1.0.6\r\n - 你的联系方式(Email/Wechat/Phone): 18217585139\r\n\r\n**报错截图**\r\n![image](https://user-images.githubusercontent.com/26101192/233894997-01884011-2fb0-40c7-a216-c23e868e4ac8.png)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "trarynight",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-04-24T03:41:51+00:00",
        "updated_at": "2024-10-16T09:28:02+00:00",
        "closed_at": "2024-10-16T09:28:02+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1088,
        "title": "Oops, there are some operators not supported yet, including conditional_block,distribute_fpn_proposals,generate_proposals_v2,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,",
        "body": "paddle2onnx.exe --model_dir D:\\pythonProject\\footbool\\model2 --model_filename model.pdmodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version True --enable_onnx_checker True\r\n\r\n\r\nodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version True --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: D:\\pythonProject\\footbool\\model2\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: D:\\pythonProject\\footbool\\model2\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,distribute_fpn_proposals,generate_proposals_v2,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\nPaddle2ONNX 1.0.6\r\n\r\n怎么办啊\r\n",
        "state": "closed",
        "user": "liming1010",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-04-25T09:08:15+00:00",
        "updated_at": "2025-03-12T02:36:42+00:00",
        "closed_at": "2025-03-12T02:36:42+00:00",
        "comments_count": [
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1092,
        "title": "ppmodel convert onnx ，paddleocr run to fail",
        "body": "paddle2onnx --model_dir ./inference/det --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/det_onnx/model.onnx --opset_version 11 --enable_onnx_checker True\r\n\r\npaddle2onnx --model_dir ./inference/rec --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/rec_onnx/model.onnx --opset_version 11 --enable_onnx_checker True\r\n\r\npaddle2onnx --model_dir ./inference/cls --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/cls_onnx/model.onnx --opset_version 11 --enable_onnx_checker True\r\n\r\nrun erro info：\r\n`Traceback (most recent call last):\r\n  File \"H:\\Develop\\paddleOCR\\test.py\", line 10, in <module>\r\n    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", use_onnx=True,\r\n  File \"H:\\Develop\\paddleOCR\\paddleocr.py\", line 502, in __init__\r\n    super().__init__(params)\r\n  File \"H:\\Develop\\paddleOCR\\tools\\infer\\predict_system.py\", line 46, in __init__\r\n    self.text_detector = predict_det.TextDetector(args)\r\n  File \"H:\\Develop\\paddleOCR\\tools\\infer\\predict_det.py\", line 146, in __init__\r\n    if img_h is not None and img_w is not None and img_h > 0 and img_w > 0:\r\nTypeError: '>' not supported between instances of 'str' and 'int'`\r\n\r\nmodel view, why x value is float32[p2o.DynamicDimension.0,3,p2o.DynamicDimension.1,p2o.DynamicDimension.2 ?",
        "state": "closed",
        "user": "jian-kuang",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-13T03:25:49+00:00",
        "updated_at": "2024-04-10T07:26:41+00:00",
        "closed_at": "2024-04-10T07:26:38+00:00",
        "comments_count": [
            "2018-Summer",
            "hoangph3"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1091,
        "title": "Make version changes to paddle2onnx to support conversion",
        "body": "\r\nThe current version of paddle2onnx has bugs and does not support inference of the model converted to onnx format as the input shape is stored as a object (p2.Dynamic). Downgrading to a earlier version of paddle2onnx fixes this issue. Would it be possible to add the functionality to the current version of paddle2onnx\r\n\r\n",
        "state": "closed",
        "user": "ss756",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-08T08:27:33+00:00",
        "updated_at": "2024-07-15T03:26:47+00:00",
        "closed_at": "2024-07-15T03:26:47+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1090,
        "title": "训练好的模型权重.pdparams怎么转换为onnx",
        "body": "使用paddle自定义网络训练出来的模型，只保存了权重为.pdparams文件\r\n加载模型的语句是\r\n```\r\nmodel = my_net() # 自定义网络类\r\nweights = paddle.load(weight_path) # 加载.pdparams权重文件\r\nmodel.load_dict(weights) \r\nmodel.eval()\r\n```\r\n请问，怎么将整个模型转换成onnx呢",
        "state": "closed",
        "user": "wzz981",
        "closed_by": "wzz981",
        "created_at": "2023-05-07T15:04:27+00:00",
        "updated_at": "2023-05-18T07:03:41+00:00",
        "closed_at": "2023-05-18T07:03:41+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1089,
        "title": "[ERROR] Paddle2ONNX: Only support weight with lod_level = 0.",
        "body": "paddle和onnx版本如下：\r\n<img width=\"1198\" alt=\"image\" src=\"https://user-images.githubusercontent.com/48076281/236613348-d837f54a-d7c9-4710-9e0d-da6e1b67ec48.png\">\r\n\r\n执行 paddle2onnx --model_dir ./ --model_filename transformer.pdmodel --params_filename transformer.pdparams  --save_file transformer.onnx 报错：\r\n\r\n<img width=\"1423\" alt=\"image\" src=\"https://user-images.githubusercontent.com/48076281/236613406-c1d702a6-2b97-4d8e-ade1-d432cbae16b2.png\">\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "hadoop2xu",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-06T08:39:42+00:00",
        "updated_at": "2025-03-11T02:37:30+00:00",
        "closed_at": "2025-03-11T02:37:29+00:00",
        "comments_count": [
            "yeliang2258",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1094,
        "title": "Only support 4D-Tensor as input for GroupNorm",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\nOnly support 4D-Tensor as input for GroupNorm\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n[ERROR][Paddle2ONNX] [group_norm: group_norm_22.tmp_0] Only support 4D-Tensor as input for GroupNorm\r\n[Paddle2ONNX] Due to the operator: group_norm, this model cannot be exported to ONNX.\r\n\r\n**更多信息 :**\r\n nn.GroupNorm(num_channels=out_ch, num_groups=8))\r\n其中x.shape为（b,c,h,w,d)五通道。\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "strawberrylazy",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-13T14:58:29+00:00",
        "updated_at": "2025-03-10T02:11:50+00:00",
        "closed_at": "2025-03-10T02:11:49+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1093,
        "title": "det 模型转onnx后怎样用python代码使用得到的模型？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "nissansz",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-13T13:41:20+00:00",
        "updated_at": "2024-04-10T07:26:14+00:00",
        "closed_at": "2024-04-10T07:26:01+00:00",
        "comments_count": [
            "MianMianMeow",
            "nissansz"
        ],
        "labels": [
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1095,
        "title": "ppyolo模型转onnx报错：存在不支持的算子",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\nppyolo模型转onnx失败啦！\r\n模型链接：\r\nhttps://github.com/PaddlePaddle/PaddleDetection/tree/release/2.5/configs/ppyolo\r\n\r\n转换命令：\r\npaddle2onnx --model_dir ppyolov2_r101vd_dcn_365e_coco --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file ppyolov2_r101vd_dcn_365e_coco.onnx\r\n\r\n报错信息：\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,matrix_nms,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：真心需要\r\n - Paddle2ONNX版本: 1.0.5\r\n - 你的联系方式(Email/Wechat/Phone): DDXRAY952（Wechat）\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/115347273/8f051c00-a901-4801-ac93-aa4e4885639b)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "WenjieZhou9",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-15T12:05:27+00:00",
        "updated_at": "2025-02-26T02:33:50+00:00",
        "closed_at": "2025-02-26T02:33:49+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1096,
        "title": "怎么修改pdmodel和pdiparams的输出节点名字",
        "body": "现在有一个模型的pdmodel和pdiparams文件，想修改一下模型的输出结点名字，请问怎样可以实现？",
        "state": "closed",
        "user": "2730gf",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-16T12:43:47+00:00",
        "updated_at": "2024-04-10T07:24:53+00:00",
        "closed_at": "2024-04-10T07:24:46+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1100,
        "title": "导出的onnx与原模型结果存在较大差异",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用paddle2onnx导出模型\r\n\r\n语句为：\r\n```\r\npaddle2onnx --model_dir model --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file model.onnx --enable_dev_version True\r\n```\r\n\r\n中间信息为：\r\n```\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: model\\inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: model\\inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 12 for ONNX export.\r\n[Paddle2ONNX] Find dumplicate output name 'fill_constant_47.tmp_0', it will rename to 'p2o.fill_constant_47.tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'p2o.fill_constant_47.tmp_0.0', it will rename to 'p2o.p2o.fill_constant_47.tmp_0.0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_0', it will rename to 'p2o.eager_tmp_0.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_1', it will rename to 'p2o.eager_tmp_1.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_2', it will rename to 'p2o.eager_tmp_2.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_3', it will rename to 'p2o.eager_tmp_3.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_4', it will rename to 'p2o.eager_tmp_4.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_5', it will rename to 'p2o.eager_tmp_5.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_6', it will rename to 'p2o.eager_tmp_6.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_7', it will rename to 'p2o.eager_tmp_7.0'.\r\n[Paddle2ONNX] Find dumplicate output name 'eager_tmp_8', it will rename to 'p2o.eager_tmp_8.0'.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2023-05-18 14:33:25 [INFO]      ===============Make PaddlePaddle Better!================\r\n2023-05-18 14:33:25 [INFO]      A little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n```\r\n能够进行推理，但存在明显差异\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime、openvino\r\n - 为什么需要转换为ONNX格式：部署\r\n - Paddle2ONNX版本: 1.0.6\r\n - 你的联系方式(Email/Wechat/Phone): wyzy981@126.com\r\n\r\n**报错截图**\r\n\r\n```\r\ndiff = outs[0] - out.numpy()\r\nmax_abs_diff = np.fabs(diff).max()\r\nif max_abs_diff < 1e-05:\r\n    print(\"The difference of results between ONNXRuntime and Paddle looks good!\")\r\nelse:\r\n    relative_diff = max_abs_diff / np.fabs(out.numpy()).max()\r\n    if relative_diff < 1e-05:\r\n        print(\"The difference of results between ONNXRuntime and Paddle looks good!\")\r\n    else:\r\n        print(\"The difference of results between ONNXRuntime and Paddle looks bad!\")\r\n    print('relative_diff: ', relative_diff)\r\nprint('max_abs_diff: ', max_abs_diff)\r\n```\r\n运行上面对比差异程序有以下情况\r\n\r\n使用paddle.inference进行推理与正常模型对比信息：\r\n```\r\nThe difference of results between ONNXRuntime and Paddle looks good!\r\nmax_abs_diff:  0.0\r\n```\r\n\r\n使用导出的onnx模型通过ONNXRuntime推理与正常模型对比信息：\r\n```\r\nThe difference of results between ONNXRuntime and Paddle looks bad!\r\nrelative_diff:  0.24361868\r\nmax_abs_diff:  0.26957464\r\n```\r\n\r\n使用openvino加载compile_model(model=onnx_model_dir, device_name=\"CPU\")能够执行推理\r\n使用导出的onnx模型通过openvino推理与正常模型对比信息：\r\n```\r\nThe difference of results between ONNXRuntime and Paddle looks bad!\r\nrelative_diff:  1.0165321\r\nmax_abs_diff:  1.1248369\r\n```\r\n\r\n使用openvino加载`ie.read_model(model=model_file_path, weights=params_file_path)`出现下面报错\r\n```\r\nRuntimeError: Check 'creator_it != CREATORS_MAP.end()' failed at C:\\Jenkins\\workspace\\private-ci\\ie\\build-windows-vs2019\\b\\repos\\openvino\\src\\frontends\\paddle\\src\\frontend.cpp:45:\r\nFrontEnd API failed with OpConversionFailure: :\r\nNo creator found for set_value node.\r\n```\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "wzz981",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-18T07:27:15+00:00",
        "updated_at": "2024-07-15T03:25:43+00:00",
        "closed_at": "2024-07-15T03:25:43+00:00",
        "comments_count": [],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1103,
        "title": "Is it possible to convert the en_number_mobile_slim_v2.0_rec model to onnx using the paddle2onnx tool?",
        "body": "I tried to convert but I get an error that the layers are not supported yet. I also get an error for the en ppocrv2 model. ",
        "state": "closed",
        "user": "yash-khurana",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-19T11:44:47+00:00",
        "updated_at": "2024-10-16T09:27:41+00:00",
        "closed_at": "2024-10-16T09:27:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1102,
        "title": "grid_sample算子导致paddle2onnx强制使用opset_version 16",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nRT，我在尝试使用PaddleDetection的rt-detr模型转换onnx，但是在paddle2onnx时会因为存在grid_sample算子导致工具强制走opset_version 16。\r\n\r\n然而我们后面对onnx模型的使用强以来与opset_version 11。有什么办法可以帮忙绕过该算子吗？\r\n\r\n转换方式：[rtdetr](https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/rtdetr)\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 厂家自定的引擎\r\n - 为什么需要转换为ONNX格式：推理引擎依赖onnx parser\r\n - Paddle2ONNX版本: 1.0.5\r\n - 你的联系方式(Email/Wechat/Phone): \r\n\r\n**报错截图**\r\n[参考log](https://github.com/PaddlePaddle/PaddleDetection/issues/8114#issuecomment-1552818223)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ShawnNew",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-19T07:56:29+00:00",
        "updated_at": "2024-05-30T09:28:20+00:00",
        "closed_at": "2024-05-30T09:28:20+00:00",
        "comments_count": [
            "jiangjiajun",
            "cqlp1314",
            "Sujie1528"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1101,
        "title": "模型qat训练要求转化的onnx版本大于等于13",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ZHIZIHUABU",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-19T02:12:38+00:00",
        "updated_at": "2024-07-15T03:23:58+00:00",
        "closed_at": "2024-07-15T03:23:56+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1106,
        "title": "Oops, there are some operators not supported yet, including nearest_interp",
        "body": "**问题描述**\r\n请在此处详细的描述报错信息\r\n执行：\r\npaddle2onnx --model_dir inference_model\\224\\ppyolo_tiny  --model_filename __model__  --params_filename __params__  --opset_version 11 --save_file ppyolo_tiny_224.onnx\r\n时报下面这个错：\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including nearest_interp,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: PaddleDetection为：release/2.1\r\n - 为什么需要转换为ONNX格式： \r\n - Paddle2ONNX版本:  paddle2onnx-1.0.6 with python>=3.6, paddlepaddle>=2.0.0\r\n - 你的联系方式(Email/Wechat/Phone): \r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "tryor",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-23T10:45:36+00:00",
        "updated_at": "2024-10-16T09:27:28+00:00",
        "closed_at": "2024-10-16T09:27:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1105,
        "title": "Oops, there are some operators not supported yet, including fake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max,",
        "body": "**问题描述**\r\n想将PaddleOCR的Multilingual_PP-OCRv3_det_slim_infer模型转换成onnx模型，使用命令报错\r\n```\r\npaddle2onnx --model_dir ./inference/ch_PP-OCRv3_det_infer \\\r\n--model_filename inference.pdmodel \\\r\n--params_filename inference.pdiparams \\\r\n--save_file ./inference/det_onnx/model.onnx \\\r\n--opset_version 10 \\\r\n--input_shape_dict=\"{'x':[-1,3,-1,-1]}\" \\\r\n--enable_onnx_checker True\r\n```\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:Multilingual_PP-OCRv3_det_slim_infer\r\n - 为什么需要转换为ONNX格式：需要加快OCR文字识别的速度\r\n - Paddle2ONNX版本:1.0.6\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/51713323/b9454ead-183f-4700-9d0b-edc89d200a42)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "L-Inkink",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-22T12:54:11+00:00",
        "updated_at": "2025-04-07T02:45:31+00:00",
        "closed_at": "2025-04-07T02:45:30+00:00",
        "comments_count": [
            "WenmuZhou",
            "Nurfen",
            "HIT-ShuWei",
            "xdd130",
            "hhhappiness",
            "leduy-it",
            "github-actions[bot]",
            "tymons",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1104,
        "title": "Cannot build on Jetson Xavier AGX with JetPack 5.1",
        "body": "I have followed the instructions found here:\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/compile.md\r\n\r\nI get below error when I try to: python setup.py install\r\n\r\n[100%] Linking CXX shared module paddle2onnx_cpp2py_export.cpython-38-aarch64-linux-gnu.so\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): in function `google::protobuf::EnumDescriptor::CopyTo(google::protobuf::EnumDescriptorProto*) const':\r\n(.text+0x390c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): in function `google::protobuf::Descriptor::CopyTo(google::protobuf::DescriptorProto*) const':\r\n(.text+0xdf9c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): in function `google::protobuf::FileDescriptor::CopyTo(google::protobuf::FileDescriptorProto*) const':\r\n(.text+0xe1fc): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.o): in function `google::protobuf::internal::ArenaStringPtr::CreateInstance(google::protobuf::Arena*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*)':\r\n(.text._ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN6google8protobuf8internal14ArenaStringPtr14CreateInstanceEPNS0_5ArenaEPKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0x110): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(int128.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZNKSt5ctypeIcE8do_widenEc' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(int128.o): in function `google::protobuf::operator<<(std::ostream&, google::protobuf::uint128 const&)':\r\n(.text+0xadc): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(int128.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZNKSt5ctypeIcE8do_widenEc' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n(.text+0xb14): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(int128.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZNKSt5ctypeIcE8do_widenEc' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n(.text+0xb4c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(int128.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZNKSt5ctypeIcE8do_widenEc' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n(.text+0xb78): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): in function `google::protobuf::EnumDescriptorProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\n(.text+0x1d934): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): in function `google::protobuf::DescriptorProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\n(.text+0x1ff5c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): in function `google::protobuf::SourceCodeInfo_Location::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\n(.text+0x209e4): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(descriptor.pb.o): in function `google::protobuf::FileDescriptorProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\n(.text+0x21650): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(generated_message_reflection.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(generated_message_reflection.o): in function `google::protobuf::internal::GeneratedMessageReflection::AddString(google::protobuf::Message*, google::protobuf::FieldDescriptor const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const':\r\n(.text+0xc854): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(generated_message_reflection.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(generated_message_reflection.o): in function `void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::internal::GenericTypeHandler<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >(void**, void**, int, int)':\r\n(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS1_18GenericTypeHandlerINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEEEEvPPvSD_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS1_18GenericTypeHandlerINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEEEEvPPvSD_ii]+0x7c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(message.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(message.o): in function `void google::protobuf::internal::RepeatedPtrFieldBase::AddAllocatedSlowWithCopy<google::protobuf::RepeatedPtrField<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::TypeHandler>(google::protobuf::RepeatedPtrField<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::TypeHandler::Type*, google::protobuf::Arena*, google::protobuf::Arena*)':\r\n(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase24AddAllocatedSlowWithCopyINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPNT_4TypeEPNS0_5ArenaESH_[_ZN6google8protobuf8internal20RepeatedPtrFieldBase24AddAllocatedSlowWithCopyINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPNT_4TypeEPNS0_5ArenaESH_]+0x1e4): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(extension_set.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(extension_set.o): in function `google::protobuf::internal::ExtensionSet::MutableString[abi:cxx11](int, unsigned char, google::protobuf::FieldDescriptor const*)':\r\n(.text+0xd40c): dangerous relocation: unsupported relocation\r\n/usr/bin/ld: /usr/lib/aarch64-linux-gnu/libprotobuf.a(extension_set.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `_ZTINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE' which may bind externally can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/aarch64-linux-gnu/libprotobuf.a(extension_set.o): in function `google::protobuf::internal::ExtensionSet::AddString[abi:cxx11](int, unsigned char, google::protobuf::FieldDescriptor const*)':\r\n(.text+0xd7a0): dangerous relocation: unsupported relocation\r\ncollect2: error: ld returned 1 exit status\r\nmake[2]: *** [CMakeFiles/paddle2onnx_cpp2py_export.dir/build.make:1910: paddle2onnx_cpp2py_export.cpython-38-aarch64-linux-gnu.so] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:206: CMakeFiles/paddle2onnx_cpp2py_export.dir/all] Error 2\r\nmake: *** [Makefile:136: all] Error 2\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 299, in <module>\r\n    setuptools.setup(\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/__init__.py\", line 145, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/command/install.py\", line 67, in run\r\n    self.do_egg_install()\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/command/install.py\", line 109, in do_egg_install\r\n    self.run_command('bdist_egg')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/command/bdist_egg.py\", line 172, in run\r\n    cmd = self.call_command('install_lib', warn_dir=0)\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/command/bdist_egg.py\", line 158, in call_command\r\n    self.run_command(cmdname)\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/home/nvidia/envs/paddle/lib/python3.8/site-packages/setuptools/command/install_lib.py\", line 23, in run\r\n    self.build()\r\n  File \"/usr/lib/python3.8/distutils/command/install_lib.py\", line 107, in build\r\n    self.run_command('build_py')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 204, in run\r\n    self.run_command('cmake_build')\r\n  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 198, in run\r\n    subprocess.check_call(build_args)\r\n  File \"/usr/lib/python3.8/subprocess.py\", line 364, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['/home/nvidia/.local/bin/cmake', '--build', '.', '--', '-j', '8']' returned non-zero exit status 2.",
        "state": "closed",
        "user": "GiorgosBetsos",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-22T08:06:47+00:00",
        "updated_at": "2024-07-15T03:23:01+00:00",
        "closed_at": "2024-07-15T03:23:01+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "CI",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1107,
        "title": "paddle2onnx转换模型失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n我在paddle官网上下载了ppyolo的模型\r\n使用的脚本如下：\r\npython tools/export_model.py -c configs/ppyolo/ppyolo_r50vd_dcn_1x_coco.yml -o weights=https://paddledet.bj.bcebos.com/models/ppyolo_r50vd_dcn_1x_coco.pdparams\r\nuse_gpu=False\r\n版本信息如下：\r\n2023-05-24 15:02:08 [INFO]      paddle2onnx-1.0.6 with python>=3.6, paddlepaddle>=2.0.0\r\n paddlepaddle==2.4.2 \r\n\r\n下载完模型后\r\n使用pip install paddle2onnx\r\n执行如下语句时\r\npaddle2onnx  --model_dir ppyolo_r50vd_dcn_1x_coco/ --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file ppyolo_r50vd_dcn_1x_coco.onnx\r\n报错\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ppyolo_r50vd_dcn_1x_coco/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ppyolo_r50vd_dcn_1x_coco/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,matrix_nms,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\nemail: liang.yang@novauto.com.cn\r\n\r\n",
        "state": "closed",
        "user": "YangLiang2017",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-24T07:08:51+00:00",
        "updated_at": "2025-02-25T02:34:21+00:00",
        "closed_at": "2025-02-25T02:34:20+00:00",
        "comments_count": [
            "1716932646",
            "river666six",
            "river666six",
            "pansinm",
            "Homura852",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleDetection",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1108,
        "title": "perators not supported",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\npaddle-bfloat                 0.1.7\r\npaddle2onnx                   1.0.6\r\npaddlecloudplatform           3.1.2\r\npaddlepaddle                  2.4.0\r\nx2paddle                      1.4.1\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n<img width=\"1055\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/50070499/d026ed04-14b2-4e5e-957d-8610eaf6ad03\">\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "soyons",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-24T07:53:50+00:00",
        "updated_at": "2025-02-25T02:34:20+00:00",
        "closed_at": "2025-02-25T02:34:19+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1109,
        "title": "tiny-pose转onnx精度丢失严重",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\ntiny-pose转onnx精度丢失严重，使用keypoint_infer.py推理结果如下：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/86467223/b99ad618-5071-46b0-8a3d-b8617f82167c)\r\n转成onnx后：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/86467223/1b9fa081-3b21-4c5f-9fcf-b837d4e541a1)\r\n试了opset11，12，15都是这样\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "jeychan518",
        "closed_by": "jeychan518",
        "created_at": "2023-05-24T08:36:10+00:00",
        "updated_at": "2023-05-25T07:16:25+00:00",
        "closed_at": "2023-05-25T07:15:59+00:00",
        "comments_count": [
            "jeychan518"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1110,
        "title": "conditional_block,equal_all,select_input,tril_triu,在转化过程中不支持，希望可以尽早支持~",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n以下算子在转化过程中不支持，希望能尽早支持\r\n Oops, there are some operators not supported yet, including conditional_block,equal_all,select_input,tril_triu,\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/134492670/b5686fad-4b4b-41eb-b02a-08c20260e400)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "zcl360168056",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-24T08:54:48+00:00",
        "updated_at": "2025-02-24T02:35:59+00:00",
        "closed_at": "2025-02-24T02:35:58+00:00",
        "comments_count": [
            "yeliang2258",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1112,
        "title": "Paddle2onnx转出来的onnx模型都会带有两个domain吗？",
        "body": "我使用Paddle2onnx转出onnx模型文件：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58839824/cb5a0302-8d1b-49fe-a2ad-57576154f8d7)\r\n但是当我用netron将转好的onnx文件打开时发现该文件有两个domain\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58839824/5233061e-8790-48ed-81fc-65f643b6554a)\r\n这是我不希望看到的，我希望转出的onnx文件中domain信息只包含ai:onnx v13不要Paddle v1\r\n",
        "state": "closed",
        "user": "RebornARX",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-27T07:11:09+00:00",
        "updated_at": "2024-05-22T04:26:47+00:00",
        "closed_at": "2024-05-22T04:26:47+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1111,
        "title": "export onnx model Cast failure",
        "body": "\r\n\r\nWhen I export PaddleOCR cls model，used  **--input_shape_dict=\"{'x': [1, 3, 48, 192]}\"** , The correct output of onnx model should be a [1x5] , but it outputs [-1x5], why batchsize is -1?\r\n\r\n\r\n - Paddle2ONNX Version: '0.9.5'\r\n - Email/Wechat/Phone: 820001401@qq.com\r\n\r\n**Screenshots**\r\n\r\n![选区_999(1546)](https://github.com/PaddlePaddle/Paddle2ONNX/assets/25164335/ff7bd114-7193-48b9-932a-1f2bf99b14fa)\r\n![选区_999(1547)](https://github.com/PaddlePaddle/Paddle2ONNX/assets/25164335/1f766763-f688-4a66-b3f2-7183c7f80a62)\r\n\r\n",
        "state": "closed",
        "user": "liguiyuan",
        "closed_by": "liguiyuan",
        "created_at": "2023-05-25T09:38:54+00:00",
        "updated_at": "2023-05-26T02:04:36+00:00",
        "closed_at": "2023-05-26T02:04:36+00:00",
        "comments_count": [
            "liguiyuan",
            "liguiyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1113,
        "title": "ModuleNotFoundError: No module named 'paddle2onnx.paddle2onnx_cpp2py_export'",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n进行paddle模型转onnx时报错：\r\nxxx/Paddle2ONNX/paddle2onnx/command.py\", line 155, in c_paddle_to_onnx               \r\n    import paddle2onnx.paddle2onnx_cpp2py_export as c_p2o\r\nModuleNotFoundError: No module named 'paddle2onnx.paddle2onnx_cpp2py_export'\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: \r\n - 为什么需要转换为ONNX格式：转tensorrt\r\n - Paddle2ONNX版本: develop版本\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Curry-Christopher",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-29T09:29:08+00:00",
        "updated_at": "2024-07-15T03:20:48+00:00",
        "closed_at": "2024-07-15T03:20:48+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1114,
        "title": "var linear_0.w_0 not in this block",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\npython ./prune_paddle_model.py --model_dir  /workspace/jia/test/orgin/infer_model/ \\\r\n                             --model_filename text.pdmodel \\\r\n                             --params_filename text.pdiparams \\\r\n                             --output_names linear_0.w_0 \\\r\n                             --save_dir ../new_model/\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58065607/5c41fd65-2eb3-4a1b-b935-1aa80701ce68)\r\n\r\n显示var not in this block ，请问这个output_names是Onnx图里面的算子名称吗还是什么。\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n![Snipaste_2023-05-30_12-31-43](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58065607/9a414098-2589-4020-87e5-0c5c5a362664)\r\n\r\n\r\n\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "TgrotCn",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-05-30T04:37:35+00:00",
        "updated_at": "2024-05-30T09:27:28+00:00",
        "closed_at": "2024-05-30T09:27:23+00:00",
        "comments_count": [
            "yeliang2258"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1118,
        "title": "paddle2onnx 执行完终端显示的问卷链接失效",
        "body": "#### 运行环境：\r\n`paddle2onnx`:  1.0.6\r\n\r\n\r\n#### 显示信息：\r\n- 模型转换为之后：\r\n```text\r\n2023-06-15 09:11:42 [INFO]      ===============Make PaddlePaddle Better!================\r\n2023-06-15 09:11:42 [INFO]      A little survey: https://iwenjuan.baidu.com/?code=r8hu2s\r\n```\r\n-  打开链接显示：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/28639377/950c717f-24ea-4f24-9ae6-8374af14ed6b)\r\n",
        "state": "closed",
        "user": "SWHL",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-06-15T01:15:59+00:00",
        "updated_at": "2024-07-15T03:26:00+00:00",
        "closed_at": "2024-07-15T03:26:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1115,
        "title": "AdaptiveAvgPool2D ，固定输入之后转化的AvgPool2D 多出了 auto_pad NOTSET，部署不支持这个算子",
        "body": "\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58769772/7f8ab1ec-a66e-4bd2-a9da-894f1a3873ba)\r\n，这个算子属性不利于onnx部署，请问可以改成常规属性嘛，例如这样\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58769772/ad728c8f-aaab-4c78-8895-ce85c19d34a0)\r\n，谢谢",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-05-31T03:07:10+00:00",
        "updated_at": "2025-02-24T02:35:58+00:00",
        "closed_at": "2025-02-24T02:35:57+00:00",
        "comments_count": [
            "chen-del",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1117,
        "title": "onnxruntime-tidl加载报错",
        "body": "**训练环境**\r\npaddle-bfloat                 0.1.7\r\npaddle2onnx                   1.0.6\r\npaddledet                     2.6.0\r\npaddlepaddle-gpu              2.4.2.post117\r\npaddleslim                    2.2.1\r\npaddlex                       2.1.0\r\n\r\n**部署环境**\r\nonnx                  1.14.0     \r\nonnxruntime-tidl      1.7.0\r\n\r\n\r\n[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: basic_string::_M_construct null not valid",
        "state": "closed",
        "user": "jinyaxuan",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-06-13T03:12:55+00:00",
        "updated_at": "2025-02-23T02:35:40+00:00",
        "closed_at": "2025-02-23T02:35:39+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1120,
        "title": "转换成onnx模型过程中，ppocr_keys_v1.txt 这个文件对应的英文版标注文件应该选择哪个？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n利用Paddle2ONNX转换paddleOCR英文识别模型 en_PP-OCRv3_rec_infer为onnx模型，采用项目提供的ppocr_keys_v1.txt文件，识别出来的全是乱码。请问相应英文标注文件ppocr_keys_v1.txt应该选择哪个呢？是否可以选择en_dict.txt这个？\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: \r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "biotech7",
        "closed_by": "biotech7",
        "created_at": "2023-06-18T05:32:34+00:00",
        "updated_at": "2023-06-20T22:43:22+00:00",
        "closed_at": "2023-06-20T22:43:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1119,
        "title": "使用pip安装报不能找到cmake",
        "body": "**问题描述**\r\n使用pip安装报不能找到cmake，出现这个报错后，本地安装了cmake，再次安装还是报错。\r\n```\r\nC:\\Windows\\system32>pip install paddle2onnx\r\nCollecting paddle2onnx\r\n  Using cached paddle2onnx-0.9.2-py3-none-any.whl (100 kB)\r\nRequirement already satisfied: six in c:\\python311\\lib\\site-packages (from paddle2onnx) (1.16.0)\r\nRequirement already satisfied: protobuf in c:\\python311\\lib\\site-packages (from paddle2onnx) (4.23.2)\r\nCollecting onnx<=1.9.0 (from paddle2onnx)\r\n  Using cached onnx-1.9.0.tar.gz (9.8 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Getting requirements to build wheel did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [22 lines of output]\r\n      fatal: not a git repository (or any of the parent directories): .git\r\n      Traceback (most recent call last):\r\n        File \"C:\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\r\n          main()\r\n        File \"C:\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\r\n          json_out['return_val'] = hook(**hook_input['kwargs'])\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\r\n          return hook(config_settings)\r\n                 ^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\YuanRui\\AppData\\Local\\Temp\\pip-build-env-xq1prqrd\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in get_requires_for_build_wheel\r\n          return self._get_build_requires(config_settings, requirements=['wheel'])\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\YuanRui\\AppData\\Local\\Temp\\pip-build-env-xq1prqrd\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 323, in _get_build_requires\r\n          self.run_setup()\r\n        File \"C:\\Users\\YuanRui\\AppData\\Local\\Temp\\pip-build-env-xq1prqrd\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 488, in run_setup\r\n          self).run_setup(setup_script=setup_script)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\YuanRui\\AppData\\Local\\Temp\\pip-build-env-xq1prqrd\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 338, in run_setup\r\n          exec(code, locals())\r\n        File \"<string>\", line 86, in <module>\r\n      AssertionError: Could not find \"cmake\" executable!\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n× Getting requirements to build wheel did not run successfully.\r\n│ exit code: 1\r\n╰─> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n```\r\n\r\n**更多信息 :**\r\n\r\n处理器\tIntel(R) Core(TM) i5-6500 CPU @ 3.20GHz   3.20 GHz\r\n机带 RAM\t16.0 GB\r\n系统类型\t64 位操作系统, 基于 x64 的处理器\r\n\r\n版本\tWindows 11 专业版\r\n版本\t21H2\r\n安装日期\t‎2021/‎12/‎22\r\n操作系统版本\t22000.1936\r\n体验\tWindows 功能体验包 1000.22001.1000.0\r\nPython 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)] on win32\r\n\r\n**报错截图**\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/3859838/e857ea2d-c7ea-4738-8170-6d95b616ec44)\r\n",
        "state": "closed",
        "user": "yuanrui",
        "closed_by": "yuanrui",
        "created_at": "2023-06-15T04:03:30+00:00",
        "updated_at": "2023-09-19T02:54:35+00:00",
        "closed_at": "2023-09-19T02:54:35+00:00",
        "comments_count": [
            "yuanrui",
            "baominghelly",
            "yuanrui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1121,
        "title": "将模型文件用cython转化后可正常训练模型，但是转onnx会报错",
        "body": "raise TypeError('module, class, method, function, traceback, frame, or '\r\nTypeError: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method",
        "state": "closed",
        "user": "DH-ai-A",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-06-21T07:48:08+00:00",
        "updated_at": "2025-02-20T02:31:22+00:00",
        "closed_at": "2025-02-20T02:31:21+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1124,
        "title": "导出paddleocr 仓库的det_r50_vd_dcn_fce_ctw之后使用paddle2onnx工具导出onnx失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n/tools/export_model.py导出det_r50_vd_dcn_fce_ctw之后得到了inference.pdmodel文件，然后输入如下命令：\r\n```shell\r\n paddle2onnx --model_dir=./ --model_filename inference.pdmodel --save_file det_r50_fce_ctw.onnx --enable_dev_version False\r\n```\r\n报错如下：\r\n```shell\r\n2023-06-28 04:33:10 [WARNING]   [Deprecated] `paddle2onnx.command.program2onnx` will be deprecated in the future version, the recommended usage is `paddle2onnx.export`\r\nTraceback (most recent call last):\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/command.py\", line 257, in main\r\n    program2onnx(\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/command.py\", line 174, in program2onnx\r\n    return program2onnx(model_dir, save_file, model_filename, params_filename,\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/legacy/command.py\", line 164, in program2onnx\r\n    [program, feed_var_names, fetch_vars] = fluid.io.load_inference_model(\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/wrapped_decorator.py\", line 26, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 558, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 1564, in load_inference_model\r\n    load_persistables(executor, load_dirname, program, params_filename)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/wrapped_decorator.py\", line 26, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 523, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 1075, in load_persistables\r\n    load_vars(executor,\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 829, in load_vars\r\n    load_vars(executor,\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 947, in load_vars\r\n    executor.run(load_prog)\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 1463, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 1450, in run\r\n    res = self._run_impl(program=program,\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 1661, in _run_impl\r\n    return new_exe.run(scope, list(feed.keys()), fetch_list,\r\n  File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 631, in run\r\n    tensors = self._new_exe.run(scope, feed_names,\r\nRuntimeError: In user code:\r\n\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/bin/paddle2onnx\", line 8, in <module>\r\n      sys.exit(main())\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/command.py\", line 257, in main\r\n      program2onnx(\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/command.py\", line 174, in program2onnx\r\n      return program2onnx(model_dir, save_file, model_filename, params_filename,\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle2onnx/legacy/command.py\", line 164, in program2onnx\r\n      [program, feed_var_names, fetch_vars] = fluid.io.load_inference_model(\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/wrapped_decorator.py\", line 26, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 558, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 1564, in load_inference_model\r\n      load_persistables(executor, load_dirname, program, params_filename)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/wrapped_decorator.py\", line 26, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 523, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 1075, in load_persistables\r\n      load_vars(executor,\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 829, in load_vars\r\n      load_vars(executor,\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/io.py\", line 875, in load_vars\r\n      load_block.append_op(\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 4040, in append_op\r\n      op = Operator(\r\n    File \"/disk1/wty/workspace/mindspore_dev/pyvenv/lib/python3.9/site-packages/paddle/fluid/framework.py\", line 2879, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    UnavailableError: Load operator fail to open file ./batch_norm_0.b_0, please check whether the model file is complete or damaged.\r\n      [Hint: Expected static_cast<bool>(fin) == true, but received static_cast<bool>(fin):0 != true:1.] (at /paddle/paddle/fluid/operators/load_op.h:43)\r\n      [operator < load > error]\r\n```\r\n使用如下命令\r\n```shell\r\npaddle2onnx --model_dir=./ --model_filename inference.pdmodel --save_file det_r50_fce_ctw.onnx\r\n```\r\n\r\n报错如下:\r\n```shell\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference.pdmodel\r\n[Paddle2ONNX] Paramters file path:\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n```\r\n\r\npaddle版本\r\n```shell\r\n[INFO]      paddle2onnx-1.0.6 with python>=3.6, paddlepaddle>=2.0.0\r\n\r\n```\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "new-TonyWang",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-06-28T07:48:47+00:00",
        "updated_at": "2024-11-22T03:04:26+00:00",
        "closed_at": "2024-11-22T03:04:26+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1125,
        "title": "PP-MobileSeg通过paddl2onnx转换报错，op问题 conditional_block",
        "body": "   \r\n    转换命令： \r\n    paddle2onnx --model_dir=./models --model_filename=model.pdmodel --params_filename=model.pdiparams -- \r\n     save_file=./models/inference.onnx --opset_version=11 --enable_onnx_checker=True  --enable_dev_version True\r\n\r\n    版本：\r\n    paddlepaddle-gpu: 2.4.2.post112\r\n    paddle2onnx:           1.0.6\r\n\r\n   ```\r\n   报错：\r\n    [Paddle2ONNX] Start to parse PaddlePaddle model...\r\n    [Paddle2ONNX] Model file path: ./models/model.pdmodel\r\n    [Paddle2ONNX] Paramters file path: ./models/model.pdiparams\r\n    [Paddle2ONNX] Start to parsing Paddle model...\r\n    [Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,\r\n    [ERROR] Due to the unsupported operators, the conversion is aborted.\r\n    Aborted (core dumped)\r\n```",
        "state": "closed",
        "user": "Yang507",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-07-03T07:11:04+00:00",
        "updated_at": "2024-07-13T12:34:25+00:00",
        "closed_at": "2024-07-13T12:34:25+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1126,
        "title": "ppyolotiny转换后，使用infer.py有多分类非最大值抑制的数组越界报错",
        "body": "![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/46918917/30ff7195-df77-4565-8074-a02ae861e489)\r\n\r\n",
        "state": "closed",
        "user": "Outstanding",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-07-05T10:20:54+00:00",
        "updated_at": "2025-02-18T02:29:37+00:00",
        "closed_at": "2025-02-18T02:29:37+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleDetection",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1127,
        "title": "Paddle2Onnx新版本为什么没提供预编译库？",
        "body": "注意到Paddle2Onnx老版本<=1.0.5都提供了预编译库：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/1317141/d2c842e0-9da5-4b4d-bd7b-0a2c5b0c89c1)\r\n\r\n想了解一下为什么Paddle2Onnx新版本>1.0.5都未提供预编译库：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/1317141/33e3adb9-d785-465b-b059-dc300e62a0d1)\r\n\r\n想了解一下为什么不提供了？windows/linux/osx的编译总归是个麻烦的事，提供预编译库能减轻很多工作，建议提供。",
        "state": "closed",
        "user": "sdcb",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-07-08T01:05:13+00:00",
        "updated_at": "2024-07-15T04:13:06+00:00",
        "closed_at": "2024-07-15T04:12:45+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1130,
        "title": "【OP转换出错】 pool2d算子在转换ONNX格式时会出现错误",
        "body": "## 基本描述\r\n\r\n* 模型地址: [ShuffleNetV2_x0_25_infer](https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/inference/ShuffleNetV2_x0_25_infer.tar)\r\n* 错误算子: batch_norm_55.tmp_3 -> pool2d_1.tmp_0 中间的`pool`算子\r\n\r\n## 错误判断\r\n\r\n直接通过netron打开`ShuffleNetV2_x0_25_infer`模型，pool算子构造如下:\r\n\r\n<img width=\"1512\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/58363586/80f6873c-5c59-4522-bd3f-f1cea60dc907\">\r\n\r\n可以看到，pool不为全局pool\r\n\r\n通过paddle2onnx-develop(1.0.8)导出后，pool构造如下:\r\n\r\n<img width=\"1512\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/58363586/76db17e4-ffd9-4d70-a4de-885b08991090\">\r\n\r\n被导出为全局池化层",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "jiangjiajun",
        "created_at": "2023-07-25T12:07:24+00:00",
        "updated_at": "2023-07-26T06:17:26+00:00",
        "closed_at": "2023-07-26T06:17:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1129,
        "title": "https://www.modelscope.cn/models/damo/cv_dla34_table-structure-recognition_cycle-centernet/summary  这个表格模型，有onnx版本吗？安装了个ubutn虚拟机，环境都安装失败了。可以帮忙转换一下onnx吗？ 微信nlanguage",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n\r\nhttps://www.modelscope.cn/models/damo/cv_dla34_table-structure-recognition_cycle-centernet/summary  这个表格模型，有onnx版本吗？安装了个ubutn虚拟机，环境都安装失败了。可以帮忙转换一下onnx吗？\r\n微信nlanguage",
        "state": "closed",
        "user": "nissansz",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-07-18T06:07:45+00:00",
        "updated_at": "2025-02-16T02:35:41+00:00",
        "closed_at": "2025-02-16T02:35:40+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1132,
        "title": "为什么paddle2onnx还不提供python3.11的 wheel 安装包",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n我需要在python3.11的环境中使用paddle2onnx，请尽快提供python3.11的pip 安装包 ，如果要使用是否要手动编译？\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):526872163@qq.com\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "526872163",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-07-27T11:06:55+00:00",
        "updated_at": "2024-07-15T04:12:26+00:00",
        "closed_at": "2024-07-15T04:12:26+00:00",
        "comments_count": [
            "526872163",
            "jiangjiajun"
        ],
        "labels": [
            "Python(New Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1134,
        "title": "Paddle2ONNX 转换 ppyoloV2报错",
        "body": "版本：1.0.6\r\n![7e7488c5bbfe4a3ab5f4de043b8e7ea](https://github.com/PaddlePaddle/Paddle2ONNX/assets/34666329/ee15aa10-b12b-453f-8c17-62c1c010f242)\r\n",
        "state": "closed",
        "user": "ltj19900609",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-08-02T04:34:52+00:00",
        "updated_at": "2025-02-06T02:29:52+00:00",
        "closed_at": "2025-02-06T02:29:51+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1136,
        "title": "Segmentation fault (core dumped) when convert paddle model to onnx",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\npaddleslim动态图QAT后的模型转ONNX的时候失败，报错Segmentation fault (core dumped)\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n版本 1.0.6\r\n - 你的联系方式(Email/Wechat/Phone):\r\n diaofeng698@163.com\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/41932458/b2bcd06c-67cf-45bb-b718-c77be7fe2fdd)\r\n\r\n\r\n**其他信息**\r\n命令：\r\npaddle2onnx --model_dir ./ --model_filename dynamic_quant_inference_model.pdmodel --params_filename dynamic_quant_inference_model.pdiparams --save_file dynamic_quant_inference_model.onnx --opset_version 13 --enable_dev_version True --deploy_backend onnxruntime --enable_onnx_checker True\r\n\r\n模型结构部分截图：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/41932458/f6d1234f-854f-4517-ba7b-6b8e88534905)\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/41932458/8ed67fec-9158-4e42-8945-74851193de2f)\r\n\r\n",
        "state": "closed",
        "user": "diaofeng698",
        "closed_by": "diaofeng698",
        "created_at": "2023-08-07T07:23:50+00:00",
        "updated_at": "2023-08-08T10:02:20+00:00",
        "closed_at": "2023-08-08T10:02:20+00:00",
        "comments_count": [
            "diaofeng698"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1137,
        "title": "p2o.DynamicDimension.0",
        "body": "![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/99791142/5aa848ad-dc00-4c98-ba78-dfbd5ee32830)\r\n\r\nonnx文件的输出batch为p2o.DynamicDimension.0，怎样改为-1。如：[-1,300,5]",
        "state": "closed",
        "user": "banhongjun",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-08-07T15:10:44+00:00",
        "updated_at": "2024-02-29T03:55:19+00:00",
        "closed_at": "2024-02-29T03:55:19+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Utils(ONNX)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1140,
        "title": "s2anet pdmodel转onnx ",
        "body": "Oops, there are some operators not supported yet, including conditional_block,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n我想将s2anet 的paddle模型转成onnx\r\nexport_onnx: True后，这些算子lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,还是有\r\n代码里也没有这个算子conditional_block和其用法",
        "state": "closed",
        "user": "railgun-zyy",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-08-14T07:54:17+00:00",
        "updated_at": "2025-02-05T02:29:34+00:00",
        "closed_at": "2025-02-05T02:29:34+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1141,
        "title": "PPOCRV4 det量化模型 转onnx出错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 2.4.2\r\n - 为什么需要转换为ONNX格式：onnx推理\r\n - Paddle2ONNX版本: 1.0.9\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/12406017/22be2617-bb92-4004-bca8-f9b52ca38e47)\r\n\r\n\r\n**其他信息**\r\n量化训练配置如下\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/12406017/f547de8e-1429-43a5-80e6-c894d1da6753)\r\ninference模型如下：\r\n[model.zip](https://github.com/PaddlePaddle/Paddle2ONNX/files/12333486/model.zip)\r\n\r\n",
        "state": "closed",
        "user": "WenmuZhou",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-08-14T09:38:11+00:00",
        "updated_at": "2025-02-03T02:29:02+00:00",
        "closed_at": "2025-02-03T02:29:02+00:00",
        "comments_count": [
            "hl-gl",
            "WenmuZhou",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1143,
        "title": "paddle2onnx工具转成的onnx文件使用tvm加载时报错",
        "body": "paddle2onnx工具将paddlenlp套件里的uie-x-base模型转成的onnx文件后，使用tvm加载时报错\r\n报错内容为：p2o.cast.22  cast is not output of any previous nodes\r\n\r\n\r\n**报错截图**\r\n![d485eac4e72f4787b5955afd0f23dfe1](https://github.com/PaddlePaddle/Paddle2ONNX/assets/140802176/a011afa8-aa24-4167-8811-761c33c1b0a3)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "vvwomen",
        "closed_by": "vvwomen",
        "created_at": "2023-08-24T02:07:54+00:00",
        "updated_at": "2023-09-11T05:25:19+00:00",
        "closed_at": "2023-09-11T05:25:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1144,
        "title": "[NVIDIA] Need to support custom op mapping through python functions",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nAfter training a FP8 model using Transformer Engine, to deploy the model using TRT, the paddle model needs to convert to ONNX model. Transformer Engine uses Paddle custom op to implement fast kernels for FP8 GEMM. Therefore, we need a python API to map custom ops to ONNX nodes.\r\n\r\nFor example, there is a custom op `cast_to_fp8`, which has the following inputs: `input, amax, scale_inv, idx, otype`.\r\n\r\nWe can define a mapper function, create ONNX nodes and set attributes / inputs as we want:\r\n\r\n```\r\n@symbolic_helper.parse_args(\"v\", \"v\", \"v\", \"fs\", \"i\", \"i\")\r\ndef onnx_cast_to_fp8(g, input, amax, scale_inv, idx, otype):\r\n    scale = g.op(\"Constant\", value_t=scale_inv[fp8_tensor])\r\n    q_op = g.op(\r\n        make_op_name(\"TRT_FP8QuantizeLinear\"), input, scale).setType(\r\n            input.type().with_dtype(torch.uint8).with_sizes(output_shape))\r\n    return q_op\r\n```\r\n\r\nFollowed by registry:\r\n```\r\npaddle2onnx.register_custom_op_symbolic('cast_to_fp8', onnx_cast_to_fp8)\r\n```\r\n\r\nThe request is very much similar to PyTorch's register_custom_op_symbolic, ([reference link](https://pytorch.org/docs/stable/onnx.html#c-operators)).\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "Tom-Zheng",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-08-24T04:02:08+00:00",
        "updated_at": "2025-02-01T02:30:50+00:00",
        "closed_at": "2025-02-01T02:30:50+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1146,
        "title": "版面分析模型和表格识别模型怎样转onnx？",
        "body": "版面分析模型和表格识别模型怎样转onnx？",
        "state": "closed",
        "user": "nissansz",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-09-04T22:35:00+00:00",
        "updated_at": "2025-01-31T02:28:00+00:00",
        "closed_at": "2025-01-31T02:28:00+00:00",
        "comments_count": [
            "Yamcanda",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1147,
        "title": "AttributeError: module 'paddle.fluid.layers' has no attribute 'multiclass_nms'",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Informations (please complete the following information):**\r\n - Paddle2ONNX Version:latest\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/107621428/2ef25c66-20fd-45cd-84a3-764d57ff4b6b)\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "mahesh11T",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-09-07T03:59:54+00:00",
        "updated_at": "2024-02-27T07:20:50+00:00",
        "closed_at": "2024-02-27T07:20:36+00:00",
        "comments_count": [
            "seejah",
            "jiangjiajun",
            "seejah"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1149,
        "title": "jetson编译最新版fastdeloy时，下载不到1.0.8rc",
        "body": "\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/26866665/3cf0764c-e23f-4947-a000-731e49ec7fb0)\r\n是不是版本对应错了？",
        "state": "closed",
        "user": "kankanjiuzou123",
        "closed_by": "jiangjiajun",
        "created_at": "2023-09-14T03:06:04+00:00",
        "updated_at": "2023-09-14T11:27:53+00:00",
        "closed_at": "2023-09-14T11:27:53+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1150,
        "title": "paddle2onnx转换为onnx模型后不能在onnxruntime=1.6的版本运行",
        "body": "paddleocr v3通过paddle2onnx转换为onnx模型后不能在onnxruntime=1.6的版本运行，opset版本从8到13都试过了\r\n\r\n\r\n![1694764681679](https://github.com/PaddlePaddle/Paddle2ONNX/assets/144425299/a7b2acf2-fb6d-4279-9dbf-d711fd0af424)\r\n\r\n联系方式：1735756353@qq.com",
        "state": "closed",
        "user": "jiangjh0908",
        "closed_by": "jiangjh0908",
        "created_at": "2023-09-15T07:59:19+00:00",
        "updated_at": "2024-02-27T07:27:30+00:00",
        "closed_at": "2023-09-16T14:27:46+00:00",
        "comments_count": [
            "jiangjiajun",
            "jiangjh0908"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1153,
        "title": "转onnx模型报错Cannot found attribute beta in op: swish",
        "body": "paddlepaddle-gpu 0.0.0.post117\r\npaddle2onnx 1.0.9\r\npaddleocr 2.6\r\n\r\n这是我使用的转换命令\r\npaddle2onnx --model_dir ./output/rec_db_inference --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/rec_onnx/model.onnx --opset_version 10 --enable_onnx_checker True\r\n\r\n下面是输出信息和报错\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./output/rec_db_inference/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./output/rec_db_inference/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Cannot found attribute beta in op: swish\r\n已放弃 (核心已转储)\r\n\r\n这个问题应该如何解决呢？",
        "state": "closed",
        "user": "666echo",
        "closed_by": "666echo",
        "created_at": "2023-10-04T03:51:52+00:00",
        "updated_at": "2024-02-27T07:24:33+00:00",
        "closed_at": "2023-10-05T10:51:52+00:00",
        "comments_count": [
            "jiangjiajun",
            "666echo"
        ],
        "labels": [
            "Bug",
            "Operator(Update)",
            "Paddle(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1156,
        "title": "[Paddle2ONNX] LodTensorArray is not supported.",
        "body": "\r\n**问题描述**\r\n对paddleDetection中的swin 模型 faster_rcnn_swin_tiny_fpn_3x_coco.yml 导出模型权重，想转化为onnx 格式，但是paddle2onnx 报错不支持LodTensorArray 算子,有其他方法可以进行转化吗\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: TensorRT 8\r\n - Paddle2ONNX版本: 1.0.9\r\n \r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/105638301/71c4f2f5-5633-4fca-bd5f-0709bf826687)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Jinjie0721",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-10-18T06:33:08+00:00",
        "updated_at": "2025-01-28T02:27:44+00:00",
        "closed_at": "2025-01-28T02:27:43+00:00",
        "comments_count": [
            "bpkrishnan",
            "DoManhQuang",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1128,
        "title": "There are some operators not supported yet",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nI'm trying to convert **faster_rcnn_r50_fpn_1x_coco** to onnx format. But some operators in '**faster_rcnn_r50_fpn_1x_coco**' are not supported by PADDLE2ONNX like this operator used for generating region proposals -> **generate_proposals_v2**\r\n\r\nThe error message :\r\nstart->\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_model/faster_rcnn_r50_fpn_1x_coco/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_model/faster_rcnn_r50_fpn_1x_coco/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n./3_export_rcnn_model_to_onnx: line 4: 18905 Aborted                 (core dumped) paddle2onnx --model_dir inference_model/faster_rcnn_r50_fpn_1x_coco --model_filename model.pdmodel --params_filename model.pdiparams --save_file faster_rcnn_r50_fpn_1x_coco.onnx\r\n\r\nend <-\r\n\r\n**My paddle packages installed version:**\r\npaddle2onnx              1.0.6\r\npaddledet                   2.6.0\r\npaddlepaddle             2.4.2\r\npaddlepaddle-gpu      2.4.2.post117\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Arslan-Mehmood1",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-07-12T11:18:56+00:00",
        "updated_at": "2024-02-29T04:03:04+00:00",
        "closed_at": "2024-02-29T04:03:04+00:00",
        "comments_count": [
            "hl-gl",
            "seejah",
            "zhjian831129",
            "seejah",
            "zhjian831129",
            "zhjian831129",
            "seejah"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1131,
        "title": "OCR自动量化后导出为onnx失败",
        "body": "\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/ocr\r\n\r\n该方案更换ICDAR2015数据集，采用预训练ResNet50模型（更改模型配置即可）可以成功运行，其精度基本不变，速度减少为1/4，获得Inference模型。此时的模型在转为ONNX时报错，缺少量化配置文件（calibration_table.txt），因此只能使用基于TRT的Inference模型推理，在相同环境下，与量化前的模型速度几乎相同。\r\n\r\n转换命令：\r\n\r\n!paddle2onnx --model_dir /home/aistudio/PaddleSlim/example/auto_compression/ocr/save_quant_ppocr_r50_det/  \\\r\n            --model_filename inference.pdmodel \\\r\n            --params_filename inference.pdiparams \\\r\n            --save_file /home/aistudio/work/ppocr_r50_db_det_slim.onnx \\\r\n            --opset_version 13 \\\r\n            --enable_dev_version True \\\r\n            --deploy_backend tensorrt  \\\r\n            --enable_onnx_checker True \r\n\r\n报错信息，缺少 calibration_table.txt\r\n\r\n无法通过量化模型起到对OCR加速的效果。",
        "state": "closed",
        "user": "xu-peng-7",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-07-26T06:07:03+00:00",
        "updated_at": "2025-02-16T02:35:40+00:00",
        "closed_at": "2025-02-16T02:35:39+00:00",
        "comments_count": [
            "xu-peng-7",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1158,
        "title": "python 版本是 3.9.13. pypi 上能看到 paddle2onnx = 1.0.9 为什么 pip 安装是提示最新的是 1.0.6 , pip 已经更新过了.",
        "body": "**问题描述**\r\npython 版本是 3.9.13. pypi 上能看到 paddle2onnx = 1.0.9 为什么 pip 安装是提示最新的是 1.0.6 , pip 已经更新过了.\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/41218920/9569b718-ecdc-4ff8-aff3-67d6d58f1632)\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/41218920/1c805bbb-b055-47c7-b360-a8303ef3eb6b)\r\n",
        "state": "closed",
        "user": "falling-ts",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-10-23T01:50:46+00:00",
        "updated_at": "2024-05-24T11:00:52+00:00",
        "closed_at": "2024-05-24T11:00:49+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1142,
        "title": "如何用opset12导出rtdetr",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n使用opset=12导出rt-detr模型时，grid_sample算子要求opset=16。但是项目后续部分要求使用opset=12。如何使用opset=12导出rt-detr？\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: rknpu\r\n - 为什么需要转换为ONNX格式：部署模型到rk3588开发板\r\n - Paddle2ONNX版本:  1.0.5\r\n - 你的联系方式(Email/Wechat/Phone): fangsujie2001@gmail.com\r\n\r\n**报错截图**\r\n![K8hVfI4cSk](https://github.com/PaddlePaddle/Paddle2ONNX/assets/63102146/9c2b7b03-3028-4183-9e59-a3864e06e21f)\r\n其中PaddleDetection是这个git repo：https://github.com/PaddlePaddle/PaddleDetection\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Sujie1528",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-08-15T02:36:10+00:00",
        "updated_at": "2024-07-15T03:19:35+00:00",
        "closed_at": "2024-07-15T03:19:35+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "RKNPU2",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1135,
        "title": "为什么 Deprecated",
        "body": "```md\r\n2023-08-02 16:42:00 [WARNING]   [Deprecated] The flag `--input_shape_dict` is deprecated, if you need to modify the input shape of PaddlePaddle model, please refer to this tool https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle\r\n```",
        "state": "closed",
        "user": "wolanx",
        "closed_by": "wolanx",
        "created_at": "2023-08-02T08:46:33+00:00",
        "updated_at": "2023-08-02T14:54:23+00:00",
        "closed_at": "2023-08-02T08:50:15+00:00",
        "comments_count": [
            "wolanx",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1139,
        "title": "自己训练paddleseg中的模型转onnx报错",
        "body": "采用自己的数据集训练paddleseg中pp_liteseg_stdc2模型，已经转换成推理模型，转onnx出现报错：\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: \r\n - 为什么需要转换为ONNX格式：标注软件X-Anylabeling需要\r\n - Paddle2ONNX版本: paddle2onnx-1.0.6\r\n - 你的联系方式(Email/Wechat/Phone): 2240316863@qq.com\r\n\r\n**报错截图**\r\n![捕获](https://github.com/PaddlePaddle/Paddle2ONNX/assets/54742276/89fccb40-5d1c-46c0-8ae5-150211141831)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "KKWY0909",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-08-11T09:30:33+00:00",
        "updated_at": "2024-04-10T07:01:21+00:00",
        "closed_at": "2024-04-10T07:01:21+00:00",
        "comments_count": [
            "hl-gl",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1145,
        "title": "Support python 3.11",
        "body": "Python 3.11 is well-released now. The library needs to support for this python version.",
        "state": "closed",
        "user": "nhatdt51",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-08-28T04:30:44+00:00",
        "updated_at": "2025-02-01T02:30:50+00:00",
        "closed_at": "2025-02-01T02:30:49+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Python(New Version)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1148,
        "title": "Paddle2ONNX不支持导出半精度ONNX模型",
        "body": "**Describe the bug**\r\n\r\npaddle框架提供的paddle.onnx.export 不支持导出半精度ONNX模型，会直接报错[ERROR] Float16 is not supported.\r\n同paddle2onnx也不支持导出半精度ONNX模型，期望提供方法能够支持这个需求。\r\n\r\nrelated issue: https://github.com/PaddlePaddle/Paddle/issues/57194\r\n\r\n最小的实现示例：\r\n```\r\nimport paddle\r\nfrom paddlenlp.transformers import UIEX # 从模型代码中导入模型\r\nmodel = UIEX.from_pretrained(\"uie-x-base\") # 实例化模型\r\nmodel.to(dtype=\"float16\") # 加载预训练模型参数\r\nmodel.eval() # 将模型设置为评估状态\r\n\r\ninput_spec = [\r\npaddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"input_ids\"),\r\npaddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"token_type_ids\"),\r\npaddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"position_ids\"),\r\npaddle.static.InputSpec(shape=[None, None], dtype=\"int64\", name=\"attention_mask\"),\r\npaddle.static.InputSpec(shape=[None, None, 4], dtype=\"int64\", name=\"bbox\"),\r\npaddle.static.InputSpec(shape=[None, 3, 224, 224], dtype=\"float16\", name=\"image\"),\r\n] # # 定义输入数据\r\n\r\nprint(\"Exporting ONNX model to %s\" % \"./uiex_fp16.onnx\")\r\npaddle.onnx.export(model, \"./uiex_fp16\", input_spec=input_spec) # ONNX模型导出\r\nprint(\"ONNX model exported.\")\r\n```\r\n\r\n另，网上提供的工具https://zenn.dev/pinto0309/scraps/588ed8342e2182 将FP32的onnx模型转为FP16后，此FP16的onnx模型存在问题不能在onnxruntime上使用。\r\n\r\n\r\n**Informations (please complete the following information):**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/127805199/a82c222a-1d8e-4bc4-b4b6-0462f9c97f99)\r\n\r\n\r\n![9f720274481b376adb75dae6f6ffd5f](https://github.com/PaddlePaddle/Paddle2ONNX/assets/127805199/c6750827-17ce-4389-8d2e-160345c658f8)\r\n![18a74c76f2f2e7a65d7106b57e8c926](https://github.com/PaddlePaddle/Paddle2ONNX/assets/127805199/43bb2460-5e33-4289-b7ac-a36e0ddb4f1d)\r\n\r\n",
        "state": "closed",
        "user": "tiandou-tangdou",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-09-11T13:21:34+00:00",
        "updated_at": "2025-01-29T02:27:17+00:00",
        "closed_at": "2025-01-29T02:27:17+00:00",
        "comments_count": [
            "hl-gl",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1152,
        "title": "Oops, there are some operators not supported yet, including roll",
        "body": "\r\ncannot export model rtdetr swin",
        "state": "closed",
        "user": "jeiva2000",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-09-28T11:20:24+00:00",
        "updated_at": "2024-04-13T11:32:24+00:00",
        "closed_at": "2024-04-13T11:32:24+00:00",
        "comments_count": [
            "jeiva2000",
            "taroshi",
            "taroshi",
            "jeiva2000",
            "jeiva2000",
            "YeXinZ",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1159,
        "title": "pip3安装的用不了，编译安装也失败",
        "body": "-- ******** Summary ********\r\n-  absl_VERSION: 20230802\r\n-- ONNX_PROTOC_EXECUTABLE: /opt/homebrew/bin/protoc\r\n-- Protobuf_VERSION: 4.24.4\r\n--   CMake version                     : 3.27.2\r\n--   CMake command                     : /opt/homebrew/lib/python3.11/site-packages/cmake/data/bin/cmake\r\n--   System                            : Darwin\r\n--   C++ compiler                      : /Library/Developer/CommandLineTools/usr/bin/c++\r\n--   C++ compiler version              : 14.0.3.14030022\r\n--   CXX flags                         :  -Wnon-virtual-dtor\r\n--   Build type                        : Release\r\n--   Compile definitions               : MAX_ONNX_OPSET_VERSION=17;PADDLE2ONNX_LIB;ONNX_NAMESPACE=paddle2onnx;__STDC_FORMAT_MACROS\r\n--   CMAKE_PREFIX_PATH                 : \r\n--   CMAKE_INSTALL_PREFIX              : /usr/local\r\n--   CMAKE_MODULE_PATH                 : \r\n-- \r\n--   ONNX version                      : 1.15.0\r\n--   ONNX NAMESPACE                    : paddle2onnx\r\n--   ONNX_USE_LITE_PROTO               : OFF\r\n--   USE_PROTOBUF_SHARED_LIBS          : OFF\r\n--   Protobuf_USE_STATIC_LIBS          : ON\r\n--   ONNX_DISABLE_EXCEPTIONS           : OFF\r\n--   ONNX_DISABLE_STATIC_REGISTRATION  : OFF\r\n--   ONNX_WERROR                       : OFF\r\n--   ONNX_BUILD_TESTS                  : OFF\r\n--   ONNX_BUILD_BENCHMARKS             : OFF\r\n--   ONNX_BUILD_SHARED_LIBS            : \r\n--   BUILD_SHARED_LIBS                 : \r\n-- \r\n--   Protobuf compiler                 : /opt/homebrew/bin/protoc\r\n--   Protobuf includes                 : /opt/homebrew/include\r\n--   Protobuf libraries                : /opt/homebrew/lib/libprotobuf.dylib\r\n--   BUILD_ONNX_PYTHON                 : OFF\r\n-- Paddle2ONNX： master\r\n",
        "state": "closed",
        "user": "Lowpower",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-10-25T09:10:24+00:00",
        "updated_at": "2024-06-24T06:30:50+00:00",
        "closed_at": "2024-06-24T06:30:50+00:00",
        "comments_count": [
            "Lowpower"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1160,
        "title": "Paddledetection 中的yolov5导出为onnx",
        "body": "球球了，大佬，导出v5为onnx的时候如何设置batch 为1 现在导出的模型要么在paddle2onnx=1.0.0版本下为-1 要么为p2o.DynamicDimension.0，怎么设置为1？",
        "state": "closed",
        "user": "ghost",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-10-26T03:26:15+00:00",
        "updated_at": "2024-02-27T07:17:11+00:00",
        "closed_at": "2024-02-27T07:17:11+00:00",
        "comments_count": [
            "jiangjiajun"
        ],
        "labels": [
            "Utils(ONNX)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1164,
        "title": "导出onnx可以设置输入输出的名称吗？例如输入的名称为“input”，输出为“output”",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n如下图，onnx的输入和输出名字修改，可以做到吗？\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/39027951/94a6179b-49f4-4a11-ae66-d67a77692486)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "zsffuture",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-12-14T04:33:30+00:00",
        "updated_at": "2024-02-27T01:39:01+00:00",
        "closed_at": "2024-02-27T01:38:32+00:00",
        "comments_count": [
            "jiangjiajun",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Utils(ONNX)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1166,
        "title": "PaddleOCRv3量化模型转ONNX推理bug",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nPaddleOCRv3量化模型量化模型转onnx后部署存在以下问题：\r\n1. 带量化节点的ONNX模型转trt提示没有输出节点，但是netron可视化onnx模型是存在输出节点．\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:　ONNXRuntime和TensorRT\r\n - 为什么需要转换为ONNX格式：边缘设备部署模型\r\n - Paddle2ONNX版本:1.1.0\r\n - 你的联系方式(Email/Wechat/Phone): 771830171@qq.com\r\n\r\n**报错截图**\r\n\r\n![111](https://github.com/PaddlePaddle/Paddle2ONNX/assets/23739417/c7d32429-4f9a-4793-9fd4-d054798d90ea)\r\n\r\n\r\n**其他信息**\r\nPaddle版本：2.4.2\r\nPaddleslim版本：2.4.1\r\n\r\n\r\n",
        "state": "closed",
        "user": "Daipuwei",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-12-18T08:49:59+00:00",
        "updated_at": "2025-01-22T02:30:13+00:00",
        "closed_at": "2025-01-22T02:30:13+00:00",
        "comments_count": [
            "Daipuwei",
            "Daipuwei",
            "Daipuwei",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1162,
        "title": "module 'paddle.fluid.layers' has no attribute 'pad2d'",
        "body": "转db++模型到onnx的时候，使用命令\r\n\r\npaddle2onnx --model_dir ./inference/det_db++/ --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/det_db++/model.onnx --opset_version 11 --input_shape_dict=\"{'x':[-1,3,-1,-1]}\" --enable_onnx_checker True --enable_dev_version False\r\n\r\n版本：\r\npaddlepaddle== 2.5.1\r\nonnx == 1.10.0\r\npaddle2onnx == 1.0.2\r\n\r\n报错：\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/command.py\", line 250, in main\r\n    program2onnx(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/command.py\", line 168, in program2onnx\r\n    return program2onnx(model_dir, save_file, model_filename, params_filename,\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/command.py\", line 200, in program2onnx\r\n    p2o.program2onnx(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 78, in program2onnx\r\n    return program2onnx(program, scope, save_file, feed_var_names, target_vars,\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/convert.py\", line 95, in program2onnx\r\n    return export_onnx(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/convert.py\", line 35, in export_onnx\r\n    onnx_graph = ONNXGraph.build(paddle_graph, opset_version,\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 323, in build\r\n    onnx_graph = ONNXGraph(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 85, in __init__\r\n    self.update_opset_version()\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/graph/onnx_graph.py\", line 202, in update_opset_version\r\n    self.opset_version = OpMapper.get_recommend_opset_version(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\", line 147, in get_recommend_opset_version\r\n    custom_paddle_graph, output_results = custom_paddle_op.get_paddle_graph(\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/op_mapper/op_mapper.py\", line 262, in get_paddle_graph\r\n    res = self.forward()\r\n  File \"/opt/conda/lib/python3.8/site-packages/paddle2onnx/legacy/op_mapper/custom_paddle_op/deformable_conv.py\", line 66, in forward\r\n    input = layers.pad2d(input, self.padding)\r\nAttributeError: module 'paddle.fluid.layers' has no attribute 'pad2d'",
        "state": "closed",
        "user": "zr-icu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-11-10T07:44:45+00:00",
        "updated_at": "2024-02-27T07:10:30+00:00",
        "closed_at": "2024-02-27T07:10:30+00:00",
        "comments_count": [
            "jiangjiajun",
            "HawkingRadiation42",
            "zr-icu",
            "HawkingRadiation42"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1161,
        "title": "paddle2tensorrt  \"Cannot infer squeeze dimensions from a dynamic shape! Please re-export your model with the Squeeze axes input set.\"",
        "body": "![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/107621428/1ed918e8-59bc-4233-aa45-39cc7fbd1fdf)\r\nhttps://github.com/NVIDIA/TensorRT/issues/2849\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/411\r\n\r\n\r\nI am trying to convert / use onnx model to tensorrt, can I get help with this?\r\n[8] Assertion failed: !isDynamic(shape) && \"Cannot infer squeeze dimensions from a dynamic shape! Please re-export your model with the Squeeze axes input set.\"",
        "state": "closed",
        "user": "mahesh11T",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-10-31T11:00:00+00:00",
        "updated_at": "2025-01-28T02:27:42+00:00",
        "closed_at": "2025-01-28T02:27:42+00:00",
        "comments_count": [
            "Ochre-amber",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1165,
        "title": "官方模型：ppmatting-hrnet_w18-human_512导出为onnx失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n官方的ppmatting-hrnet_w18-human_512的Inference模型转成onnx时，报pool2d节点错误，无法转换。已经按照建议的做法，导出成静态模型时，指定输出为1,3,512,512，导出onnx成功，但是测试结果无法和paddleinferenece推理结果对齐，抠图结果边缘过渡是锯齿，不是平滑的过渡。请问最新的版本有没有解决这个问题呢（去ppMatting微信交流群问过没人回复）\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n    onnxruntime\r\n - 为什么需要转换为ONNX格式：\r\n   需要使用onnxruntime做推理\r\n - Paddle2ONNX版本:\r\n   1.0.0rc4\r\n - 你的联系方式(Email/Wechat/Phone):\r\n   1476263438@qq.com\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/16351823/23afd9be-c213-444e-8ba8-6366f4f59d52)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "xdg2016",
        "closed_by": "github-actions[bot]",
        "created_at": "2023-12-15T02:02:22+00:00",
        "updated_at": "2025-01-24T02:28:32+00:00",
        "closed_at": "2025-01-24T02:28:31+00:00",
        "comments_count": [
            "Steph55",
            "Steph55",
            "wangkd0",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleSeg",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1163,
        "title": "Picodet模型导出Onnx出错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\npaddlex需用Picodet模型训练，导出inference_model文件夹（包含model.pdiparams，model.pdiparams.info，model.pdmodel，model.yml，pipeline.yml）\r\n新建导出python文件：\r\nfrom paddle2onnx import export\r\nmodel = r'H:/paddlex_workspace/P0025-T0128_export_model/inference_model/inference_model/model.pdmodel'\r\nparams_file= r'H:\\paddlex_workspace\\P0025-T0128_export_model\\inference_model\\inference_model\\model.pdiparams'\r\nsave_file= r'H:\\paddlex_workspace\\P0025-T0128_export_model\\inference_model\\inference_model\\picodet.onnx'\r\n# export the model to ONNX format\r\nexport(model, params_file, save_file)\r\n\r\n请在此处详细的描述报错信息\r\n运行后报如下错误：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: H:/paddlex_workspace/P0025-T0128_export_model/inference_model/inference_model/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: H:\\paddlex_workspace\\P0025-T0128_export_model\\inference_model\\inference_model\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] LodTensorArray is not supported.\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,lod_array_length,select_input,tensor_array_to_tensor,while,write_to_array,\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:  rknn\r\n - 为什么需要转换为ONNX格式：转换为rknn\r\n - Paddle2ONNX版本: \r\npaddle2onnx               1.0.6                    pypi_0    pypi\r\npaddlepaddle-gpu          2.2.2.post112            pypi_0    pypi\r\npaddleslim                2.2.1                    pypi_0    pypi\r\npaddlex                   2.1.0                    pypi_0    pypi\r\n - 你的联系方式(Email/Wechat/Phone):\r\nff-stone@163.com\r\n**报错截图**\r\n\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "ff-stone",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-12-08T07:30:56+00:00",
        "updated_at": "2024-03-05T06:13:30+00:00",
        "closed_at": "2024-02-29T03:58:59+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "ff-stone",
            "ff-stone",
            "Zheng-Bicheng",
            "ff-stone",
            "Zheng-Bicheng",
            "ff-stone",
            "Zheng-Bicheng",
            "ff-stone"
        ],
        "labels": [
            "Bug",
            "RKNPU2"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1167,
        "title": "需要将Paddle模型转换为onnx，报错：[ERROR] Cannot found attribute beta in op: swish",
        "body": "paddle2onnx               1.0.6                    \r\npaddlepaddle              2.6.0\r\n\r\n我使用的命令为：paddle2onnx --model_dir export_model --model_filename model.pdmodel --params_filename model.pdiparams --input_shape_dict \"{'image':[1,3,640,640]}\" --opset_version 11 --save_file ppyoloe_crn_s_80.onnx\r\n\r\n以下是输出信息：\r\n[WARNING] [Deprecated] The flag `--input_shape_dict` is deprecated, if you need to modify the input shape of PaddlePaddle model, please refer to this tool https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle \u001b[0m\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: export_model\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: export_model\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Cannot found attribute beta in op: swish\r\n\r\n请问大佬们这个如何解决\r\n",
        "state": "closed",
        "user": "HW-WF",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2023-12-28T10:02:40+00:00",
        "updated_at": "2024-09-27T07:28:27+00:00",
        "closed_at": "2024-02-23T05:07:08+00:00",
        "comments_count": [
            "jiangjiajun",
            "JuliusQv",
            "laugh12321",
            "HW-WF",
            "Zheng-Bicheng",
            "m00nLi",
            "yuanzhibin",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "yuanzhibin",
            "yuanzhibin",
            "Zheng-Bicheng",
            "ksdyxx",
            "unicasad",
            "Zheng-Bicheng",
            "YiAnXS",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1168,
        "title": "（已经在issues里找过一圈答案了没有解决）faster_rcnn 转onnx 提示there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2",
        "body": "  请各位大佬看一下\r\n1. 在AI studio平台上操作  BML codelab\r\n2. 环境 PaddlePaddle 2.4.0     python=3.7.4\r\n3. Paddledetection 2.5.0\r\n4. paddle2onnx-1.1.0  （从1.0.0   1.0.6    1.1.0， 三个版本都试过，还是提示如下错误）\r\n5. --opset_version 16 （从11改到16 都试过，还是提示如下错误）\r\n6. 已经在export_model时， faster_rcnn/faster_rcnn_r34_fpn_1x_coco.yml里添加了export_onnx: True。\r\n7. 该错误是在--enable_dev_version 设为True时候出现， 设为False 直接提示 找不到ModuleNotFoundError: No module named 'onnx',``\r\n\r\n以下是运行命令：\r\n! paddle2onnx --model_dir inference_model/faster_rcnn_r34_fpn_1x_coco \\\r\n              --model_filename model.pdmodel \\\r\n              --params_filename model.pdiparams \\\r\n              --opset_version 16 \\\r\n              --enable_dev_version True \\\r\n              --save_file final.onnx \\\r\n\r\n以下是提示：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_model/faster_rcnn_r34_fpn_1x_coco/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_model/faster_rcnn_r34_fpn_1x_coco/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.",
        "state": "closed",
        "user": "zhjian831129",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-01-04T03:25:54+00:00",
        "updated_at": "2025-01-22T02:30:12+00:00",
        "closed_at": "2025-01-22T02:30:11+00:00",
        "comments_count": [
            "zhjian831129",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1171,
        "title": "Can not set input_shape when converting inference model to onnx",
        "body": "Thanks for excellent work!\r\n\r\nI can not set input_shape when [converting model ocr to onnx](https://github.com/PaddlePaddle/PaddleOCR/issues/11492)\r\n\r\nI had tried setting, convert successfully, but no affect with input_shape:\r\n```\r\npaddle2onnx --model_dir ./inference/rec_en_ppocr_v4/ --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/rec_onnx/ppocr_v4_model.onnx --opset_version 10 --input_shape_dict=\"{'x':[-1,3, 32,-1]}\" --enable_onnx_checker True\r\n```\r\nHere is my envs:\r\n```\r\npaddlepaddle-gpu: 2.5.2.post116\r\npaddle2onnx: 1.0.5\r\nonnx: 1.13.1\r\nonnxruntime: 1.14.1\r\n```\r\nThanks in advance!!",
        "state": "closed",
        "user": "phamkhactu",
        "closed_by": "phamkhactu",
        "created_at": "2024-01-15T04:41:32+00:00",
        "updated_at": "2024-01-15T08:16:17+00:00",
        "closed_at": "2024-01-15T08:16:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1169,
        "title": "ppocrv4识别模型转onnx时，修改输入shape，出现数值偏差很大的问题",
        "body": "**使用ppocrv4识别模型的配置训练自定义的数据集时，backbone为PPLCNetV3，修改了输入shape，调整为【3，144，240】，同步调整backbone输出用的adaptive_avg_pool2d，训练测试正常，调用export_model.py脚本导出模型后，调用predict_rec.py,测试未出现数值精度下降情况，使用paddle2onnx将模型转换为onnx后，测试发现一致性问题，逐层检查时，输入一致，仅使用解码部分也一致，在backbone中adaptive_avg_pool2d前出现不一致情况，麻烦看看是什么原因？\r\n另外调回输入shape后导出onnx，测试数值一致。评估原因可能出在输入shape这块**\r\n\r\n\r\n\r\n**信息 :**\r\n - 用于部署的推理引擎:\r\nGPU cuda 11.2\r\n  - 主要版本信息\r\npaddlepaddle-gpu 2.4.0\r\npaddle2onnx 1.1.0\r\nPPOCR 2.7.release\r\n - Email：anshen.lw@gmail.com\r\n**报错截图**\r\n数值不一致问题\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "anshenLW",
        "closed_by": "anshenLW",
        "created_at": "2024-01-05T13:16:37+00:00",
        "updated_at": "2024-02-27T07:26:24+00:00",
        "closed_at": "2024-01-08T06:52:32+00:00",
        "comments_count": [
            "anshenLW"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1170,
        "title": "mask-rcnn明明我找到的issue上面显示已经支持generate_proposals_v2算子的转换了，但是我转换的时候还是提示不支持转换的op",
        "body": "**问题描述**\r\nmask-rcnn模型转换为onnx模型的时候，提示不支持转换的op：generate_proposals_v2，但是我在这个issue上面看说是这个算子已经支持了，同时我在环境路径上也找到了对应的文件。\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/pull/636\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/81606481/7985db19-a158-49f3-9b48-f0f6278320e9)\r\n文件打开也能看到对generate_proposals_v2的支持\r\n![企业微信截图_20240115113739](https://github.com/PaddlePaddle/Paddle2ONNX/assets/81606481/930714ae-ccc5-4111-9779-1b90113f33cc)\r\n\r\n\r\n报错信息具体如下：\r\n(paddle) D:\\Paddle\\3.PaddleDetection\\PaddleDetection-release-2.5>paddle2onnx --model_dir inference_model\\mask_rcnn_r50_1x_coco --model_file model.pdmodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version True --opset_version 16 --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_model\\mask_rcnn_r50_1x_coco\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_model\\mask_rcnn_r50_1x_coco\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including generate_proposals_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n**报错截图**\r\n![企业微信截图_20240115113612](https://github.com/PaddlePaddle/Paddle2ONNX/assets/81606481/73b0be97-2d71-47fd-a82a-fb299882ad46)\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本:1.0.6\r\n - 你的联系方式(Email/Wechat/Phone):a275257@qq.com\r\n",
        "state": "closed",
        "user": "laishenghui",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-01-15T03:38:15+00:00",
        "updated_at": "2025-01-20T02:30:10+00:00",
        "closed_at": "2025-01-20T02:30:09+00:00",
        "comments_count": [
            "laishenghui",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1173,
        "title": "paddle2onnx 新版本 --input_shape_dict 参数提示信息",
        "body": "使用1.x.x版本paddle2onnx时，--input_shape_dict 字段以及被弃用，但是会提示转到\r\n\r\n```\r\n2024-01-22 23:21:54 [WARNING]\t[Deprecated] The flag `--input_shape_dict` is deprecated, if you need to modify the input shape of PaddlePaddle model, please refer to this tool https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle\r\n```\r\n\r\n官方提供了解决方案，所以这个log输出应该需要更改一下。\r\n```\r\npython -m paddle2onnx.optimize --input_model model.onnx \\\r\n                               --output_model new_model.onnx \\\r\n                               --input_shape_dict \"{'x':[1,3,224,224]}\"\r\n```",
        "state": "closed",
        "user": "weirman",
        "closed_by": "weirman",
        "created_at": "2024-01-23T02:00:09+00:00",
        "updated_at": "2024-02-27T07:25:33+00:00",
        "closed_at": "2024-02-01T04:06:48+00:00",
        "comments_count": [
            "HawkingRadiation42",
            "weirman",
            "HawkingRadiation42",
            "weirman",
            "HawkingRadiation42",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Remove Unuseful"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1172,
        "title": "paddle2onnx转化相关问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n我这几天使用paddle2onnx，想把自己使用paddlepaddle框架训练的模型转成onnx模型并调用，但是有的算子不支持，有的转换成功了也不知道怎么搭建网络并调用，有自己训练模型转换成onnx模型并推理的教程吗。感觉支持的框架不多\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：使用了多个框架来训练模型，想把几个框架的模型都转成onnx格式的模型并推理\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "xxPete",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-01-17T05:29:23+00:00",
        "updated_at": "2024-04-10T06:58:11+00:00",
        "closed_at": "2024-04-10T06:58:11+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1174,
        "title": "No module named 'paddle2onnx.paddle2onnx_cpp2py_export'",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\nWhile compiling paddle2onnx, I cannot run it. How to solve it ?\r\n\r\n```bash\r\n# cmake installation\r\nwget https://github.com/Kitware/CMake/releases/download/v3.28.1/cmake-3.28.1-Linux-x86_64.sh && \\\r\nchmod +x cmake-3.28.1-Linux-x86_64.sh && \\\r\n./cmake-3.28.1-Linux-x86_64.sh --prefix=/usr/local --exclude-subdir --skip-license && \\\r\nrm ./cmake-3.28.1-Linux-x86_64.sh && \\\r\nsudo ln -s /usr/local/bin/cmake /usr/bin/cmake\r\n\r\n# protobuf installation\r\ngit clone https://github.com/protocolbuffers/protobuf.git\r\ncd protobuf\r\ngit checkout v3.16.0\r\ngit submodule update --init --recursive\r\n./autogen.sh\r\n./configure\r\nmake -j$(nproc)\r\nmake check\r\nmake install\r\nldconfig\r\n\r\n# paddle2onnx installation\r\ngit clone https://github.com/PaddlePaddle/Paddle2ONNX.git\r\ncd Paddle2ONNX\r\ngit submodule init\r\ngit submodule update\r\npython setup.py install\r\n```",
        "state": "closed",
        "user": "ilbash",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-01-23T13:51:49+00:00",
        "updated_at": "2024-05-24T11:18:40+00:00",
        "closed_at": "2024-05-24T11:18:40+00:00",
        "comments_count": [
            "jiangjiajun",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1176,
        "title": "您好导出onnx,有没有办法导出旧的算子",
        "body": "![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/58769772/25f42c56-cfff-4ddf-b85f-c10b156f7553)\r\n像这种旧的方式导出，有什么办法是可以的嘛谢谢",
        "state": "closed",
        "user": "chen-del",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-01-26T02:19:57+00:00",
        "updated_at": "2024-02-27T07:17:59+00:00",
        "closed_at": "2024-02-27T07:12:58+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "chen-del",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "chen-del",
            "Zheng-Bicheng",
            "chen-del",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "chen-del",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "chen-del",
            "Zheng-Bicheng",
            "chen-del"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1175,
        "title": "wav2lip 转onnx后，生成的onnx模型输出维度变为：[-1, 3, 96, 96]，而原来paddlepaddle的模型正常输出是[-1, 6, 96, 96]，请问这是什么问题？",
        "body": "感谢paddle辛勤付出！\r\n以下是我转换大致过程（全程无报错，转换后onnx可视化正常）：\r\n1、python -u tools/export_model.py -c configs/wav2lip_hq.yaml --load applications/tools/checkpoints/wav2lip_hq.pdparams --inputs_size=\"-1,1,-1,-1;-1,6,-1,-1\"\r\n2、paddle2onnx --model_dir ./ --model_filename wav2lipmodelhq_netG.pdmodel --params_filename wav2lipmodelhq_netG.pdiparams --save_file model.onnx --enable_dev_version True --opset_version 13 --enable_onnx_checker True\r\n3、onnx_model = onnx.load(\"model.onnx\")\r\n# 使用 ONNX 库检查 ONNX 模型是否合理\r\ncheck = onnx.checker.check_model(onnx_model)\r\n# 打印检查结果\r\nprint('check: ', check)\r\nNone\r\n4、ort_inputs = {ort_sess.get_inputs()[0].name: mel_batch, ort_sess.get_inputs()[1].name: img_batch}\r\npred = ort_sess.run(None, ort_inputs)\r\nprint('pred', np.asarray(pred).shape)\r\n（1，128，3，96，96） # 那个1我不知道怎么出来的，128是batch，3好像是通道？奇了怪了 ，不应该是6吗？还有就是为什么wav2lip的输入通道是6？我看了onnx模型也没发现分组卷积啊？难道我搞错了？总之，\r\n\r\n输出尺寸应该是（-1，6，96，96）对吧？可是我的onnx输出尺寸是（-1，3，96，96）\r\n请帮忙理解一下~感谢~~~",
        "state": "closed",
        "user": "drakitLiu",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-01-25T11:09:21+00:00",
        "updated_at": "2025-01-17T02:26:52+00:00",
        "closed_at": "2025-01-17T02:26:51+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1180,
        "title": "bilinear_interp输出shape为啥是[unk__34,unk__35,unk__36,unk__37] 我已经固定inputshape [1 3 512 512] ",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用paddleseg2.9 版本 pp 2.6 版本 转换ppseg模型bilinear_interp输出shape 是[unk__34,unk__35,unk__36,unk__37] \r\n输出的shape也是[unk__34,unk__35,unk__36,unk__37] \r\n\r\n**更多信息 :**\r\n我用于paddle2onnx 转onnx 再转rknn模型的\r\n现在卡在paddle2onnx这个过程中\r\n**报错截图**\r\n![微信图片_20240126204855](https://github.com/PaddlePaddle/Paddle2ONNX/assets/102646780/101843fc-3dd0-42ce-88ff-bad17cf40669)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "13950182204",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-01-27T12:23:26+00:00",
        "updated_at": "2025-01-16T02:27:21+00:00",
        "closed_at": "2025-01-16T02:27:20+00:00",
        "comments_count": [
            "13950182204",
            "13950182204",
            "13950182204",
            "1314520gu",
            "amandazw",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1184,
        "title": "命令行转换或导出onnx时报：ModuleNotFoundError: No module named 'paddle.fluid'",
        "body": "(base) PS C:\\Users\\Administrator> conda activate paddle22\r\n(paddle22) PS C:\\Users\\Administrator> pip install paddle2onnx==0.7\r\nCollecting paddle2onnx==0.7\r\n  Downloading paddle2onnx-0.7-py3-none-any.whl (94 kB)\r\n     ---------------------------------------- 94.4/94.4 kB 199.5 kB/s eta 0:00:00\r\nRequirement already satisfied: six in d:\\users\\administrator\\anaconda3\\envs\\paddle22\\lib\\site-packages (from paddle2onnx==0.7) (1.16.0)\r\nRequirement already satisfied: protobuf in d:\\users\\administrator\\anaconda3\\envs\\paddle22\\lib\\site-packages (from paddle2onnx==0.7) (3.20.2)\r\nInstalling collected packages: paddle2onnx\r\nSuccessfully installed paddle2onnx-0.7\r\n(paddle22) PS C:\\Users\\Administrator> cd 'E:\\Python Projects\\PaddleSegTest\\PaddleSeg\\contrib\\PP-HumanSeg'\r\n(paddle22) PS E:\\Python Projects\\PaddleSegTest\\PaddleSeg\\contrib\\PP-HumanSeg> paddle2onnx --model_dir output --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file output.onnx\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Scripts\\paddle2onnx.exe\\__main__.py\", line 4, in <module>\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\__init__.py\", line 18, in <module>\r\n    from .convert import dygraph2onnx, program2onnx\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\convert.py\", line 21, in <module>\r\n    from paddle.fluid.framework import Variable\r\nModuleNotFoundError: No module named 'paddle.fluid'\r\n(paddle22) PS E:\\Python Projects\\PaddleSegTest\\PaddleSeg\\contrib\\PP-HumanSeg> paddle2onnx --model_dir saved_inference_model --model_filename model.pdmodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version True\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Scripts\\paddle2onnx.exe\\__main__.py\", line 4, in <module>\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\__init__.py\", line 18, in <module>\r\n    from .convert import dygraph2onnx, program2onnx\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\convert.py\", line 21, in <module>\r\n    from paddle.fluid.framework import Variable\r\nModuleNotFoundError: No module named 'paddle.fluid'\r\n(paddle22) PS E:\\Python Projects\\PaddleSegTest\\PaddleSeg\\contrib\\PP-HumanSeg> paddle2onnx --model_dir saved_inference_model --model_filename model.pdmodel --params_filename model.pdiparams --save_file model.onnx --enable_dev_version False\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Scripts\\paddle2onnx.exe\\__main__.py\", line 4, in <module>\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\__init__.py\", line 18, in <module>\r\n    from .convert import dygraph2onnx, program2onnx\r\n  File \"D:\\Users\\Administrator\\anaconda3\\envs\\paddle22\\Lib\\site-packages\\paddle2onnx\\convert.py\", line 21, in <module>\r\n    from paddle.fluid.framework import Variable\r\nModuleNotFoundError: No module named 'paddle.fluid'\r\n(paddle22) PS E:\\Python Projects\\PaddleSegTest\\PaddleSeg\\contrib\\PP-HumanSeg>",
        "state": "closed",
        "user": "1a1aca",
        "closed_by": "1a1aca",
        "created_at": "2024-02-01T02:16:58+00:00",
        "updated_at": "2024-02-27T07:23:46+00:00",
        "closed_at": "2024-02-01T12:05:26+00:00",
        "comments_count": [],
        "labels": [
            "Bug",
            "PaddleSeg",
            "Paddle(Version)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1182,
        "title": "bash: paddle2onnx: command not found => How to fix it?",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nFirst, install paddle2onnx.\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/57930520/b073508c-9864-4ab0-8483-fd7cd81bc12a)\r\n\r\nAfter that, I try to use paddle2onnx, then command not found error occur.\r\n\r\nHow can I fix it?\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/57930520/95fe793d-1a8a-410e-bdb3-f96bafb63ae7)\r\n\r\n\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：Need to convert TensorRT.\r\n - Paddle2ONNX Version: 1.1.0\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "PeterKim1",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-01-30T04:06:14+00:00",
        "updated_at": "2024-05-24T11:20:14+00:00",
        "closed_at": "2024-05-24T11:20:14+00:00",
        "comments_count": [
            "GreatV",
            "jzhang533"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1183,
        "title": "unsupported operators, including deformable_conv",
        "body": "\r\nProblem Description:\r\nI have finetuned detection db_r50_td_tr model and have exported to inference model as well. now i want to convert it into onnx format. while converting im facing this issue\r\n\r\nMore Information:\r\n```\r\n(vp_env2) PS D:\\hawkingradiation\\paddleocr-repo> paddle2onnx --model_dir ./inference/det_db_r50_td_tr_inference_augment_complete/ --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/det_onnx/ppocr_v4_model.onnx --opset_version 10  --enable_onnx_checker True\r\n>> \r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference/det_db_r50_td_tr_inference_augment_complete/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./inference/det_db_r50_td_tr_inference_augment_complete/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including deformable_conv,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```\r\n\r\nInference engine used for deployment:\r\nWhy conversion to ONNX format is needed: conversion is needed so that to check if the inference time reduces on CPU, open to any suggestions here\r\n\r\nPaddle2ONNX version: 1.0.6\r\npaddleocr Version: 2.7.0.3\r\nonnx version: 1.13.1\r\nonnxruntime version: 1.9.0\r\n\r\nopen to any suggestions or how to solve this\r\nThankYou",
        "state": "closed",
        "user": "HawkingRadiation42",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-01-31T14:06:38+00:00",
        "updated_at": "2024-11-22T03:04:00+00:00",
        "closed_at": "2024-11-22T03:04:00+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1186,
        "title": "onnx转rknn报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n系统平台：linux x64 Ubuntu 18.04\r\nonnxruntime：1.10.0\r\n一开始用的rknn的工具是rknn_toolkit2-1.5.0+1fa95b5cl报错如下图1\r\n后来换了rknn_toolkit2-1.6.1b0+9379f5f7，报错如下图2\r\n\r\n\r\n\r\n**更多信息 :**\r\n我的联系方式是505582357@qq.com，期待您的来信，谢谢！\r\n\r\n**报错截图**\r\n![J%9S6%W}1~$L_LVQW Z6M8](https://github.com/PaddlePaddle/Paddle2ONNX/assets/143511511/f8a0994a-d2a3-40ee-956d-d41902d4312d)\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/143511511/c3b7c900-11ec-4486-bec1-df0a2d8ef681)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Nankee-Lee",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-02-02T06:51:50+00:00",
        "updated_at": "2024-11-19T08:19:24+00:00",
        "closed_at": "2024-11-19T08:19:24+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Nankee-Lee",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "RKNPU2"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1185,
        "title": "[Announcement] Paddle2ONNX PMC Officially Established",
        "body": "为了 Paddle2ONNX 项目的可持续健康发展和加强社区治理，我们宣布成立 Paddle2ONNX PMC(Project Management Committee) 来负责 Paddle2ONNX 项目的技术决策和维护。\r\n\r\n## 初始 PMC 成员\r\n- 郑必城 (@Zheng-Bicheng , PMC Chair)\r\n- 蒋佳军 (@jiangjiajun)\r\n- 张留杰 (@Aurelius84)\r\n- 汪昕 (@GreatV)\r\n\r\n## PMC 章程 \r\n### PMC 的人员构成：\r\n- PMC 由不少于 3 名在飞桨开源社区进行过开源贡献的开发者组成。\r\n- PMC 设置主席一名，主席负责维持 PMC 的正常运转。\r\n- PMC 成员仅以个人身份进行该项目的维护和开发，不代表各自雇主的利益。\r\n\r\n### PMC 的职责：\r\n- 确保 Paddle2ONNX 的 Issue 和 PR 得到及时处理。\r\n- 对用户对 Paddle2ONNX 提出的需求进行 review 并做出决策。\r\n- 协同社区的开发者开发 Paddle2ONNX 项目的新的功能。\r\n\r\n### PMC的沟通机制：\r\n- 定期举行对内会议，会议中需要研讨 Paddle2ONNX 的当前形势以及未来的项目发展。（建议每两周举行一次会议）\r\n- 会议议程和纪要需公开在开源社区中。（使用 [Community](https://github.com/PaddlePaddle/community) 代码仓库）\r\n- 每个季度形成 Paddle2ONNX 项目的状态报告，由[飞桨社区开源发展工作组](https://github.com/PaddlePaddle/community/tree/master/pposdwg)组织相关的专家，对报告进行 Review 并提供反馈。\r\n\r\n## 其他考虑\r\n- 飞桨项目间依赖： Paddle2ONNX 项目的主要目的是为飞桨的模型到 ONNX 模型的转换提供支持。 在 Paddle2ONNX 项目开发过程中遇到对其他飞桨项目的技术依赖时，PMC 可要求[飞桨社区开源发展工作组](https://github.com/PaddlePaddle/community/tree/master/pposdwg)内的来自百度的成员来协助解决问题。\r\n- 权限相关： 在涉及到代码仓库权限、CI 流水线权限 、及其他的权限问题时， PMC 可要求[飞桨社区开源发展工作组](https://github.com/PaddlePaddle/community/tree/master/pposdwg)内的来自百度的成员提供协助。\r\n- 社区运营： Paddle2ONNX在运作过程中可能需要一定的运营支持（包括直播、推文等）， PMC 可要求[飞桨社区开源发展工作组](https://github.com/PaddlePaddle/community/tree/master/pposdwg)内的来自百度的成员来协助解决问题。\r\n- 未尽事宜： Paddle2ONNX PMC 的实际运作中的未尽事宜，会尽可能参考[Apache软件基金会](https://www.apache.org/dev/pmc.html)的项目的现行最佳实践来解决。\r\n\r\n张军 (@jzhang533 ) on behalf of [PaddlePaddle Community](https://github.com/PaddlePaddle/community)\r\n\r\n---\r\n\r\nShort English version:\r\n\r\nTo foster the sustainable and healthy development of the Paddle2ONNX project, as well as to enhance community governance, we are pleased to announce the formation of the Paddle2ONNX PMC (Project Management Committee). This committee will take responsibility for technical decision-making and the ongoing maintenance of the Paddle2ONNX project.\r\n\r\nInitial PMC members: @Zheng-Bicheng (PMC chair), @jiangjiajun , @Aurelius84 , @GreatV .\r\n\r\n@jzhang533 on behalf of [PaddlePaddle Community](https://github.com/PaddlePaddle/community)\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "jzhang533",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-02-02T05:48:35+00:00",
        "updated_at": "2025-01-15T02:28:20+00:00",
        "closed_at": "2025-01-15T02:28:19+00:00",
        "comments_count": [
            "varunarora",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Announcement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1194,
        "title": "paddle2onnx转基于rocketqa-zh-base-query-encoder训练后的模型报错：operators not supported diag_v2,kldiv_loss,",
        "body": "paddle2onnx-1.1.0\r\n\r\n基于rocketqa-zh-base-query-encoder在自己的句子对上训练后动转静没有问题，但是在转onnx时报错。\r\npaddle2onnx --model_dir ./checkpoint/model_32000 --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file rocketqa32.onnx --enable_onnx_checker True --opset_version 16\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./checkpoint/model_32000/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./checkpoint/model_32000/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including diag_v2,kldiv_loss,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n\r\n请问diag_v2,kldiv_loss 这两个算子是还没有实现了，有什么解决办法吗？",
        "state": "closed",
        "user": "471417367",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-02-21T09:23:59+00:00",
        "updated_at": "2025-01-15T02:28:18+00:00",
        "closed_at": "2025-01-15T02:28:18+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "Operator(New)",
            "PaddleSeg",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1195,
        "title": "导出后的onnx模型依然存在动态维度的问题",
        "body": "操作的模型：\r\n[https://aistudio.baidu.com/modelsdetail/10/intro](url)\r\n按照以下代码进行导出：\r\n`paddle2onnx --model_dir picodet_v2_s_320_pedestrian/ --model_filename model.pdmodel --params_filename model.pdiparams --save_file picodet_v2_s_320_pedestrian.onnx --opset_version 12 --enable_onnx_checker True`\r\n`python -m paddle2onnx.optimize --input_model picodet_v2_s_320_pedestrian.onnx --output_model picodet_v2_s_320_pedestrian_static.onnx --input_shape_dict \"{'image':[1,3,320,320]}\"`\r\n此时从模型角度来看输入的确变成了静态图：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/75578545/fc30f5f0-daa2-4d06-9e60-07f66ed9f6e7)\r\n但是在转为rknn模型时：\r\n这一层报错，说这一层存在动态维度：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/75578545/f8140fb0-ceb2-45e7-b4b8-d16153034116)\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/75578545/c4e91e67-db1d-41c1-bdeb-0a26b639bfc0)\r\n针对错误文档的说法和报错信息，想问问可能的原因以及解决办法\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/75578545/5123b688-b82a-4140-8834-6aebeb8d8723)\r\n",
        "state": "closed",
        "user": "AntyRia",
        "closed_by": "AntyRia",
        "created_at": "2024-02-23T03:22:39+00:00",
        "updated_at": "2024-02-23T05:40:44+00:00",
        "closed_at": "2024-02-23T05:40:44+00:00",
        "comments_count": [
            "AntyRia",
            "Zheng-Bicheng",
            "AntyRia"
        ],
        "labels": [
            "Bug",
            "RKNPU2"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1187,
        "title": "[Bug][CI] Paddle2ONNX CI目前残存Bug汇总",
        "body": "Paddle2ONNX在PaddlePaddle框架大版本更新到2.6后，CI单测出现大量问题，已经处于失效的状态。通过两轮PR的修复，目前仍然存在以下Bug仍然未修复，:\r\n\r\n* test_auto_scan_floordiv.py: ONNX推理结果与PaddleInference不一致(已修复)\r\n* ./test_auto_scan_multiclass_nms.py: ONNX推理结果与PaddleInference不一致(已修复)\r\n* ./test_auto_scan_reducemean_ops.py: 转换模型时出现错误 （已修复）\r\n* ./test_auto_scan_unary_ops.py: 崩溃(已修复)\r\n* ./test_quantize_model.py: 数据问题 （暂时移除对量化模型的测试）\r\n* ./test_quantize_model_minist.py: 数据问题（暂时移除对量化模型的测试）\r\n* ./test_quantize_model_speedup.py: 数据问题（暂时移除对量化模型的测试）\r\n* ./test_relu6.py: 崩溃 （已修复）\r\n* ./test_swish.py: 崩溃 (已修复)",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-02-20T06:52:49+00:00",
        "updated_at": "2024-02-20T12:01:52+00:00",
        "closed_at": "2024-02-20T12:01:52+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "CI"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1203,
        "title": "there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用 paddle2.3.2、paddledetection2.7、python3.8 训练的 cascade_rcnn_r50_fpn_1x_coco 在导出onnx文件时报错\r\n执行命令：\r\n!python /opt/ppdet27/tools/export_model.py -c /opt/ppdet27/configs/cascade_rcnn/cascade_rcnn_r50_fpn_1x_coco.yml -o weights=/opt/output/model_final export_onnx=True --output_dir=/opt/signchk/inference_model\r\n【成功】\r\n执行命令：\r\n!paddle2onnx --model_dir /opt/signchk/inference_model/cascade_rcnn_r50_fpn_1x_coco --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 16 --save_file /opt/signchk/inference_model/cascade_rcnn_r50_fpn_1x_coco/signchk.onnx\r\n【报错信息】：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /opt/signchk/inference_model/cascade_rcnn_r50_fpn_1x_coco/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: /opt/signchk/inference_model/cascade_rcnn_r50_fpn_1x_coco/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: paddle\r\n - 为什么需要转换为ONNX格式：使用自动标准软件加载自训练模型时需要使用onnx格式支持\r\n - Paddle2ONNX版本: 1.1.0\r\n - 你的联系方式(Email/Wechat/Phone):  6092151@qq.com\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/27559520/a6eeca62-cbc6-4d09-be75-ce782ec18781)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Luxf01",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-03-07T01:54:54+00:00",
        "updated_at": "2025-01-13T02:37:04+00:00",
        "closed_at": "2025-01-13T02:37:04+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1205,
        "title": "ch_ppstructure_mobile_v2.0_SLANet表格识别模型转rknn模型报错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n模型：ch_ppstructure_mobile_v2.0_SLANet\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：硬件是rk3588\r\n - Paddle2ONNX Version:1.1.0\r\n - Email/Wechat/Phone:c-t-y@qq.com\r\n\r\n**Screenshots**\r\n![LR5)SJ_7@@C($WCAA6_ _5E](https://github.com/PaddlePaddle/Paddle2ONNX/assets/55014745/380162cf-c926-4277-b80a-371596b3c6a7)\r\n\r\n\r\n**Additional context**\r\nrknn_toolkit2-1.5.3b21+11d8562a-cp38-cp38-linux_x86_64.whl\r\nrknn_toolkit2-1.6.0+81f21f4d-cp38-cp38-linux_x86_64.whl\r\nrknn_toolkit2-1.6.1b16+e3c0774a-cp38-cp38-linux_x86_64.whl\r\nrknn_toolkit2-1.6.2b3+eeda9fd5-cp38-cp38-linux_x86_64.whl\r\n这几个toolkit都试过报一样的错误，转onnx没报错，再转rknn报错如截图",
        "state": "closed",
        "user": "cty-ai",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-03-15T03:02:21+00:00",
        "updated_at": "2024-10-16T09:18:09+00:00",
        "closed_at": "2024-10-16T09:18:09+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "RKNPU2"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1204,
        "title": "[Discussion] Standardized Process for Publishing a Release Branch",
        "body": "我们计划发布一个新的 Paddle2ONNX 的版本，但是距离[上次发布版本](https://github.com/PaddlePaddle/Paddle2ONNX/releases/tag/v1.0.7)已经有将近一年时间了。所以我们需要讨论为了能够实现这个目标，都需要做哪些事情：\r\n\r\n关于上次发版的时间：我们在pip上的最新版本是1.1.0，在v1.0.7 tag 之后有过三个版本：https://pypi.org/project/paddle2onnx/#history ； 但是 1.0.8, 1.0.9, 与 1.1.0 三个版本并没有对应的tag，所以我误以为我们上次的发版时间是在一年前。\r\n\r\n- 准备一份发版流程的文档。 (@Zeref996 @yinger78）\r\n- 明确发版需要完成哪些开发事项。（PMC members）\r\n\r\nto PMC members, 请协助帮忙更新这个issue，来实现发布Paddle2ONNX 新版本的目标。",
        "state": "closed",
        "user": "jzhang533",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-03-07T09:29:10+00:00",
        "updated_at": "2024-09-05T10:35:43+00:00",
        "closed_at": "2024-04-23T12:45:31+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zeref996",
            "Zeref996",
            "Zeref996",
            "Zeref996",
            "jzhang533",
            "Zheng-Bicheng",
            "jzhang533",
            "jzhang533",
            "Zheng-Bicheng",
            "jzhang533",
            "Zheng-Bicheng",
            "Zeref996",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zeref996",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1206,
        "title": "An error while attempting to convert a PaddlePaddle model to ONNX format",
        "body": "I encountered an error while attempting to convert a PaddlePaddle model to ONNX format using paddle2onnx. Below are the details of the error. I run the following command line \r\n>> paddle2onnx --model_dir ./models/v1/infer_weights --model_filename inference.pdmodel --params_filename inference.pdiparams --export_fp16_model True --save_file models/v1/model.onnx --opset_version 15 --enable_onnx_checker True >/dev/null\r\n\r\nand I got this error \r\n\r\n>>[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./models/v1/infer_weights/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./models/v1/infer_weights/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR] Cannot found attribute beta in op: swish\r\nAborted (core dumped)\r\n\r\nMy environment\r\nPython 3.8.10\r\npaddle2onnx==1.1.0\r\npaddleocr==2.7.0.3\r\npaddlepaddle==2.6.0\r\npaddlepaddle-gpu==2.6.0\r\nPlease let me know how to solve this.\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "PattaWapee",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-03-16T11:10:18+00:00",
        "updated_at": "2024-04-11T05:54:45+00:00",
        "closed_at": "2024-04-11T05:54:45+00:00",
        "comments_count": [
            "89080322",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1207,
        "title": "re_vi_layoutxlm_xfund_infer转换ONNX失败",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/55680083/c88af6b4-d507-42e1-8828-606931fb7cbf)\r\n\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: 1.0.6\r\n - Email/Wechat/Phone:18265652715@163.com\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "SANFUSHENG",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-03-19T03:32:31+00:00",
        "updated_at": "2025-01-13T02:37:03+00:00",
        "closed_at": "2025-01-13T02:37:02+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1208,
        "title": "Cannot found attribute threshold in op: relu6",
        "body": "\r\n\r\n**Describe the bug**\r\n将PLSC的人脸识别模型导出为ONNX格式，报错Cannot found attribute threshold in op: relu6\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: openvino\r\n - Why convert to onnx：use openvino for inference\r\n - Paddle2ONNX Version: 1.0.6 \r\n - PaddlePaddle version: 2.6.0, CUDA 11.8\r\n",
        "state": "closed",
        "user": "xaclincoln",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-03-19T09:00:05+00:00",
        "updated_at": "2024-10-22T10:17:34+00:00",
        "closed_at": "2024-04-08T01:22:56+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "Zheng-Bicheng",
            "wangkd0",
            "Zheng-Bicheng",
            "CvBokchoy",
            "Zheng-Bicheng",
            "CvBokchoy",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "CvBokchoy",
            "Zheng-Bicheng",
            "CvBokchoy"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1213,
        "title": "量化模型导出onnx，模型失效",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nPaddleOCR rec_ppocr_v3 模型进行PTQ量化，导出inference.pdiparams .pdmodel 进行测试是正确的\r\n推理命令\r\npython tools/infer/predict_rec.py --use_gpu=False --use_onnx=True --rec_model_dir=./inference/inference_rec_ppocr_v3_20240326_ptq/traffic_spot_rec_svtr_v1.0_20240326_ptq.onnx --image_dir=./02_spot.jpg  --rec_image_shape \"3, 48, 96\" --rec_char_dict_path ./ppocr/utils/ppocr_keys_v1_spot.txt \r\n结果\r\n[2024/03/27 18:24:20] ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320\r\n[2024/03/27 18:24:20] ppocr INFO: Predicts of ./02_spot.jpg:('5', 0.9968405961990356)\r\n\r\n但是使用这两个模型文件导出onnx + calibration cache 放在 TensorRT 上进行推理时，几乎所有结果都不对\r\n\r\npaddle2onnx --model_dir ./inference/inference_rec_ppocr_v3_20240326_ptq/ --model_filename inference.pdmodel --params_filename inference.pdiparams --deploy_backend tensorrt --save_file ./inference/inference_rec_ppocr_v3_20240326_ptq/ptq.onnx --save_calibration_file ./inference/inference_rec_ppocr_v3_20240326_ptq/ptq_calib.cache --opset_version 13  --enable_onnx_checker True\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "CtSTS",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-03-27T11:15:49+00:00",
        "updated_at": "2025-01-12T02:38:54+00:00",
        "closed_at": "2025-01-12T02:38:53+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1217,
        "title": "如何将paddle模型中的sub_block导出成onnx",
        "body": "想将paddle模型中conditional_block算子的“sub_block”属性里的子图导出成onnx，代码如下，其中第10行和11行之间应该将sub_block转为program类型的对象后再传递给run_convert，但我不知道如何去转换\r\n\r\n```\r\n\r\n1. import paddle\r\n2. import paddle2onnx\r\n3.  \r\n4. paddle.enable_static()\r\n5. \r\n6. program = paddle.load(\"inference.pdmodel\")\r\n7. for block in porgram.blocks:\r\n8.     if op.type == \"conditional_block\":\r\n9.         sub_bock_id = op.attr(\"sub_block\").id\r\n10.        sub_block = block.program.block(sub_block_id)\r\n11.        onnx_model = paddle2onnx.run_convert(sub_block)\r\n\r\n```\r\n\r\n",
        "state": "closed",
        "user": "woodenwatcher",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-02T10:16:41+00:00",
        "updated_at": "2024-07-15T03:58:49+00:00",
        "closed_at": "2024-07-15T03:58:49+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1218,
        "title": "PaddleSeg-release-2.8.1  的量化模型转onnx  onnx转rknn  没有成功的问题",
        "body": "\r\n问题1：\r\n\r\n我使用PaddleSeg-release-2.8.1 的方式进行训练自己的数据集，然进行感知量化训练  在PaddleSeg-release-2.8.1/deploy/slim/quant文件下进行了训练  动态转静态  。然后使用 paddle2onnx的静态文件转onnx文件  没有生成 onnx为文件\r\n\r\n(PaddleSeg) D:\\PY\\PaddleSeg-release-2.8.1>paddle2onnx --model_dir D:/PY/PaddleSeg-release-2.8.1/output_quant/model10000_b24_512/output_quantexport_infer ^\r\nMore?             --model_filename model.pdmodel ^\r\nMore?             --params_filename model.pdiparams ^\r\nMore?             --save_file D:/PY/PaddleSeg-release-2.8.1/output_quant/model10000_b24_512/onnxmodel/quant_modelexport.onnx ^\r\nMore?             --deploy_backend  onnxruntime ^\r\nMore?             --opset_version 13 ^\r\nMore?             --enable_dev_version True ^\r\nMore?             --enable_auto_update_opset  True ^\r\nMore?             --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: D:/PY/PaddleSeg-release-2.8.1/output_quant/model10000_b24_512/output_quantexport_infer\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: D:/PY/PaddleSeg-release-2.8.1/output_quant/model10000_b24_512/output_quantexport_infer\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [Info] The Paddle model is a quantized model.\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] Find dumplicate output name 'save_infer_model/scale_0.tmp_0', it will rename to 'p2o.save_infer_model/scale_0.tmp_0.0'.\r\n[Paddle2ONNX] [Info] Quantize model deploy backend is: onnxruntime\r\n转换的代码在这 ，没有生成 onnx文件   \r\n\r\n但是我把--deploy_backend  onnxruntime 这个选型改成tensorrt和others 可以生成 ，但是这放在rk3588板子上是有问题的。\r\n\r\n问题2：\r\n最后想放在嵌入式的rk3588上面 使用 ，但是转换的时候模型转换有问题 。 错误如下\r\n\r\n(toolkit2) g@DESKTOP-0RMSG8C:/mnt/e/rknn/rknn_model_zoo-main/examples/ppseg/python$ python convert.py  ../model/quant_modelexport.onnx  rk3588 fp ../model/quant_modelexport.rknn\r\nW __init__: rknn-toolkit2 version: 1.6.0+81f21f4d\r\n--> Config model\r\ndone\r\n--> Loading model\r\nW load_onnx: It is recommended onnx opset 19, but your onnx model opset is 13!\r\nLoading : 100%|████████████████████████████████████████████████| 413/413 [00:00<00:00, 63524.43it/s]\r\ndone\r\n--> Building model\r\nW build: The dataset='../model/dataset.txt' is ignored because do_quantization = False!\r\nE build: Catch exception when building RKNN model!\r\nE build: Traceback (most recent call last):\r\nE build:   File \"rknn/api/rknn_base.py\", line 1971, in rknn.api.rknn_base.RKNNBase.build\r\nE build:   File \"rknn/api/graph_optimizer.py\", line 824, in rknn.api.graph_optimizer.GraphOptimizer.fold_constant\r\nE build:   File \"rknn/api/session.py\", line 34, in rknn.api.session.Session.__init__\r\nE build:   File \"rknn/api/session.py\", line 130, in rknn.api.session.Session.sess_build\r\nE build:   File \"/home/g/miniconda3/envs/toolkit2/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 419, in __init__\r\nE build:     self._create_inference_session(providers, provider_options, disabled_optimizers)\r\nE build:   File \"/home/g/miniconda3/envs/toolkit2/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 462, in _create_inference_session\r\nE build:     sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)\r\nE build: onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (p2o.Resize.0) Op (Resize) [ShapeInferenceError] Either `sizes` or `scales` must be provided, but not both of them\r\nW If you can't handle this error, please try updating to the latest version of the toolkit2 and runtime from:\r\n  https://console.zbox.filez.com/l/I00fc3 (Pwd: rknn)  Path: RKNPU2_SDK / 1.X.X / develop /\r\n  If the error still exists in the latest version, please collect the corresponding error logs and the model,\r\n  convert script, and input data that can reproduce the problem, and then submit an issue on:\r\n  https://redmine.rock-chips.com (Please consult our sales or FAE for the redmine account)\r\nBuild model failed!\r\n\r\n\r\n[ONNXRuntimeError] : 1 : FAIL : Node (p2o.Resize.0) Op (Resize) [ShapeInferenceError] Either `sizes` or `scales` must be provided, but not both of them 这个错是我什么地方的问题 ，是我paddleseg配置文件的问题吗 还是啥？",
        "state": "closed",
        "user": "1314520gu",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-07T06:27:06+00:00",
        "updated_at": "2025-01-11T02:31:25+00:00",
        "closed_at": "2025-01-11T02:31:24+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "1314520gu",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1220,
        "title": "[Discussion] 迁移Paddle2ONNX构建方式到Python 新规范(pyproject.toml)",
        "body": "简介\r\n由Paddle2ONNX PMC讨论，Paddle2ONNX将要将项目构建方式从目前的使用 setup.py + requirement.txt的方式转向使用 setup.py + pyproject.toml的方式。\r\n\r\n实施过程\r\n由于Paddle2ONNX使用了pybind实现c++代码在python上的调用，因此计划使用pybind给出的例程作为Demo来实现这个过程，PMC的各位成员如果有建议可以畅所欲言。",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-09T01:33:02+00:00",
        "updated_at": "2024-04-10T01:02:07+00:00",
        "closed_at": "2024-04-10T01:02:07+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "GreatV",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Jiang-Jia-Jun",
            "jzhang533",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1224,
        "title": "] Oops, there are some operators not supported yet, including prior_box,",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference_model/blazeface_fpn_ssh_1000e\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference_model/blazeface_fpn_ssh_1000e\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including prior_box,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n**更多信息 :**\r\n\r\n - Paddle2ONNX版本:1.0.6\r\n - 你的联系方式(Email/Wechat/Phone):2460128243@qq.com\r\n\r\n\r\n",
        "state": "closed",
        "user": "yuanzhibin",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-10T09:46:37+00:00",
        "updated_at": "2025-01-10T02:35:02+00:00",
        "closed_at": "2025-01-10T02:35:01+00:00",
        "comments_count": [
            "tianjiahao",
            "tianjiahao",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1225,
        "title": "紧急，PaddleSeg中的OCRNet模型导出为onnx，推理失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n[E:onnxruntime:Default, cuda_call.cc:118 CudaCall] CUDNN failure 3: CUDNN_STATUS_BAD_PARAM ; GPU=0 ; hostname=autodl-container-f4d5458449-011211ac ; expr=cudnnAddTensor(Base::CudnnHandle(), &alpha, Base::s_.z_tensor, Base::s_.z_data, &alpha, Base::s_.y_tensor, Base::s_.y_data); \r\n2024-04-11 00:36:36.778269454 [E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running FusedConv node. Name:'p2o.Conv.34_p2o.Add.26_p2o.Relu.33' Status Message: CUDNN error executing cudnnAddTensor(Base::CudnnHandle(), &alpha, Base::s_.z_tensor, Base::s_.z_data, &alpha, Base::s_.y_tensor, Base::s_.y_data)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 32, in <module>\r\n    ort_outs = ort_session.run(None, ort_inputs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 192, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running FusedConv node. Name:'p2o.Conv.34_p2o.Add.26_p2o.Relu.33' Status Message: CUDNN error executing cudnnAddTensor(Base::CudnnHandle(), &alpha, Base::s_.z_tensor, Base::s_.z_data, &alpha, Base::s_.y_tensor, Base::s_.y_data)\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:onnxruntime\r\n - 为什么需要转换为ONNX格式：需要应用到pytorch环境中\r\n - Paddle2ONNX版本:1.10.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/138844388/d4527be1-6157-42b1-828d-d7e47a683815)\r\n\r\n\r\n**其他信息**\r\n使用paddle模型进行GPU推理可以成功\r\n转为onnx后调用CUDA推理失败\r\n已经通过语句python tools/export.py --config  my.yml --model_path ../autodl-tmp/output/best_model/model.pdparams --input_shape 1 3 480 640固定paddle模型的输入形状\r\n",
        "state": "closed",
        "user": "diyaxxxx",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-10T16:45:29+00:00",
        "updated_at": "2024-04-12T00:51:24+00:00",
        "closed_at": "2024-04-12T00:51:24+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "diyaxxxx",
            "Zheng-Bicheng",
            "diyaxxxx",
            "Zheng-Bicheng",
            "diyaxxxx",
            "diyaxxxx"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1229,
        "title": "paddle模型本来是不固定输入输出的，但是使用Paddle2ONNX转换必须指定input_size,不然会报Due to the operator: pool2d, this model cannot be exported to ONNX错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\npaddle模型本来是不固定输入输出的，但是使用Paddle2ONNX转换必须指定input_size,不然会报Due to the operator: pool2d, this model cannot be exported to ONNX错误\r\n\r\npython tools/export.py --config configs/quick_start/ppmattingv2-stdc1-human_512.yml --model_path pretrained_models/ppmattingv2-stdc1-human_512.pdparams --save_dir output/inference_model_end\r\n使用上面这个命令不指定input_size, 导出时就会报错，我不想指定size需要怎么处理\r\n\r\n模型使用的ppmattingv2-stdc1-human_512.yml\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - 使用onnxruntime运行\r\n - \r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "wangkd0",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-19T08:00:19+00:00",
        "updated_at": "2024-07-16T11:09:51+00:00",
        "closed_at": "2024-07-16T11:09:42+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "zhanglaplace",
            "Zheng-Bicheng",
            "zhanglaplace",
            "surprise335",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(Update)",
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1231,
        "title": "Matting模型转换为ONNX时报错 [pool2d: pool2d_10.tmp_0] While Attribute(ksize)'s type is Tensor, it's not supported. ",
        "body": "版本：paddle2onnx -1.2.1\r\n模型：paddleseg中Matting中的ppmattingv2模型\r\n具体报错信息如下图：\r\n![Dingtalk_20240422113727](https://github.com/PaddlePaddle/Paddle2ONNX/assets/73456895/fd73e32f-da3f-4103-8584-f54fe077947a)\r\n\r\n流程：对训练模型首先使用export.py转为预测模型，然后使用infer_paddle_model_shape.py对预测模型进行固定输入，如上图，固定为:[-1,3,1374,918]，最后对固定输入后的模型进行paddle2onnx，最后一步的文件夹文件列表如下\r\n![Dingtalk_20240422114025](https://github.com/PaddlePaddle/Paddle2ONNX/assets/73456895/78646742-2740-421e-be15-e6a8c70ed488)\r\n\r\n奇怪的是固定输入后模型在netron查看时显示没有输出（固定前查看输入输出均为动态），如下图\r\n![Dingtalk_20240422132225](https://github.com/PaddlePaddle/Paddle2ONNX/assets/73456895/e4962af7-1e3d-4b45-a5b2-afda30a7e107)\r\n\r\n请问是Matting的模型仍未支持转换为ONNX，还是以上操作流程存在问题\r\n",
        "state": "closed",
        "user": "gunh4mmer",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-22T05:23:34+00:00",
        "updated_at": "2024-04-24T03:17:39+00:00",
        "closed_at": "2024-04-24T03:17:39+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "gunh4mmer"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1230,
        "title": "paddle2onnx 在尝试将 PaddlePaddle 模型转换为 ONNX 格式时遇到了不支持的算子（operators）：distribute_fpn_proposals 和 generate_proposals_v2。由于这些算子在 ONNX 规范中没有直接的等价实现或者paddle2onnx转换工具中尚未实现对这些算子的支持，转换过程被中止了",
        "body": "paddle2onnx 在尝试将 PaddlePaddle 模型转换为 ONNX 格式时遇到了不支持的算子（operators）：distribute_fpn_proposals 和 generate_proposals_v2。由于这些算子在 ONNX 规范中没有直接的等价实现或者paddle2onnx转换工具中尚未实现对这些算子的支持，转换过程被中止了\r\n\r\n(Detection) E:\\PaddleDetection>paddle2onnx --model_dir=output/output1/inference_model/jjs_rcnn --model_filename=model.pdmodel  --params_filename=model.pdiparams --opset_version=16  --save_file=jjs_rcnn.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: output/output1/inference_model/jjs_rcnn\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: output/output1/inference_model/jjs_rcnn\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including distribute_fpn_proposals,generate_proposals_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n-用于部署的推理引擎：PaddlePaddle\r\n-为什么转换为onnx：\r\n-Paddle2ONNX版本：1.0.6\r\n\r\n![屏幕截图 2024-04-19 190949](https://github.com/PaddlePaddle/Paddle2ONNX/assets/166143077/de00f08d-358c-4dc2-a0ae-0726b76d3362)\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "jinjin4318",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-19T11:11:34+00:00",
        "updated_at": "2024-12-28T02:28:07+00:00",
        "closed_at": "2024-12-28T02:28:06+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1233,
        "title": "【开源之夏】飞桨PaddlePaddle-PIR适配Paddle2ONNX推理转换",
        "body": "# 项目描述\r\nONNX是一种开放的深度学习模型交换格式，可让模型在不同平台和框架间无缝转换与部署，Paddle2ONNX开源仓库支持将飞桨的推理模型表示转换到ONNX算子协议以实现对接ONNX生态。飞桨在3.0Beta发布了新一代的中间表示（即Paddle IR），并升级了所有的算子定义形式，取代了2.x版本基于protobuf的中间表示。因此我们期望能够基于飞桨新一代Paddle IR的算子定义，升级Paddle2ONNX中的转换规则，支持Paddle IR 协议下的ONNX模型转换。\r\n\r\n飞桨PaddlePaddle：以百度多年的深度学习技术研究和业务应用为基础，是中国首个自主研发、功能完备、开源开放的产业级深度学习平台，集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体。\r\n\r\n如果有任何疑问，可发邮件给导师同时抄送 ext_paddle_oss@baidu.com 。\r\n\r\n# 项目产出要求\r\n1. 研读Paddle2ONNX源码，给出Paddle新一代IR下算子到ONNX转换的技术思路 \r\n2. 完成20个典型算子，和2个控制流算子（if和while）的2ONNX转换支持 \r\n3. 代码合入 https://github.com/PaddlePaddle/paddle2ONNX\r\n\r\n# 项目技术要求\r\n熟悉 C++ 2. 熟悉 Python\r\n\r\n# 项目成果仓库\r\nhttps://github.com/PaddlePaddle/paddle2ONNX\r\n\r\n# 参考文档\r\n- [Paddle2ONNX 开发指南](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/Paddle2ONNX_Development_Guide.md)\r\n- [PIR设计指南](https://github.com/PaddlePaddle/community/blob/master/pfcc/paddle-code-reading/IR_Dialect/README.md)\r\n- PIR下save后的program的文件可以执行Paddle仓库中的test/ir/pir/test_ir_save_load.py单测后查看test_save_program2.json文件",
        "state": "closed",
        "user": "0x45f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-23T02:44:16+00:00",
        "updated_at": "2024-12-28T02:28:06+00:00",
        "closed_at": "2024-12-28T02:28:05+00:00",
        "comments_count": [
            "qzylalala",
            "luotao1",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Announcement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1234,
        "title": "[Discussion] 请求提供 Paddle2ONNX 开发者培训计划",
        "body": "**问题描述**\r\n最近我对 Paddle2ONNX 项目产生了浓厚的兴趣，并希望能够贡献我的力量。然而，我发现我对于如何添加新的操作（OP）以及整个开发流程并不了解。\r\n\r\n鉴于此，我想提出一个请求，希望社区能够组织一次线上培训活动，涵盖从 OP 添加流程到整个开发流程的内容。这样的培训计划将帮助像我这样的新手开发者更好地融入 Paddle2ONNX 的开发团队，并且促进项目的成长和发展。\r\n\r\n培训内容建议：\r\n\r\nOP 添加流程： 详细介绍如何在 Paddle2ONNX 中添加新的操作，包括必要的步骤、文件结构以及相关的文档要求。\r\n开发环境设置： 提供设置开发环境所需的必要工具和依赖项，以及如何构建和测试代码的说明。\r\n代码贡献流程： 解释代码贡献的基本流程，包括如何提交 Pull Request、代码审查流程等。\r\n\r\n我相信通过这样的培训计划，不仅能够吸引更多的开发者加入 Paddle2ONNX 的开发团队，也将为项目的发展注入新的活力和动力。感谢您的关注和支持！\r\n",
        "state": "closed",
        "user": "marlin433",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-23T12:54:56+00:00",
        "updated_at": "2024-04-25T08:25:07+00:00",
        "closed_at": "2024-04-25T08:25:07+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "marlin433",
            "marlin433",
            "Zheng-Bicheng",
            "marlin433",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)",
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1236,
        "title": "转换paddlespeech的KWS部署模型出现了问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n你好，我在转换paddlespeech的KWS模型出现了问题。我已经事先转换了.pdparsms文件为.pdparsms和.pdmodel文件\r\n报错信息如下：\r\nOops, there are some operators not supported yet, including conditional_block,lod_array_length,while,write_to_array,\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 语音唤醒模型KWS\r\n - Paddle2ONNX版本:#  paddle2onnx 版本：1.2.0 \r\n - 你的联系方式(Email/Wechat/Phone): wanglingyu1114@gmail.com\r\n\r\n**报错截图**\r\n![325143670-a2b266b3-08d2-41eb-a2a6-650778f31a3f](https://github.com/PaddlePaddle/Paddle2ONNX/assets/145318741/13f4bec5-5a5d-4f55-8404-401c33cdc86d)\r\n\r\n\r\n**其他信息**\r\n\r\n",
        "state": "closed",
        "user": "lingyuwangwang",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-24T08:38:32+00:00",
        "updated_at": "2024-12-27T02:31:28+00:00",
        "closed_at": "2024-12-27T02:31:28+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "eli-zheng-ubtech",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1237,
        "title": "无法通过pip install paddle2onnx安装，同时也无法通过编译安装",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n使用官方提供的所有方式均无法安装paddle2onnx\r\n\r\n**Environment**\r\nWin11 23H2\r\npython 3.11.7 & 3.12.3\r\n\r\n**Screenshots**\r\n![34f84f7c5481501d13e313e10d1499d](https://github.com/PaddlePaddle/Paddle2ONNX/assets/55677914/71bea2ed-7a38-4b73-b88c-cf39491e8f20)\r\n![55cf5c6683a46f5d9e516518b656aff](https://github.com/PaddlePaddle/Paddle2ONNX/assets/55677914/ca40a056-2b07-4aeb-aee3-eab0f2299a55)\r\n第一张是通过pip安装，第二张是通过编译安装\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "XianlinYao",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-24T08:59:15+00:00",
        "updated_at": "2024-05-24T10:18:26+00:00",
        "closed_at": "2024-05-24T10:18:26+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "XianlinYao",
            "Zheng-Bicheng",
            "XianlinYao",
            "gutenye",
            "XianlinYao"
        ],
        "labels": [
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1240,
        "title": "[Bug] 关于本地编译安装和执行单测的问题记录",
        "body": "1. 本地如何编译安装Paddle2ONNX\r\n整体上按照docs/zh/compile_local.md文档中的介绍进行安装即可，但是需要在编译安装前执行`pip install setuptools wheel auditwheel auditwheel-symbols build`，否则执行文档中最后的`python -m build`会报错。\r\n编译完成之后需要手动安装dist目录下的paddle2onnx whl包\r\n2. 如何执行tests目录下的单测\r\n执行单测前需要安装以下python库，安装后执行pytest test_abs.py即可\r\n    - onnx onnxruntime tqdm filelock\r\n    - six hypothesis\r\n    - pytest\r\n    - paddlepaddle>=2.6.0\r\n\r\n另外：是否考虑添加一个requirements.txt文件，这样可以比较方便的将所需的python库一次性安装上~",
        "state": "closed",
        "user": "0x45f",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-26T08:43:30+00:00",
        "updated_at": "2024-05-23T12:00:22+00:00",
        "closed_at": "2024-05-23T12:00:22+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "jzhang533",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1238,
        "title": "paddleseg模型和onnx模型的推理结果不一致，精度差距较大",
        "body": "使用paddleseg的seaformer模型，发现paddleseg模型和使用paddle2onnx转换出来的onnx模型的推理结果不一致，精度差距较大。\r\n\r\n具体问题描述和复现工程：https://github.com/PaddlePaddle/PaddleSeg/issues/3682\r\n\r\npaddleseg回复说这说明paddle2onnx或者onnxruntime存在精度误差，麻烦排查一下是什么问题。",
        "state": "closed",
        "user": "LS1030",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-25T02:47:15+00:00",
        "updated_at": "2024-12-27T02:31:27+00:00",
        "closed_at": "2024-12-27T02:31:27+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1241,
        "title": "can't run paddleocr converted model on onnxruntime",
        "body": "**Please fill in the following information completely so that we can solve the problem quickly, thank you! **\r\n\r\n**Problem Description**\r\npaddleOCR converted to onnx model with dynamic input is being run in onnx . first the image needs preprocessing \r\n```\r\ndef preprocess_image(image_path , it = (0, 3, 1, 2) ):\r\n    with open(image_path, 'rb') as file:\r\n        image_data = file.read()\r\n    image_bytes = np.frombuffer(image_data, dtype=np.uint8)\r\n    image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR) \r\n    # I would expect your image to be HWC at this point: [H, W, 3]\r\n    image_array = image.astype(np.float32) / 255.0\r\n    image_array = np.expand_dims(image_array, axis=0) # [1, H, W ,C]\r\n    # notice that i reordered the dimensions on transpose ! \r\n    # N = 1 and C = 3 is moved to the first axis \r\n    image_array = np.transpose(image_array, it) \r\n    image_array\r\n    return image_array\r\n```\r\n```\r\nInput names: ['x']\r\nOutput names: ['softmax_2.tmp_0']\r\nInput shape :['p2o.DynamicDimension.0',\r\n 3,\r\n 'p2o.DynamicDimension.1',\r\n 'p2o.DynamicDimension.2']\r\n```\r\nWhen running the model in the runtime ;\r\n```\r\n{\r\n\t\"name\": \"Fail\",\r\n\t\"message\": \"[ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Concat node. Name:'p2o.Concat.2' Status Message: concat.cc:157 onnxruntime::ConcatBase::PrepareForCompute Non concat axis dimensions must match: Axis 2 has mismatched dimensions of 1 and 31\",\r\n\t\"stack\": \"---------------------------------------------------------------------------\r\nFail                                      Traceback (most recent call last)\r\nCell In[12], line 3\r\n      1 print(x)\r\n      2 image_array = preprocess_image(r\\\"images\\\\2.jpg\\\")\r\n----> 3 outputs = session.run(None, {session.get_inputs()[0].name: image_array})\r\n      4 print(\\\"success\\\")\r\n\r\nFile c:\\\\Users\\\\hamza.kharbouch\\\\Desktop\\\\pp\\\\.conda\\\\lib\\\\site-packages\\\\onnxruntime\\\\capi\\\\onnxruntime_inference_collection.py:220, in Session.run(self, output_names, input_feed, run_options)\r\n    218     output_names = [output.name for output in self._outputs_meta]\r\n    219 try:\r\n--> 220     return self._sess.run(output_names, input_feed, run_options)\r\n    221 except C.EPFail as err:\r\n    222     if self._enable_fallback:\r\n\r\nFail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Concat node. Name:'p2o.Concat.2' Status Message: concat.cc:157 onnxruntime::ConcatBase::PrepareForCompute Non concat axis dimensions must match: Axis 2 has mismatched dimensions of 1 and 31\"\r\n}\r\n```\r\n**More information :**\r\n  - Inference engine for deployment: None\r\n  - Why you need to convert to ONNX format: CPU memory leaks in normal runtime for paddleOCR and fastDeploy\r\n  https://github.com/PaddlePaddle/PaddleOCR/issues/11639\r\n  - Paddle2ONNX version: 1.2.1\r\n\r\n**Error report screenshot**\r\n\r\n**other information**\r\n",
        "state": "closed",
        "user": "pxike",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-04-26T16:00:29+00:00",
        "updated_at": "2024-12-26T02:30:42+00:00",
        "closed_at": "2024-12-26T02:30:41+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "pxike",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1242,
        "title": "unsupported operator: unfold",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n```\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including unfold,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n```\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx:  for infer\r\n - Paddle2ONNX Version: 1.2.1\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n<img width=\"1349\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/17264618/525d7bbb-caff-40c9-928b-39aa3a1a3614\">\r\n\r\n\r\n**Additional context**\r\n\r\nrepo: https://github.com/GreatV/DocTrPP\r\nconvert script: `python export.py --model best.ckpt --format onnx`",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-04-28T14:54:29+00:00",
        "updated_at": "2024-07-15T05:59:53+00:00",
        "closed_at": "2024-07-15T05:59:53+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "GreatV",
            "GreatV",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1243,
        "title": "[Build] abseil demands C++14 or better",
        "body": "**Describe the bug**\r\nI'm trying to build Paddle2ONNX master with `python setup.py build`. It seems to demand C++ 11, therefore Abseil fails:\r\n```\r\n/usr/include/absl/base/policy_checks.h:79:2: error: #error \"C++ versions less than C++14 are not supported.\"\r\n   79 | #error \"C++ versions less than C++14 are not supported.\"\r\n      |  ^~~~~\r\nIn file included from /usr/include/absl/base/config.h:92,\r\n                 from /usr/include/absl/base/attributes.h:37,\r\n                 from /usr/include/google/protobuf/port_def.inc:33,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx-data_paddle2onnx.pb.h:13,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx-data_paddle2onnx.pb.cc:4:\r\n/usr/include/absl/base/policy_checks.h:79:2: error: #error \"C++ versions less than C++14 are not supported.\"\r\n   79 | #error \"C++ versions less than C++14 are not supported.\"\r\n      |  ^~~~~\r\nIn file included from /usr/include/absl/base/config.h:92,\r\n                 from /usr/include/absl/base/attributes.h:37,\r\n                 from /usr/include/google/protobuf/port_def.inc:33,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx-operators_paddle2onnx-ml.pb.h:13,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx-operators_paddle2onnx-ml.pb.cc:4:\r\n/usr/include/absl/base/policy_checks.h:79:2: error: #error \"C++ versions less than C++14 are not supported.\"\r\n   79 | #error \"C++ versions less than C++14 are not supported.\"\r\n      |  ^~~~~\r\nIn file included from /usr/include/absl/base/config.h:92,\r\n                 from /usr/include/absl/base/attributes.h:37,\r\n                 from /usr/include/google/protobuf/port_def.inc:33,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx_paddle2onnx-ml.pb.h:13,\r\n                 from ./Paddle2ONNX/.setuptools-cmake-build/third_party/onnx/onnx/onnx_paddle2onnx-ml.pb.cc:4:\r\n/usr/include/absl/base/policy_checks.h:79:2: error: #error \"C++ versions less than C++14 are not supported.\"\r\n   79 | #error \"C++ versions less than C++14 are not supported.\"\r\n      |  ^~~~~\r\n/usr/include/google/protobuf/port_def.inc:159:15: error: static assertion failed: Protobuf only supports C++14 and newer.\r\n  159 | static_assert(PROTOBUF_CPLUSPLUS_MIN(201402L), \"Protobuf only supports C++14 and newer.\");\r\n      |               ^~~~~~~~~~~~~~~~~~~~~~\r\n/usr/include/google/protobuf/port_def.inc:159:15: note: the comparison reduces to '(201103 >= 201402)'\r\n/usr/include/google/protobuf/port_def.inc:159:15: error: static assertion failed: Protobuf only supports C++14 and newer.\r\n  159 | static_assert(PROTOBUF_CPLUSPLUS_MIN(201402L), \"Protobuf only supports C++14 and newer.\");\r\n      |               ^~~~~~~~~~~~~~~~~~~~~~\r\n/usr/include/google/protobuf/port_def.inc:159:15: note: the comparison reduces to '(201103 >= 201402)'\r\n/usr/include/google/protobuf/port_def.inc:159:15: error: static assertion failed: Protobuf only supports C++14 and newer.\r\n  159 | static_assert(PROTOBUF_CPLUSPLUS_MIN(201402L), \"Protobuf only supports C++14 and newer.\");\r\n      |               ^~~~~~~~~~~~~~~~~~~~~~\r\n/usr/include/google/protobuf/port_def.inc:159:15: note: the comparison reduces to '(201103 >= 201402)'\r\n/usr/include/google/protobuf/port_def.inc:159:15: error: static assertion failed: Protobuf only supports C++14 and newer.\r\n  159 | static_assert(PROTOBUF_CPLUSPLUS_MIN(201402L), \"Protobuf only supports C++14 and newer.\");\r\n      |               ^~~~~~~~~~~~~~~~~~~~~~\r\n/usr/include/google/protobuf/port_def.inc:159:15: note: the comparison reduces to '(201103 >= 201402)'\r\n\r\n```\r\n\r\n**Informations (please complete the following information):**\r\n - Python 3.10\r\n - pybind11 2.12.0\r\n - python-absl 2.1.0\r\n - protobuf 25.3\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "waarmond",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-05T18:34:29+00:00",
        "updated_at": "2024-05-24T10:56:37+00:00",
        "closed_at": "2024-05-24T10:56:37+00:00",
        "comments_count": [
            "bruvduroiu",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Doc",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1246,
        "title": "unsupported ops: conditional_block,select_input,tril_triu",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nPaddleOCR 表格识别算法 无法导出onnx\r\n\r\nhttps://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_ch/algorithm_overview.md#3-%E8%A1%A8%E6%A0%BC%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: onnx\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: \r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n```shell\r\npaddle2onnx --model_dir inference/table_structure_tablemaster_infer --params_filename inference.pdiparams --model_filename inference.pdmodel  --save_file inference/table_structure_tablemaster_infer/best.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: inference/table_structure_tablemaster_infer/inference.pdmodel\r\n[Paddle2ONNX] Paramters file path: inference/table_structure_tablemaster_infer/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including conditional_block,select_input,tril_triu,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\nAborted (core dumped)\r\n```\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2024-05-08T14:09:58+00:00",
        "updated_at": "2024-05-17T07:49:52+00:00",
        "closed_at": "2024-05-17T07:49:52+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1244,
        "title": "将apollo-model-centerpoint训练的模型转onnx时，报算子不支持的问题",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n将apollo-model-centerpoint训练的模型转onnx时，报算子不支持的问题， 如果解决这个问题。\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/43978497/331af493-4111-4c53-bdde-0e0ebf3d0f0e)\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: tensorrt\r\n - 为什么需要转换为ONNX格式：因为支持更友好些\r\n - Paddle2ONNX版本:1.2.1\r\n - 你的联系方式(Email/Wechat/Phone):1319361380@qq.com\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "TheGreatGalaxy",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-05-07T03:52:35+00:00",
        "updated_at": "2024-12-26T02:30:41+00:00",
        "closed_at": "2024-12-26T02:30:40+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1245,
        "title": "custom_ops映射使用问题",
        "body": "我在使用命令行进行put_along_axis映射，使用了custom_ops，但是onnx的输入和输出发现对不上\r\n这个是我使用的命令行：paddle2onnx --model_dir . --model_filename paddle_put_along_axis.pdmodel --opset_version 16 --save_file put_along_axis.onnx --custom_ops '{\"put_along_axis\":\"ScatterElements\"}'\r\n\r\n下面的图片可以看到输入的名称和变量都对不上，可能是我使用的不对，能否提供一个正确的使用教程\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/32587916/f434cae3-9250-4ad7-8570-a186b9f3719a)\r\n",
        "state": "closed",
        "user": "FrankyTang",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-05-07T11:54:07+00:00",
        "updated_at": "2024-12-30T02:34:01+00:00",
        "closed_at": "2024-12-30T02:34:01+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "FrankyTang",
            "Zheng-Bicheng",
            "FrankyTang",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1247,
        "title": "量化paddle模型后通过Paddle2Onnx导出onnx存在的问题",
        "body": "现在使用paddledetection中的slim配置文件，进行了QAT量化训练，已经设置了onnx_format=True\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/38659788/a3a69dac-7607-4aec-81e5-1e2c27a46caa)\r\n\r\n量化训练后，得到结果\r\n进行导出\r\n，通过文档正常导出\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/38659788/d6959ba6-c4ec-4afa-b4c8-9e4fc52c4245)\r\n得到paddle infer模型\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/38659788/1a00e657-56d7-4c4a-a968-0575c3c586c8)\r\n\r\n接下来通过paddle2onnx,将该结果导出量化后的 onnx\r\n用这个命令可以导出\r\ncmd = ['paddle2onnx', '--model_dir', str(output_dir), '--model_filename', 'model.pdmodel',\r\n           '--params_filename', 'model.pdiparams', '--save_file', model_onnx,\r\n           '--opset_version', '13', '--deploy_backend', 'tensorrt','--enable_onnx_checker', 'True',\r\n           '--enable_dev_version', 'True']\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/38659788/95737b30-11a3-4a78-9503-bfa13c98d194)\r\n但是没有量化配置文件（calibration_table.txt），calibration.cache \r\n,根本没有这个文件。\r\n\r\n环境如下\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/38659788/9f791e93-d995-40b0-be67-ed6977602f8a)\r\n\r\n\r\n如果使用 --save_calibration_file 指定保存路径。会直接报错，显示没有该参数，paddle提供的量化模型文档的步骤，根本无法正常的让我导出量化的模型，请告知如何正常导出，并使用\r\n",
        "state": "closed",
        "user": "God-song",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-11T03:04:56+00:00",
        "updated_at": "2024-05-28T01:16:57+00:00",
        "closed_at": "2024-05-28T01:16:57+00:00",
        "comments_count": [
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "God-song",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "God-song",
            "God-song",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "God-song",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "God-song",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "PaddleDetection"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1248,
        "title": "能否指定 IR representation的版本",
        "body": "![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/12130348/47950cf2-0b04-41ac-ba71-23ad613b9079)\r\n如图，能否指定format 版本呢？在转模型时，针对特定onnx工具，对于高版本的 不支持，报错， IR representation should smaller v8",
        "state": "closed",
        "user": "DLlearn",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-13T01:53:50+00:00",
        "updated_at": "2024-05-27T14:57:54+00:00",
        "closed_at": "2024-05-27T14:57:54+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "DLlearn",
            "Zheng-Bicheng",
            "DLlearn",
            "DLlearn",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "DLlearn",
            "DLlearn",
            "Zheng-Bicheng",
            "DLlearn",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "DLlearn",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "DLlearn",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Discussion"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1251,
        "title": "量化的飞桨模型部署正常，但是转化为onnx模型出现问题（非量化的模型转为onnx可以正常部署）",
        "body": "请提供下述完整信息以便快速定位问题/Please provide the following information to quickly locate the problem\r\n\r\n- 系统环境/System Environment：python3.10.4\r\n- 版本号/Version：Paddle：  PaddleOCR： 问题相关组件/Related components：\r\npaddle2onnx           1.0.6\r\npaddlepaddle          2.5.2\r\npaddleslim            2.6.0\r\n- 运行指令/Command Code：\r\n- # 微调量化onnx部署\r\npython tools/infer/predict_system.py --use_onnx=True --use_gpu=False --det_model_dir=output/CCPD/det_quant/onnx/model.onnx --rec_model_dir=output/CCPD/rec_quant/onnx/model.onnx --image_dir=\"F:/DataSet/CCPD2020/ccpd_green/test/04131106321839081-92_258-159&509_530&611-527&611_172&599_159&509_530&525-0_0_3_32_30_31_30_30-109-106.jpg\" --rec_image_shape=3,48,320\r\n\r\n- 完整报错/Complete Error Message：\r\n[2024/05/18 02:21:46] ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320\r\n[2024/05/18 02:21:46] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.13833069801330566\r\n[2024/05/18 02:21:46] ppocr DEBUG: rec_res num  : 0, elapsed : 0.0\r\n[2024/05/18 02:21:46] ppocr DEBUG: 0  Predict time of F:/DataSet/CCPD2020/ccpd_green/test/04131106321839081-92_258-159&509_530&611-527&611_172&599_159&509_530&525-0_0_3_32_30_31_30_30-109-106.jpg: 0.141s\r\n[2024/05/18 02:21:46] ppocr DEBUG: The visualized image saved in ./inference_results\\04131106321839081-92_258-159&509_530&611-527&611_172&599_159&509_530&525-0_0_3_32_30_31_30_30-109-106.jpg\r\n[2024/05/18 02:21:46] ppocr INFO: The predict total time is 0.1968538761138916\r\n",
        "state": "closed",
        "user": "stringency",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-19T04:03:36+00:00",
        "updated_at": "2025-04-16T10:19:50+00:00",
        "closed_at": "2025-04-16T10:19:50+00:00",
        "comments_count": [
            "stringency",
            "Zheng-Bicheng",
            "stringency",
            "Homura852",
            "github-actions[bot]",
            "stringency",
            "github-actions[bot]",
            "stringency",
            "github-actions[bot]",
            "stringency",
            "github-actions[bot]",
            "stringency",
            "github-actions[bot]",
            "stringency"
        ],
        "labels": [
            "Bug",
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1252,
        "title": "编译Paddle2ONNX出现报错",
        "body": "**Describe the bug**\r\n按照https://github.com/xiaoyewww/Paddle2ONNX/blob/develop/docs/zh/compile_local.md进行编译，编译develop分支出现问题。\r\n\r\n**Env**\r\n\r\ncmake=3.18.0\r\ng++==12.1.0\r\nprotobuf==3.16.0\r\n\r\n**Screenshots**\r\n<img width=\"1526\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/50870160/8363cee4-a5af-4649-82d8-8852e3c5c798\">\r\n\r\n<img width=\"1522\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/50870160/c37c4967-6e15-45d9-8789-1c18e250fcb1\">\r\n",
        "state": "closed",
        "user": "xiaoyewww",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-19T15:15:54+00:00",
        "updated_at": "2024-05-23T03:20:13+00:00",
        "closed_at": "2024-05-23T03:06:07+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "xiaoyewww"
        ],
        "labels": [
            "Bug",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1254,
        "title": "请问如何将onnx的输入的batch size 固定为1，现在是动态输入的batch size",
        "body": "![Uploading dynamic.png…](https://img2.imgtp.com/2024/05/21/SOY8bDoI.png)\r\n\r\n\r\n即将`p2o.DynamicDimension.0`转为1。尝试如下命令后仍然不行：\r\n![Uploading dynamic.png…](https://img2.imgtp.com/2024/05/21/i0ZHULnO.png)",
        "state": "closed",
        "user": "muuda",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-21T10:40:10+00:00",
        "updated_at": "2024-05-27T14:56:57+00:00",
        "closed_at": "2024-05-27T14:56:56+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1255,
        "title": "Paddle2ONNX New and Upgraded Plan",
        "body": "这个Issues用于记录Paddle2ONNX需要更新的内容",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-05-22T04:18:58+00:00",
        "updated_at": "2024-12-25T02:30:08+00:00",
        "closed_at": "2024-12-25T02:30:07+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "Operator(Update)",
            "Announcement",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1262,
        "title": "ModuleNotFoundError: No module named 'paddle2onnx_cpp2py_export'",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nI follow the instructions [here](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/compile_local.md) to build this project, and I got no error.\r\nHowever, I got an error when I try to run script in tests(test_equal.py).\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: develop\r\n - Email/Wechat/Phone: qzylalala\r\n\r\n**Screenshots**\r\n```\r\nTraceback (most recent call last):\r\n  File \"tests/test_equal.py\", line 16, in <module>\r\n    from onnxbase import APIOnnx\r\n  File \"/work_space/Paddle2ONNX/tests/onnxbase.py\", line 23, in <module>\r\n    import paddle2onnx_cpp2py_export as c_p2o\r\nModuleNotFoundError: No module named 'paddle2onnx_cpp2py_export'\r\n```\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "qzylalala",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-27T12:18:41+00:00",
        "updated_at": "2024-05-28T01:05:25+00:00",
        "closed_at": "2024-05-28T01:05:25+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "qzylalala",
            "Zheng-Bicheng",
            "qzylalala",
            "Zheng-Bicheng",
            "qzylalala",
            "Zheng-Bicheng",
            "qzylalala"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1265,
        "title": "转换成onnx后使用netron可视化尺寸不是-1而是p2o.DynamicDimension.0-5",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n使用命令行转换paddle模型到onnx，具体命令行为：paddle2onnx --model_dir E:\\PaddleOCR\\checkpoint\\inference_new --model_filename inference_new.pdmodel --params_filename inference_new.pdiparams --save_file E:\\PaddleOCR\\checkpoint\\inference_new/model.onnx --opset_version 11 --input_shape_dict=\"{'x':[-1,3,-1,-1]}\"\r\n查看paddle2onnx没有input_shape_dict这个参数？还是我使用不对？\r\n\r\n - Paddle2ONNX版本:1.0.6\r\n -可视化截图如下：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/29697367/582891cd-3cc3-4513-92aa-6d2f69cc431e)\r\n谢谢！\r\n \r\n",
        "state": "closed",
        "user": "gaowq2017",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-05-28T02:26:29+00:00",
        "updated_at": "2024-05-30T09:25:05+00:00",
        "closed_at": "2024-05-30T09:25:05+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Utils(ONNX)",
            "Utils(Paddle)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1271,
        "title": "希望提供C API",
        "body": "**问题描述**\r\n您好，感谢您们对Paddle2ONNX项目的贡献。我在使用Paddle2ONNX进行模型转换时遇到了移植问题。目前只有C++ API，对于我们团队来说，如果有C API的话，将会更容易将该项目移植到C#等其它编程语言中。能否考虑提供一个C API接口？我们相信这会为更多开发者带来便利，非常感谢！\r\n\r\n**更多信息 :**\r\n- 用于部署的推理引擎: 无特殊要求\r\n- 为什么需要转换为ONNX格式：为了在多种平台和设备上进行推理\r\n- Paddle2ONNX版本: 最近更新的版本\r\n\r\n**报错截图**\r\n无\r\n\r\n**其他信息**\r\n无",
        "state": "closed",
        "user": "sdcb",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-06-04T08:45:48+00:00",
        "updated_at": "2025-01-26T02:29:51+00:00",
        "closed_at": "2025-01-26T02:29:50+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "sdcb",
            "jzhang533",
            "github-actions[bot]",
            "sdcb",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1272,
        "title": "Test tool bug : onnxbase.py does not support \"tensorlist\" as input when testing operators",
        "body": "**描述**\r\n当测试算子时，测试工具不支持tensorlist作为输入。\r\n**报错原因**\r\n当我执行算子单测时，使用`tensorlist`形式的输入，即`shape = [paddle.to_tensor(3), paddle.to_tensor(4)]`作为网络`输入`。\r\n```python\r\nclass Net3(paddle.nn.Layer):\r\n    \"\"\"\r\n    simple Net\r\n    \"\"\"\r\n\r\n    def __init__(self):\r\n        super(Net3, self).__init__()\r\n\r\n    def forward(self, shape):\r\n        \"\"\"\r\n        forward\r\n        \"\"\"\r\n        print(shape)\r\n        x = paddle.empty(shape, dtype=paddle.float32)\r\n        print(x)\r\n        return x\r\n\r\n\r\ndef test_empty_11_3():\r\n    \"\"\"\r\n    api: paddle.empty\r\n    op version: 11\r\n    \"\"\"\r\n    op = Net3()\r\n    op.eval()\r\n    obj = APIOnnx(op, 'empty', [11])\r\n    shape = [paddle.to_tensor(3), paddle.to_tensor(4)]\r\n    print(shape)\r\n    obj.set_input_data(\"input_data\", shape)\r\n    obj.run()\r\n\r\n```\r\n\r\n\r\n**报错详情**\r\n```bash\r\nTypeError: float() argument must be a string or a real number, not 'list'\r\ntests/onnxbase.py:218: TypeError`\r\n```\r\n**报错位置**\r\n位于`onnxbase.py`的`set_input_data()`方法，具体位于`下面代码的最后一行`。\r\n```bash\r\ndef set_input_data(self, group_name, *args):\r\n        \"\"\"\r\n        params dict tool\r\n        \"\"\"\r\n        self.kwargs_dict[group_name] = args\r\n        if isinstance(self.kwargs_dict[group_name][0], tuple):\r\n            self.kwargs_dict[group_name] = self.kwargs_dict[group_name][0]\r\n        i = 0\r\n        for in_data in self.kwargs_dict[group_name]:\r\n            if isinstance(in_data, list):\r\n                for tensor_data in in_data:\r\n                    self.input_dtype.append(tensor_data.dtype)\r\n                    self.input_spec.append(\r\n                        paddle.static.InputSpec(\r\n                            shape=tensor_data.shape,\r\n                            dtype=tensor_data.dtype,\r\n                            name=str(i)))\r\n                    if len(tensor_data.shape) == 0:\r\n                        self.input_feed[str(i)] = np.array(\r\n>                           float(in_data), dtype=dtype_map[in_data.dtype])\r\n```\r\n**补充说明**\r\n在paddle上测试没问题\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/82f87af2-db0a-4fef-9d61-8b6332afa059)\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-04T09:11:07+00:00",
        "updated_at": "2024-07-08T07:15:57+00:00",
        "closed_at": "2024-07-08T07:15:56+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "CI"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1273,
        "title": "[Split] operators bug : In ONNX opset version 18, there is a bug when inferring models with the [Split] operator.",
        "body": "**问题描述**\r\n在 ONNX 算子版本18中,使用 Split 算子进行推理时会出现错误。\r\n**报错详情**\r\nsplit-18算子要求至少存在【split】输入 或【num_outputs】属性二者其中之一。\r\n```bash\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : \r\n1 : FAIL : Load model from Paddle2ONNX/split/model.onnx failed:Node (p2o.Split.0) Op (Split) \r\n[ShapeInferenceError] Neither 'split' input nor 'num_outputs' attribute has been given\r\n```\r\n**报错位置**\r\n`网络结构`如下：\r\n```python\r\nclass Net(paddle.nn.Layer):\r\n    \"\"\"\r\n    simple Net\r\n    \"\"\"\r\n\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n\r\n    def forward(self, inputs):\r\n        \"\"\"\r\n        forward\r\n        \"\"\"\r\n        x = paddle.split(inputs, num_or_sections= 2)\r\n        return x\r\n```\r\n执行命令，导出onnx，要求`opset_version=18`\r\n```bash\r\n paddle2onnx --model_dir ./ --model_filename model.pdmodel       --save_file model.onnx --opset_version 18\r\n```\r\n但在推理过程中会出现上述报错。\r\n报错位置位于`下列代码的最后一句`。\r\n```python\r\nort_session = onnxruntime.InferenceSession(onnx_model_path)\r\ninput_names = [input.name for input in ort_session.get_inputs()]\r\n\r\n# 生成测试数据\r\ndata = np.full((10, 3), 1, dtype=np.float32)\r\n\r\n# 使用 ONNX 推理引擎执行推理\r\nresults = ort_session.run(None, {input_names[0]: data})\r\n```\r\n参考onnx-split-18的文档：https://github.com/onnx/onnx/blob/v1.13.1/docs/Changelog.md#Split-18\r\n\r\n**补充说明**\r\n已经修复此bug",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-04T10:34:43+00:00",
        "updated_at": "2024-07-08T07:15:43+00:00",
        "closed_at": "2024-07-08T07:15:43+00:00",
        "comments_count": [
            "jiuyuedeyu156"
        ],
        "labels": [
            "Bug",
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1281,
        "title": "模型推理报错：Greater OP 的输入参数(bitwise_and_5.tmp_0)的类型'tensor(bool)'无效。",
        "body": "\r\n## 问题描述\r\n模型推理报错：Greater OP 的输入参数(bitwise_and_5.tmp_0)的类型'tensor(bool)'无效。\r\nopset  version = 18\r\nonnxruntime version = 1.17\r\nonnx version = 1.16\r\n查阅onnx 1.17 greater-13的文档，发现greater不支持bool类型的输入。\r\n查阅paddle 2.6 greater_than的文档，发现greater_than支持bool的输入。\r\n\r\n## 推理代码:\r\n```python\r\nort_session = onnxruntime.InferenceSession(onnx_model_path)\r\n# 生成测试数据\r\nn, c, h, w = 1, 3, 128, 128\r\nfake_data = np.full((n, c, h, w), 1, dtype=np.float32)\r\n\r\nfake_shape = np.full((1,2), 1, dtype=np.float32)\r\nfake_shape[0, 0] = h\r\nfake_shape[0, 1] = w\r\n\r\nfake_scale = np.full((1,2), 1, dtype=np.float32)\r\n# 使用 ONNX 推理引擎执行推理\r\nresults = ort_session.run(None, {'im_shape':fake_shape, 'image': fake_data, 'scale_factor':fake_scale })\r\n```\r\n## 报错截图\r\n下图是**model.pdmodel**bitwise_and_5.tmp_0的具体位置\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/e5ae1704-858f-4cb3-b8ee-e3557c67d4cb)\r\n\r\n下图是**model.onnx**bitwise_and_5.tmp_0的具体位置\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/12f8b43f-770a-4d5d-995e-3a0d420b1ddc)\r\n\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "jiuyuedeyu156",
        "created_at": "2024-06-07T08:16:53+00:00",
        "updated_at": "2024-07-15T04:44:47+00:00",
        "closed_at": "2024-07-15T04:44:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1276,
        "title": "depthwise_conv2d, this model cannot be exported to ONNX.",
        "body": "[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: export/food_det_both_416x128_eps_v0/model.pdmodel\r\n[Paddle2ONNX] Parameters file path: export/food_det_both_416x128_eps_v0/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_1.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_2.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_3.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_5.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_6.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_7.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_9.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_10.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_11.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_13.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_14.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_15.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_17.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_18.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_19.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_21.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_22.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_23.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_26.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_27.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_30.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_31.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_34.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_35.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_38.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_39.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_42.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_43.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_46.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_47.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_50.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_51.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_54.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR][Paddle2ONNX] [depthwise_conv2d: depthwise_conv2d_55.tmp_0] While dilations != 1, cannot support padding = 'SAME'.\r\n[Paddle2ONNX] Due to the operator: depthwise_conv2d, this model cannot be exported to ONNX.\r\n[ERROR] Model exporting failed, you can report this problem to https://github.com/PaddlePaddle/Paddle2ONNX.git.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1717583184 (unix time) try \"date -d @1717583184\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3eb000019ab) received by PID 6571 (TID 0x7f5103486440) from PID 6571 ***]\r\n\r\nAborted (core dumped)\r\n",
        "state": "closed",
        "user": "MichaelZsl",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-06-05T10:33:41+00:00",
        "updated_at": "2024-12-25T02:30:06+00:00",
        "closed_at": "2024-12-25T02:30:06+00:00",
        "comments_count": [
            "MichaelZsl",
            "MichaelZsl",
            "Zheng-Bicheng",
            "MichaelZsl",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1280,
        "title": "某计算设备支持的ReduceProd算子与P2O支持的ReduceProd算子不兼容",
        "body": "\r\n## 1 问题描述 \r\n某计算设备支持的ReduceProd算子与Paddle2ONNX（ONNX1.16.1）支持的ReduceProd算子不兼容\r\nONNX1.16.1支持的ReduceProd-18，多了一个输入`axes`。据我观察，ReduceProd-11没有这个要求输入。\r\n由于必须要opset version 18，这个问题似乎无法避免。\r\n请问这种情况怎么办？\r\n\r\n## 2 报错位置\r\n### 2.1 下列代码是某计算设备的报错，定位到ReduceProd\r\n```bash\r\nE10042: GenerateOfflineModel execute failed.\r\n        TraceBack (most recent call last):\r\n        Verifying p2o.ReduceProd.0 failed.[FUNC:InferShapeAndType][FILE:infershape_pass.cc][LINE:132]\r\n        Call InferShapeAndType for node:p2o.ReduceProd.0(PartitionedCall) failed[FUNC:Infer][FILE:infershape_pass.cc][LINE:120]\r\n        process pass InferShapePass on node:p2o.ReduceProd.0 failed, ret:4294967295[FUNC:RunPassesOnNode]\r\n```\r\n\r\n### 2.2 下图是ONNX1.16.1支持的ReduceProd-18\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/04321ba4-ebd3-4096-bcbe-687416907b5a)\r\n\r\n### 2.3 下图是某计算设备支持的ReduceProd\r\n没有axes输入。\r\n由于必须要opset version 18，这个问题似乎无法避免。\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/e09537da-e7aa-4fe8-8aa7-5decbda45b7f)\r\n\r\n## 更多信息\r\n - 用于部署的推理引擎: ONNXRuntime\r\n - Paddle2ONNX版本: up-to-date\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "jiuyuedeyu156",
        "created_at": "2024-06-07T05:23:55+00:00",
        "updated_at": "2024-06-07T08:37:20+00:00",
        "closed_at": "2024-06-07T08:37:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1278,
        "title": "paddleocr    DBnet  转成onnx  后  reshape2 丢了",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n这是export的inferrence.pdmodel  输出部分\r\n<img width=\"1246\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/51013149/546786fa-1480-40cb-b1ab-b5bc6742ed37\">\r\n这是paddle2onnx 后的onnx 的输出部分\r\n<img width=\"964\" alt=\"image\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/51013149/885ef07e-3880-4cee-9c06-0f73a97c4d2e\">\r\n\r\n发现reshape2丢了？？？？\r\n\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "StarShang",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-07T00:42:15+00:00",
        "updated_at": "2024-06-17T01:14:05+00:00",
        "closed_at": "2024-06-17T01:13:51+00:00",
        "comments_count": [
            "Jiang-Jia-Jun"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1282,
        "title": "UIE多输入转onnx后输入结构与原模型不符",
        "body": "**问题描述**\r\nUIE原始模型的输入有三个: input_ids、position_ids以及常量fill constant\r\n通过paddle2onnx.command.c_paddle_to_onnx函数转onnx后输入结构发生大的变动。\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnx\r\n - 为什么需要转换为ONNX格式：需要适配国产化系统\r\n - Paddle2ONNX版本: 1.1.0\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\nUIE原始输入模型结构：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/35356847/77e73073-7211-458d-b6cb-9212f967f90c)\r\n\r\n\r\n转onnx后的输入模型结构：\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/35356847/ab02d22f-ace1-4e4f-9ad2-4bd491c6bdaa)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "XiHenSuper",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-06-14T02:48:01+00:00",
        "updated_at": "2024-12-25T02:30:06+00:00",
        "closed_at": "2024-12-25T02:30:05+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1284,
        "title": "Paddle OCR 推理模型转ONNX，固定shape后，ONNX结果相差很大，不固定shape，结果与paddle推理模型保持一致",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nPaddle OCR 推理模型转ONNX，固定shape后，ONNX结果相差很大，不固定shape，结果与paddle推理模型保持一致，这个问题要怎么处理哇：\r\n\r\n尝试了2种方法：\r\n①先将paddle推理模型的动态shape转为固定shape，再转成ONNX；\r\n②先将paddle推理模型转为ONNX,此时ONNX模型为动态shape，再使用paddle2onnx.optimize将ONNX动态shape改为固定shape\r\n\r\n这两种方法得到的固定shape的ONNX结果都和动态shape的结果有差异，请问这个怎么解决，怎么能够让Paddle OCR的模型转为固定shape的ONNX并且结果保持一致\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "xiaoxianyu12",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-14T09:42:26+00:00",
        "updated_at": "2024-06-24T06:27:06+00:00",
        "closed_at": "2024-06-24T06:27:06+00:00",
        "comments_count": [
            "GreatV",
            "YK7458",
            "Zheng-Bicheng",
            "xiaoxianyu12",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1290,
        "title": "当我使用opset 7测试bitwiseand时报错",
        "body": "## 1 问题描述\r\n（1）当我使用opset 7测试bitwiseand时报错\r\n（2）当我使用opset 7指令将（1）生成的model.pdmodel转为onnx时没有报错。\r\n问题：为什么测试时不会自动升级opset？\r\n## 2 报错详情\r\n###  2.1 使用opset7测试\r\n测试代码：\r\n```python\r\ndef test_bitwise_and_int_type():\r\n    \"\"\"\r\n    api: paddle.bitwise_and\r\n    op version: 7\r\n    \"\"\"\r\n    op = Net()\r\n    op.eval()\r\n    # net, name, ver_list, delta=1e-6, rtol=1e-5\r\n    obj = APIOnnx(op, 'BitwiseAnd_spec', [7])\r\n    obj.set_input_data(\r\n        \"input_data\",\r\n        paddle.to_tensor([-5, -1, 1]),\r\n        paddle.to_tensor([4,  2, -3]))\r\n    obj.run()\r\n```\r\n测试报错：\r\n```bash\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: BitwiseAnd_spec/cliped_model.pdmodel\r\n[Paddle2ONNX] Parameters file path: \r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [bitwise_and: bitwise_and_0.tmp_0] Requires the minimal opset version of 18.\r\n[Paddle2ONNX] Due to the operator: bitwise_and, requires opset_version >= 18.\r\n[Paddle2ONNX] This PaddlePaddle model is not able to export to ONNX with opset_version=7, please set the opset_version to 18 or higher for successfully conversion.\r\n[ERROR] Due to opset version, the model exporting is aborted, please set a higher opset_version or set auto_upgrade_opset=true.\r\n```\r\n### 2.2 使用指令转模型\r\n\r\n对 2.1 生成的model.pdmodel直接使用指令：\r\n```bash\r\npaddle2onnx --model_dir ./ --model_filename model.pdmodel  --save_file model.onnx --opset_version 7\r\n```\r\n没有报错，因为自动升级了opset：\r\n```bash\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./model.pdmodel\r\n[Paddle2ONNX] Parameters file path: \r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [bitwise_and: bitwise_and_0.tmp_0] Requires the minimal opset version of 18.\r\n[Paddle2ONNX] Due to the operator: bitwise_and, requires opset_version >= 18.\r\n[Paddle2ONNX] Opset version will change to 18 from 7\r\n[Paddle2ONNX] Use opset_version = 18 for ONNX export.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n```\r\n\r\n## 3 补充说明\r\nbitwiseand 源码\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/paddle2onnx/mapper/tensor/bitwise_and.cc#L20\r\nbitwiseand onnx\r\nhttps://onnx.ai/onnx/operators/onnx__BitwiseAnd.html\r\nand onnx\r\nhttps://onnx.ai/onnx/operators/onnx__And.html#and",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "jiuyuedeyu156",
        "created_at": "2024-06-18T01:50:38+00:00",
        "updated_at": "2024-06-18T05:39:57+00:00",
        "closed_at": "2024-06-18T05:39:57+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "jiuyuedeyu156"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1293,
        "title": "pip install failed!",
        "body": "win11\r\n\r\n```bash\r\nconda create -n paddle_onnx python=3.11\r\nconda activate paddle_onnx\r\npip install paddle2onnx\r\n```\r\n\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/44420757/b7f7ddc3-c14f-4d8e-a4c7-e591a9cc0007)\r\n",
        "state": "closed",
        "user": "hhxdestiny",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-20T07:24:56+00:00",
        "updated_at": "2024-07-08T07:15:27+00:00",
        "closed_at": "2024-07-08T07:15:27+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1301,
        "title": "when I choose convert fp16 onnx, My ATC export is wrong",
        "body": "before When I use fp32 type, it can work!\r\n\r\n\r\n<img width=\"1309\" alt=\"ScreenShot_20240705114931\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/38642697/4d2220dd-6b69-4df8-8875-49f3bffdc846\">\r\n",
        "state": "closed",
        "user": "ShaunLeeblob",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-05T03:50:40+00:00",
        "updated_at": "2024-12-24T02:31:36+00:00",
        "closed_at": "2024-12-24T02:31:35+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1295,
        "title": "[ERROR] Cannot found attribute output_padding in op: conv2d_transpose",
        "body": "## 报错详情\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./model.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [pool2d: pool2d_1.tmp_0] While ceil_model is True, Requires the minimal opset version of 10.\r\n[Paddle2ONNX] [pool2d: pool2d_2.tmp_0] While ceil_model is True, Requires the minimal opset version of 10.\r\n[Paddle2ONNX] [pool2d: pool2d_3.tmp_0] While ceil_model is True, Requires the minimal opset version of 10.\r\n[ERROR] Cannot found attribute output_padding in op: conv2d_transpose\r\nzsh: abort      paddle2onnx --model_dir ./ --model_filename model.pdmodel --params_filename  \r\n## 补充说明\r\n![image](https://github.com/PaddlePaddle/Paddle2ONNX/assets/151344256/562b5762-cf77-42bd-843b-156382b370ed)\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-06-21T04:26:07+00:00",
        "updated_at": "2024-07-01T07:13:42+00:00",
        "closed_at": "2024-07-01T07:13:42+00:00",
        "comments_count": [
            "jiuyuedeyu156",
            "jiuyuedeyu156"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1299,
        "title": "There are some operators not supported yet, including einsum, repeat_interleave",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nI tried to export model to onnx, and the terminal shows \"there are some operator not supported yet...\"\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: onnx runtime/ tensorRT\r\n - Why convert to onnx: Performance\r\n - Paddle2ONNX Version: 1.2.4 compiled locally\r\n - Email/Wechat/Phone: dmp96845@gmail.com\r\n\r\n**Screenshots**\r\n![issue](https://github.com/PaddlePaddle/Paddle2ONNX/assets/80203399/ae26e1de-4d82-400b-9e66-78bb45eda79a)\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "damopi",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-02T11:55:19+00:00",
        "updated_at": "2024-12-11T01:19:53+00:00",
        "closed_at": "2024-12-11T01:19:53+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "damopi",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "damopi",
            "damopi",
            "jiuyuedeyu156",
            "damopi",
            "jiuyuedeyu156",
            "damopi",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1302,
        "title": "AttributeError: module 'paddle2onnx' has no attribute 'dygraph2onnx'",
        "body": "貌似最新的版本里init里已经没有这个方法了，是不再支持这个方法了么",
        "state": "closed",
        "user": "EvilCalf",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-05T10:20:54+00:00",
        "updated_at": "2024-07-08T07:14:48+00:00",
        "closed_at": "2024-07-08T07:14:48+00:00",
        "comments_count": [
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1303,
        "title": "安装paddle2onnx会强制修改numpy版本",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n如果我的numpy==2.0.0 再安装paddle2onnx>=0.9.6 就会强制把numpy修改成1.26.4\r\n在代码库中也没有看到requirements.txt文件，不太清楚依赖版本\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n    pip3.9 install paddle2onnx>=0.9.6\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![a71b0bdd0a3673f3b50c681ae2667b7f](https://github.com/PaddlePaddle/Paddle2ONNX/assets/29832297/d006deca-5493-4b35-b044-ecf5d0da91f5)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "tianshuo78520a",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-05T10:46:25+00:00",
        "updated_at": "2024-07-08T07:14:54+00:00",
        "closed_at": "2024-07-08T07:14:54+00:00",
        "comments_count": [
            "jzhang533",
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1307,
        "title": "[讨论]关于mapper_registery.h.in 里REGISTER_MAPPER宏的new 操作的疑问",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n最近在看`mapper_registery.h.in` 里的代码，对如下REGISTER_MAPPER的实现有一个疑问：\r\n\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/4d27011092854bcc5e3d9785b7ca529227512b50/paddle2onnx/mapper/register_mapper.h#L34\r\n\r\n\r\n上述代码中是在`Create` 接口中调用了new 操作符，在heap上创建的对象，但是并没有找到对应的 delete操作，是否有内存泄露的风险?\r\n\r\n比如每次`MapperHelper::CreateMapper()` 都会触发一次new，然后返回 heap 上的 Mapper 指针，但是没有找到delete资源的操作；\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/4d27011092854bcc5e3d9785b7ca529227512b50/paddle2onnx/mapper/register_mapper.h#L106\r\n**更多信息 :**\r\n在飞桨Paddle 框架里也存在对于算子或者Kernel的注册管理，也是单例形式，但采用了static 全局静态变量的方式，对资源管理更加友好：\r\n```cpp\r\n// op_registry.h\r\n#define REGISTER_OPERATOR(op_type, op_class, ...)                        \\\r\n  STATIC_ASSERT_GLOBAL_NAMESPACE(                                        \\\r\n      __reg_op__##op_type,                                               \\\r\n      \"REGISTER_OPERATOR must be called in global namespace\");           \\\r\n  static ::paddle::framework::OperatorRegistrar<op_class, ##__VA_ARGS__> \\\r\n      __op_registrar_##op_type##__(#op_type);                            \\\r\n  int TouchOpRegistrar_##op_type() {                                     \\\r\n    __op_registrar_##op_type##__.Touch();                                \\\r\n    return 0;                                                            \\\r\n  }\r\n\r\n\r\ntemplate <typename... ARGS>\r\nstruct OperatorRegistrar : public Registrar {\r\n  explicit OperatorRegistrar(const char* op_type) {\r\n    PADDLE_ENFORCE_EQ(\r\n        OpInfoMap::Instance().Has(op_type),\r\n        false,\r\n        platform::errors::AlreadyExists(\r\n            \"Operator '%s' is registered more than once.\", op_type));\r\n    static_assert(sizeof...(ARGS) != 0,\r\n                  \"OperatorRegistrar should be invoked at least by OpClass\");\r\n    OpInfo info;    //  并没有使用 new 操作符\r\n    details::OperatorRegistrarRecursive<0, false, ARGS...>(op_type, &info);\r\n    OpInfoMap::Instance().Insert(op_type, info);   // 全局单例\r\n  }\r\n};\r\n```\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n还有一种方式，就是不直接返回Mapper*，再抽象一层接口wrapper下。其持有这个heap上的对象指针，然后实现一个析构函数，在里面调用delete\r\n\r\n",
        "state": "closed",
        "user": "Aurelius84",
        "closed_by": "Aurelius84",
        "created_at": "2024-07-09T07:57:20+00:00",
        "updated_at": "2024-07-10T08:12:19+00:00",
        "closed_at": "2024-07-10T08:12:19+00:00",
        "comments_count": [
            "jzhang533",
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1308,
        "title": "在转换模型时遇到了如下错误： Can't parse message of type \"paddle2onnx.framework.proto.ProgramDesc\" because it is missing required fields: blocks[0].ops[27].attrs[7].type, blocks[3].ops[12].attrs[7].type",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n转换模型时遇到错误：\r\n\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference2/model.pdmodel\r\n[Paddle2ONNX] Paramters file path: ./inference2/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[libprotobuf ERROR /workspace/Paddle2ONNX/protobuf/src/google/protobuf/message_lite.cc:133] Can't parse message of type \"paddle2onnx.framework.proto.ProgramDesc\" because it is missing required fields: blocks[0].ops[27].attrs[7].type, blocks[3].ops[12].attrs[7].type\r\n[Paddle2ONNX] Failed to parse paddlepaddle model from read content.\r\n[Paddle2ONNX] Failed to load program of PaddlePaddle model.\r\n[Paddle2ONNX] Paddle model parsing failed.\r\n[Paddle2ONNX] Paddle model convert failed.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: 1.2.5\r\n - Email/Wechat/Phone:  \r\n\r\n**Screenshots**\r\n<img width=\"852\" alt=\"截屏2024-07-09 19 47 26\" src=\"https://github.com/PaddlePaddle/Paddle2ONNX/assets/41884632/83386259-f53b-4450-9bcd-562197ada018\">\r\n\r\n**Additional context**\r\n启动命令：\r\npaddle2onnx --model_dir ./inference2 \\\r\n            --model_filename model.pdmodel \\\r\n            --params_filename model.pdiparams \\\r\n            --save_file onnx_model/model.onnx\r\n模型：baichuan13b",
        "state": "closed",
        "user": "JiaXinLI98",
        "closed_by": "Aurelius84",
        "created_at": "2024-07-09T11:49:06+00:00",
        "updated_at": "2024-07-12T01:55:50+00:00",
        "closed_at": "2024-07-12T01:55:50+00:00",
        "comments_count": [
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1309,
        "title": "使用X2Paddle将ONNX模型转Paddle时报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n在尝试将ernie+自定义操作的基于pytorch框架的模型转onnx后再转为paddle模型。在gather算子这里转换脚本报错\r\n\r\n以下为x2paddle自动转换的代码\r\n 在ernie里gather embedding时出错\r\n```\r\nx2paddle__bert_embeddings_position_embeddings_Gather_output_0 = paddle.gather(x=x2paddle_bert_embeddings_position_embeddings_weight, index=x2paddle__bert_embeddings_Constant_output_0, axis=0)\r\n x2paddle__bert_embeddings_task_type_embeddings_Gather_output_0 = paddle.gather(x=x2paddle_bert_embeddings_task_type_embeddings_weight, index=x2paddle__bert_embeddings_Constant_1_output_0, axis=0)\r\n```\r\n对应的index为：\r\n```\r\nself.x2paddle__bert_embeddings_Constant_output_0 = self.create_parameter(shape=[1, 32], attr='x2paddle__bert_embeddings_Constant_output_0', dtype='int64', default_initializer=paddle.nn.initializer.Constant(value=0.0))\r\nself.x2paddle__bert_embeddings_Constant_1_output_0 = self.create_parameter(shape=[1, 32], attr='x2paddle__bert_embeddings_Constant_1_output_0', dtype='int64', default_initializer=paddle.nn.initializer.Constant(value=0.0))\r\n```\r\n其中32为max_seqence_length\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n下面为详细报错\r\n> In transformed code:\r\n> \r\n>     File \"/Users/zhihao02.he/Codes/intent_detect_model_pytorch/data/model/ernie_mini_trained/pd_model_dynamic/x2paddle_code.py\", line 225, in forward\r\n>         x2paddle__bert_ConstantOfShape_output_0 = paddle.full(shape=x2paddle__bert_Constant_3_output_0, dtype='int64', fill_value=1)\r\n>         x2paddle__bert_Unsqueeze_output_0 = paddle.unsqueeze(x=x2paddle_attention_mask, axis=x2paddle__bert_Constant_5_output_0)\r\n>         x2paddle__bert_embeddings_position_embeddings_Gather_output_0 = paddle.gather(x=x2paddle_bert_embeddings_position_embeddings_weight, index=x2paddle__bert_embeddings_Constant_output_0, axis=0)\r\n>         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n>         x2paddle__bert_embeddings_task_type_embeddings_Gather_output_0 = paddle.gather(x=x2paddle_bert_embeddings_task_type_embeddings_weight, index=x2paddle__bert_embeddings_Constant_1_output_0, axis=0)\r\n>         x2paddle__ConstantOfShape_output_0 = paddle.full(shape=x2paddle__Constant_1_output_0, dtype='int64', fill_value=1)\r\n> \r\n>     File \"/opt/anaconda3/envs/onnx_tf/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 3019, in gather\r\n>         helper.append_op(\r\n>     File \"/opt/anaconda3/envs/onnx_tf/lib/python3.8/site-packages/paddle/base/layer_helper.py\", line 44, in append_op\r\n>         return self.main_program.current_block().append_op(*args, **kwargs)\r\n>     File \"/opt/anaconda3/envs/onnx_tf/lib/python3.8/site-packages/paddle/base/framework.py\", line 4467, in append_op\r\n>         op = Operator(\r\n>     File \"/opt/anaconda3/envs/onnx_tf/lib/python3.8/site-packages/paddle/base/framework.py\", line 3214, in __init__\r\n>         self.desc.infer_shape(self.block.desc)\r\n> \r\n>     ValueError: (InvalidArgument) The last dim of index should be 1 when it is 2D, but we get 32\r\n>   [Hint: Expected index_dims[1] == 1, but received index_dims[1]:32 != 1:1.] (at /Users/paddle/xly/workspace/6b5f2c56-ddc3-4da3-aa89-e4f3a21369ae/Paddle/paddle/phi/infermeta/binary.cc:1541)\r\n>   [operator < gather > error]\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:   \r\n 环境\r\nMacos\r\npython                     3.8.19  \r\nx2paddle                  1.4.1 \r\nonnx                      1.15.0  \r\npaddlepaddle              2.6.0          \r\n\r\n - 你的联系方式(Email/Wechat/Phone):\r\nwechat : 13714857390\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "hezhihao10",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-10T08:54:41+00:00",
        "updated_at": "2024-07-11T09:48:09+00:00",
        "closed_at": "2024-07-11T09:48:09+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1310,
        "title": "【🚀需求🚀】支持控制流conditional_block + select_input 系列算子的支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n记录一个算子转换需求的问题：控制流 if 下涉及的 conditional_block + select_input 算子转ONNX\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 待更新\r\n - 为什么需要转换为ONNX格式：业务需求\r\n - Paddle2ONNX版本: 1.2.5 \r\n - 你的联系方式(Email/Wechat/Phone): Aurelius84\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Aurelius84",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-10T12:56:19+00:00",
        "updated_at": "2024-07-13T12:52:22+00:00",
        "closed_at": "2024-07-13T12:52:22+00:00",
        "comments_count": [
            "Aurelius84",
            "jiuyuedeyu156",
            "Aurelius84",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1311,
        "title": "【🚀需求🚀】支持飞桨 swiglu 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n记录一个待支持转ONNX的算子需求：swiglu 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本: 1.2.5\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Aurelius84",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-10T12:57:58+00:00",
        "updated_at": "2024-07-11T09:47:04+00:00",
        "closed_at": "2024-07-11T09:47:04+00:00",
        "comments_count": [
            "Aurelius84"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1312,
        "title": "【🚀需求🚀】支持飞桨 top_p_sampling 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n记录一个待支持转ONNX的算子需求：top_p_sampling 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: 待更新\r\n - 为什么需要转换为ONNX格式： 业务方\r\n - Paddle2ONNX版本: 1.2.5\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Aurelius84",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-10T12:58:50+00:00",
        "updated_at": "2024-12-24T02:31:34+00:00",
        "closed_at": "2024-12-24T02:31:34+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1315,
        "title": "paddle2onnx 编译python wheel 包问题",
        "body": "**问题描述**\r\n在编译paddle2onnx的过程中发现了两个问题：\r\n1. 执行`python -m build `命令后即使编译过一次，进行些许改动后（甚至不改任何东西）重新执行`python -m build` 也会对整个项目进行重新编译，编译很慢很耗时。\r\n2. 在编译完成后，安装paddle2onnx的whl包，包里面把c++源码全部打包进去了。\r\n\r\n请问一下这俩问题该怎么优化一下吗？尤其是问题1，电脑不行编译就会很耗时。\r\n",
        "state": "closed",
        "user": "ChaoII",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-12T01:28:10+00:00",
        "updated_at": "2024-11-14T06:13:54+00:00",
        "closed_at": "2024-07-12T06:05:27+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Aurelius84",
            "ChaoII",
            "Zheng-Bicheng",
            "154775258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1326,
        "title": "TypeError: export() got an unexpected keyword argument 'model_file'",
        "body": "```bash\r\npaddle2onnx --model_dir ./ --model_filename model.pdmodel  --params_filename model.pdiparams  --save_file model.onnx\r\nTraceback (most recent call last):\r\n  File \"/Users/liuyulong06/Workdesktop/virtual_env/base_env/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"/Users/liuyulong06/Workdesktop/virtual_env/base_env/lib/python3.12/site-packages/paddle2onnx/command.py\", line 139, in main\r\n    paddle2onnx.export(\r\nTypeError: export() got an unexpected keyword argument 'model_file'\r\n```",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-15T02:48:53+00:00",
        "updated_at": "2024-07-15T03:03:16+00:00",
        "closed_at": "2024-07-15T03:03:16+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1328,
        "title": "paddle ocr 转onnx之后精度损失",
        "body": "在使用paddle的模型测试时，测试集准确率是100% ，转为onnx模型测试，同样的测试集，准确率变成了88%。出现了大量的错误。\r\n\r\n",
        "state": "closed",
        "user": "gzgc",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-15T03:07:18+00:00",
        "updated_at": "2024-12-24T02:31:33+00:00",
        "closed_at": "2024-12-24T02:31:33+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "gzgc",
            "jiuyuedeyu156",
            "Zheng-Bicheng",
            "gzgc",
            "Zheng-Bicheng",
            "gzgc",
            "GreatV",
            "Zheng-Bicheng",
            "gzgc",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1330,
        "title": "paddleocr:export onnx and inference error",
        "body": "#### 问题描述 / Problem Description\r\npaddleocr cls_model:use paddle2onnx export onnx model， running Error: onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running GlobalAveragePool node. Name:'p2o.GlobalAveragePool.18' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/nn/pool_attributes.h:105 onnxruntime::PoolAttributes::SetOutputSize input_shape.Size() > 0 || input_shape[0] == 0 was false. Invalid input shape. Only N can be zero. Got:{1,200,0,25}\r\n\r\n#### 运行环境 / Runtime Environment\r\n- OS: windows11\r\n- Paddle: 2.6.1-gpu\r\n- PaddleOCR:\r\n\r\n",
        "state": "closed",
        "user": "choococo",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-17T02:50:43+00:00",
        "updated_at": "2024-12-23T02:33:41+00:00",
        "closed_at": "2024-12-23T02:33:40+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1332,
        "title": "无法在set_value算子中找到fp32_values属性",
        "body": "## paddle模型代码\r\n```python\r\nimport paddle\r\nclass Net(paddle.nn.Layer):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n    def forward(self, inputs):\r\n        inputs[1,1] = 1\r\n        return inputs\r\nnet = Net()\r\ninputs = paddle.to_tensor([[1,2,3], [4,5,6]], dtype=paddle.float32)\r\ny = net(inputs)\r\npaddle.jit.save(net, 'model', input_spec=[inputs])\r\n```\r\n## pdmodel文件\r\n![image](https://github.com/user-attachments/assets/e4198903-4bcd-4e67-887a-490205b36393)\r\n![image](https://github.com/user-attachments/assets/f99a2d55-d1fb-490e-aa22-cafe786b84e9)\r\n\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-18T10:28:44+00:00",
        "updated_at": "2024-10-17T05:07:45+00:00",
        "closed_at": "2024-10-17T05:07:45+00:00",
        "comments_count": [
            "jiuyuedeyu156",
            "jiuyuedeyu156",
            "Zheng-Bicheng",
            "jiuyuedeyu156",
            "jiuyuedeyu156",
            "Zheng-Bicheng",
            "jiuyuedeyu156"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1331,
        "title": "SLANet-LCNetV2 转onnx模型报错",
        "body": "#### 问题描述 / Problem Description\r\n新SLANet-LCNetV2 通过paddle2onnx转onnx模型时报错\r\n\r\n#### 运行环境 / Runtime Environment\r\n- OS: centos\r\n- Paddle:  2.6.1\r\n- PaddleOCR:\r\n\r\n#### 复现代码 / Reproduction Code\r\n\r\n\r\n#### 完整报错 / Complete Error Message\r\n![image](https://github.com/user-attachments/assets/33f69309-abfb-4cbb-a93a-0c149aafdea8)\r\n\r\n#### 可能解决方案 / Possible solutions\r\n\r\n\r\n#### 附件 / Appendix\r\n",
        "state": "closed",
        "user": "milely",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-17T09:45:59+00:00",
        "updated_at": "2024-10-16T09:23:32+00:00",
        "closed_at": "2024-10-16T09:23:32+00:00",
        "comments_count": [
            "GreatV",
            "milely",
            "Zheng-Bicheng",
            "milely",
            "Zheng-Bicheng",
            "milely",
            "squallliu",
            "Zheng-Bicheng",
            "PeiyuLau",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1334,
        "title": "windwos下安装，版本是旧版本",
        "body": "环境:\r\n1) window11\r\n2) paddlepaddle-gpu  2.6.1\r\n3) onnxruntime-gpu 1.17\r\n在直接安装或者升级paddle2onnx的时候，一直安装的都是1.0.6的版本，我去pypi上看到最新的和github上发布的版本一样，是不是因为最新版本目前还不支持windows，目前看离线安装编译的都是linux版本的",
        "state": "closed",
        "user": "BeyondYourself",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-26T03:00:32+00:00",
        "updated_at": "2024-11-20T11:37:05+00:00",
        "closed_at": "2024-11-20T11:37:05+00:00",
        "comments_count": [
            "zzz-zyq",
            "yjyz1011",
            "GreatV",
            "CvBokchoy",
            "CvBokchoy",
            "zzz-zyq",
            "CvBokchoy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1335,
        "title": "中文表格识别模型ch_ppstructure_mobile_v2.0_SLANet_infer，不支持转为onnx格式吗？",
        "body": "### Search before asking\n\n- [X] I have searched the PaddleOCR [Docs](https://paddlepaddle.github.io/PaddleOCR/) and found no similar bug report.\n\n- [X] I have searched the PaddleOCR [Issues](https://github.com/PaddlePaddle/PaddleOCR/issues) and found no similar bug report.\n\n- [X] I have searched the PaddleOCR [Discussions](https://github.com/PaddlePaddle/PaddleOCR/discussions) and found no similar bug report.\n\n\n### Bug\n\n您好。我想把表格识别模型转为onnx来部署。paddle2onnx中3个例子都可以转换成功，\r\nhttps://github.com/PaddlePaddle/PaddleOCR/tree/main/deploy/paddle2onnx\r\n\r\n但是我使用同样方法转换ch_ppstructure_mobile_v2.0_SLANet_infer时，报错。\r\n\r\n\r\n~/Workspace/PaddleOCR-2.8.1$ paddle2onnx --model_dir ./inference/ch_ppstructure_mobile_v2.0_SLANet_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./inference/SLANet_onnx/model.onnx --opset_version 11 --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference/ch_ppstructure_mobile_v2.0_SLANet_infer/inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./inference/ch_ppstructure_mobile_v2.0_SLANet_infer/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including while,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1721979100 (unix time) try \"date -d @1721979100\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e8000018fb) received by PID 6395 (TID 0x7c16f51bd480) from PID 6395 ***]\r\n\r\n已中止 (核心已转储)\r\n\r\n\r\n我搜索以前的issue，有人说转换成功了，请问是哪里有问题呢？\r\n\n\n### Environment\n\n_No response_\n\n### Minimal Reproducible Example\n\n_No response_\n\n### Additional\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I'd like to help by submitting a PR!",
        "state": "closed",
        "user": "greatliu",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-07-26T07:47:21+00:00",
        "updated_at": "2024-10-16T09:23:25+00:00",
        "closed_at": "2024-10-16T09:23:25+00:00",
        "comments_count": [
            "GreatV",
            "greatliu",
            "GreatV",
            "greatliu",
            "phphappy",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1336,
        "title": "如何导出NAFNetLocal模型文件为onnx格式？",
        "body": "\r\n![1721984219602](https://github.com/user-attachments/assets/80acdd23-8089-4923-b6ee-c1cf99e63af4)\r\n\r\n如图所示，我尝试将这个模型文件导出onnx文件，实际设置为动态尺寸输入时，会报错：\r\n![1721984236285](https://github.com/user-attachments/assets/df4091a9-9897-4912-9ea7-8e08c613cd8b)\r\n\r\n![1721984242620](https://github.com/user-attachments/assets/841dba76-3fba-49ce-bee9-15735f2051b3)\r\n\r\n我检查了NAFNet网络中的check_image_size函数，并增加了打印信息，用于查验:\r\n![1721984266618](https://github.com/user-attachments/assets/3c756fea-3c5e-4c1e-9e4a-30c9cf5ac2d7)\r\n\r\n不知道这个模型，到底要如何导出呢？？\r\n----我个人测试过，如果模型事先设定一张图片的尺寸数据，导出onnx文件后。可以正常调用onnx，对该图片进行 推理，结果也正常。而使用另外一张不同尺寸的图片进行onnx模型推理时，就会报错，提示输入的数据形状不对。。---因此，我才希望导出一个可以支持动态尺寸输入的onnx文件，以便进行正常应用。\r\n",
        "state": "closed",
        "user": "lmw0320",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-26T08:59:03+00:00",
        "updated_at": "2024-12-10T02:46:27+00:00",
        "closed_at": "2024-12-10T02:46:27+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1337,
        "title": "Convert Paddle language models to onnx",
        "body": "Please help me to convert 3 language models from Paddle OCR - German, Dutch and Sweden to onnx.\r\nI am a complete incompetent in this and can't figure out how to use it.\r\nI need onnx files to add in Luna Translator program (language packages)\r\n\r\nThere must be 3 files in each converted package\r\n![onnx](https://github.com/user-attachments/assets/9e8827a3-25e8-46c5-ae73-ea9a58046d35)\r\n\r\n",
        "state": "closed",
        "user": "Farooq87",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-07-26T22:16:38+00:00",
        "updated_at": "2025-01-06T02:36:17+00:00",
        "closed_at": "2025-01-06T02:36:16+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "GreatV",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1340,
        "title": "Fairmot跟踪模型可以转换为onnx格式吗",
        "body": "**问题描述**\r\n需要将fairmot跟踪模型转换为onnx格式，但是提醒报错there are some operators not supported yet, including deformable_conv。请问目前是否支持fairmot模型转换。\r\n\r\n - Paddle2ONNX版本:\r\n   paddle2onnx版本号是1.0.6\r\n\r\n**报错截图**\r\n![image](https://github.com/user-attachments/assets/4d77b5b3-71c8-4cc4-aa6e-3e659c3a20ee)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "zhoujing21611",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-06T07:48:10+00:00",
        "updated_at": "2024-11-22T03:03:14+00:00",
        "closed_at": "2024-11-22T03:03:14+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1338,
        "title": "无法在assign_value算子中找到fp32_values和int64_values属性",
        "body": "DETR模型导出后转onnx报错无法在assign_value算子中找到fp32_values和int64_values属性\r\n转onnx命令：paddle2onnx --model_dir=./output_inference/detr_r50_1x_coco/ \\\r\n    --model_filename=model.pdmodel \\\r\n    --params_filename=model.pdiparams \\\r\n    --save_file=./output_inference/detr_r50_1x_coco/model.onnx \\\r\n    --enable_onnx_checker=True \\\r\n    --opset_version 16\r\n报错截图：\r\n<img width=\"1053\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0cd90286-f821-41ef-98e0-23b4b2b0c5c7\">\r\n<img width=\"1047\" alt=\"image\" src=\"https://github.com/user-attachments/assets/61746520-c1b9-470a-a784-2af95d90bf49\">\r\n\r\n\r\n",
        "state": "closed",
        "user": "wangna11BD",
        "closed_by": "wangna11BD",
        "created_at": "2024-07-31T05:37:58+00:00",
        "updated_at": "2024-08-01T07:43:06+00:00",
        "closed_at": "2024-08-01T07:43:06+00:00",
        "comments_count": [
            "jiuyuedeyu156",
            "wangna11BD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1346,
        "title": "中文表格识别模型ch_ppstructure_mobile_v2.0_SLANet_infer ONNX半精度推理报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "JIANG3330",
        "closed_by": "JIANG3330",
        "created_at": "2024-08-13T06:27:17+00:00",
        "updated_at": "2024-08-13T06:27:37+00:00",
        "closed_at": "2024-08-13T06:27:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1341,
        "title": "paddlenlp Taskflow(\"ner\") 2 onnx 报错",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including viterbi_decode,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1722927899 (unix time) try \"date -d @1722927899\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x4265c00259720) received by PID 2463520 (TID 0x7f192009f740) from PID 2463520 ***]\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: 1.2.6\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "Doloxetine",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-06T07:55:47+00:00",
        "updated_at": "2024-12-09T02:47:39+00:00",
        "closed_at": "2024-12-09T02:47:38+00:00",
        "comments_count": [
            "Doloxetine",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1342,
        "title": "导出onnx模型报错",
        "body": "**问题描述**\r\n印章识别模型导出onnx使用如下命令\r\npaddle2onnx --model_dir ./output/inference/det_r50_seal_0203_all --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./model_convert/onnx/seal_db++.onnx  --enable_onnx_checker True\r\n\r\n\r\n\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n paddle2onnx              1.2.6\r\npaddleocr                2.7.3\r\npaddlepaddle-gpu         2.6.1.post117\r\n\r\n - 为什么需要转换为ONNX格式：\r\n   预训练，自动标注\r\n - 你的联系方式(Email/Wechat/Phone):\r\n - phphappy@163.com,\r\n - Wechat:22869750\r\n**报错截图**\r\n![1723102285979](https://github.com/user-attachments/assets/6c0689d5-0068-455b-b67d-66224868d029)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "phphappy",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-08T07:34:26+00:00",
        "updated_at": "2024-09-05T01:27:54+00:00",
        "closed_at": "2024-09-05T01:27:54+00:00",
        "comments_count": [
            "jiuyuedeyu156",
            "phphappy",
            "jiuyuedeyu156",
            "phphappy",
            "Zheng-Bicheng",
            "phphappy",
            "jiuyuedeyu156",
            "phphappy",
            "jiuyuedeyu156",
            "phphappy",
            "phphappy",
            "jiuyuedeyu156"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1347,
        "title": "中文表格识别模型ch_ppstructure_mobile_v2.0_SLANet_infer ONNX半精度推理报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n中文表格识别模型ch_ppstructure_mobile_v2.0_SLANet_infer https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/ch_ppstructure_mobile_v2.0_SLANet_infer.tar\r\n使用paddle2onnx工具将模型转换为fp32的onnx可以正常推理，但是如果导出fp16模型`--export_fp16_model=True` onnxruntime推理会有如下报错：\r\n```\r\n    ort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\r\n  File \"E:\\anaconda3\\envs\\onnx\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 419, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"E:\\anaconda3\\envs\\onnx\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 472, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from SLANetv1_fp16.onnx failed:Node (p2o.Loop.0) Op (Loop) [TypeInferenceError] Graph attribute inferencing failed: Node:p2o.Loop.0 Tensor element type mismatch. 1 != 10\r\n```\r\n\r\n如果我先将fp32的onnx模型导出，然后用下面的代码转换为fp16的onnx模型，onnxruntime推理报错如下：\r\n```\r\n  ort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\r\n  File \"E:\\anaconda3\\envs\\onnx\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 419, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"E:\\anaconda3\\envs\\onnx\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 472, in _create_inference_session\r\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\r\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from ch_ppstructure_mobile_v2_SLANet_fp16.onnx failed:Node (p2o.Resize.0) Op (Resize) [ShapeInferenceError] Either `sizes` or `scales` must be provided, but not both of them\r\n```\r\n\r\nfp32转fp16代码：\r\n```\r\nimport onnx\r\nfrom onnxconverter_common import float16\r\n\r\nmodel = onnx.load(\"ch_ppstructure_mobile_v2.0_SLANet_infer.onnx\")\r\nmodel_fp16 = float16.convert_float_to_float16(model=model)\r\nonnx.save(model_fp16, \"ch_ppstructure_mobile_v2.0_SLANet_infer_fp16.onnx\")\r\n```\r\n\r\n推理代码：\r\n```\r\nimport onnxruntime as ort\r\nimport numpy as np\r\n\r\nmodel_path = 'ch_ppstructure_mobile_v2.0_SLANet_infer_fp16.onnx'\r\n\r\ninput_data = np.random.randn(1, 3, 488, 488).astype(np.float16)\r\n\r\nort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\r\ninput_name = ort_session.get_inputs()[0].name\r\noutput_name = ort_session.get_outputs()[0].name\r\npred_onnx = ort_session.run([output_name], {input_name: input_data})\r\n\r\nprint(pred_onnx)\r\n```\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntime 版本1.18.1\r\n - 为什么需要转换为ONNX格式：需要转换到其他推理框架\r\n - Paddle2ONNX版本:  1.2.5\r\n - 你的联系方式(Email/Wechat/Phone): a740496343@gmail.com\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n\r\n不知道这个问题是onnxruntime的问题还是paddle2onnx的问题，我在onnxruntime的仓库下看到了相似的问题：\r\nhttps://github.com/microsoft/onnxruntime/discussions/17210\r\n\r\n请相关的大佬帮忙看看，感谢~\r\n",
        "state": "closed",
        "user": "JIANG3330",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-13T06:52:00+00:00",
        "updated_at": "2024-10-16T09:39:43+00:00",
        "closed_at": "2024-10-16T09:39:43+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1356,
        "title": "While dilations != 1, cannot support padding = 'SAME'",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nWhile dilations != 1, cannot support padding = 'SAME'\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version: 1.2.7\r\n - Email/Wechat/Phone: xuyao@stu.cqut.edu.cn\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "YaoXu97",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-21T02:21:32+00:00",
        "updated_at": "2024-12-08T02:49:35+00:00",
        "closed_at": "2024-12-08T02:49:35+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1349,
        "title": "faster rcnn r50 fpn模型转为onnx格式失败",
        "body": "\r\n\r\n**问题描述**\r\n\r\n尝试将faster rcnn r50 fpn模型转为onnx格式 参考了https://github.com/PaddlePaddle/PaddleDetection/issues/5986 ，但进行export_model时失败。（如果删去export_onnx=True则能转换成功，但因为没有去掉控制流的原因，这样得到的模型无法转为onnx。）\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:onnx 1.16.0 \r\n - 为什么需要转换为ONNX格式：需要进一步转TensorRT\r\n - Paddle2ONNX版本:1.2.6\r\n - 你的联系方式(Email/Wechat/Phone):1078678422@qq.com\r\n\r\n**报错截图**\r\n![image](https://github.com/user-attachments/assets/17f766ab-856f-45a6-b9b6-a529fbfd2662)\r\n![image](https://github.com/user-attachments/assets/373f7a6e-cca5-43a7-9547-158320e46969)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Ochre-amber",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-14T02:53:10+00:00",
        "updated_at": "2024-12-09T02:47:37+00:00",
        "closed_at": "2024-12-09T02:47:37+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1358,
        "title": "[ERROR] Cannot found attribute beta in op: swish",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n运行https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/tools/paddle/README.md中的剪枝操作之后，对pd模型转换为onnx，出现报错\r\n\r\npaddle2onnx        1.0.9\r\npaddlepaddle       3.0.0b1\r\n(尝试过paddle2.6，2.5都报相同的错误，其中2.5.2在运行剪枝时找不到paddle.base这个包)\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: \r\n - 为什么需要转换为ONNX格式：后续转om\r\n - Paddle2ONNX版本: 1.0.9\r\n - 你的联系方式(Email/Wechat/Phone): dbw46784086@icloud.com\r\n\r\n**报错截图**\r\n<img width=\"1232\" alt=\"Snipaste_2024-08-22_11-55-18\" src=\"https://github.com/user-attachments/assets/dc5469ec-4d2a-4b5d-824f-ae7117d33177\">\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Hakstar",
        "closed_by": "Hakstar",
        "created_at": "2024-08-22T03:58:35+00:00",
        "updated_at": "2024-08-27T14:25:22+00:00",
        "closed_at": "2024-08-22T06:01:45+00:00",
        "comments_count": [
            "SWHL",
            "Hakstar"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1359,
        "title": "【🚀需求🚀】支持飞桨 deformable_conv 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：deformable_conv 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-22T12:17:29+00:00",
        "updated_at": "2024-08-24T04:42:00+00:00",
        "closed_at": "2024-08-24T04:42:00+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1357,
        "title": "ppdet 导出的rtdetr模型转onnx报错",
        "body": "导出命令：\r\n python tools/export_model.py -c configs/rtdetr/rtdetr_hgnetv2_l_6x_coco.yml -o weights=output/rtdetr_hgnetv2_l_6x_coco/model_final.pdparams trt=True\r\n\r\n转换命令：\r\n paddle2onnx --model_dir=./output_inference/rtdetr_hgnetv2_l_6x_coco/  --model_filename model.pdmodel --params_filename model.pdiparams --enable_onnx_checker True --enable_dev_version False --opset_version 16\r\n--save_file rtdetr_hgnetv2_6x_coco.onnx\r\n\r\n版本：\r\n![3 (2)](https://github.com/user-attachments/assets/818717cf-0d8b-4bd6-9c2a-350c14d64081)\r\n\r\n报错信息:\r\n![2 (2)](https://github.com/user-attachments/assets/5d8ad85e-4721-4990-9a9c-3c1b7cdd06d7)\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:510628461@qq.com\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "David-dotcom666",
        "closed_by": "David-dotcom666",
        "created_at": "2024-08-21T06:41:33+00:00",
        "updated_at": "2024-09-06T02:19:05+00:00",
        "closed_at": "2024-09-06T02:19:05+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1360,
        "title": "【🚀需求🚀】支持飞桨 repeat_interleave 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：repeat_interleave 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-22T12:18:37+00:00",
        "updated_at": "2024-08-24T04:42:05+00:00",
        "closed_at": "2024-08-24T04:42:05+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1361,
        "title": "【🚀需求🚀】支持飞桨 broadcast_tensors 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：broadcast_tensors 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:19:16+00:00",
        "updated_at": "2024-12-08T02:49:34+00:00",
        "closed_at": "2024-12-08T02:49:33+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1362,
        "title": "【🚀需求🚀】支持飞桨 distribute_fpn_proposals 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：distribute_fpn_proposals 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:19:58+00:00",
        "updated_at": "2024-12-08T02:49:33+00:00",
        "closed_at": "2024-12-08T02:49:32+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1364,
        "title": "【🚀需求🚀】支持飞桨 lod_array_length 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：lod_array_length 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:21:34+00:00",
        "updated_at": "2024-12-08T02:49:30+00:00",
        "closed_at": "2024-12-08T02:49:30+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1363,
        "title": "【🚀需求🚀】支持飞桨 generate_proposals_v2 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：generate_proposals_v2 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:21:06+00:00",
        "updated_at": "2024-12-08T02:49:31+00:00",
        "closed_at": "2024-12-08T02:49:31+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1365,
        "title": "【🚀需求🚀】支持飞桨 tensor_array_to_tensor 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：tensor_array_to_tensor 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:22:08+00:00",
        "updated_at": "2024-12-07T02:41:28+00:00",
        "closed_at": "2024-12-07T02:41:28+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1367,
        "title": "【🚀需求🚀】支持飞桨 tril_triu 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：tril_triu 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-22T12:23:14+00:00",
        "updated_at": "2024-08-24T04:42:09+00:00",
        "closed_at": "2024-08-24T04:42:09+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1366,
        "title": "【🚀需求🚀】支持飞桨 write_to_array 算子转ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n记录一个待支持转ONNX的算子需求：write_to_array 算子。且去ONNX官网看了下，没有直接对应的算子，需要用ONNX算子组合实现\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:待更新\r\n - 为什么需要转换为ONNX格式：业务方\r\n - Paddle2ONNX版本:1.2.8\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-22T12:22:34+00:00",
        "updated_at": "2024-12-07T02:41:27+00:00",
        "closed_at": "2024-12-07T02:41:26+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleOCR",
        "number": 14109,
        "title": "ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nWhile executing 'predict_system.py'  I have set the rec_image_shape parameter as rec_image_shape='3,32,320'. But even after specifying the value for the parameter system is still not able to recognize the value\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: CPU (windows)\r\n - Why convert to onnx：ONNX is already implemented so to use the additional functionality\r\n - Paddle2ONNX Version: paddle2onnx==1.0.6\r\n - Email/Wechat/Phone: NA\r\n\r\n**Screenshots**: \r\n<img width=\"710\" alt=\"image\" src=\"https://github.com/user-attachments/assets/64723a4a-29bd-47c6-88b4-5d244182b630\">\r\n\r\n\r\n\r\n**Additional context**: issue is not only observed for paddle2onnx but also observed for paddle.\r\nThe command which I have executed is given below:\r\n\r\npython -m predict_system.py --use_gpu=False \\\r\n--cls_model_dir=./inference/ch_ppocr_mobile_v2.0_cls_infer \\\r\n--rec_model_dir=./inference/en_PP-OCRv3_rec_infer \\\r\n--det_model_dir=./inference/en_PP-OCRv3_det_infer \\\r\n--image_dir=doc/imgs_en/img_12.jpg \\\r\n--rec_char_dict_path=ppocr/utils/en_dict.txt \\\r\n--rec_image_shape='3,32,320'\r\n\r\n(Note: I have also tried giving the shape in different but the issue  still persists. --rec_image_shape=\"3,32,320\",  \r\n--rec_image_shape \"3,32,320\", --rec_image_shape 3,32,320\r\n\r\n\r\n",
        "state": "closed",
        "user": "dsamarth08",
        "closed_by": "GreatV",
        "created_at": "2024-08-26T08:03:05+00:00",
        "updated_at": "2025-04-05T16:41:18+00:00",
        "closed_at": "2024-10-29T05:19:37+00:00",
        "comments_count": [
            "tsufbechor",
            "mengqiaofa",
            "Zheng-Bicheng",
            "GreatV",
            "ChrisEvans2"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1369,
        "title": "There are some operators not supported yet, including box_coder,density_prior_box,multiclass_nms2",
        "body": "**问题描述**\r\nThere are some operators not supported yet, including box_coder,density_prior_box,multiclass_nms2\r\n不支持的算子 ： box_coder,  density_prior_box,  multiclass_nms2\r\npdmodel版本： paddlepaddle2.5.1\r\n",
        "state": "closed",
        "user": "jiuyuedeyu156",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-08-26T10:03:41+00:00",
        "updated_at": "2024-12-07T02:41:26+00:00",
        "closed_at": "2024-12-07T02:41:25+00:00",
        "comments_count": [
            "jiuyuedeyu156",
            "jiuyuedeyu156",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Operator(New)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1372,
        "title": "为什么model_zoo没有了呢？？？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n为什么model_zoo没有了呢？？？\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n为什么model_zoo没有了呢？？？\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n为什么model_zoo没有了呢？？？\r\n\r\n**其他信息**\r\n为什么model_zoo没有了呢？？？",
        "state": "closed",
        "user": "mjz0110",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-08-31T13:07:09+00:00",
        "updated_at": "2024-09-20T02:34:37+00:00",
        "closed_at": "2024-09-20T02:34:37+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1370,
        "title": "想请问下有预计什么时间支持到paddle3.0吗",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment:\r\n - Why convert to onnx：\r\n - Paddle2ONNX Version:\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\n",
        "state": "closed",
        "user": "David-dotcom666",
        "closed_by": "David-dotcom666",
        "created_at": "2024-08-27T04:48:27+00:00",
        "updated_at": "2025-05-27T14:58:41+00:00",
        "closed_at": "2024-09-05T08:29:04+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "David-dotcom666",
            "Zheng-Bicheng",
            "David-dotcom666",
            "GreatV"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1373,
        "title": "转onnx后 lstm的seq_len 不参与计算",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/user-attachments/assets/8d204bfa-15de-4978-b3bd-6bc5e40a8957)\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "kg-nlp",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-09-04T04:42:31+00:00",
        "updated_at": "2024-12-07T02:41:24+00:00",
        "closed_at": "2024-12-07T02:41:24+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1375,
        "title": "使用paddle2onnx转换mot_ppyoloe_l_36e_pipeline模型到onnx格式，使用onnxruntime加载转换后的onnx模型文件报错。",
        "body": "使用paddle2onnx转换mot_ppyoloe_l_36e_pipeline模型到onnx格式，使用onnxruntime加载转换后的onnx模型文件报错。\r\n\r\n\r\n环境：\r\nubuntu-22.04\r\npaddle2onnx-1.2.8\r\nPaddlePaddle 2.6.1\r\nonnxruntime-1.19.2\r\n\r\n\r\n模型文件地址：\r\nhttps://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip\r\n\r\n\r\n转换命令：\r\npaddle2onnx --model_dir ./person/mot_ppyoloe_l_36e_pipeline \\\r\n\t\t\t--model_filename model.pdmodel \\\r\n\t\t\t--params_filename model.pdiparams \\\r\n\t\t\t--save_file ./person/mot_ppyoloe_l_36e_pipeline/model.onnx \\\r\n\t\t\t--enable_onnx_checker True \r\n\r\n转换命令的输出：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./person/mot_ppyoloe_l_36e_pipeline/model.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./person/mot_ppyoloe_l_36e_pipeline/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including \r\n[Paddle2ONNX] [reduce_mean: mean_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_2.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_3.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] Requires the minimal opset version of 10.\r\n[Paddle2ONNX] Due to the operator: reduce_mean, requires opset_version >= 11.\r\n[Paddle2ONNX] Opset version will change to 11 from 9\r\n[Paddle2ONNX] Use opset_version = 11 for ONNX export.\r\n[WARN][Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] [WARNING] Due to the operator multiclass_nms3, the exported ONNX model will only supports inference with input batch_size == 1.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n\r\n\r\n跟踪到onnxruntime源码内部，为加载模型文件失败，错误信息：\r\n\"Node (p2o.Gather.8) Op (Gather) [ShapeInferenceError] data tensor must have rank >= 1\"\r\n\r\n",
        "state": "closed",
        "user": "leashi",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-09-05T09:45:01+00:00",
        "updated_at": "2025-02-21T02:31:52+00:00",
        "closed_at": "2025-02-21T02:31:50+00:00",
        "comments_count": [
            "188080501",
            "github-actions[bot]",
            "swithmn1",
            "swithmn1",
            "WindLWQ",
            "swithmn1",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1379,
        "title": "python3.8编译paddle2onnx报错",
        "body": "**问题描述**\r\n请在此处详细的描述报错信息\r\n-- Found PythonInterp: C:/Users/Administrator/AppData/Local/Temp/build-env-wzq42xyf/Scripts/python.exe (found suitable version \"3.8.10\", minimum required is \"3.8\")\r\n-- Found Protobuf: D:/Paddle/installed_protobuf_lib/lib/libprotobuf.lib (found version \"3.16.0\")\r\n-- ONNX_PROTOC_EXECUTABLE: D:/Paddle/installed_protobuf_lib/bin/protoc.exe\r\n-- Protobuf_VERSION: 3.16.0\r\nGenerated: C:/Users/Administrator/AppData/Local/Temp/build-via-sdist-gjlj3gqi/paddle2onnx-1.2.8/.setuptools-cmake-build/third_party/onnx/onnx/onnx-ml.proto\r\nGenerated: C:/Users/Administrator/AppData/Local/Temp/build-via-sdist-gjlj3gqi/paddle2onnx-1.2.8/.setuptools-cmake-build/third_party/onnx/onnx/onnx-operators-ml.proto\r\nGenerated: C:/Users/Administrator/AppData/Local/Temp/build-via-sdist-gjlj3gqi/paddle2onnx-1.2.8/.setuptools-cmake-build/third_party/onnx/onnx/onnx-data.proto\r\n--\r\n-- ******** Summary ********\r\n--   CMake version                     : 3.30.3\r\n--   CMake command                     : C:/Users/Administrator/AppData/Local/Temp/build-env-wzq42xyf/Lib/site-packages/cmake/data/bin/cmake.exe\r\n--   System                            : Windows\r\n--   C++ compiler                      : C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe\r\n--   C++ compiler version              : 19.29.30148.0\r\n--   CXX flags                         : /DWIN32 /D_WINDOWS /GR /EHsc /EHsc /wd26812\r\n--   Build type                        : Release\r\n--   Compile definitions               : MAX_ONNX_OPSET_VERSION=19;PADDLE2ONNX_LIB;ONNX_NAMESPACE=onnx;__STDC_FORMAT_MACROS\r\n--   CMAKE_PREFIX_PATH                 :\r\n--   CMAKE_INSTALL_PREFIX              : C:/Program Files/paddle2onnx\r\n--   CMAKE_MODULE_PATH                 :\r\n--\r\n--   ONNX version                      : 1.16.0\r\n--   ONNX NAMESPACE                    : onnx\r\n--   ONNX_USE_LITE_PROTO               : OFF\r\n--   USE_PROTOBUF_SHARED_LIBS          : OFF\r\n--   Protobuf_USE_STATIC_LIBS          : ON\r\n--   ONNX_DISABLE_EXCEPTIONS           : OFF\r\n--   ONNX_DISABLE_STATIC_REGISTRATION  : OFF\r\n--   ONNX_WERROR                       : OFF\r\n--   ONNX_BUILD_TESTS                  : OFF\r\n--   ONNX_BUILD_BENCHMARKS             : OFF\r\n--   ONNX_BUILD_SHARED_LIBS            :\r\n--   BUILD_SHARED_LIBS                 :\r\n--\r\n--   Protobuf compiler                 : D:/Paddle/installed_protobuf_lib/bin/protoc.exe\r\n--   Protobuf includes                 : D:/Paddle/installed_protobuf_lib/include\r\n--   Protobuf libraries                : D:/Paddle/installed_protobuf_lib/lib/libprotobuf.lib\r\n--   BUILD_ONNX_PYTHON                 : OFF\r\n------ BUILD WITH MSVC --------\r\n-- Configuring done (2.9s)\r\n-- Generating done (0.1s)\r\n-- Build files have been written to: C:/Users/Administrator/AppData/Local/Temp/build-via-sdist-gjlj3gqi/paddle2onnx-1.2.8/.setuptools-cmake-build\r\n\r\n\r\n\r\n--------------------------------------------------------------------------------------------------------------------------------------------\r\n执行过程中报错\r\n  tensor_util.cc\r\nLINK : fatal error LNK1104: 无法打开文件“python38.lib” [C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-via-sdist-gjlj3gqi\\pa\r\nddle2onnx-1.2.8\\.setuptools-cmake-build\\paddle2onnx_cpp2py_export.vcxproj]\r\nTraceback (most recent call last):\r\n  File \"D:\\PY38\\lib\\site-packages\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in <module>\r\n    main()\r\n  File \"D:\\PY38\\lib\\site-packages\\pyproject_hooks\\_in_process\\_in_process.py\", line 357, in main\r\n    json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\r\n  File \"D:\\PY38\\lib\\site-packages\\pyproject_hooks\\_in_process\\_in_process.py\", line 271, in build_wheel\r\n    return _build_backend().build_wheel(\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\build_meta.py\", line 421, in build_wheel\r\n    return self._build_with_temp_dir(\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\build_meta.py\", line 403, in _build_with_temp_dir\r\n    self.run_setup()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\r\n    exec(code, locals())\r\n  File \"<string>\", line 191, in <module>\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\__init__.py\", line 117, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 184, in setup\r\n    return run_commands(dist)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 200, in run_commands\r\n    dist.run_commands()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 954, in run_commands\r\n    self.run_command(cmd)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\dist.py\", line 950, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\command\\bdist_wheel.py\", line 384, in run\r\n    self.run_command(\"build\")\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 316, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\dist.py\", line 950, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 135, in run\r\n    self.run_command(cmd_name)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 316, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\dist.py\", line 950, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\r\n    cmd_obj.run()\r\n  File \"<string>\", line 148, in run\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 316, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\dist.py\", line 950, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\build-env-wzq42xyf\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\r\n    cmd_obj.run()\r\n  File \"<string>\", line 143, in run\r\n  File \"D:\\PY38\\lib\\subprocess.py\", line 364, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['C:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Temp\\\\build-env-wzq42xyf\\\\Scripts\\\\cmake.exe', '--build', '.', '--config', 'Release', '--', '/maxcpucount:16']' returned non-zero exit status 1.\r\n\r\nERROR Backend subprocess exited when trying to invoke build_wheel\r\n我尝试把python38.lib路径添加到path中还是报这个错\r\n步骤按照\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/compile_local.md",
        "state": "closed",
        "user": "David-dotcom666",
        "closed_by": "David-dotcom666",
        "created_at": "2024-09-12T03:46:00+00:00",
        "updated_at": "2024-09-12T09:38:28+00:00",
        "closed_at": "2024-09-12T09:38:28+00:00",
        "comments_count": [
            "David-dotcom666",
            "Zheng-Bicheng",
            "David-dotcom666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1393,
        "title": "can't export SLANet with import error",
        "body": "my cmd is paddle2onnx --model_dir output/best_accuracy/  --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file table.onnx --opset_version 16 --enable_onnx_checker True\r\n![image](https://github.com/user-attachments/assets/8436d563-08ae-4e8d-838b-4957948b7208)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/bin/paddle2onnx\", line 5, in <module>\r\n    from paddle2onnx.command import main\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle2onnx/__init__.py\", line 17, in <module>\r\n    from .convert import dygraph2onnx\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle2onnx/convert.py\", line 16, in <module>\r\n    import paddle\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/__init__.py\", line 74, in <module>\r\n    import paddle.distributed.fleet  # noqa: F401\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/__init__.py\", line 17, in <module>\r\n    from .spawn import spawn\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/spawn.py\", line 25, in <module>\r\n    from paddle.distributed.cloud_utils import (\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/cloud_utils.py\", line 17, in <module>\r\n    from paddle.distributed.utils.launch_utils import (\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/utils/launch_utils.py\", line 25, in <module>\r\n    from paddle.distributed.fleet.launch_utils import get_backend_by_compile_flag\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/__init__.py\", line 17, in <module>\r\n    from .base.distributed_strategy import DistributedStrategy\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/base/distributed_strategy.py\", line 25, in <module>\r\n    from paddle.distributed.fleet.utils.log_util import logger\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/utils/__init__.py\", line 17, in <module>\r\n    from . import (  # noqa: F401\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/utils/sequence_parallel_utils.py\", line 22, in <module>\r\n    from paddle.distributed.fleet.meta_parallel import get_rng_state_tracker\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/meta_parallel/__init__.py\", line 27, in <module>\r\n    from .pipeline_parallel import (  # noqa: F401\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/meta_parallel/pipeline_parallel.py\", line 23, in <module>\r\n    from ..meta_optimizers.dygraph_optimizer import HybridParallelOptimizer\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/meta_optimizers/__init__.py\", line 35, in <module>\r\n    from .ps_optimizer import ParameterServerOptimizer  # noqa: F401\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/fleet/meta_optimizers/ps_optimizer.py\", line 19, in <module>\r\n    import paddle.distributed.passes\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/passes/__init__.py\", line 32, in <module>\r\n    from .pipeline_scheduler_pass import *  # noqa: F403\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/passes/pipeline_scheduler_pass/__init__.py\", line 18, in <module>\r\n    from .pipeline_1f1b import Pipeline1F1BPass  # noqa: F401\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/passes/pipeline_scheduler_pass/pipeline_1f1b.py\", line 28, in <module>\r\n    from .pipeline_pass_base import PipelinePassBase\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/passes/pipeline_scheduler_pass/pipeline_pass_base.py\", line 22, in <module>\r\n    from ..pass_utils import set_skip_gc_vars, shadow_var_between_sub_programs\r\nImportError: cannot import name 'shadow_var_between_sub_programs' from 'paddle.distributed.passes.pass_utils' (/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/passes/pass_utils.py)\r\n\r\n",
        "state": "closed",
        "user": "Joker1212",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-09-22T06:48:40+00:00",
        "updated_at": "2024-10-16T09:21:28+00:00",
        "closed_at": "2024-10-16T09:21:28+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1391,
        "title": "SLANetv2 转 onnx 不支持while，什么时候解决呢？或者有没有其他方式可以导出onnx呢？",
        "body": "[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /workspace/models/ch_ppstructure_openatom_SLANetv2_infer/inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: /workspace/models/ch_ppstructure_openatom_SLANetv2_infer/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including while,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1726811834 (unix time) try \"date -d @1726811834\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x33cb51) received by PID 3394385 (TID 0x7ff2b5302740) from PID 3394385 ***]",
        "state": "closed",
        "user": "yoliax",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-09-20T06:00:58+00:00",
        "updated_at": "2024-10-16T09:22:27+00:00",
        "closed_at": "2024-10-16T09:22:21+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "yoliax",
            "yoliax",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1399,
        "title": "【开源任务】Paddle2ONNX适配Paddle IR完成常用模型转化",
        "body": "# 1. 需求背景\r\nONNX是一种开放的深度学习模型交换格式，可让模型在不同平台和框架间无缝转换与部署，Paddle2ONNX开源仓库支持将飞桨的推理模型表示转换到ONNX算子协议以实现对接ONNX生态。飞桨在3.0Beta发布了新一代的中间表示（即Paddle IR），并升级了所有的算子定义形式，取代了2.x版本基于protobuf的中间表示。因此我们期望能够基于飞桨新一代Paddle IR的算子定义，升级Paddle2ONNX中的转换规则，支持Paddle IR 协议下的ONNX模型转换。\r\n# 2. 当前进展\r\n目前在Paddle2ONNX的`test_pir` 分支已经完成了基本的机制建设，包括PIR下对模型文件的解析，输入输出变量对齐，算子的注册机制，获取算子输入、输出、属性，PIR下单测执行等。Resnet50在当前机制下可以正确转化为onnx模型文件，并通过了精度验证。\r\n# 3. 任务划分\r\nPaddle2ONNX适配Paddle IR的模型转化任务按照算子级别进行划分\r\n### 认领方式\r\n**填写Excel表进行认领** 🚩[任务认领登记表](https://docs.qq.com/sheet/DSGhBUVpjZGJMaG1n?tab=BB08J2)🚩\r\n* 每一次认领最多同时认领5个算子转化适配任务，并在一个PR内提交，可多次认领，多个PR提交\r\n* PR提交格式：以`【P2O-PIR】`开头，具体要求请见【[4.8 PR提交](#0)】\r\n* 认领后，超过2周没有提交PR，将重新释放\r\n### 任务要求\r\n1. 完成算子在PIR下的注册，部分算子可能在新旧IR下名称不同，或者是PIR新增的算子，对于新增的算子，需要补充相关的的转化逻辑，可参考[Paddle2ONNX 开发指南](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/Paddle2ONNX_Development_Guide.md)\r\n2. 算子单测完善，同样，对于某些新增的算子，要补充相关的单测\r\n\r\n# 4. 开发流程\r\n## 4.1 本地环境搭建\r\n### protobuf\r\npaddle2onnx编译依赖protobuf，需要先在本地编译安装\r\n```bash\r\ngit clone https://github.com/protocolbuffers/protobuf.git\r\ncd protobuf\r\ngit checkout v4.22.0\r\ngit submodule update --init\r\nmkdir build_source && cd build_source\r\ncmake ../cmake -DCMAKE_INSTALL_PREFIX=`pwd`/installed_protobuf_lib -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\r\nmake -j\r\nmake install\r\nexport PATH=`pwd`/installed_protobuf_lib/bin:${PATH}\r\n```\r\n### paddlepaddle\r\n需要安装paddle最新的日包，满足paddlepaddle>=3.0.0.dev20240923\r\n```bash\r\npython -m pip install --pre paddlepaddle -i https://www.paddlepaddle.org.cn/packages/nightly/cpu/\r\n```\r\n### paddle2onnx\r\n```bash\r\ngit clone -b test_pir https://github.com/PaddlePaddle/Paddle2ONNX.git\r\ncd Paddle2ONNX\r\ngit submodule update --init\r\ngit checkout -b your_branch_name\r\n# build\r\nexport PIP_EXTRA_INDEX_URL=\"https://www.paddlepaddle.org.cn/packages/nightly/cpu/\"\r\npython -m build\r\npython -m pip install dist/paddle2onnx-1.2.6-cp39-cp39-linux_x86_64.whl # wheel包名字可能不同\r\n```\r\n\r\n## <span id=\"3\">4.2 本地环境验证</span>\r\n### 得到模型和参数文件\r\n可通过转化resnet50模型进行测试\r\n```python\r\n# 在./resnet50文件夹下得到model.json和model.pdiparams\r\nimport paddle\r\nmodel = paddle.vision.resnet50()\r\npaddle.jit.save(model, \"./resnet50/model\", [paddle.static.InputSpec([-1, 3, 224, 224], dtype=paddle.float32)])\r\n```\r\n### 使用paddle2onnx转化\r\n```bash\r\npaddle2onnx --model_dir=./resnet50/ \\\r\n    --model_filename=model.pdmodel \\\r\n    --params_filename=model.pdiparams \\\r\n    --save_file=./resnet50/model.onnx \\\r\n    --enable_onnx_checker=True \\\r\n    --opset_version 16\r\n```\r\n如果没有错误发生说明本地环境正常\r\n## 4.3 明确模型中需要支持的算子列表\r\n在当前版本中，保留了对模型Program打印的信息，因此，开始时可以先直接使用paddle2onnx进行转化，当然肯定会有一些问题，但是在输出的日志中可以看到打印的Program信息，可以根据此信息列举该模型使用的所有算子，并完成所有算子的【[4.4算子注册](#1)】和【[4.5单测完善](#2)】\r\n## <span id=\"1\">4.4 算子注册</span>\r\n* 对于Paddle2ONNX中已经支持的算子，在该算子的mapper头文件中增加在PIR下的构造函数，在mapper源文件中通过`REGISTER_PIR_MAPPER` 宏进行注册即可\r\n* 对于没有支持的算子，需要根据[Paddle2ONNX 开发指南](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/Paddle2ONNX_Development_Guide.md)先完成算子mapper的实现工作后再进行注册\r\n#### 确定某算子在Paddle2ONNX中是否已经支持（即存在相应的mapper文件）的方法，以transpose算子为例：\r\n1. 对于以`_` 结尾的算子`xxx_`，其是`xxx`算子的inplace版本，直接去查找`xxx` 算子是否已经支持即可\r\n2. 在Paddle2ONNX中搜索`REGISTER_MAPPER(transpose`，发现找不到完全匹配的\r\n3. 在[Paddle](https://github.com/PaddlePaddle/Paddle)仓库中的`/paddle/phi/ops/yaml/op_compat.yaml` 文件中查找该算子名，如果在能够在其中找到，说明在新旧IR下算子名发生了变化，`transpose` 即属于这种情况，在`op_compat.yaml` 中可以看到其在旧IR下的名字是`transpose2`\r\n4. 在Paddle2ONNX中搜索`REGISTER_MAPPER(transpose2`，找到完全匹配的，说明该`transpose`的转化已经支持，不需要再新增对应的mapper，直接在PIR下注册即可\r\n5. 如果在上面4步中找不到，则说明该算子需要先完成算子mapper的实现工作后再进行注册\r\n\r\n##  <span id=\"2\">4.5 单测完善</span>\r\n* 对于已经实现的算子，一般都已经实现了相关的单测，位于`tests/`文件夹下，并以`test_xxx.py`或者`test_auto_scan_xxx.py`的方式命名，这种情况可以在相关的单测文件中加入`from onnxbase import  _test_with_pir` 并在其中的以`test`为开始的函数上添加`@_test_with_pir` 即可\r\n* 对于新增的算子，或者某算子不存在相关单测，则需要新增单测文件，可参考`tests/test_auto_scan_matmul.py`文件的实现方式，首先创建一个网络结构类`Net`并继承`BaseNet`，实现其`forward`函数，然后创建一个测试类，并继承`OPConvertAutoScanTest`，实现`sample_convert_config`方法和`test`方法。完成后再按照上述添加`@_test_with_pir` 即可\r\n**Note:** 在对某算子对应的单测文件进行完善时，可能会遇到一种情况，该单测中不仅仅涉及你要支持的算子，还涉及其它算子，可以在日志中看到`[Paddle2ONNX] There are some ops not supported yet, including xxx`，此时需要一并支持其它未支持的算子。\r\n\r\n## 4.6 开发示例\r\n可以参考以下PR提供的开发示例进行开发，在该PR中完成了算子xxx的注册，并对相关单测进行了完善。新旧IR下算子的输入、输出、属性等信息可能发生改变，需要适当修改算子的mapper文件\r\n#### [开发示例 PR#1403](https://github.com/PaddlePaddle/Paddle2ONNX/pull/1403)\r\n\r\n#### 算子注册\r\n1. 在头文件中重载PIR下的构造函数\r\n```c++\r\n// paddle2onnx/mapper/tensor/split.h\r\n  SplitMapper(const PaddlePirParser& p, OnnxHelper* helper, int64_t i)\r\n      : Mapper(p, helper, i) {\r\n      in_pir_mode = true;\r\n    // GetAttr(\"axis\", &axis_); \r\n    // GetAttr(\"sections\", &sections_);\r\n    // GetAttr(\"num\", &num_);\r\n  }\r\n```\r\n可以看到上面注释了获取属性`axis`，`sections`和`num`，是因为在PIR下`paddle.split`在模型结构中会以两种算子存在，一种是`pd_op.split`，另一种是`pd_op.split_with_num`，在`pd_op.split\r\n中`axis`和`sections`成为输入，`num` 属性不存在，在`pd_op.split_with_num` 中`axis`是输入，`num` 是属性，而`sections`不存在\r\n\r\n2. 在源文件中完成注册\r\n```c++\r\n// paddle2onnx/mapper/tensor/split.cc\r\nREGISTER_PIR_MAPPER(split, SplitMapper)\r\nREGISTER_PIR_MAPPER(split_with_num, SplitMapper) // split_with_num算子可以复用split的mapper，因此在这同时注册了split_with_num\r\n```\r\n\r\n3. 检查源文件中的转化逻辑，主要根据PIR下算子的输入、输出、属性的变化来调整\r\n主要包括检查`GetMinOpsetVersion`方法和`Opset7` 方法等，如果PIR下算子的输入、输出、属性有变化，需要进行修改。需要注意的是，如果不是新增的算子，`GetInput`、`GetOutput`、`GetAttr`等方法中传入的变量或属性名使用旧IR下的即可，目前已经完成了自动映射的机制\r\n    * 修改可参考`paddle2onnx/mapper/tensor/split.cc` 中的变化\r\n\r\n#### 单测完善\r\n1. 在`paddle2onnx/tests/`目录下找到算子对应的单测文件，一般命名为`test_xxx.py` 和`test_auto_scan_xxx.py`，例如split算子的单测文件为`tests/test_split.py` 和`tests/test_auto_scan_split.py`\r\n2. 在相应的test函数前添加`_test_with_pir`进行测试\r\n```python\r\n# tests/test_split.py\r\nfrom onnxbase import _test_with_pir\r\n....\r\n@_test_with_pir\r\ndef test_split_v7_1():\r\n....\r\n```\r\n\r\n## 4.7 结果验证\r\n<!--\r\n**结果验证包含三部分：**\r\n1. 模型是否成功转化为onnx文件，可参考上面【[本地环境验证](#3)】\r\n4. 转化后模型精度是否和转化前保持一致\r\n2.1 在`tests/`文件夹下编写精度验证脚本`test_check_xxx.py`，**以resnet50模型精度验证为例：**\r\n```python\r\n# test_check_resnet50.py\r\nimport onnx\r\nimport onnxruntime as ort\r\nimport numpy as np\r\nimport paddle \r\n\r\nmodel_path = './resnet50/model.onnx'\r\nonnx_model = onnx.load(model_path)\r\nonnx.checker.check_model(onnx_model)\r\n\r\nsession = ort.InferenceSession(model_path)\r\ninput_name = session.get_inputs()[0].name  # 获取输入节点的名称\r\ndata = np.random.randn(*[1, 3, 224, 224]).astype(np.float32)\r\noutputs = session.run(None, {input_name: data})\r\n\r\nmodel_prefix = './resnet50/model'\r\nloaded_model = paddle.jit.load(model_prefix)\r\nloaded_model.eval()\r\nx = paddle.to_tensor(data)\r\nout= loaded_model(x)\r\nnp.testing.assert_allclose(outputs[0], out.numpy(), rtol=1e-5, atol=1e-5)\r\n```\r\n2.2 测试精度\r\n```bash\r\npython test_check_resnet50.py\r\n```\r\n6. 模型涉及的算子单测完善并通过测试，**以算子conv2d为例：**\r\n```bash\r\npython -m pytest test_nn_Conv2D.py\r\npython -m pytest test_auto_scan_conv2d.py\r\n```\r\n-->\r\n保证算子的单测已完善并通过本地测试，**以算子conv2d为例：**\r\n```bash\r\npython -m pytest test_nn_Conv2D.py\r\npython -m pytest test_auto_scan_conv2d.py\r\n```\r\n\r\n## <span id=\"0\">4.8 PR提交格式要求</span>\r\n1. PR标题需要以`【P2O-PIR】`开头，并写明适配的算子名称\r\n6. 在PR描述中列举本PR适配的算子名称，并说明该算子是否是新增算子以及其对应的单测文件\r\n7. 有一些特殊情况或者你认为重要的信息请在PR中一并描述\r\n",
        "state": "closed",
        "user": "0x3878f",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-09-25T13:01:08+00:00",
        "updated_at": "2024-12-07T02:41:21+00:00",
        "closed_at": "2024-12-07T02:41:20+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1396,
        "title": "RTFormer 转onnx格式在paddle2.6版本下一致，paddle3.0beta版本不一致",
        "body": "paddlepaddle-gpu：3.0.0b1\r\npaddle2onnx：1.2.9\r\nPaddleSeg：2.9.0\r\n\r\nRTFormer转onnx格式输出结果不一致，使用随机数作为输入，使用PaddleSeg提供预训练模型转换。paddle2.6版本下是一致的。\r\n",
        "state": "closed",
        "user": "mandylyin",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-09-25T02:30:35+00:00",
        "updated_at": "2024-12-07T02:41:22+00:00",
        "closed_at": "2024-12-07T02:41:21+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1398,
        "title": "请教大家一个问题，我在使用paddlespeech的kws时，想把模型转为静态图或者onnx，均出现以下报错，要怎么解决才能导出模型？",
        "body": "请教大家一个问题，我在使用paddlespeech的kws时，想把模型转为静态图或者onnx，均出现以下报错，要怎么解决才能导出模型？\r\n![image](https://github.com/user-attachments/assets/ec4857f8-59f1-494f-a1a8-a876932913c1)\r\n",
        "state": "closed",
        "user": "eli-zheng-ubtech",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-09-25T09:42:39+00:00",
        "updated_at": "2024-11-22T03:06:16+00:00",
        "closed_at": "2024-11-22T03:06:11+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1400,
        "title": "ppocr4 paddle转onnx模型后在cpu上的推理速度远大于在gpu的推理速度",
        "body": "用下面的三个命令生成ppocr4的onnx模型后，用cuda providers推理的速度很慢，用cpu providers推理的速度更快一些，请问是什么原因导致的呢？\r\n\r\npaddle2onnx命令：\r\n\r\npaddle2onnx --model_dir ch_PP-OCRv4_det_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ppocr4_det_0926.onnx --opset_version 16 --enable_onnx_checker True\r\n\r\npaddle2onnx --model_dir ch_PP-OCRv4_rec_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ppocr4_rec_0926.onnx --opset_version 16 --enable_onnx_checker True \r\n\r\npaddle2onnx --model_dir ch_ppocr_mobile_v2.0_cls_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ppocr4_cls_0926.onnx --opset_version 16 --enable_onnx_checker True\r\n\r\n",
        "state": "closed",
        "user": "Number18-tong",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-09-27T07:08:55+00:00",
        "updated_at": "2025-01-31T02:27:59+00:00",
        "closed_at": "2025-01-31T02:27:58+00:00",
        "comments_count": [
            "zaixia108",
            "zaixia108",
            "carlos-yuan",
            "zaixia108",
            "carlos-yuan",
            "zaixia108",
            "github-actions[bot]",
            "zaixia108",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1404,
        "title": "PaddleOCR量化模型转onnx报错",
        "body": "使用官网提供的模型，如下所示：\r\n![image](https://github.com/user-attachments/assets/f90a4a24-a56c-49f1-a4bf-d7ab802c6f1b)\r\n\r\n**问题描述**\r\n使用下述指令转换：\r\n`paddle2onnx --model_dir . --model_filename inference.pdmodel --params_filename inference.pdiparams --deploy_backend onnxruntime --save_file ./rec_slim.onnx --opset_version 11 --enable_onnx_checker True`\r\n\r\n - Paddle2ONNX版本 : 1.2.9\r\n\r\n**报错截图**\r\n\r\n![image](https://github.com/user-attachments/assets/ec6beb47-32be-419e-8a20-33bb86471ccb)\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "xdd130",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-10-11T08:35:34+00:00",
        "updated_at": "2025-06-11T07:51:35+00:00",
        "closed_at": "2025-01-06T02:36:15+00:00",
        "comments_count": [
            "xdd130",
            "Zheng-Bicheng",
            "xdd130",
            "github-actions[bot]",
            "github-actions[bot]",
            "yikoudamifan"
        ],
        "labels": [
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1405,
        "title": "SLANet_plus表格模型无法转换",
        "body": "在转换paddlex中的SLANet_plus表格模型，无法转换为onnx，提示常量算子好像不支持\r\n![image](https://github.com/user-attachments/assets/6fa13968-461e-4713-b5ee-8b524a9a924d)\r\n\r\n\r\naistudio@jupyter-11515527-8327948:~$ paddle2onnx --model_dir ./ --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./table.onnx --opset_version 16 --enable_onnx_checker True\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including while,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n",
        "state": "closed",
        "user": "Joker1212",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-13T08:44:20+00:00",
        "updated_at": "2024-10-16T09:22:54+00:00",
        "closed_at": "2024-10-16T09:22:54+00:00",
        "comments_count": [
            "Joker1212",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1413,
        "title": "LaTeX_OCR_rec 模型无法转换",
        "body": "[Paddle2ONNX] Oops, there are some operators not supported yet, including multinomial,put_along_axis,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.",
        "state": "closed",
        "user": "sorehadokanajw",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-10-18T04:55:50+00:00",
        "updated_at": "2024-12-07T02:41:19+00:00",
        "closed_at": "2024-12-07T02:41:19+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1411,
        "title": "导出一直报错IndexError: Input undefined_var_1 is undefined!，不管用什么linux系统，确认了没有少参数",
        "body": "\r\n[models.zip](https://github.com/user-attachments/files/17397516/models.zip)\r\n\r\n开始使用\r\npaddlepaddle==3.0.0b1\r\npaddle2onnx==2.1.10\r\n![image](https://github.com/user-attachments/assets/5821001d-23e4-49ec-ba52-944089a8aad4)\r\n将paddle2onnx换1.2.9，同样的命令就没有这个报错，还是之前的while算子问题\r\n![image](https://github.com/user-attachments/assets/4fac33e2-8355-4eb6-b691-6263ac358941)\r\n\r\n模型是paddlex的slanet_plus https://github.com/PaddlePaddle/PaddleX/blob/release/3.0-beta1/docs/module_usage/tutorials/ocr_modules/table_structure_recognition.md\r\n\r\n",
        "state": "closed",
        "user": "Joker1212",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-16T14:19:22+00:00",
        "updated_at": "2024-10-17T06:28:58+00:00",
        "closed_at": "2024-10-17T06:28:58+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Joker1212",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Joker1212"
        ],
        "labels": [
            "Operator(Update)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1414,
        "title": "how to convert model using python code",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\nI don't want to use paddle2onnx command line, How to use it using python code, thank you\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "tvone",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-18T16:55:07+00:00",
        "updated_at": "2024-10-28T02:01:13+00:00",
        "closed_at": "2024-10-28T02:01:13+00:00",
        "comments_count": [
            "jzhang533"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1415,
        "title": "自己微调的模型转换为onnx报错Oops, there are some operators not supported yet, including isnan_v2,[ERROR] Due to the unsupported operators, the conversion is aborted.",
        "body": "**问题描述**\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including isnan_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n",
        "state": "closed",
        "user": "RicardaY",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-20T03:42:58+00:00",
        "updated_at": "2024-10-28T01:50:09+00:00",
        "closed_at": "2024-10-28T01:50:03+00:00",
        "comments_count": [
            "Billybeast2003",
            "RicardaY",
            "GreatV",
            "RicardaY"
        ],
        "labels": [
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1418,
        "title": "什么时候pip可以下载最新版的paddle2onnx python库呢，现在最新是1.0.6",
        "body": null,
        "state": "closed",
        "user": "CvBokchoy",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-23T07:21:44+00:00",
        "updated_at": "2024-11-22T02:50:12+00:00",
        "closed_at": "2024-11-20T11:37:06+00:00",
        "comments_count": [
            "188080501",
            "CvBokchoy",
            "188080501",
            "CvBokchoy",
            "Zheng-Bicheng",
            "longer95",
            "188080501",
            "Zheng-Bicheng",
            "Zheng-Bicheng"
        ],
        "labels": [
            "Bug",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1417,
        "title": "[ERROR] Cannot found attribute threshold in op: relu6",
        "body": "在使用paddle2onnx过程中报错 [ERROR] Cannot found attribute threshold in op: relu6，我的paddle版本2.6.1 paddle2onnx版本为paddle2onnx     1.0.6， 我看到现在最新版本是1.2.11版本的，并且在lssues区看见在新版中该bug已经修复，但是我用源码编译安装频频出错，用pip的方式安装最高能安装到1.0.6的版本，求解，求大神指导 谢谢！ 最好可以提供一个whl也可以 我是python3.8",
        "state": "closed",
        "user": "CvBokchoy",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-10-22T08:43:15+00:00",
        "updated_at": "2024-11-22T07:30:26+00:00",
        "closed_at": "2024-11-20T11:37:06+00:00",
        "comments_count": [
            "CvBokchoy",
            "Zheng-Bicheng",
            "CvBokchoy"
        ],
        "labels": [
            "Bug",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1423,
        "title": "请问Paddle2ONNX可以配合哪一个PaddleDetection模型使用？",
        "body": "我尝试了 PP-YOLOE_plus-L和YOLOX-L模型，可以正常导出ONNX，但是加载运行时报错\r\nOp (Gather) [ShapeInferenceError] data tensor must have rank >= 1\"\r\n\r\n尝试多个方法都无法解决这个问题，也有其他人提了同个issuse，如下：\r\nhttps://github.com/PaddlePaddle/Paddle2ONNX/issues/1375\r\n\r\n然后我尝试了FasterRCNN-ResNet101模型，但是转换时报错，无法正常得到onnx文件\r\nLodTensorArray is not supported.\r\n\r\n\r\nPaddle2ONNX已经使用了最新版本1.2.11\r\nPaddleX训练的模型，使用的是3.0-beta1\r\n\r\n\r\n所以请教一下，如果我想ONNX做目标检测，我应该使用哪个模型？或者说是我参数错误导致？",
        "state": "closed",
        "user": "188080501",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-11-05T10:31:39+00:00",
        "updated_at": "2025-06-09T05:17:32+00:00",
        "closed_at": "2024-11-22T03:33:26+00:00",
        "comments_count": [
            "188080501",
            "188080501",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "188080501",
            "Zheng-Bicheng",
            "188080501",
            "Zheng-Bicheng",
            "188080501",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "188080501",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "188080501",
            "188080501",
            "tsrdsy",
            "188080501",
            "yikoudamifan",
            "188080501",
            "yikoudamifan",
            "tsrdsy",
            "moliwei2019",
            "188080501",
            "yikoudamifan",
            "188080501",
            "yikoudamifan",
            "188080501",
            "Hold-on-li",
            "Hold-on-li",
            "188080501",
            "Hold-on-li"
        ],
        "labels": [
            "Bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1432,
        "title": "在使用导出的onnx模型推理是报错：0th dimension != 279",
        "body": "**环境**\r\n\r\n - PaddlePaddle 2.6.1\r\n - Ubuntu 22.04\r\n - Paddle2ONNX 1.2.11\r\n - onnxruntime 1.19.2\r\n\r\n**问题描述**\r\n\r\n在使用onnxrunime推理的是报错，错误信息如下：\r\n```\r\n    return self._sess.run(output_names, input_feed, run_options)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status \r\ncode returned while running BatchNormalization node. Name:'BatchNormalization.2' Status Message: Invalid input scale: 0th dimension != 279\r\n```\r\n\r\n\r\n**更多信息 :**\r\n\r\n导出模型的命令：\r\n```\r\npaddle2onnx --model_dir models/inference/ \\\r\n            --model_filename model.pdmodel \\\r\n            --params_filename model.pdiparams \\\r\n            --save_file models/inference/model.onnx \\\r\n            --opset_version 16\r\n```\r\n\r\n使用PaddleInference推理正常。\r\n\r\n使用到的BatchNorm有三个：\r\n```python \r\nself.bn = nn.BatchNorm2D(num_channels_out, data_format='NCHW')\r\n······\r\nself.bn = nn.BatchNorm1D(rnn_layer_size * 2, data_format='NLC')\r\n······\r\nself.bn = nn.BatchNorm1D(hidden_size, data_format='NLC')\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-17T09:28:51+00:00",
        "updated_at": "2025-01-08T02:31:16+00:00",
        "closed_at": "2025-01-08T02:31:16+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "yeyupiaoling",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "Operator(Update)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1428,
        "title": "pintrend导出onnx模型精度问题",
        "body": "训练好的pointrend模型使用官方的额export_onnx.py导出onnx发现在np.testing.assert_allclose(onnx_out, paddle_out, rtol=0, atol=1e-03)报错，代码如下，也使用了paddle2onnx来导出模型实测发现精度不一致\r\n\r\ndef export_onnx(args):\r\nargs.config = '/workspace/PaddleSeg/configs/pointrend/pointrend_resnet50_os8_voc12aug_512x512_40k.yml'\r\nargs.model_path = '/workspace/PaddleSeg/output/best_model118/model.pdparams'\r\nargs.width = 800\r\nargs.height = 640\r\nassert args.config is not None,\r\n'Please set --config path/to/yml'\r\ncfg = Config(args.config)\r\nbuilder = SegBuilder(cfg)\r\nmodel = builder.model\r\nif args.model_path is not None:\r\nutils.load_entire_model(model, args.model_path)\r\nlogger.info('Loaded trained params of model successfully')\r\n\r\nmodel.eval()\r\nif args.print_model:\r\n    print(model)\r\n\r\ninput_shape = [1, 3, args.height, args.width]\r\nprint(\"input shape:\", input_shape)\r\ninput_data = np.random.random(input_shape).astype('float32')\r\nmodel_name = os.path.basename(args.config).split(\".\")[0]\r\n\r\npaddle_out = run_paddle(model, input_data)\r\nprint(\"out shape:\", paddle_out.shape)\r\nprint(\"The paddle model has been predicted by PaddlePaddle.\\n\")\r\n\r\ninput_spec = paddle.static.InputSpec(input_shape, 'float32', 'x')\r\nonnx_model_path = os.path.join(args.save_dir, model_name + \"_model\")\r\npaddle.onnx.export(\r\n    model, onnx_model_path, input_spec=[input_spec], opset_version=11)\r\nprint(\"Completed export onnx model.\\n\")\r\n\r\nonnx_model_path = onnx_model_path + \".onnx\"\r\nonnx_out = check_and_run_onnx(onnx_model_path, input_data)\r\nassert onnx_out.shape == paddle_out.shape\r\nnp.testing.assert_allclose(onnx_out, paddle_out, rtol=0, atol=1e-03)\r\nprint(\"The paddle and onnx models have the same outputs.\\n\")\r\n",
        "state": "closed",
        "user": "aiwenzhu",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-12T06:54:23+00:00",
        "updated_at": "2024-12-29T02:37:55+00:00",
        "closed_at": "2024-12-29T02:37:54+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "aiwenzhu",
            "Jiang-Jia-Jun",
            "aiwenzhu",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1431,
        "title": "rust burn加载ppocrv4转onnx 报错",
        "body": "转换出来以后也不能直接加载会报Nodes are not topologically sorted，然后需要优化。\r\n由于名称问题会报\"learnable_affine_block_0.w_0\" is not a valid Ident。这是因为变量出现了 .  ，修改源码修复问题以后。\r\n加载会出这个问题 Unsupported input dim (1) for GlobalAvgPoolNode\r\n![image](https://github.com/user-attachments/assets/fa1d66c5-0023-4286-901c-d59f5e3c53b9)\r\n由于初学没搞懂这是什么原因，这里维度只有1，但是框架要求的维度需要3或者4。",
        "state": "closed",
        "user": "carlos-yuan",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-14T02:17:12+00:00",
        "updated_at": "2024-12-29T02:37:54+00:00",
        "closed_at": "2024-12-29T02:37:53+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1436,
        "title": "PULC 模型转换报错",
        "body": "PULC 模型：https://github.com/PaddlePaddle/PaddleClas/blob/release/2.5/docs/zh_CN/models/PULC/PULC_text_image_orientation.md\r\n报错信息如下\r\nTraceback (most recent call last):\r\n  File \"/usr/local/python/bin/paddle2onnx\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/python/lib/python3.8/site-packages/paddle2onnx/command.py\", line 145, in main\r\n    paddle2onnx.export(\r\n  File \"/usr/local/python/lib/python3.8/site-packages/paddle2onnx/convert.py\", line 41, in export\r\n    onnx_model_str = c_p2o.export(\r\nIndexError: Input conv2d_0.w_0 is undefined!",
        "state": "closed",
        "user": "xxxyyycc",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-19T04:18:00+00:00",
        "updated_at": "2025-01-04T02:28:35+00:00",
        "closed_at": "2025-01-04T02:28:34+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "xxxyyycc",
            "Zheng-Bicheng",
            "xxxyyycc",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleClas",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1440,
        "title": "时序分类模块（TimesNet_cls），缺少算子转换失败",
        "body": "我的Paddle2ONNX版本是：paddle2onnx-1.2.11 with python>=3.8, paddlepaddle>=2.0.0\r\n\r\n转换命令和log如下：\r\n paddle2onnx --model_dir ./ --model_filename inference.pdmodel --params_filename inference.pdiparams  --save_file model.onnx\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including fft_r2c,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\nC++ Traceback (most recent call last):\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\nError Message Summary:\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1732086981 (unix time) try \"date -d @1732086981\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e8000033b9) received by PID 13241 (TID 0x7fd443546740) from PID 13241 ***]\r\n\r\nAborted (core dumped)\r\n\r\n\r\n请问后续有这个支持计划吗？支持这个模型或者说支持这个算子\r\n",
        "state": "closed",
        "user": "188080501",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-11-20T08:26:15+00:00",
        "updated_at": "2024-11-22T03:35:34+00:00",
        "closed_at": "2024-11-22T03:35:34+00:00",
        "comments_count": [
            "188080501",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "188080501"
        ],
        "labels": [
            "Operator(New)"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1441,
        "title": "使用paddle2onnx将量化后的ppyoloe_plus_s导出为onnx后，onnxruntime推理结果与paddle静态图推理不符",
        "body": "**问题描述**\r\n\r\n根据PaddleDetection提供的[模型压缩文档](https://github.com/PaddlePaddle/PaddleDetection/blob/8377e846439a709f5ab3ac6948d768221b5cf1e6/configs/slim/README.md)，我将训练好的ppyoloe plus s模型进行量化训练。量化后的模型，以及导出为paddle静态图模型均推理无误。\r\n\r\n但使用paddle2onnx将量化后的模型导出为onnx后，使用onnxruntime推理，无法得到任何检测框（使用paddle静态图推理可得到多个）\r\n\r\n**使用环境**\r\n\r\n使用的环境如下：\r\n`paddle2onnx == 1.2.11`\r\n`paddledet == develop (>= 2.8.0)`\r\n`paddlepaddle-gpu == 2.6.1.post116`\r\n`paddleslim == 2.6.0`\r\n`onnxruntime == 1.19.2`\r\n`onnxruntime-gpu == 1.19.2`\r\n\r\n**paddle静态模型及onnx文件**\r\n\r\n[ppyoloe_s_qat_abnormal_object.zip](https://github.com/user-attachments/files/17830407/ppyoloe_s_qat_abnormal_object.zip)\r\n\r\n**错误详情**\r\n\r\n原图：\r\n![yiwu](https://github.com/user-attachments/assets/c8870621-cc69-4d49-a99d-c0f8f87f47b3)\r\npaddle静态图推理效果：\r\n![visualized_result](https://github.com/user-attachments/assets/657f4516-e9f8-4dce-ae3f-a44592f811ef)\r\n\r\n在使用以下命令，导出为onnx文件\r\n```bash\r\npaddle2onnx --model_dir /mnt/data01/wzj/code/PaddleDetection-develop/export/ppyoloe_s_data1118_quant_lr0000125/ppyoloe_s_qat_abnormal_object \\\r\n            --model_filename model.pdmodel \\\r\n            --params_filename model.pdiparams \\\r\n            --save_file /mnt/data01/wzj/code/PaddleDetection-develop/export/ppyoloe_s_data1118_quant_lr0000125/ppyoloe_s_qat_abnormal_object/ppyoloe_s_qat_241118.onnx\r\n```\r\n输出结果：\r\n```bash\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /mnt/data01/wzj/code/PaddleDetection-develop/export/ppyoloe_s_data1118_quant_lr0000125/ppyoloe_s_qat_abnormal_object/model.pdmodel\r\n[Paddle2ONNX] Parameters file path: /mnt/data01/wzj/code/PaddleDetection-develop/export/ppyoloe_s_data1118_quant_lr0000125/ppyoloe_s_qat_abnormal_object/model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] [Info] The Paddle model is a quantized model. \r\n[Paddle2ONNX] [reduce_mean: mean_0.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_1.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_2.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [reduce_mean: mean_3.tmp_0] Requires the minimal opset version of 11.\r\n[Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] Requires the minimal opset version of 10.\r\n[Paddle2ONNX] Due to the operator: dequantize_linear, requires opset_version >= 13.\r\n[Paddle2ONNX] Opset version will change to 13 from 9\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[WARN][Paddle2ONNX] [multiclass_nms3: multiclass_nms3_0.tmp_1] [WARNING] Due to the operator multiclass_nms3, the exported ONNX model will only supports inference with input batch_size == 1.\r\n[Paddle2ONNX] Deploy backend is: onnxruntime\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n```\r\n\r\n然而使用onnxruntime对导出的onnx文件推理，结果中没有任何检测框。请问是将量化后的模型导出时，哪里有精度丢失问题吗？非量化的模型按照此流程导出没有任何问题",
        "state": "closed",
        "user": "EvW1998",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-20T12:45:09+00:00",
        "updated_at": "2025-02-10T02:31:34+00:00",
        "closed_at": "2025-02-10T02:31:32+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "EvW1998",
            "Zheng-Bicheng",
            "EvW1998",
            "Zheng-Bicheng",
            "EvW1998",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "EvW1998",
            "Zheng-Bicheng",
            "EvW1998",
            "WindLWQ",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1442,
        "title": "CPPD模型导出onnx模型后精度损失较大",
        "body": "**问题描述**\r\n我使用的是文本识别模型CPPD_base_ch，在同一批图片上进行文本识别：\r\n - tools/infer_rec.py使用best_accuracy.pdparams进行预测\r\n - 导出onnx模型后\r\n - tools/infer/predict_rec.py使用onnx模型进行推理\r\n - 二者得到的结果差别很大，且onnx推理结果置信度都较低，有较大精度损失\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: onnxruntim\r\n - 为什么需要转换为ONNX格式：玩\r\n - Paddle2ONNX版本: lastest\r\n - 你的联系方式(Email/Wechat/Phone): ezlifesen@outlook.com\r\n\r\n**报错截图**\r\nonnx推理：\r\n![image](https://github.com/user-attachments/assets/d01e75d3-fa3e-4602-85ec-8710fe5c1bf7)\r\npdparam预测：\r\n![image](https://github.com/user-attachments/assets/62377c27-bbe2-45c2-a7f2-36b8cb54481e)\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "EzcodingSen",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-21T09:10:18+00:00",
        "updated_at": "2025-01-06T02:36:14+00:00",
        "closed_at": "2025-01-06T02:36:13+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/X2Paddle",
        "number": 1100,
        "title": "Exception: Paddle>=2.0.0 is required, Please update version!",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nx2paddle --framework onnx --model /home/zhengxinjiang/code/DeepFilterNet-main/torchDF/denoiser_model.onnx -save_dir pd_model\r\n转模型的时候发生version报错\r\n\r\n**更多信息 :**\r\n\r\n\r\n**报错截图**\r\nTraceback (most recent call last):\r\n  File \"/home/zhengxinjiang/anaconda3/envs/py3.8/bin/x2paddle\", line 5, in <module>\r\n    from x2paddle.convert import main\r\n  File \"/home/zhengxinjiang/anaconda3/envs/py3.8/lib/python3.8/site-packages/x2paddle/convert.py\", line 17, in <module>\r\n    from x2paddle.utils import ConverterCheck\r\n  File \"/home/zhengxinjiang/anaconda3/envs/py3.8/lib/python3.8/site-packages/x2paddle/utils.py\", line 112, in <module>\r\n    paddle_dtypes = PaddleDtypes(is_new_version)\r\n  File \"/home/zhengxinjiang/anaconda3/envs/py3.8/lib/python3.8/site-packages/x2paddle/utils.py\", line 108, in __init__\r\n    raise Exception(\"Paddle>=2.0.0 is required, Please update version!\")\r\nException: Paddle>=2.0.0 is required, Please update version!\r\n\r\n**其他信息**\r\nPackage                  Version\r\n------------------------ --------------\r\nabsl-py                  1.4.0\r\naiofiles                 23.1.0\r\naiohttp                  3.8.4\r\naiosignal                1.3.1\r\naltair                   4.2.2\r\nanyio                    3.6.2\r\nappdirs                  1.4.4\r\nastor                    0.8.1\r\nasync-timeout            4.0.2\r\nattrs                    22.2.0\r\naudioread                3.0.0\r\ncachetools               5.3.0\r\ncertifi                  2022.12.7\r\ncffi                     1.15.1\r\nchardet                  5.1.0\r\ncharset-normalizer       3.0.1\r\nclick                    8.1.3\r\ncloudpickle              2.2.1\r\ncmake                    3.26.3\r\ncolorama                 0.4.6\r\ncontextlib2              21.6.0\r\ncontourpy                1.0.7\r\ncycler                   0.11.0\r\ndecorator                5.1.1\r\ndnspython                2.3.0\r\neinops                   0.6.0\r\nentrypoints              0.4\r\nfastapi                  0.95.0\r\nffmpy                    0.3.0\r\nfilelock                 3.10.0\r\nfonttools                4.38.0\r\nfrozenlist               1.3.3\r\nfsspec                   2023.3.0\r\nftfy                     6.1.1\r\nfuture                   0.18.3\r\ngoogle-auth              2.16.1\r\ngoogle-auth-oauthlib     0.4.6\r\ngradio                   3.25.0\r\ngradio_client            0.1.0\r\ngrpcio                   1.51.3\r\nh11                      0.14.0\r\nhttpcore                 0.17.0\r\nhttpx                    0.24.0\r\nhuggingface-hub          0.13.4\r\nhyperopt                 0.1.2\r\nidna                     3.4\r\nimportlib-metadata       6.0.0\r\nimportlib-resources      5.12.0\r\nJinja2                   3.1.2\r\njoblib                   1.2.0\r\njson-tricks              3.16.1\r\njsonschema               4.17.3\r\nkiwisolver               1.4.4\r\nlibrosa                  0.9.2\r\nlinkify-it-py            2.0.0\r\nlit                      16.0.1\r\nllvmlite                 0.39.1\r\nMarkdown                 3.4.1\r\nmarkdown-it-py           2.2.0\r\nMarkupSafe               2.1.2\r\nmatplotlib               3.7.0\r\nmdit-py-plugins          0.3.3\r\nmdurl                    0.1.2\r\nmpmath                   1.3.0\r\nmsgpack                  1.0.4\r\nmultidict                6.0.4\r\nnetworkx                 3.0\r\nnni                      2.10\r\nnumba                    0.56.4\r\nnumpy                    1.23.5\r\nnvidia-cublas-cu11       11.10.3.66\r\nnvidia-cuda-cupti-cu11   11.7.101\r\nnvidia-cuda-nvrtc-cu11   11.7.99\r\nnvidia-cuda-runtime-cu11 11.7.99\r\nnvidia-cudnn-cu11        8.5.0.96\r\nnvidia-cufft-cu11        10.9.0.58\r\nnvidia-curand-cu11       10.2.10.91\r\nnvidia-cusolver-cu11     11.4.0.1\r\nnvidia-cusparse-cu11     11.7.4.91\r\nnvidia-nccl-cu11         2.14.3\r\nnvidia-nvtx-cu11         11.7.91\r\noauthlib                 3.2.2\r\nolefile                  0.46\r\nopt-einsum               3.3.0\r\norjson                   3.8.10\r\npackaging                23.0\r\npaddlepaddle             3.0.0b1\r\npandas                   1.5.3\r\nPillow                   9.4.0\r\npip                      22.3.1\r\npkgutil_resolve_name     1.3.10\r\npooch                    1.6.0\r\nprettytable              3.6.0\r\nprogressbar              2.5\r\nprotobuf                 4.22.0\r\npsutil                   5.9.4\r\npyasn1                   0.4.8\r\npyasn1-modules           0.2.8\r\npycparser                2.21\r\npydantic                 1.10.7\r\npydub                    0.25.1\r\npymongo                  4.3.3\r\npyparsing                3.0.9\r\npyrsistent               0.19.3\r\npython-dateutil          2.8.2\r\npython-multipart         0.0.6\r\nPythonWebHDFS            0.2.3\r\npytorch-lightning        1.2.0\r\npytz                     2022.7.1\r\nPyYAML                   6.0\r\nregex                    2023.3.23\r\nrequests                 2.28.2\r\nrequests-oauthlib        1.3.1\r\nresampy                  0.4.2\r\nresponses                0.23.1\r\nrsa                      4.9\r\nschema                   0.7.5\r\nscikit-learn             1.2.1\r\nscipy                    1.10.1\r\nsemantic-version         2.10.0\r\nsetuptools               65.6.3\r\nsimplejson               3.18.4\r\nsix                      1.16.0\r\nsniffio                  1.3.0\r\nsoundfile                0.12.1\r\nstarlette                0.26.1\r\nsympy                    1.11.1\r\ntensorboard              2.12.0\r\ntensorboard-data-server  0.7.0\r\ntensorboard-plugin-wit   1.8.1\r\nthreadpoolctl            3.1.0\r\ntokenizers               0.13.3\r\ntoolz                    0.12.0\r\ntorch                    1.10.0+cu111\r\ntorchaudio               0.10.0+rocm4.1\r\ntorchlibrosa             0.0.9\r\ntorchvision              0.11.0+cu111\r\ntqdm                     4.64.1\r\ntransformers             4.27.4\r\ntriton                   2.0.0\r\ntypeguard                2.13.3\r\ntypes-PyYAML             6.0.12.8\r\ntyping_extensions        4.5.0\r\nuc-micro-py              1.0.1\r\nurllib3                  1.26.14\r\nuvicorn                  0.21.1\r\nwcwidth                  0.2.6\r\nwebsockets               10.4\r\nWerkzeug                 2.2.3\r\nwheel                    0.38.4\r\nx2paddle                 1.5.0\r\nyarl                     1.8.2\r\nzipp                     3.14.0\r\n",
        "state": "closed",
        "user": "zxj329",
        "closed_by": "luotao1",
        "created_at": "2024-11-19T12:34:44+00:00",
        "updated_at": "2025-01-15T03:36:26+00:00",
        "closed_at": "2025-01-15T03:36:25+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "megemini",
            "luotao1"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1447,
        "title": "pip install Paddle2ONNX发生错误",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\npip install paddle2onnx 发生错误\r\n\r\n电脑：M1 pro MacbookPro\r\nconda环境：\r\nPython 3.12 \r\npaddlepaddle==2.6.2\r\nonnxruntime==1.20.1\r\n\r\n\r\n**报错截图**\r\n<img width=\"2025\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b8741d02-9cf4-4e93-aa10-9983ff9312c6\">\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "IceSugarLemon",
        "closed_by": "IceSugarLemon",
        "created_at": "2024-11-28T06:46:06+00:00",
        "updated_at": "2024-11-29T01:33:24+00:00",
        "closed_at": "2024-11-29T01:33:03+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "IceSugarLemon"
        ],
        "labels": [
            "CI",
            "Build"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1448,
        "title": "导出提示Oops, there are some operators not supported yet, including prior_box,",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n模型下载地址：https://paddle-model-ecology.bj.bcebos.com/model/insight-face/mobileface_v1.0_infer.tar\r\n导出报错\r\n paddle2onnx --model_dir /Users/xxx/Downloads/blazeface_fpn_ssh_1000e_v1.0_infer             --model_filename inference.pdmodel             --params_filename inference.pdiparams                --save_file inference.onnx\r\n<img width=\"610\" alt=\"image\" src=\"https://github.com/user-attachments/assets/51143f3c-4e2e-4cb4-bf79-d3237b45d30c\">\r\n\r\n\r\n\r\n\r\n**更多信息 :**\r\n - Paddle2ONNX版本:1.3.1\r\n - Cpu:M1pro\r\n - 系统:macos 15\r\n - python 3.12\r\n",
        "state": "closed",
        "user": "IceSugarLemon",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-11-29T02:30:53+00:00",
        "updated_at": "2025-01-12T02:38:51+00:00",
        "closed_at": "2025-01-12T02:38:50+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1449,
        "title": "paddle2onnx >= 1.2.0 转换PPOCRv4模型失败",
        "body": "**Describe the bug**\r\n利用paddle2onnx转换PPOCRv4模型（det和rec推理模型，由https://paddlepaddle.github.io/PaddleOCR/latest/ppocr/model_list.html下载）\r\npaddle版本2.6.2\r\n命令：paddle2onnx --model_dir ch_PP-OCRv4_rec_infer --model_filename inference.pdmodel --params_filename inference.pdiparams --opset_version 16 --save_file ch_PP-OCRv4_rec_infer.onnx\r\n\r\npaddle2onnx版本1.1.0： 转换成功\r\npaddle2onnx版本1.2.0及以上：转换失败，报错如下\r\n  File \"/home/theo/anaconda3/envs/paddleocr/bin/paddle2onnx\", line 5, in <module>\r\n    from paddle2onnx.command import main\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle2onnx/__init__.py\", line 15, in <module>\r\n    from .convert import export\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle2onnx/convert.py\", line 16, in <module>\r\n    import paddle\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/__init__.py\", line 74, in <module>\r\n    import paddle.distributed.fleet  # noqa: F401\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/__init__.py\", line 17, in <module>\r\n    from .spawn import spawn\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/spawn.py\", line 25, in <module>\r\n    from paddle.distributed.cloud_utils import (\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/cloud_utils.py\", line 17, in <module>\r\n    from paddle.distributed.utils.launch_utils import (\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/utils/launch_utils.py\", line 25, in <module>\r\n    from paddle.distributed.fleet.launch_utils import get_backend_by_compile_flag\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/__init__.py\", line 17, in <module>\r\n    from .base.distributed_strategy import DistributedStrategy\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/base/distributed_strategy.py\", line 25, in <module>\r\n    from paddle.distributed.fleet.utils.log_util import logger\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/utils/__init__.py\", line 17, in <module>\r\n    from . import (  # noqa: F401\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/utils/sequence_parallel_utils.py\", line 22, in <module>\r\n    from paddle.distributed.fleet.meta_parallel import get_rng_state_tracker\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/meta_parallel/__init__.py\", line 27, in <module>\r\n    from .pipeline_parallel import (  # noqa: F401\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/meta_parallel/pipeline_parallel.py\", line 23, in <module>\r\n    from ..meta_optimizers.dygraph_optimizer import HybridParallelOptimizer\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/meta_optimizers/__init__.py\", line 35, in <module>\r\n    from .ps_optimizer import ParameterServerOptimizer  # noqa: F401\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/fleet/meta_optimizers/ps_optimizer.py\", line 19, in <module>\r\n    import paddle.distributed.passes\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/passes/__init__.py\", line 32, in <module>\r\n    from .pipeline_scheduler_pass import *  # noqa: F403\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/passes/pipeline_scheduler_pass/__init__.py\", line 18, in <module>\r\n    from .pipeline_1f1b import Pipeline1F1BPass  # noqa: F401\r\n  File \"/home/theo/anaconda3/envs/paddleocr/lib/python3.10/site-packages/paddle/distributed/passes/pipeline_scheduler_pass/pipeline_1f1b.py\", line 22, in <module>\r\n    from ..pass_utils import (",
        "state": "closed",
        "user": "relaxtheo",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-12-03T03:46:24+00:00",
        "updated_at": "2024-12-06T07:29:12+00:00",
        "closed_at": "2024-12-05T09:32:06+00:00",
        "comments_count": [
            "relaxtheo",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "GreatV",
            "leduy-it",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "leduy-it"
        ],
        "labels": [
            "Bug",
            "PaddleOCR"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1453,
        "title": "db++转onnx的19版本出现bug，The Opset Version must be between 7 and 18",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：需要做部署使用\r\n - Paddle2ONNX版本: 1.3.1最新版本\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n![image](https://github.com/user-attachments/assets/9adfb5f5-9459-4c02-9120-ab3a01321cf1)\r\n\r\n\r\n**其他信息**\r\n![image](https://github.com/user-attachments/assets/f6b2305f-da6f-4ecc-8455-3014cc240b73)\r\n已经看了很多文档，也用了最新的2onnx，onnx也是最新的，已经支持了db++的算子，paddle2onnx --model_dir D:\\BaiduNetdiskDownload\\inference\\inference\\det_r50_seal_0203_all --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file D:\\BaiduNetdiskDownload\\inference\\inference\\det_r50_seal_0203_all\\\\model.onnx --opset_version 19\r\n用了最新的19，但是显示opset必须在11-18是什么意思？",
        "state": "closed",
        "user": "shallow10",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-06T03:16:44+00:00",
        "updated_at": "2025-03-21T08:52:04+00:00",
        "closed_at": "2025-02-08T02:26:03+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "shallow10",
            "shallow10",
            "Zheng-Bicheng",
            "shallow10",
            "shallow10",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "shallow10",
            "shallow10",
            "changdazhou",
            "github-actions[bot]",
            "github-actions[bot]",
            "jhluaa",
            "JoshvirN"
        ],
        "labels": [
            "ONNX(Version)",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1457,
        "title": "报错[Error] Operator Pool2dMapper dosen't support export as custom Operator",
        "body": "##### 背景：\r\n在`fastdeploy`中，集成了`Paddle2ONNX`(以源码或者预编译库的形式，我这边直接自己编译`paddle2onnx`)，但是在使用最新的`paddle-gpu-beta2`训练出来的`PPOCRv4`识别模型，导出后在`fastdeploy`中进行推理，使用`onnxruntime backend`。\r\n##### 报错\r\n报`switch`不被支持，根据`paddle2ONNX`的`issue`发现这个问题是`Paddle2ONNX`的版本太低导致的，后升级然后重新编译`Fasdeploy`中的`Paddle2ONNX`，然后`PPOCRv4`识别模型报错`[Error] Operator Pool2dMapper dosen't support export as custom Operator`\r\n##### 问题\r\n请问一下，这个是什么原因导致的，能给个解决的办法么？\r\n",
        "state": "closed",
        "user": "ChaoII",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-13T07:19:18+00:00",
        "updated_at": "2025-02-19T02:00:00+00:00",
        "closed_at": "2025-01-28T02:27:40+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]",
            "fireae"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1458,
        "title": "module 'paddle2onnx' has no attribute 'command'",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n我在GPU环境去运行PaddleNLP的taskflow，其中使用了UIE-X-Base模型，在taskflow中，我希望用fp16精度去提高预测速度\r\n代码如下：\r\nie = Taskflow('information_extraction', schema=schema_obj,\r\n                              batch_size=batch_size, model=‘uie-x-base’,\r\n                              layout_analysis=True,precision='fp16')\r\n在GPU环境安装了必要的依赖：onnxruntime-gpu onnx onnxconverter-common paddle2onnx\r\n这是我试过的依赖的版本\r\nonnx                     1.17.0\r\nonnxconverter-common     1.14.0\r\nonnxruntime-gpu          1.14.1\r\npaddle2onnx             1.3.1\r\npaddlenlp                2.8.1 /2.7.0\r\npaddleocr                2.9.1/2.7.0.0\r\npaddlepaddle-gpu         3.0.0b2/2.6.2\r\n但是初始化Taskflow的时候总是抛出module 'paddle2onnx' has no attribute 'command' 麻烦给个建议 怎么解决，多谢\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本: 1.3.1\r\n - 你的联系方式(Email/Wechat/Phone):bodyhfp@163.com\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "huangfup",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-17T13:27:29+00:00",
        "updated_at": "2025-06-11T06:13:24+00:00",
        "closed_at": "2025-01-31T02:27:56+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]",
            "IsDora"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1460,
        "title": "将PP-OCRv4_mobile_det 模型转onnx格式失败",
        "body": "log：\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /home/cienet/project/PaddleX/pretrain_models/PP-OCRv4_mobile_det/inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: /home/cienet/project/PaddleX/pretrain_models/PP-OCRv4_mobile_det/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including isnan_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1734590833 (unix time) try \"date -d @1734590833\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e800026b07) received by PID 158471 (TID 0x7f8145e58180) from PID 158471 ***]\r\n\r\n\r\n环境版本：\r\npaddle2onnx               1.3.1\r\npaddlepaddle              3.0.0b2\r\nonnxruntime               1.19.2\r\n",
        "state": "closed",
        "user": "chaosang1994",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-19T06:48:34+00:00",
        "updated_at": "2025-02-08T02:26:02+00:00",
        "closed_at": "2025-02-08T02:26:02+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "GreatV",
            "chaosang1994",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "Bug",
            "PaddleOCR",
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1459,
        "title": "[Paddle2ONNX] Oops, there are some operators not supported yet, including uniform_random",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\nI tried to export model to onnx, and the terminal shows \"there are some operator not supported yet...\"\r\n\r\nBefore that, I re-trained the SegNeXt model (https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.8/configs/segnext), then converted the .pdparams as instructed in https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.8/docs/model_export.md, and then tried to convert to onnx as instructed in https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/README_en.md\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: onnx runtime/tensorRT\r\n - Why convert to onnx：Performance\r\n - Paddle2ONNX Version: 1.3.1\r\n - Email/Wechat/Phone:\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/4877025a-6db5-404a-a9a9-04ca8590f52f)\r\n\r\n**Additional context**\r\n- Paddle2ONNX: 1.3.1\r\n- PaddlePaddle: 2.6.0\r\n- PaddleSeg: 2.8.0\r\n- Python: 3.10.13\r\n",
        "state": "closed",
        "user": "MaciejPykoszAigo",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-17T15:21:05+00:00",
        "updated_at": "2025-03-06T02:36:56+00:00",
        "closed_at": "2025-03-06T02:36:55+00:00",
        "comments_count": [
            "Zheng-Bicheng",
            "MaciejPykoszAigo",
            "MaciejPykoszAigo",
            "4399123",
            "MaciejPykoszAigo",
            "Zheng-Bicheng",
            "Zheng-Bicheng",
            "MaciejPykoszAigo",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1461,
        "title": "windows环境下使用subprocess来对paddle模型文件进行转换报错subprocess.CalledProcessError",
        "body": "**问题描述**\r\n在cmd.exe中执行命令paddle2onnx --model_dir ./save/paddle/ --model_filename model.pdmodel --params_filename model.pdiparams --save_file ./save/paddle/paddle_model.onnx --opset_version 11'可以很顺利地转换为onnx文件，这说明环境依赖以及命令输入都是没有问题的。\r\n但是在编写.py文件时，使用subprocess就会报错subprocess.CalledProcessError\r\n\r\n源码如下：\r\nsubprocess.run([\r\n            \"cmd\", \"/c\",\r\n            \"paddle2onnx\",\r\n            \"--model_dir\", \"./save/paddle/\",\r\n            \"--model_filename\", \"model.pdmodel\",\r\n            \"--params_filename\", \"model.pdiparams\",\r\n            \"--save_file\", \"./save/paddle/paddle.onnx\",\r\n            \"--opset_version\", str(opset_version),\r\n            \"--full_graph=True\"\r\n        ], check=True)\r\n![微信图片_20241219161059](https://github.com/user-attachments/assets/41d24b77-58b6-4545-9957-bf34e8d2541e)\r\n\r\n\r\n报错信息：\r\nC:\\Users\\zly\\.conda\\envs\\python310\\lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\r\nYou can set full_graph=True, then you can assign input spec.\r\n\r\n  warnings.warn(\r\nI1219 16:10:03.694989 29176 program_interpreter.cc:212] New Executor is Running.\r\n'paddle2onnx' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\r\n���������ļ���\r\nTraceback (most recent call last):\r\n  File \"E:\\workProject\\onnx_convert-main\\convert_paddle.py\", line 115, in <module>\r\n    export_model_to_onnx(None, None, paddle_model_path, paddle_onnx_path, framework='paddlepaddle')\r\n  File \"E:\\workProject\\onnx_convert-main\\convert_paddle.py\", line 53, in export_model_to_onnx\r\n    subprocess.run([\r\n  File \"C:\\Users\\zly\\.conda\\envs\\python310\\lib\\subprocess.py\", line 526, in run\r\n    raise CalledProcessError(retcode, process.args,\r\nsubprocess.CalledProcessError: Command '['cmd', '/c', 'paddle2onnx', '--model_dir', './save/paddle/', '--model_filename', 'model.pdmodel', '--params_filename', 'model.pdiparams', '--save_file', './save/paddle/paddle.onnx', '--opset_version', '11', '--full_graph=True']' returned non-zero exit status 1.\r\n\r\nProcess finished with exit code 1\r\n![image](https://github.com/user-attachments/assets/27597def-da10-4f39-80fa-385704c9f963)\r\n",
        "state": "closed",
        "user": "sensenforever",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-12-19T08:13:23+00:00",
        "updated_at": "2024-12-23T06:52:56+00:00",
        "closed_at": "2024-12-23T06:52:56+00:00",
        "comments_count": [
            "Zheng-Bicheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1463,
        "title": "PP-YOLOE-SOD模型转ONNX后推理结果不一致",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\nonnx模型已成功转出，但推理结果与在线模型不一致。具体表现为，在固定输入数据的前提下，onnx模型的推理结果shape分别为(35,6)，(35)，而在线推理结果shape分别为(228,6)，(228)\r\n\r\n**更多信息 :**\r\npaddle2onnx 1.13\r\npaddle 3.0\r\nlinux\r\n\r\n**报错截图**\r\n\r\n\r\n\r\n**其他信息**\r\n\r\n\r\n",
        "state": "closed",
        "user": "WindLWQ",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-25T01:33:31+00:00",
        "updated_at": "2025-02-08T02:26:01+00:00",
        "closed_at": "2025-02-08T02:26:00+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1464,
        "title": "怎么将PaddleOCR部署到高通SNPE框架？",
        "body": "怎么将PaddleOCR的检测模型和识别模型串联起来然后部署到高通的SNPE框架上？现在已经将检测模型和识别模型都转换生成了dlc格式，并且能在SNPE上进行snpe-net-run，但是现在不知道怎么完成一整套流程的推理，比如输入图像再经过检测模型的dlc，再经过识别模型的dlc得到的输出再从raw格式变成图像的形式输出，这个过程需要图像的预处理吗？\r\n",
        "state": "closed",
        "user": "ziFan99",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-26T03:41:37+00:00",
        "updated_at": "2025-02-09T02:32:11+00:00",
        "closed_at": "2025-02-09T02:32:10+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1466,
        "title": "paddle2onnx转换mot_ppyoloe_l_36e_pipeline模型到onnx格式",
        "body": "请问这个代码的具体位置在哪",
        "state": "closed",
        "user": "tsrdsy",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-26T19:41:39+00:00",
        "updated_at": "2025-02-09T02:32:09+00:00",
        "closed_at": "2025-02-09T02:32:09+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1471,
        "title": "ppocr 自训练模型转为推理模型生成了json和pdiparams文件，使用paddle2onnx进行模型转换失败",
        "body": "ppocr 自训练模型转为推理模型生成了json和pdiparams文件，使用paddle2onnx进行模型转换失败\r\n\r\npaddle2onnx --model_dir ./inference_model/det_v3 --model_filename inference.json --params_filename inference.pdiparams --save_file ./inference_model/det_v3/det.onnx --opset_version 16 --enable_onnx_checker True\r\n\r\n![image](https://github.com/user-attachments/assets/c034e82f-95f4-43f2-85dd-0be5227d96a1)\r\n\r\n\r\npaddle2onnx==1.3.0\r\n\r\n",
        "state": "closed",
        "user": "LKjoey",
        "closed_by": "LKjoey",
        "created_at": "2024-12-30T05:34:45+00:00",
        "updated_at": "2024-12-30T05:51:21+00:00",
        "closed_at": "2024-12-30T05:51:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1467,
        "title": "PPYOLOE-SOD去后处理，静态图模型与onnx推理精度差距较大",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n```\r\nInput shape: (1, 3, 640, 640) mean: 0.28469935 max: 2.6399999 min:  -2.117904\r\nPaddle output0 shape: (1, 8400, 5) mean: 255.8405 max: 893.85974 min:  -283.3754\r\nOnnx output0 shape: (1, 8400, 5) mean: 255.84058 max: 893.91284 min:  -283.38022\r\nOutput0 mean cosine distance:  -7.209324e-09 mean euclidean distance 0.014979004\r\n```\r\n**问题描述**\r\n已固定模型输入\r\n\r\n\r\n**更多信息 :**\r\npaddle2onnx 1.3.1\r\npaddlepaddle 2.6.2\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n静态图模型及onnx模型\r\n通过百度网盘分享的文件：ppyoloe_crn_l_80e_sliced_smoke_640_...\r\n链接：https://pan.baidu.com/s/1_JUhtH_oUPZEwJv1DOlFng \r\n提取码：f9wz",
        "state": "closed",
        "user": "WindLWQ",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-27T07:12:17+00:00",
        "updated_at": "2025-02-10T02:31:32+00:00",
        "closed_at": "2025-02-10T02:31:31+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1468,
        "title": "Exporting PARSEQ Recognition Model to ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\n```\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: ./paddle_inference/weights/paddle_inference/parseq_171224/inference.pdmodel\n[Paddle2ONNX] Parameters file path: ./paddle_inference/weights/paddle_inference/parseq_171224/inference.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] DenseTensorArray is not supported.\n[Paddle2ONNX] Oops, there are some operators not supported yet, including lod_array_length,memcpy,tensor_array_to_tensor,while,write_to_array,\n[ERROR] Due to the unsupported operators, the conversion is aborted.\n\n\n--------------------------------------\nC++ Traceback (most recent call last):\n--------------------------------------\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\n\n----------------------\nError Message Summary:\n----------------------\nFatalError: `Process abort signal` is detected by the operating system.\n  [TimeInfo: *** Aborted at 1735310555 (unix time) try \"date -d @1735310555\" if you are using GNU date ***]\n  [SignalInfo: *** SIGABRT (@0xbb) received by PID 187 (TID 0x727a43df9740) from PID 187 ***]\n\nAborted (core dumped)\n\n```\n\n**更多信息 :**\n - 用于部署的推理引擎: 待更新\n - 为什么需要转换为ONNX格式：Deploying in ONNX Runtime\n - Paddle2ONNX版本: \n Name: paddle2onnx\nVersion: 1.3.1\n\n - 你的联系方式(Email/Wechat/Phone): levduyit@gmail.com\n\n**报错截图**\n\n<img width=\"800\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/151b5a82-27bc-4b15-80fc-f0e80f6655b2\" />\n\n**其他信息**\n\n- I am working on integrating PARSEQ OCR recognition with PaddleOCR.\n\nI came across [Issue #12](https://github.com/baudm/parseq/issues/12), which discusses ONNX export handling in PyTorch. I'm exploring ONNX export for PARSEQ but want to retain AR mode functionality and refinement iterations without compromise.\n\nWould appreciate guidance or suggestions to achieve this.\n\nThank you!\n",
        "state": "closed",
        "user": "leduy-it",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-27T15:33:32+00:00",
        "updated_at": "2025-03-01T02:39:01+00:00",
        "closed_at": "2025-03-01T02:39:01+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1472,
        "title": "微调后的slanet_plus模型转onnx时报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n您好，按照https://github.com/PaddlePaddle/PaddleX/blob/release/3.0-beta1/docs/module_usage/tutorials/ocr_modules/table_structure_recognition.md这个指导，微调slanet_plus网络，然后导出onnx模型时貌似报模型不支持\r\n paddle2onnx --model_dir ./inference \\\r\n> --model_filename inference.pdmodel \\\r\n> --params_filename inference.pdiparams \\\r\n> --save_file ./model.onnx \\\r\n> --opset_version 16 \\\r\n> --enable_onnx_checker True\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: /data/huangzaiguang/TRS/PaddleX/output/1230_slanet_plus_sync_bn/best_accuracy/inference/inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: /data/huangzaiguang/TRS/PaddleX/output/1230_slanet_plus_sync_bn/best_accuracy/inference/inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including sync_batch_norm,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1735550027 (unix time) try \"date -d @1735550027\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x30) received by PID 48 (TID 0x7febae70f740) from PID 48 ***]\r\n\r\nAborted (core dumped)\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\npaddle2onnx               1.3.1\r\npaddlefsl                     1.1.0\r\npaddlenlp                    2.8.0.post0\r\npaddleocr                    0.1.0.dev1+g3f32858\r\npaddlepaddle-gpu      3.0.0b1\r\npaddlex                       3.0.0b2 \r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "drivingchangeworld",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-30T09:19:47+00:00",
        "updated_at": "2025-03-02T02:37:53+00:00",
        "closed_at": "2025-03-02T02:37:52+00:00",
        "comments_count": [
            "Sherryran08",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1474,
        "title": "支持ernie-gram模型转onnx吗？",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\r\n\r\n**问题描述**\r\n请在此处详细的描述报错信息\r\n\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎:\r\n - 为什么需要转换为ONNX格式：\r\n - Paddle2ONNX版本:\r\n - 你的联系方式(Email/Wechat/Phone):\r\n\r\n**报错截图**\r\n\r\n\r\n**其他信息**\r\n",
        "state": "closed",
        "user": "Fafap131",
        "closed_by": "github-actions[bot]",
        "created_at": "2024-12-31T09:33:17+00:00",
        "updated_at": "2025-02-14T02:30:22+00:00",
        "closed_at": "2025-02-14T02:30:21+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1475,
        "title": "PP-OCRv4_server_det 模型转onnx格式失败",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\r\n\r\n**Describe the bug**\r\n```bash\r\n/home/longdexin/python-venvs/paddle/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:686: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n  warnings.warn(warning_message)\r\n[Paddle2ONNX] Start to parse PaddlePaddle model...\r\n[Paddle2ONNX] Model file path: ./inference.pdmodel\r\n[Paddle2ONNX] Parameters file path: ./inference.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Oops, there are some operators not supported yet, including isnan_v2,\r\n[ERROR] Due to the unsupported operators, the conversion is aborted.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle2onnx::Export(char const*, char const*, char**, int*, int, bool, bool, bool, bool, bool, paddle2onnx::CustomOp*, int, char const*, char**, int*, char const*, bool*, bool, char**, int)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1735875136 (unix time) try \"date -d @1735875136\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e80001cfef) received by PID 118767 (TID 0x74604816e080) from PID 118767 ***]\r\n\r\n已中止 (核心已转储)\r\n```\r\n\r\n\r\n**Informations (please complete the following information):**\r\n - Inference engine for deployment: CPU\r\n - Why convert to onnx：PP-OCRv4_server版本模型效果很好\r\n - Paddle2ONNX Version: 13.1\r\n - Email/Wechat/Phone: \r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/c70e0df5-6a9c-449f-a2ad-576b6c1ef9df)\r\n\r\n\r\n**Additional context**\r\n```bash\r\npaddle2onnx            1.3.1\r\npaddleclas             2.6.0\r\npaddleocr              2.9.1\r\npaddlepaddle           3.0.0b2\r\n```",
        "state": "closed",
        "user": "longdexin",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-03T03:37:57+00:00",
        "updated_at": "2025-02-17T02:33:48+00:00",
        "closed_at": "2025-02-17T02:33:47+00:00",
        "comments_count": [
            "GreatV",
            "longdexin",
            "longdexin",
            "GreatV",
            "longdexin",
            "GreatV",
            "longdexin",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1476,
        "title": "int8量化后，deploy_backend使用tensorrt，转onnx后转tensorrt，有很多Missing scale and zero-point for tensor是为什么",
        "body": "**问题描述**\r\nint8量化后，deploy_backend使用tensorrt，转onnx后转tensorrt，有很多Missing scale and zero-point for tensor\r\n\r\n**更多信息 :**\r\n - 用于部署的推理引擎: tensorrt8.6\r\n - Paddle2ONNX版本: 1.3.1\r\n - paddle版本：2.6\r\n - PaddleSeg：2.9\r\n - 量化后的模型文件：\r\n链接：https://pan.baidu.com/s/1qiNlDMr0Haq3RUWTFhqe9g?pwd=585d \r\n提取码：585d\r\n 模型是PaddleSeg的rtformer，QAT量化。\r\npaddel2onnx命令：\r\npaddle2onnx --model_dir=./output_quant_for_trt/ --model_filename=model.pdmodel --params=model.pdiparams --save_file=./output_quant_for_trt/model.onnx --opset_version=16 --enable_onnx_checker=True --deploy_backend tensorrt --save_calibration_file ./output_quant_for_trt/calibration.cache\r\n\r\n**错误信息：**\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_0.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_1.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_2.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_3.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.5, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_4.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_5.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.7, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_6.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_7.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_8.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.9, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_9.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_10.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.11, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_11.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_12.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_13.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.13, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_14.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_15.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.15, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_16.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.17, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_17.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_18.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.19, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor relu_16.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor relu_17.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor relu_18.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_20.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_20.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_2.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 75) [Softmax]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor softmax_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor ReduceSum.1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_3.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_21.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.21, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_22.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 84) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 85) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.3, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Erf.1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 88) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 89) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.25, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 92) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 93) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_23.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.29, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_22.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.31, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_23.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor split_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor split_0.tmp_1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor transpose_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_6.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_7.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_24.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_8.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_26.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_9.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 118) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 119) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.4, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 121) [Softmax]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor softmax_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_10.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_27.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_11.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.33, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_28.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 129) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 130) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.5, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Erf.3, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 133) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 134) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.37, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.6, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 137) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 138) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_29.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.41, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_26.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_27.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.43, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor relu_22.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor relu_23.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_28.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_32.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_14.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 154) [Softmax]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor softmax_2.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor ReduceSum.3, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.7, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_15.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_33.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.45, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_34.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 163) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 164) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.9, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Erf.5, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 167) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 168) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.49, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.9, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 171) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 172) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_35.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.53, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_30.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_2.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.55, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_31.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor split_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor split_1.tmp_1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor transpose_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_18.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_19.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_32.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_20.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_38.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_21.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 197) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 198) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.12, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 200) [Softmax]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor softmax_3.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_22.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_39.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor reshape2_23.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.57, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_40.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 208) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 209) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Div.11, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Erf.7, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 212) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 213) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.61, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Mul.14, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 216) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 217) [Shuffle]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_41.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.65, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_34.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_35.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.67, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_36.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor pool2d_0.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_37.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_3.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.69, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_38.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor pool2d_1.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_39.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_4.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.71, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_40.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor pool2d_2.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_41.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_5.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.73, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_42.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor pool2d_3.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_43.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_6.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.75, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_44.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Concat.8, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_45.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_46.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Add.77, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_7.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor Concat.11, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_47.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor batch_norm_48.tmp_2, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor conv2d_56.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor bilinear_interp_v2_8.tmp_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 308) [TopK]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 308) [TopK]_output_1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor ArgMax.1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n[01/03/2025-05:34:56] [TRT] [W] Missing scale and zero-point for tensor save_infer_model/scale_0.tmp_0.0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\r\n\r\n\r\n导出的calibration.cache:\r\nTRT-8XXX-EntropyCalibration2 \r\nx.quantized.dequantized: 40008102\r\nx: 40008102\r\nrelu_9.tmp_0.quantized.dequantized.0: 3e06f7a3\r\nrelu_9.tmp_0.quantized.dequantized: 3e06f7a3\r\nrelu_9.tmp_0: 3e06f7a3\r\nrelu_8.tmp_0.quantized.dequantized: 3d3cd8d8\r\nrelu_8.tmp_0: 3d3cd8d8\r\nrelu_7.tmp_0.quantized.dequantized: 3db6ed15\r\nrelu_7.tmp_0: 3db6ed15\r\nrelu_6.tmp_0.quantized.dequantized: 3d6f53ad\r\nrelu_6.tmp_0: 3d6f53ad\r\nrelu_5.tmp_0.quantized.dequantized.0: 3e3d5019\r\nrelu_5.tmp_0.quantized.dequantized: 3e3d5019\r\nrelu_5.tmp_0: 3e3d5019\r\nrelu_4.tmp_0.quantized.dequantized: 3dbe8e70\r\nrelu_4.tmp_0: 3dbe8e70\r\nrelu_39.tmp_0.quantized.dequantized: 3da30a54\r\nrelu_39.tmp_0: 3da30a54\r\nrelu_38.tmp_0.quantized.dequantized: 3e24fd50\r\nrelu_38.tmp_0: 3e24fd50\r\nrelu_37.tmp_0.quantized.dequantized: 3dba6e2e\r\nrelu_37.tmp_0: 3dba6e2e\r\nrelu_36.tmp_0.quantized.dequantized: 3d6c3bb1\r\nrelu_36.tmp_0: 3d6c3bb1\r\nrelu_35.tmp_0.quantized.dequantized: 3d8375fb\r\nrelu_35.tmp_0: 3d8375fb\r\nrelu_34.tmp_0.quantized.dequantized: 3cee0f49\r\nrelu_34.tmp_0: 3cee0f49\r\nrelu_33.tmp_0.quantized.dequantized: 3d75091e\r\nrelu_33.tmp_0: 3d75091e\r\nrelu_32.tmp_0.quantized.dequantized: 3ce96e64\r\nrelu_32.tmp_0: 3ce96e64\r\nrelu_31.tmp_0.quantized.dequantized: 3da0d844\r\nrelu_31.tmp_0: 3da0d844\r\nrelu_30.tmp_0.quantized.dequantized: 3d5d1e2f\r\nrelu_30.tmp_0: 3d5d1e2f\r\nrelu_3.tmp_0.quantized.dequantized: 3e2e2a50\r\nrelu_3.tmp_0: 3e2e2a50\r\nrelu_29.tmp_0.quantized.dequantized: 3d8e8cef\r\nrelu_29.tmp_0: 3d8e8cef\r\nrelu_28.tmp_0.quantized.dequantized: 3d34d6e5\r\nrelu_28.tmp_0: 3d34d6e5\r\nrelu_27.tmp_0.quantized.dequantized: 3da917c3\r\nrelu_27.tmp_0: 3da917c3\r\nrelu_26.tmp_0.quantized.dequantized: 3e055356\r\nrelu_26.tmp_0: 3e055356\r\nrelu_25.tmp_0.quantized.dequantized: 3dd3d1c5\r\nrelu_25.tmp_0: 3dd3d1c5\r\nrelu_24.tmp_0.quantized.dequantized: 3de9ebfa\r\nrelu_24.tmp_0: 3de9ebfa\r\nrelu_21.tmp_0.quantized.dequantized: 3e31cd00\r\nrelu_21.tmp_0: 3e31cd00\r\nrelu_20.tmp_0.quantized.dequantized: 3e1bdd95\r\nrelu_20.tmp_0: 3e1bdd95\r\nrelu_2.tmp_0.quantized.dequantized: 3e04a01b\r\nrelu_2.tmp_0: 3e04a01b\r\nrelu_19.tmp_0.quantized.dequantized: 3cf084b5\r\nrelu_19.tmp_0: 3cf084b5\r\nrelu_15.tmp_0.quantized.dequantized: 3d54e7e6\r\nrelu_15.tmp_0: 3d54e7e6\r\nrelu_14.tmp_0.quantized.dequantized: 3e2c78a6\r\nrelu_14.tmp_0: 3e2c78a6\r\nrelu_13.tmp_0.quantized.dequantized: 3dac3acc\r\nrelu_13.tmp_0: 3dac3acc\r\nrelu_12.tmp_0.quantized.dequantized: 3d23f37b\r\nrelu_12.tmp_0: 3d23f37b\r\nrelu_11.tmp_0.quantized.dequantized: 3d6ff790\r\nrelu_11.tmp_0: 3d6ff790\r\nrelu_10.tmp_0.quantized.dequantized: 3d3fce83\r\nrelu_10.tmp_0: 3d3fce83\r\nrelu_1.tmp_0.quantized.dequantized: 3e26c865\r\nrelu_1.tmp_0: 3e26c865\r\nrelu_0.tmp_0.quantized.dequantized: 3e42f76a\r\nrelu_0.tmp_0: 3e42f76a\r\nmax_pool2d_with_index_1.tmp_0.quantized.dequantized: 3da0fb91\r\nmax_pool2d_with_index_1.tmp_0: 3da0fb91\r\nmax_pool2d_with_index_0.tmp_0.quantized.dequantized: 3cfc7d2f\r\nmax_pool2d_with_index_0.tmp_0: 3cfc7d2f\r\ngelu_3.tmp_0.quantized.dequantized: 3df07eff\r\ngelu_3.tmp_0: 3df07eff\r\ngelu_2.tmp_0.quantized.dequantized: 3eab25ef\r\ngelu_2.tmp_0: 3eab25ef\r\ngelu_1.tmp_0.quantized.dequantized: 3ddf3ba1\r\ngelu_1.tmp_0: 3ddf3ba1\r\ngelu_0.tmp_0.quantized.dequantized: 3ec5ba52\r\ngelu_0.tmp_0: 3ec5ba52\r\nconv2d_9.tmp_0.tmp: 3ef6b973\r\nconv2d_9.tmp_0: 3ef6b973\r\nconv2d_8.tmp_0.tmp: 3e4498ce\r\nconv2d_8.tmp_0: 3e4498ce\r\nconv2d_7.tmp_0.tmp: 3e605dde\r\nconv2d_7.tmp_0: 3e605dde\r\nconv2d_6.tmp_0.tmp: 3f1dc67e\r\nconv2d_6.tmp_0: 3f1dc67e\r\nconv2d_56.tmp_1.tmp: 3eabf0a5\r\nconv2d_56.tmp_1: 3eabf0a5\r\nconv2d_55.tmp_0.tmp: 4007a1a0\r\nconv2d_55.tmp_0: 4007a1a0\r\nconv2d_54.tmp_0.tmp: 3e91fac6\r\nconv2d_54.tmp_0: 3e91fac6\r\nconv2d_53.tmp_0.tmp: 3e95402c\r\nconv2d_53.tmp_0: 3e95402c\r\nconv2d_52.tmp_0.tmp: 3f323ef3\r\nconv2d_52.tmp_0: 3f323ef3\r\nconv2d_51.tmp_0.tmp: 3ddfb51d\r\nconv2d_51.tmp_0: 3ddfb51d\r\nconv2d_50.tmp_0.tmp: 3f0989c8\r\nconv2d_50.tmp_0: 3f0989c8\r\nconv2d_5.tmp_0.tmp: 3e688fa3\r\nconv2d_5.tmp_0: 3e688fa3\r\nconv2d_49.tmp_0.tmp: 3da07903\r\nconv2d_49.tmp_0: 3da07903\r\nconv2d_48.tmp_0.tmp: 3f1bf9a8\r\nconv2d_48.tmp_0: 3f1bf9a8\r\nconv2d_47.tmp_0.tmp: 3e6aa4fc\r\nconv2d_47.tmp_0: 3e6aa4fc\r\nconv2d_46.tmp_0.tmp: 3f714f69\r\nconv2d_46.tmp_0: 3f714f69\r\nconv2d_45.tmp_0.tmp: 3e1485f2\r\nconv2d_45.tmp_0: 3e1485f2\r\nconv2d_44.tmp_0.tmp: 3e8f0dfa\r\nconv2d_44.tmp_0: 3e8f0dfa\r\nconv2d_43.tmp_0.tmp: 40427270\r\nconv2d_43.tmp_0: 40427270\r\nconv2d_42.tmp_0.tmp: 3f31707a\r\nconv2d_42.tmp_0: 3f31707a\r\nconv2d_41.tmp_1.tmp: 3e5baa22\r\nconv2d_41.tmp_1: 3e5baa22\r\nconv2d_40.tmp_1.tmp: 3eb15a38\r\nconv2d_40.tmp_1: 3eb15a38\r\nconv2d_4.tmp_0.tmp: 3ef83403\r\nconv2d_4.tmp_0: 3ef83403\r\nconv2d_37.tmp_0.tmp: 3e42f995\r\nconv2d_37.tmp_0: 3e42f995\r\nconv2d_36.tmp_0.tmp: 3e885d32\r\nconv2d_36.tmp_0: 3e885d32\r\nconv2d_35.tmp_1.tmp: 3f82e625\r\nconv2d_35.tmp_1: 3f82e625\r\nconv2d_34.tmp_1.tmp: 3f415c20\r\nconv2d_34.tmp_1: 3f415c20\r\nconv2d_31.tmp_0.tmp: 402dc4c6\r\nconv2d_31.tmp_0: 402dc4c6\r\nconv2d_30.tmp_0.tmp: 3f39c246\r\nconv2d_30.tmp_0: 3f39c246\r\nconv2d_3.tmp_0.tmp: 3ec4cf30\r\nconv2d_3.tmp_0: 3ec4cf30\r\nconv2d_29.tmp_1.tmp: 3e4b392b\r\nconv2d_29.tmp_1: 3e4b392b\r\nconv2d_28.tmp_1.tmp: 3e8991fa\r\nconv2d_28.tmp_1: 3e8991fa\r\nconv2d_25.tmp_0.tmp: 3e4c862c\r\nconv2d_25.tmp_0: 3e4c862c\r\nconv2d_24.tmp_0.tmp: 3d09cdf2\r\nconv2d_24.tmp_0: 3d09cdf2\r\nconv2d_23.tmp_1.tmp: 403cb514\r\nconv2d_23.tmp_1: 403cb514\r\nconv2d_22.tmp_1.tmp: 3f11b66d\r\nconv2d_22.tmp_1: 3f11b66d\r\nconv2d_2.tmp_0.tmp: 3edad7af\r\nconv2d_2.tmp_0: 3edad7af\r\nconv2d_19.tmp_0.tmp: 3e67af05\r\nconv2d_19.tmp_0: 3e67af05\r\nconv2d_18.tmp_0.tmp: 3e4dd594\r\nconv2d_18.tmp_0: 3e4dd594\r\nconv2d_17.tmp_0.tmp: 4044946a\r\nconv2d_17.tmp_0: 4044946a\r\nconv2d_16.tmp_0.tmp: 3e2543c3\r\nconv2d_16.tmp_0: 3e2543c3\r\nconv2d_15.tmp_0.tmp: 3e5a8758\r\nconv2d_15.tmp_0: 3e5a8758\r\nconv2d_14.tmp_0.tmp: 3eba2e5e\r\nconv2d_14.tmp_0: 3eba2e5e\r\nconv2d_13.tmp_0.tmp: 3e19d493\r\nconv2d_13.tmp_0: 3e19d493\r\nconv2d_12.tmp_0.tmp: 3e4b4de5\r\nconv2d_12.tmp_0: 3e4b4de5\r\nconv2d_11.tmp_0.tmp: 3f256097\r\nconv2d_11.tmp_0: 3f256097\r\nconv2d_10.tmp_0.tmp: 3e4fc34e\r\nconv2d_10.tmp_0: 3e4fc34e\r\nconv2d_1.tmp_1.tmp: 3ef71da4\r\nconv2d_1.tmp_1: 3ef71da4\r\nconv2d_0.tmp_1.tmp: 4102bafe\r\nconv2d_0.tmp_1: 4102bafe\r\nbatch_norm_33.tmp_2.quantized.dequantized: 3da6047f\r\nbatch_norm_33.tmp_2: 3da6047f\r\nbatch_norm_29.tmp_2.quantized.dequantized: 3e2ff57b\r\nbatch_norm_29.tmp_2: 3e2ff57b\r\nbatch_norm_25.tmp_2.quantized.dequantized: 3d98a698\r\nbatch_norm_25.tmp_2: 3d98a698\r\nbatch_norm_21.tmp_2.quantized.dequantized: 3d1b5e66\r\nbatch_norm_21.tmp_2: 3d1b5e66\r\nbatch_norm_19.tmp_2.quantized.dequantized: 3e1d2261\r\nbatch_norm_19.tmp_2: 3e1d2261\r\nauto.cast.9: 3f0989c8\r\nauto.cast.8: 3f1bf9a8\r\nauto.cast.7: 3f714f69\r\nauto.cast.6: 3e8f0dfa\r\nauto.cast.5: 3eb15a38\r\nauto.cast.3: 3f415c20\r\nauto.cast.2: 3e8991fa\r\nauto.cast.10: 3f323ef3\r\nauto.cast.0: 3f11b66d\r\nAdd.79: 3eabf0a5\r\nAdd.63: 3e5baa22\r\nAdd.59: 3eb15a38\r\nAdd.51: 3f82e625\r\nAdd.47: 3f415c20\r\nAdd.39: 3e4b392b\r\nAdd.35: 3e8991fa\r\nAdd.3: 3ef71da4\r\nAdd.27: 403cb514\r\nAdd.23: 3f11b66d\r\nAdd.1: 4102bafe\r\n\r\n\r\n",
        "state": "closed",
        "user": "mandylyin",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-03T06:08:22+00:00",
        "updated_at": "2025-03-01T02:38:59+00:00",
        "closed_at": "2025-03-01T02:38:59+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "mandylyin",
            "Jiang-Jia-Jun",
            "mandylyin",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1479,
        "title": "ReduceMin is created even though only Min is used",
        "body": "**Problem description:**\nPaddle2ONNX creates ReduceMin ops (which currently aren't supported by the destination platform) .\nThis even though only Min is used by the Paddle model as verified in Netron.\n(Avoided ReduceMin by running PaddleDetection PIR mode). \n\n* Architecture: PicoDet\n  *  backbone: LCNet\n  *  neck: LCPAN\n  *  head: PicoHeadV2\n\n* act: set to Relu6 everywhere*\n\n_* Note that I had to [patch PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection/pull/9280#event-15913245373) for it to stick to Relu6 for ESP-DL compatibility reasons._\n\n**More information:**\n\n- Inference engine for deployment:\nESP-DL \n- Why it needs to be converted to ONNX format:\nSee above.\n\n- Paddle2ONNX version:\npaddle2onnx-1.3.1 with python>=3.8, paddlepaddle>=2.0.0\n",
        "state": "closed",
        "user": "nicklasb",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-16T20:52:22+00:00",
        "updated_at": "2025-03-02T02:37:49+00:00",
        "closed_at": "2025-03-02T02:37:48+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1477,
        "title": "版面分析layout模型转为onnx后出现不可用，其他模型都正常",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\nTraceback (most recent call last):\n  File \"E:\\program\\PaddleOCRFastAPI\\routers\\ocr.py\", line 32, in <module>\n    table_engine = PPStructure(\n  File \"E:\\Anaconda\\envs\\paddle_env\\lib\\site-packages\\paddleocr\\paddleocr.py\", line 836, in __init__\n    super().__init__(params)\n  File \"E:\\program\\PaddleOCRFastAPI\\ppstructure\\predict_system.py\", line 67, in __init__\n    self.layout_predictor = LayoutPredictor(args)\n  File \"E:\\program\\PaddleOCRFastAPI\\ppstructure\\layout\\predict_layout.py\", line 68, in __init__\n    utility.create_predictor(args, 'layout', logger)\n  File \"E:\\program\\PaddleOCRFastAPI\\tools\\infer\\utility.py\", line 183, in create_predictor\n    sess = ort.InferenceSession(\n  File \"E:\\Anaconda\\envs\\paddle_env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 335, in __init__\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\n  File \"E:\\Anaconda\\envs\\paddle_env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 370, in _create_inference_session\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from E:\\program\\PaddleOCRFastAPI\\model\\layout failed:system error number 13\n\n\n**更多信息 :**\n - 用于部署的推理引擎:onnxruntime：1.11\n - 为什么需要转换为ONNX格式：需要部署到生产环境\n - Paddle2ONNX版本:1.3.1\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/f48588b5-e874-4aa3-ad04-152e2844b1e3)\n\n![Image](https://github.com/user-attachments/assets/2e58a9f0-49f0-4fd4-8f46-6782207e53e0)\n\n![Image](https://github.com/user-attachments/assets/2a24a812-b055-4ce4-ad9a-89d82655149e)\n\n**其他信息**\n指定了绝对路径的话会出现\n\n![Image](https://github.com/user-attachments/assets/685204f5-a4ab-4a66-b03a-fc743d140042)",
        "state": "closed",
        "user": "shallow10",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-16T01:38:35+00:00",
        "updated_at": "2025-03-02T02:37:51+00:00",
        "closed_at": "2025-03-02T02:37:51+00:00",
        "comments_count": [
            "shallow10",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1478,
        "title": "算子不支持",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\n\n**Describe the bug**\n```\nfrom paddlenlp import Taskflow\nner = Taskflow(task='ner', mode='fast')\n```\n该模型使用paddle2onnx报错\n```\n[Paddle2ONNX] Oops, there are some operators not supported yet, including viterbi_decode,\n[ERROR] Due to the unsupported operators, the conversion is aborted.\n```\n\n\n**Informations (please complete the following information):**\n - Inference engine for deployment: TensorFlow Serving\n - Why convert to onnx：模型 → onnx → pb，以便Java调用\n - Paddle2ONNX Version: paddle2onnx-1.3.1 with python>=3.8, paddlepaddle>=2.0.0\n - Email/Wechat/Phone: thejsc@foxmail.com\n\n**Screenshots**\n\n\n**Additional context**\n",
        "state": "closed",
        "user": "the-jsc",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-16T09:31:33+00:00",
        "updated_at": "2025-03-02T02:37:50+00:00",
        "closed_at": "2025-03-02T02:37:50+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1483,
        "title": "如何将PaddleDetection中的ppyoloe_seg导出为ONNX + trtexec转换",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n你好，非常感谢开源PP系列框架。我目前使用PaddleDetection的ppyoloe_seg算法，训练完成后我希望能够转换成ONNX格式然后在jetson盒子上进行trtexec转换和测试，就像ppyoloe算法（https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.8/configs/ppyoloe/README_cn.md）一样：\n\n```\n# 导出模型\npython tools/export_model.py -c configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml -o weights=https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_s_80e_coco.pdparams exclude_nms=True trt=True\n\n# 转化成ONNX格式\npaddle2onnx --model_dir output_inference/ppyoloe_plus_crn_s_80e_coco --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 12 --save_file ppyoloe_plus_crn_s_80e_coco.onnx\n\n# 测试速度，半精度，batch_size=1\ntrtexec --onnx=./ppyoloe_plus_crn_s_80e_coco.onnx --saveEngine=./ppyoloe_s_bs1.engine --workspace=1024 --avgRuns=1000 --shapes=image:1x3x640x640,scale_factor:1x2 --fp16\n\n# 测试速度，半精度，batch_size=32\ntrtexec --onnx=./ppyoloe_plus_crn_s_80e_coco.onnx --saveEngine=./ppyoloe_s_bs32.engine --workspace=1024 --avgRuns=1000 --shapes=image:32x3x640x640,scale_factor:32x2 --fp16\n\n# 使用上边的脚本, 在T4 和 TensorRT 7.2的环境下，PPYOLOE-plus-s模型速度如下\n# batch_size=1, 2.80ms, 357fps\n# batch_size=32, 67.69ms, 472fps\n```\n\n但是我在ppyoloe_seg算法的README.md文件中没有发现类似的说明（https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.8/configs/ppyoloe_seg/README.md），所以我想要知道如何进行ppyoloe_seg的正常转换，非常感谢!!!\n\n\n**问题描述**\n请在此处详细的描述报错信息\n\n我尝试着进行ONNX模型转换实现，看起来能过转换ONNX成功\n\n```\n# 导出模型\npython tools/export_model.py -c configs/ppyoloe_seg/ppyoloe_seg_s_80e_xfy.yml -o exclude_nms=True\n# 转化成ONNX格式\npaddle2onnx --model_dir output_inference/ppyoloe_seg_s_80e_xfy --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 12 --save_file ppyoloe_seg_s_80e_xfy.onnx\n```\n\n![Image](https://github.com/user-attachments/assets/60cea234-4546-4a49-ad35-6c4a1454da2f)\n\n但是最后一步在trtexec上出现了错误:\n\n```\nnvidia@linux:~/zj/paddle$ trtexec --onnx=ppyoloe_seg_s_80e_xfy.onnx --saveEngine=ppyoloe_seg_s_80e_xfy.engine --workspace=1024 --avgRuns=1000 --shapes=image:1x3x640x640,scale_factor:1x2 --fp16\n&&&& RUNNING TensorRT.trtexec # trtexec --onnx=ppyoloe_seg_s_80e_xfy.onnx --saveEngine=ppyoloe_seg_s_80e_xfy.engine --workspace=1024 --avgRuns=1000 --shapes=image:1x3x640x640,scale_factor:1x2 --fp16\n[01/21/2025-13:49:02] [I] === Model Options ===\n[01/21/2025-13:49:02] [I] Format: ONNX\n[01/21/2025-13:49:02] [I] Model: ppyoloe_seg_s_80e_xfy.onnx\n[01/21/2025-13:49:02] [I] Output:\n[01/21/2025-13:49:02] [I] === Build Options ===\n[01/21/2025-13:49:02] [I] Max batch: explicit\n[01/21/2025-13:49:02] [I] Workspace: 1024 MB\n[01/21/2025-13:49:02] [I] minTiming: 1\n[01/21/2025-13:49:02] [I] avgTiming: 8\n[01/21/2025-13:49:02] [I] Precision: FP32+FP16\n[01/21/2025-13:49:02] [I] Calibration:\n[01/21/2025-13:49:02] [I] Safe mode: Disabled\n[01/21/2025-13:49:02] [I] Save engine: ppyoloe_seg_s_80e_xfy.engine\n[01/21/2025-13:49:02] [I] Load engine:\n[01/21/2025-13:49:02] [I] Builder Cache: Enabled\n[01/21/2025-13:49:02] [I] NVTX verbosity: 0\n[01/21/2025-13:49:02] [I] Inputs format: fp32:CHW\n[01/21/2025-13:49:02] [I] Outputs format: fp32:CHW\n[01/21/2025-13:49:02] [I] Input build shape: image=1x3x640x640+1x3x640x640+1x3x640x640\n[01/21/2025-13:49:02] [I] Input build shape: scale_factor=1x2+1x2+1x2\n[01/21/2025-13:49:02] [I] Input calibration shapes: model\n[01/21/2025-13:49:02] [I] === System Options ===\n[01/21/2025-13:49:02] [I] Device: 0\n[01/21/2025-13:49:02] [I] DLACore:\n[01/21/2025-13:49:02] [I] Plugins:\n[01/21/2025-13:49:02] [I] === Inference Options ===\n[01/21/2025-13:49:02] [I] Batch: Explicit\n[01/21/2025-13:49:02] [I] Input inference shape: scale_factor=1x2\n[01/21/2025-13:49:02] [I] Input inference shape: image=1x3x640x640\n[01/21/2025-13:49:02] [I] Iterations: 10\n[01/21/2025-13:49:02] [I] Duration: 3s (+ 200ms warm up)\n[01/21/2025-13:49:02] [I] Sleep time: 0ms\n[01/21/2025-13:49:02] [I] Streams: 1\n[01/21/2025-13:49:02] [I] ExposeDMA: Disabled\n[01/21/2025-13:49:02] [I] Spin-wait: Disabled\n[01/21/2025-13:49:02] [I] Multithreading: Disabled\n[01/21/2025-13:49:02] [I] CUDA Graph: Disabled\n[01/21/2025-13:49:02] [I] Skip inference: Disabled\n[01/21/2025-13:49:02] [I] Inputs:\n[01/21/2025-13:49:02] [I] === Reporting Options ===\n[01/21/2025-13:49:02] [I] Verbose: Disabled\n[01/21/2025-13:49:02] [I] Averages: 1000 inferences\n[01/21/2025-13:49:02] [I] Percentile: 99\n[01/21/2025-13:49:02] [I] Dump output: Disabled\n[01/21/2025-13:49:02] [I] Profile: Disabled\n[01/21/2025-13:49:02] [I] Export timing to JSON file:\n[01/21/2025-13:49:02] [I] Export output to JSON file:\n[01/21/2025-13:49:02] [I] Export profile to JSON file:\n[01/21/2025-13:49:02] [I]\n----------------------------------------------------------------\nInput filename:   ppyoloe_seg_s_80e_xfy.onnx\nONNX IR version:  0.0.7\nOpset version:    13\nProducer name:\nProducer version:\nDomain:\nModel version:    0\nDoc string:\n----------------------------------------------------------------\n[01/21/2025-13:49:08] [W] [TRT] onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\nterminate called after throwing an instance of 'std::out_of_range'\n  what():  Attribute not found: axes\nAborted\nnvidia@linux:~/zj/paddle$\nnvidia@linux:~/zj/paddle$\nnvidia@linux:~/zj/paddle$ trtexec --onnx=ppyoloe_seg_s_80e_xfy.onnx --saveEngine=ppyoloe_seg_s_80e_xfy.engine\n&&&& RUNNING TensorRT.trtexec # trtexec --onnx=ppyoloe_seg_s_80e_xfy.onnx --saveEngine=ppyoloe_seg_s_80e_xfy.engine\n[01/21/2025-13:49:27] [I] === Model Options ===\n[01/21/2025-13:49:27] [I] Format: ONNX\n[01/21/2025-13:49:27] [I] Model: ppyoloe_seg_s_80e_xfy.onnx\n[01/21/2025-13:49:27] [I] Output:\n[01/21/2025-13:49:27] [I] === Build Options ===\n[01/21/2025-13:49:27] [I] Max batch: 1\n[01/21/2025-13:49:27] [I] Workspace: 16 MB\n[01/21/2025-13:49:27] [I] minTiming: 1\n[01/21/2025-13:49:27] [I] avgTiming: 8\n[01/21/2025-13:49:27] [I] Precision: FP32\n[01/21/2025-13:49:27] [I] Calibration:\n[01/21/2025-13:49:27] [I] Safe mode: Disabled\n[01/21/2025-13:49:27] [I] Save engine: ppyoloe_seg_s_80e_xfy.engine\n[01/21/2025-13:49:27] [I] Load engine:\n[01/21/2025-13:49:27] [I] Builder Cache: Enabled\n[01/21/2025-13:49:27] [I] NVTX verbosity: 0\n[01/21/2025-13:49:27] [I] Inputs format: fp32:CHW\n[01/21/2025-13:49:27] [I] Outputs format: fp32:CHW\n[01/21/2025-13:49:27] [I] Input build shapes: model\n[01/21/2025-13:49:27] [I] Input calibration shapes: model\n[01/21/2025-13:49:27] [I] === System Options ===\n[01/21/2025-13:49:27] [I] Device: 0\n[01/21/2025-13:49:27] [I] DLACore:\n[01/21/2025-13:49:27] [I] Plugins:\n[01/21/2025-13:49:27] [I] === Inference Options ===\n[01/21/2025-13:49:27] [I] Batch: 1\n[01/21/2025-13:49:27] [I] Input inference shapes: model\n[01/21/2025-13:49:27] [I] Iterations: 10\n[01/21/2025-13:49:27] [I] Duration: 3s (+ 200ms warm up)\n[01/21/2025-13:49:27] [I] Sleep time: 0ms\n[01/21/2025-13:49:27] [I] Streams: 1\n[01/21/2025-13:49:27] [I] ExposeDMA: Disabled\n[01/21/2025-13:49:27] [I] Spin-wait: Disabled\n[01/21/2025-13:49:27] [I] Multithreading: Disabled\n[01/21/2025-13:49:27] [I] CUDA Graph: Disabled\n[01/21/2025-13:49:27] [I] Skip inference: Disabled\n[01/21/2025-13:49:27] [I] Inputs:\n[01/21/2025-13:49:27] [I] === Reporting Options ===\n[01/21/2025-13:49:27] [I] Verbose: Disabled\n[01/21/2025-13:49:27] [I] Averages: 10 inferences\n[01/21/2025-13:49:27] [I] Percentile: 99\n[01/21/2025-13:49:27] [I] Dump output: Disabled\n[01/21/2025-13:49:27] [I] Profile: Disabled\n[01/21/2025-13:49:27] [I] Export timing to JSON file:\n[01/21/2025-13:49:27] [I] Export output to JSON file:\n[01/21/2025-13:49:27] [I] Export profile to JSON file:\n[01/21/2025-13:49:27] [I]\n----------------------------------------------------------------\nInput filename:   ppyoloe_seg_s_80e_xfy.onnx\nONNX IR version:  0.0.7\nOpset version:    13\nProducer name:\nProducer version:\nDomain:\nModel version:    0\nDoc string:\n----------------------------------------------------------------\n[01/21/2025-13:49:29] [W] [TRT] onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\nterminate called after throwing an instance of 'std::out_of_range'\n  what():  Attribute not found: axes\nAborted\n```\n",
        "state": "closed",
        "user": "zjykzj",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-21T05:59:43+00:00",
        "updated_at": "2025-04-24T02:47:06+00:00",
        "closed_at": "2025-04-24T02:47:05+00:00",
        "comments_count": [
            "zjykzj",
            "github-actions[bot]",
            "zjykzj",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1482,
        "title": "Trying to use test_pir branch, would be great with a beta",
        "body": "**Problem description**\nI have a GPU/PaddleDetection setup that for some reason seem to only work with  paddle>=3.0.0*, and I need to export the model, and I am not finding a working pip-build-setup, and building locally is a bit of hassle, actually I am not getting it to build either on Windows or Linux.\n\nIs there a beta with .json model beta support on the way anytime soon?\n\nNote also that FLAGS_enable_pir_api=0 on the export_model causes an error (TypeError: Cannot interpret '<VarType.FP32: 5>' as a data type), not sure if it worth finding out..",
        "state": "closed",
        "user": "nicklasb",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-01-20T23:33:52+00:00",
        "updated_at": "2025-04-06T02:45:16+00:00",
        "closed_at": "2025-04-06T02:45:15+00:00",
        "comments_count": [
            "github-actions[bot]",
            "nicklasb",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1488,
        "title": "转换RE 模型报错",
        "body": "paddle2onnx --model_dir inference/re_vi_layoutxlm_tractor_certificate_20250124 --model_filename inference.pdmodel  --params_filename inference.pdiparams --save_file inference/re_vi_layoutxlm_tractor_certificate_20250124/model.onnx\n\n\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: inference/re_vi_layoutxlm_tractor_certificate_20250124\\inference.pdmodel\n[Paddle2ONNX] Parameters file path: inference/re_vi_layoutxlm_tractor_certificate_20250124\\inference.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] DenseTensorArray is not supported.\n[Paddle2ONNX] Oops, there are some operators not supported yet, including bilinear_tensor_product,lod_array_length,tensor_array_to_tensor,while,write_to_array,\n[ERROR] Due to the unsupported operators, the conversion is aborted.\n\n这些算子何时可以得到支持？",
        "state": "closed",
        "user": "huotong1212",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-02-05T06:21:57+00:00",
        "updated_at": "2025-04-23T02:45:20+00:00",
        "closed_at": "2025-04-23T02:45:19+00:00",
        "comments_count": [
            "0x3878f",
            "charmsoya",
            "charmsoya",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1498,
        "title": "PP-MattingV2模型重训练后用onnxruntime进行推理失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n你好，我在对pp-MattingV2模型的配置文件进行修改后对模型进行了重训练，将预处理的resize从512限制修改为256限制，目前遇到在paddle框架下能够正常推理，但是用paddle2onnx转成onnx后，用onnxruntime进行推理时，模型推理失败且程序崩溃退出，目前暂时定位到是在dpp模块出现的问题，但是具体的问题原因暂时没有排查到。能否帮忙排查是模型问题还是paddle2onnx的工具bug\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：尝试在本地进行c++推理部署，测试效率\n - Paddle2ONNX版本:V1.3.1\n - 你的联系方式(Email/Wechat/Phone):15280602281@163.com\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/79730022-b0de-4486-9003-0fcc15bc6d32)\n\n**其他信息**\n同样的环境下，预训练模型转换成onnx并使用onnxruntime进行onnx推理验证并未出现类似的问题",
        "state": "closed",
        "user": "LiaoYuWei1",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-02-10T01:58:17+00:00",
        "updated_at": "2025-03-28T02:41:52+00:00",
        "closed_at": "2025-03-28T02:41:51+00:00",
        "comments_count": [
            "risemeup1",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1503,
        "title": "pt2onnx Error:onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from smoke_fire_pro.onnx failed:Fatal error: mmcv:MMCVModulatedDeformConv2d(-1) is not a registered function/op",
        "body": "采用了自定义卷积的pt模型文件怎么转成onnx文件",
        "state": "closed",
        "user": "kilikto",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-02-17T02:37:04+00:00",
        "updated_at": "2025-04-03T02:41:13+00:00",
        "closed_at": "2025-04-03T02:41:11+00:00",
        "comments_count": [
            "kilikto",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1504,
        "title": "IndexError: Input conv2d_0.w_0 is undefined!",
        "body": "模型是下面两个：\nhttps://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0rc0/SLANeXt_wired_infer.tar\nhttps://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0rc0/SLANeXt_wireless_infer.tar\n\n运行命令是：\npaddle2onnx --model_dir ./ --save_file SLANeXt_wireless_infer.onnx --model_filename inference.pdmodel\n\n报了下面的错误：\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/chateval/bin/paddle2onnx\", line 8, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/opt/anaconda3/envs/chateval/lib/python3.11/site-packages/paddle2onnx/command.py\", line 145, in main\n    paddle2onnx.export(\n  File \"/opt/anaconda3/envs/chateval/lib/python3.11/site-packages/paddle2onnx/convert.py\", line 56, in export\n    onnx_model_str = c_p2o.export(\n                     ^^^^^^^^^^^^^\nIndexError: Input conv2d_0.w_0 is undefined!\n",
        "state": "closed",
        "user": "Danee-wawawa",
        "closed_by": "0x3878f",
        "created_at": "2025-02-17T03:59:35+00:00",
        "updated_at": "2025-02-19T12:46:48+00:00",
        "closed_at": "2025-02-19T12:46:48+00:00",
        "comments_count": [
            "Jiang-Jia-Jun",
            "Danee-wawawa"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1507,
        "title": "本地编译报错",
        "body": "为了尝试解决使用pip install paddleonnx安装后转换模型报错没有one_hot算子的问题，尝试本地编译。参考本地编译方式后，运行paddle2onnx报错：\n\n/home/yxhpaul/anaconda3/lib/python3.12/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\nTraceback (most recent call last):\n  File \"/home/yxhpaul/anaconda3/bin/paddle2onnx\", line 5, in <module>\n    from paddle2onnx.command import main\n  File \"/mnt/e/01-个人/02-project/Paddle2ONNX/paddle2onnx/__init__.py\", line 85, in <module>\n    from .convert import export\n  File \"/mnt/e/01-个人/02-project/Paddle2ONNX/paddle2onnx/convert.py\", line 18, in <module>\n    import paddle2onnx.paddle2onnx_cpp2py_export as c_p2o\nImportError: /mnt/e/01-个人/02-project/Paddle2ONNX/paddle2onnx/paddle2onnx_cpp2py_export.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN6google8protobuf8internal14ArenaStringPtr3SetESt17basic_string_viewIcSt11char_traitsIcEEPNS0_5ArenaE\n\n环境：ubuntu22.02 (wsl)\n\n首先完全依靠本地编译流程，报错后尝试卸载pip uninstall protobuf后尝试pip install protobuf不同版本，错误不变。",
        "state": "closed",
        "user": "ToxicYP",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-02-19T07:43:25+00:00",
        "updated_at": "2025-06-10T02:58:16+00:00",
        "closed_at": "2025-06-10T02:58:15+00:00",
        "comments_count": [
            "0x3878f",
            "github-actions[bot]",
            "kankj",
            "yokingma",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1510,
        "title": "paddle2onnx version:1.3.1, have a bug",
        "body": "When I execute\npaddle2onnx --model_dir . --model_filename demark.pdmodel --params_filename demark.pdiparams --save_file bankcard_main_rtdetr.onnx\nError message：\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: ./demark.pdmodel\n[Paddle2ONNX] Parameters file path: ./demark.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[ERROR] Cannot found attribute padding_algorithm in op: conv2d_transpose\nzsh: abort      paddle2onnx --model_dir . --model_filename demark.pdmodel --params_filename\n\nI checked the attribute of the conv2d_transpose op in the paddle model through Netron and it does not contain padding_algorithm.\nIf the attribute of the conv2d_transpose op in the paddle model does not contain padding_algorithm, the conversion will fail.\n\nI checked the source code of version 1.3.1. The code logic in the following locations is unreasonable. Please correct it. It should be compatible with the situation without these fields.\n\nPaddle2ONNX-1.3.1/paddle2onnx/parser/parser.cc：627\nPaddle2ONNX-1.3.1/paddle2onnx/mapper/nn/conv2d_transpose.cc\n\n",
        "state": "closed",
        "user": "zhouleiMax",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-02-20T12:37:41+00:00",
        "updated_at": "2025-04-06T02:45:15+00:00",
        "closed_at": "2025-04-06T02:45:14+00:00",
        "comments_count": [
            "risemeup1",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1515,
        "title": "paddle2onnx 转换 PP-FormulaNet-S 模型失败",
        "body": "**问题描述**\n直接从官网`https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0rc0/PP-FormulaNet-S_infer.tar`下载推理模型，然后使用paddle2onnx命令行工具将推理模型转为onnx格式时报错。所有工具均按照官网安装方式安装了新版本。\n出错后也尝试将paddlepaddle切换为更低版本，也不能解决问题，错误提示是不能解析json格式的模型文件。\n\n\n**更多信息 :**\n- Paddle2ONNX及依赖版本信息如下：\n```text\nonnx                           1.17.0\nonnxruntime               1.20.1\npaddle2onnx               2.0.0\npaddlefsl                     1.1.0\npaddlenlp                    2.8.0.post0\npaddleocr                    0.1.0.dev1+g557ea76\npaddlepaddle-gpu      3.0.0rc0\npaddlex                        3.0.0rc0\n```\n - 用于部署的推理引擎:  onnxruntime\n - 为什么需要转换为ONNX格式：用于在边缘计算设备上部署\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/083514a5-76c5-47d7-b793-c33cca221dc7)\n\n",
        "state": "closed",
        "user": "lonjoy",
        "closed_by": "0x3878f",
        "created_at": "2025-02-25T03:53:31+00:00",
        "updated_at": "2025-04-22T06:38:50+00:00",
        "closed_at": "2025-04-22T06:38:50+00:00",
        "comments_count": [
            "0x3878f",
            "Devcode518",
            "0x3878f",
            "Devcode518",
            "0x3878f"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1525,
        "title": "python3.8版本下paddle2onnx最高版本只有1.3.1",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\n\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：\n - Paddle2ONNX版本:\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/97d46b6c-4405-4bf9-b854-3bd100faa837)\n\n**其他信息**\n",
        "state": "closed",
        "user": "jingsongliujing",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-03-03T09:22:41+00:00",
        "updated_at": "2025-04-17T02:44:46+00:00",
        "closed_at": "2025-04-17T02:44:45+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1526,
        "title": "关于PPMobileSeg模型转onnx模型推理结果为空",
        "body": "请教一下，我使用的是PaddleSeg-2.8.0deploy中onnxruntime_cpp的demo示例，推理官方下载的模型时结果OK,但是推理通过Paddle2Onnx转的模型时，绘制结果信息时报错，请教一下这种情况如何修改呢？输入尺寸是1522*1522\n\n![Image](https://github.com/user-attachments/assets/157ad166-2adb-4e37-bfb5-67d98053c4cc)\n\n![Image](https://github.com/user-attachments/assets/a9efbf5e-cc34-48fa-93e7-e70681dc3b5a)",
        "state": "closed",
        "user": "Hold-on-li",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-03-12T01:26:20+00:00",
        "updated_at": "2025-04-25T02:46:58+00:00",
        "closed_at": "2025-04-25T02:46:58+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1527,
        "title": "kie的re模型现在转换Onnx是否可以？DenseTensorArray在新版中支持吗",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\n[Paddle2ONNX] DenseTensorArray is not supported.\n[Paddle2ONNX] Oops, there are some operators not supported yet, including bilinear_tensor_product,lod_array_length,tensor_array_to_tensor,while,write_to_array,\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：\n - Paddle2ONNX版本:\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n\n**其他信息**\n",
        "state": "closed",
        "user": "charmsoya",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-03-12T03:11:47+00:00",
        "updated_at": "2025-04-26T02:40:27+00:00",
        "closed_at": "2025-04-26T02:40:26+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1532,
        "title": "转onnx，设置opset_version 低于14 失败",
        "body": "需要转出opset为12 的onnx，但该算子导致失败，该用哪个版本或是如何修改能成功导出呢？\n**错误：**\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: ch_PP-OCRv3_det_infer/inference.pdmodel\n[Paddle2ONNX] Parameters file path: ch_PP-OCRv3_det_infer/inference.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] Due to the operator: hard_swish, requires opset_version >= 14.\n[Paddle2ONNX] Opset version will change to 14 from 11\n[Paddle2ONNX] Use opset_version = 14 for ONNX export.\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.",
        "state": "closed",
        "user": "YuLionel",
        "closed_by": "0x3878f",
        "created_at": "2025-03-20T11:28:45+00:00",
        "updated_at": "2025-05-21T04:48:13+00:00",
        "closed_at": "2025-03-20T12:13:26+00:00",
        "comments_count": [
            "YuLionel",
            "OrdinaryChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1533,
        "title": "SLANet_plus 表格识别模型 转换报错",
        "body": "你好 又遇到这个情况吗\nhttps://github.com/PaddlePaddle/PaddleX/issues/3656#issuecomment-2742138567",
        "state": "closed",
        "user": "lyc728",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-03-21T05:39:35+00:00",
        "updated_at": "2025-06-12T02:55:57+00:00",
        "closed_at": "2025-06-12T02:55:57+00:00",
        "comments_count": [
            "github-actions[bot]",
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1536,
        "title": "Paddelx 中的 SLANeXt_wired 、SLANeXt_wireless 模型使用 ORT 进行推理，初始化、执行推理阶段有大量异常日志",
        "body": "# 1.  问题概述\n场景说明：\n- 使用 Paddelx 表格识别产线 V2 中的相关模型（SLANeXt_wired 、SLANeXt_wireless）\n- 转换为 ONNX 格式后，使用 ORT 执行推理\n\n期望帮助：\n- 这种日志有影响吗\n- 是什么原因造成的，能否解决\n\n版本说明：\n- paddlepaddle  3.0.0rc1 + paddle2onnx 2.0.0 \n- paddlepaddle  2.4.2 + paddle2onnx 1.3.1 \n- onnxruntime   1.16.3 （运行环境）\n\n[模型下载地址](https://paddlepaddle.github.io/PaddleX/latest/pipeline_usage/tutorials/ocr_pipelines/table_recognition_v2.html#1-v2)\n\n# 2. ONNX 转换\n执行命令：\n`\npaddle2onnx --model_dir ./SLANeXt_wired_infer  --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file ./SLANeXt_wired_infer_onnx/model.onnx  --enable_onnx_checker True\n`\n输出日志：\n`\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: ./SLANeXt_wired_infer/inference.pdmodel\n[Paddle2ONNX] Parameters file path: ./SLANeXt_wired_infer/inference.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] [range: range_0.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_1.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_0.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_2.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_3.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_1.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_0.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_1.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_0.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_4.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_5.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_2.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_6.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_7.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_3.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_2.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_3.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_1.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_8.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_9.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_4.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_10.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_11.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_5.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_4.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_5.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_2.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_12.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_13.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_6.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_14.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_15.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_7.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_6.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_7.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_3.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_16.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_17.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_8.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_18.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_19.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_9.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_8.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_9.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_4.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_20.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_21.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_10.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_22.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_23.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_11.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_10.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_11.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_5.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_24.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_25.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_12.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_26.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_27.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_13.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_12.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_13.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_6.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_28.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_29.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_14.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_30.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_31.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_15.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_14.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_15.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_7.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_32.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_33.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_16.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_34.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_35.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_17.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_16.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_17.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_8.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_36.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_37.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_18.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_38.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_39.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_19.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_18.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_19.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_9.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_40.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_41.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_20.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_42.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_43.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_21.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_20.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_21.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_10.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [range: range_44.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_45.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_22.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_46.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [range: range_47.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [gather_nd: gather_nd_23.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [einsum: einsum_22.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [einsum: einsum_23.tmp_0] Requires the minimal opset version of 12.\n[Paddle2ONNX] [gelu: gelu_11.tmp_0] Requires the minimal opset version of 9.\n[Paddle2ONNX] [reduce_mean: mean_0.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [reduce_mean: mean_1.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [reduce_mean: mean_2.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [reduce_mean: mean_3.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] Detected there's control flow 'while' op in your model, this requires the minimal opset version of 13.\n[Paddle2ONNX] [slice: set_value_0.tmp_0_slice_0] While has input StartsTensorList/EndsTensorListStridesTensorList, Requires the minimal opset version of 10.\n[Paddle2ONNX] [slice: set_value_1.tmp_0_slice_0] While has input StartsTensorList/EndsTensorListStridesTensorList, Requires the minimal opset version of 10.\n[Paddle2ONNX] [reduce_any: any_0.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] [reduce_all: all_0.tmp_0] Requires the minimal opset version of 11.\n[Paddle2ONNX] Detected there's control flow op('conditional_block/select_input') in your model, this requires the minimal opset version of 11.\n[Paddle2ONNX] Due to the operator: einsum, requires opset_version >= 12.\n[Paddle2ONNX] Due to the operator: range, requires opset_version >= 11.\n[Paddle2ONNX] Due to the operator: set_value, requires opset_version >= 17.\n[Paddle2ONNX] Due to the operator: while, requires opset_version >= 13.\n[Paddle2ONNX] Opset version will change to 17 from 9\n[Paddle2ONNX] Use opset_version = 17 for ONNX export.\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n`\n# 3.  创建会话\n`\n            sess = ort.InferenceSession(\n                model_file_path,\n                providers=[\n                    (\n                        \"CUDAExecutionProvider\",\n                        {\"device_id\": args.gpu_id, \"cudnn_conv_algo_search\": \"DEFAULT\"},\n                    )\n                ],\n                sess_options=sess_options,\n            )\n`\n异常日志：\n`\n2025-03-25 14:14:49.081870040 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n2025-03-25 14:14:49.081910008 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n2025-03-25 14:14:49.229537068 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n2025-03-25 14:14:49.229561428 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n2025-03-25 14:14:49.959922404 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '_generated_var_1' source:{1} target:{}. Falling back to lenient merge.\n2025-03-25 14:14:49.999473826 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.790'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999504073 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.805'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999514453 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.796'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999524577 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.802'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999536624 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.793'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999908291 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.787'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999920436 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.799'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:49.999933465 [W:onnxruntime:, graph.cc:3553 CleanUnusedInitializersAndNodeArgs] Removing initializer 'helper.constant.808'. It is not used by any node and should be removed from the model.\n2025-03-25 14:14:50.586072192 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n`\n# 4.  执行推理\n异常日志：\n`\n2025-03-24 16:53:01.611704424 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.612244741 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.613187076 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.613592435 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.614392891 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.614752119 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.615504006 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.615847414 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.616627505 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.616985472 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.617743120 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.618092058 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.618973103 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.619345862 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.620089552 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.620431435 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.621174364 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.621530354 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.622274616 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n2025-03-24 16:53:01.622626997 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output fill_constant_1047.tmp_0.0\n2025-03-24 16:53:01.623350835 [W:onnxruntime:, execution_frame.cc:857 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {1} for output logical_and_0.tmp_0.0\n`",
        "state": "closed",
        "user": "pearl88",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-03-26T06:08:09+00:00",
        "updated_at": "2025-06-12T02:55:56+00:00",
        "closed_at": "2025-06-12T02:55:56+00:00",
        "comments_count": [
            "github-actions[bot]",
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1537,
        "title": "Paddle2ONNX无法正常导出PaddleSeg中rtformer模型",
        "body": "基于PaddleSeg导出了rtformer模型：\n```\npython tools/export.py --config configs/rtformer/rtformer_slim_ade20k_512x512_160k.yml --model_path model.pdparams --save_dir output/inference_model --input_shape 1 3 512 512\n```\n\n利用Paddle2ONNX无法正常导出onnx格式模型:\n```\npaddle2onnx --model_dir ./output/inference_model --model_filename model.json --params_filename model.pdiparams  --opset_version 11  --save_file model.onnx\n/home/liu/.local/lib/python3.8/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\n[Paddle2ONNX] Start to parse PaddlePaddle model...\n[Paddle2ONNX] Model file path: ./output/inference_model/model.json\n[Paddle2ONNX] Parameters file path: ./output/inference_model/model.pdiparams\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] Failed to parse paddlepaddle model from read content.\n[Paddle2ONNX] Failed to load program of PaddlePaddle model.\n[Paddle2ONNX] Paddle model parsing failed.\n[Paddle2ONNX] Paddle model convert failed.\n```\n版本：\n```\npaddle2onnx                  1.3.1\npaddlepaddle                 3.0.0\n```",
        "state": "closed",
        "user": "damon-liush",
        "closed_by": "damon-liush",
        "created_at": "2025-03-31T05:50:30+00:00",
        "updated_at": "2025-03-31T06:46:38+00:00",
        "closed_at": "2025-03-31T06:46:38+00:00",
        "comments_count": [
            "damon-liush"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1540,
        "title": "使用bilinear的Upsample模型导出onnx，在onnxruntime中运行时报错",
        "body": "环境\npaddle2onnx              2.0.0\npaddlepaddle             3.0.0rc0\nonnxruntime              1.21.0\n\n使用如下代码导出含有Upsample的onnx模型\n```\nimport paddle\nimport paddle.nn.functional as F\nimport onnxruntime as rt\n\nclass Upsample(paddle.nn.Layer):\n    def forward(self, x):\n        return F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n\nm = Upsample()\nv = paddle.static.InputSpec([None, 1, 28, 28], 'float32', 'x')\n\npaddle.onnx.export(m, \"test\", input_spec=[v], opset_version=11)\nsess = rt.InferenceSession(\"test.onnx\")\n```\n会遇到如下报错：\n```\n2025-04-03 16:15:52.444010404 [E:onnxruntime:, inference_session.cc:2105 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/upsamplebase.h:278 onnxruntime::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const std::string&) mode attribute is . It can only be nearest(default) or linear or cubic.\n\nTraceback (most recent call last):\n  File \"/home/pc/yolotest/bilinearerror.py\", line 18, in <module>\n    sess = rt.InferenceSession(\"test.onnx\")\n  File \"/home/pc/miniconda3/envs/pad30/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 419, in __init__\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\n  File \"/home/pc/miniconda3/envs/pad30/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 491, in _create_inference_session\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/upsamplebase.h:278 onnxruntime::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const std::string&) mode attribute is . It can only be nearest(default) or linear or cubic.\n```",
        "state": "closed",
        "user": "kankj",
        "closed_by": "0x3878f",
        "created_at": "2025-04-03T08:29:31+00:00",
        "updated_at": "2025-04-14T08:05:22+00:00",
        "closed_at": "2025-04-14T08:05:06+00:00",
        "comments_count": [
            "kankj",
            "kankj",
            "0x3878f"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1541,
        "title": "Linux环境，PaddleDetection的yolo系列模型转换成onnx以后，onnxruntime报错Op (Gather) [ShapeInferenceError] data tensor must have rank >= 1",
        "body": "环境\npaddlepaddle==3.0.0rc\npaddledet==2.8.1\npaddle2onnx==1.3.1\nonnxruntime==1.21.0\n\n**在windows和linux下**，使用PaddleDetection的教程转换yolo系列模型（yolov3、pp-yoloe等，但是picodet模型是正常的）到onnx，导入到onnxruntime时发生以下错误\n```\nTraceback (most recent call last):\n  File \"/home/pc/yolotest/onnx_test.py\", line 3, in <module>\n    sess=rt.InferenceSession('yolov3.onnx')\n  File \"/home/pc/miniconda3/envs/pad30/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 419, in __init__\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\n  File \"/home/pc/miniconda3/envs/pad30/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 472, in _create_inference_session\n    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from yolov3.onnx failed:Node (Gather.12) Op (Gather) [ShapeInferenceError] data tensor must have rank >= 1\n```\n\n经过我的验证**onnxruntime<=1.17.x时onnx模型可以正确导入**，上面报错发生在onnxruntime>=1.18.x\n根据 #1423 在macOS下不会产生上面的问题。\n\n希望官方能给出windows和linux下问题的解决方案，谢谢",
        "state": "closed",
        "user": "kankj",
        "closed_by": "kankj",
        "created_at": "2025-04-05T07:45:06+00:00",
        "updated_at": "2025-04-11T06:16:04+00:00",
        "closed_at": "2025-04-11T06:16:02+00:00",
        "comments_count": [
            "kankj"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1542,
        "title": "DBnet++转onnx算子不支持",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\ndeformable_conv算子不支持\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：\n - Paddle2ONNX版本:\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/53865828-ece0-4894-b793-89962b7c5af2)\n\n**其他信息**\n\n![Image](https://github.com/user-attachments/assets/546c932a-04b3-4365-8a47-c23e32f48227)\npaddle工程2.9",
        "state": "closed",
        "user": "LJY6356",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-04-07T07:48:56+00:00",
        "updated_at": "2025-05-22T02:52:16+00:00",
        "closed_at": "2025-05-22T02:52:15+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1556,
        "title": "PaddleOCR 转换为onnx ，支持c++多线程多次推理吗？",
        "body": "c++库进行模型的多线程推理，出现开辟内存时的报错。",
        "state": "closed",
        "user": "hellochengdu",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-04-16T05:41:27+00:00",
        "updated_at": "2025-05-31T02:49:36+00:00",
        "closed_at": "2025-05-31T02:49:35+00:00",
        "comments_count": [
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1560,
        "title": "转换PP-DocLayout-L的时候失败",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\n\n**Describe the bug**\n 把来自paddlex的PP-DocLayout-L 转换为onnx\npaddle2onnx --model_dir PP-DocLayout-L --model_filename inference.pdmodel  --params_filename inference.pdiparams --save_file PP-DocLayout-L.onnx\n\n\n**Informations (please complete the following information):**\n - Inference engine for deployment:\n - Why convert to onnx：speed\n - Paddle2ONNX Version: 2.0.1\n - Email/Wechat/Phone:\n\n**Screenshots**\n\n<img width=\"912\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/503b51a0-ab58-44ed-adb7-d9529c51edaf\" />\n\n**Additional context**\n转换PP-DocLayout-S，PP-DocLayout-M 正常",
        "state": "closed",
        "user": "cole-dda",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-04-24T01:54:46+00:00",
        "updated_at": "2025-06-12T02:55:55+00:00",
        "closed_at": "2025-06-12T02:55:55+00:00",
        "comments_count": [
            "0x3878f",
            "luoxzhg",
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1562,
        "title": "公式识别模型PP-FormulaNet-L转onnx后推理重复输出",
        "body": "\n**问题描述**\n转onnx推理重复输出\n识别结果: ['S= \\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } { 2 } \\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\times\\\\frac{ 1 } \\\\times\\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times\\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\times\\\\frac{ 1 } \\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\frac{ 1 } \\\\times\\\\frac{ 1 } \\\\times{ 2 } \\\\frac{ 1 } \\\\times} \\\\frac{ { 1 2 } \\\\times} \\\\frac{ \\\\frac{ 1 } } \\\\frac\\\\times{ 1 } { 1 } \\\\frac\\\\frac{ 1 } { 1 } \\\\frac{ \\\\frac} { 1 } \\\\frac{ \\\\']\n\n",
        "state": "closed",
        "user": "brave123964",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-04-27T07:01:18+00:00",
        "updated_at": "2025-07-06T03:08:42+00:00",
        "closed_at": "2025-07-06T03:08:42+00:00",
        "comments_count": [
            "0x3878f",
            "brave123964",
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1570,
        "title": "[Windows] 无法转换Paddle3.0.0的json格式paddle inference模型",
        "body": "**Please fill in the information below so that we can solve the problem quickly, Thanks !**\n\n**Describe the bug**\n使用PDX 3.0rc1 训练时序缺陷检测后导出的模型无法转换\n\n**Informations (please complete the following information):**\n - Inference engine for deployment: PD INFERENCE 3.0-->onnxruntime\n - Why convert to onnx：在端侧设备上部署\n - Paddle2ONNX Version: 1.3.1\n - Email/Wechat/Phone:\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/e6fe71bb-23cd-47ce-83a1-36bab5ea0331)\n\n**Additional context**\n",
        "state": "closed",
        "user": "kisaragychihaya",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-04-28T08:53:33+00:00",
        "updated_at": "2025-07-06T03:08:40+00:00",
        "closed_at": "2025-07-06T03:08:40+00:00",
        "comments_count": [
            "Rogerlv51",
            "0x3878f",
            "Rogerlv51",
            "0x3878f",
            "Rogerlv51",
            "Rogerlv51",
            "0x3878f",
            "Rogerlv51",
            "0x3878f",
            "KeyKy",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1573,
        "title": "无法导出ONNX",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\n使用RT-DETR V3导出ONNX的时候，遇见报错\n\n**更多信息 :**\n - 用于部署的推理引擎:RT-Detr V3\n - 为什么需要转换为ONNX格式：用于部署\n - Paddle2ONNX版本: pip install onnx==1.13.0 pip install paddle2onnx==1.0.5\n - 你的联系方式(Email/Wechat/Phone):921137655@qq.com\n\n**报错截图**\n\n<!-- Failed to upload \"bce49b0b3b19dce80380d9b7dca6a6e.png\" -->\n\n**其他信息**\n步骤\n1.python tools/export_model.py -c configs/rtdetrv3/rtdetrv3_r18vd_6x_coco.yml \\\n              -o weights=https://bj.bcebos.com/v1/paddledet/models/rtdetrv3_r18vd_6x_coco.pdparams trt=True \\\n              --output_dir=output_inference\n2.paddle2onnx --model_dir=./output_inference/rtdetrv3_r18vd_6x_coco/ \\\n            --model_filename model.pdmodel  \\\n            --params_filename model.pdiparams \\\n            --opset_version 16 \\\n            --save_file rtdetrv3_r18vd_6x_coco.onnx",
        "state": "closed",
        "user": "yjdzyr",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-05-09T14:23:16+00:00",
        "updated_at": "2025-06-26T02:57:42+00:00",
        "closed_at": "2025-06-26T02:57:42+00:00",
        "comments_count": [
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1575,
        "title": "无法在mac x64下运行",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n在mac安装后无法使用\n\npaddle2onnx       2.0.1\n\n\npip install paddle2onnx\n\n原因：系统为x64，安装后，自带的so文件为arm64，不兼容\n\n<img width=\"971\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d8260ac8-0cf6-40ce-bf85-38a01d44a884\" />\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：\n - Paddle2ONNX版本:\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n\n**其他信息**\n",
        "state": "closed",
        "user": "cole-dda",
        "closed_by": "github-actions[bot]",
        "created_at": "2025-05-19T06:19:18+00:00",
        "updated_at": "2025-07-05T02:52:33+00:00",
        "closed_at": "2025-07-05T02:52:33+00:00",
        "comments_count": [
            "0x3878f",
            "github-actions[bot]",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1580,
        "title": "[Windows] 通过 infer_paddle_model_shape.py 修改 PP-OCRv5_mobile_det_infer 模型输入 shape 失败",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n\n运行提供的脚本文件 tools/paddle/infer_paddle_model_shape.py 修改 PP-OCRv5 文本检测模型的输入 shape 失败\n\n\n**更多信息 :**\n - 用于部署的推理引擎: tensorRT\n - 为什么需要转换为ONNX格式：端侧部署，需要模型输入宽高静态\n - Paddle2ONNX版本: 2.0.2rc1\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/85e8ccc6-23d8-49e7-acca-2a8c3c4d375e)\n\n**其他信息**\n\n- paddle2paddle 3.0.0.dev20250523\n- paddlex 3.0.0",
        "state": "open",
        "user": "Melody-Zhou",
        "closed_by": null,
        "created_at": "2025-05-24T08:16:11+00:00",
        "updated_at": "2025-06-29T03:10:48+00:00",
        "closed_at": null,
        "comments_count": [
            "Melody-Zhou",
            "qingyanbaby",
            "qingyanbaby",
            "Melody-Zhou",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1578,
        "title": "目前新版本Paddle2ONNX还支持导出FP16吗？",
        "body": "https://github.com/PaddlePaddle/Paddle2ONNX/commit/516f15180a71350fe354ea710a5eddbb05bf2999\n\n我查看了README的更新记录，在这一次更新中，删除了export_fp16_model的描述，是不是意味着新版本的Paddle2ONNX已经不支持FP16的导出？",
        "state": "closed",
        "user": "188080501",
        "closed_by": "188080501",
        "created_at": "2025-05-23T03:28:46+00:00",
        "updated_at": "2025-05-23T07:19:26+00:00",
        "closed_at": "2025-05-23T07:19:25+00:00",
        "comments_count": [
            "0x3878f",
            "188080501"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1581,
        "title": "转换成功但是报错",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n请在此处详细的描述报错信息\n在转化的过程中出现：\n C:\\Users\\dsa86\\Desktop\\model\\PP-OCRv5_mobile_det_infer>paddle2onnx --model_dir ./ --model_filename inference.json --params_filename inference.pdiparams --save_file det.onnx\n信息: 用提供的模式无法找到文件。\nC:\\Users\\dsa86\\conda\\envs\\ppocrv5\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\n[Paddle2ONNX] Start parsing the Paddle model file...\n[Paddle2ONNX] Use opset_version = 14 for ONNX export.\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n2025-05-24 19:39:35 [INFO]      Try to perform constant folding on the ONNX model with Polygraphy.\n[W] 'colored' module is not installed, will not use colors when logging. To enable colors, please install the 'colored' module: python3 -m pip install colored\n[I] Folding Constants | Pass 1\n[W] colored module is not installed, will not use colors when logging. To enable colors, please install the colored module: python3 -m pip install colored\n[W] Inference failed. You may want to try enabling partitioning to see better results. Note: Error was:\n[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: D:\\a\\_work\\1\\s\\onnxruntime\\core\\graph\\model.cc:181 onnxruntime::Model::Model Unsupported model IR version: 11, max supported IR version: 10\n[I]     Total Nodes | Original:   925, After Folding:   612 |   313 Nodes Folded\n[I] Folding Constants | Pass 2\n[W] colored module is not installed, will not use colors when logging. To enable colors, please install the colored module: python3 -m pip install colored\n[W] Inference failed. You may want to try enabling partitioning to see better results. Note: Error was:\n[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: D:\\a\\_work\\1\\s\\onnxruntime\\core\\graph\\model.cc:181 onnxruntime::Model::Model Unsupported model IR version: 11, max supported IR version: 10\n[I]     Total Nodes | Original:   612, After Folding:   612 |     0 Nodes Folded\n2025-05-24 19:39:47 [INFO]      ONNX model saved in det.onnx.\n\n**更多信息 :**\n - 用于部署的推理引擎:\n - 为什么需要转换为ONNX格式：统一推理平台所必须的\n - Paddle2ONNX版本:2.0.2rc1\n - 你的联系方式(Email/Wechat/Phone):dsa869080@126.com\n\n**报错截图**\n\n![Image](https://github.com/user-attachments/assets/ad659c32-4aed-4f76-bb2b-6d153d8df01f)\n\n**其他信息**\nonnx版本为1.19.2",
        "state": "open",
        "user": "winter-summer",
        "closed_by": null,
        "created_at": "2025-05-24T12:49:00+00:00",
        "updated_at": "2025-06-26T02:57:41+00:00",
        "closed_at": null,
        "comments_count": [
            "SWHL",
            "openvino-book",
            "openvino-book",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1583,
        "title": "转的时候提示需要低版本的paddlepaddle",
        "body": "paddle2onnx --model_dir D:\\paddle\\model_ocr\\det\\PP-OCRv5_server_det --model_filename inference.json --params_filename inference.pdiparams --save_file ./onnx_model/\n\n报错\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\conda\\envs\\pdocr\\Scripts\\paddle2onnx.exe\\__main__.py\", line 4, in <module>\n  File \"C:\\conda\\envs\\pdocr\\Lib\\site-packages\\paddle2onnx\\__init__.py\", line 38, in <module>\n    raise ValueError(\nValueError: The paddlepaddle version should not be less than 3.0.0.dev20250426. Please install the latest paddle: python -m pip install --pre paddlepaddle -i https://www.paddlepaddle.org.cn/packages/nightly/cpu/, more information: https://www.paddlepaddle.org.cn/install/quick?docurl=undefined\n\n\nv4/v5版本我都不行，paddle2onnx ==2.0.2rc1，paddlepaddle-gpu ==3.0.0，paddlex == 3.0.0\n",
        "state": "open",
        "user": "EstGarcon",
        "closed_by": null,
        "created_at": "2025-05-28T09:40:13+00:00",
        "updated_at": "2025-06-30T03:06:49+00:00",
        "closed_at": null,
        "comments_count": [
            "EstGarcon",
            "congyao123456",
            "ljq97",
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1584,
        "title": "paddle2onnx报错",
        "body": "windows系统执行：\npaddle2onnx --model_dir mobilenetv3 --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file model.onnx --enable_dev_version True --opset_version 13 --enable_onnx_checker True\n报错：\n信息: 用提供的模式无法找到文件。\nC:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\nTraceback (most recent call last):\n  File \"C:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\Scripts\\paddle2onnx.exe\\__main__.py\", line 4, in <module>\n  File \"C:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle2onnx\\__init__.py\", line 47, in <module>\n    from .convert import export  # noqa: F401\n  File \"C:\\Users\\sunjian\\Anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle2onnx\\convert.py\", line 18, in <module>\n    import paddle2onnx.paddle2onnx_cpp2py_export as c_p2o\nImportError: DLL load failed while importing paddle2onnx_cpp2py_export: 找不到指定的程序。\n",
        "state": "open",
        "user": "congyao123456",
        "closed_by": null,
        "created_at": "2025-05-30T05:24:35+00:00",
        "updated_at": "2025-06-30T03:06:48+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1585,
        "title": "Facing padddle issue",
        "body": "[expedia teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/instant-call-mx-52-c%C3%B3mo-hablar-con-un-agente-de-expedia-1-6-2025)\n[expedia teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/expedia-c%C3%B3mo-hablar-con-un-agente-de-expedia-1-6-2025)\n[expedia teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/52-expedia-c%C3%B3mo-hablar-con-un-agente-de-expedia-1-6-2025)\n[american teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/american-airlines-telefono-m%C3%A9xico-c%C3%B3mo-llamo-a-american-airlines-desde-m%C3%A9xico)\n[american teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/52-american-mx-c%C3%B3mo-comunicarse-con-un-humano-en-american-airlines)\n[american teléfono méxico](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/ayuda-c%C3%B3mo-llamar-a-american-airlines-desde-m%C3%A9xico)\n[Copa Telefono Colombia](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/oficinas-copa-tel%C3%A9fono-colombia-c%C3%B3mo-llamar-a-copa-airlines-desde-colombia)\n[Copa Telefono Colombia](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/copa-tele-f0n0-34-c%C3%B3mo-hablo-con-una-persona-viva-en-copa-airlines)\n[Copa Telefono Colombia](https://mexicotravelayuda.zohodesk.com/portal/en/kb/articles/copa-telefono-bogota-c%C3%B3mo-puedo-comunicarme-con-la-copa)\n[expedia teléfono méxico](https://yatramantra.com/topic/instantcallmx52-como-hablar-con-un-agente-de-expedia/)\n[expedia teléfono méxico](https://yatramantra.com/topic/expediacomo-hablar-con-un-agente-de-expedia-4/)\n[expedia teléfono méxico](https://yatramantra.com/topic/52expediacomo-hablar-con-un-agente-de-expedia/)\n[Copa Telefono Colombia](https://yatramantra.com/topic/guia-rapida-cual-es-el-numero-de-telefono-de-copa-airlines-en-colombia/)\n[Copa Telefono Colombia](https://yatramantra.com/topic/oficinas-copa-telefono-como-llamar-a-copa-airlines-desde-colombia/)\n[Copa Telefono Colombia](https://yatramantra.com/topic/como-llamar-a-copa-airlines-desde-colombia/)\n[Copa Telefono Colombia](https://yatramantra.com/topic/copa-telefono-bogotacomo-puedo-comunicarme-con-la-copa/)\n[Copa Telefono Colombia](https://yatramantra.com/topic/ua-57-colombia-como-llamar-a-copa-airlines-desde-colombia/)\n[KLM teléfono méxico](https://yatramantra.com/topic/52-klm-telefono-mexico-como-llamar-a-klm-desde-mexico/)\n[KLM teléfono méxico](https://yatramantra.com/topic/guia-rapida-como-hablo-con-un-agente-de-klm-2/)\n[KLM teléfono méxico](https://yatramantra.com/topic/klm-telefono-mexicocomo-hablo-con-un-agente-de-klm/)\n[KLM teléfono méxico](https://yatramantra.com/topic/klm-telefonocomo-hablo-con-un-agente-de-klm-guia-para/)\n[KLM teléfono méxico](https://yatramantra.com/topic/como-hablo-con-un-agente-de-klm-centro-de-ayuda-aerea/)\n[KLM teléfono méxico](https://yatramantra.com/topic/mexicocomo-hablo-con-un-agente-de-klm/)",
        "state": "open",
        "user": "connormecreghor",
        "closed_by": null,
        "created_at": "2025-06-02T10:43:37+00:00",
        "updated_at": "2025-07-03T02:59:57+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1586,
        "title": "paddle2onnx报错，三个算子不支持ctc_align,im2sequence,lstm",
        "body": " - 模型权重使用的是paddle1.8版本增训的，因客观原因，无法替换模型权重，所以尝试将paddle1.8转换成onnx\n - Paddle2ONNX版本:0.7和1.1都试了\n - 你的联系方式(Email/Wechat/Phone):\n852501294@qq.com\n**报错截图**\nPaddle2ONNX==0.7\nThere's 2 ops are not supported yet\n=========== ctc_align ===========\n=========== lstm ===========\n\nPaddle2ONNX==1.1\n[Paddle2ONNX] Start to parsing Paddle model...\n[Paddle2ONNX] Oops, there are some operators not supported yet, including ctc_align,im2sequence,lstm,\n",
        "state": "open",
        "user": "Smilty-z",
        "closed_by": null,
        "created_at": "2025-06-05T02:01:48+00:00",
        "updated_at": "2025-07-05T02:52:30+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1592,
        "title": "使用paddle2onnx 轉.onnx沒辦法成功會無回應跳出程序",
        "body": "我將當前訓練好的rtformer模型輸出成.onnx\npaddle2onnx.export(model_filename=\"output/inference_model/inference.json\",\n                   params_filename=\"output/inference_model/inference.pdiparams\",\n                   save_file=\"output/onnx/rtformer.onnx\",\n                   opset_version=19)\n\n顯示訊息:\n[Paddle2ONNX] Start parsing the Paddle model file...\n[Paddle2ONNX] Use opset_version = 19 for ONNX export.\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n2025-06-19 15:00:26 [INFO]      Try to perform constant folding on the ONNX model with Polygraphy.\n[I] Folding Constants | Pass 1\n[W] Falling back to `onnx.shape_inference` because `onnxruntime.tools.symbolic_shape_infer` either could not be loaded or did not run successfully.\n    Note that using ONNX-Runtime for shape inference may be faster and require less memory.\n    Consider installing ONNX-Runtime or setting POLYGRAPHY_AUTOINSTALL_DEPS=1 in your environment variables to allow Polygraphy to do so automatically.\n\n問題:\n1.會沒有回應直接跳出，然後也沒有輸出.onnx檔案出來，改用opset_version=11~13一樣無法產出。\n2.將optimize_tool=None可以產生出.onnx，但是輸出的.onnx檔案無法使用onnxruntime進行推理，使用check是正常但使用onnxruntime.InferenceSession會無回應後跳出程序。\n\n\n版本資訊\nName: paddlepaddle-gpu\nVersion: 3.0.0.dev20250609\n\nName: paddle2onnx\nVersion: 2.0.2rc3\n\nName: onnx\nVersion: 1.17.0\n\nName: onnxruntime\nVersion: 1.22.0\n\n再麻煩協助幫忙!",
        "state": "open",
        "user": "chiawei2002",
        "closed_by": null,
        "created_at": "2025-06-19T07:11:27+00:00",
        "updated_at": "2025-06-19T07:11:27+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1588,
        "title": "关于picodet_l_640转onnx成功后无法转openvino模型",
        "body": "转onnx指令：paddle2onnx --model_dir=./model/ --model_filename model.pdmodel --params_filename model.pdiparams --opset_version 11 --save_file pinDet.onnx\n\n转IR指令：python mo_onnx.py --input_model \\model.onnx --mean_values [103.53,116.28,123.675] --scale_values [57.375,57.12,58.395]\n报如下错误\n\n![Image](https://github.com/user-attachments/assets/0b48c1ee-ca95-4fc8-8cf7-b4032380ae61)\n请问如何解决？",
        "state": "open",
        "user": "Hold-on-li",
        "closed_by": null,
        "created_at": "2025-06-06T08:05:23+00:00",
        "updated_at": "2025-07-07T03:06:57+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1587,
        "title": "PPOCRV5 compatibility when?",
        "body": "When will we be able to convert the PPOCRV5 models to onnx? I think we need an update to the library here to do that.",
        "state": "open",
        "user": "omare1abd",
        "closed_by": null,
        "created_at": "2025-06-05T03:01:53+00:00",
        "updated_at": "2025-07-06T03:08:36+00:00",
        "closed_at": null,
        "comments_count": [
            "github-actions[bot]"
        ],
        "labels": [
            "stale"
        ]
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1590,
        "title": "转换pp-doclatout-M成功，但转换后的模型检测精度差",
        "body": "**请将下面信息填写完整，便于我们快速解决问题，谢谢！**\n\n**问题描述**\n模型转换命令：\n!paddle2onnx --model_dir data \\\n            --model_filename inference.json \\\n            --params_filename inference.pdiparams \\\n            --save_file model.onnx\n\n转换过程输出：\n/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n  warnings.warn(warning_message)\n[Paddle2ONNX] Start parsing the Paddle model file...\n[Paddle2ONNX] Use opset_version = 14 for ONNX export.\n[WARNING][Paddle2ONNX] [OP: pd_op.multiclass_nms3] Due to the operator multiclass_nms3, the exported ONNX model will only supports inference with input batch_size == 1.\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n2025-06-12 14:20:36 [INFO]\tTry to perform optimization on the ONNX model with onnxoptimizer.\n2025-06-12 14:20:36 [INFO]\tONNX model saved in model.onnx.\n\n测试图片：\n![Image](https://github.com/user-attachments/assets/18c51e11-c71f-4b3b-97b8-09d935c31f24)\n\n原始模型的检测输出：\n[{'l': np.float32(3.4798708), 't': np.float32(-1.3024412), 'r': np.float32(884.8374), 'b': np.float32(492.47937), 'label': 'Table', 'confidence': np.float32(0.9345335)}]\n\n转换后的模型的检测输出：\n[{'l': np.float32(485.64996), 't': np.float32(221.84998), 'r': np.float32(485.64996), 'b': np.float32(221.84998), 'label': 'Table', 'confidence': np.float32(0.93453324)}, {'l': np.float32(485.64996), 't': np.float32(271.14996), 'r': np.float32(485.64996), 'b': np.float32(271.14996), 'label': 'Table', 'confidence': np.float32(0.8567435)}, {'l': np.float32(397.34998), 't': np.float32(221.84998), 'r': np.float32(397.34998), 'b': np.float32(221.84998), 'label': 'Table', 'confidence': np.float32(0.85119826)}, {'l': np.float32(397.34998), 't': np.float32(271.14996), 'r': np.float32(397.34998), 'b': np.float32(271.14996), 'label': 'Table', 'confidence': np.float32(0.72637796)}, {'l': np.float32(485.64996), 't': np.float32(172.54999), 'r': np.float32(485.64996), 'b': np.float32(172.54999), 'label': 'Table', 'confidence': np.float32(0.6198717)}, {'l': np.float32(397.34998), 't': np.float32(172.54999), 'r': np.float32(397.34998), 'b': np.float32(172.54999), 'label': 'Table', 'confidence': np.float32(0.4847417)}, {'l': np.float32(573.94995), 't': np.float32(221.84998), 'r': np.float32(573.94995), 'b': np.float32(221.84998), 'label': 'Table', 'confidence': np.float32(0.40300032)}]\n\n**更多信息 :**\n - 用于部署的推理引擎:onnxruntime-directml\n - 为什么需要转换为ONNX格式：需要基于onnxruntime-directml运行模型\n - Paddle2ONNX版本:2.0.1\n - 你的联系方式(Email/Wechat/Phone):\n\n**报错截图**\n参见“转换后的模型的检测输出”\n\n**其他信息**\npp-doclayout-M模型下载链接：https://huggingface.co/PaddlePaddle/PP-DocLayout-M",
        "state": "open",
        "user": "LuoTengBin",
        "closed_by": null,
        "created_at": "2025-06-12T06:23:12+00:00",
        "updated_at": "2025-06-16T20:18:12+00:00",
        "closed_at": null,
        "comments_count": [
            "tmzncty"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1596,
        "title": "使用v4的ocr检测（pdmodel、pdiparams）和使用转化之后的onnx模型做trt结果不对齐问题",
        "body": "1. 使用v4版本的ocr检测模型进行推理（原版pdmodel/pdiparams）\n2. 使用同样的模型，并使用paddle2onnx转onnx之后的模型，然后进行trt推理\n\n转换脚本为：\npaddle2onnx --model_dir /ch_PP-OCRv4_det_server_infer --model_filename inference.pdmodel  --params_filename inference.pdiparams --save_file /ch_PP-OCRv4_det_server_infer/inference.onnx\n从结果看，确实是误差并没有在0.1以内，我看90%的数据是0.0001以内，但是还有10%左右误差比较大，误差大的甚至到了0.1，这个怎么解决。",
        "state": "open",
        "user": "YoungSharp",
        "closed_by": null,
        "created_at": "2025-07-07T11:14:37+00:00",
        "updated_at": "2025-07-07T11:14:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1591,
        "title": "paddleocr3.0  recv4onnx 转换tensorrt 算子问题",
        "body": "🔎 Search before asking\n\nI have searched the PaddleOCR [Docs](https://paddlepaddle.github.io/PaddleOCR/) and found no similar bug report.\n\nI have searched the PaddleOCR [Issues](https://github.com/PaddlePaddle/PaddleOCR/issues) and found no similar bug report.\n\nI have searched the PaddleOCR [Discussions](https://github.com/PaddlePaddle/PaddleOCR/discussions) and found no similar bug report.\n🐛 Bug (问题描述)\nImage\n采用了官方给出转换onnx 实例，对recv4进行转换onnx 没有问题，转换trt 出现算子问题\n使用onnxslim 也会出现有一些算子不支持\n\nImage\n\n🏃‍♂️ Environment (运行环境)\nwin 10 cud11.6 tenosrrt8\n\n🌰 Minimal Reproducible Example (最小可复现问题的Demo)\nD:\\TensorRT-8.6.1.6\\bin\\trtexec.exe --onnx=Rec4.onnx --minShapes=x:1x3x48x160 --optShapes=x:1x3x48x320 --maxShapes=x:8x3x48x3200 --saveEngine=Rec4.engine",
        "state": "open",
        "user": "SHOUshou0426",
        "closed_by": null,
        "created_at": "2025-06-18T12:56:44+00:00",
        "updated_at": "2025-07-04T05:52:56+00:00",
        "closed_at": null,
        "comments_count": [
            "SHOUshou0426",
            "SHOUshou0426",
            "SHOUshou0426",
            "SHOUshou0426",
            "SHOUshou0426",
            "inisis",
            "SHOUshou0426",
            "inisis",
            "SHOUshou0426",
            "inisis",
            "inisis",
            "SHOUshou0426",
            "SHOUshou0426",
            "inisis",
            "SHOUshou0426",
            "SHOUshou0426",
            "SHOUshou0426"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Paddle2ONNX",
        "number": 1593,
        "title": "PP-FormulaNet_plus-S onnx error on gpu",
        "body": "CPU多次推理都是正确的。\nGPU第一次推理是正确的，返回的结果ndarray的shape是(1, 51)\nGPU后面几次推理结果的是错误的，返回的结果ndarray的shape是(1, 1026)\n\n\n### 依赖\n```\nonnx                     1.17.0\nonnx_graphsurgeon        0.5.8\nonnxoptimizer            0.3.13\nonnxruntime-gpu          1.22.0\nopt-einsum               3.3.0\npaddle2onnx              2.0.2rc3\npaddlepaddle-gpu         3.0.0.dev20250617\npaddlex                  3.0.2\n```\n\n### 测试用的图片\n\n![Image](https://github.com/user-attachments/assets/44d3c2ab-36ea-495a-8e5d-6518e2f607fd)\n\n### 复现代码\n[ningpp/tmp-paddlex-onnx](https://github.com/ningpp/tmp-paddlex-onnx)\n\nhttps://github.com/PaddlePaddle/PaddleX/issues/4238",
        "state": "open",
        "user": "ningpp",
        "closed_by": null,
        "created_at": "2025-06-27T00:46:12+00:00",
        "updated_at": "2025-07-04T12:29:54+00:00",
        "closed_at": null,
        "comments_count": [
            "ningpp",
            "ningpp",
            "ningpp"
        ],
        "labels": []
    }
]