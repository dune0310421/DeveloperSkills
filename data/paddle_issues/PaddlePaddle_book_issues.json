[
    {
        "repo": "PaddlePaddle/book",
        "number": 9,
        "title": "机器翻译",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[machine_translation目录](https://github.com/PaddlePaddle/book/blob/develop/machine_translation/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/seqToseq)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/text_generation)。\r\n- 模型概览：介绍encoder-decoder、gru、attention、beam search。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:59:02+00:00",
        "updated_at": "2017-01-19T03:07:33+00:00",
        "closed_at": "2017-01-19T03:07:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 10,
        "title": "个性化推荐",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2017.01.03前提交第一版，2017.01.15前全部完成。\r\n- 提交地址：[README.md](https://github.com/PaddlePaddle/book/blob/develop/recommender_system/README.md)。如有图，请统一放在[目录](https://github.com/PaddlePaddle/book/blob/develop/recommender_system/)下。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/recommendation)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/rec)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "Zrachel",
        "created_at": "2016-12-16T10:02:47+00:00",
        "updated_at": "2017-01-19T02:16:28+00:00",
        "closed_at": "2017-01-19T02:16:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 7,
        "title": "情感分析",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[understand_sentiment目录](https://github.com/PaddlePaddle/book/blob/develop/understand_sentiment/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/sentiment)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/sentiment_analysis)。\r\n- 背景介绍：加文本分类、文本表示的背景，可参考[快速入门文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/quick_start)。 \r\n- 模型概览：需要介绍文本卷积和RNN、LSTM，不需要介绍 bi-LSTM & stacked LSTM 两个模型。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:51:45+00:00",
        "updated_at": "2017-01-13T09:22:53+00:00",
        "closed_at": "2017-01-13T09:22:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 6,
        "title": "词向量",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[word2vec目录](https://github.com/PaddlePaddle/book/blob/develop/word2vec/)。\r\n- 已有参考：[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/embedding_model)。\r\n- 背景介绍：需要加n-gram语言模型的背景。\r\n- 效果展示：需要画出word2vec降维到二维的图。\r\n- 已有参考中缺少章节：数据准备（从公开的语言模型数据集寻找），训练模型，应用模型。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "wangkuiyi",
        "created_at": "2016-12-16T09:48:08+00:00",
        "updated_at": "2017-01-01T14:36:07+00:00",
        "closed_at": "2017-01-01T14:36:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 8,
        "title": "序列标注",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2017.01.03前提交第一版，2017.01.15前全部完成。\r\n- 提交地址：[README.md](https://github.com/PaddlePaddle/book/blob/develop/label_semantic_roles/README.md)。如有图，请统一放在[目录](https://github.com/PaddlePaddle/book/blob/develop/label_semantic_roles/)下。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/semantic_role_labeling)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/semantic_role_labeling)。\r\n- 背景介绍：序列标注包含分词，词性标注，语义角色标注等。\r\n- 模型概览：简单介绍CRF、bi-LSTM & stacked LSTM 模型。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:55:14+00:00",
        "updated_at": "2017-01-22T08:40:26+00:00",
        "closed_at": "2017-01-22T08:40:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 5,
        "title": "图像分类",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[classify_images目录](https://github.com/PaddlePaddle/book/blob/develop/classify_images/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/image_classification)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/tutorials/image_classification)。\r\n- 模型概览：需要介绍ResNet & VGG16（已有文档），得加图。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:43:51+00:00",
        "updated_at": "2017-01-12T09:27:56+00:00",
        "closed_at": "2017-01-12T09:27:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 3,
        "title": "新手入门",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[fit_a_line目录](https://github.com/PaddlePaddle/book/blob/develop/fit_a_line/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/introduction)，[Paddle文档](https://github.com/PaddlePaddle/Paddle/tree/develop/doc/getstarted/basic_usage)。\r\n- 背景介绍：放样本图例。\r\n- 模型概览：介绍损失函数、fullyConnect。可以只写公式不画图。\r\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:32:16+00:00",
        "updated_at": "2017-01-13T09:22:42+00:00",
        "closed_at": "2017-01-13T09:22:42+00:00",
        "comments_count": [
            "zhouxiao-coder"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 4,
        "title": "识别数字",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[recognize_digits目录](https://github.com/PaddlePaddle/book/blob/develop/recognize_digits/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/mnist)，[tensorflow文档](https://www.tensorflow.org/tutorials/mnist/beginners/)。\r\n- 模型概览：需要写MLP、CNN和Softmax的介绍和原理，要放图。\r\n",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "luotao1",
        "created_at": "2016-12-16T09:36:44+00:00",
        "updated_at": "2017-01-19T09:10:20+00:00",
        "closed_at": "2017-01-19T09:10:20+00:00",
        "comments_count": [
            "dayhaha"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 2,
        "title": "Trying Jupyter",
        "body": "@Zrachel reminded me few days ago that Jupyter might already fit all what we want. Andrew Ng showed me today the Google Trends of Jupyter and Zeppelin notebooks:\r\n\r\n<img width=\"987\" alt=\"screen shot 2016-12-15 at 10 03 39 pm\" src=\"https://cloud.githubusercontent.com/assets/1548775/21254019/6e68c492-c317-11e6-95d1-670f16c29f3f.png\">\r\n\r\nSo I think I need to try Jupyter at least on my laptop.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "shanyi15",
        "created_at": "2016-12-16T06:39:59+00:00",
        "updated_at": "2018-08-15T09:18:42+00:00",
        "closed_at": "2018-08-15T09:18:42+00:00",
        "comments_count": [
            "wangkuiyi",
            "Zrachel",
            "wangkuiyi",
            "Zrachel",
            "wangkuiyi",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 11,
        "title": "图像自动生成",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：2016.12.26前提交临时版，2017.01.03前提交完整的第一版，2017.01.15前全部完成。\r\n- 提交地址：[gan目录](https://github.com/PaddlePaddle/book/blob/develop/gan/)。\r\n- 已有参考：[demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/gan)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-16T10:04:52+00:00",
        "updated_at": "2018-08-15T09:18:38+00:00",
        "closed_at": "2018-08-15T09:18:38+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 17,
        "title": "语音方面（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[speech_rec目录](https://github.com/PaddlePaddle/book/blob/develop/speech_rec/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 范围：说话人识别/语音识别/音素识别等，具体内容请自行设计。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T04:58:46+00:00",
        "updated_at": "2018-08-15T09:18:28+00:00",
        "closed_at": "2018-08-15T09:18:28+00:00",
        "comments_count": [
            "llxxxll",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 16,
        "title": "句向量（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[skip_thought目录](https://github.com/PaddlePaddle/book/blob/develop/skip_thought/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T04:51:56+00:00",
        "updated_at": "2018-08-15T09:19:08+00:00",
        "closed_at": "2018-08-15T09:18:31+00:00",
        "comments_count": [
            "dayhaha",
            "shanyi15",
            "rrenzixu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 15,
        "title": "文本相关性（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[query_relationship目录](https://github.com/PaddlePaddle/book/blob/develop/query_relationship/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T04:49:22+00:00",
        "updated_at": "2018-08-15T09:18:35+00:00",
        "closed_at": "2018-08-15T09:18:35+00:00",
        "comments_count": [
            "Cherishzhang",
            "Cherishzhang",
            "Zrachel",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 18,
        "title": "图像检测（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[image_detection目录](https://github.com/PaddlePaddle/book/blob/develop/image_detection/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T05:01:09+00:00",
        "updated_at": "2018-08-15T09:18:24+00:00",
        "closed_at": "2018-08-15T09:18:24+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 19,
        "title": "图像描述（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[image_caption目录](https://github.com/PaddlePaddle/book/blob/develop/image_caption/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T05:10:07+00:00",
        "updated_at": "2018-08-15T09:18:21+00:00",
        "closed_at": "2018-08-15T09:18:21+00:00",
        "comments_count": [
            "chengxiaohua1105",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 20,
        "title": "图像问答（二期）",
        "body": "请先阅读[中文教程撰写统一标准](https://github.com/PaddlePaddle/book/wiki/中文教程撰写统一标准)。\r\n\r\n要求：\r\n- 时间节点：暂未定\r\n- 提交地址：[image_qa目录](https://github.com/PaddlePaddle/book/blob/develop/image_qa/)。\r\n- 提交方式：分两个PR，先提交可完整运行的demo代码，等review通过后，再撰写中文教程。\r\n- 可参考：[其他demo代码](https://github.com/PaddlePaddle/Paddle/tree/develop/demo/)。",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "shanyi15",
        "created_at": "2016-12-22T05:12:49+00:00",
        "updated_at": "2018-08-15T09:18:18+00:00",
        "closed_at": "2018-08-15T09:18:17+00:00",
        "comments_count": [
            "llxxxll",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 34,
        "title": "这才是Tutorial",
        "body": "只是一个例子，感觉写得很好，和大家分享一下。\r\n\r\n比如说写LSTM，https://deeplearning4j.org/lstm\r\n\r\n![image](https://cloud.githubusercontent.com/assets/4532062/21716095/4636bd16-d443-11e6-8bc3-f3d2b841d9c3.png)\r\n\r\n需要几个点：RNN和feedforword network的关联，BP的改进——BPTT，简单RNN为什么走不下去了——梯度消失和梯度爆炸问题， LSTM怎样解决的该问题，长时序传播问题。\r\n\r\n再比如CNN，https://deeplearning4j.org/convolutionalnets 讲得也非常到位\r\n\r\n另外，大家还可以参考左边栏的目录，参考其他章节的知识和结构，共同完善我们的tutorial。\r\n\r\n",
        "state": "closed",
        "user": "Zrachel",
        "closed_by": "shanyi15",
        "created_at": "2017-01-06T11:13:24+00:00",
        "updated_at": "2018-08-15T09:16:26+00:00",
        "closed_at": "2018-08-15T09:16:26+00:00",
        "comments_count": [
            "lcy-seso",
            "yu239-zz",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 63,
        "title": "mac docker下运行cd data && python prepare_data.py 报错",
        "body": "貌似因为mac os Sierra默认不支持matplotlib\r\n解决方法如下：\r\n安装matplotlib\r\n`pip install matplotlib`\r\n报错\r\n`* The following required packages can not be built:Command \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-8UvQcW/matplotlib`\r\n\r\n解决方法，先执行\r\n`sudo apt-get install libfreetype6-dev pkg-config`\r\n再安装matplotlib\r\n`pip install matplotlib`\r\n\r\n\r\n\r\n最后执行\r\n`cd data && python prepare_data.py `\r\n提示\r\n`housing.data  housing.test.npy  housing.train.npy  prepare_data.py  test.list  train.lis`\r\n\r\nDone.\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "wangkuiyi",
        "created_at": "2017-02-07T08:31:57+00:00",
        "updated_at": "2017-03-08T21:55:02+00:00",
        "closed_at": "2017-03-08T21:51:31+00:00",
        "comments_count": [
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 79,
        "title": "[V2.SimpleCode]第一章，新手入门 fit_a_line",
        "body": "[V2.SimpleCode]第一章，新手入门 fit_a_line\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:37:55+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 80,
        "title": "[V2.SimpleCode]第八章，个性化推荐 recommender_system",
        "body": "[V2.SimpleCode]第八章，个性化推荐 recommender_system\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:38:27+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 81,
        "title": " [V2.SimpleCode]第四章，词向量 word2vec",
        "body": " [V2.SimpleCode]第四章，词向量 word2vec\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:38:44+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 82,
        "title": "[V2.SimpleCode]第二章，识别数字 recognize_digits",
        "body": "[V2.SimpleCode]第二章，识别数字 recognize_digits\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:39:13+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 83,
        "title": "[V2.SimpleCode]第七章，机器翻译 machine_translation",
        "body": "[V2.SimpleCode]第七章，机器翻译 machine_translation\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:39:29+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 77,
        "title": "book/image_classification的demo中，执行sh train.sh报错：Unknown class type: cudnn_conv",
        "body": "I0222 07:10:44.978152   120 Trainer.cpp:170] trainer mode: Normal\r\nF0222 07:10:44.979224   120 ClassRegistrar.h:66] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: cudnn_conv\r\n*** Check failure stack trace: ***\r\n    @     0x7fe16de95daa  (unknown)\r\n    @     0x7fe16de95ce4  (unknown)\r\n    @     0x7fe16de956e6  (unknown)\r\n    @     0x7fe16de98687  (unknown)\r\n    @           0x600835  paddle::Layer::create()\r\n    @           0x538940  _ZZN6paddle13NeuralNetwork4initERKNS_11ModelConfigESt8functionIFviPNS_9ParameterEEERKSt6vectorINS_19enumeration_wrapper13ParameterTypeESaISB_EEbENKUlRKNS_11LayerConfigEE_clESI_\r\n    @           0x539d5b  paddle::NeuralNetwork::init()\r\n    @           0x5479d2  paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @           0x53efde  paddle::GradientMachine::create()\r\n    @           0x67bc98  paddle::TrainerInternal::init()\r\n    @           0x6783ee  paddle::Trainer::init()\r\n    @           0x5132a9  main\r\n    @     0x7fe16d0a1f45  (unknown)\r\n    @           0x51f2a5  (unknown)\r\n    @              (nil)  (unknown)\r\nn_in != n_out\r\nn_in != n_out\r\n/usr/local/bin/paddle: line 109:   120 Aborted                 ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}",
        "state": "closed",
        "user": "yehanzheng",
        "closed_by": "qingqing01",
        "created_at": "2017-02-22T07:12:31+00:00",
        "updated_at": "2017-02-22T09:20:41+00:00",
        "closed_at": "2017-02-22T08:25:50+00:00",
        "comments_count": [
            "qingqing01",
            "qingqing01",
            "yehanzheng",
            "qingqing01",
            "yehanzheng",
            "qingqing01",
            "yehanzheng",
            "qingqing01",
            "yehanzheng",
            "qingqing01",
            "yehanzheng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 84,
        "title": " [V2.SimpleCode]第六章，语意角色标注 label_semantic_roles",
        "body": " [V2.SimpleCode]第六章，语意角色标注 label_semantic_roles\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:39:48+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 85,
        "title": "[V2.SimpleCode]第五章，情感分析 understand_sentiment",
        "body": "[V2.SimpleCode]第五章，情感分析 understand_sentiment\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:39:59+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 86,
        "title": "[V2.SimpleCode]第三章，图像分类 image_classification",
        "body": "[V2.SimpleCode]第三章，图像分类 image_classification\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "luotao1",
        "created_at": "2017-02-27T04:40:16+00:00",
        "updated_at": "2017-03-08T08:10:00+00:00",
        "closed_at": "2017-03-08T08:10:00+00:00",
        "comments_count": [
            "gangliao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 104,
        "title": "Broken links and other problems with recognize_digits/README.md",
        "body": "These problems were found by Sudnya @sudnya . I just post them here so to remind us to fix them:\r\n\r\nFigure 2 says weights in black, but the image doesn't have black.\r\nFigure 3, same issue black vs. blue\r\n\r\nReferences have names with special characters eg: é, ş, ö etc. that looks strange in the HTML file.\r\nThe following reference link is broken ->\r\n10. Bishop, Christopher M. “Pattern recognition.” Machine Learning 128 (2006): 1-58.\r\nI see this in my browser:\r\nThis XML file does not appear to have any style information associated with it. The document tree is shown below.\r\n<Error>\r\n<Code>AccessDenied</Code>\r\n<Message>Request has expired</Message>\r\n<Expires>2017-01-19T09:04:00Z</Expires>\r\n<ServerTime>2017-03-03T02:39:45Z</ServerTime>\r\n<RequestId>CC773176D6EE0ED3</RequestId>\r\n<HostId>\r\nlhWBsQrDQ7Y6aWcbYllrQtPicY3CtbAG0feHgYLH1l03Z3TBHfp2fD1MeAnkiqtWgTVUaRzhO+Y=\r\n</HostId>\r\n</Error>\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-03T05:55:26+00:00",
        "updated_at": "2017-03-08T10:54:02+00:00",
        "closed_at": "2017-03-08T10:54:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 114,
        "title": "Need a translation of Figure 5 in Chapter 4.",
        "body": "https://github.com/PaddlePaddle/book/blob/develop/word2vec/image/ngram.png\r\n\r\n- 词向量映射： Word Embedding Mapping\r\n- 词向量连接： Word Embedding Concatenation\r\n- 全连接层： Fully-Connected Layer\r\n- 隐层： Hidden Layer)",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "llxxxll",
        "created_at": "2017-03-03T21:05:50+00:00",
        "updated_at": "2017-03-05T03:24:48+00:00",
        "closed_at": "2017-03-05T03:24:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 88,
        "title": "label_semantic_roles下载完数据后运行train.sh出错",
        "body": "我在docker中运行情感分析understand_sentiment没有出错，但是运行语义角色标注label_semantic_roles时出现如下错误：\r\n\r\n> Traceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 3406, in parse_config_and_serialize\r\n    config = parse_config(config_file, config_arg_str)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 3382, in parse_config\r\n    execfile(config_file, make_config_environment(config_file, config_args))\r\n  File \"./db_lstm.py\", line 79, in <module>\r\n    average_window=0.5, max_average_window=10000), )\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/optimizers.py\", line 441, in settings\r\n    kwargs = __extends__(kwargs, each.to_setting_kwargs())\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/optimizers.py\", line 349, in __extends__\r\n    assert key not in dict1\r\nAssertionError\r\nF0227 09:10:32.580476   869 PythonUtil.cpp:134] Check failed: (ret) != nullptr Current PYTHONPATH: ['/usr/local/opt/paddle/bin', '/home/code/label_semantic_roles', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages']\r\nPython Error: <type 'exceptions.AssertionError'> :\r\nPython Callstack:\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py : 3406\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py : 3382\r\n            ./db_lstm.py : 79\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py : 53\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py : 53\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/optimizers.py : 441\r\n            /usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/optimizers.py : 349\r\nCall Object failed.\r\n*** Check failure stack trace: ***\r\n    @     0x7fac2f86edaa  (unknown)\r\n    @     0x7fac2f86ece4  (unknown)\r\n    @     0x7fac2f86e6e6  (unknown)\r\n    @     0x7fac2f871687  (unknown)\r\n    @           0x813eba  paddle::callPythonFuncRetPyObj()\r\n    @           0x81409c  paddle::callPythonFunc()\r\n    @           0x6b1f73  paddle::TrainerConfigHelper::TrainerConfigHelper()\r\n    @           0x6b25b4  paddle::TrainerConfigHelper::createFromFlags()\r\n    @           0x52b2f7  main\r\n    @     0x7fac2ea7af45  (unknown)\r\n    @           0x540c05  (unknown)\r\n    @              (nil)  (unknown)\r\n/usr/local/bin/paddle: line 109:   869 Aborted                 (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}\r\n\r\n第79行代码如下：\r\n\r\n> model_average=ModelAverage(\r\n        average_window=0.5, max_average_window=10000), )\r\n\r\n我注释掉该行后，报96行：\r\n\r\n> default_std = 1 / math.sqrt(hidden_dim) / 3.0\r\n\r\nsqrt找不到，但是单独在python中运行时没有问题的；\r\n\r\n万望指导，谢谢！",
        "state": "closed",
        "user": "ArrowLuo",
        "closed_by": "ArrowLuo",
        "created_at": "2017-02-27T09:15:02+00:00",
        "updated_at": "2017-03-06T06:21:18+00:00",
        "closed_at": "2017-02-27T09:49:51+00:00",
        "comments_count": [
            "llxxxll",
            "ArrowLuo",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 109,
        "title": "Examples in chapter Label Semantic Roles are in Chinese",
        "body": "This makes the translation extremely difficult.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-03T19:23:03+00:00",
        "updated_at": "2017-05-16T08:24:25+00:00",
        "closed_at": "2017-05-16T08:24:25+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 110,
        "title": "Figure 4 in Chapter Machine Translation has wrong layer labels.",
        "body": "Note: there is an error in the original figure. The locations for 源语言词序列 and 源语编码状态 should be switched.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "llxxxll",
        "created_at": "2017-03-03T19:25:57+00:00",
        "updated_at": "2017-03-05T04:40:26+00:00",
        "closed_at": "2017-03-05T04:40:26+00:00",
        "comments_count": [
            "llxxxll",
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 112,
        "title": "Errors in image of Figure 4 in Chapter 7 (Machine translation)",
        "body": "(1) For this image:\r\n\r\nhttps://github.com/PaddlePaddle/book/blob/develop/machine_translation/image/encoder_decoder.png\r\n\r\nthe locations of \"源语言编码状态\" and “源语言词序列” should be switched.\r\n\r\n(2) For this image\r\n\r\nhttps://github.com/PaddlePaddle/book/blob/develop/machine_translation/image/encoder_decoder_en.png\r\n\r\nsimilarly, the locations of \"Word Embedding Sequence for the Source Language\" and “Word Sequence for the Source Sequence” should be switched.",
        "state": "closed",
        "user": "Haichao-Zhang",
        "closed_by": "wangkuiyi",
        "created_at": "2017-03-03T19:51:41+00:00",
        "updated_at": "2017-03-05T03:31:33+00:00",
        "closed_at": "2017-03-05T03:31:33+00:00",
        "comments_count": [
            "llxxxll",
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 115,
        "title": "Translate figures in Chapter 8",
        "body": "We need the translation of Figure 3. only, as Figure 1. and 2. came from the Google Youtube paper.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "llxxxll",
        "created_at": "2017-03-03T21:23:56+00:00",
        "updated_at": "2017-03-05T04:24:09+00:00",
        "closed_at": "2017-03-05T04:24:09+00:00",
        "comments_count": [
            "llxxxll",
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 138,
        "title": "image_classificatio",
        "body": "In https://github.com/PaddlePaddle/book/pull/97, @gangliao updated the new demo program using V2 API. We need to update the README.en.md accordingly.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "helinwang",
        "created_at": "2017-03-07T01:54:18+00:00",
        "updated_at": "2017-03-08T18:24:13+00:00",
        "closed_at": "2017-03-08T18:24:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 131,
        "title": "recognize_digits/README.md 图4和下方对应解释有对不上的地方",
        "body": "比如： `如图4中有$Filter W_0$和$Filter W_1$两个卷积核` 并未在图4中标明",
        "state": "closed",
        "user": "typhoonzero",
        "closed_by": "llxxxll",
        "created_at": "2017-03-06T01:38:04+00:00",
        "updated_at": "2017-03-07T10:30:21+00:00",
        "closed_at": "2017-03-07T10:30:20+00:00",
        "comments_count": [
            "llxxxll"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 141,
        "title": "Update MNIST equation in English version",
        "body": "followup https://github.com/PaddlePaddle/book/pull/137",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-07T06:46:33+00:00",
        "updated_at": "2017-03-08T06:44:02+00:00",
        "closed_at": "2017-03-08T06:44:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 156,
        "title": "English and Chinese figures differ from each other in MNIST tutorial",
        "body": "https://github.com/PaddlePaddle/book/blob/develop/recognize_digits/image/conv_layer.png\r\n\r\n![](https://raw.githubusercontent.com/PaddlePaddle/book/develop/recognize_digits/image/conv_layer.png)\r\n\r\ndiffers from \r\n\r\nhttps://github.com/PaddlePaddle/book/blob/develop/recognize_digits/image/conv_layer_en.png\r\n\r\n![](https://raw.githubusercontent.com/PaddlePaddle/book/develop/recognize_digits/image/conv_layer_en.png)",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-07T21:18:33+00:00",
        "updated_at": "2017-03-08T08:08:41+00:00",
        "closed_at": "2017-03-08T08:08:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 144,
        "title": "image_classification killed",
        "body": "我用docker安装的，使用了cpu版本，进行vgg或者resNet训练时候报错\r\nI0307 09:38:06.377203   355 Util.cpp:130] Calling runInitFunctions\r\nI0307 09:38:06.377521   355 Util.cpp:143] Call runInitFunctions done.\r\n[INFO 2017-03-07 09:38:06,464 layers.py:1890] channels=3 size=3072\r\n[INFO 2017-03-07 09:38:06,464 layers.py:1890] output size for __conv_0__ is 32\r\n[INFO 2017-03-07 09:38:06,466 layers.py:1890] channels=64 size=65536\r\n[INFO 2017-03-07 09:38:06,466 layers.py:1890] output size for __conv_1__ is 32\r\n[INFO 2017-03-07 09:38:06,468 layers.py:1985] output size for __pool_0__ is 16*16\r\n[INFO 2017-03-07 09:38:06,469 layers.py:1890] channels=64 size=16384\r\n[INFO 2017-03-07 09:38:06,469 layers.py:1890] output size for __conv_2__ is 16\r\n[INFO 2017-03-07 09:38:06,471 layers.py:1890] channels=128 size=32768\r\n[INFO 2017-03-07 09:38:06,471 layers.py:1890] output size for __conv_3__ is 16\r\n[INFO 2017-03-07 09:38:06,472 layers.py:1985] output size for __pool_1__ is 8*8\r\n[INFO 2017-03-07 09:38:06,473 layers.py:1890] channels=128 size=8192\r\n[INFO 2017-03-07 09:38:06,473 layers.py:1890] output size for __conv_4__ is 8\r\n[INFO 2017-03-07 09:38:06,475 layers.py:1890] channels=256 size=16384\r\n[INFO 2017-03-07 09:38:06,475 layers.py:1890] output size for __conv_5__ is 8\r\n[INFO 2017-03-07 09:38:06,477 layers.py:1890] channels=256 size=16384\r\n[INFO 2017-03-07 09:38:06,478 layers.py:1890] output size for __conv_6__ is 8\r\n[INFO 2017-03-07 09:38:06,479 layers.py:1985] output size for __pool_2__ is 4*4\r\n[INFO 2017-03-07 09:38:06,480 layers.py:1890] channels=256 size=4096\r\n[INFO 2017-03-07 09:38:06,481 layers.py:1890] output size for __conv_7__ is 4\r\n[INFO 2017-03-07 09:38:06,483 layers.py:1890] channels=512 size=8192\r\n[INFO 2017-03-07 09:38:06,483 layers.py:1890] output size for __conv_8__ is 4\r\n[INFO 2017-03-07 09:38:06,485 layers.py:1890] channels=512 size=8192\r\n[INFO 2017-03-07 09:38:06,485 layers.py:1890] output size for __conv_9__ is 4\r\n[INFO 2017-03-07 09:38:06,487 layers.py:1985] output size for __pool_3__ is 2*2\r\n[INFO 2017-03-07 09:38:06,488 layers.py:1890] channels=512 size=2048\r\n[INFO 2017-03-07 09:38:06,488 layers.py:1890] output size for __conv_10__ is 2\r\n[INFO 2017-03-07 09:38:06,490 layers.py:1890] channels=512 size=2048\r\n[INFO 2017-03-07 09:38:06,490 layers.py:1890] output size for __conv_11__ is 2\r\n[INFO 2017-03-07 09:38:06,491 layers.py:1890] channels=512 size=2048\r\n[INFO 2017-03-07 09:38:06,491 layers.py:1890] output size for __conv_12__ is 2\r\n[INFO 2017-03-07 09:38:06,493 layers.py:1985] output size for __pool_4__ is 1*1\r\n[INFO 2017-03-07 09:38:06,495 networks.py:1466] The input order is [image, label]\r\n[INFO 2017-03-07 09:38:06,495 networks.py:1472] The output order is [__cost_0__]\r\nI0307 09:38:06.502377   355 Trainer.cpp:170] trainer mode: Normal\r\nI0307 09:38:06.710746   355 PyDataProvider2.cpp:257] loading dataprovider dataprovider::process\r\nI0307 09:38:06.712720   355 PyDataProvider2.cpp:257] loading dataprovider dataprovider::process\r\nI0307 09:38:06.713508   355 GradientMachine.cpp:134] Initing parameters..\r\nI0307 09:38:07.561144   355 GradientMachine.cpp:141] Init parameters done.\r\nI0307 09:38:10.089026   364 ThreadLocal.cpp:37] thread use undeterministic rand seed:365\r\nI0307 09:38:10.251857   357 ThreadLocal.cpp:37] thread use undeterministic rand seed:358\r\nI0307 09:38:10.296422   356 ThreadLocal.cpp:37] thread use undeterministic rand seed:357\r\nI0307 09:38:10.305033   359 ThreadLocal.cpp:37] thread use undeterministic rand seed:360\r\nI0307 09:38:10.348325   358 ThreadLocal.cpp:37] thread use undeterministic rand seed:359\r\n/usr/local/bin/paddle: line 109:   355 Killed                  ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}",
        "state": "closed",
        "user": "sunnysuhappy",
        "closed_by": "qingqing01",
        "created_at": "2017-03-07T09:40:14+00:00",
        "updated_at": "2017-03-09T03:34:44+00:00",
        "closed_at": "2017-03-09T03:34:44+00:00",
        "comments_count": [
            "sunnysuhappy",
            "gangliao",
            "qingqing01",
            "sunnysuhappy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 142,
        "title": "book首页新增英文html入门",
        "body": "目前首页是：\r\n新手入门 [fit_a_line] [html]\r\n\r\n加入英文网页后，要如何显示：\r\n- 新手入门 [fit_a_line] [html] [en.html]？\r\n- 其他表示？",
        "state": "closed",
        "user": "luotao1",
        "closed_by": "llxxxll",
        "created_at": "2017-03-07T06:54:43+00:00",
        "updated_at": "2017-03-08T09:08:51+00:00",
        "closed_at": "2017-03-08T09:08:51+00:00",
        "comments_count": [
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 148,
        "title": "recommender_system 里中\\英版插图内容差异比较大，是否要统一",
        "body": "![6fcbb902eb8b88c9f7b849f47](https://cloud.githubusercontent.com/assets/1908992/23653718/77f43b86-0368-11e7-80ad-f9694c7d67ae.png)\r\n\r\n如上图所示目测两版的差异。\r\n\r\n咨询了@luotao1 ,建议是『中文插图是@Zrechel 手绘，英文原版意思不对，英文版应该按照中文手绘图修改』",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-03-07T11:05:59+00:00",
        "updated_at": "2018-08-15T09:16:22+00:00",
        "closed_at": "2018-08-15T09:16:22+00:00",
        "comments_count": [
            "wangkuiyi",
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 155,
        "title": "Fix equation format error in recognize_digits/README.md",
        "body": "",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "wangkuiyi",
        "created_at": "2017-03-07T21:14:34+00:00",
        "updated_at": "2017-03-08T00:45:00+00:00",
        "closed_at": "2017-03-08T00:45:00+00:00",
        "comments_count": [
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 162,
        "title": "Bad image URL in label_semantic_roles/README.en.md",
        "body": "In book/label_semantic_roles/index.en.html, the URL to label_semantic_roles/image/db_lstm_en.png has typo `db`.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:37:11+00:00",
        "updated_at": "2017-03-08T08:12:14+00:00",
        "closed_at": "2017-03-08T08:12:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 161,
        "title": "Typeset problem with label semantic roles",
        "body": "As in book/label_semantic_roles/index.html:\r\n\r\nwe have \r\n\r\n<img width=\"959\" alt=\"screen shot 2017-03-07 at 4 34 17 pm\" src=\"https://cloud.githubusercontent.com/assets/1548775/23684477/f26c7a46-0353-11e7-829b-f208780c7cf0.png\">\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:34:41+00:00",
        "updated_at": "2017-03-08T08:12:14+00:00",
        "closed_at": "2017-03-08T08:12:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 163,
        "title": "Typeset problem in machine_translation/README.md",
        "body": "<img width=\"973\" alt=\"screen shot 2017-03-07 at 4 38 21 pm\" src=\"https://cloud.githubusercontent.com/assets/1548775/23684591/8611404c-0354-11e7-8f26-1fa7b7767288.png\">\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:38:46+00:00",
        "updated_at": "2017-03-08T08:12:14+00:00",
        "closed_at": "2017-03-08T08:12:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 164,
        "title": "recognize_digits/*.md use \\arg with softmax",
        "body": "<img width=\"590\" alt=\"screen shot 2017-03-07 at 4 41 17 pm\" src=\"https://cloud.githubusercontent.com/assets/1548775/23684637/e90270d6-0354-11e7-9292-ed18beb90986.png\">\r\n\r\n\r\nIn LaTeX, we should type `\\arg{softmax}` instead of `softmax` to get the correct font.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:42:32+00:00",
        "updated_at": "2017-03-08T07:05:20+00:00",
        "closed_at": "2017-03-08T07:05:20+00:00",
        "comments_count": [
            "luotao1",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 167,
        "title": "Update Fig 3. Conv Layer in recognize_digits/README.en.md ",
        "body": "After https://github.com/PaddlePaddle/book/issues/166 is resolved.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:49:14+00:00",
        "updated_at": "2017-03-08T08:08:41+00:00",
        "closed_at": "2017-03-08T08:08:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 165,
        "title": "Equation problems in recognize_digits/README.md",
        "body": "<img width=\"896\" alt=\"screen shot 2017-03-07 at 4 43 05 pm\" src=\"https://cloud.githubusercontent.com/assets/1548775/23684674/295d4764-0355-11e7-9475-b003a78fbfe9.png\">\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:43:33+00:00",
        "updated_at": "2017-03-08T08:08:41+00:00",
        "closed_at": "2017-03-08T08:08:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 170,
        "title": "Link book installation guide to docker ones in paddle repo. And update CN docker installation guide",
        "body": "",
        "state": "closed",
        "user": "helinwang",
        "closed_by": "wangkuiyi",
        "created_at": "2017-03-08T01:46:18+00:00",
        "updated_at": "2017-03-09T01:19:34+00:00",
        "closed_at": "2017-03-09T01:19:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 190,
        "title": "add l2 regularization to reduce fpe for machine translation english.",
        "body": "Here is Chinese part by Longfei https://github.com/PaddlePaddle/book/pull/188\r\nI will add English part.",
        "state": "closed",
        "user": "helinwang",
        "closed_by": "wangkuiyi",
        "created_at": "2017-03-08T18:54:57+00:00",
        "updated_at": "2017-03-08T21:56:32+00:00",
        "closed_at": "2017-03-08T21:56:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 166,
        "title": "Mess in recognize_digits/images/conv_layer{_en}.png",
        "body": "![](https://raw.githubusercontent.com/PaddlePaddle/book/develop/recognize_digits/image/conv_layer.png)\r\n\r\nHow comes the messy thing \"toggle movement\"?\r\n\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T00:47:01+00:00",
        "updated_at": "2017-03-08T08:08:41+00:00",
        "closed_at": "2017-03-08T08:08:41+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 169,
        "title": "Update v2 example program in understand_sentiment/README.en.md",
        "body": "",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "helinwang",
        "created_at": "2017-03-08T00:52:53+00:00",
        "updated_at": "2017-03-08T21:51:42+00:00",
        "closed_at": "2017-03-08T21:51:42+00:00",
        "comments_count": [
            "helinwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 168,
        "title": "understand_sentiment/README*.md didn't use ```python",
        "body": "This would prevent it from being converted automatically into Jupyter Notebooks.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "hedaoyuan",
        "created_at": "2017-03-08T00:51:55+00:00",
        "updated_at": "2017-03-08T11:59:19+00:00",
        "closed_at": "2017-03-08T11:59:19+00:00",
        "comments_count": [
            "hedaoyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 195,
        "title": "Sudnya currently working on the Image classification EN readme",
        "body": "I am working on https://github.com/PaddlePaddle/book/blob/develop/image_classification/README.en.md",
        "state": "closed",
        "user": "sudnya",
        "closed_by": "luotao1",
        "created_at": "2017-03-08T22:03:43+00:00",
        "updated_at": "2017-05-16T08:25:23+00:00",
        "closed_at": "2017-05-16T08:25:23+00:00",
        "comments_count": [
            "helinwang",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 217,
        "title": "No module named v2",
        "body": "操作系统ubuntu 14.04 64\r\npaddlepaddle版本：PaddlePaddle 0.9.0\r\n运行代码：\r\nPaddlePaddle/book/fit_a_line/train.py\r\n\r\nroot@ubuntu:/mydir/python/book-develop-v2/fit_a_line# python ./train.py \r\nTraceback (most recent call last):\r\n  File \"./train.py\", line 2, in <module>\r\n    import paddle.v2 as paddle\r\nImportError: No module named v2\r\n",
        "state": "closed",
        "user": "767102998",
        "closed_by": "767102998",
        "created_at": "2017-03-16T02:05:02+00:00",
        "updated_at": "2017-03-16T08:34:51+00:00",
        "closed_at": "2017-03-16T08:34:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 214,
        "title": "为每个例子增加在Kubernetes上以集群方式运行的说明",
        "body": "增加说明和对应的yaml文件和运行脚本",
        "state": "closed",
        "user": "typhoonzero",
        "closed_by": "shanyi15",
        "created_at": "2017-03-10T04:45:40+00:00",
        "updated_at": "2018-08-15T09:10:13+00:00",
        "closed_at": "2018-08-15T09:10:13+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 238,
        "title": "Make chapter directories visual salient in Jupyter Notebook",
        "body": "Add a numerical prefix to each chapter.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "reyoung",
        "created_at": "2017-03-20T16:19:50+00:00",
        "updated_at": "2017-03-20T16:24:12+00:00",
        "closed_at": "2017-03-20T16:24:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 241,
        "title": "Pack paddle.dataset cache dir into Docker image",
        "body": "When I am running Chapter 2. Recognize Images on my laptop, the data downloading process timed out:\r\n\r\n![screen shot 2017-03-20 at 3 37 30 pm](https://cloud.githubusercontent.com/assets/1548775/24124954/51f07934-0d83-11e7-8787-1b706622674e.png)\r\n\r\nCan we \r\n\r\n1. run the extracted Python programs of all chapters so to download and cache required datasets,\r\n1. pack these datasets into our Docker image?\r\n\r\nI am not sure if we'd have to change the cache dir.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "gongweibao",
        "created_at": "2017-03-20T22:40:55+00:00",
        "updated_at": "2017-03-22T10:42:14+00:00",
        "closed_at": "2017-03-22T10:42:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 231,
        "title": "some problems to do of book docker image",
        "body": "1.  If we try it for two or more times, kernel will die because google log can't be inited repeatedly\r\n```python\r\npaddle.init(use_gpu=False, trainer_count=1)\r\n```\r\n\r\n2. Do we need move index.html.tmpl and index.html.json to other directory?Because user need not to know these files？\r\n\r\n3. We need a script to check ipynb files quickly。@gongweibao\r\n\r\n4. Do we need to rm Chinese documents, and keep only English documents?\r\n\r\n5. Modify travis to auto build and push book docker image @gongweibao\r\n\r\n6. Machine_translation reports error after running some batchs @jacquesqiao \r\n#234 ",
        "state": "closed",
        "user": "gongweibao",
        "closed_by": "shanyi15",
        "created_at": "2017-03-20T11:14:27+00:00",
        "updated_at": "2018-08-15T09:10:09+00:00",
        "closed_at": "2018-08-15T09:10:09+00:00",
        "comments_count": [
            "llxxxll",
            "llxxxll",
            "llxxxll",
            "wangkuiyi",
            "gongweibao",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 246,
        "title": "Alloc fail in [03.image_classification]",
        "body": "I found an Alloc fail when I try VGG sample in [03.image_classification]\r\n\r\nError Message is:\r\n[INFO 2017-03-21 05:45:27,928 networks.py:1472] The input order is [image, label]\r\n[INFO 2017-03-21 05:45:27,928 networks.py:1478] The output order is [__classification_cost_0__]\r\nI0321 05:45:28.071794   397 GradientMachine.cpp:86] Initing parameters..\r\nI0321 05:45:28.876621   397 GradientMachine.cpp:93] Init parameters done.\r\nCache file /root/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz not found, downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\r\n/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:315: SNIMissingWarning: An HTTPS request has been made, but the SNI (Subject Name Indication) extension to TLS is not available on this platform. This may cause the server to present an incorrect TLS certificate, which can cause validation failures. For more information, see https://urllib3.readthedocs.io/en/latest/security.html#snimissingwarning.\r\n  SNIMissingWarning\r\n/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:120: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.io/en/latest/security.html#insecureplatformwarning.\r\n  InsecurePlatformWarning\r\n[==================================================]F0321 08:03:35.374790   397 Allocator.h:51] Check failed: posix_memalign(&ptr, 32ul, size) == 0 (12 vs. 0) \r\n*** Check failure stack trace: ***\r\n    @     0x7fd7f88cae78  google::LogMessage::Fail()\r\n    @     0x7fd7f88cadbf  google::LogMessage::SendToLog()\r\n    @     0x7fd7f88ca734  google::LogMessage::Flush()\r\n    @     0x7fd7f88cd929  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fd7f8769e08  paddle::CpuAllocator::alloc()\r\n    @     0x7fd7f8779626  paddle::PoolAllocator::alloc()\r\n    @     0x7fd7f875de86  paddle::CpuMemoryHandle::CpuMemoryHandle()\r\n    @     0x7fd7f87802b1  paddle::CpuMatrix::CpuMatrix()\r\n    @     0x7fd7f8780516  paddle::Matrix::create()\r\n    @     0x7fd7f878d270  paddle::Matrix::resizeOrCreate()\r\n    @     0x7fd7f85f55bc  paddle::BatchNormalizationLayer::forward()\r\n    @     0x7fd7f867899e  paddle::NeuralNetwork::forward()\r\n    @     0x7fd7f86554b3  paddle::GradientMachine::forwardBackward()\r\n    @     0x7fd7f880c92a  GradientMachine::forwardBackward()\r\n    @     0x7fd7f8530899  _wrap_GradientMachine_forwardBackward\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x567d14  (unknown)\r\n    @           0x465bf4  PyRun_FileExFlags\r\n    @           0x46612d  PyRun_SimpleFileExFlags\r\n    @           0x466d92  Py_Main\r\n    @     0x7fd7f97fbf45  __libc_start_main\r\n    @           0x577c2e  (unknown)\r\n    @              (nil)  (unknown)\r\n\r\n",
        "state": "closed",
        "user": "jekin000",
        "closed_by": "jekin000",
        "created_at": "2017-03-21T09:08:30+00:00",
        "updated_at": "2017-03-21T11:02:12+00:00",
        "closed_at": "2017-03-21T11:02:12+00:00",
        "comments_count": [
            "jekin000",
            "jekin000",
            "gongweibao",
            "jekin000",
            "gongweibao",
            "jekin000",
            "gongweibao",
            "jekin000",
            "gongweibao",
            "jekin000",
            "jekin000"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 242,
        "title": "Move many files in / to .tools",
        "body": "- Move `.theme` to `.tools/theme`\r\n- Move `.tmpl/*` to `.tools/theme`\r\n- Move `index*.json` and `index*.tmpl` to `.tools/templates`\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "luotao1",
        "created_at": "2017-03-20T23:47:25+00:00",
        "updated_at": "2017-05-16T08:23:27+00:00",
        "closed_at": "2017-05-16T08:23:27+00:00",
        "comments_count": [
            "reyoung"
        ],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 248,
        "title": "Jupyter kernel died",
        "body": "Hello,\r\n\r\nThis project is really nice !\r\n\r\nUnfortunately the Jupyter Notebook crash on the running of last cell, for the \"01.fit_a_line\" and \"04.word2vec\" notebook at least.\r\n\r\nI was able to:\r\n- dowload the docker image\r\n- run it\r\n- Access to http://localhost:8888/notebooks/04.word2vec/README.en.ipynb\r\n- Run all cell\r\n=> On the last cell I have a message \"The kernel appears to have died. It will restart automatically.\"\r\n\r\nI have access to the docker image by \"sudo docker exec -i -t 45662692a6ad /bin/bash\"\r\n\r\n**But how to have some log info to know what happen ?**\r\n\r\nMy configuration is a Ubuntu 16.04 laptop, intel core i5 with 6Gb or RAM, without GPU",
        "state": "closed",
        "user": "benoit-cty",
        "closed_by": "shanyi15",
        "created_at": "2017-03-21T12:39:28+00:00",
        "updated_at": "2018-08-15T09:10:05+00:00",
        "closed_at": "2018-08-15T09:10:05+00:00",
        "comments_count": [
            "NorthStar",
            "benoit-cty",
            "gangliao",
            "benoit-cty",
            "gangliao",
            "benoit-cty",
            "benoit-cty",
            "gangliao",
            "benoit-cty",
            "benoit-cty",
            "gangliao",
            "benoit-cty",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 253,
        "title": "情感分析html中部分标题格式错误",
        "body": "看了下html中的markdown语法是正确的，可能是渲染markdown语法时的问题。\r\n\r\n![image](https://cloud.githubusercontent.com/assets/11692045/24279072/8de0b8b2-1082-11e7-8861-fdff9b4e4fd2.png)\r\n![image](https://cloud.githubusercontent.com/assets/11692045/24279080/9d1fc00c-1082-11e7-8959-b5639810d870.png)\r\n",
        "state": "closed",
        "user": "livc",
        "closed_by": "livc",
        "created_at": "2017-03-24T03:12:55+00:00",
        "updated_at": "2017-03-30T05:28:32+00:00",
        "closed_at": "2017-03-30T05:28:32+00:00",
        "comments_count": [
            "cddesire"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 255,
        "title": "book示例训练完之后是没有模型和日志文件",
        "body": "![15b5306ba7eed5e8e51ef8a8c2f4a227](https://cloud.githubusercontent.com/assets/1908992/24327960/4f506842-1210-11e7-9668-74a13c9e3583.JPG)\r\n如上图所示，book示例，训练完之后是没有output目录、也没找到模型和日志文件。",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-03-26T02:39:13+00:00",
        "updated_at": "2018-08-15T09:10:02+00:00",
        "closed_at": "2018-08-15T09:10:02+00:00",
        "comments_count": [
            "llxxxll",
            "reyoung",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 257,
        "title": "windows-docker 下，单机直接运行 06.label_semantic_roles/trian.py报错",
        "body": "windows-docker 下，单机直接运行 06.label_semantic_roles/trian.py\r\n报错\r\n\r\n> Pass 91, Batch 300, Cost 4.274895\r\nPass 91, Batch 400, Cost 5.956556\r\nPass 91, Batch 500, Cost 2.365294\r\nPass 92, Batch 0, Cost 4.295222\r\nPass 92, Batch 100, Cost 11.625301\r\nPass 92, Batch 200, Cost 2.934830\r\nPass 92, Batch 300, Cost 8.967397\r\nPass 92, Batch 400, Cost 2.054969\r\nPass 92, Batch 500, Cost 5.914911\r\nPass 93, Batch 0, Cost 1.655390\r\nThread [140425110587136] Backwarding __lstmemory_7__, __mixed_7__, __lstmemory_6__, __mixed_6__, __lstmemory_5__, __mixed_5__, __lstmemory_4__, __mixed_4__, _\r\n_lstmemory_3__, __mixed_3__, __lstmemory_2__, __mixed_2__, __lstmemory_1__, __mixed_1__, __lstmemory_0__, __mixed_0__, __embedding_layer_1__, mark_data, __emb\r\nedding_layer_0__, verb_data, __embedding_layer_7__, ctx_p2_data, __embedding_layer_6__, ctx_p1_data, __embedding_layer_5__, ctx_0_data, __embedding_layer_4__,\r\n ctx_n1_data, __embedding_layer_3__, ctx_n2_data, __embedding_layer_2__, word_data,\r\n*** Aborted at 1490526248 (unix time) try \"date -d @1490526248\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7fb739a4368e) received by PID 759 (TID 0x7fb744d58700) from PID 967063182; stack trace: ***\r\n    @     0x7fb744512890 (unknown)\r\n    @     0x7fb739a4368e hl_avx_lstm_backward_one_sequence<>()\r\n    @     0x7fb739a42e3b paddle::LstmCompute::backwardOneSequence<>()\r\n    @     0x7fb739a42f7d paddle::LstmCompute::backwardBatch<>()\r\n    @     0x7fb739a781e1 paddle::LstmLayer::backwardBatch()\r\n    @     0x7fb739a78877 paddle::LstmLayer::backward()\r\n    @     0x7fb739ac97e0 paddle::NeuralNetwork::backward()\r\n    @     0x7fb739c5d34a GradientMachine::forwardBackward()\r\n    @     0x7fb7399822c0 _wrap_GradientMachine_forwardBackward\r\n    @     0x7fb74482f36c PyEval_EvalFrameEx\r\n    @     0x7fb744830200 PyEval_EvalCodeEx\r\n    @     0x7fb74482c04a PyEval_EvalFrameEx\r\n    @     0x7fb744830200 PyEval_EvalCodeEx\r\n    @     0x7fb74482c04a PyEval_EvalFrameEx\r\n    @     0x7fb744830200 PyEval_EvalCodeEx\r\n    @     0x7fb74482c04a PyEval_EvalFrameEx\r\n    @     0x7fb74482c257 PyEval_EvalFrameEx\r\n    @     0x7fb744830200 PyEval_EvalCodeEx\r\n    @     0x7fb744830329 PyEval_EvalCode\r\n    @     0x7fb744854a4a PyRun_FileExFlags\r\n    @     0x7fb744855fd7 PyRun_SimpleFileExFlags\r\n    @     0x7fb74486bf95 Py_Main\r\n    @     0x7fb743a71b45 __libc_start_main\r\n    @           0x4006ee (unknown)\r\n    @                0x0 (unknown)\r\nFloating point exception\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-03-26T23:47:44+00:00",
        "updated_at": "2017-04-16T10:26:15+00:00",
        "closed_at": "2017-04-16T10:26:15+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 256,
        "title": "book需要一个预测API的使用说明",
        "body": "book需要一个预测API的使用说明，模型训完之后不知道如何与自己擅长的语言结合。",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-03-26T02:40:15+00:00",
        "updated_at": "2018-08-15T09:09:58+00:00",
        "closed_at": "2018-08-15T09:09:58+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 258,
        "title": "windows-docker 下，单机直接运行 03.image_classification/trian.py没能启动训练直接Killed",
        "body": ">  python train.py\r\n>I0326 23:52:29.501113   804 Util.cpp:160] commandline:  --use_gpu=False --trainer_count=1\r\n[INFO 2017-03-26 23:52:29,509 layers.py:2106] output for __conv_0__: c = 64, h = 32, w = 32, size = 65536\r\n[INFO 2017-03-26 23:52:29,511 layers.py:2106] output for __conv_1__: c = 64, h = 32, w = 32, size = 65536\r\n[INFO 2017-03-26 23:52:29,513 layers.py:2230] output for __pool_0__: c = 64, h = 16, w = 16, size = 16384\r\n[INFO 2017-03-26 23:52:29,514 layers.py:2106] output for __conv_2__: c = 128, h = 16, w = 16, size = 32768\r\n[INFO 2017-03-26 23:52:29,517 layers.py:2106] output for __conv_3__: c = 128, h = 16, w = 16, size = 32768\r\n[INFO 2017-03-26 23:52:29,518 layers.py:2230] output for __pool_1__: c = 128, h = 8, w = 8, size = 8192\r\n[INFO 2017-03-26 23:52:29,518 layers.py:2106] output for __conv_4__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,519 layers.py:2106] output for __conv_5__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,520 layers.py:2106] output for __conv_6__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,521 layers.py:2230] output for __pool_2__: c = 256, h = 4, w = 4, size = 4096\r\n[INFO 2017-03-26 23:52:29,522 layers.py:2106] output for __conv_7__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,523 layers.py:2106] output for __conv_8__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,524 layers.py:2106] output for __conv_9__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,525 layers.py:2230] output for __pool_3__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,526 layers.py:2106] output for __conv_10__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,527 layers.py:2106] output for __conv_11__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,528 layers.py:2106] output for __conv_12__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,531 layers.py:2230] output for __pool_4__: c = 512, h = 1, w = 1, size = 512\r\n[INFO 2017-03-26 23:52:29,534 networks.py:1472] The input order is [image, label]\r\n[INFO 2017-03-26 23:52:29,535 networks.py:1478] The output order is [__classification_cost_0__]\r\n[INFO 2017-03-26 23:52:29,536 layers.py:2106] output for __conv_0__: c = 64, h = 32, w = 32, size = 65536\r\n[INFO 2017-03-26 23:52:29,537 layers.py:2106] output for __conv_1__: c = 64, h = 32, w = 32, size = 65536\r\n[INFO 2017-03-26 23:52:29,539 layers.py:2230] output for __pool_0__: c = 64, h = 16, w = 16, size = 16384\r\n[INFO 2017-03-26 23:52:29,539 layers.py:2106] output for __conv_2__: c = 128, h = 16, w = 16, size = 32768\r\n[INFO 2017-03-26 23:52:29,540 layers.py:2106] output for __conv_3__: c = 128, h = 16, w = 16, size = 32768\r\n[INFO 2017-03-26 23:52:29,541 layers.py:2230] output for __pool_1__: c = 128, h = 8, w = 8, size = 8192\r\n[INFO 2017-03-26 23:52:29,542 layers.py:2106] output for __conv_4__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,543 layers.py:2106] output for __conv_5__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,544 layers.py:2106] output for __conv_6__: c = 256, h = 8, w = 8, size = 16384\r\n[INFO 2017-03-26 23:52:29,546 layers.py:2230] output for __pool_2__: c = 256, h = 4, w = 4, size = 4096\r\n[INFO 2017-03-26 23:52:29,547 layers.py:2106] output for __conv_7__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,548 layers.py:2106] output for __conv_8__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,549 layers.py:2106] output for __conv_9__: c = 512, h = 4, w = 4, size = 8192\r\n[INFO 2017-03-26 23:52:29,552 layers.py:2230] output for __pool_3__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,553 layers.py:2106] output for __conv_10__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,555 layers.py:2106] output for __conv_11__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,556 layers.py:2106] output for __conv_12__: c = 512, h = 2, w = 2, size = 2048\r\n[INFO 2017-03-26 23:52:29,557 layers.py:2230] output for __pool_4__: c = 512, h = 1, w = 1, size = 512\r\n[INFO 2017-03-26 23:52:29,559 networks.py:1472] The input order is [image, label]\r\n[INFO 2017-03-26 23:52:29,559 networks.py:1478] The output order is [__classification_cost_0__]\r\nI0326 23:52:29.609350   804 GradientMachine.cpp:86] Initing parameters..\r\nI0326 23:52:30.362373   804 GradientMachine.cpp:93] Init parameters done.\r\nKilled",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-03-26T23:54:09+00:00",
        "updated_at": "2017-03-28T15:28:06+00:00",
        "closed_at": "2017-03-28T15:28:06+00:00",
        "comments_count": [
            "typhoonzero",
            "llxxxll",
            "typhoonzero",
            "llxxxll"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 262,
        "title": "book中的所有demo加上画图功能",
        "body": "related work\r\n\r\n1. [add plot cost in v2 api](https://github.com/PaddlePaddle/Paddle/pull/1712)\r\ndone\r\n1. [add draw line in 01.fit-a-line](https://github.com/PaddlePaddle/book/pull/259)\r\ndone\r\n1. [refine plot_curve](https://github.com/PaddlePaddle/Paddle/pull/1736)\r\n1. [add timeout](https://github.com/PaddlePaddle/book/pull/261)\r\n依赖3\r\n\r\n",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "shanyi15",
        "created_at": "2017-03-28T15:49:02+00:00",
        "updated_at": "2018-08-15T09:09:55+00:00",
        "closed_at": "2018-08-15T09:09:55+00:00",
        "comments_count": [
            "helinwang",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 265,
        "title": "Book功能完善",
        "body": "请大家每人自行跑demo，如果问题简单可以自行完善，其他问题请补充到下面的问题收集。\r\n- 目标\r\n具备上一版所有功能，包括应用部分。\r\n\r\n- 问题收集\r\n    - 01.fit_a_line @jacquesqiao \r\n    - 02.recognize_digits\t @gangliao \r\n      - 缺少部分可以自己实现[模型保存 & 预测]\r\n    - 03.image_classification\t@qingqing01   #271 \r\n       - 缺少部分可以自己实现[模型保存 & 预测]\r\n    - 04.word2vec  @reyoung \r\n       * paddle.v2不能使用sparse update, Fixed by [this PR](https://github.com/PaddlePaddle/Paddle/pull/1745)\r\n    - 05.understand_sentiment  @hedaoyuan \r\n      - 缺少部分可以自己实现[模型保存 & 预测]\r\n    - 06.label_semantic_roles\t@lcy-seso  @qingqing01  #273 \r\n        - Evalutor需要支持    @reyoung \r\n        - 训练中test需要支持\r\n    - 07.machine_translation\t@luotao1 \r\n        - beam_search还未封装（这部分有点难度）    @reyoung \r\n        - 之前v1训练好的模型还未转成v2的，且没有提供下载功能  [#1750](https://github.com/PaddlePaddle/Paddle/pull/1750) 已完成\r\n    - 08.recommender_system  @livc \r\n        - 没问题\r\n ",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2017-03-31T05:46:09+00:00",
        "updated_at": "2017-05-11T02:24:01+00:00",
        "closed_at": "2017-05-11T02:24:01+00:00",
        "comments_count": [
            "wangkuiyi",
            "luotao1",
            "qingqing01",
            "luotao1",
            "livc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 266,
        "title": "无法找到输出模型",
        "body": "您好！在运行03.image_classification.train.py结束后，无法找到输出模型。\r\n\r\npaddle.v2.SGD.train也没有配置save_dir的参数，请问在哪里可以找到这个参数？\r\n",
        "state": "closed",
        "user": "jekin000",
        "closed_by": "jekin000",
        "created_at": "2017-04-01T03:16:54+00:00",
        "updated_at": "2017-04-01T08:17:34+00:00",
        "closed_at": "2017-04-01T08:17:34+00:00",
        "comments_count": [
            "Yancey0623",
            "jekin000",
            "jekin000"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 272,
        "title": "book:0.10.0rc2-gpu镜像以--gpu_use=1方式运行示例报错",
        "body": "docker 镜像run命令\r\n`docker run -it docker.paddlepaddle.org/book:0.10.0rc2-gpu /bin/bash`\r\n修改\r\n`03.image_classification/train.py`\r\n28行\r\n`paddle.init(use_gpu=False, trainer_count=1)`\r\n为\r\n`paddle.init(use_gpu=1, trainer_count=1)`\r\n运行\r\n`python train.py`\r\n错误信息如下：\r\n\r\n> I0406 14:21:50.500150   150 Util.cpp:161] commandline:  --use_gpu=1 --trainer_count=1 \r\nF0406 14:21:50.500263   150 hl_cuda_device.cc:454] Check failed: cudaSuccess == cudaStat (0 vs. 35) Cuda Error: CUDA driver version is insufficient for CUDA runtime version\r\n*** Check failure stack trace: ***\r\n    @     0x7fbeb915137d  google::LogMessage::Fail()\r\n    @     0x7fbeb9154ec5  google::LogMessage::SendToLog()\r\n    @     0x7fbeb9150ea3  google::LogMessage::Flush()\r\n    @     0x7fbeb91563de  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fbeb910e5fe  hl_specify_devices_start()\r\n    @     0x7fbeb910e8ed  hl_start()\r\n    @     0x7fbeb90996ea  paddle::initMain()\r\n    @     0x7fbeb91380a0  initPaddle()\r\n    @     0x7fbeb8d71d6a  _wrap_initPaddle\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x568b3a  (unknown)\r\n    @           0x525cb7  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x567d14  (unknown)\r\n    @           0x465bf4  PyRun_FileExFlags\r\n    @           0x46612d  PyRun_SimpleFileExFlags\r\n    @           0x466d92  Py_Main\r\n    @     0x7fbebbf24f45  __libc_start_main\r\n    @           0x577c2e  (unknown)\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n\r\nnvidia-smi信息如下：\r\n\r\n> Thu Apr  6 22:33:01 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1070    Off  | 0000:01:00.0      On |                  N/A |\r\n|  0%   44C    P5    14W / 180W |    560MiB /  8113MiB |      1%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n>+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1147    G   /usr/lib/xorg/Xorg                             377MiB |\r\n|    0      2117    G   compiz                                         169MiB |\r\n|    0      2263    G   /usr/lib/firefox/firefox                         1MiB |\r\n|    0      2423    G   fcitx-qimpanel                                   9MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-04-06T14:31:18+00:00",
        "updated_at": "2018-05-11T12:10:16+00:00",
        "closed_at": "2017-04-16T03:05:22+00:00",
        "comments_count": [
            "gangliao",
            "llxxxll",
            "HardSoft2023"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 275,
        "title": "对于ParamAttr本身，添加更多的描述说明。",
        "body": "主要关联的文章包括\r\n\r\n```bash\r\n$ grep -n 'param_attr' $(find . -name '*.md' )\r\n```\r\n\r\n```text\r\n./04.word2vec/README.en.md:234:        param_attr=paddle.attr.Param(\r\n./04.word2vec/README.en.md:281:                          param_attr=paddle.attr.Param(\r\n./04.word2vec/README.md:219:        param_attr=paddle.attr.Param(\r\n./04.word2vec/README.md:266:                          param_attr=paddle.attr.Param(\r\n./05.understand_sentiment/README.en.md:224:                             param_attr=para_attr,\r\n./05.understand_sentiment/README.en.md:242:                             param_attr=para_attr)\r\n./05.understand_sentiment/README.md:208:                             param_attr=para_attr,\r\n./05.understand_sentiment/README.md:224:                             param_attr=para_attr)\r\n./06.label_semantic_roles/README.en.md:281:    param_attr=paddle.attr.Param(\r\n./06.label_semantic_roles/README.en.md:284:    size=mark_dim, input=mark, param_attr=std_0)\r\n./06.label_semantic_roles/README.en.md:289:        size=word_dim, input=x, param_attr=emb_para) for x in word_input\r\n./06.label_semantic_roles/README.en.md:303:            input=emb, param_attr=std_default) for emb in emb_layers\r\n./06.label_semantic_roles/README.en.md:317:    param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.en.md:328:                input=input_tmp[0], param_attr=hidden_para_attr),\r\n./06.label_semantic_roles/README.en.md:330:                input=input_tmp[1], param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.en.md:340:        param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.en.md:353:         input=input_tmp[0], param_attr=hidden_para_attr),\r\n./06.label_semantic_roles/README.en.md:355:         input=input_tmp[1], param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.en.md:366:    param_attr=paddle.attr.Param(\r\n./06.label_semantic_roles/README.en.md:380:   param_attr=paddle.attr.Param(name='crfw'))\r\n./06.label_semantic_roles/README.md:258:    param_attr=paddle.attr.Param(\r\n./06.label_semantic_roles/README.md:261:    size=mark_dim, input=mark, param_attr=std_0)\r\n./06.label_semantic_roles/README.md:266:        size=word_dim, input=x, param_attr=emb_para) for x in word_input\r\n./06.label_semantic_roles/README.md:280:        input=emb, param_attr=std_default) for emb in emb_layers\r\n./06.label_semantic_roles/README.md:294:    param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.md:305:                input=input_tmp[0], param_attr=hidden_para_attr),\r\n./06.label_semantic_roles/README.md:307:                input=input_tmp[1], param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.md:317:        param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.md:330:        input=input_tmp[0], param_attr=hidden_para_attr),\r\n./06.label_semantic_roles/README.md:332:        input=input_tmp[1], param_attr=lstm_para_attr)\r\n./06.label_semantic_roles/README.md:343:    param_attr=paddle.attr.Param(\r\n./06.label_semantic_roles/README.md:357:   param_attr=paddle.attr.Param(name='crfw'))\r\n./07.machine_translation/README.en.md:264:        param_attr=paddle.attr.ParamAttr(name='_source_language_embedding'))\r\n./07.machine_translation/README.en.md:357:        param_attr=paddle.attr.ParamAttr(name='_target_language_embedding'))\r\n./07.machine_translation/README.md:228:        param_attr=paddle.attr.ParamAttr(name='_source_language_embedding'))\r\n./07.machine_translation/README.md:319:        param_attr=paddle.attr.ParamAttr(name='_target_language_embedding'))\r\n```\r\n\r\n关联PR #274",
        "state": "closed",
        "user": "reyoung",
        "closed_by": "shanyi15",
        "created_at": "2017-04-10T08:10:36+00:00",
        "updated_at": "2018-08-15T09:09:52+00:00",
        "closed_at": "2018-08-15T09:09:52+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 276,
        "title": "Paddle Dataset Tar GZIP解压缩太慢了",
        "body": "![image](https://cloud.githubusercontent.com/assets/728699/24855442/4066ab2e-1e14-11e7-8bda-9d12acaccd0f.png)\r\n\r\n差不多解压缩时间是forward/backward时间的三倍。。",
        "state": "closed",
        "user": "reyoung",
        "closed_by": "reyoung",
        "created_at": "2017-04-10T09:36:57+00:00",
        "updated_at": "2017-04-10T09:51:08+00:00",
        "closed_at": "2017-04-10T09:51:08+00:00",
        "comments_count": [
            "reyoung"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 279,
        "title": "Profiling python codes of all demos in the book",
        "body": "Since demos in paddle book are given for the beginners to learn deep learning with Paddle, it's import to make sure the training process is efficient. It's necessary to profile python codes of all demos in the book to find the speed bottleneck and memory usage. And an automatic profiling tool is needed to make the profiling work conveniently.",
        "state": "closed",
        "user": "QiJune",
        "closed_by": "shanyi15",
        "created_at": "2017-04-14T08:41:45+00:00",
        "updated_at": "2018-08-15T09:09:47+00:00",
        "closed_at": "2018-08-15T09:09:47+00:00",
        "comments_count": [
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 309,
        "title": "move text cnn from chapter 6 to chapter 5.",
        "body": "- After we reorder book chapters, text CNN first appears in chapter 6 recommender_system, not in chapter 6 understand_sentiment. Accordingly, the related content should be modified.\r\n- some dead link caused by book chapter reordering should also be fixed.",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "luotao1",
        "created_at": "2017-05-03T10:37:07+00:00",
        "updated_at": "2017-05-16T08:22:53+00:00",
        "closed_at": "2017-05-16T08:22:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 281,
        "title": "06.label_semantic_roles/train.py 用GPU运行时报错",
        "body": "修改了train.py中的use_gpu=False > True，运行python train.py 打印错误信息如下：\r\n\r\n> python train.py \r\nI0416 10:17:39.718773   830 Util.cpp:161] commandline:  --use_gpu=True --trainer_count=1 \r\n[WARNING 2017-04-16 10:17:40,129 networks.py:1444] `outputs` routine try to calculate network's inputs and outputs order. It might not work well.Please see follow log carefully.\r\n[INFO 2017-04-16 10:17:40,137 networks.py:1472] The input order is [word_data, ctx_n2_data, ctx_n1_data, ctx_0_data, ctx_p1_data, ctx_p2_data, verb_data, mark_data, target]\r\n[INFO 2017-04-16 10:17:40,137 networks.py:1478] The output order is [__crf_layer_0__, crf_dec_l]\r\n[INFO 2017-04-16 10:17:40,171 networks.py:1472] The input order is [word_data, ctx_n2_data, ctx_n1_data, ctx_0_data, ctx_p1_data, ctx_p2_data, verb_data, mark_data, target]\r\n[INFO 2017-04-16 10:17:40,171 networks.py:1478] The output order is [__crf_layer_0__]\r\nI0416 10:17:40.196336   830 GradientMachine.cpp:86] Initing parameters..\r\nI0416 10:17:40.396483   830 GradientMachine.cpp:93] Init parameters done.\r\nF0416 10:17:42.085708   830 CRFLayer.cpp:57] Check failed: !useGpu_ GPU is not supported\r\n*** Check failure stack trace: ***\r\n    @     0x7f44c87db37d  google::LogMessage::Fail()\r\n    @     0x7f44c87deec5  google::LogMessage::SendToLog()\r\n    @     0x7f44c87daea3  google::LogMessage::Flush()\r\n    @     0x7f44c87e03de  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f44c850ff01  paddle::CRFLayer::forward()\r\n    @     0x7f44c8463664  paddle::NeuralNetwork::forward()\r\n    @     0x7f44c8450b23  paddle::GradientMachine::forwardBackward()\r\n    @     0x7f44c87b8617  GradientMachine::forwardBackward()\r\n    @     0x7f44c8417e47  _wrap_GradientMachine_forwardBackward\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x5247ea  PyEval_EvalFrameEx\r\n    @           0x567d14  (unknown)\r\n    @           0x465bf4  PyRun_FileExFlags\r\n    @           0x46612d  PyRun_SimpleFileExFlags\r\n    @           0x466d92  Py_Main\r\n    @     0x7f44cdbe4f45  __libc_start_main\r\n    @           0x577c2e  (unknown)\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)\r\n\r\ntrain.py 改回use_gpu= True > False 错误信息消失，其他simple用类似方式修改为gpu下运行没有出现这个问题。",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-04-16T10:24:35+00:00",
        "updated_at": "2018-08-15T09:09:44+00:00",
        "closed_at": "2018-08-15T09:09:44+00:00",
        "comments_count": [
            "QiJune",
            "lcy-seso",
            "lcy-seso",
            "shanyi15"
        ],
        "labels": [
            "enhancement",
            "question"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 311,
        "title": "Build docker image failed",
        "body": "```bash\r\n$.tools/build_docker.sh\r\n....\r\nRemoving intermediate container 6b73461af002\r\nStep 7 : RUN /bin/bash /book/.tools/convert-markdown-into-ipynb-and-test.sh\r\n ---> Running in e6935c26383d\r\nPlease install go https://golang.org/doc/install#install\r\nThe command '/bin/sh -c /bin/bash /book/.tools/convert-markdown-into-ipynb-and-test.sh' returned a non-zero code: 1\r\n```",
        "state": "closed",
        "user": "Yancey0623",
        "closed_by": "gangliao",
        "created_at": "2017-05-04T11:43:41+00:00",
        "updated_at": "2017-05-15T02:53:57+00:00",
        "closed_at": "2017-05-15T02:53:57+00:00",
        "comments_count": [],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 307,
        "title": "08.recommender_system/train.py falied with GPU",
        "body": "I0427 06:52:26.296445   134 Util.cpp:161] commandline:  --use_gpu=True\r\n[INFO 2017-04-27 06:52:28,615 networks.py:1472] The input order is [user_id, gender_id, age_id, job_id, movie_id, category_id, movie_title, score]\r\n[INFO 2017-04-27 06:52:28,615 networks.py:1478] The output order is [__mse_cost_0__]\r\n[INFO 2017-04-27 06:52:28,624 networks.py:1472] The input order is [user_id, gender_id, age_id, job_id, movie_id, category_id, movie_title, score]\r\n[INFO 2017-04-27 06:52:28,624 networks.py:1478] The output order is [__mse_cost_0__]\r\nI0427 06:52:28.631453   134 GradientMachine.cpp:86] Initing parameters..\r\nI0427 06:52:28.666503   134 GradientMachine.cpp:93] Init parameters done.\r\nF0427 06:52:28.772764   134 Matrix.cpp:645] Not supported\r\n*** Check failure stack trace: ***\r\n    @     0x7f16927a937d  google::LogMessage::Fail()\r\n    @     0x7f16927acec5  google::LogMessage::SendToLog()\r\n    @     0x7f16927a8ea3  google::LogMessage::Flush()\r\n    @     0x7f16927ae3de  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f16925c0706  paddle::GpuMatrix::mul()\r\n    @     0x7f16924a7b1c  paddle::FullyConnectedLayer::forward()\r\n    @     0x7f1692431664  paddle::NeuralNetwork::forward()\r\n    @     0x7f169241eb23  paddle::GradientMachine::forwardBackward()\r\n    @     0x7f1692786617  GradientMachine::forwardBackward()\r\n    @     0x7f16923e5e47  _wrap_GradientMachine_forwardBackward\r\n    @           0x52714b  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x524338  PyEval_EvalFrameEx\r\n    @           0x555551  PyEval_EvalCodeEx\r\n    @           0x525560  PyEval_EvalFrameEx\r\n    @           0x567d14  (unknown)\r\n    @           0x465bf4  PyRun_FileExFlags\r\n    @           0x46612d  PyRun_SimpleFileExFlags\r\n    @           0x466d92  Py_Main\r\n    @     0x7f169557cf45  __libc_start_main\r\n    @           0x577c2e  (unknown)\r\n    @              (nil)  (unknown)\r\nAborted (core dumped)",
        "state": "closed",
        "user": "QiJune",
        "closed_by": "shanyi15",
        "created_at": "2017-04-27T06:54:07+00:00",
        "updated_at": "2018-08-15T09:09:40+00:00",
        "closed_at": "2018-08-15T09:09:40+00:00",
        "comments_count": [
            "TexasRangers86",
            "QiJune",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 314,
        "title": "The latest version of book is not synchronized to the docker.paddlepaddle.org docker image",
        "body": "The latest version of book is not synchronized to the docker.paddlepaddle.org docker image",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-05-15T13:15:46+00:00",
        "updated_at": "2018-08-15T09:09:37+00:00",
        "closed_at": "2018-08-15T09:09:37+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 323,
        "title": "Chapters run very slow",
        "body": "I tried 02. recognize digits and 03. image classification. I expected both running pretty quickly, but each update of the plot in Jupyter Notebook takes 10+ seconds.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "wangkuiyi",
        "created_at": "2017-05-26T21:15:03+00:00",
        "updated_at": "2017-05-27T01:08:44+00:00",
        "closed_at": "2017-05-27T01:08:44+00:00",
        "comments_count": [
            "wangkuiyi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 324,
        "title": "the model in 03.image_classification/resnet.py  is  inconsistent with a stand one",
        "body": "the resnet describe in  03.image_classification/resnet.py is inconsistent with a stand one",
        "state": "closed",
        "user": "NHZlX",
        "closed_by": "NHZlX",
        "created_at": "2017-05-31T08:40:37+00:00",
        "updated_at": "2018-07-10T03:02:59+00:00",
        "closed_at": "2017-06-12T05:14:17+00:00",
        "comments_count": [
            "bBobxx"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 332,
        "title": "08.machine_translation Floating point exception",
        "body": "```bash\r\n➜  Desktop docker run -it paddlepaddle/book:0.10.0 /bin/bash\r\nUnable to find image 'paddlepaddle/book:0.10.0' locally\r\n0.10.0: Pulling from paddlepaddle/book\r\n8f229c550c2e: Pull complete\r\n8e1fb71e8df6: Pull complete\r\nf75a34586856: Pull complete\r\n8744e322b832: Pull complete\r\nd5165bfce78f: Pull complete\r\n96c07ffe1bce: Pull complete\r\n8454a8fa3f3d: Pull complete\r\n8a5eee6421bf: Pull complete\r\n332ddaa4df2c: Pull complete\r\n976505a3f051: Pull complete\r\n8c490e01dc3c: Pull complete\r\nb13e5ab6455b: Pull complete\r\nc7bed60a14bb: Pull complete\r\nDigest: sha256:d7655b911f8a498b5e2934e1480303bb9e8f5cba30d844c7b0de1c2c47eda5cc\r\nStatus: Downloaded newer image for paddlepaddle/book:0.10.0\r\nroot@091c857438ee:/# cd book/08.machine_translation/\r\nroot@091c857438ee:/book/08.machine_translation# ls\r\nimage  index.en.html  index.html  README.en.ipynb  README.en.md  README.ipynb  README.md  train.py\r\nroot@091c857438ee:/book/08.machine_translation# python train.py\r\nI0616 04:10:47.900486    15 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\n[INFO 2017-06-16 04:10:47,984 networks.py:1482] The input order is [source_language_word, target_language_word, target_language_next_word]\r\n[INFO 2017-06-16 04:10:47,985 networks.py:1488] The output order is [__classification_cost_0__]\r\n[INFO 2017-06-16 04:10:48,020 networks.py:1482] The input order is [source_language_word, target_language_word, target_language_next_word]\r\n[INFO 2017-06-16 04:10:48,023 networks.py:1488] The output order is [__classification_cost_0__]\r\nI0616 04:10:48.366200    15 GradientMachine.cpp:86] Initing parameters..\r\nI0616 04:10:51.700908    15 GradientMachine.cpp:93] Init parameters done.\r\n\r\nPass 0, Batch 0, Cost 278.337134, {'classification_error_evaluator': 1.0}\r\n.........\r\nPass 0, Batch 10, Cost 255.534497, {'classification_error_evaluator': 0.9435483813285828}\r\n.........\r\nPass 0, Batch 20, Cost 232.708838, {'classification_error_evaluator': 0.9026548862457275}\r\n.........\r\nPass 0, Batch 30, Cost 302.591309, {'classification_error_evaluator': 0.918367326259613}\r\n.........\r\nPass 0, Batch 40, Cost 246.787573, {'classification_error_evaluator': 0.9083333611488342}\r\n.........\r\nPass 0, Batch 50, Cost 303.848633, {'classification_error_evaluator': 0.9459459185600281}\r\n*** Aborted at 1497586531 (unix time) try \"date -d @1497586531\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7ff3976c7e86) received by PID 15 (TID 0x7ff38f5f0700) from PID 18446744071955054214; stack trace: ***\r\n    @     0x7ff39899c330 (unknown)\r\n    @     0x7ff3976c7e86 paddle::AssignCpuEvaluate<>()\r\n    @     0x7ff3976c90ac paddle::AssignEvaluate<>()\r\n    @     0x7ff3976c3d5b paddle::adamApply()\r\n    @     0x7ff3976c14a6 paddle::AdamParameterOptimizer::update()\r\n    @     0x7ff3976abc17 paddle::SgdThreadUpdater::threadUpdateDense()\r\n    @     0x7ff3976acd9f _ZNSt17_Function_handlerIFvimEZN6paddle16SgdThreadUpdater11finishBatchEfEUlimE_E9_M_invokeERKSt9_Any_dataim\r\n    @     0x7ff3960314ec _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv\r\n    @     0x7ff394ff1a60 (unknown)\r\n    @     0x7ff398994184 start_thread\r\n    @     0x7ff3986c1bed clone\r\n    @                0x0 (unknown)\r\nFloating point exception\r\nroot@091c857438ee:/book/08.machine_translation#\r\n```",
        "state": "closed",
        "user": "livc",
        "closed_by": "lcy-seso",
        "created_at": "2017-06-16T05:08:03+00:00",
        "updated_at": "2017-07-10T02:54:55+00:00",
        "closed_at": "2017-07-10T02:54:55+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 327,
        "title": "Broken link to DL 101 book from www.paddlepaddle.org/doc/getstarted/index_en.html",
        "body": "From www.paddlepaddle.org/doc/getstarted/index_en.html, clicking the `Deep Learning 101` hyperlink leads to http://book.paddlepaddle.org/index.en.html which returns a 404 error. It should be redirected to http://book.paddlepaddle.org/index.html",
        "state": "closed",
        "user": "alvations",
        "closed_by": "shanyi15",
        "created_at": "2017-06-02T01:30:43+00:00",
        "updated_at": "2018-08-15T09:09:33+00:00",
        "closed_at": "2018-08-15T09:09:33+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 328,
        "title": "book/03.image_classification/vgg.py dropout module wrong",
        "body": "https://github.com/PaddlePaddle/book/blob/develop/03.image_classification/vgg.py#L40\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 91, in <module>\r\n    main()\r\n  File \"train.py\", line 37, in main\r\n    net = vgg_bn_drop(image)\r\n  File \"/home/lizhao/book/03.image_classification/vgg.py\", line 40, in vgg_bn_drop\r\n    drop = paddle.networks.dropout(input=conv5, dropout_rate=0.5)\r\nAttributeError: 'module' object has no attribute 'dropout'\r\n```\r\nAccording to \r\nhttps://github.com/PaddlePaddle/Paddle/blob/0beda8736ffcac80a95bea20f873d8972d2b5b5e/doc/api/v2/config/networks.rst#dropout_layer\r\n\r\nThis line should be \r\n```\r\ndrop = paddle.networks.dropout_layer(input=conv5, dropout_rate=0.5)\r\n```",
        "state": "closed",
        "user": "livc",
        "closed_by": "lcy-seso",
        "created_at": "2017-06-05T12:04:49+00:00",
        "updated_at": "2017-06-16T02:29:08+00:00",
        "closed_at": "2017-06-16T02:29:08+00:00",
        "comments_count": [
            "livc",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 333,
        "title": "Is there a reason for buf_size=8192 ?",
        "body": "For most of the demo code in the new \"Deep Learning 101\" book, the `buf_size=8192` is used. https://github.com/PaddlePaddle/book/search?utf8=✓&q=8192&type=\r\n\r\n**Is there a reason for setting the value of 8192?**\r\n\r\n**Is there a way to find out what is the maximum value we can set for the `buf_size`?** ",
        "state": "closed",
        "user": "alvations",
        "closed_by": "shanyi15",
        "created_at": "2017-06-22T08:06:21+00:00",
        "updated_at": "2018-08-15T09:09:29+00:00",
        "closed_at": "2018-08-15T09:09:29+00:00",
        "comments_count": [
            "lcy-seso",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 335,
        "title": " [ 06.understand_sentiment ]get import error when running .ipynb as .py  in Docker",
        "body": "```\r\n➜  06.understand_sentiment jupyter nbconvert --to python README.ipynb --stdout | python\r\n[NbConvertApp] Converting notebook README.ipynb to python\r\nI0705 07:37:14.153400   475 Util.cpp:166] commandline:  --use_gpu=False\r\nload dictionary...\r\n[INFO 2017-07-05 07:37:34,012 networks.py:1482] The input order is [word, label]\r\n[INFO 2017-07-05 07:37:34,014 networks.py:1488] The output order is [__classification_cost_0__]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 353, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/plot/plot.py\", line 44, in __init__\r\n    import matplotlib.pyplot as plt\r\n  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 115, in <module>\r\n    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\r\n  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 32, in pylab_setup\r\n    globals(),locals(),[backend_name],0)\r\n  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py\", line 6, in <module>\r\n    from six.moves import tkinter as Tk\r\n  File \"/usr/local/lib/python2.7/dist-packages/six.py\", line 203, in load_module\r\n    mod = mod._resolve()\r\n  File \"/usr/local/lib/python2.7/dist-packages/six.py\", line 115, in _resolve\r\n    return _import_module(self.mod)\r\n  File \"/usr/local/lib/python2.7/dist-packages/six.py\", line 82, in _import_module\r\n    __import__(name)\r\n  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 42, in <module>\r\n    raise ImportError, str(msg) + ', please install the python-tk package'\r\nImportError: No module named _tkinter, please install the python-tk package\r\n```",
        "state": "closed",
        "user": "livc",
        "closed_by": "livc",
        "created_at": "2017-07-05T07:41:55+00:00",
        "updated_at": "2018-05-19T01:35:48+00:00",
        "closed_at": "2018-05-19T01:35:48+00:00",
        "comments_count": [
            "blendaguedes-zz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 336,
        "title": "[ 06.understand_sentiment ][README.cn.ipynb] infer:Duplicated layer name: word",
        "body": "I'm updating our RegressionTest code, and I got an error when running the .py file which is converted from .ipynb file:\r\n\r\n```bash\r\n$ jupyter nbconvert --to python README.cn.ipynb\r\n$ python README.cn.py\r\n\r\n……\r\n……\r\n[CRITICAL 2017-07-05 11:14:25,124 layers.py:854] Duplicated layer name: word\r\nTraceback (most recent call last):\r\n  File \"tmp.py\", line 427, in <module>\r\n    out = convolution_net(dict_dim, class_dim=class_dim, is_predict=True)\r\n  File \"tmp.py\", line 137, in convolution_net\r\n    paddle.data_type.integer_value_sequence(input_dim))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/layer.py\", line 88, in __data_layer__\r\n    l = v1_layers.data_layer(name, type.dim, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 350, in wrapper\r\n    return method(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 854, in data_layer\r\n    **ExtraLayerAttribute.to_kwargs(layer_attr))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 3136, in Layer\r\n    return layer_func(name, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 1681, in __init__\r\n    name, 'data', size, inputs=[], device=device)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 1363, in __init__\r\n    'Duplicated layer name: %s' % name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 156, in config_assert\r\n    logger.fatal(msg)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 3482, in my_fatal\r\n    raise Exception()\r\nException\r\n```",
        "state": "closed",
        "user": "livc",
        "closed_by": "shanyi15",
        "created_at": "2017-07-05T11:24:15+00:00",
        "updated_at": "2018-08-15T09:09:23+00:00",
        "closed_at": "2018-08-15T09:09:23+00:00",
        "comments_count": [
            "lcy-seso",
            "cszhou",
            "hxs91",
            "shanyi15"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 338,
        "title": "A typo in project homepage",
        "body": "There is a typo in the top right corner of this [webpage](http://www.paddlepaddle.org/doc/howto/index_en.html), It should be `fork` rather than `folk`.",
        "state": "closed",
        "user": "Beanocean",
        "closed_by": "luotao1",
        "created_at": "2017-07-06T07:58:16+00:00",
        "updated_at": "2017-07-07T08:31:15+00:00",
        "closed_at": "2017-07-07T08:31:15+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 340,
        "title": "Numeric prefix of chapters don't exist in Docker images",
        "body": "I ran the Docker images \r\n\r\n```bash\r\ndocker run -p 8888:8888 paddlepaddle/book\r\n```\r\n\r\nand got the following content in my Web browser:\r\n\r\n![screen shot 2017-07-09 at 5 18 53 pm](https://user-images.githubusercontent.com/1548775/27998914-1c1d6de0-64cb-11e7-9c70-9655d9e9cc77.png)\r\n\r\nWe see that the directory prefixes like `00.`, `01.` etc do not exist in the Docker image.\r\n\r\nThese prefixes are important because they direct Jupyter Notebook to sort directories in the order of book chapters.",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "shanyi15",
        "created_at": "2017-07-10T00:23:03+00:00",
        "updated_at": "2018-08-15T09:09:16+00:00",
        "closed_at": "2018-08-15T09:09:16+00:00",
        "comments_count": [
            "wangkuiyi",
            "wangkuiyi",
            "typhoonzero",
            "gangliao",
            "wangkuiyi",
            "wangkuiyi",
            "gangliao",
            "wangkuiyi",
            "helinwang",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 347,
        "title": "加载训练参数问题？",
        "body": "存储参数\r\n```\r\nwith open('params_pass_%d.tar' % event.pass_id, 'w') as f:\r\n       parameters.to_tar(f)\r\n```\r\n读取参数\r\n```\r\nwith open('params_pass_4.tar', 'r') as f:\r\n       parameters = paddle.parameters.Parameters.from_tar(f)\r\n```\r\n错误提示\r\n```\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nF0720 03:49:04.188344   464 ClassRegistrar.h:65] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: data\r\n*** Check failure stack trace: ***\r\nAborted\r\n\r\n```\r\n```\r\nimport reader\r\nimport gzip\r\nimport paddle.v2 as paddle\r\nimport train\r\nimport copy\r\n\r\nif __name__ == '__main__':\r\n    reader.__initialize_meta_info__()\r\n    # with open('params_pass_4.tar.gz', 'r') as f:\r\n    #     parameters = paddle.parameters.Parameters.from_tar(f)\r\n    with open('params_pass_4.tar', 'r') as f:\r\n        parameters = paddle.parameters.Parameters.from_tar(f)\r\n    video_feature_hidden = train.get_video_combined_features()\r\n    inference = paddle.layer.fc(input=video_feature_hidden, size=1, act=paddle.activation.Sigmoid())\r\n\r\n    movie_id = 'V_00jXmraD'\r\n    movie = reader.video_info()[movie_id]\r\n\r\n    feature = movie.value()\r\n\r\n    infer_dict = copy.copy(train.feeding)\r\n    del infer_dict['ctr']\r\n\r\n    prediction = paddle.infer(\r\n        output_layer=inference,\r\n        parameters=parameters,\r\n        input=[feature],\r\n        feeding=infer_dict)\r\n    print prediction\r\n```",
        "state": "closed",
        "user": "foxgaga",
        "closed_by": "foxgaga",
        "created_at": "2017-07-20T03:56:27+00:00",
        "updated_at": "2017-07-20T04:03:53+00:00",
        "closed_at": "2017-07-20T04:03:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 343,
        "title": "chapter 07, SRL crashes after it runs a while",
        "body": "Chapter 07, labeling semantic roles, crashes after it runs a while. The error information is as follows. It seems some bug occurs.\r\n\r\n```text\r\nB000000087012:Paddle xx$ cd ../book-develop/07.label_semantic_roles/\r\nB000000087012:07.label_semantic_roles xx$ python train.py \r\nI0714 23:42:26.339615 1946898432 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\nI0714 23:42:26.441073 1946898432 GradientMachine.cpp:85] Initing parameters..\r\nI0714 23:42:26.567050 1946898432 GradientMachine.cpp:92] Init parameters done.\r\nPass 0, Batch 0, Cost 150.801550, {'__sum_evaluator_0__': 1.0}\r\nError while running 07.label_semantic_roles:  [...Matrix.cpp:2712] Check failed: index[i] < (int)tableSize (39052 vs. 3162) \r\n\r\nTest with Pass 0, Batch 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\nPass 0, Batch 100, Cost 86.668573, {'__sum_evaluator_0__': 0.4900662302970886}\r\nPass 0, Batch 200, Cost 82.026624, {'__sum_evaluator_0__': 0.5676567554473877}\r\nPass 0, Batch 300, Cost 55.416589, {'__sum_evaluator_0__': 0.7542372941970825}\r\nPass 0, Batch 400, Cost 70.610925, {'__sum_evaluator_0__': 0.7370370626449585}\r\nPass 0, Batch 500, Cost 85.192023, {'__sum_evaluator_0__': 0.6752411723136902}\r\n\r\nTest with Pass 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\nF0714 23:44:25.227174 1946898432 Matrix.cpp:2712] Check failed: index[i] < (int)tableSize (39052 vs. 3162) \r\n*** Check failure stack trace: ***\r\n    @        0x10925f7ed  google::LogMessage::Flush()\r\n    @        0x109263a6f  google::LogMessageFatal::~LogMessageFatal()\r\n    @        0x1092606a9  google::LogMessageFatal::~LogMessageFatal()\r\n    @        0x10919dfd0  paddle::CpuMatrix::selectRowsImp<>()\r\n    @        0x108f8d263  paddle::MixedLayer::forward()\r\n    @        0x108ff779b  paddle::NeuralNetwork::forward()\r\n    @        0x108f41f94  _wrap_GradientMachine_forward()\r\n    @        0x100fc31bd  PyEval_EvalFrameEx\r\n    @        0x100fc80b2  fast_function\r\n    @        0x100fc2db3  PyEval_EvalFrameEx\r\n    @        0x100fbb8f2  PyEval_EvalCodeEx\r\n    @        0x100fc8015  fast_function\r\n    @        0x100fc2db3  PyEval_EvalFrameEx\r\n    @        0x100f3b7a1  gen_send_ex\r\n    @        0x100fc23b5  PyEval_EvalFrameEx\r\n    @        0x100f3b7a1  gen_send_ex\r\n    @        0x100fc23b5  PyEval_EvalFrameEx\r\n    @        0x100fbb8f2  PyEval_EvalCodeEx\r\n    @        0x100fc8015  fast_function\r\n    @        0x100fc2db3  PyEval_EvalFrameEx\r\n    @        0x100fbb8f2  PyEval_EvalCodeEx\r\n    @        0x100fc8015  fast_function\r\n    @        0x100fc2db3  PyEval_EvalFrameEx\r\n    @        0x100fbb8f2  PyEval_EvalCodeEx\r\n    @        0x100fc8015  fast_function\r\n    @        0x100fc2db3  PyEval_EvalFrameEx\r\n    @        0x100fbb8f2  PyEval_EvalCodeEx\r\n    @        0x100fbb2e6  PyEval_EvalCode\r\n    @        0x100fea254  PyRun_FileExFlags\r\n    @        0x100fe9dd1  PyRun_SimpleFileExFlags\r\n    @        0x100fffa12  Py_Main\r\nAbort trap: 6\r\n```",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-07-15T00:30:36+00:00",
        "updated_at": "2018-08-15T09:16:19+00:00",
        "closed_at": "2018-08-15T09:16:19+00:00",
        "comments_count": [
            "lcy-seso",
            "hedaoyuan",
            "afei-bd",
            "hedaoyuan",
            "shanyi15"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 344,
        "title": "docker需要hyper-v虚拟化能力才能使用",
        "body": "我安装完docker它就报错了，原因是我电脑不支持hyper-v虚拟化，希望能增加其他安装的方法咯，比如tensorflow教程里面的Anaconda方式安装就不错。环境在windows10下发生的，我只是提下问题和意见而已",
        "state": "closed",
        "user": "Hitvz",
        "closed_by": "Hitvz",
        "created_at": "2017-07-15T09:13:39+00:00",
        "updated_at": "2017-07-21T08:56:01+00:00",
        "closed_at": "2017-07-15T13:03:43+00:00",
        "comments_count": [
            "Hitvz",
            "Hitvz",
            "Hitvz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 345,
        "title": "房价程序运行错误（python2.7）",
        "body": "![2017-07-17_135913](https://user-images.githubusercontent.com/5136490/28256792-2abba3de-6af8-11e7-8584-3ffad71e042e.png)\r\n",
        "state": "closed",
        "user": "zgd716",
        "closed_by": "Yancey0623",
        "created_at": "2017-07-17T05:59:46+00:00",
        "updated_at": "2017-07-18T05:00:07+00:00",
        "closed_at": "2017-07-18T05:00:07+00:00",
        "comments_count": [
            "lcy-seso",
            "zgd716",
            "Yancey0623",
            "lcy-seso",
            "zgd716",
            "lcy-seso",
            "zgd716"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 346,
        "title": "08.machine_translation has error when is_generating=True",
        "body": "Error Info:\r\n```\r\nI0718 14:56:51.086495 26798 Util.cpp:166] commandline:  --use_gpu=True --trainer_count=1 \r\nTraceback (most recent call last):\r\n  File \"train.py\", line 235, in <module>\r\n    main()\r\n  File \"train.py\", line 201, in main\r\n    is_generating, beam_size)\r\n  File \"train.py\", line 132, in seq_to_seq_net\r\n    max_length=max_length)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 3803, in beam_search\r\n    is_generating=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 3498, in recurrent_group\r\n    layer_outs = step(*in_args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 3793, in __real_step__\r\n    predict = gipt.after_real_step(step(*args))\r\n  File \"train.py\", line 65, in gru_decoder_with_attention\r\n    error_clipping_threshold=100.0))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 362, in wrapper\r\n    return method(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 973, in fc_layer\r\n    **ExtraLayerAttribute.to_kwargs(layer_attr))\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 3191, in Layer\r\n    return layer_func(name, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py\", line 1583, in __init__\r\n    super(FCLayer, self).__init__(name, 'fc', size, inputs=inputs, **xargs)\r\nTypeError: __init__() got an unexpected keyword argument 'error_clipping_threshold'\r\n```",
        "state": "closed",
        "user": "lujiaying",
        "closed_by": "lujiaying",
        "created_at": "2017-07-18T07:03:11+00:00",
        "updated_at": "2017-07-19T08:25:33+00:00",
        "closed_at": "2017-07-19T08:25:33+00:00",
        "comments_count": [
            "lcy-seso",
            "lujiaying",
            "lujiaying",
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 348,
        "title": "_path.so: undefined symbol: PyUnicodeUCS4_AsASCIIString",
        "body": "error: _path.so: undefined symbol: PyUnicodeUCS4_AsASCIIString, when i run train.py.\r\n\r\npython train.py\r\nI0720 16:25:50.394904 16263 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nI0720 16:25:50.401638 16263 GradientMachine.cpp:85] Initing parameters..\r\nI0720 16:25:50.401674 16263 GradientMachine.cpp:92] Init parameters done.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 50, in <module>\r\n    main()\r\n  File \"train.py\", line 42, in main\r\n    paddle.reader.shuffle(uci_housing.train(), buf_size=500),\r\n  File \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/dataset/uci_housing.py\", line 85, in train\r\n    load_data(download(URL, 'uci_housing', MD5))\r\n  File \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/dataset/uci_housing.py\", line 66, in load_data\r\n    feature_range(maximums[:-1], minimums[:-1])\r\n  File \"/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/dataset/uci_housing.py\", line 42, in feature_range\r\n    import matplotlib.pyplot as plt\r\n  File \"/home/yanchunwei/third_party/paddle_env/paddle_box/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 29, in <module>\r\n    import matplotlib.colorbar\r\n  File \"/home/yanchunwei/third_party/paddle_env/paddle_box/lib/python2.7/site-packages/matplotlib/colorbar.py\", line 32, in <module>\r\n    import matplotlib.artist as martist\r\n  File \"/home/yanchunwei/third_party/paddle_env/paddle_box/lib/python2.7/site-packages/matplotlib/artist.py\", line 15, in <module>\r\n    from .transforms import (Bbox, IdentityTransform, TransformedBbox,\r\n  File \"/home/yanchunwei/third_party/paddle_env/paddle_box/lib/python2.7/site-packages/matplotlib/transforms.py\", line 39, in <module>\r\n    from matplotlib._path import (affine_transform, count_bboxes_overlapping_bbox,\r\nImportError: /home/yanchunwei/third_party/paddle_env/paddle_box/lib/python2.7/site-packages/matplotlib/_path.so: undefined symbol: PyUnicodeUCS4_AsASCIIString",
        "state": "closed",
        "user": "fty8788",
        "closed_by": "shanyi15",
        "created_at": "2017-07-20T08:31:06+00:00",
        "updated_at": "2018-08-15T09:16:16+00:00",
        "closed_at": "2018-08-15T09:16:16+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 351,
        "title": "07.label_semantic_roles Training报错：F0725 02:40:07.250262    59 Matrix.cpp:2712] Check failed: index[i] < (int)tableSize (39052 vs. 3162) ",
        "body": "MacOS，paddlepaddle/book Docker版，training提示Check failed，怀疑是内存不够，麻烦帮忙看下，谢谢\r\n\r\n```text\r\nroot@ded75297f65b:/book/07.label_semantic_roles# python train.py \r\nI0725 02:37:49.529109    59 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\nI0725 02:37:49.743851    59 GradientMachine.cpp:85] Initing parameters..\r\nI0725 02:37:49.939476    59 GradientMachine.cpp:92] Init parameters done.\r\nPass 0, Batch 0, Cost 125.562317, {'__sum_evaluator_0__': 1.0}\r\n\r\nTest with Pass 0, Batch 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\n^NPass 0, Batch 100, Cost 77.429456, {'__sum_evaluator_0__': 0.7728813290596008}\r\nPass 0, Batch 200, Cost 63.803693, {'__sum_evaluator_0__': 0.5230262875556946}\r\nPass 0, Batch 300, Cost 48.480524, {'__sum_evaluator_0__': 0.36206895112991333}\r\nPass 0, Batch 400, Cost 54.000317, {'__sum_evaluator_0__': 0.5486111044883728}\r\nPass 0, Batch 500, Cost 66.968311, {'__sum_evaluator_0__': 0.9027237296104431}\r\n\r\nTest with Pass 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\nF0725 02:40:07.250262    59 Matrix.cpp:2712] Check failed: index[i] < (int)tableSize (39052 vs. 3162) \r\n*** Check failure stack trace: ***\r\n    @     0x7f38d4b96c5d  google::LogMessage::Fail()\r\n    @     0x7f38d4b98fa8  google::LogMessage::SendToLog()\r\n    @     0x7f38d4b9674b  google::LogMessage::Flush()\r\n    @     0x7f38d4b99e7e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f38d4abd9dd  paddle::CpuMatrix::selectRowsImp<>()\r\n    @     0x7f38d4abaefe  paddle::CpuMatrix::selectRows()\r\n    @     0x7f38d47cbe99  paddle::TableProjection::forward()\r\n    @     0x7f38d4833704  paddle::MixedLayer::forward()\r\n    @     0x7f38d490b6f1  paddle::NeuralNetwork::forward()\r\n    @     0x7f38d4771eb6  _wrap_GradientMachine_forward\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7f38eb6f3830  __libc_start_main\r\n    @           0x49d9d9  _start\r\nAborted\r\n```",
        "state": "closed",
        "user": "afei-bd",
        "closed_by": "hedaoyuan",
        "created_at": "2017-07-25T06:48:48+00:00",
        "updated_at": "2017-07-25T07:20:57+00:00",
        "closed_at": "2017-07-25T07:20:57+00:00",
        "comments_count": [
            "hedaoyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 353,
        "title": "NN网络+CRF为什么设置GPU=True报错",
        "body": "![bef2f0f9d1449dd4857824c4076fdd6c](https://user-images.githubusercontent.com/22500910/28743349-5c464f22-747a-11e7-8f90-1cd99905f8b5.png)\r\nhi，您好，麻烦问一下，为什么我网络结构里配置RNN/LSTM+CRF，开启--use_gpu=True报错，设置成false就不报错\r\n在CPU模式下训练NN+CRF的好慢，单纯一层CRF速度倒是还可以",
        "state": "closed",
        "user": "hitwangshuai",
        "closed_by": "shanyi15",
        "created_at": "2017-07-29T08:31:27+00:00",
        "updated_at": "2018-08-15T09:16:12+00:00",
        "closed_at": "2018-08-15T09:16:12+00:00",
        "comments_count": [
            "Superjomn",
            "hitwangshuai",
            "Superjomn",
            "hitwangshuai",
            "Superjomn",
            "hitwangshuai",
            "qingqing01",
            "shanyi15"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 356,
        "title": "官网paddlepaddle/book:latest在运行07.label_semantic_roles和paddlepaddle/book:0.10.0在运行08.machine_translation有点小问题",
        "body": "在paddlepaddle/book:0.10.0中运行08.machine_translation会出现如下问题：\r\n```\r\nroot@2326a7bdee57:/book/08.machine_translation# python train.py\r\nI0801 03:01:01.564342    15 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\n[INFO 2017-08-01 03:01:01,658 networks.py:1482] The input order is [source_language_word, target_language_word, target_language_next_word]\r\n[INFO 2017-08-01 03:01:01,659 networks.py:1488] The output order is [__classification_cost_0__]\r\n[INFO 2017-08-01 03:01:01,692 networks.py:1482] The input order is [source_language_word, target_language_word, target_language_next_word]\r\n[INFO 2017-08-01 03:01:01,692 networks.py:1488] The output order is [__classification_cost_0__]\r\nI0801 03:01:02.328541    15 GradientMachine.cpp:86] Initing parameters..\r\nI0801 03:01:05.297921    15 GradientMachine.cpp:93] Init parameters done.\r\n\r\nPass 0, Batch 0, Cost 195.874988, {'classification_error_evaluator': 1.0}\r\n.........\r\nPass 0, Batch 10, Cost 204.007812, {'classification_error_evaluator': 0.9292929172515869}\r\n.........\r\nPass 0, Batch 20, Cost 257.487524, {'classification_error_evaluator': 0.9279999732971191}\r\n.........\r\nPass 0, Batch 30, Cost 300.606274, {'classification_error_evaluator': 0.9041095972061157}\r\n.........\r\nPass 0, Batch 40, Cost 216.137231, {'classification_error_evaluator': 0.9523809552192688}\r\n.......*** Aborted at 1501556672 (unix time) try \"date -d @1501556672\" if you are using GNU date ***\r\nPC: @                0x0 (unknown)\r\n*** SIGFPE (@0x7fc30ddebe86) received by PID 15 (TID 0x7fc305d14700) from PID 232701574; stack trace: ***\r\n    @     0x7fc30f0c0330 (unknown)\r\n    @     0x7fc30ddebe86 paddle::AssignCpuEvaluate<>()\r\n    @     0x7fc30dded0ac paddle::AssignEvaluate<>()\r\n    @     0x7fc30dde7d5b paddle::adamApply()\r\n    @     0x7fc30dde54a6 paddle::AdamParameterOptimizer::update()\r\n    @     0x7fc30ddcfc17 paddle::SgdThreadUpdater::threadUpdateDense()\r\n    @     0x7fc30ddd0d9f _ZNSt17_Function_handlerIFvimEZN6paddle16SgdThreadUpdater11finishBatchEfEUlimE_E9_M_invokeERKSt9_Any_dataim\r\n    @     0x7fc30c7554ec _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv\r\n    @     0x7fc30b715a60 (unknown)\r\n    @     0x7fc30f0b8184 start_thread\r\n    @     0x7fc30ede5bed clone\r\n    @                0x0 (unknown)\r\nFloating point exception\r\n```\r\n\r\n\r\n \r\n在paddlepaddle/book:latest中运行07.label_semantic_roles会出现如下问题：\r\n```\r\nroot@209789cb8eed:/book/07.label_semantic_roles# python train.py\r\nI0801 04:40:38.478021   139 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nI0801 04:40:38.577181   139 GradientMachine.cpp:85] Initing parameters..\r\nI0801 04:40:38.765612   139 GradientMachine.cpp:92] Init parameters done.\r\nPass 0, Batch 0, Cost 121.618921, {'__sum_evaluator_0__': 1.0}\r\n\r\nTest with Pass 0, Batch 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\nPass 0, Batch 100, Cost 61.798883, {'__sum_evaluator_0__': 0.6978852152824402}\r\nPass 0, Batch 200, Cost 68.420306, {'__sum_evaluator_0__': 0.5071942210197449}\r\nPass 0, Batch 300, Cost 89.819623, {'__sum_evaluator_0__': 0.8310810923576355}\r\nPass 0, Batch 400, Cost 75.320734, {'__sum_evaluator_0__': 0.5387097001075745}\r\nPass 0, Batch 500, Cost 60.577905, {'__sum_evaluator_0__': 0.748275876045227}\r\n\r\nTest with Pass 0, {'__sum_evaluator_0__': 0.7465202808380127}\r\nF0801 04:42:45.812535   139 Matrix.cpp:2540] Check failed: index[i] < (int)tableSize (39052 vs. 3162)\r\n*** Check failure stack trace: ***\r\n    @     0x7fa82a2bc78d  google::LogMessage::Fail()\r\n    @     0x7fa82a2bead8  google::LogMessage::SendToLog()\r\n    @     0x7fa82a2bc27b  google::LogMessage::Flush()\r\n    @     0x7fa82a2bf9ae  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fa82a1e3dbd  paddle::CpuMatrix::selectRowsImp<>()\r\n    @     0x7fa82a1e12be  paddle::CpuMatrix::selectRows()\r\n    @     0x7fa829ee41a9  paddle::TableProjection::forward()\r\n    @     0x7fa829f4ba14  paddle::MixedLayer::forward()\r\n    @     0x7fa82a025fd1  paddle::NeuralNetwork::forward()\r\n    @     0x7fa829e8a1c6  _wrap_GradientMachine_forward\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7fa840e1b830  __libc_start_main\r\n    @           0x49d9d9  _start\r\nAborted\r\n```",
        "state": "closed",
        "user": "chengduoZH",
        "closed_by": "shanyi15",
        "created_at": "2017-08-01T04:57:48+00:00",
        "updated_at": "2018-08-15T09:16:08+00:00",
        "closed_at": "2018-08-15T09:16:08+00:00",
        "comments_count": [
            "gangliao",
            "gangliao",
            "chengduoZH",
            "shanyi15"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 361,
        "title": "请教一下是否提供sum layer，以实现word2vec cbow",
        "body": "book里提供的方法，4个词embedding之后，做concat，然后再softmax。\r\n如果我想实现embedding之后sum/average，应该使用什么层呢？\r\nlinear_comb层吗？",
        "state": "closed",
        "user": "lujiaying",
        "closed_by": "lujiaying",
        "created_at": "2017-08-08T06:35:01+00:00",
        "updated_at": "2017-09-01T06:06:29+00:00",
        "closed_at": "2017-09-01T06:06:29+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 360,
        "title": "应用模型对图片分类问题",
        "body": "请问图中的label是5，是什么意思，怎么定义的？如图\r\n![image](https://user-images.githubusercontent.com/26181201/28950818-86e3c0ec-78f9-11e7-8de1-f01242da015b.png)\r\n\r\n",
        "state": "closed",
        "user": "yqxqls",
        "closed_by": "shanyi15",
        "created_at": "2017-08-04T01:45:58+00:00",
        "updated_at": "2018-08-15T09:15:58+00:00",
        "closed_at": "2018-08-15T09:15:58+00:00",
        "comments_count": [
            "yqxqls",
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 359,
        "title": "获取路径失败",
        "body": "如图\r\n![image](https://user-images.githubusercontent.com/26181201/28947731-1d1e207c-78e4-11e7-8854-e0347bd1a103.png)\r\n\r\n是在docker环境下运行paddlepaddle/book的",
        "state": "closed",
        "user": "yqxqls",
        "closed_by": "shanyi15",
        "created_at": "2017-08-03T23:12:16+00:00",
        "updated_at": "2018-08-15T09:16:04+00:00",
        "closed_at": "2018-08-15T09:16:04+00:00",
        "comments_count": [
            "yqxqls",
            "Yancey0623",
            "yqxqls",
            "Yancey0623",
            "shanyi15"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 362,
        "title": "请问图中的label输出5，如何知道分类5是对应哪张图啊?如图",
        "body": "请问图中的label输出5,怎么知道这个分类5是对应哪张图？如图\r\n![image](https://user-images.githubusercontent.com/30828687/29066372-973106c4-7c61-11e7-845f-ca6234321cb7.png)\r\n",
        "state": "closed",
        "user": "yanqls",
        "closed_by": "shanyi15",
        "created_at": "2017-08-08T09:47:19+00:00",
        "updated_at": "2018-08-15T09:15:51+00:00",
        "closed_at": "2018-08-15T09:15:51+00:00",
        "comments_count": [
            "yqxqls",
            "qingqing01",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 354,
        "title": "图像目录问题",
        "body": "03.image_classification/目录下，没有params_pass_50.tar.gz这个文件",
        "state": "closed",
        "user": "yqxqls",
        "closed_by": "NHZlX",
        "created_at": "2017-07-31T23:21:18+00:00",
        "updated_at": "2017-08-15T02:34:03+00:00",
        "closed_at": "2017-08-03T08:23:02+00:00",
        "comments_count": [
            "gangliao",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "NHZlX",
            "yqxqls",
            "NHZlX",
            "yqxqls",
            "yqxqls",
            "yqxqls",
            "yqxqls",
            "typhoonzero",
            "yqxqls",
            "typhoonzero",
            "yqxqls",
            "typhoonzero",
            "yqxqls",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 364,
        "title": "请问生成的参数文件 params_pass_xx.tar 怎样读取参数？",
        "body": "with open('params_pass_%d.tar'%event.pass_id,'w') as f:\r\n\t\t\tparameters.to_tar(f)\r\n把参数写进了文件，那么有了一个参数文件，怎样读参数给parameters呢？",
        "state": "closed",
        "user": "mycamphortree",
        "closed_by": "luotao1",
        "created_at": "2017-08-22T11:03:20+00:00",
        "updated_at": "2017-08-24T02:20:48+00:00",
        "closed_at": "2017-08-24T02:20:48+00:00",
        "comments_count": [
            "luotao1",
            "mycamphortree"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 365,
        "title": "pass_id和batch_id的含义是什么？",
        "body": "第2课，数字识别中，从pass_id的输出结果来看，应该是训练器trainer设置的训练次数“num_passes”，但是batch_id是什么回事，明明trainer中设置的batch_size = 128，为啥batch_id可以达到400？",
        "state": "closed",
        "user": "mycamphortree",
        "closed_by": "luotao1",
        "created_at": "2017-08-23T15:02:30+00:00",
        "updated_at": "2017-08-25T02:42:16+00:00",
        "closed_at": "2017-08-25T02:42:16+00:00",
        "comments_count": [
            "luotao1",
            "mycamphortree",
            "luotao1",
            "mycamphortree"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 366,
        "title": "使用paddlepaddle中的疑惑",
        "body": "我试了 新手入门-基本使用概念-例子，\r\n1、trainer.train(\r\n    reader = paddle.batch(train_reader(), batch_size = 1),\r\n    feeding = feeding,\r\n    event_handler = event_handler,\r\n    num_passes = 100)\r\n中\r\n   feeding = feeding, 的作用？\r\n2、训练结束时候cost是\r\nPass 99, Batch 0, Cost0.021706\r\nPass 99, Batch 1, Cost0.006622\r\nPass 99, Batch 2, Cost0.008095\r\nPass 99, Batch 3, Cost0.000031\r\n我把训练时使用的数据（换了数组名称）又带到这个训练完的模型中预测输出结果：\r\ntest_data = [[1, 1], [1, 2], [3, 4],[5, 2]];\r\nprobs = paddle.infer(\r\n    output_layer=y_predict, parameters=parameters, input=test_data)\r\nfor data in probs:\r\n    print data\r\n打印出来的结果如下\r\n[-2.18957305]\r\n[-2.18957305]\r\n[-5.97472429]\r\n[-9.7598753]\r\n感觉和上面的cost不一样\r\n3、训练结束后怎么参看parameters的内容？\r\n4、训练时一般都是设置好次数，一直执行完。后续的模型中可以设置cost的目标值吗？既不设置执行次数，只要cost能比我设定的误差值就停止，这样达到我的目的了。",
        "state": "closed",
        "user": "wwlaoxi",
        "closed_by": "shanyi15",
        "created_at": "2017-08-29T15:32:28+00:00",
        "updated_at": "2018-08-15T09:15:47+00:00",
        "closed_at": "2018-08-15T09:15:47+00:00",
        "comments_count": [
            "pkuyym",
            "wwlaoxi",
            "cdliheng",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 367,
        "title": "求解 新手入门---线性回归中的部分 疑惑",
        "body": "1、怎么样查看uci_housing的数据？\r\n2、打印相关信息\r\n  # event_handler to print training and testing info\r\n  def event_handler(event):\r\n    if isinstance(event, paddle.event.EndIteration):\r\n        if event.batch_id % 100 == 0:\r\n            print \"Pass %d, Batch %d, Cost %f\" % (\r\n                event.pass_id, event.batch_id, event.cost)\r\n\r\n    if isinstance(event, paddle.event.EndPass):\r\n        result = trainer.test(\r\n            reader=paddle.batch(\r\n                uci_housing.test(), batch_size=2),\r\n            feeding=feeding)\r\n        print \"Test %d, Cost %f\" % (event.pass_id, result.cost)\r\n\r\n打印出来的结果如下\r\nPass 0, Batch 0, Cost 5.598552\r\nPass 0, Batch 100, Cost 32.202789\r\nPass 0, Batch 200, Cost 87.088058\r\nTest 0, Cost 13.278372\r\nPass 1, Batch 0, Cost 78.872978\r\nPass 1, Batch 100, Cost 424.313202\r\nPass 1, Batch 200, Cost 12.719980\r\nTest 1, Cost 13.332345\r\n关于那个print \"Test %d, Cost %f\" % (event.pass_id, result.cost)\r\n代表result.cost 是一个batch的cost，还是说uci_housing.test()所有的cost啊？",
        "state": "closed",
        "user": "wwlaoxi",
        "closed_by": "shanyi15",
        "created_at": "2017-08-31T15:35:03+00:00",
        "updated_at": "2018-08-15T09:15:44+00:00",
        "closed_at": "2018-08-15T09:15:44+00:00",
        "comments_count": [
            "QiJune",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 368,
        "title": "浏览器无法打开http://localhost:8888/",
        "body": "按下面运行了这个docker image\r\n<img width=\"740\" alt=\"fb1bf36e5b24019d7d8aa3e7a5952970\" src=\"https://user-images.githubusercontent.com/7675778/29965399-00cb0af8-8f40-11e7-8f8a-038d013fa157.png\">\r\n但在浏览器中http://localhost:8888/一直打不开可能是啥原因？\r\n",
        "state": "closed",
        "user": "rambowding",
        "closed_by": "shanyi15",
        "created_at": "2017-09-01T10:05:25+00:00",
        "updated_at": "2018-08-15T09:15:40+00:00",
        "closed_at": "2018-08-15T09:15:40+00:00",
        "comments_count": [
            "typhoonzero",
            "wwlaoxi",
            "rambowding",
            "rambowding",
            "rambowding",
            "typhoonzero",
            "rambowding",
            "typhoonzero",
            "rambowding",
            "wwlaoxi",
            "yeyupiaoling",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 369,
        "title": "求解 识别数字中的 疑惑 ",
        "body": "1、卷积神经网络LeNet-5 中 convolutional_neural_network 函数中没有设置卷积时滤波器（卷积核）的滑动步长，该滑动步长默认是多少？如果设置的话需要设置哪个参数，怎么设置？\r\n2、训练方法（optimizer)的L2正规化是针对所有的参数都正规化吗？\r\n3、使用训练好的模型对手写体数字图片进行分类，报错，其中代码如下：\r\n  test_data = []\r\ncur_dir = os.path.dirname(os.path.realpath(__file__))\r\ntest_data.append((load_image(cur_dir + '/image/infer_3.png'),))\r\n错误如下：\r\nNameErrorTraceback (most recent call last)\r\n<ipython-input-19-108631bb6626> in <module>()\r\n     10 \r\n     11 test_data = []\r\n---> 12 cur_dir = os.path.dirname(os.path.realpath(__file__))\r\n     13 test_data.append((load_image(cur_dir + '/image/infer_3.png'),))\r\n     14 #test_data.append((load_image('/image/infer_3.png'),))\r\n\r\nNameError: name '__file__' is not defined",
        "state": "closed",
        "user": "wwlaoxi",
        "closed_by": "shanyi15",
        "created_at": "2017-09-01T16:16:22+00:00",
        "updated_at": "2018-08-15T09:18:12+00:00",
        "closed_at": "2018-08-15T09:18:12+00:00",
        "comments_count": [
            "yeyupiaoling",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 372,
        "title": "运行房价预测的代码报错: AttributeError: 'module' object has no attribute 'mse_cost'",
        "body": "`AttributeErrorTraceback (most recent call last)\r\n<ipython-input-1-fc4a5e973078> in <module>()\r\n     73 \r\n     74 if __name__ == '__main__':\r\n---> 75     main()\r\n\r\n<ipython-input-1-fc4a5e973078> in main()\r\n     11     y_predict = paddle.layer.fc(input=x, size=1, act=paddle.activation.Linear())\r\n     12     y = paddle.layer.data(name='y', type=paddle.data_type.dense_vector(1))\r\n---> 13     cost = paddle.layer.mse_cost(input=y_predict, label=y)\r\n     14 \r\n     15     # create parameters\r\n\r\nAttributeError: 'module' object has no attribute 'mse_cost'\r\n`\r\n\r\n请问这个怎么解决\r\n",
        "state": "closed",
        "user": "LNeway",
        "closed_by": "luotao1",
        "created_at": "2017-09-07T15:08:09+00:00",
        "updated_at": "2017-09-12T02:04:28+00:00",
        "closed_at": "2017-09-12T02:04:28+00:00",
        "comments_count": [
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 371,
        "title": "任务失败报找不到实际存在的文件",
        "body": "\r\nWed Sep  6 11:48:09 2017[1,5]<stderr>:F0906 11:48:09.745483 21400 PythonUtil.h:333] Check failed: (data) != nullptr Current PYTHONPATH: ['/home/normandy/maybach/286039/workspace', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/site-packages/setuptools-18.2-py2.7.egg', '/home/normandy/maybach/286039/workspace/paddle', '/home/normandy/maybach/286039/workspace', '/home/normandy/maybach/286039/workspace/thirdparty/thirdparty', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python27.zip', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/plat-linux2', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/lib-tk', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/lib-old', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/lib-dynload', '/home/normandy/maybach/286039/workspace/python27-gcc482/lib/python2.7/site-packages']\r\nWed Sep  6 11:48:09 2017[1,5]<stderr>:Python Error: <type 'exceptions.IOError'> : [Errno 2] No such file or directory: './test_data_dir/test/part-00151-B'\r\n\r\n但实际看test_data_dir/test目录下，存在part-00151-B的文件",
        "state": "closed",
        "user": "lyp2github",
        "closed_by": "luotao1",
        "created_at": "2017-09-06T06:20:26+00:00",
        "updated_at": "2017-09-06T06:34:20+00:00",
        "closed_at": "2017-09-06T06:34:20+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 376,
        "title": "update word2vector train.py",
        "body": "the train.py in word2vector is different with the content in ipynb.",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "jacquesqiao",
        "created_at": "2017-09-12T02:56:15+00:00",
        "updated_at": "2017-09-12T03:00:51+00:00",
        "closed_at": "2017-09-12T03:00:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 374,
        "title": "bug in semantic role labeling ",
        "body": "run in lastest docker image, it give the exception of \r\n```c++\r\nI0912 00:48:25.052264  1324 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1\r\nI0912 00:48:25.159572  1324 GradientMachine.cpp:85] Initing parameters..\r\nI0912 00:48:25.421331  1324 GradientMachine.cpp:92] Init parameters done.\r\nPass 0, Batch 0, Cost 145.003540, {'__sum_evaluator_0__': 1.0}\r\n\r\nTest with Pass 0, Batch 0, {'__sum_evaluator_0__': 0.9997308850288391}\r\nPass 0, Batch 100, Cost 66.704144, {'__sum_evaluator_0__': 0.9012739062309265}\r\nPass 0, Batch 200, Cost 41.758618, {'__sum_evaluator_0__': 0.4457831382751465}\r\nPass 0, Batch 300, Cost 67.263947, {'__sum_evaluator_0__': 0.7216494679450989}\r\nPass 0, Batch 400, Cost 88.009882, {'__sum_evaluator_0__': 0.6798679828643799}\r\nPass 0, Batch 500, Cost 46.322244, {'__sum_evaluator_0__': 0.548638105392456}\r\n\r\nTest with Pass 0, {'__sum_evaluator_0__': 0.5385039448738098}\r\nF0912 00:50:23.329255  1324 Matrix.cpp:3092] Check failed: index[i] < (int)tableSize (39052 vs. 3162)\r\n*** Check failure stack trace: ***\r\n    @     0x7f465f39593d  google::LogMessage::Fail()\r\n    @     0x7f465f397c88  google::LogMessage::SendToLog()\r\n    @     0x7f465f39542b  google::LogMessage::Flush()\r\n    @     0x7f465f398b5e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f465f16ef0d  paddle::CpuMatrix::selectRowsImp<>()\r\n    @     0x7f465f16c64e  paddle::CpuMatrix::selectRows()\r\n    @     0x7f465eeb22e9  paddle::TableProjection::forward()\r\n    @     0x7f465ef2ae6c  paddle::MixedLayer::forward()\r\n    @     0x7f465f0305f9  paddle::NeuralNetwork::forward()\r\n    @     0x7f465ee58216  _wrap_GradientMachine_forward\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\n    @           0x49e14a  Py_Main\r\n    @     0x7f468ac97830  __libc_start_main\r\n    @           0x49d9d9  _start\r\nAborted (core dumped)\r\n```",
        "state": "closed",
        "user": "dzhwinter",
        "closed_by": "reyoung",
        "created_at": "2017-09-12T00:54:36+00:00",
        "updated_at": "2017-09-15T23:27:51+00:00",
        "closed_at": "2017-09-15T23:27:51+00:00",
        "comments_count": [
            "lcy-seso"
        ],
        "labels": [
            "duplicate"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 377,
        "title": "最新的paddlepaddle/book:latest-gpu中代码不是最新",
        "body": "/book/01.fit_a_line/train.py  这个代码中用到了\r\n```python\r\ncost = paddle.layer.mse_cost(input=y_predict, label=y)\r\n```\r\nmse_cost已经本改名了，所以会失败，最新的book中的代码是对的，可能是没有打包到docker image中",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "jacquesqiao",
        "created_at": "2017-09-12T03:18:28+00:00",
        "updated_at": "2017-09-12T20:53:58+00:00",
        "closed_at": "2017-09-12T20:53:58+00:00",
        "comments_count": [
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 378,
        "title": "add demo code to save proto as file",
        "body": "",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "jacquesqiao",
        "created_at": "2017-09-12T20:49:38+00:00",
        "updated_at": "2017-09-12T21:20:24+00:00",
        "closed_at": "2017-09-12T21:20:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 389,
        "title": "picture for use docker.",
        "body": "![image](https://user-images.githubusercontent.com/3048612/30405546-52e953b6-98a1-11e7-9f4e-f0d95ed9172b.png)\r\n",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "jacquesqiao",
        "created_at": "2017-09-13T23:37:44+00:00",
        "updated_at": "2017-09-14T01:29:58+00:00",
        "closed_at": "2017-09-14T01:29:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 394,
        "title": "`drop_rate` is not available for LSTM",
        "body": "In the chaper6(understand_sentiment), we offer users two available models, one is CNN and the other one is LSTM. However, if we use LSTM model, some errors will occur:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 125, in <module>\r\n    cost = stacked_lstm_net(dict_dim, class_dim=class_dim, stacked_num=3)\r\n  File \"train.py\", line 69, in stacked_lstm_net\r\n    input=fc1, act=relu, bias_attr=bias_attr, layer_attr=layer_attr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py\", line 52, in wrapped\r\n    out = f(*args, **xargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py\", line 396, in wrapper\r\n    val.check(method.__name__)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/attrs.py\", line 276, in check\r\n    (layer_name, key))\r\nNotImplementedError: Layer lstmemory does not support drop_rate\r\n```\r\n\r\nThe reason is LSTM doesn't support `drop_rate`. So we shall remove `drop_rate` from LSTM's layer_attr.",
        "state": "closed",
        "user": "JiayiFeng",
        "closed_by": "JiayiFeng",
        "created_at": "2017-09-14T01:26:32+00:00",
        "updated_at": "2017-09-14T21:14:48+00:00",
        "closed_at": "2017-09-14T21:14:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 401,
        "title": "通过 pip 安装了 paddlepaddle 为0.10.0版本，book 中没有对应版本，经常因为版本不兼容无法运行",
        "body": "是否能够在 paddle release 的时候，book 同步 release 一下？",
        "state": "closed",
        "user": "szxw",
        "closed_by": "shanyi15",
        "created_at": "2017-09-15T04:38:27+00:00",
        "updated_at": "2018-08-15T09:18:09+00:00",
        "closed_at": "2018-08-15T09:18:09+00:00",
        "comments_count": [
            "jacquesqiao",
            "typhoonzero",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 419,
        "title": "word2vec demo code raise IndexError",
        "body": "When I run the example script in the documentation for `01.word2vec`, it gives me an `IndexError`\r\n\r\n```python\r\nfrom scipy import spatial\r\nimport numpy\r\n\r\ndef load_dict_and_embedding():\r\n    word_dict = dict()\r\n    with open(\"word_dict\", \"r\") as f:\r\n        for line in f:\r\n            key, value = line.strip().split(\" \")\r\n            word_dict[key] = value\r\n\r\n    embeddings = numpy.loadtxt(\"embedding_table\", delimiter=\",\")\r\n    return word_dict, embeddings\r\n\r\n# load word dict and embedding table\r\nword_dict, embedding_table = load_dict_and_embedding()\r\n\r\nprint(spatial.distance.cosine(embedding_table[word_dict['car']], embedding_table[word_dict['world']]))\r\nprint(spatial.distance.cosine(embedding_table[word_dict['say']], embedding_table[word_dict['talking']]))\r\n```",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "luotao1",
        "created_at": "2017-09-20T20:39:26+00:00",
        "updated_at": "2017-09-21T01:30:33+00:00",
        "closed_at": "2017-09-21T01:30:33+00:00",
        "comments_count": [
            "jacquesqiao"
        ],
        "labels": [
            "HackMIT"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 420,
        "title": "rnn text generation exception",
        "body": "from @Tony Fu\r\n\r\n```\r\n[INFO 2017-09-17 14:19:12,094 beam_search.py:38] dictionay len = 51200\r\nF0917 14:20:00.483598    18 Allocator.h:54] Check failed: posix_memalign(&ptr, 4096ul, size) == 0 (12 vs. 0) \r\n*** Check failure stack trace: ***\r\n    @     0x7face3d9a11d  google::LogMessage::Fail()\r\n    @     0x7face3d9c468  google::LogMessage::SendToLog()\r\n    @     0x7face3d99c0b  google::LogMessage::Flush()\r\n    @     0x7face3d9d33e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7face3b995e1  paddle::CpuAllocator::alloc()\r\n    @     0x7face3b85f18  paddle::PoolAllocator::alloc()\r\n    @     0x7face3b859c5  paddle::CpuMemoryHandle::CpuMemoryHandle()\r\n    @     0x7face3b5a7f3  paddle::CpuMatrix::CpuMatrix()\r\n    @     0x7face3b5a97e  paddle::Matrix::create()\r\n    @     0x7face3b6d798  paddle::Matrix::resizeOrCreate()\r\n    @     0x7face3956187  paddle::LstmLayer::forward()\r\n    @     0x7face3a35279  paddle::NeuralNetwork::forward()\r\n    @     0x7face3853b26  _wrap_GradientMachine_forward\r\n    @           0x4c468a  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4dddca  (unknown)\r\n    @           0x4c4c6f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca099  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4ca8d1  PyEval_EvalFrameEx\r\n    @           0x4c9d8f  PyEval_EvalFrameEx\r\n    @           0x4c2765  PyEval_EvalCodeEx\r\n    @           0x4c2509  PyEval_EvalCode\r\n    @           0x4f1def  (unknown)\r\n    @           0x4ec652  PyRun_FileExFlags\r\n    @           0x4eae31  PyRun_SimpleFileExFlags\r\nAborte\r\n```",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "shanyi15",
        "created_at": "2017-09-20T20:41:16+00:00",
        "updated_at": "2018-08-15T09:18:05+00:00",
        "closed_at": "2018-08-15T09:18:05+00:00",
        "comments_count": [
            "jacquesqiao",
            "shanyi15"
        ],
        "labels": [
            "HackMIT"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 396,
        "title": "Make CI test example programs",
        "body": "According to the [configuration file](https://github.com/PaddlePaddle/book/blob/develop/.travis.yml), currently, the Travis CI does only precommit check:\r\n\r\n```json\r\nscript:\r\n  -  PATH=/tmp/go/bin:$PATH .travis/precommit.sh\r\n```\r\n\r\nwhere the [precommit.sh](https://github.com/PaddlePaddle/book/blob/develop/.travis/precommit.sh) file runs `pre-commit run -a`, which, according to the [pre-commit configuration file](https://github.com/PaddlePaddle/book/blob/develop/.pre-commit-config.yaml), does only format checking.\r\n\r\nCan we make it call https://github.com/PaddlePaddle/book/blob/develop/.tools/convert-markdown-into-ipynb-and-test.sh to extract Python example code out from each chapter -- those directories with a numeric prefix, e.g., `01.fit_a_line/README.md`, and run them?\r\n",
        "state": "closed",
        "user": "wangkuiyi",
        "closed_by": "putcn",
        "created_at": "2017-09-14T20:51:31+00:00",
        "updated_at": "2017-09-15T17:47:56+00:00",
        "closed_at": "2017-09-15T17:47:56+00:00",
        "comments_count": [
            "putcn",
            "putcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 421,
        "title": "where is the dataset",
        "body": "from @Changming Xu\r\n```\r\nHi, we are trying to retrain the sentiment analysis code with our own dataset, is there some way to see the format of the dataset currently being passed in (i.e. paddle.dataset.imdb)\r\n```",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "shanyi15",
        "created_at": "2017-09-20T20:43:03+00:00",
        "updated_at": "2018-08-15T09:18:01+00:00",
        "closed_at": "2018-08-15T09:18:01+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "HackMIT"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 422,
        "title": "need pre-trained ImageNet model",
        "body": "Is there any pre-trained ImageNet model? I found trained CIFAR-10 model on Github but I didn't see anything like VGG-16",
        "state": "closed",
        "user": "jacquesqiao",
        "closed_by": "shanyi15",
        "created_at": "2017-09-20T20:44:44+00:00",
        "updated_at": "2018-08-15T09:17:58+00:00",
        "closed_at": "2018-08-15T09:17:58+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": [
            "HackMIT"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 424,
        "title": "pip install paddlepaddle失败",
        "body": "运行pip install paddlepaddle提示：\r\nCould not find a version that satisfies the requirement paddlepaddle (from versions: )\r\nNo matching distribution found for paddlepaddle\r\n\r\n运行pip install --upgrade pip后再install，依然出现上述问题",
        "state": "closed",
        "user": "333caowei",
        "closed_by": "333caowei",
        "created_at": "2017-09-21T04:18:56+00:00",
        "updated_at": "2017-09-21T11:03:29+00:00",
        "closed_at": "2017-09-21T11:03:29+00:00",
        "comments_count": [
            "typhoonzero",
            "333caowei",
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 429,
        "title": "AttributeError: 'module' object has no attribute 'square_error_cost'",
        "body": "root@b402efa66f54:/home/work# python train.py\r\nI0928 09:21:58.518064    86 Util.cpp:166] commandline:  --use_gpu=False \r\nTraceback (most recent call last):\r\n  File \"train.py\", line 137, in <module>\r\n    main()\r\n  File \"train.py\", line 80, in main\r\n    cost = paddle.layer.square_error_cost(\r\nAttributeError: 'module' object has no attribute 'square_error_cost'\r\nroot@b402efa66f54:/home/work# \r\n\r\n>How to solve this question?",
        "state": "closed",
        "user": "shincfk",
        "closed_by": "shincfk",
        "created_at": "2017-09-28T09:26:17+00:00",
        "updated_at": "2017-09-28T11:22:33+00:00",
        "closed_at": "2017-09-28T11:22:33+00:00",
        "comments_count": [
            "typhoonzero",
            "shincfk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 431,
        "title": "The code in book/04.word2vec/train.py is inconsistent with the doc.",
        "body": "The code in the doc is:\r\n\r\n```python\r\ndef wordemb(inlayer):\r\n    wordemb = paddle.layer.table_projection(\r\n        input=inlayer,\r\n        size=embsize,\r\n        param_attr=paddle.attr.Param(\r\n            name=\"_proj\",\r\n            initial_std=0.001,\r\n            learning_rate=1,\r\n            l2_rate=0,\r\n            sparse_update=True))\r\n    return wordemb\r\n```\r\n\r\nBut the code in `train.py` is:\r\n\r\nhttps://github.com/PaddlePaddle/book/blob/7caad04c78d142ccc9fbe56c47d588b5d562cf52/04.word2vec/train.py#L14-L20",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "shanyi15",
        "created_at": "2017-10-13T05:56:13+00:00",
        "updated_at": "2018-08-15T09:17:53+00:00",
        "closed_at": "2018-08-15T09:17:53+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 433,
        "title": "01.fit_a_line with error AttributeError: 'module' object has no attribute 'square_error_cost'",
        "body": "",
        "state": "closed",
        "user": "WhiteHorseLongGod",
        "closed_by": "luotao1",
        "created_at": "2017-10-20T09:08:11+00:00",
        "updated_at": "2017-10-20T09:24:31+00:00",
        "closed_at": "2017-10-20T09:24:31+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 434,
        "title": "初始化paddle时报错",
        "body": "在执行这一行代码是就会报错：`paddle.init(use_gpu=False, trainer_count=1)`\r\n报错信息是：The kernel appears to have died. It will restart automatically.\r\n也不知道是哪里出错，在哪里可以看详细的报错信息？谢谢",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2017-10-21T05:59:03+00:00",
        "updated_at": "2017-11-09T10:09:57+00:00",
        "closed_at": "2017-11-09T10:09:57+00:00",
        "comments_count": [
            "llxxxll",
            "yeyupiaoling",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 435,
        "title": "01.fit_a_line中的UCI Housing Data Set链接已失效",
        "body": "01.fit_a_line中的UCI Housing Data Set链接已失效，无法跟着教程入门",
        "state": "closed",
        "user": "sanwushuosi",
        "closed_by": "shanyi15",
        "created_at": "2017-10-23T08:37:52+00:00",
        "updated_at": "2018-08-15T09:17:50+00:00",
        "closed_at": "2018-08-15T09:17:50+00:00",
        "comments_count": [
            "typhoonzero",
            "yeyupiaoling",
            "linbaicome",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 436,
        "title": "“识别数字”如何引用其他训练数据",
        "body": "我想测试使用我的自己的训练数据，应该怎么做呢？[代码连接](https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/README.cn.md)",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2017-10-24T13:28:53+00:00",
        "updated_at": "2017-12-14T12:20:00+00:00",
        "closed_at": "2017-11-19T03:51:27+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 437,
        "title": "在“book”中的“数字识别”如何使用已训练的模型",
        "body": "在[数字识别](https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/README.cn.md)这章中，每次都有从零开始训练，太慢了，能不能使用之前已经训练过的模型",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "llxxxll",
        "created_at": "2017-10-24T23:50:13+00:00",
        "updated_at": "2017-12-14T12:21:30+00:00",
        "closed_at": "2017-10-27T04:13:38+00:00",
        "comments_count": [
            "llxxxll",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 438,
        "title": "paddle:0.10.0-dev镜像中跑01.fit_a_line中train.py提示ImportError: No module named paddle.v2",
        "body": "步骤是在mac版本docker下载了paddle:0.10.0-dev镜像\r\n然后执行demo中的python脚本：\r\n\r\n执行命令如下：\r\ndocker run -it --rm -v /paddle:/workspace docker.paddlepaddle.org/paddle:0.10.0-dev   python /workspace/train.py\r\n报错如下：\r\nTraceback (most recent call last):\r\n  File \"/workspace/train.py\", line 2, in <module>\r\n    import paddle.v2 as paddle\r\nImportError: No module named paddle.v2\r\n\r\n",
        "state": "closed",
        "user": "hoollywood",
        "closed_by": "hoollywood",
        "created_at": "2017-10-30T06:39:02+00:00",
        "updated_at": "2017-10-30T13:19:31+00:00",
        "closed_at": "2017-10-30T13:19:31+00:00",
        "comments_count": [
            "Xreki"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 445,
        "title": "语义角色标注示列直接运行报错",
        "body": "直接运行提供的docker镜像中语义角色标注的示列程序，运行报错的地方：\r\nlabs = paddle.infer(\r\n    output_layer=predict, parameters=parameters, input=test_data, field='id')\r\n\r\n日志显示：\r\nF1114 10:25:15.241650   798 Matrix.cpp:3065] Check failed: index[i] < (int)tableSize (39052 vs. 3162) \r\n*** Check failure stack trace: ***\r\n    @     0x7f0e3f2bc95d  google::LogMessage::Fail()\r\n    @     0x7f0e3f2beca8  google::LogMessage::SendToLog()\r\n    @     0x7f0e3f2bc46b  google::LogMessage::Flush()\r\n    @     0x7f0e3f2bfb7e  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f0e3f1df1dd  paddle::CpuMatrix::selectRowsImp<>()\r\n    @     0x7f0e3f1dc6de  paddle::CpuMatrix::selectRows()\r\n    @     0x7f0e3ee71ad9  paddle::TableProjection::forward()\r\n    @     0x7f0e3eeea0cc  paddle::MixedLayer::forward()\r\n    @     0x7f0e3f00c769  paddle::NeuralNetwork::forward()\r\n    @     0x7f0e3f01998c  paddle::TrainerThread::forward()\r\n    @     0x7f0e3f01d688  paddle::TrainerThread::computeThread()\r\n    @     0x7f0e74337c80  (unknown)\r\n    @     0x7f0e783ff6ba  start_thread\r\n    @     0x7f0e781353dd  clone\r\n    @              (nil)  (unknown)\r\n",
        "state": "closed",
        "user": "jaysharp",
        "closed_by": "jaysharp",
        "created_at": "2017-11-14T10:32:18+00:00",
        "updated_at": "2017-11-17T01:55:07+00:00",
        "closed_at": "2017-11-17T01:55:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 441,
        "title": "请求为demo添加数据维度说明",
        "body": "paddle的官方文档写的不太详细，比如concat是怎么拼接的，按照数据的哪个维度。没有数据维度层面的解释，paddle如同黑盒一般。\r\n如果有详细的数据维度说明，使用者可以很方便、灵活的根据demo构建自己的网络，会对paddle的计算流程和模型设计有清晰的认识，以便编写合乎paddle规范的代码。\r\n\r\n辛苦paddle同学补充demo的数据维度说明，\r\n比如https://github.com/PaddlePaddle/book/blob/develop/07.label_semantic_roles/train.py\r\n中的feature_out数据维度是什么（[batch, sen_len, label_cnt]?）",
        "state": "closed",
        "user": "zhuantouer",
        "closed_by": "shanyi15",
        "created_at": "2017-11-07T13:39:30+00:00",
        "updated_at": "2018-08-15T09:17:45+00:00",
        "closed_at": "2018-08-15T09:17:45+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 442,
        "title": "Display issue with 『03.image_classification/README.md』",
        "body": "In this part http://staging.paddlepaddle.org/docs/develop/book/03.image_classification/index.html#permalink-6-model-structure\r\n\r\nThere is a problem displaying the python function code starts with `def vgg_bn_drop(input):`, I checked the `README.md` but it seems there be no problem, don't know the reason.",
        "state": "closed",
        "user": "zealoct",
        "closed_by": "zealoct",
        "created_at": "2017-11-08T02:18:42+00:00",
        "updated_at": "2017-11-08T03:17:55+00:00",
        "closed_at": "2017-11-08T03:16:07+00:00",
        "comments_count": [
            "zealoct"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 446,
        "title": "crf_layer cost过大，出现浮点异常",
        "body": "这个角色标注的例子https://github.com/PaddlePaddle/book/blob/develop/07.label_semantic_roles/train.py\r\n用的batch_size=10，如果把batch_size设置较大的话（256，512），就会出现浮点异常。设置coeff参数为0.3也会出现同样的问题。\r\n想请教下 @pengli09\r\n这个有什么优化方法么，batch_size设置过小的话，训练太慢了。",
        "state": "closed",
        "user": "zhuantouer",
        "closed_by": "shanyi15",
        "created_at": "2017-11-15T02:41:36+00:00",
        "updated_at": "2018-08-15T09:09:11+00:00",
        "closed_at": "2018-08-15T09:09:11+00:00",
        "comments_count": [
            "zhuantouer",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 447,
        "title": "机器翻译的demo的一些问题",
        "body": "有以下几个问题：\r\n+ \"定义解码阶段每一个时间步的RNN行为，即根据当前时刻的源语言上下文向量...\"这段话里最后一点的\"最后，使用softmax归一化计算单词的概率，将out结果返回，即实现公式\"这里的公式，i是不是应该改成i+1呢\r\n+ 使用的reader是wmt14.py中提供的reader，该reader最终的返回如下：\r\n```python\r\n            for name in names:\r\n                for line in f.extractfile(name):\r\n                    line_split = line.strip().split('\\t')\r\n                    if len(line_split) != 2:\r\n                        continue\r\n                    src_seq = line_split[0]  # one source sequence\r\n                    src_words = src_seq.split()\r\n                    src_ids = [\r\n                        src_dict.get(w, UNK_IDX)\r\n                        for w in [START] + src_words + [END]\r\n                    ]\r\n\r\n                    trg_seq = line_split[1]  # one target sequence\r\n                    trg_words = trg_seq.split()\r\n                    trg_ids = [trg_dict.get(w, UNK_IDX) for w in trg_words]\r\n\r\n                    # remove sequence whose length > 80 in training mode\r\n                    if len(src_ids) > 80 or len(trg_ids) > 80:\r\n                        continue\r\n                    trg_ids_next = trg_ids + [trg_dict[END]]\r\n                    trg_ids = [trg_dict[START]] + trg_ids\r\n\r\n                    yield src_ids, trg_ids, trg_ids_next\r\n```\r\n而在模型实际使用时，直接指定的name，但好像没看到reader常见的feeding参数，好奇这些name是在哪里和yield的下标对应上的呢\r\n```python\r\nsrc_word_id = paddle.layer.data(\r\n     name='source_language_word',\r\n     type=paddle.data_type.integer_value_sequence(source_dict_dim))\r\n\r\ntrg_embedding = paddle.layer.embedding(\r\n        input=paddle.layer.data(\r\n            name='target_language_word',\r\n            type=paddle.data_type.integer_value_sequence(target_dict_dim)),\r\n        size=word_vector_dim,\r\n        param_attr=paddle.attr.ParamAttr(name='_target_language_embedding'))\r\n\r\nlbl = paddle.layer.data(\r\n        name='target_language_next_word',\r\n        type=paddle.data_type.integer_value_sequence(target_dict_dim))\r\n```",
        "state": "closed",
        "user": "daiwk",
        "closed_by": "shanyi15",
        "created_at": "2017-11-19T16:28:20+00:00",
        "updated_at": "2018-08-15T09:09:08+00:00",
        "closed_at": "2018-08-15T09:09:08+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 448,
        "title": "翻译任务报错got an unexpected keyword argument 'error_clipping_threshold'",
        "body": "我是百度员工，向内网集群提交一个机器翻译的任务，基本上都参照demo写的。但是运行时报错\r\nTypeError: __init__() got an unexpected keyword argument 'error_clipping_threshold'",
        "state": "closed",
        "user": "wellesliang",
        "closed_by": "shanyi15",
        "created_at": "2017-11-21T10:34:39+00:00",
        "updated_at": "2018-08-15T09:09:04+00:00",
        "closed_at": "2018-08-15T09:09:04+00:00",
        "comments_count": [
            "wellesliang",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 449,
        "title": "太难用了，文档说明和程序实现都不一致",
        "body": "![image](https://user-images.githubusercontent.com/6964441/33072312-edfb6b30-cef9-11e7-944d-017567fd8f70.png)\r\n文档中说明可以不用传入字典文件和标签字典，但实现却又是另一回事，这个也算了，字典文件是怎样格式，标签字典又是怎样的，也没有说明，能不能走心一点，不是每个人都是大神，我们只是一个想进门的小白，请paddlepaddle不要再标榜简单易用了，好么？\r\n![image](https://user-images.githubusercontent.com/6964441/33072357-22dcf468-cefa-11e7-9812-4e5935953222.png)\r\n",
        "state": "closed",
        "user": "liuchyi",
        "closed_by": "shanyi15",
        "created_at": "2017-11-21T12:27:26+00:00",
        "updated_at": "2018-08-15T09:08:57+00:00",
        "closed_at": "2018-08-15T09:08:57+00:00",
        "comments_count": [
            "liuchyi",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 450,
        "title": "在第三章的图片分类中，输出的数字代表的是哪个类别啊？",
        "body": "我在[cifar-10d的官方](http://www.cs.toronto.edu/~kriz/cifar.html)中看到的图片，是不是那个顺序？好像不太对",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2017-11-22T03:27:48+00:00",
        "updated_at": "2017-12-14T12:28:07+00:00",
        "closed_at": "2017-11-26T14:45:38+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 451,
        "title": "在第三章的图片分类中，输出的数字代表的是哪个类别啊？",
        "body": "我在[cifar-10d](http://www.cs.toronto.edu/~kriz/cifar.html)的官方中看到的图片，是不是那个顺序？好像不太对",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2017-11-26T14:45:32+00:00",
        "updated_at": "2017-12-14T12:28:56+00:00",
        "closed_at": "2017-11-26T15:13:38+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 454,
        "title": "第6课understand sentiment的doc示例代码目录结构和源码目录结构不一致",
        "body": "[github源码](https://github.com/PaddlePaddle/book/tree/develop/06.understand_sentiment)的目录结构如：\r\n![image](https://user-images.githubusercontent.com/3206718/33310680-5ea3df1c-d45d-11e7-87a9-a208e0a85897.png)\r\n\r\n\r\n\r\n[doc](http://www.paddlepaddle.org/docs/develop/models/text_classification/README.html)中的目录结构如：\r\n![image](https://user-images.githubusercontent.com/3206718/33310764-a9cdf09a-d45d-11e7-8228-6a27185b21c5.png)\r\n",
        "state": "closed",
        "user": "OleNet",
        "closed_by": "shanyi15",
        "created_at": "2017-11-28T08:59:02+00:00",
        "updated_at": "2018-08-15T09:08:50+00:00",
        "closed_at": "2018-08-15T09:08:50+00:00",
        "comments_count": [
            "OleNet",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 452,
        "title": "角色标注例子没有任何标注结果",
        "body": "直接运行docker中的例子，\r\n1.直接运行没有任何标注结果\r\n2.增加训练轮次达到100次，仍然没有任何标注结果\r\n3.改变学习率增加训练轮次，偶尔出现kernel崩溃。\r\n",
        "state": "closed",
        "user": "jaysharp",
        "closed_by": "shanyi15",
        "created_at": "2017-11-27T05:51:17+00:00",
        "updated_at": "2018-08-15T09:08:54+00:00",
        "closed_at": "2018-08-15T09:08:54+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 456,
        "title": "paddlepaddle-gpu可以在Windows下 pip安装吗？",
        "body": "paddlepaddle-gpu可以在Windows下 pip安装吗？\r\n可以这样用吗？\r\nUbuntu下好难搞啊，NVIDIA驱动一直没搞定",
        "state": "closed",
        "user": "breaknormal1",
        "closed_by": "shanyi15",
        "created_at": "2017-12-05T02:25:37+00:00",
        "updated_at": "2018-08-15T09:08:47+00:00",
        "closed_at": "2018-08-15T09:08:47+00:00",
        "comments_count": [
            "NHZlX",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 457,
        "title": "请问为什么Jupyter Notebook无法启动？",
        "body": "在docker的虚拟机default中输入了下列两行代码：\r\n`docker pull paddlepaddle/paddle`\r\n`docker run -p 8888:8888 paddlepaddle/book`\r\n![paddle](https://user-images.githubusercontent.com/33109831/33592704-3e5d020a-d9c7-11e7-888d-bf4e94f3e4cc.png)\r\n这样是说明已经Jupyter Notebokk已经启动了吗？\r\n但是在360、火狐、IE浏览器中http://localhost:8888/ 、 http://0.0.0.0:8888/ 都打不开，请问这是为什么呢？\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Vcdan",
        "closed_by": "Vcdan",
        "created_at": "2017-12-05T06:24:17+00:00",
        "updated_at": "2017-12-07T04:02:00+00:00",
        "closed_at": "2017-12-07T04:02:00+00:00",
        "comments_count": [
            "Vcdan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 458,
        "title": "寻求paddlepaddle自动桃子分拣器图片、代码",
        "body": "看到有报道基于paddlepaddle的桃子分拣器\r\nhttp://prnews.techweb.com.cn/qiyenews/archives/37698.html\r\n“这 4 位学生已将所有代码和材料清单，上传至 GitHub 进行开源和分享，请全世界关注农业和关注深度学习的人共同完善”\r\npaddle的同志们，你们知道这些code和材料在GitHub分享网址吗？\r\n谢谢\r\n\r\n",
        "state": "closed",
        "user": "breaknormal1",
        "closed_by": "breaknormal1",
        "created_at": "2017-12-05T08:29:38+00:00",
        "updated_at": "2017-12-06T06:45:29+00:00",
        "closed_at": "2017-12-06T06:45:29+00:00",
        "comments_count": [
            "luotao1",
            "breaknormal1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 461,
        "title": "02.recognize_digits/client/client.py run error",
        "body": "```bash\r\npython client.py \r\nTraceback (most recent call last):\r\n  File \"client.py\", line 19, in <module>\r\n    r = requests.post(\"http://0.0.0.0:8000\", json={'img': data})\r\n  File \"/Library/Python/2.7/site-packages/requests/api.py\", line 111, in post\r\n    return request('post', url, data=data, json=json, **kwargs)\r\n  File \"/Library/Python/2.7/site-packages/requests/api.py\", line 57, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"/Library/Python/2.7/site-packages/requests/sessions.py\", line 475, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/Library/Python/2.7/site-packages/requests/sessions.py\", line 585, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/Library/Python/2.7/site-packages/requests/adapters.py\", line 442, in send\r\n    raise ConnectionError(e, request=request)\r\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='0.0.0.0', port=8000): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x108ae8c10>: Failed to establish a new connection: [Errno 61] Connection refused',))\r\n```\r\n\r\nMaybe missing http services? or tips.",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "llxxxll",
        "created_at": "2017-12-11T10:47:47+00:00",
        "updated_at": "2017-12-11T11:03:25+00:00",
        "closed_at": "2017-12-11T11:03:25+00:00",
        "comments_count": [
            "jacquesqiao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 460,
        "title": "请问The kernel appears to have died. It will restart automatically.是什么原因？",
        "body": "在Jupyter Notebook中运行fit_a_line里的代码时，显示：“The kernel appears to have died. It will restart automatically.”\r\nGit Bash中如下：\r\n![image](https://user-images.githubusercontent.com/33109831/33805014-1c6aec10-ddec-11e7-9240-91105f7bf361.png)\r\n请问这是什么原因？\r\n",
        "state": "closed",
        "user": "Vcdan",
        "closed_by": "shanyi15",
        "created_at": "2017-12-10T12:56:53+00:00",
        "updated_at": "2018-08-15T09:08:43+00:00",
        "closed_at": "2018-08-15T09:08:43+00:00",
        "comments_count": [
            "tigerneil",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 463,
        "title": "book/mnist-client, 1 step need tips for installing Flask",
        "body": "book/mnist-client, 1 step need tips for installing Flask\r\n`pip install flask`",
        "state": "closed",
        "user": "llxxxll",
        "closed_by": "shanyi15",
        "created_at": "2017-12-11T13:46:41+00:00",
        "updated_at": "2018-08-15T09:08:39+00:00",
        "closed_at": "2018-08-15T09:08:39+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 464,
        "title": "several question about book migration",
        "body": "- should the python syntax be exactly the same with V2 API?\r\n  - currently, we have some new concept such as `executor`, `default_program`, `fetch_list`\r\n  - some new concepts bring flexibility(such as `while op`) and are hard to hide as the underlying of V2 API.\r\n\r\n- when the book based on Fluid is completed, should we discard the old V2 content?\r\n  - during migration, new content will be placed to a `chapter_xxx_fluid` directory\r\n  - the new Fluid content can co-exist with the V2 content.\r\n  - if we want to drop V2 content, just replace them with `chapter_xxx_fluid`.\r\n",
        "state": "closed",
        "user": "Superjomn",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T03:52:02+00:00",
        "updated_at": "2018-08-15T09:08:36+00:00",
        "closed_at": "2018-08-15T09:08:36+00:00",
        "comments_count": [
            "kavyasrinet",
            "wanghaoshuang",
            "dzhwinter",
            "shanyi15"
        ],
        "labels": [
            "migration"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 465,
        "title": "chapter 1 Linear Regression",
        "body": "port Linear Regression to fluid API",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T04:58:37+00:00",
        "updated_at": "2018-08-15T09:08:31+00:00",
        "closed_at": "2018-08-15T09:08:31+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 466,
        "title": "port chapter 2 Recognize Digits to fluid API",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T05:45:54+00:00",
        "updated_at": "2018-08-15T09:08:28+00:00",
        "closed_at": "2018-08-15T09:08:28+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 467,
        "title": "Chapter 3 Image Classification",
        "body": "",
        "state": "closed",
        "user": "Superjomn",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T05:49:27+00:00",
        "updated_at": "2018-08-15T09:08:24+00:00",
        "closed_at": "2018-08-15T09:08:24+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 471,
        "title": "PaddlePaddle文档梳理工作",
        "body": "## 背景\r\n\r\n因Paddle官网文档体系的完备性和逻辑性有所欠缺，给开发者的阅读带来了困难。\r\n\r\n为了优化产品、提升用户体验，我们希望参考Tensor Flow，改进PaddlePaddle的文档架构。\r\n\r\n因此，我们整理了Tensor Flow官网的文档架构，这部分内容请见[TensorFlow framework.xlsx](https://github.com/PaddlePaddle/book/files/1562109/TensorFlow.framework.xlsx)。\r\n\r\n在表格中， 我们将PaddlePaddle和TensorFlow有相似内容的模块列出，并附URL。\r\n\r\n目前，已经完成了初步比对，但仍有一些不完善的地方，辛苦RD们协助我们继续完成比对工作。\r\n\r\n    \r\n\r\n## 具体的方法\r\n\r\n `1.` 标注PaddlePaddle是否有必要建设该内容，如有，打√；\r\n\r\n `2.` PaddlePaddle是否已经有内容，如有，附上PaddlePaddle的URL，没有内容则为空；\r\n\r\n `3.` 后续行动，如果有可以写上需要做哪些工作（比如，需要优化文档、需要新增文档、需要建设模型），如没有则不写。\r\n\r\n`期望完成时间：北京时间 2017年12月15日，19:00前`\r\n 辛苦  @lcy-seso 安排填写以上三个维度的内容，谢谢！\r\n",
        "state": "closed",
        "user": "angelashane",
        "closed_by": "angelashane",
        "created_at": "2017-12-15T09:50:37+00:00",
        "updated_at": "2017-12-15T10:31:04+00:00",
        "closed_at": "2017-12-15T10:31:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 472,
        "title": "自己写的机器翻译的程序报错",
        "body": "为了能够查看程序经过每一层后的输出状况，我自己修改了下代码：\r\n抱歉，我的描述不是很全面。实际上，我是将机器翻译的代码根据我的需要更改了，成这样，然后进行上\r\n\r\n\r\n",
        "state": "closed",
        "user": "yyhlvdl",
        "closed_by": "yyhlvdl",
        "created_at": "2017-12-19T04:03:05+00:00",
        "updated_at": "2017-12-19T09:58:07+00:00",
        "closed_at": "2017-12-19T09:58:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 468,
        "title": "Refusing to serve hidden file, via 404 Error",
        "body": "Jupyter Notebook会报这个错误导致html文件在浏览器上无法被正确访问：\r\n\r\n`[I 16:57:47.917 NotebookApp] Refusing to serve hidden file, via 404 Error\r\n[W 16:57:47.919 NotebookApp] 404 GET /files/.tools/theme/marked.js (172.18.21.156) 2.46ms referer=None\r\n[I 16:57:47.920 NotebookApp] Refusing to serve hidden file, via 404 Error\r\n[W 16:57:47.922 NotebookApp] 404 GET /files/.tools/theme/github-markdown.css (172.18.21.156) 2.17ms referer=None\r\n[I 16:57:48.015 NotebookApp] Refusing to serve hidden file, via 404 Error\r\n[W 16:57:48.016 NotebookApp] 404 GET /files/.tools/theme/github-markdown.css (172.18.21.156) 2.45ms referer=None`\r\n\r\njupyter notebook --version：5.2.2",
        "state": "closed",
        "user": "zengjialuo",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T09:16:45+00:00",
        "updated_at": "2018-08-15T09:08:20+00:00",
        "closed_at": "2018-08-15T09:08:20+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 469,
        "title": "Port Chapter 7 Semantic Role Labeling to fluid API",
        "body": "",
        "state": "closed",
        "user": "lcy-seso",
        "closed_by": "shanyi15",
        "created_at": "2017-12-12T14:08:00+00:00",
        "updated_at": "2018-08-15T09:08:17+00:00",
        "closed_at": "2018-08-15T09:08:17+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 470,
        "title": "个性化推荐demo报错：'module' object has no attribute 'square_error_cost'",
        "body": " cost = paddle.layer.square_error_cost(\r\nAttributeError: 'module' object has no attribute 'square_error_cost'",
        "state": "closed",
        "user": "wzh420",
        "closed_by": "luotao1",
        "created_at": "2017-12-14T03:55:44+00:00",
        "updated_at": "2017-12-14T05:18:34+00:00",
        "closed_at": "2017-12-14T05:18:34+00:00",
        "comments_count": [
            "will-am",
            "wzh420"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 473,
        "title": "Get https://docker.paddlepaddle.org/v2/: net/http: TLS handshake timeout.",
        "body": "docker run -d -p 8888:8888 docker.paddlepaddle.org/book\r\nUnable to find image 'docker.paddlepaddle.org/book:latest' locally\r\ndocker: Error response from daemon: Get https://docker.paddlepaddle.org/v2/: net/http: TLS handshake timeout.",
        "state": "closed",
        "user": "lishoujun",
        "closed_by": "shanyi15",
        "created_at": "2017-12-20T03:21:00+00:00",
        "updated_at": "2018-08-15T09:08:14+00:00",
        "closed_at": "2018-08-15T09:08:14+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 474,
        "title": "image_classification was killed when I run the train.py in docker",
        "body": "Version: Last\r\nPlatform: macOS High Sierra 10.13.2, Docker 17.09.1-ce, paddle 0.11.0\r\nLog:\r\n![paddlelog](https://user-images.githubusercontent.com/16774273/34339346-ea6fab06-e9ad-11e7-9eb6-edc844150215.jpg)\r\n\r\nDebug:\r\nIt was killed when the trainer began training.The event_handler received BeginPass status and BeginInteration status.But there were no EndIteration status or EndPass status.\r\n",
        "state": "closed",
        "user": "KawhiZhuuu",
        "closed_by": "shanyi15",
        "created_at": "2017-12-25T12:01:33+00:00",
        "updated_at": "2018-08-15T09:08:10+00:00",
        "closed_at": "2018-08-15T09:08:10+00:00",
        "comments_count": [
            "will-am",
            "KawhiZhuuu",
            "will-am",
            "KawhiZhuuu",
            "will-am",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 476,
        "title": "paddlepaddle 使用mpi训练batch模型报错Connection timed out",
        "body": " Sat Dec 30 07:39:58 2017[1,158]<stderr>:F1230 07:39:58.004369 48789 SocketChannel.cpp:56] Check failed: len >= 0  peer=10.89.144.34: Connection timed out [110]\r\n![image](https://user-images.githubusercontent.com/15210529/34483359-e4b8af9a-eff8-11e7-9920-9a5b646d598b.png)\r\n",
        "state": "closed",
        "user": "bigshipbig",
        "closed_by": "will-am",
        "created_at": "2018-01-02T12:10:07+00:00",
        "updated_at": "2018-01-06T04:13:25+00:00",
        "closed_at": "2018-01-06T04:13:25+00:00",
        "comments_count": [
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 477,
        "title": "PaddlePaddle新年大礼！周边产品送不停！",
        "body": "各位亲爱的PaddlePaddle用户：\r\n\r\n2017年已经过去，感谢你们一直陪伴PaddlePaddle在深度学习领域共同成长，无论是应用、贡献、还是review、纠错；每一个人的付出对于PaddlePaddle都是至关重要的。**值此新年，PaddlePaddle准备了一批周边小礼物赠送给各位，与各位一同迎接更好的2018！PaddlePaddle，一起加油！**\r\n\r\n**周边礼物领取方式如下：**\r\n请各位使用者、贡献者将**如下信息**发到PaddlePaddle-TechWriter@baidu.com\r\n**【“姓名“+“github账号名” +“周边礼物快递邮寄地址”+”快递联系电话“+”定制卫衣号码（S：160，M：165，L：170，XL：175，xxL：180）“】** →发到PaddlePaddle-TechWriter@baidu.com\r\n我们会根据邮件中的地址为您送上PaddlePaddle周边礼物一份。\r\n您也可以同时回复此issue-”你对PaddlePaddle的祝福和嘱咐“或“PaddlePaddle，一起加油！”来提醒我们查收您的邮件。\r\n\r\n# 礼物内容如下：\r\n每位发送邮件的用户都能获得PaddlePaddle**礼袋一个，内置“LOGO卫衣+贴纸+纪念小徽章“**\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556980-9ed91f42-f173-11e7-974c-e0db65314868.png)\r\n\r\n\r\n# 重要贡献用户随机加发下列周边产品之一：\r\n## PaddlePaddle定制款-膳魔师保温水杯\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556983-a3bcbed8-f173-11e7-9c0c-7fe35348b0c7.png)\r\n\r\n## PaddlePaddle定制款-机械键盘\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34556989-a9dc7c4a-f173-11e7-80d0-5af5ec9f2a20.png)\r\n\r\n\r\n## PaddlePaddle定制款-树莓派\r\n\r\n![image](https://user-images.githubusercontent.com/27677185/34557019-d4f113e6-f173-11e7-9489-265ac6ba207b.png)\r\n\r\n# 如有其他疑问，可以直接回复本issue~~感谢大家的支持！",
        "state": "closed",
        "user": "angelashane",
        "closed_by": "shanyi15",
        "created_at": "2018-01-04T09:26:32+00:00",
        "updated_at": "2018-08-15T09:08:06+00:00",
        "closed_at": "2018-08-15T09:08:06+00:00",
        "comments_count": [
            "cdliheng",
            "qianliheng",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 482,
        "title": "Need to update the mirror registry server address",
        "body": "",
        "state": "closed",
        "user": "Yancey0623",
        "closed_by": "luotao1",
        "created_at": "2018-01-31T02:02:05+00:00",
        "updated_at": "2018-01-31T02:10:25+00:00",
        "closed_at": "2018-01-31T02:10:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 478,
        "title": "如何实现自定义loss?",
        "body": "paddlepaddle新手, 请问各位大佬如何在pdpd中实现自定义的loss呢?\r\npaddlepaddle有类似于pytorch的autograd功能吗",
        "state": "closed",
        "user": "sonack",
        "closed_by": "sonack",
        "created_at": "2018-01-13T08:53:11+00:00",
        "updated_at": "2018-01-14T08:51:58+00:00",
        "closed_at": "2018-01-14T08:51:58+00:00",
        "comments_count": [
            "lcy-seso",
            "sonack",
            "lcy-seso",
            "sonack"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 480,
        "title": "06understand_sentiment, 直接运行报错'generator' object is not callable ",
        "body": "运行02识别数字没问题，06报错。\r\n如下文报错：TypeError: 'generator' object is not callable\r\n\r\nI0124 19:52:20.866607 24031 Util.cpp:166] commandline:  --use_gpu=False \r\nW0124 19:52:20.866672 24031 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON\r\nload dictionary...\r\nI0124 19:53:14.328279 24031 GradientMachine.cpp:85] Initing parameters..\r\nI0124 19:53:14.465420 24031 GradientMachine.cpp:92] Init parameters done.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 161, in <module>\r\n    num_passes=20)\r\n  File \"/home/map/paddle/python27-gcc482/lib/python2.7/site-packages/paddle/v2/trainer.py\", line 154, in train\r\n    for batch_id, data_batch in enumerate(reader()):\r\n  File \"/home/map/paddle/python27-gcc482/lib/python2.7/site-packages/paddle/v2/minibatch.py\", line 33, in batch_reader\r\n    for instance in r:\r\n  File \"/home/map/paddle/python27-gcc482/lib/python2.7/site-packages/paddle/v2/reader/decorator.py\", line 67, in data_reader\r\n    for e in reader():\r\nTypeError: 'generator' object is not callable",
        "state": "closed",
        "user": "Archimondecy",
        "closed_by": "shanyi15",
        "created_at": "2018-01-24T11:56:02+00:00",
        "updated_at": "2018-08-15T09:08:01+00:00",
        "closed_at": "2018-08-15T09:08:01+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 479,
        "title": "mnist手写体识别的那个示例怎么坏了？",
        "body": "\r\nroot@cb462c7b76b1:/opt# **git clone https://github.com/PaddlePaddle/book**\r\n正克隆到 'book'...\r\nremote: Counting objects: 4782, done.\r\nremote: Total 4782 (delta 0), reused 0 (delta 0), pack-reused 4782\r\n接收对象中: 100% (4782/4782), 33.64 MiB | 281.00 KiB/s, 完成.\r\n处理 delta 中: 100% (3156/3156), 完成.\r\n检查连接... 完成。\r\nroot@cb462c7b76b1:/opt# **cd book/**\r\nroot@cb462c7b76b1:/opt/book# **ls**\r\n01.fit_a_line            05.recommender_system    index.cn.html  pending\r\n02.recognize_digits      06.understand_sentiment  index.html     README.cn.md\r\n03.image_classification  07.label_semantic_roles  mnist-client   README.md\r\n04.word2vec              08.machine_translation   paddle         serve\r\nroot@cb462c7b76b1:/opt/book# **cd 02.recognize_digits/**\r\nroot@cb462c7b76b1:/opt/book/02.recognize_digits# **ls**\r\nclient  image  index.cn.html  index.html  README.cn.md  README.md  train.py\r\nroot@cb462c7b76b1:/opt/book/02.recognize_digits# **python2 train.py** \r\nI0122 08:59:13.437571   121 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=1 \r\n[INFO 2018-01-22 08:59:13,443 layers.py:2689] output for __conv_pool_0___conv: c = 20, h = 24, w = 24, size = 11520\r\n[INFO 2018-01-22 08:59:13,444 layers.py:2829] output for __conv_pool_0___pool: c = 20, h = 12, w = 12, size = 2880\r\n[INFO 2018-01-22 08:59:13,445 layers.py:2689] output for __conv_pool_1___conv: c = 50, h = 8, w = 8, size = 3200\r\n[INFO 2018-01-22 08:59:13,446 layers.py:2829] output for __conv_pool_1___pool: c = 50, h = 4, w = 4, size = 800\r\nI0122 08:59:13.449390   121 GradientMachine.cpp:94] Initing parameters..\r\nI0122 08:59:13.451611   121 GradientMachine.cpp:101] Init parameters done.\r\nPass 0, Batch 0, Cost 2.836447, {'classification_error_evaluator': 0.875}\r\nPass 0, Batch 100, Cost 2.305167, {'classification_error_evaluator': 0.875}\r\nPass 0, Batch 200, Cost 2.305494, {'classification_error_evaluator': 0.890625}\r\nPass 0, Batch 300, Cost 2.297118, {'classification_error_evaluator': 0.859375}\r\nPass 0, Batch 400, Cost 2.316209, {'classification_error_evaluator': 0.9140625}\r\nTest with Pass 0, Cost 2.302148, **{'classification_error_evaluator': 0.8865000009536743}**\r\n\r\nPass 1, Batch 0, Cost 2.303937, {'classification_error_evaluator': 0.890625}\r\nPass 1, Batch 100, Cost 2.302149, {'classification_error_evaluator': 0.90625}\r\nPass 1, Batch 200, Cost 2.302109, {'classification_error_evaluator': 0.890625}\r\nPass 1, Batch 300, Cost 2.300121, {'classification_error_evaluator': 0.9140625}\r\nPass 1, Batch 400, Cost 2.293390, {'classification_error_evaluator': 0.859375}\r\nTest with Pass 1, Cost 2.302162, **{'classification_error_evaluator': 0.8971999883651733}**\r\n\r\nPass 2, Batch 0, Cost 2.299892, {'classification_error_evaluator': 0.8984375}\r\nPass 2, Batch 100, Cost 2.308000, {'classification_error_evaluator': 0.8984375}\r\nPass 2, Batch 200, Cost 2.301318, {'classification_error_evaluator': 0.9140625}\r\nPass 2, Batch 300, Cost 2.300943, {'classification_error_evaluator': 0.859375}\r\nPass 2, Batch 400, Cost 2.313893, {'classification_error_evaluator': 0.953125}\r\nTest with Pass 2, Cost 2.302042, **{'classification_error_evaluator': 0.8971999883651733}**\r\n\r\nPass 3, Batch 0, Cost 2.294420, {'classification_error_evaluator': 0.84375}\r\nPass 3, Batch 100, Cost 2.325497, {'classification_error_evaluator': 0.9296875}\r\nPass 3, Batch 200, Cost 2.296998, {'classification_error_evaluator': 0.8671875}\r\nPass 3, Batch 300, Cost 2.294434, {'classification_error_evaluator': 0.8515625}\r\nPass 3, Batch 400, Cost 2.301574, {'classification_error_evaluator': 0.859375}\r\nTest with Pass 3, Cost 2.301726, **{'classification_error_evaluator': 0.8971999883651733}**\r\n\r\nPass 4, Batch 0, Cost 2.316931, {'classification_error_evaluator': 0.921875}\r\nPass 4, Batch 100, Cost 2.304905, {'classification_error_evaluator': 0.921875}\r\nPass 4, Batch 200, Cost 2.294854, {'classification_error_evaluator': 0.859375}\r\nPass 4, Batch 300, Cost 2.303220, {'classification_error_evaluator': 0.8671875}\r\nPass 4, Batch 400, Cost 2.307637, {'classification_error_evaluator': 0.890625}\r\nTest with Pass 4, Cost 2.302750, **{'classification_error_evaluator': 0.8971999883651733}**\r\n\r\nBest pass is 3, testing Avgcost is 2.30172612419\r\nThe classification accuracy is 10.28%\r\nLabel of image/infer_3.png is: 7\r\nroot@cb462c7b76b1:/opt/book/02.recognize_digits#\r\n",
        "state": "closed",
        "user": "lifubang",
        "closed_by": "lifubang",
        "created_at": "2018-01-22T09:04:13+00:00",
        "updated_at": "2018-02-02T05:57:19+00:00",
        "closed_at": "2018-02-02T05:57:19+00:00",
        "comments_count": [
            "lifubang",
            "Xreki",
            "lifubang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 481,
        "title": "docker运行提示权限不够",
        "body": "~/works$ docker run -it -v $PWD:/work paddlepaddle/paddle /work/train.py\r\ndocker: Error response from daemon: invalid header field value \"oci runtime error: container_linux.go:247: starting container process caused \\\"exec: \\\\\\\"/work/train.py\\\\\\\": permission denied\\\"\\n\".``",
        "state": "closed",
        "user": "LGinC",
        "closed_by": "typhoonzero",
        "created_at": "2018-01-28T15:12:00+00:00",
        "updated_at": "2018-01-29T02:17:48+00:00",
        "closed_at": "2018-01-29T02:17:48+00:00",
        "comments_count": [
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 484,
        "title": "05.recommender_system使用GPU时报错Matrix.cpp:652] Not supported",
        "body": "在GPU上运行05.recommender_system时报错",
        "state": "closed",
        "user": "sunandsky1992",
        "closed_by": "JiayiFeng",
        "created_at": "2018-02-06T12:57:12+00:00",
        "updated_at": "2018-02-07T12:57:41+00:00",
        "closed_at": "2018-02-07T12:57:41+00:00",
        "comments_count": [
            "JiayiFeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 485,
        "title": "ask to translate into indonesian language",
        "body": "hello sir ...\r\n may i translate into indonesia.agar bahasa indonesia is easier to read .....?\r\n thank you very much for your attention",
        "state": "closed",
        "user": "mohdhaekal",
        "closed_by": "shanyi15",
        "created_at": "2018-02-10T04:01:44+00:00",
        "updated_at": "2018-08-15T09:15:29+00:00",
        "closed_at": "2018-08-15T09:15:28+00:00",
        "comments_count": [
            "shanyi15",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 486,
        "title": "请教关于训练数据的归一化问题",
        "body": "官方自带的“基本使用概念”里面有个线性回归的例子，使用的训练数据集是自己传入的。\r\n我把数据值修改大了，比如[5061,245]，就会报“The kernel appears to have died. It will restart automatically.”错误。请问该如何解决呢？谢谢。\r\n附上代码：\r\n\r\ndefine training dataset reader\r\ndef train_reader():\r\ntrain_x = np.array([[1, 1], [1, 2], [3, 4], [5, 2]])\r\ntrain_y = np.array([[-2], [-3], [-7], [-7]])\r\n\r\ndef reader():\r\n    for i in xrange(train_y.shape[0]):\r\n        yield train_x[i], train_y[i]\r\n\r\nreturn reader",
        "state": "closed",
        "user": "cdliheng",
        "closed_by": "shanyi15",
        "created_at": "2018-02-16T12:06:27+00:00",
        "updated_at": "2018-08-15T09:15:25+00:00",
        "closed_at": "2018-08-15T09:15:25+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 487,
        "title": "我自己模拟了一个数据集，读取后训练无法收敛，请指教该怎么处理？谢谢",
        "body": "**模拟了t.data数据文件。\r\n由第1-3列“年份，收入，成本”，预测第4列“利润”**\r\n\r\n2012\t320.00\t270.00\t32.00\r\n2013\t400.00\t310.00\t45.00\r\n2014\t450.00\t350.00\t50.00\r\n2015\t500.00\t400.00\t60.00\r\n2016\t780.00\t500.00\t210.00\r\n2017\t930.00\t610.00\t290.00\r\n\r\n**# 代码如下：训练后cost无法收敛，请问该如何处理？谢谢**\r\n\r\nimport paddle.v2 as paddle\r\nimport numpy as np\r\n\r\n> # init paddle\r\n\r\npaddle.init(use_gpu=False)\r\n\r\n# network config\r\nx = paddle.layer.data(name='x', type=paddle.data_type.dense_vector(3))\r\ny_predict = paddle.layer.fc(input=x, size=1, act=paddle.activation.Linear())\r\ny = paddle.layer.data(name='y', type=paddle.data_type.dense_vector(1))\r\ncost = paddle.layer.square_error_cost(input=y_predict, label=y)\r\n\r\n# create parameters\r\nparameters = paddle.parameters.create(cost)\r\n# create optimizer\r\noptimizer = paddle.optimizer.Momentum(momentum=0)\r\n# create trainer\r\ntrainer = paddle.trainer.SGD(cost=cost,\r\n                             parameters=parameters,\r\n                             update_equation=optimizer)\r\n\r\n\r\n# event_handler to print training info\r\ndef event_handler(event):\r\n    if isinstance(event, paddle.event.EndIteration):\r\n        if event.batch_id % 1 == 0:\r\n            print \"Pass %d, Batch %d, Cost %f\" % (event.pass_id, event.batch_id,\r\n                                                  event.cost)\r\n    # product model every 10 pass\r\n    if isinstance(event, paddle.event.EndPass):\r\n        if event.pass_id % 10 == 0:\r\n            with open('params_pass_%d.tar' % event.pass_id, 'w') as f:\r\n                trainer.save_parameter_to_tar(f)\r\n\r\n\r\n# define training dataset reader\r\ndef train_reader():\r\n    data = np.fromfile('t.data', sep=' ')\r\n    data = data.reshape(data.shape[0] / 4, 4)\r\n    maximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0) / data.shape[0]\r\n    for i in xrange(4 - 1):\r\n        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])\r\n\r\n    print(data)\r\n    def reader():\r\n        for d in data:\r\n            yield d[:-1], d[-1:]\r\n            #print(d[:-1])\r\n            #print(d[-1:])\r\n    return reader\r\n\r\n\r\n# define feeding map\r\nfeeding = {'x': 0, 'y': 1}\r\n\r\n# training\r\ntrainer.train(\r\n    reader=paddle.batch(\r\n        train_reader(), batch_size=1),\r\n    feeding=feeding,\r\n    event_handler=event_handler,\r\n    num_passes=100)\r\n===========================代码结束\r\n\r\n\r\n**训练打印输出**：\r\n[[ -5.00000000e-01  -3.98907104e-01  -4.01960784e-01   3.20000000e+01]\r\n [ -3.00000000e-01  -2.67759563e-01  -2.84313725e-01   4.50000000e+01]\r\n [ -1.00000000e-01  -1.85792350e-01  -1.66666667e-01   5.00000000e+01]\r\n [  1.00000000e-01  -1.03825137e-01  -1.96078431e-02   6.00000000e+01]\r\n [  3.00000000e-01   3.55191257e-01   2.74509804e-01   2.10000000e+02]\r\n [  5.00000000e-01   6.01092896e-01   5.98039216e-01   2.90000000e+02]]\r\nPass 0, Batch 0, Cost 998.369568\r\nPass 0, Batch 1, Cost 1991.135254\r\nPass 0, Batch 2, Cost 2454.105225\r\nPass 0, Batch 3, Cost 3535.465088\r\nPass 0, Batch 4, Cost 44173.917969\r\nPass 0, Batch 5, Cost 84036.164062\r\nPass 1, Batch 0, Cost 944.376953\r\nPass 1, Batch 1, Cost 1899.681396\r\nPass 1, Batch 2, Cost 2337.895264\r\nPass 1, Batch 3, Cost 3376.836426\r\nPass 1, Batch 4, Cost 43450.796875\r\nPass 1, Batch 5, Cost 82866.148438\r\nPass 2, Batch 0, Cost 892.736389\r\nPass 2, Batch 1, Cost 1811.649170\r\nPass 2, Batch 2, Cost 2225.972900\r\nPass 2, Batch 3, Cost 3223.693604\r\nPass 2, Batch 4, Cost 42741.007812\r\nPass 2, Batch 5, Cost 81715.218750\r\nPass 3, Batch 0, Cost 843.364197\r\nPass 3, Batch 1, Cost 1726.931519\r\nPass 3, Batch 2, Cost 2118.210938\r\nPass 3, Batch 3, Cost 3075.884277\r\nPass 3, Batch 4, Cost 42044.289062\r\nPass 3, Batch 5, Cost 80583.023438\r\nPass 4, Batch 0, Cost 796.179260\r\nPass 4, Batch 1, Cost 1645.424072\r\nPass 4, Batch 2, Cost 2014.485718\r\nPass 4, Batch 3, Cost 2933.261475\r\nPass 4, Batch 4, Cost 41360.378906\r\nPass 4, Batch 5, Cost 79469.257812\r\nPass 5, Batch 0, Cost 751.102844\r\nPass 5, Batch 1, Cost 1567.025269\r\nPass 5, Batch 2, Cost 1914.676392\r\nPass 5, Batch 3, Cost 2795.680420\r\nPass 5, Batch 4, Cost 40689.027344\r\nPass 5, Batch 5, Cost 78373.562500\r\nPass 6, Batch 0, Cost 708.059021\r\nPass 6, Batch 1, Cost 1491.637207\r\nPass 6, Batch 2, Cost 1818.666626\r\nPass 6, Batch 3, Cost 2663.002441\r\nPass 6, Batch 4, Cost 40029.980469\r\nPass 6, Batch 5, Cost 77295.609375\r\nPass 7, Batch 0, Cost 666.973816\r\nPass 7, Batch 1, Cost 1419.163208\r\nPass 7, Batch 2, Cost 1726.341553\r\nPass 7, Batch 3, Cost 2535.089355\r\nPass 7, Batch 4, Cost 39382.996094\r\nPass 7, Batch 5, Cost 76235.085938\r\nPass 8, Batch 0, Cost 627.776001\r\nPass 8, Batch 1, Cost 1349.510742\r\nPass 8, Batch 2, Cost 1637.591309\r\nPass 8, Batch 3, Cost 2411.809082\r\nPass 8, Batch 4, Cost 38747.839844\r\nPass 8, Batch 5, Cost 75191.687500\r\nPass 9, Batch 0, Cost 590.395996\r\nPass 9, Batch 1, Cost 1282.589844\r\nPass 9, Batch 2, Cost 1552.307251\r\nPass 9, Batch 3, Cost 2293.031250\r\nPass 9, Batch 4, Cost 38124.273438\r\nPass 9, Batch 5, Cost 74165.085938\r\nPass 10, Batch 0, Cost 554.766724\r\nPass 10, Batch 1, Cost 1218.312012\r\nPass 10, Batch 2, Cost 1470.384766\r\nPass 10, Batch 3, Cost 2178.629883\r\nPass 10, Batch 4, Cost 37512.070312\r\nPass 10, Batch 5, Cost 73154.992188\r\nPass 11, Batch 0, Cost 520.823242\r\nPass 11, Batch 1, Cost 1156.592529\r\nPass 11, Batch 2, Cost 1391.721436\r\nPass 11, Batch 3, Cost 2068.481445\r\nPass 11, Batch 4, Cost 36911.007812\r\nPass 11, Batch 5, Cost 72161.109375\r\nPass 12, Batch 0, Cost 488.502838\r\nPass 12, Batch 1, Cost 1097.348511\r\nPass 12, Batch 2, Cost 1316.218384\r\nPass 12, Batch 3, Cost 1962.466309\r\nPass 12, Batch 4, Cost 36320.859375\r\nPass 12, Batch 5, Cost 71183.148438\r\nPass 13, Batch 0, Cost 457.744415\r\nPass 13, Batch 1, Cost 1040.499023\r\nPass 13, Batch 2, Cost 1243.778442\r\nPass 13, Batch 3, Cost 1860.467163\r\nPass 13, Batch 4, Cost 35741.421875\r\nPass 13, Batch 5, Cost 70220.828125\r\nPass 14, Batch 0, Cost 428.489014\r\nPass 14, Batch 1, Cost 985.966675\r\nPass 14, Batch 2, Cost 1174.308228\r\nPass 14, Batch 3, Cost 1762.370605\r\nPass 14, Batch 4, Cost 35172.468750\r\nPass 14, Batch 5, Cost 69273.859375\r\nPass 15, Batch 0, Cost 400.679443\r\nPass 15, Batch 1, Cost 933.675171\r\nPass 15, Batch 2, Cost 1107.715698\r\nPass 15, Batch 3, Cost 1668.065186\r\nPass 15, Batch 4, Cost 34613.812500\r\nPass 15, Batch 5, Cost 68341.968750\r\nPass 16, Batch 0, Cost 374.260498\r\nPass 16, Batch 1, Cost 883.550842\r\nPass 16, Batch 2, Cost 1043.912231\r\nPass 16, Batch 3, Cost 1577.442749\r\nPass 16, Batch 4, Cost 34065.242188\r\nPass 16, Batch 5, Cost 67424.906250\r\nPass 17, Batch 0, Cost 349.178741\r\nPass 17, Batch 1, Cost 835.522339\r\nPass 17, Batch 2, Cost 982.811401\r\nPass 17, Batch 3, Cost 1490.398682\r\nPass 17, Batch 4, Cost 33526.554688\r\nPass 17, Batch 5, Cost 66522.375000\r\nPass 18, Batch 0, Cost 325.382050\r\nPass 18, Batch 1, Cost 789.519653\r\nPass 18, Batch 2, Cost 924.328735\r\nPass 18, Batch 3, Cost 1406.829102\r\nPass 18, Batch 4, Cost 32997.570312\r\nPass 18, Batch 5, Cost 65634.148438\r\nPass 19, Batch 0, Cost 302.820587\r\nPass 19, Batch 1, Cost 745.476074\r\nPass 19, Batch 2, Cost 868.382629\r\nPass 19, Batch 3, Cost 1326.635254\r\nPass 19, Batch 4, Cost 32478.087891\r\nPass 19, Batch 5, Cost 64759.968750\r\nPass 20, Batch 0, Cost 281.445862\r\nPass 20, Batch 1, Cost 703.325623\r\nPass 20, Batch 2, Cost 814.893494\r\nPass 20, Batch 3, Cost 1249.719238\r\nPass 20, Batch 4, Cost 31967.929688\r\nPass 20, Batch 5, Cost 63899.562500\r\nPass 21, Batch 0, Cost 261.210815\r\nPass 21, Batch 1, Cost 663.004761\r\nPass 21, Batch 2, Cost 763.783813\r\nPass 21, Batch 3, Cost 1175.986206\r\nPass 21, Batch 4, Cost 31466.902344\r\nPass 21, Batch 5, Cost 63052.714844\r\nPass 22, Batch 0, Cost 242.070312\r\nPass 22, Batch 1, Cost 624.451965\r\nPass 22, Batch 2, Cost 714.978516\r\nPass 22, Batch 3, Cost 1105.343872\r\nPass 22, Batch 4, Cost 30974.845703\r\nPass 22, Batch 5, Cost 62219.171875\r\nPass 23, Batch 0, Cost 223.980225\r\nPass 23, Batch 1, Cost 587.607300\r\nPass 23, Batch 2, Cost 668.404480\r\nPass 23, Batch 3, Cost 1037.702271\r\nPass 23, Batch 4, Cost 30491.572266\r\nPass 23, Batch 5, Cost 61398.707031\r\nPass 24, Batch 0, Cost 206.898270\r\nPass 24, Batch 1, Cost 552.412476\r\nPass 24, Batch 2, Cost 623.990356\r\nPass 24, Batch 3, Cost 972.973816\r\nPass 24, Batch 4, Cost 30016.916016\r\nPass 24, Batch 5, Cost 60591.082031\r\nPass 25, Batch 0, Cost 190.783264\r\nPass 25, Batch 1, Cost 518.811035\r\nPass 25, Batch 2, Cost 581.667053\r\nPass 25, Batch 3, Cost 911.072815\r\nPass 25, Batch 4, Cost 29550.708984\r\nPass 25, Batch 5, Cost 59796.085938\r\nPass 26, Batch 0, Cost 175.595657\r\nPass 26, Batch 1, Cost 486.748444\r\nPass 26, Batch 2, Cost 541.367432\r\nPass 26, Batch 3, Cost 851.916382\r\nPass 26, Batch 4, Cost 29092.785156\r\nPass 26, Batch 5, Cost 59013.476562\r\nPass 27, Batch 0, Cost 161.297089\r\nPass 27, Batch 1, Cost 456.171570\r\nPass 27, Batch 2, Cost 503.026031\r\nPass 27, Batch 3, Cost 795.423767\r\nPass 27, Batch 4, Cost 28642.990234\r\nPass 27, Batch 5, Cost 58243.050781\r\nPass 28, Batch 0, Cost 147.850388\r\nPass 28, Batch 1, Cost 427.028473\r\nPass 28, Batch 2, Cost 466.579224\r\nPass 28, Batch 3, Cost 741.515686\r\nPass 28, Batch 4, Cost 28201.158203\r\nPass 28, Batch 5, Cost 57484.589844\r\nPass 29, Batch 0, Cost 135.219757\r\nPass 29, Batch 1, Cost 399.269287\r\nPass 29, Batch 2, Cost 431.965332\r\nPass 29, Batch 3, Cost 690.115356\r\nPass 29, Batch 4, Cost 27767.140625\r\nPass 29, Batch 5, Cost 56737.886719\r\nPass 30, Batch 0, Cost 123.370583\r\nPass 30, Batch 1, Cost 372.845734\r\nPass 30, Batch 2, Cost 399.124176\r\nPass 30, Batch 3, Cost 641.148376\r\nPass 30, Batch 4, Cost 27340.785156\r\nPass 30, Batch 5, Cost 56002.742188\r\nPass 31, Batch 0, Cost 112.269615\r\nPass 31, Batch 1, Cost 347.710663\r\nPass 31, Batch 2, Cost 367.997986\r\nPass 31, Batch 3, Cost 594.541992\r\nPass 31, Batch 4, Cost 26921.951172\r\nPass 31, Batch 5, Cost 55278.949219\r\nPass 32, Batch 0, Cost 101.884293\r\nPass 32, Batch 1, Cost 323.818054\r\nPass 32, Batch 2, Cost 338.529022\r\nPass 32, Batch 3, Cost 550.224792\r\nPass 32, Batch 4, Cost 26510.488281\r\nPass 32, Batch 5, Cost 54566.312500\r\nPass 33, Batch 0, Cost 92.183479\r\nPass 33, Batch 1, Cost 301.123779\r\nPass 33, Batch 2, Cost 310.662933\r\nPass 33, Batch 3, Cost 508.127991\r\nPass 33, Batch 4, Cost 26106.251953\r\nPass 33, Batch 5, Cost 53864.640625\r\nPass 34, Batch 0, Cost 83.137093\r\nPass 34, Batch 1, Cost 279.585114\r\nPass 34, Batch 2, Cost 284.346191\r\nPass 34, Batch 3, Cost 468.184570\r\nPass 34, Batch 4, Cost 25709.109375\r\nPass 34, Batch 5, Cost 53173.730469\r\nPass 35, Batch 0, Cost 74.715981\r\nPass 35, Batch 1, Cost 259.159973\r\nPass 35, Batch 2, Cost 259.526215\r\nPass 35, Batch 3, Cost 430.328857\r\nPass 35, Batch 4, Cost 25318.919922\r\nPass 35, Batch 5, Cost 52493.414062\r\nPass 36, Batch 0, Cost 66.892220\r\nPass 36, Batch 1, Cost 239.808395\r\nPass 36, Batch 2, Cost 236.152908\r\nPass 36, Batch 3, Cost 394.497192\r\nPass 36, Batch 4, Cost 24935.550781\r\nPass 36, Batch 5, Cost 51823.503906\r\nPass 37, Batch 0, Cost 59.638596\r\nPass 37, Batch 1, Cost 221.490891\r\nPass 37, Batch 2, Cost 214.177032\r\nPass 37, Batch 3, Cost 360.627686\r\nPass 37, Batch 4, Cost 24558.873047\r\nPass 37, Batch 5, Cost 51163.808594\r\nPass 38, Batch 0, Cost 52.928894\r\nPass 38, Batch 1, Cost 204.169571\r\nPass 38, Batch 2, Cost 193.550613\r\nPass 38, Batch 3, Cost 328.659729\r\nPass 38, Batch 4, Cost 24188.763672\r\nPass 38, Batch 5, Cost 50514.167969\r\nPass 39, Batch 0, Cost 46.738022\r\nPass 39, Batch 1, Cost 187.807571\r\nPass 39, Batch 2, Cost 174.227539\r\nPass 39, Batch 3, Cost 298.534698\r\nPass 39, Batch 4, Cost 23825.087891\r\nPass 39, Batch 5, Cost 49874.394531\r\nPass 40, Batch 0, Cost 41.041603\r\nPass 40, Batch 1, Cost 172.369232\r\nPass 40, Batch 2, Cost 156.162567\r\nPass 40, Batch 3, Cost 270.195282\r\nPass 40, Batch 4, Cost 23467.728516\r\nPass 40, Batch 5, Cost 49244.335938\r\nPass 41, Batch 0, Cost 35.816124\r\nPass 41, Batch 1, Cost 157.819946\r\nPass 41, Batch 2, Cost 139.312103\r\nPass 41, Batch 3, Cost 243.585785\r\nPass 41, Batch 4, Cost 23116.562500\r\nPass 41, Batch 5, Cost 48623.808594\r\nPass 42, Batch 0, Cost 31.039007\r\nPass 42, Batch 1, Cost 144.126282\r\nPass 42, Batch 2, Cost 123.633591\r\nPass 42, Batch 3, Cost 218.652054\r\nPass 42, Batch 4, Cost 22771.480469\r\nPass 42, Batch 5, Cost 48012.656250\r\nPass 43, Batch 0, Cost 26.688408\r\nPass 43, Batch 1, Cost 131.255524\r\nPass 43, Batch 2, Cost 109.085587\r\nPass 43, Batch 3, Cost 195.341202\r\nPass 43, Batch 4, Cost 22432.357422\r\nPass 43, Batch 5, Cost 47410.722656\r\nPass 44, Batch 0, Cost 22.743280\r\nPass 44, Batch 1, Cost 119.176384\r\nPass 44, Batch 2, Cost 95.628380\r\nPass 44, Batch 3, Cost 173.602219\r\nPass 44, Batch 4, Cost 22099.083984\r\nPass 44, Batch 5, Cost 46817.851562\r\nPass 45, Batch 0, Cost 19.183456\r\nPass 45, Batch 1, Cost 107.858414\r\nPass 45, Batch 2, Cost 83.222885\r\nPass 45, Batch 3, Cost 153.385071\r\nPass 45, Batch 4, Cost 21771.548828\r\nPass 45, Batch 5, Cost 46233.878906\r\nPass 46, Batch 0, Cost 15.989351\r\nPass 46, Batch 1, Cost 97.271904\r\nPass 46, Batch 2, Cost 71.831223\r\nPass 46, Batch 3, Cost 134.640778\r\nPass 46, Batch 4, Cost 21449.644531\r\nPass 46, Batch 5, Cost 45658.656250\r\nPass 47, Batch 0, Cost 13.142146\r\nPass 47, Batch 1, Cost 87.388237\r\nPass 47, Batch 2, Cost 61.416683\r\nPass 47, Batch 3, Cost 117.322159\r\nPass 47, Batch 4, Cost 21133.259766\r\nPass 47, Batch 5, Cost 45092.046875\r\nPass 48, Batch 0, Cost 10.623784\r\nPass 48, Batch 1, Cost 78.179733\r\nPass 48, Batch 2, Cost 51.943718\r\nPass 48, Batch 3, Cost 101.383385\r\nPass 48, Batch 4, Cost 20822.300781\r\nPass 48, Batch 5, Cost 44533.886719\r\nPass 49, Batch 0, Cost 8.416836\r\nPass 49, Batch 1, Cost 69.619568\r\nPass 49, Batch 2, Cost 43.377838\r\nPass 49, Batch 3, Cost 86.779503\r\nPass 49, Batch 4, Cost 20516.658203\r\nPass 49, Batch 5, Cost 43984.046875\r\nPass 50, Batch 0, Cost 6.504500\r\nPass 50, Batch 1, Cost 61.681782\r\nPass 50, Batch 2, Cost 35.685337\r\nPass 50, Batch 3, Cost 73.466934\r\nPass 50, Batch 4, Cost 20216.234375\r\nPass 50, Batch 5, Cost 43442.382812\r\nPass 51, Batch 0, Cost 4.870667\r\nPass 51, Batch 1, Cost 54.341232\r\nPass 51, Batch 2, Cost 28.833775\r\nPass 51, Batch 3, Cost 61.403290\r\nPass 51, Batch 4, Cost 19920.925781\r\nPass 51, Batch 5, Cost 42908.753906\r\nPass 52, Batch 0, Cost 3.499800\r\nPass 52, Batch 1, Cost 47.573387\r\nPass 52, Batch 2, Cost 22.791424\r\nPass 52, Batch 3, Cost 50.547337\r\nPass 52, Batch 4, Cost 19630.646484\r\nPass 52, Batch 5, Cost 42383.019531\r\nPass 53, Batch 0, Cost 2.376952\r\nPass 53, Batch 1, Cost 41.354767\r\nPass 53, Batch 2, Cost 17.527554\r\nPass 53, Batch 3, Cost 40.858765\r\nPass 53, Batch 4, Cost 19345.292969\r\nPass 53, Batch 5, Cost 41865.066406\r\nPass 54, Batch 0, Cost 1.487789\r\nPass 54, Batch 1, Cost 35.662506\r\nPass 54, Batch 2, Cost 13.012529\r\nPass 54, Batch 3, Cost 32.298729\r\nPass 54, Batch 4, Cost 19064.777344\r\nPass 54, Batch 5, Cost 41354.742188\r\nPass 55, Batch 0, Cost 0.818505\r\nPass 55, Batch 1, Cost 30.474575\r\nPass 55, Batch 2, Cost 9.217384\r\nPass 55, Batch 3, Cost 24.829203\r\nPass 55, Batch 4, Cost 18789.005859\r\nPass 55, Batch 5, Cost 40851.937500\r\nPass 56, Batch 0, Cost 0.355856\r\nPass 56, Batch 1, Cost 25.769497\r\nPass 56, Batch 2, Cost 6.114123\r\nPass 56, Batch 3, Cost 18.413240\r\nPass 56, Batch 4, Cost 18517.900391\r\nPass 56, Batch 5, Cost 40356.511719\r\nPass 57, Batch 0, Cost 0.087098\r\nPass 57, Batch 1, Cost 21.526691\r\nPass 57, Batch 2, Cost 3.675503\r\nPass 57, Batch 3, Cost 13.014841\r\nPass 57, Batch 4, Cost 18251.359375\r\nPass 57, Batch 5, Cost 39868.347656\r\nPass 58, Batch 0, Cost 0.000000\r\nPass 58, Batch 1, Cost 17.726084\r\nPass 58, Batch 2, Cost 1.875215\r\nPass 58, Batch 3, Cost 8.599192\r\nPass 58, Batch 4, Cost 17989.306641\r\nPass 58, Batch 5, Cost 39387.324219\r\nPass 59, Batch 0, Cost 0.082829\r\nPass 59, Batch 1, Cost 14.348381\r\nPass 59, Batch 2, Cost 0.687650\r\nPass 59, Batch 3, Cost 5.132210\r\nPass 59, Batch 4, Cost 17731.656250\r\nPass 59, Batch 5, Cost 38913.316406\r\nPass 60, Batch 0, Cost 0.324326\r\nPass 60, Batch 1, Cost 11.374795\r\nPass 60, Batch 2, Cost 0.087999\r\nPass 60, Batch 3, Cost 2.580912\r\nPass 60, Batch 4, Cost 17478.328125\r\nPass 60, Batch 5, Cost 38446.222656\r\nPass 61, Batch 0, Cost 0.713679\r\nPass 61, Batch 1, Cost 8.787268\r\nPass 61, Batch 2, Cost 0.052216\r\nPass 61, Batch 3, Cost 0.913144\r\nPass 61, Batch 4, Cost 17229.242188\r\nPass 61, Batch 5, Cost 37985.914062\r\nPass 62, Batch 0, Cost 1.240534\r\nPass 62, Batch 1, Cost 6.568283\r\nPass 62, Batch 2, Cost 0.556986\r\nPass 62, Batch 3, Cost 0.097678\r\nPass 62, Batch 4, Cost 16984.314453\r\nPass 62, Batch 5, Cost 37532.281250\r\nPass 63, Batch 0, Cost 1.894981\r\nPass 63, Batch 1, Cost 4.700949\r\nPass 63, Batch 2, Cost 1.579694\r\nPass 63, Batch 3, Cost 0.104153\r\nPass 63, Batch 4, Cost 16743.474609\r\nPass 63, Batch 5, Cost 37085.218750\r\nPass 64, Batch 0, Cost 2.667472\r\nPass 64, Batch 1, Cost 3.168898\r\nPass 64, Batch 2, Cost 3.098427\r\nPass 64, Batch 3, Cost 0.903045\r\nPass 64, Batch 4, Cost 16506.642578\r\nPass 64, Batch 5, Cost 36644.605469\r\nPass 65, Batch 0, Cost 3.548920\r\nPass 65, Batch 1, Cost 1.956396\r\nPass 65, Batch 2, Cost 5.091931\r\nPass 65, Batch 3, Cost 2.465654\r\nPass 65, Batch 4, Cost 16273.752930\r\nPass 65, Batch 5, Cost 36210.355469\r\nPass 66, Batch 0, Cost 4.530585\r\nPass 66, Batch 1, Cost 1.048127\r\nPass 66, Batch 2, Cost 7.539648\r\nPass 66, Batch 3, Cost 4.764084\r\nPass 66, Batch 4, Cost 16044.721680\r\nPass 66, Batch 5, Cost 35782.343750\r\nPass 67, Batch 0, Cost 5.604118\r\nPass 67, Batch 1, Cost 0.429383\r\nPass 67, Batch 2, Cost 10.421539\r\nPass 67, Batch 3, Cost 7.771211\r\nPass 67, Batch 4, Cost 15819.485352\r\nPass 67, Batch 5, Cost 35360.484375\r\nPass 68, Batch 0, Cost 6.761579\r\nPass 68, Batch 1, Cost 0.085904\r\nPass 68, Batch 2, Cost 13.718390\r\nPass 68, Batch 3, Cost 11.460693\r\nPass 68, Batch 4, Cost 15597.969727\r\nPass 68, Batch 5, Cost 34944.664062\r\nPass 69, Batch 0, Cost 7.995314\r\nPass 69, Batch 1, Cost 0.003949\r\nPass 69, Batch 2, Cost 17.411449\r\nPass 69, Batch 3, Cost 15.807013\r\nPass 69, Batch 4, Cost 15380.108398\r\nPass 69, Batch 5, Cost 34534.785156\r\nPass 70, Batch 0, Cost 9.298052\r\nPass 70, Batch 1, Cost 0.170253\r\nPass 70, Batch 2, Cost 21.482538\r\nPass 70, Batch 3, Cost 20.785160\r\nPass 70, Batch 4, Cost 15165.834961\r\nPass 70, Batch 5, Cost 34130.757812\r\nPass 71, Batch 0, Cost 10.662812\r\nPass 71, Batch 1, Cost 0.571993\r\nPass 71, Batch 2, Cost 25.914043\r\nPass 71, Batch 3, Cost 26.370989\r\nPass 71, Batch 4, Cost 14955.083008\r\nPass 71, Batch 5, Cost 33732.480469\r\nPass 72, Batch 0, Cost 12.082880\r\nPass 72, Batch 1, Cost 1.196806\r\nPass 72, Batch 2, Cost 30.688990\r\nPass 72, Batch 3, Cost 32.540951\r\nPass 72, Batch 4, Cost 14747.792969\r\nPass 72, Batch 5, Cost 33339.863281\r\nPass 73, Batch 0, Cost 13.552006\r\nPass 73, Batch 1, Cost 2.032743\r\nPass 73, Batch 2, Cost 35.790833\r\nPass 73, Batch 3, Cost 39.272305\r\nPass 73, Batch 4, Cost 14543.895508\r\nPass 73, Batch 5, Cost 32952.820312\r\nPass 74, Batch 0, Cost 15.064060\r\nPass 74, Batch 1, Cost 3.068297\r\nPass 74, Batch 2, Cost 41.203789\r\nPass 74, Batch 3, Cost 46.542789\r\nPass 74, Batch 4, Cost 14343.330078\r\nPass 74, Batch 5, Cost 32571.244141\r\nPass 75, Batch 0, Cost 16.613373\r\nPass 75, Batch 1, Cost 4.292356\r\nPass 75, Batch 2, Cost 46.912132\r\nPass 75, Batch 3, Cost 54.330997\r\nPass 75, Batch 4, Cost 14146.038086\r\nPass 75, Batch 5, Cost 32195.056641\r\nPass 76, Batch 0, Cost 18.194450\r\nPass 76, Batch 1, Cost 5.694260\r\nPass 76, Batch 2, Cost 52.901173\r\nPass 76, Batch 3, Cost 62.615723\r\nPass 76, Batch 4, Cost 13951.961914\r\nPass 76, Batch 5, Cost 31824.173828\r\nPass 77, Batch 0, Cost 19.802031\r\nPass 77, Batch 1, Cost 7.263558\r\nPass 77, Batch 2, Cost 59.156204\r\nPass 77, Batch 3, Cost 71.376923\r\nPass 77, Batch 4, Cost 13761.039062\r\nPass 77, Batch 5, Cost 31458.501953\r\nPass 78, Batch 0, Cost 21.431011\r\nPass 78, Batch 1, Cost 8.990344\r\nPass 78, Batch 2, Cost 65.663254\r\nPass 78, Batch 3, Cost 80.594566\r\nPass 78, Batch 4, Cost 13573.213867\r\nPass 78, Batch 5, Cost 31097.957031\r\nPass 79, Batch 0, Cost 23.077068\r\nPass 79, Batch 1, Cost 10.865185\r\nPass 79, Batch 2, Cost 72.409225\r\nPass 79, Batch 3, Cost 90.250000\r\nPass 79, Batch 4, Cost 13388.429688\r\nPass 79, Batch 5, Cost 30742.466797\r\nPass 80, Batch 0, Cost 24.735430\r\nPass 80, Batch 1, Cost 12.878654\r\nPass 80, Batch 2, Cost 79.380348\r\nPass 80, Batch 3, Cost 100.324203\r\nPass 80, Batch 4, Cost 13206.633789\r\nPass 80, Batch 5, Cost 30391.945312\r\nPass 81, Batch 0, Cost 26.401871\r\nPass 81, Batch 1, Cost 15.021864\r\nPass 81, Batch 2, Cost 86.564293\r\nPass 81, Batch 3, Cost 110.799263\r\nPass 81, Batch 4, Cost 13027.768555\r\nPass 81, Batch 5, Cost 30046.298828\r\nPass 82, Batch 0, Cost 28.072607\r\nPass 82, Batch 1, Cost 17.286402\r\nPass 82, Batch 2, Cost 93.949013\r\nPass 82, Batch 3, Cost 121.657677\r\nPass 82, Batch 4, Cost 12851.783203\r\nPass 82, Batch 5, Cost 29705.466797\r\nPass 83, Batch 0, Cost 29.743605\r\nPass 83, Batch 1, Cost 19.663858\r\nPass 83, Batch 2, Cost 101.522324\r\nPass 83, Batch 3, Cost 132.882462\r\nPass 83, Batch 4, Cost 12678.626953\r\nPass 83, Batch 5, Cost 29369.369141\r\nPass 84, Batch 0, Cost 31.411360\r\nPass 84, Batch 1, Cost 22.146376\r\nPass 84, Batch 2, Cost 109.272850\r\nPass 84, Batch 3, Cost 144.457031\r\nPass 84, Batch 4, Cost 12508.248047\r\nPass 84, Batch 5, Cost 29037.925781\r\nPass 85, Batch 0, Cost 33.072460\r\nPass 85, Batch 1, Cost 24.726248\r\nPass 85, Batch 2, Cost 117.189400\r\nPass 85, Batch 3, Cost 156.365036\r\nPass 85, Batch 4, Cost 12340.597656\r\nPass 85, Batch 5, Cost 28711.062500\r\nPass 86, Batch 0, Cost 34.723644\r\nPass 86, Batch 1, Cost 27.396126\r\nPass 86, Batch 2, Cost 125.261574\r\nPass 86, Batch 3, Cost 168.591415\r\nPass 86, Batch 4, Cost 12175.625000\r\nPass 86, Batch 5, Cost 28388.707031\r\nPass 87, Batch 0, Cost 36.362034\r\nPass 87, Batch 1, Cost 30.149040\r\nPass 87, Batch 2, Cost 133.478989\r\nPass 87, Batch 3, Cost 181.120850\r\nPass 87, Batch 4, Cost 12013.282227\r\nPass 87, Batch 5, Cost 28070.789062\r\nPass 88, Batch 0, Cost 37.984570\r\nPass 88, Batch 1, Cost 32.978020\r\nPass 88, Batch 2, Cost 141.831284\r\nPass 88, Batch 3, Cost 193.938644\r\nPass 88, Batch 4, Cost 11853.526367\r\nPass 88, Batch 5, Cost 27757.240234\r\nPass 89, Batch 0, Cost 39.588879\r\nPass 89, Batch 1, Cost 35.876877\r\nPass 89, Batch 2, Cost 150.309433\r\nPass 89, Batch 3, Cost 207.031021\r\nPass 89, Batch 4, Cost 11696.303711\r\nPass 89, Batch 5, Cost 27447.978516\r\nPass 90, Batch 0, Cost 41.172405\r\nPass 90, Batch 1, Cost 38.839088\r\nPass 90, Batch 2, Cost 158.903702\r\nPass 90, Batch 3, Cost 220.383804\r\nPass 90, Batch 4, Cost 11541.577148\r\nPass 90, Batch 5, Cost 27142.958984\r\nPass 91, Batch 0, Cost 42.732601\r\nPass 91, Batch 1, Cost 41.858547\r\nPass 91, Batch 2, Cost 167.605011\r\nPass 91, Batch 3, Cost 233.983643\r\nPass 91, Batch 4, Cost 11389.296875\r\nPass 91, Batch 5, Cost 26842.093750\r\nPass 92, Batch 0, Cost 44.267384\r\nPass 92, Batch 1, Cost 44.929634\r\nPass 92, Batch 2, Cost 176.405182\r\nPass 92, Batch 3, Cost 247.817673\r\nPass 92, Batch 4, Cost 11239.422852\r\nPass 92, Batch 5, Cost 26545.337891\r\nPass 93, Batch 0, Cost 45.774612\r\nPass 93, Batch 1, Cost 48.046532\r\nPass 93, Batch 2, Cost 185.294937\r\nPass 93, Batch 3, Cost 261.872894\r\nPass 93, Batch 4, Cost 11091.913086\r\nPass 93, Batch 5, Cost 26252.603516\r\nPass 94, Batch 0, Cost 47.252724\r\nPass 94, Batch 1, Cost 51.204491\r\nPass 94, Batch 2, Cost 194.267410\r\nPass 94, Batch 3, Cost 276.138031\r\nPass 94, Batch 4, Cost 10946.722656\r\nPass 94, Batch 5, Cost 25963.841797\r\nPass 95, Batch 0, Cost 48.699574\r\nPass 95, Batch 1, Cost 54.397942\r\nPass 95, Batch 2, Cost 203.314148\r\nPass 95, Batch 3, Cost 290.600891\r\nPass 95, Batch 4, Cost 10803.809570\r\nPass 95, Batch 5, Cost 25678.986328\r\nPass 96, Batch 0, Cost 50.114002\r\nPass 96, Batch 1, Cost 57.622173\r\nPass 96, Batch 2, Cost 212.427643\r\nPass 96, Batch 3, Cost 305.249725\r\nPass 96, Batch 4, Cost 10663.138672\r\nPass 96, Batch 5, Cost 25397.978516\r\nPass 97, Batch 0, Cost 51.493916\r\nPass 97, Batch 1, Cost 60.872307\r\nPass 97, Batch 2, Cost 221.600769\r\nPass 97, Batch 3, Cost 320.073914\r\nPass 97, Batch 4, Cost 10524.663086\r\nPass 97, Batch 5, Cost 25120.755859\r\nPass 98, Batch 0, Cost 52.838322\r\nPass 98, Batch 1, Cost 64.144127\r\nPass 98, Batch 2, Cost 230.826340\r\nPass 98, Batch 3, Cost 335.062134\r\nPass 98, Batch 4, Cost 10388.354492\r\nPass 98, Batch 5, Cost 24847.261719\r\nPass 99, Batch 0, Cost 54.145802\r\nPass 99, Batch 1, Cost 67.433212\r\nPass 99, Batch 2, Cost 240.098190\r\nPass 99, Batch 3, Cost 350.204529\r\nPass 99, Batch 4, Cost 10254.166992\r\nPass 99, Batch 5, Cost 24577.437500\r\nPass 100, Batch 0, Cost 55.415184\r\nPass 100, Batch 1, Cost 70.735352\r\nPass 100, Batch 2, Cost 249.409180\r\nPass 100, Batch 3, Cost 365.490784\r\nPass 100, Batch 4, Cost 10122.065430\r\nPass 100, Batch 5, Cost 24311.222656",
        "state": "closed",
        "user": "cdliheng",
        "closed_by": "shanyi15",
        "created_at": "2018-02-17T10:09:39+00:00",
        "updated_at": "2018-08-15T09:15:21+00:00",
        "closed_at": "2018-08-15T09:15:21+00:00",
        "comments_count": [
            "yeyupiaoling",
            "cdliheng",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 488,
        "title": "请修改官网中文版book的左侧导航栏“新手入门”",
        "body": "![image](https://user-images.githubusercontent.com/35982308/36709986-f764d91e-1bb5-11e8-8d33-24f92718379e.png)\r\n“线性回归”在左侧导航栏里是“新手入门”，建议左侧导航栏也一并改为“线性回归”\r\n谢谢！",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "luotao1",
        "created_at": "2018-02-27T04:02:22+00:00",
        "updated_at": "2018-02-28T06:56:12+00:00",
        "closed_at": "2018-02-28T06:56:12+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 494,
        "title": "Translation to Spanish",
        "body": "I would like to contribute to your project by translating into Spanish if there is any content that needs that kind of work.. :+1: ",
        "state": "closed",
        "user": "Santu41",
        "closed_by": "shanyi15",
        "created_at": "2018-03-03T05:12:32+00:00",
        "updated_at": "2018-08-15T09:15:17+00:00",
        "closed_at": "2018-08-15T09:15:17+00:00",
        "comments_count": [
            "daming-lu",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 496,
        "title": "import fluid error",
        "body": "Hi all, \r\n\r\nI use `nvidia-docker run -d -p 8888:8888 docker.paddlepaddlehub.com/book:latest-gpu` to run a docker container on my GPU.\r\nWhen I run the code as follow:\r\n```\r\nimport paddle.v2 as paddle\r\nimport paddle.fluid as fluid\r\n```\r\nIt raised a exception: `ImportError: No module named fluid`. \r\n\r\nBut when I use `docker run -d -p 8888:8888 docker.paddlepaddlehub.com/book`  to run a docker container on my CPU. \r\nI run the code and it goes well.  why there is a difference between them? \r\nthanks\r\n",
        "state": "closed",
        "user": "buaawht",
        "closed_by": "shanyi15",
        "created_at": "2018-03-14T11:13:39+00:00",
        "updated_at": "2018-08-15T09:15:10+00:00",
        "closed_at": "2018-08-15T09:15:10+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 495,
        "title": "book/04.word2vec/的demo程序出错",
        "body": "I0311 18:32:50.721074 3406201792 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=3 \r\nI0311 18:32:51.937851 3406201792 GradientMachine.cpp:85] Initing parameters..\r\nI0311 18:32:51.954010 3406201792 GradientMachine.cpp:92] Init parameters done.\r\nThread [0x70000f129000] Forwarding __fc_layer_0__, \r\n*** Aborted at 1520764372 (unix time) try \"date -d @1520764372\" if you are using GNU date ***\r\n\r\nPC: @                0x0 (unknown)\r\n\r\n*** SIGBUS (@0x70000f0a88f0) received by PID 26709 (TID 0x70000f129000) stack trace: ***\r\n\r\n    @     0x7fffc2363b3a _sigtramp\r\n\r\n    @        0x110841d91 sgemm_thread_nn\r\n\r\n    @        0x11072a247 cblas_sgemm\r\n\r\n    @        0x1106562d5 paddle::gemm<>()\r\n\r\n    @        0x1106688ba paddle::CpuMatrix::mul()\r\n\r\n    @        0x110454a6e paddle::FullyConnectedLayer::forward()\r\n\r\n    @        0x1104a674e paddle::NeuralNetwork::forward()\r\n\r\n    @        0x1104b1a14 paddle::TrainerThread::forward()\r\n\r\n    @        0x1104b1780 paddle::TrainerThread::computeThread()\r\n\r\n    @        0x1104b5230 _ZNSt3__114__thread_proxyINS_5tupleIJZN6paddle13TrainerThread5startEvE3$_1EEEEEPvS6_\r\n\r\n    @     0x7fffc236d93b _pthread_body\r\n\r\n    @     0x7fffc236d887 _pthread_start\r\n[Finished in 2.9s]",
        "state": "closed",
        "user": "iamadog3333",
        "closed_by": "shanyi15",
        "created_at": "2018-03-11T10:38:21+00:00",
        "updated_at": "2018-08-15T09:15:14+00:00",
        "closed_at": "2018-08-15T09:15:14+00:00",
        "comments_count": [
            "iamadog3333",
            "iamadog3333",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 497,
        "title": "建议增加运动姿态识别分类的例子",
        "body": "建议增加基于时间序列的传感器数据的识别运动姿态分类的例子，帮助大家学习使用。\r\n这里有一些相关资料和论文索引 \r\nhttps://github.com/jindongwang/activityrecognition",
        "state": "closed",
        "user": "realsnake",
        "closed_by": "shanyi15",
        "created_at": "2018-03-14T12:26:28+00:00",
        "updated_at": "2023-11-05T14:48:08+00:00",
        "closed_at": "2018-08-15T09:15:04+00:00",
        "comments_count": [
            "shanyi15",
            "NHZlX",
            "realsnake",
            "NHZlX",
            "realsnake",
            "shanyi15",
            "cernard"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 498,
        "title": "paddlepaddle在mac环境下安装运行遇到2个问题",
        "body": "1.本地安装 提示缺少 _swig_paddle动态库，这个库可以从哪儿获得？\r\n2.docker中安装，图片识别教程需要显示图像时，提示没有tkinter，安装_tkinter后又提示没有DISPLAY，一番研究之后，发现是一个在docker中显示GUI的问题。按照这个文档https://medium.com/@dimitris.kapanidis/running-gui-apps-in-docker-containers-3bd25efa862a 可以在docker中运行firefox，但是我们的paddle教程的例子没有错误提示了，但是没有显示出图像。\r\n先暂停一下，总结梳理后再重新搞。",
        "state": "closed",
        "user": "DAVINDAI",
        "closed_by": "shanyi15",
        "created_at": "2018-03-15T02:03:56+00:00",
        "updated_at": "2018-08-15T09:15:00+00:00",
        "closed_at": "2018-08-15T09:15:00+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 499,
        "title": "mac本地安装 提示缺少 _swig_paddle动态库，这个库可以从哪儿获得?",
        "body": "mac本地安装 提示缺少 _swig_paddle动态库，这个库可以从哪儿获得?",
        "state": "closed",
        "user": "DAVINDAI",
        "closed_by": "shanyi15",
        "created_at": "2018-03-17T10:22:07+00:00",
        "updated_at": "2018-08-15T09:14:57+00:00",
        "closed_at": "2018-08-15T09:14:57+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 500,
        "title": "docker 中运行教程中的图像代码，图形化的训练过程显示不出来",
        "body": "`from paddle.v2.plot import Ploter\r\n\r\ntrain_title = \"Train cost\"\r\ntest_title = \"Test cost\"\r\ncost_ploter = Ploter(train_title, test_title)\r\n\r\n\r\nstep = 0\r\ndef event_handler_plot(event):\r\n    global step\r\n    if isinstance(event, paddle.event.EndIteration):\r\n        if step % 1 == 0:\r\n            cost_ploter.append(train_title, step, event.cost)\r\n            cost_ploter.plot()\r\n        step += 1\r\n    if isinstance(event, paddle.event.EndPass):\r\n\r\n        result = trainer.test(\r\n            reader=paddle.batch(\r\n                paddle.dataset.cifar.test10(), batch_size=128),\r\n            feeding=feeding)\r\n        cost_ploter.append(test_title, step, result.cost)`\r\n\r\n`# End batch and end pass event handler\r\ndef event_handler(event):\r\n    if isinstance(event, paddle.event.EndIteration):\r\n        if event.batch_id % 100 == 0:\r\n            print \"\\nPass %d, Batch %d, Cost %f, %s\" % (\r\n                event.pass_id, event.batch_id, event.cost, event.metrics)\r\n        else:\r\n            sys.stdout.write('.')\r\n            sys.stdout.flush()\r\n    if isinstance(event, paddle.event.EndPass):\r\n        # save parameters\r\n        with open('params_pass_%d.tar' % event.pass_id, 'w') as f:\r\n            trainer.save_parameter_to_tar(f)\r\n\r\n        result = trainer.test(\r\n            reader=paddle.batch(\r\n                paddle.dataset.cifar.test10(), batch_size=128),\r\n            feeding=feeding)\r\n        print \"\\nTest with Pass %d, %s\" % (event.pass_id, result.metrics)`\r\n ##这段代码的运行结果显示不出来。\r\n\r\n",
        "state": "closed",
        "user": "DAVINDAI",
        "closed_by": "shanyi15",
        "created_at": "2018-03-17T10:26:08+00:00",
        "updated_at": "2018-08-15T09:14:54+00:00",
        "closed_at": "2018-08-15T09:14:54+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 510,
        "title": "paddlepaddle/paddle:latest-noavx-openblas镜像下添加en_US.UTF-8字符集报错",
        "body": "`paddlepaddle/paddle:latest-noavx-openblas`镜像下  \r\n执行`localedef -c -f UTF-8 -i en_US en_US.UTF-8`会出现错误  \r\n错误信息为：    \r\n\"character map file `UTF-8' not found: No such file or directory  \r\ncannot read character map directory `/usr/share/i18n/charmaps': No such file or directory\"",
        "state": "closed",
        "user": "Zhaoyangzhen",
        "closed_by": "Zhaoyangzhen",
        "created_at": "2018-04-12T09:38:50+00:00",
        "updated_at": "2018-04-22T10:08:28+00:00",
        "closed_at": "2018-04-22T10:08:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 501,
        "title": "machine_translation中案例出现Cost nan现象",
        "body": "machine_translation中案例出现Cost nan现象，厂内0.10.0-gpu-book镜像，用nvidia-docker,版本是Docker version 1.11.2, build b9f10c9",
        "state": "closed",
        "user": "zqmath1994",
        "closed_by": "shanyi15",
        "created_at": "2018-03-21T03:23:46+00:00",
        "updated_at": "2018-08-15T09:07:53+00:00",
        "closed_at": "2018-08-15T09:07:53+00:00",
        "comments_count": [
            "typhoonzero",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 502,
        "title": "typo in 02.recognize_digits fig. 4",
        "body": "![image](https://user-images.githubusercontent.com/143647/37700624-3cae018a-2d27-11e8-94a8-333dfc3d5bd7.png)\r\n\r\nhttps://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/image/conv_layer.png",
        "state": "closed",
        "user": "wanglun",
        "closed_by": "shanyi15",
        "created_at": "2018-03-21T08:47:32+00:00",
        "updated_at": "2018-03-22T04:15:51+00:00",
        "closed_at": "2018-03-22T04:15:28+00:00",
        "comments_count": [
            "shanyi15",
            "shanyi15",
            "wanglun",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 508,
        "title": "AVX 指令集问题",
        "body": "官方提供的 pip 安装方法和 docker 镜像都默认带有 AVX 指令集，有没有不带默认 AVX 指令集的镜像呢？源码编译一次需要好长时间。",
        "state": "closed",
        "user": "memory-overflow",
        "closed_by": "shanyi15",
        "created_at": "2018-04-08T10:17:33+00:00",
        "updated_at": "2018-08-15T09:07:49+00:00",
        "closed_at": "2018-08-15T09:07:49+00:00",
        "comments_count": [
            "typhoonzero",
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 503,
        "title": "paddle.init(use_gpu=False, trainer_count=1) 出现错误",
        "body": "import paddle.v2 as paddle\r\npaddle.init(use_gpu=False, trainer_count=1) 出现错误\r\n```\r\n\r\nRuntimeErrorTraceback (most recent call last)\r\nRuntimeError: module compiled against API version 0xb but this version of numpy is 0xa\r\n\r\nImportErrorTraceback (most recent call last)\r\n<ipython-input-22-c695be438938> in <module>()\r\n----> 1 paddle.init(use_gpu=False, trainer_count=1)\r\n\r\n/opt/conda/lib/python2.7/site-packages/paddle/v2/__init__.pyc in init(**kwargs)\r\n    117 \r\n    118 def init(**kwargs):\r\n--> 119     import py_paddle.swig_paddle as api\r\n    120     args = []\r\n    121     args_dict = {}\r\n\r\n/opt/conda/lib/python2.7/site-packages/py_paddle/__init__.py in <module>()\r\n     13 # limitations under the License.\r\n     14 \r\n---> 15 from util import DataProviderWrapperConverter\r\n     16 from dataprovider_converter import DataProviderConverter\r\n     17 \r\n\r\n/opt/conda/lib/python2.7/site-packages/py_paddle/util.py in <module>()\r\n     16 \"\"\"\r\n     17 \r\n---> 18 import swig_paddle\r\n     19 import os\r\n     20 import paddle.trainer.PyDataProviderWrapper\r\n\r\n/opt/conda/lib/python2.7/site-packages/py_paddle/swig_paddle.py in <module>()\r\n     26                 fp.close()\r\n     27             return _mod\r\n---> 28     _swig_paddle = swig_import_helper()\r\n     29     del swig_import_helper\r\n     30 else:\r\n\r\n/opt/conda/lib/python2.7/site-packages/py_paddle/swig_paddle.py in swig_import_helper()\r\n     22         if fp is not None:\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_swig_paddle', fp, pathname, description)\r\n     25             finally:\r\n     26                 fp.close()\r\n\r\nImportError: numpy.core.multiarray failed to import\r\n\r\n```\r\n\r\npython version: Python 2.7.14 :: Anaconda, Inc.\r\nnumpy version: numpy-1.12.1\r\n",
        "state": "closed",
        "user": "wangxiaobaidu11",
        "closed_by": "typhoonzero",
        "created_at": "2018-03-21T10:01:42+00:00",
        "updated_at": "2018-03-22T02:16:10+00:00",
        "closed_at": "2018-03-22T02:16:02+00:00",
        "comments_count": [
            "wangxiaobaidu11",
            "wangxiaobaidu11",
            "typhoonzero",
            "typhoonzero",
            "wangxiaobaidu11",
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 511,
        "title": "paddle book机器翻译BLEU值",
        "body": "我按照paddle book上机器翻译的例子用作者提供的训练好的模型进行预测，并计算了一下BLEU值，发现这个BLEU值与作者说的26.92差距太大，我测出来是3.37。请问是什么问题呢？\r\n\r\npaddle book NMT的链接： http://paddlepaddle.org/docs/develop/book/08.machine_translation/index.cn.html",
        "state": "closed",
        "user": "hjchen2",
        "closed_by": "luotao1",
        "created_at": "2018-04-17T07:00:45+00:00",
        "updated_at": "2018-04-18T03:36:00+00:00",
        "closed_at": "2018-04-18T03:36:00+00:00",
        "comments_count": [
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 512,
        "title": "capi v2 设置多线程，结果只调用了一个processor",
        "body": "![2018-04-18 10 36 01](https://user-images.githubusercontent.com/22136543/38908752-56c1355a-42f4-11e8-81d0-e3b69a51dc41.png)\r\n问题如图，设置了16个thread，速度比单线程还慢，发现只用了一个processor。",
        "state": "closed",
        "user": "hyo009",
        "closed_by": "shanyi15",
        "created_at": "2018-04-18T02:37:31+00:00",
        "updated_at": "2018-08-15T09:07:46+00:00",
        "closed_at": "2018-08-15T09:07:46+00:00",
        "comments_count": [
            "dzhwinter",
            "hyo009",
            "dzhwinter",
            "shanyi15"
        ],
        "labels": [
            "usr"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 513,
        "title": "没有 avx 指令集的能在 centos 上用的 paddlepaddle 镜像到底要怎么装！",
        "body": "没有 avx 指令集的能在 centos 上用的 paddlepaddle 镜像到底要怎么装！",
        "state": "closed",
        "user": "Zhaoyangzhen",
        "closed_by": "Zhaoyangzhen",
        "created_at": "2018-04-20T06:34:35+00:00",
        "updated_at": "2018-04-22T10:08:10+00:00",
        "closed_at": "2018-04-22T10:08:10+00:00",
        "comments_count": [
            "Zhaoyangzhen",
            "Zhaoyangzhen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 516,
        "title": "DSSM训练不收敛",
        "body": "models里面的DSSM模型训练不收敛，请问是否有案例成功将models里面的DSSM模型训练收敛？",
        "state": "closed",
        "user": "chengxiaohua1105",
        "closed_by": "shanyi15",
        "created_at": "2018-05-03T06:16:02+00:00",
        "updated_at": "2018-08-15T09:07:42+00:00",
        "closed_at": "2018-08-15T09:07:42+00:00",
        "comments_count": [
            "JiayiFeng",
            "chengxiaohua1105",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 517,
        "title": "production docker file failed at copying pserver to /usr/bin",
        "body": "I was using paddle_build.sh to generate dockerfile in build dir, my build was conducted with WITH_GOLANG=OFF. which means paserver and master bin will not be generated, but looks when I run paddle_build.sh dockerfile, it still generates the line as follows:\r\n\r\n``` dockerfile\r\nADD go/cmd/pserver/pserver /usr/bin/\r\nADD go/cmd/master/master /usr/bin/\r\n```\r\nwhich fails the build process.\r\n\r\nI think this issue was fixed in non-paddle_build.sh script.",
        "state": "closed",
        "user": "putcn",
        "closed_by": "putcn",
        "created_at": "2018-05-04T18:51:54+00:00",
        "updated_at": "2018-05-04T18:54:52+00:00",
        "closed_at": "2018-05-04T18:54:52+00:00",
        "comments_count": [
            "putcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 518,
        "title": "build failed due to blas missing deps of operator",
        "body": "error msg:\r\nhttp://172.19.32.197:8111/viewLog.html?tab=buildLog&logTab=tree&filter=debug&expand=all&buildId=34973&_focus=2164\r\n\r\n```\r\n[11:01:37]\t[Step 1/4] [ 13%] Building CXX object paddle/fluid/operators/math/CMakeFiles/blas.dir/blas.cc.o\r\n[11:01:38]\t[Step 1/4] In file included from /paddle/paddle/fluid/framework/tensor.h:26:0,\r\n[11:01:38]\t[Step 1/4]                  from /paddle/paddle/fluid/framework/mixed_vector.h:21,\r\n[11:01:38]\t[Step 1/4]                  from /paddle/paddle/fluid/framework/lod_tensor.h:28,\r\n[11:01:38]\t[Step 1/4]                  from /paddle/paddle/fluid/framework/operator.h:28,\r\n[11:01:38]\t[Step 1/4]                  from /paddle/paddle/fluid/operators/math/blas.h:17,\r\n[11:01:38]\t[Step 1/4]                  from /paddle/paddle/fluid/operators/math/blas.cc:15:\r\n[11:01:38]\t[Step 1/4] /paddle/paddle/fluid/platform/device_context.h:26:22: fatal error: mkldnn.hpp: No such file or directory\r\n[11:01:38]\t[Step 1/4]  #include <mkldnn.hpp>\r\n[11:01:38]\t[Step 1/4]                       ^\r\n[11:01:38]\t[Step 1/4] compilation terminated.\r\n```\r\n",
        "state": "closed",
        "user": "putcn",
        "closed_by": "putcn",
        "created_at": "2018-05-04T21:23:54+00:00",
        "updated_at": "2018-05-04T21:26:54+00:00",
        "closed_at": "2018-05-04T21:26:54+00:00",
        "comments_count": [
            "putcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 521,
        "title": "`paddle.dataset.movielens.train()` should be `paddle.dataset.mnist.train()`",
        "body": "<img width=\"1016\" alt=\"screen shot 2018-05-07 at 3 14 52 pm\" src=\"https://user-images.githubusercontent.com/5635322/39727913-782d77c0-5209-11e8-997f-1ea055ab20c4.png\">\r\n",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "shanyi15",
        "created_at": "2018-05-07T22:18:08+00:00",
        "updated_at": "2018-08-15T09:07:38+00:00",
        "closed_at": "2018-08-15T09:07:38+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 522,
        "title": "Accuracy goes down with higher PASS_NUM",
        "body": "In PaddlePaddle's book chapter (Recommendation System), I tuned the PASS_NUM to be higher [here](https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/book/test_recommender_system.py#L218)\r\n\r\nBut the accuracy goes down... From `ml-1m` dataset, we can know the real rating from user 1 to movie 783 is 4\r\n\r\n`1::783::4::978824291`\r\n\r\nBut the experimental result never went pass 3 ...\r\n\r\n```python\r\n(Pdb) np.array(user_id)[0][0]\r\n1\r\n(Pdb) np.array(movie_id)[0][0]\r\n783\r\nNUM_PASS \r\n100\r\n('inferred score: ', array([[2.1509817]], dtype=float32))\r\n\r\n500\r\n('inferred score: ', array([[2.3413014]], dtype=float32))\r\n\r\n5000\r\n('inferred score: ', array([[2.3629897]], dtype=float32))\r\n\r\n500000\r\n('inferred score: ', array([[2.8035383]], dtype=float32))\r\n\r\n50000000 (because it is over 1M ???)\r\n('inferred score: ', array([[2.038723]], dtype=float32))\r\n\r\n1000000 (1M)\r\n('inferred score: ', array([[2.015883]], dtype=float32))\r\n\r\n```",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "shanyi15",
        "created_at": "2018-05-22T23:08:16+00:00",
        "updated_at": "2018-08-15T09:07:35+00:00",
        "closed_at": "2018-08-15T09:07:35+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 527,
        "title": "Cut a release branch for v2. ",
        "body": "As Paddle moving forward, `book` should also update its tutorial examples. We certainly want to keep the old example around as references. \r\n\r\nTherefore, we should cut a release version `release/0.10.0` now to indicate that all the existing example will work with `paddle 0.10.0`\r\n\r\nOnce the release branch is cut, we can freely update the example in `develop` with the fluid contents. This allows us to focus with the latest paddle fluid example and no long need to worry about v2 example. Of course, we still have the ability to update `v2` examples if necessary. If we need to update any `v2` example, we can still go back to the `release/0.10.0` branch to update the documentation.\r\n",
        "state": "closed",
        "user": "jetfuel",
        "closed_by": "shanyi15",
        "created_at": "2018-05-31T18:53:30+00:00",
        "updated_at": "2018-08-15T09:07:31+00:00",
        "closed_at": "2018-08-15T09:07:31+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 534,
        "title": "Using trained model in Word2Vec does not give any meaningful inference",
        "body": "After training the word2vec model using PaddlePaddle for about 1 hour, I used it to try to predict the next word of a sentence:\r\n\r\n`\r\na form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported \r\n`\r\n\r\n**among a group of** is part of the sentence. But the inference gave `2072`, which is `<unk>`. Note the sentence appears exactly in the training dataset (the 5th sentence).\r\n\r\n```python\r\n(Pdb) word_dict['among']\r\n211\r\n(Pdb) word_dict['a']\r\n6\r\n(Pdb) word_dict['group']\r\n96\r\n(Pdb) word_dict['of']\r\n4\r\n(Pdb) first_word = fluid.create_lod_tensor([[211]], [[1]], place)\r\n(Pdb) second_word = fluid.create_lod_tensor([[6]], [[1]], place)\r\n(Pdb) third_word = fluid.create_lod_tensor([[96]], [[1]], place)\r\n(Pdb) fourth_word = fluid.create_lod_tensor([[4]], [[1]], place)\r\n(Pdb) result = inferencer.infer({'firstw': first_word,'secondw': second_word,'thirdw': third_word,'fourthw': fourth_word},return_numpy=False)\r\n(Pdb) result_list = numpy.array(result[0])\r\n(Pdb) np.argmax(result_list[0])\r\n2072\r\n(Pdb) word_dict['<unk>']\r\n2072\r\n```\r\nI suspect the training data `imikolov` is not built correctly. `ptb.train.txt` file has `42068` sentences but the built `word_dict` only has 2073 words, including `a`, `the`, `<s>`, `<e>` and `<unk>`.\r\n\r\n",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "shanyi15",
        "created_at": "2018-06-06T01:16:26+00:00",
        "updated_at": "2018-08-15T09:07:27+00:00",
        "closed_at": "2018-08-15T09:07:27+00:00",
        "comments_count": [
            "daming-lu",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 537,
        "title": "06.understand_sentiment情感分析的demo，程序怎么读取我自己的数据？",
        "body": "",
        "state": "closed",
        "user": "wowuhuaihuai",
        "closed_by": "shanyi15",
        "created_at": "2018-06-07T08:00:36+00:00",
        "updated_at": "2018-08-15T09:07:24+00:00",
        "closed_at": "2018-08-15T09:07:24+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 543,
        "title": "请问paddle中对于load embeding的oov有设置初始化值的参数吗？",
        "body": "load embeding对于nlp任务应该是很常见的操作，一般初始化要么设全0，要么设置一个均值为0的正太分布，但是了解到ParameterAttribute里面的initial_*相关参数只在初始化的时候会用到，load已有词向量的话不生效。\r\n对于nlp任务，这应该是一个比较常见的操作，建议支持一下。",
        "state": "closed",
        "user": "bbgasj",
        "closed_by": "Yancey0623",
        "created_at": "2018-06-11T08:49:46+00:00",
        "updated_at": "2018-06-11T08:55:13+00:00",
        "closed_at": "2018-06-11T08:55:13+00:00",
        "comments_count": [
            "bbgasj",
            "Yancey0623"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 547,
        "title": "如何利用训练好的模型",
        "body": "\r\nbeam_result = paddle.infer(\r\n            output_layer=beam_gen,\r\n            parameters=parameters,\r\n            input=gen_data,\r\n            field=['prob', 'id'])\r\n\r\nbeam_gen  是什么？是gru_decoder_with_attention这个函数？这个函数的参数如何传入",
        "state": "closed",
        "user": "WangTaoSpace",
        "closed_by": "shanyi15",
        "created_at": "2018-06-15T01:19:21+00:00",
        "updated_at": "2018-08-15T09:07:21+00:00",
        "closed_at": "2018-08-15T09:07:21+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 551,
        "title": "capi正式化后的置信度获取",
        "body": "线下预测获取的每条prob的大小prob_size==beam_size，模型类似于：https://github.com/PaddlePaddle/book/tree/develop/08.machine_translation\r\n\r\n但是，使用capi正式化时使用如下方法得到的prob_size!=beam_size，貌似等于输出序列长度+beam_size，获取代码如下：\r\n￼\r\n![image](https://user-images.githubusercontent.com/6702524/41643910-347b6394-749f-11e8-99fb-2e59677aaafb.png)\r\n\r\n请问这是什么原因？我该怎么预测序列的概率？",
        "state": "closed",
        "user": "fmantianxing",
        "closed_by": "shanyi15",
        "created_at": "2018-06-20T07:35:40+00:00",
        "updated_at": "2018-08-15T09:06:17+00:00",
        "closed_at": "2018-08-15T09:06:17+00:00",
        "comments_count": [
            "JiayiFeng",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 557,
        "title": "08. 机器翻译 的 infer.py 会 crash",
        "body": "训练没问题，但是会 run 很久，所以没有等 run 完\r\n![screen shot 2018-06-22 at 6 52 21 pm](https://user-images.githubusercontent.com/5635322/41804646-44d55996-764f-11e8-84dc-8b8531c945b7.png)\r\n\r\n\r\ninfer.py 会 crash\r\n![screen shot 2018-06-22 at 6 52 40 pm](https://user-images.githubusercontent.com/5635322/41804648-48488256-764f-11e8-94f3-991285f5e445.png)\r\n\r\n\r\n我记得 infer 是不会用到 train 的结果的，那不知道为啥会crash。如果需要用到训练完的model，如果不大的话，能否提供在github里？这样能确保 infer 不 crash",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "shanyi15",
        "created_at": "2018-06-23T02:06:00+00:00",
        "updated_at": "2018-08-15T09:06:13+00:00",
        "closed_at": "2018-08-15T09:06:13+00:00",
        "comments_count": [
            "luotao1",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 568,
        "title": "关于“04.word2vec”JupyterNotebook版本README.cn的疑问和建议",
        "body": "以下提及的问题均是在通过docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入book后测试过程中遇到。\r\n\r\n#### 格式问题\r\n\r\n![png](https://user-images.githubusercontent.com/22561442/42570860-da25b85e-8547-11e8-9b58-51f94513b8cb.jpeg)\r\n![image](https://user-images.githubusercontent.com/22561442/42570861-dafcb0d4-8547-11e8-9355-0347fc863eba.png)\r\n\r\n这里不应该是code格式的\r\n\r\n#### 结果解释\r\n\r\n![image1](https://user-images.githubusercontent.com/22561442/42570913-01bdc79e-8548-11e8-922d-be49f443222c.png)\r\n\r\n这里的结果是否需要解释一下？\r\n",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-11T12:22:15+00:00",
        "updated_at": "2018-07-23T02:49:35+00:00",
        "closed_at": "2018-07-23T02:49:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 566,
        "title": "dssm双塔损失函数",
        "body": "看dssm电影推荐那个例子，我的目的是想得到vector，demo里损失函数是用的mse，但是我label里只有0和1，请问下paddle能实现如下的损失函数吗？用的是v2版本\r\n![image](https://user-images.githubusercontent.com/2037256/42455063-cc8821e4-83c3-11e8-9a3e-0f6d0e816bc7.png)\r\n",
        "state": "closed",
        "user": "zachzh",
        "closed_by": "AIpioneer",
        "created_at": "2018-07-09T14:04:48+00:00",
        "updated_at": "2019-06-19T05:58:47+00:00",
        "closed_at": "2019-06-19T05:58:04+00:00",
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 567,
        "title": "关于“03.image_classification”JupyterNotebook版本README.cn的一些疑问和建议",
        "body": "以下提及的问题均是在通过`docker run -d -p 8888:8888 paddlepaddle/book`启动相应Docker image，进入book后测试过程中遇到。\r\n\r\n### CPU训练（默认）\r\n\r\n#### 01. 词汇描述\r\n\r\n![png](https://user-images.githubusercontent.com/22561442/42569669-e5c4244c-8543-11e8-8883-d31555fa385e.jpeg)  \r\n  \r\n建议：这里是否应该改为“训练”？\r\n\r\n#### 02. 标题问题\r\n\r\n![image1](https://user-images.githubusercontent.com/22561442/42569771-3cc0752a-8544-11e8-995f-0ddff2cd16da.png)\r\n  \r\n建议：图片的标题能居中吗？居中阅读感受好一些\r\n\r\n#### 03. 训练测试结果\r\n\r\n![image](https://user-images.githubusercontent.com/22561442/42569741-2610c154-8544-11e8-9a3b-813f1f9b4df0.png)\r\n  \r\n实际的训练和测试效果比文本描述得要好。\r\n疑问：这里的结果差距是否在合理范围内？",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-11T12:04:26+00:00",
        "updated_at": "2018-07-23T02:49:49+00:00",
        "closed_at": "2018-07-23T02:49:49+00:00",
        "comments_count": [
            "chenwhql",
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 560,
        "title": "IndexError: list index out of range",
        "body": "<Figure size 600x400 with 0 Axes>\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-3-ceb20fca6c67>\", line 1, in <module>\r\n    runfile('/home/sleep/Recognize Digits.py', wdir='/home/sleep')\r\n\r\n  File \"/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py\", line 699, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py\", line 81, in execfile\r\n    builtins.execfile(filename, *where)\r\n\r\n  File \"/home/sleep/Recognize Digits.py\", line 132, in <module>\r\n    best = sorted(lists, key=lambda list: float(list[1]))[0]\r\nIndexError: list index out of range\r\n\r\nwhat happened?",
        "state": "closed",
        "user": "fkuner",
        "closed_by": "shanyi15",
        "created_at": "2018-06-29T04:04:57+00:00",
        "updated_at": "2018-08-15T09:02:49+00:00",
        "closed_at": "2018-08-15T09:02:49+00:00",
        "comments_count": [
            "typhoonzero",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 569,
        "title": "关于“02.recognize_digits”JupyterNotebook版本README.cn的疑问和建议",
        "body": "以下问题是以docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入book后测试过程中发生的，使用过程中希望分别通过CPU和GPU进行训练，但train with GPU未成功。\r\n\r\n1. 这里使用net0，net1不太合适，是否使用neural0, neural1更合适\r\n![2018-07-11 5 23 16](https://user-images.githubusercontent.com/22361972/42573271-3439f32c-854e-11e8-9701-b521b1684939.png)\r\n\r\n2. 损失交叉函数（cross entropy loss)是否应该应补全\r\n等号左边：Loss(cross entropy)是否更合适\r\n![2018-07-11 5 25 53](https://user-images.githubusercontent.com/22361972/42573867-d7d1a8bc-854f-11e8-91b7-d1d3827070f5.png)\r\n\r\n3. Softmax的准确率比叙述低2%，是否影响\r\n![2018-07-11 7 27 21](https://user-images.githubusercontent.com/22361972/42573914-f49f27bc-854f-11e8-977c-54c83ac05071.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiabinYang",
        "closed_by": "JiabinYang",
        "created_at": "2018-07-11T13:21:53+00:00",
        "updated_at": "2018-08-15T12:57:23+00:00",
        "closed_at": "2018-08-15T12:57:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 571,
        "title": "关于“05.recommender_system”Jupyter README.cn和train.py例程的建议",
        "body": "使用的时候分别体验了docker里JupyterNotebook版本，也直接运行了train.py脚本，这里从普通用户角度给出一些小建议。\r\n\r\n#### 01. Jupyter版本最后未打印预测结果，建议输出结果，并给出一定解释。\r\n\r\n![image](https://user-images.githubusercontent.com/22561442/42744098-582c31c6-88fc-11e8-83f8-cb20d5f91a78.png)\r\n\r\n例如，增加输出：\r\n\r\n![imag1e](https://user-images.githubusercontent.com/22561442/42744146-bcb7a8a0-88fc-11e8-9f1c-570f927c1906.png)\r\n\r\n\r\n#### 02. train.py脚本输出结果意义不明，建议规范格式，给出一定解释。\r\n\r\n![image2](https://user-images.githubusercontent.com/22561442/42744149-bff32508-88fc-11e8-9040-f2219b187efb.png)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-16T05:33:25+00:00",
        "updated_at": "2018-07-19T08:11:40+00:00",
        "closed_at": "2018-07-19T08:11:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 570,
        "title": "关于“06.understand_sentiment”JupyterNotebook版本README.cn的疑问和建议",
        "body": "以下提及的问题均是在通过docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入book后测试过程中遇到。\r\n\r\n#### 01. 图片标题格式\r\n![image1](https://user-images.githubusercontent.com/22561442/42611134-30979ae8-85c7-11e8-8e3c-e5fffd08d8ab.png)\r\n  \r\n建议：标题不换行阅读感受更好一些\r\n\r\n#### 02. CPU训练过程报错\r\n\r\n![image2](https://user-images.githubusercontent.com/22561442/42611233-b176127a-85c7-11e8-9816-d00ce04df971.png)\r\n\r\n执行到这里会报错，inferencer不能正常创建",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-12T03:42:21+00:00",
        "updated_at": "2018-07-19T08:11:23+00:00",
        "closed_at": "2018-07-19T08:11:23+00:00",
        "comments_count": [
            "chenwhql",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 572,
        "title": "关于“01.fit_a_line”JupyterNotebook版本README.cn的疑问和建议",
        "body": "以下提及的问题均是在通过docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入book后测试过程中遇到。\r\n\r\n1. 这里路径直接使用directory表达就可以，不需要加path\r\n![2018-07-12 9 37 57](https://user-images.githubusercontent.com/22361972/42752959-0a28f02e-8922-11e8-91d3-8a6233233f9e.png)\r\n2. 正常的英语表达应该是“record the test cost every 10 seconds”\r\n![2018-07-12 9 39 35](https://user-images.githubusercontent.com/22361972/42752969-0fb31fce-8922-11e8-964b-504be8126669.png)\r\n3. 注释改为 event_handler prints training and testing info\r\n![2018-07-13 1 55 47](https://user-images.githubusercontent.com/22361972/42752980-1a65f6a8-8922-11e8-9b9c-d47114660017.png)\r\n4. 这个预测结果是否需要解释一下\r\n![2018-07-13 2 04 20](https://user-images.githubusercontent.com/22361972/42752995-22fe56d4-8922-11e8-993e-5bbd69169408.png)\r\n5. 当完成上一个book后，进入下一个book，在gpu运行的情况下会出现如下问题\r\n![2018-07-16 12 08 35](https://user-images.githubusercontent.com/22361972/42753010-2fe9c36a-8922-11e8-97c1-24a8bf72cd13.png)\r\n而gpu监控显示，显存未被占用\r\n![2018-07-16 12 08 28](https://user-images.githubusercontent.com/22361972/42753018-37659d08-8922-11e8-88f9-8663301810df.png)\r\n\t解决方法：正确的操作为在Running中找到对应在运行的book，然后点击shutdown之后再运行下一个book。这里是否应该在文档中说明\r\n",
        "state": "closed",
        "user": "JiabinYang",
        "closed_by": "JiabinYang",
        "created_at": "2018-07-16T10:01:46+00:00",
        "updated_at": "2018-07-23T02:49:40+00:00",
        "closed_at": "2018-07-23T02:49:40+00:00",
        "comments_count": [
            "JiabinYang",
            "luotao1",
            "JiabinYang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 573,
        "title": "关于“07.label_semantic_roles”JupyterNotebook版本README.cn的疑问和建议",
        "body": "以下提及的问题均是在通过docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入book后测试过程中遇到。\r\n\r\n1. 当二次运行教程代码后会出现以下错误\r\n![2018-07-16 7 51 41](https://user-images.githubusercontent.com/22361972/42757476-d5c58868-8932-11e8-9474-5165411e5928.png)\r\n",
        "state": "closed",
        "user": "JiabinYang",
        "closed_by": "chenwhql",
        "created_at": "2018-07-16T12:00:22+00:00",
        "updated_at": "2018-07-19T08:11:09+00:00",
        "closed_at": "2018-07-19T08:11:09+00:00",
        "comments_count": [
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 574,
        "title": "关于“08.machine_translation”JupyterNotebook版本README.cn的疑问和建议",
        "body": "通过docker run -d -p 8888:8888 paddlepaddle/book启动相应Docker image，进入jupyter notebook的使用版本存在公式显示不正确的问题。\r\n\r\n![default](https://user-images.githubusercontent.com/22561442/42759190-a7f381be-8938-11e8-9313-e06e99d4a344.png)\r\n\r\n",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-16T12:42:09+00:00",
        "updated_at": "2018-07-19T08:10:52+00:00",
        "closed_at": "2018-07-19T08:10:52+00:00",
        "comments_count": [
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 575,
        "title": "PaddlePaddle book使用体验总结",
        "body": "### 使用感受\r\n- 优点：绝大部分例程均正确执行，配合图文讲解，易于理解\r\n- 缺点：个别例程存在一些问题，建议完善一些文字与结果描述的细节\r\n\r\n### 使用环境说明：\r\n##### JupyterNoteBook版本（CPU & GPU）\r\n- 根据文档建议，运行  \r\n`docker run -d -p 8888:8888 paddlepaddle/book`  \r\n或  \r\n`nvidia-docker run -d -p 8888:8888 paddlepaddle/book:latest-gpu`  \r\n然后在Jupyter Notebook中结合教程运行\r\n##### Fluid Docker版本（CPU & GPU）：\r\n- 根据官网Paddle安装建议，使用docker安装GPU版本镜像  \r\n`docker pull paddlepaddle/paddle:latest-gpu`  \r\n然后在docker中执行PaddlePaddle book的train.py脚本\r\n\r\n### 教程体验\r\n#### 01. 线性回归\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[注释完善、测试结果、显存占用等](https://github.com/PaddlePaddle/book/issues/572)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 02. 数字识别\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议： [文档表述完善、测试结果等](https://github.com/PaddlePaddle/book/issues/569)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 03. 图像分类\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[词汇使用、图片标题显示、测试结果等](https://github.com/PaddlePaddle/book/issues/567)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 04. 词向量\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[误用Code格式、测试结果等](https://github.com/PaddlePaddle/book/issues/568)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 05. 个性化推荐\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[结尾未打印测试结果](https://github.com/PaddlePaddle/book/issues/571)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n- 完善建议：[result显示格式意义不明](https://github.com/PaddlePaddle/book/issues/571)\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 06. 情感分析\r\n##### JupyterNoteBook版本（CPU）\r\n- 运行结果：\r\n    - convolution_net：**失败**，[【bug】inferencer未成功创建](https://github.com/PaddlePaddle/book/issues/570)\r\n    - stacked_lstm_net：**缺少参数**\r\n- 完善建议：[图片标题居中](https://github.com/PaddlePaddle/book/issues/570)\r\n##### JupyterNoteBook版本（GPU）：**失败**，错误同CPU\r\n##### Fluid Docker版本（CPU）\r\n- 运行结果：\r\n    - convolution_net：成功\r\n    - dyn_rnn_net: 成功\r\n    - stacked_lstm_net: 成功\r\n##### Fluid Docker版本（GPU）\r\n- 运行结果：\r\n    - convolution_net：成功\r\n    - dyn_rnn_net: 成功\r\n    - stacked_lstm_net: 成功\r\n\r\n#### 07. 语义角色标注\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[图片标题居中、二次执行报错等](https://github.com/PaddlePaddle/book/issues/573)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n#### 08. 机器翻译\r\n##### JupyterNoteBook版本（CPU）：成功\r\n- 完善建议：[公式格式等](https://github.com/PaddlePaddle/book/issues/574)\r\n##### JupyterNoteBook版本（GPU）：成功\r\n##### Fluid Docker版本（CPU）：成功\r\n##### Fluid Docker版本（GPU）：成功\r\n\r\n\r\n### 综合建议\r\n1. 是否可以完善jupyter Notebook版本的格式问题（均已在issue中提出）\r\n    - 标题未居中（8个教程均存在）\r\n    - 部分code与description的格式混乱（04）\r\n> 作为一个普通用户，会优先按照首页README的使用描述 ，进入docker体验例程，所以需要优先保证jupyter Notebook版本的易用性和专业性，及时同步\r\n\r\n2. 是否可以对于最后的预测结果做下简要的解释\r\n    - （01-08均可以完善）\r\n> 实验中最后的预测结果往往是一对数字，并没有给出有意义的解释，因为这里的例程带有一定教学性质，解释不充分对于用户理解来说是不太友好的\r\n\r\n3. 对于用户开发的简洁性优化\r\n> book中例如param_dirname的部分应通过封装避免用户重复输入相同的文件后缀名如\".inference.model\"",
        "state": "closed",
        "user": "chenwhql",
        "closed_by": "chenwhql",
        "created_at": "2018-07-16T12:59:48+00:00",
        "updated_at": "2019-12-13T03:57:34+00:00",
        "closed_at": "2019-12-13T03:57:34+00:00",
        "comments_count": [
            "xsrobin",
            "zhengxijiang",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 585,
        "title": "情感分析的问题",
        "body": "我就做了一个小实验。就是用 one word 来做训练和预测。训练集采用 1905 个正面面词汇和 4658 个负面词汇（如附件所示）。训练过后用5+/5- 的词汇来预测。居然结果是同一个。。。参看  [output_log.txt](https://github.com/PaddlePaddle/book/files/2242153/output_log.txt)。 我觉得情感分析这一章的模型可能有问题。要么是模型搭建有错，更有可能的是Paddle本身的计算有bug。能不能请Paddle的工程师们，先尝试复现一下 情感分析这章的demo程序，预测用例就用10个训练集里面的review就好，看看能不能达到 Paddle report 的精度。比如Paddle Acc 0.82， 那么10个review应该能对8个左右。\r\n \r\n多谢啦！",
        "state": "closed",
        "user": "daming-lu",
        "closed_by": "chenwhql",
        "created_at": "2018-07-30T17:12:14+00:00",
        "updated_at": "2020-01-08T12:45:24+00:00",
        "closed_at": "2020-01-08T12:45:24+00:00",
        "comments_count": [
            "kuke",
            "chenwhql",
            "chenwhql",
            "kuke",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 589,
        "title": "情感分析运行两遍Paddle.init()就会出core",
        "body": "\r\n![image](https://user-images.githubusercontent.com/37108001/44041905-83cafe1e-9f51-11e8-93b6-a324d1f7bb8a.png)\r\n这一段如果运行两次, 就会让notebook的内核crush掉. \r\n\r\n错误日志是:\r\n![image](https://user-images.githubusercontent.com/37108001/44041940-9975bbbe-9f51-11e8-9e27-2fecf1e94dfb.png)\r\n",
        "state": "open",
        "user": "weiexcelpro",
        "closed_by": null,
        "created_at": "2018-08-13T15:35:58+00:00",
        "updated_at": "2018-08-30T04:17:57+00:00",
        "closed_at": null,
        "comments_count": [
            "chenwhql",
            "weiexcelpro",
            "chenwhql",
            "cheradam",
            "weiexcelpro",
            "chenwhql",
            "chenwhql"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 596,
        "title": "关于01.fit line JupyterNotebook版本README的疑问",
        "body": "1. 英文版 README中，运行docker打开时，数据集说明表格的格式有误，在我的机器上显示效果为：\r\n![default](https://user-images.githubusercontent.com/31891223/44212158-31aa9380-a19d-11e8-9582-b9882ed821f7.png)\r\n\r\n是否需要将此处改为“ \\\\$10,000”?（github预览时没有问题）\r\n![default](https://user-images.githubusercontent.com/31891223/44212000-c6f95800-a19c-11e8-92bd-304ae563d532.png)\r\n",
        "state": "closed",
        "user": "tink2123",
        "closed_by": "tink2123",
        "created_at": "2018-08-16T13:44:20+00:00",
        "updated_at": "2018-08-31T09:08:37+00:00",
        "closed_at": "2018-08-31T09:08:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 591,
        "title": "建议增加图像识别model--update",
        "body": "建议增加图像识别model",
        "state": "closed",
        "user": "kagome112",
        "closed_by": "shanyi15",
        "created_at": "2018-08-14T10:28:25+00:00",
        "updated_at": "2018-08-15T08:51:13+00:00",
        "closed_at": "2018-08-14T10:53:12+00:00",
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 600,
        "title": "关于06.understand_sentiment JupyterNotebook版本README的疑问",
        "body": "1. 使用trainer.tain开始训练时，kernel会崩溃。重启也会出现同样的错误，如下所示：\r\n![default](https://user-images.githubusercontent.com/31891223/44255521-f3fb4880-a238-11e8-9c03-f180eab7ce0f.png)\r\n",
        "state": "closed",
        "user": "tink2123",
        "closed_by": "tink2123",
        "created_at": "2018-08-17T08:20:32+00:00",
        "updated_at": "2018-08-31T09:08:25+00:00",
        "closed_at": "2018-08-31T09:08:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 603,
        "title": "PaddlePaddle/book正确性验证",
        "body": "## 使用环境说明：\r\nJupyterNoteBook版本（CPU）\r\n\r\n- 根据文档建议，运行\r\n`docker run -d -p 7777:8888 docker.paddlepaddlehub.com/book`\r\n\r\n- 05-08 为保证更新状态，运行\r\n`docker run -d -p 8888:8888 paddlepaddle/book`\r\n\r\n## 使用体验：\r\n\r\n**01.线性回归**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正：[英文版数据集说明list格式有误。](https://github.com/PaddlePaddle/book/issues/596)\r\n\r\n**02.数字识别**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正： 无\r\n\r\n**03. 图像分类**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正： 无\r\n\r\n**04.词向量**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正：[相似度效果展示、输出结果与文字描述不一致](https://github.com/PaddlePaddle/book/issues/598)\r\n\r\n**05. 个性化推荐**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n- 文档修正：修改了文档中的错别字\r\n\r\n**06. 情感分析**\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正：暂无\r\n\r\n**07. 语义角色标注**\r\n\r\n\r\n- NoteBook（cpu）运行结果：成功\r\n\r\n- 文档修正： 无\r\n\r\n**08. 机器翻译**\r\n\r\n\r\n- NoteBook（cpu）运行结果：[失败——预测时无法正确输出](https://github.com/PaddlePaddle/book/issues/602)\r\n\r\n- 文档修正：暂无\r\n\r\n\r\n",
        "state": "closed",
        "user": "tink2123",
        "closed_by": "tink2123",
        "created_at": "2018-08-17T09:07:00+00:00",
        "updated_at": "2018-08-31T09:08:10+00:00",
        "closed_at": "2018-08-31T09:08:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 602,
        "title": "关于08.machine_translation JupyterNotebook版本README的疑问",
        "body": "1. 预测时输出有误\r\n![default](https://user-images.githubusercontent.com/31891223/44257824-c960be00-a23f-11e8-950f-656e0f514ba8.png)\r\n\r\n",
        "state": "closed",
        "user": "tink2123",
        "closed_by": "tink2123",
        "created_at": "2018-08-17T09:06:12+00:00",
        "updated_at": "2018-08-31T09:08:19+00:00",
        "closed_at": "2018-08-31T09:08:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 598,
        "title": "关于04.word2vec  JupyterNotebook版本README的疑问",
        "body": "1. README.cn词向量效果展示中，词向量相关性的输出结果是否是写反了呢？\r\n\r\n文档中为：\r\n\r\n```\r\nsimilarity: 0.899180685161\r\nplease input two words: big huge\r\n\r\nplease input two words: from company\r\nsimilarity: -0.0997506977351\r\n```\r\n\r\n是否应改成：\r\n\r\n```\r\nplease input two words: big huge\r\nsimilarity: 0.899180685161\r\n\r\nplease input two words: from company\r\nsimilarity: -0.0997506977351\r\n```\r\n\r\n2. 最终跑完代码预测结果与文字表述不同，得到的是停止符<e>而非字母，需要调整嘛？\r\n\r\n![default](https://user-images.githubusercontent.com/31891223/44249426-5f85eb80-a222-11e8-800b-729b90923acd.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "tink2123",
        "closed_by": "tink2123",
        "created_at": "2018-08-17T04:44:14+00:00",
        "updated_at": "2020-12-02T08:40:37+00:00",
        "closed_at": "2018-08-31T09:08:31+00:00",
        "comments_count": [
            "201901"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 609,
        "title": "0.14版本下 08.machine_translation infer无法运行",
        "body": "```\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 210, in <module>\r\n    main(use_cuda)\r\n  File \"infer.py\", line 205, in main\r\n    decode_main(False)  # Beam Search does not support CUDA\r\n  File \"infer.py\", line 147, in decode_main\r\n    translation_ids, translation_scores = decode(context)\r\n  File \"infer.py\", line 112, in decode\r\n    level=0)\r\nTypeError: beam_search() got multiple values for keyword argument 'end_id'\r\n```\r\n\r\n",
        "state": "open",
        "user": "zhuantouer",
        "closed_by": null,
        "created_at": "2018-08-25T02:25:02+00:00",
        "updated_at": "2018-10-16T03:58:51+00:00",
        "closed_at": null,
        "comments_count": [
            "zhuantouer",
            "qshi95"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 610,
        "title": "启动paddlepaddle/book的image后，无法访问jupyter notebook页面",
        "body": "启动方法：\r\ndocker run -d -p 8888:8888 docker.paddlepaddlehub.com/book\r\n\r\n查看的启动结果：\r\nC:\\>docker ps -a\r\nCONTAINER ID        IMAGE                             COMMAND                  CREATED             STATUS              PORTS                    NAMES\r\na79b59a7d0a2        docker.paddlepaddlehub.com/book   \"sh -c 'jupyter note\"   23 minutes ago      Up 23 minutes       0.0.0.0:8888->8888/tcp   sad_williams\r\n![image](https://user-images.githubusercontent.com/12709352/44766608-d5784400-ab8c-11e8-99c5-7a948b99ae11.png)\r\n\r\n之后访问http://localhost:8888，显示ERR_CONNECTION_REFUSED\r\n\r\n![image](https://user-images.githubusercontent.com/12709352/44766747-84b51b00-ab8d-11e8-9c29-155f33761ca4.png)\r\n",
        "state": "closed",
        "user": "duanlin0505",
        "closed_by": "sneaxiy",
        "created_at": "2018-08-29T05:15:05+00:00",
        "updated_at": "2018-08-31T09:14:33+00:00",
        "closed_at": "2018-08-31T09:14:33+00:00",
        "comments_count": [
            "velconia",
            "duanlin0505",
            "velconia",
            "duanlin0505",
            "duanlin0505"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 612,
        "title": "GPU模式下，flask threaded=true时，只发送单个请求inference infer报错",
        "body": "报错具体信息：\r\nF0905 03:29:56.093694  4176 hl_cuda_cudnn.cc:251] Check failed: CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 3) Cudnn Error: CUDNN_STATUS_BAD_PARAM\r\n*** Check failure stack trace: ***\r\n    @     0x7f2ac561fcfd  google::LogMessage::Fail()\r\n    @     0x7f2ac56237ac  google::LogMessage::SendToLog()\r\n    @     0x7f2ac561f823  google::LogMessage::Flush()\r\n    @     0x7f2ac5624cbe  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7f2ac55d2b35  hl_conv_workspace()\r\n    @     0x7f2ac523c4d2  paddle::ConvBaseProjection::reshape()\r\n    @     0x7f2ac52f59bb  paddle::ConvProjection::forward()\r\n    @     0x7f2ac523ecaf  paddle::CudnnConvBaseLayer::forward()\r\n    @     0x7f2ac51f2f6d  paddle::NeuralNetwork::forward()\r\n    @     0x7f2ac519157d  _wrap_GradientMachine_forward\r\n    @           0x4c30ce  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c1e6f  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4d4c9d  (unknown)\r\n    @           0x4bc9b6  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4c16e7  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d55f3  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n    @           0x4bed3d  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4c136f  PyEval_EvalFrameEx\r\n    @           0x4b9ab6  PyEval_EvalCodeEx\r\n    @           0x4d54b9  (unknown)\r\n    @           0x4eebee  (unknown)\r\n    @           0x4a577e  PyObject_Call\r\n\r\nserving代码：\r\n```python\r\n@app.route('/', methods=['POST'])\r\ndef infer():\r\n    fields = filter(lambda x: len(x) != 0, outputField.split(\",\"))\r\n    with open(paramFile) as param_f, open(topologyFile) as topo_f:\r\n        params = paddle.parameters.Parameters.from_tar(param_f)\r\n        inferer = paddle.inference.Inference(parameters=params, fileobj=topo_f)\r\n    try:\r\n        feeding = {}\r\n        d = []\r\n        for i, key in enumerate(request.json):\r\n            d.append(request.json[key])\r\n            feeding[key] = i\r\n            r = inferer.infer([d,d], feeding=feeding, field=fields)\r\n    except:\r\n        trace = traceback.format_exc()\r\n        errorResp(trace)\r\n    if isinstance(r, list):\r\n        return successResp([elem.tolist() for elem in r])\r\n    else:\r\n        return successResp(r.tolist())\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = parser.parse_args()\r\n    paddle.init(use_gpu=args.gpu)\r\n    paramFile = args.paramFile\r\n    topologyFile = args.topologyFile\r\n    outputField = args.outputField\r\n    print 'serving on port', args.port\r\n    app.run(host='0.0.0.0', port=args.port, threaded=True)\r\n```\r\n\r\n当执行`python start_paddleServ.py --topologyFile /data/objectDetection/inference_topology.pkl --paramFile /data/objectDetection/param.tar --gpu`启动serve，接着只通过一个client访问时，也会报上述错误。\r\n\r\n将treaded置为false则不会；或者非gpu模式下，启动为treaded=true也不会报错。\r\n\r\n参考其他issue：https://github.com/PaddlePaddle/DeepSpeech/issues/254\r\n如果GPU模式下，多线程调用cudnn不安全，但是单个访问也会出现问题吗？",
        "state": "open",
        "user": "RacingDawn",
        "closed_by": null,
        "created_at": "2018-09-05T03:52:13+00:00",
        "updated_at": "2018-09-05T09:39:53+00:00",
        "closed_at": null,
        "comments_count": [
            "typhoonzero",
            "RacingDawn",
            "typhoonzero",
            "RacingDawn",
            "typhoonzero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 622,
        "title": "paddlepaddle1.0不支持machine_translation模型",
        "body": "machine_translation模型在paddlepaddle1.0版本下运行时报错'module' object has no attribute 'Trainer'",
        "state": "closed",
        "user": "lipanpan03",
        "closed_by": "reyoung",
        "created_at": "2018-09-29T06:48:52+00:00",
        "updated_at": "2018-09-29T07:41:58+00:00",
        "closed_at": "2018-09-29T07:41:58+00:00",
        "comments_count": [
            "kolinwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 635,
        "title": "运行image_classification中demo  python train.py 直接killed   ",
        "body": "这是为什么呢 ，求解答",
        "state": "open",
        "user": "1293464778",
        "closed_by": null,
        "created_at": "2018-10-18T10:14:49+00:00",
        "updated_at": "2018-11-16T06:33:03+00:00",
        "closed_at": null,
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 640,
        "title": "运行paddle v2 serve的测试用例，出现core dump",
        "body": "测试paddle v2的serving程序，用例[demo](https://github.com/PaddlePaddle/book/blob/develop/serve/main.py);\r\n执行[client.py](https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/client/client.py)进行访问时，出现\r\n![image](https://user-images.githubusercontent.com/13477849/47707304-7905d380-dc66-11e8-9796-e64945d99006.png)\r\n通过gdb解析core文件，得到：\r\n![image](https://user-images.githubusercontent.com/13477849/47707484-e9145980-dc66-11e8-901c-a8f06d6d78b8.png)\r\n\r\n",
        "state": "closed",
        "user": "RacingDawn",
        "closed_by": "Superjomn",
        "created_at": "2018-10-30T09:14:09+00:00",
        "updated_at": "2018-10-31T08:07:35+00:00",
        "closed_at": "2018-10-31T07:26:26+00:00",
        "comments_count": [
            "dzhwinter",
            "RacingDawn",
            "Superjomn",
            "RacingDawn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 641,
        "title": "修改book文档开头话术",
        "body": "由于book开头话术容易引起误解，而且fluid-book并没有视频课程，因此建议对每篇book文档有如下修改：\r\n\r\n**以book01为例**\r\n\r\n“本教程源代码目录在book/fit_a_line， 初次使用请参考PaddlePaddle安装教程，更多内容请参考本教程的视频课堂”\r\n===>\r\n中文版：\r\n“本教程源代码目录在[book/fit_a_line](https://github.com/PaddlePaddle/book/tree/develop/01.fit_a_line)， 初次使用请您参考[Book文档使用说明](https://github.com/PaddlePaddle/book/blob/develop/README.cn.md#%E8%BF%90%E8%A1%8C%E8%BF%99%E6%9C%AC%E4%B9%A6)。\r\n英文版：\r\nThe source code for this tutorial lives on [book/fit_a_line](https://github.com/PaddlePaddle/book/tree/develop/01.fit_a_line). For instructions on getting started with this book, see [Running This Book](https://github.com/PaddlePaddle/book#running-the-book).",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "shanyi15",
        "created_at": "2018-11-12T04:02:16+00:00",
        "updated_at": "2018-11-15T02:55:14+00:00",
        "closed_at": "2018-11-15T02:55:14+00:00",
        "comments_count": [
            "shanyi15",
            "tink2123",
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 645,
        "title": "gpu版本docker.paddlepaddlehub.com/book，运行程序会出现core文件",
        "body": "",
        "state": "closed",
        "user": "zhuziying",
        "closed_by": "xuezhong",
        "created_at": "2018-11-30T23:50:04+00:00",
        "updated_at": "2019-02-01T04:18:35+00:00",
        "closed_at": "2019-02-01T04:18:35+00:00",
        "comments_count": [
            "xuezhong",
            "zhuziying",
            "xuezhong",
            "xuezhong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 653,
        "title": "在word2vec实验中如何在fluid版本得到并保存训练之后词的embedding。",
        "body": "实验环境：aistudio平台，paddlepaddle1.0，python3.5\r\n在v2版本中给出了这项工作的实现方法。\r\n可以通过parameters函数实现。\r\n# save word dict and embedding table\r\nembeddings = parameters.get(\"_proj\").reshape(len(word_dict), embsize)\r\nsave_dict_and_embedding(word_dict, embeddings)\r\n请问在fluid版本中我该如何获取训练后每个词的向量呢？希望可以给出一个具体实例。感谢！",
        "state": "open",
        "user": "zjyyyy",
        "closed_by": null,
        "created_at": "2018-12-12T08:48:12+00:00",
        "updated_at": "2019-06-19T05:57:05+00:00",
        "closed_at": null,
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 654,
        "title": "使用最新版image_classification训练完成后预测出现paddle.fluid.core.EnforceNotMet...错误",
        "body": "操作系统win7 64位，python版本是3.7.64，本机测试图像识别示例程序image_classification。\r\n训练完成后，用image目录下的dog.png图片验证是正确的，但从网络上随机找了一些猫，船之类的图片，验证时提示如下错误：\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 209, in <module>\r\n    main(use_cuda=False)\r\n  File \"train.py\", line 203, in main\r\n    infer(use_cuda=use_cuda, params_dirname=save_path)\r\n  File \"train.py\", line 175, in infer\r\n    fetch_list=fetch_targets)\r\n  File \"C:\\Users\\miles.liu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packa\r\nges\\paddle\\fluid\\executor.py\", line 472, in run\r\n    self.executor.run(program.desc, scope, 0, True, True)\r\npaddle.fluid.core.EnforceNotMet: Enforce failed. Expected in_dims[1] == filter_d\r\nims[1] * groups, but received in_dims[1]:4 != filter_dims[1] * groups:3.\r\nThe number of input channels should be equal to filter channels * groups. at [E:\r\n\\dist\\Paddle\\paddle\\fluid\\operators\\conv_op.cc:60]\r\nPaddlePaddle Call Stacks:\r\nWindows not support stack backtrace yet.\r\n开始以为图片格式有问题，然后将图片格式改为png，长和高都设定为32与dog.png一致，但还是报以上错误",
        "state": "open",
        "user": "xfliu138",
        "closed_by": null,
        "created_at": "2018-12-13T09:19:20+00:00",
        "updated_at": "2018-12-15T17:55:17+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 655,
        "title": "paddle1.1版本gpu环境08.machine_translation报错",
        "body": "**环境**\r\n百度云 paddle cloud产品\r\npaddle1.1版本\r\ngpu环境\r\n\r\n**问题**\r\n08.machine_translation实验内容，报错NameError: name 'result_ids_lod' is not defined如下图\r\n\r\n![gpu](https://user-images.githubusercontent.com/9932424/49988087-82e25c80-ffb0-11e8-81ba-1c48f8d3edef.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "fionwang223",
        "created_at": "2018-12-14T06:59:54+00:00",
        "updated_at": "2018-12-19T11:06:15+00:00",
        "closed_at": "2018-12-14T11:54:27+00:00",
        "comments_count": [
            "Xreki",
            "junjun315",
            "fionwang223",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 656,
        "title": "paddle1.1版本gpu环境04.word2vec报错",
        "body": "**环境**\r\n百度云 paddle cloud产品\r\npaddle1.1版本\r\ngpu环境\r\n\r\n**问题**\r\n04.word2vec实验内容，报错NameError: global name 'partial' is not defined如下图\r\n![gpu](https://user-images.githubusercontent.com/9932424/49988493-dd2fed00-ffb1-11e8-82cf-2a0189966376.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "fionwang223",
        "created_at": "2018-12-14T07:07:25+00:00",
        "updated_at": "2018-12-25T06:55:30+00:00",
        "closed_at": "2018-12-25T06:55:30+00:00",
        "comments_count": [
            "Xreki",
            "fionwang223",
            "fionwang223",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 657,
        "title": "paddle1.1版本gpu环境06.understand_sentiment报错",
        "body": "**环境**\r\n百度云 paddle cloud产品\r\npaddle1.1版本\r\ngpu环境\r\n\r\n**内容来源**\r\ndocker镜像中paddlepaddle/book:latest-gpu中的ipynb文件\r\n\r\n**问题**\r\n06.understand_sentiment实验内容，报错NameError: global name 'train_test' is not defined如下图\r\n![gpu](https://user-images.githubusercontent.com/9932424/49990830-ffc60400-ffb9-11e8-85a6-7cda96f9c7b9.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "junjun315",
        "created_at": "2018-12-14T08:12:11+00:00",
        "updated_at": "2019-02-22T03:13:09+00:00",
        "closed_at": "2019-02-22T03:13:09+00:00",
        "comments_count": [
            "shippingwang",
            "fionwang223",
            "junjun315",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 659,
        "title": "03.image_classification运行报错",
        "body": "EnforceNotMetTraceback (most recent call last)\r\n<ipython-input-3-a8d70f563465> in <module>()\r\n    207     # For demo purpose, the training runs on CPU\r\n    208     # Please change accordingly.\r\n--> 209     main(use_cuda=True)\r\n\r\n<ipython-input-3-a8d70f563465> in main(use_cuda)\r\n    199     save_path = \"image_classification_resnet.inference.model\"\r\n    200 \r\n--> 201     train(use_cuda=use_cuda, params_dirname=save_path)\r\n    202 \r\n    203     infer(use_cuda=use_cuda, params_dirname=save_path)\r\n\r\n<ipython-input-3-a8d70f563465> in train(use_cuda, params_dirname)\r\n    127                                               [predict], exe)\r\n    128 \r\n--> 129     train_loop()\r\n    130 \r\n    131 \r\n\r\n<ipython-input-3-a8d70f563465> in train_loop()\r\n    119 \r\n    120             avg_cost_test, accuracy_test = train_test(\r\n--> 121                 test_program, reader=test_reader)\r\n    122             print('\\nTest with Pass {0}, Loss {1:2.2}, Acc {2:2.2}'.format(\r\n    123                 pass_id, avg_cost_test, accuracy_test))\r\n\r\n<ipython-input-3-a8d70f563465> in train_test(program, reader)\r\n     88                 program=program,\r\n     89                 feed=feeder_test.feed(test_data),\r\n---> 90                 fetch_list=[avg_cost, acc])\r\n     91             accumulated = [\r\n     92                 x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\r\n\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.pyc in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    468 \r\n    469         self._feed_data(program, feed, feed_var_name, scope)\r\n--> 470         self.executor.run(program.desc, scope, 0, True, True)\r\n    471         outs = self._fetch_data(fetch_list, fetch_var_name, scope)\r\n    472         if return_numpy:\r\n\r\nEnforceNotMet: holder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:22]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f66dc932a12p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482\r\n1       0x7f66ddfb2906p paddle::framework::Tensor::check_memory_size() const + 214\r\n2       0x7f66dc93bb69p float const* paddle::framework::Tensor::data<float>() const + 25\r\n3       0x7f66dd026dcap paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 1738\r\n4       0x7f66dd027f30p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 32\r\n5       0x7f66ddf3e85ap paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 506\r\n6       0x7f66ddf3ad3fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 447\r\n7       0x7f66dc9f8957p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 247\r\n8       0x7f66dc9f9635p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 117\r\n9       0x7f66dc91775ap\r\n10      0x7f66dc948212p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2338\r\n11            0x4c5326p PyEval_EvalFrameEx + 37958\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n18            0x4b9b66p PyEval_EvalCodeEx + 774\r\n19            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n20            0x4b9b66p PyEval_EvalCodeEx + 774\r\n21            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n22            0x4b9b66p PyEval_EvalCodeEx + 774\r\n23            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n24            0x4b9b66p PyEval_EvalCodeEx + 774\r\n25            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n26            0x4b9b66p PyEval_EvalCodeEx + 774\r\n27            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4d57a3p\r\n30            0x4a587ep PyObject_Call + 62\r\n31            0x4be51ep PyEval_EvalFrameEx + 9790\r\n32            0x4b9b66p PyEval_EvalCodeEx + 774\r\n33            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n34            0x4b9b66p PyEval_EvalCodeEx + 774\r\n35            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n36            0x4b9b66p PyEval_EvalCodeEx + 774\r\n37            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n38            0x4b9b66p PyEval_EvalCodeEx + 774\r\n39            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n40            0x4b9b66p PyEval_EvalCodeEx + 774\r\n41            0x4d57a3p\r\n42            0x4a587ep PyObject_Call + 62\r\n43            0x4be51ep PyEval_EvalFrameEx + 9790\r\n44            0x4b9b66p PyEval_EvalCodeEx + 774\r\n45            0x4d57a3p\r\n46            0x4a587ep PyObject_Call + 62\r\n47            0x4be51ep PyEval_EvalFrameEx + 9790\r\n48            0x4b9b66p PyEval_EvalCodeEx + 774\r\n49            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n50            0x4b9b66p PyEval_EvalCodeEx + 774\r\n51            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n52            0x4b9b66p PyEval_EvalCodeEx + 774\r\n53            0x4d57a3p\r\n54            0x4a587ep PyObject_Call + 62\r\n55            0x4be51ep PyEval_EvalFrameEx + 9790\r\n56            0x4b9b66p PyEval_EvalCodeEx + 774\r\n57            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n58            0x4b9b66p PyEval_EvalCodeEx + 774\r\n59            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n60            0x4b9b66p PyEval_EvalCodeEx + 774\r\n61            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n62            0x4b9b66p PyEval_EvalCodeEx + 774\r\n63            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n64            0x4b9b66p PyEval_EvalCodeEx + 774\r\n65            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n66            0x4b9b66p PyEval_EvalCodeEx + 774\r\n67            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n68            0x4b9b66p PyEval_EvalCodeEx + 774\r\n69            0x4d5669p\r\n70            0x4a587ep PyObject_Call + 62\r\n71            0x51a866p\r\n72            0x4939ccp Py_Main + 1612\r\n73      0x7f67281c4830p __libc_start_main + 240\r\n74            0x493299p _start + 41\r\n",
        "state": "closed",
        "user": "zhuziying",
        "closed_by": "shippingwang",
        "created_at": "2018-12-17T02:33:06+00:00",
        "updated_at": "2019-01-09T12:10:19+00:00",
        "closed_at": "2019-01-09T12:10:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 660,
        "title": "book/03.image_classification/ GPY第一次正常第二次运行报错",
        "body": "",
        "state": "closed",
        "user": "zhuziying",
        "closed_by": "zhuziying",
        "created_at": "2018-12-18T07:16:09+00:00",
        "updated_at": "2018-12-18T07:17:51+00:00",
        "closed_at": "2018-12-18T07:17:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 658,
        "title": "paddle0.14版本cpu环境08.machine_translation报错",
        "body": "**环境**\r\n百度云 paddle cloud产品\r\npaddle0.14版本\r\ncpu环境\r\n\r\n**问题**\r\n08.machine_translation实验内容，报错TypeError: beam_search() got multiple values for keyword argument 'end_id'，如下图\r\n![cpu](https://user-images.githubusercontent.com/9932424/50012347-569efe00-fff9-11e8-8335-04293240a264.PNG)\r\n\r\ndecode函数如下\r\n![decode](https://user-images.githubusercontent.com/9932424/50012595-fc526d00-fff9-11e8-8bdf-34fec1d2ca07.png)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "shanyi15",
        "created_at": "2018-12-14T15:43:32+00:00",
        "updated_at": "2019-01-08T09:11:15+00:00",
        "closed_at": "2019-01-08T09:11:15+00:00",
        "comments_count": [
            "shippingwang",
            "fionwang223"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 661,
        "title": "book/03.image_classification/ GPU第一次正常第二次运行报错",
        "body": "Pass 0, Batch 0, Cost 3.194520, Acc 0.078125\r\n...................................................................................................\r\nPass 100, Batch 0, Cost 1.607098, Acc 0.445312\r\n...................................................................................................\r\nPass 200, Batch 0, Cost 1.341645, Acc 0.500000\r\n...................................................................................................\r\nPass 300, Batch 0, Cost 1.294024, Acc 0.546875\r\n..........................................................................................\r\n\r\nEnforceNotMetTraceback (most recent call last)\r\n<ipython-input-2-4cf485e0cb2e> in <module>()\r\n    207     # For demo purpose, the training runs on CPU\r\n    208     # Please change accordingly.\r\n--> 209     main(use_cuda=True)\r\n\r\n<ipython-input-2-4cf485e0cb2e> in main(use_cuda)\r\n    199     save_path = \"image_classification_resnet.inference.model\"\r\n    200 \r\n--> 201     train(use_cuda=use_cuda, params_dirname=save_path)\r\n    202 \r\n    203     infer(use_cuda=use_cuda, params_dirname=save_path)\r\n\r\n<ipython-input-2-4cf485e0cb2e> in train(use_cuda, params_dirname)\r\n    127                                               [predict], exe)\r\n    128 \r\n--> 129     train_loop()\r\n    130 \r\n    131 \r\n\r\n<ipython-input-2-4cf485e0cb2e> in train_loop()\r\n    119 \r\n    120             avg_cost_test, accuracy_test = train_test(\r\n--> 121                 test_program, reader=test_reader)\r\n    122             print('\\nTest with Pass {0}, Loss {1:2.2}, Acc {2:2.2}'.format(\r\n    123                 pass_id, avg_cost_test, accuracy_test))\r\n\r\n<ipython-input-2-4cf485e0cb2e> in train_test(program, reader)\r\n     88                 program=program,\r\n     89                 feed=feeder_test.feed(test_data),\r\n---> 90                 fetch_list=[avg_cost, acc])\r\n     91             accumulated = [\r\n     92                 x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\r\n\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.pyc in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    468 \r\n    469         self._feed_data(program, feed, feed_var_name, scope)\r\n--> 470         self.executor.run(program.desc, scope, 0, True, True)\r\n    471         outs = self._fetch_data(fetch_list, fetch_var_name, scope)\r\n    472         if return_numpy:\r\n\r\nEnforceNotMet: holder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:22]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f2451449a12p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482\r\n1       0x7f2452ac9906p paddle::framework::Tensor::check_memory_size() const + 214\r\n2       0x7f2451452b69p float const* paddle::framework::Tensor::data<float>() const + 25\r\n3       0x7f2451b3ddcap paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 1738\r\n4       0x7f2451b3ef30p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 32\r\n5       0x7f2452a5585ap paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 506\r\n6       0x7f2452a51d3fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 447\r\n7       0x7f245150f957p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 247\r\n8       0x7f2451510635p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 117\r\n9       0x7f245142e75ap\r\n10      0x7f245145f212p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2338\r\n11            0x4c5326p PyEval_EvalFrameEx + 37958\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n18            0x4b9b66p PyEval_EvalCodeEx + 774\r\n19            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n20            0x4b9b66p PyEval_EvalCodeEx + 774\r\n21            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n22            0x4b9b66p PyEval_EvalCodeEx + 774\r\n23            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n24            0x4b9b66p PyEval_EvalCodeEx + 774\r\n25            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n26            0x4b9b66p PyEval_EvalCodeEx + 774\r\n27            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4d57a3p\r\n30            0x4a587ep PyObject_Call + 62\r\n31            0x4be51ep PyEval_EvalFrameEx + 9790\r\n32            0x4b9b66p PyEval_EvalCodeEx + 774\r\n33            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n34            0x4b9b66p PyEval_EvalCodeEx + 774\r\n35            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n36            0x4b9b66p PyEval_EvalCodeEx + 774\r\n37            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n38            0x4b9b66p PyEval_EvalCodeEx + 774\r\n39            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n40            0x4b9b66p PyEval_EvalCodeEx + 774\r\n41            0x4d57a3p\r\n42            0x4a587ep PyObject_Call + 62\r\n43            0x4be51ep PyEval_EvalFrameEx + 9790\r\n44            0x4b9b66p PyEval_EvalCodeEx + 774\r\n45            0x4d57a3p\r\n46            0x4a587ep PyObject_Call + 62\r\n47            0x4be51ep PyEval_EvalFrameEx + 9790\r\n48            0x4b9b66p PyEval_EvalCodeEx + 774\r\n49            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n50            0x4b9b66p PyEval_EvalCodeEx + 774\r\n51            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n52            0x4b9b66p PyEval_EvalCodeEx + 774\r\n53            0x4d57a3p\r\n54            0x4a587ep PyObject_Call + 62\r\n55            0x4be51ep PyEval_EvalFrameEx + 9790\r\n56            0x4b9b66p PyEval_EvalCodeEx + 774\r\n57            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n58            0x4b9b66p PyEval_EvalCodeEx + 774\r\n59            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n60            0x4b9b66p PyEval_EvalCodeEx + 774\r\n61            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n62            0x4b9b66p PyEval_EvalCodeEx + 774\r\n63            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n64            0x4b9b66p PyEval_EvalCodeEx + 774\r\n65            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n66            0x4b9b66p PyEval_EvalCodeEx + 774\r\n67            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n68            0x4b9b66p PyEval_EvalCodeEx + 774\r\n69            0x4d5669p\r\n70            0x4a587ep PyObject_Call + 62\r\n71            0x51a866p\r\n72            0x4939ccp Py_Main + 1612\r\n73      0x7f249ccc1830p __libc_start_main + 240\r\n74            0x493299p _start + 41\r\n",
        "state": "closed",
        "user": "zhuziying",
        "closed_by": "zhuziying",
        "created_at": "2018-12-18T07:16:11+00:00",
        "updated_at": "2018-12-19T01:21:21+00:00",
        "closed_at": "2018-12-19T01:21:21+00:00",
        "comments_count": [
            "junjun315",
            "shippingwang",
            "zhuziying",
            "zhuziying",
            "zhuziying"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 664,
        "title": "新手上路，代码跑不动",
        "body": "我尝试着去跑动识别数字的代码，发现它跑不动（windows10 专业版下），代码附上\r\n```\r\ntrain_reader = paddle.batch(\r\n        paddle.reader.shuffle(paddle.dataset.mnist.train(), buf_size=500),\r\n        batch_size=BATCH_SIZE)\r\n\r\ntry:\r\n    for step_id, data in enumerate(train_reader()):\r\n        print(data)\r\nexcept BaseException as err:\r\n    print('Some problems')\r\n    print(err)\r\n```\r\n输出到控制台的信息全为空\r\n```\r\n\r\n\r\nSome problem\r\n\r\n```\r\n恳请问是怎么一回事呢？",
        "state": "open",
        "user": "StepToTop",
        "closed_by": null,
        "created_at": "2018-12-23T14:25:58+00:00",
        "updated_at": "2019-06-19T06:00:27+00:00",
        "closed_at": null,
        "comments_count": [
            "junjun315",
            "StepToTop",
            "junjun315",
            "StepToTop",
            "junjun315",
            "StepToTop"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 662,
        "title": "transfer learning",
        "body": "How to Transfer Learning in Fluid Version",
        "state": "closed",
        "user": "zhiAung",
        "closed_by": "AIpioneer",
        "created_at": "2018-12-20T12:18:46+00:00",
        "updated_at": "2019-06-19T06:09:10+00:00",
        "closed_at": "2019-06-19T06:09:10+00:00",
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 685,
        "title": "deadlink check",
        "body": "检查发现以下几处有死链，请修复\r\n1. \r\nhttps://github.com/PaddlePaddle/book/blob/develop/03.image_classification/README.cn.md\r\nThe Pascal Visual Object Classes Challenge: A Retrospective 链接错误\r\n\r\n2. \r\nhttps://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/README.cn.md\r\nHybrid Web Recommender Systems\r\n\r\n3. \r\nhttps://github.com/PaddlePaddle/book/blob/develop/06.understand_sentiment/README.cn.md\r\nsequence_conv_pool\r\n\r\n4. \r\nhttps://github.com/PaddlePaddle/book/blob/develop/07.label_semantic_roles/README.cn.md\r\nConditional random fields: Probabilistic models for segmenting and labeling sequence data\r\n\r\n5. \r\nhttps://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.cn.md\r\nWMT-14\r\nbitexts(after selection)\r\ndev+test data\r\n较小规模的数据集",
        "state": "open",
        "user": "shanyi15",
        "closed_by": null,
        "created_at": "2019-02-23T08:57:12+00:00",
        "updated_at": "2019-06-19T06:06:43+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 665,
        "title": "fix book 02",
        "body": "plz fix `trainer` and `inferencer` in book 02",
        "state": "closed",
        "user": "shanyi15",
        "closed_by": "junjun315",
        "created_at": "2019-01-08T11:32:07+00:00",
        "updated_at": "2019-03-05T11:32:09+00:00",
        "closed_at": "2019-03-05T11:32:09+00:00",
        "comments_count": [
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 674,
        "title": "快速入门-识别数字出现问题",
        "body": "线性回归通过，不通的是识别数字，网址：http://www.paddlepaddle.org/documentation/docs/zh/1.2/beginners_guide/quick_start/fit_a_line/README.cn.html\r\n![image](https://user-images.githubusercontent.com/37862032/52769942-ccacf900-306c-11e9-8f32-fe1c0b8b9d1e.png)\r\n",
        "state": "closed",
        "user": "mingkai1369",
        "closed_by": "heavengate",
        "created_at": "2019-02-14T06:40:58+00:00",
        "updated_at": "2019-02-15T15:02:16+00:00",
        "closed_at": "2019-02-15T15:02:16+00:00",
        "comments_count": [
            "mingkai1369",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 691,
        "title": "python3版本冲突报错",
        "body": "1. \r\nhttp://paddlepaddle.org/documentation/docs/zh/1.3/beginners_guide/quick_start/fit_a_line/README.cn.html\r\n\r\n<img width=\"499\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/34557281/54671844-babdea80-4b31-11e9-9594-ed2b26633f87.png\">\r\n\r\n2. \r\nhttp://paddlepaddle.org/documentation/docs/zh/1.3/beginners_guide/quick_start/recognize_digits/README.cn.html\r\n\r\n<img width=\"667\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/34557281/54672380-dc6ba180-4b32-11e9-9059-1a9c73c68e62.png\">\r\n\r\n",
        "state": "closed",
        "user": "Genie-Liu",
        "closed_by": "Genie-Liu",
        "created_at": "2019-03-20T09:09:13+00:00",
        "updated_at": "2019-03-20T09:10:27+00:00",
        "closed_at": "2019-03-20T09:10:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 688,
        "title": "Paddle book python3运行问题 - (fit_a_line, recognize_digit)",
        "body": "线性回归的示例代码中，主循环里使用了  **plot_prompt**调用了 **ploter**中使用了“basestring”。然后报错未定义 “basestring”，因为python3没有basestring。\r\n\r\n报错如下\r\n\r\n```python\r\nfor pass_id in range(num_epochs):\r\n    for data_train in train_reader():\r\n        avg_loss_value, = exe.run(main_program,\r\n                                  feed=feeder.feed(data_train),\r\n                                  fetch_list=[avg_loss])\r\n        if step % 10 == 0: # 每10个批次记录并输出一下训练损失\r\n            plot_prompt.append(train_prompt, step, avg_loss_value[0])\r\n            plot_prompt.plot()\r\n            print(\"%s, Step %d, Cost %f\" % \r\n                      (train_prompt, step, avg_loss_value[0]))\r\n        if step % 100 == 0:  # 每100批次记录并输出一下测试损失\r\n            test_metics = train_test(executor=exe_test,\r\n                                     program=test_program,\r\n                                     reader=test_reader,\r\n                                     fetch_list=[avg_loss.name],\r\n                                     feeder=feeder)\r\n            plot_prompt.append(test_prompt, step, test_metics[0])\r\n            plot_prompt.plot()\r\n            print(\"%s, Step %d, Cost %f\" %\r\n                      (test_prompt, step, test_metics[0]))\r\n            if test_metics[0] < 10.0: # 如果准确率达到要求，则停止训练\r\n                break\r\n\r\n        step += 1\r\n\r\n        if math.isnan(float(avg_loss_value[0])):\r\n            sys.exit(\"got NaN loss, training failed.\")\r\n\r\n        #保存训练参数到之前给定的路径中\r\n        if params_dirname is not None:\r\n            fluid.io.save_inference_model(params_dirname, ['x'], [y_predict], exe)\r\n```\r\n\r\n\r\n    ---------------------------------------------------------------------------\r\n    \r\n    NameError                                 Traceback (most recent call last)\r\n    \r\n    <ipython-input-8-4379eae5beee> in <module>\r\n          5                                   fetch_list=[avg_loss])\r\n          6         if step % 10 == 0: # 每10个批次记录并输出一下训练损失\r\n    ----> 7             plot_prompt.append(train_prompt, step, avg_loss_value[0])\r\n          8             plot_prompt.plot()\r\n          9             print(\"%s, Step %d, Cost %f\" % \r\n\r\n\r\n    /anaconda3/lib/python3.7/site-packages/paddle/utils/plot.py in append(self, title, step, value)\r\n         73                 plot_curve.append(title=\"Curve 1\",step=1,value=1)\r\n         74 \t\"\"\"\r\n    ---> 75         assert isinstance(title, basestring)\r\n         76         assert self.__plot_data__.has_key(title)\r\n         77         data = self.__plot_data__[title]\r\n\r\n\r\n    NameError: name 'basestring' is not defined\r\n\r\n\r\n",
        "state": "closed",
        "user": "OliverLPH",
        "closed_by": "junjun315",
        "created_at": "2019-03-05T07:12:14+00:00",
        "updated_at": "2019-04-28T02:42:12+00:00",
        "closed_at": "2019-04-28T02:42:12+00:00",
        "comments_count": [
            "OliverLPH",
            "OliverLPH",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 689,
        "title": "图片分类出错",
        "body": "我使用当前的docker 1.3 版本，运行图片分类示例，出现错误：\r\n代码：\r\n\r\n```\r\nfrom __future__ import print_function\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport numpy\r\nimport sys\r\n\r\ndef vgg_bn_drop(input):\r\n    def conv_block(ipt, num_filter, groups, dropouts):\r\n        return fluid.nets.img_conv_group(\r\n            input=ipt,\r\n            pool_size=2,\r\n            pool_stride=2,\r\n            conv_num_filter=[num_filter] * groups,\r\n            conv_filter_size=3,\r\n            conv_act='relu',\r\n            conv_with_batchnorm=True,\r\n            conv_batchnorm_drop_rate=dropouts,\r\n            pool_type='max')\r\n\r\n    conv1=conv_block(input,64,2,[0.3,0])\r\n    conv2=conv_block(conv1,128,2,[0.4,0])\r\n    conv3=conv_block(conv2,256,3,[0.4,0.4,0])\r\n    conv4=conv_block(conv3,512,3,[0.4,0.4,0])\r\n    conv5=conv_block(conv4,512,3,[0.4,0.4,0])\r\n    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)\r\n    fc1= fluid.layers.fc(input=drop,size=512,act=None)\r\n    bn=fluid.layers.batch_norm(input=fc1,act='relu')\r\n    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.5)\r\n    fc2= fluid.layers.fc(input=drop2,size=512,act=None)\r\n    predict=fluid.layers.fc(input=fc2,size=10,act='softmax')\r\n    return predict\r\n```\r\n```\r\ndef conv_bn_layer(input, ch_out, filter_size, stride, padding, act='relu', bias_attr=False):\r\n    tmp=fluid.layers.conv2d(input=input, filter_size=filter_size, num_filters=ch_out, stride=stride, padding=padding, act=None, bias_attr=bias_attr )\r\n    return fluid.layers.batch_norm(input=tmp,act=act)\r\n\r\ndef shortcut(input,ch_in,ch_out,stride):\r\n    if ch_in != ch_out:\r\n        return conv_bn_layer(input,ch_out,1,stride,0, None)\r\n    else:\r\n        return input\r\n\r\ndef basicblock(input, ch_in, ch_out, stride):\r\n    tmp = conv_bn_layer(input, ch_out, 3, stride, 1)\r\n    tmp1= conv_bn_layer(tmp, ch_out, 3,stride,1)\r\n    short=shortcut(input, ch_in,ch_out,stride)\r\n    return fluid.layers.elementwise_add(x=tmp1,y=short,act='relu')\r\n\r\ndef layer_warp(block_func,input,ch_in,ch_out,count,stride):\r\n    tmp=block_func(input, ch_in,ch_out,stride)\r\n    for i in range(1,count):\r\n        tmp=block_func(tmp,ch_out,ch_out,1)\r\n    return tmp\r\ndef resnet_cifar10(ipt,depth=32):\r\n    assert(depth-2)%6==0\r\n    n=(depth-2)//6\r\n    nStages={16,64,128}\r\n    conv1=conv_bn_layer(ipt,ch_out=16,filter_size=3,stride=1,padding=1)\r\n    res1=layer_warp(basicblock,conv1,16,16,n,1)\r\n    res2=layer_warp(basicblock,res1,16,32,n,2)\r\n    res3=layer_warp(basicblock,res2,32,64,n,2)\r\n    pool=fluid.layers.pool2d(input=res3, pool_size=4, pool_type='max', pool_stride=1, global_pooling=False)\r\n    predict=fluid.layers.fc(input=pool,size=10,act='softmax')\r\n    return predict\r\n```\r\n```\r\ndef inference_program():\r\n    data_shape=[3,32,32]\r\n    images=fluid.layers.data(name='pixel',shape=data_shape,dtype='float32')\r\n    predict=resnet_cifar10(images,32)\r\n    #predict=vgg_bn_drop(images)\r\n    return predict\r\n```\r\n\r\n# Train Program Config\r\n**CODE COPY FROM README**\r\n\r\n```\r\ndef train_program():\r\n    predict=inference_program()\r\n    label=fluid.layers.data(name='label',shape=[1],dtype='int64')\r\n    cost=fluid.layers.cross_entropy(input=predict,label=label)\r\n    avg_cost=fluid.layers.mean(cost)\r\n    accuracy=fluid.layers.accuracy(input=predict,label=label )\r\n    return [avg_cost,accuracy]\r\n\r\ndef optimizer_program():\r\n    return fluid.optimizer.Adam(learning_rate=0.001)\r\n```\r\n```\r\n\r\nBATCH_SIZE=128\r\nprint(BATCH_SIZE)\r\ntrain_reader=paddle.batch( paddle.reader.shuffle(paddle.dataset.cifar.train10(),buf_size=50000),batch_size=BATCH_SIZE )\r\ntest_reader=paddle.batch(paddle.dataset.cifar.test10(),batch_size=BATCH_SIZE)\r\n\r\nuse_cuda = False\r\nplace = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\nfeeder_order=['pixel','label']\r\nmain_program=fluid.default_main_program()\r\nstar_program=fluid.default_startup_program()\r\navg_cost,acc=train_program()\r\n\r\ntest_program=main_program.clone(for_test=True)\r\noptimizer = optimizer_program()\r\noptimizer.minimize(avg_cost)\r\nexe=fluid.Executor(place)\r\nEPOCH_NUM =2\r\n# for traning test cost\r\ndef train_test(program,reader):\r\n    count = 0\r\n    feed_var_list = [\r\n        program.global_block().var(var_name) for var_name in feed_order\r\n    ]\r\n    feeder_test = fluid.DataFeeder(\r\n        feed_list=feed_var_list, place=place)\r\n    test_exe = fluid.Executor(place)\r\n    accumulated = len([avg_cost, acc]) * [0]\r\n    for tid, test_data in enumerate(reader()):\r\n        avg_cost_np = test_exe.run(program=program,\r\n                                   feed=feeder_test.feed(test_data),\r\n                                   fetch_list=[avg_cost, acc])\r\n        accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\r\n        count += 1\r\n    return [x / count for x in accumulated]\r\n\r\nparams_dirname = \"image_classification_resnet.inference.model\"\r\ndef train_loop():\r\n    feed_var_list_loop = [main_program.global_block().var(var_name) for var_name in feeder_order]\r\n    feeder = fluid.DataFeeder( feed_list=feed_var_list_loop, place=place )\r\n    exe.run(star_program)\r\n\r\n    step=0\r\n    for pass_id in range( EPOCH_NUM ):\r\n        for step_id,data_train in enumerate( train_reader() ):\r\n            avg_loss_value = exe.run(main_program, feed=feeder.feed(data_train), fetch_list=[avg_cost, acc])\r\n            if step%1 == 0:\r\n                print(\"step:\")\r\n                print(step)\r\n                print(avg_cost)\r\n            step += 1\r\n        \r\n        avg_cost_test, accuracy_test = train_test(test_program, reader=test_reader)\r\n\r\n        if params_dirname is not None:\r\n            fluid.io.save_inference_model(params_dirname,[\"pixel\"],[predict], exe)\r\n\r\n\r\ntrain_loop()            \r\n\r\n```\r\n\r\n报错：\r\nFile \"paddle_iamgeclassify.py\", line 95, in <module>\r\n    avg_cost,acc=train_program()\r\n  File \"paddle_iamgeclassify.py\", line 75, in train_program\r\n    predict=inference_program()\r\n  File \"paddle_iamgeclassify.py\", line 69, in inference_program\r\n    predict=resnet_cifar10(images,32)\r\n  File \"paddle_iamgeclassify.py\", line 62, in resnet_cifar10\r\n    pool=fluid.layers.pool2d(input=res3, pool_size=4, pool_type='max', pool_stride=1, global_pooling=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py\", line 2383, in pool2d\r\n    \"exclusive\": exclusive,\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/layer_helper.py\", line 50, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 1208, in append_op\r\n    op = Operator(block=self, desc=op_desc, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/paddle/fluid/framework.py\", line 657, in __init__\r\n    self.desc.infer_shape(self.block.desc)\r\npaddle.fluid.core.EnforceNotMet: Due to the settings of padding(0), filter_size(4) and stride(1), the output size is less than 0, please check again. Input_size:2 at [/paddle/paddle/fluid/operators/pool_op.cc:39]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f8971787a96p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486\r\n1       0x7f8971dcef1cp paddle::operators::PoolOutputSize(int, int, int, int, bool) + 252\r\n2       0x7f8971dd1e81p paddle::operators::PoolOp::InferShape(paddle::framework::InferShapeContext*) const + 1537\r\n3       0x7f897183c376p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 902\r\n4       0x7f89717f054cp\r\n5       0x7f89717c18d0p\r\n6             0x4c5326p PyEval_EvalFrameEx + 37958\r\n7             0x4b9b66p PyEval_EvalCodeEx + 774\r\n8             0x4d57a3p\r\n9             0x4eef5ep\r\n10            0x4eeb66p\r\n11            0x4aaafbp\r\n12            0x4a587ep PyObject_Call + 62\r\n13            0x4be51ep PyEval_EvalFrameEx + 9790\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4d57a3p\r\n16            0x4a587ep PyObject_Call + 62\r\n17            0x4be51ep PyEval_EvalFrameEx + 9790\r\n18            0x4b9b66p PyEval_EvalCodeEx + 774\r\n19            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n20            0x4b9b66p PyEval_EvalCodeEx + 774\r\n21            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n22            0x4b9b66p PyEval_EvalCodeEx + 774\r\n23            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n24            0x4b9b66p PyEval_EvalCodeEx + 774\r\n25            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n26            0x4b9b66p PyEval_EvalCodeEx + 774\r\n27            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4eb69fp\r\n30            0x4e58f2p PyRun_FileExFlags + 130\r\n31            0x4e41a6p PyRun_SimpleFileExFlags + 390\r\n32            0x4938cep Py_Main + 1358\r\n33      0x7f8a4d522830p __libc_start_main + 240\r\n34            0x493299p _start + 41\r\n\r\n在我学习语义角色标注的示例时出现con1105 模块不存在的情况\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhenghl1",
        "closed_by": "shippingwang",
        "created_at": "2019-03-08T09:30:46+00:00",
        "updated_at": "2019-04-02T02:29:21+00:00",
        "closed_at": "2019-04-02T02:29:21+00:00",
        "comments_count": [
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 697,
        "title": "DEADLINK check from doc team",
        "body": "![image](https://user-images.githubusercontent.com/35982308/56332156-c8fb3700-61c1-11e9-91af-645356026782.png)\r\n![image](https://user-images.githubusercontent.com/35982308/56332169-d1537200-61c1-11e9-8dca-bf8c51dc6728.png)\r\n![image](https://user-images.githubusercontent.com/35982308/56332182-dfa18e00-61c1-11e9-875f-62d32fee6c7d.png)\r\n![image](https://user-images.githubusercontent.com/35982308/56332194-eb8d5000-61c1-11e9-8469-08e255f60798.png)\r\n",
        "state": "open",
        "user": "shanyi15",
        "closed_by": null,
        "created_at": "2019-04-18T02:15:43+00:00",
        "updated_at": "2019-06-19T05:55:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 693,
        "title": "import包的顺序",
        "body": "book/01.filt_a_line/train.py中15-21行import包顺序不符合PEP8规范。后续也有类似的问题。\r\nfrom __future__ import print_function\r\n\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport numpy\r\nimport math\r\nimport sys\r\n\r\n\r\n推荐所有的模块在 Python 模块的开头部分导入。 而且最好按照这样的顺序: Python 标准库模块、Python 第三方模块、应用程序自定义模块。使用一个空行分割这三类模块的导入语句。 \r\n\r\n建议改为：\r\nfrom __future__ import print_function\r\n\r\nimport sys\r\n\r\nimport numpy\r\nimport math\r\n\r\nimport paddle\r\nimport paddle.fluid as fluid\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "Steffy-zxf",
        "closed_by": "junjun315",
        "created_at": "2019-03-21T11:48:41+00:00",
        "updated_at": "2019-04-28T02:42:30+00:00",
        "closed_at": "2019-04-28T02:42:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 698,
        "title": "最新版09.gan报错 else后冒号为中文输入法",
        "body": "运行环境：\r\n百度云paddle cloud产品，Python3，gpu\r\n\r\n问题：\r\nelse后冒号为中文输入法\r\n\r\n报错截图：\r\n![捕获 3PNG](https://user-images.githubusercontent.com/9932424/56404284-66289f00-6298-11e9-9818-6665af46cde3.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "junjun315",
        "created_at": "2019-04-19T03:45:08+00:00",
        "updated_at": "2019-04-28T02:39:22+00:00",
        "closed_at": "2019-04-28T02:39:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 699,
        "title": "最新版09.gan报错 NameError: name 'run_ce' is not defined",
        "body": "运行环境：\r\n百度云paddle cloud产品，Python3，gpu\r\n\r\n问题：\r\nNameError: name 'run_ce' is not defined\r\n\r\n报错截图：\r\n![捕获4](https://user-images.githubusercontent.com/9932424/56404507-b5bb9a80-6299-11e9-85bf-e50a794d6a2d.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "junjun315",
        "created_at": "2019-04-19T03:54:49+00:00",
        "updated_at": "2019-04-28T02:41:19+00:00",
        "closed_at": "2019-04-28T02:41:19+00:00",
        "comments_count": [
            "fionwang223",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 708,
        "title": "plt.gcf().clear()会使其在Jupyter Notebook中不显示绘图",
        "body": "在plot.py文件里\r\n```\r\npython/paddle/utils/plot.py\r\n\r\n110行  self.plt.gcf().clear()\r\n```\r\nclear()函数会清空Figure对象，导致在Jupyter Notebook中不能显示绘图（尤其是在AIStudio里的Jupyter Notebook），我们可以显示的调用close_plot()这样的函数来清除Figure对象，释放内存。\r\n如图所示，始终打印Figure实例，而不显示绘图\r\n\r\n<img width=\"576\" alt=\"WX20190504-085303@2x\" src=\"https://user-images.githubusercontent.com/6853884/57171753-0d393900-6e4a-11e9-9e97-7146151d7c2a.png\">\r\n",
        "state": "closed",
        "user": "VictorZhang2014",
        "closed_by": "VictorZhang2014",
        "created_at": "2019-05-04T00:53:57+00:00",
        "updated_at": "2019-05-04T00:57:09+00:00",
        "closed_at": "2019-05-04T00:57:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 703,
        "title": "recurrent单词写错了，情感分析那一小节。",
        "body": "LSTM enhances its ability to handle long-range dependencies by adding memory and control gates to RNN. A similar principle improvement is Gated Recurrent Unit (GRU)[8], which is more concise in design. These improvements are different, but their macro descriptions are the same as simple recurrent neural networks (as shown in Figure 2). That is, the hidden state changes according to the current input and the hidden state of the previous moment, and this process is continuous until the input is processed:\r\n\r\n$$ h_t=**Recrurent**(x_t,h_{t-1})$$\r\n\r\nAmong them, $**Recrurent**$ can represent a RNN, GRU or LSTM.\r\n\r\n\r\n情感分析那一小节，这两个Recurrent单词都写错了",
        "state": "open",
        "user": "xiaotao321",
        "closed_by": null,
        "created_at": "2019-04-25T07:42:23+00:00",
        "updated_at": "2019-06-19T05:52:37+00:00",
        "closed_at": null,
        "comments_count": [
            "shanyi15"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 705,
        "title": "PipeReader的get_line函数的注释的转义有问题",
        "body": "代码中是这么写的：\r\npaddle/reader/decorator.py\r\n![图片](https://user-images.githubusercontent.com/35131887/56883314-df926f80-6a98-11e9-95a3-359c2a601c5d.png)\r\n但是渲染出来之后，这些\\n和\\r都没有显示出来，而是变成了这样\r\n![图片](https://user-images.githubusercontent.com/35131887/56883382-1c5e6680-6a99-11e9-9529-44b26b098871.png)\r\n上图中应该出现\\n和\\r，而不是渲染成真正的换行符。",
        "state": "open",
        "user": "houj04",
        "closed_by": null,
        "created_at": "2019-04-29T08:09:57+00:00",
        "updated_at": "2019-05-05T09:40:55+00:00",
        "closed_at": null,
        "comments_count": [
            "haowang101779990"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 700,
        "title": "最新版09.gan报错 output_dcgan/{:04d}_{:04d}.png不存在",
        "body": "运行环境：\r\n百度云paddle cloud产品，Python3，gpu\r\n\r\n问题：\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output_dcgan/0010_0460.png'\r\n\r\n报错截图：\r\n![捕获7](https://user-images.githubusercontent.com/9932424/56410436-b3643b00-62af-11e9-882a-39fdd4fc165e.PNG)\r\n",
        "state": "closed",
        "user": "fionwang223",
        "closed_by": "junjun315",
        "created_at": "2019-04-19T06:31:02+00:00",
        "updated_at": "2019-04-26T03:23:45+00:00",
        "closed_at": "2019-04-26T03:23:45+00:00",
        "comments_count": [
            "fionwang223",
            "junjun315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 709,
        "title": "02.recognize_digits 中 print中step和epoch_id顺序似乎反了",
        "body": "train.py中第128行打印的step和epoch_id顺序似乎反了，一个batch应该是一个step，一个pass应该是一个epoch。\r\n![image](https://user-images.githubusercontent.com/48793257/57205216-9342b480-6fef-11e9-8c09-2769d0d4bf72.png)\r\n若是按照上图顺序打印，则打印结果奇怪，batch一直为0。\r\n![image](https://user-images.githubusercontent.com/48793257/57205226-ab1a3880-6fef-11e9-932d-b21f915bad77.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "Steffy-zxf",
        "closed_by": "junjun315",
        "created_at": "2019-05-06T03:11:53+00:00",
        "updated_at": "2019-06-19T06:04:06+00:00",
        "closed_at": "2019-06-19T06:04:06+00:00",
        "comments_count": [
            "tink2123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 711,
        "title": "book中01-09模型的文档公式需要修正",
        "body": "book中01-09模型的文档公式存在问题，非常影响阅读理解，建议整体修复一下。以01.fit_a_line为例，需去掉冗余$以及omega、ldots等修改为对用的数学符号；\r\n<img width=\"1053\" alt=\"01-02\" src=\"https://user-images.githubusercontent.com/37854899/57593917-2e97d480-7570-11e9-97ad-407bdc88e787.png\">\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "xsrobin",
        "created_at": "2019-05-13T03:14:20+00:00",
        "updated_at": "2019-06-19T05:45:20+00:00",
        "closed_at": "2019-06-19T05:45:20+00:00",
        "comments_count": [
            "xsrobin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 712,
        "title": "book 01-fit_a_line模型文档链接失效",
        "body": "如图所示，该模型文档中很多链接失效, 若蓝色文字不是链接，建议将字体修改为黑色。\r\n<img width=\"577\" alt=\"01\" src=\"https://user-images.githubusercontent.com/37854899/57594236-a286ac80-7571-11e9-9943-877db73323d4.png\">\r\n<img width=\"919\" alt=\"02\" src=\"https://user-images.githubusercontent.com/37854899/57594249-ad414180-7571-11e9-9039-7a0cc64bbdcc.png\">\r\n<img width=\"535\" alt=\"03\" src=\"https://user-images.githubusercontent.com/37854899/57594259-b500e600-7571-11e9-8cd5-36e5c1793f10.png\">\r\n<img width=\"443\" alt=\"04\" src=\"https://user-images.githubusercontent.com/37854899/57594266-be8a4e00-7571-11e9-9cd1-d89ad98b523c.png\">\r\n<img width=\"402\" alt=\"05\" src=\"https://user-images.githubusercontent.com/37854899/57594272-c2b66b80-7571-11e9-9ea8-43cf1855c355.png\">\r\n\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "ceci3",
        "created_at": "2019-05-13T03:25:12+00:00",
        "updated_at": "2019-06-19T05:18:55+00:00",
        "closed_at": "2019-06-19T05:18:55+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 713,
        "title": "book提供的paddlepaddle/book镜像无法使用GPU进行训练",
        "body": "按照https://github.com/PaddlePaddle/book/blob/develop/README.md#running-the-book\r\n 部分的设置是用GPU对模型进行1训练：\r\n1. sudo nvidia-docker run  -it paddlepaddle/book:latest-gpu /bin/bash 进入该容器；\r\n2. 将01.fit_a_line模型train.py中 use_cuda = False改为 use_cuda = True\r\n3. python train.py报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/57598770-0a93bd80-7587-11e9-968a-c1b88fab5c17.png)\r\n其他docker image可以正确使用GPU对该模型进行训练。\r\n4. 在该容器卸载paddle后，通过pip install paddlepaddle-gpu重新安装paddle，是用GPU对模型进行训练，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/57598982-d79df980-7587-11e9-9826-5025260de008.png)\r\n",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-05-13T06:03:26+00:00",
        "updated_at": "2019-10-10T05:20:52+00:00",
        "closed_at": null,
        "comments_count": [
            "JiabinYang",
            "JiabinYang"
        ],
        "labels": [
            "内部提出"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 714,
        "title": "typo in BuildStrategy section",
        "body": "link:\r\nhttp://www.paddlepaddle.org/documentation/docs/zh/1.4/api_cn/fluid_cn.html#sync_batch_norm\r\n\"不支持FP16培训\" should be \"不支持FP16训练\".",
        "state": "closed",
        "user": "houj04",
        "closed_by": "xsrobin",
        "created_at": "2019-05-20T02:45:03+00:00",
        "updated_at": "2019-06-19T05:46:10+00:00",
        "closed_at": "2019-06-19T05:46:10+00:00",
        "comments_count": [
            "AIpioneer",
            "xsrobin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 726,
        "title": "08.machine_translation的log输出数据易用性",
        "body": "1. 目前训练部分代码，仅打印出来了pass_id和batch，未打印输出train_cost相关数据，请问在代码中如何获取train_cost数据呢？建议在输出的log中增加train_cost相关数据，目前从输出数据中得不到有价值的数据。\r\n![image](https://user-images.githubusercontent.com/37854899/58402851-d0044780-8093-11e9-83b6-20a9447c9782.png)\r\n2. 从哪里可以找到paddle.fluid.contrib.trainer和paddle.fluid.contrib.inferencer用法的详细介绍呢？\r\n\r\n\r\n\r\n\r\n  \r\n\r\n\r\n  ",
        "state": "closed",
        "user": "JiaXiao243",
        "closed_by": "JiaXiao243",
        "created_at": "2019-05-27T07:25:29+00:00",
        "updated_at": "2019-06-10T11:19:33+00:00",
        "closed_at": "2019-06-10T11:19:33+00:00",
        "comments_count": [
            "JiaXiao243",
            "JiaXiao243"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 729,
        "title": "06.understand_sentiment中的dyn_rnn训练出nan",
        "body": "修改use_cuda=True，执行python train_dyn_rnn.py指令，对该模型进行训练，报错信息如下：\r\n![image](https://user-images.githubusercontent.com/37854899/58419486-541ef500-80bd-11e9-93ab-d24530a1bdb7.png)\r\n\r\n\r\n ",
        "state": "open",
        "user": "JiaXiao243",
        "closed_by": null,
        "created_at": "2019-05-27T12:22:52+00:00",
        "updated_at": "2019-08-03T07:25:32+00:00",
        "closed_at": null,
        "comments_count": [
            "JesseyXujin",
            "JiaXiao243",
            "JesseyXujin",
            "JesseyXujin",
            "JiaXiao243",
            "JesseyXujin",
            "JesseyXujin",
            "JiaXiao243",
            "zkx-kk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 746,
        "title": "08.machine_translation infer 时报错",
        "body": "代码使用train.py中的代码，但是数据集是自己的，训练完成了，但是infer时报错：\r\nC++ Callstacks: \r\nDataType of Paddle Op sequence_expand Y must be the same. Get (float) != (int64_t) at [/paddle/paddle/fluid/framework/operator.cc:1115]\r\n\r\nfrom __future__ import print_function\r\nimport os\r\nimport six\r\n\r\nimport numpy as np\r\nimport paddle\r\nimport paddle.fluid as fluid\r\n\r\ndict_size = 29364\r\nsource_dict_size = target_dict_size = dict_size\r\nword_dim = 512\r\nhidden_dim = 512\r\ndecoder_size = hidden_dim\r\nmax_length = 256\r\nbeam_size = 4\r\nbatch_size = 64\r\n\r\nis_sparse = True\r\nmodel_save_dir = \"1_machine_translation.inference.model\"\r\n\r\n\r\ndef encoder():\r\n    src_word_id = fluid.layers.data(\r\n        name=\"src_word_id\", shape=[1], dtype='int64', lod_level=1)\r\n    src_embedding = fluid.layers.embedding(\r\n        input=src_word_id,\r\n        size=[source_dict_size, word_dim],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,param_attr='shared_w')\r\n\r\n    fc_forward = fluid.layers.fc(\r\n        input=src_embedding, size=hidden_dim * 3, bias_attr=False)\r\n    src_forward = fluid.layers.dynamic_gru(input=fc_forward, size=hidden_dim)\r\n    fc_backward = fluid.layers.fc(\r\n        input=src_embedding, size=hidden_dim * 3, bias_attr=False)\r\n    src_backward = fluid.layers.dynamic_gru(\r\n        input=fc_backward, size=hidden_dim, is_reverse=True)\r\n    encoded_vector = fluid.layers.concat(\r\n        input=[src_forward, src_backward], axis=1)\r\n    return encoded_vector\r\n\r\n\r\ndef cell(x, hidden, encoder_out, encoder_out_proj):\r\n    def simple_attention(encoder_vec, encoder_proj, decoder_state):\r\n        decoder_state_proj = fluid.layers.fc(\r\n            input=decoder_state, size=decoder_size, bias_attr=False)\r\n        decoder_state_expand = fluid.layers.sequence_expand(\r\n            x=decoder_state_proj, y=encoder_proj)\r\n        mixed_state = fluid.layers.elementwise_add(encoder_proj,\r\n                                                   decoder_state_expand)\r\n        attention_weights = fluid.layers.fc(\r\n            input=mixed_state, size=1, bias_attr=False)\r\n        attention_weights = fluid.layers.sequence_softmax(\r\n            input=attention_weights)\r\n        weigths_reshape = fluid.layers.reshape(x=attention_weights, shape=[-1])\r\n        scaled = fluid.layers.elementwise_mul(\r\n            x=encoder_vec, y=weigths_reshape, axis=0)\r\n        context = fluid.layers.sequence_pool(input=scaled, pool_type='sum')\r\n        return context\r\n\r\n    context = simple_attention(encoder_out, encoder_out_proj, hidden)\r\n    out = fluid.layers.fc(\r\n        input=[x, context], size=decoder_size * 3, bias_attr=False)\r\n    out = fluid.layers.gru_unit(\r\n        input=out, hidden=hidden, size=decoder_size * 3)[0]\r\n    return out, out\r\n\r\n\r\ndef train_decoder(encoder_out):\r\n    encoder_last = fluid.layers.sequence_last_step(input=encoder_out)\r\n    encoder_last_proj = fluid.layers.fc(\r\n        input=encoder_last, size=decoder_size, act='tanh')\r\n    # cache the encoder_out's computed result in attention\r\n    encoder_out_proj = fluid.layers.fc(\r\n        input=encoder_out, size=decoder_size, bias_attr=False)\r\n\r\n    trg_language_word = fluid.layers.data(\r\n        name=\"target_language_word\", shape=[1], dtype='int64', lod_level=1)\r\n    trg_embedding = fluid.layers.embedding(\r\n        input=trg_language_word,\r\n        size=[target_dict_size, word_dim],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,param_attr='shared_w')\r\n\r\n    rnn = fluid.layers.DynamicRNN()\r\n    with rnn.block():\r\n        x = rnn.step_input(trg_embedding)\r\n        pre_state = rnn.memory(init=encoder_last_proj, need_reorder=True)\r\n        encoder_out = rnn.static_input(encoder_out)\r\n        encoder_out_proj = rnn.static_input(encoder_out_proj)\r\n        out, current_state = cell(x, pre_state, encoder_out, encoder_out_proj)\r\n        prob = fluid.layers.fc(input=out, size=target_dict_size, act='softmax')\r\n\r\n        rnn.update_memory(pre_state, current_state)\r\n        rnn.output(prob)\r\n\r\n    return rnn()\r\n\r\n\r\ndef train_model():\r\n    encoder_out = encoder()\r\n    rnn_out = train_decoder(encoder_out)\r\n    label = fluid.layers.data(\r\n        name=\"target_language_next_word\", shape=[1], dtype='int64', lod_level=1)\r\n    cost = fluid.layers.cross_entropy(input=rnn_out, label=label)\r\n    avg_cost = fluid.layers.mean(cost)\r\n    return avg_cost\r\n\r\n\r\ndef optimizer_func():\r\n    fluid.clip.set_gradient_clip(\r\n        clip=fluid.clip.GradientClipByGlobalNorm(clip_norm=5.0))\r\n    lr_decay = fluid.layers.learning_rate_scheduler.noam_decay(hidden_dim, 1000)\r\n    return fluid.optimizer.Adam(\r\n        learning_rate=lr_decay,\r\n        regularization=fluid.regularizer.L2DecayRegularizer(\r\n            regularization_coeff=1e-4))\r\n\r\n\r\ndef train(use_cuda):\r\n    train_prog = fluid.Program()\r\n    startup_prog = fluid.Program()\r\n    with fluid.program_guard(train_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            avg_cost = train_model()\r\n            optimizer = optimizer_func()\r\n            optimizer.minimize(avg_cost)\r\n\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    #fluid.io.load_params(exe, model_save_dir, main_program=train_prog)\r\n\r\n    train_data = paddle.batch(\r\n            paddle.reader.shuffle(\r\n                train_reader1, buf_size=100000),\r\n            batch_size=batch_size)\r\n\r\n    feeder = fluid.DataFeeder(\r\n        feed_list=[\r\n            'src_word_id', 'target_language_word', 'target_language_next_word'\r\n        ],\r\n        place=place,\r\n        program=train_prog)\r\n\r\n    exe.run(startup_prog)\r\n\r\n    EPOCH_NUM = 20\r\n    for pass_id in six.moves.xrange(EPOCH_NUM):\r\n        batch_id = 0\r\n        for data in train_data():\r\n            cost = exe.run(\r\n                train_prog, feed=feeder.feed(data), fetch_list=[avg_cost])[0]\r\n            print('pass_id: %d, batch_id: %d, loss: %f' % (pass_id, batch_id,\r\n                                                           cost))\r\n            batch_id += 1\r\n        fluid.io.save_params(exe, model_save_dir, main_program=train_prog)\r\n\r\n\r\ndef infer_decoder(encoder_out):\r\n    encoder_last = fluid.layers.sequence_last_step(input=encoder_out)\r\n    encoder_last_proj = fluid.layers.fc(\r\n        input=encoder_last, size=decoder_size, act='tanh')\r\n    encoder_out_proj = fluid.layers.fc(\r\n        input=encoder_out, size=decoder_size, bias_attr=False)\r\n\r\n    max_len = fluid.layers.fill_constant(\r\n        shape=[1], dtype='int64', value=max_length)\r\n    counter = fluid.layers.zeros(shape=[1], dtype='int64', force_cpu=True)\r\n\r\n    init_ids = fluid.layers.data(\r\n        name=\"init_ids\", shape=[1], dtype=\"int64\", lod_level=2)\r\n    init_scores = fluid.layers.data(\r\n        name=\"init_scores\", shape=[1], dtype=\"float32\", lod_level=2)\r\n    # create and init arrays to save selected ids, scores and states for each step\r\n    ids_array = fluid.layers.array_write(init_ids, i=counter)\r\n    scores_array = fluid.layers.array_write(init_scores, i=counter)\r\n    state_array = fluid.layers.array_write(encoder_last_proj, i=counter)\r\n\r\n    cond = fluid.layers.less_than(x=counter, y=max_len)\r\n    while_op = fluid.layers.While(cond=cond)\r\n    with while_op.block():\r\n        pre_ids = fluid.layers.array_read(array=ids_array, i=counter)\r\n        pre_score = fluid.layers.array_read(array=scores_array, i=counter)\r\n        pre_state = fluid.layers.array_read(array=state_array, i=counter)\r\n\r\n        pre_ids_emb = fluid.layers.embedding(\r\n            input=pre_ids,\r\n            size=[target_dict_size, word_dim],\r\n            dtype='float32',\r\n            is_sparse=is_sparse,param_attr='shared_w')\r\n        out, current_state = cell(pre_ids_emb, pre_state, encoder_out,\r\n                                  encoder_out_proj)\r\n        prob = fluid.layers.fc(\r\n            input=current_state, size=target_dict_size, act='softmax')\r\n\r\n        # beam search\r\n        topk_scores, topk_indices = fluid.layers.topk(prob, k=beam_size)\r\n        accu_scores = fluid.layers.elementwise_add(\r\n            x=fluid.layers.log(topk_scores),\r\n            y=fluid.layers.reshape(pre_score, shape=[-1]),\r\n            axis=0)\r\n        accu_scores = fluid.layers.lod_reset(x=accu_scores, y=pre_ids)\r\n        selected_ids, selected_scores = fluid.layers.beam_search(\r\n            pre_ids, pre_score, topk_indices, accu_scores, beam_size, end_id=1)\r\n\r\n        fluid.layers.increment(x=counter, value=1, in_place=True)\r\n        # save selected ids and corresponding scores of each step\r\n        fluid.layers.array_write(selected_ids, array=ids_array, i=counter)\r\n        fluid.layers.array_write(selected_scores, array=scores_array, i=counter)\r\n        # update rnn state by sequence_expand acting as gather\r\n        current_state = fluid.layers.sequence_expand(current_state,\r\n                                                     selected_ids)\r\n        fluid.layers.array_write(current_state, array=state_array, i=counter)\r\n        current_enc_out = fluid.layers.sequence_expand(encoder_out,\r\n                                                       selected_ids)\r\n        fluid.layers.assign(current_enc_out, encoder_out)\r\n        current_enc_out_proj = fluid.layers.sequence_expand(encoder_out_proj,\r\n                                                            selected_ids)\r\n        fluid.layers.assign(current_enc_out_proj, encoder_out_proj)\r\n\r\n        # update conditional variable\r\n        length_cond = fluid.layers.less_than(x=counter, y=max_len)\r\n        finish_cond = fluid.layers.logical_not(\r\n            fluid.layers.is_empty(x=selected_ids))\r\n        fluid.layers.logical_and(x=length_cond, y=finish_cond, out=cond)\r\n\r\n    translation_ids, translation_scores = fluid.layers.beam_search_decode(\r\n        ids=ids_array, scores=scores_array, beam_size=beam_size, end_id=1)\r\n\r\n    return translation_ids, translation_scores\r\n\r\n\r\ndef infer_model():\r\n    encoder_out = encoder()\r\n    translation_ids, translation_scores = infer_decoder(encoder_out)\r\n    return translation_ids, translation_scores\r\n\r\n\r\ndef infer(use_cuda):\r\n    infer_prog = fluid.Program()\r\n    startup_prog = fluid.Program()\r\n    with fluid.program_guard(infer_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            translation_ids, translation_scores = infer_model()\r\n\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n    test_data = paddle.batch(\r\n        test_reader,\r\n        batch_size=batch_size)\r\n    src_idx2word = reverse_vocab\r\n    trg_idx2word = reverse_vocab\r\n\r\n    fluid.io.load_params(exe, model_save_dir, main_program=infer_prog)\r\n\r\n    for data in test_data():\r\n        src_word_id = fluid.create_lod_tensor(\r\n            data=[x[0] for x in data],\r\n            recursive_seq_lens=[[len(x[0]) for x in data]],\r\n            place=place)\r\n        init_ids = fluid.create_lod_tensor(\r\n            data=np.array([[0]] * len(data), dtype='int64'),\r\n            recursive_seq_lens=[[1] * len(data)] * 2,\r\n            place=place)\r\n        init_scores = fluid.create_lod_tensor(\r\n            data=np.array([[0.]] * len(data), dtype='float32'),\r\n            recursive_seq_lens=[[1] * len(data)] * 2,\r\n            place=place)\r\n        seq_ids, seq_scores = exe.run(\r\n            infer_prog,\r\n            feed={\r\n                'src_word_id': src_word_id,\r\n                'init_ids': init_ids,\r\n                'init_scores': init_scores\r\n            },\r\n            fetch_list=[translation_ids, translation_scores],\r\n            return_numpy=False)\r\n        # How to parse the results:\r\n        #   Suppose the lod of seq_ids is:\r\n        #     [[0, 3, 6], [0, 12, 24, 40, 54, 67, 82]]\r\n        #   then from lod[0]:\r\n        #     there are 2 source sentences, beam width is 3.\r\n        #   from lod[1]:\r\n        #     the first source sentence has 3 hyps; the lengths are 12, 12, 16\r\n        #     the second source sentence has 3 hyps; the lengths are 14, 13, 15\r\n        hyps = [[] for i in range(len(seq_ids.lod()[0]) - 1)]\r\n        scores = [[] for i in range(len(seq_scores.lod()[0]) - 1)]\r\n        for i in range(len(seq_ids.lod()[0]) - 1):  # for each source sentence\r\n            start = seq_ids.lod()[0][i]\r\n            end = seq_ids.lod()[0][i + 1]\r\n            print(\"Original sentence:\")\r\n            print(\" \".join([src_idx2word[idx] for idx in data[i][0][1:-1]]))\r\n            print(\"Translated score and sentence:\")\r\n            for j in range(end - start):  # for each candidate\r\n                sub_start = seq_ids.lod()[1][start + j]\r\n                sub_end = seq_ids.lod()[1][start + j + 1]\r\n                hyps[i].append(\" \".join([\r\n                    trg_idx2word[idx]\r\n                    for idx in np.array(seq_ids)[sub_start:sub_end][1:-1]\r\n                ]))\r\n                scores[i].append(np.array(seq_scores)[sub_end - 1])\r\n                print(scores[i][-1], hyps[i][-1].encode('utf8'))\r\n\r\n\r\ndef main(use_cuda):\r\n    train(use_cuda)\r\n    #infer(use_cuda)\r\n  \r\n\r\n\r\nif __name__ == '__main__':\r\n    use_cuda = False  # set to True if training with GPU\r\n    main(use_cuda)\r\n    #infer(use_cuda)",
        "state": "closed",
        "user": "Alanyh",
        "closed_by": "Alanyh",
        "created_at": "2019-06-16T05:25:51+00:00",
        "updated_at": "2019-06-16T05:37:48+00:00",
        "closed_at": "2019-06-16T05:37:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 743,
        "title": "01.fit_a_line中输出图像后报错",
        "body": "在输出图像的时候提示：\r\n\r\n/opt/conda/envs/python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: \r\nThis call to matplotlib.use() has no effect because the backend has already\r\nbeen chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\r\nor matplotlib.backends is imported for the first time.\r\n",
        "state": "closed",
        "user": "luckeriam",
        "closed_by": "ceci3",
        "created_at": "2019-06-11T07:24:01+00:00",
        "updated_at": "2019-06-19T05:49:36+00:00",
        "closed_at": "2019-06-19T05:49:36+00:00",
        "comments_count": [
            "ceci3",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 744,
        "title": "求助怎么使用单机多gpu",
        "body": "我使用的就是手写字体的例子，然后在exe之后使用了多gpu的compiled_prog，但是运行结果报错。\r\n\r\n环境\r\nubuntu 18.04\r\ncuda 9.0\r\ncudnn 7.1\r\npaddlepdaalde 1.4.1.post85\r\n\r\n在~/.bashrc中已经修改了LD_LIBRARY_PATH路径：\r\n![图片](https://user-images.githubusercontent.com/30866942/59479560-13cabf80-8e90-11e9-9372-1fac52a8847b.png)\r\n![图片](https://user-images.githubusercontent.com/30866942/59479562-13cabf80-8e90-11e9-98dd-91740a8835be.png)\r\n![图片](https://user-images.githubusercontent.com/30866942/59479572-19c0a080-8e90-11e9-88b9-1d7f261749d3.png)\r\n![图片](https://user-images.githubusercontent.com/30866942/59479589-2c3ada00-8e90-11e9-8a18-aa8c068d0464.png)\r\n以上集中修改之后都人就包以下错误\r\n\r\n\r\n报的错误：\r\nW0614 10:27:29.849985  9177 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!\r\nW0614 10:27:31.884308  9177 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 8.0\r\nW0614 10:27:31.884506  9177 dynamic_loader.cc:107] Can not find library: libcudnn.so. Please try to add the lib path to LD_LIBRARY_PATH.\r\nW0614 10:27:31.884533  9177 dynamic_loader.cc:165] Failed to find dynamic library: libcudnn.so ( libcudnn.so: cannot open shared object file: No such file or directory ) \r\n Please specify its path correctly using following ways: \r\n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \r\n For instance, issue command: export LD_LIBRARY_PATH=... \r\n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled.\r\nTraceback (most recent call last):\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 263, in <module>\r\n    main(use_cuda=use_cuda, nn_type=predict)\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 243, in main\r\n    params_filename=params_filename)\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 149, in train\r\n    exe.run(startup_program)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 565, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 642, in _run\r\n    exe.run(program.desc, scope, 0, True, True, fetch_var_name)\r\npaddle.fluid.core.EnforceNotMet: Invoke operator fill_constant error.\r\nPython Callstacks: \r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1725, in _prepend_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/initializer.py\", line 167, in __call__\r\n    stop_gradient=True)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1517, in create_var\r\n    kwargs['initializer'](var, self)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\", line 382, in set_variable_initializer\r\n    initializer=initializer)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/layers/tensor.py\", line 152, in create_global_var\r\n    value=float(value), force_cpu=force_cpu))\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 136, in _create_global_learning_rate\r\n    persistable=True)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 275, in _create_optimization_pass\r\n    self._create_global_learning_rate()\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 441, in apply_gradients\r\n    optimize_ops = self._create_optimization_pass(params_grads)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 469, in apply_optimize\r\n    optimize_ops = self.apply_gradients(params_grads)\r\n  File \"/home/cj1/env-python3/lib/python3.6/site-packages/paddle/fluid/optimizer.py\", line 500, in minimize\r\n    loss, startup_program=startup_program, params_grads=params_grads)\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 119, in train\r\n    optimizer.minimize(avg_loss)\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 243, in main\r\n    params_filename=params_filename)\r\n  File \"/home/cj1/zz/book/02.recognize_digits/train.py\", line 263, in <module>\r\n    main(use_cuda=use_cuda, nn_type=predict)\r\nC++ Callstacks: \r\nCannot load cudnn shared library. Cannot invoke method cudnnGetVersion at [/paddle/paddle/fluid/platform/dynload/cudnn.cc:59]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f338b3a1eb0p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f338b3a2229p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f338d1fcd48p paddle::platform::dynload::EnforceCUDNNLoaded(char const*) + 200\r\n3       0x7f338d1d9515p paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace) + 741\r\n4       0x7f338d1de1e8p std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&) + 104\r\n5       0x7f338d1dc7cap std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&) + 42\r\n6       0x7f338b46e747p std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) + 39\r\n7       0x7f33e9761827p\r\n8       0x7f338d1dfabcp std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred() + 220\r\n9       0x7f338d1d9fe9p paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 137\r\n10      0x7f338d12c6d8p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 72\r\n11      0x7f338d12d094p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 292\r\n12      0x7f338d12a9bcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n13      0x7f338b5145dep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382\r\n14      0x7f338b51541fp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143\r\n15      0x7f338b391abep\r\n16      0x7f338b3d497ep\r\n17            0x565d5cp _PyCFunction_FastCallDict + 860\r\n18            0x503073p\r\n19            0x506859p _PyEval_EvalFrameDefault + 1097\r\n20            0x504c28p\r\n21            0x502540p\r\n22            0x502f3dp\r\n23            0x507641p _PyEval_EvalFrameDefault + 4657\r\n24            0x504c28p\r\n25            0x502540p\r\n26            0x502f3dp\r\n27            0x506859p _PyEval_EvalFrameDefault + 1097\r\n28            0x504c28p\r\n29            0x502540p\r\n30            0x502f3dp\r\n31            0x507641p _PyEval_EvalFrameDefault + 4657\r\n32            0x504c28p\r\n33            0x502540p\r\n34            0x502f3dp\r\n35            0x507641p _PyEval_EvalFrameDefault + 4657\r\n36            0x504c28p\r\n37            0x506393p PyEval_EvalCode + 35\r\n38            0x634d52p\r\n39            0x634e0ap PyRun_FileExFlags + 154\r\n40            0x6385c8p PyRun_SimpleFileExFlags + 392\r\n41            0x63915ap Py_Main + 1402\r\n42            0x4a6f10p main + 224\r\n43      0x7f33e9992b97p __libc_start_main + 231\r\n44            0x5afa0ap _start + 42     0x7fá\r\n\r\n最后是整个代码：\r\n`\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport argparse\r\nfrom PIL import Image\r\nimport numpy\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport time\r\n\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(\"mnist\")\r\n    parser.add_argument(\r\n        '--enable_ce',\r\n        action='store_true',\r\n        help=\"If set, run the task with continuous evaluation logs.\")\r\n    parser.add_argument(\r\n        '--use_gpu',\r\n        type=bool,\r\n        default=False,\r\n        help=\"Whether to use GPU or not.\")\r\n    parser.add_argument(\r\n        '--num_epochs', type=int, default=5, help=\"number of epochs.\")\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\ndef loss_net(hidden, label):\r\n    prediction = fluid.layers.fc(input=hidden, size=10, act='softmax')\r\n    loss = fluid.layers.cross_entropy(input=prediction, label=label)\r\n    avg_loss = fluid.layers.mean(loss)\r\n    acc = fluid.layers.accuracy(input=prediction, label=label)\r\n    return prediction, avg_loss, acc\r\n\r\n\r\ndef multilayer_perceptron(img, label):\r\n    img = fluid.layers.fc(input=img, size=200, act='tanh')\r\n    hidden = fluid.layers.fc(input=img, size=200, act='tanh')\r\n    return loss_net(hidden, label)\r\n\r\n\r\ndef softmax_regression(img, label):\r\n    return loss_net(img, label)\r\n\r\n\r\ndef convolutional_neural_network(img, label):\r\n    conv_pool_1 = fluid.nets.simple_img_conv_pool(\r\n        input=img,\r\n        filter_size=5,\r\n        num_filters=20,\r\n        pool_size=2,\r\n        pool_stride=2,\r\n        act=\"relu\")\r\n    conv_pool_1 = fluid.layers.batch_norm(conv_pool_1)\r\n    conv_pool_2 = fluid.nets.simple_img_conv_pool(\r\n        input=conv_pool_1,\r\n        filter_size=5,\r\n        num_filters=50,\r\n        pool_size=2,\r\n        pool_stride=2,\r\n        act=\"relu\")\r\n    return loss_net(conv_pool_2, label)\r\n\r\n\r\ndef train(nn_type,\r\n          use_cuda,\r\n          save_dirname=None,\r\n          model_filename=None,\r\n          params_filename=None):\r\n    if use_cuda and not fluid.core.is_compiled_with_cuda():\r\n        return\r\n\r\n    startup_program = fluid.default_startup_program()\r\n    main_program = fluid.default_main_program()\r\n\r\n    if args.enable_ce:\r\n        train_reader = paddle.batch(\r\n            paddle.dataset.mnist.train(), batch_size=BATCH_SIZE)\r\n        test_reader = paddle.batch(\r\n            paddle.dataset.mnist.test(), batch_size=BATCH_SIZE)\r\n        startup_program.random_seed = 90\r\n        main_program.random_seed = 90\r\n    else:\r\n        train_reader = paddle.batch(\r\n            paddle.reader.shuffle(paddle.dataset.mnist.train(), buf_size=500),\r\n            batch_size=BATCH_SIZE)\r\n        test_reader = paddle.batch(\r\n            paddle.dataset.mnist.test(), batch_size=BATCH_SIZE)\r\n\r\n    img = fluid.layers.data(name='img', shape=[1, 28, 28], dtype='float32')\r\n    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n\r\n    if nn_type == 'softmax_regression':\r\n        net_conf = softmax_regression\r\n    elif nn_type == 'multilayer_perceptron':\r\n        net_conf = multilayer_perceptron\r\n    else:\r\n        net_conf = convolutional_neural_network\r\n\r\n    prediction, avg_loss, acc = net_conf(img, label)\r\n\r\n    test_program = main_program.clone(for_test=True)\r\n    optimizer = fluid.optimizer.Adam(learning_rate=0.001)\r\n    optimizer.minimize(avg_loss)\r\n\r\n    def train_test(train_test_program, train_test_feed, train_test_reader):\r\n        acc_set = []\r\n        avg_loss_set = []\r\n        for test_data in train_test_reader():\r\n            acc_np, avg_loss_np = exe.run(\r\n                program=train_test_program,\r\n                feed=train_test_feed.feed(test_data),\r\n                fetch_list=[acc, avg_loss])\r\n            acc_set.append(float(acc_np))\r\n            avg_loss_set.append(float(avg_loss_np))\r\n        # get test acc and loss\r\n        acc_val_mean = numpy.array(acc_set).mean()\r\n        avg_loss_val_mean = numpy.array(avg_loss_set).mean()\r\n        return avg_loss_val_mean, acc_val_mean\r\n\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n\r\n\r\n    exe = fluid.Executor(place)\r\n\r\n    compiled_prog = fluid.compiler.CompiledProgram(\r\n        fluid.default_main_program()).with_data_parallel(\r\n        loss_name=[avg_loss, acc])\r\n\r\n    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\r\n    exe.run(startup_program)\r\n    epochs = [epoch_id for epoch_id in range(PASS_NUM)]\r\n\r\n    lists = []\r\n    step = 0\r\n    for epoch_id in epochs:\r\n        for step_id, data in enumerate(train_reader()):\r\n            metrics = exe.run(\r\n                compiled_prog,\r\n                feed=feeder.feed(data),\r\n                fetch_list=[avg_loss, acc])\r\n            if step % 100 == 0:\r\n                print(\"Pass %d, Batch %d, Cost %f\" % (step, epoch_id,\r\n                                                      metrics[0]))\r\n            step += 1\r\n        # test for epoch\r\n        avg_loss_val, acc_val = train_test(\r\n            train_test_program=test_program,\r\n            train_test_reader=test_reader,\r\n            train_test_feed=feeder)\r\n\r\n        print(\"Test with Epoch %d, avg_cost: %s, acc: %s\" %\r\n              (epoch_id, avg_loss_val, acc_val))\r\n        lists.append((epoch_id, avg_loss_val, acc_val))\r\n        if save_dirname is not None:\r\n            fluid.io.save_inference_model(\r\n                save_dirname, [\"img\"], [prediction],\r\n                exe,\r\n                model_filename=model_filename,\r\n                params_filename=params_filename)\r\n\r\n    if args.enable_ce:\r\n        print(\"kpis\\ttrain_cost\\t%f\" % metrics[0])\r\n        print(\"kpis\\ttest_cost\\t%s\" % avg_loss_val)\r\n        print(\"kpis\\ttest_acc\\t%s\" % acc_val)\r\n\r\n    # find the best pass\r\n    best = sorted(lists, key=lambda list: float(list[1]))[0]\r\n    print('Best pass is %s, testing Avgcost is %s' % (best[0], best[1]))\r\n    print('The classification accuracy is %.2f%%' % (float(best[2]) * 100))\r\n\r\n\r\ndef infer(use_cuda,\r\n          save_dirname=None,\r\n          model_filename=None,\r\n          params_filename=None):\r\n    if save_dirname is None:\r\n        return\r\n\r\n    place = fluid.CUDAPlace(3) if use_cuda else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    t1=time.time()\r\n    def load_image(file):\r\n        im = Image.open(file).convert('L')\r\n        im = im.resize((28, 28), Image.ANTIALIAS)\r\n        im = numpy.array(im).reshape(1, 1, 28, 28).astype(numpy.float32)\r\n        im = im / 255.0 * 2.0 - 1.0\r\n        return im\r\n\r\n    cur_dir = os.path.dirname(os.path.realpath(__file__))\r\n    tensor_img = load_image(cur_dir + '/image/infer_3.png')\r\n\r\n    inference_scope = fluid.core.Scope()\r\n    with fluid.scope_guard(inference_scope):\r\n        # Use fluid.io.load_inference_model to obtain the inference program desc,\r\n        # the feed_target_names (the names of variables that will be feeded\r\n        # data using feed operators), and the fetch_targets (variables that\r\n        # we want to obtain data from using fetch operators).\r\n        [inference_program, feed_target_names,\r\n         fetch_targets] = fluid.io.load_inference_model(\r\n             save_dirname, exe, model_filename, params_filename)\r\n\r\n        # Construct feed as a dictionary of {feed_target_name: feed_target_data}\r\n        # and results will contain a list of data corresponding to fetch_targets.\r\n        results = exe.run(\r\n            inference_program,\r\n            feed={feed_target_names[0]: tensor_img},\r\n            fetch_list=fetch_targets)\r\n        lab = numpy.argsort(results)\r\n        print(\"Inference result of image/infer_3.png is: %d\" % lab[0][0][-1])\r\n    t2=time.time()\r\n    print(t2-t1)\r\n\r\ndef main(use_cuda, nn_type):\r\n    model_filename = None\r\n    params_filename = None\r\n    save_dirname = \"recognize_digits_\" + nn_type + \".inference.model\"\r\n    t1=time.time()\r\n    # call train() with is_local argument to run distributed train\r\n    train(\r\n        nn_type=nn_type,\r\n        use_cuda=use_cuda,\r\n        save_dirname=save_dirname,\r\n        model_filename=model_filename,\r\n        params_filename=params_filename)\r\n    t3=time.time()\r\n    infer(\r\n        use_cuda=use_cuda,\r\n        save_dirname=save_dirname,\r\n        model_filename=model_filename,\r\n        params_filename=params_filename)\r\n    t2=time.time()\r\n    print(t3-t1)\r\n    print(t2-t3)\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = parse_args()\r\n    BATCH_SIZE = 64\r\n    PASS_NUM = args.num_epochs\r\n    use_cuda = args.use_gpu\r\n    predict = 'softmax_regression' # uncomment for Softmax\r\n    # predict = 'multilayer_perceptron' # uncomment for MLP\r\n    # predict = 'convolutional_neural_network'  # uncomment for LeNet5\r\n    main(use_cuda=use_cuda, nn_type=predict)\r\n`",
        "state": "open",
        "user": "DianaZhang",
        "closed_by": null,
        "created_at": "2019-06-13T07:03:42+00:00",
        "updated_at": "2019-06-20T06:20:57+00:00",
        "closed_at": null,
        "comments_count": [
            "chengduoZH",
            "DianaZhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 747,
        "title": "08.machine_translation infer时报错",
        "body": "代码使用train.py中的代码，但是数据集是自己的，训练完成了，但是infer时报错：\r\nEnforceNotMet: Invoke operator sequence_expand error.\r\n\r\nC++ Callstacks:\r\nDataType of Paddle Op sequence_expand Y must be the same. Get (float) != (int64_t) at [/paddle/paddle/fluid/framework/operator.cc:1115]\r\n\r\nfrom future import print_function\r\nimport os\r\nimport six\r\n\r\nimport numpy as np\r\nimport paddle\r\nimport paddle.fluid as fluid\r\n\r\ndict_size = 29364\r\nsource_dict_size = target_dict_size = dict_size\r\nword_dim = 512\r\nhidden_dim = 512\r\ndecoder_size = hidden_dim\r\nmax_length = 256\r\nbeam_size = 4\r\nbatch_size = 64\r\n\r\nis_sparse = True\r\nmodel_save_dir = \"1_machine_translation.inference.model\"\r\n\r\ndef encoder():\r\nsrc_word_id = fluid.layers.data(\r\nname=\"src_word_id\", shape=[1], dtype='int64', lod_level=1)\r\nsrc_embedding = fluid.layers.embedding(\r\ninput=src_word_id,\r\nsize=[source_dict_size, word_dim],\r\ndtype='float32',\r\nis_sparse=is_sparse,param_attr='shared_w')\r\n\r\nfc_forward = fluid.layers.fc(\r\n    input=src_embedding, size=hidden_dim * 3, bias_attr=False)\r\nsrc_forward = fluid.layers.dynamic_gru(input=fc_forward, size=hidden_dim)\r\nfc_backward = fluid.layers.fc(\r\n    input=src_embedding, size=hidden_dim * 3, bias_attr=False)\r\nsrc_backward = fluid.layers.dynamic_gru(\r\n    input=fc_backward, size=hidden_dim, is_reverse=True)\r\nencoded_vector = fluid.layers.concat(\r\n    input=[src_forward, src_backward], axis=1)\r\nreturn encoded_vector\r\ndef cell(x, hidden, encoder_out, encoder_out_proj):\r\ndef simple_attention(encoder_vec, encoder_proj, decoder_state):\r\ndecoder_state_proj = fluid.layers.fc(\r\ninput=decoder_state, size=decoder_size, bias_attr=False)\r\ndecoder_state_expand = fluid.layers.sequence_expand(\r\nx=decoder_state_proj, y=encoder_proj)\r\nmixed_state = fluid.layers.elementwise_add(encoder_proj,\r\ndecoder_state_expand)\r\nattention_weights = fluid.layers.fc(\r\ninput=mixed_state, size=1, bias_attr=False)\r\nattention_weights = fluid.layers.sequence_softmax(\r\ninput=attention_weights)\r\nweigths_reshape = fluid.layers.reshape(x=attention_weights, shape=[-1])\r\nscaled = fluid.layers.elementwise_mul(\r\nx=encoder_vec, y=weigths_reshape, axis=0)\r\ncontext = fluid.layers.sequence_pool(input=scaled, pool_type='sum')\r\nreturn context\r\n\r\ncontext = simple_attention(encoder_out, encoder_out_proj, hidden)\r\nout = fluid.layers.fc(\r\n    input=[x, context], size=decoder_size * 3, bias_attr=False)\r\nout = fluid.layers.gru_unit(\r\n    input=out, hidden=hidden, size=decoder_size * 3)[0]\r\nreturn out, out\r\ndef train_decoder(encoder_out):\r\nencoder_last = fluid.layers.sequence_last_step(input=encoder_out)\r\nencoder_last_proj = fluid.layers.fc(\r\ninput=encoder_last, size=decoder_size, act='tanh')\r\n# cache the encoder_out's computed result in attention\r\nencoder_out_proj = fluid.layers.fc(\r\ninput=encoder_out, size=decoder_size, bias_attr=False)\r\n\r\ntrg_language_word = fluid.layers.data(\r\n    name=\"target_language_word\", shape=[1], dtype='int64', lod_level=1)\r\ntrg_embedding = fluid.layers.embedding(\r\n    input=trg_language_word,\r\n    size=[target_dict_size, word_dim],\r\n    dtype='float32',\r\n    is_sparse=is_sparse,param_attr='shared_w')\r\n\r\nrnn = fluid.layers.DynamicRNN()\r\nwith rnn.block():\r\n    x = rnn.step_input(trg_embedding)\r\n    pre_state = rnn.memory(init=encoder_last_proj, need_reorder=True)\r\n    encoder_out = rnn.static_input(encoder_out)\r\n    encoder_out_proj = rnn.static_input(encoder_out_proj)\r\n    out, current_state = cell(x, pre_state, encoder_out, encoder_out_proj)\r\n    prob = fluid.layers.fc(input=out, size=target_dict_size, act='softmax')\r\n\r\n    rnn.update_memory(pre_state, current_state)\r\n    rnn.output(prob)\r\n\r\nreturn rnn()\r\ndef train_model():\r\nencoder_out = encoder()\r\nrnn_out = train_decoder(encoder_out)\r\nlabel = fluid.layers.data(\r\nname=\"target_language_next_word\", shape=[1], dtype='int64', lod_level=1)\r\ncost = fluid.layers.cross_entropy(input=rnn_out, label=label)\r\navg_cost = fluid.layers.mean(cost)\r\nreturn avg_cost\r\n\r\ndef optimizer_func():\r\nfluid.clip.set_gradient_clip(\r\nclip=fluid.clip.GradientClipByGlobalNorm(clip_norm=5.0))\r\nlr_decay = fluid.layers.learning_rate_scheduler.noam_decay(hidden_dim, 1000)\r\nreturn fluid.optimizer.Adam(\r\nlearning_rate=lr_decay,\r\nregularization=fluid.regularizer.L2DecayRegularizer(\r\nregularization_coeff=1e-4))\r\n\r\ndef train(use_cuda):\r\ntrain_prog = fluid.Program()\r\nstartup_prog = fluid.Program()\r\nwith fluid.program_guard(train_prog, startup_prog):\r\nwith fluid.unique_name.guard():\r\navg_cost = train_model()\r\noptimizer = optimizer_func()\r\noptimizer.minimize(avg_cost)\r\n\r\nplace = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\n#fluid.io.load_params(exe, model_save_dir, main_program=train_prog)\r\n\r\ntrain_data = paddle.batch(\r\n        paddle.reader.shuffle(\r\n            train_reader1, buf_size=100000),\r\n        batch_size=batch_size)\r\n\r\nfeeder = fluid.DataFeeder(\r\n    feed_list=[\r\n        'src_word_id', 'target_language_word', 'target_language_next_word'\r\n    ],\r\n    place=place,\r\n    program=train_prog)\r\n\r\nexe.run(startup_prog)\r\n\r\nEPOCH_NUM = 20\r\nfor pass_id in six.moves.xrange(EPOCH_NUM):\r\n    batch_id = 0\r\n    for data in train_data():\r\n        cost = exe.run(\r\n            train_prog, feed=feeder.feed(data), fetch_list=[avg_cost])[0]\r\n        print('pass_id: %d, batch_id: %d, loss: %f' % (pass_id, batch_id,\r\n                                                       cost))\r\n        batch_id += 1\r\n    fluid.io.save_params(exe, model_save_dir, main_program=train_prog)\r\ndef infer_decoder(encoder_out):\r\nencoder_last = fluid.layers.sequence_last_step(input=encoder_out)\r\nencoder_last_proj = fluid.layers.fc(\r\ninput=encoder_last, size=decoder_size, act='tanh')\r\nencoder_out_proj = fluid.layers.fc(\r\ninput=encoder_out, size=decoder_size, bias_attr=False)\r\n\r\nmax_len = fluid.layers.fill_constant(\r\n    shape=[1], dtype='int64', value=max_length)\r\ncounter = fluid.layers.zeros(shape=[1], dtype='int64', force_cpu=True)\r\n\r\ninit_ids = fluid.layers.data(\r\n    name=\"init_ids\", shape=[1], dtype=\"int64\", lod_level=2)\r\ninit_scores = fluid.layers.data(\r\n    name=\"init_scores\", shape=[1], dtype=\"float32\", lod_level=2)\r\n# create and init arrays to save selected ids, scores and states for each step\r\nids_array = fluid.layers.array_write(init_ids, i=counter)\r\nscores_array = fluid.layers.array_write(init_scores, i=counter)\r\nstate_array = fluid.layers.array_write(encoder_last_proj, i=counter)\r\n\r\ncond = fluid.layers.less_than(x=counter, y=max_len)\r\nwhile_op = fluid.layers.While(cond=cond)\r\nwith while_op.block():\r\n    pre_ids = fluid.layers.array_read(array=ids_array, i=counter)\r\n    pre_score = fluid.layers.array_read(array=scores_array, i=counter)\r\n    pre_state = fluid.layers.array_read(array=state_array, i=counter)\r\n\r\n    pre_ids_emb = fluid.layers.embedding(\r\n        input=pre_ids,\r\n        size=[target_dict_size, word_dim],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,param_attr='shared_w')\r\n    out, current_state = cell(pre_ids_emb, pre_state, encoder_out,\r\n                              encoder_out_proj)\r\n    prob = fluid.layers.fc(\r\n        input=current_state, size=target_dict_size, act='softmax')\r\n\r\n    # beam search\r\n    topk_scores, topk_indices = fluid.layers.topk(prob, k=beam_size)\r\n    accu_scores = fluid.layers.elementwise_add(\r\n        x=fluid.layers.log(topk_scores),\r\n        y=fluid.layers.reshape(pre_score, shape=[-1]),\r\n        axis=0)\r\n    accu_scores = fluid.layers.lod_reset(x=accu_scores, y=pre_ids)\r\n    selected_ids, selected_scores = fluid.layers.beam_search(\r\n        pre_ids, pre_score, topk_indices, accu_scores, beam_size, end_id=1)\r\n\r\n    fluid.layers.increment(x=counter, value=1, in_place=True)\r\n    # save selected ids and corresponding scores of each step\r\n    fluid.layers.array_write(selected_ids, array=ids_array, i=counter)\r\n    fluid.layers.array_write(selected_scores, array=scores_array, i=counter)\r\n    # update rnn state by sequence_expand acting as gather\r\n    current_state = fluid.layers.sequence_expand(current_state,\r\n                                                 selected_ids)\r\n    fluid.layers.array_write(current_state, array=state_array, i=counter)\r\n    current_enc_out = fluid.layers.sequence_expand(encoder_out,\r\n                                                   selected_ids)\r\n    fluid.layers.assign(current_enc_out, encoder_out)\r\n    current_enc_out_proj = fluid.layers.sequence_expand(encoder_out_proj,\r\n                                                        selected_ids)\r\n    fluid.layers.assign(current_enc_out_proj, encoder_out_proj)\r\n\r\n    # update conditional variable\r\n    length_cond = fluid.layers.less_than(x=counter, y=max_len)\r\n    finish_cond = fluid.layers.logical_not(\r\n        fluid.layers.is_empty(x=selected_ids))\r\n    fluid.layers.logical_and(x=length_cond, y=finish_cond, out=cond)\r\n\r\ntranslation_ids, translation_scores = fluid.layers.beam_search_decode(\r\n    ids=ids_array, scores=scores_array, beam_size=beam_size, end_id=1)\r\n\r\nreturn translation_ids, translation_scores\r\ndef infer_model():\r\nencoder_out = encoder()\r\ntranslation_ids, translation_scores = infer_decoder(encoder_out)\r\nreturn translation_ids, translation_scores\r\n\r\ndef infer(use_cuda):\r\ninfer_prog = fluid.Program()\r\nstartup_prog = fluid.Program()\r\nwith fluid.program_guard(infer_prog, startup_prog):\r\nwith fluid.unique_name.guard():\r\ntranslation_ids, translation_scores = infer_model()\r\n\r\nplace = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\n\r\ntest_data = paddle.batch(\r\n    test_reader,\r\n    batch_size=batch_size)\r\nsrc_idx2word = reverse_vocab\r\ntrg_idx2word = reverse_vocab\r\n\r\nfluid.io.load_params(exe, model_save_dir, main_program=infer_prog)\r\n\r\nfor data in test_data():\r\n    src_word_id = fluid.create_lod_tensor(\r\n        data=[x[0] for x in data],\r\n        recursive_seq_lens=[[len(x[0]) for x in data]],\r\n        place=place)\r\n    init_ids = fluid.create_lod_tensor(\r\n        data=np.array([[0]] * len(data), dtype='int64'),\r\n        recursive_seq_lens=[[1] * len(data)] * 2,\r\n        place=place)\r\n    init_scores = fluid.create_lod_tensor(\r\n        data=np.array([[0.]] * len(data), dtype='float32'),\r\n        recursive_seq_lens=[[1] * len(data)] * 2,\r\n        place=place)\r\n    seq_ids, seq_scores = exe.run(\r\n        infer_prog,\r\n        feed={\r\n            'src_word_id': src_word_id,\r\n            'init_ids': init_ids,\r\n            'init_scores': init_scores\r\n        },\r\n        fetch_list=[translation_ids, translation_scores],\r\n        return_numpy=False)\r\n    # How to parse the results:\r\n    #   Suppose the lod of seq_ids is:\r\n    #     [[0, 3, 6], [0, 12, 24, 40, 54, 67, 82]]\r\n    #   then from lod[0]:\r\n    #     there are 2 source sentences, beam width is 3.\r\n    #   from lod[1]:\r\n    #     the first source sentence has 3 hyps; the lengths are 12, 12, 16\r\n    #     the second source sentence has 3 hyps; the lengths are 14, 13, 15\r\n    hyps = [[] for i in range(len(seq_ids.lod()[0]) - 1)]\r\n    scores = [[] for i in range(len(seq_scores.lod()[0]) - 1)]\r\n    for i in range(len(seq_ids.lod()[0]) - 1):  # for each source sentence\r\n        start = seq_ids.lod()[0][i]\r\n        end = seq_ids.lod()[0][i + 1]\r\n        print(\"Original sentence:\")\r\n        print(\" \".join([src_idx2word[idx] for idx in data[i][0][1:-1]]))\r\n        print(\"Translated score and sentence:\")\r\n        for j in range(end - start):  # for each candidate\r\n            sub_start = seq_ids.lod()[1][start + j]\r\n            sub_end = seq_ids.lod()[1][start + j + 1]\r\n            hyps[i].append(\" \".join([\r\n                trg_idx2word[idx]\r\n                for idx in np.array(seq_ids)[sub_start:sub_end][1:-1]\r\n            ]))\r\n            scores[i].append(np.array(seq_scores)[sub_end - 1])\r\n            print(scores[i][-1], hyps[i][-1].encode('utf8'))\r\ndef main(use_cuda):\r\ntrain(use_cuda)\r\n#infer(use_cuda)\r\n\r\nif name == 'main':\r\nuse_cuda = False # set to True if training with GPU\r\nmain(use_cuda)\r\n#infer(use_cuda)",
        "state": "open",
        "user": "Alanyh",
        "closed_by": null,
        "created_at": "2019-06-16T05:39:53+00:00",
        "updated_at": "2019-06-19T06:55:28+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS",
            "Alanyh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 763,
        "title": "请问推荐系统的官方例子的训练速度是怎么样的",
        "body": "我这边用的是单卡Tesla V100-SXM2，3天存训练了不到2000轮，loss 2.4",
        "state": "closed",
        "user": "lijc210",
        "closed_by": "lijc210",
        "created_at": "2019-06-20T10:37:11+00:00",
        "updated_at": "2023-08-23T05:52:23+00:00",
        "closed_at": "2023-08-23T05:52:23+00:00",
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 754,
        "title": "03.image_classification 报错",
        "body": "Inferencer 配置和预测\r\n代码部分运行报错\r\n\r\nValueErrorTraceback (most recent call last)\r\n<ipython-input-15-93da5af3de14> in <module>()\r\n      6 \r\n      7     [inference_program, feed_target_names,\r\n----> 8      fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\r\n      9 \r\n     10         # The input's dimension of conv should be 4-D or 5-D.\r\n\r\n/opt/conda/lib/python2.7/site-packages/paddle/fluid/io.pyc in load_inference_model(dirname, executor, model_filename, params_filename, pserver_endpoints)\r\n   1079     \"\"\"\r\n   1080     if not os.path.isdir(dirname):\r\n-> 1081         raise ValueError(\"There is no directory named '%s'\", dirname)\r\n   1082 \r\n   1083     if model_filename is not None:\r\n\r\nValueError: (\"There is no directory named '%s'\", 'image_classification_resnet.inference.model')",
        "state": "open",
        "user": "luckeriam",
        "closed_by": null,
        "created_at": "2019-06-19T09:51:26+00:00",
        "updated_at": "2019-06-25T07:14:28+00:00",
        "closed_at": null,
        "comments_count": [
            "wzzju",
            "luckeriam",
            "wzzju",
            "luckeriam",
            "wzzju"
        ],
        "labels": [
            "usr"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 764,
        "title": "提一个04.word2vec README.cn.md的bug",
        "body": "def infer 方法中\r\n        data1 = [[211]] # 'among'\r\n        data2 = [[6]] # 'a'\r\n        data3 = [[96]] # 'group'\r\n        data4 = [[4]] # 'of'\r\n        lod = [[1]]\r\n运行会报错，按照train.py按如下转换就正常了：\r\n data1 = [[numpy.int64(211)]]  # 'among'\r\n        data2 = [[numpy.int64(6)]]    # 'a'\r\n        data3 = [[numpy.int64(96)]]   # 'group'\r\n        data4 = [[numpy.int64(4)]]    # 'of'\r\n        lod = [[numpy.int64(1)]]",
        "state": "closed",
        "user": "xonze",
        "closed_by": "junjun315",
        "created_at": "2019-06-24T02:54:37+00:00",
        "updated_at": "2019-07-10T11:43:48+00:00",
        "closed_at": "2019-07-10T11:43:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 775,
        "title": "GPU 跑03.image_classification报错，只修改了use_cuda=true；train.py跑正常",
        "body": "\r\n```shell\r\nEnforceNotMetTraceback (most recent call last)\r\n<ipython-input-32-6590b82f66d8> in <module>()\r\n----> 1 train_loop()\r\n\r\n<ipython-input-31-373fd84903b7> in train_loop()\r\n     28 \r\n     29         avg_cost_test, accuracy_test = train_test(test_program,\r\n---> 30                                                   reader=test_reader)\r\n     31         plot_cost.append(test_prompt, step, avg_cost_test)\r\n     32 \r\n\r\n<ipython-input-30-4806cfbf43de> in train_test(program, reader)\r\n     34         avg_cost_np = test_exe.run(program=program,\r\n     35                                    feed=feeder_test.feed(test_data),\r\n---> 36                                    fetch_list=[avg_cost, acc])\r\n     37         accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\r\n     38         count += 1\r\n\r\n/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.pyc in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    470 \r\n    471         self._feed_data(program, feed, feed_var_name, scope)\r\n--> 472         self.executor.run(program.desc, scope, 0, True, True)\r\n    473         outs = self._fetch_data(fetch_list, fetch_var_name, scope)\r\n    474         if return_numpy:\r\n\r\nEnforceNotMet: holder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:22]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f46f0ddebf2p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482\r\n1       0x7f46f2685f5fp paddle::framework::Tensor::check_memory_size() const + 207\r\n2       0x7f46f0de9625p float const* paddle::framework::Tensor::data<float>() const + 21\r\n3       0x7f46f163b73ep paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 1822\r\n4       0x7f46f163d040p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::BatchNormGradKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 32\r\n5       0x7f46f2619bcap paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 506\r\n6       0x7f46f2615f4fp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 447\r\n7       0x7f46f0eb34a7p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 247\r\n8       0x7f46f0eb3e15p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 117\r\n9       0x7f46f0dcaaf2p\r\n10      0x7f46f0e0739cp\r\n11            0x4c5326p PyEval_EvalFrameEx + 37958\r\n12            0x4b9b66p PyEval_EvalCodeEx + 774\r\n13            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n14            0x4b9b66p PyEval_EvalCodeEx + 774\r\n15            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n16            0x4b9b66p PyEval_EvalCodeEx + 774\r\n17            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n18            0x4b9b66p PyEval_EvalCodeEx + 774\r\n19            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n20            0x4b9b66p PyEval_EvalCodeEx + 774\r\n21            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n22            0x4b9b66p PyEval_EvalCodeEx + 774\r\n23            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n24            0x4b9b66p PyEval_EvalCodeEx + 774\r\n25            0x4d57a3p\r\n26            0x4a587ep PyObject_Call + 62\r\n27            0x4be51ep PyEval_EvalFrameEx + 9790\r\n28            0x4b9b66p PyEval_EvalCodeEx + 774\r\n29            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n30            0x4b9b66p PyEval_EvalCodeEx + 774\r\n31            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n32            0x4b9b66p PyEval_EvalCodeEx + 774\r\n33            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n34            0x4b9b66p PyEval_EvalCodeEx + 774\r\n35            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n36            0x4b9b66p PyEval_EvalCodeEx + 774\r\n37            0x4d57a3p\r\n38            0x4a587ep PyObject_Call + 62\r\n39            0x4be51ep PyEval_EvalFrameEx + 9790\r\n40            0x4b9b66p PyEval_EvalCodeEx + 774\r\n41            0x4d57a3p\r\n42            0x4a587ep PyObject_Call + 62\r\n43            0x4be51ep PyEval_EvalFrameEx + 9790\r\n44            0x4b9b66p PyEval_EvalCodeEx + 774\r\n45            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n46            0x4b9b66p PyEval_EvalCodeEx + 774\r\n47            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n48            0x4b9b66p PyEval_EvalCodeEx + 774\r\n49            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n50            0x4b9b66p PyEval_EvalCodeEx + 774\r\n51            0x4d57a3p\r\n52            0x4a587ep PyObject_Call + 62\r\n53            0x4be51ep PyEval_EvalFrameEx + 9790\r\n54            0x4b9b66p PyEval_EvalCodeEx + 774\r\n55            0x4d5669p\r\n56            0x4a587ep PyObject_Call + 62\r\n57            0x53a183p\r\n58            0x4c166dp PyEval_EvalFrameEx + 22413\r\n59            0x4b9b66p PyEval_EvalCodeEx + 774\r\n60            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n61            0x4b9b66p PyEval_EvalCodeEx + 774\r\n62            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n63            0x4b9b66p PyEval_EvalCodeEx + 774\r\n64            0x4c1f56p PyEval_EvalFrameEx + 24694\r\n65            0x4b9b66p PyEval_EvalCodeEx + 774\r\n66            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n67            0x4b9b66p PyEval_EvalCodeEx + 774\r\n68            0x4bf7a2p PyEval_EvalFrameEx + 14530\r\n69            0x4b9b66p PyEval_EvalCodeEx + 774\r\n70            0x4c17c6p PyEval_EvalFrameEx + 22758\r\n71            0x4b9b66p PyEval_EvalCodeEx + 774\r\n72            0x4d5669p\r\n73            0x4a587ep PyObject_Call + 62\r\n74            0x51a866p\r\n75            0x4939ccp Py_Main + 1612\r\n76      0x7f47b97e3830p __libc_start_main + 240\r\n77            0x493299p _start + 41\r\n\r\n```",
        "state": "closed",
        "user": "mmglove",
        "closed_by": "ysh329",
        "created_at": "2019-07-16T08:46:32+00:00",
        "updated_at": "2019-07-17T09:02:31+00:00",
        "closed_at": "2019-07-17T09:02:31+00:00",
        "comments_count": [
            "ysh329"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 767,
        "title": "根目录README.md没有包含09示例的链接",
        "body": "根目录README.md中没有包含09示例的链接，中文文档也是",
        "state": "open",
        "user": "junjun315",
        "closed_by": null,
        "created_at": "2019-07-05T11:54:02+00:00",
        "updated_at": "2019-07-13T13:35:39+00:00",
        "closed_at": null,
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 774,
        "title": "内容修改申请：book/02.recognize_digits/README.cn.md ",
        "body": "您好，我在做 paddle 教学过程中发现手写字体识别的代码，在教学的时候还有可以修改的空间，因为有些代码冗余，没办法给学员解释，所以申请对代码做一些修改。\r\n\r\n### 1.请删除代码：  \r\n删除函数：optimizer_program\r\n![image](https://user-images.githubusercontent.com/27996442/61215266-f0b85780-a73c-11e9-87b9-18e058d0f10f.png)\r\n该代码并没有在后续代码中调用，写了却没有使用，对学员没法解释\r\n\r\n### 2.修改代码：  \r\n![image](https://user-images.githubusercontent.com/27996442/61215396-599fcf80-a73d-11e9-8f6d-1204c95c7b22.png)\r\n是否可以考虑修改为：\r\n```python\r\n删除：# 输入的原始图像数据，大小为28*28*1\r\n删除：img = fluid.layers.data(name='img', shape=[1, 28, 28], dtype='float32')\r\n删除：# 标签层，名称为label,对应输入图片的类别标签\r\n删除：label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n# 告知网络传入的数据分为两部分，第一部分是img值，第二部分是label值\r\n修改：feeder = fluid.DataFeeder(feed_list=[‘img‘, ’label‘’], place=place)\r\n```\r\n由于 变量和数据层已经在前面函数定义过了，这里又定义一遍，不太好解释\r\n\r\n### 3.增加一点注释：\r\n![image](https://user-images.githubusercontent.com/27996442/61215677-1c880d00-a73e-11e9-916c-848a99a50e84.png)\r\n绝大多数学员应该是对 Image 的操作是不熟悉的，所以如果能加上注释可能更方便学员学习",
        "state": "closed",
        "user": "baihaojie2011",
        "closed_by": "ceci3",
        "created_at": "2019-07-15T12:15:40+00:00",
        "updated_at": "2019-07-19T05:47:53+00:00",
        "closed_at": "2019-07-19T05:47:53+00:00",
        "comments_count": [
            "zhhsplendid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 783,
        "title": "如何提取训练好的embedding?",
        "body": "```python\r\n#coding:utf-8\r\nfrom __future__ import print_function\r\nimport paddle as paddle\r\nimport paddle.fluid as fluid\r\nimport six\r\nimport numpy\r\nimport math\r\nimport sys\r\n\r\n\r\n\r\n\r\nEMBED_SIZE = 32      # embedding维度\r\nHIDDEN_SIZE = 256    # 隐层大小\r\nN = 5                # ngram大小，这里固定取5\r\nBATCH_SIZE = 100     # batch大小\r\nPASS_NUM = 100       # 训练轮数\r\n\r\nuse_cuda = False  # 如果用GPU训练，则设置为True\r\n\r\nword_dict = paddle.dataset.imikolov.build_dict()\r\ndict_size = len(word_dict)\r\n\r\n\r\ndef inference_program(words, is_sparse):\r\n\r\n    embed_first = fluid.layers.embedding(\r\n        input=words[0],\r\n        size=[dict_size, EMBED_SIZE],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,\r\n        param_attr='shared_w')\r\n    embed_second = fluid.layers.embedding(\r\n        input=words[1],\r\n        size=[dict_size, EMBED_SIZE],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,\r\n        param_attr='shared_w')\r\n    embed_third = fluid.layers.embedding(\r\n        input=words[2],\r\n        size=[dict_size, EMBED_SIZE],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,\r\n        param_attr='shared_w')\r\n    embed_fourth = fluid.layers.embedding(\r\n        input=words[3],\r\n        size=[dict_size, EMBED_SIZE],\r\n        dtype='float32',\r\n        is_sparse=is_sparse,\r\n        param_attr='shared_w')\r\n\r\n    concat_embed = fluid.layers.concat(\r\n        input=[embed_first, embed_second, embed_third, embed_fourth], axis=1)\r\n    hidden1 = fluid.layers.fc(input=concat_embed,\r\n                              size=HIDDEN_SIZE,\r\n                              act='sigmoid')\r\n    predict_word = fluid.layers.fc(input=hidden1, size=dict_size, act='softmax')\r\n    return predict_word,embed_first\r\n\r\n\r\ndef train_program(predict_word):\r\n    # 'next_word'的定义必须要在inference_program的声明之后，\r\n    # 否则train program输入数据的顺序就变成了[next_word, firstw, secondw,\r\n    # thirdw, fourthw], 这是不正确的.\r\n    next_word = fluid.layers.data(name='nextw', shape=[1], dtype='int64')\r\n    cost = fluid.layers.cross_entropy(input=predict_word, label=next_word)\r\n    avg_cost = fluid.layers.mean(cost)\r\n    return avg_cost\r\n\r\ndef optimizer_func():\r\n    return fluid.optimizer.AdagradOptimizer(\r\n        learning_rate=3e-3,\r\n        regularization=fluid.regularizer.L2DecayRegularizer(8e-4))\r\n\r\n\r\ndef train(if_use_cuda, params_dirname, embedding_params_dirname, is_sparse=True):\r\n    place = fluid.CUDAPlace(0) if if_use_cuda else fluid.CPUPlace()\r\n\r\n    train_reader = paddle.batch(\r\n        paddle.dataset.imikolov.train(word_dict, N), BATCH_SIZE)\r\n    test_reader = paddle.batch(\r\n        paddle.dataset.imikolov.test(word_dict, N), BATCH_SIZE)\r\n\r\n    first_word = fluid.layers.data(name='firstw', shape=[1], dtype='int64')\r\n    second_word = fluid.layers.data(name='secondw', shape=[1], dtype='int64')\r\n    third_word = fluid.layers.data(name='thirdw', shape=[1], dtype='int64')\r\n    forth_word = fluid.layers.data(name='fourthw', shape=[1], dtype='int64')\r\n    next_word = fluid.layers.data(name='nextw', shape=[1], dtype='int64')\r\n\r\n    word_list = [first_word, second_word, third_word, forth_word, next_word]\r\n    feed_order = ['firstw', 'secondw', 'thirdw', 'fourthw', 'nextw']\r\n\r\n    main_program = fluid.default_main_program()\r\n    star_program = fluid.default_startup_program()\r\n\r\n    predict_word, embed_first = inference_program(word_list, is_sparse)\r\n    avg_cost = train_program(predict_word)\r\n    test_program = main_program.clone(for_test=True)\r\n\r\n    sgd_optimizer = optimizer_func()\r\n    sgd_optimizer.minimize(avg_cost)\r\n\r\n    exe = fluid.Executor(place)\r\n\r\n    def train_test(program, reader):\r\n        count = 0\r\n        feed_var_list = [\r\n            program.global_block().var(var_name) for var_name in feed_order\r\n        ]\r\n        feeder_test = fluid.DataFeeder(feed_list=feed_var_list, place=place)\r\n        test_exe = fluid.Executor(place)\r\n        accumulated = len([avg_cost]) * [0]\r\n        for test_data in reader():\r\n            avg_cost_np = test_exe.run(\r\n                program=program,\r\n                feed=feeder_test.feed(test_data),\r\n                fetch_list=[avg_cost])\r\n            accumulated = [\r\n                x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)\r\n            ]\r\n            count += 1\r\n        return [x / count for x in accumulated]\r\n\r\n    def train_loop():\r\n        step = 0\r\n        feed_var_list_loop = [\r\n            main_program.global_block().var(var_name) for var_name in feed_order\r\n        ]\r\n        feeder = fluid.DataFeeder(feed_list=feed_var_list_loop, place=place)\r\n        exe.run(star_program)\r\n        for pass_id in range(PASS_NUM):\r\n            for data in train_reader():\r\n                avg_cost_np = exe.run(\r\n                    main_program, feed=feeder.feed(data), fetch_list=[avg_cost])\r\n\r\n                if step % 10 == 0:\r\n                    outs = train_test(test_program, test_reader)\r\n\r\n                    print(\"Step %d: Average Cost %f\" % (step, outs[0]))\r\n\r\n                    # 整个训练过程要花费几个小时，如果平均损失低于5.8，\r\n                    # 我们就认为模型已经达到很好的效果可以停止训练了。\r\n                    # 注意5.8是一个相对较高的值，为了获取更好的模型，可以将\r\n                    # 这里的阈值设为3.5，但训练时间也会更长。\r\n                    if outs[0] < 5.8:\r\n                        if params_dirname is not None:\r\n                            fluid.io.save_inference_model(params_dirname, [\r\n                                'firstw', 'secondw', 'thirdw', 'fourthw'\r\n                            ], [predict_word], exe)\r\n                        # 保存embedding参数\r\n                        if embedding_params_dirname is not None:\r\n                            fluid.io.save_inference_model(embedding_params_dirname, [\r\n                                'firstw', 'secondw', 'thirdw', 'fourthw'\r\n                            ], [embed_first], exe)\r\n                        return\r\n                step += 1\r\n                if math.isnan(float(avg_cost_np[0])):\r\n                    sys.exit(\"got NaN loss, training failed.\")\r\n\r\n        raise AssertionError(\"Cost is too large {0:2.2}\".format(avg_cost_np[0]))\r\n\r\n    train_loop()\r\n\r\ndef infer(use_cuda, params_dirname=None):\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n\r\n    exe = fluid.Executor(place)\r\n\r\n    inference_scope = fluid.core.Scope()\r\n    with fluid.scope_guard(inference_scope):\r\n        # 使用fluid.io.load_inference_model获取inference program，\r\n        # feed变量的名称feed_target_names和从scope中fetch的对象fetch_targets\r\n        [inferencer, feed_target_names,\r\n         fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\r\n\r\n        # 设置输入，用四个LoDTensor来表示4个词语。这里每个词都是一个id，\r\n        # 用来查询embedding表获取对应的词向量，因此其形状大小是[1]。\r\n        # recursive_sequence_lengths设置的是基于长度的LoD，因此都应该设为[[1]]\r\n        # 注意recursive_sequence_lengths是列表的列表\r\n        data1 = numpy.asarray([[211]], dtype=numpy.int64)  # 'among'\r\n        data2 = numpy.asarray([[6]], dtype=numpy.int64)  # 'a'\r\n        data3 = numpy.asarray([[96]], dtype=numpy.int64)  # 'group'\r\n        data4 = numpy.asarray([[4]], dtype=numpy.int64)  # 'of'\r\n        lod = numpy.asarray([[1]], dtype=numpy.int64)\r\n\r\n        first_word = fluid.create_lod_tensor(data1, lod, place)\r\n        second_word = fluid.create_lod_tensor(data2, lod, place)\r\n        third_word = fluid.create_lod_tensor(data3, lod, place)\r\n        fourth_word = fluid.create_lod_tensor(data4, lod, place)\r\n\r\n        assert feed_target_names[0] == 'firstw'\r\n        assert feed_target_names[1] == 'secondw'\r\n        assert feed_target_names[2] == 'thirdw'\r\n        assert feed_target_names[3] == 'fourthw'\r\n\r\n        # 构造feed词典 {feed_target_name: feed_target_data}\r\n        # 预测结果包含在results之中\r\n        results = exe.run(\r\n            inferencer,\r\n            feed={\r\n                feed_target_names[0]: first_word,\r\n                feed_target_names[1]: second_word,\r\n                feed_target_names[2]: third_word,\r\n                feed_target_names[3]: fourth_word\r\n            },\r\n            fetch_list=fetch_targets,\r\n            return_numpy=False)\r\n\r\n        print(numpy.array(results[0]))\r\n        print('next word results[0]:',numpy.array(results[0]))\r\n        print('next word results[0].shape:',numpy.array(results[0]).shape)\r\n        most_possible_word_index = numpy.argmax(results[0])\r\n        print(most_possible_word_index)\r\n        print([\r\n            key for key, value in six.iteritems(word_dict)\r\n            if value == most_possible_word_index\r\n        ][0])\r\n\r\n\r\ndef embedding_infer(use_cuda, embedding_params_dirname=None):\r\n    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n\r\n    exe = fluid.Executor(place)\r\n\r\n    inference_scope = fluid.core.Scope()\r\n    with fluid.scope_guard(inference_scope):\r\n        # 使用fluid.io.load_inference_model获取inference program，\r\n        # feed变量的名称feed_target_names和从scope中fetch的对象fetch_targets\r\n        [inferencer, feed_target_names,\r\n         fetch_targets] = fluid.io.load_inference_model(embedding_params_dirname, exe)\r\n\r\n        # 设置输入，用四个LoDTensor来表示4个词语。这里每个词都是一个id，\r\n        # 用来查询embedding表获取对应的词向量，因此其形状大小是[1]。\r\n        # recursive_sequence_lengths设置的是基于长度的LoD，因此都应该设为[[1]]\r\n        # 注意recursive_sequence_lengths是列表的列表\r\n        data1 = numpy.asarray([[211]], dtype=numpy.int64)  # 'among'\r\n        data2 = numpy.asarray([[6]], dtype=numpy.int64)  # 'a'\r\n        data3 = numpy.asarray([[96]], dtype=numpy.int64)  # 'group'\r\n        data4 = numpy.asarray([[4]], dtype=numpy.int64)  # 'of'\r\n        lod = numpy.asarray([[1]], dtype=numpy.int64)\r\n\r\n        first_word = fluid.create_lod_tensor(data1, lod, place)\r\n        second_word = fluid.create_lod_tensor(data2, lod, place)\r\n        third_word = fluid.create_lod_tensor(data3, lod, place)\r\n        fourth_word = fluid.create_lod_tensor(data4, lod, place)\r\n\r\n        assert feed_target_names[0] == 'firstw'\r\n        assert feed_target_names[1] == 'secondw'\r\n        assert feed_target_names[2] == 'thirdw'\r\n        assert feed_target_names[3] == 'fourthw'\r\n\r\n        # 构造feed词典 {feed_target_name: feed_target_data}\r\n        # 预测结果包含在results之中\r\n        print(feed_target_names)\r\n        results = exe.run(\r\n            inferencer,\r\n            feed={\r\n                feed_target_names[0]: first_word,\r\n                feed_target_names[1]: second_word,\r\n                feed_target_names[2]: third_word,\r\n                feed_target_names[3]: fourth_word\r\n            },\r\n            # feed={\r\n            #     feed_target_names[0]: data1,\r\n            #     feed_target_names[1]: data2,\r\n            #     feed_target_names[2]: data3,\r\n            #     feed_target_names[3]: data4\r\n            # },\r\n            fetch_list=fetch_targets,\r\n            return_numpy=False)\r\n\r\n        print( word embedding results[0]:',numpy.array(results[0]))\r\n        print( word embedding results[0].shape:',numpy.array(results[0]).shape)\r\n\r\n\r\ndef main(use_cuda, is_sparse):\r\n    if use_cuda and not fluid.core.is_compiled_with_cuda():\r\n        return\r\n\r\n    params_dirname = \"word2vec.inference.model\"\r\n    embedding_params_dirname = \"word2vec.embedding.inference.model\"\r\n\r\n    train(\r\n        if_use_cuda=use_cuda,\r\n        params_dirname=params_dirname,\r\n        embedding_params_dirname=embedding_params_dirname,\r\n        is_sparse=is_sparse)\r\n\r\n    infer(use_cuda=use_cuda, params_dirname=params_dirname)\r\n\r\n    embedding_infer(use_cuda=use_cuda,embedding_params_dirname=embedding_params_dirname)\r\n\r\n\r\nmain(use_cuda=use_cuda, is_sparse=True)\r\n\r\n\r\n\r\n```\r\n\r\noutput:\r\n```python\r\nStep 0: Average Cost 7.377010\r\n\r\nStep 10: Average Cost 6.168406\r\n\r\nStep 20: Average Cost 5.790505\r\n[[0.02989654 0.03431715 0.00012712 ... 0.00019843 0.00016911 0.02760296]]\r\nnext word results[0]: [[0.02989654 0.03431715 0.00012712 ... 0.00019843 0.00016911 0.02760296]]\r\nnext word results[0].shape: (1, 2073)\r\n1\r\n<e>\r\n[u'firstw', u'secondw', u'thirdw', u'fourthw'] \r\nword embedding results[0]: [[0.02989654 0.03431715 0.00012712 ... 0.00019843 0.00016911 0.02760296]] \r\nword embedding results[0].shape: (1, 2073)\r\n```",
        "state": "open",
        "user": "hflyzju",
        "closed_by": null,
        "created_at": "2019-07-24T08:56:41+00:00",
        "updated_at": "2019-07-24T09:03:40+00:00",
        "closed_at": null,
        "comments_count": [
            "hflyzju"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 776,
        "title": "『机器翻译』『词向量』『数字识别』中的一些问题",
        "body": "1.\t『机器翻译』中mixed_state =fluid.layers.elementwise_add(encoder_proj,decoder_state_expand)交换两个参数的位置为什么会导致程序毫无错误提示地直接退出呢？它前一步的decoder_state_expand=fluid.layers.sequence_expand(x=decoder_state_proj,y=encoder_proj)的API看不懂，不明白API中例1的输出怎么来的，例2的输出为什么会是[5,1]，b怎么就没了，同时例2说它的output类型是Tensor，这与后文『返回：扩展变量 LoDTensor』矛盾。\r\n2.\t『词向量』中不明白只是改变了声明的顺序，为什么就说『否则train program输入数据的顺序就变成了[next_word, firstw, secondw,thirdw, fourthw]』\r\n3.  『数字识别』use_conda=False能够正常运行，=True报错，需要修改for_test=False才能够正常运行",
        "state": "open",
        "user": "kinghuin",
        "closed_by": null,
        "created_at": "2019-07-16T13:07:05+00:00",
        "updated_at": "2019-07-22T02:24:30+00:00",
        "closed_at": null,
        "comments_count": [
            "tink2123",
            "kinghuin",
            "tink2123",
            "kinghuin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 785,
        "title": "是否考虑更新打包镜像中的python和cuda版本",
        "body": "cuda8和python2有点老了，无法在测试环境中运行gpu实例，可否更新下或者在book里加一个python3版本的内核",
        "state": "open",
        "user": "epylice",
        "closed_by": null,
        "created_at": "2019-08-02T08:10:13+00:00",
        "updated_at": "2019-09-06T08:03:13+00:00",
        "closed_at": null,
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 787,
        "title": "示例代码错误：02.recognize_digits任务中README.cn.md示例代码有部分语法错误",
        "body": "<img width=\"572\" alt=\"屏幕快照 2019-08-07 下午7 47 37\" src=\"https://user-images.githubusercontent.com/16509038/62620653-7ac69b00-b94c-11e9-9ad2-e04b3ade11f7.png\">\r\n如图，应该改为英文单引号。",
        "state": "open",
        "user": "JepsonWong",
        "closed_by": null,
        "created_at": "2019-08-07T11:50:38+00:00",
        "updated_at": "2019-08-22T06:29:47+00:00",
        "closed_at": null,
        "comments_count": [
            "Xreki",
            "JepsonWong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 790,
        "title": "05.recommender_system，预测的时候如何应对大数据，如果1亿用户需要预测",
        "body": "05.recommender_system，预测的时候如何应对大数据，如果1亿用户需要预测",
        "state": "open",
        "user": "huangxianliang",
        "closed_by": null,
        "created_at": "2019-08-14T11:35:06+00:00",
        "updated_at": "2019-09-06T09:48:31+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 791,
        "title": "from paddle.utils.plot import Ploter 实时画图功能无法触发画布显示",
        "body": "Pycharm  win10  python 3.5  执行的时候console 打印\r\n<Figure size 640x480 with 1 Axes>\r\n<Figure size 640x480 with 1 Axes>\r\n<Figure size 640x480 with 1 Axes>\r\n<Figure size 640x480 with 1 Axes>\r\n<Figure size 640x480 with 1 Axes>\r\n如何解决？\r\n",
        "state": "open",
        "user": "liuzengzhen1",
        "closed_by": null,
        "created_at": "2019-08-14T12:11:31+00:00",
        "updated_at": "2019-09-06T09:48:38+00:00",
        "closed_at": null,
        "comments_count": [
            "hutuxian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 802,
        "title": "机器翻译，英中翻译，训练可以跑通，但是测试报错",
        "body": "![捕获](https://user-images.githubusercontent.com/16262785/64149628-f2f38400-ce58-11e9-876a-e611ecd6f2ec.PNG)\r\n训练集和测试集的数据格式是一样的，预处理过程也是直接仿照VMT16里面的代码来写的",
        "state": "open",
        "user": "AI-Candy-Yang",
        "closed_by": null,
        "created_at": "2019-09-03T06:42:44+00:00",
        "updated_at": "2019-09-06T15:48:23+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 801,
        "title": "data_feeder里面的有一段代码在调试的时候发现好像有点问题",
        "body": "\r\n![捕获](https://user-images.githubusercontent.com/16262785/64148564-2da7ed00-ce56-11e9-9e5c-9c82a2f17960.PNG)\r\n\r\n您好，\r\n    在使用paddlepaddle的时候进行调试报错，定位了一下，这个截图上面的代码是不是有点问题，如果我的data是一维列表，那么遍历的时候each_data就可能是Int类型的元素，继续调用这个方法的时候如果进到else里面就会导致len()这个方法报错\r\n",
        "state": "open",
        "user": "AI-Candy-Yang",
        "closed_by": null,
        "created_at": "2019-09-03T06:24:43+00:00",
        "updated_at": "2019-09-07T04:02:43+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 810,
        "title": "from __future__ imports must occur at the beginning of the file",
        "body": "In this document:\r\nhttps://www.paddlepaddle.org.cn/documentation/docs/zh/beginners_guide/basics/image_classification/index.html\r\nSee this section of codes:\r\n![图片](https://user-images.githubusercontent.com/35131887/65580494-57af8380-dfac-11e9-82c4-29c35089339e.png)\r\nThe line of `from __future__ import print_function` should be above all other imports. Otherwise will encounter a \"from __future__ imports must occur at the beginning of the file\" error.",
        "state": "open",
        "user": "houj04",
        "closed_by": null,
        "created_at": "2019-09-25T07:52:52+00:00",
        "updated_at": "2019-10-09T02:04:21+00:00",
        "closed_at": null,
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 804,
        "title": "06.understand_sentiment情感分析中的问题",
        "body": "def inference_program(word_dict):\r\n    data = fluid.layers.data(\r\n        name=\"words\", shape=[1], dtype=\"int64\", lod_level=1)\r\n\r\n    dict_dim = len(word_dict)\r\n    pred = dynamic_rnn_lstm(data, dict_dim, CLASS_DIM, EMB_DIM, LSTM_SIZE)\r\n    return pred\r\n\r\n请问这个创建的data层为什么shape是[1]呢？\r\n我看了之前的实例，这个data中的shape都代表的是输入数据的维度",
        "state": "open",
        "user": "freefreesea",
        "closed_by": null,
        "created_at": "2019-09-06T08:57:08+00:00",
        "updated_at": "2019-10-09T02:10:15+00:00",
        "closed_at": null,
        "comments_count": [
            "seiriosPlus",
            "freefreesea",
            "freefreesea",
            "freefreesea",
            "seiriosPlus",
            "freefreesea",
            "freefreesea",
            "freefreesea",
            "freefreesea",
            "seiriosPlus",
            "freefreesea",
            "freefreesea"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 834,
        "title": "continuous evaluation test不能直接使用，需要加入一个库。",
        "body": "如题，直接跑的话会报错KeyError。需要导入这个库：https://github.com/PaddlePaddle/continuous_evaluation，并配置环境变量的路径。",
        "state": "open",
        "user": "cstghitpku",
        "closed_by": null,
        "created_at": "2019-10-25T03:37:27+00:00",
        "updated_at": "2019-11-11T10:23:21+00:00",
        "closed_at": null,
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 835,
        "title": "机器翻译里面的数据集下载有问题",
        "body": "\r\n\r\n详情见上传的附件。\r\n![WechatIMG831](https://user-images.githubusercontent.com/45337802/67646345-a57f2900-f968-11e9-967e-6b92b187ab58.png)\r\n",
        "state": "open",
        "user": "luckeriam",
        "closed_by": null,
        "created_at": "2019-10-28T01:52:34+00:00",
        "updated_at": "2019-10-31T10:45:35+00:00",
        "closed_at": null,
        "comments_count": [
            "guoshengCS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 837,
        "title": "book的docker拉下来，一直显示http://127.0.0.1:8888/files/.tools/theme/marked.js无法访问",
        "body": "docker内的web server是不是配置了不允许访问隐藏文件夹？",
        "state": "open",
        "user": "SweetZone",
        "closed_by": null,
        "created_at": "2019-12-04T06:19:19+00:00",
        "updated_at": "2019-12-04T22:23:39+00:00",
        "closed_at": null,
        "comments_count": [
            "zhiqiu",
            "SweetZone"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 836,
        "title": "06.情感分析示例中，如何得到句子转化成的向量",
        "body": "在情感分析的示例中，待预测的句子会转化为向量吗？我要如何得到转化后的向量呢。又是以怎样的标准判断一个句子为正面评价或是负面评价的可能性的呢，是通过对向量进行比较吗？",
        "state": "open",
        "user": "Bennu-Li",
        "closed_by": null,
        "created_at": "2019-12-03T09:25:30+00:00",
        "updated_at": "2019-12-23T08:57:08+00:00",
        "closed_at": null,
        "comments_count": [
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 838,
        "title": "docker run -d -p 8888:8888 hub.baidubce.com/paddlepaddle/book后，html显示报错，所有模块都一样",
        "body": "![image](https://user-images.githubusercontent.com/14163941/70767838-aeec1580-1d9d-11ea-8113-6f265219111b.png)\r\n",
        "state": "open",
        "user": "zhengxijiang",
        "closed_by": null,
        "created_at": "2019-12-13T03:43:09+00:00",
        "updated_at": "2019-12-13T03:49:22+00:00",
        "closed_at": null,
        "comments_count": [
            "zhengxijiang",
            "zhengxijiang",
            "zhengxijiang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 848,
        "title": "07.label_semantic_roles 如何保存 crf_decode, infer 如何 decode？",
        "body": "https://github.com/PaddlePaddle/book/blob/develop/07.label_semantic_roles/train.py\r\n这个代码中，save_inference_model 时有个todo  改为存储 crf_decode ，但是一直没有完成。\r\n\r\n自己改为 save crf_decode  后，infer 就出错了。\r\n\r\n请问这个有参考代码么？\r\n谢谢",
        "state": "closed",
        "user": "linghaolu",
        "closed_by": "linghaolu",
        "created_at": "2020-04-13T02:24:54+00:00",
        "updated_at": "2020-04-13T08:13:12+00:00",
        "closed_at": "2020-04-13T08:12:18+00:00",
        "comments_count": [
            "linghaolu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 849,
        "title": "基于栈式双向LSTM的情感识别 GPU训练报错",
        "body": "> step: 194, Metrics [array([0.24539784], dtype=float32), array([0.921875], dtype=float32)]\r\nstep: 195, Metrics [array([0.4097221], dtype=float32), array([0.8], dtype=float32)]\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"SA_Test.py\", line 252, in <module>\r\n    main(use_cuda)\r\n  File \"SA_Test.py\", line 246, in main\r\n    infer(use_cuda, params_dirname)\r\n  File \"SA_Test.py\", line 234, in infer\r\n    return_numpy=False)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 831, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 902, in _run_program\r\n    self._feed_data(program, feed, feed_var_name, scope)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 580, in _feed_data\r\n    check_feed_shape_type(var, cur_feed)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 230, in check_feed_shape_type\r\n    (var.name, len(var.shape), var.shape, feed_shape))\r\nValueError: The feeded Variable 'words' should have dimensions = 1, shape = (-1,), but received feeded shape [-1, 1] on each device\r\n>\r\n用的代码：[https://github.com/PaddlePaddle/book/blob/develop/06.understand_sentiment/train_stacked_lstm.py](url)\r\n没有修改任何部分 运行指令：\r\n`python SA_Test.py --use_gpu 1`",
        "state": "open",
        "user": "AlucardNosferatu",
        "closed_by": "AlucardNosferatu",
        "created_at": "2020-04-18T15:50:33+00:00",
        "updated_at": "2020-06-03T17:17:52+00:00",
        "closed_at": null,
        "comments_count": [
            "AlucardNosferatu",
            "miaomiao3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 851,
        "title": "Network structure not consistent with proposed DCGAN",
        "body": "The original DCGAN proposed to replace all fully connected layers with convolutional layers. But in the DCGAN implementation in PaddlePaddle, the developer used a fully connected layer as the last layer in both the generator and discriminator. This may raise an inconsistent result.",
        "state": "closed",
        "user": "a411919924",
        "closed_by": "a411919924",
        "created_at": "2020-05-09T13:46:21+00:00",
        "updated_at": "2020-05-11T22:28:59+00:00",
        "closed_at": "2020-05-11T22:28:58+00:00",
        "comments_count": [
            "ceci3",
            "a411919924"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 852,
        "title": "06情感分析，案例data type报错",
        "body": "运行情感分析案例，最后一步报错：The data type of fed Variable 'words' must be 'int64', but received 'int32'",
        "state": "open",
        "user": "lfc07",
        "closed_by": null,
        "created_at": "2020-05-14T03:23:02+00:00",
        "updated_at": "2020-05-15T06:12:55+00:00",
        "closed_at": null,
        "comments_count": [
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 853,
        "title": "06情感分析代码出现维度错误",
        "body": "错误提示如下，使用的是CNN模型\r\n/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py:782: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"cnn.py\", line 203, in <module>\r\n    main(use_cuda)\r\n  File \"cnn.py\", line 197, in main\r\n    infer(use_cuda, params_dirname)\r\n  File \"cnn.py\", line 178, in infer\r\n    fetch_list=fetch_targets)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 783, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 778, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 831, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 902, in _run_program\r\n    self._feed_data(program, feed, feed_var_name, scope)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 580, in _feed_data\r\n    check_feed_shape_type(var, cur_feed)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 230, in check_feed_shape_type\r\n    (var.name, len(var.shape), var.shape, feed_shape))\r\nValueError: The fed Variable u'words' should have dimensions = 1, shape = (-1L,), but received fed shape [-1, 1L] on each device\r\naistudio@jupyter-284539-468867:~/work$ ",
        "state": "closed",
        "user": "Er1-x",
        "closed_by": "Er1-x",
        "created_at": "2020-05-20T08:13:22+00:00",
        "updated_at": "2020-05-26T02:24:34+00:00",
        "closed_at": "2020-05-26T02:24:34+00:00",
        "comments_count": [
            "Aurelius84",
            "Er1-x",
            "Er1-x",
            "lfchener",
            "Er1-x",
            "Aurelius84"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 855,
        "title": "语义序列标注修改输入出现的问题",
        "body": "在学习 语义序列标注 官方案例时\r\n利用那个构造了 ipynb文件。\r\n在没有进行修改前完美运行。\r\n尝试修改数据结构，即把emb_layer修改成【word，verb】层，而不是之前的8层\r\n并且对数据读取后也进行了处理，处理为【word,verb】的形式，出现了一系列错误\r\n现在把ipynb文件放进来，请大佬们看一下是哪里的问题？\r\n[label_semantic_roles.zip](https://github.com/PaddlePaddle/book/files/4686424/label_semantic_roles.zip)\r\n\r\n",
        "state": "closed",
        "user": "Gs-Zhang",
        "closed_by": "gongweibao",
        "created_at": "2020-05-27T04:22:15+00:00",
        "updated_at": "2020-05-28T07:12:58+00:00",
        "closed_at": "2020-05-28T07:12:58+00:00",
        "comments_count": [
            "Gs-Zhang",
            "gongweibao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 856,
        "title": "图像分类的代码运行到训练部分报错",
        "body": "代码：train_loop()\r\n\r\n报错信息：\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-27-6590b82f66d8> in <module>\r\n----> 1 train_loop()\r\n\r\n<ipython-input-26-373fd84903b7> in train_loop()\r\n     28 \r\n     29         avg_cost_test, accuracy_test = train_test(test_program,\r\n---> 30                                                   reader=test_reader)\r\n     31         plot_cost.append(test_prompt, step, avg_cost_test)\r\n     32 \r\n\r\n<ipython-input-25-cf0c981baf25> in train_test(program, reader)\r\n     32         avg_cost_np = test_exe.run(program=program,\r\n     33                                    feed=feeder_test.feed(test_data),\r\n---> 34                                    fetch_list=[avg_cost, acc])\r\n     35         accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\r\n     36         count += 1\r\n\r\n/opt/conda/lib/python3.6/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    781                 warnings.warn(\r\n    782                     \"The following exception is not an EOF exception.\")\r\n--> 783             six.reraise(*sys.exc_info())\r\n    784 \r\n    785     def _run_impl(self, program, feed, fetch_list, feed_var_name,\r\n\r\n/opt/conda/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n/opt/conda/lib/python3.6/site-packages/paddle/fluid/executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    776                 scope=scope,\r\n    777                 return_numpy=return_numpy,\r\n--> 778                 use_program_cache=use_program_cache)\r\n    779         except Exception as e:\r\n    780             if not isinstance(e, core.EOFException):\r\n\r\n/opt/conda/lib/python3.6/site-packages/paddle/fluid/executor.py in _run_impl(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    829                 scope=scope,\r\n    830                 return_numpy=return_numpy,\r\n--> 831                 use_program_cache=use_program_cache)\r\n    832 \r\n    833         program._compile(scope, self.place)\r\n\r\n/opt/conda/lib/python3.6/site-packages/paddle/fluid/executor.py in _run_program(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n    903         if not use_program_cache:\r\n    904             self._default_executor.run(program.desc, scope, 0, True, True,\r\n--> 905                                        fetch_var_name)\r\n    906         else:\r\n    907             self._default_executor.run_prepared_ctx(ctx, scope, False, False,\r\n\r\nRuntimeError: boost::bad_get: failed value get using boost::get\r\nGather\r\n<Figure size 432x288 with 0 Axes>",
        "state": "open",
        "user": "luckeriam",
        "closed_by": null,
        "created_at": "2020-05-29T08:51:40+00:00",
        "updated_at": "2020-06-01T07:20:43+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "luckeriam",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 854,
        "title": "fit_a_line的示例中，数据的归一化处理时，应该只使用train data。",
        "body": "飞桨官网上的教程里的做法是正确的\r\nhttps://www.paddlepaddle.org.cn/tutorials/projectdetail/392090\r\n这份文档里也应该更新一下。\r\n\r\nbook/01.fit_a_line/README.cn.md\r\n",
        "state": "open",
        "user": "jzhang533",
        "closed_by": null,
        "created_at": "2020-05-26T10:48:21+00:00",
        "updated_at": "2020-05-29T10:57:53+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": [
            "bug"
        ]
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 859,
        "title": "01.fit_a_line预测结果差异较大",
        "body": "infer results: (House Price)\r\n0: 13.79\r\n1: 14.05\r\n2: 13.57\r\n3: 15.91\r\n4: 14.50\r\n5: 15.57\r\n6: 14.89\r\n7: 14.78\r\n8: 11.73\r\n9: 14.28\r\n\r\nground truth:\r\n0: 8.50\r\n1: 5.00\r\n2: 11.90\r\n3: 27.90\r\n4: 17.20\r\n5: 27.50\r\n6: 15.00\r\n7: 17.20\r\n8: 17.90\r\n9: 16.30\r\n\r\n预测结果和实际结果差别有点大，主要是什么原因导致的？该现象是否正常？",
        "state": "closed",
        "user": "yuewuya20180928",
        "closed_by": "yuewuya20180928",
        "created_at": "2020-07-29T10:23:24+00:00",
        "updated_at": "2020-08-11T07:29:16+00:00",
        "closed_at": "2020-08-11T07:29:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 860,
        "title": "无法访问隐藏文件",
        "body": "在index.html 里总是加载不出来内容，提示　hidden file无法access。仔细一查　发现是　/book/.tools/theme　下的一个图片没法加载，估计是因为　.tools 为hidden file 的原因。\r\n\r\n找了半天也没找到原因，docker  里运行时明明有　allow root，\r\n\r\n只能建议阁下在新版本里能否把所有的隐藏文件不再隐藏？这样或可以解决问题。",
        "state": "closed",
        "user": "WangHaiYang874",
        "closed_by": "WangHaiYang874",
        "created_at": "2020-08-07T06:30:15+00:00",
        "updated_at": "2023-06-15T21:07:18+00:00",
        "closed_at": "2023-06-15T21:07:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 857,
        "title": "房价预测代码跑错误",
        "body": "环境：GPU-T4\r\nCPU-2C\r\n内存-4G\r\npaddle版本：1.7.1\r\npython：3\r\n\r\n\r\n出现问题的代码：\r\nfeature_names = [\r\n    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\r\n    'PTRATIO', 'B', 'LSTAT', 'convert'\r\n]\r\nfeature_num = len(feature_names)\r\ndata = numpy.fromfile(filename, sep=' ') # 从文件中读取原始数据\r\ndata = data.reshape(data.shape[0] // feature_num, feature_num)\r\nmaximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0)/data.shape[0]\r\n\r\nfor i in six.moves.range(feature_num-1):\r\n   data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i]) # six.moves可以兼容python2和python3\r\n\r\nratio = 0.8 # 训练集和验证集的划分比例\r\noffset = int(data.shape[0]*ratio)\r\ntrain_data = data[:offset]\r\ntest_data = data[offset:]\r\n\r\ndef reader_creator(train_data):  \r\n    def reader():  \r\n        for d in train_data:  \r\n            yield d[:-1], d[-1:]  \r\n    return reader\r\n\r\ntrain_reader = paddle.batch(\r\n    paddle.reader.shuffle(\r\n        reader_creator(train_data), buf_size=500),\r\n        batch_size=BATCH_SIZE)\r\n\r\ntest_reader = paddle.batch(\r\n    paddle.reader.shuffle(\r\n        reader_creator(test_data), buf_size=500),\r\n        batch_size=BATCH_SIZE)\r\n\r\n出现的报错信息：\r\n\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-5-0ca5a969836b> in <module>\r\n      4 ]\r\n      5 feature_num = len(feature_names)\r\n----> 6 data = numpy.fromfile(filename, sep=' ') # 从文件中读取原始数据\r\n      7 data = data.reshape(data.shape[0] // feature_num, feature_num)\r\n      8 maximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0)/data.shape[0]\r\n\r\nNameError: name 'filename' is not defined",
        "state": "closed",
        "user": "luckeriam",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-05-29T09:37:24+00:00",
        "updated_at": "2020-06-03T01:48:51+00:00",
        "closed_at": "2020-06-03T01:48:51+00:00",
        "comments_count": [
            "wanghaoshuang",
            "luckeriam",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 907,
        "title": "通过DCGAN实现人脸图像生成",
        "body": "",
        "state": "closed",
        "user": "Siyou-Li",
        "closed_by": "Siyou-Li",
        "created_at": "2020-10-09T06:15:21+00:00",
        "updated_at": "2020-10-09T06:39:20+00:00",
        "closed_at": "2020-10-09T06:39:20+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 858,
        "title": "机器翻译infer报错",
        "body": "\"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"seq2seq.py\", line 343, in <module>\r\n    main(use_cuda)\r\n  File \"seq2seq.py\", line 338, in main\r\n    infer(use_cuda)\r\n  File \"seq2seq.py\", line 319, in infer\r\n    seq_ids = exe.run(prog, feed=data, fetch_list=[predict_seqs])[0]\r\n\r\n用的是demo代码，未做修改，paddle版本1.6.1，python版本2.7.13",
        "state": "open",
        "user": "chopperm",
        "closed_by": null,
        "created_at": "2020-06-08T03:32:57+00:00",
        "updated_at": "2021-01-14T07:14:59+00:00",
        "closed_at": null,
        "comments_count": [
            "heavengate",
            "zhaowenfeng555",
            "zhaowenfeng555",
            "zhaowenfeng555",
            "zhaowenfeng555",
            "lfchener"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 908,
        "title": "认领 题目：通过AutoEncoder实现时序数据异常检测",
        "body": "认领 题目：通过AutoEncoder实现时序数据异常检测",
        "state": "closed",
        "user": "liu824",
        "closed_by": "liu824",
        "created_at": "2020-10-09T07:28:39+00:00",
        "updated_at": "2020-10-13T03:56:18+00:00",
        "closed_at": "2020-10-13T03:56:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 905,
        "title": "[Call for Contribution] Tutorials for PaddlePaddle 2.0（基于飞桨2.0的应用案例教程建设）",
        "body": "## 1. 目标\r\n\r\n目前飞桨2.0 RC1版本已经发布，不久的将来即将发布2.0正式版，在2.0版本中，飞桨深度学习框架面向用户体验做了一系列的升级优化：API体系的全面升级以及命令式编程（动态图）能力的全面完善；系统优化了飞桨基础API的目录结构，全面修复了历史遗留的相关问题，并对API做了充分补充，特别是提供了更为完善的高层API功能；同时提供了对动态图的量化训练、混合精度训练的支持，动静转换实现了完备的语法支持，并且易用性大幅提升，动态图相关功能趋于完善，默认推荐使用动态图模式；数据处理、组网方式、模型训练、多卡启动、模型保存和推理等开发流程都有了对应优化；此外，推理库的C++接口也做了升级优化，推理库对量化模型的支持以及推理性能都有了全面增强。\r\n\r\n这是飞桨框架的一个全新版本，为了能够让用户快速掌握到飞桨框架升级内容，并了解和学习如何使用2.0进行相关任务的开发，我们进行应用案例教程的立项，在不同的任务场景上为用户提供一个端到端的易学案例，来快速的传递相关知识和使用方法。\r\n\r\n在此呼吁广大的飞桨开发者来一起共建我们的应用案例教程，努力为用户提供更加优质的示例教程，为用户学会使用框架铺设一条高速公路。\r\n\r\n## 2. 教程清单\r\n\r\n目前我们从已有内容和待补充方向进行了初步评估，梳理了以下建议的选题方向和题目，并为大家提供了比较优秀的对标文章进行学习参考，大家可以从这个列表中选择自己想要进行贡献的题目，或者也可以进行非列表内的题目自选。\r\n\r\n### 招募列表\r\n\r\n| 类别         | 标题                          | 参考链接                                                     | 已认领作者ID                                    |\r\n| ------------ | ----------------------------- | ------------------------------------------------------------ | ----------------------------------------------- |\r\n| 计算机视觉   | 通过OCR实现验证码识别         | <https://keras.io/examples/vision/captcha_ocr/>              | [GT-ZhangAcer](https://github.com/GT-ZhangAcer) |\r\n| 计算机视觉   | 基于fine-tuning的图像分类     | <https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/> | [zky001](https://github.com/zky001)             |\r\n| 计算机视觉   | 通过Sub-Pixel实现图像超分辨率 | <https://keras.io/examples/vision/super_resolution_sub_pixel/> | [ralph0813](https://github.com/ralph0813) |\r\n| 自然语言处理 | 基于seq2seq的文本加法         | <https://keras.io/examples/nlp/addition_rnn/>                | [jm12138](https://github.com/jm12138) |\r\n| 自然语言处理 | 使用预训练的词向量            | <https://keras.io/examples/nlp/pretrained_word_embeddings/>  | [fiyen](https://github.com/fiyen) |\r\n| 自然语言处理 | 基于Bert的语义相似度计算      | <https://keras.io/examples/nlp/semantic_similarity_with_bert/> | [wangxiao1021](https://github.com/wangxiao1021) |\r\n| 自然语言处理 | 通过transformer实现文本分类   | <https://keras.io/examples/nlp/text_classification_with_transformer/> | [YinHang2515](https://github.com/YinHang2515)   |\r\n| 生成模型     | 通过DCGAN实现人脸图像生成     | <https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html> | [ZMpursue](https://github.com/ZMpursue)         |\r\n| 生成模型     | 通过CycleGAN实现图像风格迁移  | <https://keras.io/examples/generative/cyclegan/>             | [ctkindle](https://github.com/ctkindle) |\r\n| 结构化数据   | 信用卡反欺诈-样本不均衡下的分类任务 | <https://keras.io/examples/structured_data/imbalanced_classification/> |[davidlinhl](https://github.com/davidlinhl)|\r\n| 时序数据     | 通过AutoEncoder实现时序数据异常检测 | <https://keras.io/examples/timeseries/timeseries_anomaly_detection/> |[Reatris](https://github.com/Reatris)|\r\n| 计算机视觉  | 卷积层可视化 |  https://keras.io/examples/vision/visualizing_what_convnets_learn/  |    |\r\n| 计算机视觉  | 使用PointNet实现点云分类  |  https://keras.io/examples/vision/pointnet/  |   |\r\n| 计算机视觉 | 使用Retinanet实现目标检测 | https://keras.io/examples/vision/retinanet/ |   |\r\n| 自然语言处理 | 基于Bert实现智能写诗 | https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/advanced_use/nlp_bert_poetry.html |   |  \r\n| 自然语言处理 | 相声文本生成 | https://zhuanlan.zhihu.com/p/42568781 |   |\r\n| 自然语言处理 | 图片描述 | https://www.tensorflow.org/tutorials/text/image_captioning?hl=en |   |\r\n| 强化学习 | Actor Critic Method | https://keras.io/examples/rl/actor_critic_cartpole/|   |\r\n| 生成对抗网络 | 通过StackGAN输入文本生成图像 | https://arxiv.org/pdf/1612.03242v1.pdf |   |\r\n| 生成对抗网络 | 使用DanceNet自动生成舞蹈 | https://zhuanlan.zhihu.com/p/41946184|   |\r\n| 时序数据 | 时序数据预测：天气预报 | https://keras.io/examples/timeseries/timeseries_weather_forecasting/ |   |\r\n| 推荐 | 使用协同过滤实现电影推荐 | https://keras.io/examples/structured_data/collaborative_filtering_movielens/ |   | \r\n\r\n### 招募列表外开发者主动贡献列表\r\n\r\n| 标题 | 已认领作者ID |\r\n|---|---|\r\n|关键点检测方法及应用|[zzs95](https://github.com/zzs95)|\r\n\r\n## 3. 贡献指南\r\n\r\n### 3.1 飞桨框架2.0版本安装和使用\r\n\r\n1. 飞桨（PaddlePaddle）版本统一使用2.0最新版，安装说明：<https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/install/index_cn.html>。\r\n2. 2.0版本使用教程：<https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/guides/index_cn.html>。\r\n3. 2.0版本已有应用实践教程：<https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/tutorial/index_cn.html>。\r\n\r\n### 3.2 题目认领\r\n\r\n1. 可以在上面提供的列表中进行题目选择或自选题目，并将确定的题目回复到本Issue中，方便他人同步知晓已开展的文章列表信息，避免重复选题。\r\n\r\n### 3.3 教程编写\r\n\r\n1. 应用案例教程统一使用Notebook格式（.ipynb）来进行编写，可以在本地安装使用Jupyter开发，或使用AIStudio（<https://aistudio.baidu.com>）。\r\n\r\n2. 为了方便大家进行教程的编写，并统一阅读体验，下面为大家提供了一个简单的概要框架，大家根据实际任务按照下面的框架结构进行内容编写和组织，可以结合实际场景进行微调。如果对模板有一些建议我们也可以在下面进行回复讨论。\r\n\r\n   ```markdown\r\n   # 题目\r\n   \r\n   作者信息：Github ID (github个人主页URL)\r\n   \r\n   ## 1. 简要介绍\r\n   简单的一段文字介绍本案例场景和用到的一些知识点，不用太复杂的讲述知识细节，\r\n   \r\n   ## 2. 环境设置\r\n   导入包，运行一些初始化方法\r\n   \r\n   ## 3. 数据集\r\n   讲述数据集的一些基础信息，描述数据集组成等。进行数据集的下载、抽样查看、数据集定义等。\r\n   \r\n   ## 4. 模型组网\r\n   基于Layer定义模型网络结构，模型的可视化展示。可以概要讲述一些网络结构代码设计的原因。\r\n   \r\n   ## 5. 模型训练\r\n   使用模型网络结构和数据集进行模型训练。需要讲述一些实践中的知识点。\r\n   \r\n   ## 6. 模型评估\r\n   使用评估数据评估训练好的模型。\r\n   \r\n   ## 7. 模型预测\r\n   对模型进行预测，展示效果。\r\n   ```\r\n\r\n### 3.4 教程上传\r\n\r\n1. 写好的文档通过向[https://github.com/PaddlePaddle/book](https://github.com/PaddlePaddle/book)仓库提交Pull Request的方式来进行教程文档的上传。\r\n2. 对提交好的PR可以指定Reviewer（[saxon-zh](https://github.com/saxon-zh)、[jzhang533](https://github.com/jzhang533)、[TCChenlong](https://github.com/TCChenlong)）进行内容和代码的评审，通过后会由具有Merge权限的同学进行最终的合入。\r\n\r\n### 3.5 一些原则\r\n\r\n* 代码封装得当，易读性好，不用一些随意的变量/类/函数命名。\r\n* 注释清晰，不仅说明做了什么，也要说明为什么这么做。\r\n* 文字部分暂时不用考虑国际化，先统一使用中文编写，注意概念和描述的清晰度，尽量让大家通俗易懂，如果实在难以解释，可以给出一些能够详细介绍的页面链接。\r\n* 代码编写过程中能使用高层API的部分就使用高层API，无法使用高层API的部分就使用基础API。高层API使用指南：[链接](https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/tutorial/quick_start/high_level_api/high_level_api.html)\r\n* 做好代码的自测工作，每段代码块需要有运行结果。\r\n\r\n## 4. 已合入仓库的教程\r\n\r\n目前已经有13篇基于飞桨2.0的教程贡献，查看方式：\r\n\r\n1. Repo目录查看已经Merge的Notebook源文件：[https://github.com/PaddlePaddle/book/tree/develop/paddle2.0_docs](https://github.com/PaddlePaddle/book/tree/develop/paddle2.0_docs)。\r\n2. 查看官网渲染后的页面：[https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/tutorial/index_cn.html](https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-beta/tutorial/index_cn.html)。\r\n\r\n## 5. 还有不清楚的怎么办？\r\n\r\n欢迎大家随时在这个Issue下进行提问。\r\n\r\n\r\n\r\n**非常感谢大家一起来贡献！共建飞桨繁荣社区！**",
        "state": "open",
        "user": "saxon-zh",
        "closed_by": null,
        "created_at": "2020-09-24T16:25:44+00:00",
        "updated_at": "2021-03-08T10:24:47+00:00",
        "closed_at": null,
        "comments_count": [
            "Reatris",
            "GT-ZhangAcer",
            "YinHang2515",
            "zky001",
            "Siyou-Li",
            "wangxiao1021",
            "ralph0813",
            "jm12138",
            "zzs95",
            "fiyen",
            "ctkindle",
            "shaunhurryup",
            "linhandev",
            "liu824",
            "Reatris",
            "liu824",
            "SunHao-TSU",
            "TCChenlong",
            "Reatris",
            "SunHao-TSU",
            "ctkindle",
            "lwbmowgli",
            "DawnMagnet",
            "Reatris",
            "EastSmith",
            "YinHang2515",
            "Kqnonrime",
            "fiyen",
            "liu824",
            "WhiteFireFox",
            "Siyou-Li",
            "ctkindle",
            "Kqnonrime",
            "WhiteFireFox",
            "guojiahuiEmily"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 935,
        "title": "test bot",
        "body": "hi",
        "state": "open",
        "user": "swtkiwi",
        "closed_by": null,
        "created_at": "2020-11-25T10:13:17+00:00",
        "updated_at": "2021-05-12T14:27:37+00:00",
        "closed_at": null,
        "comments_count": [
            "huan",
            "jzhang533",
            "huan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/book",
        "number": 950,
        "title": "typo in image",
        "body": "https://www.paddlepaddle.org.cn/tutorials/projectdetail/1515071\r\n![图片](https://user-images.githubusercontent.com/35131887/108653977-bf039700-7502-11eb-8bb9-6372993bb0a3.png)\r\n",
        "state": "closed",
        "user": "houj04",
        "closed_by": "TCChenlong",
        "created_at": "2021-02-22T03:40:35+00:00",
        "updated_at": "2021-02-23T09:27:14+00:00",
        "closed_at": "2021-02-23T09:27:14+00:00",
        "comments_count": [
            "TCChenlong"
        ],
        "labels": []
    }
]